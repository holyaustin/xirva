[{"id": "1404.0075", "submitter": "EPTCS", "authors": "Ed Blakey (University of Bristol)", "title": "Ray tracing -- computing the incomputable?", "comments": "In Proceedings DCM 2012, arXiv:1403.7579", "journal-ref": "EPTCS 143, 2014, pp. 32-40", "doi": "10.4204/EPTCS.143.3", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recall from previous work a model-independent framework of computational\ncomplexity theory. Notably for the present paper, the framework allows\nformalization of the issues of precision that present themselves when one\nconsiders physical, error-prone (especially analogue rather than digital)\ncomputational systems. We take as a case study the ray-tracing problem, a\nTuring-machine-incomputable problem that can, in apparent violation of the\nChurch-Turing thesis, nonetheless be said to be solved by certain optical\ncomputers; however, we apply the framework of complexity theory so as to\nformalize the intuition that the purported super-Turing power of these\ncomputers in fact vanishes once precision is properly considered.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2014 00:37:14 GMT"}], "update_date": "2014-04-02", "authors_parsed": [["Blakey", "Ed", "", "University of Bristol"]]}, {"id": "1404.0077", "submitter": "Evira Mayordomo", "authors": "Elvira Mayordomo", "title": "Effective dimension in some general metric spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of effective dimension for a wide class of metric\nspaces that are not required to have a computable measure. Effective dimension\nwas defined by Lutz in (Lutz 2003) for Cantor space and has also been extended\nto Euclidean space. Lutz effectivization uses the concept of gale and\nsupergale, our extension of Hausdorff dimension to other metric spaces is also\nbased on a supergale characterization of dimension, which in practice avoids an\nextra quantifier present in the classical definition of dimension that is based\non Hausdorff measure and therefore allows effectivization for small\ntime-bounds.\n  We present here the concept of constructive dimension and its\ncharacterization in terms of Kolmogorov complexity, for which we extend the\nconcept of Kolmogorov complexity to any metric space defining the Kolmogorov\ncomplexity of a point at a certain precision. Further research directions are\nindicated.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2014 00:37:42 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 11:02:49 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Mayordomo", "Elvira", ""]]}, {"id": "1404.0117", "submitter": "George Mertzios", "authors": "Josep Diaz and George B. Mertzios", "title": "Minimum Bisection is NP-hard on Unit Disk Graphs", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove that the \\textsc{Min-Bisection} problem is NP-hard on\n\\emph{unit disk graphs}, thus solving a longstanding open question.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2014 03:31:55 GMT"}, {"version": "v2", "created": "Fri, 4 Apr 2014 00:44:11 GMT"}, {"version": "v3", "created": "Thu, 27 Apr 2017 17:27:28 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Diaz", "Josep", ""], ["Mertzios", "George B.", ""]]}, {"id": "1404.0337", "submitter": "Paul Bonsma", "authors": "Paul Bonsma and Amer E. Mouawad", "title": "The Complexity of Bounded Length Graph Recoloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following question: Given are two $k$-colorings $\\alpha$ and\n$\\beta$ of a graph $G$ on $n$ vertices, and integer $\\ell$. The question is\nwhether $\\alpha$ can be modified into $\\beta$, by recoloring vertices one at a\ntime, while maintaining a $k$-coloring throughout, and using at most $\\ell$\nsuch recoloring steps. This problem is weakly PSPACE-hard for every constant\n$k\\ge 4$. We show that it is also strongly NP-hard for every constant $k\\ge 4$.\nOn the positive side, we give an $O(f(k,\\ell) n^{O(1)})$ algorithm for the\nproblem, for some computable function $f$. Hence the problem is fixed-parameter\ntractable when parameterized by $k+\\ell$. Finally, we show that the problem is\nW[1]-hard (but in XP) when parameterized only by $\\ell$.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2014 18:38:49 GMT"}, {"version": "v2", "created": "Wed, 16 Apr 2014 11:04:26 GMT"}], "update_date": "2014-04-17", "authors_parsed": [["Bonsma", "Paul", ""], ["Mouawad", "Amer E.", ""]]}, {"id": "1404.0606", "submitter": "Andr\\'e Frochaux", "authors": "Andr\\'e Frochaux and Martin Grohe and Nicole Schweikardt", "title": "Monadic Datalog Containment on Trees", "comments": "This article is the full version of an article published in the\n  proccedings of the 8th Alberto Mendelzon Workshop (AMW 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the query containment problem for monadic datalog on finite\nunranked labeled trees can be solved in 2-fold exponential time when (a)\nconsidering unordered trees using the axes child and descendant, and when (b)\nconsidering ordered trees using the axes firstchild, nextsibling, child, and\ndescendant. When omitting the descendant-axis, we obtain that in both cases the\nproblem is EXPTIME-complete.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 16:34:17 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Frochaux", "Andr\u00e9", ""], ["Grohe", "Martin", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "1404.0653", "submitter": "Greta Panova", "authors": "Igor Pak and Greta Panova", "title": "On the complexity of computing Kronecker coefficients", "comments": "v3: incorporated referee's comments; accepted to Computational\n  Complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of computing Kronecker coefficients\n$g(\\lambda,\\mu,\\nu)$. We give explicit bounds in terms of the number of parts\n$\\ell$ in the partitions, their largest part size $N$ and the smallest second\npart $M$ of the three partitions. When $M = O(1)$, i.e. one of the partitions\nis hook-like, the bounds are linear in $\\log N$, but depend exponentially on\n$\\ell$. Moreover, similar bounds hold even when $M=e^{O(\\ell)}$. By a separate\nargument, we show that the positivity of Kronecker coefficients can be decided\nin $O(\\log N)$ time for a bounded number $\\ell$ of parts and without\nrestriction on $M$. Related problems of computing Kronecker coefficients when\none partition is a hook, and computing characters of $S_n$ are also considered.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 19:01:31 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 08:00:32 GMT"}, {"version": "v3", "created": "Tue, 24 Feb 2015 02:42:58 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Pak", "Igor", ""], ["Panova", "Greta", ""]]}, {"id": "1404.0654", "submitter": "Gil Cohen", "authors": "Gil Cohen, Avishay Tal", "title": "Two Structural Results for Low Degree Polynomials and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, two structural results concerning low degree polynomials over\nfinite fields are given. The first states that over any finite field\n$\\mathbb{F}$, for any polynomial $f$ on $n$ variables with degree $d \\le\n\\log(n)/10$, there exists a subspace of $\\mathbb{F}^n$ with dimension $\\Omega(d\n\\cdot n^{1/(d-1)})$ on which $f$ is constant. This result is shown to be tight.\nStated differently, a degree $d$ polynomial cannot compute an affine disperser\nfor dimension smaller than $\\Omega(d \\cdot n^{1/(d-1)})$. Using a recursive\nargument, we obtain our second structural result, showing that any degree $d$\npolynomial $f$ induces a partition of $F^n$ to affine subspaces of dimension\n$\\Omega(n^{1/(d-1)!})$, such that $f$ is constant on each part.\n  We extend both structural results to more than one polynomial. We further\nprove an analog of the first structural result to sparse polynomials (with no\nrestriction on the degree) and to functions that are close to low degree\npolynomials. We also consider the algorithmic aspect of the two structural\nresults.\n  Our structural results have various applications, two of which are:\n  * Dvir [CC 2012] introduced the notion of extractors for varieties, and gave\nexplicit constructions of such extractors over large fields. We show that over\nany finite field, any affine extractor is also an extractor for varieties with\nrelated parameters. Our reduction also holds for dispersers, and we conclude\nthat Shaltiel's affine disperser [FOCS 2011] is a disperser for varieties over\n$F_2$.\n  * Ben-Sasson and Kopparty [SIAM J. C 2012] proved that any degree 3 affine\ndisperser over a prime field is also an affine extractor with related\nparameters. Using our structural results, and based on the work of Kaufman and\nLovett [FOCS 2008] and Haramaty and Shpilka [STOC 2010], we generalize this\nresult to any constant degree.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 19:05:04 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Cohen", "Gil", ""], ["Tal", "Avishay", ""]]}, {"id": "1404.0753", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Gregory B. Sorkin", "title": "Separate, Measure and Conquer: Faster Algorithms for Max 2-CSP and\n  Counting Dominating Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a method resulting in the improvement of several polynomial-space,\nexponential-time algorithms.\n  An instance of the problem Max (r,2)-CSP, or simply Max 2-CSP, is\nparametrized by the domain size r (often 2), the number of variables n\n(vertices in the constraint graph G), and the number of constraints m (edges in\nG). When G is cubic, and omitting sub-exponential terms here for clarity, we\ngive an algorithm running in time r^((1/5)n) = r^((2/15)m); the previous best\nwas r^((1/4)n) = r^((1/6)m). By known results, this improvement for the cubic\ncase results in an algorithm running in time r^((9/50)m) for general instances;\nthe previous best was r^((19/100)m). We show that the analysis of the earlier\nalgorithm was tight: our improvement is in the algorithm, not just the\nanalysis. The new algorithm, like the old, extends to Polynomial and Ring CSP.\n  We also give faster algorithms for #Dominating Set, counting the dominating\nsets of every cardinality 0,...,n for a graph G of order n. For cubic graphs,\nour algorithm runs in time 3^((1/6)n); the previous best was 2^((1/2)n). For\ngeneral graphs, we give an unrelated algorithm running in time 1.5183^n; the\nprevious best was 1.5673^n.\n  The previous best algorithms for these problems all used local\ntransformations and were analyzed by the \"Measure and Conquer\" method. Our new\nalgorithms capitalize on the existence of small balanced separators for cubic\ngraphs - a non-local property - and the ability to tailor the local algorithms\nalways to \"pivot\" on a vertex in the separator. The new algorithms perform much\nas the old ones until the separator is empty, at which point they gain because\nthe remaining vertices are split into two independent problem instances that\ncan be solved recursively. It is likely that such algorithms can be effective\nfor other problems too, and we present their design and analysis in a general\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2014 03:19:51 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 03:25:08 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Gaspers", "Serge", ""], ["Sorkin", "Gregory B.", ""]]}, {"id": "1404.0799", "submitter": "Seth Pettie", "authors": "Allan Gr{\\o}nlund, Seth Pettie", "title": "Threesomes, Degenerates, and Love Triangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 3SUM problem is to decide, given a set of $n$ real numbers, whether any\nthree sum to zero. It is widely conjectured that a trivial $O(n^2)$-time\nalgorithm is optimal and over the years the consequences of this conjecture\nhave been revealed. This 3SUM conjecture implies $\\Omega(n^2)$ lower bounds on\nnumerous problems in computational geometry and a variant of the conjecture\nimplies strong lower bounds on triangle enumeration, dynamic graph algorithms,\nand string matching data structures.\n  In this paper we refute the 3SUM conjecture. We prove that the decision tree\ncomplexity of 3SUM is $O(n^{3/2}\\sqrt{\\log n})$ and give two subquadratic 3SUM\nalgorithms, a deterministic one running in $O(n^2 / (\\log n/\\log\\log n)^{2/3})$\ntime and a randomized one running in $O(n^2 (\\log\\log n)^2 / \\log n)$ time with\nhigh probability. Our results lead directly to improved bounds for $k$-variate\nlinear degeneracy testing for all odd $k\\ge 3$. The problem is to decide, given\na linear function $f(x_1,\\ldots,x_k) = \\alpha_0 + \\sum_{1\\le i\\le k} \\alpha_i\nx_i$ and a set $A \\subset \\mathbb{R}$, whether $0\\in f(A^k)$. We show the\ndecision tree complexity of this problem is $O(n^{k/2}\\sqrt{\\log n})$.\n  Finally, we give a subcubic algorithm for a generalization of the\n$(\\min,+)$-product over real-valued matrices and apply it to the problem of\nfinding zero-weight triangles in weighted graphs. We give a\ndepth-$O(n^{5/2}\\sqrt{\\log n})$ decision tree for this problem, as well as an\nalgorithm running in time $O(n^3 (\\log\\log n)^2/\\log n)$.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2014 08:30:03 GMT"}, {"version": "v2", "created": "Thu, 29 May 2014 10:02:28 GMT"}, {"version": "v3", "created": "Fri, 30 May 2014 19:46:20 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Gr\u00f8nlund", "Allan", ""], ["Pettie", "Seth", ""]]}, {"id": "1404.0818", "submitter": "Marcin Pilipczuk", "authors": "Daniel Lokshtanov and Marcin Pilipczuk and Micha{\\l} Pilipczuk and\n  Saket Saurabh", "title": "Fixed-parameter tractable canonization and isomorphism test for graphs\n  of bounded treewidth", "comments": "Full version of a paper presented at FOCS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a fixed-parameter tractable algorithm that, given a parameter $k$ and\ntwo graphs $G_1,G_2$, either concludes that one of these graphs has treewidth\nat least $k$, or determines whether $G_1$ and $G_2$ are isomorphic. The running\ntime of the algorithm on an $n$-vertex graph is $2^{O(k^5\\log k)}\\cdot n^5$,\nand this is the first fixed-parameter algorithm for Graph Isomorphism\nparameterized by treewidth.\n  Our algorithm in fact solves the more general canonization problem. We namely\ndesign a procedure working in $2^{O(k^5\\log k)}\\cdot n^5$ time that, for a\ngiven graph $G$ on $n$ vertices, either concludes that the treewidth of $G$ is\nat least $k$, or: * finds in an isomorphic-invariant way a graph\n$\\mathfrak{c}(G)$ that is isomorphic to $G$; * finds an isomorphism-invariant\nconstruction term --- an algebraic expression that encodes $G$ together with a\ntree decomposition of $G$ of width $O(k^4)$.\n  Hence, the isomorphism test reduces to verifying whether the computed\nisomorphic copies or the construction terms for $G_1$ and $G_2$ are equal.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2014 09:49:54 GMT"}, {"version": "v2", "created": "Wed, 10 Dec 2014 11:32:25 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Lokshtanov", "Daniel", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""], ["Saurabh", "Saket", ""]]}, {"id": "1404.0842", "submitter": "EPTCS", "authors": "Xiang Jiang (University of Cambridge), Arno Pauly (University of\n  Cambridge)", "title": "Efficient Decomposition of Bimatrix Games (Extended Abstract)", "comments": "In Proceedings SR 2014, arXiv:1404.0414", "journal-ref": "EPTCS 146, 2014, pp. 75-81", "doi": "10.4204/EPTCS.146.10", "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting the algebraic structure of the set of bimatrix games, a\ndivide-and-conquer algorithm for finding Nash equilibria is proposed. The\nalgorithm is fixed-parameter tractable with the size of the largest irreducible\ncomponent of a game as parameter. An implementation of the algorithm is shown\nto yield a significant performance increase on inputs with small parameters.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2014 10:38:45 GMT"}], "update_date": "2014-04-04", "authors_parsed": [["Jiang", "Xiang", "", "University of Cambridge"], ["Pauly", "Arno", "", "University of\n  Cambridge"]]}, {"id": "1404.0967", "submitter": "Steffen Kopecki", "authors": "Lila Kari, Steffen Kopecki, Pierre-\\'Etienne Meunier, Matthew J.\n  Patitz, Shinnosuke Seki", "title": "Binary pattern tile set synthesis is NP-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of algorithmic self-assembly, a long-standing unproven\nconjecture has been that of the NP-hardness of binary pattern tile set\nsynthesis (2-PATS). The $k$-PATS problem is that of designing a tile assembly\nsystem with the smallest number of tile types which will self-assemble an input\npattern of $k$ colors. Of both theoretical and practical significance, $k$-PATS\nhas been studied in a series of papers which have shown $k$-PATS to be NP-hard\nfor $k = 60$, $k = 29$, and then $k = 11$. In this paper, we close the\nfundamental conjecture that 2-PATS is NP-hard, concluding this line of study.\n  While most of our proof relies on standard mathematical proof techniques, one\ncrucial lemma makes use of a computer-assisted proof, which is a relatively\nnovel but increasingly utilized paradigm for deriving proofs for complex\nmathematical problems. This tool is especially powerful for attacking\ncombinatorial problems, as exemplified by the proof of the four color theorem\nby Appel and Haken (simplified later by Robertson, Sanders, Seymour, and\nThomas) or the recent important advance on the Erd\\H{o}s discrepancy problem by\nKonev and Lisitsa using computer programs. We utilize a massively parallel\nalgorithm and thus turn an otherwise intractable portion of our proof into a\nprogram which requires approximately a year of computation time, bringing the\nuse of computer-assisted proofs to a new scale. We fully detail the algorithm\nemployed by our code, and make the code freely available online.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2014 15:26:13 GMT"}], "update_date": "2014-04-04", "authors_parsed": [["Kari", "Lila", ""], ["Kopecki", "Steffen", ""], ["Meunier", "Pierre-\u00c9tienne", ""], ["Patitz", "Matthew J.", ""], ["Seki", "Shinnosuke", ""]]}, {"id": "1404.1103", "submitter": "Daniel Kane", "authors": "Daniel M. Kane", "title": "A Polylogarithmic PRG for Degree $2$ Threshold Functions in the Gaussian\n  Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise a new pseudorandom generator against degree 2 polynomial threshold\nfunctions in the Gaussian setting. We manage to achieve $\\epsilon$ error with\nseed length polylogarithmic in $\\epsilon$ and the dimension, and exponential\nimprovement over previous constructions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2014 21:34:15 GMT"}], "update_date": "2014-04-07", "authors_parsed": [["Kane", "Daniel M.", ""]]}, {"id": "1404.1191", "submitter": "Amirali Abdullah", "authors": "Amirali Abdullah and Suresh Venkatasubramanian", "title": "A directed isoperimetric inequality with application to Bregman near\n  neighbor lower bounds", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bregman divergences $D_\\phi$ are a class of divergences parametrized by a\nconvex function $\\phi$ and include well known distance functions like\n$\\ell_2^2$ and the Kullback-Leibler divergence. There has been extensive\nresearch on algorithms for problems like clustering and near neighbor search\nwith respect to Bregman divergences, in all cases, the algorithms depend not\njust on the data size $n$ and dimensionality $d$, but also on a structure\nconstant $\\mu \\ge 1$ that depends solely on $\\phi$ and can grow without bound\nindependently.\n  In this paper, we provide the first evidence that this dependence on $\\mu$\nmight be intrinsic. We focus on the problem of approximate near neighbor search\nfor Bregman divergences. We show that under the cell probe model, any\nnon-adaptive data structure (like locality-sensitive hashing) for\n$c$-approximate near-neighbor search that admits $r$ probes must use space\n$\\Omega(n^{1 + \\frac{\\mu}{c r}})$. In contrast, for LSH under $\\ell_1$ the best\nbound is $\\Omega(n^{1+\\frac{1}{cr}})$.\n  Our new tool is a directed variant of the standard boolean noise operator. We\nshow that a generalization of the Bonami-Beckner hypercontractivity inequality\nexists \"in expectation\" or upon restriction to certain subsets of the Hamming\ncube, and that this is sufficient to prove the desired isoperimetric inequality\nthat we use in our data structure lower bound.\n  We also present a structural result reducing the Hamming cube to a Bregman\ncube. This structure allows us to obtain lower bounds for problems under\nBregman divergences from their $\\ell_1$ analog. In particular, we get a\n(weaker) lower bound for approximate near neighbor search of the form\n$\\Omega(n^{1 + \\frac{1}{cr}})$ for an $r$-query non-adaptive data structure,\nand new cell probe lower bounds for a number of other near neighbor questions\nin Bregman space.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2014 09:25:35 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 14:04:51 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Abdullah", "Amirali", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1404.1323", "submitter": "Theresa Migler-VonDollen", "authors": "Glencora Borradaile and Claire Mathieu and Theresa Migler", "title": "Lower bounds for testing digraph connectivity with one-pass streaming\n  algorithms", "comments": "Added some references to previous work, removed the part of the\n  result that was already known before, and changed the label of the result\n  from \"Theorem\" to \"Lemma\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we show that three graph properties - strong connectivity,\nacyclicity, and reachability from a vertex $s$ to all vertices - each require a\nworking memory of $\\Omega (\\epsilon m)$ on a graph with $m$ edges to be\ndetermined correctly with probability greater than $(1+\\epsilon)/2$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2014 17:50:49 GMT"}, {"version": "v2", "created": "Tue, 8 Apr 2014 18:56:06 GMT"}], "update_date": "2014-04-09", "authors_parsed": [["Borradaile", "Glencora", ""], ["Mathieu", "Claire", ""], ["Migler", "Theresa", ""]]}, {"id": "1404.1366", "submitter": "Rahul Jain", "authors": "Anurag Anshu, Rahul Jain, Priyanka Mukhopadhyay, Ala Shayeghi, Penghui\n  Yao", "title": "New one shot quantum protocols with application to communication\n  complexity", "comments": "23 pages. Changed title, abstract and presentation of the paper", "journal-ref": "IEEE Transactions on Information Theory (Volume: 62, Issue: 12,\n  Dec. 2016)", "doi": "10.1109/TIT.2016.2616125", "report-no": null, "categories": "quant-ph cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the following quantum compression protocol:\n  P : Let $\\rho,\\sigma$ be quantum states such that $S(\\rho || \\sigma) =\n\\text{Tr} (\\rho \\log \\rho - \\rho \\log \\sigma)$, the relative entropy between\n$\\rho$ and $\\sigma$, is finite. Alice gets to know the eigen-decomposition of\n$\\rho$. Bob gets to know the eigen-decomposition of $\\sigma$. Both Alice and\nBob know $S(\\rho || \\sigma)$ and an error parameter $\\epsilon$. Alice and Bob\nuse shared entanglement and after communication of $\\mathcal{O}((S(\\rho ||\n\\sigma)+1)/\\epsilon^4)$ bits from Alice to Bob, Bob ends up with a quantum\nstate $\\tilde{\\rho}$ such that $F(\\rho, \\tilde{\\rho}) \\geq 1 - 5\\epsilon$,\nwhere $F(\\cdot)$ represents fidelity.\n  This result can be considered as a non-commutative generalization of a result\ndue to Braverman and Rao [2011] where they considered the special case when\n$\\rho$ and $\\sigma$ are classical probability distributions (or commute with\neach other) and use shared randomness instead of shared entanglement. We use P\nto obtain an alternate proof of a direct-sum result for entanglement assisted\nquantum one-way communication complexity for all relations, which was first\nshown by Jain, Radhakrishnan and Sen [2005,2008]. We also present a variant of\nprotocol P in which Bob has some side information about the state with Alice.\nWe show that in such a case, the amount of communication can be further\nreduced, based on the side information that Bob has.\n  Our second result provides a quantum analogue of the widely used classical\ncorrelated-sampling protocol. For example, Holenstein [2007] used the classical\ncorrelated-sampling protocol in his proof of a parallel-repetition theorem for\ntwo-player one-round games.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2014 20:45:09 GMT"}, {"version": "v2", "created": "Wed, 9 Apr 2014 04:29:29 GMT"}, {"version": "v3", "created": "Sun, 10 Aug 2014 00:56:40 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2015 07:22:18 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Anshu", "Anurag", ""], ["Jain", "Rahul", ""], ["Mukhopadhyay", "Priyanka", ""], ["Shayeghi", "Ala", ""], ["Yao", "Penghui", ""]]}, {"id": "1404.1684", "submitter": "Shenggen Zheng", "authors": "Andris Ambainis, Jozef Gruska, Shenggen Zheng", "title": "Exact quantum algorithms have advantage for almost all Boolean functions", "comments": "17 pages. Accepted to Quantum information & Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been proved that almost all $n$-bit Boolean functions have exact\nclassical query complexity $n$. However, the situation seemed to be very\ndifferent when we deal with exact quantum query complexity. In this paper, we\nprove that almost all $n$-bit Boolean functions can be computed by an exact\nquantum algorithm with less than $n$ queries. More exactly, we prove that\n${AND}_n$ is the only $n$-bit Boolean function, up to isomorphism, that\nrequires $n$ queries.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 08:05:31 GMT"}, {"version": "v2", "created": "Tue, 15 Jul 2014 14:47:41 GMT"}, {"version": "v3", "created": "Mon, 29 Sep 2014 12:54:36 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Ambainis", "Andris", ""], ["Gruska", "Jozef", ""], ["Zheng", "Shenggen", ""]]}, {"id": "1404.1689", "submitter": "Shenggen Zheng", "authors": "Jozef Gruska, Daowen Qiu, Shenggen Zheng", "title": "Potential of quantum finite automata with exact acceptance", "comments": "We have improved the presentation of the paper. Accepted to\n  International Journal of Foundation of Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential of the exact quantum information processing is an interesting,\nimportant and intriguing issue. For examples, it has been believed that quantum\ntools can provide significant, that is larger than polynomial, advantages in\nthe case of exact quantum computation only, or mainly, for problems with very\nspecial structures. We will show that this is not the case.\n  In this paper the potential of quantum finite automata producing outcomes not\nonly with a (high) probability, but with certainty (so called exactly) is\nexplored in the context of their uses for solving promise problems and with\nrespect to the size of automata. It is shown that for solving particular\nclasses $\\{A^n\\}_{n=1}^{\\infty}$ of promise problems, even those without some\nvery special structure, that succinctness of the exact quantum finite automata\nunder consideration, with respect to the number of (basis) states, can be very\nsmall (and constant) though it grows proportional to $n$ in the case\ndeterministic finite automata (DFAs) of the same power are used. This is here\ndemonstrated also for the case that the component languages of the promise\nproblems solvable by DFAs are non-regular. The method used can be applied in\nfinding more exact quantum finite automata or quantum algorithms for other\npromise problems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 08:29:54 GMT"}, {"version": "v2", "created": "Wed, 30 Apr 2014 11:57:33 GMT"}, {"version": "v3", "created": "Thu, 10 Jul 2014 15:32:18 GMT"}, {"version": "v4", "created": "Tue, 25 Nov 2014 14:22:49 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Gruska", "Jozef", ""], ["Qiu", "Daowen", ""], ["Zheng", "Shenggen", ""]]}, {"id": "1404.1741", "submitter": "Nir Ailon", "authors": "Nir Ailon", "title": "Tighter Fourier Transform Complexity Tradeoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fourier Transform is one of the most important linear transformations\nused in science and engineering. Cooley and Tukey's Fast Fourier Transform\n(FFT) from 1964 is a method for computing this transformation in time $O(n\\log\nn)$. Achieving a matching lower bound in a reasonable computational model is\none of the most important open problems in theoretical computer science.\n  In 2014, improving on his previous work, Ailon showed that if an algorithm\nspeeds up the FFT by a factor of $b=b(n)\\geq 1$, then it must rely on\ncomputing, as an intermediate \"bottleneck\" step, a linear mapping of the input\nwith condition number $\\Omega(b(n))$. Our main result shows that a factor $b$\nspeedup implies existence of not just one but $\\Omega(n)$ $b$-ill conditioned\nbottlenecks occurring at $\\Omega(n)$ different steps, each causing information\nfrom independent (orthogonal) components of the input to either overflow or\nunderflow. This provides further evidence that beating FFT is hard. Our result\nalso gives the first quantitative tradeoff between computation speed and\ninformation loss in Fourier computation on fixed word size architectures. The\nmain technical result is an entropy analysis of the Fourier transform under\ntransformations of low trace, which is interesting in its own right.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 11:01:15 GMT"}, {"version": "v10", "created": "Sun, 4 Jan 2015 10:47:05 GMT"}, {"version": "v11", "created": "Sun, 18 Jan 2015 14:14:29 GMT"}, {"version": "v12", "created": "Wed, 11 Feb 2015 11:41:56 GMT"}, {"version": "v13", "created": "Wed, 15 Apr 2015 10:58:05 GMT"}, {"version": "v2", "created": "Thu, 10 Apr 2014 06:30:03 GMT"}, {"version": "v3", "created": "Sun, 13 Apr 2014 21:21:18 GMT"}, {"version": "v4", "created": "Tue, 22 Apr 2014 23:27:52 GMT"}, {"version": "v5", "created": "Thu, 18 Sep 2014 16:08:56 GMT"}, {"version": "v6", "created": "Fri, 19 Sep 2014 14:28:58 GMT"}, {"version": "v7", "created": "Wed, 1 Oct 2014 09:07:12 GMT"}, {"version": "v8", "created": "Tue, 4 Nov 2014 17:27:01 GMT"}, {"version": "v9", "created": "Fri, 12 Dec 2014 18:43:42 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Ailon", "Nir", ""]]}, {"id": "1404.1950", "submitter": "Mrinal Kumar", "authors": "Mrinal Kumar, Shubhangi Saraf", "title": "On the power of homogeneous depth 4 arithmetic circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove exponential lower bounds on the size of homogeneous depth 4\narithmetic circuits computing an explicit polynomial in $VP$. Our results hold\nfor the {\\it Iterated Matrix Multiplication} polynomial - in particular we show\nthat any homogeneous depth 4 circuit computing the $(1,1)$ entry in the product\nof $n$ generic matrices of dimension $n^{O(1)}$ must have size\n$n^{\\Omega(\\sqrt{n})}$.\n  Our results strengthen previous works in two significant ways.\n  Our lower bounds hold for a polynomial in $VP$. Prior to our work, Kayal et\nal [KLSS14] proved an exponential lower bound for homogeneous depth 4 circuits\n(over fields of characteristic zero) computing a poly in $VNP$. The best known\nlower bounds for a depth 4 homogeneous circuit computing a poly in $VP$ was the\nbound of $n^{\\Omega(\\log n)}$ by [LSS, KLSS14].Our exponential lower bounds\nalso give the first exponential separation between general arithmetic circuits\nand homogeneous depth 4 arithmetic circuits. In particular they imply that the\ndepth reduction results of Koiran [Koi12] and Tavenas [Tav13] are tight even\nfor reductions to general homogeneous depth 4 circuits (without the restriction\nof bounded bottom fanin).\n  Our lower bound holds over all fields. The lower bound of [KLSS14] worked\nonly over fields of characteristic zero. Prior to our work, the best lower\nbound for homogeneous depth 4 circuits over fields of positive characteristic\nwas $n^{\\Omega(\\log n)}$ [LSS, KLSS14].\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 21:23:25 GMT"}], "update_date": "2014-04-09", "authors_parsed": [["Kumar", "Mrinal", ""], ["Saraf", "Shubhangi", ""]]}, {"id": "1404.2761", "submitter": "Abuzer Yakaryilmaz", "authors": "Jibran Rashid and Abuzer Yakaryilmaz", "title": "Implications of quantum automata for contextuality", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct zero-error quantum finite automata (QFAs) for promise problems\nwhich cannot be solved by bounded-error probabilistic finite automata (PFAs).\nHere is a summary of our results:\n  - There is a promise problem solvable by an exact two-way QFA in exponential\nexpected time, but not by any bounded-error sublogarithmic space probabilistic\nTuring machine (PTM).\n  - There is a promise problem solvable by an exact two-way QFA in quadratic\nexpected time, but not by any bounded-error $ o(\\log \\log n) $-space PTMs in\npolynomial expected time. The same problem can be solvable by a one-way Las\nVegas (or exact two-way) QFA with quantum head in linear (expected) time.\n  - There is a promise problem solvable by a Las Vegas realtime QFA, but not by\nany bounded-error realtime PFA. The same problem can be solvable by an exact\ntwo-way QFA in linear expected time but not by any exact two-way PFA.\n  - There is a family of promise problems such that each promise problem can be\nsolvable by a two-state exact realtime QFAs, but, there is no such bound on the\nnumber of states of realtime bounded-error PFAs solving the members this\nfamily.\n  Our results imply that there exist zero-error quantum computational devices\nwith a \\emph{single qubit} of memory that cannot be simulated by any finite\nmemory classical computational model. This provides a computational perspective\non results regarding ontological theories of quantum mechanics \\cite{Hardy04},\n\\cite{Montina08}. As a consequence we find that classical automata based\nsimulation models \\cite{Kleinmann11}, \\cite{Blasiak13} are not sufficiently\npowerful to simulate quantum contextuality. We conclude by highlighting the\ninterplay between results from automata models and their application to\ndeveloping a general framework for quantum contextuality.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2014 10:04:37 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Rashid", "Jibran", ""], ["Yakaryilmaz", "Abuzer", ""]]}, {"id": "1404.2962", "submitter": "Aleck Johnsen", "authors": "Aleck C. Johnsen, Ming-Yang Kao, Shinnosuke Seki", "title": "Computing Minimum Tile Sets to Self-Assemble Colors Patterns", "comments": null, "journal-ref": "Proceedings from the 24th International Symposium on Agorithms and\n  Computation, ISAAC 2013, Hong Kong, China. Springer-Verlag Berlin Heidelberg.\n  699-710", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patterned self-assembly tile set synthesis (PATS) aims at finding a minimum\ntile set to uniquely self-assemble a given rectangular color pattern. For $k\n\\ge 1$, $k$-PATS is a variant of PATS that restricts input patterns to those\nwith at most $k$ colors. We prove the {\\bf NP}-hardness of 29-PATS, where the\nbest known is that of 60-PATS.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2014 22:48:39 GMT"}], "update_date": "2014-04-14", "authors_parsed": [["Johnsen", "Aleck C.", ""], ["Kao", "Ming-Yang", ""], ["Seki", "Shinnosuke", ""]]}, {"id": "1404.3082", "submitter": "Juho Lauri", "authors": "Juho Lauri", "title": "Further Hardness Results on Rainbow and Strong Rainbow Connectivity", "comments": "13 pages, 4 figures", "journal-ref": "Discrete Applied Mathematics 201: 191-200 (2016)", "doi": "10.1016/j.dam.2015.07.041", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A path in an edge-colored graph is \\textit{rainbow} if no two edges of it are\ncolored the same. The graph is said to be \\textit{rainbow connected} if there\nis a rainbow path between every pair of vertices. If there is a rainbow\nshortest path between every pair of vertices, the graph is \\textit{strong\nrainbow connected}. We consider the complexity of the problem of deciding if a\ngiven edge-colored graph is rainbow or strong rainbow connected. These problems\nare called \\textsc{Rainbow connectivity} and \\textsc{Strong rainbow\nconnectivity}, respectively. We prove both problems remain $\\NP$\\hyp{}complete\non interval outerplanar graphs and $k$-regular graphs for $k \\geq 3$.\nPreviously, no graph class was known where the complexity of the two problems\nwould differ. We show that for block graphs, which form a subclass of chordal\ngraphs, \\textsc{Rainbow connectivity} is $\\NP$\\hyp{}complete while\n\\textsc{Strong rainbow connectivity} is in $\\P$. We conclude by considering\nsome tractable special cases, and show for instance that both problems are in\n$\\XP$ when parameterized by tree-depth.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2014 11:50:55 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 14:40:45 GMT"}, {"version": "v3", "created": "Sat, 24 May 2014 09:45:53 GMT"}, {"version": "v4", "created": "Wed, 17 Feb 2016 07:17:40 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Lauri", "Juho", ""]]}, {"id": "1404.3131", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli", "title": "The Possibility Problem for Probabilistic XML (Extended Version)", "comments": "20 pages, 1 table, 2 figures. This is the complete version (including\n  proofs) of work initially submitted as an extended abstract (without proofs)\n  at the AMW 2014 workshop and subsequently submitted (with proofs) at the BDA\n  2014 conference (no formal proceedings). This version integrates the feedback\n  from both rounds of reviews", "journal-ref": null, "doi": "10.3166/isi.20.5.53-75", "report-no": null, "categories": "cs.DB cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the possibility problem of determining if a document is a\npossible world of a probabilistic document, in the setting of probabilistic\nXML. This basic question is a special case of query answering or tree automata\nevaluation, but it has specific practical uses, such as checking whether an\nuser-provided probabilistic document outcome is possible or sufficiently\nlikely. In this paper, we study the complexity of the possibility problem for\nprobabilistic XML models of varying expressiveness. We show that the decision\nproblem is often tractable in the absence of long-distance dependencies, but\nthat its computation variant is intractable on unordered documents. We also\nintroduce an explicit matches variant to generalize practical situations where\nnode labels are unambiguous; this ensures tractability of the possibility\nproblem, even under long-distance dependencies, provided event conjunctions are\ndisallowed. Our results entirely classify the tractability boundary over all\nconsidered problem variants.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2014 15:07:19 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 15:08:59 GMT"}, {"version": "v3", "created": "Fri, 16 May 2014 09:47:13 GMT"}, {"version": "v4", "created": "Tue, 22 Jul 2014 10:55:57 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Amarilli", "Antoine", ""]]}, {"id": "1404.3166", "submitter": "Robert Brijder", "authors": "Robert Brijder", "title": "Minimal Output Unstable Configurations in Chemical Reaction Networks and\n  Deciders", "comments": "14 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the set of output stable configurations of chemical reaction\ndeciders (CRDs). It turns out that CRDs with only bimolecular reactions (which\nare almost equivalent to population protocols) have a special structure that\nallows for an algorithm to efficiently compute their finite set of minimal\noutput unstable configurations. As a consequence, a relatively large set of\nconfigurations may be efficiently checked for output stability.\n  We also provide a number of observations regarding the semilinearity result\nof Angluin et al. [Distrib. Comput., 2007] from the context of population\nprotocols (which is a central result for output stable CRDs). In particular, we\nobserve that the computation-friendly class of totally stable CRDs has equal\nexpressive power as the larger class of output stable CRDs.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2014 17:48:50 GMT"}, {"version": "v2", "created": "Tue, 22 Apr 2014 09:32:30 GMT"}, {"version": "v3", "created": "Fri, 6 Jun 2014 12:19:11 GMT"}, {"version": "v4", "created": "Thu, 24 Jul 2014 08:34:03 GMT"}, {"version": "v5", "created": "Mon, 15 Jun 2015 09:46:29 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Brijder", "Robert", ""]]}, {"id": "1404.3320", "submitter": "Aviad Rubinstein", "authors": "Ilan Adler, Christos Papadimitriou, Aviad Rubinstein", "title": "On Simplex Pivoting Rules and Complexity Theory", "comments": "To appear in IPCO 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there are simplex pivoting rules for which it is PSPACE-complete\nto tell if a particular basis will appear on the algorithm's path. Such rules\ncannot be the basis of a strongly polynomial algorithm, unless P = PSPACE. We\nconjecture that the same can be shown for most known variants of the simplex\nmethod. However, we also point out that Dantzig's shadow vertex algorithm has a\npolynomial path problem. Finally, we discuss in the same context randomized\npivoting rules.\n", "versions": [{"version": "v1", "created": "Sat, 12 Apr 2014 21:42:05 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Adler", "Ilan", ""], ["Papadimitriou", "Christos", ""], ["Rubinstein", "Aviad", ""]]}, {"id": "1404.3368", "submitter": "Aryeh Kontorovich", "authors": "Lee-Ad Gottlieb and Aryeh Kontorovich and Pinhas Nisnevitch", "title": "Near-optimal sample compression for nearest neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first sample compression algorithm for nearest neighbors with\nnon-trivial performance guarantees. We complement these guarantees by\ndemonstrating almost matching hardness lower bounds, which show that our bound\nis nearly optimal. Our result yields new insight into margin-based nearest\nneighbor classification in metric spaces and allows us to significantly sharpen\nand simplify existing bounds. Some encouraging empirical results are also\npresented.\n", "versions": [{"version": "v1", "created": "Sun, 13 Apr 2014 11:13:02 GMT"}, {"version": "v2", "created": "Thu, 4 Dec 2014 15:23:49 GMT"}, {"version": "v3", "created": "Fri, 5 Dec 2014 10:38:21 GMT"}, {"version": "v4", "created": "Mon, 26 Mar 2018 08:54:17 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kontorovich", "Aryeh", ""], ["Nisnevitch", "Pinhas", ""]]}, {"id": "1404.3378", "submitter": "Amit Daniely", "authors": "Amit Daniely and Shai Shalev-Shwatz", "title": "Complexity theoretic limitations on learning DNF's", "comments": "arXiv admin note: substantial text overlap with arXiv:1311.2272", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the recently developed framework of [Daniely et al, 2014], we show that\nunder a natural assumption on the complexity of refuting random K-SAT formulas,\nlearning DNF formulas is hard. Furthermore, the same assumption implies the\nhardness of learning intersections of $\\omega(\\log(n))$ halfspaces,\nagnostically learning conjunctions, as well as virtually all (distribution\nfree) learning problems that were previously shown hard (under complexity\nassumptions).\n", "versions": [{"version": "v1", "created": "Sun, 13 Apr 2014 12:42:10 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2014 18:28:50 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Daniely", "Amit", ""], ["Shalev-Shwatz", "Shai", ""]]}, {"id": "1404.3396", "submitter": "Yuval Filmus", "authors": "Yuval Filmus, Hamed Hatami, Nathan Keller, Noam Lifshitz", "title": "On the sum of the L1 influences of bounded functions", "comments": "16 pages; accepted for publication in the Israel Journal of\n  Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $f\\colon \\{-1,1\\}^n \\to [-1,1]$ have degree $d$ as a multilinear\npolynomial. It is well-known that the total influence of $f$ is at most $d$.\nAaronson and Ambainis asked whether the total $L_1$ influence of $f$ can also\nbe bounded as a function of $d$. Ba\\v{c}kurs and Bavarian answered this\nquestion in the affirmative, providing a bound of $O(d^3)$ for general\nfunctions and $O(d^2)$ for homogeneous functions. We improve on their results\nby providing a bound of $d^2$ for general functions and $O(d\\log d)$ for\nhomogeneous functions. In addition, we prove a bound of $d/(2 \\pi)+o(d)$ for\nmonotone functions, and provide a matching example.\n", "versions": [{"version": "v1", "created": "Sun, 13 Apr 2014 15:57:37 GMT"}, {"version": "v2", "created": "Tue, 28 Oct 2014 22:30:19 GMT"}, {"version": "v3", "created": "Sat, 28 Mar 2015 17:43:54 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Filmus", "Yuval", ""], ["Hatami", "Hamed", ""], ["Keller", "Nathan", ""], ["Lifshitz", "Noam", ""]]}, {"id": "1404.3482", "submitter": "Philippe Gaborit", "authors": "Gaborit Philippe and Zemor Gilles", "title": "On the hardness of the decoding and the minimum distance problems for\n  rank codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give a randomized reduction for the Rank Syndrome Decoding\nproblem and Rank Minimum Distance problem for rank codes. Our results are based\non an embedding from linear codes equipped with Hamming distance unto linear\ncodes over an extension field equipped with the rank metric. We prove that if\nboth previous problems for rank metric are in ZPP = RP$\\cap$coRP, then we would\nhave NP=ZPP. We also give complexity results for the respective approximation\nproblems in rank metric.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 08:09:48 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Philippe", "Gaborit", ""], ["Gilles", "Zemor", ""]]}, {"id": "1404.3675", "submitter": "Clement Carbonnel", "authors": "Clement Carbonnel, Martin C. Cooper and Emmanuel Hebrard", "title": "On Backdoors To Tractable Constraint Languages", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of CSPs, a strong backdoor is a subset of variables such that\nevery complete assignment yields a residual instance guaranteed to have a\nspecified property. If the property allows efficient solving, then a small\nstrong backdoor provides a reasonable decomposition of the original instance\ninto easy instances. An important challenge is the design of algorithms that\ncan find quickly a small strong backdoor if one exists. We present a systematic\nstudy of the parameterized complexity of backdoor detection when the target\nproperty is a restricted type of constraint language defined by means of a\nfamily of polymorphisms. In particular, we show that under the weak assumption\nthat the polymorphisms are idempotent, the problem is unlikely to be FPT when\nthe parameter is either r (the constraint arity) or k (the size of the\nbackdoor) unless P = NP or FPT = W[2]. When the parameter is k+r, however, we\nare able to identify large classes of languages for which the problem of\nfinding a small backdoor is FPT.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 18:13:23 GMT"}, {"version": "v2", "created": "Fri, 10 Oct 2014 14:47:51 GMT"}], "update_date": "2014-10-13", "authors_parsed": [["Carbonnel", "Clement", ""], ["Cooper", "Martin C.", ""], ["Hebrard", "Emmanuel", ""]]}, {"id": "1404.3684", "submitter": "Pablo Romero Rodr\\'iguez", "authors": "Eduardo Canale and Pablo Romero", "title": "Diameter Constrained Reliability: Computational Complexity in terms of\n  the diameter and number of terminals", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G=(V,E)$ be a simple graph with $|V|=n$ nodes and $|E|=m$ links, a\nsubset $K \\subseteq V$ of \\emph{terminals}, a vector $p=(p_1,\\ldots,p_m) \\in\n[0,1]^m$ and a positive integer $d$, called \\emph{diameter}. We assume nodes\nare perfect but links fail stochastically and independently, with probabilities\n$q_i=1-p_i$. The \\emph{diameter-constrained reliability} (DCR for short), is\nthe probability that the terminals of the resulting subgraph remain connected\nby paths composed by $d$ links, or less. This number is denoted by\n$R_{K,G}^{d}(p)$.\n  The general DCR computation is inside the class of\n$\\mathcal{N}\\mathcal{P}$-Hard problems, since is subsumes the complexity that a\nrandom graph is connected. In this paper, the computational complexity of\nDCR-subproblems is discussed in terms of the number of terminal nodes $k=|K|$\nand diameter $d$. Either when $d=1$ or when $d=2$ and $k$ is fixed, the DCR is\ninside the class $\\mathcal{P}$ of polynomial-time problems. The DCR turns\n$\\mathcal{N}\\mathcal{P}$-Hard when $k \\geq 2$ is a fixed input parameter and\n$d\\geq 3$.\n  The case where $k=n$ and $d \\geq 2$ is fixed are not studied in prior\nliterature. Here, the $\\mathcal{N}\\mathcal{P}$-Hardness of this case is\nestablished.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 18:29:48 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Canale", "Eduardo", ""], ["Romero", "Pablo", ""]]}, {"id": "1404.3733", "submitter": "Dave Touchette", "authors": "Dave Touchette", "title": "Quantum Information Complexity and Amortized Communication", "comments": "v1, 38 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new notion of information cost for quantum protocols, and a\ncorresponding notion of quantum information complexity for bipartite quantum\nchannels, and then investigate the properties of such quantities. These are the\nfully quantum generalizations of the analogous quantities for bipartite\nclassical functions that have found many applications recently, in particular\nfor proving communication complexity lower bounds. Our definition is strongly\ntied to the quantum state redistribution task.\n  Previous attempts have been made to define such a quantity for quantum\nprotocols, with particular applications in mind; our notion differs from these\nin many respects. First, it directly provides a lower bound on the quantum\ncommunication cost, independent of the number of rounds of the underlying\nprotocol. Secondly, we provide an operational interpretation for quantum\ninformation complexity: we show that it is exactly equal to the amortized\nquantum communication complexity of a bipartite channel on a given state. This\ngeneralizes a result of Braverman and Rao to quantum protocols, and even\nstrengthens the classical result in a bounded round scenario. Also, this\nprovides an analogue of the Schumacher source compression theorem for\ninteractive quantum protocols, and answers a question raised by Braverman.\n  We also discuss some potential applications to quantum communication\ncomplexity lower bounds by specializing our definition for classical functions\nand inputs. Building on work of Jain, Radhakrishnan and Sen, we provide new\nevidence suggesting that the bounded round quantum communication complexity of\nthe disjointness function is \\Omega (n/M + M), for M-message protocols. This\nwould match the best known upper bound.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 20:00:28 GMT"}], "update_date": "2014-04-16", "authors_parsed": [["Touchette", "Dave", ""]]}, {"id": "1404.3801", "submitter": "Amer Mouawad", "authors": "Amer E. Mouawad, Naomi Nishimura, Vinayak Pathak, Venkatesh Raman", "title": "Shortest reconfiguration paths in the solution space of Boolean formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a Boolean formula and a satisfying assignment, a flip is an operation\nthat changes the value of a variable in the assignment so that the resulting\nassignment remains satisfying. We study the problem of computing the shortest\nsequence of flips (if one exists) that transforms a given satisfying assignment\n$s$ to another satisfying assignment $t$ of a Boolean formula. Earlier work\ncharacterized the complexity of finding any (not necessarily the shortest)\nsequence of flips from one satisfying assignment to another using Schaefer's\nframework for classification of Boolean formulas. We build on it to provide a\ntrichotomy for the complexity of finding the shortest sequence of flips and\nshow that it is either in P, NP-complete, or PSPACE-complete.\n  Our result adds to the small set of complexity results known for shortest\nreconfiguration sequence problems by providing an example where the shortest\nsequence can be found in polynomial time even though its length is not equal to\nthe symmetric difference of the values of the variables in $s$ and $t$. This is\nin contrast to all reconfiguration problems studied so far, where polynomial\ntime algorithms for computing the shortest path were known only for cases where\nthe path modified the symmetric difference only.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 02:35:44 GMT"}, {"version": "v2", "created": "Tue, 27 May 2014 00:25:27 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Mouawad", "Amer E.", ""], ["Nishimura", "Naomi", ""], ["Pathak", "Vinayak", ""], ["Raman", "Venkatesh", ""]]}, {"id": "1404.3820", "submitter": "Joshua Grochow", "authors": "Joshua A. Grochow and Toniann Pitassi", "title": "Circuit complexity, proof complexity, and polynomial identity testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new algebraic proof system, which has tight connections to\n(algebraic) circuit complexity. In particular, we show that any\nsuper-polynomial lower bound on any Boolean tautology in our proof system\nimplies that the permanent does not have polynomial-size algebraic circuits\n(VNP is not equal to VP). As a corollary to the proof, we also show that\nsuper-polynomial lower bounds on the number of lines in Polynomial Calculus\nproofs (as opposed to the usual measure of number of monomials) imply the\nPermanent versus Determinant Conjecture. Note that, prior to our work, there\nwas no proof system for which lower bounds on an arbitrary tautology implied\nany computational lower bound.\n  Our proof system helps clarify the relationships between previous algebraic\nproof systems, and begins to shed light on why proof complexity lower bounds\nfor various proof systems have been so much harder than lower bounds on the\ncorresponding circuit classes. In doing so, we highlight the importance of\npolynomial identity testing (PIT) for understanding proof complexity.\n  More specifically, we introduce certain propositional axioms satisfied by any\nBoolean circuit computing PIT. We use these PIT axioms to shed light on\nAC^0[p]-Frege lower bounds, which have been open for nearly 30 years, with no\nsatisfactory explanation as to their apparent difficulty. We show that either:\na) Proving super-polynomial lower bounds on AC^0[p]-Frege implies VNP does not\nhave polynomial-size circuits of depth d - a notoriously open question for d at\nleast 4 - thus explaining the difficulty of lower bounds on AC^0[p]-Frege, or\nb) AC^0[p]-Frege cannot efficiently prove the depth d PIT axioms, and hence we\nhave a lower bound on AC^0[p]-Frege.\n  Using the algebraic structure of our proof system, we propose a novel way to\nextend techniques from algebraic circuit complexity to prove lower bounds in\nproof complexity.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 05:54:46 GMT"}], "update_date": "2014-04-16", "authors_parsed": [["Grochow", "Joshua A.", ""], ["Pitassi", "Toniann", ""]]}, {"id": "1404.4020", "submitter": "Tyson Williams", "authors": "Jin-Yi Cai, Heng Guo, Tyson Williams", "title": "The Complexity of Counting Edge Colorings and a Dichotomy for Some\n  Higher Domain Holant Problems", "comments": "75 pages, 29 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that an effective version of Siegel's Theorem on finiteness of\ninteger solutions and an application of elementary Galois theory are key\ningredients in a complexity classification of some Holant problems. These\nHolant problems, denoted by Holant(f), are defined by a symmetric ternary\nfunction f that is invariant under any permutation of the k >= 3 domain\nelements. We prove that Holant(f) exhibits a complexity dichotomy. This\ndichotomy holds even when restricted to planar graphs. A special case of this\nresult is that counting edge k-colorings is #P-hard over planar 3-regular\ngraphs for k >= 3. In fact, we prove that counting edge k-colorings is #P-hard\nover planar r-regular graphs for all k >= r >= 3. The problem is\npolynomial-time computable in all other parameter settings. The proof of the\ndichotomy theorem for Holant(f) depends on the fact that a specific polynomial\np(x,y) has an explicitly listed finite set of integer solutions, and the\ndetermination of the Galois groups of some specific polynomials. In the\nprocess, we also encounter the Tutte polynomial, medial graphs, Eulerian\npartitions, Puiseux series, and a certain lattice condition on the (logarithm\nof) the roots of polynomials.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 18:52:42 GMT"}], "update_date": "2014-04-16", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Guo", "Heng", ""], ["Williams", "Tyson", ""]]}, {"id": "1404.4273", "submitter": "Alan Guo", "authors": "Alan Guo and Madhu Sudan", "title": "List decoding group homomorphisms between supersolvable groups", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the set of homomorphisms between two supersolvable groups can be\nlocally list decoded up to the minimum distance of the code, extending the\nresults of Dinur et al who studied the case where the groups are abelian.\nMoreover, when specialized to the abelian case, our proof is more streamlined\nand gives a better constant in the exponent of the list size. The constant is\nimproved from about 3.5 million to 105.\n", "versions": [{"version": "v1", "created": "Wed, 16 Apr 2014 14:50:22 GMT"}], "update_date": "2014-04-17", "authors_parsed": [["Guo", "Alan", ""], ["Sudan", "Madhu", ""]]}, {"id": "1404.4416", "submitter": "Dong Han Kim", "authors": "Teturo Kamae, Dong Han Kim", "title": "A characterization of eventually periodicity", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we show that the Kamae-Xue complexity function for an\ninfinite sequence classifies eventual periodicity completely. We prove that an\ninfinite binary word $x_1x_2 \\cdots $ is eventually periodic if and only if\n$\\Sigma(x_1x_2\\cdots x_n)/n^3$ has a positive limit, where $\\Sigma(x_1x_2\\cdots\nx_n)$ is the sum of the squares of all the numbers of appearance of finite\nwords in $x_1 x_2 \\cdots x_n$, which was introduced by Kamae-Xue as a criterion\nof randomness in the sense that $x_1x_2\\cdots x_n$ is more random if\n$\\Sigma(x_1x_2\\cdots x_n)$ is smaller. In fact, it is known that the lower\nlimit of $\\Sigma(x_1x_2\\cdots x_n) /n^2 $ is at least 3/2 for any sequence\n$x_1x_2 \\cdots$, while the limit exists as 3/2 almost surely for the\n$(1/2,1/2)$ product measure. For the other extreme, the upper limit of\n$\\Sigma(x_1x_2\\cdots x_n)/n^3$ is bounded by 1/3. There are sequences which are\nnot eventually periodic but the lower limit of $\\Sigma(x_1x_2\\cdots x_n)/n^3$\nis positive, while the limit does not exist.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2014 02:35:59 GMT"}], "update_date": "2014-04-18", "authors_parsed": [["Kamae", "Teturo", ""], ["Kim", "Dong Han", ""]]}, {"id": "1404.4478", "submitter": "Deepak Rajendraprasad", "authors": "L. Sunil Chandran, Deepak Rajendraprasad and Marek Tesa\\v{r}", "title": "Rainbow Colouring of Split Graphs", "comments": "This is the full version of a paper to be presented at ICGT 2014.\n  This complements the results in arXiv:1205.1670 (which were presented in\n  COCOON 2013), and both will be merged into a single journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rainbow path in an edge coloured graph is a path in which no two edges are\ncoloured the same. A rainbow colouring of a connected graph G is a colouring of\nthe edges of G such that every pair of vertices in G is connected by at least\none rainbow path. The minimum number of colours required to rainbow colour G is\ncalled its rainbow connection number. Between them, Chakraborty et al. [J.\nComb. Optim., 2011] and Ananth et al. [FSTTCS, 2012] have shown that for every\ninteger k, k \\geq 2, it is NP-complete to decide whether a given graph can be\nrainbow coloured using k colours.\n  A split graph is a graph whose vertex set can be partitioned into a clique\nand an independent set. Chandran and Rajendraprasad have shown that the problem\nof deciding whether a given split graph G can be rainbow coloured using 3\ncolours is NP-complete and further have described a linear time algorithm to\nrainbow colour any split graph using at most one colour more than the optimum\n[COCOON, 2012]. In this article, we settle the computational complexity of the\nproblem on split graphs and thereby discover an interesting dichotomy.\nSpecifically, we show that the problem of deciding whether a given split graph\ncan be rainbow coloured using k colours is NP-complete for k \\in {2,3}, but can\nbe solved in polynomial time for all other values of k.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2014 10:41:32 GMT"}], "update_date": "2014-04-18", "authors_parsed": [["Chandran", "L. Sunil", ""], ["Rajendraprasad", "Deepak", ""], ["Tesa\u0159", "Marek", ""]]}, {"id": "1404.4560", "submitter": "Lane A. Hemaspaandra", "authors": "Edith Hemaspaandra and Lane A. Hemaspaandra and Henning Schnoor", "title": "A Control Dichotomy for Pure Scoring Rules", "comments": "A shorter version of this paper will appear in the proceedings of the\n  Twenty-Eighth AAAI Conference on Artificial Intelligence (AAAI 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scoring systems are an extremely important class of election systems. A\nlength-$m$ (so-called) scoring vector applies only to $m$-candidate elections.\nTo handle general elections, one must use a family of vectors, one per length.\nThe most elegant approach to making sure such families are \"family-like\" is the\nrecently introduced notion of (polynomial-time uniform) pure scoring rules\n[Betzler and Dorn 2010], where each scoring vector is obtained from its\nprecursor by adding one new coefficient. We obtain the first dichotomy theorem\nfor pure scoring rules for a control problem. In particular, for constructive\ncontrol by adding voters (CCAV), we show that CCAV is solvable in polynomial\ntime for $k$-approval with $k \\leq 3$, $k$-veto with $k \\leq 2$, every pure\nscoring rule in which only the two top-rated candidates gain nonzero scores,\nand a particular rule that is a \"hybrid\" of 1-approval and 1-veto. For all\nother pure scoring rules, CCAV is NP-complete. We also investigate the\ndescriptive richness of different models for defining pure scoring rules,\nproving how more rule-generation time gives more rules, proving that rationals\ngive more rules than do the natural numbers, and proving that some restrictions\npreviously thought to be \"w.l.o.g.\" in fact do lose generality.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2014 15:38:54 GMT"}], "update_date": "2014-04-18", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""], ["Schnoor", "Henning", ""]]}, {"id": "1404.4622", "submitter": "Jeremiah Blocki", "authors": "Calvin Beideman and Jeremiah Blocki", "title": "Set Families with Low Pairwise Intersection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $\\left(n,\\ell,\\gamma\\right)$-sharing set family of size $m$ is a family of\nsets $S_1,\\ldots,S_m\\subseteq [n]$ s.t. each set has size $\\ell$ and each pair\nof sets shares at most $\\gamma$ elements. We let $m\\left(n,\\ell,\\gamma\\right)$\ndenote the maximum size of any such set family and we consider the following\nquestion: How large can $m\\left(n,\\ell,\\gamma\\right)$ be?\n$\\left(n,\\ell,\\gamma\\right)$-sharing set families have a rich set of\napplications including the construction of pseudorandom number generators and\nusable and secure password management schemes. We analyze the explicit\nconstruction of Blocki et al using recent bounds on the value of the $t$'th\nRamanujan prime. We show that this explicit construction produces a\n$\\left(4\\ell^2\\ln 4\\ell,\\ell,\\gamma\\right)$-sharing set family of size $\\left(2\n\\ell \\ln 2\\ell\\right)^{\\gamma+1}$ for any $\\ell\\geq \\gamma$. We also show that\nthe construction of Blocki et al can be used to obtain a weak\n$\\left(n,\\ell,\\gamma\\right)$-sharing set family of size $m$ for any $m >0$.\nThese results are competitive with the inexplicit construction of Raz et al for\nweak $\\left(n,\\ell,\\gamma\\right)$-sharing families. We show that our explicit\nconstruction of weak $\\left(n,\\ell,\\gamma\\right)$-sharing set families can be\nused to obtain a parallelizable pseudorandom number generator with a low memory\nfootprint by using the pseudorandom number generator of Nisan and Wigderson. We\nalso prove that $m\\left(n,n/c_1,c_2n\\right)$ must be a constant whenever $c_2\n\\leq \\frac{2}{c_1^3+c_1^2}$. We show that this bound is nearly tight as\n$m\\left(n,n/c_1,c_2n\\right)$ grows exponentially fast whenever $c_2 >\nc_1^{-2}$.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2014 19:38:20 GMT"}], "update_date": "2014-04-18", "authors_parsed": [["Beideman", "Calvin", ""], ["Blocki", "Jeremiah", ""]]}, {"id": "1404.4692", "submitter": "Nishant Doshi mr.", "authors": "Nishant Doshi", "title": "Approximation for the Path Complexity of Binary Search Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of an algorithm is an important parameter to determine its\neffi-ciency. They are of different types viz. Time complexity, Space\ncomplexity, etc. However, none of them consider the execution path as a\ncomplexity measure. Ashok et al, firstly proposed the notion of the Path\nComplexity of a pro-gram/algorithm, which defined based on the number of\nexecution paths as a function of the input size. However, the notion of path\ncomplexity of the pro-gram, cannot apply to the object-oriented environment.\nTherefore, Anupam et al, has extended the notion of path complexity to the\nclass as follows. The notion of the state of the class is defined based on\nstructural representation (aka state) of the class. The class contains data\nmembers and data operations. It considers only those data operations that\nchange the state of the class. The path complexity of the class is defined to\nbe the number of valid input sequences, each of them con-taining valid data\noperations. Anupam et al, had applied this notion to the class Stack. However,\nthe stack is basic and simple data structures. Therefore, in this research we\nhave used a more complex class to understand the path complexity behavior in\nthe object oriented environment. Binary Search Tree (BST) is one of the well\nknown (and more complex too) data structure, which is useful in sorting,\nsearching, Traffic Engineering and many more applications. We have analyzed the\npath complexity of the class BST based on the algorithms for insert and delete\noperations. Additionally, we have modified the delete operation to minimize the\npath complexity for the class BST.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2014 05:41:46 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Doshi", "Nishant", ""]]}, {"id": "1404.4834", "submitter": "Rafael Mendes de Oliveira", "authors": "Zeev Dvir, Rafael Mendes de Oliveira", "title": "Factors of Sparse Polynomials are Sparse", "comments": "This paper was removed due to an error in the proof (Claim 4.12 as\n  stated is not true)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.AG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper was removed due to an error in the proof (Claim 4.12 as stated is\nnot true). The authors would like to thank Ilya Volkovich for pointing out a\ncounterexample to this paper's main result in positive characteristic: If $F$\nis a field with prime characteristic $p$, then the polynomial $x_1^p + x_2^p +\n\\ldots + x^n^p$ has the following factor: $(x_1+x_2+ \\ldots + x_n)^{p-1}$,\nwhich has sparsity $n^p$.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2014 16:25:38 GMT"}, {"version": "v2", "created": "Mon, 19 May 2014 01:02:47 GMT"}], "update_date": "2014-08-10", "authors_parsed": [["Dvir", "Zeev", ""], ["de Oliveira", "Rafael Mendes", ""]]}, {"id": "1404.4852", "submitter": "Kenneth Regan", "authors": "Robert L. Surowka and Kenneth W. Regan", "title": "Polynomials Modulo Composite Numbers: Ax-Katz type theorems for the\n  structure of their solution sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the Ax-Katz theorem for a single polynomial from finite fields to\nthe rings Z_m with m composite. This extension not only yields the analogous\nresult, but gives significantly higher divisibility bounds. We conjecture what\ncomputer runs suggest is the optimal result for any m, and prove a special case\nof it. The special case is for m = 2^r and polynomials of degree 2. Our results\nalso yield further properties of the solution spaces. Polynomials modulo\ncomposites are the focus of some computational complexity lower bound\nfrontiers, while those modulo 2^r arise in the simulation of quantum circuits.\nWe give some prospective applications of this research.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2014 18:37:40 GMT"}, {"version": "v2", "created": "Mon, 18 Aug 2014 15:59:43 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Surowka", "Robert L.", ""], ["Regan", "Kenneth W.", ""]]}, {"id": "1404.4859", "submitter": "Paul Accisano", "authors": "Paul Accisano and Alper \\\"Ung\\\"or", "title": "Matching Curves to Imprecise Point Sets using Fr\\'echet Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a polygonal curve in $\\mathbb{R}^d$ of length $n$, and $S$ be a\npoint-set of size $k$. The Curve/Point Set Matching problem consists of finding\na polygonal curve $Q$ on $S$ such that the Fr\\'echet distance from $P$ is less\nthan a given $\\varepsilon$. We consider eight variations of the problem based\non the distance metric used and the omittability or repeatability of the\npoints. We provide closure to a recent series of complexity results for the\ncase where $S$ consists of precise points. More importantly, we formulate a\nmore realistic version of the problem that takes into account measurement\nerrors. This new problem is posed as the matching of a given curve to a set of\nimprecise points. We prove that all three variations of the problem that are in\nP when $S$ consists of precise points become NP-complete when $S$ consists of\nimprecise points. We also discuss approximation results.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2014 19:07:04 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Accisano", "Paul", ""], ["\u00dcng\u00f6r", "Alper", ""]]}, {"id": "1404.5169", "submitter": "Ragesh Jaiswal", "authors": "Ragesh Jaiswal", "title": "A note on the relation between XOR and Selective XOR Lemmas", "comments": "The previous version has been significantly simplified to highlight\n  the main result", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an unpredictable Boolean function $f: \\{0, 1\\}^n \\rightarrow \\{0, 1\\}$,\nthe standard Yao's XOR lemma is a statement about the unpredictability of\ncomputing $\\oplus_{i \\in [k]}f(x_i)$ given $x_1, ..., x_k \\in \\{0, 1\\}^n$,\nwhereas the Selective XOR lemma is a statement about the unpredictability of\ncomputing $\\oplus_{i \\in S}f(x_i)$ given $x_1, ..., x_k \\in \\{0, 1\\}^n$ and $S\n\\subseteq \\{1, ..., k\\}$. We give a reduction from the Selective XOR lemma to\nthe standard XOR lemma. Our reduction gives better quantitative bounds for\ncertain choice of parameters and does not require the assumption of being able\nto sample $(x, f(x))$ pairs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Apr 2014 10:41:32 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 17:55:06 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Jaiswal", "Ragesh", ""]]}, {"id": "1404.5236", "submitter": "Boaz Barak", "authors": "Boaz Barak and David Steurer", "title": "Sum-of-squares proofs and the quest toward optimal algorithms", "comments": "Survey. To appear in proceedings of ICM 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to obtain the best-known guarantees, algorithms are traditionally\ntailored to the particular problem we want to solve. Two recent developments,\nthe Unique Games Conjecture (UGC) and the Sum-of-Squares (SOS) method,\nsurprisingly suggest that this tailoring is not necessary and that a single\nefficient algorithm could achieve best possible guarantees for a wide range of\ndifferent problems.\n  The Unique Games Conjecture (UGC) is a tantalizing conjecture in\ncomputational complexity, which, if true, will shed light on the complexity of\na great many problems. In particular this conjecture predicts that a single\nconcrete algorithm provides optimal guarantees among all efficient algorithms\nfor a large class of computational problems.\n  The Sum-of-Squares (SOS) method is a general approach for solving systems of\npolynomial constraints. This approach is studied in several scientific\ndisciplines, including real algebraic geometry, proof complexity, control\ntheory, and mathematical programming, and has found applications in fields as\ndiverse as quantum information theory, formal verification, game theory and\nmany others.\n  We survey some connections that were recently uncovered between the Unique\nGames Conjecture and the Sum-of-Squares method. In particular, we discuss new\ntools to rigorously bound the running time of the SOS method for obtaining\napproximate solutions to hard optimization problems, and how these tools give\nthe potential for the sum-of-squares method to provide new guarantees for many\nproblems of interest, and possibly to even refute the UGC.\n", "versions": [{"version": "v1", "created": "Mon, 21 Apr 2014 16:24:13 GMT"}, {"version": "v2", "created": "Tue, 27 May 2014 17:52:52 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Barak", "Boaz", ""], ["Steurer", "David", ""]]}, {"id": "1404.5352", "submitter": "Dan Hassin", "authors": "Dan Hassin, Adam Scrivener, and Yibo Zhou", "title": "Critique of J. Kim's \"P is not equal to NP by Modus Tollens\"", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a critique of version three of Joonmo Kim's paper entitled \"P\nis not equal to NP by Modus Tollens. [arXiv:1403.4143v3]\" After summarizing\nKim's proof, we note that the logic that Kim uses is inconsistent, which\nprovides evidence that the proof is invalid. To show this, we will consider two\nreasonable interpretations of Kim's definitions, and show that \"P is not equal\nto NP\" does not seem to follow in an obvious way using any of them.\n", "versions": [{"version": "v1", "created": "Tue, 22 Apr 2014 00:05:19 GMT"}, {"version": "v2", "created": "Sun, 27 Apr 2014 00:10:30 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Hassin", "Dan", ""], ["Scrivener", "Adam", ""], ["Zhou", "Yibo", ""]]}, {"id": "1404.5424", "submitter": "Damien Prot", "authors": "Odile Bellenguez-Morineau, Marek Chrobak, Christoph D\\\"urr, Damien\n  Prot", "title": "A Note on NP-Hardness of Preemptive Mean Flow-Time Scheduling for\n  Parallel Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper \"The complexity of mean flow time scheduling problems with\nrelease times\", by Baptiste, Brucker, Chrobak, D\\\"urr, Kravchenko and Sourd,\nthe authors claimed to prove strong NP-hardness of the scheduling problem\n$P|pmtn,r_j|\\sum C_j$, namely multiprocessor preemptive scheduling where the\nobjective is to minimize the mean flow time. We point out a serious error in\ntheir proof and give a new proof of strong NP-hardness for this problem.\n", "versions": [{"version": "v1", "created": "Tue, 22 Apr 2014 08:54:20 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["Bellenguez-Morineau", "Odile", ""], ["Chrobak", "Marek", ""], ["D\u00fcrr", "Christoph", ""], ["Prot", "Damien", ""]]}, {"id": "1404.5565", "submitter": "Mateus de Oliveira Oliveira", "authors": "Mateus de Oliveira Oliveira", "title": "On the Satisfiability of Quantum Circuits of Small Treewidth", "comments": "30 Pages. A preliminary version of this paper appeared at the 10th\n  International Computer Science Symposium in Russia (CSR 2015). This version\n  has been submitted to a journal and is currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been known for almost three decades that many $\\mathrm{NP}$-hard\noptimization problems can be solved in polynomial time when restricted to\nstructures of constant treewidth. In this work we provide the first extension\nof such results to the quantum setting. We show that given a quantum circuit\n$C$ with $n$ uninitialized inputs, $\\mathit{poly}(n)$ gates, and treewidth $t$,\none can compute in time $(\\frac{n}{\\delta})^{\\exp(O(t))}$ a classical\nassignment $y\\in \\{0,1\\}^n$ that maximizes the acceptance probability of $C$ up\nto a $\\delta$ additive factor. In particular, our algorithm runs in polynomial\ntime if $t$ is constant and $1/poly(n) < \\delta < 1$. For unrestricted values\nof $t$, this problem is known to be complete for the complexity class\n$\\mathrm{QCMA}$, a quantum generalization of MA. In contrast, we show that the\nsame problem is $\\mathrm{NP}$-complete if $t=O(\\log n)$ even when $\\delta$ is\nconstant.\n  On the other hand, we show that given a $n$-input quantum circuit $C$ of\ntreewidth $t=O(\\log n)$, and a constant $\\delta<1/2$, it is\n$\\mathrm{QMA}$-complete to determine whether there exists a quantum state\n$\\mid\\!\\varphi\\rangle \\in (\\mathbb{C}^d)^{\\otimes n}$ such that the acceptance\nprobability of $C\\mid\\!\\varphi\\rangle$ is greater than $1-\\delta$, or whether\nfor every such state $\\mid\\!\\varphi\\rangle$, the acceptance probability of\n$C\\mid\\!\\varphi\\rangle$ is less than $\\delta$. As a consequence, under the\nwidely believed assumption that $\\mathrm{QMA} \\neq \\mathrm{NP}$, we have that\nquantum witnesses are strictly more powerful than classical witnesses with\nrespect to Merlin-Arthur protocols in which the verifier is a quantum circuit\nof logarithmic treewidth.\n", "versions": [{"version": "v1", "created": "Tue, 22 Apr 2014 17:31:56 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2016 21:47:30 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Oliveira", "Mateus de Oliveira", ""]]}, {"id": "1404.5584", "submitter": "Arne Reimers", "authors": "Arne C. Reimers, Leen Stougie", "title": "Polynomial time vertex enumeration of convex polytopes of bounded\n  branch-width", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.CO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years the vertex enumeration problem of polyhedra has seen a\nrevival in the study of metabolic networks, which increased the demand for\nefficient vertex enumeration algorithms for high-dimensional polyhedra given by\ninequalities. It is a famous and long standing open question in polyhedral\ntheory and computational geometry whether the vertices of a polytope (bounded\npolyhedron), described by a set of linear constraints, can be enumerated in\ntotal polynomial time. In this paper we apply the concept of\nbranch-decomposition to the vertex enumeration problem of polyhedra $P = \\{x :\nAx = b, x \\geq 0\\}$. For this purpose, we introduce the concept of $k$-module\nand show how it relates to the separators of the linear matroid generated by\nthe columns of $A$. We then use this to present a total polynomial time\nalgorithm for polytopes $P$ for which the branch-width of the linear matroid\ngenerated by $A$ is bounded by a constant $k$.\n", "versions": [{"version": "v1", "created": "Tue, 22 Apr 2014 18:25:14 GMT"}, {"version": "v2", "created": "Sat, 9 Jul 2016 18:19:26 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Reimers", "Arne C.", ""], ["Stougie", "Leen", ""]]}, {"id": "1404.5985", "submitter": "Matthew Patitz", "authors": "Jacob Hendricks, Matthew J. Patitz, Trent A. Rogers", "title": "Reflections on Tiles (in Self-Assembly)", "comments": "New results which classify the types of shapes which can\n  self-assemble in the RTAM have been added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define the Reflexive Tile Assembly Model (RTAM), which is obtained from\nthe abstract Tile Assembly Model (aTAM) by allowing tiles to reflect across\ntheir horizontal and/or vertical axes. We show that the class of directed\ntemperature-1 RTAM systems is not computationally universal, which is\nconjectured but unproven for the aTAM, and like the aTAM, the RTAM is\ncomputationally universal at temperature 2. We then show that at temperature 1,\nwhen starting from a single tile seed, the RTAM is capable of assembling n x n\nsquares for n odd using only n tile types, but incapable of assembling n x n\nsquares for n even. Moreover, we show that n is a lower bound on the number of\ntile types needed to assemble n x n squares for n odd in the temperature-1\nRTAM. The conjectured lower bound for temperature-1 aTAM systems is 2n-1.\nFinally, we give preliminary results toward the classification of which finite\nconnected shapes in Z^2 can be assembled (strictly or weakly) by a singly\nseeded (i.e. seed of size 1) RTAM system, including a complete classification\nof which finite connected shapes be strictly assembled by a \"mismatch-free\"\nsingly seeded RTAM system.\n", "versions": [{"version": "v1", "created": "Wed, 23 Apr 2014 21:12:43 GMT"}, {"version": "v2", "created": "Fri, 25 Apr 2014 00:54:08 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2015 22:12:24 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Hendricks", "Jacob", ""], ["Patitz", "Matthew J.", ""], ["Rogers", "Trent A.", ""]]}, {"id": "1404.6049", "submitter": "Hai-Jun Zhou", "authors": "Jin-Hua Zhao and Hai-Jun Zhou", "title": "Statistical physics of hard combinatorial optimization: The vertex cover\n  problem", "comments": "17 pages. A mini-review to be published in Chinese Physics B", "journal-ref": "Chinese Physics B 23: 078901 (2014)", "doi": "10.1088/1674-1056/23/7/078901", "report-no": null, "categories": "cond-mat.dis-nn cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical-case computation complexity is a research topic at the boundary of\ncomputer science, applied mathematics, and statistical physics. In the last\ntwenty years the replica-symmetry-breaking mean field theory of spin glasses\nand the associated message-passing algorithms have greatly deepened our\nunderstanding of typical-case computation complexity. In this paper we use the\nvertex cover problem, a basic nondeterministic-polynomial (NP)-complete\ncombinatorial optimization problem of wide application, as an example to\nintroduce the statistical physical methods and algorithms. We do not go into\nthe technical details but emphasize mainly the intuitive physical meanings of\nthe message-passing equations. A nonfamiliar reader shall be able to understand\nto a large extent the physics behind the mean field approaches and to adjust\nthem in solving other optimization problems.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 08:10:22 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Zhao", "Jin-Hua", ""], ["Zhou", "Hai-Jun", ""]]}, {"id": "1404.6175", "submitter": "Giordano Da Lozzo", "authors": "Patrizio Angelini and Giordano Da Lozzo", "title": "Deepening the Relationship between SEFE and C-Planarity", "comments": "8 pages, 3 figures, Extended version of 'SEFE = C-Planarity?' (9th\n  International Colloquium on Graph Theory and Combinatorics - ICGT 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deepen the understanding of the connection between two\nlong-standing Graph Drawing open problems, that is, Simultaneous Embedding with\nFixed Edges (SEFE) and Clustered Planarity (C-PLANARITY). In his GD'12 paper\nMarcus Schaefer presented a reduction from C-PLANARITY to SEFE of two planar\ngraphs (SEFE-2). We prove that a reduction exists also in the opposite\ndirection, if we consider instances of SEFE-2 in which the intersection graph\nis connected. We pose as an open question whether the two problems are\npolynomial-time equivalent.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 16:46:56 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["Angelini", "Patrizio", ""], ["Da Lozzo", "Giordano", ""]]}, {"id": "1404.6196", "submitter": "Naohi Eguchi", "authors": "Naohi Eguchi", "title": "Proving Termination of Unfolding Graph Rewriting for General Safe\n  Recursion", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new termination proof and complexity analysis of\nunfolding graph rewriting which is a specific kind of infinite graph rewriting\nexpressing the general form of safe recursion. We introduce a termination order\nover sequences of terms together with an interpretation of term graphs into\nsequences of terms. Unfolding graph rewrite rules expressing general safe\nrecursion can be successfully embedded into the termination order by the\ninterpretation, yielding the polynomial runtime complexity. Moreover,\ngeneralising the definition of unfolding graph rewrite rules for general safe\nrecursion, we propose a new criterion for the polynomial runtime complexity of\ninfinite GRSs and for the polynomial size of normal forms in infinite GRSs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 17:44:57 GMT"}, {"version": "v2", "created": "Wed, 30 Apr 2014 08:03:50 GMT"}, {"version": "v3", "created": "Wed, 28 May 2014 20:35:58 GMT"}, {"version": "v4", "created": "Fri, 20 Jun 2014 16:06:14 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Eguchi", "Naohi", ""]]}, {"id": "1404.6535", "submitter": "Aritanan Gruber", "authors": "Martin Anthony, Endre Boros, Yves Crama, Aritanan Gruber", "title": "Quadratization of Symmetric Pseudo-Boolean Functions", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.CV math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pseudo-Boolean function is a real-valued function\n$f(x)=f(x_1,x_2,\\ldots,x_n)$ of $n$ binary variables; that is, a mapping from\n$\\{0,1\\}^n$ to $\\mathbb{R}$. For a pseudo-Boolean function $f(x)$ on\n$\\{0,1\\}^n$, we say that $g(x,y)$ is a quadratization of $f$ if $g(x,y)$ is a\nquadratic polynomial depending on $x$ and on $m$ auxiliary binary variables\n$y_1,y_2,\\ldots,y_m$ such that $f(x)= \\min \\{g(x,y) : y \\in \\{0,1\\}^m \\}$ for\nall $x \\in \\{0,1\\}^n$. By means of quadratizations, minimization of $f$ is\nreduced to minimization (over its extended set of variables) of the quadratic\nfunction $g(x,y)$. This is of some practical interest because minimization of\nquadratic functions has been thoroughly studied for the last few decades, and\nmuch progress has been made in solving such problems exactly or heuristically.\nA related paper \\cite{ABCG} initiated a systematic study of the minimum number\nof auxiliary $y$-variables required in a quadratization of an arbitrary\nfunction $f$ (a natural question, since the complexity of minimizing the\nquadratic function $g(x,y)$ depends, among other factors, on the number of\nbinary variables). In this paper, we determine more precisely the number of\nauxiliary variables required by quadratizations of symmetric pseudo-Boolean\nfunctions $f(x)$, those functions whose value depends only on the Hamming\nweight of the input $x$ (the number of variables equal to $1$).\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2014 20:00:22 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Anthony", "Martin", ""], ["Boros", "Endre", ""], ["Crama", "Yves", ""], ["Gruber", "Aritanan", ""]]}, {"id": "1404.7053", "submitter": "Sergey Yakhontov V", "authors": "Sergey V. Yakhontov", "title": "Computable real function F such that F is not polynomial time computable\n  on [0,1]", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computable real function F on [0,1] is constructed such that there exists\nan exponential time algorithm for the evaluation of the function on [0,1] on\nTuring machine but there does not exist any polynomial time algorithm for the\nevaluation of the function on [0,1] on Turing machine (moreover, it holds for\nany rational point on (0,1))\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2014 02:31:06 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Yakhontov", "Sergey V.", ""]]}, {"id": "1404.7169", "submitter": "Sicun Gao", "authors": "Sicun Gao, Soonho Kong, Edmund Clarke", "title": "Revisiting the Complexity of Stability of Continuous and Hybrid Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework to give upper bounds on the \"practical\" computational\ncomplexity of stability problems for a wide range of nonlinear continuous and\nhybrid systems. To do so, we describe stability properties of dynamical systems\nusing first-order formulas over the real numbers, and reduce stability problems\nto the delta-decision problems of these formulas. The framework allows us to\nobtain a precise characterization of the complexity of different notions of\nstability for nonlinear continuous and hybrid systems. We prove that bounded\nversions of the stability problems are generally decidable, and give upper\nbounds on their complexity. The unbounded versions are generally undecidable,\nfor which we give upper bounds on their degrees of unsolvability.\n", "versions": [{"version": "v1", "created": "Mon, 28 Apr 2014 21:14:45 GMT"}, {"version": "v2", "created": "Thu, 1 May 2014 06:23:22 GMT"}, {"version": "v3", "created": "Sun, 11 May 2014 19:09:01 GMT"}, {"version": "v4", "created": "Wed, 4 Jun 2014 05:22:49 GMT"}], "update_date": "2014-06-05", "authors_parsed": [["Gao", "Sicun", ""], ["Kong", "Soonho", ""], ["Clarke", "Edmund", ""]]}, {"id": "1404.7443", "submitter": "Sajin Koroth Mr.", "authors": "Sajin Koroth, Jayalal Sarma", "title": "Depth Lower Bounds against Circuits with Sparse Orientation", "comments": "Version submitted to Journal. Replaced Theorem 3 with a weaker\n  version fixing an error in the earlier version of the proof. This does not\n  affect the main claims of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study depth lower bounds against non-monotone circuits, parametrized by a\nnew measure of non-monotonicity: the orientation of a function $f$ is the\ncharacteristic vector of the minimum sized set of negated variables needed in\nany DeMorgan circuit computing $f$. We prove trade-off results between the\ndepth and the weight/structure of the orientation vectors in any circuit $C$\ncomputing the Clique function on an $n$ vertex graph. We prove that if $C$ is\nof depth $d$ and each gate computes a Boolean function with orientation of\nweight at most $w$ (in terms of the inputs to $C$), then $d \\times w$ must be\n$\\Omega(n)$. In particular, if the weights are $o(\\frac{n}{\\log^k n})$, then\n$C$ must be of depth $\\omega(\\log^k n)$. We prove a barrier for our general\ntechnique. However, using specific properties of the Clique function and the\nKarchmer-Wigderson framework (Karchmer and Wigderson, 1988), we go beyond the\nlimitations and obtain lower bounds when the weight restrictions are less\nstringent. We then study the depth lower bounds when the structure of the\norientation vector is restricted. Asymptotic improvements to our results (in\nthe restricted setting), separates NP from NC. As our main tool, we generalize\nKarchmer-Wigderson gamefor monotone functions to work for non-monotone circuits\nparametrized by the weight/structure of the orientation. We also prove\nstructural results about orientation and prove connections between number of\nnegations and weight of orientations required to compute a function.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2014 17:57:47 GMT"}, {"version": "v2", "created": "Tue, 3 Feb 2015 06:42:23 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Koroth", "Sajin", ""], ["Sarma", "Jayalal", ""]]}, {"id": "1404.7758", "submitter": "Sigve Hortemo S{\\ae}ther", "authors": "Sigve Hortemo S{\\ae}ther, Jan Arne Telle", "title": "Between Treewidth and Clique-width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many hard graph problems can be solved efficiently when restricted to graphs\nof bounded treewidth, and more generally to graphs of bounded clique-width. But\nthere is a price to be paid for this generality, exemplified by the four\nproblems MaxCut, Graph Coloring, Hamiltonian Cycle and Edge Dominating Set that\nare all FPT parameterized by treewidth but none of which can be FPT\nparameterized by clique-width unless FPT = W[1], as shown by Fomin et al [7,\n8]. We therefore seek a structural graph parameter that shares some of the\ngenerality of clique-width without paying this price. Based on splits, branch\ndecompositions and the work of Vatshelle [18] on Maximum Matching-width, we\nconsider the graph parameter sm-width which lies between treewidth and\nclique-width. Some graph classes of unbounded treewidth, like\ndistance-hereditary graphs, have bounded sm-width. We show that MaxCut, Graph\nColoring, Hamiltonian Cycle and Edge Dominating Set are all FPT parameterized\nby sm-width.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 15:13:45 GMT"}], "update_date": "2014-05-01", "authors_parsed": [["S\u00e6ther", "Sigve Hortemo", ""], ["Telle", "Jan Arne", ""]]}, {"id": "1404.7810", "submitter": "Markus Sortland Dregi", "authors": "Markus Sortland Dregi and Daniel Lokshtanov", "title": "Parameterized Complexity of Bandwidth on Trees", "comments": "33 pages, To appear at ICALP 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bandwidth of a $n$-vertex graph $G$ is the smallest integer $b$ such that\nthere exists a bijective function $f : V(G) \\rightarrow \\{1,...,n\\}$, called a\nlayout of $G$, such that for every edge $uv \\in E(G)$, $|f(u) - f(v)| \\leq b$.\nIn the {\\sc Bandwidth} problem we are given as input a graph $G$ and integer\n$b$, and asked whether the bandwidth of $G$ is at most $b$. We present two\nresults concerning the parameterized complexity of the {\\sc Bandwidth} problem\non trees.\n  First we show that an algorithm for {\\sc Bandwidth} with running time\n$f(b)n^{o(b)}$ would violate the Exponential Time Hypothesis, even if the input\ngraphs are restricted to be trees of pathwidth at most two. Our lower bound\nshows that the classical $2^{O(b)}n^{b+1}$ time algorithm by Saxe [SIAM Journal\non Algebraic and Discrete Methods, 1980] is essentially optimal.\n  Our second result is a polynomial time algorithm that given a tree $T$ and\ninteger $b$, either correctly concludes that the bandwidth of $T$ is more than\n$b$ or finds a layout of $T$ of bandwidth at most $b^{O(b)}$. This is the first\nparameterized approximation algorithm for the bandwidth of trees.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 17:44:03 GMT"}], "update_date": "2014-05-01", "authors_parsed": [["Dregi", "Markus Sortland", ""], ["Lokshtanov", "Daniel", ""]]}]