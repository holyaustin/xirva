[{"id": "1411.0264", "submitter": "Igor Razgon", "authors": "Igor Razgon", "title": "On the read-once property of branching programs and CNFs of bounded\n  treewidth", "comments": "Significantly simplified proof of the main combinatorial lemma.\n  AROSRN replaced back by NROBP due to their equivalence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove a space lower bound of $n^{\\Omega(k)}$ for\nnon-deterministic (syntactic) read-once branching programs ({\\sc nrobp}s) on\nfunctions expressible as {\\sc cnf}s with treewidth at most $k$ of their primal\ngraphs. This lower bound rules out the possibility of fixed-parameter space\ncomplexity of {\\sc nrobp}s parameterized by $k$.\n  We use lower bound for {\\sc nrobp}s to obtain a quasi-polynomial separation\nbetween Free Binary Decision Diagrams and Decision Decomposable Negation Normal\nForms, essentially matching the existing upper bound introduced by Beame et al.\nand thus proving the tightness of the latter.\n", "versions": [{"version": "v1", "created": "Sun, 2 Nov 2014 14:51:29 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2014 11:49:31 GMT"}, {"version": "v3", "created": "Sun, 26 Jul 2015 10:25:59 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Razgon", "Igor", ""]]}, {"id": "1411.0628", "submitter": "Valerii Sopin", "authors": "Valerii Sopin", "title": "PH = PSPACE", "comments": "The author greatly appreciate suggestions and help of Professor Lew\n  Gordeew", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that PSPACE is equal to 4th level in the polynomial\nhierarchy. We also deduce a lot of important consequences.\n", "versions": [{"version": "v1", "created": "Mon, 3 Nov 2014 19:41:08 GMT"}, {"version": "v10", "created": "Mon, 19 Sep 2016 19:40:19 GMT"}, {"version": "v11", "created": "Thu, 29 Apr 2021 17:42:35 GMT"}, {"version": "v12", "created": "Mon, 3 May 2021 07:16:41 GMT"}, {"version": "v13", "created": "Sat, 15 May 2021 06:36:59 GMT"}, {"version": "v14", "created": "Tue, 27 Jul 2021 19:02:02 GMT"}, {"version": "v2", "created": "Tue, 4 Nov 2014 15:29:22 GMT"}, {"version": "v3", "created": "Wed, 5 Nov 2014 01:20:47 GMT"}, {"version": "v4", "created": "Tue, 18 Nov 2014 22:45:44 GMT"}, {"version": "v5", "created": "Wed, 21 Jan 2015 08:11:18 GMT"}, {"version": "v6", "created": "Tue, 3 Feb 2015 02:14:00 GMT"}, {"version": "v7", "created": "Wed, 4 Feb 2015 23:09:45 GMT"}, {"version": "v8", "created": "Sun, 8 Feb 2015 01:49:50 GMT"}, {"version": "v9", "created": "Fri, 8 May 2015 15:58:54 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Sopin", "Valerii", ""]]}, {"id": "1411.0644", "submitter": "Kasper Green Larsen", "authors": "Allan Gr{\\o}nlund, Kasper Green Larsen", "title": "Towards Tight Lower Bounds for Range Reporting on the RAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the orthogonal range reporting problem, we are to preprocess a set of $n$\npoints with integer coordinates on a $U \\times U$ grid. The goal is to support\nreporting all $k$ points inside an axis-aligned query rectangle. This is one of\nthe most fundamental data structure problems in databases and computational\ngeometry. Despite the importance of the problem its complexity remains\nunresolved in the word-RAM. On the upper bound side, three best tradeoffs\nexists: (1.) Query time $O(\\lg \\lg n + k)$ with $O(nlg^{\\varepsilon}n)$ words\nof space for any constant $\\varepsilon>0$. (2.) Query time $O((1 + k) \\lg \\lg\nn)$ with $O(n \\lg \\lg n)$ words of space. (3.) Query time\n$O((1+k)\\lg^{\\varepsilon} n)$ with optimal $O(n)$ words of space. However, the\nonly known query time lower bound is $\\Omega(\\log \\log n +k)$, even for linear\nspace data structures.\n  All three current best upper bound tradeoffs are derived by reducing range\nreporting to a ball-inheritance problem. Ball-inheritance is a problem that\nessentially encapsulates all previous attempts at solving range reporting in\nthe word-RAM. In this paper we make progress towards closing the gap between\nthe upper and lower bounds for range reporting by proving cell probe lower\nbounds for ball-inheritance. Our lower bounds are tight for a large range of\nparameters, excluding any further progress for range reporting using the\nball-inheritance reduction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Nov 2014 20:10:57 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Gr\u00f8nlund", "Allan", ""], ["Larsen", "Kasper Green", ""]]}, {"id": "1411.0821", "submitter": "Uriel Feige", "authors": "Uriel Feige", "title": "NP-hardness of hypercube 2-segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypercube 2-segmentation problem is a certain biclustering problem that\nwas previously claimed to be NP-hard, but for which there does not appear to be\na publicly available proof of NP-hardness. This manuscript provides such a\nproof.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 08:08:17 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Feige", "Uriel", ""]]}, {"id": "1411.1397", "submitter": "Henry S. Yuen", "authors": "Kai-Min Chung, Xiaodi Wu, Henry Yuen", "title": "Strong parallel repetition for free entangled games, with any number of\n  players", "comments": "This manuscript has been withdrawn due to an error in Lemma 6.1, and\n  has been replaced by arXiv:1501.0033", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a strong parallel repetition theorem for the entangled value of\nmulti-player, one-round free games (games where the inputs come from a product\ndistribution). Our result is the first parallel repetition theorem for\nentangled games involving more than two players. Furthermore, our theorem\napplies to games where the players are allowed to output (possibly entangled)\nquantum states as answers.\n  More specifically, let $G$ be a $k$-player free game, with entangled value\n$\\mathrm{val}^*(G) = 1 - \\epsilon$. We show that the entangled value of the\n$n$-fold repetition of $G$, $\\mathrm{val}^*(G^{\\otimes n})$, is at most $(1 -\n\\epsilon)^{\\Omega(n/k^2)}$. In the traditional setting of $k=2$ players, our\nparallel repetition theorem is optimal in terms of its dependence on $\\epsilon$\nand $n$. For an arbitrary number of players, our result is nearly optimal: for\nall $k$, we exhibit a $k$-player free game $G$ and $n > 1$ such that\n$\\mathrm{val}^*(G^{\\otimes n}) \\geq \\mathrm{val}^*(G)^{n/k}$. Hence, exponent\nof the repeated game value cannot be improved beyond $\\Omega(n/k)$.\n  Our parallel repetition theorem improves on the prior results of [Jain, et\nal. 2014] and [Chailloux, Scarpa 2014] in a number of ways: (1) our theorem\napplies to a larger class of games (arbitrary number of players, quantum\noutputs); (2) we demonstrate that strong parallel repetition holds for the\nentangled value of free games: i.e., the base of the repeated game value is $1\n- \\epsilon$, rather than $1 - \\epsilon^2$; and (3) there is no dependence of\nthe repeated game value on the input and output alphabets of $G$. In contrast,\nit is known that the repeated game value of classical free games must depend on\nthe output size. Thus our results demonstrate a seperation between the behavior\nof entangled games and classical games.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 20:54:58 GMT"}, {"version": "v2", "created": "Mon, 5 Jan 2015 01:32:03 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Chung", "Kai-Min", ""], ["Wu", "Xiaodi", ""], ["Yuen", "Henry", ""]]}, {"id": "1411.1582", "submitter": "Rotem Arnon-Friedman", "authors": "Rotem Arnon-Friedman, Renato Renner, Thomas Vidick", "title": "Non-signalling parallel repetition using de Finetti reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of multiplayer games, the parallel repetition problem can be\nphrased as follows: given a game $G$ with optimal winning probability\n$1-\\alpha$ and its repeated version $G^n$ (in which $n$ games are played\ntogether, in parallel), can the players use strategies that are substantially\nbetter than ones in which each game is played independently? This question is\nrelevant in physics for the study of correlations and plays an important role\nin computer science in the context of complexity and cryptography. In this work\nthe case of multiplayer non-signalling games is considered, i.e., the only\nrestriction on the players is that they are not allowed to communicate during\nthe game. For complete-support games (games where all possible combinations of\nquestions have non-zero probability to be asked) with any number of players we\nprove a threshold theorem stating that the probability that non-signalling\nplayers win more than a fraction $1-\\alpha+\\beta$ of the $n$ games is\nexponentially small in $n\\beta^2$, for every $0\\leq \\beta \\leq \\alpha$. For\ngames with incomplete support we derive a similar statement, for a slightly\nmodified form of repetition. The result is proved using a new technique, based\non a recent de Finetti theorem, which allows us to avoid central technical\ndifficulties that arise in standard proofs of parallel repetition theorems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 12:19:16 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Arnon-Friedman", "Rotem", ""], ["Renner", "Renato", ""], ["Vidick", "Thomas", ""]]}, {"id": "1411.1619", "submitter": "Paul Wollan", "authors": "Ilario Bonacina, Nicola Galesi, Tony Huynh, and Paul Wollan", "title": "Space proof complexity for random $3$-CNFs via a $(2-\\epsilon)$-Hall's\n  Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the space complexity of refuting $3$-CNFs in Resolution and\nalgebraic systems. No lower bound for refuting any family of $3$-CNFs was\npreviously known for the total space in resolution or for the monomial space in\nalgebraic systems. We prove that every Polynomial Calculus with Resolution\nrefutation of a random $3$-CNF $\\phi$ in $n$ variables requires, with high\nprobability, $\\Omega(n/\\log n)$ distinct monomials to be kept simultaneously in\nmemory. The same construction also proves that every Resolution refutation\n$\\phi$ requires, with high probability, $\\Omega(n/\\log n)$ clauses each of\nwidth $\\Omega(n/\\log n)$ to be kept at the same time in memory. This gives a\n$\\Omega(n^2/\\log^2 n)$ lower bound for the total space needed in Resolution to\nrefute $\\phi$.\n  The main technical innovation is a variant of Hall's theorem. We show that in\nbipartite graphs $G$ with bipartition $(L,R)$ and left-degree at most 3, $L$\ncan be covered by certain families of disjoint paths, called $(2,4)$-matchings,\nprovided that $L$ expands in $R$ by a factor of $(2-\\epsilon)$, for $\\epsilon <\n\\frac{1}{23}$.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 14:08:24 GMT"}], "update_date": "2014-11-07", "authors_parsed": [["Bonacina", "Ilario", ""], ["Galesi", "Nicola", ""], ["Huynh", "Tony", ""], ["Wollan", "Paul", ""]]}, {"id": "1411.1879", "submitter": "Carsten Grimm", "authors": "Prosenjit Bose, Jean-Lou De Carufel, Carsten Grimm, Anil Maheshwari,\n  Michiel Smid", "title": "Optimal Data Structures for Farthest-Point Queries in Cactus Networks", "comments": null, "journal-ref": null, "doi": "10.7155/jgaa.00345", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the continuum of points on the edges of a network, i.e., a\nconnected, undirected graph with positive edge weights. We measure the distance\nbetween these points in terms of the weighted shortest path distance, called\nthe network distance. Within this metric space, we study farthest points and\nfarthest distances. We introduce optimal data structures supporting queries for\nthe farthest distance and the farthest points on trees, cycles, uni-cyclic\nnetworks, and cactus networks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 10:32:27 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Bose", "Prosenjit", ""], ["De Carufel", "Jean-Lou", ""], ["Grimm", "Carsten", ""], ["Maheshwari", "Anil", ""], ["Smid", "Michiel", ""]]}, {"id": "1411.1977", "submitter": "Pascal Schweitzer", "authors": "Pascal Schweitzer", "title": "Towards an Isomorphism Dichotomy for Hereditary Graph Classes", "comments": "37 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we resolve the complexity of the isomorphism problem on all but\nfinitely many of the graph classes characterized by two forbidden induced\nsubgraphs. To this end we develop new techniques applicable for the structural\nand algorithmic analysis of graphs. First, we develop a methodology to show\nisomorphism completeness of the isomorphism problem on graph classes by\nproviding a general framework unifying various reduction techniques. Second, we\ngeneralize the concept of the modular decomposition to colored graphs, allowing\nfor non-standard decompositions. We show that, given a suitable decomposition\nfunctor, the graph isomorphism problem reduces to checking isomorphism of\ncolored prime graphs. Third, we extend the techniques of bounded color valence\nand hypergraph isomorphism on hypergraphs of bounded color size as follows. We\nsay a colored graph has generalized color valence at most k if, after removing\nall vertices in color classes of size at most k, for each color class C every\nvertex has at most k neighbors in C or at most k non-neighbors in C. We show\nthat isomorphism of graphs of bounded generalized color valence can be solved\nin polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 16:58:25 GMT"}], "update_date": "2014-11-10", "authors_parsed": [["Schweitzer", "Pascal", ""]]}, {"id": "1411.1995", "submitter": "Simone Bova", "authors": "Simone Bova, Florent Capelli, Stefan Mengel, Friedrich Slivovsky", "title": "A Strongly Exponential Separation of DNNFs from CNF Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposable Negation Normal Forms (DNNFs) are Boolean circuits in negation\nnormal form where the subcircuits leading into each AND gate are defined on\ndisjoint sets of variables. We prove a strongly exponential lower bound on the\nsize of DNNFs for a class of CNF formulas built from expander graphs. As a\ncorollary, we obtain a strongly exponential separation between DNNFs and CNF\nformulas in prime implicates form. This settles an open problem in the area of\nknowledge compilation (Darwiche and Marquis, 2002).\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 17:43:33 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 15:30:16 GMT"}, {"version": "v3", "created": "Thu, 19 Feb 2015 13:43:45 GMT"}], "update_date": "2015-02-20", "authors_parsed": [["Bova", "Simone", ""], ["Capelli", "Florent", ""], ["Mengel", "Stefan", ""], ["Slivovsky", "Friedrich", ""]]}, {"id": "1411.2286", "submitter": "Venmugil Elango", "authors": "Venmugil Elango, Fabrice Rastello, Louis-Noel Pouchet, J. Ramanujam\n  and P. Sadayappan", "title": "On Characterizing the Data Access Complexity of Programs", "comments": null, "journal-ref": null, "doi": "10.1145/2676726.2677010", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology trends will cause data movement to account for the majority of\nenergy expenditure and execution time on emerging computers. Therefore,\ncomputational complexity will no longer be a sufficient metric for comparing\nalgorithms, and a fundamental characterization of data access complexity will\nbe increasingly important. The problem of developing lower bounds for data\naccess complexity has been modeled using the formalism of Hong & Kung's\nred/blue pebble game for computational directed acyclic graphs (CDAGs).\nHowever, previously developed approaches to lower bounds analysis for the\nred/blue pebble game are very limited in effectiveness when applied to CDAGs of\nreal programs, with computations comprised of multiple sub-computations with\ndiffering DAG structure. We address this problem by developing an approach for\neffectively composing lower bounds based on graph decomposition. We also\ndevelop a static analysis algorithm to derive the asymptotic data-access lower\nbounds of programs, as a function of the problem size and cache size.\n", "versions": [{"version": "v1", "created": "Sun, 9 Nov 2014 21:40:41 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Elango", "Venmugil", ""], ["Rastello", "Fabrice", ""], ["Pouchet", "Louis-Noel", ""], ["Ramanujam", "J.", ""], ["Sadayappan", "P.", ""]]}, {"id": "1411.2315", "submitter": "Xiaodi Wu", "authors": "Kai-Min Chung, Xin Li, Xiaodi Wu", "title": "Multi-Source Randomness Extractors Against Quantum Side Information, and\n  their Applications", "comments": "52 pages; comments are welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of constructing multi-source extractors in the quantum\nsetting, which extract almost uniform random bits against quantum side\ninformation collected from several initially independent classical random\nsources. This is a natural generalization of seeded randomness extraction\nagainst quantum side information and classical independent source extraction.\nWith new challenges such as potential entanglement in the side information, it\nis not a prior clear under what conditions do quantum multi-source extractors\nexist; the only previous work is [KK12], where the classical inner-product\ntwo-source extractors of [CG88] and [DEOR04] are shown to be quantum secure in\nthe restricted Independent Adversary (IA) Model and entangled Bounded Storage\n(BS) Model.\n  In this paper we propose a new model called General Entangled (GE) Adversary\nModel, which allows arbitrary entanglement in the side information and subsumes\nboth the IA model and the BS model. We proceed to show how to construct\nGE-secure quantum multi-source extractors. To that end, we propose another\nmodel called One-sided Adversary (OA) Model, which is weaker than all the above\nmodels. Somewhat surprisingly, we establish equivalence between strong\nOA-security and strong GE-security. As a result, all classical multi-source\nextractors can either directly work, or be modified to work in the GE model at\nthe cost of one extra random source. Thus, our constructions essentially match\nthe best known constructions of classical multi-source extractors.\n  We also apply our techniques to two important problems in cryptography and\ndistributed computing --- privacy amplification and network extractor. We show\nthat as long as the sources have certain amounts of conditional min-entropy in\nour GE model (even with entangled quantum side information), we can design very\nefficient privacy amplification protocols and network extractors.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 03:40:05 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Chung", "Kai-Min", ""], ["Li", "Xin", ""], ["Wu", "Xiaodi", ""]]}, {"id": "1411.2378", "submitter": "Eduardo Hermo Reyes", "authors": "Eduardo Hermo Reyes and Joost J. Joosten", "title": "The Selfish Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of Generalized Natural Selection (GNS) states that in nature,\ncomputational processes of high computational sophistication are more likely to\nmaintain/abide than processes of lower computational sophistication provided\nthat sufficiently many resources are around to sustain the processes. In this\npaper we give a concrete set-up how to test GNS in a weak sense. In particular,\nwe work in the setting of Cellular Automata and see how GNS can manifest itself\nin this setting.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 11:01:58 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Reyes", "Eduardo Hermo", ""], ["Joosten", "Joost J.", ""]]}, {"id": "1411.2577", "submitter": "Ilya Razenshteyn", "authors": "Alexandr Andoni, Robert Krauthgamer, Ilya Razenshteyn", "title": "Sketching and Embedding are Equivalent for Norms", "comments": "33 pages, an extended abstract appeared in the proceedings of the\n  47th ACM Symposium on Theory of Computing (STOC 2015); changes in v2: added\n  quantitative bounds for the main results, preliminaries section with\n  necessary definitions and facts has been added; v3: several clarifications,\n  including a section on the basics of communication complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An outstanding open question posed by Guha and Indyk in 2006 asks to\ncharacterize metric spaces in which distances can be estimated using efficient\nsketches. Specifically, we say that a sketching algorithm is efficient if it\nachieves constant approximation using constant sketch size. A well-known result\nof Indyk (J. ACM, 2006) implies that a metric that admits a constant-distortion\nembedding into $\\ell_p$ for $p\\in(0,2]$ also admits an efficient sketching\nscheme. But is the converse true, i.e., is embedding into $\\ell_p$ the only way\nto achieve efficient sketching?\n  We address these questions for the important special case of normed spaces,\nby providing an almost complete characterization of sketching in terms of\nembeddings. In particular, we prove that a finite-dimensional normed space\nallows efficient sketches if and only if it embeds (linearly) into\n$\\ell_{1-\\varepsilon}$ with constant distortion. We further prove that for\nnorms that are closed under sum-product, efficient sketching is equivalent to\nembedding into $\\ell_1$ with constant distortion. Examples of such norms\ninclude the Earth Mover's Distance (specifically its norm variant, called\nKantorovich-Rubinstein norm), and the trace norm (a.k.a. Schatten $1$-norm or\nthe nuclear norm). Using known non-embeddability theorems for these norms by\nNaor and Schechtman (SICOMP, 2007) and by Pisier (Compositio. Math., 1978), we\nthen conclude that these spaces do not admit efficient sketches either, making\nprogress towards answering another open question posed by Indyk in 2006.\n  Finally, we observe that resolving whether \"sketching is equivalent to\nembedding into $\\ell_1$ for general norms\" (i.e., without the above\nrestriction) is equivalent to resolving a well-known open problem in Functional\nAnalysis posed by Kwapien in 1969.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 20:42:51 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2015 13:02:08 GMT"}, {"version": "v3", "created": "Wed, 15 Feb 2017 15:03:49 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Andoni", "Alexandr", ""], ["Krauthgamer", "Robert", ""], ["Razenshteyn", "Ilya", ""]]}, {"id": "1411.2901", "submitter": "Bernd Schuh", "authors": "Bernd R. Schuh", "title": "Easy/Hard Transition in k-SAT", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A heuristic model procedure for determining satisfiability of CNF-formulae is\nset up and described by nonlinear recursion relations for m (number of\nclauses), n (number of variables) and clause filling k. The system mimicked by\nthe recursion undergoes a sharp transition from bounded running times (easy) to\nuncontrolled runaway behaviour (hard). Thus the parameter space turns out to be\nseparated into regions with qualitatively different efficiency of the model\nprocedure. The transition results from a competition of exponential blow up by\nbranching versus growing number of orthogonal clauses.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 17:51:27 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Schuh", "Bernd R.", ""]]}, {"id": "1411.3010", "submitter": "Leonid A. Levin", "authors": "Leonid A. Levin", "title": "Computational Complexity of Functions", "comments": "Partial translation from [Levin 74]; preliminary version is in [Levin\n  73]", "journal-ref": "Theoretical Computer Science, 157:267-271, 1996", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Below is a translation from my Russian paper. I added references, unavailable\nto me in Moscow. Similar results have been also given in [Schnorr Stumpf 75]\n(see also [Lynch 75]). Earlier relevant work (classical theorems like\nCompression, Speed-up, etc.) was done in [Tseitin 56, Rabin 59, Hartmanis\nStearns 65, Blum 67, Trakhtenbrot 67, Meyer Fischer 72].\n  I translated only the part with the statement of the results. Instead of the\nproof part I appended a later (1979, unpublished) proof sketch of a slightly\ntighter version. The improvement is based on the results of [Meyer Winklmann\n78, Sipser 78]. Meyer and Winklmann extended earlier versions to machines with\na separate input and working tape, thus allowing complexities smaller than the\ninput length (down to its log). Sipser showed the space-bounded Halting Problem\nto require only additive constant overhead. The proof in the appendix below\nemploys both advances to extend the original proofs to machines with a fixed\nalphabet and a separate input and working space. The extension has no (even\nlogarithmic) restrictions on complexity and no overhead (beyond an additive\nconstant). The sketch is very brief and a more detailed exposition is expected\nlater: [Seiferas Meyer].\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 22:50:51 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Levin", "Leonid A.", ""]]}, {"id": "1411.3164", "submitter": "Anthony Widjaja Lin", "authors": "Anthony Widjaja Lin, Sanming Zhou", "title": "A linear time algorithm for the orbit problem over cyclic groups", "comments": "Accepted in Acta Informatica in Nov 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The orbit problem is at the heart of symmetry reduction methods for model\nchecking concurrent systems. It asks whether two given configurations in a\nconcurrent system (represented as finite strings over some finite alphabet) are\nin the same orbit with respect to a given finite permutation group (represented\nby their generators) acting on this set of configurations by permuting indices.\nIt is known that the problem is in general as hard as the graph isomorphism\nproblem, whose precise complexity (whether it is solvable in polynomial-time)\nis a long-standing open problem. In this paper, we consider the restriction of\nthe orbit problem when the permutation group is cyclic (i.e. generated by a\nsingle permutation), an important restriction of the problem. It is known that\nthis subproblem is solvable in polynomial-time. Our main result is a\nlinear-time algorithm for this subproblem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 13:09:13 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2015 03:45:11 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Lin", "Anthony Widjaja", ""], ["Zhou", "Sanming", ""]]}, {"id": "1411.3419", "submitter": "Mohammad Bavarian", "authors": "Andris Ambainis, Mohammad Bavarian, Yihan Gao, Jieming Mao, Xiaoming\n  Sun, Song Zuo", "title": "Tighter Relations Between Sensitivity and Other Complexity Measures", "comments": "This is the merged form of arXiv submission 1306.4466 with another\n  work. Appeared in ICALP 2014, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitivity conjecture is a longstanding and fundamental open problem in the\narea of complexity measures of Boolean functions and decision tree complexity.\nThe conjecture postulates that the maximum sensitivity of a Boolean function is\npolynomially related to other major complexity measures. Despite much attention\nto the problem and major advances in analysis of Boolean functions in the past\ndecade, the problem remains wide open with no positive result toward the\nconjecture since the work of Kenyon and Kutin from 2004.\n  In this work, we present new upper bounds for various complexity measures in\nterms of sensitivity improving the bounds provided by Kenyon and Kutin.\nSpecifically, we show that deg(f)^{1-o(1)}=O(2^{s(f)}) and C(f) < 2^{s(f)-1}\ns(f); these in turn imply various corollaries regarding the relation between\nsensitivity and other complexity measures, such as block sensitivity, via known\nresults. The gap between sensitivity and other complexity measures remains\nexponential but these results are the first improvement for this difficult\nproblem that has been achieved in a decade.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 02:25:53 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Ambainis", "Andris", ""], ["Bavarian", "Mohammad", ""], ["Gao", "Yihan", ""], ["Mao", "Jieming", ""], ["Sun", "Xiaoming", ""], ["Zuo", "Song", ""]]}, {"id": "1411.3517", "submitter": "Girish Varma", "authors": "Irit Dinur, Prahladh Harsha, Srikanth Srinivasan, Girish Varma", "title": "Derandomized Graph Product Results using the Low Degree Long Code", "comments": null, "journal-ref": "In Proc. 32nd STACS, vol 30 of LiPiCS, pages 275-287, 2015", "doi": "10.4230/LIPIcs.STACS.2015.275", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the question of whether the recent derandomization\nresults obtained by the use of the low-degree long code can be extended to\nother product settings. We consider two settings: (1) the graph product results\nof Alon, Dinur, Friedgut and Sudakov [GAFA, 2004] and (2) the \"majority is\nstablest\" type of result obtained by Dinur, Mossel and Regev [SICOMP, 2009] and\nDinur and Shinkar [In Proc. APPROX, 2010] while studying the hardness of\napproximate graph coloring.\n  In our first result, we show that there exists a considerably smaller\nsubgraph of $K_3^{\\otimes R}$ which exhibits the following property (shown for\n$K_3^{\\otimes R}$ by Alon et al.): independent sets close in size to the\nmaximum independent set are well approximated by dictators.\n  The \"majority is stablest\" type of result of Dinur et al. and Dinur and\nShinkar shows that if there exist two sets of vertices $A$ and $B$ in\n$K_3^{\\otimes R}$ with very few edges with one endpoint in $A$ and another in\n$B$, then it must be the case that the two sets $A$ and $B$ share a single\ninfluential coordinate. In our second result, we show that a similar \"majority\nis stablest\" statement holds good for a considerably smaller subgraph of\n$K_3^{\\otimes R}$. Furthermore using this result, we give a more efficient\nreduction from Unique Games to the graph coloring problem, leading to improved\nhardness of approximation results for coloring.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 12:21:55 GMT"}, {"version": "v2", "created": "Tue, 10 Feb 2015 16:54:13 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Dinur", "Irit", ""], ["Harsha", "Prahladh", ""], ["Srinivasan", "Srikanth", ""], ["Varma", "Girish", ""]]}, {"id": "1411.3603", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne, Venkatesan Guruswami, Raghu Meka, Madhu Sudan", "title": "Communication with Imperfectly Shared Randomness", "comments": "Updated some references and discussion w.r.t. previous work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The communication complexity of many fundamental problems reduces greatly\nwhen the communicating parties share randomness that is independent of the\ninputs to the communication task. Natural communication processes (say between\nhumans) however often involve large amounts of shared correlations among the\ncommunicating players, but rarely allow for perfect sharing of randomness. Can\nthe communication complexity benefit from shared correlations as well as it\ndoes from shared randomness? This question was considered mainly in the context\nof simultaneous communication by Bavarian et al. (ICALP 2014). In this work we\nstudy this problem in the standard interactive setting and give some general\nresults. In particular, we show that every problem with communication\ncomplexity of $k$ bits with perfectly shared randomness has a protocol using\nimperfectly shared randomness with complexity $\\exp(k)$ bits. We also show that\nthis is best possible by exhibiting a promise problem with complexity $k$ bits\nwith perfectly shared randomness which requires $\\exp(k)$ bits when the\nrandomness is imperfectly shared. Along the way we also highlight some other\nbasic problems such as compression, and agreement distillation, where shared\nrandomness plays a central role and analyze the complexity of these problems in\nthe imperfectly shared randomness model.\n  The technical highlight of this work is the lower bound that goes into the\nresult showing the tightness of our general connection. This result builds on\nthe intuition that communication with imperfectly shared randomness needs to be\nless sensitive to its random inputs than communication with perfectly shared\nrandomness. The formal proof invokes results about the small-set expansion of\nthe noisy hypercube and an invariance principle to convert this intuition to a\nproof, thus giving a new application domain for these fundamental results.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 16:23:22 GMT"}, {"version": "v2", "created": "Tue, 18 Nov 2014 18:56:02 GMT"}, {"version": "v3", "created": "Tue, 10 May 2016 18:25:02 GMT"}, {"version": "v4", "created": "Thu, 27 Jul 2017 17:59:10 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Guruswami", "Venkatesan", ""], ["Meka", "Raghu", ""], ["Sudan", "Madhu", ""]]}, {"id": "1411.3799", "submitter": "Luis Rademacher", "authors": "Navin Goyal, Luis Rademacher, Santosh Vempala", "title": "Query complexity of sampling and small geometric partitions", "comments": null, "journal-ref": "Combinator. Probab. Comp. 24 (2015) 733-753", "doi": "10.1017/S0963548314000704", "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the following problem:\n  Discrete partitioning problem (DPP): Let $\\mathbb{F}_q P^n$ denote the\n$n$-dimensional finite projective space over $\\mathbb{F}_q$. For positive\ninteger $k \\leq n$, let $\\{ A^i\\}_{i=1}^N$ be a partition of $(\\mathbb{F}_q\nP^n)^k$ such that\n  (1) for all $i \\leq N$, $A^i = \\prod_{j=1}^k A^i_j$ (partition into product\nsets),\n  (2) for all $i \\leq N$, there is a $(k-1)$-dimensional subspace $L^i\n\\subseteq \\mathbb{F}_q P^n$ such that $A^i \\subseteq (L^i)^k$.\n  What is the minimum value of $N$ as a function of $q,n,k$? We will be mainly\ninterested in the case $k=n$.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 05:41:56 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Goyal", "Navin", ""], ["Rademacher", "Luis", ""], ["Vempala", "Santosh", ""]]}, {"id": "1411.4074", "submitter": "Mark Huber", "authors": "Mark Huber", "title": "Improving Monte Carlo randomized approximation schemes", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a central problem in randomized approximation schemes that use a\nMonte Carlo approach. Given a sequence of independent, identically distributed\nrandom variables $X_1,X_2,\\ldots$ with mean $\\mu$ and standard deviation at\nmost $c \\mu$, where $c$ is a known constant, and $\\epsilon,\\delta > 0$, create\nan estimate $\\hat \\mu$ for $\\mu$ such that $\\text{P}(|\\hat \\mu - \\mu| >\n\\epsilon \\mu) \\leq \\delta$. This technique has been used for building\nrandomized approximation schemes for the volume of a convex body, the permanent\nof a nonnegative matrix, the number of linear extensions of a poset, the\npartition function of the Ising model and many other problems. Existing methods\nuse (to the leading order) $19.35 (c/\\epsilon)^2 \\ln(\\delta^{-1})$ samples.\nThis is the best possible number up to the constant factor, and it is an open\nquestion as to what is the best constant possible. This work gives an easy to\napply estimate that only uses $6.96 (c/\\epsilon)^2 \\ln(\\delta^{-1})$ samples in\nthe leading order.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 22:40:04 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Huber", "Mark", ""]]}, {"id": "1411.4184", "submitter": "Marcin Pilipczuk", "authors": "Marek Cygan and D\\'aniel Marx and Marcin Pilipczuk and Micha{\\l}\n  Pilipczuk", "title": "Hitting forbidden subgraphs in graphs of bounded treewidth", "comments": "A full version of a paper presented at MFCS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of a generic hitting problem H-Subgraph Hitting,\nwhere given a fixed pattern graph $H$ and an input graph $G$, the task is to\nfind a set $X \\subseteq V(G)$ of minimum size that hits all subgraphs of $G$\nisomorphic to $H$. In the colorful variant of the problem, each vertex of $G$\nis precolored with some color from $V(H)$ and we require to hit only\n$H$-subgraphs with matching colors. Standard techniques shows that for every\nfixed $H$, the problem is fixed-parameter tractable parameterized by the\ntreewidth of $G$; however, it is not clear how exactly the running time should\ndepend on treewidth. For the colorful variant, we demonstrate matching upper\nand lower bounds showing that the dependence of the running time on treewidth\nof $G$ is tightly governed by $\\mu(H)$, the maximum size of a minimal vertex\nseparator in $H$. That is, we show for every fixed $H$ that, on a graph of\ntreewidth $t$, the colorful problem can be solved in time\n$2^{\\mathcal{O}(t^{\\mu(H)})}\\cdot|V(G)|$, but cannot be solved in time\n$2^{o(t^{\\mu(H)})}\\cdot |V(G)|^{O(1)}$, assuming the Exponential Time\nHypothesis (ETH). Furthermore, we give some preliminary results showing that,\nin the absence of colors, the parameterized complexity landscape of H-Subgraph\nHitting is much richer.\n", "versions": [{"version": "v1", "created": "Sat, 15 Nov 2014 20:47:20 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Cygan", "Marek", ""], ["Marx", "D\u00e1niel", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1411.4369", "submitter": "Karsten Lehmann", "authors": "Karsten Lehmann, Alban Grastien and Pascal Van Hentenryck", "title": "The Complexity of DC-Switching Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report provides a comprehensive complexity study of line switching in\nthe Linear DC model for the feasibility problem and the optimization problems\nof maximizing the load that can be served (maximum switching flow, MSF) and\nminimizing generation cost (optimal transmission switching, OTS). Our results\nshow that these problems are NP-complete and that there is no fully\npolynomial-time approximation scheme for planar networks with a maximum-node\ndegree of 3. Additionally, we demonstrate that the problems are still NP-hard\nif we restrict the network structure to cacti with a maximum degree of 3. We\nalso show that the optimization problems can not be approximated within any\nconstant factor.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 05:46:38 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Lehmann", "Karsten", ""], ["Grastien", "Alban", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1411.4584", "submitter": "Raghu Meka", "authors": "Parikshit Gopalan, Daniel Kane, Raghu Meka", "title": "Pseudorandomness for concentration bounds and signed majorities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constructing pseudorandom generators that fool halfspaces has\nbeen studied intensively in recent times. For fooling halfspaces over the\nhypercube with polynomially small error, the best construction known requires\nseed-length O(log^2 n) (MekaZ13). Getting the seed-length down to O(log(n)) is\na natural challenge in its own right, which needs to be overcome in order to\nderandomize RL. In this work we make progress towards this goal by obtaining\nnear-optimal generators for two important special cases:\n  1) We give a near optimal derandomization of the Chernoff bound for\nindependent, uniformly random bits. Specifically, we show how to generate a x\nin {1,-1}^n using $\\tilde{O}(\\log (n/\\epsilon))$ random bits such that for any\nunit vector u, <u,x> matches the sub-Gaussian tail behaviour predicted by the\nChernoff bound up to error eps.\n  2) We construct a generator which fools halfspaces with {0,1,-1} coefficients\nwith error eps with a seed-length of $\\tilde{O}(\\log(n/\\epsilon))$. This\nincludes the important special case of majorities.\n  In both cases, the best previous results required seed-length of $O(\\log n +\n\\log^2(1/\\epsilon))$.\n  Technically, our work combines new Fourier-analytic tools with the iterative\ndimension reduction techniques and the gradually increasing independence\nparadigm of previous works (KaneMN11, CelisRSW13, GopalanMRTV12).\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 18:42:56 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Gopalan", "Parikshit", ""], ["Kane", "Daniel", ""], ["Meka", "Raghu", ""]]}, {"id": "1411.5060", "submitter": "Jugal Garg", "authors": "Jugal Garg and Ruta Mehta and Vijay V. Vazirani and Sadra Yazdanbod", "title": "Settling the Complexity of Arrow-Debreu Markets under Leontief and PLC\n  Utilities, using the Classes FIXP and \\Exists-R", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper resolves two of the handful of remaining questions on the\ncomputability of market equilibria, a central theme within algorithmic game\ntheory (AGT). Our results are as follows:\n  1. We show FIXP-hardness of computing equilibria in Arrow-Debreu markets\nunder Leontief utility functions, and Arrow-Debreu markets under linear utility\nfunctions and Leontief production sets. We note that these are the first\nFIXP-hardness results ever since the introduction of the class FIXP and the\nhardness of 3-Nash established therein.\n  2. We note that for the problems stated above, the corresponding results\nshowing membership in FIXP were established after imposing suitable sufficiency\nconditions to render the problems total, as is customary in economics. However,\nif all instances are under consideration, then in both cases we prove that the\nproblem of deciding if a given instance admits an equilibrium is\n\\Exists-R-complete, where \\Exists-R is the class of decision problems which can\nbe reduced in polynomial time to Existential Theory of the Reals.\n  3. For Arrow-Debreu markets under Leontief utility functions and a constant\nnumber of agents, we give a polynomial-time algorithm for computing an\nequilibrium. This settles part of an open problem of Devanur and Kannan\n(FOCS'08).\n  We note that PLC utilities are about the most general utilities of interest\nin economics and several fundamental utility functions studied within AGT are\nspecial cases of it. Several important problems, which have been shown to be in\nFIXP, are waiting for proofs of FIXP-hardness. In this context, our technique\nof reducing from 3-Nash to Multivariate Polynomial Equations and then to the\nproblem is likely to be useful in the future.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 23:04:07 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 03:23:51 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Garg", "Jugal", ""], ["Mehta", "Ruta", ""], ["Vazirani", "Vijay V.", ""], ["Yazdanbod", "Sadra", ""]]}, {"id": "1411.5414", "submitter": "Francois Le Gall", "authors": "Andris Ambainis, Yuval Filmus, Fran\\c{c}ois Le Gall", "title": "Fast Matrix Multiplication: Limitations of the Laser Method", "comments": "38 pages + cover page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Until a few years ago, the fastest known matrix multiplication algorithm, due\nto Coppersmith and Winograd (1990), ran in time $O(n^{2.3755})$. Recently, a\nsurge of activity by Stothers, Vassilevska-Williams, and Le Gall has led to an\nimproved algorithm running in time $O(n^{2.3729})$. These algorithms are\nobtained by analyzing higher and higher tensor powers of a certain identity of\nCoppersmith and Winograd. We show that this exact approach cannot result in an\nalgorithm with running time $O(n^{2.3725})$, and identify a wide class of\nvariants of this approach which cannot result in an algorithm with running time\n$O(n^{2.3078})$; in particular, this approach cannot prove the conjecture that\nfor every $\\epsilon > 0$, two $n\\times n$ matrices can be multiplied in time\n$O(n^{2+\\epsilon})$.\n  We describe a new framework extending the original laser method, which is the\nmethod underlying the previously mentioned algorithms. Our framework\naccommodates the algorithms by Coppersmith and Winograd, Stothers,\nVassilevska-Williams and Le Gall. We obtain our main result by analyzing this\nframework. The framework is also the first to explain why taking tensor powers\nof the Coppersmith-Winograd identity results in faster algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Nov 2014 01:07:08 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Ambainis", "Andris", ""], ["Filmus", "Yuval", ""], ["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "1411.5437", "submitter": "Stephen A. Fenner", "authors": "Stephen A. Fenner (University of South Carolina, USA)", "title": "The complexity of some regex crossword problems", "comments": "25 pages, 3 figures; three references added with explanation,\n  citation added to Corollary 5, more detail in proof of Theorem 8, other minor\n  corrections (results unchanged)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a typical regular expression (regex) crossword puzzle, you are given two\nnonempty lists $R_1,\\ldots,R_m$ and $C_1,\\ldots,C_n$ of regular expressions\nover some alphabet, and your goal is to fill in an $m\\times n$ grid with\nletters from that alphabet so that the string formed by the $i$th row is in\n$L(R_i)$, and the string formed by the $j$th column is in $L(C_j)$, for all\n$1\\le i\\le m$ and $1\\le j\\le n$. Such a grid is a solution to the puzzle. It is\nknown that determining whether a solution exists is NP-complete. We consider a\nnumber of restrictions and variants to this problem where all the $R_i$ are\nequal to some regular expression $R$, and all the $C_j$ are equal to some\nregular expression $C$. We call the solution to such a puzzle an\n$(R,C)$-crossword. Our main results are the following:\n  1. There exists a fixed regular expression $C$ over the alphabet $\\{0,1\\}$\nsuch that the following problem is NP-complete: \"Given a regular expression $R$\nover $\\{0,1\\}$ and positive integers $m$ and $n$ given in unary, does an\n$m\\times n$ $(R,C)$-crossword exist?\" This improves the result mentioned above.\n  2. The following problem is NP-hard: \"Given a regular expression $E$ over\n$\\{0,1\\}$ and positive integers $m$ and $n$ given in unary, does an $m\\times n$\n$(E,E)$-crossword exist?\"\n  3. There exists a fixed regular expression $C$ over $\\{0,1\\}$ such that the\nfollowing problem is undecidable (equivalent to the Halting Problem): \"Given a\nregular expression $R$ over $\\{0,1\\}$, does an $(R,C)$-crossword exist (of any\nsize)?\"\n  4. The following problem is undecidable (equivalent to the Halting Problem):\n\"Given a regular expression $E$ over $\\{0,1\\}$, does an $(E,E)$-crossword exist\n(of any size)?\"\n", "versions": [{"version": "v1", "created": "Thu, 20 Nov 2014 04:28:47 GMT"}, {"version": "v2", "created": "Fri, 28 Nov 2014 20:43:46 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Fenner", "Stephen A.", "", "University of South Carolina, USA"]]}, {"id": "1411.5729", "submitter": "Scott Aaronson", "authors": "Scott Aaronson and Andris Ambainis", "title": "Forrelation: A Problem that Optimally Separates Quantum from Classical\n  Computing", "comments": "60 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We achieve essentially the largest possible separation between quantum and\nclassical query complexities. We do so using a property-testing problem called\nForrelation, where one needs to decide whether one Boolean function is highly\ncorrelated with the Fourier transform of a second function. This problem can be\nsolved using 1 quantum query, yet we show that any randomized algorithm needs\n~sqrt(N)/log(N) queries (improving an ~N^{1/4} lower bound of Aaronson).\nConversely, we show that this 1 versus ~sqrt(N) separation is optimal: indeed,\nany t-query quantum algorithm whatsoever can be simulated by an\nO(N^{1-1/2t})-query randomized algorithm. Thus, resolving an open question of\nBuhrman et al. from 2002, there is no partial Boolean function whose quantum\nquery complexity is constant and whose randomized query complexity is linear.\nWe conjecture that a natural generalization of Forrelation achieves the optimal\nt versus ~N^{1-1/2t} separation for all t. As a bonus, we show that this\ngeneralization is BQP-complete. This yields what's arguably the simplest\nBQP-complete problem yet known, and gives a second sense in which Forrelation\n\"captures the maximum power of quantum computation.\"\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 00:21:03 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["Aaronson", "Scott", ""], ["Ambainis", "Andris", ""]]}, {"id": "1411.5765", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt", "title": "TrackMania is NP-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that completing an untimed, unbounded track in TrackMania Nations\nForever is NP-complete by using a reduction from 3-SAT and showing that a\nsolution can be checked in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 04:08:28 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["Dernoncourt", "Franck", ""]]}, {"id": "1411.5951", "submitter": "Tom van der Zanden", "authors": "Tom C. van der Zanden and Hans L. Bodlaender", "title": "PSPACE-completeness of Bloxorz and of Games with 2-Buttons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bloxorz is an online puzzle game where players move a 1 by 1 by 2 block by\ntilting it on a subset of the two dimensional grid. Bloxorz features switches\nthat open and close trapdoors. The puzzle is to move the block from its initial\nposition to an upright position on the destination square. We show that the\nproblem of deciding whether a given Bloxorz level is solvable is\nPSPACE-complete and that this remains so even when all trapdoors are initially\nclosed or all trapdoors are initially open. We also answer an open question of\nViglietta, showing that 2-buttons are sufficient for PSPACE-hardness of general\npuzzle games. We also examine the hardness of some variants of Bloxorz,\nincluding variants where the block is a 1 by 1 by 1 cube, and variants with\nsingle-use tiles.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 16:46:40 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["van der Zanden", "Tom C.", ""], ["Bodlaender", "Hans L.", ""]]}, {"id": "1411.6049", "submitter": "Gorjan Alagic", "authors": "Gorjan Alagic, Catharine Lo", "title": "Quantum Invariants of 3-manifolds and NP vs #P", "comments": "22 pages, 5 figures", "journal-ref": "Quantum Information & Computation 17(1&2): 125-141 (2017)", "doi": null, "report-no": null, "categories": "cs.CC math.QA quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity class #P captures the difficulty of counting the\nsatisfying assignments to a boolean formula. In this work, we use basic tools\nfrom quantum computation to give a proof that the SO(3)\nWitten-Reshetikhin-Turaev (WRT) invariant of 3-manifolds is #P-hard to\ncalculate. We then apply this result to a question about the combinatorics of\nHeegaard splittings, motivated by analogous work on link diagrams by M.\nFreedman. We show that, if $\\#\\text{P}\\neq\\text{FP}^\\text{NP}$, then there\nexist infinitely many Heegaard splittings which cannot be made logarithmically\nthin by local WRT-preserving moves, except perhaps via a superpolynomial number\nof steps. We also outline two extensions of the above results. First, adapting\na result of Kuperberg, we show that any presentation-independent approximation\nof WRT is also #P-hard. Second, we sketch out how all of our results can be\ntranslated to the setting of triangulations and Turaev-Viro invariants.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 23:11:17 GMT"}, {"version": "v2", "created": "Sun, 19 Mar 2017 17:45:44 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Alagic", "Gorjan", ""], ["Lo", "Catharine", ""]]}, {"id": "1411.6299", "submitter": "Pravesh Kothari", "authors": "Pravesh Kothari and Raghu Meka", "title": "Almost Optimal Pseudorandom Generators for Spherical Caps", "comments": "28 Pages (including the title page)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Halfspaces or linear threshold functions are widely studied in complexity\ntheory, learning theory and algorithm design. In this work we study the natural\nproblem of constructing pseudorandom generators (PRGs) for halfspaces over the\nsphere, aka spherical caps, which besides being interesting and basic geometric\nobjects, also arise frequently in the analysis of various randomized algorithms\n(e.g., randomized rounding). We give an explicit PRG which fools spherical caps\nwithin error $\\epsilon$ and has an almost optimal seed-length of $O(\\log n +\n\\log(1/\\epsilon) \\cdot \\log\\log(1/\\epsilon))$. For an inverse-polynomially\ngrowing error $\\epsilon$, our generator has a seed-length optimal up to a\nfactor of $O( \\log \\log {(n)})$. The most efficient PRG previously known (due\nto Kane, 2012) requires a seed-length of $\\Omega(\\log^{3/2}{(n)})$ in this\nsetting. We also obtain similar constructions to fool halfspaces with respect\nto the Gaussian distribution.\n  Our construction and analysis are significantly different from previous works\non PRGs for halfspaces and build on the iterative dimension reduction ideas of\nKane et. al. (2011) and Celis et. al. (2013), the \\emph{classical moment\nproblem} from probability theory and explicit constructions of \\emph{orthogonal\ndesigns} based on the seminal work of Bourgain and Gamburd (2011) on expansion\nin Lie groups.\n", "versions": [{"version": "v1", "created": "Sun, 23 Nov 2014 21:19:14 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2015 21:00:42 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Kothari", "Pravesh", ""], ["Meka", "Raghu", ""]]}, {"id": "1411.6317", "submitter": "James Lee", "authors": "James R. Lee and Prasad Raghavendra and David Steurer", "title": "Lower bounds on the size of semidefinite programming relaxations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for proving lower bounds on the efficacy of\nsemidefinite programming (SDP) relaxations for combinatorial problems. In\nparticular, we show that the cut, TSP, and stable set polytopes on $n$-vertex\ngraphs are not the linear image of the feasible region of any SDP (i.e., any\nspectrahedron) of dimension less than $2^{n^c}$, for some constant $c > 0$.\nThis result yields the first super-polynomial lower bounds on the semidefinite\nextension complexity of any explicit family of polytopes.\n  Our results follow from a general technique for proving lower bounds on the\npositive semidefinite rank of a matrix. To this end, we establish a close\nconnection between arbitrary SDPs and those arising from the sum-of-squares SDP\nhierarchy. For approximating maximum constraint satisfaction problems, we prove\nthat SDPs of polynomial-size are equivalent in power to those arising from\ndegree-$O(1)$ sum-of-squares relaxations. This result implies, for instance,\nthat no family of polynomial-size SDP relaxations can achieve better than a\n7/8-approximation for MAX-3-SAT.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 01:00:51 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Lee", "James R.", ""], ["Raghavendra", "Prasad", ""], ["Steurer", "David", ""]]}, {"id": "1411.6322", "submitter": "Ioannis Panageas", "authors": "Ruta Mehta and Ioannis Panageas and Georgios Piliouras and Sadra\n  Yazdanbod", "title": "The Complexity of Genetic Diversity", "comments": "24 pages, 2 figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CC cs.GT math.DS math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key question in biological systems is whether genetic diversity persists in\nthe long run under evolutionary competition or whether a single dominant\ngenotype emerges. Classic work by Kalmus in 1945 has established that even in\nsimple diploid species (species with two chromosomes) diversity can be\nguaranteed as long as the heterozygote individuals enjoy a selective advantage.\nDespite the classic nature of the problem, as we move towards increasingly\npolymorphic traits (e.g. human blood types) predicting diversity and\nunderstanding its implications is still not fully understood. Our key\ncontribution is to establish complexity theoretic hardness results implying\nthat even in the textbook case of single locus diploid models predicting\nwhether diversity survives or not given its fitness landscape is\nalgorithmically intractable. We complement our results by establishing that\nunder randomly chosen fitness landscapes diversity survives with significant\nprobability. Our results are structurally robust along several dimensions\n(e.g., choice of parameter distribution, different definitions of\nstability/persistence, restriction to typical subclasses of fitness\nlandscapes). Technically, our results exploit connections between game theory,\nnonlinear dynamical systems, complexity theory and biology and establish\nhardness results for predicting the evolution of a deterministic variant of the\nwell known multiplicative weights update algorithm in symmetric coordination\ngames which could be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 01:35:10 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 14:51:53 GMT"}], "update_date": "2015-10-23", "authors_parsed": [["Mehta", "Ruta", ""], ["Panageas", "Ioannis", ""], ["Piliouras", "Georgios", ""], ["Yazdanbod", "Sadra", ""]]}, {"id": "1411.6549", "submitter": "Bernhard Bliem", "authors": "Bernhard Bliem and Stefan Woltran", "title": "Complexity of Secure Sets", "comments": "28 pages, 9 figures, short version accepted at WG 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A secure set $S$ in a graph is defined as a set of vertices such that for any\n$X\\subseteq S$ the majority of vertices in the neighborhood of $X$ belongs to\n$S$. It is known that deciding whether a set $S$ is secure in a graph is\nco-NP-complete. However, it is still open how this result contributes to the\nactual complexity of deciding whether for a given graph $G$ and integer $k$, a\nnon-empty secure set for $G$ of size at most $k$ exists. In this work, we\npinpoint the complexity of this problem by showing that it is\n$\\Sigma^P_2$-complete. Furthermore, the problem has so far not been subject to\na parameterized complexity analysis that considers structural parameters. In\nthe present work, we prove that the problem is $W[1]$-hard when parameterized\nby treewidth. This is surprising since the problem is known to be FPT when\nparameterized by solution size and \"subset problems\" that satisfy this property\nusually tend to be FPT for bounded treewidth as well. Finally, we give an upper\nbound by showing membership in XP, and we provide a positive result in the form\nof an FPT algorithm for checking whether a given set is secure on graphs of\nbounded treewidth.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 17:55:05 GMT"}, {"version": "v2", "created": "Sun, 25 Dec 2016 16:00:11 GMT"}, {"version": "v3", "created": "Mon, 10 Jul 2017 13:09:20 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Bliem", "Bernhard", ""], ["Woltran", "Stefan", ""]]}, {"id": "1411.6614", "submitter": "Yichen Huang", "authors": "Yichen Huang", "title": "Two-dimensional local Hamiltonian problem with area laws is QMA-complete", "comments": "v2: conference version; v3: journal version with improved\n  presentation (thanks to the reviewers' suggestions). 20-minute video\n  presentation: https://youtu.be/CKwt_pqLOVM", "journal-ref": "2020 IEEE International Symposium on Information Theory,\n  1927-1932; Journal of Computational Physics 444, 110534, 2021", "doi": "10.1109/ISIT44484.2020.9174029 10.1016/j.jcp.2021.110534", "report-no": null, "categories": "cond-mat.str-el cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the two-dimensional (2D) local Hamiltonian problem with the\nconstraint that the ground state obeys area laws is QMA-complete. We also prove\nsimilar results in 2D translation-invariant systems and for the 3D Heisenberg\nand Hubbard models with local magnetic fields. Consequently, unless MA = QMA,\nnot all ground states of 2D local Hamiltonians with area laws have efficient\nclassical representations that support efficient computation of local\nexpectation values. In the future, even if area laws are proved for ground\nstates of 2D gapped systems, the computational complexity of these systems\nremains unclear.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 20:56:03 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 21:10:00 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 18:52:37 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Huang", "Yichen", ""]]}, {"id": "1411.6712", "submitter": "Zhaohui Wei", "authors": "Troy Lee and Zhaohui Wei", "title": "The square root rank of the correlation polytope is exponential", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The square root rank of a nonnegative matrix $A$ is the minimum rank of a\nmatrix $B$ such that $A=B \\circ B$, where $\\circ$ denotes entrywise product. We\nshow that the square root rank of the slack matrix of the correlation polytope\nis exponential. Our main technique is a way to lower bound the rank of certain\nmatrices under arbitrary sign changes of the entries using properties of the\nroots of polynomials in number fields. The square root rank is an upper bound\non the positive semidefinite rank of a matrix, and corresponds the special case\nwhere all matrices in the factorization are rank-one.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 03:08:40 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Lee", "Troy", ""], ["Wei", "Zhaohui", ""]]}, {"id": "1411.6829", "submitter": "John Lapinskas", "authors": "Leslie Ann Goldberg and Rob Gysel and John Lapinskas", "title": "Approximately counting locally-optimal structures", "comments": "Accepted to JCSS, preliminary version accepted to ICALP 2015 (Track\n  A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A locally-optimal structure is a combinatorial structure such as a maximal\nindependent set that cannot be improved by certain (greedy) local moves, even\nthough it may not be globally optimal. It is trivial to construct an\nindependent set in a graph. It is easy to (greedily) construct a maximal\nindependent set. However, it is NP-hard to construct a globally-optimal\n(maximum) independent set. In general, constructing a locally-optimal structure\nis somewhat more difficult than constructing an arbitrary structure, and\nconstructing a globally-optimal structure is more difficult than constructing a\nlocally-optimal structure. The same situation arises with listing. The\ndifferences between the problems become obscured when we move from listing to\ncounting because nearly everything is #P-complete. However, we highlight an\ninteresting phenomenon that arises in approximate counting, where the situation\nis apparently reversed. Specifically, we show that counting maximal independent\nsets is complete for #P with respect to approximation-preserving reductions,\nwhereas counting all independent sets, or counting maximum independent sets is\ncomplete for an apparently smaller class, $\\mathrm{\\#RH}\\Pi_1$ which has a\nprominent role in the complexity of approximate counting. Motivated by the\ndifficulty of approximately counting maximal independent sets in bipartite\ngraphs, we also study the problem of approximately counting other\nlocally-optimal structures that arise in algorithmic applications, particularly\nproblems involving minimal separators and minimal edge separators. Minimal\nseparators have applications via fixed-parameter-tractable algorithms for\nconstructing triangulations and phylogenetic trees. Although exact\n(exponential-time) algorithms exist for listing these structures, we show that\nthe counting problems are #P-complete with respect to both exact and\napproximation-preserving reductions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 12:12:31 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2015 16:35:02 GMT"}, {"version": "v3", "created": "Mon, 18 Apr 2016 21:57:52 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Goldberg", "Leslie Ann", ""], ["Gysel", "Rob", ""], ["Lapinskas", "John", ""]]}, {"id": "1411.6993", "submitter": "Ameya Velingker", "authors": "Venkatesan Guruswami, Ameya Velingker", "title": "An Entropy Sumset Inequality and Polynomially Fast Convergence to\n  Shannon Capacity Over All Alphabets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a lower estimate on the increase in entropy when two copies of a\nconditional random variable $X | Y$, with $X$ supported on\n$\\mathbb{Z}_q=\\{0,1,\\dots,q-1\\}$ for prime $q$, are summed modulo $q$.\nSpecifically, given two i.i.d copies $(X_1,Y_1)$ and $(X_2,Y_2)$ of a pair of\nrandom variables $(X,Y)$, with $X$ taking values in $\\mathbb{Z}_q$, we show \\[\nH(X_1 + X_2 \\mid Y_1, Y_2) - H(X|Y) \\ge \\alpha(q) \\cdot H(X|Y) (1-H(X|Y)) \\]\nfor some $\\alpha(q) > 0$, where $H(\\cdot)$ is the normalized (by factor $\\log_2\nq$) entropy. Our motivation is an effective analysis of the finite-length\nbehavior of polar codes, and the assumption of $q$ being prime is necessary.\nFor $X$ supported on infinite groups without a finite subgroup and no\nconditioning, a sumset inequality for the absolute increase in (unnormalized)\nentropy was shown by Tao (2010).\n  We use our sumset inequality to analyze Ar{\\i}kan's construction of polar\ncodes and prove that for any $q$-ary source $X$, where $q$ is any fixed prime,\nand any $\\epsilon > 0$, polar codes allow {\\em efficient} data compression of\n$N$ i.i.d. copies of $X$ into $(H(X)+\\epsilon)N$ $q$-ary symbols, as soon as\n$N$ is polynomially large in $1/\\epsilon$. We can get capacity-achieving source\ncodes with similar guarantees for composite alphabets, by factoring $q$ into\nprimes and combining different polar codes for each prime in factorization.\n  A consequence of our result for noisy channel coding is that for {\\em all}\ndiscrete memoryless channels, there are explicit codes enabling reliable\ncommunication within $\\epsilon > 0$ of the symmetric Shannon capacity for a\nblock length and decoding complexity bounded by a polynomial in $1/\\epsilon$.\nThe result was previously shown for the special case of binary input channels\n(Guruswami-Xia '13 and Hassani-Alishahi-Urbanke '13), and this work extends the\nresult to channels over any alphabet.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 19:55:48 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Velingker", "Ameya", ""]]}, {"id": "1411.7280", "submitter": "Ronald de Wolf", "authors": "Jedrzej Kaniewski (CQT, Singapore, and QuTech, Delft), Troy Lee\n  (Nanyang Technological University and CQT, Singapore), Ronald de Wolf (CWI\n  and University of Amsterdam)", "title": "Query complexity in expectation", "comments": "16 pages LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of computing a function f:{0,1}^n-->R_+ in\nexpectation. This requires the algorithm on input x to output a nonnegative\nrandom variable whose expectation equals f(x), using as few queries to the\ninput x as possible. We exactly characterize both the randomized and the\nquantum query complexity by two polynomial degrees, the nonnegative literal\ndegree and the sum-of-squares degree, respectively. We observe that the quantum\ncomplexity can be unboundedly smaller than the classical complexity for some\nfunctions, but can be at most polynomially smaller for functions with range\n{0,1}.\n  These query complexities relate to (and are motivated by) the extension\ncomplexity of polytopes. The linear extension complexity of a polytope is\ncharacterized by the randomized communication complexity of computing its slack\nmatrix in expectation, and the semidefinite (psd) extension complexity is\ncharacterized by the analogous quantum model. Since query complexity can be\nused to upper bound communication complexity of related functions, we can\nderive some upper bounds on psd extension complexity by constructing efficient\nquantum query algorithms. As an example we give an exponentially-close\nentrywise approximation of the slack matrix of the perfect matching polytope\nwith psd-rank only 2^{n^{1/2+epsilon}}. Finally, we show there is a precise\nsense in which randomized/quantum query complexity in expectation corresponds\nto the Sherali-Adams and Lasserre hierarchies, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 16:12:07 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Kaniewski", "Jedrzej", "", "CQT, Singapore, and QuTech, Delft"], ["Lee", "Troy", "", "Nanyang Technological University and CQT, Singapore"], ["de Wolf", "Ronald", "", "CWI\n  and University of Amsterdam"]]}, {"id": "1411.7341", "submitter": "Arpita Korwar", "authors": "Rohit Gurjar and Arpita Korwar and Nitin Saxena and Thomas Thierauf", "title": "Deterministic Identity Testing for Sum of Read-Once Oblivious Arithmetic\n  Branching Programs", "comments": "22 pages, Computational Complexity Conference, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A read-once oblivious arithmetic branching program (ROABP) is an arithmetic\nbranching program (ABP) where each variable occurs in at most one layer. We\ngive the first polynomial time whitebox identity test for a polynomial computed\nby a sum of constantly many ROABPs. We also give a corresponding blackbox\nalgorithm with quasi-polynomial time complexity $n^{O(\\log n)}$. In both the\ncases, our time complexity is double exponential in the number of ROABPs.\n  ROABPs are a generalization of set-multilinear depth-$3$ circuits. The prior\nresults for the sum of constantly many set-multilinear depth-$3$ circuits were\nonly slightly better than brute-force, i.e. exponential-time.\n  Our techniques are a new interplay of three concepts for ROABP: low\nevaluation dimension, basis isolating weight assignment and low-support rank\nconcentration. We relate basis isolation to rank concentration and extend it to\na sum of two ROABPs using evaluation dimension (or partial derivatives).\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 19:24:14 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 11:36:33 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Gurjar", "Rohit", ""], ["Korwar", "Arpita", ""], ["Saxena", "Nitin", ""], ["Thierauf", "Thomas", ""]]}, {"id": "1411.7346", "submitter": "Gautam Kamath", "authors": "Jayadev Acharya, Cl\\'ement L. Canonne, Gautam Kamath", "title": "A Chasm Between Identity and Equivalence Testing with Conditional\n  Queries", "comments": "39 pages. To appear in Theory of Computing. Preliminary version\n  appeared in RANDOM 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent model for property testing of probability distributions (Chakraborty\net al., ITCS 2013, Canonne et al., SICOMP 2015) enables tremendous savings in\nthe sample complexity of testing algorithms, by allowing them to condition the\nsampling on subsets of the domain. In particular, Canonne, Ron, and Servedio\n(SICOMP 2015) showed that, in this setting, testing identity of an unknown\ndistribution $D$ (whether $D=D^\\ast$ for an explicitly known $D^\\ast$) can be\ndone with a constant number of queries, independent of the support size $n$ --\nin contrast to the required $\\Omega(\\sqrt{n})$ in the standard sampling model.\nIt was unclear whether the same stark contrast exists for the case of testing\nequivalence, where both distributions are unknown. While Canonne et al.\nestablished a $\\mathrm{poly}(\\log n)$-query upper bound for equivalence\ntesting, very recently brought down to $\\tilde O(\\log\\log n)$ by Falahatgar et\nal. (COLT 2015), whether a dependence on the domain size $n$ is necessary was\nstill open, and explicitly posed by Fischer at the Bertinoro Workshop on\nSublinear Algorithms (2014). We show that any testing algorithm for equivalence\nmust make $\\Omega(\\sqrt{\\log\\log n})$ queries in the conditional sampling\nmodel. This demonstrates a gap between identity and equivalence testing, absent\nin the standard sampling model (where both problems have sampling complexity\n$n^{\\Theta(1)}$).\n  We also obtain results on the query complexity of uniformity testing and\nsupport-size estimation with conditional samples. We answer a question of\nChakraborty et al. (ITCS 2013) showing that non-adaptive uniformity testing\nindeed requires $\\Omega(\\log n)$ queries in the conditional model. For the\nrelated problem of support-size estimation, we provide both adaptive and\nnon-adaptive algorithms, with query complexities $\\mathrm{poly}(\\log\\log n)$\nand $\\mathrm{poly}(\\log n)$, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 19:44:12 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2015 23:37:46 GMT"}, {"version": "v3", "created": "Fri, 7 Dec 2018 01:30:55 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Acharya", "Jayadev", ""], ["Canonne", "Cl\u00e9ment L.", ""], ["Kamath", "Gautam", ""]]}, {"id": "1411.7455", "submitter": "Michael A. Forbes", "authors": "Michael A. Forbes and Venkatesan Guruswami", "title": "Dimension Expanders via Rank Condensers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging theory of \"linear-algebraic pseudorandomness\" aims to understand\nthe linear-algebraic analogs of fundamental Boolean pseudorandom objects where\nthe rank of subspaces plays the role of the size of subsets. In this work, we\nstudy and highlight the interrelationships between several such algebraic\nobjects such as subspace designs, dimension expanders, seeded rank condensers,\ntwo-source rank condensers, and rank-metric codes. In particular, with the\nrecent construction of near-optimal subspace designs by Guruswami and Kopparty\nas a starting point, we construct good (seeded) rank condensers (both lossless\nand lossy versions), which are a small collection of linear maps $\\mathbb{F}^n\n\\to \\mathbb{F}^t$ for $t \\ll n$ such that for every subset of $\\mathbb{F}^n$ of\nsmall rank, its rank is preserved (up to a constant factor in the lossy case)\nby at least one of the maps.\n  We then compose a tensoring operation with our lossy rank condenser to\nconstruct constant-degree dimension expanders over polynomially large fields.\nThat is, we give $O(1)$ explicit linear maps $A_i:\\mathbb{F}^n\\to \\mathbb{F}^n$\nsuch that for any subspace $V \\subseteq \\mathbb{F}^n$ of dimension at most\n$n/2$, $\\dim\\bigl( \\sum_i A_i(V)\\bigr) \\ge (1+\\Omega(1)) \\dim(V)$. Previous\nconstructions of such constant-degree dimension expanders were based on\nKazhdan's property $T$ (for the case when $\\mathbb{F}$ has characteristic zero)\nor monotone expanders (for every field $\\mathbb{F}$); in either case the\nconstruction was harder than that of usual vertex expanders. Our construction,\non the other hand, is simpler.\n  Via an equivalence to linear rank-metric codes, we then construct optimal\nlossless two-source condensers. We then use our seeded rank condensers to\nobtain near-optimal lossy two-source condensers for constant rank sources.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 03:11:11 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Forbes", "Michael A.", ""], ["Guruswami", "Venkatesan", ""]]}, {"id": "1411.7472", "submitter": "Yichong Xu", "authors": "Pingzhong Tang, Yifeng Teng, Zihe Wang, Shenke Xiao, Yichong Xu", "title": "Computational issues in time-inconsistent planning", "comments": "20 pages, 7 figures, submitted to EC'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-inconsistency refers to a paradox in decision making where agents\nexhibit inconsistent behaviors over time. Examples are procrastination where\nagents tends to costly postpone easy tasks, and abandonments where agents start\na plan and quit in the middle. These behaviors are undesirable in the sense\nthat agents make clearly suboptimal decisions over optimal ones. To capture\nsuch behaviors and more importantly, to quantify inefficiency caused by such\nbehaviors, [Kleinberg & Oren 2014] propose a graph model which is essentially\nsame as the standard planning model except for the cost structure. Using this\nmodel, they initiate the study of several interesting problems: 1) cost ratio:\nthe worst ratio between the actual cost of the agent and the optimal cost, over\nall graph instances; 2) motivating subgraph: how to motivate the agent to reach\nthe goal by deleting nodes and edges; 3) Intermediate rewards: how to motivate\nagents to reach the goal by placing intermediate rewards. Kleinberg and Oren\ngive partial answers to these questions, but the main problems are still open.\nIn fact, they raise these problems explicitly as open problems in their paper.\nIn this paper, we give answers to all three open problems in [Kleinberg & Oren\n2014]. First, we show a tight upper bound of cost ratio for graphs without\nAkerlof's structure, thus confirm the conjecture by Kleinberg and Oren that\nAkerlof's structure is indeed the worst case for cost ratio. Second, we prove\nthat finding a motivating subgraph is NP-hard, showing that it is generally\ninefficient to motivate agents by deleting nodes and edges in the graph. Last\nbut not least, we show that computing a strategy to place minimum amount of\ntotal reward is also NP-hard. Therefore, it is computational inefficient to\nmotivate agents by placing intermediate rewards. The techniques we use to prove\nthese results are nontrivial and of independent interests.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 05:15:08 GMT"}, {"version": "v2", "created": "Wed, 11 Feb 2015 07:41:27 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2015 14:37:34 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Tang", "Pingzhong", ""], ["Teng", "Yifeng", ""], ["Wang", "Zihe", ""], ["Xiao", "Shenke", ""], ["Xu", "Yichong", ""]]}, {"id": "1411.7492", "submitter": "Ben lee Volk", "authors": "Rafael Oliveira, Amir Shpilka, Ben Lee Volk", "title": "Subexponential Size Hitting Sets for Bounded Depth Multilinear Formulas", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give subexponential size hitting sets for bounded depth\nmultilinear arithmetic formulas. Using the known relation between black-box PIT\nand lower bounds we obtain lower bounds for these models.\n  For depth-3 multilinear formulas, of size $\\exp(n^\\delta)$, we give a hitting\nset of size $\\exp(\\tilde{O}(n^{2/3 + 2\\delta/3}))$. This implies a lower bound\nof $\\exp(\\tilde{\\Omega}(n^{1/2}))$ for depth-3 multilinear formulas, for some\nexplicit polynomial.\n  For depth-4 multilinear formulas, of size $\\exp(n^\\delta)$, we give a hitting\nset of size $\\exp(\\tilde{O}(n^{2/3 + 4\\delta/3}))$. This implies a lower bound\nof $\\exp(\\tilde{\\Omega}(n^{1/4}))$ for depth-4 multilinear formulas, for some\nexplicit polynomial.\n  A regular formula consists of alternating layers of $+,\\times$ gates, where\nall gates at layer $i$ have the same fan-in. We give a hitting set of size\n(roughly) $\\exp\\left(n^{1- \\delta} \\right)$, for regular depth-$d$ multilinear\nformulas of size $\\exp(n^\\delta)$, where $\\delta = O(\\frac{1}{\\sqrt{5}^d})$.\nThis result implies a lower bound of roughly\n$\\exp(\\tilde{\\Omega}(n^{\\frac{1}{\\sqrt{5}^d}}))$ for such formulas.\n  We note that better lower bounds are known for these models, but also that\nnone of these bounds was achieved via construction of a hitting set. Moreover,\nno lower bound that implies such PIT results, even in the white-box model, is\ncurrently known.\n  Our results are combinatorial in nature and rely on reducing the underlying\nformula, first to a depth-4 formula, and then to a read-once algebraic\nbranching program (from depth-3 formulas we go straight to read-once algebraic\nbranching programs).\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 07:56:43 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Oliveira", "Rafael", ""], ["Shpilka", "Amir", ""], ["Volk", "Ben Lee", ""]]}, {"id": "1411.7614", "submitter": "Rohit Gurjar", "authors": "Rahul Arora and Ashu Gupta and Rohit Gurjar and Raghunath Tewari", "title": "Derandomizing Isolation Lemma for $K_{3,3}$-free and $K_5$-free\n  Bipartite Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The perfect matching problem has a randomized NC algorithm, using the\ncelebrated Isolation Lemma of Mulmuley, Vazirani and Vazirani. The Isolation\nLemma states that giving a random weight assignment to the edges of a graph,\nensures that it has a unique minimum weight perfect matching, with a good\nprobability. We derandomize this lemma for $K_{3,3}$-free and $K_5$-free\nbipartite graphs, i.e. we give a deterministic log-space construction of such a\nweight assignment for these graphs. Such a construction was known previously\nfor planar bipartite graphs. Our result implies that the perfect matching\nproblem for $K_{3,3}$-free and $K_5$-free bipartite graphs is in SPL.\n  It also gives an alternate proof for an already known result -- reachability\nfor $K_{3,3}$-free and $K_5$-free graphs is in UL.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 14:51:00 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Arora", "Rahul", ""], ["Gupta", "Ashu", ""], ["Gurjar", "Rohit", ""], ["Tewari", "Raghunath", ""]]}, {"id": "1411.7647", "submitter": "Abuzer Yakaryilmaz", "authors": "A. C. Cem Say and Abuzer Yakaryilmaz", "title": "Magic coins are useful for small-space quantum machines", "comments": "16 pages!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although polynomial-time probabilistic Turing machines can utilize\nuncomputable transition probabilities to recognize uncountably many languages\nwith bounded error when allowed to use logarithmic space, it is known that such\n\"magic coins\" give no additional computational power to constant-space versions\nof those machines. We show that adding a few quantum bits to the model changes\nthe picture dramatically. For every language $L$, there exists such a two-way\nquantum finite automaton that recognizes a language of the same Turing degree\nas $L$ with bounded error in polynomial time. When used as verifiers in\npublic-coin interactive proof systems, such automata can verify membership in\nall languages with bounded error, outperforming their classical counterparts,\nwhich are known to fail for the palindromes language.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 17:12:55 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Say", "A. C. Cem", ""], ["Yakaryilmaz", "Abuzer", ""]]}, {"id": "1411.7747", "submitter": "Amey Bhangale", "authors": "Amey Bhangale and Prahladh Harsha and Girish Varma", "title": "A Characterization of hard-to-cover CSPs", "comments": "Fixed minor typos (including statement of Theorem 1.2)", "journal-ref": "Theory of Computing, 16(16):1-29, 2020 (Journal) and In Proc. 30th\n  Computational Complexity Conference (CCC) (Portland, Oregon, 17-19 June),\n  volume 33 of LiPiCS pages 280-303, 2015 (Conference)", "doi": "10.4086/toc.2020.v016a016, 10.4230/LIPIcs.CCC.2015.280", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue the study of the covering complexity of constraint satisfaction\nproblems (CSPs) initiated by Guruswami, H{\\aa}stad and Sudan [SIAM J. Comp.\n2002] and Dinur and Kol [CCC'13]. The covering number of a CSP instance $\\Phi$\nis the smallest number of assignments to the variables of $\\Phi$, such that\neach constraint of $\\Phi$ is satisfied by at least one of the assignments. We\nshow the following results:\n  1. Assuming a covering variant of the Unique Games Conjecture, introduced by\nDinur and Kol, we show that for every non-odd predicate $P$ over any\nconstant-size alphabet and every integer $K$, it is NP-hard to approximate the\ncovering number within a factor of $K$. This yields a complete characterization\nof CSPs over constant-size alphabets that are hard to cover.\n  2. For a large class of predicates that are contained in the 2k-LIN\npredicate, we show that it is quasi-NP-hard to distinguish between instances\nwith covering number at most $2$ and those with covering number at least\n$\\Omega(\\log\\log n)$. This generalizes and improves the 4-LIN covering hardness\nresult of Dinur and Kol.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2014 04:21:41 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2015 15:01:55 GMT"}, {"version": "v3", "created": "Sat, 14 Sep 2019 01:30:42 GMT"}, {"version": "v4", "created": "Sun, 3 Jan 2021 06:51:59 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bhangale", "Amey", ""], ["Harsha", "Prahladh", ""], ["Varma", "Girish", ""]]}]