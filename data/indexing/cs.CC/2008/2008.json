[{"id": "2008.00044", "submitter": "Aleksandar Nikolov", "authors": "Lily Li, Aleksandar Nikolov", "title": "On the Computational Complexity of Linear Discrepancy", "comments": "ESA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in computer science and applied mathematics require rounding a\nvector $\\mathbf{w}$ of fractional values lying in the interval $[0,1]$ to a\nbinary vector $\\mathbf{x}$ so that, for a given matrix $\\mathbf{A}$,\n$\\mathbf{A}\\mathbf{x}$ is as close to $\\mathbf{A}\\mathbf{w}$ as possible. For\nexample, this problem arises in LP rounding algorithms used to approximate\n$\\mathsf{NP}$-hard optimization problems and in the design of uniformly\ndistributed point sets for numerical integration. For a given matrix\n$\\mathbf{A}$, the worst-case error over all choices of $\\mathbf{w}$ incurred by\nthe best possible rounding is measured by the linear discrepancy of\n$\\mathbf{A}$, a quantity studied in discrepancy theory, and introduced by\nLovasz, Spencer, and Vesztergombi (EJC, 1986).\n  We initiate the study of the computational complexity of linear discrepancy.\nOur investigation proceeds in two directions: (1) proving hardness results and\n(2) finding both exact and approximate algorithms to evaluate the linear\ndiscrepancy of certain matrices. For (1), we show that linear discrepancy is\n$\\mathsf{NP}$-hard. Thus we do not expect to find an efficient exact algorithm\nfor the general case. Restricting our attention to matrices with a constant\nnumber of rows, we present a poly-time exact algorithm for matrices consisting\nof a single row and matrices with a constant number of rows and entries of\nbounded magnitude. We also present an exponential-time approximation algorithm\nfor general matrices, and an algorithm that approximates linear discrepancy to\nwithin an exponential factor.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:16:26 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Li", "Lily", ""], ["Nikolov", "Aleksandar", ""]]}, {"id": "2008.00266", "submitter": "Nikhil Mande", "authors": "Nikhil S. Mande, Swagato Sanyal", "title": "On parity decision trees for Fourier-sparse Boolean functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study parity decision trees for Boolean functions. The motivation of our\nstudy is the log-rank conjecture for XOR functions and its connection to\nFourier analysis and parity decision tree complexity. Let f be a Boolean\nfunction with Fourier support S and Fourier sparsity k.\n  1) We prove via the probabilistic method that there exists a parity decision\ntree of depth O(sqrt k) that computes f. This matches the best known upper\nbound on the parity decision tree complexity of Boolean functions (Tsang, Wong,\nXie, and Zhang, FOCS 2013). Moreover, while previous constructions (Tsang et\nal., FOCS 2013, Shpilka, Tal, and Volk, Comput. Complex. 2017) build the trees\nby carefully choosing the parities to be queried in each step, our proof shows\nthat a naive sampling of the parities suffices.\n  2) We generalize the above result by showing that if the Fourier spectra of\nBoolean functions satisfy a natural \"folding property\", then the above proof\ncan be adapted to establish existence of a tree of complexity polynomially\nsmaller than O(sqrt k). We make a conjecture in this regard which, if true,\nimplies that the communication complexity of an XOR function is bounded above\nby the fourth root of the rank of its communication matrix, improving upon the\npreviously known upper bound of square root of rank (Tsang et al., FOCS 2013,\nLovett, J. ACM. 2016).\n  3) It can be shown by elementary techniques that for any Boolean function f\nand all pairs (alpha, beta) of parities in S, there exists another pair (gamma,\ndelta) of parities in S such that alpha + beta = gamma + delta. We show, among\nother results, that there must exist several gamma in F_2^n such that there are\nat least three pairs (alpha_1, alpha_2) of parities in S with alpha_1 + alpha_2\n= gamma.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 13:59:48 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Mande", "Nikhil S.", ""], ["Sanyal", "Swagato", ""]]}, {"id": "2008.00466", "submitter": "Natalia Berloff", "authors": "Kirill P. Kalinin and Natalia G. Berloff", "title": "Complexity continuum within Ising formulation of NP problems", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.CC cs.ET physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising approach to achieve computational supremacy over the classical\nvon Neumann architecture explores classical and quantum hardware as Ising\nmachines. The minimisation of the Ising Hamiltonian is known to be NP-hard\nproblem for certain interaction matrix classes, yet not all problem instances\nare equivalently hard to optimise. We propose to identify computationally\nsimple instances with an `optimisation simplicity criterion'. Such optimisation\nsimplicity can be found for a wide range of models from spin glasses to\nk-regular maximum cut problems. Many optical, photonic, and electronic systems\nare neuromorphic architectures that can naturally operate to optimise problems\nsatisfying this criterion and, therefore, such problems are often chosen to\nillustrate the computational advantages of new Ising machines. We further probe\nan intermediate complexity for sparse and dense models by analysing circulant\ncoupling matrices, that can be `rewired' to introduce greater complexity. A\ncompelling approach for distinguishing easy and hard instances within the same\nNP-hard class of problems can be a starting point in developing a standardised\nprocedure for the performance evaluation of emerging physical simulators and\nphysics-inspired algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 11:36:38 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kalinin", "Kirill P.", ""], ["Berloff", "Natalia G.", ""]]}, {"id": "2008.00581", "submitter": "Mingyue Ji", "authors": "Nicholas Woolsey, Rong-Rong Chen, Mingyue Ji", "title": "A Combinatorial Design for Cascaded Coded Distributed Computing on\n  General Networks", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coding theoretic approached have been developed to significantly reduce the\ncommunication load in modern distributed computing system. In particular, coded\ndistributed computing (CDC) introduced by Li et al. can efficiently trade\ncomputation resources to reduce the communication load in MapReduce like\ncomputing systems. For the more general cascaded CDC, Map computations are\nrepeated at r nodes to significantly reduce the communication load among nodes\ntasked with computing Q Reduce functions s times. In this paper, we propose a\nnovel low-complexity combinatorial design for cascaded CDC which 1) determines\nboth input file and output function assignments, 2) requires significantly less\nnumber of input files and output functions, and 3) operates on heterogeneous\nnetworks where nodes have varying storage and computing capabilities. We\nprovide an analytical characterization of the computation-communication\ntradeoff, from which we show the proposed scheme can outperform the\nstate-of-the-art scheme proposed by Li et al. for the homogeneous networks.\nFurther, when the network is heterogeneous, we show that the performance of the\nproposed scheme can be better than its homogeneous counterpart. In addition,\nthe proposed scheme is optimal within a constant factor of the information\ntheoretic converse bound while fixing the input file and the output function\nassignments.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 23:00:11 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Woolsey", "Nicholas", ""], ["Chen", "Rong-Rong", ""], ["Ji", "Mingyue", ""]]}, {"id": "2008.00601", "submitter": "Andras Farago", "authors": "Andr\\'as Farag\\'o", "title": "The Amazing Power of Randomness: NP=RP", "comments": "Paper is withdrawn because a counterexample was found to Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We (claim to) prove the extremely surprising fact that NP=RP. It is achieved\nby creating a Fully Polynomial-Time Randomized Approximation Scheme (FPRAS) for\napproximately counting the number of independent sets in bounded degree graphs,\nwith any fixed degree bound, which is known to imply NP=RP. While our method is\nrooted in the well known Markov Chain Monte Carlo (MCMC) approach, we overcome\nthe notorious problem of slow mixing by a new idea for generating a random\nsample from among the independent sets. A key tool that enables the result is a\nsolution to a novel sampling task that we call Subset Sampling. In its basic\nform, a stationary sample is given from the (exponentially large) state space\nof a Markov chain, as input, and we want to transform it into another\nstationary sample that is conditioned on falling into a given subset, which is\nstill exponentially large. In general, Subset Sampling can be both harder and\neasier than stationary sampling from a Markov chain. It can be harder, due to\nthe conditioning on a subset, which may have more complex structure than the\noriginal state space. But it may also be easier, since a stationary sample is\nalready given, which, in a sense, already encompasses \"most of the hardness\" of\nsuch sampling tasks, being already in the stationary distribution, which is\nhard to reach in a slowly mixing chain. We show that it is possible to\nefficiently balance the two sides: we can capitalize on already having a\nstationary sample from the original space, so that the complexity of confining\nit to a subset is mitigated. We prove that an efficient approximation is\npossible for the considered sampling task, and then it is applied recursively\nto create the FPRAS.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 00:58:08 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 12:37:52 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Farag\u00f3", "Andr\u00e1s", ""]]}, {"id": "2008.00896", "submitter": "Batya Kenig", "authors": "Batya Kenig and Dan Suciu", "title": "A Dichotomy for the Generalized Model Counting Problem for Unions of\n  Conjunctive Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the $generalized~model~counting~problem$, defined as follows: given\na database, and a set of deterministic tuples, count the number of subsets of\nthe database that include all deterministic tuples and satisfy the query. This\nproblem is computationally equivalent to the evaluation of the query over a\ntuple-independent probabilistic database where all tuples have probabilities in\n$\\{0,\\frac{1}{2},1\\}$. Previous work has established a dichotomy for Unions of\nConjunctive Queries (UCQ) when the probabilities are arbitrary rational\nnumbers, showing that, for each query, its complexity is either in polynomial\ntime or #P-hard. The query is called $safe$ in the first case, and $unsafe$ in\nthe second case. Here, we strengthen the hardness proof, by proving that an\nunsafe UCQ query remains #P-hard even if the probabilities are restricted to\n$\\{0,\\frac{1}{2},1\\}$. This requires a complete redesign of the hardness proof,\nusing new techniques. A related problem is the $model~counting~problem$, which\nasks for the probability of the query when the input probabilities are\nrestricted to $\\{0,\\frac{1}{2}\\}$. While our result does not extend to model\ncounting for all unsafe UCQs, we prove that model counting is #P-hard for a\nclass of unsafe queries called Type-I forbidden queries.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 14:24:08 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 16:11:20 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 07:40:31 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Kenig", "Batya", ""], ["Suciu", "Dan", ""]]}, {"id": "2008.01316", "submitter": "Abhishek Shetty", "authors": "Eshan Chattopadhyay, Jason Gaitonde, Chin Ho Lee, Shachar Lovett,\n  Abhishek Shetty", "title": "Fractional Pseudorandom Generators from Any Fourier Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove new results on the polarizing random walk framework introduced in\nrecent works of Chattopadhyay {et al.} [CHHL19,CHLT19] that exploit $L_1$\nFourier tail bounds for classes of Boolean functions to construct pseudorandom\ngenerators (PRGs). We show that given a bound on the $k$-th level of the\nFourier spectrum, one can construct a PRG with a seed length whose quality\nscales with $k$. This interpolates previous works, which either require Fourier\nbounds on all levels [CHHL19], or have polynomial dependence on the error\nparameter in the seed length [CHLT10], and thus answers an open question in\n[CHLT19]. As an example, we show that for polynomial error, Fourier bounds on\nthe first $O(\\log n)$ levels is sufficient to recover the seed length in\n[CHHL19], which requires bounds on the entire tail.\n  We obtain our results by an alternate analysis of fractional PRGs using\nTaylor's theorem and bounding the degree-$k$ Lagrange remainder term using\nmultilinearity and random restrictions. Interestingly, our analysis relies only\non the \\emph{level-k unsigned Fourier sum}, which is potentially a much smaller\nquantity than the $L_1$ notion in previous works. By generalizing a connection\nestablished in [CHH+20], we give a new reduction from constructing PRGs to\nproving correlation bounds. Finally, using these improvements we show how to\nobtain a PRG for $\\mathbb{F}_2$ polynomials with seed length close to the\nstate-of-the-art construction due to Viola [Vio09], which was not known to be\npossible using this framework.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 04:00:21 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 00:09:18 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 15:58:27 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chattopadhyay", "Eshan", ""], ["Gaitonde", "Jason", ""], ["Lee", "Chin Ho", ""], ["Lovett", "Shachar", ""], ["Shetty", "Abhishek", ""]]}, {"id": "2008.01590", "submitter": "Daniel Paulusma", "authors": "Nick Brettell, Jake Horsfield, Andrea Munaro, Daniel Paulusma", "title": "List $k$-Colouring $P_t$-Free Graphs: a Mim-width Perspective", "comments": "arXiv admin note: text overlap with arXiv:2004.05022 merge of\n  arXiv:2004.05022 and previous version of arxiv:2008.01590", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A colouring of a graph $G=(V,E)$ is a mapping $c\\colon V\\to \\{1,2,\\ldots\\}$\nsuch that $c(u)\\neq c(v)$ for every two adjacent vertices $u$ and $v$ of $G$.\nThe {\\sc List $k$-Colouring} problem is to decide whether a graph $G=(V,E)$\nwith a list $L(u)\\subseteq \\{1,\\ldots,k\\}$ for each $u\\in V$ has a colouring\n$c$ such that $c(u)\\in L(u)$ for every $u\\in V$. Let $P_t$ be the path on $t$\nvertices and let $K_{1,s}^1$ be the graph obtained from the $(s+1)$-vertex star\n$K_{1,s}$ by subdividing each of its edges exactly once.Recently, Chudnovsky,\nSpirkl and Zhong (DM 2020) proved that List $3$-Colouring is polynomial-time\nsolvable for $(K_{1,s}^1,P_t)$-free graphs for every $t\\geq 1$ and $s\\geq 1$.\nWe generalize their result to List $k$-Colouring for every $k\\geq 1$. Our\nresult also generalizes the known result that for every $k\\geq 1$ and $s\\geq\n0$, List $k$-Colouring is polynomial-time solvable for $(sP_1+P_5)$-free\ngraphs, which was proven for $s=0$ by Ho\\`ang, Kami\\'nski, Lozin, Sawada, and\nShu (Algorithmica 2010) and for every $s\\geq 1$ by Couturier, Golovach, Kratsch\nand Paulusma (Algorithmica 2015). We show our result by proving boundedness of\nan underlying width parameter. Namely, we show that for every $k\\geq 1$, $s\\geq\n1$, $t\\geq 1$, the class of $(K_k,K_{1,s}^1,P_t)$-free graphs has bounded\nmim-width and that a corresponding branch decomposition is \"quickly computable\"\nfor these graphs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 14:58:57 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 21:02:56 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Brettell", "Nick", ""], ["Horsfield", "Jake", ""], ["Munaro", "Andrea", ""], ["Paulusma", "Daniel", ""]]}, {"id": "2008.01820", "submitter": "Rebekah Herrman", "authors": "James Ostrowski, Rebekah Herrman, Travis S. Humble and George Siopsis", "title": "Lower Bounds on Circuit Depth of the Quantum Approximate Optimization\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantum approximate optimization algorithm (QAOA) is a method of\napproximately solving combinatorial optimization problems. While QAOA is\ndeveloped to solve a broad class of combinatorial optimization problems, it is\nnot clear which classes of problems are best suited for it. One factor in\ndemonstrating quantum advantage is the relationship between a problem instance\nand the circuit depth required to implement the QAOA method. As errors in NISQ\ndevices increases exponentially with circuit depth, identifying lower bounds on\ncircuit depth can provide insights into when quantum advantage could be\nfeasible. Here, we identify how the structure of problem instances can be used\nto identify lower bounds for circuit depth for each iteration of QAOA and\nexamine the relationship between problem structure and the circuit depth for a\nvariety of combinatorial optimization problems including MaxCut and MaxIndSet.\nSpecifically, we show how to derive a graph, $G$, that describes a general\ncombinatorial optimization problem and show that the depth of circuit is at\nleast the chromatic index of $G$. By looking at the scaling of circuit depth,\nwe argue that MaxCut, MaxIndSet, and some instances of Vertex Covering and\nBoolean satisifiability problems are suitable for QAOA approaches while\nKnapsack and Traveling Sales Person problems are not.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:52:34 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 15:47:02 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ostrowski", "James", ""], ["Herrman", "Rebekah", ""], ["Humble", "Travis S.", ""], ["Siopsis", "George", ""]]}, {"id": "2008.02138", "submitter": "Barnaby Martin", "authors": "Stefan Dantchev, Nicola Galesi, Abdul Ghani, Barnaby Martin", "title": "Proof complexity and the binary encoding of combinatorial principles", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.02843,\n  arXiv:1911.00403", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Proof Complexity in light of the unusual binary encoding of\ncertain combinatorial principles. We contrast this Proof Complexity with the\nnormal unary encoding in several refutation systems, based on Resolution and\nInteger Linear Programming. Please consult the article for the full abstract.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:24:19 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Dantchev", "Stefan", ""], ["Galesi", "Nicola", ""], ["Ghani", "Abdul", ""], ["Martin", "Barnaby", ""]]}, {"id": "2008.02146", "submitter": "Santosh Vempala", "authors": "He Jia, Aditi Laddha, Yin Tat Lee, Santosh S. Vempala", "title": "Reducing Isotropy and Volume to KLS: An $O(n^3\\psi^2)$ Volume Algorithm", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the the volume of a convex body in ${\\mathbb R}^{n}$ in the\ngeneral membership oracle model can be computed with\n$\\widetilde{O}(n^{3}\\psi^{2}/\\varepsilon^{2})$ oracle queries, where $\\psi$ is\nthe KLS constant ($\\widetilde{O}$ suppresses polylogarithmic terms.\n$O^{*}$suppresses dependence on error parameters as well as polylogarithmic\nterms.). With the current bound of $\\psi\\lesssim n^{\\frac{1}{4}}$, this gives\nan $\\widetilde{O}(n^{3.5}/\\varepsilon^{2})$ algorithm, the first general\nimprovement on the Lov\\'{a}sz-Vempala $\\widetilde{O}(n^{4}/\\varepsilon^{2})$\nalgorithm from 2003. The main new ingredient is\\emph{ }an\n$\\widetilde{O}(n^{3}\\psi^{2})$ algorithm for isotropic transformation,\nfollowing which we can apply the $\\widetilde{O}(n^{3}/\\varepsilon^{2})$ volume\nalgorithm of Cousins and Vempala for well-rounded convex bodies. A positive\nresolution of the KLS conjecture would imply an\n$\\widetilde{O}(n^{3}/\\epsilon^{2})$ volume algorithm. We also give an efficient\nimplementation of the new algorithm for convex polytopes defined by $m$\ninequalities in ${\\mathbb R}^{n}$: polytope volume can be estimated in time\n$\\widetilde{O}(mn^{c}/\\varepsilon^{2})$ where $c<3.7$ depends on the current\nmatrix multiplication exponent and improves on the the previous best bound.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:08:16 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Jia", "He", ""], ["Laddha", "Aditi", ""], ["Lee", "Yin Tat", ""], ["Vempala", "Santosh S.", ""]]}, {"id": "2008.02269", "submitter": "Alexander Wein", "authors": "Tselil Schramm and Alexander S. Wein", "title": "Computational Barriers to Estimation from Low-Degree Polynomials", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.DS stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One fundamental goal of high-dimensional statistics is to detect or recover\nstructure from noisy data. In many cases, the data can be faithfully modeled by\na planted structure (such as a low-rank matrix) perturbed by random noise. But\neven for these simple models, the computational complexity of estimation is\nsometimes poorly understood. A growing body of work studies low-degree\npolynomials as a proxy for computational complexity: it has been demonstrated\nin various settings that low-degree polynomials of the data can match the\nstatistical performance of the best known polynomial-time algorithms for\ndetection. While prior work has studied the power of low-degree polynomials for\nthe task of detecting the presence of hidden structures, it has failed to\naddress the estimation problem in settings where detection is qualitatively\neasier than estimation.\n  In this work, we extend the method of low-degree polynomials to address\nproblems of estimation and recovery. For a large class of \"signal plus noise\"\nproblems, we give a user-friendly lower bound for the best possible mean\nsquared error achievable by any degree-D polynomial. To our knowledge, this is\nthe first instance in which the low-degree polynomial method can establish\nlow-degree hardness of recovery problems where the associated detection problem\nis easy. As applications, we give a tight characterization of the low-degree\nminimum mean squared error for the planted submatrix and planted dense subgraph\nproblems, resolving (in the low-degree framework) open problems about the\ncomputational complexity of recovery in both cases.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:52:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Schramm", "Tselil", ""], ["Wein", "Alexander S.", ""]]}, {"id": "2008.02753", "submitter": "Jugal Garg", "authors": "Bhaskar Ray Chaudhury and Jugal Garg and Peter McGlaughlin and Ruta\n  Mehta", "title": "Competitive Allocation of a Mixed Manna", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DM cs.DS cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the fair division problem of allocating a mixed manna under\nadditively separable piecewise linear concave (SPLC) utilities. A mixed manna\ncontains goods that everyone likes and bads that everyone dislikes, as well as\nitems that some like and others dislike. The seminal work of Bogomolnaia et al.\n[Econometrica'17] argue why allocating a mixed manna is genuinely more\ncomplicated than a good or a bad manna, and why competitive equilibrium is the\nbest mechanism. They also provide the existence of equilibrium and establish\nits peculiar properties (e.g., non-convex and disconnected set of equilibria\neven under linear utilities), but leave the problem of computing an equilibrium\nopen. This problem remained unresolved even for only bad manna under linear\nutilities.\n  Our main result is a simplex-like algorithm based on Lemke's scheme for\ncomputing a competitive allocation of a mixed manna under SPLC utilities, a\nstrict generalization of linear. Experimental results on randomly generated\ninstances suggest that our algorithm will be fast in practice. The problem is\nknown to be PPAD-hard for the case of good manna, and we also show a similar\nresult for the case of bad manna. Given these PPAD-hardness results, designing\nsuch an algorithm is the only non-brute-force (non-enumerative) option known,\ne.g., the classic Lemke-Howson algorithm (1964) for computing a Nash\nequilibrium in a 2-player game is still one of the most widely used algorithms\nin practice.\n  Our algorithm also yields several new structural properties as simple\ncorollaries. We obtain a (constructive) proof of existence for a far more\ngeneral setting, membership of the problem in PPAD, rational-valued solution,\nand odd number of solutions property. The last property also settles the\nconjecture of Bogomolnaia et al. in the affirmative.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:38:00 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Chaudhury", "Bhaskar Ray", ""], ["Garg", "Jugal", ""], ["McGlaughlin", "Peter", ""], ["Mehta", "Ruta", ""]]}, {"id": "2008.02769", "submitter": "Philipp Schepper", "authors": "Philipp Schepper", "title": "Fine-Grained Complexity of Regular Expression Pattern Matching and\n  Membership", "comments": "Full version of the paper accepted at ESA 2020; v2: typos and\n  reference to conference version corrected", "journal-ref": null, "doi": "10.4230/LIPIcs.ESA.2020.80", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The currently fastest algorithm for regular expression pattern matching and\nmembership improves the classical O(nm) time algorithm by a factor of about\nlog^{3/2}n. Instead of focussing on general patterns we analyse homogeneous\npatterns of bounded depth in this work. For them a classification splitting the\ntypes in easy (strongly sub-quadratic) and hard (essentially quadratic time\nunder SETH) is known. We take a very fine-grained look at the hard pattern\ntypes from this classification and show a dichotomy: few types allow\nsuper-poly-logarithmic improvements while the algorithms for the other pattern\ntypes can only be improved by a constant number of log-factors, assuming the\nFormula-SAT Hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:13:58 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 15:02:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Schepper", "Philipp", ""]]}, {"id": "2008.02924", "submitter": "Hengzhao Ma", "authors": "Hengzhao Ma, Jianzhong Li", "title": "A Sub-linear Time Algorithm for Approximating k-Nearest-Neighbor with\n  Full Quality Guarantee", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an algorithm for the approximate k-Nearest-Neighbors\nproblem. According to the existing researches, there are two kinds of\napproximation criterion. One is the distance criteria, and the other is the\nrecall criteria. All former algorithms suffer the problem that there are no\ntheoretical guarantees for the two approximation criterion. The algorithm\nproposed in this paper unifies the two kinds of approximation criterion, and\nhas full theoretical guarantees. Furthermore, the query time of the algorithm\nis sub-linear. As far as we know, it is the first algorithm that achieves both\nsub-linear query time and full theoretical approximation guarantee.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:15:50 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ma", "Hengzhao", ""], ["Li", "Jianzhong", ""]]}, {"id": "2008.02932", "submitter": "EPTCS", "authors": "Neil D. Jones (University of Copenhagen), Siddharth Bhaskar\n  (University of Copenhagen), Cynthia Kop (Radboud University, Nijmegen), Jakob\n  Grue Simonsen (University of Copenhagen)", "title": "Cons-free Programs and Complexity Classes between LOGSPACE and PTIME", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483", "journal-ref": "EPTCS 320, 2020, pp. 65-79", "doi": "10.4204/EPTCS.320.5", "report-no": null, "categories": "cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming language concepts are used to give some new perspectives on a\nlong-standing open problem: is logspace = ptime ?\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:23:16 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Jones", "Neil D.", "", "University of Copenhagen"], ["Bhaskar", "Siddharth", "", "University of Copenhagen"], ["Kop", "Cynthia", "", "Radboud University, Nijmegen"], ["Simonsen", "Jakob Grue", "", "University of Copenhagen"]]}, {"id": "2008.02941", "submitter": "Cunlu Zhou", "authors": "Roeland Wiersema, Cunlu Zhou, Yvette de Sereville, Juan Felipe\n  Carrasquilla, Yong Baek Kim, Henry Yuen", "title": "Exploring entanglement and optimization within the Hamiltonian\n  Variational Ansatz", "comments": "Updated figure 6, 7 and 11. Other minor changes", "journal-ref": "PRX Quantum 1, 020319 (2020)", "doi": "10.1103/PRXQuantum.1.020319", "report-no": null, "categories": "quant-ph cond-mat.str-el cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum variational algorithms are one of the most promising applications of\nnear-term quantum computers; however, recent studies have demonstrated that\nunless the variational quantum circuits are configured in a problem-specific\nmanner, optimization of such circuits will most likely fail. In this paper, we\nfocus on a special family of quantum circuits called the Hamiltonian\nVariational Ansatz (HVA), which takes inspiration from the quantum\napproximation optimization algorithm and adiabatic quantum computation. Through\nthe study of its entanglement spectrum and energy gradient statistics, we find\nthat HVA exhibits favorable structural properties such as mild or entirely\nabsent barren plateaus and a restricted state space that eases their\noptimization in comparison to the well-studied \"hardware-efficient ansatz.\" We\nalso numerically observe that the optimization landscape of HVA becomes almost\ntrap free when the ansatz is over-parameterized. We observe a size-dependent\n\"computational phase transition\" as the number of layers in the HVA circuit is\nincreased where the optimization crosses over from a hard to an easy region in\nterms of the quality of the approximations and speed of convergence to a good\nsolution. In contrast with the analogous transitions observed in the learning\nof random unitaries which occur at a number of layers that grows exponentially\nwith the number of qubits, our Variational Quantum Eigensolver experiments\nsuggest that the threshold to achieve the over-parameterization phenomenon\nscales at most polynomially in the number of qubits for the transverse field\nIsing and XXZ models. Lastly, as a demonstration of its entangling power and\neffectiveness, we show that HVA can find accurate approximations to the ground\nstates of a modified Haldane-Shastry Hamiltonian on a ring, which has\nlong-range interactions and has a power-law entanglement scaling.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:28:26 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 17:53:03 GMT"}], "update_date": "2021-01-04", "authors_parsed": [["Wiersema", "Roeland", ""], ["Zhou", "Cunlu", ""], ["de Sereville", "Yvette", ""], ["Carrasquilla", "Juan Felipe", ""], ["Kim", "Yong Baek", ""], ["Yuen", "Henry", ""]]}, {"id": "2008.03061", "submitter": "Svein H{\\o}gemo", "authors": "Svein H{\\o}gemo, Christophe Paul and Jan Arne Telle", "title": "Hierarchical Clusterings of Unweighted Graphs", "comments": "19 pages, 7 figures. Extended version of conference paper, to appear\n  in proceedings from MFCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of finding an optimal hierarchical clustering of an\nunweighted similarity graph under the recently introduced Dasgupta objective\nfunction. We introduce a proof technique, called the normalization procedure,\nthat takes any such clustering of a graph $G$ and iteratively improves it until\na desired target clustering of G is reached. We use this technique to show both\na negative and a positive complexity result. Firstly, we show that in general\nthe problem is NP-complete. Secondly, we consider min-well-behaved graphs,\nwhich are graphs $H$ having the property that for any $k$ the graph $H(k)$\nbeing the join of $k$ copies of $H$ has an optimal hierarchical clustering that\nsplits each copy of $H$ in the same optimal way. To optimally cluster such a\ngraph $H(k)$ we thus only need to optimally cluster the smaller graph $H$.\nCo-bipartite graphs are min-well-behaved, but otherwise they seem to be scarce.\nWe use the normalization procedure to show that also the cycle on 6 vertices is\nmin-well-behaved.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 09:45:46 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["H\u00f8gemo", "Svein", ""], ["Paul", "Christophe", ""], ["Telle", "Jan Arne", ""]]}, {"id": "2008.03115", "submitter": "Jamie Tucker-Foltz", "authors": "Jamie Tucker-Foltz", "title": "Approximating Constraint Satisfaction Problems Symmetrically", "comments": "91 pages, 6 figures, master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis investigates the extent to which the optimal value of a\nconstraint satisfaction problem (CSP) can be approximated by some sentence of\nfixed point logic with counting (FPC). It is known that, assuming $\\mathsf{P}\n\\neq \\mathsf{NP}$ and the Unique Games Conjecture, the best polynomial time\napproximation algorithm for any CSP is given by solving and rounding a specific\nsemidefinite programming relaxation. We prove an analogue of this result for\nalgorithms that are definable as FPC-interpretations, which holds without the\nassumption that $\\mathsf{P} \\neq \\mathsf{NP}$. While we are not able to drop\n(an FPC-version of) the Unique Games Conjecture as an assumption, we do present\nsome partial results toward proving it. Specifically, we give a novel\nconstruction which shows that, for all $\\alpha > 0$, there exists a positive\ninteger $q = \\text{poly}(\\frac{1}{\\alpha})$ such that no there is no\nFPC-interpretation giving an $\\alpha$-approximation of Unique Games on a label\nset of size $q$.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 19:48:25 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Tucker-Foltz", "Jamie", ""]]}, {"id": "2008.04116", "submitter": "Ross Dempsey", "authors": "Ross Dempsey and Charles Guinn", "title": "A Phase Transition in Minesweeper", "comments": "10 pages, 5 figures. Accepted to FUN with Algorithms 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the average-case complexity of the classic Minesweeper game in which\nplayers deduce the locations of mines on a two-dimensional lattice. Playing\nMinesweeper is known to be co-NP-complete. We show empirically that Minesweeper\nexhibits a phase transition analogous to the well-studied SAT phase transition.\nAbove the critical mine density it becomes almost impossible to play\nMinesweeper by logical inference. We use a reduction to Boolean\nunsatisfiability to characterize the hardness of Minesweeper instances, and\nshow that the hardness peaks at the phase transition. Furthermore, we\ndemonstrate algorithmic barriers at the phase transition for polynomial-time\napproaches to Minesweeper inference. Finally, we comment on expectations for\nthe asymptotic behavior of the phase transition.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:21:13 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Dempsey", "Ross", ""], ["Guinn", "Charles", ""]]}, {"id": "2008.04853", "submitter": "Praveen Damacharla", "authors": "Praveen Damacharla, Dhwani Mehta, Ahmad Y Javaid, Vijay K.\n  Devabhaktuni", "title": "Study on State-of-the-art Cloud Services Integration Capabilities with\n  Autonomous Ground Vehicles", "comments": null, "journal-ref": "2018 IEEE 88th Vehicular Technology Conference (VTC-Fall),\n  Chicago, IL, USA, 2018, pp. 1-5", "doi": "10.1109/VTCFall.2018.8690650", "report-no": null, "categories": "cs.CY cs.CC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computing and intelligence are substantial requirements for the accurate\nperformance of autonomous ground vehicles (AGVs). In this context, the use of\ncloud services in addition to onboard computers enhances computing and\nintelligence capabilities of AGVs. In addition, the vast amount of data\nprocessed in a cloud system contributes to overall performance and capabilities\nof the onboard system. This research study entails a qualitative analysis to\ngather insights on the applicability of the leading cloud service providers in\nAGV operations. These services include Google Cloud, Microsoft Azure, Amazon\nAWS, and IBM Cloud. The study begins with a brief review of AGV technical\nrequirements that are necessary to determine the rationale for identifying the\nmost suitable cloud service. The qualitative analysis studies and addresses the\napplicability of the cloud service over the proposed generalized AGV's\narchitecture integration, performance, and manageability. Our findings conclude\nthat a generalized AGV architecture can be supported by state-of-the-art cloud\nservice, but there should be a clear line of separation between the primary and\nsecondary computing needs. Moreover, our results show significant lags while\nusing cloud services and preventing their use in real-time AGV operation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:56:14 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Damacharla", "Praveen", ""], ["Mehta", "Dhwani", ""], ["Javaid", "Ahmad Y", ""], ["Devabhaktuni", "Vijay K.", ""]]}, {"id": "2008.05059", "submitter": "Justin Holmgren", "authors": "Justin Holmgren and Ran Raz", "title": "A Parallel Repetition Theorem for the GHZ Game", "comments": "22 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that parallel repetition of the (3-player) GHZ game reduces the\nvalue of the game polynomially fast to 0. That is, the value of the GHZ game\nrepeated in parallel $t$ times is at most $t^{-\\Omega(1)}$. Previously, only a\nbound of $\\approx \\frac{1}{\\alpha(t)}$, where $\\alpha$ is the inverse Ackermann\nfunction, was known.\n  The GHZ game was recently identified by Dinur, Harsha, Venkat and Yuen as a\nmulti-player game where all existing techniques for proving strong bounds on\nthe value of the parallel repetition of the game fail. Indeed, to prove our\nresult we use a completely new proof technique. Dinur, Harsha, Venkat and Yuen\nspeculated that progress on bounding the value of the parallel repetition of\nthe GHZ game may lead to further progress on the general question of parallel\nrepetition of multi-player games. They suggested that the strong correlations\npresent in the GHZ question distribution represent the \"hardest instance\" of\nthe multi-player parallel repetition problem.\n  Another motivation for studying the parallel repetition of the GHZ game comes\nfrom the field of quantum information. The GHZ game, first introduced by\nGreenberger, Horne and Zeilinger, is a central game in the study of quantum\nentanglement and has been studied in numerous works. For example, it is used\nfor testing quantum entanglement and for device-independent quantum\ncryptography. In such applications a game is typically repeated to reduce the\nprobability of error, and hence bounds on the value of the parallel repetition\nof the game may be useful.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 01:32:34 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Holmgren", "Justin", ""], ["Raz", "Ran", ""]]}, {"id": "2008.05177", "submitter": "Gil Kalai", "authors": "Yosef Rinott, Tomer Shoham, and Gil Kalai", "title": "Statistical Aspects of the Quantum Supremacy Demonstration", "comments": "38 pages, 9 figures (v3. some additional analysis), to appear in\n  Statistical Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notable claim of quantum supremacy presented by Google's team in 2019\nconsists of demonstrating the ability of a quantum circuit to generate, albeit\nwith considerable noise, bitstrings from a distribution that is considered hard\nto simulate on classical computers. Verifying that the generated data is indeed\nfrom the claimed distribution and assessing the circuit's noise level and its\nfidelity is a purely statistical undertaking. The objective of this paper is to\nexplain the relations between quantum computing and some of the statistical\naspects involved in demonstrating quantum supremacy in terms that are\naccessible to statisticians, computer scientists, and mathematicians. Starting\nwith the statistical analysis in Google's demonstration, which we explain, we\nstudy various estimators of the fidelity, and different approaches to testing\nthe distributions generated by the quantum computer. We propose different noise\nmodels, and discuss their implications. A preliminary study of the Google data,\nfocusing mostly on circuits of 12 and 14 qubits is discussed throughout the\npaper.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:46:02 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 07:34:45 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 19:24:41 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Rinott", "Yosef", ""], ["Shoham", "Tomer", ""], ["Kalai", "Gil", ""]]}, {"id": "2008.05188", "submitter": "Gil Kalai", "authors": "Gil Kalai", "title": "The Argument against Quantum Computers, the Quantum Laws of Nature, and\n  Google's Supremacy Claims", "comments": "33 pages 2 Figures. To appear in: The Intercontinental Academia,\n  Laws: 'Rigidity and Dynamics,' (M. J. Hannon and E. Z. Rabinovici (ed.))\n  Proceedings of the ICA Workshops 2018\\&2019, Singapore and Birmingham, World\n  Scientific. version 2: Added section on recent developments and some minor\n  changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  My 2018 lecture at the ICA workshop in Singapore dealt with quantum\ncomputation as a meeting point of the laws of computation and the laws of\nquantum mechanics. We described a computational complexity argument against the\nfeasibility of quantum computers: we identified a very low-level complexity\nclass of probability distributions described by noisy intermediate-scale\nquantum computers, and explained why it would allow neither good-quality\nquantum error-correction nor a demonstration of \"quantum supremacy,\" namely,\nthe ability of quantum computers to make computations that are impossible or\nextremely hard for classical computers. We went on to describe general\npredictions arising from the argument and proposed general laws that manifest\nthe failure of quantum computers.\n  In October 2019, \"Nature\" published a paper describing an experimental work\nthat took place at Google. The paper claims to demonstrate quantum\n(computational) supremacy on a 53-qubit quantum computer, thus clearly\nchallenging my theory. In this paper, I will explain and discuss my work in the\nperspective of Google's supremacy claims.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 09:11:55 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 12:27:13 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Kalai", "Gil", ""]]}, {"id": "2008.05558", "submitter": "Jeffrey Zhang", "authors": "Amir Ali Ahmadi, Jeffrey Zhang", "title": "On the complexity of finding a local minimizer of a quadratic function\n  over a polytope", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that unless P=NP, there cannot be a polynomial-time algorithm that\nfinds a point within Euclidean distance $c^n$ (for any constant $c \\ge 0$) of a\nlocal minimizer of an $n$-variate quadratic function over a polytope. This\nresult (even with $c=0$) answers a question of Pardalos and Vavasis that\nappeared in 1992 on a list of seven open problems in complexity theory for\nnumerical optimization. Our proof technique also implies that the problem of\ndeciding whether a quadratic function has a local minimizer over an (unbounded)\npolyhedron, and that of deciding if a quartic polynomial has a local minimizer\nare NP-hard.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:09:34 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 00:25:54 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 23:34:08 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Zhang", "Jeffrey", ""]]}, {"id": "2008.05677", "submitter": "M.H. Khalifeh", "authors": "M. H. Khalifeh, A.-H. Esfahanian", "title": "Some Preliminary Result About the Inset Edge and Average Distance of\n  Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An added edge to a graph is called an inset edge. Predicting k inset edges\nwhich minimize the average distance of a graph is known to be NP-Hard. However,\nwhen k = 1 the complexity of the problem is polynomial. In this paper, some\ntools for a precise analysis of the problem for the trees are established.\nUsing the tools, we can avoid using the distance matrix. This leads to more\nefficient algorithms and a better analysis of the problem. Several applications\nof the tools as well as a tight bound for the change of average distance when\nan inset edge is added to a tree are presented.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 03:53:43 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Khalifeh", "M. H.", ""], ["Esfahanian", "A. -H.", ""]]}, {"id": "2008.05728", "submitter": "Anuj Tawari", "authors": "Samir Datta, Anuj Tawari and Yadu Vasudev", "title": "Dynamic Complexity of Expansion", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Complexity was introduced by Immerman and Patnaik\n\\cite{PatnaikImmerman97} (see also \\cite{DongST95}). It has seen a resurgence\nof interest in the recent past, see\n\\cite{DattaHK14,ZeumeS15,MunozVZ16,BouyerJ17,Zeume17,DKMSZ18,DMVZ18,BarceloRZ18,DMSVZ19,SchmidtSVZK20,DKMTVZ20}\nfor some representative examples. Use of linear algebra has been a notable\nfeature of some of these papers. We extend this theme to show that the gap\nversion of spectral expansion in bounded degree graphs can be maintained in the\nclass $\\DynACz$ (also known as $\\dynfo$, for domain independent queries) under\nbatch changes (insertions and deletions) of $O(\\frac{\\log{n}}{\\log{\\log{n}}})$\nmany edges.\n  The spectral graph theoretic material of this work is based on the paper by\nKale-Seshadri \\cite{KaleS11}. Our primary technical contribution is to maintain\nup to logarithmic powers of the transition matrix of a bounded degree\nundirected graph in $\\DynACz$.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 07:29:39 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Datta", "Samir", ""], ["Tawari", "Anuj", ""], ["Vasudev", "Yadu", ""]]}, {"id": "2008.05800", "submitter": "Noleen K\\\"ohler", "authors": "Isolde Adler (1), Noleen K\\\"ohler (1) and Pan Peng (2) ((1) University\n  of Leeds, (2) University of Sheffield)", "title": "On Testability of First-Order Properties in Bounded-Degree Graphs", "comments": "37 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study property testing of properties that are definable in first-order\nlogic (FO) in the bounded-degree graph and relational structure models. We show\nthat any FO property that is defined by a formula with quantifier prefix\n$\\exists^*\\forall^*$ is testable (i.e., testable with constant query\ncomplexity), while there exists an FO property that is expressible by a formula\nwith quantifier prefix $\\forall^*\\exists^*$ that is not testable. In the dense\ngraph model, a similar picture is long known (Alon, Fischer, Krivelevich,\nSzegedy, Combinatorica 2000), despite the very different nature of the two\nmodels. In particular, we obtain our lower bound by a first-order formula that\ndefines a class of bounded-degree expanders, based on zig-zag products of\ngraphs. We expect this to be of independent interest. We then prove testability\nof some first-order properties that speak about isomorphism types of\nneighbourhoods, including testability of $1$-neighbourhood-freeness, and\n$r$-neighbourhood-freeness under a mild assumption on the degrees.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:21:46 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 15:23:38 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Adler", "Isolde", ""], ["K\u00f6hler", "Noleen", ""], ["Peng", "Pan", ""]]}, {"id": "2008.05801", "submitter": "Noleen K\\\"ohler", "authors": "Isolde Adler (1) and Noleen K\\\"ohler (1) ((1) University of Leeds)", "title": "An explicit construction of graphs of bounded degree that are far from\n  being Hamiltonian", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian cycles in graphs were first studied in the 1850s. Since then, an\nimpressive amount of research has been dedicated to identifying classes of\ngraphs that allow Hamiltonian cycles, and to related questions. The\ncorresponding decision problem, that asks whether a given graph is Hamiltonian\n(i.\\,e.\\ admits a Hamiltonian cycle), is one of Karp's famous NP-complete\nproblems. In this paper we study graphs of bounded degree that are \\emph{far}\nfrom being Hamiltonian, where a graph $G$ on $n$ vertices is \\emph{far} from\nbeing Hamiltonian, if modifying a constant fraction of $n$ edges is necessary\nto make $G$ Hamiltonian. We give an explicit deterministic construction of a\nclass of graphs of bounded degree that are locally Hamiltonian, but (globally)\nfar from being Hamiltonian. Here, \\emph{locally Hamiltonian} means that every\nsubgraph induced by the neighbourhood of a small vertex set appears in some\nHamiltonian graph. More precisely, we obtain graphs which differ in $\\Theta(n)$\nedges from any Hamiltonian graph, but non-Hamiltonicity cannot be detected in\nthe neighbourhood of $o(n)$ vertices. Our class of graphs yields a class of\nhard instances for one-sided error property testers with linear query\ncomplexity. It is known that any property tester (even with two-sided error)\nrequires a linear number of queries to test Hamiltonicity (Yoshida, Ito, 2010).\nThis is proved via a randomised construction of hard instances. In contrast,\nour construction is deterministic. So far only very few deterministic\nconstructions of hard instances for property testing are known. We believe that\nour construction may lead to future insights in graph theory and towards a\ncharacterisation of the properties hat are testable in the bounded-degree\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:22:53 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 17:20:56 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 10:11:01 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Adler", "Isolde", "", "University of Leeds"], ["K\u00f6hler", "Noleen", "", "University of Leeds"]]}, {"id": "2008.06148", "submitter": "Jeffrey Zhang", "authors": "Amir Ali Ahmadi, Jeffrey Zhang", "title": "Complexity aspects of local minima and related notions", "comments": "41 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the notions of (i) critical points, (ii) second-order points,\n(iii) local minima, and (iv) strict local minima for multivariate polynomials.\nFor each type of point, and as a function of the degree of the polynomial, we\nstudy the complexity of deciding (1) if a given point is of that type, and (2)\nif a polynomial has a point of that type. Our results characterize the\ncomplexity of these two questions for all degrees left open by prior\nliterature. Our main contributions reveal that many of these questions turn out\nto be tractable for cubic polynomials. In particular, we present an\nefficiently-checkable necessary and sufficient condition for local minimality\nof a point for a cubic polynomial. We also show that a local minimum of a cubic\npolynomial can be efficiently found by solving semidefinite programs of size\nlinear in the number of variables. By contrast, we show that it is strongly\nNP-hard to decide if a cubic polynomial has a critical point. We also prove\nthat the set of second-order points of any cubic polynomial is a spectrahedron,\nand conversely that any spectrahedron is the projection of the set of\nsecond-order points of a cubic polynomial. In our final section, we briefly\npresent a potential application of finding local minima of cubic polynomials to\nthe design of a third-order Newton method.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 00:50:13 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 22:05:57 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Zhang", "Jeffrey", ""]]}, {"id": "2008.06167", "submitter": "Ioannis Avramopoulos", "authors": "Ioannis Avramopoulos", "title": "Poising on Ariadne's thread: An algorithm for computing a maximum clique\n  in polynomial time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a polynomial-time algorithm for the maximum clique\nproblem, which implies P = NP. Our algorithm is based on a continuous\ngame-theoretic representation of this problem and at its heart lies a\ndiscrete-time dynamical system. The rule of our dynamical system depends on a\nparameter such that if this parameter is equal to the maximum-clique size, the\niterates of our dynamical system are guaranteed to converge to a maximum\nclique.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 02:25:00 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 05:42:13 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 14:25:33 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 00:54:50 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Avramopoulos", "Ioannis", ""]]}, {"id": "2008.06317", "submitter": "Subhamoy Maitra", "authors": "Chandra Sekhar Mukherjee, Subhamoy Maitra", "title": "Exact Quantum Query Algorithms Outperforming Parity -- Beyond The\n  Symmetric functions", "comments": "22 pages, modified the presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Exact Quantum Query model, almost all of the Boolean functions for which\nnon-trivial query algorithms exist are symmetric in nature. The most well known\ntechniques in this domain exploit parity decision trees, in which the parity of\ntwo bits can be obtained by a single query. Thus, exact quantum query\nalgorithms outperforming parity decision trees are rare. In this paper we first\nobtain optimal exact quantum query algorithms ($Q_{algo}(f)$) for a direct sum\nbased class of $\\Omega \\left( 2^{\\frac{\\sqrt{n}}{2}} \\right)$ non-symmetric\nfunctions. We construct these algorithms by analyzing the algebraic normal form\ntogether with a novel untangling strategy. Next we obtain the generalized\nparity decision tree complexity ($D_{\\oplus}(f)$) analysing the Walsh Spectrum.\nFinally, we show that query complexity of $Q_{algo}$ is $\\lceil \\frac{3n}{4}\n\\rceil$ whereas $D_{\\oplus}(f)$ varies between $n-1$ and $\\lceil \\frac{3n}{4}\n\\rceil+1$ for different classes, underlining linear separation between the two\nmeasures in many cases. To the best of our knowledge, this is the first family\nof algorithms beyond generalized parity (and thus parity) for a large class of\nnon-symmetric functions. We also implement these techniques for a larger\n(doubly exponential in $\\frac{n}{4}$) class of Maiorana-McFarland type\nfunctions, but could only obtain partial results using similar algorithmic\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 12:17:48 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 06:25:37 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 18:31:58 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 09:29:37 GMT"}, {"version": "v5", "created": "Sun, 16 May 2021 13:35:55 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mukherjee", "Chandra Sekhar", ""], ["Maitra", "Subhamoy", ""]]}, {"id": "2008.06591", "submitter": "Mina Dalirrooyfard", "authors": "Mina Dalirrooyfard, Andrea Lincoln and Virginia Vassilevska Williams", "title": "New Techniques for Proving Fine-Grained Average-Case Hardness", "comments": "To appear in FOCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent emergence of fine-grained cryptography strongly motivates\ndeveloping an average-case analogue of Fine-Grained Complexity (FGC).\n  This paper defines new versions of OV, $k$SUM and zero-$k$-clique that are\nboth worst-case and average-case fine-grained hard assuming the core hypotheses\nof FGC. We then use these as a basis for fine-grained hardness and average-case\nhardness of other problems. The new problems represent their inputs in a\ncertain ``factored'' form. We call them ``factored''-OV,\n``factored''-zero-$k$-clique and ``factored''-$3$SUM. We show that\nfactored-$k$-OV and factored $k$SUM are equivalent and are complete for a class\nof problems defined over Boolean functions. Factored zero-$k$-clique is also\ncomplete, for a different class of problems.\n  Our hard factored problems are also simple enough that we can reduce them to\nmany other problems, e.g.~to edit distance, $k$-LCS and versions of Max-Flow.\nWe further consider counting variants of the factored problems and give\nWCtoACFG reductions for them for a natural distribution. Through FGC reductions\nwe then get average-case hardness for well-studied problems like regular\nexpression matching from standard worst-case FGC assumptions.\n  To obtain our WCtoACFG reductions, we formalize the framework of [Boix-Adsera\net al. 2019] that was used to give a WCtoACFG reduction for counting\n$k$-cliques. We define an explicit property of problems such that if a problem\nhas that property one can use the framework on the problem to get a WCtoACFG\nself reduction. We then use the framework to slightly extend Boix-Adsera et\nal.'s average-case counting $k$-cliques result to average-case hardness for\ncounting arbitrary subgraph patterns of constant size in $k$-partite graphs...\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 22:21:41 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Dalirrooyfard", "Mina", ""], ["Lincoln", "Andrea", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "2008.06700", "submitter": "Karthik C. S.", "authors": "Vincent Cohen-Addad, Karthik C. S., and Guillaume Lagarde", "title": "On Efficient Low Distortion Ultrametric Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.LG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic problem in unsupervised learning and data analysis is to find\nsimpler and easy-to-visualize representations of the data that preserve its\nessential properties. A widely-used method to preserve the underlying\nhierarchical structure of the data while reducing its complexity is to find an\nembedding of the data into a tree or an ultrametric. The most popular\nalgorithms for this task are the classic linkage algorithms (single, average,\nor complete). However, these methods on a data set of $n$ points in\n$\\Omega(\\log n)$ dimensions exhibit a quite prohibitive running time of\n$\\Theta(n^2)$.\n  In this paper, we provide a new algorithm which takes as input a set of\npoints $P$ in $\\mathbb{R}^d$, and for every $c\\ge 1$, runs in time\n$n^{1+\\frac{\\rho}{c^2}}$ (for some universal constant $\\rho>1$) to output an\nultrametric $\\Delta$ such that for any two points $u,v$ in $P$, we have\n$\\Delta(u,v)$ is within a multiplicative factor of $5c$ to the distance between\n$u$ and $v$ in the \"best\" ultrametric representation of $P$. Here, the best\nultrametric is the ultrametric $\\tilde\\Delta$ that minimizes the maximum\ndistance distortion with respect to the $\\ell_2$ distance, namely that\nminimizes $\\underset{u,v \\in P}{\\max}\\ \\frac{\\tilde\\Delta(u,v)}{\\|u-v\\|_2}$.\n  We complement the above result by showing that under popular complexity\ntheoretic assumptions, for every constant $\\varepsilon>0$, no algorithm with\nrunning time $n^{2-\\varepsilon}$ can distinguish between inputs in\n$\\ell_\\infty$-metric that admit isometric embedding and those that incur a\ndistortion of $\\frac{3}{2}$.\n  Finally, we present empirical evaluation on classic machine learning datasets\nand show that the output of our algorithm is comparable to the output of the\nlinkage algorithms while achieving a much faster running time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 11:06:45 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["S.", "Karthik C.", ""], ["Lagarde", "Guillaume", ""]]}, {"id": "2008.06801", "submitter": "Edinah K. Gnang", "authors": "Edinah K. Gnang", "title": "On Partial Differential Encodings, with Application to Boolean Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work argues that strong arithmetic circuit lower bounds yield\nBoolean circuit lower bounds. In particular we show that the De Morgan Boolean\nformula complexity upper-bounds algebraic variants of the Kolomogorov\ncomplexity measure of partial differential incarnations of Turing machines. We\ndevise from this connection new non-trivial upper and lower bounds for the De\nMorgan Boolean formula complexity of some familiar Boolean functions.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 22:36:58 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 07:17:00 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 13:28:11 GMT"}, {"version": "v4", "created": "Fri, 14 May 2021 15:27:41 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Gnang", "Edinah K.", ""]]}, {"id": "2008.06805", "submitter": "Michael Wehar", "authors": "Andr\\'as Z. Salamon and Michael Wehar", "title": "Superlinear Lower Bounds Based on ETH", "comments": "Changed title, fixed minor typos, added additional explanation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce techniques for proving superlinear conditional lower bounds for\npolynomial time problems. In particular, we show that CircuitSat for circuits\nwith m gates and log(m) inputs (denoted by log-CircuitSat) is not decidable in\nessentially-linear time unless the exponential time hypothesis (ETH) is false\nand k-Clique is decidable in essentially-linear time in terms of the graph's\nsize for all fixed k. These results offer significant progress towards proving\nunconditional superlinear time complexity lower bounds for natural problems in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 23:00:23 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 23:25:24 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 04:56:02 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 01:11:24 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Salamon", "Andr\u00e1s Z.", ""], ["Wehar", "Michael", ""]]}, {"id": "2008.07003", "submitter": "Makrand Sinha", "authors": "Nikhil Bansal and Makrand Sinha", "title": "$k$-Forrelation Optimally Separates Quantum and Classical Query\n  Complexity", "comments": "40 pages, 2 figures. Change from v1 to v2: Updated figures to fix an\n  Adobe Acrobat specific issue. Change from v0 to v1: Improved the advantage\n  $\\delta$ to $2^{-O(k)}$ strengthening the main conclusions. Added a reference\n  to the independent work of Sherstov, Storozhenko and Wu (arxiv:2008.10223)\n  who obtained a similar lower bound for the randomized query complexity of\n  $k$-Rorrelation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aaronson and Ambainis (SICOMP `18) showed that any partial function on $N$\nbits that can be computed with an advantage $\\delta$ over a random guess by\nmaking $q$ quantum queries, can also be computed classically with an advantage\n$\\delta/2$ by a randomized decision tree making\n${O}_q(N^{1-\\frac{1}{2q}}\\delta^{-2})$ queries. Moreover, they conjectured the\n$k$-Forrelation problem -- a partial function that can be computed with $q =\n\\lceil k/2 \\rceil$ quantum queries -- to be a suitable candidate for exhibiting\nsuch an extremal separation.\n  We prove their conjecture by showing a tight lower bound of\n$\\widetilde{\\Omega}(N^{1-1/k})$ for the randomized query complexity of\n$k$-Forrelation, where the advantage $\\delta = 2^{-O(k)}$. By standard\namplification arguments, this gives an explicit partial function that exhibits\nan $O_\\epsilon(1)$ vs $\\Omega(N^{1-\\epsilon})$ separation between bounded-error\nquantum and randomized query complexities, where $\\epsilon>0$ can be made\narbitrarily small. Our proof also gives the same bound for the closely related\nbut non-explicit $k$-Rorrelation function introduced by Tal (FOCS `20).\n  Our techniques rely on classical Gaussian tools, in particular, Gaussian\ninterpolation and Gaussian integration by parts, and in fact, give a more\ngeneral statement. We show that to prove lower bounds for $k$-Forrelation\nagainst a family of functions, it suffices to bound the $\\ell_1$-weight of the\nFourier coefficients between levels $k$ and $(k-1)k$. We also prove new\ninterpolation and integration by parts identities that might be of independent\ninterest in the context of rounding high-dimensional Gaussian vectors.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:26:46 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 20:40:00 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 14:51:56 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Bansal", "Nikhil", ""], ["Sinha", "Makrand", ""]]}, {"id": "2008.07252", "submitter": "Johannes Blum", "authors": "Johannes Blum", "title": "W[1]-Hardness of the k-Center Problem Parameterized by the Skeleton\n  Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the $k$-Center problem, we are given a graph $G=(V,E)$ with positive edge\nweights and an integer $k$ and the goal is to select $k$ center vertices $C\n\\subseteq V$ such that the maximum distance from any vertex to the closest\ncenter vertex is minimized. On general graphs, the problem is NP-hard and\ncannot be approximated within a factor less than $2$.\n  Typical applications of the $k$-Center problem can be found in logistics or\nurban planning and hence, it is natural to study the problem on transportation\nnetworks. Such networks are often characterized as graphs that are (almost)\nplanar or have low doubling dimension, highway dimension or skeleton dimension.\nIt was shown by Feldmann and Marx that $k$-Center is W[1]-hard on planar graphs\nof constant doubling dimension when parameterized by the number of centers $k$,\nthe highway dimension $hd$ and the pathwidth $pw$. We extend their result and\nshow that even if we additionally parameterize by the skeleton dimension\n$\\kappa$, the $k$-Center problem remains W[1]-hard. Moreover, we prove that\nunder the Exponential Time Hypothesis there is no exact algorithm for\n$k$-Center that has runtime $f(k,hd,pw,\\kappa) \\cdot \\vert V \\vert^{o(pw +\n\\kappa + \\sqrt{k+hd})}$ for any computable function $f$.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:27:14 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Blum", "Johannes", ""]]}, {"id": "2008.07445", "submitter": "Abel Molina", "authors": "Abel Molina", "title": "Parallel repetition with a threshold in quantum interactive proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we show that $O(\\log (1/\\epsilon))$ rounds of parallel\nrepetition with a threshold suffice to reduce completeness and soundness error\nto $\\epsilon$ for single-prover quantum interactive proof systems. This\nimproves on a previous $O(\\log (1/\\epsilon) \\log \\log (1/\\epsilon))$ bound from\nHornby (2018), while also simplifying its proof. A key element in our proof is\na concentration bound from Impagliazzo and Kabanets (2010).\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:06:48 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Molina", "Abel", ""]]}, {"id": "2008.07468", "submitter": "Mikhail Raskin", "authors": "Bruno Courcelle, Ir\\`ene Durand, Michael Raskin", "title": "A unified algorithm for colouring graphs of bounded clique-width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clique-width is one of the graph complexity measures leading to polynomial\nspecial-case algorithms for generally NP-complete problems, e.g. graph\ncolourability. The best two currently known algorithms for verifying\nc-colourability of graphs represented as clique-width terms are optimised\ntowards two different extreme cases, a constant number of colours and a very\nlarge number of colours. We present a way to unify these approaches in a single\nrelatively simple algorithm that achieves the state of the art complexity in\nboth cases. The unified algorithm also provides a speed-up for a large number\nof colours.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:47:53 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Courcelle", "Bruno", ""], ["Durand", "Ir\u00e8ne", ""], ["Raskin", "Michael", ""]]}, {"id": "2008.07470", "submitter": "Gregory Rosenthal", "authors": "Gregory Rosenthal", "title": "Bounds on the QAC$^0$ Complexity of Approximating Parity", "comments": "39 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  QAC circuits are quantum circuits with one-qubit gates and Toffoli gates of\narbitrary arity. QAC$^0$ circuits are QAC circuits of constant depth, and are\nquantum analogues of AC$^0$ circuits. We prove the following:\n  $\\bullet$ For all $d \\ge 7$ and $\\varepsilon>0$ there is a depth-$d$ QAC\ncircuit of size $\\exp(\\mathrm{poly}(n^{1/d}) \\log(n/\\varepsilon))$ that\napproximates the $n$-qubit parity function to within error $\\varepsilon$ on\nworst-case quantum inputs. Previously it was unknown whether QAC circuits of\nsublogarithmic depth could approximate parity regardless of size.\n  $\\bullet$ We introduce a class of \"mostly classical\" QAC circuits, including\na major component of our circuit from the above upper bound, and prove a tight\nlower bound on the size of low-depth, mostly classical QAC circuits that\napproximate this component.\n  $\\bullet$ Arbitrary depth-$d$ QAC circuits require at least $\\Omega(n/d)$\nmulti-qubit gates to achieve a $1/2 + \\exp(-o(n/d))$ approximation of parity.\nWhen $d = \\Theta(\\log n)$ this nearly matches an easy $O(n)$ size upper bound\nfor computing parity exactly.\n  $\\bullet$ QAC circuits with at most two layers of multi-qubit gates cannot\nachieve a $1/2 + \\exp(-o(n))$ approximation of parity, even non-cleanly.\nPreviously it was known only that such circuits could not cleanly compute\nparity exactly for sufficiently large $n$.\n  The proofs use a new normal form for quantum circuits which may be of\nindependent interest, and are based on reductions to the problem of\nconstructing certain generalizations of the cat state which we name \"nekomata\"\nafter an analogous cat y\\=okai.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:51:04 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 17:49:24 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 10:19:07 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Rosenthal", "Gregory", ""]]}, {"id": "2008.07556", "submitter": "Ibrahim Al-Nahhal Mr", "authors": "Ibrahim Al-Nahhal, Octavia A. Dobre, and Salama Ikki", "title": "On the Complexity Reduction of Uplink Sparse Code Multiple Access for\n  Spatial Modulation", "comments": "13 pages, 10 figures, to be appeared on IEEE Transactions on\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-user spatial modulation (SM) assisted by sparse code multiple access\n(SCMA) has been recently proposed to provide uplink high spectral efficiency\ntransmission. The message passing algorithm (MPA) is employed to detect the\ntransmitted signals, which suffers from high complexity. This paper proposes\nthree low-complexity algorithms for the first time to the SM-SCMA. The first\nalgorithm is referred to as successive user detection (SUD), while the second\nalgorithm is the modified version of SUD, namely modified SUD (MSUD). Then, for\nthe first time, the tree-search of the SM-SCMA is constructed. Based on that\ntree-search, another variant of the sphere decoder (SD) is proposed for the\nSM-SCMA, referred to as fixed-complexity SD (FCSD). SUD provides a benchmark\nfor decoding complexity at the expense of bit-error-rate (BER) performance.\nFurther, MSUD slightly increases the complexity of SUD with a significant\nimprovement in BER performance. Finally, FCSD provides a near-optimum BER with\na considerable reduction of the complexity compared to the MPA decoder and also\nsupports parallel hardware implementation. The proposed algorithms provide\nflexible design choices for practical implementation based on system design\ndemands. The complexity analysis and Monte-Carlo simulations of the BER are\nprovided for the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 18:06:03 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Al-Nahhal", "Ibrahim", ""], ["Dobre", "Octavia A.", ""], ["Ikki", "Salama", ""]]}, {"id": "2008.07898", "submitter": "Martin Kucera", "authors": "Martin Ku\\v{c}era, Ond\\v{r}ej Such\\'y", "title": "Minimum Eccentricity Shortest Path Problem with Respect to Structural\n  Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Minimum Eccentricity Shortest Path Problem consists in finding a shortest\npath with minimum eccentricity in a given undirected graph. The problem is\nknown to be NP-complete and W[2]-hard with respect to the desired eccentricity.\nWe present fpt algorithms for the problem parameterized by the modular width,\ndistance to cluster graph, the combination of distance to disjoint paths with\nthe desired eccentricity, and maximum leaf number.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 12:56:02 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 19:58:26 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ku\u010dera", "Martin", ""], ["Such\u00fd", "Ond\u0159ej", ""]]}, {"id": "2008.08480", "submitter": "Will Rosenbaum", "authors": "Christine T. Cheng and Will Rosenbaum", "title": "Stable Matchings with Restricted Preferences: Structure and Complexity", "comments": "Various updates and improvements in response to reviewer comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.GT math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that every stable matching instance $I$ has a rotation poset\n$R(I)$ that can be computed efficiently and the downsets of $R(I)$ are in\none-to-one correspondence with the stable matchings of $I$. Furthermore, for\nevery poset $P$, an instance $I(P)$ can be constructed efficiently so that the\nrotation poset of $I(P)$ is isomorphic to $P$. In this case, we say that $I(P)$\nrealizes $P$. Many researchers exploit the rotation poset of an instance to\ndevelop fast algorithms or to establish the hardness of stable matching\nproblems.\n  In order to gain a parameterized understanding of the complexity of sampling\nstable matchings, Bhatnagar et al. [SODA 2008] introduced stable matching\ninstances whose preference lists are restricted but nevertheless model\nsituations that arise in practice. In this paper, we study four such\nparameterized restrictions; our goal is to characterize the rotation posets\nthat arise from these models: $k$-bounded, $k$-attribute, $(k_1, k_2)$-list,\n$k$-range.\n  We prove that there is a constant $k$ so that every rotation poset is\nrealized by some instance in the first three models for some fixed constant\n$k$. We describe efficient algorithms for constructing such instances given the\nHasse diagram of a poset. As a consequence, the fundamental problem of counting\nstable matchings remains $\\#$BIS-complete even for these restricted instances.\n  For $k$-range preferences, we show that a poset $P$ is realizable if and only\nif the Hasse diagram of $P$ has pathwidth bounded by functions of $k$. Using\nthis characterization, we show that the following problems are fixed parameter\ntractable when parametrized by the range of the instance: exactly counting and\nuniformly sampling stable matchings, finding median, sex-equal, and balanced\nstable matchings.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:39:02 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 15:11:47 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Cheng", "Christine T.", ""], ["Rosenbaum", "Will", ""]]}, {"id": "2008.08680", "submitter": "{\\L}ukasz Grabowski", "authors": "Endre Cs\\'oka, {\\L}ukasz Grabowski", "title": "On directed analogues of expander and hyperfinite graph sequences", "comments": "17 pages, no figures, v3: very minor changes compared to v2, final\n  accepted version to appear in Comb. Probab. Comput", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study analogues of expander and hyperfinite graph sequences\nin the context of directed acyclic graphs, which we call \"extender\" and\n\"hypershallow\" graph sequences, respectively. Our main result is a\nprobabilistic construction of non-hypershallow graph sequences.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 21:45:43 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 17:17:31 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 14:37:56 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Cs\u00f3ka", "Endre", ""], ["Grabowski", "\u0141ukasz", ""]]}, {"id": "2008.08721", "submitter": "William Kretschmer", "authors": "William Kretschmer", "title": "The Quantum Supremacy Tsirelson Inequality", "comments": "26 pages. V2: corrected typos, added additional discussion, added\n  journal reference. V3: additional minor corrections", "journal-ref": "12th Innovations in Theoretical Computer Science Conference (ITCS\n  2021), Leibniz International Proceedings in Informatics (LIPIcs) 185, pp.\n  13:1-13:13 (2021)", "doi": "10.4230/LIPIcs.ITCS.2021.13", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A leading proposal for verifying near-term quantum supremacy experiments on\nnoisy random quantum circuits is linear cross-entropy benchmarking. For a\nquantum circuit $C$ on $n$ qubits and a sample $z \\in \\{0,1\\}^n$, the benchmark\ninvolves computing $|\\langle z|C|0^n \\rangle|^2$, i.e. the probability of\nmeasuring $z$ from the output distribution of $C$ on the all zeros input. Under\na strong conjecture about the classical hardness of estimating output\nprobabilities of quantum circuits, no polynomial-time classical algorithm given\n$C$ can output a string $z$ such that $|\\langle z|C|0^n\\rangle|^2$ is\nsubstantially larger than $\\frac{1}{2^n}$ (Aaronson and Gunn, 2019). On the\nother hand, for a random quantum circuit $C$, sampling $z$ from the output\ndistribution of $C$ achieves $|\\langle z|C|0^n\\rangle|^2 \\approx \\frac{2}{2^n}$\non average (Arute et al., 2019).\n  In analogy with the Tsirelson inequality from quantum nonlocal correlations,\nwe ask: can a polynomial-time quantum algorithm do substantially better than\n$\\frac{2}{2^n}$? We study this question in the query (or black box) model,\nwhere the quantum algorithm is given oracle access to $C$. We show that, for\nany $\\varepsilon \\ge \\frac{1}{\\mathrm{poly}(n)}$, outputting a sample $z$ such\nthat $|\\langle z|C|0^n\\rangle|^2 \\ge \\frac{2 + \\varepsilon}{2^n}$ on average\nrequires at least $\\Omega\\left(\\frac{2^{n/4}}{\\mathrm{poly}(n)}\\right)$ queries\nto $C$, but not more than $O\\left(2^{n/3}\\right)$ queries to $C$, if $C$ is\neither a Haar-random $n$-qubit unitary, or a canonical state preparation oracle\nfor a Haar-random $n$-qubit state. We also show that when $C$ samples from the\nFourier distribution of a random Boolean function, the naive algorithm that\nsamples from $C$ is the optimal 1-query algorithm for maximizing $|\\langle\nz|C|0^n\\rangle|^2$ on average.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 01:04:32 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 22:09:20 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 04:14:17 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Kretschmer", "William", ""]]}, {"id": "2008.08963", "submitter": "Srijita Kundu", "authors": "Rahul Jain and Srijita Kundu", "title": "A Direct Product Theorem for One-Way Quantum Communication", "comments": "31 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a direct product theorem for the one-way entanglement-assisted\nquantum communication complexity of a general relation\n$f\\subseteq\\mathcal{X}\\times\\mathcal{Y}\\times\\mathcal{Z}$. For any\n$\\varepsilon, \\zeta > 0$ and any $k\\geq1$, we show that \\[\n\\mathrm{Q}^1_{1-(1-\\varepsilon)^{\\Omega(\\zeta^6k/\\log|\\mathcal{Z}|)}}(f^k) =\n\\Omega\\left(k\\left(\\zeta^5\\cdot\\mathrm{Q}^1_{\\varepsilon + 12\\zeta}(f) -\n\\log\\log(1/\\zeta)\\right)\\right),\\] where $\\mathrm{Q}^1_{\\varepsilon}(f)$\nrepresents the one-way entanglement-assisted quantum communication complexity\nof $f$ with worst-case error $\\varepsilon$ and $f^k$ denotes $k$ parallel\ninstances of $f$.\n  As far as we are aware, this is the first direct product theorem for quantum\ncommunication. Our techniques are inspired by the parallel repetition theorems\nfor the entangled value of two-player non-local games, under product\ndistributions due to Jain, Pereszl\\'{e}nyi and Yao, and under anchored\ndistributions due to Bavarian, Vidick and Yuen, as well as message-compression\nfor quantum protocols due to Jain, Radhakrishnan and Sen.\n  Our techniques also work for entangled non-local games which have input\ndistributions anchored on any one side. In particular, we show that for any\ngame $G = (q, \\mathcal{X}\\times\\mathcal{Y}, \\mathcal{A}\\times\\mathcal{B},\n\\mathsf{V})$ where $q$ is a distribution on $\\mathcal{X}\\times\\mathcal{Y}$\nanchored on any one side with anchoring probability $\\zeta$, then \\[\n\\omega^*(G^k) = \\left(1 - (1-\\omega^*(G))^5\\right)^{\\Omega\\left(\\frac{\\zeta^2\nk}{\\log(|\\mathcal{A}|\\cdot|\\mathcal{B}|)}\\right)}\\] where $\\omega^*(G)$\nrepresents the entangled value of the game $G$. This is a generalization of the\nresult of Bavarian, Vidick and Yuen, who proved a parallel repetition theorem\nfor games anchored on both sides, and potentially a simplification of their\nproof.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:31:41 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Jain", "Rahul", ""], ["Kundu", "Srijita", ""]]}, {"id": "2008.09004", "submitter": "Daniel Paulusma", "authors": "Flavia Bonomo-Braberman and Nick Brettell and Andrea Munaro and\n  Dani\\\"el Paulusma", "title": "Solving Problems on Generalized Convex Graphs via Mim-Width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bipartite graph $G=(A,B,E)$ is ${\\cal H}$-convex, for some family of graphs\n${\\cal H}$, if there exists a graph $H\\in {\\cal H}$ with $V(H)=A$ such that the\nset of neighbours in $A$ of each $b\\in B$ induces a connected subgraph of $H$.\nMany $\\mathsf{NP}$-complete problems, including problems such as Dominating\nSet, Feedback Vertex Set, Induced Matching and List $k$-Colouring, become\npolynomial-time solvable for ${\\mathcal H}$-convex graphs when ${\\mathcal H}$\nis the set of paths. In this case, the class of ${\\mathcal H}$-convex graphs is\nknown as the class of convex graphs. The underlying reason is that the class of\nconvex graphs has bounded mim-width. We extend the latter result to families of\n${\\mathcal H}$-convex graphs where (i) ${\\mathcal H}$ is the set of cycles, or\n(ii) ${\\mathcal H}$ is the set of trees with bounded maximum degree and a\nbounded number of vertices of degree at least $3$. As a consequence, we can\nre-prove and strengthen a large number of results on generalized convex graphs\nknown in the literature. To complement result (ii), we show that the mim-width\nof ${\\mathcal H}$-convex graphs is unbounded if ${\\mathcal H}$ is the set of\ntrees with arbitrarily large maximum degree or an arbitrarily large number of\nvertices of degree at least $3$. In this way we are able to determine\ncomplexity dichotomies for the aforementioned graph problems. Afterwards we\nperform a more refined width-parameter analysis, which shows even more clearly\nwhich width parameters are bounded for classes of ${\\cal H}$-convex graphs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:47:54 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 23:18:39 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Bonomo-Braberman", "Flavia", ""], ["Brettell", "Nick", ""], ["Munaro", "Andrea", ""], ["Paulusma", "Dani\u00ebl", ""]]}, {"id": "2008.09008", "submitter": "Saeed Akhoondian Amiri", "authors": "Saeed Akhoondian Amiri", "title": "On Fine-Grained Exact Computation in Regular Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there is no subexponential time algorithm for computing the\nexact solution of the maximum independent set problem in d-regular graphs\nunless ETH fails. We expand our method to show that it helps to provide lower\nbounds for other covering problems such as vertex cover and clique. We utilize\nthe construction to show the NP-hardness of MIS on 5-regular planar graphs,\nclosing the exact complexity status of the problem on regular planar graphs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:55:57 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 10:40:10 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Amiri", "Saeed Akhoondian", ""]]}, {"id": "2008.09317", "submitter": "Aayush Jain", "authors": "Aayush Jain and Huijia Lin and Amit Sahai", "title": "Indistinguishability Obfuscation from Well-Founded Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we show how to construct indistinguishability obfuscation from\nsubexponential hardness of four well-founded assumptions. We prove:\n  Let $\\tau \\in (0,\\infty), \\delta \\in (0,1), \\epsilon \\in (0,1)$ be arbitrary\nconstants. Assume sub-exponential security of the following assumptions, where\n$\\lambda$ is a security parameter, and the parameters $\\ell,k,n$ below are\nlarge enough polynomials in $\\lambda$:\n  - The SXDH assumption on asymmetric bilinear groups of a prime order $p =\nO(2^\\lambda)$,\n  - The LWE assumption over $\\mathbb{Z}_{p}$ with subexponential\nmodulus-to-noise ratio $2^{k^\\epsilon}$, where $k$ is the dimension of the LWE\nsecret,\n  - The LPN assumption over $\\mathbb{Z}_p$ with polynomially many LPN samples\nand error rate $1/\\ell^\\delta$, where $\\ell$ is the dimension of the LPN\nsecret,\n  - The existence of a Boolean PRG in $\\mathsf{NC}^0$ with stretch\n$n^{1+\\tau}$,\n  Then, (subexponentially secure) indistinguishability obfuscation for all\npolynomial-size circuits exists.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:34:30 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Jain", "Aayush", ""], ["Lin", "Huijia", ""], ["Sahai", "Amit", ""]]}, {"id": "2008.09660", "submitter": "Akash Kumar", "authors": "Akash Kumar and Mithilesh Kumar", "title": "Deletion to Induced Matching", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the DELETION TO INDUCED MATCHING problem, we are given a graph $G$ on $n$\nvertices, $m$ edges and a non-negative integer $k$ and asks whether there\nexists a set of vertices $S \\subseteq V(G) $ such that $|S|\\le k$ and the size\nof any connected component in $G-S$ is exactly 2. In this paper, we provide a\nfixed-parameter tractable (FPT) algorithm of running time $O^*(1.748^{k})$ for\nthe DELETION TO INDUCED MATCHING problem using branch-and-reduce strategy and\npath decomposition. We also extend our work to the exact-exponential version of\nthe problem.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 19:30:18 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 16:51:59 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Kumar", "Akash", ""], ["Kumar", "Mithilesh", ""]]}, {"id": "2008.09921", "submitter": "Arash Rafiey", "authors": "Jeff Kinne, Ashwin Murali, Arash Rafiey", "title": "Digraphs Homomorphism Problems with Maltsev Condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generalization of finding a homomorphism from an input digraph\n$G$ to a fixed digraph $H$, HOM($H$). In this setting, we are given an input\ndigraph $G$ together with a list function from $G$ to $2^H$. The goal is to\nfind a homomorphism from $G$ to $H$ with respect to the lists if one exists.\n  We show that if the list function is a Maltsev polymorphism then deciding\nwhether $G$ admits a homomorphism to $H$ is polynomial time solvable. In our\napproach, we only use the existence of the Maltsev polymorphism. Furthermore,\nwe show that deciding whether a relational structure $\\mathcal{R}$ admits a\nMaltsev polymorphism is a special case of finding a homormphism from a graph\n$G$ to a graph $H$ and a list function with a Maltsev polymorphism. Since the\nexistence of Maltsev is not required in our algorithm, we can decide in\npolynomial time whether the relational structure $\\mathcal{R}$ admits Maltsev\nor not.\n  We also discuss forbidden obstructions for the instances admitting Maltsev\nlist polymorphism. We have implemented our algorithm and tested on instances\narising from linear equations, and other types of instances.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 22:17:18 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 14:52:44 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kinne", "Jeff", ""], ["Murali", "Ashwin", ""], ["Rafiey", "Arash", ""]]}, {"id": "2008.10223", "submitter": "Alexander A. Sherstov", "authors": "Alexander A. Sherstov, Andrey A. Storozhenko, and Pei Wu", "title": "An Optimal Separation of Randomized and Quantum Query Complexity", "comments": "47 pages. Changes from v2 to v3: added applications to communication\n  complexity (a near-optimal separation of bounded-error quantum vs classical\n  communication complexity)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that for every decision tree, the absolute values of the Fourier\ncoefficients of given order $\\ell\\geq1$ sum to at most\n$c^{\\ell}\\sqrt{\\binom{d}{\\ell}(1+\\log n)^{\\ell-1}},$ where $n$ is the number of\nvariables, $d$ is the tree depth, and $c>0$ is an absolute constant. This bound\nis essentially tight and settles a conjecture due to Tal (arxiv 2019; FOCS\n2020). The bounds prior to our work degraded rapidly with $\\ell,$ becoming\ntrivial already at $\\ell=\\sqrt{d}.$\n  As an application, we obtain, for every integer $k\\geq1,$ a partial Boolean\nfunction on $n$ bits that has bounded-error quantum query complexity at most\n$\\lceil k/2\\rceil$ and randomized query complexity $\\tilde{\\Omega}(n^{1-1/k}).$\nThis separation of bounded-error quantum versus randomized query complexity is\nbest possible, by the results of Aaronson and Ambainis (STOC 2015). Prior to\nour work, the best known separation was polynomially weaker: $O(1)$ versus\n$\\Omega(n^{2/3-\\epsilon})$ for any $\\epsilon>0$ (Tal, FOCS 2020).\n  As another application, we obtain an essentially optimal separation of\n$O(\\log n)$ versus $\\Omega(n^{1-\\epsilon})$ for bounded-error quantum versus\nrandomized communication complexity, for any $\\epsilon>0.$ The best previous\nseparation was polynomially weaker: $O(\\log n)$ versus\n$\\Omega(n^{2/3-\\epsilon})$ (implicit in Tal, FOCS 2020).\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 06:50:57 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 09:12:25 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 07:45:09 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Sherstov", "Alexander A.", ""], ["Storozhenko", "Andrey A.", ""], ["Wu", "Pei", ""]]}, {"id": "2008.11315", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet", "title": "Inapproximability of Diameter in super-linear time: Beyond the 5/3 ratio", "comments": "13 pages, 4 figures, expanded introduction and discussion on\n  follow-up works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show, assuming the Strong Exponential Time Hypothesis, that for every\n$\\varepsilon > 0$, approximating directed Diameter on $m$-arc graphs within\nratio $7/4 - \\varepsilon$ requires $m^{4/3 - o(1)}$ time. Our construction uses\nnonnegative edge weights but even holds for sparse digraphs, i.e., for which\nthe number of vertices $n$ and the number of arcs $m$ satisfy $m = n\n\\log^{O(1)} n$. This is the first result that conditionally rules out a\nnear-linear time $5/3$-approximation for Diameter.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 00:28:52 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 00:55:08 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Bonnet", "\u00c9douard", ""]]}, {"id": "2008.11786", "submitter": "Daniel Gibney", "authors": "Daniel Gibney, Gary Hoppenworth, Sharma V. Thankachan", "title": "Simple Reductions from Formula-SAT to Pattern Matching on Labeled Graphs\n  and Subtree Isomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CNF formula satisfiability problem (CNF-SAT) has been reduced to many\nfundamental problems in P to prove tight lower bounds under the Strong\nExponential Time Hypothesis (SETH). Recently, the works of Abboud, Hansen,\nVassilevska W. and Williams (STOC 16), and later, Abboud and Bringmann (ICALP\n18) have proposed basing lower bounds on the hardness of general boolean\nformula satisfiability (Formula-SAT). Reductions from Formula-SAT have two\nadvantages over the usual reductions from CNF-SAT: (1) conjectures on the\nhardness of Formula-SAT are arguably much more plausible than those of CNF-SAT,\nand (2) these reductions give consequences even for logarithmic improvements in\na problems upper bounds.\n  Here we give tight reductions from Formula-SAT to two more problems: pattern\nmatching on labeled graphs (PMLG) and subtree isomorphism. Previous reductions\nfrom Formula-SAT were to sequence alignment problems such as Edit Distance,\nLCS, and Frechet Distance and required some technical work. This paper uses\nideas similar to those used previously, but in a decidedly simpler setting,\nhelping to illustrate the most salient features of the underlying techniques.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:10:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Gibney", "Daniel", ""], ["Hoppenworth", "Gary", ""], ["Thankachan", "Sharma V.", ""]]}, {"id": "2008.11943", "submitter": "Simon Kn\\\"auer", "authors": "Manuel Bodirsky and Simon Kn\\\"auer", "title": "Network satisfaction for symmetric relation algebras with a flexible\n  atom", "comments": "32 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robin Hirsch posed in 1996 the Really Big Complexity Problem: classify the\ncomputational complexity of the network satisfaction problem for all finite\nrelation algebras $\\bf A$. We provide a complete classification for the case\nthat $\\bf A$ is symmetric and has a flexible atom; the problem is in this case\nNP-complete or in P. If a finite integral relation algebra has a flexible atom,\nthen it has a normal representation $\\mathfrak{B}$. We can then study the\ncomputational complexity of the network satisfaction problem of ${\\bf A}$ using\nthe universal-algebraic approach, via an analysis of the polymorphisms of\n$\\mathfrak{B}$. We also use a Ramsey-type result of Ne\\v{s}et\\v{r}il and R\\\"odl\nand a complexity dichotomy result of Bulatov for conservative finite-domain\nconstraint satisfaction problems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 06:43:25 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Kn\u00e4uer", "Simon", ""]]}, {"id": "2008.12170", "submitter": "Jeffrey Zhang", "authors": "Jeffrey Zhang", "title": "Complexity Aspects of Fundamental Questions in Polynomial Optimization", "comments": "196 pages, 11 figures, PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we settle the computational complexity of some fundamental\nquestions in polynomial optimization. These include the questions of (i)\nfinding a local minimum, (ii) testing local minimality of a point, and (iii)\ndeciding attainment of the optimal value. Our results characterize the\ncomplexity of these three questions for all degrees of the defining polynomials\nleft open by prior literature.\n  Regarding (i) and (ii), we show that unless P=NP, there cannot be a\npolynomial-time algorithm that finds a point within Euclidean distance $c^n$\n(for any constant $c$) of a local minimum of an $n$-variate quadratic program.\nBy contrast, we show that a local minimum of a cubic polynomial can be found\nefficiently by semidefinite programming (SDP). We prove that second-order\npoints of cubic polynomials admit an efficient semidefinite representation,\neven though their critical points are NP-hard to find. We also give an\nefficiently-checkable necessary and sufficient condition for local minimality\nof a point for a cubic polynomial.\n  Regarding (iii), we prove that testing whether a quadratically constrained\nquadratic program with a finite optimal value has an optimal solution is\nNP-hard. We also show that testing coercivity of the objective function,\ncompactness of the feasible set, and the Archimedean property associated with\nthe description of the feasible set are all NP-hard. We also give a new\ncharacterization of coercive polynomials that lends itself to a hierarchy of\nSDPs.\n  In our final chapter, we present an SDP relaxation for finding approximate\nNash equilibria in bimatrix games. We show that for a symmetric game, a\n$1/3$-Nash equilibrium can be efficiently recovered from any rank-2 solution to\nthis relaxation. We also propose SDP relaxations for NP-hard problems related\nto Nash equilibria, such as that of finding the highest achievable welfare\nunder any Nash equilibrium.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 14:58:02 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Zhang", "Jeffrey", ""]]}, {"id": "2008.12237", "submitter": "Alexander Wein", "authors": "Afonso S. Bandeira, Jess Banks, Dmitriy Kunisky, Cristopher Moore,\n  Alexander S. Wein", "title": "Spectral Planting and the Hardness of Refuting Cuts, Colorability, and\n  Communities in Random Graphs", "comments": "59 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.SI math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of efficiently refuting the k-colorability of a graph,\nor equivalently certifying a lower bound on its chromatic number. We give\nformal evidence of average-case computational hardness for this problem in\nsparse random regular graphs, showing optimality of a simple spectral\ncertificate. This evidence takes the form of a computationally-quiet planting:\nwe construct a distribution of d-regular graphs that has significantly smaller\nchromatic number than a typical regular graph drawn uniformly at random, while\nproviding evidence that these two distributions are indistinguishable by a\nlarge class of algorithms. We generalize our results to the more general\nproblem of certifying an upper bound on the maximum k-cut.\n  This quiet planting is achieved by minimizing the effect of the planted\nstructure (e.g. colorings or cuts) on the graph spectrum. Specifically, the\nplanted structure corresponds exactly to eigenvectors of the adjacency matrix.\nThis avoids the pushout effect of random matrix theory, and delays the point at\nwhich the planting becomes visible in the spectrum or local statistics. To\nillustrate this further, we give similar results for a Gaussian analogue of\nthis problem: a quiet version of the spiked model, where we plant an eigenspace\nrather than adding a generic low-rank perturbation.\n  Our evidence for computational hardness of distinguishing two distributions\nis based on three different heuristics: stability of belief propagation, the\nlocal statistics hierarchy, and the low-degree likelihood ratio. Of independent\ninterest, our results include general-purpose bounds on the low-degree\nlikelihood ratio for multi-spiked matrix models, and an improved low-degree\nanalysis of the stochastic block model.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:35:57 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Bandeira", "Afonso S.", ""], ["Banks", "Jess", ""], ["Kunisky", "Dmitriy", ""], ["Moore", "Cristopher", ""], ["Wein", "Alexander S.", ""]]}, {"id": "2008.12727", "submitter": "Lasse Wulf", "authors": "Marc Goerigk, Stefan Lendl, Lasse Wulf", "title": "Recoverable Robust Representatives Selection Problems with Discrete\n  Budgeted Uncertainty", "comments": "v2: Added hardness of recoverable and two-stage selection (K=1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recoverable robust optimization is a multi-stage approach, where it is\npossible to adjust a first-stage solution after the uncertain cost scenario is\nrevealed. We analyze this approach for a class of selection problems. The aim\nis to choose a fixed number of items from several disjoint sets, such that the\nworst-case costs after taking a recovery action are as small as possible. The\nuncertainty is modeled as a discrete budgeted set, where the adversary can\nincrease the costs of a fixed number of items. While special cases of this\nproblem have been studied before, its complexity has remained open. In this\nwork we make several contributions towards closing this gap. We show that the\nproblem is NP-hard and identify a special case that remains solvable in\npolynomial time. We provide a compact mixed-integer programming formulation and\ntwo additional extended formulations. Finally, computational results are\nprovided that compare the efficiency of different exact solution approaches.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 16:30:24 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 12:39:11 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Goerigk", "Marc", ""], ["Lendl", "Stefan", ""], ["Wulf", "Lasse", ""]]}, {"id": "2008.12825", "submitter": "Jay Mardia", "authors": "Jay Mardia", "title": "Is the space complexity of planted clique recovery the same as that of\n  detection?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the planted clique problem in which a clique of size k is planted in\nan Erd\\H{o}s-R\\'enyi graph G(n, 1/2), and one is interested in either detecting\nor recovering this planted clique. This problem is interesting because it is\nwidely believed to show a statistical-computational gap at clique size\nk=sqrt{n}, and has emerged as the prototypical problem with such a gap from\nwhich average-case hardness of other statistical problems can be deduced. It\nalso displays a tight computational connection between the detection and\nrecovery variants, unlike other problems of a similar nature. This wide\ninvestigation into the computational complexity of the planted clique problem\nhas, however, mostly focused on its time complexity. In this work, we ask-\n  Do the statistical-computational phenomena that make the planted clique an\ninteresting problem also hold when we use `space efficiency' as our notion of\ncomputational efficiency?\n  It is relatively easy to show that a positive answer to this question depends\non the existence of a O(log n) space algorithm that can recover planted cliques\nof size k = Omega(sqrt{n}). Our main result comes very close to designing such\nan algorithm. We show that for k=Omega(sqrt{n}), the recovery problem can be\nsolved in O((log*{n}-log*{k/sqrt{n}}) log n) bits of space.\n  1. If k = omega(sqrt{n}log^{(l)}n) for any constant integer l > 0, the space\nusage is O(log n) bits.\n  2.If k = Theta(sqrt{n}), the space usage is O(log*{n} log n) bits.\n  Our result suggests that there does exist an O(log n) space algorithm to\nrecover cliques of size k = Omega(sqrt{n}), since we come very close to\nachieving such parameters. This provides evidence that the\nstatistical-computational phenomena that (conjecturally) hold for planted\nclique time complexity also (conjecturally) hold for space complexity.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:49:42 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 23:44:57 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mardia", "Jay", ""]]}, {"id": "2008.12928", "submitter": "Alexandra Lassota", "authors": "Klaus Jansen, Kim-Manuel Klein, Alexandra Lassota", "title": "The Double Exponential Runtime is Tight for 2-Stage Stochastic ILPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider fundamental algorithmic number theoretic problems and their\nrelation to a class of block structured Integer Linear Programs (ILPs) called\n$2$-stage stochastic. A $2$-stage stochastic ILP is an integer program of the\nform $\\min \\{c^T x \\mid \\mathcal{A} x = b, \\ell \\leq x \\leq u, x \\in\n\\mathbb{Z}^{r + ns} \\}$ where the constraint matrix $\\mathcal{A} \\in\n\\mathbb{Z}^{nt \\times r +ns}$ consists of $n$ matrices $A_i \\in \\mathbb{Z}^{t\n\\times r}$ on the vertical line and $n$ matrices $B_i \\in \\mathbb{Z}^{t \\times\ns}$ on the diagonal line aside.\n  First, we show a stronger hardness result for a number theoretic problem\ncalled Quadratic Congruences where the objective is to compute a number $z \\leq\n\\gamma$ satisfying $z^2 \\equiv \\alpha \\bmod \\beta$ for given $\\alpha, \\beta,\n\\gamma \\in \\mathbb{Z}$. This problem was proven to be NP-hard already in 1978\nby Manders and Adleman. However, this hardness only applies for instances where\nthe prime factorization of $\\beta$ admits large multiplicities of each prime\nnumber. We circumvent this necessity proving that the problem remains NP-hard,\neven if each prime number only occurs constantly often.\n  Then, using this new hardness result for the Quadratic Congruences problem,\nwe prove a lower bound of $2^{2^{\\delta(s+t)}} |I|^{O(1)}$ for some $\\delta >\n0$ for the running time of any algorithm solving $2$-stage stochastic ILPs\nassuming the Exponential Time Hypothesis (ETH). Here, $|I|$ is the encoding\nlength of the instance. This result even holds if $r$, $||b||_{\\infty}$,\n$||c||_{\\infty}, ||\\ell||_{\\infty}$ and the largest absolute value $\\Delta$ in\nthe constraint matrix $\\mathcal{A}$ are constant. This shows that the\nstate-of-the-art algorithms are nearly tight. Further, it proves the suspicion\nthat these ILPs are indeed harder to solve than the closely related $n$-fold\nILPs where the contraint matrix is the transpose of $\\mathcal A$.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 07:35:24 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 07:31:18 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 09:33:43 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Jansen", "Klaus", ""], ["Klein", "Kim-Manuel", ""], ["Lassota", "Alexandra", ""]]}, {"id": "2008.13491", "submitter": "Arti Pandey", "authors": "Michael A. Henning, Arti Pandey, Vikash Tripathi", "title": "Semipaired Domination in Some Subclasses of Chordal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dominating set $D$ of a graph $G$ without isolated vertices is called\nsemipaired dominating set if $D$ can be partitioned into $2$-element subsets\nsuch that the vertices in each set are at distance at most $2$. The semipaired\ndomination number, denoted by $\\gamma_{pr2}(G)$ is the minimum cardinality of a\nsemipaired dominating set of $G$. Given a graph $G$ with no isolated vertices,\nthe \\textsc{Minimum Semipaired Domination} problem is to find a semipaired\ndominating set of $G$ of cardinality $\\gamma_{pr2}(G)$. The decision version of\nthe \\textsc{Minimum Semipaired Domination} problem is already known to be\nNP-complete for chordal graphs, an important graph class. In this paper, we\nshow that the decision version of the \\textsc{Minimum Semipaired Domination}\nproblem remains NP-complete for split graphs, a subclass of chordal graphs. On\nthe positive side, we propose a linear-time algorithm to compute a minimum\ncardinality semipaired dominating set of block graphs. In addition, we prove\nthat the \\textsc{Minimum Semipaired Domination} problem is APX-complete for\ngraphs with maximum degree $3$.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 11:07:51 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 09:15:46 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 11:21:36 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Henning", "Michael A.", ""], ["Pandey", "Arti", ""], ["Tripathi", "Vikash", ""]]}, {"id": "2008.13648", "submitter": "Daniel Kline", "authors": "Calin Chindris, Daniel Kline", "title": "Edmonds' problem and the membership problem for orbit semigroups of\n  quiver representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in algebraic complexity, posed by J. Edmonds, asks to\ndecide if the span of a given $l$-tuple $\\V=(\\V_1, \\ldots, \\V_l)$ of $N \\times\nN$ complex matrices contains a non-singular matrix.\n  In this paper, we provide a quiver invariant theoretic approach to this\nproblem. Viewing $\\V$ as a representation of the $l$-Kronecker quiver $\\K_l$,\nEdmonds' problem can be rephrased as asking to decide if there exists a\nsemi-invariant on the representation space $(\\CC^{N\\times N})^l$ of weight\n$(1,-1)$ that does not vanish at $\\V$. In other words, Edmonds' problem is\nasking to decide if the weight $(1,-1)$ belongs to the orbit semigroup of $\\V$.\n  Let $Q$ be an arbitrary acyclic quiver and $\\V$ a representation of $Q$. We\nstudy the membership problem for the orbit semi-group of $\\V$ by focusing on\nthe so-called $\\V$-saturated weights. We first show that for any given\n$\\V$-saturated weight $\\sigma$, checking if $\\sigma$ belongs to the orbit\nsemigroup of $\\V$ can be done in deterministic polynomial time.\n  Next, let $(Q, \\R)$ be an acyclic bound quiver with bound quiver algebra\n$A=KQ/\\langle \\R \\rangle$ and assume that $\\V$ satisfies the relations in $\\R$.\nWe show that if $A/\\Ann_A(\\V)$ is a tame algebra then any weight $\\sigma$ in\nthe weight semigroup of $\\V$ is $\\V$-saturated.\n  Our results provide a systematic way of producing families of tuples of\nmatrices for which Edmonds' problem can be solved effectively.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:36:34 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chindris", "Calin", ""], ["Kline", "Daniel", ""]]}]