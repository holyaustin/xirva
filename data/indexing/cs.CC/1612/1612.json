[{"id": "1612.00143", "submitter": "Neil Lutz", "authors": "Neil Lutz, D. M. Stull", "title": "Bounding the Dimension of Points on a Line", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Kolmogorov complexity methods to give a lower bound on the effective\nHausdorff dimension of the point (x, ax+b), given real numbers a, b, and x. We\napply our main theorem to a problem in fractal geometry, giving an improved\nlower bound on the (classical) Hausdorff dimension of generalized sets of\nFurstenberg type.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 04:57:37 GMT"}, {"version": "v2", "created": "Sat, 14 Jan 2017 13:39:22 GMT"}, {"version": "v3", "created": "Thu, 6 Apr 2017 01:52:28 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Lutz", "Neil", ""], ["Stull", "D. M.", ""]]}, {"id": "1612.00675", "submitter": "Johannes Schmidt", "authors": "Johannes Schmidt", "title": "The Weight in Enumeration", "comments": "12 main pages + 5 appendix pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our setting enumeration amounts to generate all solutions of a problem\ninstance without duplicates. We address the problem of enumerating the models\nof B-formulae. A B-formula is a propositional formula whose connectives are\ntaken from a fixed set B of Boolean connectives. Without imposing any specific\norder to output the solutions, this task is solved. We completely classify the\ncomplexity of this enumeration task for all possible sets of connectives B\nimposing the orders of (1) non-decreasing weight, (2) non-increasing weight;\nthe weight of a model being the number of variables assigned to 1. We consider\nalso the weighted variants where a non-negative integer weight is assigned to\neach variable and show that this add-on leads to more sophisticated enumeration\nalgorithms and even renders previously tractable cases intractable, contrarily\nto the constraint setting. As a by-product we obtain complete complexity\nclassifications for the optimization problems known as Min-Ones and Max-Ones\nwhich are in the B-formula setting two different tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 13:32:41 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Schmidt", "Johannes", ""]]}, {"id": "1612.01041", "submitter": "Pritish Kamath", "authors": "Mohammad Bavarian, Badih Ghazi, Elad Haramaty, Pritish Kamath, Ronald\n  L. Rivest, Madhu Sudan", "title": "Optimality of Correlated Sampling Strategies", "comments": "12 pages; Improved presentation (again) based on feedback from\n  anonymous ToC reviewers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the \"correlated sampling\" problem, two players are given probability\ndistributions $P$ and $Q$, respectively, over the same finite set, with access\nto shared randomness. Without any communication, the two players are each\nrequired to output an element sampled according to their respective\ndistributions, while trying to minimize the probability that their outputs\ndisagree. A well known strategy due to Kleinberg-Tardos and Holenstein, with a\nclose variant (for a similar problem) due to Broder, solves this task with\ndisagreement probability at most $2 \\delta/(1+\\delta)$, where $\\delta$ is the\ntotal variation distance between $P$ and $Q$. This strategy has been used in\nseveral different contexts, including sketching algorithms, approximation\nalgorithms based on rounding linear programming relaxations, the study of\nparallel repetition and cryptography.\n  In this paper, we give a surprisingly simple proof that this strategy is\nessentially optimal. Specifically, for every $\\delta \\in (0,1)$, we show that\nany correlated sampling strategy incurs a disagreement probability of\nessentially $2\\delta/(1+\\delta)$ on some inputs $P$ and $Q$ with total\nvariation distance at most $\\delta$. This partially answers a recent question\nof Rivest.\n  Our proof is based on studying a new problem that we call \"constrained\nagreement\". Here, the two players are given subsets $A \\subseteq [n]$ and $B\n\\subseteq [n]$, respectively, and their goal is to output an element $i \\in A$\nand $j \\in B$, respectively, while minimizing the probability that $i \\neq j$.\nWe prove tight bounds for this question, which in turn imply tight bounds for\ncorrelated sampling. Though we settle basic questions about the two problems,\nour formulation leads to more fine-grained questions that remain open.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 00:26:39 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 22:52:50 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2020 04:19:00 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bavarian", "Mohammad", ""], ["Ghazi", "Badih", ""], ["Haramaty", "Elad", ""], ["Kamath", "Pritish", ""], ["Rivest", "Ronald L.", ""], ["Sudan", "Madhu", ""]]}, {"id": "1612.01147", "submitter": "Stanislav Zivny", "authors": "Johan Thapper, Stanislav Zivny", "title": "The limits of SDP relaxations for general-valued CSPs", "comments": "Full version of a LICS'17 paper. Builds on and extends\n  arXiv:1606.02577. arXiv admin note: text overlap with arXiv:1606.02577", "journal-ref": "ACM Transactions on Computation Theory 10(3) Article no. 12 (2018)", "doi": "10.1145/3201777", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that for a general-valued constraint language $\\Gamma$ the\nfollowing statements are equivalent: (1) any instance of\n$\\operatorname{VCSP}(\\Gamma)$ can be solved to optimality using a constant\nlevel of the Sherali-Adams LP hierarchy; (2) any instance of\n$\\operatorname{VCSP}(\\Gamma)$ can be solved to optimality using the third level\nof the Sherali-Adams LP hierarchy; (3) the support of $\\Gamma$ satisfies the\n\"bounded width condition\", i.e., it contains weak near-unanimity operations of\nall arities.\n  We show that if the support of $\\Gamma$ violates the bounded width condition\nthen not only is $\\operatorname{VCSP}(\\Gamma)$ not solved by a constant level\nof the Sherali-Adams LP hierarchy but it is also not solved by $\\Omega(n)$\nlevels of the Lasserre SDP hierarchy (also known as the sum-of-squares SDP\nhierarchy). For $\\Gamma$ corresponding to linear equations in an Abelian group,\nthis result follows from existing work on inapproximability of Max-CSPs. By a\nbreakthrough result of Lee, Raghavendra, and Steurer [STOC'15], our result\nimplies that for any $\\Gamma$ whose support violates the bounded width\ncondition no SDP relaxation of polynomial-size solves\n$\\operatorname{VCSP}(\\Gamma)$.\n  We establish our result by proving that various reductions preserve exact\nsolvability by the Lasserre SDP hierarchy (up to a constant factor in the level\nof the hierarchy). Our results hold for general-valued constraint languages,\ni.e., sets of functions on a fixed finite domain that take on rational or\ninfinite values, and thus also hold in notable special cases of\n$\\{0,\\infty\\}$-valued languages (CSPs), $\\{0,1\\}$-valued languages\n(Min-CSPs/Max-CSPs), and $\\mathbb{Q}$-valued languages (finite-valued CSPs).\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 17:23:42 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 15:48:13 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 20:14:07 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Thapper", "Johan", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1612.01527", "submitter": "Joshua Grochow", "authors": "Joshua A. Grochow and Cristopher Moore", "title": "Matrix multiplication algorithms from group orbits", "comments": "Added transparent proof of Strassen's algorithm and its\n  generalization using lattices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.AG math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to construct highly symmetric algorithms for matrix\nmultiplication. In particular, we consider algorithms which decompose the\nmatrix multiplication tensor into a sum of rank-1 tensors, where the\ndecomposition itself consists of orbits under some finite group action. We show\nhow to use the representation theory of the corresponding group to derive\nsimple constraints on the decomposition, which we solve by hand for n=2,3,4,5,\nrecovering Strassen's algorithm (in a particularly symmetric form) and new\nalgorithms for larger n. While these new algorithms do not improve the known\nupper bounds on tensor rank or the matrix multiplication exponent, they are\nbeautiful in their own right, and we point out modifications of this idea that\ncould plausibly lead to further improvements. Our constructions also suggest\nfurther patterns that could be mined for new algorithms, including a\ntantalizing connection with lattices. In particular, using lattices we give the\nmost transparent proof to date of Strassen's algorithm; the same proof works\nfor all n, to yield a decomposition with $n^3 - n + 1$ terms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 21:00:02 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 20:13:02 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Grochow", "Joshua A.", ""], ["Moore", "Cristopher", ""]]}, {"id": "1612.01652", "submitter": "Hang Li", "authors": "Hang Li, Xun Gao, Tao Xin, Man-Hong Yung and Guilu Long", "title": "Experimental Study of Forrelation in Nuclear Spins", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlation functions are often employed to quantify the relationships among\ninterdependent variables or sets of data. Recently, a new class of correlation\nfunctions, called Forrelation, has been introduced by Aaronson and Ambainis for\nstudying the query complexity of quantum devices. It was found that there\nexists a quantum query algorithm solving 2-fold Forrelation problems with an\nexponential quantum speedup over all possible classical means, which represents\nessentially the largest possible separation between quantum and classical query\ncomplexities. Here we report an experimental study probing the 2-fold and\n3-fold Forrelations encoded in nuclear spins. The major experimental challenge\nis to control the spin fluctuation to within a threshold value, which is\nachieved by developing a set of optimized GRAPE pulse sequences. Overall, our\nsmall-scale implementation indicates that the quantum query algorithm is\ncapable of determine the values of Forrelations within an acceptable accuracy\nrequired for demonstrating quantum supremacy, given the current technology and\nin the presence of experimental noise.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 03:32:30 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Li", "Hang", ""], ["Gao", "Xun", ""], ["Xin", "Tao", ""], ["Yung", "Man-Hong", ""], ["Long", "Guilu", ""]]}, {"id": "1612.01659", "submitter": "Neil Lutz", "authors": "Neil Lutz", "title": "Fractal Intersections and Products via Algorithmic Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fractal dimensions quantify the algorithmic information density\nof individual points and may be defined in terms of Kolmogorov complexity. This\nwork uses these dimensions to bound the classical Hausdorff and packing\ndimensions of intersections and Cartesian products of fractals in Euclidean\nspaces. This approach shows that two prominent, fundamental results about the\ndimension of Borel or analytic sets also hold for arbitrary sets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 04:34:16 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2017 19:32:12 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 04:14:20 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 22:45:10 GMT"}, {"version": "v5", "created": "Tue, 5 Jan 2021 02:49:56 GMT"}, {"version": "v6", "created": "Mon, 1 Mar 2021 00:31:16 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Lutz", "Neil", ""]]}, {"id": "1612.01752", "submitter": "Sascha Brauer", "authors": "Sascha Brauer", "title": "Complexity of Single-Swap Heuristics for Metric Facility Location and\n  Related Problem", "comments": "This is a full version of the paper with the same name that will be\n  presented at CIAC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric facility location and $K$-means are well-known problems of\ncombinatorial optimization. Both admit a fairly simple heuristic called\nsingle-swap, which adds, drops or swaps open facilities until it reaches a\nlocal optimum. For both problems, it is known that this algorithm produces a\nsolution that is at most a constant factor worse than the respective global\noptimum. In this paper, we show that single-swap applied to the weighted metric\nuncapacitated facility location and weighted discrete $K$-means problem is\ntightly PLS-complete and hence has exponential worst-case running time.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 11:08:19 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2017 08:50:55 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Brauer", "Sascha", ""]]}, {"id": "1612.01817", "submitter": "Igor Carboni Oliveira", "authors": "Igor C. Oliveira, Rahul Santhanam", "title": "Pseudodeterministic Constructions in Subexponential Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS math.CO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pseudodeterministic constructions, i.e., randomized algorithms which\noutput the same solution on most computation paths. We establish\nunconditionally that there is an infinite sequence $\\{p_n\\}_{n \\in \\mathbb{N}}$\nof increasing primes and a randomized algorithm $A$ running in expected\nsub-exponential time such that for each $n$, on input $1^{|p_n|}$, $A$ outputs\n$p_n$ with probability $1$. In other words, our result provides a\npseudodeterministic construction of primes in sub-exponential time which works\ninfinitely often.\n  This result follows from a much more general theorem about\npseudodeterministic constructions. A property $Q \\subseteq \\{0,1\\}^{*}$ is\n$\\gamma$-dense if for large enough $n$, $|Q \\cap \\{0,1\\}^n| \\geq \\gamma 2^n$.\nWe show that for each $c > 0$ at least one of the following holds: (1) There is\na pseudodeterministic polynomial time construction of a family $\\{H_n\\}$ of\nsets, $H_n \\subseteq \\{0,1\\}^n$, such that for each $(1/n^c)$-dense property $Q\n\\in \\mathsf{DTIME}(n^c)$ and every large enough $n$, $H_n \\cap Q \\neq\n\\emptyset$; or (2) There is a deterministic sub-exponential time construction\nof a family $\\{H'_n\\}$ of sets, $H'_n \\subseteq \\{0,1\\}^n$, such that for each\n$(1/n^c)$-dense property $Q \\in \\mathsf{DTIME}(n^c)$ and for infinitely many\nvalues of $n$, $H'_n \\cap Q \\neq \\emptyset$.\n  We provide further algorithmic applications that might be of independent\ninterest. Perhaps intriguingly, while our main results are unconditional, they\nhave a non-constructive element, arising from a sequence of applications of the\nhardness versus randomness paradigm.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 14:20:41 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Oliveira", "Igor C.", ""], ["Santhanam", "Rahul", ""]]}, {"id": "1612.02526", "submitter": "Vatsal Sharan", "authors": "Vatsal Sharan, Sham Kakade, Percy Liang, Gregory Valiant", "title": "Prediction with a Short Memory", "comments": "Updates for STOC camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting the next observation given a sequence\nof past observations, and consider the extent to which accurate prediction\nrequires complex algorithms that explicitly leverage long-range dependencies.\nPerhaps surprisingly, our positive results show that for a broad class of\nsequences, there is an algorithm that predicts well on average, and bases its\npredictions only on the most recent few observation together with a set of\nsimple summary statistics of the past observations. Specifically, we show that\nfor any distribution over observations, if the mutual information between past\nobservations and future observations is upper bounded by $I$, then a simple\nMarkov model over the most recent $I/\\epsilon$ observations obtains expected KL\nerror $\\epsilon$---and hence $\\ell_1$ error $\\sqrt{\\epsilon}$---with respect to\nthe optimal predictor that has access to the entire past and knows the data\ngenerating distribution. For a Hidden Markov Model with $n$ hidden states, $I$\nis bounded by $\\log n$, a quantity that does not depend on the mixing time, and\nwe show that the trivial prediction algorithm based on the empirical\nfrequencies of length $O(\\log n/\\epsilon)$ windows of observations achieves\nthis error, provided the length of the sequence is $d^{\\Omega(\\log\nn/\\epsilon)}$, where $d$ is the size of the observation alphabet.\n  We also establish that this result cannot be improved upon, even for the\nclass of HMMs, in the following two senses: First, for HMMs with $n$ hidden\nstates, a window length of $\\log n/\\epsilon$ is information-theoretically\nnecessary to achieve expected $\\ell_1$ error $\\sqrt{\\epsilon}$. Second, the\n$d^{\\Theta(\\log n/\\epsilon)}$ samples required to estimate the Markov model for\nan observation alphabet of size $d$ is necessary for any computationally\ntractable learning algorithm, assuming the hardness of strongly refuting a\ncertain class of CSPs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 04:18:09 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 17:51:39 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 07:01:47 GMT"}, {"version": "v4", "created": "Sun, 27 May 2018 01:30:15 GMT"}, {"version": "v5", "created": "Thu, 28 Jun 2018 01:54:04 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Sharan", "Vatsal", ""], ["Kakade", "Sham", ""], ["Liang", "Percy", ""], ["Valiant", "Gregory", ""]]}, {"id": "1612.02788", "submitter": "Nikhil Vyas", "authors": "Nikhil Bansal, Shashwat Garg, Jesper Nederlof, Nikhil Vyas", "title": "Faster Space-Efficient Algorithms for Subset Sum, k-Sum and Related\n  Problems", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present space efficient Monte Carlo algorithms that solve Subset Sum and\nKnapsack instances with $n$ items using $O^*(2^{0.86n})$ time and polynomial\nspace, where the $O^*(\\cdot)$ notation suppresses factors polynomial in the\ninput size. Both algorithms assume random read-only access to random bits.\nModulo this mild assumption, this resolves a long-standing open problem in\nexact algorithms for NP-hard problems. These results can be extended to solve\nBinary Linear Programming on $n$ variables with few constraints in a similar\nrunning time. We also show that for any constant $k\\geq 2$, random instances of\n$k$-Sum can be solved using $O(n^{k-0.5}polylog(n))$ time and $O(\\log n)$\nspace, without the assumption of random access to random bits.\n  Underlying these results is an algorithm that determines whether two given\nlists of length $n$ with integers bounded by a polynomial in $n$ share a common\nvalue. Assuming random read-only access to random bits, we show that this\nproblem can be solved using $O(\\log n)$ space significantly faster than the\ntrivial $O(n^2)$ time algorithm if no value occurs too often in the same list.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 20:09:55 GMT"}, {"version": "v2", "created": "Sat, 24 Jun 2017 18:35:30 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Bansal", "Nikhil", ""], ["Garg", "Shashwat", ""], ["Nederlof", "Jesper", ""], ["Vyas", "Nikhil", ""]]}, {"id": "1612.02948", "submitter": "Ryo Yoshinaka", "authors": "Jun Kawahara, Toshiki Saitoh, and Ryo Yoshinaka", "title": "The Time Complexity of Permutation Routing via Matching, Token Swapping\n  and a Variant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problems of Permutation Routing via Matching and Token Swapping are\nreconfiguration problems on graphs. This paper is concerned with the complexity\nof those problems and a colored variant. For a given graph where each vertex\nhas a unique token on it, those problems require to find a shortest way to\nmodify a token placement into another by swapping tokens on adjacent vertices.\nWhile all pairs of tokens on a matching can be exchanged at once in Permutation\nRouting via Matching, Token Swapping allows only one pair of tokens can be\nswapped. In the colored version, vertices and tokens are colored and the goal\nis to relocate tokens so that each vertex has a token of the same color. We\ninvestigate the time complexity of several restricted cases of those problems\nand show when those problems become tractable and remain intractable.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 09:08:51 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 12:01:50 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Kawahara", "Jun", ""], ["Saitoh", "Toshiki", ""], ["Yoshinaka", "Ryo", ""]]}, {"id": "1612.03086", "submitter": "Prahladh Harsha", "authors": "Prahladh Harsha and Srikanth Srinivasan", "title": "Robust Multiplication-based Tests for Reed-Muller Codes", "comments": null, "journal-ref": "IEEE Transactions on Information Theory, 65(1):184-197, 2019", "doi": "10.1109/TIT.2018.2863713", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following multiplication-based tests to check if a given\nfunction $f: \\mathbb{F}_q^n\\to \\mathbb{F}_q$ is a codeword of the Reed-Muller\ncode of dimension $n$ and order $d$ over the finite field $\\mathbb{F}_q$ for\nprime $q$ (i.e., $f$ is the evaluation of a degree-$d$ polynomial over\n$\\mathbb{F}_q$ for $q$ prime).\n  * $\\mathrm{Test}_{e,k}$: Pick $P_1,\\ldots,P_k$ independent random degree-$e$\npolynomials and accept iff the function $fP_1\\cdots P_k$ is the evaluation of a\ndegree-$(d+ek)$ polynomial (i.e., is a codeword of the Reed-Muller code of\ndimension $n$ and order $(d+ek)$).\n  We prove the robust soundness of the above tests for large values of $e$,\nanswering a question of Dinur and Guruswami [Israel Journal of Mathematics,\n209:611-649, 2015]. Previous soundness analyses of these tests were known only\nfor the case when either $e=1$ or $k=1$. Even for the case $k=1$ and $e>1$,\nearlier soundness analyses were not robust.\n  We also analyze a derandomized version of this test, where (for example) the\npolynomials $P_1,\\dots,P_k$ can be the same random polynomial $P$. This\ngeneralizes a result of Guruswami et al. [SIAM J. Comput., 46(1):132-159,\n2017].\n  One of the key ingredients that go into the proof of this robust soundness is\nan extension of the standard Schwartz-Zippel lemma over general finite fields\n$\\mathbb{F}_q$, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 17:02:11 GMT"}, {"version": "v2", "created": "Tue, 20 Dec 2016 14:18:25 GMT"}, {"version": "v3", "created": "Wed, 19 Apr 2017 19:09:08 GMT"}, {"version": "v4", "created": "Mon, 6 Aug 2018 17:47:15 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Harsha", "Prahladh", ""], ["Srinivasan", "Srikanth", ""]]}, {"id": "1612.03097", "submitter": "Rahil Sharma", "authors": "Rahil Sharma", "title": "Hard Capacitated Set Cover and Uncapacitated Geometric Set Cover", "comments": "This report has original work mentioned in Section 2.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first part of this report describes the following result that,\nlogarithmic approximation factor for hard capacitated set cover can be achieved\nfrom Wolsey's work [9], using a simpler and more intuitive analysis. We further\nshow in our work, that O(log n) approximation factor can be achieved for the\nsame problem by applying analysis of general set cover to analyze Wolsey's\nalgorithm [5]. This work is based on the key observation that we make in Lemma\n3 of this report. The second part of the report describes the geometric hitting\nset problem, where X is a ground set of points in a plane and S is a set of\naxis parallel rectangles. It is shown that epsilon-nets of size O(1/epsilon log\nlog 1/epsilon) can be computed in polynomial time. Applying Bronnimann and\nGoodrich result [3] gives the hitting set of size O(log log OPT) for this\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 04:54:25 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Sharma", "Rahil", ""]]}, {"id": "1612.03148", "submitter": "Anindya De", "authors": "Anindya De and Ryan O'Donnell and Rocco Servedio", "title": "Optimal mean-based algorithms for trace reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the (deletion-channel) trace reconstruction problem, there is an unknown\n$n$-bit source string $x$. An algorithm is given access to independent traces\nof $x$, where a trace is formed by deleting each bit of~$x$ independently with\nprobability~$\\delta$. The goal of the algorithm is to recover~$x$ exactly (with\nhigh probability), while minimizing samples (number of traces) and running\ntime.\n  Previously, the best known algorithm for the trace reconstruction problem was\ndue to Holenstein~et~al.; it uses $\\exp(\\tilde{O}(n^{1/2}))$ samples and\nrunning time for any fixed $0 < \\delta < 1$. It is also what we call a\n\"mean-based algorithm\", meaning that it only uses the empirical means of the\nindividual bits of the traces. Holenstein~et~al.~also gave a lower bound,\nshowing that any mean-based algorithm must use at least $n^{\\tilde{\\Omega}(\\log\nn)}$ samples.\n  In this paper we improve both of these results, obtaining matching upper and\nlower bounds for mean-based trace reconstruction. For any constant deletion\nrate $0 < \\delta < 1$, we give a mean-based algorithm that uses\n$\\exp(O(n^{1/3}))$ time and traces; we also prove that any mean-based algorithm\nmust use at least $\\exp(\\Omega(n^{1/3}))$ traces. In fact, we obtain matching\nupper and lower bounds even for $\\delta$ subconstant and $\\rho := 1-\\delta$\nsubconstant: when $(\\log^3 n)/n \\ll \\delta \\leq 1/2$ the bound is\n$\\exp(-\\Theta(\\delta n)^{1/3})$, and when $1/\\sqrt{n} \\ll \\rho \\leq 1/2$ the\nbound is $\\exp(-\\Theta(n/\\rho)^{1/3})$.\n  Our proofs involve estimates for the maxima of Littlewood polynomials on\ncomplex disks. We show that these techniques can also be used to perform trace\nreconstruction with random insertions and bit-flips in addition to deletions.\nWe also find a surprising result: for deletion probabilities $\\delta > 1/2$,\nthe presence of insertions can actually help with trace reconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 20:05:19 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["De", "Anindya", ""], ["O'Donnell", "Ryan", ""], ["Servedio", "Rocco", ""]]}, {"id": "1612.03638", "submitter": "Tillmann Miltzow", "authors": "Jean Cardinal and Stefan Felsner and Tillmann Miltzow and Casey\n  Tompkins and Birgit Vogtenhuber", "title": "Intersection Graphs of Rays and Grounded Segments", "comments": "16 pages 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several classes of intersection graphs of line segments in the\nplane and prove new equality and separation results between those classes. In\nparticular, we show that: (1) intersection graphs of grounded segments and\nintersection graphs of downward rays form the same graph class, (2) not every\nintersection graph of rays is an intersection graph of downward rays, and (3)\nnot every intersection graph of rays is an outer segment graph. The first\nresult answers an open problem posed by Cabello and Jej\\v{c}i\\v{c}. The third\nresult confirms a conjecture by Cabello. We thereby completely elucidate the\nremaining open questions on the containment relations between these classes of\nsegment graphs. We further characterize the complexity of the recognition\nproblems for the classes of outer segment, grounded segment, and ray\nintersection graphs. We prove that these recognition problems are complete for\nthe existential theory of the reals. This holds even if a 1-string realization\nis given as additional input.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 12:10:02 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Cardinal", "Jean", ""], ["Felsner", "Stefan", ""], ["Miltzow", "Tillmann", ""], ["Tompkins", "Casey", ""], ["Vogtenhuber", "Birgit", ""]]}, {"id": "1612.04338", "submitter": "Daniel \\v{S}tefankovi\\v{c}", "authors": "Marcus Schaefer and Daniel Stefankovic", "title": "The Complexity of Tensor Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that determining the rank of a tensor over a field has the same\ncomplexity as deciding the existential theory of that field. This implies\nearlier NP-hardness results by H{\\aa}stad~\\cite{H90}. The hardness proof also\nimplies an algebraic universality result.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 20:12:03 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Schaefer", "Marcus", ""], ["Stefankovic", "Daniel", ""]]}, {"id": "1612.04914", "submitter": "Tommaso Federico Demarie Dr", "authors": "Tommaso F. Demarie and Yingkai Ouyang and Joseph F. Fitzsimons", "title": "Classical verification of quantum circuits containing few basis changes", "comments": "5 pages, comments welcome!", "journal-ref": "Phys. Rev. A 97, 042319 (2018)", "doi": "10.1103/PhysRevA.97.042319", "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of verifying the correctness of quantum computation for\na restricted class of circuits which contain at most two basis changes. This\ncontains circuits giving rise to the second level of the Fourier Hierarchy, the\nlowest level for which there is an established quantum advantage. We show that,\nwhen the circuit has an outcome with probability at least the inverse of some\npolynomial in the circuit size, the outcome can be checked in polynomial time\nwith bounded error by a completely classical verifier. This verification\nprocedure is based on random sampling of computational paths and is only\npossible given knowledge of the likely outcome.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 03:24:33 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Demarie", "Tommaso F.", ""], ["Ouyang", "Yingkai", ""], ["Fitzsimons", "Joseph F.", ""]]}, {"id": "1612.05221", "submitter": "Felipe Abrah\\~ao", "authors": "Felipe S. Abrah\\~ao (National Laboratory for Scientific Computing\n  (LNCC), Brazil)", "title": "Relativizing an incompressible number and an incompressible function\n  through subrecursive extensions of Turing machines", "comments": "22 pages 0 figures Submitted to Information Sciences journal\n  (Elsevier)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show in this article that uncomputability is also a relative property of\nsubrecursive classes built on a recursive relative incompressible function,\nwhich acts as a higher-order \"yardstick\" of irreducible information for the\nrespective subrecursive class. We define the concept of a Turing submachine,\nand a recursive relative version for the Busy Beaver function and for the\nhalting probability (or Chaitin's constant) Omega; respectively the Busy Beaver\nPlus (BBP) function and a time-bounded halting probability. Therefore, we prove\nthat the computable BBP function defined on any Turing submachine is neither\ncomputable nor compressible by any program running on this submachine. In\naddition, we build a Turing submachine that can use lower approximations to its\nown time-bounded halting probability to calculate the values of its Busy Beaver\nPlus function, in the \"same\" manner that universal Turing machines use\napproximations to Omega to calculate Busy Beaver values. Thus, the algorithmic\ninformation carried by the BBP function is relatively incompressible (and\nuncomputable) at the same time that it still is occasionally reached by\nsubmachines. We point that this phenomenon enriches the research on the\nrelativization and simulation of uncomputability and irreducible information.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 20:15:58 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Abrah\u00e3o", "Felipe S.", "", "National Laboratory for Scientific Computing"]]}, {"id": "1612.05602", "submitter": "David Gosset", "authors": "Sergey Bravyi, David Gosset", "title": "Polynomial-time classical simulation of quantum ferromagnets", "comments": null, "journal-ref": "Phys. Rev. Lett. 119, 100503 (2017)", "doi": "10.1103/PhysRevLett.119.100503", "report-no": null, "categories": "quant-ph cond-mat.str-el cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a family of quantum spin systems which includes as special cases\nthe ferromagnetic XY model and ferromagnetic Ising model on any graph, with or\nwithout a transverse magnetic field. We prove that the partition function of\nany model in this family can be efficiently approximated to a given relative\nerror E using a classical randomized algorithm with runtime polynomial in 1/E,\nsystem size, and inverse temperature. As a consequence we obtain a polynomial\ntime algorithm which approximates the free energy or ground energy to a given\nadditive error. We first show how to approximate the partition function by the\nperfect matching sum of a finite graph with positive edge weights. Although the\nperfect matching sum is not known to be efficiently approximable in general,\nthe graphs obtained by our method have a special structure which facilitates\nefficient approximation via a randomized algorithm due to Jerrum and Sinclair.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 19:23:49 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Bravyi", "Sergey", ""], ["Gosset", "David", ""]]}, {"id": "1612.05832", "submitter": "Leslie Ann Goldberg", "authors": "Andreas Galanis, Leslie Ann Goldberg, Daniel Stefankovic", "title": "Implementations and the independent set polynomial below the Shearer\n  threshold", "comments": "Updated to clarify the contribution, in particular that it is used by\n  arXiv:1711.00282 (and is not superseded by it)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The independent set polynomial is important in many areas. For every integer\n$\\Delta\\geq 2$, the Shearer threshold is the value\n$\\lambda^*(\\Delta)=(\\Delta-1)^{\\Delta-1}/\\Delta^{\\Delta}$ . It is known that\nfor $\\lambda < - \\lambda^*(\\Delta)$, there are graphs~$G$ with maximum\ndegree~$\\Delta$ whose independent set polynomial, evaluated at~$\\lambda$, is at\nmost~$0$. Also, there are no such graphs for any $\\lambda >\n-\\lambda^*(\\Delta)$. This paper is motivated by the computational problem of\napproximating the independent set polynomial when $\\lambda < -\n\\lambda^*(\\Delta)$. The key issue in complexity bounds for this problem is\n\"implementation\". Informally, an implementation of a real number $\\lambda'$ is\na graph whose hard-core partition function, evaluated at~$\\lambda$, simulates a\nvertex-weight of~$\\lambda'$ in the sense that $\\lambda'$ is the ratio between\nthe contribution to the partition function from independent sets containing a\ncertain vertex and the contribution from independent sets that do not contain\nthat vertex. Implementations are the cornerstone of intractability results for\nthe problem of approximately evaluating the independent set polynomial. Our\nmain result is that, for any $\\lambda < - \\lambda^*(\\Delta)$, it is possible to\nimplement a set of values that is dense over the reals. The result is tight in\nthe sense that it is not possible to implement a set of values that is dense\nover the reals for any $\\lambda> \\lambda^*(\\Delta)$. Our result has already\nbeen used in a paper with \\bezakova{} (STOC 2018) to show that it is \\#P-hard\nto approximate the evaluation of the independent set polynomial on graphs of\ndegree at most~$\\Delta$ at any value $\\lambda<-\\lambda^*(\\Delta)$. In the\nappendix, we give an additional incomparable inapproximability result\n(strengthening the inapproximability bound to an exponential factor, but\nweakening the hardness to NP-hardness).\n", "versions": [{"version": "v1", "created": "Sat, 17 Dec 2016 22:33:15 GMT"}, {"version": "v2", "created": "Tue, 25 Apr 2017 17:36:52 GMT"}, {"version": "v3", "created": "Wed, 21 Jun 2017 16:22:35 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 08:47:57 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Galanis", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Stefankovic", "Daniel", ""]]}, {"id": "1612.05849", "submitter": "Neil Lutz", "authors": "Neil Lutz", "title": "A Note on Pointwise Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note describes a connection between algorithmic dimensions of\nindividual points and classical pointwise dimensions of measures.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 03:07:35 GMT"}, {"version": "v2", "created": "Wed, 5 Apr 2017 02:35:19 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Lutz", "Neil", ""]]}, {"id": "1612.05903", "submitter": "Lijie Chen", "authors": "Scott Aaronson, Lijie Chen", "title": "Complexity-Theoretic Foundations of Quantum Supremacy Experiments", "comments": "abstract shortened to meet the constraint", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the near future, there will likely be special-purpose quantum computers\nwith 40-50 high-quality qubits. This paper lays general theoretical foundations\nfor how to use such devices to demonstrate \"quantum supremacy\": that is, a\nclear quantum speedup for some task, motivated by the goal of overturning the\nExtended Church-Turing Thesis as confidently as possible. First, we study the\nhardness of sampling the output distribution of a random quantum circuit, along\nthe lines of a recent proposal by the the Quantum AI group at Google. We show\nthat there's a natural hardness assumption, which has nothing to do with\nsampling, yet implies that no efficient classical algorithm can pass a\nstatistical test that the quantum sampling procedure's outputs do pass.\nCompared to previous work, the central advantage is that we can now talk\ndirectly about the observed outputs, rather than about the distribution being\nsampled. Second, in an attempt to refute our hardness assumption, we give a new\nalgorithm, for simulating a general quantum circuit with n qubits and m gates\nin polynomial space and m^O(n) time. We then discuss why this and other known\nalgorithms fail to refute our assumption. Third, resolving an open problem of\nAaronson and Arkhipov, we show that any strong quantum supremacy theorem--of\nthe form \"if approximate quantum sampling is classically easy, then PH\ncollapses\"--must be non-relativizing. Fourth, refuting a conjecture by Aaronson\nand Ambainis, we show that the Fourier Sampling problem achieves a constant\nversus linear separation between quantum and randomized query complexities.\nFifth, we study quantum supremacy relative to oracles in P/poly. Previous work\nimplies that, if OWFs exist, then quantum supremacy is possible relative to\nsuch oracles. We show that some assumption is needed: if SampBPP=SampBQP and NP\nis in BPP, then quantum supremacy is impossible relative to such oracles.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 12:18:32 GMT"}, {"version": "v2", "created": "Mon, 26 Dec 2016 18:48:10 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Aaronson", "Scott", ""], ["Chen", "Lijie", ""]]}, {"id": "1612.05954", "submitter": "Armin Wei{\\ss}", "authors": "Alexei Miasnikov and Svetla Vassileva and Armin Wei{\\ss}", "title": "The conjugacy problem in free solvable groups and wreath product of\n  abelian groups is in TC$^0$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the conjugacy problem in a wreath product $A \\wr B$ is\nuniform-$\\mathsf{TC}^0$-Turing-reducible to the conjugacy problem in the\nfactors $A$ and $B$ and the power problem in $B$. If $B$ is torsion free, the\npower problem for $B$ can be replaced by the slightly weaker cyclic submonoid\nmembership problem for $B$. Moreover, if $A$ is abelian, the cyclic subgroup\nmembership problem suffices, which itself is\nuniform-$\\mathsf{AC}^0$-many-one-reducible to the conjugacy problem in $A \\wr\nB$.\n  Furthermore, under certain natural conditions, we give a uniform\n$\\mathsf{TC}^0$ Turing reduction from the power problem in $A \\wr B$ to the\npower problems of $A$ and $B$. Together with our first result, this yields a\nuniform $\\mathsf{TC}^0$ solution to the conjugacy problem in iterated wreath\nproducts of abelian groups - and, by the Magnus embedding, also in free\nsolvable groups.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 17:21:44 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 09:12:08 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Miasnikov", "Alexei", ""], ["Vassileva", "Svetla", ""], ["Wei\u00df", "Armin", ""]]}, {"id": "1612.06057", "submitter": "Rameshwar Pratap", "authors": "Raghav Kulkarni, Rameshwar Pratap", "title": "Similarity preserving compressions of high dimensional sparse data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of internet has resulted in an explosion of data consisting of\nmillions of articles, images, songs, and videos. Most of this data is high\ndimensional and sparse. The need to perform an efficient search for similar\nobjects in such high dimensional big datasets is becoming increasingly common.\nEven with the rapid growth in computing power, the brute-force search for such\na task is impractical and at times impossible. Therefore it is quite natural to\ninvestigate the techniques that compress the dimension of the data-set while\npreserving the similarity between data objects.\n  In this work, we propose an efficient compression scheme mapping binary\nvectors into binary vectors and simultaneously preserving Hamming distance and\nInner Product. The length of our compression depends only on the sparsity and\nis independent of the dimension of the data. Moreover our schemes provide\none-shot solution for Hamming distance and Inner Product, and work in the\nstreaming setting as well. In contrast with the \"local projection\" strategies\nused by most of the previous schemes, our scheme combines (using sparsity) the\nfollowing two strategies: $1.$ Partitioning the dimensions into several\nbuckets, $2.$ Then obtaining \"global linear summaries\" in each of these\nbuckets. We generalize our scheme for real-valued data and obtain compressions\nfor Euclidean distance, Inner Product, and $k$-way Inner Product.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 06:27:45 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Kulkarni", "Raghav", ""], ["Pratap", "Rameshwar", ""]]}, {"id": "1612.06092", "submitter": "Kamil Khadiev", "authors": "Kamil Khadiev", "title": "On the Hierarchies for Deterministic, Nondeterministic and Probabilistic\n  Ordered Read-k-times Branching Programs", "comments": "30 pages", "journal-ref": "Lobachevskii J Math (2016) 37: 683", "doi": "10.1134/S1995080216060159", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper examines hierarchies for nondeterministic and deterministic ordered\nread-$k$-times Branching programs. The currently known hierarchies for\ndeterministic $k$-OBDD models of Branching programs for $\nk=o(n^{1/2}/\\log^{3/2}n)$ are proved by B. Bollig, M. Sauerhoff, D. Sieling,\nand I. Wegener in 1998. Their lower bound technique was based on communication\ncomplexity approach. For nondeterministic $k$-OBDD it is known that, if $k$ is\nconstant then polynomial size $k$-OBDD computes same functions as polynomial\nsize OBDD (The result of Brosenne, Homeister and Waack, 2006). In the same time\ncurrently known hierarchies for nondeterministic read $k$-times Branching\nprograms for $k=o(\\sqrt{\\log{n}}/\\log\\log{n})$ are proved by Okolnishnikova in\n1997, and for probabilistic read $k$-times Branching programs for $k\\leq \\log\nn/3$ are proved by Hromkovic and Saurhoff in 2003.\n  We show that increasing $k$ for polynomial size nodeterministic $k$-OBDD\nmakes model more powerful if $k$ is not constant. Moreover, we extend the\nhierarchy for probabilistic and nondeterministic $k$-OBDDs for $ k=o(n/ \\log\nn)$. These results extends hierarchies for read $k$-times Branching programs,\nbut $k$-OBDD has more regular structure. The lower bound techniques we propose\nare a \"functional description\" of Boolean function presented by\nnondeterministic $k$-OBDD and communication complexity technique. We present\nsimilar hierarchies for superpolynomial and subexponential width\nnondeterministic $k$-OBDDs.\n  Additionally we expand the hierarchies for deterministic $k$-OBDDs using our\nlower bounds for $ k=o(n/ \\log n)$. We also analyze similar hierarchies for\nsuperpolynomial and subexponential width $k$-OBDDs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 09:46:44 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Khadiev", "Kamil", ""]]}, {"id": "1612.06335", "submitter": "Ray Li", "authors": "Venkatesan Guruswami and Ray Li", "title": "Coding against deletions in oblivious and online models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider binary error correcting codes when errors are deletions. A basic\nchallenge concerning deletion codes is determining $p_0^{(adv)}$, the zero-rate\nthreshold of adversarial deletions, defined to be the supremum of all $p$ for\nwhich there exists a code family with rate bounded away from 0 capable of\ncorrecting a fraction $p$ of adversarial deletions. A recent construction of\ndeletion-correcting codes [Bukh et al 17] shows that $p_0^{(adv)} \\ge\n\\sqrt{2}-1$, and the trivial upper bound, $p_0^{(adv)}\\le\\frac{1}{2}$, is the\nbest known. Perhaps surprisingly, we do not know whether or not $p_0^{(adv)} =\n1/2$.\n  In this work, to gain further insight into deletion codes, we explore two\nrelated error models: oblivious deletions and online deletions, which are in\nbetween random and adversarial deletions in power. In the oblivious model, the\nchannel can inflict an arbitrary pattern of $pn$ deletions, picked without\nknowledge of the codeword. We prove the existence of binary codes of positive\nrate that can correct any fraction $p < 1$ of oblivious deletions, establishing\nthat the associated zero-rate threshold $p_0^{(obliv)}$ equals $1$.\n  For online deletions, where the channel decides whether to delete bit $x_i$\nbased only on knowledge of bits $x_1x_2\\dots x_i$, define the deterministic\nzero-rate threshold for online deletions $p_0^{(on,d)}$ to be the supremum of\n$p$ for which there exist deterministic codes against an online channel causing\n$pn$ deletions with low average probability of error. That is, the probability\nthat a randomly chosen codeword is decoded incorrectly is small. We prove\n$p_0^{(adv)}=\\frac{1}{2}$ if and only if $p_0^{(on,d)}=\\frac{1}{2}$.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 20:36:01 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 15:49:00 GMT"}, {"version": "v3", "created": "Fri, 5 May 2017 17:23:00 GMT"}, {"version": "v4", "created": "Wed, 26 Jul 2017 02:39:04 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Li", "Ray", ""]]}, {"id": "1612.06419", "submitter": "J\\\"urgen Koslowski", "authors": "Florian Steinberg", "title": "Complexity theory for spaces of integrable functions", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  12, 2017) lmcs:3924", "doi": "10.23638/LMCS-13(3:21)2017", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates second-order representations in the sense of Kawamura\nand Cook for spaces of integrable functions that regularly show up in analysis.\nIt builds upon prior work about the space of continuous functions on the unit\ninterval: Kawamura and Cook introduced a representation inducing the right\ncomplexity classes and proved that it is the weakest second-order\nrepresentation such that evaluation is polynomial-time computable. The first\npart of this paper provides a similar representation for the space of\nintegrable functions on a bounded subset of Euclidean space: The weakest\nrepresentation rendering integration over boxes is polynomial-time computable.\nIn contrast to the representation of continuous functions, however, this\nrepresentation turns out to be discontinuous with respect to both the norm and\nthe weak topology. The second part modifies the representation to be continuous\nand generalizes it to Lp-spaces. The arising representations are proven to be\ncomputably equivalent to the standard representations of these spaces as metric\nspaces and to still render integration polynomial-time computable. The family\nis extended to cover Sobolev spaces on the unit interval, where less basic\noperations like differentiation and some Sobolev embeddings are shown to be\npolynomial-time computable. Finally as a further justification quantitative\nversions of the Arzel\\`a-Ascoli and Fr\\'echet-Kolmogorov Theorems are presented\nand used to argue that these representations fulfill a minimality condition. To\nprovide tight bounds for the Fr\\'echet-Kolmogorov Theorem, a form of\nexponential time computability of the norm of Lp is proven.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 21:26:22 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 17:05:15 GMT"}, {"version": "v3", "created": "Sat, 9 Sep 2017 13:02:34 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Steinberg", "Florian", ""]]}, {"id": "1612.06546", "submitter": "Ashley Montanaro", "authors": "Ashley Montanaro", "title": "Quantum states cannot be transmitted efficiently classically", "comments": "24 pages; v3: accepted version incorporating many minor corrections\n  and clarifications", "journal-ref": "Quantum 3, 154 (2019)", "doi": "10.22331/q-2019-06-28-154", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that any classical two-way communication protocol with shared\nrandomness that can approximately simulate the result of applying an arbitrary\nmeasurement (held by one party) to a quantum state of $n$ qubits (held by\nanother), up to constant accuracy, must transmit at least $\\Omega(2^n)$ bits.\nThis lower bound is optimal and matches the complexity of a simple protocol\nbased on discretisation using an $\\epsilon$-net. The proof is based on a lower\nbound on the classical communication complexity of a distributed variant of the\nFourier sampling problem. We obtain two optimal quantum-classical separations\nas easy corollaries. First, a sampling problem which can be solved with one\nquantum query to the input, but which requires $\\Omega(N)$ classical queries\nfor an input of size $N$. Second, a nonlocal task which can be solved using $n$\nBell pairs, but for which any approximate classical solution must communicate\n$\\Omega(2^n)$ bits.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 08:23:49 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 13:40:25 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 09:22:41 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Montanaro", "Ashley", ""]]}, {"id": "1612.07015", "submitter": "Abuzer Yakaryilmaz", "authors": "Aida Gainutdinova and Abuzer Yakary{\\i}lmaz", "title": "Nondeterministic unitary OBDDs", "comments": "16 pages!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the width complexity of nondeterministic unitary OBDDs\n(NUOBDDs). Firstly, we present a generic lower bound on their widths based on\nthe size of strong 1-fooling sets. Then, we present classically cheap functions\nthat are expensive for NUOBDDs and vice versa by improving the previous gap. We\nalso present a function for which neither classical nor unitary nondeterminism\ndoes help. Moreover, based on our results, we present a width hierarchy for\nNUOBDDs. Lastly, we provide the bounds on the widths of NUOBDDs for the basic\nBoolean operations negation, union, and intersection.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 08:58:16 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Gainutdinova", "Aida", ""], ["Yakary\u0131lmaz", "Abuzer", ""]]}, {"id": "1612.07162", "submitter": "Jakob Nordstr\\\"om", "authors": "Christoph Berkholz, Jakob Nordstr\\\"om", "title": "Supercritical Space-Width Trade-offs for Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there are CNF formulas which can be refuted in resolution in\nboth small space and small width, but for which any small-width proof must have\nspace exceeding by far the linear worst-case upper bound. This significantly\nstrengthens the space-width trade-offs in [Ben-Sasson '09]}, and provides one\nmore example of trade-offs in the \"supercritical\" regime above worst case\nrecently identified by [Razborov '16]. We obtain our results by using\nRazborov's new hardness condensation technique and combining it with the space\nlower bounds in [Ben-Sasson and Nordstrom '08].\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 15:02:45 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Berkholz", "Christoph", ""], ["Nordstr\u00f6m", "Jakob", ""]]}, {"id": "1612.07491", "submitter": "Irit Dinur", "authors": "Amey Bhangale, Irit Dinur, Inbal Livni Navon", "title": "Cube vs. Cube Low Degree Test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the Raz-Safra plane-vs.-plane test and study the closely related\ncube vs. cube test. In this test the tester has access to a \"cubes table\" which\nassigns to every cube a low degree polynomial. The tester randomly selects two\ncubes (affine sub-spaces of dimension $3$) that intersect on a point $x\\in\n\\mathbf{F}^m$, and checks that the assignments to the cubes agree with each\nother on the point $x$.\n  Our main result is a new combinatorial proof for a low degree test that comes\ncloser to the soundness limit, as it works for all $\\epsilon \\ge\npoly(d)/{\\mathbf{F}}^{1/2}$, where $d$ is the degree. This should be compared\nto the previously best soundness value of $\\epsilon \\ge poly(m,\nd)/\\mathbf{F}^{1/8}$. Our soundness limit improves upon the dependence on the\nfield size and does not depend on the dimension of the ambient space.\n  Our proof is combinatorial and direct: unlike the Raz-Safra proof, it\nproceeds in one shot and does not require induction on the dimension of the\nambient space. The ideas in our proof come from works on direct product testing\nwhich are even simpler in the current setting thanks to the low degree.\n  Along the way we also prove a somewhat surprising fact about connection\nbetween different agreement tests: it does not matter if the tester chooses the\ncubes to intersect on points or on lines: for every given table, its success\nprobability in either test is nearly the same.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 08:54:49 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Bhangale", "Amey", ""], ["Dinur", "Irit", ""], ["Navon", "Inbal Livni", ""]]}, {"id": "1612.07601", "submitter": "Johannes Klaus Fichte", "authors": "Johannes Fichte and Markus Hecher and Michael Morak and Stefan Woltran", "title": "Counting Answer Sets via Dynamic Programming", "comments": "Informal proceedings of the 1st Workshop on Trends and Applications\n  of Answer Set Programming (TAASP 2016), Klagenfurt, Austria, 26 September\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the solution counting problem for propositional satisfiability (#SAT)\nhas received renewed attention in recent years, this research trend has not\naffected other AI solving paradigms like answer set programming (ASP). Although\nASP solvers are designed to enumerate all solutions, and counting can therefore\nbe easily done, the involved materialization of all solutions is a clear\nbottleneck for the counting problem of ASP (#ASP). In this paper we propose\ndynamic programming-based #ASP algorithms that exploit the structure of the\nunderlying (ground) ASP program. Experimental results for a prototype\nimplementation show promise when compared to existing solvers.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 14:03:21 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Fichte", "Johannes", ""], ["Hecher", "Markus", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "1612.07768", "submitter": "Juho Lauri", "authors": "Juho Lauri", "title": "Complexity of Rainbow Vertex Connectivity Problems for Restricted Graph\n  Classes", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": "10.1016/j.dam.2016.11.023", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A path in a vertex-colored graph $G$ is \\emph{vertex rainbow} if all of its\ninternal vertices have a distinct color. The graph $G$ is said to be\n\\emph{rainbow vertex connected} if there is a vertex rainbow path between every\npair of its vertices. Similarly, the graph $G$ is \\emph{strongly rainbow vertex\nconnected} if there is a shortest path which is vertex rainbow between every\npair of its vertices. We consider the complexity of deciding if a given\nvertex-colored graph is rainbow or strongly rainbow vertex connected. We call\nthese problems \\probRvc and \\probSrvc, respectively. We prove both problems\nremain NP-complete on very restricted graph classes including bipartite planar\ngraphs of maximum degree 3, interval graphs, and $k$-regular graphs for $k \\geq\n3$. We settle precisely the complexity of both problems from the viewpoint of\ntwo width parameters: pathwidth and tree-depth. More precisely, we show both\nproblems remain NP-complete for bounded pathwidth graphs, while being\nfixed-parameter tractable parameterized by tree-depth. Moreover, we show both\nproblems are solvable in polynomial time for block graphs, while \\probSrvc is\ntractable for cactus graphs and split graphs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 19:52:12 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Lauri", "Juho", ""]]}, {"id": "1612.08070", "submitter": "Franklin Marquezino", "authors": "S. A. Grillo and F. L. Marquezino", "title": "Fourier 1-norm and quantum speed-up", "comments": "16 pages, 1 figure, changed title, improved text, added applications", "journal-ref": "Quantum Inf Process (2019) 18: 99", "doi": "10.1007/s11128-019-2208-7", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding quantum speed-up over classical computing is fundamental for\nthe development of efficient quantum algorithms. In this paper, we study such\nproblem within the framework of the Quantum Query Model, which represents the\nprobability of output $x \\in \\{0,1\\}^n$ as a function $\\pi(x)$. We present a\nclassical simulation for output probabilities $\\pi$, whose error depends on the\nFourier $1$-norm of $\\pi$. Such dependence implies upper-bounds for the\nquotient between the number of queries applied by an optimal classical\nalgorithm and our quantum algorithm, respectively. These upper-bounds show a\nstrong relation between Fourier $1$-norm and quantum parallelism. We show\napplications to query complexity.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 19:45:32 GMT"}, {"version": "v2", "created": "Tue, 30 May 2017 18:41:37 GMT"}, {"version": "v3", "created": "Thu, 18 Jan 2018 18:20:22 GMT"}, {"version": "v4", "created": "Fri, 19 Oct 2018 17:33:22 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Grillo", "S. A.", ""], ["Marquezino", "F. L.", ""]]}, {"id": "1612.08192", "submitter": "Benjamin Rossman", "authors": "Benjamin Rossman", "title": "An Improved Homomorphism Preservation Theorem From Lower Bounds in\n  Circuit Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work of the author [39] showed that the Homomorphism Preservation\nTheorem of classical model theory remains valid when its statement is\nrestricted to finite structures. In this paper, we give a new proof of this\nresult via a reduction to lower bounds in circuit complexity, specifically on\nthe AC$^0$ formula size of the colored subgraph isomorphism problem. Formally,\nwe show the following: if a first-order sentence $\\Phi$ of quantifier-rank $k$\nis preserved under homomorphisms on finite structures, then it is equivalent on\nfinite structures to an existential-positive sentence $\\Psi$ of quantifier-rank\n$k^{O(1)}$. Quantitatively, this improves the result of [39], where the upper\nbound on the quantifier-rank of $\\Psi$ is a non-elementary function of $k$.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 15:07:24 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Rossman", "Benjamin", ""]]}, {"id": "1612.08351", "submitter": "Jiamou Liu", "authors": "Jiamou Liu and Ziheng Wei", "title": "Network, Popularity and Social Cohesion: A Game-Theoretic Approach", "comments": "This paper is a slightly modified version of a paper with the same\n  title to appear at AAAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In studies of social dynamics, cohesion refers to a group's tendency to stay\nin unity, which -- as argued in sociometry -- arises from the network topology\nof interpersonal ties between members of the group. We follow this idea and\npropose a game-based model of cohesion that not only relies on the social\nnetwork, but also reflects individuals' social needs. In particular, our model\nis a type of cooperative games where players may gain popularity by\nstrategically forming groups. A group is socially cohesive if the grand\ncoalition is core stable. We study social cohesion in some special types of\ngraphs and draw a link between social cohesion and the classical notion of\nstructural cohesion. We then focus on the problem of deciding whether a given\nsocial network is socially cohesive and show that this problem is\nCoNP-complete. Nevertheless, we give two efficient heuristics for coalition\nstructures where players enjoy high popularity and experimentally evaluate\ntheir performances.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 09:41:56 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Liu", "Jiamou", ""], ["Wei", "Ziheng", ""]]}, {"id": "1612.08537", "submitter": "George Barmpalias Dr", "authors": "George Barmpalias and Douglas Cenzer and Christopher P. Porter", "title": "The probability of a computable output from a random oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a universal Turing machine that produces a partial or total function\n(or a binary stream), based on the answers to the binary queries that it makes\nduring the computation. We study the probability that the machine will produce\na computable function when it is given a random stream of bits as the answers\nto its queries. Surprisingly, we find that these probabilities are the entire\nclass of real numbers in (0, 1) that can be written as the difference of two\nhalting probabilities relative to the halting problem. In particular, there are\nuniversal Turing machines which produce a computable output with probability\nexactly 1/2. Our results contrast a large array of facts (the most well-known\nbeing the randomness of Chaitin's halting probability) which witness maximal\ninitial segment complexity of probabilities associated with universal machines.\nOur proof uses recent advances in algorithmic randomness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 08:56:55 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 05:50:05 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Barmpalias", "George", ""], ["Cenzer", "Douglas", ""], ["Porter", "Christopher P.", ""]]}, {"id": "1612.09306", "submitter": "Aram Harrow", "authors": "Aram W. Harrow and Anand Natarajan and Xiaodi Wu", "title": "Limitations of semidefinite programs for separable states and entangled\n  games", "comments": "47 pages. v2. small changes, fixes and clarifications. published\n  version", "journal-ref": "Commun. Math. Phys., Vol. 366, No. 2, pp 423-468 (2019)", "doi": "10.1007/s00220-019-03382-y", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semidefinite programs (SDPs) are a framework for exact or approximate\noptimization that have widespread application in quantum information theory. We\nintroduce a new method for using reductions to construct integrality gaps for\nSDPs. These are based on new limitations on the sum-of-squares (SoS) hierarchy\nin approximating two particularly important sets in quantum information theory,\nwhere previously no $\\omega(1)$-round integrality gaps were known: the set of\nseparable (i.e. unentangled) states, or equivalently, the $2 \\rightarrow 4$\nnorm of a matrix, and the set of quantum correlations; i.e. conditional\nprobability distributions achievable with local measurements on a shared\nentangled state. In both cases no-go theorems were previously known based on\ncomputational assumptions such as the Exponential Time Hypothesis (ETH) which\nasserts that 3-SAT requires exponential time to solve. Our unconditional\nresults achieve the same parameters as all of these previous results (for\nseparable states) or as some of the previous results (for quantum\ncorrelations). In some cases we can make use of the framework of\nLee-Raghavendra-Steurer (LRS) to establish integrality gaps for any SDP, not\nonly the SoS hierarchy. Our hardness result on separable states also yields a\ndimension lower bound of approximate disentanglers, answering a question of\nWatrous and Aaronson et al. These results can be viewed as limitations on the\nmonogamy principle, the PPT test, the ability of Tsirelson-type bounds to\nrestrict quantum correlations, as well as the SDP hierarchies of\nDoherty-Parrilo-Spedalieri, Navascues-Pironio-Acin and Berta-Fawzi-Scholz.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 21:01:01 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 20:32:30 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Harrow", "Aram W.", ""], ["Natarajan", "Anand", ""], ["Wu", "Xiaodi", ""]]}]