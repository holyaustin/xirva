[{"id": "1012.0232", "submitter": "Thomas Hugel", "authors": "Thomas Hugel", "title": "Kolmogorov-Loveland Sets and Advice Complexity Classes", "comments": "11 pages - typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loveland complexity is a variant of Kolmogorov complexity, where it is asked\nto output separately the bits of the desired string, instead of the string\nitself. Similarly to the resource-bounded Kolmogorov sets we define Loveland\nsets. We highlight a structural connection between resource-bounded Loveland\nsets and some advice complexity classes. This structural connection enables us\nto map to advice complexity classes some properties of Kolmogorov sets first\nnoticed by Hartmanis and thoroughly investigated in Longpr\\'e's thesis: 1.\nNon-inclusion properties of Loveland sets result in hierarchy properties on the\ncorresponding advice complexity classes; 2. Immunity properties of Loveland\nsets result in the non-existence of natural proofs between the corresponding\nadvice complexity classes, in the sense of Razborov & Rudich.\n", "versions": [{"version": "v1", "created": "Wed, 1 Dec 2010 15:57:48 GMT"}, {"version": "v2", "created": "Wed, 16 Feb 2011 16:26:25 GMT"}], "update_date": "2011-02-17", "authors_parsed": [["Hugel", "Thomas", ""]]}, {"id": "1012.0366", "submitter": "Roman Belavkin", "authors": "Roman V. Belavkin", "title": "Optimal measures and Markov transition kernels", "comments": "Replaced with a final and accepted draft; Journal of Global\n  Optimization, Springer, Jan 1, 2012", "journal-ref": null, "doi": "10.1007/s10898-012-9851-1", "report-no": null, "categories": "math.OC cs.CC cs.IT math-ph math.FA math.IT math.MP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study optimal solutions to an abstract optimization problem for measures,\nwhich is a generalization of classical variational problems in information\ntheory and statistical physics. In the classical problems, information and\nrelative entropy are defined using the Kullback-Leibler divergence, and for\nthis reason optimal measures belong to a one-parameter exponential family.\nMeasures within such a family have the property of mutual absolute continuity.\nHere we show that this property characterizes other families of optimal\npositive measures if a functional representing information has a strictly\nconvex dual. Mutual absolute continuity of optimal probability measures allows\nus to strictly separate deterministic and non-deterministic Markov transition\nkernels, which play an important role in theories of decisions, estimation,\ncontrol, communication and computation. We show that deterministic transitions\nare strictly sub-optimal, unless information resource with a strictly convex\ndual is unconstrained. For illustration, we construct an example where, unlike\nnon-deterministic, any deterministic kernel either has negatively infinite\nexpected utility (unbounded expected error) or communicates infinite\ninformation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Dec 2010 02:08:15 GMT"}, {"version": "v2", "created": "Mon, 13 Dec 2010 22:53:01 GMT"}, {"version": "v3", "created": "Mon, 11 Jul 2011 15:15:14 GMT"}, {"version": "v4", "created": "Fri, 22 Jul 2011 16:42:50 GMT"}, {"version": "v5", "created": "Fri, 3 Feb 2012 03:27:13 GMT"}, {"version": "v6", "created": "Mon, 3 Sep 2012 18:01:59 GMT"}, {"version": "v7", "created": "Wed, 5 Sep 2012 14:56:52 GMT"}], "update_date": "2012-09-06", "authors_parsed": [["Belavkin", "Roman V.", ""]]}, {"id": "1012.0531", "submitter": "Jacob Biamonte", "authors": "Jacob D. Biamonte, Stephen R. Clark and Dieter Jaksch", "title": "Categorical Tensor Network States", "comments": "39 pages, 31 figures, published version", "journal-ref": "AIP Advances 1(4), 042172 (2011)", "doi": "10.1063/1.3672009", "report-no": null, "categories": "quant-ph cond-mat.other cs.CC cs.LO math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the use of string diagrams and the mathematics of category theory\nin the description of quantum states by tensor networks. This approach lead to\na unification of several ideas, as well as several results and methods that\nhave not previously appeared in either side of the literature. Our approach\nenabled the development of a tensor network framework allowing a solution to\nthe quantum decomposition problem which has several appealing features.\nSpecifically, given an n-body quantum state S, we present a new and general\nmethod to factor S into a tensor network of clearly defined building blocks. We\nuse the solution to expose a previously unknown and large class of quantum\nstates which we prove can be sampled efficiently and exactly. This general\nframework of categorical tensor network states, where a combination of generic\nand algebraically defined tensors appear, enhances the theory of tensor network\nstates.\n", "versions": [{"version": "v1", "created": "Thu, 2 Dec 2010 18:21:09 GMT"}, {"version": "v2", "created": "Sat, 17 Dec 2011 07:13:48 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Biamonte", "Jacob D.", ""], ["Clark", "Stephen R.", ""], ["Jaksch", "Dieter", ""]]}, {"id": "1012.0556", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra", "title": "A Note on Nonuniform versus Uniform ACC^k Circuits for NE", "comments": null, "journal-ref": null, "doi": null, "report-no": "URCS-TR-2010-964", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We note that for each k \\in {0,1,2, ...} the following holds: NE has\n(nonuniform) ACC^k circuits if and only if NE has P^{NE}-uniform ACC^k\ncircuits. And we mention how to get analogous results for other circuit and\ncomplexity classes.\n", "versions": [{"version": "v1", "created": "Thu, 2 Dec 2010 20:01:54 GMT"}, {"version": "v2", "created": "Fri, 3 Dec 2010 07:21:21 GMT"}], "update_date": "2010-12-06", "authors_parsed": [["Hemaspaandra", "Lane A.", ""]]}, {"id": "1012.0672", "submitter": "Pierre Guillon", "authors": "Dora Giammarresi", "title": "Tiling-Recognizable Two-Dimensional Languages: From Non-Determinism to\n  Determinism through Unambiguity", "comments": "Journ\\'ees Automates Cellulaires 2010, Turku : Finland (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tiling recognizable two-dimensional languages, also known as REC, generalize\nrecognizable string languages to two dimensions and share with them several\ntheoretical properties. Nevertheless REC is not closed under complementation\nand the membership problem is NP-complete. This implies that this family REC is\nintrinsically non-deterministic. The natural and immediate definition of\nunambiguity corresponds to a family UREC of languages that is strictly\ncontained in REC. On the other hand this definition of unambiguity leads to an\nundecidability result and therefore it cannot correspond to any deterministic\nnotion. We introduce the notion of line-unambiguous tiling recognizable\nlanguages and prove that it corresponds or somehow naturally introduces\ndifferent notions of determin- ism that define a hierarchy inside REC.\n", "versions": [{"version": "v1", "created": "Fri, 3 Dec 2010 09:31:13 GMT"}], "update_date": "2010-12-06", "authors_parsed": [["Giammarresi", "Dora", ""]]}, {"id": "1012.0729", "submitter": "Prasad Raghavendra", "authors": "Vitaly Feldman, Venkatesan Guruswami, Prasad Raghavendra, Yi Wu", "title": "Agnostic Learning of Monomials by Halfspaces is Hard", "comments": "37 pages, Preliminary version appeared in FOCS 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the following strong hardness result for learning: Given a\ndistribution of labeled examples from the hypercube such that there exists a\nmonomial consistent with $(1-\\eps)$ of the examples, it is NP-hard to find a\nhalfspace that is correct on $(1/2+\\eps)$ of the examples, for arbitrary\nconstants $\\eps > 0$. In learning theory terms, weak agnostic learning of\nmonomials is hard, even if one is allowed to output a hypothesis from the much\nbigger concept class of halfspaces. This hardness result subsumes a long line\nof previous results, including two recent hardness results for the proper\nlearning of monomials and halfspaces. As an immediate corollary of our result\nwe show that weak agnostic learning of decision lists is NP-hard.\n  Our techniques are quite different from previous hardness proofs for\nlearning. We define distributions on positive and negative examples for\nmonomials whose first few moments match. We use the invariance principle to\nargue that regular halfspaces (all of whose coefficients have small absolute\nvalue relative to the total $\\ell_2$ norm) cannot distinguish between\ndistributions whose first few moments match. For highly non-regular subspaces,\nwe use a structural lemma from recent work on fooling halfspaces to argue that\nthey are ``junta-like'' and one can zero out all but the top few coefficients\nwithout affecting the performance of the halfspace. The top few coefficients\nform the natural list decoding of a halfspace in the context of dictatorship\ntests/Label Cover reductions.\n  We note that unlike previous invariance principle based proofs which are only\nknown to give Unique-Games hardness, we are able to reduce from a version of\nLabel Cover problem that is known to be NP-hard. This has inspired follow-up\nwork on bypassing the Unique Games conjecture in some optimal geometric\ninapproximability results.\n", "versions": [{"version": "v1", "created": "Fri, 3 Dec 2010 13:11:22 GMT"}], "update_date": "2010-12-06", "authors_parsed": [["Feldman", "Vitaly", ""], ["Guruswami", "Venkatesan", ""], ["Raghavendra", "Prasad", ""], ["Wu", "Yi", ""]]}, {"id": "1012.0821", "submitter": "Gus Gutoski", "authors": "Gus Gutoski", "title": "Interactive proofs with competing teams of no-signaling provers", "comments": "24 pages. Final version published in CJTCS at\n  http://cjtcs.cs.uchicago.edu/articles/2013/7/contents.html", "journal-ref": "Chicago Journal of Theoretical Computer Science, article 7, 2013", "doi": "10.4086/cjtcs.2013.007", "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper studies a generalization of multi-prover interactive proofs in\nwhich a verifier interacts with two competing teams of provers: one team\nattempts to convince the verifier to accept while the other attempts to\nconvince the verifier to reject. Each team consists of two provers who jointly\nimplement a no-signaling strategy. No-signaling strategies are a curious class\nof joint strategy that cannot in general be implemented without communication\nbetween the provers, yet cannot be used as a black box to establish\ncommunication between them. Attention is restricted in this paper to two-turn\ninteractions in which the verifier asks questions of each of the four provers\nand decides whether to accept or reject based on their responses.\n  We prove that the complexity class of decision problems that admit two-turn\ninteractive proofs with competing teams of no-signaling provers is a subset of\nPSPACE. This upper bound matches existing PSPACE lower bounds on the following\ntwo disparate and weaker classes of interactive proof:\n  1. Two-turn multi-prover interactive proofs with only one team of\nno-signaling provers.\n  2. Two-turn competing-prover interactive proofs with only one prover per\nteam.\n  Our result implies that the complexity of these two models is unchanged by\nthe addition of a second competing team of no-signaling provers in the first\ncase and by the addition of a second no-signaling prover to each team in the\nsecond case. Moreover, our result unifies and subsumes prior PSPACE upper\nbounds on these classes.\n", "versions": [{"version": "v1", "created": "Fri, 3 Dec 2010 19:13:38 GMT"}, {"version": "v2", "created": "Sat, 15 Oct 2011 03:40:56 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2013 19:07:11 GMT"}], "update_date": "2013-08-08", "authors_parsed": [["Gutoski", "Gus", ""]]}, {"id": "1012.0956", "submitter": "Ioannis Paparrizos", "authors": "Ioannis Paparrizos", "title": "A tight bound on the worst-case number of comparisons for Floyd's heap\n  construction algorithm", "comments": "This (full) paper was accepted for publication in the 37th\n  International Conference on Current Trends in Theory and Practice of Computer\n  Science (SOFSEM2011), 22-28 January 2011, Novy Smokovec, Slovakia (9 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a tight bound on the worst-case number of comparisons for\nFloyd's well known heap construction algorithm, is derived. It is shown that at\nmost 2n-2{\\mu}(n)-{\\sigma}(n) comparisons are executed in the worst case, where\n{\\mu}(n) is the number of ones and {\\sigma}(n) is the number of zeros after the\nlast one in the binary representation of the number of keys n.\n", "versions": [{"version": "v1", "created": "Sun, 5 Dec 2010 00:01:09 GMT"}, {"version": "v2", "created": "Mon, 3 Jan 2011 12:49:09 GMT"}, {"version": "v3", "created": "Mon, 18 Apr 2011 11:25:44 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Paparrizos", "Ioannis", ""]]}, {"id": "1012.1221", "submitter": "Pierre Guillon", "authors": "Fabien Givors (LIF), Gr\\'egory Lafitte (LIF), Nicolas Ollinger (LIF)", "title": "Infinite Time Cellular Automata: A Real Computation Model", "comments": "Journ\\'ees Automates Cellulaires 2010, Turku : Finland (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CG cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new transfinite time model of computation, infinite time cellular\nautomata. The model is shown to be as powerful than infinite time Turing\nmachines, both on finite and infinite inputs; thus inheriting many of its\nproperties. We then show how to simulate the canonical real computation model,\nBSS machines, with infinite time cellular automata in exactly \\omega steps.\n", "versions": [{"version": "v1", "created": "Fri, 3 Dec 2010 09:57:11 GMT"}], "update_date": "2010-12-07", "authors_parsed": [["Givors", "Fabien", "", "LIF"], ["Lafitte", "Gr\u00e9gory", "", "LIF"], ["Ollinger", "Nicolas", "", "LIF"]]}, {"id": "1012.1237", "submitter": "Russell Martin", "authors": "Prasad Chebolu, Leslie Ann Goldberg, Russell Martin", "title": "The Complexity of Approximately Counting Stable Roommate Assignments", "comments": null, "journal-ref": "JCSS 2012", "doi": "10.1016/j.jcss.2012.02.003", "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of approximately counting stable roommate\nassignments in two models: (i) the $k$-attribute model, in which the preference\nlists are determined by dot products of \"preference vectors\" with \"attribute\nvectors\" and (ii) the $k$-Euclidean model, in which the preference lists are\ndetermined by the closeness of the \"positions\" of the people to their\n\"preferred positions\". Exactly counting the number of assignments is\n#P-complete, since Irving and Leather demonstrated #P-completeness for the\nspecial case of the stable marriage problem. We show that counting the number\nof stable roommate assignments in the $k$-attribute model ($k \\geq 4$) and the\n3-Euclidean model($k \\geq 3$) is interreducible, in an approximation-preserving\nsense, with counting independent sets (of all sizes) (#IS) in a graph, or\ncounting the number of satisfying assignments of a Boolean formula (#SAT). This\nmeans that there can be no FPRAS for any of these problems unless NP=RP. As a\nconsequence, we infer that there is no FPRAS for counting stable roommate\nassignments (#SR) unless NP=RP. Utilizing previous results by the authors, we\ngive an approximation-preserving reduction from counting the number of\nindependent sets in a bipartite graph (#BIS) to counting the number of stable\nroommate assignments both in the 3-attribute model and in the 2-Euclidean\nmodel. #BIS is complete with respect to approximation-preserving reductions in\nthe logically-defined complexity class $#RH\\Pi_1$. Hence, our result shows that\nan FPRAS for counting stable roommate assignments in the 3-attribute model\nwould give an FPRAS for all of $#RH\\Pi_1$. We also show that the 1-attribute\nstable roommate problem always has either one or two stable roommate\nassignments, so the number of assignments can be determined exactly in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Dec 2010 16:43:49 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2012 16:12:36 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Chebolu", "Prasad", ""], ["Goldberg", "Leslie Ann", ""], ["Martin", "Russell", ""]]}, {"id": "1012.1283", "submitter": "Pierre Guillon", "authors": "Alexander Shen (LIF)", "title": "Decomposition Complexity", "comments": "Journ\\'ees Automates Cellulaires 2010, Turku : Finland (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of decomposition of a ternary function into a\ncomposition of binary ones from the viewpoint of communication complexity and\nalgorithmic information theory as well as some applications to cellular\nautomata.\n", "versions": [{"version": "v1", "created": "Fri, 3 Dec 2010 09:33:57 GMT"}], "update_date": "2010-12-07", "authors_parsed": [["Shen", "Alexander", "", "LIF"]]}, {"id": "1012.1330", "submitter": "Pierre Guillon", "authors": "Emmanuel Jeandel (LIF), Pascal Vanier (LIF)", "title": "Slopes of Tilings", "comments": "Journ\\'ees Automates Cellulaires 2010, Turku : Finland (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study here slopes of periodicity of tilings. A tiling is of slope if it is\nperiodic along direction but has no other direction of periodicity. We\ncharacterize in this paper the set of slopes we can achieve with tilings, and\nprove they coincide with recursively enumerable sets of rationals.\n", "versions": [{"version": "v1", "created": "Fri, 3 Dec 2010 09:38:53 GMT"}], "update_date": "2010-12-08", "authors_parsed": [["Jeandel", "Emmanuel", "", "LIF"], ["Vanier", "Pascal", "", "LIF"]]}, {"id": "1012.1336", "submitter": "Daniel Kane", "authors": "Daniel M. Kane", "title": "Unary Subset-Sum is in Logspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple Logspace algorithm that solves the Unary Subset-Sum\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 6 Dec 2010 21:10:05 GMT"}, {"version": "v2", "created": "Wed, 8 Dec 2010 06:15:33 GMT"}, {"version": "v3", "created": "Thu, 27 Jul 2017 00:13:45 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Kane", "Daniel M.", ""]]}, {"id": "1012.1614", "submitter": "Daniel Kane", "authors": "Daniel M. Kane", "title": "$k$-Independent Gaussians Fool Polynomial Threshold Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any $O_d(\\epsilon^{-4d 7^d})$-independent family of Gaussians\n$\\epsilon$-fools any degree-$d$ polynomial threshold function.\n", "versions": [{"version": "v1", "created": "Tue, 7 Dec 2010 21:31:04 GMT"}, {"version": "v2", "created": "Wed, 9 Mar 2011 22:55:42 GMT"}, {"version": "v3", "created": "Fri, 11 Nov 2011 01:44:23 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["Kane", "Daniel M.", ""]]}, {"id": "1012.1908", "submitter": "Pablo A. Parrilo", "authors": "Amir Ali Ahmadi, Alex Olshevsky, Pablo A. Parrilo and John N.\n  Tsitsiklis", "title": "NP-hardness of Deciding Convexity of Quartic Polynomials and Related\n  Problems", "comments": "20 pages", "journal-ref": "Mathematical Programming, Vol. 137, Issue 1-2, pp 453-476, 2013", "doi": "10.1007/s10107-011-0499-2", "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that unless P=NP, there exists no polynomial time (or even\npseudo-polynomial time) algorithm that can decide whether a multivariate\npolynomial of degree four (or higher even degree) is globally convex. This\nsolves a problem that has been open since 1992 when N. Z. Shor asked for the\ncomplexity of deciding convexity for quartic polynomials. We also prove that\ndeciding strict convexity, strong convexity, quasiconvexity, and\npseudoconvexity of polynomials of even degree four or higher is strongly\nNP-hard. By contrast, we show that quasiconvexity and pseudoconvexity of odd\ndegree polynomials can be decided in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 9 Dec 2010 01:56:05 GMT"}], "update_date": "2013-06-10", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Olshevsky", "Alex", ""], ["Parrilo", "Pablo A.", ""], ["Tsitsiklis", "John N.", ""]]}, {"id": "1012.2034", "submitter": "Lance Fortnow", "authors": "Lance Fortnow and Rahul Santhanam", "title": "Robust Simulations and Significant Separations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study a new notion of \"robust simulations\" between complexity\nclasses which is intermediate between the traditional notions of\ninfinitely-often and almost-everywhere, as well as a corresponding notion of\n\"significant separations\". A language L has a robust simulation in a complexity\nclass C if there is a language in C which agrees with L on arbitrarily large\npolynomial stretches of input lengths. There is a significant separation of L\nfrom C if there is no robust simulation of L in C. The new notion of simulation\nis a cleaner and more natural notion of simulation than the infinitely-often\nnotion. We show that various implications in complexity theory such as the\ncollapse of PH if NP = P and the Karp-Lipton theorem have analogues for robust\nsimulations. We then use these results to prove that most known separations in\ncomplexity theory, such as hierarchy theorems, fixed polynomial circuit lower\nbounds, time-space tradeoffs, and the theorems of Allender and Williams, can be\nstrengthened to significant separations, though in each case, an almost\neverywhere separation is unknown.\n  Proving our results requires several new ideas, including a completely\ndifferent proof of the hierarchy theorem for non-deterministic polynomial time\nthan the ones previously known.\n", "versions": [{"version": "v1", "created": "Thu, 9 Dec 2010 15:47:35 GMT"}], "update_date": "2010-12-10", "authors_parsed": [["Fortnow", "Lance", ""], ["Santhanam", "Rahul", ""]]}, {"id": "1012.2081", "submitter": "Harm Derksen", "authors": "Harm Derksen", "title": "The Graph Isomorphism Problem and approximate categories", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC math.AC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is unknown whether two graphs can be tested for isomorphism in polynomial\ntime. A classical approach to the Graph Isomorphism Problem is the\nd-dimensional Weisfeiler-Lehman algorithm. The d-dimensional WL-algorithm can\ndistinguish many pairs of graphs, but the pairs of non-isomorphic graphs\nconstructed by Cai, Furer and Immerman it cannot distinguish. If d is fixed,\nthen the WL-algorithm runs in polynomial time. We will formulate the Graph\nIsomorphism Problem as an Orbit Problem: Given a representation V of an\nalgebraic group G and two elements v_1,v_2 in V, decide whether v_1 and v_2 lie\nin the same G-orbit. Then we attack the Orbit Problem by constructing certain\napproximate categories C_d(V), d=1,2,3,... whose objects include the elements\nof V. We show that v_1 and v_2 are not in the same orbit by showing that they\nare not isomorphic in the category C_d(V) for some d. For every d this gives us\nan algorithm for isomorphism testing. We will show that the WL-algorithms\nreduce to our algorithms, but that our algorithms cannot be reduced to the\nWL-algorithms. Unlike the Weisfeiler-Lehman algorithm, our algorithm can\ndistinguish the Cai-Furer-Immerman graphs in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 9 Dec 2010 19:02:45 GMT"}], "update_date": "2010-12-10", "authors_parsed": [["Derksen", "Harm", ""]]}, {"id": "1012.2088", "submitter": "J\\'an Katreni\\v{c}", "authors": "Bo\\v{s}tjan Bre\\v{s}ar and Franti\\v{s}ek Kardo\\v{s} and J\\'an\n  Katreni\\v{c} and Gabriel Semani\\v{s}in", "title": "Minimum k-path vertex cover", "comments": "submitted manuscript", "journal-ref": "Discrete Applied Mathematics Volume 159, Issue 12, 28 July 2011,\n  Pages 1189-1195", "doi": "10.1016/j.dam.2011.04.008", "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A subset S of vertices of a graph G is called a k-path vertex cover if every\npath of order k in G contains at least one vertex from S. Denote by \\psi_k(G)\nthe minimum cardinality of a k-path vertex cover in G. It is shown that the\nproblem of determining \\psi_k(G) is NP-hard for each k \\geq 2, while for trees\nthe problem can be solved in linear time. We investigate upper bounds on the\nvalue of \\psi_k(G) and provide several estimations and exact values of\n\\psi_k(G). We also prove that \\psi_3(G) \\leq (2n + m)/6, for every graph G with\nn vertices and m edges.\n", "versions": [{"version": "v1", "created": "Thu, 9 Dec 2010 19:25:09 GMT"}, {"version": "v2", "created": "Fri, 10 Dec 2010 08:03:39 GMT"}], "update_date": "2011-08-02", "authors_parsed": [["Bre\u0161ar", "Bo\u0161tjan", ""], ["Kardo\u0161", "Franti\u0161ek", ""], ["Katreni\u010d", "J\u00e1n", ""], ["Semani\u0161in", "Gabriel", ""]]}, {"id": "1012.2112", "submitter": "J\\'er\\'emie Roland", "authors": "Andris Ambainis, Lo\\\"ick Magnin, Martin Roetteler and J\\'er\\'emie\n  Roland", "title": "Symmetry-assisted adversaries for quantum state generation", "comments": "35 pages, 5 figures", "journal-ref": "26th IEEE Conference on Computational Complexity (CCC'11), pages\n  167-177, 2011", "doi": "10.1109/CCC.2011.24", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new quantum adversary method to prove lower bounds on the\nquery complexity of the quantum state generation problem. This problem\nencompasses both, the computation of partial or total functions and the\npreparation of target quantum states. There has been hope for quite some time\nthat quantum state generation might be a route to tackle the {\\sc Graph\nIsomorphism} problem. We show that for the related problem of {\\sc Index\nErasure} our method leads to a lower bound of $\\Omega(\\sqrt N)$ which matches\nan upper bound obtained via reduction to quantum search on $N$ elements. This\ncloses an open problem first raised by Shi [FOCS'02].\n  Our approach is based on two ideas: (i) on the one hand we generalize the\nknown additive and multiplicative adversary methods to the case of quantum\nstate generation, (ii) on the other hand we show how the symmetries of the\nunderlying problem can be leveraged for the design of optimal adversary\nmatrices and dramatically simplify the computation of adversary bounds. Taken\ntogether, these two ideas give the new result for {\\sc Index Erasure} by using\nthe representation theory of the symmetric group. Also, the method can lead to\nlower bounds even for small success probability, contrary to the standard\nadversary method. Furthermore, we answer an open question due to \\v{S}palek\n[CCC'08] by showing that the multiplicative version of the adversary method is\nstronger than the additive one for any problem. Finally, we prove that the\nmultiplicative bound satisfies a strong direct product theorem, extending a\nresult by \\v{S}palek to quantum state generation problems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Dec 2010 20:58:46 GMT"}], "update_date": "2011-07-29", "authors_parsed": [["Ambainis", "Andris", ""], ["Magnin", "Lo\u00efck", ""], ["Roetteler", "Martin", ""], ["Roland", "J\u00e9r\u00e9mie", ""]]}, {"id": "1012.2142", "submitter": "Pavel Ghosh", "authors": "Sujogya Banerjee, Shahrzad Shirazipourazad, Pavel Ghosh, Arunabha Sen", "title": "NP-completeness Proof: RBCDN Reduction Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational complexity of the design problem for a network with a target\nvalue of Region-Based Component Decomposition Number (RBCDN) has been proven to\nbe NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 9 Dec 2010 23:39:32 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Banerjee", "Sujogya", ""], ["Shirazipourazad", "Shahrzad", ""], ["Ghosh", "Pavel", ""], ["Sen", "Arunabha", ""]]}, {"id": "1012.2291", "submitter": "J\\\"urg Wullschleger", "authors": "J\\\"urg Wullschleger", "title": "Bitwise Quantum Min-Entropy Sampling and New Lower Bounds for Random\n  Access Codes", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Min-entropy sampling gives a bound on the min-entropy of a randomly chosen\nsubset of a string, given a bound on the min-entropy of the whole string.\nK\\\"onig and Renner showed a min-entropy sampling theorem that holds relative to\nquantum knowledge. Their result achieves the optimal rate, but it can only be\napplied if the bits are sampled in blocks, and only gives weak bounds for the\nnon-smooth min-entropy. We give two new quantum min-entropy sampling theorems\nthat do not have the above weaknesses. The first theorem shows that the result\nby K\\\"onig and Renner also applies to bitwise sampling, and the second theorem\ngives a strong bound for the non-smooth min-entropy. Our results imply a new\nlower bound for k-out-of-n random access codes: while previous results by\nBen-Aroya, Regev, and de Wolf showed that the decoding probability is\nexponentially small in k if the storage rate is smaller than 0.7, our results\nimply that this holds for any storage rate strictly smaller than 1, which is\noptimal.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 15:32:42 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2011 16:50:35 GMT"}], "update_date": "2011-07-18", "authors_parsed": [["Wullschleger", "J\u00fcrg", ""]]}, {"id": "1012.2377", "submitter": "Bin Fu", "authors": "Bin Fu", "title": "Multivariate Polynomial Integration and Derivative Are Polynomial Time\n  Inapproximable unless P=NP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of integration and derivative for multivariate\npolynomials in the standard computation model. The integration is in the unit\ncube $[0,1]^d$ for a multivariate polynomial, which has format $f(x_1,\\cdots,\nx_d)=p_1(x_1,\\cdots, x_d)p_2(x_1,\\cdots, x_d)\\cdots p_k(x_1,\\cdots, x_d)$,\nwhere each $p_i(x_1,\\cdots, x_d)=\\sum_{j=1}^d q_j(x_j)$ with all single\nvariable polynomials $q_j(x_j)$ of degree at most two and constant\ncoefficients. We show that there is no any factor polynomial time approximation\nfor the integration $\\int_{[0,1]^d}f(x_1,\\cdots,x_d)d_{x_1}\\cdots d_{x_d}$\nunless $P=NP$. For the complexity of multivariate derivative, we consider the\nfunctions with the format $f(x_1,\\cdots, x_d)=p_1(x_1,\\cdots,\nx_d)p_2(x_1,\\cdots, x_d)\\cdots p_k(x_1,\\cdots, x_d),$ where each\n$p_i(x_1,\\cdots, x_d)$ is of degree at most $2$ and $0,1$ coefficients. We also\nshow that unless $P=NP$, there is no any factor polynomial time approximation\nto its derivative ${\\partial f^{(d)}(x_1,\\cdots, x_d)\\over \\partial x_1\\cdots\n\\partial x_d}$ at the origin point $(x_1,\\cdots, x_d)=(0,\\cdots,0)$. Our\nresults show that the derivative may not be easier than the integration in high\ndimension. We also give some tractable cases of high dimension integration and\nderivative.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 20:51:16 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Fu", "Bin", ""]]}, {"id": "1012.2394", "submitter": "Bin Fu", "authors": "Bin Fu", "title": "NE is not NP Turing Reducible to Nonexpoentially Dense NP Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long standing open problem in the computational complexity theory is to\nseparate NE from BPP, which is a subclass of $NP_T(NP\\cap P/poly)$. In this\npaper, we show that $NE\\not\\subseteq NP_(NP \\cap$\nNonexponentially-Dense-Class), where Nonexponentially-Dense-Class is the class\nof languages A without exponential density (for each constant c>0,$|A^{\\le\nn}|\\le 2^{n^c}$ for infinitely many integers n).\n  Our result implies $NE\\not\\subseteq NP_T({pad(NP, g(n))})$ for every time\nconstructible super-polynomial function g(n) such as\n$g(n)=n^{\\ceiling{\\log\\ceiling{\\log n}}}$, where Pad(NP, g(n)) is class of all\nlanguages $L_B=\\{s10^{g(|s|)-|s|-1}:s\\in B\\}$ for $B\\in NP$. We also show\n$NE\\not\\subseteq NP_T(P_{tt}(NP)\\cap Tally)$.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 21:19:11 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Fu", "Bin", ""]]}, {"id": "1012.2440", "submitter": "Othon Michail", "authors": "Ioannis Chatzigiannakis, Othon Michail, Stavros Nikolaou, Andreas\n  Pavlogiannis, Paul G. Spirakis", "title": "Passively Mobile Communicating Machines that Use Restricted Space", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new theoretical model for passively mobile Wireless Sensor\nNetworks, called PM, standing for Passively mobile Machines. The main\nmodification w.r.t. the Population Protocol model is that agents now, instead\nof being automata, are Turing Machines. We provide general definitions for\nunbounded memories, but we are mainly interested in computations upper-bounded\nby plausible space limitations. However, we prove that our results hold for\nmore general cases. We focus on complete communication graphs and define the\ncomplexity classes PMSPACE(f(n)) parametrically, consisting of all predicates\nthat are stably computable by some PM protocol that uses O(f(n)) memory on each\nagent. We provide a protocol that generates unique ids from scratch only by\nusing O(log n) memory, and use it to provide an exact characterization for the\nclasses PMSPACE(f(n)) when f(n)={\\Omega}(log n): they are precisely the classes\nof all symmetric predicates in NSPACE(nf(n)). In this way, we provide a space\nhierarchy for the PM model when the memory bounds are {\\Omega}(log n). Finally,\nwe explore the computability of the PM model when the protocols use o(loglog n)\nspace per machine and prove that SEMILINEAR=PMSPACE(f(n)) when f(n)=o(loglog\nn), where SEMILINEAR denotes the class of the semilinear predicates. In fact,\nwe prove that this bound acts as a threshold, so that SEMILINEAR is a proper\nsubset of PMSPACE(f(n)) when f(n)=O(loglog n).\n", "versions": [{"version": "v1", "created": "Sat, 11 Dec 2010 10:05:38 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Chatzigiannakis", "Ioannis", ""], ["Michail", "Othon", ""], ["Nikolaou", "Stavros", ""], ["Pavlogiannis", "Andreas", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1012.2527", "submitter": "Nicolaos Matsakis", "authors": "Nicolaos Matsakis", "title": "Solving the Rural Postman problem using the Adleman-Lipton model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey we investigate the application of the Adleman-Lipton model on\nRural Postman problem, which given an undirected graph $G=(V,E)$ with positive\ninteger lengths on each of its edges and a subset $E^{'}\\subseteq E$, asks\nwhether there exists a hamiltonian circuit that includes each edge of $E^{'}$\nand has total cost (sum of edge lengths) less or equal to a given integer B (we\nare allowed to use any edges of the set $E-E^{'}$, but we must use all edges of\nthe set $E'$). The Rural Postman problem (RPP) is a very interesting\nNP-complete problem used, especially, in network optimization. RPP is actually\na special case of the Route Inspection problem, where we need to traverse all\nedges of an undirected graph at a minimum total cost. As all NP-complete\nproblems, it currently admits no efficient solution and if actually $P\\neq NP$\nas it is widely accepted to be, it cannot admit a polynomial time algorithm to\nsolve it. The application of the Adleman-Lipton model on this problem, provides\nan efficient way to solve RPP, as it is the fact for many other hard problems\non which the Adleman-Lipton model has been applied. In this survey, we provide\na polynomial algorithm based on the Lipton-Adleman model, which solves the RPP\nin $\\mathcal{O}(n^{2})$ time, where n refers to the input of the problem.\n", "versions": [{"version": "v1", "created": "Sun, 12 Dec 2010 10:14:22 GMT"}, {"version": "v2", "created": "Wed, 15 Dec 2010 11:44:59 GMT"}], "update_date": "2010-12-16", "authors_parsed": [["Matsakis", "Nicolaos", ""]]}, {"id": "1012.2648", "submitter": "Georg Gottlob", "authors": "S. Abiteboul, G. Gottlob, M. Manna", "title": "Distributed XML Design", "comments": "\"56 pages, 4 figures\"", "journal-ref": "Proceedings of PODS '09 (2009) 247-258", "doi": "10.1145/1559795.1559833", "report-no": null, "categories": "cs.DB cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed XML document is an XML document that spans several machines. We\nassume that a distribution design of the document tree is given, consisting of\nan XML kernel-document T[f1,...,fn] where some leaves are \"docking points\" for\nexternal resources providing XML subtrees (f1,...,fn, standing, e.g., for Web\nservices or peers at remote locations). The top-down design problem consists\nin, given a type (a schema document that may vary from a DTD to a tree\nautomaton) for the distributed document, \"propagating\" locally this type into a\ncollection of types, that we call typing, while preserving desirable\nproperties. We also consider the bottom-up design which consists in, given a\ntype for each external resource, exhibiting a global type that is enforced by\nthe local types, again with natural desirable properties. In the article, we\nlay out the fundamentals of a theory of distributed XML design, analyze\nproblems concerning typing issues in this setting, and study their complexity.\n", "versions": [{"version": "v1", "created": "Mon, 13 Dec 2010 07:45:30 GMT"}], "update_date": "2010-12-15", "authors_parsed": [["Abiteboul", "S.", ""], ["Gottlob", "G.", ""], ["Manna", "M.", ""]]}, {"id": "1012.2713", "submitter": "Minghao Yin", "authors": "Junping Zhou and Minghao Yin", "title": "Phase Transitions of Plan Modification in Conformant Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We explore phase transitions of plan modification, which mainly focus on the\nconformant planning problems. By analyzing features of plan modification in\nconformant planning problems, quantitative results are obtained. If the number\nof operators is less than, almost all conformant planning problems can't be\nsolved with plan modification. If the number of operators is more than, almost\nall conformant planning problems can be solved with plan modification. The\nresults of the experiments also show that there exists an experimental\nthreshold of density (ratio of number of operators to number of propositions),\nwhich separates the region where almost all conformant planning problems can't\nbe solved with plan modification from the region where almost all conformant\nplanning problems can be solved with plan modification.\n", "versions": [{"version": "v1", "created": "Mon, 13 Dec 2010 12:42:15 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Zhou", "Junping", ""], ["Yin", "Minghao", ""]]}, {"id": "1012.2738", "submitter": "Irit Dinur", "authors": "Irit Dinur and Tali Kaufman", "title": "Dense locally testable codes cannot have constant rate and distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A q-query locally testable code (LTC) is an error correcting code that can be\ntested by a randomized algorithm that reads at most q symbols from the given\nword. An important question is whether there exist LTCs that have the\nccc-property: constant relative rate, constant relative distance, and that can\nbe tested with a constant number of queries. Such codes are sometimes referred\nto as \"asymptotically good\".\n  We show that dense LTCs cannot be ccc. The density of a tester is roughly the\naverage number of distinct local views in which a coordinate participates. An\nLTC is dense if it has a tester with density >> 1.\n  More precisely, we show that a 3-query locally testable code with a tester of\ndensity >> 1 cannot be ccc. Moreover, we show that a q-query locally testable\ncode (q>3) with a tester of density >> n^{q-2} cannot be ccc. Our results hold\nwhen the tester has the following two properties: 1) \"no weights\": Every\nq-tuple of queries occurs with the same probability. 2) \"last-one-fixed\": In\nevery `test' of the tester, the value to any q-1 of the symbols determines the\nvalue of the last symbol. (Linear codes have constraints of this type).\n  We also show that several natural ways to quantitatively improve our results\nwould already resolve the general ccc-question, i.e. also for non-dense LTCs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Dec 2010 14:31:33 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Dinur", "Irit", ""], ["Kaufman", "Tali", ""]]}, {"id": "1012.3000", "submitter": "Massimo Santini", "authors": "Massimo Santini", "title": "Random Generation and Approximate Counting of Combinatorial Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The aim of this thesis is to determine classes of NP relations for which\nrandom generation and approximate counting problems admit an efficient\nsolution. Since efficient rank implies efficient random generation, we first\ninvestigate some classes of NP relations admitting efficient ranking. On the\nother hand, there are situations in which efficient random generation is\npossible even when ranking is computationally infeasible. We introduce the\nnotion of ambiguous description as a tool for random generation and approximate\ncounting in such cases and show, in particular, some applications to the case\nof formal languages. Finally, we discuss a limit of an heuristic for\ncombinatorial optimization problems based on the random initialization of local\nsearch algorithms showing that derandomizing such heuristic can be, in some\ncases, #P-hard.\n", "versions": [{"version": "v1", "created": "Tue, 14 Dec 2010 11:41:24 GMT"}], "update_date": "2010-12-15", "authors_parsed": [["Santini", "Massimo", ""]]}, {"id": "1012.3018", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore and Marco Schaerf", "title": "On the size of data structures used in symbolic model checking", "comments": null, "journal-ref": null, "doi": "10.1109/TC.2015.2512872", "report-no": null, "categories": "cs.AI cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Logic Model Checking is a verification method in which we describe a\nsystem, the model, and then we verify whether some properties, expressed in a\ntemporal logic formula, hold in the system. It has many industrial\napplications. In order to improve performance, some tools allow preprocessing\nof the model, verifying on-line a set of properties reusing the same compiled\nmodel; we prove that the complexity of the Model Checking problem, without any\npreprocessing or preprocessing the model or the formula in a polynomial data\nstructure, is the same. As a result preprocessing does not always exponentially\nimprove performance.\n  Symbolic Model Checking algorithms work by manipulating sets of states, and\nthese sets are often represented by BDDs. It has been observed that the size of\nBDDs may grow exponentially as the model and formula increase in size. As a\nside result, we formally prove that a superpolynomial increase of the size of\nthese BDDs is unavoidable in the worst case. While this exponential growth has\nbeen empirically observed, to the best of our knowledge it has never been\nproved so far in general terms. This result not only holds for all types of\nBDDs regardless of the variable ordering, but also for more powerful data\nstructures, such as BEDs, RBCs, MTBDDs, and ADDs.\n", "versions": [{"version": "v1", "created": "Tue, 14 Dec 2010 13:18:44 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Liberatore", "Paolo", ""], ["Schaerf", "Marco", ""]]}, {"id": "1012.3174", "submitter": "Yi-Kai Liu", "authors": "Andris Ambainis, Andrew M. Childs, Yi-Kai Liu", "title": "Quantum property testing for bounded-degree graphs", "comments": "21 pages; v3: more detailed proof of the lower bound; v2: minor\n  corrections to Lemma 6", "journal-ref": "Proceedings of RANDOM 2011, Lecture Notes in Computer Science\n  6845, pp. 365-376", "doi": "10.1007/978-3-642-22935-0_31", "report-no": "NSF-KITP-10-147", "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study quantum algorithms for testing bipartiteness and expansion of\nbounded-degree graphs. We give quantum algorithms that solve these problems in\ntime O(N^(1/3)), beating the Omega(sqrt(N)) classical lower bound. For testing\nexpansion, we also prove an Omega(N^(1/4)) quantum query lower bound, thus\nruling out the possibility of an exponential quantum speedup. Our quantum\nalgorithms follow from a combination of classical property testing techniques\ndue to Goldreich and Ron, derandomization, and the quantum algorithm for\nelement distinctness. The quantum lower bound is obtained by the polynomial\nmethod, using novel algebraic techniques and combinatorial analysis to\naccommodate the graph structure.\n", "versions": [{"version": "v1", "created": "Tue, 14 Dec 2010 21:07:54 GMT"}, {"version": "v2", "created": "Thu, 16 Dec 2010 23:04:33 GMT"}, {"version": "v3", "created": "Mon, 20 Jun 2011 20:58:52 GMT"}], "update_date": "2011-09-12", "authors_parsed": [["Ambainis", "Andris", ""], ["Childs", "Andrew M.", ""], ["Liu", "Yi-Kai", ""]]}, {"id": "1012.3319", "submitter": "Itai Arad", "authors": "Itai Arad", "title": "A note about a partial no-go theorem for quantum PCP", "comments": "7 pages, comments are welcome! revised version with very minor\n  corrections", "journal-ref": "Quantum Information & Computation, Vol.11, (2011), pp 1019", "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is not a disproof of the quantum PCP conjecture!\n  In this note we use perturbation on the commuting Hamiltonian problem on a\ngraph, based on results by Bravyi and Vyalyi, to provide a partial no-go\ntheorem for quantum PCP. Specifically, we derive an upper bound on how large\nthe promise gap can be for the quantum PCP still to hold, as a function of the\nnon-commuteness of the system. As the system becomes more and more commuting,\nthe maximal promise gap shrinks.\n  We view these results as possibly a preliminary step towards disproving the\nquantum PCP conjecture. A different way to view these results is actually as\nindications that a critical point exists, beyond which quantum PCP indeed\nholds; in any case, we hope that these results will lead to progress on this\nimportant open problem.\n", "versions": [{"version": "v1", "created": "Wed, 15 Dec 2010 13:08:29 GMT"}, {"version": "v2", "created": "Fri, 4 Feb 2011 15:50:16 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Arad", "Itai", ""]]}, {"id": "1012.3506", "submitter": "Widad Machmouchi", "authors": "Widad Machmouchi", "title": "Local-Testability and Self-Correctability of q-ary Sparse Linear Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that q-ary sparse codes with small bias are self-correctable and\nlocally testable. We generalize a result of Kaufman and Sudan that proves the\nlocal testability and correctability of binary sparse codes with small bias. We\nuse properties of q-ary Krawtchouk polynomials and the McWilliams identity\n-that relates the weight distribution of a code to the weight distribution of\nits dual- to derive bounds on the error probability of the randomized tester\nand self-corrector we are analyzing.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 03:23:20 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Machmouchi", "Widad", ""]]}, {"id": "1012.3548", "submitter": "Philippe Moser", "authors": "Philippe Moser", "title": "On the polynomial depth of various sets of random strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes new notions of polynomial depth (called monotone poly\ndepth), based on a polynomial version of monotone Kolmogorov complexity. We\nshow that monotone poly depth satisfies all desirable properties of depth\nnotions i.e., both trivial and random sequences are not monotone poly deep,\nmonotone poly depth satisfies the slow growth law i.e., no simple process can\ntransform a non deep sequence into a deep one, and monotone poly deep sequences\nexist (unconditionally). We give two natural examples of deep sets, by showing\nthat both the set of Levin-random strings and the set of Kolmogorov random\nstrings are monotone poly deep.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 10:07:39 GMT"}, {"version": "v2", "created": "Fri, 31 Dec 2010 05:36:25 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Moser", "Philippe", ""]]}, {"id": "1012.3828", "submitter": "Felix Weiss", "authors": "Martin Mundhenk, Felix Weiss", "title": "The model checking problem for intuitionistic propositional logic with\n  one variable is AC1-complete", "comments": "A preliminary version of this work was presented at STACS 2011. 19\n  pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We show that the model checking problem for intuitionistic propositional\nlogic with one variable is complete for logspace-uniform AC1. As basic tool we\nuse the connection between intuitionistic logic and Heyting algebra, and\ninvestigate its complexity theoretical aspects. For superintuitionistic logics\nwith one variable, we obtain NC1-completeness for the model checking problem.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 08:46:44 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2011 13:34:33 GMT"}, {"version": "v3", "created": "Thu, 15 Sep 2011 12:53:48 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Mundhenk", "Martin", ""], ["Weiss", "Felix", ""]]}, {"id": "1012.4019", "submitter": "David Jao", "authors": "Andrew M. Childs, David Jao, Vladimir Soukharev", "title": "Constructing elliptic curve isogenies in quantum subexponential time", "comments": "Errata: Remark 5.5 is incorrect as stated. For full discussion see\n  https://eprint.iacr.org/2017/774 section 7.0.1", "journal-ref": "J. Math. Cryptol., 8(1):1-29, 2014", "doi": "10.1515/jmc-2012-0016", "report-no": null, "categories": "quant-ph cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two elliptic curves over a finite field having the same cardinality and\nendomorphism ring, it is known that the curves admit an isogeny between them,\nbut finding such an isogeny is believed to be computationally difficult. The\nfastest known classical algorithm takes exponential time, and prior to our work\nno faster quantum algorithm was known. Recently, public-key cryptosystems based\non the presumed hardness of this problem have been proposed as candidates for\npost-quantum cryptography. In this paper, we give a subexponential-time quantum\nalgorithm for constructing isogenies, assuming the Generalized Riemann\nHypothesis (but with no other assumptions). Our algorithm is based on a\nreduction to a hidden shift problem, together with a new subexponential-time\nalgorithm for evaluating isogenies from kernel ideals (under only GRH), and\nrepresents the first nontrivial application of Kuperberg's quantum algorithm\nfor the hidden shift problem. This result suggests that isogeny-based\ncryptosystems may be uncompetitive with more mainstream quantum-resistant\ncryptosystems such as lattice-based cryptosystems.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 21:05:37 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2011 16:21:36 GMT"}, {"version": "v3", "created": "Mon, 16 Apr 2018 08:43:16 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Childs", "Andrew M.", ""], ["Jao", "David", ""], ["Soukharev", "Vladimir", ""]]}, {"id": "1012.4404", "submitter": "Walter Quattrociocchi", "authors": "Sara Brunetti, Elena Lodi, Walter Quattrociocchi", "title": "Multicolored Dynamos on Toroidal Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting on a graph the presence of the minimum number of nodes (target set)\nthat will be able to \"activate\" a prescribed number of vertices in the graph is\ncalled the target set selection problem (TSS) proposed by Kempe, Kleinberg, and\nTardos. In TSS's settings, nodes have two possible states (active or\nnon-active) and the threshold triggering the activation of a node is given by\nthe number of its active neighbors. Dealing with fault tolerance in a majority\nbased system the two possible states are used to denote faulty or non-faulty\nnodes, and the threshold is given by the state of the majority of neighbors.\nHere, the major effort was in determining the distribution of initial faults\nleading the entire system to a faulty behavior. Such an activation pattern,\nalso known as dynamic monopoly (or shortly dynamo), was introduced by Peleg in\n1996. In this paper we extend the TSS problem's settings by representing nodes'\nstates with a \"multicolored\" set. The extended version of the problem can be\ndescribed as follows: let G be a simple connected graph where every node is\nassigned a color from a finite ordered set C = {1, . . ., k} of colors. At each\nlocal time step, each node can recolor itself, depending on the local\nconfigurations, with the color held by the majority of its neighbors. Given G,\nwe study the initial distributions of colors leading the system to a k\nmonochromatic configuration in toroidal meshes, focusing on the minimum number\nof initial k-colored nodes. We find upper and lower bounds to the size of a\ndynamo, and then special classes of dynamos, outlined by means of a new\napproach based on recoloring patterns, are characterized.\n", "versions": [{"version": "v1", "created": "Mon, 20 Dec 2010 17:02:51 GMT"}], "update_date": "2010-12-21", "authors_parsed": [["Brunetti", "Sara", ""], ["Lodi", "Elena", ""], ["Quattrociocchi", "Walter", ""]]}, {"id": "1012.4427", "submitter": "Tsuyoshi Ito", "authors": "Tsuyoshi Ito, Hirotada Kobayashi, John Watrous", "title": "Quantum interactive proofs with weak error bounds", "comments": "18 pages. v3: improved presentation, corrected minor errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proves that the computational power of quantum interactive proof\nsystems, with a double-exponentially small gap in acceptance probability\nbetween the completeness and soundness cases, is precisely characterized by\nEXP, the class of problems solvable in exponential time by deterministic Turing\nmachines. This fact, and our proof of it, has implications concerning quantum\nand classical interactive proof systems in the setting of unbounded error that\ninclude the following:\n  * Quantum interactive proof systems are strictly more powerful than their\nclassical counterparts in the unbounded-error setting unless PSPACE=EXP, as\neven unbounded error classical interactive proof systems can be simulated in\nPSPACE.\n  * The recent proof of Jain, Ji, Upadhyay, and Watrous (STOC 2010)\nestablishing QIP=PSPACE relies heavily on the fact that the quantum interactive\nproof systems defining the class QIP have bounded error. Our result implies\nthat some nontrivial assumption on the error bounds for quantum interactive\nproofs is unavoidable to establish this result (unless PSPACE=EXP).\n  * To prove our result, we give a quantum interactive proof system for EXP\nwith perfect completeness and soundness error 1-2^{-2^poly}, for which the\nsoundness error bound is provably tight. This establishes another respect in\nwhich quantum and classical interactive proof systems differ, because such a\nbound cannot hold for any classical interactive proof system: distinct\nacceptance probabilities for classical interactive proof systems must be\nseparated by a gap that is at least (single-)exponentially small.\n  We also study the computational power of a few other related unbounded-error\ncomplexity classes.\n", "versions": [{"version": "v1", "created": "Mon, 20 Dec 2010 18:28:57 GMT"}, {"version": "v2", "created": "Wed, 22 Dec 2010 19:54:27 GMT"}, {"version": "v3", "created": "Tue, 6 Sep 2011 17:49:48 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Ito", "Tsuyoshi", ""], ["Kobayashi", "Hirotada", ""], ["Watrous", "John", ""]]}, {"id": "1012.4701", "submitter": "Bart M. P. Jansen", "authors": "Bart M. P. Jansen and Hans L. Bodlaender", "title": "Vertex Cover Kernelization Revisited: Upper and Lower Bounds for a\n  Refined Parameter", "comments": "Published in \"Theory of Computing Systems\" as an Open Access\n  publication", "journal-ref": "Theory Comput. Syst. 53(2): 263-299 (2013)", "doi": "10.1007/s00224-012-9393-4", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important result in the study of polynomial-time preprocessing shows that\nthere is an algorithm which given an instance (G,k) of Vertex Cover outputs an\nequivalent instance (G',k') in polynomial time with the guarantee that G' has\nat most 2k' vertices (and thus O((k')^2) edges) with k' <= k. Using the\nterminology of parameterized complexity we say that k-Vertex Cover has a kernel\nwith 2k vertices. There is complexity-theoretic evidence that both 2k vertices\nand Theta(k^2) edges are optimal for the kernel size. In this paper we consider\nthe Vertex Cover problem with a different parameter, the size fvs(G) of a\nminimum feedback vertex set for G. This refined parameter is structurally\nsmaller than the parameter k associated to the vertex covering number vc(G)\nsince fvs(G) <= vc(G) and the difference can be arbitrarily large. We give a\nkernel for Vertex Cover with a number of vertices that is cubic in fvs(G): an\ninstance (G,X,k) of Vertex Cover, where X is a feedback vertex set for G, can\nbe transformed in polynomial time into an equivalent instance (G',X',k') such\nthat |V(G')| <= 2k and |V(G')| <= O(|X'|^3). A similar result holds when the\nfeedback vertex set X is not given along with the input. In sharp contrast we\nshow that the Weighted Vertex Cover problem does not have a polynomial kernel\nwhen parameterized by the cardinality of a given vertex cover of the graph\nunless NP is in coNP/poly and the polynomial hierarchy collapses to the third\nlevel.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 15:47:46 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2013 15:41:10 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Jansen", "Bart M. P.", ""], ["Bodlaender", "Hans L.", ""]]}, {"id": "1012.4874", "submitter": "Xiaoxin Zhang", "authors": "Xiaoxin Zhang, Liang Chen, Jianwei Huang, Minghua Chen, and Yuping\n  Zhao", "title": "Distributed and Optimal Reduced Primal-Dual Algorithm for Uplink OFDM\n  Resource Allocation", "comments": "12 pages, 22 figures, and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CC cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Orthogonal Frequency Division Multiplexing (OFDM) is the key component of\nmany emerging broadband wireless access standards. The resource allocation in\nOFDM uplink, however, is challenging due to heterogeneity of users' Quality of\nService requirements, channel conditions, and individual resource constraints.\nWe formulate the resource allocation problem as a non-strictly convex\noptimization problem, which typically has multiple global optimal solutions. We\nthen propose a reduced primal-dual algorithm, which is distributed, low in\ncomputational complexity, and probably globally convergent to a global optimal\nsolution. The performance of the algorithm is studied through a realistic OFDM\nsimulator. Compared with the previously proposed centralized optimal algorithm,\nour algorithm not only significantly reduces the message overhead but also\nrequires less iterations to converge.\n", "versions": [{"version": "v1", "created": "Wed, 22 Dec 2010 03:34:38 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Zhang", "Xiaoxin", ""], ["Chen", "Liang", ""], ["Huang", "Jianwei", ""], ["Chen", "Minghua", ""], ["Zhao", "Yuping", ""]]}, {"id": "1012.4889", "submitter": "Mert Sa\\u{g}lam", "authors": "Hossein Jowhari, Mert Sa\\u{g}lam, G\\'abor Tardos", "title": "Tight Bounds for Lp Samplers, Finding Duplicates in Streams, and Related\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present near-optimal space bounds for Lp-samplers. Given a\nstream of updates (additions and subtraction) to the coordinates of an\nunderlying vector x \\in R^n, a perfect Lp sampler outputs the i-th coordinate\nwith probability |x_i|^p/||x||_p^p. In SODA 2010, Monemizadeh and Woodruff\nshowed polylog space upper bounds for approximate Lp-samplers and demonstrated\nvarious applications of them. Very recently, Andoni, Krauthgamer and Onak\nimproved the upper bounds and gave a O(\\epsilon^{-p} log^3 n) space \\epsilon\nrelative error and constant failure rate Lp-sampler for p \\in [1,2]. In this\nwork, we give another such algorithm requiring only O(\\epsilon^{-p} log^2 n)\nspace for p \\in (1,2). For p \\in (0,1), our space bound is O(\\epsilon^{-1}\nlog^2 n), while for the $p=1$ case we have an O(log(1/\\epsilon)\\epsilon^{-1}\nlog^2 n) space algorithm. We also give a O(log^2 n) bits zero relative error\nL0-sampler, improving the O(log^3 n) bits algorithm due to Frahling, Indyk and\nSohler.\n  As an application of our samplers, we give better upper bounds for the\nproblem of finding duplicates in data streams. In case the length of the stream\nis longer than the alphabet size, L1 sampling gives us an O(log^2 n) space\nalgorithm, thus improving the previous O(log^3 n) bound due to Gopalan and\nRadhakrishnan.\n  In the second part of our work, we prove an Omega(log^2 n) lower bound for\nsampling from 0, \\pm 1 vectors (in this special case, the parameter p is not\nrelevant for Lp sampling). This matches the space of our sampling algorithms\nfor constant \\epsilon > 0. We also prove tight space lower bounds for the\nfinding duplicates and heavy hitters problems. We obtain these lower bounds\nusing reductions from the communication complexity problem augmented indexing.\n", "versions": [{"version": "v1", "created": "Wed, 22 Dec 2010 06:55:58 GMT"}], "update_date": "2010-12-23", "authors_parsed": [["Jowhari", "Hossein", ""], ["Sa\u011flam", "Mert", ""], ["Tardos", "G\u00e1bor", ""]]}, {"id": "1012.5130", "submitter": "Naoyuki Kamiyama", "authors": "Naoyuki Kamiyama", "title": "A Relation between the Protocol Partition Number and the Quasi-Additive\n  Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we show that the linear programming for computing the\nquasi-additive bound of the formula size of a Boolean function presented by\nUeno [MFCS'10] is equivalent to the dual problem of the linear programming\nrelaxation of an integer programming for computing the protocol partition\nnumber. Together with the result of Ueno [MFCS'10], our results imply that\nthere exists no gap between our integer programming for computing the protocol\npartition number and its linear programming relaxation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Dec 2010 01:57:18 GMT"}], "update_date": "2010-12-24", "authors_parsed": [["Kamiyama", "Naoyuki", ""]]}, {"id": "1012.5141", "submitter": "Shengyu Zhang", "authors": "Shengyu Zhang", "title": "Quantum Strategic Game Theory", "comments": "38 pages. Presented in QIP 2011. v2: more on background, our model\n  and related work; a conjecture added; discussion added for CE generation with\n  untrusted local operations", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet rich model to extend the notions of Nash equilibria\nand correlated equilibria of strategic games to the quantum setting, in which\nwe then study the relations between classical and quantum equilibria. Unlike\nthe previous work that focus on qualitative questions on specific games of\nsmall sizes, we address the following fundamental and quantitative question for\ngeneral games:\n  How much \"advantage\" can playing quantum strategies provide, if any?\n  Two measures of the advantage are studied, summarized as follows.\n  1. A natural measure is the increase of payoff. We consider natural mappings\nbetween classical and quantum states, and study how well those mappings\npreserve the equilibrium properties. Among other results, we exhibit correlated\nequilibrium $p$ whose quantum superposition counterpart $\\sum_s\n\\sqrt{p(s)}\\ket{s}$ is far from being a quantum correlated equilibrium;\nactually a player can increase her payoff from almost 0 to almost 1 in a\n[0,1]-normalized game. We achieve this by a tensor product construction on\ncarefully designed base cases.\n  2. For studying the hardness of generating correlated equilibria, we propose\nto examine \\emph{correlation complexity}, a new complexity measure for\ncorrelation generation. We show that there are $n$-bit correlated equilibria\nwhich can be generated by only one EPR pair followed by local operation\n(without communication), but need at least $\\log(n)$ classical shared random\nbits plus communication. The randomized lower bound can be improved to $n$, the\nbest possible, assuming (even a much weaker version of) a recent conjecture in\nlinear algebra. We believe that the correlation complexity, as a\ncomplexity-theoretical counterpart of the celebrated Bell's inequality, has\nindependent interest in both physics and computational complexity theory and\ndeserves more explorations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Dec 2010 04:13:11 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2011 00:31:07 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Zhang", "Shengyu", ""]]}, {"id": "1012.5248", "submitter": "Sergey Verlan", "authors": "Ion Petre, Sergey Verlan", "title": "Matrix Insertion-Deletion Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.CL cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider for the first time the operations of insertion\nand deletion working in a matrix controlled manner. We show that, similarly as\nin the case of context-free productions, the computational power is strictly\nincreased when using a matrix control: computational completeness can be\nobtained by systems with insertion or deletion rules involving at most two\nsymbols in a contextual or in a context-free manner and using only binary\nmatrices.\n", "versions": [{"version": "v1", "created": "Thu, 23 Dec 2010 17:00:40 GMT"}], "update_date": "2010-12-24", "authors_parsed": [["Petre", "Ion", ""], ["Verlan", "Sergey", ""]]}, {"id": "1012.5563", "submitter": "EPTCS", "authors": "Ren\\'e Thiemann (University of Innsbruck, Austria), Christian\n  Sternagel (University of Innsbruck, Austria), J\\\"urgen Giesl (RWTH Aachen\n  University, Germany), Peter Schneider-Kamp (University of Southern Denmark,\n  Denmark)", "title": "Loops under Strategies ... Continued", "comments": "In Proceedings IWS 2010, arXiv:1012.5337", "journal-ref": "EPTCS 44, 2010, pp. 51-65", "doi": "10.4204/EPTCS.44.4", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there are many approaches for automatically proving termination of term\nrewrite systems, up to now there exist only few techniques to disprove their\ntermination automatically. Almost all of these techniques try to find loops,\nwhere the existence of a loop implies non-termination of the rewrite system.\nHowever, most programming languages use specific evaluation strategies, whereas\nloop detection techniques usually do not take strategies into account. So even\nif a rewrite system has a loop, it may still be terminating under certain\nstrategies.\n  Therefore, our goal is to develop decision procedures which can determine\nwhether a given loop is also a loop under the respective evaluation strategy.\nIn earlier work, such procedures were presented for the strategies of\ninnermost, outermost, and context-sensitive evaluation. In the current paper,\nwe build upon this work and develop such decision procedures for important\nstrategies like leftmost-innermost, leftmost-outermost,\n(max-)parallel-innermost, (max-)parallel-outermost, and forbidden patterns\n(which generalize innermost, outermost, and context-sensitive strategies). In\nthis way, we obtain the first approach to disprove termination under these\nstrategies automatically.\n", "versions": [{"version": "v1", "created": "Mon, 27 Dec 2010 06:30:24 GMT"}], "update_date": "2010-12-30", "authors_parsed": [["Thiemann", "Ren\u00e9", "", "University of Innsbruck, Austria"], ["Sternagel", "Christian", "", "University of Innsbruck, Austria"], ["Giesl", "J\u00fcrgen", "", "RWTH Aachen\n  University, Germany"], ["Schneider-Kamp", "Peter", "", "University of Southern Denmark,\n  Denmark"]]}, {"id": "1012.5568", "submitter": "Prabhu Manyem", "authors": "Prabhu Manyem", "title": "Duality Gap, Computational Complexity and NP Completeness: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey research that studies the connection between the computational\ncomplexity of optimization problems on the one hand, and the duality gap\nbetween the primal and dual optimization problems on the other. To our\nknowledge, this is the first survey that connects the two very important areas.\nWe further look at a similar phenomenon in finite model theory relating to\ncomplexity and optimization.\n", "versions": [{"version": "v1", "created": "Mon, 27 Dec 2010 07:08:28 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2011 08:36:29 GMT"}], "update_date": "2011-11-16", "authors_parsed": [["Manyem", "Prabhu", ""]]}, {"id": "1012.5659", "submitter": "Xi Chen", "authors": "Jin-Yi Cai and Xi Chen and Pinyan Lu", "title": "Non-negative Weighted #CSPs: An Effective Complexity Dichotomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a complexity dichotomy theorem for all non-negative weighted\ncounting Constraint Satisfaction Problems (CSP). This caps a long series of\nimportant results on counting problems including unweighted and weighted graph\nhomomorphisms and the celebrated dichotomy theorem for unweighted #CSP. Our\ndichotomy theorem gives a succinct criterion for tractability. If a set F of\nconstraint functions satisfies the criterion, then the counting CSP problem\ndefined by F is solvable in polynomial time; if it does not satisfy the\ncriterion, then the problem is #P-hard. We furthermore show that the question\nof whether F satisfies the criterion is decidable in NP.\n  Surprisingly, our tractability criterion is simpler than the previous\ncriteria for the more restricted classes of problems, although when specialized\nto those cases, they are logically equivalent. Our proof mainly uses Linear\nAlgebra, and represents a departure from Universal Algebra, the dominant\nmethodology in recent years.\n", "versions": [{"version": "v1", "created": "Mon, 27 Dec 2010 20:49:07 GMT"}], "update_date": "2010-12-30", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Chen", "Xi", ""], ["Lu", "Pinyan", ""]]}, {"id": "1012.5699", "submitter": "Matthew McKague", "authors": "Matthew McKague", "title": "Interactive proofs with efficient quantum prover for recursive Fourier\n  sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recursive Fourier sampling problem (RFS), and show that there\nexists an interactive proof for RFS with an efficient classical verifier and\nefficient quantum prover.\n", "versions": [{"version": "v1", "created": "Tue, 28 Dec 2010 05:33:27 GMT"}, {"version": "v2", "created": "Wed, 24 Aug 2011 03:56:00 GMT"}], "update_date": "2011-08-25", "authors_parsed": [["McKague", "Matthew", ""]]}, {"id": "1012.5804", "submitter": "Algirdas Antano Maknickas Dr.", "authors": "Algirdas Antano Maknickas", "title": "Finding of k in Fagin's R. Theorem 24", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  By using of analytical multi-logic expresses in conjunction with\nnon-deterministic Turing machine the proposition was proved that algorithm of\ndeterministic Turing counter machine of polynomial time complexity can be\ndecreased to the algorithm of linear time complexity in non-deterministic\nTuring counter machine. Furthermore, it was shown that existence of reduction\nof polynomial time complexity to the linear time complexity by switching from\ndeterministic to non-deterministic Turing machine for string recognition imply\nP equals to NP. Analytical generation functions of higher order logic were used\nfor finding of k value in Fagin's R. Theorem 24.\n", "versions": [{"version": "v1", "created": "Tue, 28 Dec 2010 17:46:39 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2012 06:49:34 GMT"}, {"version": "v3", "created": "Mon, 17 Oct 2016 13:34:56 GMT"}, {"version": "v4", "created": "Wed, 19 Oct 2016 09:09:58 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Maknickas", "Algirdas Antano", ""]]}]