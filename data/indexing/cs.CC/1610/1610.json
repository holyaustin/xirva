[{"id": "1610.00159", "submitter": "Christian Ikenmeyer", "authors": "Christian Ikenmeyer and J.M. Landsberg", "title": "On the complexity of the permanent in various computational models", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer a question in [Landsberg, Ressayre, 2015], showing the regular\ndeterminantal complexity of the determinant det_m is O(m^3). We answer\nquestions in, and generalize results of [Aravind, Joglekar, 2015], showing\nthere is no rank one determinantal expression for perm_m or det_m when m >= 3.\nFinally we state and prove several \"folklore\" results relating different models\nof computation.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 17:04:36 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Ikenmeyer", "Christian", ""], ["Landsberg", "J. M.", ""]]}, {"id": "1610.00353", "submitter": "Moustapha Diaby", "authors": "M. Diaby, M.H. Karwan, and L. Sun", "title": "Exact extended formulation of the linear assignment problem (LAP)\n  polytope for solving the traveling salesman and quadratic assignment problems", "comments": "36 pages; 9 figures; 2 tables. Revision of the model in \"A\n  Small-Order-Polynomial-Sized Linear Program for Solving the Traveling\n  Salesman Problem.\" Model and proofs are more straightforward and much\n  simpler. In this version (#7): Step 2.b of the proof of integrality has been\n  elaborated on, while the whole proof has been further streamlined", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an O(n^6 ) linear programming model for the traveling salesman\n(TSP) and quadratic assignment (QAP) problems. The basic model is developed\nwithin the framework of the TSP. It does not involve the city-to-city\nvariables-based, traditional TSP polytope referred to in the literature as \"the\nTSP polytope.\" We do not model explicit Hamiltonian cycles of the cities.\nInstead, we use a time-dependent abstraction of TSP tours and develop a direct\nextended formulation of the linear assignment problem (LAP) polytope. The model\nis exact in the sense that it has integral extreme points which are in\none-to-one correspondence with TSP tours. It can be solved optimally using any\nlinear programming (LP) solver, hence offering a new (incidental) proof of the\nequality of the computational complexity classes \"P\" and \"NP.\" The extensions\nof the model to the time-dependent traveling salesman problem (TDTSP) as well\nas the quadratic assignment problem (QAP) are straightforward. The reasons for\nthe non-applicability of existing negative extended formulations results for\n\"the TSP polytope\" to the model in this paper as well as our software\nimplementation and the computational experimentation we conducted are briefly\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 21:31:19 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 06:40:18 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 23:20:01 GMT"}, {"version": "v4", "created": "Mon, 11 Feb 2019 21:49:08 GMT"}, {"version": "v5", "created": "Sat, 6 Apr 2019 00:02:30 GMT"}, {"version": "v6", "created": "Mon, 29 Apr 2019 15:10:49 GMT"}, {"version": "v7", "created": "Sat, 11 May 2019 14:28:08 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Diaby", "M.", ""], ["Karwan", "M. H.", ""], ["Sun", "L.", ""]]}, {"id": "1610.00373", "submitter": "Georg Zetzsche", "authors": "Markus Lohrey and Georg Zetzsche", "title": "The Complexity of Knapsack in Graph Groups", "comments": "26 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Myasnikov et al. have introduced the knapsack problem for arbitrary finitely\ngenerated groups. In previous work, the authors proved that for each graph\ngroup, the knapsack problem can be solved in $\\mathsf{NP}$. Here, we determine\nthe exact complexity of the problem for every graph group. While the problem is\n$\\mathsf{TC}^0$-complete for complete graphs, it is $\\mathsf{LogCFL}$-complete\nfor each (non-complete) transitive forest. For every remaining graph, the\nproblem is $\\mathsf{NP}$-complete.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 00:05:08 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 15:34:54 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Lohrey", "Markus", ""], ["Zetzsche", "Georg", ""]]}, {"id": "1610.00571", "submitter": "Vincent Jug\\'e", "authors": "Patricia Bouyer and Vincent Jug\\'e and Nicolas Markey", "title": "Dynamic Complexity of Parity Games with Bounded Tree-Width", "comments": "33 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic complexity is concerned with updating the output of a problem when\nthe input is slightly changed. We study the dynamic complexity of two-player\nparity games over graphs of bounded tree-width, where updates may add or delete\nedges, or change the owner or color of states. We show that this problem is in\nDynFO (with LOGSPACE precomputation); this is achieved by a reduction to a\nDyck-path problem on an acyclic automaton.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 14:40:55 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Bouyer", "Patricia", ""], ["Jug\u00e9", "Vincent", ""], ["Markey", "Nicolas", ""]]}, {"id": "1610.01019", "submitter": "Victor Dalmau", "authors": "Victor Dalmau, Andrei Krokhin, Rajsekar Manokaran", "title": "Towards a Characterization of Constant-Factor Approximable Finite-Valued\n  CSPs", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the approximability of (Finite-)Valued Constraint\nSatisfaction Problems (VCSPs) with a fixed finite constraint language {\\Gamma}\nconsisting of finitary functions on a fixed finite domain. An instance of VCSP\nis given by a finite set of variables and a sum of functions belonging to\n{\\Gamma} and depending on a subset of the variables. Each function takes values\nin [0, 1] specifying costs of assignments of labels to its variables, and the\ngoal is to find an assignment of labels to the variables that minimizes the\nsum. A recent result of Ene et al. says that, under the mild technical\ncondition that {\\Gamma} contains the equality relation, the basic LP relaxation\nis optimal for constant-factor approximation for VCSP({\\Gamma}) unless the\nUnique Games Conjecture fails. Using the algebraic approach to the CSP, we give\nnew natural algebraic conditions for the finiteness of the integrality gap for\nthe basic LP relaxation of VCSP({\\Gamma}). We also show how these algebraic\nconditions can in principle be used to round solutions of the basic LP\nrelaxation, and how, for several examples that cover all previously known\ncases, this leads to efficient constant-factor approximation algorithms.\nFinally, we show that the absence of another algebraic condition leads to\nNP-hardness of constant-factor approximation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 14:31:40 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 13:35:16 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Dalmau", "Victor", ""], ["Krokhin", "Andrei", ""], ["Manokaran", "Rajsekar", ""]]}, {"id": "1610.01185", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra and Daniel Rubery", "title": "Recursion-Theoretic Ranking and Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For which sets A does there exist a mapping, computed by a total or partial\nrecursive function, such that the mapping, when its domain is restricted to A,\nis a 1-to-1, onto mapping to $\\Sigma^*$? And for which sets A does there exist\nsuch a mapping that respects the lexicographical ordering within A? Both cases\nare types of perfect, minimal hash functions. The complexity-theoretic versions\nof these notions are known as compression functions and ranking functions. The\npresent paper defines and studies the recursion-theoretic versions of\ncompression and ranking functions, and in particular studies the question of\nwhich sets have, or lack, such functions. Thus, this is a case where, in\ncontrast to the usual direction of notion transferal, notions from complexity\ntheory are inspiring notions, and an investigation, in computability theory.\n  We show that the rankable and compressible sets broadly populate the\n1-truth-table degrees, and we prove that every nonempty coRE cylinder is\nrecursively compressible.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 20:18:40 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 04:48:14 GMT"}, {"version": "v3", "created": "Fri, 20 Oct 2017 14:38:45 GMT"}, {"version": "v4", "created": "Fri, 24 Nov 2017 17:05:31 GMT"}, {"version": "v5", "created": "Wed, 29 Nov 2017 03:48:13 GMT"}, {"version": "v6", "created": "Mon, 4 Dec 2017 03:35:47 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Hemaspaandra", "Lane A.", ""], ["Rubery", "Daniel", ""]]}, {"id": "1610.01199", "submitter": "William Hoza", "authors": "William M. Hoza and Chris Umans", "title": "Targeted Pseudorandom Generators, Simulation Advice Generators, and\n  Derandomizing Logspace", "comments": "24 pages, 2 figures; added more commentary and references, fixed\n  typos, changed notation and formatting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume that for every derandomization result for logspace algorithms, there\nis a pseudorandom generator strong enough to nearly recover the derandomization\nby iterating over all seeds and taking a majority vote. We prove under a\nprecise version of this assumption that $\\mathbf{BPL} \\subseteq \\bigcap_{\\alpha\n> 0} \\mathbf{DSPACE}(\\log^{1 + \\alpha} n)$.\n  We strengthen the theorem to an equivalence by considering two\ngeneralizations of the concept of a pseudorandom generator against logspace. A\ntargeted pseudorandom generator against logspace takes as input a short uniform\nrandom seed and a finite automaton; it outputs a long bitstring that looks\nrandom to that particular automaton. A simulation advice generator for logspace\nstretches a small uniform random seed into a long advice string; the\nrequirement is that there is some logspace algorithm that, given a finite\nautomaton and this advice string, simulates the automaton reading a long\nuniform random input. We prove that $\\bigcap_{\\alpha > 0}\n\\mathbf{promise\\mbox{-}BPSPACE}(\\log^{1 + \\alpha} n) = \\bigcap_{\\alpha > 0}\n\\mathbf{promise\\mbox{-}DSPACE}(\\log^{1 + \\alpha} n)$ if and only if for every\ntargeted pseudorandom generator against logspace, there is a simulation advice\ngenerator for logspace with similar parameters.\n  Finally, we observe that in a certain uniform setting (namely, if we only\nworry about sequences of automata that can be generated in logspace), targeted\npseudorandom generators against logspace can be transformed into simulation\nadvice generators with similar parameters.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 20:56:10 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2016 15:59:04 GMT"}, {"version": "v3", "created": "Sat, 29 Oct 2016 05:56:23 GMT"}, {"version": "v4", "created": "Sun, 9 Apr 2017 20:23:27 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Hoza", "William M.", ""], ["Umans", "Chris", ""]]}, {"id": "1610.01920", "submitter": "Daowen Qiu", "authors": "Guangya Cai, Daowen Qiu", "title": "Optimal Separation in Exact Query Complexities for Simon's Problem", "comments": "16 pages; some minor changes have been made; comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simon's problem is one of the most important problems demonstrating the power\nof quantum computers, which achieves a large separation between quantum and\nclassical query complexities. However, Simon's discussion on his problem was\nlimited to bounded-error setting, which means his algorithm can not always get\nthe correct answer. Exact quantum algorithms for Simon's problem have also been\nproposed, which deterministically solve the problem with O(n) queries. Also the\nquantum lower bound \\Omega(n) for Simon's problem is known. Although these\nalgorithms are either complicated or specialized, their results give an O(n)\nversus \\Omega(\\sqrt{2^{n}}) separation in exact query complexities for Simon's\nproblem (\\Omega(\\sqrt{2^{n}}) is the lower bound for classical probabilistic\nalgorithms), but it has not been proved whether this separation is optimal. In\nthis paper, we propose another exact quantum algorithm for solving Simon's\nproblem with O(n) queries, which is simple, concrete and does not rely on\nspecial query oracles. Our algorithm combines Simon's algorithm with the\nquantum amplitude amplification technique to ensure its determinism. In\nparticular, we show that Simon's problem can be solved by a classical\ndeterministic algorithm with O(\\sqrt{2^{n}}) queries (as we are aware, there\nwere no classical deterministic algorithms for solving Simon's problem with\nO(\\sqrt{2^{n}}) queries). Combining some previous results, we obtain the\noptimal separation in exact query complexities for Simon's problem: \\Theta({n})\nversus \\Theta({\\sqrt{2^{n}}}).\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 16:08:35 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 13:46:51 GMT"}, {"version": "v3", "created": "Mon, 10 Oct 2016 04:19:14 GMT"}, {"version": "v4", "created": "Thu, 29 Dec 2016 14:45:44 GMT"}, {"version": "v5", "created": "Tue, 3 Jan 2017 14:43:42 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Cai", "Guangya", ""], ["Qiu", "Daowen", ""]]}, {"id": "1610.02336", "submitter": "Ramin Yarinezhad", "authors": "Ramin Yarinezhad, Seyed Naser Hashemi", "title": "Approximation Algorithms for Multi-Multiway Cut and Multicut Problems on\n  Directed Graphs", "comments": "This version is completely correct and does not have any problem. All\n  mistakes are corrected in this version. AUT Journal of Mathematics and\n  Computing (2020)", "journal-ref": null, "doi": "10.22060/AJMC.2018.15109.1014", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present two approximation algorithms for the directed\nmulti-multiway cut and directed multicut problems. The so called region growing\nparadigm \\cite{1} is modified and used for these two cut problems on directed\ngraphs. By using this paradigm, we give for each problem an approximation\nalgorithm such that both algorithms have the approximate factor $O(k)$ the same\nas the previous works done on these problems. However, the previous works need\nto solve $k$ linear programming, whereas our algorithms require only one linear\nprogramming. Therefore, our algorithms improve the running time of the previous\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 16:09:43 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 17:48:59 GMT"}, {"version": "v3", "created": "Wed, 7 Feb 2018 20:06:07 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2019 17:21:43 GMT"}, {"version": "v5", "created": "Sat, 30 Mar 2019 12:36:40 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Yarinezhad", "Ramin", ""], ["Hashemi", "Seyed Naser", ""]]}, {"id": "1610.02686", "submitter": "Vladimir Podolskii", "authors": "Alexander S. Kulikov, Vladimir V. Podolskii", "title": "Computing Majority by Constant Depth Majority Circuits with Low Fan-in\n  Gates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following computational problem: for which values of $k$, the\nmajority of $n$ bits $\\text{MAJ}_n$ can be computed with a depth two formula\nwhose each gate computes a majority function of at most $k$ bits? The\ncorresponding computational model is denoted by $\\text{MAJ}_k \\circ\n\\text{MAJ}_k$. We observe that the minimum value of $k$ for which there exists\na $\\text{MAJ}_k \\circ \\text{MAJ}_k$ circuit that has high correlation with the\nmajority of $n$ bits is equal to $\\Theta(n^{1/2})$. We then show that for a\nrandomized $\\text{MAJ}_k \\circ \\text{MAJ}_k$ circuit computing the majority of\n$n$ input bits with high probability for every input, the minimum value of $k$\nis equal to $n^{2/3+o(1)}$. We show a worst case lower bound: if a\n$\\text{MAJ}_k \\circ \\text{MAJ}_k$ circuit computes the majority of $n$ bits\ncorrectly on all inputs, then $k\\geq n^{13/19+o(1)}$. This lower bound exceeds\nthe optimal value for randomized circuits and thus is unreachable for pure\nrandomized techniques. For depth $3$ circuits we show that a circuit with $k=\nO(n^{2/3})$ can compute $\\text{MAJ}_n$ correctly on all inputs.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 15:37:17 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Kulikov", "Alexander S.", ""], ["Podolskii", "Vladimir V.", ""]]}, {"id": "1610.02704", "submitter": "Pravesh K Kothari", "authors": "Pravesh K. Kothari, Raghu Meka and Prasad Raghavendra", "title": "Approximating Rectangles by Juntas and Weakly-Exponential Lower Bounds\n  for LP Relaxations of CSPs", "comments": "Fixed bug in the statement of Theorem 1.7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for constraint satisfaction problems (CSPs), sub-exponential\nsize linear programming relaxations are as powerful as $n^{\\Omega(1)}$-rounds\nof the Sherali-Adams linear programming hierarchy. As a corollary, we obtain\nsub-exponential size lower bounds for linear programming relaxations that beat\nrandom guessing for many CSPs such as MAX-CUT and MAX-3SAT. This is a\nnearly-exponential improvement over previous results, previously, it was only\nknown that linear programs of size $n^{o(\\log n)}$ cannot beat random guessing\nfor any CSP (Chan-Lee-Raghavendra-Steurer 2013).\n  Our bounds are obtained by exploiting and extending the recent progress in\ncommunication complexity for \"lifting\" query lower bounds to communication\nproblems. The main ingredient in our results is a new structural result on\n\"high-entropy rectangles\" that may of independent interest in communication\ncomplexity.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 18:11:58 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2016 06:09:56 GMT"}, {"version": "v3", "created": "Sun, 20 Nov 2016 00:03:59 GMT"}, {"version": "v4", "created": "Sat, 30 Dec 2017 20:02:39 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Kothari", "Pravesh K.", ""], ["Meka", "Raghu", ""], ["Raghavendra", "Prasad", ""]]}, {"id": "1610.03029", "submitter": "David Witmer", "authors": "Ryuhei Mori, David Witmer", "title": "Lower bounds for CSP refutation by SDP hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a $k$-ary predicate $P$, a random instance of CSP$(P)$ with $n$ variables\nand $m$ constraints is unsatisfiable with high probability when $m \\gg n$. The\nnatural algorithmic task in this regime is \\emph{refutation}: finding a proof\nthat a given random instance is unsatisfiable. Recent work of Allen et al.\nsuggests that the difficulty of refuting CSP$(P)$ using an SDP is determined by\na parameter $\\mathrm{cmplx}(P)$, the smallest $t$ for which there does not\nexist a $t$-wise uniform distribution over satisfying assignments to $P$. In\nparticular they show that random instances of CSP$(P)$ with $m \\gg\nn^{\\mathrm{cmplx(P)}/2}$ can be refuted efficiently using an SDP.\n  In this work, we give evidence that $n^{\\mathrm{cmplx}(P)/2}$ constraints are\nalso \\emph{necessary} for refutation using SDPs. Specifically, we show that if\n$P$ supports a $(t-1)$-wise uniform distribution over satisfying assignments,\nthen the Sherali-Adams$_+$ and Lov\\'{a}sz-Schrijver$_+$ SDP hierarchies cannot\nrefute a random instance of CSP$(P)$ in polynomial time for any $m \\leq\nn^{t/2-\\epsilon}$.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 19:05:54 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Mori", "Ryuhei", ""], ["Witmer", "David", ""]]}, {"id": "1610.03133", "submitter": "Zhengfeng Ji", "authors": "Zhengfeng Ji", "title": "Compression of Quantum Multi-Prover Interactive Proofs", "comments": "56 pages, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a protocol that transforms any quantum multi-prover interactive\nproof into a nonlocal game in which questions consist of logarithmic number of\nbits and answers of constant number of bits. As a corollary, this proves that\nthe promise problem corresponding to the approximation of the nonlocal value to\ninverse polynomial accuracy is complete for QMIP*, and therefore NEXP-hard.\nThis establishes that nonlocal games are provably harder than classical games\nwithout any complexity theory assumptions. Our result also indicates that gap\namplification for nonlocal games may be impossible in general and provides a\nnegative evidence for the possibility of the gap amplification approach to the\nmulti-prover variant of the quantum PCP conjecture.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 23:44:23 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Ji", "Zhengfeng", ""]]}, {"id": "1610.03266", "submitter": "Qian Li", "authors": "Qian Li, Xiaoming Sun, and Jialin Zhang", "title": "On the Optimality of Tape Merge of Two Lists with Similar Size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of merging sorted lists in the least number of pairwise\ncomparisons has been solved completely only for a few special cases. Graham and\nKarp \\cite{taocp} independently discovered that the tape merge algorithm is\noptimal in the worst case when the two lists have the same size. In the seminal\npapers, Stockmeyer and Yao\\cite{yao}, Murphy and Paull\\cite{3k3}, and\nChristen\\cite{christen1978optimality} independently showed when the lists to be\nmerged are of size $m$ and $n$ satisfying $m\\leq\nn\\leq\\lfloor\\frac{3}{2}m\\rfloor+1$, the tape merge algorithm is optimal in the\nworst case. This paper extends this result by showing that the tape merge\nalgorithm is optimal in the worst case whenever the size of one list is no\nlarger than 1.52 times the size of the other. The main tool we used to prove\nlower bounds is Knuth's adversary methods \\cite{taocp}. In addition, we show\nthat the lower bound cannot be improved to 1.8 via Knuth's adversary methods.\nWe also develop a new inequality about Knuth's adversary methods, which might\nbe interesting in its own right. Moreover, we design a simple procedure to\nachieve constant improvement of the upper bounds for $2m-2\\leq n\\leq 3m $.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 10:21:28 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Li", "Qian", ""], ["Sun", "Xiaoming", ""], ["Zhang", "Jialin", ""]]}, {"id": "1610.03543", "submitter": "Guy Kindler", "authors": "Guy Kindler and Ryan O`Donnell", "title": "Quantum automata cannot detect biased coins, even in the limit", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aaronson and Drucker (2011) asked whether there exists a quantum finite\nautomaton that can distinguish fair coin tosses from biased ones by spending\nsignificantly more time in accepting states, on average, given an infinite\nsequence of tosses. We answer this question negatively.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 21:52:05 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Kindler", "Guy", ""], ["O`Donnell", "Ryan", ""]]}, {"id": "1610.03574", "submitter": "Anand Natarajan", "authors": "Anand Natarajan and Thomas Vidick", "title": "Robust self-testing of many-qubit states", "comments": "36 pages. Improves upon and supersedes our earlier submission\n  arXiv:1512.02090", "journal-ref": "Proc. of STOC '17, pp. 1003-1015 (2017)", "doi": "10.1145/3055399.3055468", "report-no": "MIT-CTP/4846", "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple two-player test which certifies that the players apply\ntensor products of Pauli $\\sigma_X$ and $\\sigma_Z$ observables on the tensor\nproduct of $n$ EPR pairs. The test has constant robustness: any strategy\nachieving success probability within an additive $\\varepsilon$ of the optimal\nmust be $\\mathrm{poly}(\\varepsilon)$-close, in the appropriate distance\nmeasure, to the honest $n$-qubit strategy. The test involves $2n$-bit questions\nand $2$-bit answers. The key technical ingredient is a quantum version of the\nclassical linearity test of Blum, Luby, and Rubinfeld.\n  As applications of our result we give (i) the first robust self-test for $n$\nEPR pairs; (ii) a quantum multiprover interactive proof system for the local\nHamiltonian problem with a constant number of provers and classical questions\nand answers, and a constant completeness-soundness gap independent of system\nsize; (iii) a robust protocol for delegated quantum computation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 01:40:25 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Natarajan", "Anand", ""], ["Vidick", "Thomas", ""]]}, {"id": "1610.03582", "submitter": "Jenish C. Mehta", "authors": "David Gosset, Jenish C. Mehta, Thomas Vidick", "title": "QCMA hardness of ground space connectivity for commuting Hamiltonians", "comments": "14 pages, Quantum journal version", "journal-ref": "Quantum 1, 16 (2017)", "doi": "10.22331/q-2017-07-14-16", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we consider the ground space connectivity problem for commuting\nlocal Hamiltonians. The ground space connectivity problem asks whether it is\npossible to go from one (efficiently preparable) state to another by applying a\npolynomial length sequence of 2-qubit unitaries while remaining at all times in\na state with low energy for a given Hamiltonian $H$. It was shown in [Gharibian\nand Sikora, ICALP'15] that this problem is QCMA-complete for general local\nHamiltonians, where QCMA is defined as QMA with a classical witness and BQP\nverifier. Here we show that the commuting version of the problem is also\nQCMA-complete. This provides one of the first examples where commuting local\nHamiltonians exhibit complexity theoretic hardness equivalent to general local\nHamiltonians.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 02:25:05 GMT"}, {"version": "v2", "created": "Wed, 12 Jul 2017 21:13:57 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Gosset", "David", ""], ["Mehta", "Jenish C.", ""], ["Vidick", "Thomas", ""]]}, {"id": "1610.03798", "submitter": "Alessandro Chiesa", "authors": "Eli Ben-Sasson and Alessandro Chiesa and Michael A. Forbes and Ariel\n  Gabizon and Michael Riabzev and Nicholas Spooner", "title": "On Probabilistic Checking in Perfect Zero Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first constructions of single-prover proof systems that\nachieve perfect zero knowledge (PZK) for languages beyond NP, under no\nintractability assumptions:\n  1. The complexity class #P has PZK proofs in the model of Interactive PCPs\n(IPCPs) [KR08], where the verifier first receives from the prover a PCP and\nthen engages with the prover in an Interactive Proof (IP).\n  2. The complexity class NEXP has PZK proofs in the model of Interactive\nOracle Proofs (IOPs) [BCS16,RRR16], where the verifier, in every round of\ninteraction, receives a PCP from the prover.\n  Our constructions rely on succinct simulators that enable us to \"simulate\nbeyond NP\", achieving exponential savings in efficiency over [BCGV16]. These\nsimulators crucially rely on solving a problem that lies at the intersection of\ncoding theory, linear algebra, and computational complexity, which we call the\nsuccinct constraint detection problem, and consists of detecting dual\nconstraints with polynomial support size for codes of exponential block length.\nOur two results rely on solutions to this problem for fundamental classes of\nlinear codes:\n  * An algorithm to detect constraints for Reed--Muller codes of exponential\nlength.\n  * An algorithm to detect constraints for PCPs of Proximity of Reed--Solomon\ncodes [BS08] of exponential degree.\n  The first algorithm exploits the Raz--Shpilka [RS05] deterministic polynomial\nidentity testing algorithm, and shows, to our knowledge, a first connection of\nalgebraic complexity theory with zero knowledge. Along the way, we give a\nperfect zero knowledge analogue of the celebrated sumcheck protocol [LFKN92],\nby leveraging both succinct constraint detection and low-degree testing. The\nsecond algorithm exploits the recursive structure of the PCPs of Proximity to\nshow that small-support constraints are \"locally\" spanned by a small number of\nsmall-support constraints.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 17:39:55 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Ben-Sasson", "Eli", ""], ["Chiesa", "Alessandro", ""], ["Forbes", "Michael A.", ""], ["Gabizon", "Ariel", ""], ["Riabzev", "Michael", ""], ["Spooner", "Nicholas", ""]]}, {"id": "1610.04026", "submitter": "Xiu-Li Wang", "authors": "Yang Bai, Xiuli Wang", "title": "Complexities Approach to Two Problems In Number Theory", "comments": "4 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By Kolmogorov Complexity,two number-theoretic problems are solved in\ndifferent way than before,one problem is Maxim Kontsevich and Don Bernard\nZagier's Problem 3 \\emph{Exhibit at least one number which does not belong to}\n$ \\mathcal{P}$ (period number) in their paper,another is the problem about\nexistence of bounded coefficients of continued fraction expansion of\ntranscendental number.Thus we show a new approach to mathematical problems in\nthe non-logical discipline.Futhermore,we show that resource-bounded Kolmogorov\nComplexity and computational complexity can at least provide tips or principles\nto mathematical problems in the non-traditional or logical discipline.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 11:14:37 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2016 08:50:15 GMT"}, {"version": "v3", "created": "Fri, 21 Oct 2016 00:36:15 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Bai", "Yang", ""], ["Wang", "Xiuli", ""]]}, {"id": "1610.04055", "submitter": "Leslie Ann Goldberg", "authors": "Andreas Galanis, Leslie Ann Goldberg, and Kuan Yang", "title": "Approximating partition functions of bounded-degree Boolean counting\n  Constraint Satisfaction Problems", "comments": "To appear in JCSS. This version: minor corrections to typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of approximate counting Constraint Satisfaction\nProblems (#CSPs) in a bounded degree setting. Specifically, given a Boolean\nconstraint language $\\Gamma$ and a degree bound $\\Delta$, we study the\ncomplexity of #CSP$_\\Delta(\\Gamma)$, which is the problem of counting\nsatisfying assignments to CSP instances with constraints from $\\Gamma$ and\nwhose variables can appear at most $\\Delta$ times. Our main result shows that:\n(i) if every function in $\\Gamma$ is affine, then #CSP$_\\Delta(\\Gamma)$ is in\nFP for all $\\Delta$, (ii) otherwise, if every function in $\\Gamma$ is in a\nclass called IM$_2$, then for all sufficiently large $\\Delta$,\n#CSP$_\\Delta(\\Gamma)$ is equivalent under approximation-preserving (AP)\nreductions to the counting problem #BIS (the problem of counting independent\nsets in bipartite graphs) (iii) otherwise, for all sufficiently large $\\Delta$,\nit is NP-hard to approximate the number of satisfying assignments of an\ninstance of #CSP$_\\Delta(\\Gamma)$, even within an exponential factor. Our\nresult extends previous results, which apply only in the so-called\n\"conservative\" case.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 12:46:33 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 11:18:27 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 08:20:01 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Galanis", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Yang", "Kuan", ""]]}, {"id": "1610.04317", "submitter": "Ankur Moitra", "authors": "Ankur Moitra", "title": "Approximate Counting, the Lovasz Local Lemma and Inference in Graphical\n  Models", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new approach for approximately counting in\nbounded degree systems with higher-order constraints. Our main result is an\nalgorithm to approximately count the number of solutions to a CNF formula\n$\\Phi$ when the width is logarithmic in the maximum degree. This closes an\nexponential gap between the known upper and lower bounds.\n  Moreover our algorithm extends straightforwardly to approximate sampling,\nwhich shows that under Lov\\'asz Local Lemma-like conditions it is not only\npossible to find a satisfying assignment, it is also possible to generate one\napproximately uniformly at random from the set of all satisfying assignments.\nOur approach is a significant departure from earlier techniques in approximate\ncounting, and is based on a framework to bootstrap an oracle for computing\nmarginal probabilities on individual variables. Finally, we give an application\nof our results to show that it is algorithmically possible to sample from the\nposterior distribution in an interesting class of graphical models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 03:44:12 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 01:30:09 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Moitra", "Ankur", ""]]}, {"id": "1610.04523", "submitter": "Piotr Wojciechowski", "authors": "Hans Kleine B\\\"uning, Piotr Wojciechowski, K. Subramani", "title": "On the computational complexity of read once resolution decidability in\n  2CNF formulas", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze 2CNF formulas from the perspectives of Read-Once\nresolution (ROR) refutation schemes. We focus on two types of ROR refutations,\nviz., variable-once refutation and clause-once refutation. In the former, each\nvariable may be used at most once in the derivation of a refutation, while in\nthe latter, each clause may be used at most once. We show that the problem of\nchecking whether a given 2CNF formula has an ROR refutation under both schemes\nis NP-complete. This is surprising in light of the fact that there exist\npolynomial refutation schemes (tree-resolution and DAG-resolution) for 2CNF\nformulas. On the positive side, we show that 2CNF formulas have copy-complexity\n2, which means that any unsatisfiable 2CNF formula has a refutation in which\nany clause needs to be used at most twice.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 16:32:12 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["B\u00fcning", "Hans Kleine", ""], ["Wojciechowski", "Piotr", ""], ["Subramani", "K.", ""]]}, {"id": "1610.04670", "submitter": "Daniel Grier", "authors": "Daniel Grier, Luke Schaeffer", "title": "New Hardness Results for the Permanent Using Linear Optics", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2011, Aaronson gave a striking proof, based on quantum linear optics,\nshowing that the problem of computing the permanent of a matrix is #P-hard.\nAaronson's proof led naturally to hardness of approximation results for the\npermanent, and it was arguably simpler than Valiant's seminal proof of the same\nfact in 1979. Nevertheless, it did not prove that computing the permanent was\n#P-hard for any class of matrices which was not previously known. In this\npaper, we present a collection of new results about matrix permanents that are\nderived primarily via these linear optical techniques.\n  First, we show that the problem of computing the permanent of a real\northogonal matrix is #P-hard. Much like Aaronson's original proof, this will\nshow that even a multiplicative approximation remains #P-hard to compute. The\nhardness result even translates to permanents over finite fields, where the\nproblem of computing the permanent of an orthogonal matrix is ModpP-hard in the\nfinite field F_{p^4} for all primes p not equal to 2 or 3. Interestingly, this\ncharacterization is tight: in fields of characteristic 2, the permanent\ncoincides with the determinant; in fields of characteristic 3, one can\nefficiently compute the permanent of an orthogonal matrix by a nontrivial\nresult of Kogan.\n  Finally, we use more elementary arguments to prove #P-hardness for the\npermanent of a positive semidefinite matrix, which shows that certain\nprobabilities of boson sampling experiments with thermal states are hard to\ncompute exactly despite the fact that they can be efficiently sampled by a\nclassical computer.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2016 00:03:32 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 04:17:10 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Grier", "Daniel", ""], ["Schaeffer", "Luke", ""]]}, {"id": "1610.04937", "submitter": "Dave Touchette", "authors": "Ashwin Nayak and Dave Touchette", "title": "Augmented Index and Quantum Streaming Algorithms for DYCK(2)", "comments": "v1, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how two recently developed quantum information theoretic tools can be\napplied to obtain lower bounds on quantum information complexity. We also\ndevelop new tools with potential for broader applicability, and use them to\nestablish a lower bound on the quantum information complexity for the Augmented\nIndex function on an easy distribution. This approach allows us to handle\nsuperpositions rather than distributions over inputs, the main technical\nchallenge faced previously. By providing a quantum generalization of the\nargument of Jain and Nayak [IEEE TIT'14], we leverage this to obtain a lower\nbound on the space complexity of multi-pass, unidirectional quantum streaming\nalgorithms for the DYCK(2) language.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 00:59:16 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Nayak", "Ashwin", ""], ["Touchette", "Dave", ""]]}, {"id": "1610.04946", "submitter": "Saugata Basu", "authors": "Saugata Basu and Cordian Riener", "title": "On the equivariant Betti numbers of symmetric definable sets: vanishing,\n  bounds and algorithms", "comments": "Some typos corrected. New reference added. Final version to appear in\n  Selecta Mathematica", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathrm{R}$ be a real closed field. We prove that for any fixed $d$, the\nequivariant rational cohomology groups of closed symmetric semi-algebraic\nsubsets of $\\mathrm{R}^k$ defined by polynomials of degrees bounded by $d$\nvanishes in dimensions $d$ and larger. This vanishing result is tight. Using a\nnew geometric approach we also prove an upper bound of $d^{O(d)} s^d k^{\\lfloor\nd/2 \\rfloor-1} $ on the equivariant Betti numbers of closed symmetric\nsemi-algebraic subsets of $\\mathrm{R}^k$ defined by quantifier-free formulas\ninvolving $s$ symmetric polynomials of degrees bounded by $d$, where $1 < d \\ll\ns,k$. This bound is tight up to a factor depending only on $d$. These results\nsignificantly improve upon those obtained previously which were proved using\ndifferent techniques. Our new methods are quite general, and also yield bounds\non the equivariant Betti numbers of certain special classes of symmetric\ndefinable sets (definable sets symmetrized by pulling back under symmetric\npolynomial maps of fixed degree) in arbitrary o-minimal structures over\n$\\mathrm{R}$. Finally, we utilize our new approach to obtain an algorithm with\npolynomially bounded complexity for computing these equivariant Betti numbers.\nIn contrast, the problem of computing the ordinary Betti numbers of (not\nnecessarily symmetric) semi-algebraic sets is considered to be an intractable\nproblem, and all known algorithms for this problem have doubly exponential\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 01:42:15 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 18:25:17 GMT"}, {"version": "v3", "created": "Thu, 23 Feb 2017 18:33:22 GMT"}, {"version": "v4", "created": "Sun, 14 May 2017 12:31:12 GMT"}, {"version": "v5", "created": "Wed, 14 Feb 2018 09:12:05 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Basu", "Saugata", ""], ["Riener", "Cordian", ""]]}, {"id": "1610.05115", "submitter": "Timothy Highley Jr.", "authors": "Timothy Highley, Hoang Le", "title": "Tropical Vertex-Disjoint Cycles of a Vertex-Colored Digraph: Barter\n  Exchange with Multiple Items Per Agent", "comments": "Published in Discrete Mathematics and Theoretical Computer Science", "journal-ref": "Discrete Mathematics & Theoretical Computer Science, vol. 20 no.\n  2, Analysis of Algorithms (July 31, 2018) dmtcs:4690", "doi": "10.23638/DMTCS-20-2-1", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a barter exchange market, agents bring items and seek to exchange their\nitems with one another. Agents may agree to a k-way exchange involving a cycle\nof k agents. A barter exchange market can be represented by a digraph where the\nvertices represent items and the edges out of a vertex indicate the items that\nan agent is willing to accept in exchange for that item. It is known that the\nproblem of finding a set of vertex-disjoint cycles with the maximum total\nnumber of vertices (MAX-SIZE-EXCHANGE) can be solved in polynomial time. We\nconsider a barter exchange where each agent may bring multiple items, and items\nof the same agent are represented by vertices with the same color. A set of\ncycles is said to be tropical if for every color there is a cycle that contains\na vertex of that color. We show that the problem of determining whether there\nexists a tropical set of vertex-disjoint cycles in a digraph\n(TROPICAL-EXCHANGE) is NP-complete and APX-hard. This is equivalent to\ndetermining whether it is possible to arrange an exchange of items among agents\nsuch that every agent trades away at least one item. TROPICAL-MAX-SIZE-EXCHANGE\nis a similar problem, where the goal is to find a set of vertex-disjoint cycles\nthat contains the maximum number of vertices and also contains all of the\ncolors in the graph. We show that this problem is likewise NP-complete and\nAPX-hard. For the restricted case where there are at most two vertices of each\ncolor (corresponding to a restriction that each agent may bring at most two\nitems), both problems remain NP-hard but are in APX. Finally, we consider\nMAX-SIZE-TROPICAL-EXCHANGE, where the set of cycles must primarily include as\nmany colors as possible and secondarily include as many vertices as possible.\nWe show that this problem is NP-hard.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 01:10:21 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 18:25:43 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 20:16:11 GMT"}, {"version": "v4", "created": "Fri, 6 Apr 2018 21:54:41 GMT"}, {"version": "v5", "created": "Wed, 18 Jul 2018 03:36:20 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Highley", "Timothy", ""], ["Le", "Hoang", ""]]}, {"id": "1610.05493", "submitter": "Markus Kroell", "authors": "Nadia Creignou, Markus Kr\\\"oll, Reinhard Pichler, Sebastian Skritek,\n  Heribert Vollmer", "title": "A Complexity Theory for Hard Enumeration Problems", "comments": "Preprint submitted to Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complexity theory provides a wealth of complexity classes for analyzing the\ncomplexity of decision and counting problems. Despite the practical relevance\nof enumeration problems, the tools provided by complexity theory for this\nimportant class of problems are very limited. In particular, complexity classes\nanalogous to the polynomial hierarchy and an appropriate notion of problem\nreduction are missing. In this work, we lay the foundations for a complexity\ntheory of hard enumeration problems by proposing a hierarchy of complexity\nclasses and by investigating notions of reductions for enumeration problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 09:15:14 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 12:32:33 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Creignou", "Nadia", ""], ["Kr\u00f6ll", "Markus", ""], ["Pichler", "Reinhard", ""], ["Skritek", "Sebastian", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1610.05825", "submitter": "Joshua Grochow", "authors": "Joshua A. Grochow", "title": "NP-hard sets are not sparse unless P=NP: An exposition of a simple proof\n  of Mahaney's Theorem, with applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mahaney's Theorem states that, assuming $\\mathsf{P} \\neq \\mathsf{NP}$, no\nNP-hard set can have a polynomially bounded number of yes-instances at each\ninput length. We give an exposition of a very simple unpublished proof of\nManindra Agrawal whose ideas appear in Agrawal-Arvind (\"Geometric sets of low\ninformation content,\" Theoret. Comp. Sci., 1996). This proof is so simple that\nit can easily be taught to undergraduates or a general graduate CS audience -\nnot just theorists! - in about 10 minutes, which the author has done\nsuccessfully several times. We also include applications of Mahaney's Theorem\nto fundamental questions that bright undergraduates would ask which could be\nused to fill the remaining hour of a lecture, as well as an application (due to\nIkenmeyer, Mulmuley, and Walter, arXiv:1507.02955) to the representation theory\nof the symmetric group and the Geometric Complexity Theory Program. To this\nauthor, the fact that sparsity results on NP-complete sets have an application\nto classical questions in representation theory says that they are not only a\ngem of classical theoretical computer science, but indeed a gem of mathematics.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 23:01:55 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Grochow", "Joshua A.", ""]]}, {"id": "1610.06503", "submitter": "Delaram Kahrobaei", "authors": "Jonathan Gryak and Delaram Kahrobaei and Conchita Martinez-Perez", "title": "On the Conjugacy Problem in Certain Metabelian Groups", "comments": null, "journal-ref": "Glasgow Math. J. 61 (2019) 251-269", "doi": "10.1017/S0017089518000198", "report-no": null, "categories": "math.GR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weanalyzethecomputationalcomplexityofanalgorithmtosolve the conjugacy search\nproblem in a certain family of metabelian groups. We prove that in general the\ntime complexity of the conjugacy search problem for these groups is at most\nexponential. For a subfamily of groups we prove that the conjugacy search\nproblem is polynomial. We also show that for a different subfamily the\nconjugacy search problem reduces to the discrete logarithm problem.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 17:08:00 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 17:41:03 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Gryak", "Jonathan", ""], ["Kahrobaei", "Delaram", ""], ["Martinez-Perez", "Conchita", ""]]}, {"id": "1610.06646", "submitter": "Saeed Mehraban", "authors": "Scott Aaronson, Adam Bouland, Greg Kuperberg, Saeed Mehraban", "title": "The Computational Complexity of Ball Permutations", "comments": "59 pages, 10 figures. Partially based on Saeed Mehraban's Master's\n  thesis (arXiv: 1512.09243)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by connections to two dimensional quantum theory, we define several\nmodels of computation based on permuting distinguishable particles (which we\ncall balls), and characterize their computational complexity. In the quantum\nsetting, we find that the computational power of this model depends on the\ninitial input states. More precisely, with a standard basis input state, we\nshow how to approximate the amplitudes of this model within additive error\nusing the model DQC1 (the class of problems solvable with one clean qubit),\nproviding evidence that the model in this case is weaker than universal quantum\ncomputing. However, for specific choices of input states, the model is shown to\nbe universal for BQP in an encoded sense. We use representation theory of the\nsymmetric group to partially classify the computational complexity of this\nmodel for arbitrary input states. Interestingly, we find some input states\nwhich yield a model intermediate between DQC1 and BQP. Furthermore, we consider\na restricted version of this model based on an integrable scattering problem in\n1+1 dimensions. We show it is universal under postselection, if we allow\nintermediate destructive measurements and specific input states. Therefore, the\nexistence of any classical procedure to sample from the output distribution of\nthis model within multiplicative error implies collapse of polynomial hierarchy\nto its third level. Finally, we define a classical version of this model in\nwhich one can probabilistically permute balls. We find this yields a complexity\nclass which is intermediate between L and BPP. Moreover, we find a\nnondeterministic version of this model is NP-complete.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 02:06:43 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Aaronson", "Scott", ""], ["Bouland", "Adam", ""], ["Kuperberg", "Greg", ""], ["Mehraban", "Saeed", ""]]}, {"id": "1610.06950", "submitter": "Chris Jones", "authors": "Chris Jones", "title": "A Noisy-Influence Regularity Lemma for Boolean Functions", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a regularity lemma for Boolean functions $f:\\{-1,1\\}^n \\to\n\\{-1,1\\}$ based on noisy influence, a measure of how locally correlated $f$ is\nwith each input bit. We provide an application of the regularity lemma to\nweaken the conditions on the Majority is Stablest Theorem. We also prove a\n\"homogenized\" version stating that there is a set of input bits so that most\nrestrictions of $f$ on those bits have small noisy influences. These results\nwere sketched out by [OSTW10], but never published. With their permission, we\npresent the full details here.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 20:51:42 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Jones", "Chris", ""]]}, {"id": "1610.07175", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami", "title": "Not All Multi-Valued Partial CFL Functions Are Refined by Single-Valued\n  Functions", "comments": "(A4 size, 10 pt, 18 pages, 2 figures) This is a complete and\n  corrected version of an extended abstract that appeared in the Proceedings of\n  the 8th IFIP International Conference on Theoretical Computer Science (IFIP\n  TCS 2014), Rome, Italy, September 1-3, 2014, Lecture Notes in Computer\n  Science, Springer, vol. 8705, pp. 136-150, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-valued partial CFL functions are functions computed along accepting\ncomputation paths by one-way nondeterministic pushdown automata, equipped with\nwrite-only output tapes, which are allowed to reject an input, in comparison\nwith single-valued partial CFL functions. We give an answer to a fundamental\nquestion, raised by Konstantinidis, Santean, and Yu [Act. Inform. 43 (2007)\n395-417], of whether all such multi-valued partial CFL functions can be refined\nby single-valued partial CFL functions. We negatively solve this open question\nby presenting a special multi-valued partial CFL function as an example\nfunction and by proving that no refinement of this particular function becomes\na single-valued partial CFL function. This contrasts an early result of\nKobayashi [Inform. Control 15 (1969) 95-109] that multi-valued partial NFA\nfunctions are always refined by single-valued NFA functions, where NFA\nfunctions are computed by one-way nondeterministic finite automata with output\ntapes. Our example function turns out to be unambiguously 2-valued, and thus we\nobtain a stronger separation result, in which no refinement of unambiguously\n2-valued partial CFL functions can be single-valued. For the proof of this\nfact, we first introduce a new concept of colored automata having no output\ntapes but having \"colors,\" which can simulate pushdown automata equipped with\nconstant-space output tapes. We then conduct an extensive combinatorial\nanalysis on the behaviors of transition records of stack contents (called stack\nhistories) of these colored automata.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 14:21:40 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 08:22:41 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Yamakami", "Tomoyuki", ""]]}, {"id": "1610.07190", "submitter": "Javier A. Arroyo-Figueroa", "authors": "Javier A. Arroyo-Figueroa", "title": "The Security of Hardware-Based Omega(n^2) Cryptographic One-Way\n  Functions: Beyond Satisfiability and P=NP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of hardware-based cryptographic one-way functions that, in\npractice, would be hard to invert even if P=NP and linear-time satisfiability\nalgorithms exist. Such functions use a hardware-based component with omega(n^2)\nsize circuits, and omega(n^2) run time.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 16:13:35 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Arroyo-Figueroa", "Javier A.", ""]]}, {"id": "1610.07244", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae, Keisuke Fujii, Harumichi Nishimura", "title": "Power of one non-clean qubit", "comments": "6 pages", "journal-ref": "Phys. Rev. A 95, 042336 (2017)", "doi": "10.1103/PhysRevA.95.042336", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cond-mat.str-el cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The one-clean qubit model (or the DQC1 model) is a restricted model of\nquantum computing where only a single qubit of the initial state is pure and\nothers are maximally mixed. Although the model is not universal, it can\nefficiently solve several problems whose classical efficient solutions are not\nknown. Furthermore, it was recently shown that if the one-clean qubit model is\nclassically efficiently simulated, the polynomial hierarchy collapses to the\nsecond level. A disadvantage of the one-clean qubit model is, however, that the\nclean qubit is too clean: for example, in realistic NMR experiments,\npolarizations are not enough high to have the perfectly pure qubit. In this\npaper, we consider a more realistic one-clean qubit model, where the clean\nqubit is not clean, but depolarized. We first show that, for any polarization,\na multiplicative-error calculation of the output probability distribution of\nthe model is possible in a classical polynomial time if we take an\nappropriately large multiplicative error. The result is in a strong contrast to\nthat of the ideal one-clean qubit model where the classical efficient\nmultiplicative-error calculation (or even the sampling) with the same amount of\nerror causes the collapse of the polynomial hierarchy. We next show that, for\nany polarization lower-bounded by an inverse polynomial, a classical efficient\nsampling (in terms of a sufficiently small multiplicative error or an\nexponentially-small additive error) of the output probability distribution of\nthe model is impossible unless BQP is contained in the second level of the\npolynomial hierarchy, which suggests the hardness of the classical efficient\nsimulation of the one non-clean qubit model.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 22:54:15 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Morimae", "Tomoyuki", ""], ["Fujii", "Keisuke", ""], ["Nishimura", "Harumichi", ""]]}, {"id": "1610.07499", "submitter": "Vincent Jug\\'e", "authors": "Patricia Bouyer and Vincent Jug\\'e", "title": "Dynamic Complexity of the Dyck Reachability", "comments": "16 pages, 2 figures - Full version of FoSSaCS 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic complexity is concerned with updating the output of a problem when\nthe input is slightly changed. We study the dynamic complexity of Dyck\nreachability problems in directed and undirected graphs, where updates may add\nor delete edges. We show a strong dichotomy between such problems, based on the\nsize of the Dyck alphabet. Some of them are P-complete (under a strong notion\nof reduction) while the others lie either in DynFO or in NL.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 17:15:32 GMT"}, {"version": "v2", "created": "Sat, 15 Apr 2017 17:58:57 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Bouyer", "Patricia", ""], ["Jug\u00e9", "Vincent", ""]]}, {"id": "1610.07685", "submitter": "James P. Crutchfield", "authors": "C. Aghamohammadi and J. P. Crutchfield", "title": "The Markov Memory for Generating Rare Events", "comments": "10 pages, 5 figures;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/mmgre.htm", "journal-ref": null, "doi": "10.1103/PhysRevE.95.032101", "report-no": null, "categories": "cond-mat.stat-mech cs.CC cs.IT math.IT nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify the rare events of structured, memoryful stochastic processes and\nuse this to analyze sequential and parallel generators for these events. Given\na stochastic process, we introduce a method to construct a new process whose\ntypical realizations are a given process' rare events. This leads to an\nexpression for the minimum memory required to generate rare events. We then\nshow that the recently discovered classical-quantum ambiguity of simplicity\nalso occurs when comparing the structure of process fluctuations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 23:54:05 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Aghamohammadi", "C.", ""], ["Crutchfield", "J. P.", ""]]}, {"id": "1610.07737", "submitter": "Saugata Basu", "authors": "Saugata Basu, M. Umut Isik", "title": "Categorical Complexity", "comments": "47 pages", "journal-ref": "Forum of Mathematics, Sigma 8 (2020) e34", "doi": "10.1017/fms.2020.26", "report-no": null, "categories": "math.CT cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a notion of complexity of diagrams (and in particular of objects\nand morphisms) in an arbitrary category, as well as a notion of complexity of\nfunctors between categories equipped with complexity functions. We discuss\nseveral examples of this new definition in categories of wide common interest,\nsuch as finite sets, Boolean functions, topological spaces, vector spaces,\nsemi-linear and semi-algebraic sets, graded algebras, affine and projective\nvarieties and schemes, and modules over polynomial rings. We show that on one\nhand categorical complexity recovers in several settings classical notions of\nnon-uniform computational complexity (such as circuit complexity), while on the\nother hand it has features which make it mathematically more natural. We also\npostulate that studying functor complexity is the categorical analog of\nclassical questions in complexity theory about separating different complexity\nclasses.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 05:39:59 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 16:42:45 GMT"}, {"version": "v3", "created": "Thu, 11 Jan 2018 21:42:51 GMT"}, {"version": "v4", "created": "Tue, 10 Dec 2019 15:46:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Basu", "Saugata", ""], ["Isik", "M. Umut", ""]]}, {"id": "1610.07766", "submitter": "Marcin Pilipczuk", "authors": "Anna Adamaszek and Tomasz Kociumaka and Marcin Pilipczuk and Micha{\\l}\n  Pilipczuk", "title": "Hardness of approximation for strip packing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strip packing is a classical packing problem, where the goal is to pack a set\nof rectangular objects into a strip of a given width, while minimizing the\ntotal height of the packing. The problem has multiple applications, e.g. in\nscheduling and stock-cutting, and has been studied extensively.\n  When the dimensions of objects are allowed to be exponential in the total\ninput size, it is known that the problem cannot be approximated within a factor\nbetter than $3/2$, unless $\\mathrm{P}=\\mathrm{NP}$. However, there was no\ncorresponding lower bound for polynomially bounded input data. In fact,\nNadiradze and Wiese [SODA 2016] have recently proposed a $(1.4 + \\epsilon)$\napproximation algorithm for this variant, thus showing that strip packing with\npolynomially bounded data can be approximated better than when exponentially\nlarge values in the input data are allowed. Their result has subsequently been\nimproved to a $(4/3 + \\epsilon)$ approximation by two independent research\ngroups [FSTTCS 2016, arXiv:1610.04430]. This raises a question whether strip\npacking with polynomially bounded input data admits a quasi-polynomial time\napproximation scheme, as is the case for related two-dimensional packing\nproblems like maximum independent set of rectangles or two-dimensional\nknapsack.\n  In this paper we answer this question in negative by proving that it is\nNP-hard to approximate strip packing within a factor better than $12/11$, even\nwhen admitting only polynomially bounded input data. In particular, this shows\nthat the strip packing problem admits no quasi-polynomial time approximation\nscheme, unless $\\mathrm{NP} \\subseteq \\mathrm{DTIME}(2^{\\mathrm{polylog}(n)})$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 07:44:21 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Adamaszek", "Anna", ""], ["Kociumaka", "Tomasz", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1610.07908", "submitter": "Damien Regnault M.", "authors": "Pierre-\\'Etienne Meunier, Damien Regnault", "title": "A pumping lemma for non-cooperative self-assembly", "comments": "proof is 80 pages long. Also contains 150 figures which are not\n  mandatory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a result which strongly hints at the computational weakness of a\nmodel of tile assembly that has so far resisted many attempts of formal\nanalysis or positive constructions. Specifically, we prove that, in Winfree's\nabstract Tile Assembly Model, when restricted to use only noncooperative\nbindings, any long enough path starting from the seed that can grow in all\nterminal assemblies is pumpable, meaning that this path can be extended into an\ninfinite, ultimately periodic path. This result can be seen as a geometric\ngeneralization of the pumping lemma of finite state automata, and closes the\nquestion of what can be computed deterministically in this model. Moreover,\nthis question has motivated the development of a new method called visible\nglues. We believe that this method can also be used to tackle other\nlong-standing problems in computational geometry, in relation for instance with\nself-avoiding paths. Tile assembly (including non-cooperative tile assembly)\nwas originally introduced by Winfree and Rothemund in STOC 2000 to understand\nhow to program shapes. The non-cooperative variant, also known as temperature 1\ntile assembly, is the model where tiles are allowed to bind as soon as they\nmatch on one side, whereas in cooperative tile assembly, some tiles need to\nmatch on several sides in order to bind. Previously, exactly one known result\n(SODA 2014) showed a restriction on the assemblies general non-cooperative\nself-assembly could achieve, without any implication on its computational\nexpressiveness. With non-square tiles (like polyominos, SODA 2015), other\nrecent works have shown that the model quickly becomes computationally\npowerful.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 15:00:20 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 15:20:14 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Meunier", "Pierre-\u00c9tienne", ""], ["Regnault", "Damien", ""]]}, {"id": "1610.07999", "submitter": "Jonathan Hermon", "authors": "Jonathan Hermon, Allan Sly, and Yumeng Zhang", "title": "Rapid Mixing of Hypergraph Independent Set", "comments": "36 pages, 3 figures", "journal-ref": "Random Structures & Algorithms. Vol. 54, 4 (2019) 730--767", "doi": "10.1002/rsa.20830", "report-no": null, "categories": "math.PR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the the mixing time of the Glauber dynamics for sampling\nindependent sets on $n$-vertex $k$-uniform hypergraphs is $O(n\\log n)$ when the\nmaximum degree $\\Delta$ satisfies $\\Delta \\leq c 2^{k/2}$, improving on the\nprevious bound [BDK06] of $\\Delta \\leq k-2$. This result brings the algorithmic\nbound to within a constant factor of the hardness bound of [BGG+16] which\nshowed that it is NP-hard to approximately count independent sets on\nhypergraphs when $\\Delta \\geq 5 \\cdot 2^{k/2}$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 18:19:17 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 06:31:27 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Hermon", "Jonathan", ""], ["Sly", "Allan", ""], ["Zhang", "Yumeng", ""]]}, {"id": "1610.08349", "submitter": "Henry Yuen", "authors": "Irit Dinur, Prahladh Harsha, Rakesh Venkat, Henry Yuen", "title": "Multiplayer parallel repetition for expander games", "comments": "Appeared in the Innovations in Theoretical Computer Science (ITCS)\n  2017 conference", "journal-ref": "In Proc. 8th Innovations in Theoretical Computer Science (ITCS)\n  (Berkeley, USA, 9-11 January), volume 67 of LiPiCS, pages 37:1-37:16, 2017", "doi": "10.4230/LIPIcs.ITCS.2017.37", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the value of parallel repetition of one-round games with any\nnumber of players $k\\ge 2$. It has been an open question whether an analogue of\nRaz's Parallel Repetition Theorem holds for games with more than two players,\ni.e., whether the value of the repeated game decays exponentially with the\nnumber of repetitions. Verbitsky has shown, via a reduction to the density\nHales-Jewett theorem, that the value of the repeated game must approach zero,\nas the number of repetitions increases. However, the rate of decay obtained in\nthis way is extremely slow, and it is an open question whether the true rate is\nexponential as is the case for all two-player games.\n  Exponential decay bounds are known for several special cases of multi-player\ngames, e.g., free games and anchored games. In this work, we identify a certain\nexpansion property of the base game and show all games with this property\nsatisfy an exponential decay parallel repetition bound. Free games and anchored\ngames satisfy this expansion property, and thus our parallel repetition theorem\nreproduces all earlier exponential-decay bounds for multiplayer games. More\ngenerally, our parallel repetition bound applies to all multiplayer games that\nare connected in a certain sense.\n  We also describe a very simple game, called the GHZ game, that does not\nsatisfy this connectivity property, and for which we do not know an exponential\ndecay bound. We suspect that progress on bounding the value of this the\nparallel repetition of the GHZ game will lead to further progress on the\ngeneral question.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 14:26:38 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 19:58:10 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Dinur", "Irit", ""], ["Harsha", "Prahladh", ""], ["Venkat", "Rakesh", ""], ["Yuen", "Henry", ""]]}, {"id": "1610.08364", "submitter": "J. M. Landsberg", "authors": "Luca Chiantini, Christian Ikenmeyer, J.M. Landsberg and Giorgio\n  Ottaviani", "title": "The geometry of rank decompositions of matrix multiplication I: 2x2\n  matrices", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the first in a series of papers on rank decompositions of the matrix\nmultiplication tensor. In this paper we: establish general facts about rank\ndecompositions of tensors, describe potential ways to search for new matrix\nmultiplication decompositions, give a geometric proof of the theorem of\nBurichenko's theorem establishing the symmetry group of Strassen's algorithm,\nand present two particularly nice subfamilies in the Strassen family of\ndecompositions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 16:12:12 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Chiantini", "Luca", ""], ["Ikenmeyer", "Christian", ""], ["Landsberg", "J. M.", ""], ["Ottaviani", "Giorgio", ""]]}, {"id": "1610.08739", "submitter": "Andre Droschinsky", "authors": "Andre Droschinsky and Nils Kriege and Petra Mutzel", "title": "Finding Largest Common Substructures of Molecules in Quadratic Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the common structural features of two molecules is a fundamental task\nin cheminformatics. Most drugs are small molecules, which can naturally be\ninterpreted as graphs. Hence, the task is formalized as maximum common subgraph\nproblem. Albeit the vast majority of molecules yields outerplanar graphs this\nproblem remains NP-hard.\n  We consider a variation of the problem of high practical relevance, where the\nrings of molecules must not be broken, i.e., the block and bridge structure of\nthe input graphs must be retained by the common subgraph. We present an\nalgorithm for finding a maximum common connected induced subgraph of two given\nouterplanar graphs subject to this constraint. Our approach runs in time\n$\\mathcal{O}(\\Delta n^2)$ in outerplanar graphs on $n$ vertices with maximum\ndegree $\\Delta$. This leads to a quadratic time complexity in molecular graphs,\nwhich have bounded degree. The experimental comparison on synthetic and\nreal-world datasets shows that our approach is highly efficient in practice and\noutperforms comparable state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 12:16:01 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Droschinsky", "Andre", ""], ["Kriege", "Nils", ""], ["Mutzel", "Petra", ""]]}, {"id": "1610.09130", "submitter": "Tom C. van der Zanden", "authors": "Hans L. Bodlaender, Tom C. van der Zanden", "title": "Improved Lower Bounds for Graph Embedding Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give new, tight subexponential lower bounds for a number of\ngraph embedding problems. We introduce two related combinatorial problems,\nwhich we call String Crafting and Orthogonal Vector crafting, and show that\nthese cannot be solved in time $2^{o(|s|/\\log{|s|})}$, unless the Exponential\nTime Hypothesis fails.\n  These results are used to obtain simplified hardness results for several\ngraph embedding problems, on more restricted graph classes than previously\nknown: assuming the Exponential Time Hypothesis, there do not exist algorithms\nthat run in $2^{o(n/\\log n)}$ time for Subgraph Isomorphism on graphs of\npathwidth 1, Induced Subgraph Isomorphism on graphs of pathwidth 1, Graph Minor\non graphs of pathwidth 1, Induced Graph Minor on graphs of pathwidth 1,\nIntervalizing 5-Colored Graphs on trees, and finding a tree or path\ndecomposition with width at most $c$ with a minimum number of bags, for any\nfixed $c\\geq 16$.\n  $2^{\\Theta(n/\\log n)}$ appears to be the \"correct\" running time for many\npacking and embedding problems on restricted graph classes, and we think String\nCrafting and Orthogonal Vector Crafting form a useful framework for\nestablishing lower bounds of this form.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 09:13:30 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["van der Zanden", "Tom C.", ""]]}, {"id": "1610.09132", "submitter": "Martin Olsen", "authors": "Martin Olsen", "title": "Towards Asymptotically Optimal One-to-One PDP Algorithms for Capacity 2+\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the one-to-one Pickup and Delivery Problem (PDP) in Euclidean\nSpace with arbitrary dimension $d$ where $n$ transportation requests are picked\ni.i.d. with a separate origin-destination pair for each object to be moved.\nFirst, we consider the problem from the customer perspective where the\nobjective is to compute a plan for transporting the objects such that the\nEuclidean distance traveled by the vehicles when carrying objects is minimized.\nWe develop a polynomial time asymptotically optimal algorithm for vehicles with\ncapacity $o(\\sqrt[2d]{n})$ for this case. This result also holds imposing LIFO\nconstraints for loading and unloading objects. Secondly, we extend our\nalgorithm to the classical single-vehicle PDP where the objective is to\nminimize the total distance traveled by the vehicle and present results\nindicating that the extended algorithm is asymptotically optimal for a fixed\nvehicle capacity if the origins and destinations are picked i.i.d. using the\nsame distribution.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 09:18:06 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Olsen", "Martin", ""]]}, {"id": "1610.09574", "submitter": "Lucy Ham", "authors": "Lucy Ham", "title": "Gap theorems for robust satisfiability: Boolean CSPs and beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational problem exhibits a \"gap property\" when there is no tractable\nboundary between two disjoint sets of instances. We establish a Gap Trichotomy\nTheorem for a family of constraint problem variants, completely classifying the\ncomplexity of possible ${\\bf NP}$-hard gaps in the case of Boolean domains. As\na consequence, we obtain a number of dichotomies for the complexity of specific\nvariants of the constraint satisfaction problem: all are either polynomial-time\ntractable or $\\mathbf{NP}$-complete. Schaefer's original dichotomy for\n$\\textsf{SAT}$ variants is a notable particular case.\n  Universal algebraic methods have been central to recent efforts in\nclassifying the complexity of constraint satisfaction problems. A second\ncontribution of the article is to develop aspects of the algebraic approach in\nthe context of a number of variants of the constraint satisfaction problem. In\nparticular, this allows us to lift our results on Boolean domains to many\ntemplates on non-Boolean domains.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 22:04:18 GMT"}, {"version": "v2", "created": "Sun, 26 Mar 2017 23:25:02 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Ham", "Lucy", ""]]}, {"id": "1610.09660", "submitter": "Michael Pinsker", "authors": "Manuel Bodirsky and Michael Pinsker", "title": "Canonical Functions: a proof via topological dynamics", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC math.DS math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical functions are a powerful concept with numerous applications in the\nstudy of groups, monoids, and clones on countable structures with Ramsey-type\nproperties. In this short note, we present a proof of the existence of\ncanonical functions in certain sets using topological dynamics, providing a\nshorter alternative to the original combinatorial argument. We moreover present\nequivalent algebraic characterisations of canonicity.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 15:23:49 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 19:29:38 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 15:38:56 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Pinsker", "Michael", ""]]}, {"id": "1610.09834", "submitter": "Igor Potapov", "authors": "Sang-Ki Ko and Igor Potapov", "title": "Matrix Semigroup Freeness Problems in $\\mathrm{SL}(2,\\mathbb{Z})$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study decidability and complexity of decision problems on\nmatrices from the special linear group $\\mathrm{SL}(2,\\mathbb{Z})$. In\nparticular, we study the freeness problem: given a finite set of matrices $G$\ngenerating a multiplicative semigroup $S$, decide whether each element of $S$\nhas at most one factorization over $G$. In other words, is $G$ a code? We show\nthat the problem of deciding whether a matrix semigroup in\n$\\mathrm{SL}(2,\\mathbb{Z})$ is non-free is NP-hard. Then, we study questions\nabout the number of factorizations of matrices in the matrix semigroup such as\nthe finite freeness problem, the recurrent matrix problem, the unique\nfactorizability problem, etc. Finally, we show that some factorization problems\ncould be even harder in $\\mathrm{SL}(2,\\mathbb{Z})$, for example we show that\nto decide whether every prime matrix has at most $k$ factorizations is\nPSPACE-hard.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 09:06:53 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Ko", "Sang-Ki", ""], ["Potapov", "Igor", ""]]}]