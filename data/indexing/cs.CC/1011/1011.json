[{"id": "1011.0046", "submitter": "Panigrahy Rina", "authors": "Rina Panigrahy", "title": "A non-expert view on Turing machines, Proof Verifiers, and Mental\n  reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper explores known results related to the problem of identifying if a\ngiven program terminates on all inputs -- this is a simple generalization of\nthe halting problem. We will see how this problem is related and the notion of\nproof verifiers. We also see how verifying if a program is terminating involves\nreasoning through a tower of axiomatic theories -- such a tower of theories is\nknown as Turing progressions and was first studied by Alan Turing in the\n1930's. We will see that this process has a natural connection to ordinal\nnumbers. The paper is presented from the perspective of a non-expert in the\nfield of logic and proof theory.\n", "versions": [{"version": "v1", "created": "Sat, 30 Oct 2010 06:11:35 GMT"}, {"version": "v2", "created": "Tue, 2 Nov 2010 01:36:18 GMT"}, {"version": "v3", "created": "Tue, 9 Nov 2010 14:36:02 GMT"}, {"version": "v4", "created": "Thu, 18 Nov 2010 14:25:13 GMT"}, {"version": "v5", "created": "Wed, 2 Feb 2011 18:21:47 GMT"}, {"version": "v6", "created": "Thu, 1 Mar 2012 05:21:39 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Panigrahy", "Rina", ""]]}, {"id": "1011.0180", "submitter": "Varsha Dani", "authors": "Varsha Dani and Cristopher Moore", "title": "Independent sets in random graphs from the weighted second moment method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cond-mat.stat-mech math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove new lower bounds on the likely size of a maximum independent set in\na random graph with a given average degree. Our method is a weighted version of\nthe second moment method, where we give each independent set a weight based on\nthe total degree of its vertices.\n", "versions": [{"version": "v1", "created": "Sun, 31 Oct 2010 17:12:57 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2011 22:15:05 GMT"}], "update_date": "2011-11-15", "authors_parsed": [["Dani", "Varsha", ""], ["Moore", "Cristopher", ""]]}, {"id": "1011.0217", "submitter": "EPTCS", "authors": "St\\'ephane Demri (LSV, CNRS, ENSC, INRIA, France)", "title": "On Selective Unboundedness of VASS", "comments": "In Proceedings INFINITY 2010, arXiv:1010.6112", "journal-ref": "EPTCS 39, 2010, pp. 1-15", "doi": "10.4204/EPTCS.39.1", "report-no": null, "categories": "cs.FL cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous properties of vector addition systems with states amount to checking\nthe (un)boundedness of some selective feature (e.g., number of reversals, run\nlength). Some of these features can be checked in exponential space by using\nRackoff's proof or its variants, combined with Savitch's theorem. However, the\nquestion is still open for many others, e.g., reversal-boundedness. In the\npaper, we introduce the class of generalized unboundedness properties that can\nbe verified in exponential space by extending Rackoff's technique, sometimes in\nan unorthodox way. We obtain new optimal upper bounds, for example for\nplace-boundedness problem, reversal-boundedness detection (several variants\nexist), strong promptness detection problem and regularity detection. Our\nanalysis is sufficiently refined so as we also obtain a polynomial-space bound\nwhen the dimension is fixed.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 00:18:45 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Demri", "St\u00e9phane", "", "LSV, CNRS, ENSC, INRIA, France"]]}, {"id": "1011.0253", "submitter": "Albert Xin Jiang", "authors": "Albert Xin Jiang and Kevin Leyton-Brown", "title": "Polynomial-time Computation of Exact Correlated Equilibrium in Compact\n  Games", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a landmark paper, Papadimitriou and Roughgarden described a\npolynomial-time algorithm (\"Ellipsoid Against Hope\") for computing sample\ncorrelated equilibria of concisely-represented games. Recently, Stein, Parrilo\nand Ozdaglar showed that this algorithm can fail to find an exact correlated\nequilibrium, but can be easily modified to efficiently compute approximate\ncorrelated equilibria. Currently, it remains unresolved whether the algorithm\ncan be modified to compute an exact correlated equilibrium. We show that it\ncan, presenting a variant of the Ellipsoid Against Hope algorithm that\nguarantees the polynomial-time identification of exact correlated equilibrium.\nOur new algorithm differs from the original primarily in its use of a\nseparation oracle that produces cuts corresponding to pure-strategy profiles.\nAs a result, we no longer face the numerical precision issues encountered by\nthe original approach, and both the resulting algorithm and its analysis are\nconsiderably simplified. Our new separation oracle can be understood as a\nderandomization of Papadimitriou and Roughgarden's original separation oracle\nvia the method of conditional probabilities. Also, the equilibria returned by\nour algorithm are distributions with polynomial-sized supports, which are\nsimpler (in the sense of being representable in fewer bits) than the mixtures\nof product distributions produced previously; no tractable algorithm has\npreviously been proposed for identifying such equilibria.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 05:06:59 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Jiang", "Albert Xin", ""], ["Leyton-Brown", "Kevin", ""]]}, {"id": "1011.0354", "submitter": "Pooya Hatami", "authors": "Pooya Hatami, Raghav Kulkarni and Denis Pankratov", "title": "Variations on the Sensitivity Conjecture", "comments": "16 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a selection of known as well as new variants of the Sensitivity\nConjecture and point out some weaker versions that are also open.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 15:44:49 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Hatami", "Pooya", ""], ["Kulkarni", "Raghav", ""], ["Pankratov", "Denis", ""]]}, {"id": "1011.1157", "submitter": "Laurent Bulteau", "authors": "Laurent Bulteau, Guillaume Fertin, Irena Rusu", "title": "Sorting by Transpositions is Difficult", "comments": null, "journal-ref": null, "doi": "10.1137/110851390", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In comparative genomics, a transposition is an operation that exchanges two\nconsecutive sequences of genes in a genome. The transposition distance, that\nis, the minimum number of transpositions needed to transform a genome into\nanother, is, according to numerous studies, a relevant evolutionary distance.\nThe problem of computing this distance when genomes are represented by\npermutations, called the Sorting by Transpositions problem, has been introduced\nby Bafna and Pevzner in 1995. It has naturally been the focus of a number of\nstudies, but the computational complexity of this problem has remained\nundetermined for 15 years. In this paper, we answer this long-standing open\nquestion by proving that the Sorting by Transpositions problem is NP-hard. As a\ncorollary of our result, we also prove that the following problem is NP-hard:\ngiven a permutation pi, is it possible to sort pi using db(pi)/3 permutations,\nwhere db(pi) is the number of breakpoints of pi?\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 13:41:12 GMT"}], "update_date": "2012-09-05", "authors_parsed": [["Bulteau", "Laurent", ""], ["Fertin", "Guillaume", ""], ["Rusu", "Irena", ""]]}, {"id": "1011.1201", "submitter": "Abuzer Yakaryilmaz", "authors": "Abuzer Yakaryilmaz and Rusins Freivalds and A. C. Cem Say and Ruben\n  Agadzanyan", "title": "Quantum computation with devices whose contents are never read", "comments": "32 pages, a preliminary version of this work was presented in the 9th\n  International Conference on Unconventional Computation (UC2010)", "journal-ref": "Natural Computing, March 2012, Volume 11, Issue 1, pp 81-94", "doi": "10.1007/s11047-011-9270-0", "report-no": null, "categories": "cs.CC cs.FL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical computation, a \"write-only memory\" (WOM) is little more than an\noxymoron, and the addition of WOM to a (deterministic or probabilistic)\nclassical computer brings no advantage. We prove that quantum computers that\nare augmented with WOM can solve problems that neither a classical computer\nwith WOM nor a quantum computer without WOM can solve, when all other resource\nbounds are equal. We focus on realtime quantum finite automata, and examine the\nincrease in their power effected by the addition of WOMs with different access\nmodes and capacities. Some problems that are unsolvable by two-way\nprobabilistic Turing machines using sublogarithmic amounts of read/write memory\nare shown to be solvable by these enhanced automata.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 16:20:48 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Yakaryilmaz", "Abuzer", ""], ["Freivalds", "Rusins", ""], ["Say", "A. C. Cem", ""], ["Agadzanyan", "Ruben", ""]]}, {"id": "1011.1264", "submitter": "Holenstein Thomas", "authors": "Thomas Holenstein and Robin K\\\"unzler and Stefano Tessaro", "title": "Equivalence of the Random Oracle Model and the Ideal Cipher Model,\n  Revisited", "comments": "Reduced number of rounds from 18 to 14 as this is sufficient for the\n  proof, improved presentation of several lemmas and introduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the cryptographic problem of constructing an invertible random\npermutation from a public random function (i.e., which can be accessed by the\nadversary). This goal is formalized by the notion of indifferentiability of\nMaurer et al. (TCC 2004). This is the natural extension to the public setting\nof the well-studied problem of building random permutations from random\nfunctions, which was first solved by Luby and Rackoff (Siam J. Comput., '88)\nusing the so-called Feistel construction.\n  The most important implication of such a construction is the equivalence of\nthe random oracle model (Bellare and Rogaway, CCS '93) and the ideal cipher\nmodel, which is typically used in the analysis of several constructions in\nsymmetric cryptography.\n  Coron et al. (CRYPTO 2008) gave a rather involved proof that the six-round\nFeistel construction with independent random round functions is\nindifferentiable from an invertible random permutation. Also, it is known that\nfewer than six rounds do not suffice for indifferentiability. The first\ncontribution (and starting point) of our paper is a concrete distinguishing\nattack which shows that the indifferentiability proof of Coron et al. is not\ncorrect. In addition, we provide supporting evidence that an\nindifferentiability proof for the six-round Feistel construction may be very\nhard to find.\n  To overcome this gap, our main contribution is a proof that the Feistel\nconstruction with eigthteen rounds is indifferentiable from an invertible\nrandom permutation. The approach of our proof relies on assigning to each of\nthe rounds in the construction a unique and specific role needed in the proof.\nThis avoids many of the problems that appear in the six-round case.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 20:55:27 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2011 07:59:47 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Holenstein", "Thomas", ""], ["K\u00fcnzler", "Robin", ""], ["Tessaro", "Stefano", ""]]}, {"id": "1011.1273", "submitter": "Michele Castellana", "authors": "Michele Castellana, Lenka Zdeborov\\'a", "title": "Adversarial Satisfiability Problem", "comments": null, "journal-ref": "Journal of Statistical Mechanics 2011(3), P03023 (2011)", "doi": "10.1088/1742-5468/2011/03/P03023", "report-no": null, "categories": "cs.CC cond-mat.dis-nn cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the adversarial satisfiability problem, where the adversary can\nchoose whether variables are negated in clauses or not in order to make the\nresulting formula unsatisfiable. This is one case of a general class of\nadversarial optimization problems that often arise in practice and are\nalgorithmically much harder than the standard optimization problems. We use the\ncavity method to compute large deviations of the entropy in the random\nsatisfiability problem with respect to the negation-configurations. We conclude\nthat in the thermodynamic limit the best strategy the adversary can adopt is\nextremely close to simply balancing the number of times every variable is and\nis not negated. We also conduct a numerical study of the problem, and find that\nthere are very strong pre-asymptotic effects that are due to the fact that for\nsmall sizes exponential and factorial growth is hardly distinguishable.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 21:30:56 GMT"}], "update_date": "2015-03-23", "authors_parsed": [["Castellana", "Michele", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1011.1338", "submitter": "Ildiko Schlotter", "authors": "Britta Dorn and Ildik\\'o Schlotter", "title": "Multivariate Analyis of Swap Bribery", "comments": "20 pages. Conference version published at IPEC 2010", "journal-ref": null, "doi": "10.1007/978-3-642-17493-3_12", "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the computational complexity of a problem modeling bribery in the\ncontext of voting systems. In the scenario of Swap Bribery, each voter assigns\na certain price for swapping the positions of two consecutive candidates in his\npreference ranking. The question is whether it is possible, without exceeding a\ngiven budget, to bribe the voters in a way that the preferred candidate wins in\nthe election. We initiate a parameterized and multivariate complexity analysis\nof Swap Bribery, focusing on the case of k-approval. We investigate how\ndifferent cost functions affect the computational complexity of the problem. We\nidentify a special case of k-approval for which the problem can be solved in\npolynomial time, whereas we prove NP-hardness for a slightly more general\nscenario. We obtain fixed-parameter tractability as well as W[1]-hardness\nresults for certain natural parameters.\n", "versions": [{"version": "v1", "created": "Fri, 5 Nov 2010 08:25:57 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Dorn", "Britta", ""], ["Schlotter", "Ildik\u00f3", ""]]}, {"id": "1011.1350", "submitter": "Peter B\\\"urgisser", "authors": "Peter Buergisser and Christian Ikenmeyer", "title": "Geometric Complexity Theory and Tensor Rank", "comments": "Extended Abstract and Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mulmuley and Sohoni (GCT1 in SICOMP 2001, GCT2 in SICOMP 2008) proposed to\nview the permanent versus determinant problem as a specific orbit closure\nproblem and to attack it by methods from geometric invariant and representation\ntheory. We adopt these ideas towards the goal of showing lower bounds on the\nborder rank of specific tensors, in particular for matrix multiplication. We\nthus study specific orbit closure problems for the group $G = GL(W_1)\\times\nGL(W_2)\\times GL(W_3)$ acting on the tensor product $W=W_1\\otimes W_2\\otimes\nW_3$ of complex finite dimensional vector spaces. Let $G_s = SL(W_1)\\times\nSL(W_2)\\times SL(W_3)$. A key idea from GCT2 is that the irreducible\n$G_s$-representations occurring in the coordinate ring of the $G$-orbit closure\nof a stable tensor $w\\in W$ are exactly those having a nonzero invariant with\nrespect to the stabilizer group of $w$.\n  However, we prove that by considering $G_s$-representations, as suggested in\nGCT1-2, only trivial lower bounds on border rank can be shown. It is thus\nnecessary to study $G$-representations, which leads to geometric extension\nproblems that are beyond the scope of the subgroup restriction problems\nemphasized in GCT1-2. We prove a very modest lower bound on the border rank of\nmatrix multiplication tensors using $G$-representations. This shows at least\nthat the barrier for $G_s$-representations can be overcome. To advance, we\nsuggest the coarser approach to replace the semigroup of representations of a\ntensor by its moment polytope. We prove first results towards determining the\nmoment polytopes of matrix multiplication and unit tensors.\n", "versions": [{"version": "v1", "created": "Fri, 5 Nov 2010 09:10:30 GMT"}], "update_date": "2010-11-08", "authors_parsed": [["Buergisser", "Peter", ""], ["Ikenmeyer", "Christian", ""]]}, {"id": "1011.1443", "submitter": "Robin Kothari", "authors": "Andrew M. Childs and Robin Kothari", "title": "Quantum query complexity of minor-closed graph properties", "comments": "v1: 25 pages, 2 figures. v2: 26 pages", "journal-ref": "Proc. 28th Symposium on Theoretical Aspects of Computer Science\n  (STACS 2011), Leibniz International Proceedings in Informatics 9, pp. 661-672", "doi": "10.4230/LIPIcs.STACS.2011.661", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantum query complexity of minor-closed graph properties, which\ninclude such problems as determining whether an $n$-vertex graph is planar, is\na forest, or does not contain a path of a given length. We show that most\nminor-closed properties---those that cannot be characterized by a finite set of\nforbidden subgraphs---have quantum query complexity \\Theta(n^{3/2}). To\nestablish this, we prove an adversary lower bound using a detailed analysis of\nthe structure of minor-closed properties with respect to forbidden topological\nminors and forbidden subgraphs. On the other hand, we show that minor-closed\nproperties (and more generally, sparse graph properties) that can be\ncharacterized by finitely many forbidden subgraphs can be solved strictly\nfaster, in o(n^{3/2}) queries. Our algorithms are a novel application of the\nquantum walk search framework and give improved upper bounds for several\nsubgraph-finding problems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Nov 2010 16:03:10 GMT"}, {"version": "v2", "created": "Thu, 19 May 2011 17:53:02 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Childs", "Andrew M.", ""], ["Kothari", "Robin", ""]]}, {"id": "1011.2152", "submitter": "Pierre Fraigniaud", "authors": "Pierre Fraigniaud, Amos Korman, David Peleg", "title": "Local Distributed Decision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central theme in distributed network algorithms concerns understanding and\ncoping with the issue of locality. Inspired by sequential complexity theory, we\nfocus on a complexity theory for distributed decision problems. In the context\nof locality, solving a decision problem requires the processors to\nindependently inspect their local neighborhoods and then collectively decide\nwhether a given global input instance belongs to some specified language. This\npaper introduces several classes of distributed decision problems, proves\nseparation among them and presents some complete problems. More specifically,\nwe consider the standard LOCAL model of computation and define LD (for local\ndecision) as the class of decision problems that can be solved in constant\nnumber of communication rounds. We first study the intriguing question of\nwhether randomization helps in local distributed computing, and to what extent.\nSpecifically, we define the corresponding randomized class BPLD, and ask\nwhether LD=BPLD. We provide a partial answer to this question by showing that\nin many cases, randomization does not help for deciding hereditary languages.\nIn addition, we define the notion of local many-one reductions, and introduce\nthe (nondeterministic) class NLD of decision problems for which there exists a\ncertificate that can be verified in constant number of communication rounds. We\nprove that there exists an NLD-complete problem. We also show that there exist\nproblems not in NLD. On the other hand, we prove that the class NLD#n, which is\nNLD assuming that each processor can access an oracle that provides the number\nof nodes in the network, contains all (decidable) languages. For this class we\nprovide a natural complete problem as well.\n", "versions": [{"version": "v1", "created": "Tue, 9 Nov 2010 17:13:13 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2011 12:50:32 GMT"}], "update_date": "2011-03-04", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Korman", "Amos", ""], ["Peleg", "David", ""]]}, {"id": "1011.2551", "submitter": "Xin Li", "authors": "Xin Li", "title": "On the Problem of Local Randomness in Privacy Amplification with an\n  Active Adversary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of privacy amplification with an active adversary in the\ninformation theoretic setting. In this setting, two parties Alice and Bob start\nout with a shared $n$-bit weak random string $W$, and try to agree on a secret\nrandom key $R$ over a public channel fully controlled by an active and\nunbounded adversary. Typical assumptions are that these two parties have access\nto local private uniform random bits. In this paper we seek to minimize the\nrequirements on the local randomness used by the two parties.\n  We make two improvements over previous results. First, we reduce the number\nof random bits needed for each party to $\\Theta(\\ell+\\log n)$, where $\\ell$ is\nthe security parameter, as long as $W$ has min-entropy $n^{\\Omega(1)}$.\nPreviously, the best known result needs to use $\\Theta((\\ell+\\log n)\\log n)$\nbits. Our result is also asymptotically optimal. Second, we generalize the\nproblem to the case where the two parties only have local weak random sources\ninstead of truly uniform random bits. We show that when each party has a local\nweak random source with min-entropy $> n/2$, there is an efficient privacy\namplification protocol that works nearly as good as if the two parties have\naccess to local uniform random bits. Next, in the case where each party only\nhas a weak random source with arbitrarily linear min-entropy, we give an\nefficient privacy amplification protocol where we can achieve security\nparameter up to $\\Omega(\\log k)$. Our results give the first protocols that\nachieve privacy amplification when each party only has access to a local weak\nrandom source.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 04:16:27 GMT"}], "update_date": "2010-11-12", "authors_parsed": [["Li", "Xin", ""]]}, {"id": "1011.2586", "submitter": "David Steurer", "authors": "Prasad Raghavendra and David Steurer and Madhur Tulsiani", "title": "Reductions Between Expansion Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Small-Set Expansion Hypothesis (Raghavendra, Steurer, STOC 2010) is a\nnatural hardness assumption concerning the problem of approximating the edge\nexpansion of small sets in graphs. This hardness assumption is closely\nconnected to the Unique Games Conjecture (Khot, STOC 2002). In particular, the\nSmall-Set Expansion Hypothesis implies the Unique Games Conjecture\n(Raghavendra, Steurer, STOC 2010).\n  Our main result is that the Small-Set Expansion Hypothesis is in fact\nequivalent to a variant of the Unique Games Conjecture. More precisely, the\nhypothesis is equivalent to the Unique Games Conjecture restricted to instance\nwith a fairly mild condition on the expansion of small sets. Alongside, we\nobtain the first strong hardness of approximation results for the Balanced\nSeparator and Minimum Linear Arrangement problems. Before, no such hardness was\nknown for these problems even assuming the Unique Games Conjecture.\n  These results not only establish the Small-Set Expansion Hypothesis as a\nnatural unifying hypothesis that implies the Unique Games Conjecture, all its\nconsequences and, in addition, hardness results for other problems like\nBalanced Separator and Minimum Linear Arrangement, but our results also show\nthat the Small-Set Expansion Hypothesis problem lies at the combinatorial heart\nof the Unique Games Conjecture.\n  The key technical ingredient is a new way of exploiting the structure of the\nUnique Games instances obtained from the Small-Set Expansion Hypothesis via\n(Raghavendra, Steurer, 2010). This additional structure allows us to modify\nstandard reductions in a way that essentially destroys their local-gadget\nnature. Using this modification, we can argue about the expansion in the graphs\nproduced by the reduction without relying on expansion properties of the\nunderlying Unique Games instance (which would be impossible for a local-gadget\nreduction).\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 07:39:48 GMT"}], "update_date": "2010-11-12", "authors_parsed": [["Raghavendra", "Prasad", ""], ["Steurer", "David", ""], ["Tulsiani", "Madhur", ""]]}, {"id": "1011.2719", "submitter": "Pierre Fraigniaud", "authors": "Pierre Fraigniaud and Andrzej Pelc", "title": "Decidability Classes for Mobile Agents Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a classification of decision problems that are to be solved by\nmobile agents operating in unlabeled graphs, using a deterministic protocol.\nThe classification is with respect to the ability of a team of agents to solve\nthe problem, possibly with the aid of additional information. In particular,\nour focus is on studying differences between the decidability of a decision\nproblem by agents and its verifiability when a certificate for a positive\nanswer is provided to the agents. We show that the class MAV of mobile agents\nverifiable problems is much wider than the class MAD of mobile agents decidable\nproblems. Our main result shows that there exist natural MAV-complete problems:\nthe most difficult problems in this class, to which all problems in MAV are\nreducible. Our construction of a MAV-complete problem involves two main\ningredients in mobile agents computability: the topology of the quotient graph\nand the number of operating agents. Beyond the class MAV we show that, for a\nsingle agent, three natural oracles yield a strictly increasing chain of\nrelative decidability classes.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 17:46:08 GMT"}], "update_date": "2010-11-12", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1011.2730", "submitter": "Frank Vega Delgado", "authors": "Frank Vega Delgado", "title": "A Solution to the P versus NP Problem", "comments": "Admin note: withdrawn by arXiv admin because of the use of a\n  pseudonym, in violation of arXiv policy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship between the complexity classes P and NP is a question that\nhas not yet been answered by the Theory of Computation. The existence of a\nlanguage in NP, proven not to belong to P, is sufficient evidence to establish\nthe separation of P from NP. If a language is not recursive, it can't belong to\nthe complexity class NP. We find a problem in NP which is not in P; because if\nit would be present in that class, then it will imply that some undecidable\nproblem will be in NP too. That's why it can be confirmed by reduction ad\nabsurdum the following result: P doesn't equal NP. This new problem named\nCertifying is to find a possible input given a particular deterministic Turing\nmachine named Certified Turing machine and its output.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 18:19:07 GMT"}, {"version": "v10", "created": "Mon, 28 Mar 2011 18:50:39 GMT"}, {"version": "v11", "created": "Mon, 18 Jul 2011 16:12:51 GMT"}, {"version": "v12", "created": "Thu, 28 Jul 2011 16:44:10 GMT"}, {"version": "v13", "created": "Fri, 29 Jul 2011 14:35:01 GMT"}, {"version": "v14", "created": "Wed, 10 Aug 2011 19:50:42 GMT"}, {"version": "v15", "created": "Fri, 12 Aug 2011 19:36:01 GMT"}, {"version": "v16", "created": "Tue, 30 Aug 2011 18:54:46 GMT"}, {"version": "v17", "created": "Wed, 31 Aug 2011 19:45:11 GMT"}, {"version": "v18", "created": "Mon, 12 Sep 2011 17:49:29 GMT"}, {"version": "v19", "created": "Tue, 13 Sep 2011 16:38:35 GMT"}, {"version": "v2", "created": "Fri, 12 Nov 2010 20:22:00 GMT"}, {"version": "v20", "created": "Wed, 14 Sep 2011 18:38:55 GMT"}, {"version": "v21", "created": "Wed, 21 Sep 2011 12:34:33 GMT"}, {"version": "v22", "created": "Fri, 30 Sep 2011 14:38:50 GMT"}, {"version": "v23", "created": "Tue, 25 Oct 2011 16:14:08 GMT"}, {"version": "v24", "created": "Mon, 19 Nov 2012 19:12:22 GMT"}, {"version": "v3", "created": "Mon, 15 Nov 2010 14:37:40 GMT"}, {"version": "v4", "created": "Tue, 23 Nov 2010 14:10:42 GMT"}, {"version": "v5", "created": "Mon, 29 Nov 2010 16:34:09 GMT"}, {"version": "v6", "created": "Tue, 30 Nov 2010 18:20:43 GMT"}, {"version": "v7", "created": "Thu, 9 Dec 2010 17:49:02 GMT"}, {"version": "v8", "created": "Tue, 4 Jan 2011 18:27:28 GMT"}, {"version": "v9", "created": "Mon, 17 Jan 2011 14:26:02 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Delgado", "Frank Vega", ""]]}, {"id": "1011.2751", "submitter": "Fernando Brandao", "authors": "Fernando G.S.L. Brandao, Matthias Christandl, Jon Yard", "title": "A quasipolynomial-time algorithm for the quantum separability problem", "comments": "9 pages, no figures; to appear in proceedings STOC '11", "journal-ref": "Proceedings of ACM Symposium on Theory of Computation (STOC'11),\n  June 2011, p. 343-351", "doi": "10.1145/1993636.1993683", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a quasipolynomial-time algorithm for solving the weak membership\nproblem for the convex set of separable, i.e. non-entangled, bipartite density\nmatrices. The algorithm decides whether a density matrix is separable or\nwhether it is eps-away from the set of the separable states in time\nexp(O(eps^-2 log |A| log |B|)), where |A| and |B| are the local dimensions, and\nthe distance is measured with either the Euclidean norm, or with the so-called\nLOCC norm. The latter is an operationally motivated norm giving the optimal\nprobability of distinguishing two bipartite quantum states, each shared by two\nparties, using any protocol formed by quantum local operations and classical\ncommunication (LOCC) between the parties. We also obtain improved algorithms\nfor optimizing over the set of separable states and for computing the\nground-state energy of mean-field Hamiltonians.\n  The techniques we develop are also applied to quantum Merlin-Arthur games,\nwhere we show that multiple provers are not more powerful than a single prover\nwhen the verifier is restricted to LOCC protocols, or when the verification\nprocedure is formed by a measurement of small Euclidean norm. This answers a\nquestion posed by Aaronson et al (Theory of Computing 5, 1, 2009) and provides\ntwo new characterizations of the complexity class QMA, a quantum analog of NP.\nOur algorithm uses semidefinite programming to search for a symmetric\nextension, as first proposed by Doherty, Parrilo and Spedialieri (Phys. Rev. A,\n69, 022308, 2004). The bound on the runtime follows from an improved de\nFinetti-type bound quantifying the monogamy of quantum entanglement, proved in\n(arXiv:1010.1750). This result, in turn, follows from a new lower bound on the\nquantum conditional mutual information and the entanglement measure squashed\nentanglement.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 20:17:17 GMT"}, {"version": "v2", "created": "Sat, 2 Apr 2011 21:26:26 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["Brandao", "Fernando G. S. L.", ""], ["Christandl", "Matthias", ""], ["Yard", "Jon", ""]]}, {"id": "1011.2787", "submitter": "Gus Gutoski", "authors": "Gus Gutoski and Xiaodi Wu", "title": "Parallel approximation of min-max problems", "comments": "28 pages. Final version, compiled in letterpaper with reasonable\n  margins", "journal-ref": "Computational Complexity: Volume 22, Issue 2 (2013), Page 385-428", "doi": "10.1007/s00037-013-0065-9", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient parallel approximation scheme for a new\nclass of min-max problems. The algorithm is derived from the matrix\nmultiplicative weights update method and can be used to find near-optimal\nstrategies for competitive two-party classical or quantum interactions in which\na referee exchanges any number of messages with one party followed by any\nnumber of additional messages with the other. It considerably extends the class\nof interactions which admit parallel solutions, demonstrating for the first\ntime the existence of a parallel algorithm for an interaction in which one\nparty reacts adaptively to the other.\n  As a consequence, we prove that several competing-provers complexity classes\ncollapse to PSPACE such as QRG(2), SQG and two new classes called DIP and DQIP.\nA special case of our result is a parallel approximation scheme for a specific\nclass of semidefinite programs whose feasible region consists of lists of\nsemidefinite matrices that satisfy a transcript-like consistency condition.\nApplied to this special case, our algorithm yields a direct polynomial-space\nsimulation of multi-message quantum interactive proofs resulting in a\nfirst-principles proof of QIP=PSPACE.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 22:39:13 GMT"}, {"version": "v2", "created": "Mon, 11 Apr 2011 17:15:54 GMT"}, {"version": "v3", "created": "Sat, 8 Dec 2012 14:43:35 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Gutoski", "Gus", ""], ["Wu", "Xiaodi", ""]]}, {"id": "1011.2887", "submitter": "HongVan Le", "authors": "Hong Van Le", "title": "Constructing elusive functions with help of evaluation mappings", "comments": "v. 5: 23 pages, misprints are corrected, a condition on $n$ and $r$\n  in Proposition 4.11 is added, a proof of Corollary 4.12 is added, v. 6: 24\n  pages, improved presentation, in particular Lemmas 4.8, 4.13 are added,\n  Reference 5 is added (and commented)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method to construct elusive functions using techniques of\ncommutative algebra and algebraic geometry. The key notions of this method are\nelusive subsets and evaluation mappings. We also develop the effective\nelimination theory combined with algebraic number field theory in order to\nconstruct concrete points outside the image of a polynomial mapping. Using the\ndeveloped methods, for $F = C \\text{or} F = R$, we construct examples of\n$(s,r)$-elusive functions whose monomial coefficients are algebraic numbers,\nwhich give polynomials with algebraic number coefficients of large circuit\nsize.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 11:44:54 GMT"}, {"version": "v2", "created": "Fri, 3 Feb 2012 10:39:41 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2012 13:44:40 GMT"}, {"version": "v4", "created": "Fri, 15 Feb 2013 10:26:58 GMT"}, {"version": "v5", "created": "Thu, 9 Jan 2014 11:26:55 GMT"}, {"version": "v6", "created": "Sun, 28 Sep 2014 22:08:29 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Van Le", "Hong", ""]]}, {"id": "1011.2894", "submitter": "Michael Pinsker", "authors": "Manuel Bodirsky and Michael Pinsker", "title": "Schaefer's theorem for graphs", "comments": "54 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schaefer's theorem is a complexity classification result for so-called\nBoolean constraint satisfaction problems: it states that every Boolean\nconstraint satisfaction problem is either contained in one out of six classes\nand can be solved in polynomial time, or is NP-complete.\n  We present an analog of this dichotomy result for the propositional logic of\ngraphs instead of Boolean logic. In this generalization of Schaefer's result,\nthe input consists of a set W of variables and a conjunction \\Phi\\ of\nstatements (\"constraints\") about these variables in the language of graphs,\nwhere each statement is taken from a fixed finite set \\Psi\\ of allowed\nquantifier-free first-order formulas; the question is whether \\Phi\\ is\nsatisfiable in a graph.\n  We prove that either \\Psi\\ is contained in one out of 17 classes of graph\nformulas and the corresponding problem can be solved in polynomial time, or the\nproblem is NP-complete. This is achieved by a universal-algebraic approach,\nwhich in turn allows us to use structural Ramsey theory. To apply the\nuniversal-algebraic approach, we formulate the computational problems under\nconsideration as constraint satisfaction problems (CSPs) whose templates are\nfirst-order definable in the countably infinite random graph. Our method to\nclassify the computational complexity of those CSPs is based on a\nRamsey-theoretic analysis of functions acting on the random graph, and we\ndevelop general tools suitable for such an analysis which are of independent\nmathematical interest.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 12:15:48 GMT"}, {"version": "v2", "created": "Sun, 2 Oct 2011 17:46:16 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2013 22:24:07 GMT"}, {"version": "v4", "created": "Tue, 14 Oct 2014 16:19:40 GMT"}, {"version": "v5", "created": "Sun, 17 May 2015 16:42:27 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Pinsker", "Michael", ""]]}, {"id": "1011.3234", "submitter": "Nitin Saxena", "authors": "Nitin Saxena and C. Seshadhri", "title": "Blackbox identity testing for bounded top fanin depth-3 circuits: the\n  field doesn't matter", "comments": "14 pages, 1 figure, preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let C be a depth-3 circuit with n variables, degree d and top fanin k (called\nsps(k,d,n) circuits) over base field F. It is a major open problem to design a\ndeterministic polynomial time blackbox algorithm that tests if C is identically\nzero. Klivans & Spielman (STOC 2001) observed that the problem is open even\nwhen k is a constant. This case has been subjected to a serious study over the\npast few years, starting from the work of Dvir & Shpilka (STOC 2005).\n  We give the first polynomial time blackbox algorithm for this problem. Our\nalgorithm runs in time poly(nd^k), regardless of the base field. The only field\nfor which polynomial time algorithms were previously known is F=Q (Kayal &\nSaraf, FOCS 2009, and Saxena & Seshadhri, FOCS 2010). This is the first\nblackbox algorithm for depth-3 circuits that does not use the rank based\napproaches of Karnin & Shpilka (CCC 2008).\n  We prove an important tool for the study of depth-3 identities. We design a\nblackbox polynomial time transformation that reduces the number of variables in\na sps(k,d,n) circuit to k variables, but preserves the identity structure.\n", "versions": [{"version": "v1", "created": "Sun, 14 Nov 2010 16:50:51 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Saxena", "Nitin", ""], ["Seshadhri", "C.", ""]]}, {"id": "1011.3245", "submitter": "Scott Aaronson", "authors": "Scott Aaronson and Alex Arkhipov", "title": "The Computational Complexity of Linear Optics", "comments": "94 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give new evidence that quantum computers -- moreover, rudimentary quantum\ncomputers built entirely out of linear-optical elements -- cannot be\nefficiently simulated by classical computers. In particular, we define a model\nof computation in which identical photons are generated, sent through a\nlinear-optical network, then nonadaptively measured to count the number of\nphotons in each mode. This model is not known or believed to be universal for\nquantum computation, and indeed, we discuss the prospects for realizing the\nmodel using current technology. On the other hand, we prove that the model is\nable to solve sampling problems and search problems that are classically\nintractable under plausible assumptions. Our first result says that, if there\nexists a polynomial-time classical algorithm that samples from the same\nprobability distribution as a linear-optical network, then P^#P=BPP^NP, and\nhence the polynomial hierarchy collapses to the third level. Unfortunately,\nthis result assumes an extremely accurate simulation. Our main result suggests\nthat even an approximate or noisy classical simulation would already imply a\ncollapse of the polynomial hierarchy. For this, we need two unproven\nconjectures: the \"Permanent-of-Gaussians Conjecture\", which says that it is\n#P-hard to approximate the permanent of a matrix A of independent N(0,1)\nGaussian entries, with high probability over A; and the \"Permanent\nAnti-Concentration Conjecture\", which says that |Per(A)|>=sqrt(n!)/poly(n) with\nhigh probability over A. We present evidence for these conjectures, both of\nwhich seem interesting even apart from our application. This paper does not\nassume knowledge of quantum optics. Indeed, part of its goal is to develop the\nbeautiful theory of noninteracting bosons underlying our model, and its\nconnection to the permanent function, in a self-contained way accessible to\ntheoretical computer scientists.\n", "versions": [{"version": "v1", "created": "Sun, 14 Nov 2010 18:36:44 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Aaronson", "Scott", ""], ["Arkhipov", "Alex", ""]]}, {"id": "1011.3493", "submitter": "David Doty", "authors": "Ho-Lin Chen, David Doty, and Shinnosuke Seki", "title": "Program Size and Temperature in Self-Assembly", "comments": "The previous version contained more sections, but we have split that\n  paper into two. The other half will be posted as a separate paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Winfree's abstract Tile Assembly Model (aTAM) is a model of molecular\nself-assembly of DNA complexes known as tiles, which float freely in solution\nand attach one at a time to a growing \"seed\" assembly based on specific binding\nsites on their four sides. We show that there is a polynomial-time algorithm\nthat, given an n x n square, finds the minimal tile system (i.e., the system\nwith the smallest number of distinct tile types) that uniquely self-assembles\nthe square, answering an open question of Adleman, Cheng, Goel, Huang, Kempe,\nMoisset de Espanes, and Rothemund (\"Combinatorial Optimization Problems in\nSelf-Assembly\", STOC 2002). Our investigation leading to this algorithm reveals\nother positive and negative results about the relationship between the size of\na tile system and its \"temperature\" (the binding strength threshold required\nfor a tile to attach).\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 20:22:58 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2011 17:25:06 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Chen", "Ho-Lin", ""], ["Doty", "David", ""], ["Seki", "Shinnosuke", ""]]}, {"id": "1011.3840", "submitter": "Shiva Kintali", "authors": "Shiva Kintali", "title": "Realizable Paths and the NL vs L Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A celebrated theorem of Savitch states that NSPACE(S) is contained in\nDSPACE(S^2). In particular, Savitch gave a deterministic algorithm to solve\nST-CONNECTIVITY (an NL-complete problem) using O(log^2{n}) space, implying NL\nis in DSPACE(log^2{n}). While Savitch's theorem itself has not been improved in\nthe last four decades, studying the space complexity of several special cases\nof ST-CONNECTIVITY has provided new insights into the space-bounded complexity\nclasses.\n  In this paper, we introduce new kind of graph connectivity problems which we\ncall graph realizability problems. All of our graph realizability problems are\ngeneralizations of UNDIRECTED ST-CONNECTIVITY. ST-REALIZABILITY, the most\ngeneral graph realizability problem, is LogCFL-complete. We define the\ncorresponding complexity classes that lie between L and LogCFL and study their\nrelationships.\n  As special cases of our graph realizability problems we define two natural\nproblems, BALANCED ST-CONNECTIVITY and POSITIVE BALANCED ST-CONNECTIVITY, that\nlie between L and NL. We present a deterministic O(lognloglogn) space algorithm\nfor BALANCED ST-CONNECTIVITY. More generally we prove that SGSLogCFL, a\ngeneralization of BALANCED ST-CONNECTIVITY, is contained in\nDSPACE(lognloglogn). To achieve this goal we generalize several concepts (such\nas graph squaring and transitive closure) and algorithms (such as parallel\nalgorithms) known in the context of UNDIRECTED ST-CONNECTIVITY.\n", "versions": [{"version": "v1", "created": "Tue, 16 Nov 2010 21:51:53 GMT"}], "update_date": "2010-11-18", "authors_parsed": [["Kintali", "Shiva", ""]]}, {"id": "1011.4128", "submitter": "J. Maurice Rojas", "authors": "Kaitlyn Phillipson and J. Maurice Rojas", "title": "Fewnomial Systems with Many Roots, and an Adelic Tau Conjecture", "comments": "23 pages, 9 illustrations, accepted for publication. Mainly fixing\n  some dumb typos introduced in last version, particularly in Adelic Tau\n  Conjecture", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a system F of n polynomials in n variables, with a total of n+k\ndistinct exponent vectors, over any local field L. We discuss conjecturally\ntight bounds on the maximal number of non-degenerate roots F can have over L,\nwith all coordinates having fixed phase, as a function of n, k, and L only. In\nparticular, we give new explicit systems with number of roots approaching the\nbest known upper bounds. We also briefly review the background behind such\nbounds, and their application, including connections to computational number\ntheory and variants of the Shub-Smale tau-Conjecture and the P vs. NP Problem.\nOne of our key tools is the construction of combinatorially constrained\ntropical varieties with maximally many intersections.\n", "versions": [{"version": "v1", "created": "Thu, 18 Nov 2010 03:10:42 GMT"}, {"version": "v2", "created": "Tue, 23 Nov 2010 00:15:28 GMT"}, {"version": "v3", "created": "Tue, 14 Feb 2012 04:10:04 GMT"}, {"version": "v4", "created": "Sat, 3 Nov 2012 02:04:11 GMT"}, {"version": "v5", "created": "Tue, 6 Nov 2012 04:16:53 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Phillipson", "Kaitlyn", ""], ["Rojas", "J. Maurice", ""]]}, {"id": "1011.4138", "submitter": "David Rosenbaum", "authors": "David Rosenbaum", "title": "Quantum Algorithms for Tree Isomorphism and State Symmetrization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph isomorphism problem is theoretically interesting and also has many\npractical applications. The best known classical algorithms for graph\nisomorphism all run in time super-polynomial in the size of the graph in the\nworst case. An interesting open problem is whether quantum computers can solve\nthe graph isomorphism problem in polynomial time. In this paper, an algorithm\nis shown which can decide if two rooted trees are isomorphic in polynomial\ntime. Although this problem is easy to solve efficiently on a classical\ncomputer, the techniques developed may be useful as a basis for quantum\nalgorithms for deciding isomorphism of more interesting types of graphs. The\nrelated problem of quantum state symmetrization is also studied. A polynomial\ntime algorithm for the problem of symmetrizing a set of orthonormal states over\nan arbitrary permutation group is shown.\n", "versions": [{"version": "v1", "created": "Thu, 18 Nov 2010 06:01:19 GMT"}, {"version": "v2", "created": "Sat, 4 Dec 2010 06:03:23 GMT"}, {"version": "v3", "created": "Mon, 25 Apr 2011 07:36:47 GMT"}], "update_date": "2011-04-26", "authors_parsed": [["Rosenbaum", "David", ""]]}, {"id": "1011.4224", "submitter": "Bart M. P. Jansen", "authors": "Hans L. Bodlaender and Bart M. P. Jansen and Stefan Kratsch", "title": "Cross-Composition: A New Technique for Kernelization Lower Bounds", "comments": "Updated information based on final version submitted to STACS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We introduce a new technique for proving kernelization lower bounds, called\ncross-composition. A classical problem L cross-composes into a parameterized\nproblem Q if an instance of Q with polynomially bounded parameter value can\nexpress the logical OR of a sequence of instances of L. Building on work by\nBodlaender et al. (ICALP 2008) and using a result by Fortnow and Santhanam\n(STOC 2008) we show that if an NP-complete problem cross-composes into a\nparameterized problem Q then Q does not admit a polynomial kernel unless the\npolynomial hierarchy collapses. Our technique generalizes and strengthens the\nrecent techniques of using OR-composition algorithms and of transferring the\nlower bounds via polynomial parameter transformations. We show its\napplicability by proving kernelization lower bounds for a number of important\ngraphs problems with structural (non-standard) parameterizations, e.g.,\nChromatic Number, Clique, and Weighted Feedback Vertex Set do not admit\npolynomial kernels with respect to the vertex cover number of the input graphs\nunless the polynomial hierarchy collapses, contrasting the fact that these\nproblems are trivially fixed-parameter tractable for this parameter. We have\nsimilar lower bounds for Feedback Vertex Set.\n", "versions": [{"version": "v1", "created": "Thu, 18 Nov 2010 16:30:44 GMT"}, {"version": "v2", "created": "Fri, 10 Dec 2010 15:44:57 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Jansen", "Bart M. P.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1011.4686", "submitter": "Carlos Pedro dos Santos Gon\\c{c}alves", "authors": "Carlos Pedro Gon\\c{c}alves", "title": "Chaos in Binary Category Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.CC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Category computation theory deals with a web-based systemic processing that\nunderlies the morphic webs, which constitute the basis of categorial logical\ncalculus. It is proven that, for these structures, algorithmically\nincompressible binary patterns can be morphically compressed, with respect to\nthe local connectivities, in a binary morphic program. From the local\nconnectivites, there emerges a global morphic connection that can be\ncharacterized by a low length binary string, leading to the identification of\nchaotic categorial dynamics, underlying the algorithmically random pattern. The\nwork focuses on infinite binary chains of C2, which is a category that\nimplements an X-OR-based categorial logical calculus.\n", "versions": [{"version": "v1", "created": "Sun, 21 Nov 2010 18:38:57 GMT"}], "update_date": "2010-11-23", "authors_parsed": [["Gon\u00e7alves", "Carlos Pedro", ""]]}, {"id": "1011.4744", "submitter": "Florian Richoux", "authors": "Florian Richoux", "title": "Complexity of Homogeneous Co-Boolean Constraint Satisfaction Problems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Satisfaction Problems (CSP) constitute a convenient way to capture\nmany combinatorial problems. The general CSP is known to be NP-complete, but\nits complexity depends on a template, usually a set of relations, upon which\nthey are constructed. Following this template, there exist tractable and\nintractable instances of CSPs. It has been proved that for each CSP problem\nover a given set of relations there exists a corresponding CSP problem over\ngraphs of unary functions belonging to the same complexity class. In this short\nnote we show a dichotomy theorem for every finite domain D of CSP built upon\ngraphs of homogeneous co-Boolean functions, i.e., unary functions sharing the\nBoolean range {0, 1}.\n", "versions": [{"version": "v1", "created": "Mon, 22 Nov 2010 07:17:50 GMT"}], "update_date": "2010-11-23", "authors_parsed": [["Richoux", "Florian", ""]]}, {"id": "1011.4757", "submitter": "Florian Richoux", "authors": "Manuel Bodirsky, Miki Hermann and Florian Richoux", "title": "Complexity of Existential Positive First-Order Logic", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let gamma be a (not necessarily finite) structure with a finite relational\nsignature. We prove that deciding whether a given existential positive sentence\nholds in gamma is in Logspace or complete for the class CSP(gamma)_NP under\ndeterministic polynomial-time many-one reductions. Here, CSP(gamma)_NP is the\nclass of problems that can be reduced to the Constraint Satisfaction Problem of\ngamma under non-deterministic polynomial-time many-one reductions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Nov 2010 09:37:23 GMT"}, {"version": "v2", "created": "Wed, 12 Jan 2011 02:42:55 GMT"}], "update_date": "2011-01-13", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Hermann", "Miki", ""], ["Richoux", "Florian", ""]]}, {"id": "1011.4935", "submitter": "Alexander A. Sherstov", "authors": "Alexander A. Sherstov", "title": "Strong direct product theorems for quantum communication and query\n  complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strong direct product theorem (SDPT) states that solving n instances of a\nproblem requires Omega(n) times the resources for a single instance, even to\nachieve success probability exp(-Omega(n)). We prove that quantum communication\ncomplexity obeys an SDPT whenever the communication lower bound for a single\ninstance is proved by the generalized discrepancy method, the strongest\ntechnique in that model. We prove that quantum query complexity obeys an SDPT\nwhenever the query lower bound for a single instance is proved by the\npolynomial method, one of the two main techniques in that model. In both\nmodels, we prove the corresponding XOR lemmas and threshold direct product\ntheorems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Nov 2010 20:55:58 GMT"}], "update_date": "2010-11-23", "authors_parsed": [["Sherstov", "Alexander A.", ""]]}, {"id": "1011.4974", "submitter": "Ran Raz", "authors": "Shira Kritchman and Ran Raz", "title": "The Surprise Examination Paradox and the Second Incompleteness Theorem", "comments": "8 pages", "journal-ref": "Notices of the AMS volume 57 number 11 (December 2010), published\n  by the American Mathematical Society", "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new proof for Godel's second incompleteness theorem, based on\nKolmogorov complexity, Chaitin's incompleteness theorem, and an argument that\nresembles the surprise examination paradox. We then go the other way around and\nsuggest that the second incompleteness theorem gives a possible resolution of\nthe surprise examination paradox. Roughly speaking, we argue that the flaw in\nthe derivation of the paradox is that it contains a hidden assumption that one\ncan prove the consistency of the mathematical theory in which the derivation is\ndone; which is impossible by the second incompleteness theorem.\n", "versions": [{"version": "v1", "created": "Mon, 22 Nov 2010 23:35:10 GMT"}], "update_date": "2010-11-24", "authors_parsed": [["Kritchman", "Shira", ""], ["Raz", "Ran", ""]]}, {"id": "1011.5447", "submitter": "Rastislav Lenhardt", "authors": "Rastislav Lenhardt", "title": "Proof of Concept: Fast Solutions to NP-problems by Using SAT and Integer\n  Programming Solvers", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, the power of the state-of-the-art SAT and Integer\nProgramming solvers has dramatically increased. They implement many new\ntechniques and heuristics and since any NP problem can be converted to SAT or\nILP instance, we could take advantage of these techniques in general by\nconverting the instance of NP problem to SAT formula or Integer program. A\nproblem we consider, in this proof of concept, is finding a largest clique in a\ngraph. We ran several experiments on large random graphs and compared 3\napproaches: Optimised backtrack solution, Translation to SAT and Translation to\nInteger program. The last one was the fastest one.\n", "versions": [{"version": "v1", "created": "Wed, 24 Nov 2010 18:19:29 GMT"}], "update_date": "2010-11-25", "authors_parsed": [["Lenhardt", "Rastislav", ""]]}, {"id": "1011.5737", "submitter": "Juraj Stacho", "authors": "Michel Habib and Juraj Stacho", "title": "Unique perfect phylogeny is NP-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer, in the affirmative, the following question proposed by Mike Steel\nas a $100 challenge: \"Is the following problem NP-hard? Given a ternary\nphylogenetic X-tree T and a collection Q of quartet subtrees on X, is T the\nonly tree that displays Q ?\"\n", "versions": [{"version": "v1", "created": "Fri, 26 Nov 2010 09:36:03 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Habib", "Michel", ""], ["Stacho", "Juraj", ""]]}, {"id": "1011.5966", "submitter": "Saeed Asaeedi", "authors": "Saeed Asaeedi, Farzad Didehvar", "title": "Enumeration Order complexity Equivalency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout this article we develop and change the definitions and the ideas\nin \"arXiv:1006.4939\", in order to consider the efficiency of functions and\ncomplexity time problems. The central idea here is effective enumeration and\nlisting, and efficiency of function which is defined between two sets proposed\nin basic definitions. More in detail, it might be that h and g were co-order\nbut the velocity of them be different.\n", "versions": [{"version": "v1", "created": "Sat, 27 Nov 2010 11:24:21 GMT"}], "update_date": "2010-11-30", "authors_parsed": [["Asaeedi", "Saeed", ""], ["Didehvar", "Farzad", ""]]}, {"id": "1011.6021", "submitter": "Prabhanjan Ananth", "authors": "Prabhanjan V. Ananth, Ambedkar Dukkipati", "title": "Border basis detection is NP-complete", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Border basis detection (BBD) is described as follows: given a set of\ngenerators of an ideal, decide whether that set of generators is a border basis\nof the ideal with respect to some order ideal. The motivation for this problem\ncomes from a similar problem related to Gr\\\"obner bases termed as Gr\\\"obner\nbasis detection (GBD) which was proposed by Gritzmann and Sturmfels (1993). GBD\nwas shown to be NP-hard by Sturmfels and Wiegelmann (1996). In this paper, we\ninvestigate the computational complexity of BBD and show that it is\nNP-complete.\n", "versions": [{"version": "v1", "created": "Sun, 28 Nov 2010 08:22:42 GMT"}], "update_date": "2010-11-30", "authors_parsed": [["Ananth", "Prabhanjan V.", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1011.6239", "submitter": "Marcin Pilipczuk", "authors": "Marek Cygan and Geevarghese Philip and Marcin Pilipczuk and Micha{\\l}\n  Pilipczuk and Jakub Onufry Wojtaszczyk", "title": "Dominating Set is Fixed Parameter Tractable in Claw-free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the dominating set problem parameterized by solution size is\nfixed-parameter tractable (FPT) in graphs that do not contain the claw\n(K(1,3)), the complete bipartite graph on four vertices where the two parts\nhave one and three vertices, respectively) as an induced subgraph. We present\nan algorithm that uses 2^O(k^2)n^O(1) time and polynomial space to decide\nwhether a claw-free graph on n vertices has a dominating set of size at most k.\nNote that this parameterization of dominating set is W[2]-hard on the set of\nall graphs, and thus is unlikely to have an FPT algorithm for graphs in\ngeneral. The most general class of graphs for which an FPT algorithm was\npreviously known for this parameterization of dominating set is the class of\nK(i,j)-free graphs, which exclude, for some fixed i,j, the complete bipartite\ngraph K(i,j) as a subgraph. For i,i >= 2, the class of claw-free graphs and any\nclass of K(i,j)-free graphs are not comparable with respect to set inclusion.\nWe thus extend the range of graphs over which this parameterization of\ndominating set is known to be fixed-parameter tractable. We also show that, in\nsome sense, it is the presence of the claw that makes this parameterization of\nthe dominating set problem hard. More precisely, we show that for any t ?>= 4,\nthe dominating set problem parameterized by the solution size is W[2]-hard in\ngraphs that exclude the t-claw K(1,t) as an induced subgraph. Our arguments\nalso imply that the related connected dominating set and dominating clique\nproblems are W[2]-hard in these graph classes. Finally, we show that for any t,\nthe clique problem parameterized by solution size, which is W[1]-hard on\ngeneral graphs, is FPT in t-claw-free graphs. Our results add to the small and\ngrowing collection of FPT results for graph classes defined by excluded\nsubgraphs, rather than by excluded minors.\n", "versions": [{"version": "v1", "created": "Mon, 29 Nov 2010 14:28:40 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2011 13:19:14 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Cygan", "Marek", ""], ["Philip", "Geevarghese", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""], ["Wojtaszczyk", "Jakub Onufry", ""]]}, {"id": "1011.6397", "submitter": "Raghu Meka", "authors": "Raghu Meka", "title": "Almost Optimal Explicit Johnson-Lindenstrauss Transformations", "comments": "Updated references to prior work and minor formatting changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Johnson-Lindenstrauss lemma is a fundamental result in probability with\nseveral applications in the design and analysis of algorithms in high\ndimensional geometry. Most known constructions of linear embeddings that\nsatisfy the Johnson-Lindenstrauss property involve randomness. We address the\nquestion of explicitly constructing such embedding families and provide a\nconstruction with an almost optimal use of randomness: we use\nO(log(n/delta)log(log(n/delta)/epsilon)) random bits for embedding n dimensions\nto O(log(1/delta)/epsilon^2) dimensions with error probability at most delta,\nand distortion at most epsilon.\n  In particular, for delta = 1/poly(n) and fixed epsilon, we use O(log n loglog\nn) random bits. Previous constructions required at least O(log^2 n) random bits\nto get polynomially small error.\n", "versions": [{"version": "v1", "created": "Mon, 29 Nov 2010 21:42:10 GMT"}, {"version": "v2", "created": "Fri, 10 Dec 2010 20:23:02 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Meka", "Raghu", ""]]}]