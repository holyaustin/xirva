[{"id": "1205.0036", "submitter": "David J. Rosenbaum", "authors": "David Rosenbaum", "title": "Optimal Quantum Circuits for Nearest-Neighbor Architectures", "comments": "24 pages, 6 figures. v1 introduces all the results. v2 and v3 make\n  minor improvements to the presentation and add additional references", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the depth of quantum circuits in the realistic architecture\nwhere a classical controller determines which local interactions to apply on\nthe kD grid Z^k where k >= 2 is the same (up to a constant factor) as in the\nstandard model where arbitrary interactions are allowed. This allows\nminimum-depth circuits (up to a constant factor) for the nearest-neighbor\narchitecture to be obtained from minimum-depth circuits in the standard\nabstract model. Our work therefore justifies the standard assumption that\ninteractions can be performed between arbitrary pairs of qubits. In particular,\nour results imply that Shor's algorithm, controlled operations and fanouts can\nbe implemented in constant depth, polynomial size and polynomial width in this\narchitecture.\n  We also present optimal non-adaptive quantum circuits for controlled\noperations and fanouts on a kD grid. These circuits have depth Theta(n^(1 /\nk)), size Theta(n) and width Theta(n). Our lower bound also applies to a more\ngeneral class of operations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 21:35:44 GMT"}, {"version": "v2", "created": "Thu, 10 May 2012 02:21:04 GMT"}, {"version": "v3", "created": "Wed, 8 May 2013 01:50:41 GMT"}], "update_date": "2013-05-09", "authors_parsed": [["Rosenbaum", "David", ""]]}, {"id": "1205.0263", "submitter": "Cristopher Moore", "authors": "Russell Impagliazzo, Cristopher Moore, and Alexander Russell", "title": "An Entropic Proof of Chang's Inequality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chang's lemma is a useful tool in additive combinatorics and the analysis of\nBoolean functions. Here we give an elementary proof using entropy. The constant\nwe obtain is tight, and we give a slight improvement in the case where the\nvariables are highly biased.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2012 21:13:05 GMT"}, {"version": "v2", "created": "Wed, 16 May 2012 04:28:58 GMT"}], "update_date": "2012-05-17", "authors_parsed": [["Impagliazzo", "Russell", ""], ["Moore", "Cristopher", ""], ["Russell", "Alexander", ""]]}, {"id": "1205.0314", "submitter": "Li-Yang Tan", "authors": "Li-Yang Tan", "title": "Analysis of Boolean Functions", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scribe notes from the 2012 Barbados Workshop on Computational Complexity. A\nseries of lectures on Analysis of Boolean Functions by Ryan O'Donnell, with a\nguest lecture by Per Austrin.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2012 03:51:56 GMT"}], "update_date": "2012-05-03", "authors_parsed": [["Tan", "Li-Yang", ""]]}, {"id": "1205.0606", "submitter": "Philipp Hupp", "authors": "Philipp Hupp, Riko Jacob", "title": "Tight Bounds for Low Dimensional Star Stencils in the Parallel External\n  Memory Model", "comments": "64 pages, 8 figures, 4 tables", "journal-ref": "WADS 2013, LNCS 8037, pp. 415-426, 2013", "doi": "10.1007/978-3-642-40104-6_36", "report-no": "eth-5672-01", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stencil computations on low dimensional grids are kernels of many scientific\napplications including finite difference methods used to solve partial\ndifferential equations. On typical modern computer architectures, such stencil\ncomputations are limited by the performance of the memory subsystem, namely by\nthe bandwidth between main memory and the cache. This work considers the\ncomputation of star stencils, like the 5-point and 7-point stencil, in the\nexternal memory model and parallel external memory model and analyses the\nconstant of the leading term of the non-compulsory I/Os. While optimizing\nstencil computations is an active field of research, there has been a\nsignificant gap between the lower bounds and the performance of the algorithms\nso far. In two dimensions, this work provides matching constants for lower and\nupper bounds closing a multiplicative gap of 4. In three dimensions, the bounds\nmatch up to a factor of $\\sqrt{2}$ improving the known results by a factor of\n$2 \\sqrt{3}\\sqrt{B}$, where $B$ is the block (cache line) size of the external\nmemory model. For dimensions $d\\geq 4$, the lower bound is improved between a\nfactor of $4$ and $6$. For arbitrary dimension~$d$, the first analysis of the\nconstant of the leading term of the non-compulsory I/Os is presented. For\n$d\\geq 3$ the lower and upper bound match up to a factor of\n$\\sqrt[d-1]{d!}\\approx \\frac{d}{e}$.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 03:27:41 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2012 14:00:14 GMT"}, {"version": "v3", "created": "Thu, 22 Jan 2015 15:07:17 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Hupp", "Philipp", ""], ["Jacob", "Riko", ""]]}, {"id": "1205.0679", "submitter": "Christoph Berkholz", "authors": "Christoph Berkholz (RWTH Aachen University)", "title": "Lower Bounds for Existential Pebble Games and k-Consistency Tests", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 4 (October 8,\n  2013) lmcs:1010", "doi": "10.2168/LMCS-9(4:2)2013", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existential k-pebble game characterizes the expressive power of the\nexistential-positive k-variable fragment of first-order logic on finite\nstructures. The winner of the existential k-pebble game on two given finite\nstructures can be determined in time O(n2k) by dynamic programming on the graph\nof game configurations. We show that there is no O(n(k-3)/12)-time algorithm\nthat decides which player can win the existential k-pebble game on two given\nstructures. This lower bound is unconditional and does not rely on any\ncomplexity-theoretic assumptions. Establishing strong k-consistency is a\nwell-known heuristic for solving the constraint satisfaction problem (CSP). By\nthe game characterization of Kolaitis and Vardi our result implies that there\nis no O(n(k-3)/12)-time algorithm that decides if strong k-consistency can be\nestablished for a given CSP-instance.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 11:32:49 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2013 13:38:12 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2013 08:03:51 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Berkholz", "Christoph", "", "RWTH Aachen University"]]}, {"id": "1205.0722", "submitter": "Arne Meier", "authors": "Arne Meier", "title": "Generalized Complexity of ALC Subsumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subsumption problem with respect to terminologies in the description\nlogic ALC is EXPTIME-complete. We investigate the computational complexity of\nfragments of this problem by means of allowed Boolean operators. Hereto we make\nuse of the notion of clones in the context of Post's lattice. Furthermore we\nconsider all four possible quantifier combinations for each fragment\nparameterized by a clone. We will see that depending on what quantifiers are\navailable the classification will be either tripartite or a quartering.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 14:26:38 GMT"}], "update_date": "2012-05-04", "authors_parsed": [["Meier", "Arne", ""]]}, {"id": "1205.0852", "submitter": "Jason Crampton", "authors": "Jason Crampton, Gregory Gutin, Anders Yeo", "title": "On the Parameterized Complexity and Kernelization of the Workflow\n  Satisfiability Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A workflow specification defines a set of steps and the order in which those\nsteps must be executed. Security requirements may impose constraints on which\ngroups of users are permitted to perform subsets of those steps. A workflow\nspecification is said to be satisfiable if there exists an assignment of users\nto workflow steps that satisfies all the constraints. An algorithm for\ndetermining whether such an assignment exists is important, both as a static\nanalysis tool for workflow specifications, and for the construction of run-time\nreference monitors for workflow management systems. Finding such an assignment\nis a hard problem in general, but work by Wang and Li in 2010 using the theory\nof parameterized complexity suggests that efficient algorithms exist under\nreasonable assumptions about workflow specifications. In this paper, we improve\nthe complexity bounds for the workflow satisfiability problem. We also\ngeneralize and extend the types of constraints that may be defined in a\nworkflow specification and prove that the satisfiability problem remains\nfixed-parameter tractable for such constraints. Finally, we consider\npreprocessing for the problem and prove that in an important special case, in\npolynomial time, we can reduce the given input into an equivalent one, where\nthe number of users is at most the number of steps. We also show that no such\nreduction exists for two natural extensions of this case, which bounds the\nnumber of users by a polynomial in the number of steps, provided a\nwidely-accepted complexity-theoretical assumption holds.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 03:47:46 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2012 16:36:22 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2013 09:39:22 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Crampton", "Jason", ""], ["Gutin", "Gregory", ""], ["Yeo", "Anders", ""]]}, {"id": "1205.0903", "submitter": "Henning Wunderlich", "authors": "Henning Wunderlich", "title": "A note on a problem in communication complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we prove a version of Tarui's Theorem in communication\ncomplexity, namely $PH^{cc} \\subseteq BP\\cdot PP^{cc}$. Consequently, every\nmeasure for $PP^{cc}$ leads to a measure for $PH^{cc}$, subsuming a result of\nLinial and Shraibman that problems with high mc-rigidity lie outside the\npolynomial hierarchy. By slightly changing the definition of mc-rigidity\n(arbitrary instead of uniform distribution), it is then evident that the class\n$M^{cc}$ of problems with low mc-rigidity equals $BP\\cdot PP^{cc}$. As $BP\\cdot\nPP^{cc} \\subseteq PSPACE^{cc}$, this rules out the possibility, that had been\nleft open, that even polynomial space is contained in $M^{cc}$.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 10:15:03 GMT"}], "update_date": "2012-05-07", "authors_parsed": [["Wunderlich", "Henning", ""]]}, {"id": "1205.0968", "submitter": "Amit Chakrabarti", "authors": "Amit Chakrabarti and Ranganath Kondapally and Zhenghui Wang", "title": "Information Complexity versus Corruption and Applications to\n  Orthogonality and Gap-Hamming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three decades of research in communication complexity have led to the\ninvention of a number of techniques to lower bound randomized communication\ncomplexity. The majority of these techniques involve properties of large\nsubmatrices (rectangles) of the truth-table matrix defining a communication\nproblem. The only technique that does not quite fit is information complexity,\nwhich has been investigated over the last decade. Here, we connect information\ncomplexity to one of the most powerful \"rectangular\" techniques: the\nrecently-introduced smooth corruption (or \"smooth rectangle\") bound. We show\nthat the former subsumes the latter under rectangular input distributions. We\nconjecture that this subsumption holds more generally, under arbitrary\ndistributions, which would resolve the long-standing direct sum question for\nrandomized communication. As an application, we obtain an optimal $\\Omega(n)$\nlower bound on the information complexity---under the {\\em uniform\ndistribution}---of the so-called orthogonality problem (ORT), which is in turn\nclosely related to the much-studied Gap-Hamming-Distance (GHD). The proof of\nthis bound is along the lines of recent communication lower bounds for GHD, but\nwe encounter a surprising amount of additional technical detail.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 14:51:04 GMT"}], "update_date": "2012-05-07", "authors_parsed": [["Chakrabarti", "Amit", ""], ["Kondapally", "Ranganath", ""], ["Wang", "Zhenghui", ""]]}, {"id": "1205.0991", "submitter": "Marc Hellmuth", "authors": "Marc Hellmuth", "title": "On the Complexity of Recognizing S-composite and S-prime Graphs", "comments": null, "journal-ref": null, "doi": "10.1016/j.dam.2012.11.003", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  S-prime graphs are graphs that cannot be represented as nontrivial subgraphs\nof nontrivial Cartesian products of graphs, i.e., whenever it is a subgraph of\na nontrivial Cartesian product graph it is a subgraph of one the factors. A\ngraph is S-composite if it is not S-prime. Although linear time recognition\nalgorithms for determining whether a graph is prime or not with respect to the\nCartesian product are known, it remained unknown if a similar result holds also\nfor the recognition of S-prime and S-composite graphs.\n  In this contribution the computational complexity of recognizing S-composite\nand S-prime graphs is considered. Klav{\\v{z}}ar \\emph{et al.} [\\emph{Discr.\\\nMath.} \\textbf{244}: 223-230 (2002)] proved that a graph is S-composite if and\nonly if it admits a nontrivial path-$k$-coloring. The problem of determining\nwhether there exists a path-$k$-coloring for a given graph is shown to be\nNP-complete even for $k=2$. This in turn is utilized to show that determining\nwhether a graph is S-composite is NP-complete and thus, determining whether a\ngraph is S-prime is CoNP-complete. Many other problems are shown to be NP-hard,\nusing the latter results.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 15:49:05 GMT"}, {"version": "v2", "created": "Mon, 7 May 2012 14:04:40 GMT"}, {"version": "v3", "created": "Wed, 9 May 2012 11:25:16 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2013 16:15:37 GMT"}, {"version": "v5", "created": "Wed, 10 May 2017 12:00:22 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Hellmuth", "Marc", ""]]}, {"id": "1205.1015", "submitter": "S\\'ebastien Tavenas", "authors": "Pascal Koiran, Natacha Portier and S\\'ebastien Tavenas", "title": "A Wronskian Approach to the real \\tau-conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the real \\tau-conjecture, the number of real roots of a sum of\nproducts of sparse polynomials should be polynomially bounded in the size of\nsuch an expression. It is known that this conjecture implies a superpolynomial\nlower bound on the arithmetic circuit complexity of the permanent.\n  In this paper, we use the Wronksian determinant to give an upper bound on the\nnumber of real roots of sums of products of sparse polynomials. The proof\ntechnique is quite versatile; it can in particular be applied to some sparse\ngeometric problems that do not originate from arithmetic circuit complexity.\nThe paper should therefore be of interest to researchers from these two\ncommunities (complexity theory and sparse polynomial systems).\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 17:40:44 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2013 18:56:24 GMT"}, {"version": "v3", "created": "Fri, 16 May 2014 14:42:55 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Koiran", "Pascal", ""], ["Portier", "Natacha", ""], ["Tavenas", "S\u00e9bastien", ""]]}, {"id": "1205.1050", "submitter": "Alasdair Urquhart", "authors": "Alasdair Urquhart (University of Toronto)", "title": "Width and size of regular resolution proofs", "comments": "The article was reformatted using the style file for Logical Methods\n  in Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 2 (June 1,\n  2012) lmcs:862", "doi": "10.2168/LMCS-8(2:8)2012", "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the topic of the minimum width of a regular resolution\nrefutation of a set of clauses. The main result shows that there are examples\nhaving small regular resolution refutations, for which any regular refutation\nmust contain a large clause. This forms a contrast with corresponding results\nfor general resolution refutations.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 19:43:10 GMT"}, {"version": "v2", "created": "Mon, 7 May 2012 18:26:30 GMT"}, {"version": "v3", "created": "Thu, 31 May 2012 18:59:49 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Urquhart", "Alasdair", "", "University of Toronto"]]}, {"id": "1205.1183", "submitter": "Xiaohui Bei", "authors": "Xiaohui Bei, Ning Chen, Shengyu Zhang", "title": "On the Complexity of Trial and Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by certain applications from physics, biochemistry, economics, and\ncomputer science, in which the objects under investigation are not accessible\nbecause of various limitations, we propose a trial-and-error model to examine\nalgorithmic issues in such situations. Given a search problem with a hidden\ninput, we are asked to find a valid solution, to find which we can propose\ncandidate solutions (trials), and use observed violations (errors), to prepare\nfuture proposals. In accordance with our motivating applications, we consider\nthe fairly broad class of constraint satisfaction problems, and assume that\nerrors are signaled by a verification oracle in the format of the index of a\nviolated constraint (with the content of the constraint still hidden).\n  Our discoveries are summarized as follows. On one hand, despite the seemingly\nvery little information provided by the verification oracle, efficient\nalgorithms do exist for a number of important problems. For the Nash, Core,\nStable Matching, and SAT problems, the unknown-input versions are as hard as\nthe corresponding known-input versions, up to a factor of polynomial. We\nfurther give almost tight bounds on the latter two problems' trial\ncomplexities. On the other hand, there are problems whose complexities are\nsubstantially increased in the unknown-input model. In particular, no\ntime-efficient algorithms exist (under standard hardness assumptions) for Graph\nIsomorphism and Group Isomorphism problems. The tools used to achieve these\nresults include order theory, strong ellipsoid method, and some non-standard\nreductions.\n  Our model investigates the value of information, and our results demonstrate\nthat the lack of input information can introduce various levels of extra\ndifficulty. The model exhibits intimate connections with (and we hope can also\nserve as a useful supplement to) certain existing learning and complexity\ntheories.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2012 06:03:27 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 05:39:19 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Bei", "Xiaohui", ""], ["Chen", "Ning", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1205.1271", "submitter": "Rajesh Chitnis", "authors": "Rajesh Chitnis, Marek Cygan, MohammadTaghi Hajiaghayi, D\\'aniel Marx", "title": "Directed Subset Feedback Vertex Set is Fixed-Parameter Tractable", "comments": "To appear in ACM Transactions on Algorithms. A preliminary version\n  appeared in ICALP '12. We would like to thank Marcin Pilipczuk for pointing\n  out a missing case in the conference version which has been considered in\n  this version. Also, we give an single exponential FPT algorithm improving on\n  the double exponential algorithm from the conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G$ and an integer $k$, the Feedback Vertex Set (FVS) problem\nasks if there is a vertex set $T$ of size at most $k$ that hits all cycles in\nthe graph. The fixed-parameter tractability status of FVS in directed graphs\nwas a long-standing open problem until Chen et al. (STOC '08) showed that it is\nFPT by giving a $4^{k}k!n^{O(1)}$ time algorithm. In the subset versions of\nthis problems, we are given an additional subset $S$ of vertices (resp., edges)\nand we want to hit all cycles passing through a vertex of $S$ (resp. an edge of\n$S$). Recently, the Subset Feedback Vertex Set in undirected graphs was shown\nto be FPT by Cygan et al. (ICALP '11) and independently by Kakimura et al.\n(SODA '12). We generalize the result of Chen et al. (STOC '08) by showing that\nSubset Feedback Vertex Set in directed graphs can be solved in time\n$2^{O(k^3)}n^{O(1)}$. By our result, we complete the picture for feedback\nvertex set problems and their subset versions in undirected and directed\ngraphs. Besides proving the fixed-parameter tractability of Directed Subset\nFeedback Vertex Set, we reformulate the random sampling of important separators\ntechnique in an abstract way that can be used for a general family of\ntransversal problems. Moreover, we modify the probability distribution used in\nthe technique to achieve better running time; in particular, this gives an\nimprovement from $2^{2^{O(k)}}$ to $2^{O(k^2)}$ in the parameter dependence of\nthe Directed Multiway Cut algorithm of Chitnis et al. (SODA '12).\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2012 02:59:39 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2013 11:25:14 GMT"}, {"version": "v3", "created": "Tue, 2 Dec 2014 16:15:16 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["Chitnis", "Rajesh", ""], ["Cygan", "Marek", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1205.1462", "submitter": "Mohammad Iftekhar Husain", "authors": "Mohammad Iftekhar Husain and Steve Ko and Atri Rudra and Steve Uurtamo", "title": "Almost Universal Hash Families are also Storage Enforcing", "comments": "arXiv admin note: substantial text overlap with arXiv:1104.3025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every almost universal hash function also has the storage\nenforcement property. Almost universal hash functions have found numerous\napplications and we show that this new storage enforcement property allows the\napplication of almost universal hash functions in a wide range of remote\nverification tasks: (i) Proof of Secure Erasure (where we want to remotely\nerase and securely update the code of a compromised machine with memory-bounded\nadversary), (ii) Proof of Ownership (where a storage server wants to check if a\nclient has the data it claims to have before giving access to deduplicated\ndata) and (iii) Data possession (where the client wants to verify whether the\nremote storage server is storing its data). Specifically, storage enforcement\nguarantee in the classical data possession problem removes any practical\nincentive for the storage server to cheat the client by saving on storage\nspace.\n  The proof of our result relies on a natural combination of Kolmogorov\nComplexity and List Decoding. To the best of our knowledge this is the first\nwork that combines these two techniques. We believe the newly introduced\nstorage enforcement property of almost universal hash functions will open\npromising avenues of exciting research under memory-bounded (bounded storage)\nadversary model.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2012 17:01:07 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Husain", "Mohammad Iftekhar", ""], ["Ko", "Steve", ""], ["Rudra", "Atri", ""], ["Uurtamo", "Steve", ""]]}, {"id": "1205.1473", "submitter": "Petr Novotn\\'y", "authors": "Tom\\'a\\v{s} Br\\'azdil, Anton\\'in Ku\\v{c}era, Petr Novotn\\'y, Dominik\n  Wojtczak", "title": "Minimizing Expected Termination Time in One-Counter Markov Decision\n  Processes", "comments": "35 pages, this is a full version of a paper accepted for publication\n  in proceedings of ICALP 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the value and an optimal strategy for\nminimizing the expected termination time in one-counter Markov decision\nprocesses. Since the value may be irrational and an optimal strategy may be\nrather complicated, we concentrate on the problems of approximating the value\nup to a given error epsilon > 0 and computing a finite representation of an\nepsilon-optimal strategy. We show that these problems are solvable in\nexponential time for a given configuration, and we also show that they are\ncomputationally hard in the sense that a polynomial-time approximation\nalgorithm cannot exist unless P=NP.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 14:21:11 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Ku\u010dera", "Anton\u00edn", ""], ["Novotn\u00fd", "Petr", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "1205.1670", "submitter": "Deepak Rajendraprasad", "authors": "L. Sunil Chandran and Deepak Rajendraprasad", "title": "Rainbow Colouring of Split and Threshold Graphs", "comments": "15 pages, 3 figures, accepted for presentation at the 18th Annual\n  International Computing and Combinatorics Conference (COCOON 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A rainbow colouring of a connected graph is a colouring of the edges of the\ngraph, such that every pair of vertices is connected by at least one path in\nwhich no two edges are coloured the same. Such a colouring using minimum\npossible number of colours is called an optimal rainbow colouring, and the\nminimum number of colours required is called the rainbow connection number of\nthe graph. In this article, we show the following:\n  1. The problem of deciding whether a graph can be rainbow coloured using 3\ncolours remains NP-complete even when restricted to the class of split graphs.\nHowever, any split graph can be rainbow coloured in linear time using at most\none more colour than the optimum.\n  2. For every integer k larger than 2, the problem of deciding whether a graph\ncan be rainbow coloured using k colours remains NP-complete even when\nrestricted to the class of chordal graphs.\n  3. For every positive integer k, threshold graphs with rainbow connection\nnumber k can be characterised based on their degree sequence alone. Further, we\ncan optimally rainbow colour a threshold graph in linear time.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 12:25:19 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Chandran", "L. Sunil", ""], ["Rajendraprasad", "Deepak", ""]]}, {"id": "1205.2174", "submitter": "Mikhail Volkov", "authors": "F\\\"odor Fominykh and Pavel Martyugin and Mikhail Volkov", "title": "P(l)aying for Synchronization", "comments": "Version 1 (by F\\\"odor Fominykh and Mikhail Volkov): 12 pages, 5\n  figures, close to the version published in the Proceedings of the 17th\n  International Conference on Implementation and Application of Automata (LNCS\n  7381). Version 2: 19 pages, 7 figures, one of the problems left open in\n  Version 1 solved, submitted", "journal-ref": "Int. J. Found. Comput. Sci. 24 (2013), 765-780", "doi": "10.1142/S0129054113400170", "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two topics are presented: synchronization games and synchronization costs. In\na synchronization game on a deterministic finite automaton, there are two\nplayers, Alice and Bob, whose moves alternate. Alice wants to synchronize the\ngiven automaton, while Bob aims to make her task as hard as possible. We answer\na few natural questions related to such games. Speaking about synchronization\ncosts, we consider deterministic automata in which each transition has a\ncertain price. The problem is whether or not a given automaton can be\nsynchronized within a given budget. We determine the complexity of this\nproblem. We also formulate a few open questions.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 07:06:12 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2012 18:27:54 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Fominykh", "F\u00f6dor", ""], ["Martyugin", "Pavel", ""], ["Volkov", "Mikhail", ""]]}, {"id": "1205.2234", "submitter": "Aravindan Vijayaraghavan", "authors": "Konstantin Makarychev, Yury Makarychev and Aravindan Vijayaraghavan", "title": "Approximation Algorithms for Semi-random Graph Partitioning Problems", "comments": "To appear at the 44th ACM Symposium on Theory of Computing (STOC\n  2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and study a new semi-random model for graph\npartitioning problems. We believe that it captures many properties of\nreal--world instances. The model is more flexible than the semi-random model of\nFeige and Kilian and planted random model of Bui, Chaudhuri, Leighton and\nSipser.\n  We develop a general framework for solving semi-random instances and apply it\nto several problems of interest. We present constant factor bi-criteria\napproximation algorithms for semi-random instances of the Balanced Cut,\nMulticut, Min Uncut, Sparsest Cut and Small Set Expansion problems. We also\nshow how to almost recover the optimal solution if the instance satisfies an\nadditional expanding condition. Our algorithms work in a wider range of\nparameters than most algorithms for previously studied random and semi-random\nmodels.\n  Additionally, we study a new planted algebraic expander model and develop\nconstant factor bi-criteria approximation algorithms for graph partitioning\nproblems in this model.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 11:22:24 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Makarychev", "Konstantin", ""], ["Makarychev", "Yury", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1205.2761", "submitter": "Attila Pereszl\\'enyi", "authors": "Attila Pereszl\\'enyi", "title": "Multi-Prover Quantum Merlin-Arthur Proof Systems with Small Gap", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies multiple-proof quantum Merlin-Arthur (QMA) proof systems\nin the setting when the completeness-soundness gap is small. Small means that\nwe only lower-bound the gap with an inverse-exponential function of the input\nlength, or with an even smaller function. Using the protocol of Blier and Tapp\n[arXiv:0709.0738], we show that in this case the proof system has the same\nexpressive power as non-deterministic exponential time (NEXP). Since\nsingle-proof QMA proof systems, with the same bound on the gap, have expressive\npower at most exponential time (EXP), we get a separation between single and\nmulti-prover proof systems in the 'small-gap setting', under the assumption\nthat EXP is not equal to NEXP. This implies, among others, the nonexistence of\ncertain operators called disentanglers (defined by Aaronson et al.\n[arXiv:0804.0802]), with good approximation parameters.\n  We also show that in this setting the proof system has the same expressive\npower if we restrict the verifier to be able to perform only Bell-measurements,\ni.e., using a BellQMA verifier. This is not known to hold in the usual setting,\nwhen the gap is bounded by an inverse-polynomial function of the input length.\nTo show this we use the protocol of Chen and Drucker [arXiv:1011.0716]. The\nonly caveat here is that we need at least a linear amount of proofs to achieve\nthe power of NEXP, while in the previous setting two proofs were enough.\n  We also study the case when the proof-lengths are only logarithmic in the\ninput length and observe that in some cases the expressive power decreases.\nHowever, we show that it doesn't decrease further if we make the proof lengths\nto be even shorter.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2012 09:49:58 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Pereszl\u00e9nyi", "Attila", ""]]}, {"id": "1205.2934", "submitter": "Xi Chen", "authors": "Jin-Yi Cai and Xi Chen and Heng Guo and Pinyan Lu", "title": "Inapproximability After Uniqueness Phase Transition in Two-Spin Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A two-state spin system is specified by a 2 x 2 matrix\n  A = {A_{0,0} A_{0,1}, A_{1,0} A_{1,1}} = {\\beta 1, 1 \\gamma} where \\beta,\n\\gamma \\ge 0. Given an input graph G=(V,E), the partition function Z_A(G) of a\nsystem is defined as\n  Z_A(G) = \\sum_{\\sigma: V -> {0,1}} \\prod_{(u,v) \\in E} A_{\\sigma(u),\n\\sigma(v)}\n  We prove inapproximability results for the partition function in the region\nspecified by the non-uniqueness condition from phase transition for the Gibbs\nmeasure. More specifically, assuming NP \\ne RP, for any fixed \\beta, \\gamma in\nthe unit square, there is no randomized polynomial-time algorithm that\napproximates Z_A(G) for d-regular graphs G with relative error \\epsilon =\n10^{-4}, if d = \\Omega(\\Delta(\\beta,\\gamma)), where \\Delta(\\beta,\\gamma) >\n1/(1-\\beta\\gamma) is the uniqueness threshold. Up to a constant factor, this\nhardness result confirms the conjecture that the uniqueness phase transition\ncoincides with the transition from computational tractability to intractability\nfor Z_A(G). We also show a matching inapproximability result for a region of\nparameters \\beta, \\gamma outside the unit square, and all our results\ngeneralize to partition functions with an external field.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 03:10:28 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Chen", "Xi", ""], ["Guo", "Heng", ""], ["Lu", "Pinyan", ""]]}, {"id": "1205.3534", "submitter": "Parikshit Gopalan", "authors": "Parikshit Gopala, Raghu Meka, Omer Reingold", "title": "DNF Sparsification and a Faster Deterministic Counting Algorithm", "comments": "To appear in the IEEE Conference on Computational Complexity, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a DNF formula on n variables, the two natural size measures are the\nnumber of terms or size s(f), and the maximum width of a term w(f). It is\nfolklore that short DNF formulas can be made narrow. We prove a converse,\nshowing that narrow formulas can be sparsified. More precisely, any width w DNF\nirrespective of its size can be $\\epsilon$-approximated by a width $w$ DNF with\nat most $(w\\log(1/\\epsilon))^{O(w)}$ terms.\n  We combine our sparsification result with the work of Luby and Velikovic to\ngive a faster deterministic algorithm for approximately counting the number of\nsatisfying solutions to a DNF. Given a formula on n variables with poly(n)\nterms, we give a deterministic $n^{\\tilde{O}(\\log \\log(n))}$ time algorithm\nthat computes an additive $\\epsilon$ approximation to the fraction of\nsatisfying assignments of f for $\\epsilon = 1/\\poly(\\log n)$. The previous best\nresult due to Luby and Velickovic from nearly two decades ago had a run-time of\n$n^{\\exp(O(\\sqrt{\\log \\log n}))}$.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 00:36:34 GMT"}], "update_date": "2012-05-17", "authors_parsed": [["Gopala", "Parikshit", ""], ["Meka", "Raghu", ""], ["Reingold", "Omer", ""]]}, {"id": "1205.3554", "submitter": "Manoj Prabhakaran", "authors": "Mohammad Mahmoody, Hemanta K. Maji, Manoj Prabhakaran", "title": "Limits of Random Oracles in Secure Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The seminal result of Impagliazzo and Rudich (STOC 1989) gave a black-box\nseparation between one-way functions and public-key encryption: informally, a\npublic-key encryption scheme cannot be constructed using one-way functions as\nthe sole source of computational hardness. In addition, this implied a\nblack-box separation between one-way functions and protocols for certain Secure\nFunction Evaluation (SFE) functionalities (in particular, Oblivious Transfer).\nSurprisingly, however, {\\em since then there has been no further progress in\nseparating one-way functions and SFE functionalities} (though several other\nblack-box separation results were shown). In this work, we present the complete\npicture for deterministic 2-party SFE functionalities. We show that one-way\nfunctions are black-box separated from {\\em all such SFE functionalities},\nexcept the ones which have unconditionally secure protocols (and hence do not\nrely on any computational hardness), when secure computation against\nsemi-honest adversaries is considered. In the case of security against active\nadversaries, a black-box one-way function is indeed useful for SFE, but we show\nthat it is useful only as much as access to an ideal commitment functionality\nis useful.\n  Technically, our main result establishes the limitations of random oracles\nfor secure computation.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 05:27:08 GMT"}], "update_date": "2012-05-17", "authors_parsed": [["Mahmoody", "Mohammad", ""], ["Maji", "Hemanta K.", ""], ["Prabhakaran", "Manoj", ""]]}, {"id": "1205.3655", "submitter": "Asia Furones", "authors": "Asia Furones", "title": "P versus UP", "comments": "Administratively withdrawn due to policy violations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Admin note: withdrawn by arXiv admin because of the use of a pseudonym, in\nviolation of arXiv policy.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 12:26:51 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2012 16:18:48 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2012 18:05:31 GMT"}, {"version": "v4", "created": "Mon, 13 Aug 2012 17:37:36 GMT"}, {"version": "v5", "created": "Mon, 19 Nov 2012 17:34:47 GMT"}], "update_date": "2014-07-18", "authors_parsed": [["Furones", "Asia", ""]]}, {"id": "1205.3728", "submitter": "Ignasi Sau", "authors": "Nicolas Bousquet, Daniel Gon\\c{c}alves, George B. Mertzios, Christophe\n  Paul, Ignasi Sau, and St\\'ephan Thomass\\'e", "title": "Parameterized Domination in Circle Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A circle graph is the intersection graph of a set of chords in a circle. Keil\n[Discrete Applied Mathematics, 42(1):51-63, 1993] proved that Dominating Set,\nConnected Dominating Set, and Total Dominating Set are NP-complete in circle\ngraphs. To the best of our knowledge, nothing was known about the parameterized\ncomplexity of these problems in circle graphs. In this paper we prove the\nfollowing results, which contribute in this direction:\n  - Dominating Set, Independent Dominating Set, Connected Dominating Set, Total\nDominating Set, and Acyclic Dominating Set are W[1]-hard in circle graphs,\nparameterized by the size of the solution.\n  - Whereas both Connected Dominating Set and Acyclic Dominating Set are\nW[1]-hard in circle graphs, it turns out that Connected Acyclic Dominating Set\nis polynomial-time solvable in circle graphs.\n  - If T is a given tree, deciding whether a circle graph has a dominating set\nisomorphic to T is NP-complete when T is in the input, and FPT when\nparameterized by |V(T)|. We prove that the FPT algorithm is subexponential.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 16:32:43 GMT"}], "update_date": "2012-05-17", "authors_parsed": [["Bousquet", "Nicolas", ""], ["Gon\u00e7alves", "Daniel", ""], ["Mertzios", "George B.", ""], ["Paul", "Christophe", ""], ["Sau", "Ignasi", ""], ["Thomass\u00e9", "St\u00e9phan", ""]]}, {"id": "1205.3813", "submitter": "William  Gasarch", "authors": "Daniel Apon, William Gasarch and Kevin Lawler", "title": "An NP-Complete Problem in Grid Coloring", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A c-coloring of G(n,m)=n x m is a mapping of G(n,m) into {1,...,c} such that\nno four corners forming a rectangle have the same color. In 2009 a challenge\nwas proposed via the internet to find a 4-coloring of G(17,17). This attracted\nconsiderable attention from the popular mathematics community. A coloring was\nproduced; however, finding it proved to be difficult. The question arises: is\nthe problem of grid coloring is difficult in general? We present three results\nthat support this conjecture, (1) an NP completeness result, (2) a lower bound\non Tree-resolution, (3) a lower bound on Tree-CP proofs. Note that items (2)\nand (3) yield statements from Ramsey Theory which are of size polynomial in\ntheir parameters and require exponential size in various proof systems.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 21:23:47 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 17:04:09 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Apon", "Daniel", ""], ["Gasarch", "William", ""], ["Lawler", "Kevin", ""]]}, {"id": "1205.4124", "submitter": "Christian Schridde", "authors": "Christian Schridde", "title": "The permanent, graph gadgets and counting solutions for certain types of\n  planar formulas", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we build on the idea of Valiant \\cite{Val79a} and\nBen-Dor/Halevi \\cite{Ben93}, that is, to count the number of satisfying\nsolutions of a boolean formula via computing the permanent of a specially\nconstructed matrix. We show that the Desnanot-Jacobi identity ($\\dji$) prevents\nValiant's original approach to achieve a parsimonious reduction to the\npermanent over a field of characteristic two. As the next step, since the\ncomputation of the permanent is $#\\classP$-complete, we make use of the\nequality of the permanent and the number of perfect matchings in an unweighted\ngraph's bipartite double cover. Whenever this bipartite double cover (BDC) is\nplanar, the number of perfect matchings can be counted in polynomial time using\nKasteleyn's algorithm \\cite{Kas67}. To enforce planarity of the BDC, we replace\nValiant's original gadgets with new gadgets and describe what properties these\ngadgets must have. We show that the property of \\textit{circular planarity}\nplays a crucial role to find the correct gadgets for a counting problem. To\ncircumvent the $\\dji$-barrier, we switch over to fields\n$\\mathbb{Z}/p\\mathbb{Z}$, for a prime $p > 2$.\n  With this approach we are able to count the number of solutions for\n$\\forestdreisat$ formulas in randomized polynomial time. Finally, we present a\nconjecture that states which kind of generalized gadgets can not be found,\nsince otherwise one could prove $\\classRP = \\classNP$. The conjecture\nestablishes a relationship between the determinants of the minors of a graph\n$\\grG$'s adjacency matrix and the \\textit{circular planar} structure of\n$\\grG$'s BDC regarding a given set of nodes.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2012 10:03:17 GMT"}], "update_date": "2012-05-21", "authors_parsed": [["Schridde", "Christian", ""]]}, {"id": "1205.4484", "submitter": "Aram Harrow", "authors": "Boaz Barak, Fernando G.S.L. Brand\\~ao, Aram W. Harrow, Jonathan A.\n  Kelner, David Steurer, Yuan Zhou", "title": "Hypercontractivity, Sum-of-Squares Proofs, and their Applications", "comments": "v1: 52 pages. v2: 53 pages, fixed small bugs in proofs of section 6\n  (on UG integrality gaps) and section 7 (on 2->4 norm of random matrices).\n  Added comments about real-vs-complex random matrices and about the\n  k-extendable vs k-extendable & PPT hierarchies. v3: fixed mistakes in random\n  matrix section. The result now holds only for matrices with random entries\n  instead of random columns", "journal-ref": "Proc. STOC 2012, pp. 307--326", "doi": "10.1145/2213977.2214006", "report-no": null, "categories": "cs.CC cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of approximating the 2->q norm of\nlinear operators (defined as ||A||_{2->q} = sup_v ||Av||_q/||v||_2), as well as\nconnections between this question and issues arising in quantum information\ntheory and the study of Khot's Unique Games Conjecture (UGC). We show the\nfollowing:\n  1. For any constant even integer q>=4, a graph $G$ is a \"small-set expander\"\nif and only if the projector into the span of the top eigenvectors of G's\nadjacency matrix has bounded 2->q norm. As a corollary, a good approximation to\nthe 2->q norm will refute the Small-Set Expansion Conjecture--a close variant\nof the UGC. We also show that such a good approximation can be obtained in\nexp(n^(2/q)) time, thus obtaining a different proof of the known subexponential\nalgorithm for Small Set Expansion.\n  2. Constant rounds of the \"Sum of Squares\" semidefinite programing hierarchy\ncertify an upper bound on the 2->4 norm of the projector to low-degree\npolynomials over the Boolean cube, as well certify the unsatisfiability of the\n\"noisy cube\" and \"short code\" based instances of Unique Games considered by\nprior works. This improves on the previous upper bound of exp(poly log n)\nrounds (for the \"short code\"), as well as separates the \"Sum of\nSquares\"/\"Lasserre\" hierarchy from weaker hierarchies that were known to\nrequire omega(1) rounds.\n  3. We show reductions between computing the 2->4 norm and computing the\ninjective tensor norm of a tensor, a problem with connections to quantum\ninformation theory. Three corollaries are: (i) the 2->4 norm is NP-hard to\napproximate to precision inverse-polynomial in the dimension, (ii) the 2->4\nnorm does not have a good approximation (in the sense above) unless 3-SAT can\nbe solved in time exp(sqrt(n) polylog(n)), and (iii) known algorithms for the\nquantum separability problem imply a non-trivial additive approximation for the\n2->4 norm.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 04:00:32 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2012 17:51:32 GMT"}, {"version": "v3", "created": "Sun, 16 Nov 2014 13:11:20 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Barak", "Boaz", ""], ["Brand\u00e3o", "Fernando G. S. L.", ""], ["Harrow", "Aram W.", ""], ["Kelner", "Jonathan A.", ""], ["Steurer", "David", ""], ["Zhou", "Yuan", ""]]}, {"id": "1205.4550", "submitter": "Gabor Etesi", "authors": "Gabor Etesi", "title": "A proof of the Geroch-Horowitz-Penrose formulation of the strong cosmic\n  censor conjecture motivated by computability theory", "comments": "16pp, LaTeX, no figures. Final published version", "journal-ref": "Int. Journ. Theor. Phys. 52(3), 946-960 (2013)", "doi": "10.1007/s10773-012-1407-0", "report-no": null, "categories": "gr-qc cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a proof of a mathematical version of the strong\ncosmic censor conjecture attributed to Geroch-Horowitz and Penrose but\nformulated explicitly by Wald. The proof is based on the existence of\nfuture-inextendible causal curves in causal pasts of events on the future\nCauchy horizon in a non-globally hyperbolic space-time. By examining explicit\nnon-globally hyperbolic space-times we find that in case of several physically\nrelevant solutions these future-inextendible curves have in fact infinite\nlength. This way we recognize a close relationship between asymptotically flat\nor anti-de Sitter, physically relevant extendible space-times and the so-called\nMalament-Hogarth space-times which play a central role in recent investigations\nin the theory of \"gravitational computers\". This motivates us to exhibit a more\nsharp, more geometric formulation of the strong cosmic censor conjecture,\nnamely \"all physically relevant, asymptotically flat or anti-de Sitter but\nnon-globally hyperbolic space-times are Malament-Hogarth ones\".\n  Our observations may indicate a natural but hidden connection between the\nstrong cosmic censorship scenario and the Church-Turing thesis revealing an\nunexpected conceptual depth beneath both conjectures.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 10:18:48 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2012 08:05:23 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2013 09:02:33 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Etesi", "Gabor", ""]]}, {"id": "1205.4576", "submitter": "Holenstein Thomas", "authors": "Thomas Holenstein and Makrand Sinha", "title": "Constructing a Pseudorandom Generator Requires an Almost Linear Number\n  of Calls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a black-box construction of a pseudorandom generator from a\none-way function needs to make Omega(n/log(n)) calls to the underlying one-way\nfunction. The bound even holds if the one-way function is guaranteed to be\nregular. In this case it matches the best known construction due to Goldreich,\nKrawczyk, and Luby (SIAM J. Comp. 22, 1993), which uses O(n/log(n)) calls.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 12:06:16 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Holenstein", "Thomas", ""], ["Sinha", "Makrand", ""]]}, {"id": "1205.4605", "submitter": "Mika G\\\"o\\\"os", "authors": "Mika G\\\"o\\\"os, Jukka Suomela", "title": "No Sublogarithmic-time Approximation Scheme for Bipartite Vertex Cover", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": "10.1007/s00446-013-0194-z", "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K\\\"onig's theorem states that on bipartite graphs the size of a maximum\nmatching equals the size of a minimum vertex cover. It is known from prior work\nthat for every \\epsilon > 0 there exists a constant-time distributed algorithm\nthat finds a (1+\\epsilon)-approximation of a maximum matching on 2-coloured\ngraphs of bounded degree. In this work, we show---somewhat surprisingly---that\nno sublogarithmic-time approximation scheme exists for the dual problem: there\nis a constant \\delta > 0 so that no randomised distributed algorithm with\nrunning time o(\\log n) can find a (1+\\delta)-approximation of a minimum vertex\ncover on 2-coloured graphs of maximum degree 3. In fact, a simple application\nof the Linial--Saks (1993) decomposition demonstrates that this lower bound is\ntight.\n  Our lower-bound construction is simple and, to some extent, independent of\nprevious techniques. Along the way we prove that a certain cut minimisation\nproblem, which might be of independent interest, is hard to approximate locally\non expander graphs.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 14:07:00 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["G\u00f6\u00f6s", "Mika", ""], ["Suomela", "Jukka", ""]]}, {"id": "1205.4821", "submitter": "Randall Dougherty", "authors": "Randall Dougherty, Jack Lutz, R. Daniel Mauldin, and Jason Teutsch", "title": "Translating the Cantor set by a random", "comments": null, "journal-ref": "Trans. Amer. Math. Soc. 366 (2014), 3027-3041", "doi": "10.1090/S0002-9947-2014-05912-6", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the constructive dimension of points in random translates of the\nCantor set. The Cantor set \"cancels randomness\" in the sense that some of its\nmembers, when added to Martin-Lof random reals, identify a point with lower\nconstructive dimension than the random itself. In particular, we find the\nHausdorff dimension of the set of points in a Cantor set translate with a given\nconstructive dimension.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 07:12:49 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Dougherty", "Randall", ""], ["Lutz", "Jack", ""], ["Mauldin", "R. Daniel", ""], ["Teutsch", "Jason", ""]]}, {"id": "1205.4893", "submitter": "Amit Daniely", "authors": "Yonatan Bilu and Amit Daniely and Nati Linial and Michael Saks", "title": "On the practically interesting instances of MAXCUT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of a computational problem is traditionally quantified based\non the hardness of its worst case. This approach has many advantages and has\nled to a deep and beautiful theory. However, from the practical perspective,\nthis leaves much to be desired. In application areas, practically interesting\ninstances very often occupy just a tiny part of an algorithm's space of\ninstances, and the vast majority of instances are simply irrelevant. Addressing\nthese issues is a major challenge for theoretical computer science which may\nmake theory more relevant to the practice of computer science.\n  Following Bilu and Linial, we apply this perspective to MAXCUT, viewed as a\nclustering problem. Using a variety of techniques, we investigate practically\ninteresting instances of this problem. Specifically, we show how to solve in\npolynomial time distinguished, metric, expanding and dense instances of MAXCUT\nunder mild stability assumptions. In particular, $(1+\\epsilon)$-stability\n(which is optimal) suffices for metric and dense MAXCUT. We also show how to\nsolve in polynomial time $\\Omega(\\sqrt{n})$-stable instances of MAXCUT,\nsubstantially improving the best previously known result.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 12:30:27 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Bilu", "Yonatan", ""], ["Daniely", "Amit", ""], ["Linial", "Nati", ""], ["Saks", "Michael", ""]]}, {"id": "1205.5282", "submitter": "Anil Ada", "authors": "Anil Ada, Omar Fawzi, Hamed Hatami", "title": "Spectral Norm of Symmetric Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spectral norm of a Boolean function $f:\\{0,1\\}^n \\to \\{-1,1\\}$ is the sum\nof the absolute values of its Fourier coefficients. This quantity provides\nuseful upper and lower bounds on the complexity of a function in areas such as\nlearning theory, circuit complexity, and communication complexity. In this\npaper, we give a combinatorial characterization for the spectral norm of\nsymmetric functions. We show that the logarithm of the spectral norm is of the\nsame order of magnitude as $r(f)\\log(n/r(f))$ where $r(f) = \\max\\{r_0,r_1\\}$,\nand $r_0$ and $r_1$ are the smallest integers less than $n/2$ such that $f(x)$\nor $f(x) \\cdot parity(x)$ is constant for all $x$ with $\\sum x_i \\in [r_0,\nn-r_1]$. We mention some applications to the decision tree and communication\ncomplexity of symmetric functions.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2012 20:12:08 GMT"}], "update_date": "2012-05-25", "authors_parsed": [["Ada", "Anil", ""], ["Fawzi", "Omar", ""], ["Hatami", "Hamed", ""]]}, {"id": "1205.5324", "submitter": "Kenneth Shum", "authors": "Chi Wan Sung, Linyu Huang, Ho Yuet Kwan, Kenneth W. Shum", "title": "Linear Network Code for Erasure Broadcast Channel with Feedback:\n  Complexity and Algorithms", "comments": "18 pages, 11 figures, submitted to IEEE Trans. Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the construction of linear network codes for\nbroadcasting a set of data packets to a number of users. The links from the\nsource to the users are modeled as independent erasure channels. Users are\nallowed to inform the source node whether a packet is received correctly via\nfeedback channels. In order to minimize the number of packet transmissions\nuntil all users have received all packets successfully, it is necessary that a\ndata packet, if successfully received by a user, can increase the dimension of\nthe vector space spanned by the encoding vectors he or she has received by one.\nSuch an encoding vector is called innovative. We prove that innovative linear\nnetwork code is uniformly optimal in minimizing user download delay. When the\nfinite field size is strictly smaller than the number of users, the problem of\ndetermining the existence of innovative vectors is proven to be NP-complete.\nWhen the field size is larger than or equal to the number of users, innovative\nvectors always exist and random linear network code (RLNC) is able to find an\ninnovative vector with high probability. While RLNC is optimal in terms of\ncompletion time, it has high decoding complexity due to the need of solving a\nsystem of linear equations. To reduce decoding time, we propose the use of\nsparse linear network code, since the sparsity property of encoding vectors can\nbe exploited when solving systems of linear equations. Generating a sparsest\nencoding vector with large finite field size, however, is shown to be NP-hard.\nAn approximation algorithm that guarantee the Hamming weight of a generated\nencoding vector to be smaller than a certain factor of the optimal value is\nconstructed. Our simulation results show that our proposed methods have\nexcellent performance in completion time and outperforms RLNC in terms of\ndecoding time.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 03:39:23 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2013 03:21:27 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Sung", "Chi Wan", ""], ["Huang", "Linyu", ""], ["Kwan", "Ho Yuet", ""], ["Shum", "Kenneth W.", ""]]}, {"id": "1205.5395", "submitter": "Abuzer Yakaryilmaz", "authors": "Abuzer Yakaryilmaz", "title": "Turing-equivalent automata using a fixed-size quantum memory", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new public quantum interactive proof system and\nthe first quantum alternating Turing machine: qAM proof system and qATM,\nrespectively. Both are obtained from their classical counterparts\n(Arthur-Merlin proof system and alternating Turing machine, respectively,) by\naugmenting them with a fixed-size quantum register. We focus on space-bounded\ncomputation, and obtain the following surprising results: Both of them with\nconstant-space are Turing-equivalent. More specifically, we show that for any\nTuring-recognizable language, there exists a constant-space weak-qAM system,\n(the nonmembers do not need to be rejected with high probability), and we show\nthat any Turing-recognizable language can be recognized by a constant-space\nqATM even with one-way input head.\n  For strong proof systems, where the nonmembers must be rejected with high\nprobability, we show that the known space-bounded classical private protocols\ncan also be simulated by our public qAM system with the same space bound.\nBesides, we introduce a strong version of qATM: The qATM that must halt in\nevery computation path. Then, we show that strong qATMs (similar to private\nATMs) can simulate deterministic space with exponentially less space. This\nleads to shifting the deterministic space hierarchy exactly by one-level. The\nmethod behind the main results is a new public protocol cleverly using its\nfixed-size quantum register. Interestingly, the quantum part of this public\nprotocol cannot be simulated by any space-bounded classical protocol in some\ncases.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 10:48:02 GMT"}], "update_date": "2012-05-25", "authors_parsed": [["Yakaryilmaz", "Abuzer", ""]]}, {"id": "1205.5653", "submitter": "Manuel Arora", "authors": "Manuel Arora, G\\'abor Ivanyos, Marek Karpinski, Nitin Saxena", "title": "Deterministic Polynomial Factoring and Association Schemes", "comments": null, "journal-ref": "LMS J. Comput. Math. 17 (2014) 123-140", "doi": "10.1112/S1461157013000296", "report-no": null, "categories": "cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding a nontrivial factor of a polynomial f(x) over a finite\nfield F_q has many known efficient, but randomized, algorithms. The\ndeterministic complexity of this problem is a famous open question even\nassuming the generalized Riemann hypothesis (GRH). In this work we improve the\nstate of the art by focusing on prime degree polynomials; let n be the degree.\nIf (n-1) has a `large' r-smooth divisor s, then we find a nontrivial factor of\nf(x) in deterministic poly(n^r,log q) time; assuming GRH and that s >\nsqrt{n/(2^r)}. Thus, for r = O(1) our algorithm is polynomial time. Further,\nfor r > loglog n there are infinitely many prime degrees n for which our\nalgorithm is applicable and better than the best known; assuming GRH.\n  Our methods build on the algebraic-combinatorial framework of m-schemes\ninitiated by Ivanyos, Karpinski and Saxena (ISSAC 2009). We show that the\nm-scheme on n points, implicitly appearing in our factoring algorithm, has an\nexceptional structure; leading us to the improved time complexity. Our\nstructure theorem proves the existence of small intersection numbers in any\nassociation scheme that has many relations, and roughly equal valencies and\nindistinguishing numbers.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2012 10:24:12 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Arora", "Manuel", ""], ["Ivanyos", "G\u00e1bor", ""], ["Karpinski", "Marek", ""], ["Saxena", "Nitin", ""]]}, {"id": "1205.5745", "submitter": "Hubie Chen", "authors": "Simone Bova and Hubie Chen and Matthew Valeriote", "title": "Generic Expression Hardness Results for Primitive Positive Formula\n  Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the expression complexity of two basic problems involving the\ncomparison of primitive positive formulas: equivalence and containment. In\nparticular, we study the complexity of these problems relative to finite\nrelational structures. We present two generic hardness results for the studied\nproblems, and discuss evidence that they are optimal and yield, for each of the\nproblems, a complexity trichotomy.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2012 16:18:29 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Bova", "Simone", ""], ["Chen", "Hubie", ""], ["Valeriote", "Matthew", ""]]}, {"id": "1205.5823", "submitter": "Hector Zenil", "authors": "Roger Penrose", "title": "Foreword: A Computable Universe, Understanding Computation and Exploring\n  Nature As Computation", "comments": "26 pages, foreword to the book A Computable Universe: Understanding\n  Computation and Exploring Nature As Computation, World Scientific, 2012\n  http://www.mathrix.org/experimentalAIT/ComputationNature.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GL cs.AI cs.CC cs.IT math.IT physics.hist-ph physics.pop-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I am most honoured to have the privilege to present the Foreword to this\nfascinating and wonderfully varied collection of contributions, concerning the\nnature of computation and of its deep connection with the operation of those\nbasic laws, known or yet unknown, governing the universe in which we live.\nFundamentally deep questions are indeed being grappled with here, and the fact\nthat we find so many different viewpoints is something to be expected, since,\nin truth, we know little about the foundational nature and origins of these\nbasic laws, despite the immense precision that we so often find revealed in\nthem. Accordingly, it is not surprising that within the viewpoints expressed\nhere is some unabashed speculation, occasionally bordering on just partially\njustified guesswork, while elsewhere we find a good deal of precise reasoning,\nsome in the form of rigorous mathematical theorems. Both of these are as should\nbe, for without some inspired guesswork we cannot have new ideas as to where\nlook in order to make genuinely new progress, and without precise mathematical\nreasoning, no less than in precise observation, we cannot know when we are\nright -- or, more usually, when we are wrong.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2012 21:04:53 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Penrose", "Roger", ""]]}, {"id": "1205.5865", "submitter": "Branden Fitelson", "authors": "Branden Fitelson and Daniel Osherson", "title": "Remarks on \"Random Sequences\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we show that classical statistical tests for randomness are\nlanguage dependent.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2012 09:11:18 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Fitelson", "Branden", ""], ["Osherson", "Daniel", ""]]}, {"id": "1205.5994", "submitter": "Rasoul Ramezanian", "authors": "Rasoul Ramezanian", "title": "Computation Environments, An Interactive Semantics for Turing Machines\n  (which P is not equal to NP considering it)", "comments": "33 pages, interactive computation, P vs NP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To scrutinize notions of computation and time complexity, we introduce and\nformally define an interactive model for computation that we call it the\n\\emph{computation environment}. A computation environment consists of two main\nparts: i) a universal processor and ii) a computist who uses the computability\npower of the universal processor to perform effective procedures. The notion of\ncomputation finds it meaning, for the computist, through his\n\\underline{interaction} with the universal processor.\n  We are interested in those computation environments which can be considered\nas alternative for the real computation environment that the human being is its\ncomputist. These computation environments must have two properties: 1- being\nphysically plausible, and 2- being enough powerful.\n  Based on Copeland' criteria for effective procedures, we define what a\n\\emph{physically plausible} computation environment is.\n  We construct two \\emph{physically plausible} and \\emph{enough powerful}\ncomputation environments: 1- the Turing computation environment, denoted by\n$E_T$, and 2- a persistently evolutionary computation environment, denoted by\n$E_e$, which persistently evolve in the course of executing the computations.\n  We prove that the equality of complexity classes $\\mathrm{P}$ and\n$\\mathrm{NP}$ in the computation environment $E_e$ conflicts with the\n\\underline{free will} of the computist.\n  We provide an axiomatic system $\\mathcal{T}$ for Turing computability and\nprove that ignoring just one of the axiom of $\\mathcal{T}$, it would not be\npossible to derive $\\mathrm{P=NP}$ from the rest of axioms.\n  We prove that the computist who lives inside the environment $E_T$, can never\nbe confident that whether he lives in a static environment or a persistently\nevolutionary one.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2012 19:21:03 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Ramezanian", "Rasoul", ""]]}, {"id": "1205.6218", "submitter": "Cristopher Moore", "authors": "Cristopher Moore and Alexander Russell", "title": "Optimal epsilon-biased sets with just a little randomness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsets of F_2^n that are eps-biased, meaning that the parity of any set of\nbits is even or odd with probability eps close to 1/2, are powerful tools for\nderandomization. A simple randomized construction shows that such sets exist of\nsize O(n/eps^2), and known deterministic constructions achieve sets of size\nO(n/eps^3), O(n^2/eps^2), and O((n/eps^2)^{5/4}). Rather than derandomizing\nthese sets completely in exchange for making them larger, we attempt a partial\nderandomization while keeping them small, constructing sets of size O(n/eps^2)\nwith as few random bits as possible. The naive randomized construction requires\nO(n^2/eps^2) random bits. We give two constructions. The first uses Nisan's\nspace-bounded pseudorandom generator to partly derandomize a folklore\nprobabilistic construction of an error-correcting code, and requires O(n log\n(1/eps)) bits. Our second construction requires O(n log (n/eps)) bits, but is\nmore elementary; it adds randomness to a Legendre symbol construction on Alon,\nGoldreich, H{\\aa}stad, and Peralta, and uses Weil sums to bound high moments of\nthe bias.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2012 21:02:50 GMT"}, {"version": "v2", "created": "Wed, 30 May 2012 01:59:01 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2013 03:10:01 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Moore", "Cristopher", ""], ["Russell", "Alexander", ""]]}, {"id": "1205.6658", "submitter": "Michel Feldmann", "authors": "Michel Feldmann", "title": "Solving satisfiability by Bayesian inference", "comments": "This version V5: Editorial revisions. 11 pages, no figure. (Initial\n  title:From classical versus quantum algorithms to P versus NP). Additional\n  comments on relations with quantum computing in arXiv: 1312.7551", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that any logical problem can be solved by Bayesian inference.\nIn this approach, the distinction between complexity classes vanishes. The\nmethod is illustrated by solving the 3-SAT problem in polynomial time. Beyond\nthis, Bayesian inference could be the background of artificial neural network\ntheory.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 13:06:28 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2012 09:55:58 GMT"}, {"version": "v3", "created": "Thu, 13 Nov 2014 12:47:52 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 09:48:15 GMT"}, {"version": "v5", "created": "Tue, 4 Feb 2020 08:44:03 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Feldmann", "Michel", ""]]}, {"id": "1205.6990", "submitter": "Edinah Gnang k", "authors": "Edinah K. Gnang, Vidit Nanda", "title": "The devil is in Asymmetries (Rough Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formally investigate some computational obstacles to tractability of\ncomputing the variety determined by K complex polynomials in N boolean\nvariables. We show that using algebraic methods for solving combinatorial\nproblems, the obstacles to tractability lies in the order of magnitude of\nasymmetries admitted by the given system of equations.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2012 12:48:09 GMT"}], "update_date": "2012-06-01", "authors_parsed": [["Gnang", "Edinah K.", ""], ["Nanda", "Vidit", ""]]}, {"id": "1205.7041", "submitter": "Stefan Kiefer", "authors": "Stefan Kiefer", "title": "BPA Bisimilarity is EXPTIME-hard", "comments": "technical report for a an article that is to appear in Information\n  Processing Letters. The present version takes into account improvements\n  prompted by the journal's reviewers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a basic process algebra (BPA) and two stack symbols, the BPA\nbisimilarity problem asks whether the two stack symbols are bisimilar. We show\nthat this problem is EXPTIME-hard.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2012 16:43:21 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2012 14:42:40 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Kiefer", "Stefan", ""]]}]