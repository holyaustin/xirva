[{"id": "1902.00196", "submitter": "L\\^e Th\\`anh D\\~ung Nguy\\^en", "authors": "L\\^e Th\\`anh D\\~ung Nguy\\^en", "title": "Around finite second-order coherence spaces", "comments": "The v1 of this is being split into multiple smaller papers. A\n  forthcoming paper with Pistone, Seiller and Tortora de Falco will cover the\n  syntactic aspects not included in the present v3. Changes from v2: add\n  hypercoherences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many applications of denotational semantics, such as higher-order model\nchecking or the complexity of normalization, rely on finite semantics for\nmonomorphic type systems. We exhibit such a finite semantics for a polymorphic\npurely linear language: more precisely, we show that in Girard's semantics of\nsecond-order linear logic using coherence spaces and normal functors, the\ndenotations of multiplicative-additive formulas are finite.\n  This model is also effective, in the sense that the denotations of formulas\nand proofs are computable, as we show. We also establish analogous results for\na second-order extension of Ehrhard's hypercoherences; while finiteness holds\nfor the same reason as in coherence spaces, effectivity presents additional\ndifficulties.\n  Finally, we discuss the applications our our work to implicit computational\ncomplexity in linear (or affine) logic. In view of these applications, we study\ncardinality and complexity bounds in our finite semantics.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 06:18:14 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 15:55:10 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 05:13:20 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Nguy\u00ean", "L\u00ea Th\u00e0nh D\u0169ng", ""]]}, {"id": "1902.00246", "submitter": "Fabian M\\\"uller", "authors": "Anselm Haak, Juha Kontinen, Fabian M\\\"uller, Heribert Vollmer, Fan\n  Yang", "title": "Counting of Teams in First-Order Team Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study descriptive complexity of counting complexity classes in the range\nfrom #P to #$\\cdot$NP. A corollary of Fagin's characterization of NP by\nexistential second-order logic is that #P can be logically described as the\nclass of functions counting satisfying assignments to free relation variables\nin first-order formulae. In this paper we extend this study to classes beyond\n#P and extensions of first-order logic with team semantics. These team-based\nlogics are closely related to existential second-order logic and its fragments,\nhence our results also shed light on the complexity of counting for extensions\nof FO in Tarski's semantics. Our results show that the class #$\\cdot$NP can be\nlogically characterized by independence logic and existential second-order\nlogic, whereas dependence logic and inclusion logic give rise to subclasses of\n#$\\cdot$NP and #P , respectively. Our main technical result shows that the\nproblem of counting satisfying assignments for monotone Boolean\n$\\Sigma_1$-formulae is #$\\cdot$NP-complete as well as complete for the function\nclass generated by dependence logic.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 09:34:22 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 05:53:14 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 06:19:28 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Haak", "Anselm", ""], ["Kontinen", "Juha", ""], ["M\u00fcller", "Fabian", ""], ["Vollmer", "Heribert", ""], ["Yang", "Fan", ""]]}, {"id": "1902.00247", "submitter": "Cong Fang", "authors": "Cong Fang, Zhouchen Lin, Tong Zhang", "title": "Sharp Analysis for Nonconvex SGD Escaping from Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a sharp analysis for Stochastic Gradient Descent (SGD)\nand prove that SGD is able to efficiently escape from saddle points and find an\n$(\\epsilon, O(\\epsilon^{0.5}))$-approximate second-order stationary point in\n$\\tilde{O}(\\epsilon^{-3.5})$ stochastic gradient computations for generic\nnonconvex optimization problems, when the objective function satisfies\ngradient-Lipschitz, Hessian-Lipschitz, and dispersive noise assumptions. This\nresult subverts the classical belief that SGD requires at least\n$O(\\epsilon^{-4})$ stochastic gradient computations for obtaining an\n$(\\epsilon,O(\\epsilon^{0.5}))$-approximate second-order stationary point. Such\nSGD rate matches, up to a polylogarithmic factor of problem-dependent\nparameters, the rate of most accelerated nonconvex stochastic optimization\nalgorithms that adopt additional techniques, such as Nesterov's momentum\nacceleration, negative curvature search, as well as quadratic and cubic\nregularization tricks. Our novel analysis gives new insights into nonconvex SGD\nand can be potentially generalized to a broad class of stochastic optimization\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 09:35:27 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 12:23:24 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Fang", "Cong", ""], ["Lin", "Zhouchen", ""], ["Zhang", "Tong", ""]]}, {"id": "1902.00488", "submitter": "Rahul Jain", "authors": "Rahul Jain and Raghunath Tewari", "title": "Grid Graph Reachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reachability problem is to determine if there exists a path from one\nvertex to another in a graph. Grid graphs are the class of graphs where\nvertices are present on the lattice points of a two-dimensional grid, and an\nedge can occur between a vertex and its immediate horizontal or vertical\nneighbor only. Asano et al. presented the first simultaneous time space bound\nfor reachability in grid graphs by presenting an algorithm that solves the\nproblem in polynomial time and $O(n^{1/2 + \\epsilon})$ space. In 2018, the\nspace bound was improved to $\\tilde{O}(n^{1/3})$ by Ashida and Nakagawa. In\nthis paper, we show that reachability in an $n$ vertex grid graph can be\ndecided by an algorithm using $O(n^{1/4 + \\epsilon})$ space and polynomial time\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 18:22:11 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 09:33:00 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Jain", "Rahul", ""], ["Tewari", "Raghunath", ""]]}, {"id": "1902.00633", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti", "title": "Computational Complexity of Queries Based on Itemsets", "comments": null, "journal-ref": null, "doi": "10.1016/j.ipl.2006.02.003", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate determining the exact bounds of the frequencies of\nconjunctions based on frequent sets. Our scenario is an important special case\nof some general probabilistic logic problems that are known to be intractable.\nWe show that despite the limitations our problems are also intractable, namely,\nwe show that checking whether the maximal consistent frequency of a query is\nlarger than a given threshold is NP-complete and that evaluating the Maximum\nEntropy estimate of a query is PP-hard. We also prove that checking consistency\nis NP-complete.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 03:07:13 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tatti", "Nikolaj", ""]]}, {"id": "1902.00919", "submitter": "Wenxin Li", "authors": "Wenxin Li, Joohyun Lee", "title": "A Faster FPTAS for Knapsack Problem With Cardinality Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the $K$-item knapsack problem (i.e., $1.5$-dimensional KP), which is\na generalization of the famous 0-1 knapsack problem (i.e., $1$-dimensional KP)\nin which an upper bound $K$ is imposed on the number of items selected. This\nproblem is of fundamental importance and is known to have a broad range of\napplications in various fields. It is well known that, there is no FPTAS for\nthe $d$-dimensional knapsack problem when $d\\geq 2$, unless P $=$ NP. While the\n$K$-item knapsack problem is known to admit an FPTAS, the complexity of all\nexisting FPTASs have a high dependency on the cardinality bound $K$ and\napproximation error $\\varepsilon$, which could result in inefficiencies\nespecially when $K$ and $\\varepsilon^{-1}$ increase. The current best results\nare due to Mastrolilli and Hutter (2006), in which two schemes are presented\nexhibiting a space-time tradeoff--one scheme with time complexity\n$O(n+Kz^{2}/\\varepsilon^{2})$ and space complexity $O(n+z^{3}/\\varepsilon)$,\nwhile another scheme requires $O(n+(Kz^{2}+z^{4})/\\varepsilon^{2})$ run-time\nbut only needs $O(n+z^{2}/\\varepsilon)$ space, where\n$z=\\min\\{K,1/\\varepsilon\\}$. In this paper we close the space-time tradeoff\nexhibited in the state-of-the-art by designing a new FPTAS with a run-time of\n$\\widetilde{O}(n+z^{2}/\\varepsilon^{2})$, while simultaneously reaching the\n$O(n+z^{2}/\\varepsilon)$ space bound. Our scheme provides $\\widetilde{O}(K)$\nand $O(z)$ improvements on the state-of-the-art algorithms in time and space\ncomplexity respectively, and is the first scheme that achieves a run-time that\nis independent of cardinality bound $K$ (up to logarithmic factors) under fixed\n$\\varepsilon$. Another salient feature of our scheme is that it is the first\nFPTAS that achieves better time and space complexity bounds than the very first\nstandard FPTAS over all parameter regimes.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 16:29:01 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 04:12:25 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 17:22:13 GMT"}, {"version": "v4", "created": "Thu, 19 Nov 2020 07:27:40 GMT"}, {"version": "v5", "created": "Sat, 12 Dec 2020 12:41:39 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Wenxin", ""], ["Lee", "Joohyun", ""]]}, {"id": "1902.00947", "submitter": "Adrien B. Taylor", "authors": "Adrien Taylor, Francis Bach", "title": "Stochastic first-order methods: non-asymptotic and computer-aided\n  analyses via potential functions", "comments": "Accepted to COLT2019; 12 pages + appendix; code available at\n  https://github.com/AdrienTaylor/Potential-functions-for-first-order-methods.\n  [V5: typos & minor improvements to appendix E.4]", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel computer-assisted technique for systematically analyzing\nfirst-order methods for optimization. In contrast with previous works, the\napproach is particularly suited for handling sublinear convergence rates and\nstochastic oracles. The technique relies on semidefinite programming and\npotential functions. It allows simultaneously obtaining worst-case guarantees\non the behavior of those algorithms, and assisting in choosing appropriate\nparameters for tuning their worst-case performances. The technique also\nbenefits from comfortable tightness guarantees, meaning that unsatisfactory\nresults can be improved only by changing the setting. We use the approach for\nanalyzing deterministic and stochastic first-order methods under different\nassumptions on the nature of the stochastic noise. Among others, we treat\nunstructured noise with bounded variance, different noise models arising in\nover-parametrized expectation minimization problems, and randomized\nblock-coordinate descent schemes.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 18:22:33 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 09:52:08 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 14:26:54 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 18:46:42 GMT"}, {"version": "v5", "created": "Sun, 5 Apr 2020 16:26:14 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Taylor", "Adrien", ""], ["Bach", "Francis", ""]]}, {"id": "1902.00975", "submitter": "Holger Petersen", "authors": "Holger Petersen", "title": "Some Remarks on Real-Time Turing Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of real-time Turing machines using sublinear space is investigated.\nIn contrast to a claim appearing in the literature, such machines can accept\nnon-regular languages, even if working in deterministic mode. While maintaining\na standard binary counter appears to be impossible in real-time, we present a\nguess and check approach that yields a binary representation of the input\nlength. Based on this technique, we show that unary encodings of languages\naccepted in exponential time can be recognized by nondeterministic real-time\nTuring machines.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 22:06:20 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Petersen", "Holger", ""]]}, {"id": "1902.01668", "submitter": "Stefan Jaax", "authors": "Michael Blondin, Javier Esparza, Stefan Jaax", "title": "Expressive Power of Broadcast Consensus Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population protocols are a formal model of computation by identical,\nanonymous mobile agents interacting in pairs. Their computational power is\nrather limited: Angluin et al. have shown that they can only compute the\npredicates over $\\mathbb{N}^k$ expressible in Presburger arithmetic. For this\nreason, several extensions of the model have been proposed, including the\naddition of devices called cover-time services, absence detectors, and clocks.\nAll these extensions increase the expressive power to the class of predicates\nover $\\mathbb{N}^k$ lying in the complexity class NL when the input is given in\nunary. However, these devices are difficult to implement, since they require\nthat an agent atomically receives messages from all other agents in a\npopulation of unknown size; moreover, the agent must know that they have all\nbeen received. Inspired by the work of the verification community on Emerson\nand Namjoshi's broadcast protocols, we show that NL-power is also achieved by\nextending population protocols with reliable broadcasts, a simpler, standard\ncommunication primitive.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 13:12:43 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 22:12:08 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Blondin", "Michael", ""], ["Esparza", "Javier", ""], ["Jaax", "Stefan", ""]]}, {"id": "1902.01765", "submitter": "Alexander A. Sherstov", "authors": "Alexander A. Sherstov", "title": "The Hardest Halfspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation of halfspaces $h:\\{0,1\\}^n\\to\\{0,1\\}$ in the\ninfinity norm by polynomials and rational functions of any given degree. Our\nmain result is an explicit construction of the \"hardest\" halfspace, for which\nwe prove polynomial and rational approximation lower bounds that match the\ntrivial upper bounds achievable for all halfspaces. This completes a lengthy\nline of work started by Myhill and Kautz (1961).\n  As an application, we construct a communication problem that achieves\nessentially the largest possible separation, of $O(n)$ versus $2^{-\\Omega(n)},$\nbetween the sign-rank and discrepancy. Equivalently, our problem exhibits a gap\nof $\\log n$ versus $\\Omega(n)$ between the communication complexity with\nunbounded versus weakly unbounded error, improving quadratically on previous\nconstructions and completing a line of work started by Babai, Frankl, and Simon\n(FOCS 1986). Our results further generalize to the $k$-party\nnumber-on-the-forehead model, where we obtain an explicit separation of $\\log\nn$ versus $\\Omega(n/4^{n})$ for communication with unbounded versus weakly\nunbounded error. This gap is a quadratic improvement on previous work and\nmatches the state of the art for number-on-the-forehead lower bounds.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 16:15:45 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Sherstov", "Alexander A.", ""]]}, {"id": "1902.01960", "submitter": "Daniel Gibney", "authors": "Daniel Gibney, Sharma V. Thankachan", "title": "On the Hardness and Inapproximability of Recognizing Wheeler Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years several compressed indexes based on variants of the\nBurrows-Wheeler transformation have been introduced. Some of these index\nstructures far more complex than a single string, as was originally done with\nthe FM-index [Ferragina and Manzini, J. ACM 2005]. As such, there has been an\neffort to better understand under which conditions such an indexing scheme is\npossible. This led to the introduction of Wheeler graphs [Gagie it et al.,\nTheor. Comput. Sci., 2017]. A Wheeler graph is a directed graph with edge\nlabels which satisfies two simple axioms. Wheeler graphs can be indexed in a\nway which is space efficient and allows for fast traversal. Gagie et al. showed\nthat de Bruijn graphs, generalized compressed suffix arrays, and several other\nBWT related structures can be represented as Wheeler graphs. Here we answer the\nopen question of whether or not there exists an efficient algorithm for\nrecognizing if a graph is a Wheeler graph. We demonstrate:(i) Recognizing if a\ngraph is a Wheeler graph is NP-complete for any edge label alphabet of size\n$\\sigma \\geq 2$, even for DAGs. It can be solved in linear time for $\\sigma\n=1$; (ii) An optimization variant called Wheeler Graph Violation (WGV) which\naims to remove the minimum number of edges needed to obtain a Wheeler graph is\nAPX-hard, even for DAGs. Hence, unless P = NP, there exists constant $C > 1$\nsuch that there is no $C$-approximation algorithm. We show conditioned on the\nUnique Games Conjecture, for every constant $C \\geq 1$, it is NP-hard to find a\n$C$-approximation to WGV; (iii) The Wheeler Subgraph problem (WS) which aims to\nfind the largest Wheeler subgraph is in APX for $\\sigma=O(1)$; (iv) For the\nabove problems there exist efficient exponential time exact algorithms, relying\non graph isomorphism being computed in strictly sub-exponential time; (v) A\nclass of graphs where the recognition problem is polynomial time solvable.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 22:29:03 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 19:39:39 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gibney", "Daniel", ""], ["Thankachan", "Sharma V.", ""]]}, {"id": "1902.02123", "submitter": "Henning Seidler", "authors": "Victor Magron, Henning Seidler, Timo de Wolff", "title": "Exact Optimization via Sums of Nonnegative Circuits and Sums of AM/GM\n  Exponentials", "comments": "19 pages + 4 pages appendix, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide two hybrid numeric-symbolic optimization algorithms, computing\nexact sums of nonnegative circuits (SONC) and sums of\narithmetic-geometric-exponentials (SAGE) decompositions. Moreover, we provide a\nhybrid numeric-symbolic decision algorithm for polynomials lying in the\ninterior of the SAGE cone. Each framework, inspired by previous contributions\nof Parrilo and Peyrl, is a rounding-projection procedure.\n  For a polynomial lying in the interior of the SAGE cone, we prove that the\ndecision algorithm terminates within a number of arithmetic operations, which\nis polynomial in the degree and number of terms of the input, and singly\nexponential in the number of variables. We also provide experimental\ncomparisons regarding the implementation of the two optimization algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 11:39:18 GMT"}], "update_date": "2019-02-10", "authors_parsed": [["Magron", "Victor", ""], ["Seidler", "Henning", ""], ["de Wolff", "Timo", ""]]}, {"id": "1902.02159", "submitter": "Bertrand Jouve", "authors": "Pierre Coupechoux, Marc Demange, David Ellison, Bertrand Jouve", "title": "Firefighting on Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Firefighter problem, introduced by Hartnell in 1995, a fire spreads\nthrough a graph while a player chooses which vertices to protect in order to\ncontain it. In this paper, we focus on the case of trees and we consider as\nwell the Fractional Firefighter game where the amount of protection allocated\nto a vertex lies between 0 and 1. While most of the work in this area deals\nwith a constant amount of firefighters available at each turn, we consider\nthree research questions which arise when including the sequence of\nfirefighters as part of the instance. We first introduce the online version of\nboth Firefighter and Fractional Firefighter, in which the number of\nfirefighters available at each turn is revealed over time. We show that a\ngreedy algorithm on finite trees is 1/2-competitive for both online versions,\nwhich generalises a result previously known for special cases of Firefighter.\nWe also show that the optimal competitive ratio of online Firefighter ranges\nbetween 1/2 and the inverse of the golden ratio. Next, given two firefighter\nsequences, we discuss sufficient conditions for the existence of an infinite\ntree that separates them, in the sense that the fire can be contained with one\nsequence but not with the other. To this aim, we study a new purely numerical\ngame called targeting game. Finally, we give sufficient conditions for the fire\nto be contained, expressed as the asymptotic comparison of the number of\nfirefighters and the size of the tree levels.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 13:24:06 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Coupechoux", "Pierre", ""], ["Demange", "Marc", ""], ["Ellison", "David", ""], ["Jouve", "Bertrand", ""]]}, {"id": "1902.02253", "submitter": "Damien Regnault M.", "authors": "Pierre-Etienne Meunier and Damien Regnault", "title": "Non-cooperatively assembling large structures: a 2D pumping lemma cannot\n  be as powerful as its 1D counterpart", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show the first asymptotically efficient constructions in the so-called\n\"noncooperative planar tile assembly\" model.\n  Algorithmic self-assembly is the study of the local, distributed,\nasynchronous algorithms ran by molecules to self-organise, in particular during\ncrystal growth. The general cooperative model, also called \"temperature 2\",\nuses synchronisation to simulate Turing machines, build shapes using the\nsmallest possible amount of tile types, and other algorithmic tasks. However,\nin the non-cooperative (\"temperature 1\") model, the growth process is entirely\nasynchronous, and mostly relies on geometry. Even though the model looks like a\ngeneralisation of finite automata to two dimensions, its 3D generalisation is\ncapable of performing arbitrary (Turing) computation, and of universal\nsimulations, whereby a single 3D non-cooperative tileset can simulate the\ndynamics of all possible 3D non-cooperative systems, up to a constant scaling\nfactor.\n  However, it was shown that the original 2D non-cooperative model is not\ncapable of universal simulations, and the question of its computational power\nis still widely open. Here, we show an unexpected result, namely that this\nmodel can reliably grow assemblies of size Omega(n log n) with only n tile\ntypes, which is the first asymptotically efficient positive construction.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 16:08:32 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 16:18:15 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Meunier", "Pierre-Etienne", ""], ["Regnault", "Damien", ""]]}, {"id": "1902.02258", "submitter": "Valery Shchesnovich", "authors": "Valery Shchesnovich", "title": "Noise in BosonSampling and the threshold of efficient classical\n  simulatability", "comments": "Revision 6, few minor typos corrected. 15 pages, 1 figure", "journal-ref": "Phys. Rev. A 100, 012340 (2019)", "doi": "10.1103/PhysRevA.100.012340", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantum to classical transition in Boson Sampling by analysing\nhow $N$-boson interference is affected by inevitable noise in an experimental\nsetup. We adopt the Gaussian noise model of Kalai and Kindler for Boson\nSampling and show that it appears from some realistic experimental\nimperfections. We reveal a connection between noise in Boson Sampling and\npartial distinguishability of bosons, which allows us to prove efficient\nclassical simulatability of noisy no-collision Boson Sampling with finite noise\namplitude $\\epsilon$, i.e., $\\epsilon = \\Omega(1)$ as $N\\to \\infty$. On the\nother hand, using an equivalent representation of network noise as losses of\nbosons compensated by random (dark) counts of detectors, it is proven that for\nnoise amplitude inversely proportional to total number of bosons, i.e.,\n$\\epsilon=O(1/N)$, noisy no-collision Boson Sampling is as hard to simulate\nclassically as in the noiseless case. Moreover, the ratio of ``noise clicks\"\n(lost bosons compensated by dark counts) to the total number of bosons $N$\nvanishes as $N\\to \\infty$ for arbitrarily small noise amplitude, i.e.,\n$\\epsilon = o(1)$ as $N\\to \\infty$, hence, we conjecture that such a noisy\nBoson Sampling is also hard to simulate classically. The results significantly\nrelax sufficient condition on noise in a network components, such as two-mode\nbeam splitters, for classical hardness of experimental Boson Sampling.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 16:21:23 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 12:25:50 GMT"}, {"version": "v3", "created": "Sun, 10 Feb 2019 21:25:20 GMT"}, {"version": "v4", "created": "Thu, 21 Mar 2019 18:47:51 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 17:10:11 GMT"}, {"version": "v6", "created": "Mon, 10 Jun 2019 17:19:09 GMT"}, {"version": "v7", "created": "Sat, 20 Jul 2019 09:54:51 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Shchesnovich", "Valery", ""]]}, {"id": "1902.02398", "submitter": "William Kretschmer", "authors": "William Kretschmer", "title": "$\\mathsf{QMA}$ Lower Bounds for Approximate Counting", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a query complexity lower bound for $\\mathsf{QMA}$ protocols that\nsolve approximate counting: estimating the size of a set given a membership\noracle. This gives rise to an oracle $A$ such that $\\mathsf{SBP}^A \\not\\subset\n\\mathsf{QMA}^A$, resolving an open problem of Aaronson [2]. Our proof uses the\npolynomial method to derive a lower bound for the $\\mathsf{SBQP}$ query\ncomplexity of the $\\mathsf{AND}$ of two approximate counting instances. We use\nLaurent polynomials as a tool in our proof, showing that the \"Laurent\npolynomial method\" can be useful even for problems involving ordinary\npolynomials.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 21:02:12 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Kretschmer", "William", ""]]}, {"id": "1902.02428", "submitter": "Chin Ho Lee", "authors": "Chin Ho Lee", "title": "Fourier bounds and pseudorandom generators for product tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Fourier spectrum of functions $f\\colon \\{0,1\\}^{mk} \\to\n\\{-1,0,1\\}$ which can be written as a product of $k$ Boolean functions $f_i$ on\ndisjoint $m$-bit inputs. We prove that for every positive integer $d$, \\[\n  \\sum_{S \\subseteq [mk]: |S|=d} |\\hat{f_S}| = O(m)^d . \\] Our upper bound is\ntight up to a constant factor in the $O(\\cdot)$. Our proof builds on a new\n`level-$d$ inequality' that bounds above $\\sum_{|S|=d} \\hat{f_S}^2$ for any\n$[0,1]$-valued function $f$ in terms of its expectation, which may be of\nindependent interest.\n  As a result, we construct pseudorandom generators for such functions with\nseed length $\\tilde O(m + \\log(k/\\varepsilon))$, which is optimal up to\npolynomial factors in $\\log m$, $\\log\\log k$ and $\\log\\log(1/\\varepsilon)$. Our\ngenerator in particular works for the well-studied class of combinatorial\nrectangles, where in addition we allow the bits to be read in any order. Even\nfor this special case, previous generators have an extra $\\tilde\nO(\\log(1/\\varepsilon))$ factor in their seed lengths.\n  Using Schur-convexity, we also extend our results to functions $f_i$ whose\nrange is $[-1,1]$.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 23:22:55 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Lee", "Chin Ho", ""]]}, {"id": "1902.02967", "submitter": "Pascal Giorgi", "authors": "Pascal Giorgi (ECO), Bruno Grenet (ECO), Daniel Roche", "title": "Generic reductions for in-place polynomial multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polynomial multiplication problem has attracted considerable attention\nsince the early days of computer algebra, and several algorithms have been\ndesigned to achieve the best possible time complexity. More recently, efforts\nhave been made to improve the space complexity, developing modified versions of\na few specific algorithms to use no extra space while keeping the same\nasymptotic running time. In this work, we broaden the scope in two regards.\nFirst, we ask whether an arbitrary multiplication algorithm can be performed\nin-place generically. Second, we consider two important variants which produce\nonly part of the result (and hence have less space to work with), the so-called\nmiddle and short products, and ask whether these operations can also be\nperformed in-place. To answer both questions in (mostly) the affirmative, we\nprovide a series of reductions starting with any linear-space multiplication\nalgorithm. For full and short product algorithms these reductions yield\nin-place versions with the same asymptotic time complexity as the out-of-place\nversion. For the middle product, the reduction incurs an extra logarithmic\nfactor in the time complexity only when the algorithm is quasi-linear.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 08:06:40 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Giorgi", "Pascal", "", "ECO"], ["Grenet", "Bruno", "", "ECO"], ["Roche", "Daniel", ""]]}, {"id": "1902.03164", "submitter": "Colin Lee", "authors": "Colin Do-Yan Lee and John Watrous", "title": "Detecting mixed-unitary quantum channels is NP-hard", "comments": "24 pages", "journal-ref": "Quantum 4, 253 (2020)", "doi": "10.22331/q-2020-04-16-253", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A quantum channel is said to be a mixed-unitary channel if it can be\nexpressed as a convex combination of unitary channels. We prove that, given the\nChoi representation of a quantum channel, it is NP-hard with respect to\npolynomial-time Turing reductions to determine whether or not that channel is a\nmixed-unitary channel. This hardness result holds even under the assumption\nthat the channel is not within an inverse-polynomial distance (in the dimension\nof the space upon which it acts) of the boundary of the mixed-unitary channels.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 16:09:45 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 18:54:02 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 09:35:49 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lee", "Colin Do-Yan", ""], ["Watrous", "John", ""]]}, {"id": "1902.03513", "submitter": "Alessio Benavoli", "authors": "Alessio Benavoli and Alessandro Facchini and Marco Zaffalon", "title": "Computational Complexity and the Nature of Quantum Mechanics (Extended\n  version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum theory (QT) has been confirmed by numerous experiments, yet we still\ncannot fully grasp the meaning of the theory. As a consequence, the quantum\nworld appears to us paradoxical. Here we shed new light on QT by having it\nfollow from two main postulates (i) the theory should be logically consistent;\n(ii) inferences in the theory should be computable in polynomial time. The\nfirst postulate is what we require to each well-founded mathematical theory.\nThe computation postulate defines the physical component of the theory. We show\nthat the computation postulate is the only true divide between QT, seen as a\ngeneralised theory of probability, and classical probability. All quantum\nparadoxes, and entanglement in particular, arise from the clash of trying to\nreconcile a computationally intractable, somewhat idealised, theory (classical\nphysics) with a computationally tractable theory (QT) or, in other words, from\nregarding physics as fundamental rather than computation.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 23:44:18 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Benavoli", "Alessio", ""], ["Facchini", "Alessandro", ""], ["Zaffalon", "Marco", ""]]}, {"id": "1902.03549", "submitter": "Moustapha Diaby", "authors": "Moustapha Diaby, Mark H. Karwan, and Lei Sun", "title": "On modeling hard combinatorial optimization problems as linear programs:\n  Refutations of the \"unconditional impossibility\" claims", "comments": "17 pages; 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a series of developments in the recent literature (by\nessentially a same \"circle\" of authors) with the absolute/unconditioned\n(implicit or explicit) claim that there exists no abstraction of an NP-Complete\ncombinatorial optimization problem in which the defining combinatorial\nconfigurations (such as \"tours\" in the case of the traveling salesman problem\n(TSP) for example) can be modeled by a polynomial-sized system of linear\nconstraints. The purpose of this paper is to provide general as well as\nspecific refutations for these recent claims.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 07:09:22 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Diaby", "Moustapha", ""], ["Karwan", "Mark H.", ""], ["Sun", "Lei", ""]]}, {"id": "1902.03560", "submitter": "Massimo Equi", "authors": "Massimo Equi, Roberto Grossi, Alexandru I. Tomescu, Veli M\\\"akinen", "title": "On the Complexity of Exact Pattern Matching in Graphs: Determinism and\n  Zig-Zag Matching", "comments": "Further developments on our previous work: arXiv:1901.05264", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exact pattern matching in labeled graphs is the problem of searching paths of\na graph $G=(V,E)$ that spell the same string as the given pattern $P[1..m]$.\nThis basic problem can be found at the heart of more complex operations on\nvariation graphs in computational biology, query operations in graph databases,\nand analysis of heterogeneous networks, where the nodes of some paths must\nmatch a sequence of labels or types. In our recent work we described a\nconditional lower bound stating that the exact pattern matching problem in\nlabeled graphs cannot be solved in less than quadratic time, namely, $O(|E|^{1\n- \\epsilon} \\, m)$ time or $O(|E| \\, m^{1 - \\epsilon})$ time for any constant\n$\\epsilon>0$, unless the Strong Exponential Time Hypothesis (SETH) is false.\nThe result holds even if node labels and pattern $P$ are drawn from a binary\nalphabet, and $G$ is restricted to undirected graphs of maximum degree three or\ndirected acyclic graphs of maximum sum of indegree and outdegree three. It was\nleft open what happens on undirected graphs of maximum degree two, i.e., when\nthe pattern can have a zig-zag match in a (cyclic) bidirectional string. Also,\nthe reduction created a non-determistic directed acyclic graph, and it was left\nopen if determinism would make the problem easier. In this work, we show\nthrough the Orthogonal Vectors hypothesis (OV) that the same conditional lower\nbound holds even for these restricted cases.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 09:43:38 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Equi", "Massimo", ""], ["Grossi", "Roberto", ""], ["Tomescu", "Alexandru I.", ""], ["M\u00e4kinen", "Veli", ""]]}, {"id": "1902.03660", "submitter": "Robin Kothari", "authors": "Shalev Ben-David and Robin Kothari", "title": "Quantum distinguishing complexity, zero-error algorithms, and\n  statistical zero knowledge", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new query measure we call quantum distinguishing complexity,\ndenoted QD(f) for a Boolean function f. Unlike a quantum query algorithm, which\nmust output a state close to |0> on a 0-input and a state close to |1> on a\n1-input, a \"quantum distinguishing algorithm\" can output any state, as long as\nthe output states for any 0-input and 1-input are distinguishable.\n  Using this measure, we establish a new relationship in query complexity: For\nall total functions f, Q_0(f)=O~(Q(f)^5), where Q_0(f) and Q(f) denote the\nzero-error and bounded-error quantum query complexity of f respectively,\nimproving on the previously known sixth power relationship.\n  We also define a query measure based on quantum statistical zero-knowledge\nproofs, QSZK(f), which is at most Q(f). We show that QD(f) in fact lower bounds\nQSZK(f) and not just Q(f). QD(f) also upper bounds the (positive-weights)\nadversary bound, which yields the following relationships for all f: Q(f) >=\nQSZK(f) >= QS(f) = Omega(Adv(f)). This sheds some light on why the adversary\nbound proves suboptimal bounds for problems like Collision and Set Equality,\nwhich have low QSZK complexity.\n  Lastly, we show implications for lifting theorems in communication\ncomplexity. We show that a general lifting theorem for either zero-error\nquantum query complexity or for QSZK would imply a general lifting theorem for\nbounded-error quantum query complexity.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 19:48:27 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Ben-David", "Shalev", ""], ["Kothari", "Robin", ""]]}, {"id": "1902.03702", "submitter": "Bingkai Lin", "authors": "Bingkai Lin", "title": "A Simple Gap-producing Reduction for the Parameterized Set Cover Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an $n$-vertex bipartite graph $I=(S,U,E)$, the goal of set cover\nproblem is to find a minimum sized subset of $S$ such that every vertex in $U$\nis adjacent to some vertex of this subset. It is NP-hard to approximate set\ncover to within a $(1-o(1))\\ln n$ factor. If we use the size of the optimum\nsolution $k$ as the parameter, then it can be solved in $n^{k+o(1)}$ time. A\nnatural question is: can we approximate set cover to within an $o(\\ln n)$\nfactor in $n^{k-\\epsilon}$ time?\n  In a recent breakthrough result, Karthik, Laekhanukit and Manurangsi showed\nthat assuming the Strong Exponential Time Hypothesis (SETH), for any computable\nfunction $f$, no $f(k)\\cdot n^{k-\\epsilon}$-time algorithm can approximate set\ncover to a factor below $(\\log n)^{\\frac{1}{poly(k,e(\\epsilon))}}$ for some\nfunction $e$.\n  This paper presents a simple gap-producing reduction which, given a set cover\ninstance $I=(S,U,E)$ and two integers $k<h\\le (1-o(1))\\sqrt[k]{\\log\n|S|/\\log\\log |S|}$, outputs a new set cover instance $I'=(S,U',E')$ with\n$|U'|=|U|^{h^k}|S|^{O(1)}$ in $|U|^{h^k}\\cdot |S|^{O(1)}$ time such that:\n  (1) if $I$ has a $k$-sized solution, then so does $I'$;\n  (2) if $I$ has no $k$-sized solution, then every solution of $I'$ must\ncontain at least $h$ vertices.\n  Setting $h=(1-o(1))\\sqrt[k]{\\log |S|/\\log\\log |S|}$, we show that assuming\nSETH, for any computable function $f$, no $f(k)\\cdot n^{k-\\epsilon}$-time\nalgorithm can distinguish between a set cover instance with $k$-sized solution\nand one whose minimum solution size is at least $(1-o(1))\\cdot\n\\sqrt[k]{\\frac{\\log n}{\\log\\log n}}$. This improves the result of Karthik,\nLaekhanukit and Manurangsi.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 01:50:23 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 07:52:39 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Lin", "Bingkai", ""]]}, {"id": "1902.03852", "submitter": "Jean-Camille Birget", "authors": "J.C. Birget", "title": "The word problem of the Brin-Thompson group is coNP-complete", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the word problem of the Brin-Thompson group nV over a finite\ngenerating set is coNP-complete for every n \\ge 2. It is known that the groups\nnV are an infinite family of infinite, finitely presented, simple groups. We\nalso prove that the word problem of the Thompson group V over a certain\ninfinite set of generators, related to boolean circuits, is coNP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 13:05:10 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:44:24 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Birget", "J. C.", ""]]}, {"id": "1902.03879", "submitter": "Antonio E. Porreca", "authors": "Alberto Leporati, Luca Manzoni, Giancarlo Mauri, Antonio E. Porreca,\n  Claudio Zandron", "title": "Solving QSAT in sublinear depth", "comments": "19th International Conference on Membrane Computing (CMC19)", "journal-ref": "Lecture Notes in Computer Science 11399 (2019) 188-201", "doi": "10.1007/978-3-030-12797-8_13", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among $\\mathbf{PSPACE}$-complete problems, QSAT, or quantified SAT, is one of\nthe most used to show that the class of problems solvable in polynomial time by\nfamilies of a given variant of P systems includes the whole $\\mathbf{PSPACE}$.\nHowever, most solutions require a membrane nesting depth that is linear with\nrespect to the number of variables of the QSAT instance under consideration.\nWhile a system of a certain depth is needed, since depth 1 systems only allows\nto solve problems in $\\mathbf{P^{\\#P}}$, it was until now unclear if a linear\ndepth was, in fact, necessary. Here we use P systems with active membranes with\ncharges, and we provide a construction that proves that QSAT can be solved with\na sublinear nesting depth of order $\\frac{n}{\\log n}$, where $n$ is the number\nof variables in the quantified formula given as input.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 13:59:08 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 09:07:08 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Leporati", "Alberto", ""], ["Manzoni", "Luca", ""], ["Mauri", "Giancarlo", ""], ["Porreca", "Antonio E.", ""], ["Zandron", "Claudio", ""]]}, {"id": "1902.03883", "submitter": "Antonio E. Porreca", "authors": "Alberto Leporati, Luca Manzoni, Giancarlo Mauri, Antonio E. Porreca,\n  Claudio Zandron", "title": "A Turing machine simulation by P systems without charges", "comments": "Asian Branch of International Conference on Membrane Computing (ACMC\n  2018). arXiv admin note: text overlap with arXiv:1902.03879", "journal-ref": "Journal of Membrane Computing 2, 71-79 (2020)", "doi": "10.1007/s41965-020-00031-5", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the kind of P systems involved in the definition of the\nP conjecture is able to solve problems in the complexity class $\\mathbf{P}$ by\nleveraging the uniformity condition. Here we show that these systems are indeed\nable to simulate deterministic Turing machines working in polynomial time with\na weaker uniformity condition and using only one level of membrane nesting.\nThis allows us to embed this construction into more complex membrane\nstructures, possibly showing that constructions similar to the one performed in\n[1] for P systems with charges can be carried out also in this case.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 14:07:29 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Leporati", "Alberto", ""], ["Manzoni", "Luca", ""], ["Mauri", "Giancarlo", ""], ["Porreca", "Antonio E.", ""], ["Zandron", "Claudio", ""]]}, {"id": "1902.03950", "submitter": "Guillaume O. Berger", "authors": "Guillaume O. Berger, P.-A. Absil, Lieven De Lathauwer, Rapha\\\"el M.\n  Jungers and Marc Van Barel", "title": "Equivalent Polyadic Decompositions of Matrix Multiplication Tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariance transformations of polyadic decompositions of matrix\nmultiplication tensors define an equivalence relation on the set of such\ndecompositions. In this paper, we present an algorithm to efficiently decide\nwhether two polyadic decompositions of a given matrix multiplication tensor are\nequivalent. With this algorithm, we analyze the equivalence classes of\ndecompositions of several matrix multiplication tensors. This analysis is\nrelevant for the study of fast matrix multiplication as it relates to the\nquestion of how many essentially different fast matrix multiplication\nalgorithms there exist. This question has been first studied by de~Groote, who\nshowed that for the multiplication of $2\\times2$ matrices with $7$ active\nmultiplications, all algorithms are essentially equivalent to Strassen's\nalgorithm. In contrast, the results of our analysis show that for the\nmultiplication of larger matrices, (e.g., $2\\times3$ by $3\\times2$ or\n$3\\times3$ by $3\\times3$ matrices), two decompositions are very likely to be\nessentially different. We further provide a necessary criterion for a polyadic\ndecomposition to be equivalent to a polyadic decomposition with integer\nentries. Decompositions with specific integer entries, e.g., powers of two,\nprovide fast matrix multiplication algorithms with better efficiency and\nstability properties. This condition can be tested algorithmically and we\npresent the conclusions obtained for the decompositions of small/medium matrix\nmultiplication tensors.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 15:47:37 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Berger", "Guillaume O.", ""], ["Absil", "P. -A.", ""], ["De Lathauwer", "Lieven", ""], ["Jungers", "Rapha\u00ebl M.", ""], ["Van Barel", "Marc", ""]]}, {"id": "1902.04569", "submitter": "Alessio Benavoli", "authors": "Alessio Benavoli and Alessandro Facchini and Marco Zaffalon", "title": "Computational Complexity and the Nature of Quantum Mechanics", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.03513", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum theory (QT) has been confirmed by numerous experiments, yet we still\ncannot fully grasp the meaning of the theory. As a consequence, the quantum\nworld appears to us paradoxical. Here we shed new light on QT by being based on\ntwo main postulates: 1. the theory should be logically consistent; 2.\ninferences in the theory should be computable in polynomial time. The first\npostulate is what we require to each well-founded mathematical theory. The\ncomputation postulate defines the physical component of the theory. We show\nthat the computation postulate is the only true divide between QT, seen as a\ngeneralised theory of probability, and classical probability. All quantum\nparadoxes, and entanglement in particular, arise from the clash of trying to\nreconcile a computationally intractable, somewhat idealised, theory (classical\nphysics) with a computationally tractable theory (QT) or, in other words, from\nregarding physics as fundamental rather than computation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 09:38:45 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 10:20:44 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Benavoli", "Alessio", ""], ["Facchini", "Alessandro", ""], ["Zaffalon", "Marco", ""]]}, {"id": "1902.04703", "submitter": "Thomas Gabor", "authors": "Thomas Gabor, Sebastian Zielinski, Sebastian Feld, Christoph Roch,\n  Christian Seidel, Florian Neukart, Isabella Galter, Wolfgang Mauerer, Claudia\n  Linnhoff-Popien", "title": "Assessing Solution Quality of 3SAT on a Quantum Annealing Platform", "comments": "13 pages, published at QTOP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When solving propositional logic satisfiability (specifically 3SAT) using\nquantum annealing, we analyze the effect the difficulty of different instances\nof the problem has on the quality of the answer returned by the quantum\nannealer. A high-quality response from the annealer in this case is defined by\na high percentage of correct solutions among the returned answers. We show that\nthe phase transition regarding the computational complexity of the problem,\nwhich is well-known to occur for 3SAT on classical machines (where it causes a\ndetrimental increase in runtime), persists in some form (but possibly to a\nlesser extent) for quantum annealing.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 02:09:07 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Gabor", "Thomas", ""], ["Zielinski", "Sebastian", ""], ["Feld", "Sebastian", ""], ["Roch", "Christoph", ""], ["Seidel", "Christian", ""], ["Neukart", "Florian", ""], ["Galter", "Isabella", ""], ["Mauerer", "Wolfgang", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1902.04740", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek, Sivakanth Gopi and Venkatesan Guruswami", "title": "CSPs with Global Modular Constraints: Algorithms and Hardness via\n  Polynomial Representations", "comments": "52 pages; to appear in STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of Boolean constraint satisfaction problems (CSPs)\nwhen the assignment must have Hamming weight in some congruence class modulo M,\nfor various choices of the modulus M. Due to the known classification of\ntractable Boolean CSPs, this mainly reduces to the study of three cases: 2-SAT,\nHORN-SAT, and LIN-2 (linear equations mod 2). We classify the moduli M for\nwhich these respective problems are polynomial time solvable, and when they are\nnot (assuming the ETH). Our study reveals that this modular constraint lends a\nsurprising richness to these classic, well-studied problems, with interesting\nbroader connections to complexity theory and coding theory. The HORN-SAT case\nis connected to the covering complexity of polynomials representing the NAND\nfunction mod M. The LIN-2 case is tied to the sparsity of polynomials\nrepresenting the OR function mod M, which in turn has connections to modular\nweight distribution properties of linear codes and locally decodable codes. In\nboth cases, the analysis of our algorithm as well as the hardness reduction\nrely on these polynomial representations, highlighting an interesting algebraic\ncommon ground between hard cases for our algorithms and the gadgets which show\nhardness. These new complexity measures of polynomial representations merit\nfurther study.\n  The inspiration for our study comes from a recent work by N\\\"agele, Sudakov,\nand Zenklusen on submodular minimization with a global congruence constraint.\nOur algorithm for HORN-SAT has strong similarities to their algorithm, and in\nparticular identical kind of set systems arise in both cases. Our connection to\npolynomial representations leads to a simpler analysis of such set systems, and\nalso sheds light on (but does not resolve) the complexity of submodular\nminimization with a congruency requirement modulo a composite M.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 04:49:40 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Gopi", "Sivakanth", ""], ["Guruswami", "Venkatesan", ""]]}, {"id": "1902.04764", "submitter": "Cupjin Huang", "authors": "Cupjin Huang, Michael Newman and Mario Szegedy", "title": "Explicit lower bounds on strong simulation of quantum circuits in terms\n  of $T$-gate count", "comments": "Combined with arxiv:1804.10368 and submitted for publication. Similar\n  results have been obtained recently in arxiv:1901.01637 independently", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate Clifford+$T$ quantum circuits with a small number of\n$T$-gates. Using the sparsification lemma, we identify time complexity lower\nbounds in terms of $T$-gate count below which a strong simulator would improve\non the state-of-the-art $3$-SAT solving.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 06:27:04 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 05:45:39 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Huang", "Cupjin", ""], ["Newman", "Michael", ""], ["Szegedy", "Mario", ""]]}, {"id": "1902.04828", "submitter": "Dimitri Lajou", "authors": "Dimitri Lajou (LaBRI, UB)", "title": "On the achromatic number of signed graphs", "comments": null, "journal-ref": "Theoretical Computer Science, Elsevier, 2019", "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we generalize the concept of complete coloring and achromatic\nnumber to 2-edge-colored graphs and signed graphs. We give some useful\nrelationships between different possible definitions of such achromatic numbers\nand prove that computing any of them is NP-complete.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 10:03:26 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Lajou", "Dimitri", "", "LaBRI, UB"]]}, {"id": "1902.04919", "submitter": "Ioannis Katsikarelis", "authors": "R\\'emy Belmonte, Tesshu Hanaka, Ioannis Katsikarelis, Eun Jung Kim,\n  Michael Lampis", "title": "New Results on Directed Edge Dominating Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a family of generalizations of Edge Dominating Set on directed\ngraphs called Directed $(p,q)$-Edge Dominating Set. In this problem an arc\n$(u,v)$ is said to dominate itself, as well as all arcs which are at distance\nat most $q$ from $v$, or at distance at most $p$ to $u$.\n  First, we give significantly improved FPT algorithms for the two most\nimportant cases of the problem, $(0,1)$-dEDS and $(1,1)$-dEDS (that correspond\nto versions of Dominating Set on line graphs), as well as polynomial kernels.\nWe also improve the best-known approximation for these cases from logarithmic\nto constant. In addition, we show that $(p,q)$-dEDS is FPT parameterized by\n$p+q+tw$, but W-hard parameterized by $tw$ (even if the size of the optimal is\nadded as a second parameter), where $tw$ is the treewidth of the underlying\ngraph of the input.\n  We then go on to focus on the complexity of the problem on tournaments. Here,\nwe provide a complete classification for every possible fixed value of $p,q$,\nwhich shows that the problem exhibits a surprising behavior, including cases\nwhich are in P; cases which are solvable in quasi-polynomial time but not in P;\nand a single case $(p=q=1)$ which is NP-hard (under randomized reductions) and\ncannot be solved in sub-exponential time, under standard assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 14:30:41 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 16:44:45 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Belmonte", "R\u00e9my", ""], ["Hanaka", "Tesshu", ""], ["Katsikarelis", "Ioannis", ""], ["Kim", "Eun Jung", ""], ["Lampis", "Michael", ""]]}, {"id": "1902.04960", "submitter": "Marc Roth", "authors": "Holger Dell, Marc Roth, Philip Wellnitz", "title": "Counting Answers to Existential Questions", "comments": "49 pages, 5 figures, corrected typos, revised argument in Section\n  5.4, ICALP B 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conjunctive queries select and are expected to return certain tuples from a\nrelational database. We study the potentially easier problem of counting all\nselected tuples, rather than enumerating them. In particular, we are interested\nin the problem's parameterized and data complexity, where the query is\nconsidered to be small or fixed, and the database is considered to be large. We\nidentify two structural parameters for conjunctive queries that capture their\ninherent complexity: The dominating star size and the linked matching number.\nIf the dominating star size of a conjunctive query is large, then we show that\ncounting solution tuples to the query is at least as hard as counting\ndominating sets, which yields a fine-grained complexity lower bound under the\nStrong Exponential Time Hypothesis as well as a #W[2]-hardness result.\nMoreover, if the linked matching number of a conjunctive query is large, then\nwe show that the structure of the query is so rich that arbitrary queries up to\na certain size can be encoded into it; this essentially establishes\n#A[2]-completeness. Using ideas stemming from Lov\\'asz, we lift complexity\nresults from the class of conjunctive queries to arbitrary existential or\nuniversal formulas that might contain inequalities and negations on constraints\nover the free variables. As a consequence, we obtain a complexity\nclassification that generalizes previous results of Chen, Durand, and Mengel\n(ToCS 2015; ICDT 2015; PODS 2016) for conjunctive queries and of Curticapean\nand Marx (FOCS 2014) for the subgraph counting problem. Our proof also relies\non graph minors, and we show a strengthening of the Excluded-Grid-Theorem which\nmight be of independent interest: If the linked matching number is large, then\nnot only can we find a large grid somewhere in the graph, but we can find a\nlarge grid whose diagonal has disjoint paths leading into an assumed\nnode-well-linked set.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 15:47:33 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 10:16:52 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Dell", "Holger", ""], ["Roth", "Marc", ""], ["Wellnitz", "Philip", ""]]}, {"id": "1902.05070", "submitter": "Mee Seong Im", "authors": "Mee Seong Im, Venkat R. Dasari, Lubjana Beshaj, Dale Shires", "title": "Optimization problems with low SWaP tactical Computing", "comments": "8 pages, 1 figure. To appear in Proc. SPIE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.CL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a resource-constrained, contested environment, computing resources need to\nbe aware of possible size, weight, and power (SWaP) restrictions. SWaP-aware\ncomputational efficiency depends upon optimization of computational resources\nand intelligent time versus efficiency tradeoffs in decision making. In this\npaper we address the complexity of various optimization strategies related to\nlow SWaP computing. Due to these restrictions, only a small subset of less\ncomplicated and fast computable algorithms can be used for tactical, adaptive\ncomputing.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 11:17:43 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Im", "Mee Seong", ""], ["Dasari", "Venkat R.", ""], ["Beshaj", "Lubjana", ""], ["Shires", "Dale", ""]]}, {"id": "1902.05101", "submitter": "Sami Davies", "authors": "Sami Davies, Miklos Z. Racz, Cyrus Rashtchian", "title": "Reconstructing Trees from Traces", "comments": "Major revisions in the new version including algorithm descriptions,\n  more details in section 3.1, and several new figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a node-labeled tree given independent traces\nfrom an appropriately defined deletion channel. This problem, tree trace\nreconstruction, generalizes string trace reconstruction, which corresponds to\nthe tree being a path. For many classes of trees, including complete trees and\nspiders, we provide algorithms that reconstruct the labels using only a\npolynomial number of traces. This exhibits a stark contrast to known results on\nstring trace reconstruction, which require exponentially many traces, and where\na central open problem is to determine whether a polynomial number of traces\nsuffice. Our techniques combine novel combinatorial and complex analytic\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 19:59:36 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 22:38:46 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 23:16:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Davies", "Sami", ""], ["Racz", "Miklos Z.", ""], ["Rashtchian", "Cyrus", ""]]}, {"id": "1902.05479", "submitter": "Fernando Soler-Toscano", "authors": "Fernando Soler-Toscano", "title": "Which is the least complex explanation? Abduction and complexity", "comments": null, "journal-ref": "Published in M.A. Freund, M. Fernandez de Castro and M. Ruffino\n  (eds.), Logic and Philosophy of Logic. Recent Trends in Latin America and\n  Spain. College Publicacions. Studies in Logic, Vol. 78, 2018, pp. 100-116", "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It may happen that for a certain abductive problem there are several possible\nexplanations, not all of them mutually compatible. What explanation is selected\nand which criteria are used to select it? This is the well-known problem of the\nselection of abductive hypotheses. Are there criteria that can help us to\nselect the simplest explanation in a broad spectrum of abductive problems? To\ngive an (affirmative) answer to this question we will move to a field in\ntheoretical computer science: Algorithmic Information Theory (AIT). The\nalgorithmic complexity measure K(s) can be used to determine which is the best\ntheory within those explaining a set of observations. We introduce an\napplication of K(s) to the selection of the best abductive explanation, in the\ncontext of dynamic epistemic logic (DEL).\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 16:22:16 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Soler-Toscano", "Fernando", ""]]}, {"id": "1902.05487", "submitter": "Augusto Modanese", "authors": "Augusto Modanese", "title": "Complexity-Theoretic Aspects of Expanding Cellular Automata", "comments": "19 pages, 3 figures", "journal-ref": "Nat Comput (2020)", "doi": "10.1007/s11047-020-09814-2", "report-no": null, "categories": "cs.CC cs.FL math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expanding cellular automata (XCA) variant of cellular automata is\ninvestigated and characterized from a complexity-theoretical standpoint. An XCA\nis a one-dimensional cellular automaton which can dynamically create new cells\nbetween existing ones. The respective polynomial-time complexity class is shown\nto coincide with ${\\le_{tt}^p}(\\mathsf{NP})$, that is, the class of decision\nproblems polynomial-time truth-table reducible to problems in $\\mathsf{NP}$. An\nalternative characterization based on a variant of non-deterministic Turing\nmachines is also given. In addition, corollaries on select XCA variants are\nproven: XCAs with multiple accept and reject states are shown to be\npolynomial-time equivalent to the original XCA model. Finally, XCAs with\nalternative acceptance conditions are considered and classified in terms of\n${\\le_{tt}^p}(\\mathsf{NP})$ and the Turing machine polynomial-time class\n$\\mathsf{P}$.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 16:43:48 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 08:13:23 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 13:42:33 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Modanese", "Augusto", ""]]}, {"id": "1902.05529", "submitter": "Antonis Antonopoulos", "authors": "Elli Anastasiadi, Antonis Antonopoulos, Aris Pagourtzis, Stavros\n  Petsalakis", "title": "Parameterized Fine-Grained Reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During recent years the field of fine-grained complexity has bloomed to\nproduce a plethora of results, with both applied and theoretical impact on the\ncomputer science community. The cornerstone of the framework is the notion of\nfine-grained reductions, which correlate the exact complexities of problems\nsuch that improvements in their running times or hardness results are carried\nover. We provide a parameterized viewpoint of these reductions (PFGR) in order\nto further analyze the structure of improvable problems and set the foundations\nof a unified methodology for extending algorithmic results. In this context, we\ndefine a class of problems (FPI) that admit fixed-parameter improvements on\ntheir running time. As an application of this framework we present a truly\nsub-quadratic fixed-parameter algorithm for the orthogonal vectors problem.\nFinally, we provide a circuit characterization for FPI to further solidify the\nnotion of improvement.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 18:10:23 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Anastasiadi", "Elli", ""], ["Antonopoulos", "Antonis", ""], ["Pagourtzis", "Aris", ""], ["Petsalakis", "Stavros", ""]]}, {"id": "1902.05876", "submitter": "Shay Moran", "authors": "Olivier Bousquet and Daniel Kane and Shay Moran", "title": "The Optimal Approximation Factor in Density Estimation", "comments": "fixed a coupkle of typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following problem: given two arbitrary densities $q_1,q_2$ and a\nsample-access to an unknown target density $p$, find which of the $q_i$'s is\ncloser to $p$ in total variation.\n  A remarkable result due to Yatracos shows that this problem is tractable in\nthe following sense: there exists an algorithm that uses $O(\\epsilon^{-2})$\nsamples from $p$ and outputs~$q_i$ such that with high probability, $TV(q_i,p)\n\\leq 3\\cdot\\mathsf{opt} + \\epsilon$, where $\\mathsf{opt}=\n\\min\\{TV(q_1,p),TV(q_2,p)\\}$. Moreover, this result extends to any finite class\nof densities $\\mathcal{Q}$: there exists an algorithm that outputs the best\ndensity in $\\mathcal{Q}$ up to a multiplicative approximation factor of 3.\n  We complement and extend this result by showing that: (i) the factor 3 can\nnot be improved if one restricts the algorithm to output a density from\n$\\mathcal{Q}$, and (ii) if one allows the algorithm to output arbitrary\ndensities (e.g.\\ a mixture of densities from $\\mathcal{Q}$), then the\napproximation factor can be reduced to 2, which is optimal. In particular this\ndemonstrates an advantage of improper learning over proper in this setup.\n  We develop two approaches to achieve the optimal approximation factor of 2:\nan adaptive one and a static one. Both approaches are based on a geometric\npoint of view of the problem and rely on estimating surrogate metrics to the\ntotal variation. Our sample complexity bounds exploit techniques from {\\it\nAdaptive Data Analysis}.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 23:15:26 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 05:06:29 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 01:05:53 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Bousquet", "Olivier", ""], ["Kane", "Daniel", ""], ["Moran", "Shay", ""]]}, {"id": "1902.06123", "submitter": "Nicola Gigante", "authors": "Nicola Gigante", "title": "Timeline-based planning: Expressiveness and Complexity", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Timeline-based planning is an approach originally developed in the context of\nspace mission planning and scheduling, where problem domains are modelled as\nsystems made of a number of independent but interacting components, whose\nbehaviour over time, the timelines, is governed by a set of temporal\nconstraints. This approach is different from the action-based perspective of\ncommon PDDL-like planning languages. Timeline-based systems have been\nsuccessfully deployed in a number of space missions and other domains. However,\ndespite this practical success, a thorough theoretical understanding of the\nparadigm was missing.\n  This thesis fills this gap, providing the first detailed account of formal\nand computational properties of the timeline-based approach to planning. In\nparticular, we show that a particularly restricted variant of the formalism is\nalready expressive enough to compactly capture action-based temporal planning\nproblems. Then, finding a solution plan for a timeline-based planning problem\nis proved to be EXPSPACE-complete.\n  Then, we study the problem of timeline-based planning with uncertainty, that\ninclude external components whose behaviour is not under the control of the\nplanned system. We identify a few issues in the state-of-the-art approach based\non flexible plans, proposing timeline-based games, a more general\ngame-theoretic formulation of the problem, that addresses those issues. We show\nthat winning strategies for such games can be found in doubly-exponential time.\n  Then, we study the expressiveness of the formalism from a logic point of\nview, showing that (most of) timeline-based planning problems can be captured\nby Bounded TPTL with Past, a fragment of TPTL+P that, unlike the latter, keeps\nan EXPSPACE satisfiability problem. The logic is introduced and its\nsatisfiabilty problem is solved by extending a recent one-pass tree-shaped\ntableau method for LTL.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 16:45:03 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 12:20:23 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Gigante", "Nicola", ""]]}, {"id": "1902.06196", "submitter": "Thijs Laarhoven", "authors": "Thijs Laarhoven", "title": "Nearest neighbor decoding for Tardos fingerprinting codes", "comments": "6 pages, 1 figure, 2 tables", "journal-ref": "ACM Workshop on Information Hiding and Multimedia Security\n  (IH&MMSec), pp. 182-187, 2019", "doi": "10.1145/3335203.3335732", "report-no": null, "categories": "cs.CR cs.CC cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, various improvements have been made to Tardos'\ncollusion-resistant fingerprinting scheme [Tardos, STOC 2003], ultimately\nresulting in a good understanding of what is the minimum code length required\nto achieve collusion-resistance. In contrast, decreasing the cost of the actual\ndecoding algorithm for identifying the potential colluders has received less\nattention, even though previous results have shown that using joint decoding\nstrategies, deemed too expensive for decoding, may lead to better code lengths.\nMoreover, in dynamic settings a fast decoder may be required to provide answers\nin real-time, further raising the question whether the decoding costs of\nscore-based fingerprinting schemes can be decreased with a smarter decoding\nalgorithm. In this paper we show how to model the decoding step of score-based\nfingerprinting as a nearest neighbor search problem, and how this relation\nallows us to apply techniques from the field of (approximate) nearest neighbor\nsearching to obtain decoding times which are sublinear in the total number of\nusers. As this does not affect the encoding and embedding steps, this decoding\nmechanism can easily be deployed within existing fingerprinting schemes, and\nthis may bring a truly efficient joint decoder closer to reality. Besides the\napplication to fingerprinting, similar techniques can be used to decrease the\ndecoding costs of group testing methods, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 03:35:23 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Laarhoven", "Thijs", ""]]}, {"id": "1902.06380", "submitter": "Gregory Rosenthal", "authors": "Gregory Rosenthal", "title": "Beating Treewidth for Average-Case Subgraph Isomorphism", "comments": "31 pages. International Symposium on Parameterized and Exact\n  Computation (IPEC) 2019", "journal-ref": null, "doi": "10.4230/LIPIcs.IPEC.2019.24", "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any fixed graph $G$, the subgraph isomorphism problem asks whether an\n$n$-vertex input graph has a subgraph isomorphic to $G$. A well-known algorithm\nof Alon, Yuster and Zwick (1995) efficiently reduces this to the \"colored\"\nversion of the problem, denoted $G$-$\\mathsf{SUB}$, and then solves\n$G$-$\\mathsf{SUB}$ in time $O(n^{tw(G)+1})$ where $tw(G)$ is the treewidth of\n$G$. Marx (2010) conjectured that $G$-$\\mathsf{SUB}$ requires time\n$\\Omega(n^{\\mathrm{const}\\cdot tw(G)})$ and, assuming the Exponential Time\nHypothesis, proved a lower bound of $\\Omega(n^{\\mathrm{const}\\cdot emb(G)})$\nfor a certain graph parameter $emb(G) \\ge \\Omega(tw(G)/\\log tw(G))$. With\nrespect to the size of $\\mathrm{AC}^0$ circuits solving $G$-$\\mathsf{SUB}$ in\nthe average case, Li, Razborov and Rossman (2017) proved (unconditional) upper\nand lower bounds of $O(n^{2\\kappa(G)+\\mathrm{const}})$ and\n$\\Omega(n^{\\kappa(G)})$ for a different graph parameter $\\kappa(G) \\ge\n\\Omega(tw(G)/\\log tw(G))$.\n  Our contributions are as follows. First, we prove that $emb(G)$ is\n$O(\\kappa(G))$ for all graphs $G$. Next, we show that $\\kappa(G)$ can be\nasymptotically less than $tw(G)$; for example, if $G$ is a hypercube then\n$\\kappa(G)$ is $\\Theta\\big(tw(G)\\big/\\sqrt{\\log tw(G)}\\big)$. This implies that\nthe average-case complexity of $G$-$\\mathsf{SUB}$ is $n^{o(tw(G))}$ when $G$ is\na hypercube. Finally, we construct $\\mathrm{AC}^0$ circuits of size\n$O(n^{\\kappa(G)+\\mathrm{const}})$ that solve $G$-$\\mathsf{SUB}$ in the average\ncase, closing the gap between the upper and lower bounds of Li et al.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 02:53:32 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 14:45:20 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 17:00:22 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 05:01:26 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Rosenthal", "Gregory", ""]]}, {"id": "1902.06473", "submitter": "Jean Cardinal", "authors": "Jean Cardinal, Gwena\\\"el Joret, J\\'er\\'emie Roland", "title": "Information-theoretic lower bounds for quantum sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the quantum query complexity of sorting under partial information.\nIn this problem, we are given a partially ordered set $P$ and are asked to\nidentify a linear extension of $P$ using pairwise comparisons. For the standard\nsorting problem, in which $P$ is empty, it is known that the quantum query\ncomplexity is not asymptotically smaller than the classical\ninformation-theoretic lower bound. We prove that this holds for a wide class of\npartially ordered sets, thereby improving on a result from Yao (STOC'04).\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 09:16:43 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Cardinal", "Jean", ""], ["Joret", "Gwena\u00ebl", ""], ["Roland", "J\u00e9r\u00e9mie", ""]]}, {"id": "1902.06493", "submitter": "{\\L}ukasz Lachowski", "authors": "{\\L}ukasz Lachowski", "title": "Complexity of the quorum intersection property of the Federated\n  Byzantine Agreement System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Federated Byzantine Agreement System is defined as a pair $(V, Q)$\ncomprising a set of nodes $V$ and a quorum function $Q: V \\mapsto 2^{2^{V}}\n\\setminus \\{\\emptyset\\}$ specifying for each node a set of subsets of nodes,\ncalled quorum slices. A subset of nodes is a quorum if and only if for each of\nits nodes it also contains at least one of its quorum slices. The Disjoint\nQuorums Problem answers the question whether a given instance of \\acrlong{fbas}\ncontains two quorums that have no nodes in common. We show that this problem is\n$\\mathsf{NP-complete}$. We also study the problem of finding a quorum of\nminimal size and show it is $\\mathsf{NP-hard}$. Further, we consider the\nproblem of checking whether a given subset of nodes contains a quorum for some\nselected node. We show this problem is $\\mathsf{P-complete}$ and describe a\nmethod that solves it in linear time with respect to number of nodes and the\ntotal size of all quorum slices. Moreover, we analyze the complexity of some of\nthese problems using the parametrized point of view.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 10:20:05 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Lachowski", "\u0141ukasz", ""]]}, {"id": "1902.06648", "submitter": "Anuj Dawar", "authors": "Anuj Dawar, Erich Gr\\\"adel, Wied Pakusa", "title": "Approximations of Isomorphism and Logics with Linear-Algebraic Operators", "comments": "46 pages. Pre-submission version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invertible map equivalences are approximations of graph isomorphism that\nrefine the well-known Weisfeiler-Leman method. They are parametrised by a\nnumber k and a set Q of primes. The intuition is that two graphs G and H which\nare equivalent with respect to k-Q-IM-equivalence cannot be distinguished by a\nrefinement of k-tuples given by linear operators acting on vector spaces over\nfields of characteristic p, for any p in Q. These equivalences first appeared\nin the study of rank logic, but in fact they can be used to delimit the\nexpressive power of any extension of fixed-point logic with linear-algebraic\noperators. We define an infinitary logic with k variables and all\nlinear-algebraic operators over finite vector spaces of characteristic p in Q\nand show that the k-Q-IM-equivalence is the natural notion of elementary\nequivalence for this logic.\n  By means of a new and much deeper algebraic analysis of a generalized\nvariant, for any prime p, of the CFI-structures due to Cai, F\\\"urer, and\nImmerman, we prove that, as long as Q is not the set of all primes, there is no\nk such that k-Q-IM-equivalence is the same as isomorphism. It follows that\nthere are polynomial-time properties of graphs which are not definable in the\ninfinitary logic with all Q-linear-algebraic operators and finitely many\nvariables, which implies that no extension of fixed-point logic with\nlinear-algebraic operators can capture PTIME, unless it includes such operators\nfor all prime characteristics. Our analysis requires substantial algebraic\nmachinery, including a homogeneity property of CFI-structures and Maschke's\nTheorem, an important result from the representation theory of finite groups.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 17:01:23 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 15:10:53 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Dawar", "Anuj", ""], ["Gr\u00e4del", "Erich", ""], ["Pakusa", "Wied", ""]]}, {"id": "1902.06803", "submitter": "Jukka Suomela", "authors": "Alkida Balliu, Sebastian Brandt, Dennis Olivetti, Jukka Suomela", "title": "How much does randomness help with locally checkable problems?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally checkable labeling problems (LCLs) are distributed graph problems in\nwhich a solution is globally feasible if it is locally feasible in all\nconstant-radius neighborhoods. Vertex colorings, maximal independent sets, and\nmaximal matchings are examples of LCLs.\n  On the one hand, it is known that some LCLs benefit exponentially from\nrandomness---for example, any deterministic distributed algorithm that finds a\nsinkless orientation requires $\\Theta(\\log n)$ rounds in the LOCAL model, while\nthe randomized complexity of the problem is $\\Theta(\\log \\log n)$ rounds. On\nthe other hand, there are also many LCLs in which randomness is useless.\n  Previously, it was not known if there are any LCLs that benefit from\nrandomness, but only subexponentially. We show that such problems exist: for\nexample, there is an LCL with deterministic complexity $\\Theta(\\log^2 n)$\nrounds and randomized complexity $\\Theta(\\log n \\log \\log n)$ rounds.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 21:22:04 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 12:25:28 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Balliu", "Alkida", ""], ["Brandt", "Sebastian", ""], ["Olivetti", "Dennis", ""], ["Suomela", "Jukka", ""]]}, {"id": "1902.06852", "submitter": "Debajyoti Bera", "authors": "Debajyoti Bera and Tharrmashastha P.V", "title": "Error reduction of quantum algorithms", "comments": null, "journal-ref": "Phys. Rev. A 100, 012331 (2019)", "doi": "10.1103/PhysRevA.100.012331", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We give a technique to reduce the error probability of quantum algorithms\nthat determine whether its input has a specified property of interest. The\nstandard process of reducing this error is statistical processing of the\nresults of multiple independent executions of an algorithm. Denoting by $\\rho$\nan upper bound of this probability (wlog., assume $\\rho \\le \\frac{1}{2}$),\nclassical techniques require $O(\\frac{\\rho}{[(1-\\rho) - \\rho]^2})$ executions\nto reduce the error to a negligible constant. We investigated when and how\nquantum algorithmic techniques like amplitude amplification and estimation may\nreduce the number of executions. On one hand, the former idea does not directly\nbenefit algorithms that can err on both yes and no answers and the number of\nexecutions in the latter approach is $O(\\frac{1}{(1-\\rho) - \\rho})$. We propose\na novel approach named as {\\em Amplitude Separation} that combines both these\napproaches and achieves $O(\\frac{1}{\\sqrt{1-\\rho} - \\sqrt{\\rho}})$ executions\nthat betters existing approaches when the errors are high.\n  In the Multiple-Weight Decision Problem, the input is an $n$-bit Boolean\nfunction $f()$ given as a black-box and the objective is to determine the\nnumber of $x$ for which $f(x)=1$, denoted as $wt(f)$, given some possible\nvalues $\\{w_1, \\ldots, w_k\\}$ for $wt(f)$. When our technique is applied to\nthis problem, we obtain the correct answer, maybe with a negligible error,\nusing $O(\\log_2 k \\sqrt{2^n})$ calls to $f()$ that shows a quadratic speedup\nover classical approaches and currently known quantum algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 00:47:31 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Bera", "Debajyoti", ""], ["P.", "Tharrmashastha", "V"]]}, {"id": "1902.06916", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler, Wasim Huleihel", "title": "Universality of Computational Lower Bounds for Submatrix Detection", "comments": "46 pages, accepted for presentation at Conference on Learning Theory\n  (COLT) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the general submatrix detection problem, the task is to detect the\npresence of a small $k \\times k$ submatrix with entries sampled from a\ndistribution $\\mathcal{P}$ in an $n \\times n$ matrix of samples from\n$\\mathcal{Q}$. This formulation includes a number of well-studied problems,\nsuch as biclustering when $\\mathcal{P}$ and $\\mathcal{Q}$ are Gaussians and the\nplanted dense subgraph formulation of community detection when the submatrix is\na principal minor and $\\mathcal{P}$ and $\\mathcal{Q}$ are Bernoulli random\nvariables. These problems all seem to exhibit a universal phenomenon: there is\na statistical-computational gap depending on $\\mathcal{P}$ and $\\mathcal{Q}$\nbetween the minimum $k$ at which this task can be solved and the minimum $k$ at\nwhich it can be solved in polynomial time. Our main result is to tightly\ncharacterize this computational barrier as a tradeoff between $k$ and the KL\ndivergences between $\\mathcal{P}$ and $\\mathcal{Q}$ through average-case\nreductions from the planted clique conjecture. These computational lower bounds\nhold given mild assumptions on $\\mathcal{P}$ and $\\mathcal{Q}$ arising\nnaturally from classical binary hypothesis testing. Our results recover and\ngeneralize the planted clique lower bounds for Gaussian biclustering in Ma-Wu\n(2015) and Brennan et al. (2018) and for the sparse and general regimes of\nplanted dense subgraph in Hajek et al. (2015) and Brennan et al. (2018). This\nyields the first universality principle for computational lower bounds obtained\nthrough average-case reductions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 06:37:02 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 05:01:18 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 17:05:34 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""], ["Huleihel", "Wasim", ""]]}, {"id": "1902.07055", "submitter": "Przemys{\\l}aw Uzna\\'nski", "authors": "Adrian Kosowski, Przemys{\\l}aw Uzna\\'nski, Laurent Viennot", "title": "Hardness of Exact Distance Queries in Sparse Graphs Through Hub Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distance labeling scheme is an assignment of bit-labels to the vertices of\nan undirected, unweighted graph such that the distance between any pair of\nvertices can be decoded solely from their labels. An important class of\ndistance labeling schemes is that of hub labelings, where a node $v \\in G$\nstores its distance to the so-called hubs $S_v \\subseteq V$, chosen so that for\nany $u,v \\in V$ there is $w \\in S_u \\cap S_v$ belonging to some shortest $uv$\npath. Notice that for most existing graph classes, the best distance labelling\nconstructions existing use at some point a hub labeling scheme at least as a\nkey building block. Our interest lies in hub labelings of sparse graphs, i.e.,\nthose with $|E(G)| = O(n)$, for which we show a lowerbound of\n$\\frac{n}{2^{O(\\sqrt{\\log n})}}$ for the average size of the hubsets.\nAdditionally, we show a hub-labeling construction for sparse graphs of average\nsize $O(\\frac{n}{RS(n)^{c}})$ for some $0 < c < 1$, where $RS(n)$ is the\nso-called Ruzsa-Szemer{\\'e}di function, linked to structure of induced\nmatchings in dense graphs. This implies that further improving the lower bound\non hub labeling size to $\\frac{n}{2^{(\\log n)^{o(1)}}}$ would require a\nbreakthrough in the study of lower bounds on $RS(n)$, which have resisted\nsubstantial improvement in the last 70 years. For general distance labeling of\nsparse graphs, we show a lowerbound of $\\frac{1}{2^{O(\\sqrt{\\log n})}}\nSumIndex(n)$, where $SumIndex(n)$ is the communication complexity of the\nSum-Index problem over $Z_n$. Our results suggest that the best achievable\nhub-label size and distance-label size in sparse graphs may be\n$\\Theta(\\frac{n}{2^{(\\log n)^c}})$ for some $0<c < 1$.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 13:57:29 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 20:16:04 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 18:28:46 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Kosowski", "Adrian", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""], ["Viennot", "Laurent", ""]]}, {"id": "1902.07063", "submitter": "Ramprasad Saptharishi", "authors": "Mrinal Kumar and Rafael Oliveira and Ramprasad Saptharishi", "title": "Towards Optimal Depth Reductions for Syntactically Multilinear Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that any $n$-variate polynomial computable by a syntactically\nmultilinear circuit of size $\\operatorname{poly}(n)$ can be computed by a\ndepth-$4$ syntactically multilinear ($\\Sigma\\Pi\\Sigma\\Pi$) circuit of size at\nmost $\\exp\\left({O\\left(\\sqrt{n\\log n}\\right)}\\right)$. For degree $d =\n\\omega(n/\\log n)$, this improves upon the upper bound of\n$\\exp\\left({O(\\sqrt{d}\\log n)}\\right)$ obtained by Tavenas~\\cite{T15} for\ngeneral circuits, and is known to be asymptotically optimal in the exponent\nwhen $d < n^{\\epsilon}$ for a small enough constant $\\epsilon$. Our upper bound\nmatches the lower bound of $\\exp\\left({\\Omega\\left(\\sqrt{n\\log\nn}\\right)}\\right)$ proved by Raz and Yehudayoff~\\cite{RY09}, and thus cannot be\nimproved further in the exponent. Our results hold over all fields and also\ngeneralize to circuits of small individual degree.\n  More generally, we show that an $n$-variate polynomial computable by a\nsyntactically multilinear circuit of size $\\operatorname{poly}(n)$ can be\ncomputed by a syntactically multilinear circuit of product-depth $\\Delta$ of\nsize at most $\\exp\\left(O\\left(\\Delta \\cdot (n/\\log n)^{1/\\Delta} \\cdot \\log\nn\\right)\\right)$. It follows from the lower bounds of Raz and Yehudayoff (CC\n2009) that in general, for constant $\\Delta$, the exponent in this upper bound\nis tight and cannot be improved to $o\\left(\\left(n/\\log\nn\\right)^{1/\\Delta}\\cdot \\log n\\right)$.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 14:10:23 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Kumar", "Mrinal", ""], ["Oliveira", "Rafael", ""], ["Saptharishi", "Ramprasad", ""]]}, {"id": "1902.07175", "submitter": "Alexander Kozachinskiy", "authors": "Alexander Kozachinskiy, Mikhail Vyalyi", "title": "An application of communication complexity, Kolmogorov complexity and\n  extremal combinatorics to parity games", "comments": "32 pages, 3 figures. Slight improvements of the exposition compared\n  with version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  So-called separation automata are in the core of several recently invented\nquasi-polynomial time algorithms for parity games. An explicit $q$-state\nseparation automaton implies an algorithm for parity games with running time\npolynomial in $q$. It is open whether a polynomial-state separation automaton\nexists. A positive answer will lead to a polynomial-time algorithm for parity\ngames, while a negative answer will at least demonstrate impossibility to\nconstruct such an algorithm using separation approach.\n  In this work we prove exponential lower bound for a restricted class of\nseparation automata. Our technique combines communication complexity and\nKolmogorov complexity. One of our technical contributions belongs to extremal\ncombinatorics. Namely, we prove a new upper bound on the product of sizes of\ntwo families of sets with small pairwise intersection.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:11:50 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 10:31:26 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 06:59:44 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Kozachinskiy", "Alexander", ""], ["Vyalyi", "Mikhail", ""]]}, {"id": "1902.07201", "submitter": "Alexey Milovanov", "authors": "Alexey Milovanov", "title": "PIT for depth-$4$ circuits and Sylvester-Gallai conjecture for\n  polynomials", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This text is a development of a preprint of Ankit Gupta.\n  We present an approach for devising a deterministic polynomial time blackbox\nidentity testing (PIT) algorithm for depth-$4$ circuits with bounded top fanin.\nThis approach is similar to Kayal-Shubhangi approach for depth-$3$ circuits.\nKayal and Shubhangi based their algorithm on Sylvester-Gallai-type theorem\nabout linear polynomials. We show how it is possible to generalize this\napproach to depth-$4$ circuits. However we failed to implement this plan\ncompletely. We succeeded to construct a polynomial time deterministic algorithm\nfor depth-$4$ circuits with bounded top fanin and its correctness requires a\nhypothesis. Also we present a polynomial-time (unconditional) algorithm for\nsome subclass of depth-$4$ circuits with bounded top fanin.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:58:43 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Milovanov", "Alexey", ""]]}, {"id": "1902.07245", "submitter": "Olivier Bournez", "authors": "Olivier Bournez and Sabrina Ouazzani", "title": "Continuous Ordinary Differential Equations and Transfinite Computations", "comments": "The model is not sufficiently precisely detailed. Part of the article\n  needs clarification and rewriting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Continuous Ordinary Differential Equations (CODE) y'=f(y), where\nf is a continuous function. They are known to always have solutions for a given\ninitial condition y(0)=y0, these solutions being possibly non unique. We\nrestrict to our attention to a class of continuous functions, that we call\ngreedy: they always admit unique greedy solutions, i.e. going in greedy way in\nsome fixed direction.\n  We prove that they can be seen as models of computation over the ordinals and\nconversely in a very strong sense.\n  In particular, for such ODEs, to a greedy trajectory can be associated some\nordinal corresponding to some time of computation, and conversely models of\ncomputation over the ordinals can be associated to some CODE. In particular,\nanalyzing reachability for one or the other concept with respect to greedy\ntrajectories has the same hardness. This also brings new perspectives on\nanalysis in Mathematics, by providing ways to translate results for ITTMs to\nCODEs. This also extends some recent results about the relations between\nordinary differential equations and Turing machines, and more widely with\n(generalized) computability theory.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 19:29:32 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 12:19:10 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 10:30:16 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2019 15:03:03 GMT"}, {"version": "v5", "created": "Mon, 20 Jan 2020 18:22:52 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bournez", "Olivier", ""], ["Ouazzani", "Sabrina", ""]]}, {"id": "1902.07324", "submitter": "Dmitriy Kunisky", "authors": "Afonso S. Bandeira, Dmitriy Kunisky, Alexander S. Wein", "title": "Computational Hardness of Certifying Bounds on Constrained PCA Problems", "comments": "Submitted version (minor text revisions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a random $n \\times n$ symmetric matrix $\\boldsymbol W$ drawn from the\nGaussian orthogonal ensemble (GOE), we consider the problem of certifying an\nupper bound on the maximum value of the quadratic form $\\boldsymbol x^\\top\n\\boldsymbol W \\boldsymbol x$ over all vectors $\\boldsymbol x$ in a constraint\nset $\\mathcal{S} \\subset \\mathbb{R}^n$. For a certain class of normalized\nconstraint sets $\\mathcal{S}$ we show that, conditional on certain\ncomplexity-theoretic assumptions, there is no polynomial-time algorithm\ncertifying a better upper bound than the largest eigenvalue of $\\boldsymbol W$.\nA notable special case included in our results is the hypercube $\\mathcal{S} =\n\\{ \\pm 1 / \\sqrt{n}\\}^n$, which corresponds to the problem of certifying bounds\non the Hamiltonian of the Sherrington-Kirkpatrick spin glass model from\nstatistical physics.\n  Our proof proceeds in two steps. First, we give a reduction from the\ndetection problem in the negatively-spiked Wishart model to the above\ncertification problem. We then give evidence that this Wishart detection\nproblem is computationally hard below the classical spectral threshold, by\nshowing that no low-degree polynomial can (in expectation) distinguish the\nspiked and unspiked models. This method for identifying computational\nthresholds was proposed in a sequence of recent works on the sum-of-squares\nhierarchy, and is believed to be correct for a large class of problems. Our\nproof can be seen as constructing a distribution over symmetric matrices that\nappears computationally indistinguishable from the GOE, yet is supported on\nmatrices whose maximum quadratic form over $\\boldsymbol x \\in \\mathcal{S}$ is\nmuch larger than that of a GOE matrix.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 22:18:46 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 04:46:25 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Bandeira", "Afonso S.", ""], ["Kunisky", "Dmitriy", ""], ["Wein", "Alexander S.", ""]]}, {"id": "1902.07334", "submitter": "Allen Liu", "authors": "Zeev Dvir, Allen Liu", "title": "Fourier and Circulant Matrices are Not Rigid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of matrix rigidity was first introduced by Valiant in 1977.\nRoughly speaking, a matrix is rigid if its rank cannot be reduced significantly\nby changing a small number of entries. There has been extensive interest in\nrigid matrices as Valiant showed in his MFCS'77 paper that rigidity can be used\nto prove arithmetic circuit lower bounds.\n  In a surprising result, Alman and Williams (FOCS'19) showed that the (real\nvalued) Hadamard matrix, which was conjectured to be rigid, is actually not\nvery rigid. This line of work was extended by Dvir and Edelman (\\emph{Theory of\nComputing}, 2019) to a family of matrices related to the Hadamard matrix, but\nover finite fields. In our work, we take another step in this direction and\nshow that for any abelian group $G$ and function $f:G \\rightarrow \\mathbb{C}$,\nthe matrix given by $M_{xy} = f(x - y)$ for $x,y \\in G$ is not rigid. In\nparticular, we get that complex valued Fourier matrices, circulant matrices,\nand Toeplitz matrices are all not rigid and cannot be used to carry out\nValiant's approach to proving circuit lower bounds. Our results also hold when\nwe consider matrices over a fixed finite field instead of the complex numbers.\nThis complements a recent result of Goldreich and Tal (\\emph{Comp. Complexity},\n2018) who showed that Toeplitz matrices are nontrivially rigid (but not enough\nfor Valiant's method). Our work differs from previous non-rigidity results in\nthat those works considered matrices whose underlying group of symmetries was\nof the form $\\mathbb{F}_p^n$ with $p$ fixed and $n$ tending to infinity, while\nin the families of matrices we study, the underlying group of symmetries can be\nany abelian group and, in particular, the cyclic group $\\mathbb{Z}_N$, which\nhas very different structure. Our results also suggest natural new candidates\nfor rigidity in the form of matrices whose symmetry groups are highly\nnon-abelian.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 22:45:26 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 00:20:01 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 07:06:39 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Dvir", "Zeev", ""], ["Liu", "Allen", ""]]}, {"id": "1902.07336", "submitter": "Nathan Lindzey", "authors": "Nathan Lindzey, Ansis Rosmanis", "title": "A Tight Lower Bound for Index Erasure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math.CO math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Index Erasure problem asks a quantum computer to prepare a uniform\nsuperposition over the image of an injective function given by an oracle. We\nprove a tight $\\Omega(\\sqrt{n})$ lower bound on the quantum query complexity of\nthe non-coherent case of the problem, where, in addition to preparing the\nrequired superposition, the algorithm is allowed to leave the ancillary memory\nin an arbitrary function-dependent state. This resolves an open question of\nAmbainis, Magnin, Roetteler, and Roland (CCC 2011), who gave a tight bound for\nthe coherent case, the case where the ancillary memory must return to its\ninitial state.\n  The proof is based on evaluating certain Krein parameters of a symmetric\nassociation scheme defined over partial permutations. The study of this\nassociation scheme may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 22:56:53 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Lindzey", "Nathan", ""], ["Rosmanis", "Ansis", ""]]}, {"id": "1902.07349", "submitter": "Murray Elder", "authors": "Laura Ciobanu and Murray Elder", "title": "Solutions sets to systems of equations in hyperbolic groups are EDT0L in\n  PSPACE", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the full set of solutions to systems of equations and\ninequations in a hyperbolic group, with or without torsion, as shortlex\ngeodesic words, is an EDT0L language whose specification can be computed in\n$\\mathsf{NSPACE}(n^2\\log n)$ for the torsion-free case and\n$\\mathsf{NSPACE}(n^4\\log n)$ in the torsion case. Our work combines deep\ngeometric results by Rips, Sela, Dahmani and Guirardel on decidability of\nexistential theories of hyperbolic groups, work of computer scientists\nincluding Plandowski, Je\\.z, Diekert and others on $\\mathsf{PSPACE}$ algorithms\nto solve equations in free monoids and groups using compression, and an\nintricate language-theoretic analysis. The present work gives an essentially\noptimal formal language description for all solutions in all hyperbolic groups,\nand an explicit and surprising low space complexity to compute them.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 23:47:38 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 06:14:20 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Ciobanu", "Laura", ""], ["Elder", "Murray", ""]]}, {"id": "1902.07380", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler", "title": "Optimal Average-Case Reductions to Sparse PCA: From Weak Assumptions to\n  Strong Hardness", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, sparse principal component analysis has emerged as an\narchetypal problem for illustrating statistical-computational tradeoffs. This\ntrend has largely been driven by a line of research aiming to characterize the\naverage-case complexity of sparse PCA through reductions from the planted\nclique (PC) conjecture - which conjectures that there is no polynomial-time\nalgorithm to detect a planted clique of size $K = o(N^{1/2})$ in\n$\\mathcal{G}(N, \\frac{1}{2})$. All previous reductions to sparse PCA either\nfail to show tight computational lower bounds matching existing algorithms or\nshow lower bounds for formulations of sparse PCA other than its canonical\ngenerative model, the spiked covariance model. Also, these lower bounds all\nquickly degrade with the exponent in the PC conjecture. Specifically, when only\ngiven the PC conjecture up to $K = o(N^\\alpha)$ where $\\alpha < 1/2$, there is\nno sparsity level $k$ at which these lower bounds remain tight. If $\\alpha \\le\n1/3$ these reductions fail to even show the existence of a\nstatistical-computational tradeoff at any sparsity $k$. We give a reduction\nfrom PC that yields the first full characterization of the computational\nbarrier in the spiked covariance model, providing tight lower bounds at all\nsparsities $k$. We also show the surprising result that weaker forms of the PC\nconjecture up to clique size $K = o(N^\\alpha)$ for any given $\\alpha \\in (0,\n1/2]$ imply tight computational lower bounds for sparse PCA at sparsities $k =\no(n^{\\alpha/3})$. This shows that even a mild improvement in the signal\nstrength needed by the best known polynomial-time sparse PCA algorithms would\nimply that the hardness threshold for PC is subpolynomial. This is the first\ninstance of a suboptimal hardness assumption implying optimal lower bounds for\nanother problem in unsupervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 02:35:39 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""]]}, {"id": "1902.07408", "submitter": "Yihan Zhang", "authors": "Aditya Potukuchi, Yihan Zhang", "title": "Improved efficiency for covering codes matching the sphere-covering\n  bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DM math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A covering code is a subset $\\mathcal{C} \\subseteq \\{0,1\\}^n$ with the\nproperty that any $z \\in \\{0,1\\}^n$ is close to some $c \\in \\mathcal{C}$ in\nHamming distance. For every $\\epsilon,\\delta>0$, we show a construction of a\nfamily of codes with relative covering radius $\\delta + \\epsilon$ and rate $1 -\n\\mathrm{H}(\\delta) $ with block length at most $\\exp(O((1/\\epsilon) \\log\n(1/\\epsilon)))$ for every $\\epsilon > 0$. This improves upon a folklore\nconstruction which only guaranteed codes of block length $\\exp(1/\\epsilon^2)$.\nThe main idea behind this proof is to find a distribution on codes with\nrelatively small support such that most of these codes have good covering\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 05:15:30 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 13:30:45 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 09:00:07 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Potukuchi", "Aditya", ""], ["Zhang", "Yihan", ""]]}, {"id": "1902.07465", "submitter": "Mehran Hosseini", "authors": "Mehran Hosseini, Jo\\\"el Ouaknine, James Worrell", "title": "Termination of Linear Loops over the Integers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of deciding termination of single-path while loops\nwith integer variables, affine updates, and affine guard conditions. The\nquestion is whether such a loop terminates on all integer initial values. This\nproblem is known to be decidable for the subclass of loops whose update\nmatrices are diagonalisable, but the general case has remained open since being\nconjectured decidable by Tiwari in 2004. In this paper we show decidability of\ndetermining termination for arbitrary update matrices, confirming Tiwari's\nconjecture. For the class of loops considered in this paper, the question of\ndeciding termination on a specific initial value is a longstanding open problem\nin number theory. The key to our decision procedure is in showing how to\ncircumvent the difficulties inherent in deciding termination on a fixed initial\nvalue.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 09:32:01 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 21:35:50 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Hosseini", "Mehran", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Worrell", "James", ""]]}, {"id": "1902.07515", "submitter": "Fabian Kunze", "authors": "Yannick Forster, Fabian Kunze, Marc Roth", "title": "The Weak Call-By-Value {\\lambda}-Calculus is Reasonable for Both Time\n  and Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the weak call-by-value $\\lambda$-calculus as a model for\ncomputational complexity theory and establish the natural measures for time and\nspace -- the number of beta-reductions and the size of the largest term in a\ncomputation -- as reasonable measures with respect to the invariance thesis of\nSlot and van Emde Boas [STOC~84]. More precisely, we show that, using those\nmeasures, Turing machines and the weak call-by-value $\\lambda$-calculus can\nsimulate each other within a polynomial overhead in time and a constant factor\noverhead in space for all computations that terminate in (encodings) of 'true'\nor 'false'. We consider this result as a solution to the long-standing open\nproblem, explicitly posed by Accattoli [ENTCS~18], of whether the natural\nmeasures for time and space of the $\\lambda$-calculus are reasonable, at least\nin case of weak call-by-value evaluation.\n  Our proof relies on a hybrid of two simulation strategies of reductions in\nthe weak call-by-value $\\lambda$-calculus by Turing machines, both of which are\ninsufficient if taken alone. The first strategy is the most naive one in the\nsense that a reduction sequence is simulated precisely as given by the\nreduction rules; in particular, all substitutions are executed immediately.\nThis simulation runs within a constant overhead in space, but the overhead in\ntime might be exponential. The second strategy is heap-based and relies on\nstructure sharing, similar to existing compilers of eager functional languages.\nThis strategy only has a polynomial overhead in time, but the space consumption\nmight require an additional factor of $\\log n$, which is essentially due to the\nsize of the pointers required for this strategy. Our main contribution is the\nconstruction and verification of a space-aware interleaving of the two\nstrategies, which is shown to yield both a constant overhead in space and a\npolynomial overhead in time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 11:30:17 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Forster", "Yannick", ""], ["Kunze", "Fabian", ""], ["Roth", "Marc", ""]]}, {"id": "1902.07657", "submitter": "Alexandros Hollender", "authors": "Paul W. Goldberg, Alexandros Hollender", "title": "The Hairy Ball Problem is PPAD-Complete", "comments": "Minor changes in presentation based on reviewers' comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hairy Ball Theorem states that every continuous tangent vector field on\nan even-dimensional sphere must have a zero. We prove that the associated\ncomputational problem of computing an approximate zero is PPAD-complete. We\nalso give a FIXP-hardness result for the general exact computation problem.\n  In order to show that this problem lies in PPAD, we provide new results on\nmultiple-source variants of END-OF-LINE, the canonical PPAD-complete problem.\nIn particular, finding an approximate zero of a Hairy Ball vector field on an\neven-dimensional sphere reduces to a 2-source END-OF-LINE problem. If the\ndomain is changed to be the torus of genus $g \\geq 2$ instead (where the Hairy\nBall Theorem also holds), then the problem reduces to a $2(g-1)$-source\nEND-OF-LINE problem.\n  These multiple-source END-OF-LINE results are of independent interest and\nprovide new tools for showing membership in PPAD. In particular, we use them to\nprovide the first full proof of PPAD-completeness for the IMBALANCE problem\ndefined by Beame et al. in 1998.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 17:11:20 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 14:11:30 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Goldberg", "Paul W.", ""], ["Hollender", "Alexandros", ""]]}, {"id": "1902.07660", "submitter": "Malte Skambath", "authors": "Max Bannach, Malte Skambath, Till Tantau", "title": "Towards Work-Efficient Parallel Parameterized Algorithms", "comments": "Prior full version of the paper that will appear in Proceedings of\n  the 13th International Conference and Workshops on Algorithms and Computation\n  (WALCOM 2019), February 27 - March 02, 2019, Guwahati, India. The final\n  authenticated version is available online at\n  https://doi.org/10.1007/978-3-030-10564-8_27", "journal-ref": null, "doi": "10.1007/978-3-030-10564-8_27", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel parameterized complexity theory studies how fixed-parameter\ntractable (fpt) problems can be solved in parallel. Previous theoretical work\nfocused on parallel algorithms that are very fast in principle, but did not\ntake into account that when we only have a small number of processors (between\n2 and, say, 1024), it is more important that the parallel algorithms are\nwork-efficient. In the present paper we investigate how work-efficient fpt\nalgorithms can be designed. We review standard methods from fpt theory, like\nkernelization, search trees, and interleaving, and prove trade-offs for them\nbetween work efficiency and runtime improvements. This results in a toolbox for\ndeveloping work-efficient parallel fpt algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 17:16:39 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Bannach", "Max", ""], ["Skambath", "Malte", ""], ["Tantau", "Till", ""]]}, {"id": "1902.07785", "submitter": "Ashish Dwivedi", "authors": "Ashish Dwivedi, Rajat Mittal, Nitin Saxena", "title": "Counting basic-irreducible factors mod $p^k$ in deterministic poly-time\n  and $p$-adic applications", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC cs.DS math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding an irreducible factor, of a polynomial $f(x)$ modulo a prime $p$, is\nnot known to be in deterministic polynomial time. Though there is such a\nclassical algorithm that {\\em counts} the number of irreducible factors of\n$f\\bmod p$. We can ask the same question modulo prime-powers $p^k$. The\nirreducible factors of $f\\bmod p^k$ blow up exponentially in number; making it\nhard to describe them. Can we count those irreducible factors $\\bmod~p^k$ that\nremain irreducible mod $p$? These are called {\\em basic-irreducible}. A simple\nexample is in $f=x^2+px \\bmod p^2$; it has $p$ many basic-irreducible factors.\nAlso note that, $x^2+p \\bmod p^2$ is irreducible but not basic-irreducible!\n  We give an algorithm to count the number of basic-irreducible factors of\n$f\\bmod p^k$ in deterministic poly(deg$(f),k\\log p$)-time. This solves the open\nquestions posed in (Cheng et al, ANTS'18 \\& Kopp et al, Math.Comp.'19). In\nparticular, we are counting roots $\\bmod\\ p^k$; which gives the first\ndeterministic poly-time algorithm to compute Igusa zeta function of $f$. Also,\nour algorithm efficiently partitions the set of all basic-irreducible factors\n(possibly exponential) into merely deg$(f)$-many disjoint sets, using a compact\ntree data structure and {\\em split} ideals.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 21:33:43 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Dwivedi", "Ashish", ""], ["Mittal", "Rajat", ""], ["Saxena", "Nitin", ""]]}, {"id": "1902.08086", "submitter": "Will Rosenbaum", "authors": "Talya Eden, Dana Ron, Will Rosenbaum", "title": "The Arboricity Captures the Complexity of Sampling Edges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the problem of sampling edges in an unknown graph\n$G = (V, E)$ from a distribution that is (pointwise) almost uniform over $E$.\nWe consider the case where there is some a priori upper bound on the arboriciy\nof $G$. Given query access to a graph $G$ over $n$ vertices and of average\ndegree $d$ and arboricity at most $\\alpha$, we design an algorithm that\nperforms $O\\!\\left(\\frac{\\alpha}{d} \\cdot \\frac{\\log^3 n}{\\varepsilon}\\right)$\nqueries in expectation and returns an edge in the graph such that every edge $e\n\\in E$ is sampled with probability $(1 \\pm \\varepsilon)/m$. The algorithm\nperforms two types of queries: degree queries and neighbor queries. We show\nthat the upper bound is tight (up to poly-logarithmic factors and the\ndependence in $\\varepsilon$), as $\\Omega\\!\\left(\\frac{\\alpha}{d} \\right)$\nqueries are necessary for the easier task of sampling edges from any\ndistribution over $E$ that is close to uniform in total variational distance.\nWe also prove that even if $G$ is a tree (i.e., $\\alpha = 1$ so that\n$\\frac{\\alpha}{d}=\\Theta(1)$), $\\Omega\\left(\\frac{\\log n}{\\log\\log n}\\right)$\nqueries are necessary to sample an edge from any distribution that is pointwise\nclose to uniform, thus establishing that a $\\mathrm{poly}(\\log n)$ factor is\nnecessary for constant $\\alpha$. Finally we show how our algorithm can be\napplied to obtain a new result on approximately counting subgraphs, based on\nthe recent work of Assadi, Kapralov, and Khanna (ITCS, 2019).\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 15:03:44 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Eden", "Talya", ""], ["Ron", "Dana", ""], ["Rosenbaum", "Will", ""]]}, {"id": "1902.08299", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra", "title": "The Power of Self-Reducibility: Selectivity, Information, and\n  Approximation", "comments": "A coordinated set of slides is available online at\n  https://bit.ly/2SpcujV and is designed to support professors who wish to\n  teach a lecture or a two-lecture series on this material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter provides a hands-on tutorial on the important technique known as\nself-reducibility. Through a series of \"Challenge Problems\" that are theorems\nthat the reader will---after being given definitions and tools---try to prove,\nthe tutorial will ask the reader not to read proofs that use self-reducibility,\nbut rather to discover proofs that use self-reducibility. In particular, the\nchapter will seek to guide the reader to the discovery of proofs of four\ninteresting theorems---whose focus areas range from selectivity to information\nto approximation---from the literature, whose proofs draw on self-reducibility.\n  The chapter's goal is to allow interested readers to add self-reducibility to\ntheir collection of proof tools. The chapter simultaneously has a related but\ndifferent goal, namely, to provide a \"lesson plan\" (and a coordinated set of\nslides is available online to support this use [Hem19]) for a lecture to a\ntwo-lecture series that can be given to undergraduate students---even those\nwith no background other than basic discrete mathematics and an understanding\nof what polynomial-time computation is---to immerse them in hands-on proving,\nand by doing that, to serve as an invitation to them to take courses on Models\nof Computation or Complexity Theory.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 23:04:54 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 18:02:20 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 18:34:49 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Hemaspaandra", "Lane A.", ""]]}, {"id": "1902.08382", "submitter": "Tomoyuki Morimae", "authors": "Ryu Hayakawa, Tomoyuki Morimae and Suguru Tamaki", "title": "Fine-grained quantum supremacy based on Orthogonal Vectors, 3-SUM and\n  All-Pairs Shortest Paths", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "YITP-19-11", "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained quantum supremacy is a study of proving (nearly) tight time\nlower bounds for classical simulations of quantum computing under \"fine-grained\ncomplexity\" assumptions. We show that under conjectures on Orthogonal Vectors\n(OV), 3-SUM, All-Pairs Shortest Paths (APSP) and their variants, strong and\nweak classical simulations of quantum computing are impossible in certain\nexponential time with respect to the number of qubits. Those conjectures are\nwidely used in classical fine-grained complexity theory in which polynomial\ntime hardness is conjectured. All previous results of fine-grained quantum\nsupremacy are based on ETH, SETH, or their variants that are conjectures for\nSAT in which exponential time hardness is conjectured. We show that there exist\nquantum circuits which cannot be classically simulated in certain exponential\ntime with respect to the number of qubits first by considering a Quantum Random\nAccess Memory (QRAM) based quantum computing model and next by considering a\nnon-QRAM model quantum computation. In the case of the QRAM model, the size of\nquantum circuits is linear with respect to the number of qubits and in the case\nof the non-QRAM model, the size of the quantum circuits is exponential with\nrespect to the number of qubits but the results are still non-trivial.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 07:02:04 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 11:28:32 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Hayakawa", "Ryu", ""], ["Morimae", "Tomoyuki", ""], ["Tamaki", "Suguru", ""]]}, {"id": "1902.08723", "submitter": "Saket Saurabh", "authors": "Daniel Lokshtanov and Daniel Marx and Saket Saurabh", "title": "Slightly Superexponential Parameterized Problems", "comments": null, "journal-ref": "SIAM Journal on Computing, 2018", "doi": "10.1137/16M1104834", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in parameterized algorithms is to obtain algorithms\n  with running time $f(k)\\cdot n^{O(1)}$ such that $f$ is as slow growing\nfunction of the parameter $k$ as possible. In particular, a large number of\nbasic parameterized problems admit parameterized algorithms where $f(k)$ is\nsingle-exponential, that is, $c^k$ for some constant $c$, which makes aiming\nfor such a running time a natural goal for other problems as well. However\nthere are still plenty of problems where the $f(k)$ appearing in the best known\nrunning time is worse than single-exponential and it remained ``slightly\nsuperexponential'' even after serious attempts to bring it down. A natural\nquestion to ask is whether the $f(k)$ appearing in the running time of the\nbest-known algorithms is optimal for any of these problems.\n  In this paper, we examine parameterized problems where $f(k)$ is\n$k^{O(k)}=2^{O(k\\log k)}$ in the best known running time and for a number of\nsuch problems, we show that the dependence on $k$ in the running time cannot be\nimproved to single exponential. (See paper for the longer abstract.)\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 03:06:26 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Lokshtanov", "Daniel", ""], ["Marx", "Daniel", ""], ["Saurabh", "Saket", ""]]}, {"id": "1902.09114", "submitter": "Bai Zonglei", "authors": "Zonglei Bai, Yongzhi Cao and Hanpin Wang", "title": "FPRAS for the Potts Model and the Number of $k$-colorings", "comments": "We find an error in the analysis of the algorithm, and it makes the\n  results wrong", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a sampling algorithm for the Potts model using Markov\nchains. Based on the sampling algorithm, we give \\emph{FPRAS}es for the Potts\nmodel and the number of $k$-colorings of the graph.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 07:17:58 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 07:36:32 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2019 10:59:39 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Bai", "Zonglei", ""], ["Cao", "Yongzhi", ""], ["Wang", "Hanpin", ""]]}, {"id": "1902.09407", "submitter": "Paul Bell", "authors": "Paul C. Bell", "title": "Polynomially Ambiguous Probabilistic Automata on Restricted Languages", "comments": "Amended an issue regarding commutativity of matrices in Theorem 1 to\n  show why the matrices commute", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the computability and complexity of decision questions for\nProbabilistic Finite Automata (PFA) with sub-exponential ambiguity. We show\nthat the emptiness problem for strict and non-strict cut-points of polynomially\nambiguous commutative PFA remains undecidable, implying that the problem is\nundecidable when inputs are from a letter monotonic language. We show that the\nproblem remains undecidable over a binary input alphabet when the input word is\nover a bounded language, in the noncommutative case. In doing so, we introduce\na new technique based upon the Turakainen construction of a PFA from a Weighted\nFinite Automata which can be used to generate PFA of lower dimensions and of\nsubexponential ambiguity. We also study freeness/injectivity problems for\npolynomially ambiguous PFA and study the border of decidability and\ntractability for various cases.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 16:10:17 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 11:14:21 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 14:16:06 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Bell", "Paul C.", ""]]}, {"id": "1902.09523", "submitter": "Antonio E. Porreca", "authors": "Alberto Leporati, Luca Manzoni, Giancarlo Mauri, Antonio E. Porreca,\n  Claudio Zandron", "title": "Characterizing PSPACE with shallow non-confluent P systems", "comments": "Preprint. arXiv admin note: text overlap with arXiv:1902.03879", "journal-ref": "Journal of Membrane Computing 1, 75-84 (2019)", "doi": "10.1007/s41965-019-00011-4", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In P systems with active membranes, the question of understanding the power\nof non-confluence within a polynomial time bound is still an open problem. It\nis known that, for shallow P systems, that is, with only one level of nesting,\nnon-confluence allows them to solve conjecturally harder problems than\nconfluent P systems, thus reaching PSPACE. Here we show that PSPACE is not only\na bound, but actually an exact characterization. Therefore, the power endowed\nby non-confluence to shallow P systems is equal to the power gained by\nconfluent P systems when non-elementary membrane division and polynomial depth\nare allowed, thus suggesting a connection between the roles of non-confluence\nand nesting depth.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 21:45:27 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Leporati", "Alberto", ""], ["Manzoni", "Luca", ""], ["Mauri", "Giancarlo", ""], ["Porreca", "Antonio E.", ""], ["Zandron", "Claudio", ""]]}, {"id": "1902.09597", "submitter": "Pavel Semukhin", "authors": "Thomas Colcombet, Jo\\\"el Ouaknine, Pavel Semukhin and James Worrell", "title": "On Reachability Problems for Low-Dimensional Matrix Semigroups", "comments": "Full version of the paper submitted to ICALP 2019", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2019.39", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Membership and the Half-Space Reachability problems for\nmatrices in dimensions two and three. Our first main result is that the\nMembership Problem is decidable for finitely generated sub-semigroups of the\nHeisenberg group over rational numbers. Furthermore, we prove two decidability\nresults for the Half-Space Reachability Problem. Namely, we show that this\nproblem is decidable for sub-semigroups of $\\mathrm{GL}(2,\\mathbb{Z})$ and of\nthe Heisenberg group over rational numbers.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 20:18:13 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 15:14:01 GMT"}, {"version": "v3", "created": "Mon, 29 Apr 2019 14:31:43 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Colcombet", "Thomas", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Semukhin", "Pavel", ""], ["Worrell", "James", ""]]}, {"id": "1902.10188", "submitter": "Pavel Semukhin", "authors": "Paul C. Bell, Igor Potapov, Pavel Semukhin", "title": "On the Mortality Problem: from multiplicative matrix equations to linear\n  recurrence sequences and beyond", "comments": "Full version of the MFCS submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following variant of the Mortality Problem: given $k\\times k$\nmatrices $A_1, A_2, \\dots,A_{t}$, does there exist nonnegative integers $m_1,\nm_2, \\dots,m_t$ such that the product $A_1^{m_1} A_2^{m_2} \\cdots\nA_{t}^{m_{t}}$ is equal to the zero matrix? It is known that this problem is\ndecidable when $t \\leq 2$ for matrices over algebraic numbers but becomes\nundecidable for sufficiently large $t$ and $k$ even for integral matrices.\n  In this paper, we prove the first decidability results for $t>2$. We show as\none of our central results that for $t=3$ this problem in any dimension is\nTuring equivalent to the well-known Skolem problem for linear recurrence\nsequences. Our proof relies on the Primary Decomposition Theorem for matrices\nthat was not used to show decidability results in matrix semigroups before. As\na corollary we obtain that the above problem is decidable for $t=3$ and $k \\leq\n3$ for matrices over algebraic numbers and for $t=3$ and $k=4$ for matrices\nover real algebraic numbers. Another consequence is that the set of triples\n$(m_1,m_2,m_3)$ for which the equation $A_1^{m_1} A_2^{m_2} A_3^{m_3}$ equals\nthe zero matrix is equal to a finite union of direct products of semilinear\nsets.\n  For $t=4$ we show that the solution set can be non-semilinear, and thus it\nseems unlikely that there is a direct connection to the Skolem problem. However\nwe prove that the problem is still decidable for upper-triangular $2 \\times 2$\nrational matrices by employing powerful tools from transcendence theory such as\nBaker's theorem and S-unit equations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:03:52 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 17:34:24 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 14:32:08 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Bell", "Paul C.", ""], ["Potapov", "Igor", ""], ["Semukhin", "Pavel", ""]]}, {"id": "1902.10349", "submitter": "Michael Haythorpe", "authors": "Jerzy A Filar, Michael Haythorpe and Richard Taylor", "title": "Linearly-growing Reductions of Karp's 21 NP-complete Problems", "comments": null, "journal-ref": "Numerical Algebra, Control and Optimization, 8(1):1-16, 2018", "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of whether it may be worthwhile to convert certain,\nnow classical, NP-complete problems to one of a smaller number of kernel\nNP-complete problems. In particular, we show that Karp's classical set of 21\nNP-complete problems contains a kernel subset of six problems with the property\nthat each problem in the larger set can be converted to one of these six\nproblems with only linear growth in problem size. This finding has potential\napplications in optimisation theory because the kernel subset includes 0-1\ninteger programming, job sequencing and undirected Hamiltonian cycle problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 06:17:56 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Filar", "Jerzy A", ""], ["Haythorpe", "Michael", ""], ["Taylor", "Richard", ""]]}, {"id": "1902.10765", "submitter": "Hugo Akitaya", "authors": "Hugo A. Akitaya, Matthew D. Jones, Matias Korman, Christopher\n  Meierfrankenfeld, Michael J. Munje, Diane L. Souvaine, Michael Thramann,\n  Csaba D. T\\'oth", "title": "Reconfiguration of Connected Graph Partitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent computational models for redistricting and detection of\ngerrymandering, we study the following problem on graph partitions. Given a\ngraph $G$ and an integer $k\\geq 1$, a $k$-district map of $G$ is a partition of\n$V(G)$ into $k$ nonempty subsets, called districts, each of which induces a\nconnected subgraph of $G$. A switch is an operation that modifies a\n$k$-district map by reassigning a subset of vertices from one district to an\nadjacent district; a 1-switch is a switch that moves a single vertex. We study\nthe connectivity of the configuration space of all $k$-district maps of a graph\n$G$ under 1-switch operations. We give a combinatorial characterization for the\nconnectedness of this space that can be tested efficiently. We prove that it is\nNP-complete to decide whether there exists a sequence of 1-switches that takes\na given $k$-district map into another; and NP-hard to find the shortest such\nsequence (even if a sequence of polynomial length is known to exist). We also\npresent efficient algorithms for computing a sequence of 1-switches that takes\na given $k$-district map into another when the space is connected, and show\nthat these algorithms perform a worst-case optimal number of switches up to\nconstant factors.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 20:18:23 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 14:29:29 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Akitaya", "Hugo A.", ""], ["Jones", "Matthew D.", ""], ["Korman", "Matias", ""], ["Meierfrankenfeld", "Christopher", ""], ["Munje", "Michael J.", ""], ["Souvaine", "Diane L.", ""], ["Thramann", "Michael", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1902.10773", "submitter": "Viswambhara Makam", "authors": "Harm Derksen and Visu Makam", "title": "An exponential lower bound for the degrees of invariants of cubic forms\n  and tensor actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.CC math.AC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the Grosshans Principle, we develop a method for proving lower bounds\nfor the maximal degree of a system of generators of an invariant ring. This\nmethod also gives lower bounds for the maximal degree of a set of invariants\nthat define Hilbert's null cone. We consider two actions: The first is the\naction of ${\\rm SL}(V)$ on ${\\rm Sym}^3(V)^{\\oplus 4}$, the space of $4$-tuples\nof cubic forms, and the second is the action of ${\\rm SL}(V) \\times {\\rm SL}(W)\n\\times {\\rm SL}(Z)$ on the tensor space $(V \\otimes W \\otimes Z)^{\\oplus 9}$.\nIn both these cases, we prove an exponential lower degree bound for a system of\ninvariants that generate the invariant ring or that define the null cone.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 20:35:31 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Derksen", "Harm", ""], ["Makam", "Visu", ""]]}, {"id": "1902.10851", "submitter": "Yusuke Kinoshita", "authors": "Yusuke Kinoshita", "title": "Analysis of Quantum Multi-Prover Zero-Knowledge Systems: Elimination of\n  the Honest Condition and Computational Zero-Knowledge Systems for QMIP*", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-knowledge and multi-prover systems are both central notions in classical\nand quantum complexity theory. There is, however, little research in quantum\nmulti-prover zero-knowledge systems. This paper studies complexity-theoretical\naspects of the quantum multi-prover zero-knowledge systems. This paper has two\nresults:\n  1.QMIP* systems with honest zero-knowledge can be converted into general\nzero-knowledge systems without any assumptions.\n  2.QMIP* has computational quantum zero-knowledge systems if a natural\ncomputational conjecture holds.\n  One of the main tools is a test (called the GHZ test) that uses GHZ states\nshared by the provers, which prevents the verifier's attack in the above two\nresults. Another main tool is what we call the Local Hamiltonian based\nInteractive protocol (LHI protocol). The LHI protocol makes previous research\nfor Local Hamiltonians applicable to check the history state of interactive\nproofs, and we then apply Broadbent et al.'s zero-knowledge protocol for QMA\n\\cite{BJSW} to quantum multi-prover systems in order to obtain the second\nresult.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 00:45:54 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Kinoshita", "Yusuke", ""]]}, {"id": "1902.10935", "submitter": "Lior Kamma", "authors": "Peyman Afshani, Casper Benjamin Freksen, Lior Kamma, Kasper Green\n  Larsen", "title": "Lower Bounds for Multiplication via Network Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplication is one of the most fundamental computational problems, yet its\ntrue complexity remains elusive. The best known upper bound, by F\\\"{u}rer,\nshows that two $n$-bit numbers can be multiplied via a boolean circuit of size\n$O(n \\lg n \\cdot 4^{\\lg^*n})$, where $\\lg^*n$ is the very slowly growing\niterated logarithm. In this work, we prove that if a central conjecture in the\narea of network coding is true, then any constant degree boolean circuit for\nmultiplication must have size $\\Omega(n \\lg n)$, thus almost completely\nsettling the complexity of multiplication circuits. We additionally revisit\nclassic conjectures in circuit complexity, due to Valiant, and show that the\nnetwork coding conjecture also implies one of Valiant's conjectures.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 07:35:19 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Afshani", "Peyman", ""], ["Freksen", "Casper Benjamin", ""], ["Kamma", "Lior", ""], ["Larsen", "Kasper Green", ""]]}, {"id": "1902.11006", "submitter": "Jouke Witteveen", "authors": "Jouke Witteveen, Ralph Bottesch, Leen Torenvliet", "title": "A Hierarchy of Polynomial Kernels", "comments": null, "journal-ref": "SOFSEM 2019: Theory and Practice of Computer Science 504-518", "doi": "10.1007/978-3-030-10801-4_39", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In parameterized algorithmics, the process of kernelization is defined as a\npolynomial time algorithm that transforms the instance of a given problem to an\nequivalent instance of a size that is limited by a function of the parameter.\nAs, afterwards, this smaller instance can then be solved to find an answer to\nthe original question, kernelization is often presented as a form of\npreprocessing. A natural generalization of kernelization is the process that\nallows for a number of smaller instances to be produced to provide an answer to\nthe original problem, possibly also using negation. This generalization is\ncalled Turing kernelization. Immediately, questions of equivalence occur or,\nwhen is one form possible and not the other. These have been long standing open\nproblems in parameterized complexity. In the present paper, we answer many of\nthese. In particular, we show that Turing kernelizations differ not only from\nregular kernelization, but also from intermediate forms as truth-table\nkernelizations. We achieve absolute results by diagonalizations and also\nresults on natural problems depending on widely accepted complexity theoretic\nassumptions. In particular, we improve on known lower bounds for the kernel\nsize of compositional problems using these assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 10:47:53 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Witteveen", "Jouke", ""], ["Bottesch", "Ralph", ""], ["Torenvliet", "Leen", ""]]}, {"id": "1902.11149", "submitter": "Sujoy Bhore", "authors": "Sandip Banerjee, Sujoy Bhore", "title": "Algorithm and Hardness results on Liar's Dominating Set and $k$-tuple\n  Dominating Set", "comments": "Appears in the Proceedings of the 30th International Workshop on\n  Combinatorial Algorithms (IWOCA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G=(V,E)$, the dominating set problem asks for a minimum subset\nof vertices $D\\subseteq V$ such that every vertex $u\\in V\\setminus D$ is\nadjacent to at least one vertex $v\\in D$. That is, the set $D$ satisfies the\ncondition that $|N[v]\\cap D|\\geq 1$ for each $v\\in V$, where $N[v]$ is the\nclosed neighborhood of $v$. In this paper, we study two variants of the\nclassical dominating set problem: $\\boldmath{k}$-tuple dominating set ($k$-DS)\nproblem and Liar's dominating set (LDS) problem, and obtain several algorithmic\nand hardness results.\n  On the algorithmic side, we present a constant factor\n($\\frac{11}{2}$)-approximation algorithm for the Liar's dominating set problem\non unit disk graphs. Then, we obtain a PTAS for the $\\boldmath{k}$-tuple\ndominating set problem on unit disk graphs. On the hardness side, we show a\n$\\Omega (n^2)$ bits lower bound for the space complexity of any (randomized)\nstreaming algorithm for Liar's dominating set problem as well as for the\n$\\boldmath{k}$-tuple dominating set problem. Furthermore, we prove that the\nLiar's dominating set problem on bipartite graphs is W[2]-hard.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:25:12 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 16:19:31 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Banerjee", "Sandip", ""], ["Bhore", "Sujoy", ""]]}, {"id": "1902.11169", "submitter": "Riko Jacob", "authors": "Riko Jacob, Gerth St{\\o}lting Brodal", "title": "Dynamic Planar Convex Hull", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we determine the amortized computational complexity of the\nplanar dynamic convex hull problem by querying.\n  We present a data structure that maintains a set of n points in the plane\nunder the insertion and deletion of points in amortized O(log n) time per\noperation. The space usage of the data structure is O(n). The data structure\nsupports extreme point queries in a given direction, tangent queries through a\ngiven point, and queries for the neighboring points on the convex hull in O(log\nn) time. The extreme point queries can be used to decide whether or not a given\nline intersects the convex hull, and the tangent queries to determine whether a\ngiven point is inside the convex hull.\n  We give a lower bound on the amortized asymptotic time complexity that\nmatches the performance of this data structure.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 15:49:06 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Jacob", "Riko", ""], ["Brodal", "Gerth St\u00f8lting", ""]]}, {"id": "1902.11202", "submitter": "Thibaut Horel", "authors": "Rohit Agrawal and Yi-Hsiu Chen and Thibaut Horel and Salil Vadhan", "title": "Unifying computational entropies via Kullback-Leibler divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce hardness in relative entropy, a new notion of hardness for\nsearch problems which on the one hand is satisfied by all one-way functions and\non the other hand implies both next-block pseudoentropy and inaccessible\nentropy, two forms of computational entropy used in recent constructions of\npseudorandom generators and statistically hiding commitment schemes,\nrespectively. Thus, hardness in relative entropy unifies the latter two notions\nof computational entropy and sheds light on the apparent \"duality\" between\nthem. Additionally, it yields a more modular and illuminating proof that\none-way functions imply next-block inaccessible entropy, similar in structure\nto the proof that one-way functions imply next-block pseudoentropy (Vadhan and\nZheng, STOC '12).\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 16:39:59 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 17:09:39 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Agrawal", "Rohit", ""], ["Chen", "Yi-Hsiu", ""], ["Horel", "Thibaut", ""], ["Vadhan", "Salil", ""]]}, {"id": "1902.11257", "submitter": "Kaifeng Bu", "authors": "Kaifeng Bu, Dax Enshan Koh", "title": "Efficient classical simulation of Clifford circuits with nonstabilizer\n  input states", "comments": "4+12 pages, 3 figures", "journal-ref": "Phys. Rev. Lett. 123, 170502 (2019)", "doi": "10.1103/PhysRevLett.123.170502", "report-no": null, "categories": "quant-ph cs.CC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of evaluating the output probabilities of Clifford\ncircuits with nonstabilizer product input states. First, we consider the case\nwhen the input state is mixed, and give an efficient classical algorithm to\napproximate the output probabilities, with respect to the $l_1$ norm, of a\nlarge fraction of Clifford circuits. The running time of our algorithm\ndecreases as the inputs become more mixed. Second, we consider the case when\nthe input state is a pure nonstabilizer product state, and show that a similar\nefficient algorithm exists to approximate the output probabilities, when a\nsuitable restriction is placed on the number of qubits measured. This\nrestriction depends on a magic monotone that we call the Pauli rank. We apply\nour results to give an efficient output probability approximation algorithm for\nsome restricted quantum computation models, such as Clifford circuits with\nsolely magic state inputs (CM), Pauli-based computation (PBC) and instantaneous\nquantum polynomial time (IQP) circuits.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 18:04:04 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Bu", "Kaifeng", ""], ["Koh", "Dax Enshan", ""]]}]