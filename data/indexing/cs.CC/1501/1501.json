[{"id": "1501.00011", "submitter": "Aram Harrow", "authors": "Aram W. Harrow", "title": "Why now is the right time to study quantum computing", "comments": "6 pages, written to explain quantum computing to computer science\n  undergrads", "journal-ref": "ACM XRDS: vol. 18, no. 3, pp. 32-37, Spring 2012", "doi": "10.1145/2090276.2090288", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing is a good way to justify difficult physics experiments. But\nuntil quantum computers are built, do computer scientists need to know anything\nabout quantum information? In fact, quantum computing is not merely a recipe\nfor new computing devices, but a new way of looking at the world that has been\nastonishingly intellectually productive. In this article, I'll talk about where\nquantum computing came from, what it is, and what we can learn from it.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 21:00:25 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Harrow", "Aram W.", ""]]}, {"id": "1501.00033", "submitter": "Henry S. Yuen", "authors": "Kai-Min Chung, Xiaodi Wu, Henry Yuen", "title": "Parallel repetition for entangled k-player games via fast quantum search", "comments": "This paper is a significantly revised version of arXiv:1411.1397,\n  which erroneously claimed strong parallel repetition for free entangled\n  games. Fixed author order to alphabetical", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two parallel repetition theorems for the entangled value of\nmulti-player, one-round free games (games where the inputs come from a product\ndistribution). Our first theorem shows that for a $k$-player free game $G$ with\nentangled value $\\mathrm{val}^*(G) = 1 - \\epsilon$, the $n$-fold repetition of\n$G$ has entangled value $\\mathrm{val}^*(G^{\\otimes n})$ at most $(1 -\n\\epsilon^{3/2})^{\\Omega(n/sk^4)}$, where $s$ is the answer length of any\nplayer. In contrast, the best known parallel repetition theorem for the\nclassical value of two-player free games is $\\mathrm{val}(G^{\\otimes n}) \\leq\n(1 - \\epsilon^2)^{\\Omega(n/s)}$, due to Barak, et al. (RANDOM 2009). This\nsuggests the possibility of a separation between the behavior of entangled and\nclassical free games under parallel repetition.\n  Our second theorem handles the broader class of free games $G$ where the\nplayers can output (possibly entangled) quantum states. For such games, the\nrepeated entangled value is upper bounded by $(1 -\n\\epsilon^2)^{\\Omega(n/sk^2)}$. We also show that the dependence of the exponent\non $k$ is necessary: we exhibit a $k$-player free game $G$ and $n \\geq 1$ such\nthat $\\mathrm{val}^*(G^{\\otimes n}) \\geq \\mathrm{val}^*(G)^{n/k}$.\n  Our analysis exploits the novel connection between communication protocols\nand quantum parallel repetition, first explored by Chailloux and Scarpa (ICALP\n2014). We demonstrate that better communication protocols yield better parallel\nrepetition theorems: our first theorem crucially uses a quantum search protocol\nby Aaronson and Ambainis, which gives a quadratic speed-up for distributed\nsearch problems. Finally, our results apply to a broader class of games than\nwere previously considered before; in particular, we obtain the first parallel\nrepetition theorem for entangled games involving more than two players, and for\ngames involving quantum outputs.\n", "versions": [{"version": "v1", "created": "Fri, 26 Dec 2014 23:55:20 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2015 04:57:48 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["Chung", "Kai-Min", ""], ["Wu", "Xiaodi", ""], ["Yuen", "Henry", ""]]}, {"id": "1501.00265", "submitter": "Slavcho Shtrakov", "authors": "Sl. Shtrakov and I. Damyanov", "title": "On the complexity of finite valued functions", "comments": "23 pages, 4 figures, 6 tables, Preprint of the article is submitted\n  for consideration in [WSPC (2015)]\n  [http://www.worldscientific.com/worldscinet/ijfcs]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The essential variables in a finite function $f$ are defined as variables\nwhich occur in $f$ and weigh with the values of that function.\n  The number of essential variables is an important measure of complexity for\ndiscrete functions.\n  When replacing some variables in a function with constants the resulting\nfunctions are called subfunctions, and when replacing all essential variables\nin a function with constants we obtain an implementation of this function.\n  Such an implementation corresponds with a path in an ordered decision diagram\n(ODD) of the function which connects the root with a leaf of the diagram. The\nsets of essential variables in subfunctions of $f$ are called separable in $f$.\nIn this paper we study several properties of separable sets of variables in\nfunctions which directly impact on the number of implementations and\nsubfunctions in these functions.\n  We define equivalence relations which classify the functions of $k$-valued\nlogic into classes with same number of implementations, subfunctions or\nseparable sets. These relations induce three transformation groups which are\ncompared with the lattice of all subgroups of restricted affine group (RAG).\nThis allows us to solve several important computational and combinatorial\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jan 2015 09:47:02 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Shtrakov", "Sl.", ""], ["Damyanov", "I.", ""]]}, {"id": "1501.00437", "submitter": "Shai Ben-David", "authors": "Shai Ben-David", "title": "Computational Feasibility of Clustering under Clusterability Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that most of the common clustering objectives are NP-hard to\noptimize. In practice, however, clustering is being routinely carried out. One\napproach for providing theoretical understanding of this seeming discrepancy is\nto come up with notions of clusterability that distinguish realistically\ninteresting input data from worst-case data sets. The hope is that there will\nbe clustering algorithms that are provably efficient on such 'clusterable'\ninstances. In other words, hope that \"Clustering is difficult only when it does\nnot matter\" (CDNM thesis, for short).\n  We believe that to some extent this may indeed be the case. This paper\nprovides a survey of recent papers along this line of research and a critical\nevaluation their results. Our bottom line conclusion is that that CDNM thesis\nis still far from being formally substantiated. We start by discussing which\nrequirements should be met in order to provide formal support the validity of\nthe CDNM thesis. In particular, we list some implied requirements for notions\nof clusterability. We then examine existing results in view of those\nrequirements and outline some research challenges and open questions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 17:10:52 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Ben-David", "Shai", ""]]}, {"id": "1501.00611", "submitter": "Shihyen Chen", "authors": "Shihyen Chen", "title": "A Review on the Tree Edit Distance Problem and Related\n  Path-Decomposition Algorithms", "comments": "23 pages. 13 figures. Revisions: minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ordered labeled tree is a tree in which the nodes are labeled and the\nleft-to-right order among siblings is relevant. The edit distance between two\nordered labeled trees is the minimum cost of changing one tree into the other\nthrough a sequence of edit steps. In the literature, there are a class of\nalgorithms based on different yet closely related path-decomposition schemes.\nThis article reviews the principles of these algorithms, and studies the\nconcepts related to the algorithmic complexities as a consequence of the\ndecomposition schemes.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jan 2015 22:31:32 GMT"}, {"version": "v2", "created": "Thu, 22 Jan 2015 03:37:32 GMT"}, {"version": "v3", "created": "Sun, 25 Jan 2015 06:40:59 GMT"}, {"version": "v4", "created": "Thu, 29 Jan 2015 02:08:44 GMT"}, {"version": "v5", "created": "Tue, 3 Feb 2015 23:07:44 GMT"}, {"version": "v6", "created": "Mon, 9 Feb 2015 02:12:18 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Chen", "Shihyen", ""]]}, {"id": "1501.00622", "submitter": "Zizhuo Wang", "authors": "Yichen Chen, Dongdong Ge, Mengdi Wang, Zizhuo Wang, Yinyu Ye, Hao Yin", "title": "Strong NP-Hardness for Sparse Optimization with Concave Penalty\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the regularized sparse minimization problem, which involves\nempirical sums of loss functions for $n$ data points (each of dimension $d$)\nand a nonconvex sparsity penalty. We prove that finding an\n$\\mathcal{O}(n^{c_1}d^{c_2})$-optimal solution to the regularized sparse\noptimization problem is strongly NP-hard for any $c_1, c_2\\in [0,1)$ such that\n$c_1+c_2<1$. The result applies to a broad class of loss functions and sparse\npenalty functions. It suggests that one cannot even approximately solve the\nsparse optimization problem in polynomial time, unless P $=$ NP.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2015 01:38:23 GMT"}, {"version": "v2", "created": "Sat, 24 Jan 2015 16:00:11 GMT"}, {"version": "v3", "created": "Tue, 21 Jun 2016 14:38:24 GMT"}, {"version": "v4", "created": "Mon, 19 Jun 2017 01:46:43 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Chen", "Yichen", ""], ["Ge", "Dongdong", ""], ["Wang", "Mengdi", ""], ["Wang", "Zizhuo", ""], ["Ye", "Yinyu", ""], ["Yin", "Hao", ""]]}, {"id": "1501.00671", "submitter": "Gaurav Rattan", "authors": "V. Arvind, Pushkar S Joglekar, Gaurav Rattan", "title": "On the Complexity of Noncommutative Polynomial Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the complexity of factorization of polynomials in the\nfree noncommutative ring $\\mathbb{F}\\langle x_1,x_2,\\dots,x_n\\rangle$ of\npolynomials over the field $\\mathbb{F}$ and noncommuting variables\n$x_1,x_2,\\ldots,x_n$. Our main results are the following.\n  Although $\\mathbb{F}\\langle x_1,x_2,\\dots,x_n \\rangle$ is not a unique\nfactorization ring, we note that variable-disjoint factorization in\n$\\mathbb{F}\\langle x_1,x_2,\\dots,x_n \\rangle$ has the uniqueness property.\nFurthermore, we prove that computing the variable-disjoint factorization is\npolynomial-time equivalent to Polynomial Identity Testing (both when the input\npolynomial is given by an arithmetic circuit or an algebraic branching\nprogram). We also show that variable-disjoint factorization in the black-box\nsetting can be efficiently computed (where the factors computed will be also\ngiven by black-boxes, analogous to the work [KT91] in the commutative setting).\n  As a consequence of the previous result we show that homogeneous\nnoncommutative polynomials and multilinear noncommutative polynomials have\nunique factorizations in the usual sense, which can be efficiently computed.\n  Finally, we discuss a polynomial decomposition problem in $\\mathbb{F}\\langle\nx_1,x_2,\\dots,x_n\\rangle$ which is a natural generalization of homogeneous\npolynomial factorization and prove some complexity bounds for it.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2015 12:56:47 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Arvind", "V.", ""], ["Joglekar", "Pushkar S", ""], ["Rattan", "Gaurav", ""]]}, {"id": "1501.00734", "submitter": "Pravesh Kothari", "authors": "Boaz Barak and Siu On Chan and Pravesh Kothari", "title": "Sum of Squares Lower Bounds from Pairwise Independence", "comments": "27 Pages (including the title page) and 4 figures including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that for every $\\epsilon>0$ and predicate $P:\\{0,1\\}^k\\rightarrow\n\\{0,1\\}$ that supports a pairwise independent distribution, there exists an\ninstance $\\mathcal{I}$ of the $\\mathsf{Max}P$ constraint satisfaction problem\non $n$ variables such that no assignment can satisfy more than a\n$\\tfrac{|P^{-1}(1)|}{2^k}+\\epsilon$ fraction of $\\mathcal{I}$'s constraints but\nthe degree $\\Omega(n)$ Sum of Squares semidefinite programming hierarchy cannot\ncertify that $\\mathcal{I}$ is unsatisfiable. Similar results were previously\nonly known for weaker hierarchies.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2015 23:27:12 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2015 22:10:55 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Barak", "Boaz", ""], ["Chan", "Siu On", ""], ["Kothari", "Pravesh", ""]]}, {"id": "1501.00850", "submitter": "Valery Shchesnovich", "authors": "V. S. Shchesnovich", "title": "Tight bound on trace distance between a realistic device with partially\n  indistinguishable bosons and the ideal Boson Sampling", "comments": "8 pages, no figures. Small changes from version 3: title and Abstract\n  revised. [This submission, since version 3, is restricted to identical\n  detectors. Arbitrary detectors were treated in version 1. Those results\n  remain valid, but the derivation contains a flaw. Corrected version 1 will be\n  resubmitted as a separate article generalizing this one.]", "journal-ref": "Phys. Rev. A 91, 063842 (2015)", "doi": "10.1103/PhysRevA.91.063842", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the closeness of an experimental unitary bosonic network with only\npartially indistinguishable bosons in an arbitrary mixed input state, in\nparticular an experimental realization of the Boson Sampling, to the ideal\nbosonic network, where the measure of closeness of two networks is the trace\ndistance between the output probability distributions. An upper bound on the\ntrace distance to the ideal bosonic network is proven and also a bound on the\ndifference between probabilities of an output configuration. Moreover, the\nupper bound on the trace distance is tight, provided that a physically\ntransparent distinguishability conjecture is true. For a small\ndistinguishability error it is shown that a realistic device with $N$ bosons is\nat a constant trace distance to the ideal Boson Sampling under the\n$O(N^{-1})$-scaling of the mismatch of internal states of bosons.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 13:17:19 GMT"}, {"version": "v2", "created": "Fri, 16 Jan 2015 12:11:39 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2015 14:08:55 GMT"}, {"version": "v4", "created": "Thu, 21 May 2015 00:42:09 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Shchesnovich", "V. S.", ""]]}, {"id": "1501.00894", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Ugo Dal Lago", "title": "On Sharing, Memoization, and Polynomial Time (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We study how the adoption of an evaluation mechanism with sharing and\nmemoization impacts the class of functions which can be computed in polynomial\ntime. We first show how a natural cost model in which lookup for an already\ncomputed value has no cost is indeed invariant. As a corollary, we then prove\nthat the most general notion of ramified recurrence is sound for polynomial\ntime, this way settling an open problem in implicit computational complexity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 15:34:07 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Avanzini", "Martin", ""], ["Lago", "Ugo Dal", ""]]}, {"id": "1501.01331", "submitter": "Yura Maximov", "authors": "Yura Maximov", "title": "DNF complexity of complete boolean functions", "comments": "19 pages, 1 figure, in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyse the complexity of boolean functions takes value 0 on\na sufficiently small number of points. For many functions this leads to the\nanalysis of a single function attains 0 only on unsigned representation of\nnumbers from 1 to d for various d. Here we obtain a tight bounds on the DNF\ncomplexity of complete functions in terms of the number of literals and\nconjunctions. The method is based on a certain efficient approximation of the\nhypercube covering problem related to DNF complexity of a given boolean\nfunction.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 22:46:14 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Maximov", "Yura", ""]]}, {"id": "1501.01598", "submitter": "Jonah Brown-Cohen", "authors": "Jonah Brown-Cohen and Prasad Raghavendra", "title": "Combinatorial Optimization Algorithms via Polymorphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An elegant characterization of the complexity of constraint satisfaction\nproblems has emerged in the form of the the algebraic dichotomy conjecture of\n[BKJ00]. Roughly speaking, the characterization asserts that a CSP {\\Lambda} is\ntractable if and only if there exist certain non-trivial operations known as\npolymorphisms to combine solutions to {\\Lambda} to create new ones. In an\nentirely separate line of work, the unique games conjecture yields a\ncharacterization of approximability of Max-CSPs. Surprisingly, this\ncharacterization for Max-CSPs can also be reformulated in the language of\npolymorphisms.\n  In this work, we study whether existence of non-trivial polymorphisms implies\ntractability beyond the realm of constraint satisfaction problems, namely in\nthe value-oracle model. Specifically, given a function f in the value-oracle\nmodel along with an appropriate operation that never increases the value of f ,\nwe design algorithms to minimize f . In particular, we design a randomized\nalgorithm to minimize a function f that admits a fractional polymorphism which\nis measure preserving and has a transitive symmetry.\n  We also reinterpret known results on MaxCSPs and thereby reformulate the\nunique games conjecture as a characterization of approximability of max-CSPs in\nterms of their approximate polymorphisms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 19:17:25 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Brown-Cohen", "Jonah", ""], ["Raghavendra", "Prasad", ""]]}, {"id": "1501.01696", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal, Daniel P. Miranker", "title": "On the Complexity of Sorted Neighborhood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Record linkage concerns identifying semantically equivalent records in\ndatabases. Blocking methods are employed to avoid the cost of full pairwise\nsimilarity comparisons on $n$ records. In a seminal work, Hernandez and Stolfo\nproposed the Sorted Neighborhood blocking method. Several empirical variants\nhave been proposed in recent years. In this paper, we investigate the\ncomplexity of the Sorted Neighborhood procedure on which the variants are\nbuilt. We show that achieving maximum performance on the Sorted Neighborhood\nprocedure entails solving a sub-problem, which is shown to be NP-complete by\nreducing from the Travelling Salesman Problem. We also show that the\nsub-problem can occur in the traditional blocking method. Finally, we draw on\nrecent developments concerning approximate Travelling Salesman solutions to\ndefine and analyze three approximation algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 00:49:45 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Miranker", "Daniel P.", ""]]}, {"id": "1501.01906", "submitter": "Yu Li liu", "authors": "Yu Li", "title": "What is NP? - Interpretation of a Chinese paradox \"white horse is not\n  horse\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of nondeterminism has disappeared from the current definition of\nNP, which has led to ambiguities in understanding NP, and caused fundamental\ndifficulties in studying the relation P versus NP. In this paper, we question\nthe equivalence of the two definitions of NP, the one defining NP as the class\nof problems solvable by a nondeterministic Turing machine in polynomial time,\nand the other defining NP as the class of problems verifiable by a\ndeterministic Turing machine in polynomial time, and reveal cognitive biases in\nthis equivalence. Inspired from a famous Chinese paradox white horse is not\nhorse, we further analyze these cognitive biases. The work shows that these\ncognitive biases arise from the confusion between different levels of\nnondeterminism and determinism, due to the lack of understanding about the\nessence of nondeterminism. Therefore, we argue that fundamental difficulties in\nunderstanding P versus NP lie firstly at cognition level, then logic level.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 17:25:18 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Li", "Yu", ""]]}, {"id": "1501.01910", "submitter": "Yu Li liu", "authors": "JianMing Zhou, Yu Li", "title": "What is Cook's theorem?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we make a preliminary interpretation of Cook's theorem\npresented in [1]. This interpretation reveals cognitive biases in the proof of\nCook's theorem that arise from the attempt of constructing a formula in CNF to\nrepresent a computation of a nondeterministic Turing machine. Such cognitive\nbiases are due to the lack of understanding about the essence of\nnondeterminism, and lead to the confusion between different levels of\nnondeterminism and determinism, thus cause the loss of nondeterminism from the\nNP-completeness theory. The work shows that Cook's theorem is the origin of the\nloss of nondeterminism in terms of the equivalence of the two definitions of\nNP, the one defining NP as the class of problems solvable by a nondeterministic\nTuring machine in polynomial time, and the other defining NP as the class of\nproblems verifiable by a deterministic Turing machine in polynomial time.\nTherefore, we argue that fundamental difficulties in understanding P versus NP\nlie firstly at cognition level, then logic level.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 17:41:21 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Zhou", "JianMing", ""], ["Li", "Yu", ""]]}, {"id": "1501.02212", "submitter": "Holger Petersen", "authors": "Holger Petersen", "title": "Efficient Computation by Three Counter Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that multiplication can be done in polynomial time on a three counter\nmachine that receives its input as the contents of two counters. The technique\nis generalized to functions of two variables computable by deterministic Turing\nmachines in linear space.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 18:02:01 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Petersen", "Holger", ""]]}, {"id": "1501.02500", "submitter": "Yura Maximov", "authors": "Yura Maximov", "title": "Lower bounds on the DNF exception problem for short exception lists and\n  related problems", "comments": "in Russian, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prowide lower bounds on the complexity of the DNF exception\nproblem for short exception lists and hypercube covering problem. The method\nproposed is based on the relaxation of the initial problem to a certain linear\nprogramming problem. Some explicit bounds are provided for the case when\nexception list size is bounded above by a logarithm of dimension. The bound\nprovided in this case is significantly stronger than the bounds known before.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jan 2015 22:05:35 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Maximov", "Yura", ""]]}, {"id": "1501.03444", "submitter": "Yura Maximov", "authors": "Sergey Granin, Yura Maximov", "title": "Average case complexity of DNFs and Shannon semi-effect for narrow\n  subclasses of boolean functions", "comments": "8 pages, in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we establish some bounds on the complexity of disjunctive\nnormal forms of boolean function from narrow subclasses (e.g. functions takes\nvalue 0 in a limited number of points). The bounds are obtained by reduction\nthe initial problem to a simple set covering problem. The nature of the\ncomplexity bounds provided is tightly connected with Shannon effect and\nsemi-effect for this classes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 18:58:49 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Granin", "Sergey", ""], ["Maximov", "Yura", ""]]}, {"id": "1501.03837", "submitter": "Ahmed Abdelkader", "authors": "Ahmed Abdelkader, Aditya Acharya, Philip Dasler", "title": "On the Complexity of Slide-and-Merge Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of a particular class of board games, which we call\n`slide and merge' games. Namely, we consider 2048 and Threes, which are among\nthe most popular games of their type. In both games, the player is required to\nslide all rows or columns of the board in one direction to create a high value\ntile by merging pairs of equal tiles into one with the sum of their values.\nThis combines features from both block pushing and tile matching puzzles, like\nPush and Bejeweled, respectively. We define a number of natural decision\nproblems on a suitable generalization of these games and prove NP-hardness for\n2048 by reducing from 3SAT. Finally, we discuss the adaptation of our reduction\nto Threes and conjecture a similar result.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 21:56:05 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Abdelkader", "Ahmed", ""], ["Acharya", "Aditya", ""], ["Dasler", "Philip", ""]]}, {"id": "1501.03872", "submitter": "Andr\\'e Luiz Barbosa", "authors": "Andr\\'e Luiz Barbosa", "title": "The Dead Cryptographers Society Problem", "comments": "7 pages, 2 tables, 1 JavaScript code and some great new ideas on\n  Cryptography!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines The Dead Cryptographers Society Problem - DCS (where\nseveral great cryptographers created many polynomial-time Deterministic Turing\nMachines (DTMs) of a specific type, ran them on their proper descriptions\nconcatenated with some arbitrary strings, deleted them and left only the\nresults from those running, after they died: if those DTMs only permute and\nsometimes invert the bits on input, is it possible to decide the language\nformed by such resulting strings within polynomial time?), proves some facts\nabout its computational complexity, and discusses some possible uses on\nCryptography, such as into distance keys distribution, online reverse auction\nand secure communication.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 03:40:20 GMT"}, {"version": "v10", "created": "Tue, 4 Jul 2017 06:12:28 GMT"}, {"version": "v11", "created": "Sun, 9 Jul 2017 19:10:02 GMT"}, {"version": "v12", "created": "Fri, 14 Jul 2017 20:36:01 GMT"}, {"version": "v13", "created": "Thu, 28 Sep 2017 23:13:13 GMT"}, {"version": "v14", "created": "Sun, 5 Nov 2017 15:15:49 GMT"}, {"version": "v15", "created": "Sun, 6 May 2018 07:48:56 GMT"}, {"version": "v16", "created": "Fri, 21 Dec 2018 21:34:25 GMT"}, {"version": "v2", "created": "Tue, 20 Jan 2015 20:53:52 GMT"}, {"version": "v3", "created": "Wed, 18 Feb 2015 15:48:09 GMT"}, {"version": "v4", "created": "Sun, 22 Feb 2015 17:55:49 GMT"}, {"version": "v5", "created": "Tue, 6 Oct 2015 04:10:15 GMT"}, {"version": "v6", "created": "Sun, 6 Nov 2016 15:48:20 GMT"}, {"version": "v7", "created": "Thu, 1 Jun 2017 05:56:13 GMT"}, {"version": "v8", "created": "Fri, 2 Jun 2017 06:11:23 GMT"}, {"version": "v9", "created": "Thu, 22 Jun 2017 16:55:37 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Barbosa", "Andr\u00e9 Luiz", ""]]}, {"id": "1501.04558", "submitter": "Florent Madelaine", "authors": "Catarina Carvalho, Florent Madelaine, Barnaby Martin", "title": "From complexity to algebra and back: digraph classes, collapsibility and\n  the PGP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by computational complexity results for the quantified constraint\nsatisfaction problem, we study the clones of idempotent polymorphisms of\ncertain digraph classes. Our first results are two algebraic dichotomy, even\n\"gap\", theorems. Building on and extending [Martin CP'11], we prove that\npartially reflexive paths bequeath a set of idempotent polymorphisms whose\nassociated clone algebra has: either the polynomially generated powers property\n(PGP); or the exponentially generated powers property (EGP). Similarly, we\nbuild on [DaMM ICALP'14] to prove that semicomplete digraphs have the same\nproperty.\n  These gap theorems are further motivated by new evidence that PGP could be\nthe algebraic explanation that a QCSP is in NP even for unbounded alternation.\nAlong the way we also effect a study of a concrete form of PGP known as\ncollapsibility, tying together the algebraic and structural threads from [Chen\nSicomp'08], and show that collapsibility is equivalent to its\n$\\Pi_2$-restriction. We also give a decision procedure for $k$-collapsibility\nfrom a singleton source of a finite structure (a form of collapsibility which\ncovers all known examples of PGP for finite structures).\n  Finally, we present a new QCSP trichotomy result, for partially reflexive\npaths with constants. Without constants it is known these QCSPs are either in\nNL or Pspace-complete [Martin CP'11], but we prove that with constants they\nattain the three complexities NL, NP-complete and Pspace-complete.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 16:58:39 GMT"}, {"version": "v2", "created": "Mon, 11 May 2015 22:04:10 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Carvalho", "Catarina", ""], ["Madelaine", "Florent", ""], ["Martin", "Barnaby", ""]]}, {"id": "1501.05104", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert (LACL), Marc Bagnol (I2M), Thomas Seiller (IHES)", "title": "Memoization for Unary Logic Programming: Characterizing PTIME", "comments": "Soumis {\\`a} LICS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a characterization of deterministic polynomial time computation based\non an algebraic structure called the resolution semiring, whose elements can be\nunderstood as logic programs or sets of rewriting rules over first-order terms.\nMore precisely, we study the restriction of this framework to terms (and logic\nprograms, rewriting rules) using only unary symbols. We prove it is complete\nfor polynomial time computation, using an encoding of pushdown automata. We\nthen introduce an algebraic counterpart of the memoization technique in order\nto show its PTIME soundness. We finally relate our approach and complexity\nresults to complexity of logic programming. As an application of our\ntechniques, we show a PTIME-completeness result for a class of logic\nprogramming queries which use only unary function symbols.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 09:34:31 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 07:56:47 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "LACL"], ["Bagnol", "Marc", "", "I2M"], ["Seiller", "Thomas", "", "IHES"]]}, {"id": "1501.05296", "submitter": "Daniel Roche", "authors": "Andrew Arnold and Daniel S. Roche", "title": "Output-sensitive algorithms for sumset and sparse polynomial\n  multiplication", "comments": "Submitted to ISSAC 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC cs.DS", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We present randomized algorithms to compute the sumset (Minkowski sum) of two\ninteger sets, and to multiply two univariate integer polynomials given by\nsparse representations. Our algorithm for sumset has cost softly linear in the\ncombined size of the inputs and output. This is used as part of our sparse\nmultiplication algorithm, whose cost is softly linear in the combined size of\nthe inputs, output, and the sumset of the supports of the inputs. As a\nsubroutine, we present a new method for computing the coefficients of a sparse\npolynomial, given a set containing its support. Our multiplication algorithm\nextends to multivariate Laurent polynomials over finite fields and rational\nnumbers. Our techniques are based on sparse interpolation algorithms and\nresults from analytic number theory.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 04:43:58 GMT"}, {"version": "v2", "created": "Fri, 23 Jan 2015 20:40:10 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2015 11:10:00 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Arnold", "Andrew", ""], ["Roche", "Daniel S.", ""]]}, {"id": "1501.05405", "submitter": "EPTCS", "authors": "Manuela Bujorianu (University of Leicester), Rafael Wisniewski\n  (Aalborg University)", "title": "Proceedings 4th Workshop on Hybrid Autonomous Systems", "comments": null, "journal-ref": "EPTCS 174, 2015", "doi": "10.4204/EPTCS.174", "report-no": null, "categories": "cs.SY cs.CC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in autonomous systems is increasing both in industry and\nacademia. Such systems must operate with limited human intervention in a\nchanging environment and must be able to compensate for significant system\nfailures without external intervention. The most appropriate models of\nautonomous systems can be found in the class of hybrid systems that interact\nwith their environment. This workshop brings together researchers interested in\nall aspects of autonomy and resilience of hybrid systems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 06:40:18 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Bujorianu", "Manuela", "", "University of Leicester"], ["Wisniewski", "Rafael", "", "Aalborg University"]]}, {"id": "1501.05528", "submitter": "Christian Ikenmeyer", "authors": "Peter B\\\"urgisser and Christian Ikenmeyer and Jesko H\\\"uttenhain", "title": "Permanent versus determinant: not via saturations", "comments": "12 pages; shortened title, corrected error in proof, added bound on\n  stretching factor, provided explicit examples", "journal-ref": "Proceedings of the AMS, 145:1247-1258, 2017", "doi": "10.1090/proc/13310", "report-no": null, "categories": "cs.CC math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let Det_n denote the closure of the GL_{n^2}(C)-orbit of the determinant\npolynomial det_n with respect to linear substitution. The highest weights\n(partitions) of irreducible GL_{n^2}(C)-representations occurring in the\ncoordinate ring of Det_n form a finitely generated monoid S(Det_n). We prove\nthat the saturation of S(Det_n) contains all partitions lambda with length at\nmost n and size divisible by n. This implies that representation theoretic\nobstructions for the permanent versus determinant problem must be holes of the\nmonoid S(Det_n).\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 15:11:40 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 14:13:36 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["B\u00fcrgisser", "Peter", ""], ["Ikenmeyer", "Christian", ""], ["H\u00fcttenhain", "Jesko", ""]]}, {"id": "1501.05800", "submitter": "Matthew  Johnson", "authors": "Carl Feghali, Matthew Johnson, Dani\\\"el Paulusma", "title": "A Reconfigurations Analogue of Brooks' Theorem and its Consequences", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a simple undirected graph on $n$ vertices with maximum\ndegree~$\\Delta$. Brooks' Theorem states that $G$ has a $\\Delta$-colouring\nunless~$G$ is a complete graph, or a cycle with an odd number of vertices. To\nrecolour $G$ is to obtain a new proper colouring by changing the colour of one\nvertex. We show an analogue of Brooks' Theorem by proving that from any\n$k$-colouring, $k>\\Delta$, a $\\Delta$-colouring of $G$ can be obtained by a\nsequence of $O(n^2)$ recolourings using only the original $k$ colours unless\n$G$ is a complete graph or a cycle with an odd number of vertices, or\n$k=\\Delta+1$, $G$ is $\\Delta$-regular and, for each vertex $v$ in $G$, no two\nneighbours of $v$ are coloured alike.\n  We use this result to study the reconfiguration graph $R_k(G)$ of the\n$k$-colourings of $G$. The vertex set of $R_k(G)$ is the set of all possible\n$k$-colourings of $G$ and two colourings are adjacent if they differ on exactly\none vertex. We prove that for $\\Delta\\geq 3$, $R_{\\Delta+1}(G)$ consists of\nisolated vertices and at most one further component which has diameter\n$O(n^2)$. This result enables us to complete both a structural classification\nand an algorithmic classification for reconfigurations of colourings of graphs\nof bounded maximum degree.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 13:50:07 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Feghali", "Carl", ""], ["Johnson", "Matthew", ""], ["Paulusma", "Dani\u00ebl", ""]]}, {"id": "1501.05814", "submitter": "Emmanuel Jeandel", "authors": "Pierre Guillon (I2M), Emmanuel Jeandel (INRIA Nancy - Grand Est /\n  LORIA)", "title": "Infinite Communication Complexity", "comments": "First Version. Written from the Computer Science POV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that Alice and Bob are given each an infinite string, and they want\nto decide whether their two strings are in a given relation. How much\ncommunication do they need? How can communication be even defined and measured\nfor infinite strings? In this article, we propose a formalism for a notion of\ninfinite communication complexity, prove that it satisfies some natural\nproperties and coincides, for relevant applications, with the classical notion\nof amortized communication complexity. More-over, an application is given for\ntackling some conjecture about tilings and multidimensional sofic shifts.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 14:39:15 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Guillon", "Pierre", "", "I2M"], ["Jeandel", "Emmanuel", "", "INRIA Nancy - Grand Est /\n  LORIA"]]}, {"id": "1501.05828", "submitter": "Diptarka Chakraborty", "authors": "Diptarka Chakraborty and Raghunath Tewari", "title": "An $O(n^{\\epsilon})$ Space and Polynomial Time Algorithm for\n  Reachability in Directed Layered Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G$ and two vertices $s$ and $t$ in it, {\\em graph\nreachability} is the problem of checking whether there exists a path from $s$\nto $t$ in $G$. We show that reachability in directed layered planar graphs can\nbe decided in polynomial time and $O(n^\\epsilon)$ space, for any $\\epsilon >\n0$. The previous best known space bound for this problem with polynomial time\nwas approximately $O(\\sqrt{n})$ space \\cite{INPVW13}.\n  Deciding graph reachability in {\\SC} is an important open question in\ncomplexity theory and in this paper we make progress towards resolving this\nquestion.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 15:23:25 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Chakraborty", "Diptarka", ""], ["Tewari", "Raghunath", ""]]}, {"id": "1501.06281", "submitter": "Ayaka Sakata", "authors": "Ayaka Sakata and Yoshiyuki Kabashima", "title": "Replica Symmetric Bound for Restricted Isometry Constant", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cond-mat.dis-nn cond-mat.stat-mech cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for evaluating restricted isometry constants (RICs). This\nevaluation is reduced to the identification of the zero-points of entropy,\nwhich is defined for submatrices that are composed of columns selected from a\ngiven measurement matrix. Using the replica method developed in statistical\nmechanics, we assess RICs for Gaussian random matrices under the replica\nsymmetric (RS) assumption. In order to numerically validate the adequacy of our\nanalysis, we employ the exchange Monte Carlo (EMC) method, which has been\nempirically demonstrated to achieve much higher numerical accuracy than naive\nMonte Carlo methods. The EMC method suggests that our theoretical estimation of\nan RIC corresponds to an upper bound that is tighter than in preceding studies.\nPhysical consideration indicates that our assessment of the RIC could be\nimproved by taking into account the replica symmetry breaking.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 08:23:33 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2015 10:32:47 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2015 07:32:44 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Sakata", "Ayaka", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "1501.06323", "submitter": "Hiroshi Nishiyama", "authors": "Hiroshi Nishiyama, Yusuke Kobayashi, Yukiko Yamauchi, Shuji Kijima,\n  Masafumi Yamashita", "title": "The Parity Hamiltonian Cycle Problem", "comments": "29 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a relaxed notion of the celebrated Hamiltonian cycle, this paper\ninvestigates its variant, parity Hamiltonian cycle (PHC): A PHC of a graph is a\nclosed walk which visits every vertex an odd number of times, where we remark\nthat the walk may use an edge more than once. First, we give a complete\ncharacterization of the graphs which have PHCs, and give a linear time\nalgorithm to find a PHC, in which every edge appears at most four times, in\nfact. In contrast, we show that finding a PHC is NP-hard if a closed walk is\nallowed to use each edge at most z times for each z=1,2,3 (PHCz for short),\neven when a given graph is two-edge connected. We then further investigate the\nPHC3 problem, and show that the problem is in P when an input graph is\nfour-edge connected. Finally, we are concerned with three (or two)-edge\nconnected graphs, and show that the PHC3 is in P for any C_>=5-free or P6-free\ngraphs. Note that the Hamiltonian cycle problem is known to be NP-hard for\nthose graph classes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 10:49:26 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2016 03:42:57 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Nishiyama", "Hiroshi", ""], ["Kobayashi", "Yusuke", ""], ["Yamauchi", "Yukiko", ""], ["Kijima", "Shuji", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1501.06398", "submitter": "Jens Ma{\\ss}berg", "authors": "Jens Ma{\\ss}berg", "title": "Solitaire Chess is NP-complete", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Solitaire Chess\" is a logic puzzle published by Thinkfun, that can be seen\nas a single person version of traditional chess. Given a chess board with some\nchess pieces of the same color placed on it, the task is to capture all pieces\nbut one using only moves that are allowed in chess. Moreover, in each move one\npiece has to be captured. We prove that deciding if a given instance of\nSolitaire Chess is solvable is NP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 14:02:29 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Ma\u00dfberg", "Jens", ""]]}, {"id": "1501.06461", "submitter": "Paul Vitanyi", "authors": "Paul M.B. Vitanyi (National Research Center for Mathematics and\n  Computer Science in the Netherlands (CWI) and Univrsity of Amsterdam)", "title": "On The Average-Case Complexity of Shellsort", "comments": "13 pages LaTeX", "journal-ref": "Random Structures and Algorithms, 52:2(2018), 354-363", "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a lower bound expressed in the increment sequence on the\naverage-case complexity of the number of inversions of Shellsort. This lower\nbound is sharp in every case where it could be checked. A special case of this\nlower bound yields the general Jiang-Li-Vit\\'anyi lower bound. We obtain new\nresults e.g. determining the average-case complexity precisely in the\nYao-Janson-Knuth 3-pass case.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 16:18:27 GMT"}, {"version": "v2", "created": "Tue, 27 Jan 2015 16:45:25 GMT"}, {"version": "v3", "created": "Mon, 6 Feb 2017 16:38:57 GMT"}, {"version": "v4", "created": "Wed, 8 Feb 2017 17:35:52 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Vitanyi", "Paul M. B.", "", "National Research Center for Mathematics and\n  Computer Science in the Netherlands"]]}, {"id": "1501.06729", "submitter": "Christoph Haase", "authors": "Christoph Haase, Stefan Kiefer", "title": "The Complexity of the Kth Largest Subset Problem and Related Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Kth largest subset problem and the Kth largest m-tuple\nproblem are in PP and hard for PP under polynomial-time Turing reductions.\nSeveral problems from the literature were previously shown NP-hard via\nreductions from those two problems, and by our main result they become PP-hard\nas well. We also provide complementary PP-upper bounds for some of them.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 10:33:56 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2015 14:58:32 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Haase", "Christoph", ""], ["Kiefer", "Stefan", ""]]}, {"id": "1501.07053", "submitter": "Amir Abboud", "authors": "Amir Abboud and Arturs Backurs and Virginia Vassilevska Williams", "title": "Quadratic-Time Hardness of LCS and other Sequence Similarity Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two important similarity measures between sequences are the longest common\nsubsequence (LCS) and the dynamic time warping distance (DTWD). The\ncomputations of these measures for two given sequences are central tasks in a\nvariety of applications. Simple dynamic programming algorithms solve these\ntasks in $O(n^2)$ time, and despite an extensive amount of research, no\nalgorithms with significantly better worst case upper bounds are known.\n  In this paper, we show that an $O(n^{2-\\epsilon})$ time algorithm, for some\n$\\epsilon>0$, for computing the LCS or the DTWD of two sequences of length $n$\nover a constant size alphabet, refutes the popular Strong Exponential Time\nHypothesis (SETH). Moreover, we show that computing the LCS of $k$ strings over\nan alphabet of size $O(k)$ cannot be done in $O(n^{k-\\epsilon})$ time, for any\n$\\epsilon>0$, under SETH. Finally, we also address the time complexity of\napproximating the DTWD of two strings in truly subquadratic time.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 10:12:58 GMT"}, {"version": "v2", "created": "Thu, 29 Jan 2015 22:57:04 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Abboud", "Amir", ""], ["Backurs", "Arturs", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1501.07195", "submitter": "Stefan Mengel", "authors": "Hubie Chen and Stefan Mengel", "title": "The Logic of Counting Query Answers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of counting the number of answers to a first-order\nformula on a finite structure. We present and study an extension of first-order\nlogic in which algorithms for this counting problem can be naturally and\nconveniently expressed, in senses that are made precise and that are motivated\nby the wish to understand tractable cases of the counting problem.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 17:02:31 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 11:09:42 GMT"}, {"version": "v3", "created": "Thu, 20 Apr 2017 09:04:59 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Chen", "Hubie", ""], ["Mengel", "Stefan", ""]]}, {"id": "1501.07209", "submitter": "Marco Voigt", "authors": "Marco Voigt and Christoph Weidenbach", "title": "Bernays-Schoenfinkel-Ramsey with Simple Bounds is NEXPTIME-complete", "comments": "This is a revised version of the initial arXiv submission. Although\n  submitted in 2020, the last update of its contents dates back to June 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order predicate logic extended with linear arithmetic is undecidable,\nin general. We show that the Bernays-Sch\\\"onfinkel-Ramsey (BSR) fragment\nextended with linear arithmetic restricted to simple bounds (SB) is decidable\nthrough finite ground instantiation. The identified ground instances can be\nemployed to restrict the search space of existing automated reasoning\nprocedures for BSR(SB). Satisfiability of BSR(SB) compared to BSR remains\nNEXPTIME-complete. The decidability result is almost tight because BSR is\nundecidable if extended with linear difference inequations, simple additive\ninequations, quotient inequations and multiplicative inequations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 17:41:07 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 14:04:26 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Voigt", "Marco", ""], ["Weidenbach", "Christoph", ""]]}, {"id": "1501.07539", "submitter": "David Richerby", "authors": "Andreas G\\\"obel, Leslie Ann Goldberg and David Richerby", "title": "Counting Homomorphisms to Square-Free Graphs, Modulo 2", "comments": "32 pages, 8 figures (v4 adds Corollary 3.7 to fix a bug in the proof\n  of Lemma 5.15; v3 is a minor update; v2 corrects a typo: we wrote \"dist\"\n  instead of \"dom\" for the domain of a function in v1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem HomsTo$H$ of counting, modulo 2, the homomorphisms from\nan input graph to a fixed undirected graph $H$. A characteristic feature of\nmodular counting is that cancellations make wider classes of instances\ntractable than is the case for exact (non-modular) counting, so subtle\ndichotomy theorems can arise. We show the following dichotomy: for any $H$ that\ncontains no 4-cycles, HomsTo$H$ is either in polynomial time or is $\\oplus\nP$-complete. This confirms a conjecture of Faben and Jerrum that was previously\nonly known to hold for trees and for a restricted class of treewidth-2 graphs\ncalled cactus graphs. We confirm the conjecture for a rich class of graphs\nincluding graphs of unbounded treewidth. In particular, we focus on square-free\ngraphs, which are graphs without 4-cycles. These graphs arise frequently in\ncombinatorics, for example in connection with the strong perfect graph theorem\nand in certain graph algorithms. Previous dichotomy theorems required the graph\nto be tree-like so that tree-like decompositions could be exploited in the\nproof. We prove the conjecture for a much richer class of graphs by adopting a\nmuch more general approach.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 18:35:52 GMT"}, {"version": "v2", "created": "Sun, 1 Feb 2015 16:14:19 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2015 12:54:40 GMT"}, {"version": "v4", "created": "Wed, 26 Aug 2015 18:13:01 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["G\u00f6bel", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Richerby", "David", ""]]}, {"id": "1501.07814", "submitter": "Daniel Karapetyan Dr", "authors": "Jason Crampton and Gregory Z. Gutin and Daniel Karapetyan", "title": "Valued Workflow Satisfiability Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A workflow is a collection of steps that must be executed in some specific\norder to achieve an objective. A computerised workflow management system may\nenforce authorisation policies and constraints, thereby restricting which users\ncan perform particular steps in a workflow. The existence of policies and\nconstraints may mean that a workflow is unsatisfiable, in the sense that it is\nimpossible to find an authorised user for each step in the workflow and satisfy\nall constraints. In this paper, we consider the problem of finding the \"least\nbad\" assignment of users to workflow steps by assigning a weight to each policy\nand constraint violation. To this end, we introduce a framework for associating\ncosts with the violation of workflow policies and constraints and define the\n\\emph{valued workflow satisfiability problem} (Valued WSP), whose solution is\nan assignment of steps to users of minimum cost. We establish the computational\ncomplexity of Valued WSP with user-independent constraints and show that it is\nfixed-parameter tractable. We then describe an algorithm for solving Valued WSP\nwith user-independent constraints and evaluate its performance, comparing it to\nthat of an off-the-shelf mixed integer programming package.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2015 15:47:06 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Crampton", "Jason", ""], ["Gutin", "Gregory Z.", ""], ["Karapetyan", "Daniel", ""]]}]