[{"id": "1402.0052", "submitter": "David Gamarnik", "authors": "David Gamarnik, Madhu Sudan", "title": "Performance of the Survey Propagation-guided decimation algorithm for\n  the random NAE-K-SAT problem", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cond-mat.stat-mech cs.AI cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Survey Propagation-guided decimation algorithm fails to find\nsatisfying assignments on random instances of the \"Not-All-Equal-$K$-SAT\"\nproblem if the number of message passing iterations is bounded by a constant\nindependent of the size of the instance and the clause-to-variable ratio is\nabove $(1+o_K(1)){2^{K-1}\\over K}\\log^2 K$ for sufficiently large $K$. Our\nanalysis in fact applies to a broad class of algorithms described as\n\"sequential local algorithms\". Such algorithms iteratively set variables based\non some local information and then recurse on the reduced instance. Survey\nPropagation-guided as well as Belief Propagation-guided decimation algorithms -\ntwo widely studied message passing based algorithms, fall under this category\nof algorithms provided the number of message passing iterations is bounded by a\nconstant. Another well-known algorithm falling into this category is the Unit\nClause algorithm. Our work constitutes the first rigorous analysis of the\nperformance of the SP-guided decimation algorithm.\n  The approach underlying our paper is based on an intricate geometry of the\nsolution space of random NAE-$K$-SAT problem. We show that above the\n$(1+o_K(1)){2^{K-1}\\over K}\\log^2 K$ threshold, the overlap structure of\n$m$-tuples of satisfying assignments exhibit a certain clustering behavior\nexpressed in the form of constraints on distances between the $m$ assignments,\nfor appropriately chosen $m$. We further show that if a sequential local\nalgorithm succeeds in finding a satisfying assignment with probability bounded\naway from zero, then one can construct an $m$-tuple of solutions violating\nthese constraints, thus leading to a contradiction. Along with (citation), this\nresult is the first work which directly links the clustering property of random\nconstraint satisfaction problems to the computational hardness of finding\nsatisfying assignments.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 05:05:12 GMT"}, {"version": "v2", "created": "Tue, 30 Sep 2014 02:07:36 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Gamarnik", "David", ""], ["Sudan", "Madhu", ""]]}, {"id": "1402.0054", "submitter": "Amir Abboud", "authors": "Amir Abboud and Virginia Vassilevska Williams", "title": "Popular conjectures imply strong lower bounds for dynamic problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several well-studied problems in dynamic algorithms and prove\nthat sufficient progress on any of them would imply a breakthrough on one of\nfive major open problems in the theory of algorithms:\n  1. Is the 3SUM problem on $n$ numbers in $O(n^{2-\\epsilon})$ time for some\n$\\epsilon>0$?\n  2. Can one determine the satisfiability of a CNF formula on $n$ variables in\n$O((2-\\epsilon)^n poly n)$ time for some $\\epsilon>0$?\n  3. Is the All Pairs Shortest Paths problem for graphs on $n$ vertices in\n$O(n^{3-\\epsilon})$ time for some $\\epsilon>0$?\n  4. Is there a linear time algorithm that detects whether a given graph\ncontains a triangle?\n  5. Is there an $O(n^{3-\\epsilon})$ time combinatorial algorithm for $n\\times\nn$ Boolean matrix multiplication?\n  The problems we consider include dynamic versions of bipartite perfect\nmatching, bipartite maximum weight matching, single source reachability, single\nsource shortest paths, strong connectivity, subgraph connectivity, diameter\napproximation and some nongraph problems such as Pagh's problem defined in a\nrecent paper by Patrascu [STOC 2010].\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 06:20:09 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Abboud", "Amir", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1402.0146", "submitter": "Zhengjun Cao", "authors": "Zhengjun Cao and Lihua Liu", "title": "Remarks on AKS Primality Testing Algorithm and A Flaw in the Definition\n  of P", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We remark that the AKS primality testing algorithm [Annals of Mathematics 160\n(2), 2004] needs about 1,000,000,000 G (gigabyte) storage space for a number of\n1024 bits. The requirement is very hard to meet. The complexity class P which\ncontains all decision problems that can be solved by a deterministic Turing\nmachine using a polynomial amount of computation time, is generally believed to\nbe ``easy\". We point out that the time is estimated only in terms of the amount\nof arithmetic operations. It does not comprise the time for reading and writing\ndata on the tape in a Turing machine. The flaw makes some deterministic\npolynomial time algorithms impractical, and humbles the importance of P=NP\nquestion.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2014 03:12:24 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Cao", "Zhengjun", ""], ["Liu", "Lihua", ""]]}, {"id": "1402.0471", "submitter": "David Auger", "authors": "David Auger (MAGMAT), Pierre COUCHENEY (PRISM), Yann Strozecki (PRISM)", "title": "Finding Optimal Strategies of Almost Acyclic Simple Stochatic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal value computation for turned-based stochastic games with\nreachability objectives, also known as simple stochastic games, is one of the\nfew problems in $NP \\cap coNP$ which are not known to be in $P$. However, there\nare some cases where these games can be easily solved, as for instance when the\nunderlying graph is acyclic. In this work, we try to extend this tractability\nto several classes of games that can be thought as \"almost\" acyclic. We give\nsome fixed-parameter tractable or polynomial algorithms in terms of different\nparameters such as the number of cycles or the size of the minimal feedback\nvertex set.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 19:24:12 GMT"}], "update_date": "2014-08-10", "authors_parsed": [["Auger", "David", "", "MAGMAT"], ["COUCHENEY", "Pierre", "", "PRISM"], ["Strozecki", "Yann", "", "PRISM"]]}, {"id": "1402.0532", "submitter": "Alican Bozkurt", "authors": "Alican Bozkurt, Musa Tun\\c{c} Arslan, Rasim Akin Sevimli, Cem Emre\n  Akbas, A. Enis \\c{C}etin", "title": "Approximate Computation of DFT without Performing Any Multiplications:\n  Applications to Radar Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical problems it is not necessary to compute the DFT in a\nperfect manner including some radar problems. In this article a new\nmultiplication free algorithm for approximate computation of the DFT is\nintroduced. All multiplications $(a\\times b)$ in DFT are replaced by an\noperator which computes $sign(a\\times b)(|a|+|b|)$. The new transform is\nespecially useful when the signal processing algorithm requires correlations.\nAmbiguity function in radar signal processing requires high number of\nmultiplications to compute the correlations. This new additive operator is used\nto decrease the number of multiplications. Simulation examples involving\npassive radars are presented.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 21:59:49 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Bozkurt", "Alican", ""], ["Arslan", "Musa Tun\u00e7", ""], ["Sevimli", "Rasim Akin", ""], ["Akbas", "Cem Emre", ""], ["\u00c7etin", "A. Enis", ""]]}, {"id": "1402.0858", "submitter": "Peter Franek", "authors": "Peter Franek, Marek Krcal", "title": "Robust Satisfiability of Systems of Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of \\emph{robust satisfiability} of systems of nonlinear\nequations, namely, whether for a given continuous function\n$f:\\,K\\to\\mathbb{R}^n$ on a~finite simplicial complex $K$ and $\\alpha>0$, it\nholds that each function $g:\\,K\\to\\mathbb{R}^n$ such that $\\|g-f\\|_\\infty \\leq\n\\alpha$, has a root in $K$. Via a reduction to the extension problem of maps\ninto a sphere, we particularly show that this problem is decidable in\npolynomial time for every fixed $n$, assuming $\\dim K \\le 2n-3$. This is a\nsubstantial extension of previous computational applications of\n\\emph{topological degree} and related concepts in numerical and interval\nanalysis. Via a reverse reduction we prove that the problem is undecidable when\n$\\dim K\\ge 2n-2$, where the threshold comes from the \\emph{stable range} in\nhomotopy theory. For the lucidity of our exposition, we focus on the setting\nwhen $f$ is piecewise linear. Such functions can approximate general continuous\nfunctions, and thus we get approximation schemes and undecidability of the\nrobust satisfiability in other possible settings.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 20:51:37 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Franek", "Peter", ""], ["Krcal", "Marek", ""]]}, {"id": "1402.1429", "submitter": "Zheng Qu", "authors": "Stephane Gaubert and Zheng Qu", "title": "Checking the strict positivity of Kraus maps is NP-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT math.OA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Basic properties in Perron-Frobenius theory are strict positivity,\nprimitivityand irreducibility. Whereas for nonnegative matrices, these\nproperties are equivalent to elementary graph properties which can be checked\nin polynomial time, we show that for Kraus maps- the noncommutative\ngeneralization of stochastic matrices - checking strict positivity (whether the\nmap sends the cone to its interior) is NP-hard. The proof proceeds by reducing\nto the latter problem the existence of a non-zero solution of a special system\nof bilinear equations. The complexity of irreducibility and primitivity is also\ndiscussed in the noncommutative setting.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 17:38:57 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Gaubert", "Stephane", ""], ["Qu", "Zheng", ""]]}, {"id": "1402.1810", "submitter": "Martin F\\\"urer", "authors": "Martin F\\\"urer", "title": "A Natural Generalization of Bounded Tree-Width and Bounded Clique-Width", "comments": "To appear in the proceedings of Latin 2014. Springer LNCS 8392", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a new width parameter, the fusion-width of a graph. It is a\nnatural generalization of the tree-width, yet strong enough that not only\ngraphs of bounded tree-width, but also graphs of bounded clique-width,\ntrivially have bounded fusion-width. In particular, there is no exponential\ngrowth between tree-width and fusion-width, as is the case between tree-width\nand clique-width. The new parameter gives a good intuition about the\nrelationship between tree-width and clique-width.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2014 01:55:12 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["F\u00fcrer", "Martin", ""]]}, {"id": "1402.1811", "submitter": "Martin F\\\"urer", "authors": "Martin F\\\"urer", "title": "How Fast Can We Multiply Large Integers on an Actual Computer?", "comments": "To appear in the proceedings of Latin 2014. Springer LNCS 8392", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide two complexity measures that can be used to measure the running\ntime of algorithms to compute multiplications of long integers. The random\naccess machine with unit or logarithmic cost is not adequate for measuring the\ncomplexity of a task like multiplication of long integers. The Turing machine\nis more useful here, but fails to take into account the multiplication\ninstruction for short integers, which is available on physical computing\ndevices. An interesting outcome is that the proposed refined complexity\nmeasures do not rank the well known multiplication algorithms the same way as\nthe Turing machine model.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2014 02:47:25 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["F\u00fcrer", "Martin", ""]]}, {"id": "1402.1918", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang, Martin J. Wainwright, Michael I. Jordan", "title": "Lower bounds on the performance of polynomial-time algorithms for sparse\n  linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under a standard assumption in complexity theory (NP not in P/poly), we\ndemonstrate a gap between the minimax prediction risk for sparse linear\nregression that can be achieved by polynomial-time algorithms, and that\nachieved by optimal algorithms. In particular, when the design matrix is\nill-conditioned, the minimax prediction loss achievable by polynomial-time\nalgorithms can be substantially greater than that of an optimal algorithm. This\nresult is the first known gap between polynomial and optimal algorithms for\nsparse linear regression, and does not depend on conjectures in average-case\ncomplexity.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 06:02:29 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 05:41:06 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Zhang", "Yuchen", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1402.2175", "submitter": "Yuichi Yoshida", "authors": "Yuichi Yoshida", "title": "A Characterization of Locally Testable Affine-Invariant Properties via\n  Decomposition Theorems", "comments": "27 pages, appearing in STOC 2014. arXiv admin note: text overlap with\n  arXiv:1306.0649, arXiv:1212.3849 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathcal{P}$ be a property of function $\\mathbb{F}_p^n \\to \\{0,1\\}$ for\na fixed prime $p$. An algorithm is called a tester for $\\mathcal{P}$ if, given\na query access to the input function $f$, with high probability, it accepts\nwhen $f$ satisfies $\\mathcal{P}$ and rejects when $f$ is \"far\" from satisfying\n$\\mathcal{P}$. In this paper, we give a characterization of affine-invariant\nproperties that are (two-sided error) testable with a constant number of\nqueries. The characterization is stated in terms of decomposition theorems,\nwhich roughly claim that any function can be decomposed into a structured part\nthat is a function of a constant number of polynomials, and a pseudo-random\npart whose Gowers norm is small. We first give an algorithm that tests whether\nthe structured part of the input function has a specific form. Then we show\nthat an affine-invariant property is testable with a constant number of queries\nif and only if it can be reduced to the problem of testing whether the\nstructured part of the input function is close to one of a constant number of\ncandidates.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 15:03:42 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Yoshida", "Yuichi", ""]]}, {"id": "1402.2331", "submitter": "Prasad Raghavendra", "authors": "Moritz Hardt, Raghu Meka, Prasad Raghavendra, and Benjamin Weitz", "title": "Computational Limits for Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Completion is the problem of recovering an unknown real-valued\nlow-rank matrix from a subsample of its entries. Important recent results show\nthat the problem can be solved efficiently under the assumption that the\nunknown matrix is incoherent and the subsample is drawn uniformly at random.\nAre these assumptions necessary?\n  It is well known that Matrix Completion in its full generality is NP-hard.\nHowever, little is known if make additional assumptions such as incoherence and\npermit the algorithm to output a matrix of slightly higher rank. In this paper\nwe prove that Matrix Completion remains computationally intractable even if the\nunknown matrix has rank $4$ but we are allowed to output any constant rank\nmatrix, and even if additionally we assume that the unknown matrix is\nincoherent and are shown $90%$ of the entries. This result relies on the\nconjectured hardness of the $4$-Coloring problem. We also consider the positive\nsemidefinite Matrix Completion problem. Here we show a similar hardness result\nunder the standard assumption that $\\mathrm{P}\\ne \\mathrm{NP}.$\n  Our results greatly narrow the gap between existing feasibility results and\ncomputational lower bounds. In particular, we believe that our results give the\nfirst complexity-theoretic justification for why distributional assumptions are\nneeded beyond the incoherence assumption in order to obtain positive results.\nOn the technical side, we contribute several new ideas on how to encode hard\ncombinatorial problems in low-rank optimization problems. We hope that these\ntechniques will be helpful in further understanding the computational limits of\nMatrix Completion and related problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 23:43:11 GMT"}, {"version": "v2", "created": "Thu, 10 Apr 2014 07:30:37 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Hardt", "Moritz", ""], ["Meka", "Raghu", ""], ["Raghavendra", "Prasad", ""], ["Weitz", "Benjamin", ""]]}, {"id": "1402.2371", "submitter": "Zach Teitler", "authors": "Grigoriy Blekherman, Zach Teitler", "title": "On Maximum, Typical and Generic Ranks", "comments": "v1: 8pp. v2: 9pp. Corrected gap in Theorem 6, other minor\n  corrections. v3: 10pp. Minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for several notions of rank including tensor rank, Waring rank,\nand generalized rank with respect to a projective variety, the maximum value of\nrank is at most twice the generic rank. We show that over the real numbers, the\nmaximum value of the real rank is at most twice the smallest typical rank,\nwhich is equal to the (complex) generic rank.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 04:51:48 GMT"}, {"version": "v2", "created": "Tue, 4 Mar 2014 05:42:56 GMT"}, {"version": "v3", "created": "Thu, 24 Jul 2014 23:02:25 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Blekherman", "Grigoriy", ""], ["Teitler", "Zach", ""]]}, {"id": "1402.2843", "submitter": "Edouard Bonnet", "authors": "Edouard Bonnet and Vangelis Th. Paschos", "title": "Sparsification and subexponential approximation", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance sparsification is well-known in the world of exact computation since\nit is very closely linked to the Exponential Time Hypothesis. In this paper, we\nextend the concept of sparsification in order to capture subexponential time\napproximation. We develop a new tool for inapproximability, called\napproximation preserving sparsification and use it in order to get strong\ninapproximability results in subexponential time for several fundamental\noptimization problems as Max Independent Set, Min Dominating Set, Min Feedback\nVertex Set, and Min Set Cover.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 15:07:50 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2014 17:35:33 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Bonnet", "Edouard", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "1402.3449", "submitter": "Masaki Nakanishi", "authors": "Masaki Nakanishi", "title": "Quantum Pushdown Automata with a Garbage Tape", "comments": "v3 Proofs in Section 4 were revised. Introduction was revised.\n  Theorem 1 was removed since Theorem 2, which is Theorem 1 in the new version,\n  is the generalization of it. Several other minor revisions were made. v4 The\n  well-formedness conditions were added. Several other minor revisions were\n  made", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several kinds of quantum pushdown automaton models have been proposed, and\ntheir computational power is investigated intensively. However, for some\nquantum pushdown automaton models, it is not known whether quantum models are\nat least as powerful as classical counterparts or not. This is due to the\nreversibility restriction. In this paper, we introduce a new quantum pushdown\nautomaton model that has a garbage tape. This model can overcome the\nreversibility restriction by exploiting the garbage tape to store popped\nsymbols. We show that the proposed model can simulate any quantum pushdown\nautomaton with a classical stack as well as any probabilistic pushdown\nautomaton. We also show that our model can solve a certain promise problem\nexactly while deterministic pushdown automata cannot. These results imply that\nour model is strictly more powerful than classical counterparts in the setting\nof exact, one-sided error and non-deterministic computation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 12:31:15 GMT"}, {"version": "v2", "created": "Sun, 27 Apr 2014 09:32:16 GMT"}, {"version": "v3", "created": "Wed, 13 Aug 2014 08:29:39 GMT"}, {"version": "v4", "created": "Thu, 2 Oct 2014 06:42:29 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Nakanishi", "Masaki", ""]]}, {"id": "1402.3450", "submitter": "Ioannis Caragiannis", "authors": "Ioannis Caragiannis and Angelo Fanelli and Nick Gravin", "title": "Short sequences of improvement moves lead to approximate equilibria in\n  constraint satisfaction games", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that computes approximate pure Nash equilibria in a\nbroad class of constraint satisfaction games that generalize the well-known cut\nand party affiliation games. Our results improve previous ones by Bhalgat et\nal.~(EC 10) in terms of the obtained approximation guarantee. More importantly,\nour algorithm identifies a polynomially-long sequence of improvement moves from\nany initial state to an approximate equilibrium in these games. The existence\nof such short sequences is an interesting structural property which, to the\nbest of our knowledge, was not known before. Our techniques adapt and extend\nour previous work for congestion games (FOCS 11) but the current analysis is\nconsiderably simpler.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 12:31:36 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Caragiannis", "Ioannis", ""], ["Fanelli", "Angelo", ""], ["Gravin", "Nick", ""]]}, {"id": "1402.3452", "submitter": "Markus Lohrey", "authors": "Markus Lohrey and Manfred Schmidt-Schauss", "title": "Processing Succinct Matrices and Vectors", "comments": "An extended abstract of this paper will appear in the Proceedings of\n  CSR 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of algorithmic problems for matrices that are\nrepresented by multi-terminal decision diagrams (MTDD). These are a variant of\nordered decision diagrams, where the terminal nodes are labeled with arbitrary\nelements of a semiring (instead of 0 and 1). A simple example shows that the\nproduct of two MTDD-represented matrices cannot be represented by an MTDD of\npolynomial size. To overcome this deficiency, we extended MTDDs to MTDD_+ by\nallowing componentwise symbolic addition of variables (of the same dimension)\nin rules. It is shown that accessing an entry, equality checking, matrix\nmultiplication, and other basic matrix operations can be solved in polynomial\ntime for MTDD_+-represented matrices. On the other hand, testing whether the\ndeterminant of a MTDD-represented matrix vanishes PSPACE$-complete, and the\nsame problem is NP-complete for MTDD_+-represented diagonal matrices. Computing\na specific entry in a product of MTDD-represented matrices is #P-complete.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 12:44:47 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Lohrey", "Markus", ""], ["Schmidt-Schauss", "Manfred", ""]]}, {"id": "1402.3543", "submitter": "Parikshit Gopalan", "authors": "Parikshit Gopalan and Amir Yehudayoff", "title": "Inequalities and tail bounds for elementary symmetric polynomial with\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the extent of independence needed to approximate the product of\nbounded random variables in expectation, a natural question that has\napplications in pseudorandomness and min-wise independent hashing.\n  For random variables whose absolute value is bounded by $1$, we give an error\nbound of the form $\\sigma^{\\Omega(k)}$ where $k$ is the amount of independence\nand $\\sigma^2$ is the total variance of the sum. Previously known bounds only\napplied in more restricted settings, and were quanitively weaker. We use this\nto give a simpler and more modular analysis of a construction of min-wise\nindependent hash functions and pseudorandom generators for combinatorial\nrectangles due to Gopalan et al., which also slightly improves their\nseed-length.\n  Our proof relies on a new analytic inequality for the elementary symmetric\npolynomials $S_k(x)$ for $x \\in \\mathbb{R}^n$ which we believe to be of\nindependent interest. We show that if $|S_k(x)|,|S_{k+1}(x)|$ are small\nrelative to $|S_{k-1}(x)|$ for some $k>0$ then $|S_\\ell(x)|$ is also small for\nall $\\ell > k$. From these, we derive tail bounds for the elementary symmetric\npolynomials when the inputs are only $k$-wise independent.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 18:17:42 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 21:33:14 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Gopalan", "Parikshit", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1402.4183", "submitter": "Zizhuo Wang", "authors": "Dongdong Ge, Zizhuo Wang, Lai Wei, Jiawei Zhang", "title": "An Improved Algorithm for Fixed-Hub Single Allocation Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the fixed-hub single allocation problem (FHSAP). In this\nproblem, a network consists of hub nodes and terminal nodes. Hubs are fixed and\nfully connected; each terminal node is connected to a single hub which routes\nall its traffic. The goal is to minimize the cost of routing the traffic in the\nnetwork. In this paper, we propose a linear programming (LP)-based rounding\nalgorithm. The algorithm is based on two ideas. First, we modify the LP\nrelaxation formulation introduced in Ernst and Krishnamoorthy (1996, 1999) by\nincorporating a set of validity constraints. Then, after obtaining a fractional\nsolution to the LP relaxation, we make use of a geometric rounding algorithm to\nobtain an integral solution. We show that by incorporating the validity\nconstraints, the strengthened LP often provides much tighter upper bounds than\nthe previous methods with a little more computational effort, and the solution\nobtained often has a much smaller gap with the optimal solution. We also\nformulate a robust version of the FHSAP and show that it can guard against data\nuncertainty with little cost.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 23:42:50 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Ge", "Dongdong", ""], ["Wang", "Zizhuo", ""], ["Wei", "Lai", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1402.4312", "submitter": "Hartmut Klauck", "authors": "Hartmut Klauck and Supartha Podder", "title": "Two Results about Quantum Messages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show two results about the relationship between quantum and classical\nmessages. Our first contribution is to show how to replace a quantum message in\na one-way communication protocol by a deterministic message, establishing that\nfor all partial Boolean functions $f:\\{0,1\\}^n\\times\\{0,1\\}^m\\to\\{0,1\\}$ we\nhave $D^{A\\to B}(f)\\leq O(Q^{A\\to B,*}(f)\\cdot m)$. This bound was previously\nknown for total functions, while for partial functions this improves on results\nby Aaronson, in which either a log-factor on the right hand is present, or the\nleft hand side is $R^{A\\to B}(f)$, and in which also no entanglement is\nallowed.\n  In our second contribution we investigate the power of quantum proofs over\nclassical proofs. We give the first example of a scenario, where quantum proofs\nlead to exponential savings in computing a Boolean function. The previously\nonly known separation between the power of quantum and classical proofs is in a\nsetting where the input is also quantum.\n  We exhibit a partial Boolean function $f$, such that there is a one-way\nquantum communication protocol receiving a quantum proof (i.e., a protocol of\ntype QMA) that has cost $O(\\log n)$ for $f$, whereas every one-way quantum\nprotocol for $f$ receiving a classical proof (protocol of type QCMA) requires\ncommunication $\\Omega(\\sqrt n/\\log n)$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 12:27:58 GMT"}, {"version": "v2", "created": "Wed, 16 Apr 2014 08:29:19 GMT"}], "update_date": "2014-04-17", "authors_parsed": [["Klauck", "Hartmut", ""], ["Podder", "Supartha", ""]]}, {"id": "1402.4338", "submitter": "Gabriel Istrate", "authors": "Gabriel Istrate and Adrian Cr\\u{a}ciun", "title": "Proof Complexity and the Kneser-Lov\\'asz Theorem", "comments": null, "journal-ref": "Proceedings of the 17th International Conference on Theory and\n  Applications of Satisfiability Testing (SAT'14), vol. 8561, 2014", "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the proof complexity of a class of propositional formulas\nexpressing a combinatorial principle known as the Kneser-Lov\\'{a}sz Theorem.\nThis is a family of propositional tautologies, indexed by an nonnegative\ninteger parameter $k$ that generalizes the Pigeonhole Principle (obtained for\n$k=1$).\n  We show, for all fixed $k$, $2^{\\Omega(n)}$ lower bounds on resolution\ncomplexity and exponential lower bounds for bounded depth Frege proofs. These\nresults hold even for the more restricted class of formulas encoding\nSchrijver's strenghtening of the Kneser-Lov\\'{a}sz Theorem. On the other hand\nfor the cases $k=2,3$ (for which combinatorial proofs of the Kneser-Lov\\'{a}sz\nTheorem are known) we give polynomial size Frege ($k=2$), respectively extended\nFrege ($k=3$) proofs. The paper concludes with a brief announcement of the\nresults (presented in subsequent work) on the proof complexity of the general\ncase of the Kneser-Lov\\'{a}sz theorem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 13:58:07 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 14:52:06 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Istrate", "Gabriel", ""], ["Cr\u0103ciun", "Adrian", ""]]}, {"id": "1402.4346", "submitter": "Chihao Zhang", "authors": "Jingcheng Liu, Pinyan Lu and Chihao Zhang", "title": "The Complexity of Ferromagnetic Two-spin Systems with External Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximability of computing the partition function for\nferromagnetic two-state spin systems. The remarkable algorithm by Jerrum and\nSinclair showed that there is a fully polynomial-time randomized approximation\nscheme (FPRAS) for the special ferromagnetic Ising model with any given uniform\nexternal field. Later, Goldberg and Jerrum proved that it is #BIS-hard for\nIsing model if we allow inconsistent external fields on different nodes. In\ncontrast to these two results, we prove that for any ferromagnetic two-state\nspin systems except the Ising model, there exists a threshold for external\nfields beyond which the problem is #BIS-hard, even if the external field is\nuniform.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 14:20:54 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Liu", "Jingcheng", ""], ["Lu", "Pinyan", ""], ["Zhang", "Chihao", ""]]}, {"id": "1402.4376", "submitter": "Jeremy Kun", "authors": "Jeremy Kun and Lev Reyzin", "title": "On Coloring Resilient Graphs", "comments": "Appearing in MFCS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new notion of resilience for constraint satisfaction problems,\nwith the goal of more precisely determining the boundary between NP-hardness\nand the existence of efficient algorithms for resilient instances. In\nparticular, we study $r$-resiliently $k$-colorable graphs, which are those\n$k$-colorable graphs that remain $k$-colorable even after the addition of any\n$r$ new edges. We prove lower bounds on the NP-hardness of coloring resiliently\ncolorable graphs, and provide an algorithm that colors sufficiently resilient\ngraphs. We also analyze the corresponding notion of resilience for $k$-SAT.\nThis notion of resilience suggests an array of open questions for graph\ncoloring and other combinatorial problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 15:50:15 GMT"}, {"version": "v2", "created": "Wed, 11 Jun 2014 22:20:46 GMT"}], "update_date": "2014-06-13", "authors_parsed": [["Kun", "Jeremy", ""], ["Reyzin", "Lev", ""]]}, {"id": "1402.4422", "submitter": "L\\'aszl\\'o Varga", "authors": "L\\'aszl\\'o Varga", "title": "Combinatorial Nullstellensatz modulo prime powers and the Parity\n  Argument", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new generalizations of Olson's theorem and of a consequence of\nAlon's Combinatorial Nullstellensatz. These enable us to extend some of their\ncombinatorial applications with conditions modulo primes to conditions modulo\nprime powers. We analyze computational search problems corresponding to these\nkinds of combinatorial questions and we prove that the problem of finding\ndegree-constrained subgraphs modulo $2^d$ such as $2^d$-divisible subgraphs and\nthe search problem corresponding to the Combinatorial Nullstellensatz over\n$\\mathbb{F}_2$ belong to the complexity class Polynomial Parity Argument (PPA).\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 18:01:15 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Varga", "L\u00e1szl\u00f3", ""]]}, {"id": "1402.4515", "submitter": "Trent Rogers", "authors": "Jacob Hendricks, Matthew J. Patitz, Trent A. Rogers, and Scott M.\n  Summers", "title": "The Power of Duples (in Self-Assembly): It's Not So Hip To Be Square", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we define the Dupled abstract Tile Assembly Model (DaTAM),\nwhich is a slight extension to the abstract Tile Assembly Model (aTAM) that\nallows for not only the standard square tiles, but also \"duple\" tiles which are\nrectangles pre-formed by the joining of two square tiles. We show that the\naddition of duples allows for powerful behaviors of self-assembling systems at\ntemperature 1, meaning systems which exclude the requirement of cooperative\nbinding by tiles (i.e., the requirement that a tile must be able to bind to at\nleast 2 tiles in an existing assembly if it is to attach). Cooperative binding\nis conjectured to be required in the standard aTAM for Turing universal\ncomputation and the efficient self-assembly of shapes, but we show that in the\nDaTAM these behaviors can in fact be exhibited at temperature 1. We then show\nthat the DaTAM doesn't provide asymptotic improvements over the aTAM in its\nability to efficiently build thin rectangles. Finally, we present a series of\nresults which prove that the temperature-2 aTAM and temperature-1 DaTAM have\nmutually exclusive powers. That is, each is able to self-assemble shapes that\nthe other can't, and each has systems which cannot be simulated by the other.\nBeyond being of purely theoretical interest, these results have practical\nmotivation as duples have already proven to be useful in laboratory\nimplementations of DNA-based tiles.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 22:23:27 GMT"}, {"version": "v2", "created": "Fri, 7 Mar 2014 00:52:37 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["Hendricks", "Jacob", ""], ["Patitz", "Matthew J.", ""], ["Rogers", "Trent A.", ""], ["Summers", "Scott M.", ""]]}, {"id": "1402.4642", "submitter": "Oleg Verbitsky", "authors": "Johannes K\\\"obler, Sebastian Kuhnert, Oleg Verbitsky", "title": "On the Isomorphism Problem for Helly Circular-Arc Graphs", "comments": "22 pages, 5 figures. Section 5 is revised in this version", "journal-ref": "Information and Computation 247 (2016), pp. 266-277", "doi": "10.1016/j.ic.2016.01.006", "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The isomorphism problem is known to be efficiently solvable for interval\ngraphs, while for the larger class of circular-arc graphs its complexity status\nstays open. We consider the intermediate class of intersection graphs for\nfamilies of circular arcs that satisfy the Helly property. We solve the\nisomorphism problem for this class in logarithmic space. If an input graph has\na Helly circular-arc model, our algorithm constructs it canonically, which\nmeans that the models constructed for isomorphic graphs are equal.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 12:32:59 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2015 11:52:11 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["K\u00f6bler", "Johannes", ""], ["Kuhnert", "Sebastian", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "1402.4718", "submitter": "Bart M. P. Jansen", "authors": "Bart M. P. Jansen", "title": "Turing Kernelization for Finding Long Paths and Cycles in Restricted\n  Graph Classes", "comments": "39 pages, 8 figures", "journal-ref": "J. Comput. Syst. Sci. vol 85 pages 18--37, 2017", "doi": "10.1016/j.jcss.2016.10.008", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NP-complete $k$-Path problem asks whether a given undirected graph has a\n(simple) path of length at least $k$. We prove that $k$-Path has\npolynomial-size Turing kernels when restricted to planar graphs, graphs of\nbounded degree, claw-free graphs, or to $K_{3,t}$-minor-free graphs for some\nconstant $t$. This means that there is an algorithm that, given a $k$-Path\ninstance $(G,k)$ belonging to one of these graph classes, computes its answer\nin polynomial time when given access to an oracle that solves $k$-Path\ninstances of size polynomial in $k$ in a single step. The difficulty of\n$k$-Path can therefore be confined to subinstances whose size is independent of\nthe total input size, but is bounded by a polynomial in the parameter $k$\nalone. These results contrast existing superpolynomial lower bounds for the\nsizes of traditional kernels for the $k$-Path problem on these graph classes:\nthere is no polynomial-time algorithm that reduces any instance $(G,k)$ to a\nsingle, equivalent instance $(G',k')$ of size polynomial in $k$ unless $NP\n\\subseteq coNP/poly$. The same positive and negative results apply to the\n$k$-Cycle problem, which asks for the existence of a cycle of length at least\n$k$. Our kernelization schemes are based on a new methodology called\nDecompose-Query-Reduce.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 16:26:30 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2016 09:51:07 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Jansen", "Bart M. P.", ""]]}, {"id": "1402.4926", "submitter": "Amer Mouawad", "authors": "Amer E. Mouawad, Naomi Nishimura, Venkatesh Raman, Sebastian Siebertz", "title": "Vertex Cover Reconfiguration and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Vertex Cover Reconfiguration (VCR) problem, given a graph $G$,\npositive integers $k$ and $\\ell$ and two vertex covers $S$ and $T$ of $G$ of\nsize at most $k$, we determine whether $S$ can be transformed into $T$ by a\nsequence of at most $\\ell$ vertex additions or removals such that every\noperation results in a vertex cover of size at most $k$. Motivated by results\nestablishing the W[1]-hardness of VCR when parameterized by $\\ell$, we\ndelineate the complexity of the problem restricted to various graph classes. In\nparticular, we show that VCR remains W[1]-hard on bipartite graphs, is NP-hard,\nbut fixed-parameter tractable on (regular) graphs of bounded degree and more\ngenerally on nowhere dense graphs and is solvable in polynomial time on trees\nand (with some additional restrictions) on cactus graphs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 08:24:29 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 16:00:28 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 19:02:07 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Mouawad", "Amer E.", ""], ["Nishimura", "Naomi", ""], ["Raman", "Venkatesh", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1402.5078", "submitter": "Kri\\v{s}j\\=anis Pr\\=usis", "authors": "Andris Ambainis and Kri\\v{s}j\\=anis Pr\\=usis", "title": "A Tight Lower Bound on Certificate Complexity in Terms of Block\n  Sensitivity and Sensitivity", "comments": "12 pages", "journal-ref": null, "doi": "10.1007/978-3-662-44465-8_4", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitivity, certificate complexity and block sensitivity are widely used\nBoolean function complexity measures. A longstanding open problem, proposed by\nNisan and Szegedy, is whether sensitivity and block sensitivity are\npolynomially related. Motivated by the constructions of functions which achieve\nthe largest known separations, we study the relation between 1-certificate\ncomplexity and 0-sensitivity and 0-block sensitivity.\n  Previously the best known lower bound was $C_1(f)\\geq \\frac{bs_0(f)}{2\ns_0(f)}$, achieved by Kenyon and Kutin. We improve this to $C_1(f)\\geq \\frac{3\nbs_0(f)}{2 s_0(f)}$. While this improvement is only by a constant factor, this\nis quite important, as it precludes achieving a superquadratic separation\nbetween $bs(f)$ and $s(f)$ by iterating functions which reach this bound. In\naddition, this bound is tight, as it matches the construction of Ambainis and\nSun up to an additive constant.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 17:16:23 GMT"}, {"version": "v2", "created": "Thu, 31 Jul 2014 11:55:55 GMT"}], "update_date": "2015-03-27", "authors_parsed": [["Ambainis", "Andris", ""], ["Pr\u016bsis", "Kri\u0161j\u0101nis", ""]]}, {"id": "1402.5164", "submitter": "Justin Thaler", "authors": "Varun Kanade and Justin Thaler", "title": "Distribution-Independent Reliable Learning", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several questions in the reliable agnostic learning framework of\nKalai et al. (2009), which captures learning tasks in which one type of error\nis costlier than others. A positive reliable classifier is one that makes no\nfalse positive errors. The goal in the positive reliable agnostic framework is\nto output a hypothesis with the following properties: (i) its false positive\nerror rate is at most $\\epsilon$, (ii) its false negative error rate is at most\n$\\epsilon$ more than that of the best positive reliable classifier from the\nclass. A closely related notion is fully reliable agnostic learning, which\nconsiders partial classifiers that are allowed to predict \"unknown\" on some\ninputs. The best fully reliable partial classifier is one that makes no errors\nand minimizes the probability of predicting \"unknown\", and the goal in fully\nreliable learning is to output a hypothesis that is almost as good as the best\nfully reliable partial classifier from a class.\n  For distribution-independent learning, the best known algorithms for PAC\nlearning typically utilize polynomial threshold representations, while the\nstate of the art agnostic learning algorithms use point-wise polynomial\napproximations. We show that one-sided polynomial approximations, an\nintermediate notion between polynomial threshold representations and point-wise\npolynomial approximations, suffice for learning in the reliable agnostic\nsettings. We then show that majorities can be fully reliably learned and\ndisjunctions of majorities can be positive reliably learned, through\nconstructions of appropriate one-sided polynomial approximations. Our fully\nreliable algorithm for majorities provides the first evidence that fully\nreliable learning may be strictly easier than agnostic learning. Our algorithms\nalso satisfy strong attribute-efficiency properties, and provide smooth\ntradeoffs between sample complexity and running time.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 22:41:39 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Kanade", "Varun", ""], ["Thaler", "Justin", ""]]}, {"id": "1402.5311", "submitter": "Eldar Aharoni", "authors": "Eldar Aharoni and Eyal Kushilevitz", "title": "On the Power of Multiplexing in Number-on-the-Forehead Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the direct-sum problem for $k$-party ``Number On the Forehead''\n(NOF) deterministic communication complexity. We prove several positive\nresults, showing that the complexity of computing a function $f$ in this model,\non $\\ell$ instances, may be significantly cheaper than $\\ell$ times the\ncomplexity of computing $f$ on a single instance. Quite surprisingly, we show\nthat this is the case for ``most'' (boolean, $k$-argument) functions. We then\nformalize two-types of sufficient conditions on a NOF protocol $Q$, for a\nsingle instance, each of which guarantees some communication complexity savings\nwhen appropriately extending $Q$ to work on $\\ell$ instances. One such\ncondition refers to what each party needs to know about inputs of the other\nparties, and the other condition, additionally, refers to the communication\npattern that the single-instance protocol $Q$ uses. In both cases, the tool\nthat we use is ``multiplexing'': we combine messages sent in parallel\nexecutions of protocols for a single instance, into a single message for the\nmulti-instance (direct-sum) case, by xoring them with each other.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 14:53:11 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Aharoni", "Eldar", ""], ["Kushilevitz", "Eyal", ""]]}, {"id": "1402.5449", "submitter": "Igor Shparlinski", "authors": "Joachim von zur Gathen and Igor E. Shparlinski", "title": "Circulant graphs and GCD and LCM of Subsets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two sets $A$ and $B$ of integers, we consider the problem of finding a\nset $S \\subseteq A$ of the smallest possible cardinality such the greatest\ncommon divisor of the elements of $S \\cup B$ equals that of those of $A \\cup\nB$. The particular cases of $B = \\emptyset$ and $\\#B = 1$ are of special\ninterest and have some links with graph theory. We also consider the\ncorresponding question for the least common multiple of the elements. We\nestablish NP-completeness and approximation results for these problems by\nrelating them to the Minimum Cover Problem.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 23:34:31 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Gathen", "Joachim von zur", ""], ["Shparlinski", "Igor E.", ""]]}, {"id": "1402.5687", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic", "title": "Monoidal computer II: Normal complexity by string diagrams", "comments": "11 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Monoidal Computer I, we introduced a categorical model of computation\nwhere the formal reasoning about computability was supported by the simple and\npopular diagrammatic language of string diagrams. In the present paper, we\nrefine and extend that model of computation to support a formal complexity\ntheory as well. This formalization brings to the foreground the concept of\nnormal complexity measures, which allow decompositions akin to Kleene's normal\nform. Such measures turn out to be just those where evaluating the complexity\nof a program does not require substantially more resources than evaluating the\nprogram itself. The usual time and space complexity are thus normal measures,\nwhereas the average and the randomized complexity measures are not. While the\nmeasures that are not normal provide important design time information about\nalgorithms, and for theoretical analyses, normal measures can also be used at\nrun time, as practical tools of computation, e.g. to set the bounds for\nhypothesis testing, inductive inference and algorithmic learning.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 22:59:30 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Pavlovic", "Dusko", ""]]}, {"id": "1402.5857", "submitter": "Kitty Meeks", "authors": "Kitty Meeks", "title": "The challenges of unbounded treewidth in parameterised subgraph counting\n  problems", "comments": "Survey part of paper substantially extended and reorganised; some\n  additional figures added to illustrate proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterised subgraph counting problems are the most thoroughly studied\ntopic in the theory of parameterised counting, and there has been significant\nrecent progress in this area. Many of the existing tractability results for\nparameterised problems which involve finding or counting subgraphs with\nparticular properties rely on bounding the treewidth of these subgraphs in some\nsense; here, we prove a number of hardness results for the situation in which\nthis bounded treewidth condition does not hold, resulting in dichotomies for\nsome special cases of the general subgraph counting problem. The paper also\ngives a thorough survey of known results on this subject and the methods used,\nas well as discussing the relationships both between multicolour and uncoloured\nversions of subgraph counting problems, and between exact counting, approximate\ncounting and the corresponding decision problems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 15:34:17 GMT"}, {"version": "v2", "created": "Fri, 29 May 2015 10:47:04 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Meeks", "Kitty", ""]]}, {"id": "1402.5950", "submitter": "Hans Raj Tiwary", "authors": "David Avis, Hans Raj Tiwary", "title": "A generalization of extension complexity that captures $P$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a generalization of the extension complexity of a\npolyhedron $Q$. On the one hand it is general enough so that all problems in\n$P$ can be formulated as linear programs with polynomial size extension\ncomplexity. On the other hand it still allows non-polynomial lower bounds to be\nproved for $NP$-hard problems independently of whether or not $P=NP$. The\ngeneralization, called $H$-free extension complexity, allows for a set of valid\ninequalities $H$ to be excluded in computing the extension complexity of $Q$.\nWe give results on the $H$-free extension complexity of hard matching problems\n(when $H$ are the odd set inequalities) and the traveling salesman problem\n(when $H$ are the subtour elimination constraints).\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 18:34:38 GMT"}, {"version": "v2", "created": "Fri, 11 Apr 2014 13:30:50 GMT"}], "update_date": "2014-04-14", "authors_parsed": [["Avis", "David", ""], ["Tiwary", "Hans Raj", ""]]}, {"id": "1402.6278", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and David Xiao", "title": "Sample Complexity Bounds on Differentially Private Learning via\n  Communication Complexity", "comments": "Extended abstract appears in Conference on Learning Theory (COLT)\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we analyze the sample complexity of classification by\ndifferentially private algorithms. Differential privacy is a strong and\nwell-studied notion of privacy introduced by Dwork et al. (2006) that ensures\nthat the output of an algorithm leaks little information about the data point\nprovided by any of the participating individuals. Sample complexity of private\nPAC and agnostic learning was studied in a number of prior works starting with\n(Kasiviswanathan et al., 2008) but a number of basic questions still remain\nopen, most notably whether learning with privacy requires more samples than\nlearning without privacy.\n  We show that the sample complexity of learning with (pure) differential\nprivacy can be arbitrarily higher than the sample complexity of learning\nwithout the privacy constraint or the sample complexity of learning with\napproximate differential privacy. Our second contribution and the main tool is\nan equivalence between the sample complexity of (pure) differentially private\nlearning of a concept class $C$ (or $SCDP(C)$) and the randomized one-way\ncommunication complexity of the evaluation problem for concepts from $C$. Using\nthis equivalence we prove the following bounds:\n  1. $SCDP(C) = \\Omega(LDim(C))$, where $LDim(C)$ is the Littlestone's (1987)\ndimension characterizing the number of mistakes in the online-mistake-bound\nlearning model. Known bounds on $LDim(C)$ then imply that $SCDP(C)$ can be much\nhigher than the VC-dimension of $C$.\n  2. For any $t$, there exists a class $C$ such that $LDim(C)=2$ but $SCDP(C)\n\\geq t$.\n  3. For any $t$, there exists a class $C$ such that the sample complexity of\n(pure) $\\alpha$-differentially private PAC learning is $\\Omega(t/\\alpha)$ but\nthe sample complexity of the relaxed $(\\alpha,\\beta)$-differentially private\nPAC learning is $O(\\log(1/\\beta)/\\alpha)$. This resolves an open problem of\nBeimel et al. (2013b).\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 19:00:15 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2014 04:14:50 GMT"}, {"version": "v3", "created": "Tue, 27 May 2014 02:06:43 GMT"}, {"version": "v4", "created": "Sun, 13 Sep 2015 04:53:25 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Feldman", "Vitaly", ""], ["Xiao", "David", ""]]}, {"id": "1402.6485", "submitter": "Martin Vatshelle", "authors": "Sigve Hortemo S{\\ae}ther, Jan Arne Telle, Martin Vatshelle", "title": "Solving MaxSAT and #SAT on structured CNF formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a structural parameter of CNF formulas and use it to\nidentify instances of weighted MaxSAT and #SAT that can be solved in polynomial\ntime. Given a CNF formula we say that a set of clauses is precisely satisfiable\nif there is some complete assignment satisfying these clauses only. Let the\nps-value of the formula be the number of precisely satisfiable sets of clauses.\nApplying the notion of branch decompositions to CNF formulas and using ps-value\nas cut function, we define the ps-width of a formula. For a formula given with\na decomposition of polynomial ps-width we show dynamic programming algorithms\nsolving weighted MaxSAT and #SAT in polynomial time. Combining with results of\n'Belmonte and Vatshelle, Graph classes with structured neighborhoods and\nalgorithmic applications, Theor. Comput. Sci. 511: 54-65 (2013)' we get\npolynomial-time algorithms solving weighted MaxSAT and #SAT for some classes of\nstructured CNF formulas. For example, we get $O(m^2(m + n)s)$ algorithms for\nformulas $F$ of $m$ clauses and $n$ variables and size $s$, if $F$ has a linear\nordering of the variables and clauses such that for any variable $x$ occurring\nin clause $C$, if $x$ appears before $C$ then any variable between them also\noccurs in $C$, and if $C$ appears before $x$ then $x$ occurs also in any clause\nbetween them. Note that the class of incidence graphs of such formulas do not\nhave bounded clique-width.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 10:48:36 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["S\u00e6ther", "Sigve Hortemo", ""], ["Telle", "Jan Arne", ""], ["Vatshelle", "Martin", ""]]}, {"id": "1402.6658", "submitter": "Anand Kumar Narayanan", "authors": "Ming-Deh Huang and Anand Kumar Narayanan", "title": "Computing discrete logarithms in subfields of residue class rings", "comments": "arXiv admin note: substantial text overlap with arXiv:1312.1674", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR cs.SC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthrough methods \\cite{gggz,joux,bgjt} on computing discrete\nlogarithms in small characteristic finite fields share an interesting feature\nin common with the earlier medium prime function field sieve method \\cite{jl}.\nTo solve discrete logarithms in a finite extension of a finite field $\\F$, a\npolynomial $h(x) \\in \\F[x]$ of a special form is constructed with an\nirreducible factor $g(x) \\in \\F[x]$ of the desired degree. The special form of\n$h(x)$ is then exploited in generating multiplicative relations that hold in\nthe residue class ring $\\F[x]/h(x)\\F[x]$ hence also in the target residue class\nfield $\\F[x]/g(x)\\F[x]$. An interesting question in this context and addressed\nin this paper is: when and how does a set of relations on the residue class\nring determine the discrete logarithms in the finite fields contained in it? We\ngive necessary and sufficient conditions for a set of relations on the residue\nclass ring to determine discrete logarithms in the finite fields contained in\nit. We also present efficient algorithms to derive discrete logarithms from the\nrelations when the conditions are met. The derived necessary conditions allow\nus to clearly identify structural obstructions intrinsic to the special\npolynomial $h(x)$ in each of the aforementioned methods, and propose\nmodifications to the selection of $h(x)$ so as to avoid obstructions.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 19:40:38 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["Huang", "Ming-Deh", ""], ["Narayanan", "Anand Kumar", ""]]}, {"id": "1402.6713", "submitter": "Simon Portegies Zwart", "authors": "Simon Portegies Zwart and Tjarda Boekholt (Sterrewacht Leiden)", "title": "On the minimal accuracy required for simulating self-gravitating systems\n  by means of direct N-body methods", "comments": "ApJ Letters (accepted for publication)", "journal-ref": null, "doi": "10.1088/2041-8205/785/1/L3", "report-no": null, "categories": "astro-ph.IM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conservation of energy, linear momentum and angular momentum are\nimportant drivers for our physical understanding of the evolution of the\nUniverse. These quantities are also conserved in Newton's laws of motion under\ngravity \\citep{Newton:1687}. Numerical integration of the associated equations\nof motion is extremely challenging, in particular due to the steady growth of\nnumerical errors (by round-off and discrete time-stepping,\n\\cite{1981PAZh....7..752B,1993ApJ...415..715G,1993ApJ...402L..85H,1994LNP...430..131M})\nand the exponential divergence \\citep{1964ApJ...140..250M,2009MNRAS.392.1051U}\nbetween two nearby solution. As a result, numerical solutions to the general\nN-body problem are intrinsically questionable\n\\citep{2003gmbp.book.....H,1994JAM....61..226L}. Using brute force integrations\nto arbitrary numerical precision we demonstrate empirically that ensembles of\ndifferent realizations of resonant 3-body interactions produce statistically\nindistinguishable results. Although individual solutions using common\nintegration methods are notoriously unreliable, we conjecture that an ensemble\nof approximate 3-body solutions accurately represents an ensemble of true\nsolutions, so long as the energy during integration is conserved to better than\n1/10. We therefore provide an independent confirmation that previous work on\nself-gravitating systems can actually be trusted, irrespective of the intrinsic\nchaotic nature of the N-body problem.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 21:17:46 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Zwart", "Simon Portegies", "", "Sterrewacht Leiden"], ["Boekholt", "Tjarda", "", "Sterrewacht Leiden"]]}, {"id": "1402.6800", "submitter": "Ved Prakash", "authors": "Hartmut Klauck and Ved Prakash", "title": "An Improved Interactive Streaming Algorithm for the Distinct Elements\n  Problem", "comments": "Submitted to ICALP 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exact computation of the number of distinct elements (frequency moment\n$F_0$) is a fundamental problem in the study of data streaming algorithms. We\ndenote the length of the stream by $n$ where each symbol is drawn from a\nuniverse of size $m$. While it is well known that the moments $F_0,F_1,F_2$ can\nbe approximated by efficient streaming algorithms, it is easy to see that exact\ncomputation of $F_0,F_2$ requires space $\\Omega(m)$. In previous work, Cormode\net al. therefore considered a model where the data stream is also processed by\na powerful helper, who provides an interactive proof of the result. They gave\nsuch protocols with a polylogarithmic number of rounds of communication between\nhelper and verifier for all functions in NC. This number of rounds\n$\\left(O(\\log^2 m) \\;\\text{in the case of} \\;F_0 \\right)$ can quickly make such\nprotocols impractical.\n  Cormode et al. also gave a protocol with $\\log m +1$ rounds for the exact\ncomputation of $F_0$ where the space complexity is $O\\left(\\log m \\log n+\\log^2\nm\\right)$ but the total communication $O\\left(\\sqrt{n}\\log m\\left(\\log n+ \\log\nm \\right)\\right)$. They managed to give $\\log m$ round protocols with\n$\\operatorname{polylog}(m,n)$ complexity for many other interesting problems\nincluding $F_2$, Inner product, and Range-sum, but computing $F_0$ exactly with\npolylogarithmic space and communication and $O(\\log m)$ rounds remained open.\n  In this work, we give a streaming interactive protocol with $\\log m$ rounds\nfor exact computation of $F_0$ using $O\\left(\\log m \\left(\\,\\log n + \\log m\n\\log\\log m\\,\\right)\\right)$ bits of space and the communication is $O\\left(\n\\log m \\left(\\,\\log n +\\log^3 m (\\log\\log m)^2 \\,\\right)\\right)$. The update\ntime of the verifier per symbol received is $O(\\log^2 m)$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 06:31:42 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Klauck", "Hartmut", ""], ["Prakash", "Ved", ""]]}, {"id": "1402.6952", "submitter": "Guangda Hu", "authors": "Jop Bri\\\"et and Zeev Dvir and Guangda Hu and Shubhangi Saraf", "title": "Lower Bounds for Approximate LDC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an approximate version of $q$-query LDCs (Locally Decodable Codes)\nover the real numbers and prove lower bounds on the encoding length of such\ncodes. A $q$-query $(\\alpha,\\delta)$-approximate LDC is a set $V$ of $n$ points\nin $\\mathbb{R}^d$ so that, for each $i \\in [d]$ there are $\\Omega(\\delta n)$\ndisjoint $q$-tuples $(\\vec{u}_1,\\ldots,\\vec{u}_q) $ in $V$ so that\n$\\text{span}(\\vec{u}_1,\\ldots,\\vec{u}_q)$ contains a unit vector whose $i$'th\ncoordinate is at least $\\alpha$. We prove exponential lower bounds of the form\n$n \\geq 2^{\\Omega(\\alpha \\delta \\sqrt{d})}$ for the case $q=2$ and, in some\ncases, stronger bounds (exponential in $d$).\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 16:14:10 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Bri\u00ebt", "Jop", ""], ["Dvir", "Zeev", ""], ["Hu", "Guangda", ""], ["Saraf", "Shubhangi", ""]]}, {"id": "1402.6970", "submitter": "Daegene Song", "authors": "D. Song", "title": "The P versus NP Problem in Quantum Physics", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.gen-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the fact that information is encoded and processed by physical\nsystems, the P versus NP problem is examined in terms of physical processes. In\nparticular, we consider P as a class of deterministic, and NP as\nnondeterministic, polynomial-time physical processes. Based on these\nidentifications, we review a self-reference physical process in quantum theory,\nwhich belongs to NP but cannot be contained in P.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 01:21:32 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Song", "D.", ""]]}, {"id": "1402.7254", "submitter": "Shenggen Zheng", "authors": "Jozef Gruska, Daowen Qiu, Shenggen Zheng", "title": "Generalizations of the distributed Deutsch-Jozsa promise problem", "comments": "we correct some errors of and improve the presentation the previous\n  version. arXiv admin note: substantial text overlap with arXiv:1309.7739", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the {\\em distributed Deutsch-Jozsa promise problem}, two parties are to\ndetermine whether their respective strings $x,y\\in\\{0,1\\}^n$ are at the {\\em\nHamming distance} $H(x,y)=0$ or $H(x,y)=\\frac{n}{2}$. Buhrman et al. (STOC' 98)\nproved that the exact {\\em quantum communication complexity} of this problem is\n${\\bf O}(\\log {n})$ while the {\\em deterministic communication complexity} is\n${\\bf \\Omega}(n)$. This was the first impressive (exponential) gap between\nquantum and classical communication complexity.\n  In this paper, we generalize the above distributed Deutsch-Jozsa promise\nproblem to determine, for any fixed $\\frac{n}{2}\\leq k\\leq n$, whether\n$H(x,y)=0$ or $H(x,y)= k$, and show that an exponential gap between exact\nquantum and deterministic communication complexity still holds if $k$ is an\neven such that $\\frac{1}{2}n\\leq k<(1-\\lambda) n$, where $0<\n\\lambda<\\frac{1}{2}$ is given. We also deal with a promise version of the\nwell-known {\\em disjointness} problem and show also that for this promise\nproblem there exists an exponential gap between quantum (and also\nprobabilistic) communication complexity and deterministic communication\ncomplexity of the promise version of such a disjointness problem. Finally, some\napplications to quantum, probabilistic and deterministic finite automata of the\nresults obtained are demonstrated.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 14:21:06 GMT"}, {"version": "v2", "created": "Mon, 24 Mar 2014 08:47:19 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2015 14:12:18 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Gruska", "Jozef", ""], ["Qiu", "Daowen", ""], ["Zheng", "Shenggen", ""]]}]