[{"id": "0911.0201", "submitter": "Julia Kempe", "authors": "Julia Kempe and Oded Regev", "title": "No Strong Parallel Repetition with Entangled and Non-signaling Provers", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider one-round games between a classical verifier and two provers. One\nof the main questions in this area is the \\emph{parallel repetition question}:\nIf the game is played $\\ell$ times in parallel, does the maximum winning\nprobability decay exponentially in $\\ell$? In the classical setting, this\nquestion was answered in the affirmative by Raz. More recently the question\narose whether the decay is of the form $(1-\\Theta(\\eps))^\\ell$ where $1-\\eps$\nis the value of the game and $\\ell$ is the number of repetitions. This question\nis known as the \\emph{strong parallel repetition question} and was motivated by\nits connections to the unique games conjecture. It was resolved by Raz who\nshowed that strong parallel repetition does \\emph{not} hold, even in the very\nspecial case of games known as XOR games.\n  This opens the question whether strong parallel repetition holds in the case\nwhen the provers share entanglement. Evidence for this is provided by the\nbehavior of XOR games, which have strong (in fact \\emph{perfect}) parallel\nrepetition, and by the recently proved strong parallel repetition of linear\nunique games. A similar question was open for games with so-called\nnon-signaling provers. Here the best known parallel repetition theorem is due\nto Holenstein, and is of the form $(1-\\Theta(\\eps^2))^\\ell$.\n  We show that strong parallel repetition holds neither with entangled provers\nnor with non-signaling provers. In particular we obtain that Holenstein's bound\nis tight. Along the way we also provide a tight characterization of the\nasymptotic behavior of the entangled value under parallel repetition of unique\ngames in terms of a semidefinite program.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2009 20:28:21 GMT"}], "update_date": "2009-11-03", "authors_parsed": [["Kempe", "Julia", ""], ["Regev", "Oded", ""]]}, {"id": "0911.0664", "submitter": "Aaron Potechin", "authors": "Aaron Potechin", "title": "Bounds on monotone switching networks for directed connectivity", "comments": "49 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We separate monotone analogues of L and NL by proving that any monotone\nswitching network solving directed connectivity on $n$ vertices must have size\nat least $n^(\\Omega(\\lg(n)))$.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2009 20:10:05 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2009 22:40:59 GMT"}, {"version": "v3", "created": "Sat, 14 Aug 2010 06:07:27 GMT"}, {"version": "v4", "created": "Sun, 27 Nov 2011 19:34:27 GMT"}, {"version": "v5", "created": "Fri, 30 Nov 2012 15:01:57 GMT"}, {"version": "v6", "created": "Sat, 30 Nov 2013 19:28:33 GMT"}, {"version": "v7", "created": "Tue, 29 Nov 2016 21:05:30 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Potechin", "Aaron", ""]]}, {"id": "0911.0801", "submitter": "D\\'aniel Marx", "authors": "D\\'aniel Marx", "title": "Tractable hypergraph properties for constraint satisfaction and\n  conjunctive queries", "comments": "Extended abstract appeared in STOC 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DB cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important question in the study of constraint satisfaction problems (CSP)\nis understanding how the graph or hypergraph describing the incidence structure\nof the constraints influences the complexity of the problem. For binary CSP\ninstances (i.e., where each constraint involves only two variables), the\nsituation is well understood: the complexity of the problem essentially depends\non the treewidth of the graph of the constraints. However, this is not the\ncorrect answer if constraints with unbounded number of variables are allowed,\nand in particular, for CSP instances arising from query evaluation problems in\ndatabase theory. Formally, if H is a class of hypergraphs, then let CSP(H) be\nCSP restricted to instances whose hypergraph is in H. Our goal is to\ncharacterize those classes of hypergraphs for which CSP(H) is polynomial-time\nsolvable or fixed-parameter tractable, parameterized by the number of\nvariables. Note that in the applications related to database query evaluation,\nwe usually assume that the number of variables is much smaller than the size of\nthe instance, thus parameterization by the number of variables is a meaningful\nquestion. The most general known property of H that makes CSP(H)\npolynomial-time solvable is bounded fractional hypertree width. Here we\nintroduce a new hypergraph measure called submodular width, and show that\nbounded submodular width of H implies that CSP(H) is fixed-parameter tractable.\nIn a matching hardness result, we show that if H has unbounded submodular\nwidth, then CSP(H) is not fixed-parameter tractable, unless the Exponential\nTime Hypothesis fails.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2009 14:07:38 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2010 09:35:29 GMT"}, {"version": "v3", "created": "Tue, 6 Dec 2011 15:12:49 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Marx", "D\u00e1niel", ""]]}, {"id": "0911.0996", "submitter": "Scott Aaronson", "authors": "Scott Aaronson and Andris Ambainis", "title": "The Need for Structure in Quantum Speedups", "comments": "31 pages; journal version; fixed several significant errors (which\n  were indeed fixable); improved main result from a 9th-power to a 7th-power\n  relation. Conference version in Proceedings of ICS (Innovations in Computer\n  Science) 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is there a general theorem that tells us when we can hope for exponential\nspeedups from quantum algorithms, and when we cannot? In this paper, we make\ntwo advances toward such a theorem, in the black-box model where most quantum\nalgorithms operate.\n  First, we show that for any problem that is invariant under permuting inputs\nand outputs (like the collision or the element distinctness problems), the\nquantum query complexity is at least the 7th root of the classical randomized\nquery complexity. (An earlier version of this paper gave the 9th root.) This\nresolves a conjecture of Watrous from 2002.\n  Second, inspired by recent work of O'Donnell et al. (2005) and Dinur et al.\n(2006), we conjecture that every bounded low-degree polynomial has a \"highly\ninfluential\" variable. Assuming this conjecture, we show that every T-query\nquantum algorithm can be simulated on most inputs by a poly(T)-query classical\nalgorithm, and that one essentially cannot hope to prove P!=BQP relative to a\nrandom oracle.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2009 09:10:42 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2012 22:07:31 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2014 20:13:48 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Aaronson", "Scott", ""], ["Ambainis", "Andris", ""]]}, {"id": "0911.1393", "submitter": "Lek-Heng Lim", "authors": "Christopher Hillar and Lek-Heng Lim", "title": "Most tensor problems are NP-hard", "comments": "38 pages; to appear in Journal of the ACM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that multilinear (tensor) analogues of many efficiently computable\nproblems in numerical linear algebra are NP-hard. Our list here includes:\ndetermining the feasibility of a system of bilinear equations, deciding whether\na 3-tensor possesses a given eigenvalue, singular value, or spectral norm;\napproximating an eigenvalue, eigenvector, singular vector, or the spectral\nnorm; and determining the rank or best rank-1 approximation of a 3-tensor.\nFurthermore, we show that restricting these problems to symmetric tensors does\nnot alleviate their NP-hardness. We also explain how deciding nonnegative\ndefiniteness of a symmetric 4-tensor is NP-hard and how computing the\ncombinatorial hyperdeterminant of a 4-tensor is NP-, #P-, and VNP-hard. We\nshall argue that our results provide another view of the boundary separating\nthe computational tractability of linear/convex problems from the\nintractability of nonlinear/nonconvex ones.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2009 05:21:11 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2010 10:36:24 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2012 18:02:09 GMT"}, {"version": "v4", "created": "Tue, 12 Feb 2013 00:33:53 GMT"}, {"version": "v5", "created": "Mon, 1 Jul 2013 01:10:12 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Hillar", "Christopher", ""], ["Lim", "Lek-Heng", ""]]}, {"id": "0911.1677", "submitter": "Bernd Schuh", "authors": "Bernd R. Schuh", "title": "Logical Primes, Metavariables and Satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For formulas F of propositional calculus I introduce a \"metavariable\" MF and\nshow how it can be used to define an algorithm for testing satisfiability. MF\nis a formula which is true/false under all possible truth assignments iff F is\nsatisfiable/unsatisfiable. In this sense MF is a metavariable with the\n\"meaning\" 'F is SAT'. For constructing MF a group of transformations of the\nbasic variables ai is used which corresponds to 'flipping\" literals to their\nnegation. The whole procedure corresponds to branching algorithms where a\nformula is split with respect to the truth values of its variables, one by one.\nEach branching step corresponds to an approximation to the metatheorem which\ndoubles the chance to find a satisfying truth assignment but also doubles the\nlength of the formulas to be tested, in principle. Simplifications arise by\nadditional length reductions. I also discuss the notion of \"logical primes\" and\nshow that each formula can be written as a uniquely defined product of such\nprime factors. Satisfying truth assignments can be found by determining the\n\"missing\" primes in the factorization of a formula.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 13:29:53 GMT"}], "update_date": "2009-11-10", "authors_parsed": [["Schuh", "Bernd R.", ""]]}, {"id": "0911.1696", "submitter": "Julia Kempe", "authors": "Andris Ambainis, Julia Kempe, Or Sattath", "title": "A Quantum Lovasz Local Lemma", "comments": "19 pages", "journal-ref": "Journal of the ACM, Volume 59 Issue 5, October 2012, Article No.\n  24", "doi": "10.1145/2371656.2371659", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lovasz Local Lemma (LLL) is a powerful tool in probability theory to show\nthe existence of combinatorial objects meeting a prescribed collection of\n\"weakly dependent\" criteria. We show that the LLL extends to a much more\ngeneral geometric setting, where events are replaced with subspaces and\nprobability is replaced with relative dimension, which allows to lower bound\nthe dimension of the intersection of vector spaces under certain independence\nconditions. Our result immediately applies to the k-QSAT problem: For instance\nwe show that any collection of rank 1 projectors with the property that each\nqubit appears in at most $2^k/(e \\cdot k)$ of them, has a joint satisfiable\nstate.\n  We then apply our results to the recently studied model of random k-QSAT.\nRecent works have shown that the satisfiable region extends up to a density of\n1 in the large k limit, where the density is the ratio of projectors to qubits.\nUsing a hybrid approach building on work by Laumann et al. we greatly extend\nthe known satisfiable region for random k-QSAT to a density of\n$\\Omega(2^k/k^2)$. Since our tool allows us to show the existence of joint\nsatisfying states without the need to construct them, we are able to penetrate\ninto regions where the satisfying states are conjectured to be entangled,\navoiding the need to construct them, which has limited previous approaches to\nproduct states.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 15:07:25 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Ambainis", "Andris", ""], ["Kempe", "Julia", ""], ["Sattath", "Or", ""]]}, {"id": "0911.1739", "submitter": "Shmuel Friedland", "authors": "Shmuel Friedland", "title": "Graph isomorphism and volumes of convex bodies", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a nontrivial graph isomorphism problem of two undirected graphs,\nand more generally, the permutation similarity of two given $n\\times n$\nmatrices, is equivalent to equalities of volumes of the induced three convex\nbounded polytopes intersected with a given sequence of balls, centered at the\norigin with radii $t_i\\in (0,\\sqrt{n-1})$, where $\\{t_i\\}$ is an increasing\nsequence converging to $\\sqrt{n-1}$. These polytopes are characterized by $n^2$\ninequalities in at most $n^2$ variables. The existence of fpras for computing\nvolumes of convex bodies gives rise to a semi-frpas of order $O^*(n^{14})$ at\nmost to find if given two undirected graphs are isomorphic.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 17:48:36 GMT"}], "update_date": "2009-11-10", "authors_parsed": [["Friedland", "Shmuel", ""]]}, {"id": "0911.1813", "submitter": "Aaron Roth", "authors": "Aaron Roth, Tim Roughgarden", "title": "Interactive Privacy via the Median Mechanism", "comments": "Appeared in STOC 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new interactive differentially private mechanism -- the median\nmechanism -- for answering arbitrary predicate queries that arrive online.\nRelative to fixed accuracy and privacy constraints, this mechanism can answer\nexponentially more queries than the previously best known interactive privacy\nmechanism (the Laplace mechanism, which independently perturbs each query\nresult). Our guarantee is almost the best possible, even for non-interactive\nprivacy mechanisms. Conceptually, the median mechanism is the first privacy\nmechanism capable of identifying and exploiting correlations among queries in\nan interactive setting.\n  We also give an efficient implementation of the median mechanism, with\nrunning time polynomial in the number of queries, the database size, and the\ndomain size. This efficient implementation guarantees privacy for all input\ndatabases, and accurate query results for almost all input databases. The\ndependence of the privacy on the number of queries in this mechanism improves\nover that of the best previously known efficient mechanism by a\nsuper-polynomial factor, even in the non-interactive setting.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2009 03:55:44 GMT"}, {"version": "v2", "created": "Wed, 19 Jan 2011 16:09:18 GMT"}], "update_date": "2011-01-20", "authors_parsed": [["Roth", "Aaron", ""], ["Roughgarden", "Tim", ""]]}, {"id": "0911.2280", "submitter": "Bal\\'azs Csan\\'ad Cs\\'aji", "authors": "Bal\\'azs Csan\\'ad Cs\\'aji, Rapha\\\"el M. Jungers, and Vincent D.\n  Blondel", "title": "PageRank Optimization by Edge Selection", "comments": "30 pages, 3 figures", "journal-ref": "Discrete Applied Mathematics, Volume 169, 2014, Pages 73-87", "doi": "10.1016/j.dam.2014.01.007", "report-no": null, "categories": "cs.DS cs.CC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of a node in a directed graph can be measured by its PageRank.\nThe PageRank of a node is used in a number of application contexts - including\nranking websites - and can be interpreted as the average portion of time spent\nat the node by an infinite random walk. We consider the problem of maximizing\nthe PageRank of a node by selecting some of the edges from a set of edges that\nare under our control. By applying results from Markov decision theory, we show\nthat an optimal solution to this problem can be found in polynomial time. Our\ncore solution results in a linear programming formulation, but we also provide\nan alternative greedy algorithm, a variant of policy iteration, which runs in\npolynomial time, as well. Finally, we show that, under the slight modification\nfor which we are given mutually exclusive pairs of edges, the problem of\nPageRank optimization becomes NP-hard.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 12:57:09 GMT"}, {"version": "v2", "created": "Wed, 18 Jan 2012 09:09:34 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Cs\u00e1ji", "Bal\u00e1zs Csan\u00e1d", ""], ["Jungers", "Rapha\u00ebl M.", ""], ["Blondel", "Vincent D.", ""]]}, {"id": "0911.2317", "submitter": "EPTCS", "authors": "Farid Ablayev, Alexander Vasiliev", "title": "Algorithms for Quantum Branching Programs Based on Fingerprinting", "comments": null, "journal-ref": "EPTCS 9, 2009, pp. 1-11", "doi": "10.4204/EPTCS.9.1", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we develop a method for constructing quantum algorithms for\ncomputing Boolean functions by quantum ordered read-once branching programs\n(quantum OBDDs). Our method is based on fingerprinting technique and\nrepresentation of Boolean functions by their characteristic polynomials. We use\ncircuit notation for branching programs for desired algorithms presentation.\nFor several known functions our approach provides optimal QOBDDs. Namely we\nconsider such functions as Equality, Palindrome, and Permutation Matrix Test.\nWe also propose a generalization of our method and apply it to the Boolean\nvariant of the Hidden Subgroup Problem.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 08:24:23 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Ablayev", "Farid", ""], ["Vasiliev", "Alexander", ""]]}, {"id": "0911.2322", "submitter": "EPTCS", "authors": "Amin Coja-Oghlan", "title": "Random Constraint Satisfaction Problems", "comments": null, "journal-ref": "EPTCS 9, 2009, pp. 32-37", "doi": "10.4204/EPTCS.9.4", "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random instances of constraint satisfaction problems such as k-SAT provide\nchallenging benchmarks. If there are m constraints over n variables there is\ntypically a large range of densities r=m/n where solutions are known to exist\nwith probability close to one due to non-constructive arguments. However, no\nalgorithms are known to find solutions efficiently with a non-vanishing\nprobability at even much lower densities. This fact appears to be related to a\nphase transition in the set of all solutions. The goal of this extended\nabstract is to provide a perspective on this phenomenon, and on the\ncomputational challenge that it poses.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 08:42:42 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Coja-Oghlan", "Amin", ""]]}, {"id": "0911.2325", "submitter": "EPTCS", "authors": "Walid Gomaa (Alexandria University)", "title": "Characterizing Polynomial Time Computability of Rational and Real\n  Functions", "comments": null, "journal-ref": "EPTCS 9, 2009, pp. 54-64", "doi": "10.4204/EPTCS.9.7", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive analysis was introduced by A. Turing [1936], A. Grzegorczyk [1955],\nand D. Lacombe [1955]. It is based on a discrete mechanical framework that can\nbe used to model computation over the real numbers. In this context the\ncomputational complexity of real functions defined over compact domains has\nbeen extensively studied. However, much less have been done for other kinds of\nreal functions. This article is divided into two main parts. The first part\ninvestigates polynomial time computability of rational functions and the role\nof continuity in such computation. On the one hand this is interesting for its\nown sake. On the other hand it provides insights into polynomial time\ncomputability of real functions for the latter, in the sense of recursive\nanalysis, is modeled as approximations of rational computations. The main\nconclusion of this part is that continuity does not play any role in the\nefficiency of computing rational functions. The second part defines polynomial\ntime computability of arbitrary real functions, characterizes it, and compares\nit with the corresponding notion over rational functions. Assuming continuity,\nthe main conclusion is that there is a conceptual difference between polynomial\ntime computation over the rationals and the reals manifested by the fact that\nthere are polynomial time computable rational functions whose extensions to the\nreals are not polynomial time computable and vice versa.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 08:50:28 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Gomaa", "Walid", "", "Alexandria University"]]}, {"id": "0911.2567", "submitter": "Christoph Durr", "authors": "Marek Chrobak, Christoph Durr, Flavio Guinez, Antoni Lozano, Nguyen\n  Kim Thang", "title": "Tile Packing Tomography is NP-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete tomography deals with reconstructing finite spatial objects from\nlower dimensional projections and has applications for example in timetable\ndesign. In this paper we consider the problem of reconstructing a tile packing\nfrom its row and column projections. It consists of disjoint copies of a fixed\ntile, all contained in some rectangular grid. The projections tell how many\ncells are covered by a tile in each row and column. How difficult is it to\nconstruct a tile packing satisfying given projections? It was known to be\nsolvable by a greedy algorithm for bars (tiles of width or height 1), and\nNP-hardness results were known for some specific tiles. This paper shows that\nthe problem is NP-hard whenever the tile is not a bar.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2009 08:54:27 GMT"}, {"version": "v2", "created": "Tue, 21 Dec 2010 09:43:49 GMT"}], "update_date": "2010-12-22", "authors_parsed": [["Chrobak", "Marek", ""], ["Durr", "Christoph", ""], ["Guinez", "Flavio", ""], ["Lozano", "Antoni", ""], ["Thang", "Nguyen Kim", ""]]}, {"id": "0911.2829", "submitter": "EPTCS", "authors": "S. Barry Cooper, Vincent Danos", "title": "Proceedings Fifth Workshop on Developments in Computational\n  Models--Computational Models From Nature", "comments": null, "journal-ref": "EPTCS 9, 2009", "doi": "10.4204/EPTCS.9", "report-no": null, "categories": "cs.CE cs.AI cs.CC cs.FL cs.LO cs.NE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The special theme of DCM 2009, co-located with ICALP 2009, concerned\nComputational Models From Nature, with a particular emphasis on computational\nmodels derived from physics and biology. The intention was to bring together\ndifferent approaches - in a community with a strong foundational background as\nproffered by the ICALP attendees - to create inspirational cross-boundary\nexchanges, and to lead to innovative further research. Specifically DCM 2009\nsought contributions in quantum computation and information, probabilistic\nmodels, chemical, biological and bio-inspired ones, including spatial models,\ngrowth models and models of self-assembly. Contributions putting to the test\nlogical or algorithmic aspects of computing (e.g., continuous computing with\ndynamical systems, or solid state computing models) were also very much\nwelcomed.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2009 03:35:32 GMT"}], "update_date": "2009-11-17", "authors_parsed": [["Cooper", "S. Barry", ""], ["Danos", "Vincent", ""]]}, {"id": "0911.2907", "submitter": "William Bradley", "authors": "William F. Bradley", "title": "A Recursive Definition of the Holographic Standard Signature", "comments": "Fixed small typo in Section 3.6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a recursive description of the signatures realizable on the\nstandard basis by a holographic algorithm. The description allows us to prove\ntight bounds on the size of planar matchgates and efficiently test for standard\nsignatures. Over finite fields, it allows us to count the number of n-bit\nstandard signatures and calculate their expected sparsity.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2009 19:30:21 GMT"}], "update_date": "2009-11-17", "authors_parsed": [["Bradley", "William F.", ""]]}, {"id": "0911.3162", "submitter": "Lance Fortnow", "authors": "Lance Fortnow and Rahul Santhanam", "title": "Bounding Rationality by Discounting Time", "comments": "To appear in Proceedings of The First Symposium on Innovations in\n  Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a game where Alice generates an integer and Bob wins if he can\nfactor that integer. Traditional game theory tells us that Bob will always win\nthis game even though in practice Alice will win given our usual assumptions\nabout the hardness of factoring.\n  We define a new notion of bounded rationality, where the payoffs of players\nare discounted by the computation time they take to produce their actions. We\nuse this notion to give a direct correspondence between the existence of\nequilibria where Alice has a winning strategy and the hardness of factoring.\nNamely, under a natural assumption on the discount rates, there is an\nequilibriumwhere Alice has a winning strategy iff there is a linear-time\nsamplable distribution with respect to which Factoring is hard on average.\n  We also give general results for discounted games over countable action\nspaces, including showing that any game with bounded and computable payoffs has\nan equilibrium in our model, even if each player is allowed a countable number\nof actions. It follows, for example, that the Largest Integer game has an\nequilibrium in our model though it has no Nash equilibria or epsilon-Nash\nequilibria.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2009 21:10:26 GMT"}], "update_date": "2009-11-18", "authors_parsed": [["Fortnow", "Lance", ""], ["Santhanam", "Rahul", ""]]}, {"id": "0911.3291", "submitter": "Frederic Magniez", "authors": "F. Magniez, C. Mathieu, A. Nayak", "title": "Recognizing well-parenthesized expressions in the streaming model", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a concrete problem and with the goal of understanding the sense\nin which the complexity of streaming algorithms is related to the complexity of\nformal languages, we investigate the problem Dyck(s) of checking matching\nparentheses, with $s$ different types of parenthesis.\n  We present a one-pass randomized streaming algorithm for Dyck(2) with space\n$\\Order(\\sqrt{n}\\log n)$, time per letter $\\polylog (n)$, and one-sided error.\nWe prove that this one-pass algorithm is optimal, up to a $\\polylog n$ factor,\neven when two-sided error is allowed. For the lower bound, we prove a direct\nsum result on hard instances by following the \"information cost\" approach, but\nwith a few twists. Indeed, we play a subtle game between public and private\ncoins. This mixture between public and private coins results from a balancing\nact between the direct sum result and a combinatorial lower bound for the base\ncase.\n  Surprisingly, the space requirement shrinks drastically if we have access to\nthe input stream in reverse. We present a two-pass randomized streaming\nalgorithm for Dyck(2) with space $\\Order((\\log n)^2)$, time $\\polylog (n)$ and\none-sided error, where the second pass is in the reverse direction. Both\nalgorithms can be extended to Dyck(s) since this problem is reducible to\nDyck(2) for a suitable notion of reduction in the streaming model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2009 12:42:11 GMT"}], "update_date": "2009-11-18", "authors_parsed": [["Magniez", "F.", ""], ["Mathieu", "C.", ""], ["Nayak", "A.", ""]]}, {"id": "0911.3389", "submitter": "Jelani Nelson", "authors": "Ilias Diakonikolas, Daniel M. Kane, Jelani Nelson", "title": "Bounded Independence Fools Degree-2 Threshold Functions", "comments": "Using v1 numbering: removed Lemma G.5 from the Appendix (it was\n  wrong). Net effect is that Theorem G.6 reduces the m^6 dependence of Theorem\n  8.1 to m^4, not m^2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let x be a random vector coming from any k-wise independent distribution over\n{-1,1}^n. For an n-variate degree-2 polynomial p, we prove that E[sgn(p(x))] is\ndetermined up to an additive epsilon for k = poly(1/epsilon). This answers an\nopen question of Diakonikolas et al. (FOCS 2009). Using standard constructions\nof k-wise independent distributions, we obtain a broad class of explicit\ngenerators that epsilon-fool the class of degree-2 threshold functions with\nseed length log(n)*poly(1/epsilon).\n  Our approach is quite robust: it easily extends to yield that the\nintersection of any constant number of degree-2 threshold functions is\nepsilon-fooled by poly(1/epsilon)-wise independence. Our results also hold if\nthe entries of x are k-wise independent standard normals, implying for example\nthat bounded independence derandomizes the Goemans-Williamson hyperplane\nrounding scheme.\n  To achieve our results, we introduce a technique we dub multivariate\nFT-mollification, a generalization of the univariate form introduced by Kane et\nal. (SODA 2010) in the context of streaming algorithms. Along the way we prove\na generalized hypercontractive inequality for quadratic forms which takes the\noperator norm of the associated matrix into account. These techniques may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2009 20:24:27 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2010 17:15:56 GMT"}], "update_date": "2010-02-18", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Nelson", "Jelani", ""]]}, {"id": "0911.3438", "submitter": "Francesco Zamponi", "authors": "T.Jorg, F.Krzakala, G.Semerjian, F.Zamponi", "title": "First-order transitions and the performance of quantum algorithms in\n  random optimization problems", "comments": "4 pages, 4 figures; final version accepted on Phys.Rev.Lett", "journal-ref": "Phys. Rev. Lett. 104, 207206 (2010)", "doi": "10.1103/PhysRevLett.104.207206", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study of the phase diagram of a random optimization problem in\npresence of quantum fluctuations. Our main result is the characterization of\nthe nature of the phase transition, which we find to be a first-order quantum\nphase transition. We provide evidence that the gap vanishes exponentially with\nthe system size at the transition. This indicates that the Quantum Adiabatic\nAlgorithm requires a time growing exponentially with system size to find the\nground state of this problem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2009 23:36:16 GMT"}, {"version": "v2", "created": "Thu, 20 May 2010 21:22:38 GMT"}], "update_date": "2010-05-24", "authors_parsed": [["Jorg", "T.", ""], ["Krzakala", "F.", ""], ["Semerjian", "G.", ""], ["Zamponi", "F.", ""]]}, {"id": "0911.3473", "submitter": "Shachar Lovett", "authors": "Ido Ben-Eliezer, Shachar Lovett, Ariel Yadin", "title": "Polynomial Threshold Functions: Structure, Approximation and\n  Pseudorandomness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational power of polynomial threshold functions, that is,\nthreshold functions of real polynomials over the boolean cube. We provide two\nnew results bounding the computational power of this model.\n  Our first result shows that low-degree polynomial threshold functions cannot\napproximate any function with many influential variables. We provide a couple\nof examples where this technique yields tight approximation bounds.\n  Our second result relates to constructing pseudorandom generators fooling\nlow-degree polynomial threshold functions. This problem has received attention\nrecently, where Diakonikolas et al proved that $k$-wise independence suffices\nto fool linear threshold functions. We prove that any low-degree polynomial\nthreshold function, which can be represented as a function of a small number of\nlinear threshold functions, can also be fooled by $k$-wise independence. We\nview this as an important step towards fooling general polynomial threshold\nfunctions, and we discuss a plausible approach achieving this goal based on our\ntechniques.\n  Our results combine tools from real approximation theory, hyper-contractive\ninequalities and probabilistic methods. In particular, we develop several new\ntools in approximation theory which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2009 07:28:08 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2009 22:31:41 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2009 20:37:14 GMT"}], "update_date": "2009-11-29", "authors_parsed": [["Ben-Eliezer", "Ido", ""], ["Lovett", "Shachar", ""], ["Yadin", "Ariel", ""]]}, {"id": "0911.3492", "submitter": "Britta Dorn", "authors": "Nadja Betzler, Britta Dorn", "title": "Towards a Dichotomy for the Possible Winner Problem in Elections Based\n  on Scoring Rules", "comments": "minor changes and updates; accepted for publication in JCSS, online\n  version available.", "journal-ref": null, "doi": "10.1016/j.jcss.2010.04.002", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make a joint decision, agents (or voters) are often required to provide\ntheir preferences as linear orders. To determine a winner, the given linear\norders can be aggregated according to a voting protocol. However, in realistic\nsettings, the voters may often only provide partial orders. This directly leads\nto the Possible Winner problem that asks, given a set of partial votes, whether\na distinguished candidate can still become a winner. In this work, we consider\nthe computational complexity of Possible Winner for the broad class of voting\nprotocols defined by scoring rules. A scoring rule provides a score value for\nevery position which a candidate can have in a linear order. Prominent examples\ninclude plurality, k-approval, and Borda. Generalizing previous NP-hardness\nresults for some special cases, we settle the computational complexity for all\nbut one scoring rule. More precisely, for an unbounded number of candidates and\nunweighted voters, we show that Possible Winner is NP-complete for all pure\nscoring rules except plurality, veto, and the scoring rule defined by the\nscoring vector (2,1,...,1,0), while it is solvable in polynomial time for\nplurality and veto.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2009 10:02:39 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2010 11:36:55 GMT"}], "update_date": "2010-05-03", "authors_parsed": [["Betzler", "Nadja", ""], ["Dorn", "Britta", ""]]}, {"id": "0911.3674", "submitter": "Sebastian Maneth", "authors": "Omer Gim\\'enez, Guillem Godoy, Sebastian Maneth", "title": "Deciding Regularity of the Set of Instances of a Set of Terms with\n  Regular Constraints is EXPTIME-Complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-state tree automata are a well studied formalism for representing term\nlanguages. This paper studies the problem of determining the regularity of the\nset of instances of a finite set of terms with variables, where each variable\nis restricted to instantiations of a regular set given by a tree automaton. The\nproblem was recently proved decidable, but with an unknown complexity. Here,\nthe exact complexity of the problem is determined by proving\nEXPTIME-completeness. The main contribution is a new, exponential time\nalgorithm that performs various exponential transformations on the involved\nterms and tree automata, and decides regularity by analyzing formulas over\ninequality and height predicates.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2009 23:02:12 GMT"}], "update_date": "2009-11-20", "authors_parsed": [["Gim\u00e9nez", "Omer", ""], ["Godoy", "Guillem", ""], ["Maneth", "Sebastian", ""]]}, {"id": "0911.3708", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Manipulability of Single Transferable Vote", "comments": "Proceedings of the CARE'09 International Workshop on Collaborative\n  Agents -- REsearch and Development, Melbourne 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many voting rules, it is NP-hard to compute a successful manipulation.\nHowever, NP-hardness only bounds the worst-case complexity. Recent theoretical\nresults suggest that manipulation may often be easy in practice. We study\nempirically the cost of manipulating the single transferable vote (STV) rule.\nThis was one of the first rules shown to be NP-hard to manipulate. It also\nappears to be one of the harder rules to manipulate since it involves multiple\nrounds and since, unlike many other rules, it is NP-hard for a single agent to\nmanipulate without weights on the votes or uncertainty about how the other\nagents have voted. In almost every election in our experiments, it was easy to\ncompute how a single agent could manipulate the election or to prove that\nmanipulation by a single agent was impossible. It remains an interesting open\nquestion if manipulation by a coalition of agents is hard to compute in\npractice.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2009 06:23:55 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "0911.3836", "submitter": "Edwin James Beggs", "authors": "E. J. Beggs, J. F. Costa, J. V. Tucker", "title": "Limits to measurement in experiments governed by algorithms", "comments": "32 pages approx", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We pose the following question: If a physical experiment were to be\ncompletely controlled by an algorithm, what effect would the algorithm have on\nthe physical measurements made possible by the experiment?\n  In a programme to study the nature of computation possible by physical\nsystems, and by algorithms coupled with physical systems, we have begun to\nanalyse (i) the algorithmic nature of experimental procedures, and (ii) the\nidea of using a physical experiment as an oracle to Turing Machines. To answer\nthe question, we will extend our theory of experimental oracles in order to use\nTuring machines to model the experimental procedures that govern the conduct of\nphysical experiments. First, we specify an experiment that measures mass via\ncollisions in Newtonian Dynamics; we examine its properties in preparation for\nits use as an oracle. We start to classify the computational power of\npolynomial time Turing machines with this experimental oracle using non-uniform\ncomplexity classes. Second, we show that modelling an experimenter and\nexperimental procedure algorithmically imposes a limit on what can be measured\nwith equipment. Indeed, the theorems suggest a new form of uncertainty\nprinciple for our knowledge of physical quantities measured in simple physical\nexperiments. We argue that the results established here are representative of a\nhuge class of experiments.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2009 16:24:11 GMT"}], "update_date": "2009-11-20", "authors_parsed": [["Beggs", "E. J.", ""], ["Costa", "J. F.", ""], ["Tucker", "J. V.", ""]]}, {"id": "0911.4322", "submitter": "Alexander Gutfraind", "authors": "Alexander Gutfraind, Kiyan Ahmadizadeh", "title": "Markovian Network Interdiction and the Four Color Theorem", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-09-07611", "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Unreactive Markovian Evader Interdiction Problem (UME) asks to optimally\nplace sensors on a network to detect Markovian motion by one or more \"evaders\".\nIt was previously proved that finding the optimal sensor placement is NP-hard\nif the number of evaders is unbounded. Here we show that the problem is NP-hard\nwith just 2 evaders using a connection to coloring of planar graphs. The\nresults suggest that approximation algorithms are needed even in applications\nwhere the number of evaders is small. It remains an open problem to determine\nthe complexity of the 1-evader case or to devise efficient algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2009 03:57:04 GMT"}], "update_date": "2009-11-24", "authors_parsed": [["Gutfraind", "Alexander", ""], ["Ahmadizadeh", "Kiyan", ""]]}, {"id": "0911.4337", "submitter": "Srikanth Srinivasan", "authors": "Vikraman Arvind, Srikanth Srinivasan", "title": "Circuit Lower Bounds, Help Functions, and the Remote Point Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power of Algebraic Branching Programs (ABPs) augmented\nwith help polynomials, and constant-depth Boolean circuits augmented with help\nfunctions. We relate the problem of proving explicit lower bounds in both these\nmodels to the Remote Point Problem (introduced by Alon, Panigrahy, and Yekhanin\n(RANDOM '09)). More precisely, proving lower bounds for ABPs with help\npolynomials is related to the Remote Point Problem w.r.t. the rank metric, and\nfor constant-depth circuits with help functions it is related to the Remote\nPoint Problem w.r.t. the Hamming metric. For algebraic branching programs with\nhelp polynomials with some degree restrictions we show exponential size lower\nbounds for explicit polynomials.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2009 08:25:40 GMT"}], "update_date": "2009-11-24", "authors_parsed": [["Arvind", "Vikraman", ""], ["Srinivasan", "Srikanth", ""]]}, {"id": "0911.4521", "submitter": "Bruno Bauwens", "authors": "Bruno Bauwens", "title": "On the equivalence between minimal sufficient statistics, minimal\n  typical models and initial segments of the Halting sequence", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that the length of the algorithmic minimal sufficient statistic\nof a binary string x, either in a representation of a finite set, computable\nsemimeasure, or a computable function, has a length larger than the\ncomputational depth of x, and can solve the Halting problem for all programs\nwith length shorter than the m-depth of x. It is also shown that there are\nstrings for which the algorithmic minimal sufficient statistics can contain a\nsubstantial amount of information that is not Halting information. The weak\nsufficient statistic is introduced, and it is shown that a minimal weak\nsufficient statistic for x is equivalent to a minimal typical model of x, and\nto the Halting problem for all strings shorter than the BB-depth of x.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2009 23:57:53 GMT"}], "update_date": "2009-11-25", "authors_parsed": [["Bauwens", "Bruno", ""]]}, {"id": "0911.4724", "submitter": "Martin Roetteler", "authors": "Martin Roetteler", "title": "Quantum algorithms to solve the hidden shift problem for quadratics and\n  for functions of large Gowers norm", "comments": "12 pages, no figures, Proc. MFCS'09, LNCS vol. 5734, pp. 663-674,\n  2009. Mezzanine tranche of earlier paper arXiv:0811.3208", "journal-ref": "Proceedings MFCS'09, LNCS vol. 5734, pp. 663-674, 2009", "doi": "10.1007/978-3-642-03816-7_56", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most quantum algorithms that give an exponential speedup over classical\nalgorithms exploit the Fourier transform in some way. In Shor's algorithm,\nsampling from the quantum Fourier spectrum is used to discover periodicity of\nthe modular exponentiation function. In a generalization of this idea, quantum\nFourier sampling can be used to discover hidden subgroup structures of some\nfunctions much more efficiently than it is possible classically. Another\nproblem for which the Fourier transform has been recruited successfully on a\nquantum computer is the hidden shift problem. Quantum algorithms for hidden\nshift problems usually have a slightly different flavor from hidden subgroup\nalgorithms, as they use the Fourier transform to perform a correlation with a\ngiven reference function, instead of sampling from the Fourier spectrum\ndirectly. In this paper we show that hidden shifts can be extracted efficiently\nfrom Boolean functions that are quadratic forms. We also show how to identify\nan unknown quadratic form on n variables using a linear number of queries, in\ncontrast to the classical case were this takes Theta(n^2) many queries to a\nblack box. What is more, we show that our quantum algorithm is robust in the\nsense that it can also infer the shift if the function is close to a quadratic,\nwhere we consider a Boolean function to be close to a quadratic if it has a\nlarge Gowers U_3 norm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2009 21:07:02 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Roetteler", "Martin", ""]]}, {"id": "0911.5262", "submitter": "Rob Van Son", "authors": "R.J.J.H. van Son", "title": "Quantifying Resource Use in Computations", "comments": "26 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  It is currently not possible to quantify the resources needed to perform a\ncomputation. As a consequence, it is not possible to reliably evaluate the\nhardware resources needed for the application of algorithms or the running of\nprograms. This is apparent in both computer science, for instance, in\ncryptanalysis, and in neuroscience, for instance, comparative neuro-anatomy. A\nSystem versus Environment game formalism is proposed based on Computability\nLogic that allows to define a computational work function that describes the\ntheoretical and physical resources needed to perform any purely algorithmic\ncomputation. Within this formalism, the cost of a computation is defined as the\nsum of information storage over the steps of the computation. The size of the\ncomputational device, eg, the action table of a Universal Turing Machine, the\nnumber of transistors in silicon, or the number and complexity of synapses in a\nneural net, is explicitly included in the computational cost. The proposed cost\nfunction leads in a natural way to known computational trade-offs and can be\nused to estimate the computational capacity of real silicon hardware and neural\nnets. The theory is applied to a historical case of 56 bit DES key recovery, as\nan example of application to cryptanalysis. Furthermore, the relative\ncomputational capacities of human brain neurons and the C. elegans nervous\nsystem are estimated as an example of application to neural nets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2009 13:22:55 GMT"}], "update_date": "2009-11-30", "authors_parsed": [["van Son", "R. J. J. H.", ""]]}, {"id": "0911.5384", "submitter": "Gregory Gutin", "authors": "Robert Crowston, Gregory Gutin and Mark Jones", "title": "Note on Max Lin-2 above Average", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Max Lin-2 problem we are given a system $S$ of $m$ linear equations in\n$n$ variables over $\\mathbb{F}_2$ in which Equation $j$ is assigned a positive\nintegral weight $w_j$ for each $j$. We wish to find an assignment of values to\nthe variables which maximizes the total weight of satisfied equations. This\nproblem generalizes Max Cut. The expected weight of satisfied equations is\n$W/2$, where $W=w_1+... +w_m$; $W/2$ is a tight lower bound on the optimal\nsolution of Max Lin-2.\n  Mahajan et al. (J. Comput. Syst. Sci. 75, 2009) stated the following\nparameterized version of Max Lin-2: decide whether there is an assignment of\nvalues to the variables that satisfies equations of total weight at least\n$W/2+k$, where $k$ is the parameter. They asked whether this parameterized\nproblem is fixed-parameter tractable, i.e., can be solved in time\n$f(k)(nm)^{O(1)}$, where $f(k)$ is an arbitrary computable function in $k$\nonly. Their question remains open, but using some probabilistic inequalities\nand, in one case, a Fourier analysis inequality, Gutin et al. (IWPEC 2009)\nproved that the problem is fixed-parameter tractable in three special cases.\n  In this paper we significantly extend two of the three special cases using\nonly tools from combinatorics. We show that one of our results can be used to\nobtain a combinatorial proof that another problem from Mahajan et al. (J.\nComput. Syst. Sci. 75, 2009), Max $r$-SAT above the Average, is fixed-parameter\ntractable for each $r\\ge 2.$ Note that Max $r$-SAT above the Average has been\nalready shown to be fixed-parameter tractable by Alon et al. (SODA 2010), but\nthe paper used the approach of Gutin et al. (IWPEC 2009).\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2009 15:59:51 GMT"}], "update_date": "2009-12-01", "authors_parsed": [["Crowston", "Robert", ""], ["Gutin", "Gregory", ""], ["Jones", "Mark", ""]]}, {"id": "0911.5526", "submitter": "Moritz Hardt", "authors": "Boaz Barak, Moritz Hardt, Thomas Holenstein, David Steurer", "title": "Subsampling Mathematical Relaxations and Average-case Complexity", "comments": "Includes several more general results that subsume the previous\n  version of the paper.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a study of when the value of mathematical relaxations such as\nlinear and semidefinite programs for constraint satisfaction problems (CSPs) is\napproximately preserved when restricting the instance to a sub-instance induced\nby a small random subsample of the variables. Let $C$ be a family of CSPs such\nas 3SAT, Max-Cut, etc., and let $\\Pi$ be a relaxation for $C$, in the sense\nthat for every instance $P\\in C$, $\\Pi(P)$ is an upper bound the maximum\nfraction of satisfiable constraints of $P$. Loosely speaking, we say that\nsubsampling holds for $C$ and $\\Pi$ if for every sufficiently dense instance $P\n\\in C$ and every $\\epsilon>0$, if we let $P'$ be the instance obtained by\nrestricting $P$ to a sufficiently large constant number of variables, then\n$\\Pi(P') \\in (1\\pm \\epsilon)\\Pi(P)$. We say that weak subsampling holds if the\nabove guarantee is replaced with $\\Pi(P')=1-\\Theta(\\gamma)$ whenever\n$\\Pi(P)=1-\\gamma$. We show: 1. Subsampling holds for the BasicLP and BasicSDP\nprograms. BasicSDP is a variant of the relaxation considered by Raghavendra\n(2008), who showed it gives an optimal approximation factor for every CSP under\nthe unique games conjecture. BasicLP is the linear programming analog of\nBasicSDP. 2. For tighter versions of BasicSDP obtained by adding additional\nconstraints from the Lasserre hierarchy, weak subsampling holds for CSPs of\nunique games type. 3. There are non-unique CSPs for which even weak subsampling\nfails for the above tighter semidefinite programs. Also there are unique CSPs\nfor which subsampling fails for the Sherali-Adams linear programming hierarchy.\nAs a corollary of our weak subsampling for strong semidefinite programs, we\nobtain a polynomial-time algorithm to certify that random geometric graphs (of\nthe type considered by Feige and Schechtman, 2002) of max-cut value $1-\\gamma$\nhave a cut value at most $1-\\gamma/10$.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2009 23:23:38 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2010 21:35:23 GMT"}], "update_date": "2010-05-03", "authors_parsed": [["Barak", "Boaz", ""], ["Hardt", "Moritz", ""], ["Holenstein", "Thomas", ""], ["Steurer", "David", ""]]}]