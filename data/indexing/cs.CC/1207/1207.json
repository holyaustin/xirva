[{"id": "1207.0158", "submitter": "Dimitri Hendriks", "authors": "Joerg Endrullis, Dimitri Hendriks and Rena Bakhshi", "title": "On the Complexity of Equivalence of Specifications of Infinite Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of deciding the equality of infinite objects\nspecified by systems of equations, and of infinite objects specified by\nlambda-terms. For equational specifications there are several natural notions\nof equality: equality in all models, equality of the sets of solutions, and\nequality of normal forms for productive specifications. For lambda-terms we\ninvestigate Boehm-tree equality and various notions of observational equality.\nWe pinpoint the complexity of each of these notions in the arithmetical or\nanalytical hierarchy. We show that the complexity of deciding equality in all\nmodels subsumes the entire analytical hierarchy. This holds already for the\nmost simple infinite objects, viz. streams over {0,1}, and stands in sharp\ncontrast to the low arithmetical Pi^0_2-completeness of equality of\nequationally specified streams derived in [Rosu 2006] employing a different\nnotion of equality.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2012 22:06:21 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Endrullis", "Joerg", ""], ["Hendriks", "Dimitri", ""], ["Bakhshi", "Rena", ""]]}, {"id": "1207.0252", "submitter": "Amos Korman", "authors": "Pierre Fraigniaud and Amos Korman and Merav Parter and David Peleg", "title": "Randomized Distributed Decision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper tackles the power of randomization in the context of locality by\nanalyzing the ability to`boost' the success probability of deciding a\ndistributed language. The main outcome of this analysis is that the distributed\ncomputing setting contrasts significantly with the sequential one as far as\nrandomization is concerned. Indeed, we prove that in some cases, the ability to\nincrease the success probability for deciding distributed languages is rather\nlimited. Informally, a (p,q)-decider for a language L is a distributed\nrandomized algorithm which accepts instances in L with probability at least p\nand rejects instances outside of L with probability at least q. It is known\nthat every hereditary language that can be decided in t rounds by a\n(p,q)-decider, where p^2+q>1, can actually be decided deterministically in O(t)\nrounds. In one of our results we give evidence supporting the conjecture that\nthe above statement holds for all distributed languages. This is achieved by\nconsidering the restricted case of path topologies. We then turn our attention\nto the range below the aforementioned threshold, namely, the case where\np^2+q\\leq1. We define B_k(t) to be the set of all languages decidable in at\nmost t rounds by a (p,q)-decider, where p^{1+1/k}+q>1. It is easy to see that\nevery language is decidable (in zero rounds) by a (p,q)-decider satisfying\np+q=1. Hence, the hierarchy B_k provides a spectrum of complexity classes\nbetween determinism and complete randomization. We prove that all these classes\nare separated: for every integer k\\geq 1, there exists a language L satisfying\nL\\in B_{k+1}(0) but L\\notin B_k(t) for any t=o(n). In addition, we show that\nB_\\infty(t) does not contain all languages, for any t=o(n). Finally, we show\nthat if the inputs can be restricted in certain ways, then the ability to boost\nthe success probability becomes almost null.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 23:16:12 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Korman", "Amos", ""], ["Parter", "Merav", ""], ["Peleg", "David", ""]]}, {"id": "1207.0255", "submitter": "Pavel Klav\\'ik", "authors": "Pavel Klavik, Jan Kratochvil, Yota Otachi, Toshiki Saitoh", "title": "Extending Partial Representations of Subclasses of Chordal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chordal graphs are intersection graphs of subtrees of a tree T. We\ninvestigate the complexity of the partial representation extension problem for\nchordal graphs. A partial representation specifies a tree T' and some pre-drawn\nsubtrees of T'. It asks whether it is possible to construct a representation\ninside a modified tree T which extends the partial representation (i.e, keeps\nthe pre-drawn subtrees unchanged).\n  We consider four modifications of T' and get vastly different problems. In\nsome cases, it is interesting to consider the complexity even if just T' is\ngiven and no subtree is pre-drawn. Also, we consider three well-known\nsubclasses of chordal graphs: Proper interval graphs, interval graphs and path\ngraphs. We give an almost complete complexity characterization.\n  We further study the parametrized complexity of the problems when\nparametrized by the number of pre-drawn subtrees, the number of components and\nthe size of the tree T'. We describe an interesting relation with integer\npartition problems. The problem Partition is used for all NP-completeness\nreductions. The extension of interval graphs when the space in T' is limited is\n\"equivalent\" to the BinPacking problem.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 23:47:02 GMT"}, {"version": "v2", "created": "Mon, 20 May 2013 20:24:00 GMT"}], "update_date": "2013-05-22", "authors_parsed": [["Klavik", "Pavel", ""], ["Kratochvil", "Jan", ""], ["Otachi", "Yota", ""], ["Saitoh", "Toshiki", ""]]}, {"id": "1207.0393", "submitter": "J\\\"urgen Koslowski", "authors": "Jan Kraj\\'i\\v{c}ek", "title": "Pseudo-finite hard instances for a student-teacher game with a\n  Nisan-Wigderson generator", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 3 (August 13,\n  2012) lmcs:788", "doi": "10.2168/LMCS-8(3:9)2012", "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an NP intersect coNP function g of the Nisan-Wigderson type and a string\nb outside its range we consider a two player game on a common input a to the\nfunction. One player, a computationally limited Student, tries to find a bit of\ng(a) that differs from the corresponding bit of b. He can query a\ncomputationally unlimited Teacher for the witnesses of the values of constantly\nmany bits of g(a). The Student computes the queries from a and from Teacher's\nanswers to his previous queries. It was proved by Krajicek (2011) that if g is\nbased on a hard bit of a one-way permutation then no Student computed by a\npolynomial size circuit can succeed on all a. In this paper we give a lower\nbound on the number of inputs a any such Student must fail on. Using that we\nshow that there is a pseudo-finite set of hard instances on which all uniform\nstudents must fail. The hard-core set is defined in a non-standard model of\ntrue arithmetic and has applications in a forcing construction relevant to\nproof complexity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 14:12:50 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2012 09:15:34 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kraj\u00ed\u010dek", "Jan", ""]]}, {"id": "1207.0550", "submitter": "Thomas Vidick", "authors": "Tsuyoshi Ito and Thomas Vidick", "title": "A multi-prover interactive proof for NEXP sound against entangled\n  provers", "comments": "47 pages. Minor improvements; reduced number of provers from 4 to 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a strong limitation on the ability of entangled provers to collude\nin a multiplayer game. Our main result is the first nontrivial lower bound on\nthe class MIP* of languages having multi-prover interactive proofs with\nentangled provers; namely MIP* contains NEXP, the class of languages decidable\nin non-deterministic exponential time. While Babai, Fortnow, and Lund\n(Computational Complexity 1991) proved the celebrated equality MIP = NEXP in\nthe absence of entanglement, ever since the introduction of the class MIP* it\nwas open whether shared entanglement between the provers could weaken or\nstrengthen the computational power of multi-prover interactive proofs. Our\nresult shows that it does not weaken their computational power: MIP* contains\nMIP.\n  At the heart of our result is a proof that Babai, Fortnow, and Lund's\nmultilinearity test is sound even in the presence of entanglement between the\nprovers, and our analysis of this test could be of independent interest. As a\nbyproduct we show that the correlations produced by any entangled strategy\nwhich succeeds in the multilinearity test with high probability can always be\nclosely approximated using shared randomness alone.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 00:02:11 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2012 18:52:13 GMT"}], "update_date": "2012-09-27", "authors_parsed": [["Ito", "Tsuyoshi", ""], ["Vidick", "Thomas", ""]]}, {"id": "1207.0634", "submitter": "Sumit Kumar", "authors": "Garimella Rama Murthy (International Institute of Information\n  Technology, Gachibowli, Hyderabad, India)", "title": "Optimization of Quadratic Forms: NP Hard Problems : Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research paper, the problem of optimization of a quadratic form over\nthe convex hull generated by the corners of hypercube is attempted and solved.\nSome results related to stable states/vectors, anti-stable states/vectors (over\nthe hypercube) are discussed. Some results related to the computation of global\noptimum stable state (an NP hard problem) are discussed. It is hoped that the\nresults shed light on resolving the P \\neq NP problem.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 11:08:21 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Murthy", "Garimella Rama", "", "International Institute of Information\n  Technology, Gachibowli, Hyderabad, India"]]}, {"id": "1207.0663", "submitter": "Martin Zimmermann", "authors": "Nathana\\\"el Fijalkow (LIAFA, Universit\\'e Paris 7 and Institute of\n  Informatics, University of Warsaw), Martin Zimmermann (Saarland University)", "title": "Parity and Streett Games with Costs", "comments": "A preliminary version of this work appeared in FSTTCS 2012 under the\n  name \"Cost-parity and Cost-Streett Games\". The research leading to these\n  results has received funding from the European Union's Seventh Framework\n  Programme (FP7/2007-2013) under grant agreements 259454 (GALE) and 239850\n  (SOSNA)", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 2 (June 26,\n  2014) lmcs:794", "doi": "10.2168/LMCS-10(2:14)2014", "report-no": null, "categories": "cs.LO cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two-player games played on finite graphs equipped with costs on\nedges and introduce two winning conditions, cost-parity and cost-Streett, which\nrequire bounds on the cost between requests and their responses. Both\nconditions generalize the corresponding classical omega-regular conditions and\nthe corresponding finitary conditions. For parity games with costs we show that\nthe first player has positional winning strategies and that determining the\nwinner lies in NP and coNP. For Streett games with costs we show that the first\nplayer has finite-state winning strategies and that determining the winner is\nEXPTIME-complete. The second player might need infinite memory in both games.\nBoth types of games with costs can be solved by solving linearly many instances\nof their classical variants.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 13:16:47 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2012 11:45:48 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2013 09:49:15 GMT"}, {"version": "v4", "created": "Tue, 27 May 2014 18:55:03 GMT"}, {"version": "v5", "created": "Wed, 28 May 2014 08:39:07 GMT"}, {"version": "v6", "created": "Tue, 24 Jun 2014 00:12:57 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", "", "LIAFA, Universit\u00e9 Paris 7 and Institute of\n  Informatics, University of Warsaw"], ["Zimmermann", "Martin", "", "Saarland University"]]}, {"id": "1207.0933", "submitter": "Marek Karpinski", "authors": "Marek Karpinski, Andrzej Lingas, Dzmitry Sledneu", "title": "Optimal Cuts and Bisections on the Real Line in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exact complexity of geometric cuts and bisections is the longstanding\nopen problem including even the dimension one. In this paper, we resolve this\nproblem for dimension one (the real line) by designing an exact polynomial time\nalgorithm. Our results depend on a new technique of dealing with metric\nequalities and their connection to dynamic programming. The method of our\nsolution could be also of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 10:02:15 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Karpinski", "Marek", ""], ["Lingas", "Andrzej", ""], ["Sledneu", "Dzmitry", ""]]}, {"id": "1207.0979", "submitter": "Nicolai H\\\"ahnle", "authors": "Friedrich Eisenbrand and Nicolai H\\\"ahnle", "title": "Minimizing the number of lattice points in a translated polygon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parametric lattice-point counting problem is as follows: Given an integer\nmatrix $A \\in Z^{m \\times n}$, compute an explicit formula parameterized by $b\n\\in R^m$ that determines the number of integer points in the polyhedron $\\{x\n\\in R^n : Ax \\leq b\\}$. In the last decade, this counting problem has received\nconsiderable attention in the literature. Several variants of Barvinok's\nalgorithm have been shown to solve this problem in polynomial time if the\nnumber $n$ of columns of $A$ is fixed.\n  Central to our investigation is the following question: Can one also\nefficiently determine a parameter $b$ such that the number of integer points in\n$\\{x \\in R^n : Ax \\leq b\\}$ is minimized? Here, the parameter $b$ can be chosen\nfrom a given polyhedron $Q \\subseteq R^m$.\n  Our main result is a proof that finding such a minimizing parameter is\n$NP$-hard, even in dimension 2 and even if the parametrization reflects a\ntranslation of a 2-dimensional convex polygon. This result is established via a\nrelationship of this problem to arithmetic progressions and simultaneous\nDiophantine approximation.\n  On the positive side we show that in dimension 2 there exists a polynomial\ntime algorithm for each fixed $k$ that either determines a minimizing\ntranslation or asserts that any translation contains at most $1 + 1/k$ times\nthe minimal number of lattice points.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 13:34:33 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Eisenbrand", "Friedrich", ""], ["H\u00e4hnle", "Nicolai", ""]]}, {"id": "1207.1238", "submitter": "Mladen Kova\\v{c}evi\\'c", "authors": "Mladen Kova\\v{c}evi\\'c, Ivan Stanojevi\\'c, and Vojin \\v{S}enk", "title": "On the Hardness of Entropy Minimization and Related Problems", "comments": "IEEE Information Theory Workshop (ITW) 2012", "journal-ref": null, "doi": "10.1109/ITW.2012.6404727", "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate certain optimization problems for Shannon information\nmeasures, namely, minimization of joint and conditional entropies $H(X,Y)$,\n$H(X|Y)$, $H(Y|X)$, and maximization of mutual information $I(X;Y)$, over\nconvex regions. When restricted to the so-called transportation polytopes (sets\nof distributions with fixed marginals), very simple proofs of NP-hardness are\nobtained for these problems because in that case they are all equivalent, and\ntheir connection to the well-known \\textsc{Subset sum} and \\textsc{Partition}\nproblems is revealed. The computational intractability of the more general\nproblems over arbitrary polytopes is then a simple consequence. Further, a\nsimple class of polytopes is shown over which the above problems are not\nequivalent and their complexity differs sharply, namely, minimization of\n$H(X,Y)$ and $H(Y|X)$ is trivial, while minimization of $H(X|Y)$ and\nmaximization of $I(X;Y)$ are strongly NP-hard problems. Finally, two new\n(pseudo)metrics on the space of discrete probability distributions are\nintroduced, based on the so-called variation of information quantity, and\nNP-hardness of their computation is shown.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2012 12:25:06 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Kova\u010devi\u0107", "Mladen", ""], ["Stanojevi\u0107", "Ivan", ""], ["\u0160enk", "Vojin", ""]]}, {"id": "1207.1824", "submitter": "Meena Boppana", "authors": "Meena Boppana", "title": "Lattice Variant of the Sensitivity Conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sensitivity Conjecture, posed in 1994, states that the fundamental\nmeasures known as the sensitivity and block sensitivity of a Boolean function\nf, s(f) and bs(f) respectively, are polynomially related. It is known that\nbs(f) is polynomially related to important measures in computer science\nincluding the decision-tree depth, polynomial degree, and parallel RAM\ncomputation time of f, but little is known how the sensitivity compares; the\nseparation between s(f) and bs(f) is at least quadratic and at most\nexponential. We analyze a promising variant by Aaronson that implies the\nSensitivity Conjecture, stating that for all two-colorings of the d-dimensional\nlattice $\\mathbb{Z}^d$, d and the sensitivity s(C) are polynomially related,\nwhere s(C) is the maximum number of differently-colored neighbors of a point.\nWe construct a coloring with the largest known separation between d and s(C),\nin which $d=O(s(C)^2)$, and demonstrate that it is optimal for a large class of\ncolorings. We also give a reverse reduction from the Lattice Variant to the\nSensitivity Conjecture, and using this prove the first non-constant lower bound\non s(C). These results indicate that the Lattice Variant can help further the\nlimited progress on the Sensitivity Conjecture.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2012 19:26:09 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Boppana", "Meena", ""]]}, {"id": "1207.1885", "submitter": "Markus Jalsenius", "authors": "Raphael Clifford, Markus Jalsenius, Benjamin Sach", "title": "Tight Cell-Probe Bounds for Online Hamming Distance Computation", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show tight bounds for online Hamming distance computation in the\ncell-probe model with word size w. The task is to output the Hamming distance\nbetween a fixed string of length n and the last n symbols of a stream. We give\na lower bound of Omega((d/w)*log n) time on average per output, where d is the\nnumber of bits needed to represent an input symbol. We argue that this bound is\ntight within the model. The lower bound holds under randomisation and\namortisation.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 16:44:49 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2012 15:35:22 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2012 16:05:17 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Clifford", "Raphael", ""], ["Jalsenius", "Markus", ""], ["Sach", "Benjamin", ""]]}, {"id": "1207.2171", "submitter": "Satoshi Tazawa", "authors": "Satoshi Tazawa", "title": "Relationship between circuit complexity and symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is already shown that a Boolean function for a NP-complete problem can be\ncomputed by a polynomial-sized circuit if its variables have enough number of\nautomorphisms. Looking at this previous study from the different perspective\ngives us the idea that the small number of automorphisms might be a barrier for\na polynomial time solution for NP-complete problems. Here I show that by\ninterpreting a Boolean circuit as a graph, the small number of graph\nautomorphisms and the large number of subgraph automorphisms in the circuit\nestablishes the exponential circuit lower bound for NP-complete problems. As\nthis strategy violates the largeness condition in Natural proof, this result\nshows that P!=NP without any contradictions to the existence of pseudorandom\nfunctions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 19:45:23 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2012 18:34:34 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2012 15:26:16 GMT"}, {"version": "v4", "created": "Sun, 14 Apr 2013 18:02:25 GMT"}, {"version": "v5", "created": "Thu, 18 Apr 2013 09:58:45 GMT"}, {"version": "v6", "created": "Tue, 23 Apr 2013 15:48:53 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Tazawa", "Satoshi", ""]]}, {"id": "1207.2229", "submitter": "Ilias Diakonikolas", "authors": "Anindya De, Ilias Diakonikolas, Rocco A. Servedio", "title": "A robust Khintchine inequality, and algorithms for computing optimal\n  constants in Fourier analysis and high-dimensional geometry", "comments": "Extended abstract to appear in ICALP'13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes two contributions towards determining some well-studied\noptimal constants in Fourier analysis \\newa{of Boolean functions} and\nhigh-dimensional geometry.\n  \\begin{enumerate}\n  \\item It has been known since 1994 \\cite{GL:94} that every linear threshold\nfunction has squared Fourier mass at least 1/2 on its degree-0 and degree-1\ncoefficients. Denote the minimum such Fourier mass by $\\w^{\\leq 1}[\\ltf]$,\nwhere the minimum is taken over all $n$-variable linear threshold functions and\nall $n \\ge 0$. Benjamini, Kalai and Schramm \\cite{BKS:99} have conjectured that\nthe true value of $\\w^{\\leq 1}[\\ltf]$ is $2/\\pi$. We make progress on this\nconjecture by proving that $\\w^{\\leq 1}[\\ltf] \\geq 1/2 + c$ for some absolute\nconstant $c>0$. The key ingredient in our proof is a \"robust\" version of the\nwell-known Khintchine inequality in functional analysis, which we believe may\nbe of independent interest.\n  \\item We give an algorithm with the following property: given any $\\eta > 0$,\nthe algorithm runs in time $2^{\\poly(1/\\eta)}$ and determines the value of\n$\\w^{\\leq 1}[\\ltf]$ up to an additive error of $\\pm\\eta$. We give a similar\n$2^{{\\poly(1/\\eta)}}$-time algorithm to determine \\emph{Tomaszewski's constant}\nto within an additive error of $\\pm \\eta$; this is the minimum (over all\norigin-centered hyperplanes $H$) fraction of points in $\\{-1,1\\}^n$ that lie\nwithin Euclidean distance 1 of $H$. Tomaszewski's constant is conjectured to be\n1/2; lower bounds on it have been given by Holzman and Kleitman \\cite{HK92} and\nindependently by Ben-Tal, Nemirovski and Roos \\cite{BNR02}.\n  Our algorithms combine tools from anti-concentration of sums of independent\nrandom variables, Fourier analysis, and Hermite analysis of linear threshold\nfunctions.\n  \\end{enumerate}\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 06:27:44 GMT"}, {"version": "v2", "created": "Fri, 3 May 2013 01:18:51 GMT"}], "update_date": "2013-05-06", "authors_parsed": [["De", "Anindya", ""], ["Diakonikolas", "Ilias", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1207.2354", "submitter": "Mingji Xia", "authors": "Jin-Yi Cai, Pinyan Lu, Mingji Xia", "title": "Dichotomy for Holant* Problems with a Function on Domain Size 3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Holant problems are a general framework to study the algorithmic complexity\nof counting problems. Both counting constraint satisfaction problems and graph\nhomomorphisms are special cases. All previous results of Holant problems are\nover the Boolean domain. In this paper, we give the first dichotomy theorem for\nHolant problems for domain size $>2$. We discover unexpected tractable families\nof counting problems, by giving new polynomial time algorithms. This paper also\ninitiates holographic reductions in domains of size $>2$. This is our main\nalgorithmic technique, and is used for both tractable families and hardness\nreductions. The dichotomy theorem is the following: For any complex-valued\nsymmetric function ${\\bf F}$ with arity 3 on domain size 3, we give an explicit\ncriterion on ${\\bf F}$, such that if ${\\bf F}$ satisfies the criterion then the\nproblem ${\\rm Holant}^*({\\bf F})$ is computable in polynomial time, otherwise\n${\\rm Holant}^*({\\bf F})$ is #P-hard.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 13:52:15 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Lu", "Pinyan", ""], ["Xia", "Mingji", ""]]}, {"id": "1207.3154", "submitter": "Fraser Stewart Dr.", "authors": "Fraser Stewart", "title": "Escape and Evasion on Finite Graphs", "comments": "This paper has been withdrawn due to an error with theorem 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we will be introducing a type of game which as far as this\nauthor is aware has never been studied before. These are games where there are\ntwo players, one who is trying to get one of his pieces, called a King to a\npredefined escape vertex, and the other, called attackers, who is trying to\ncapture him by occupying all of his neighbours. We will be showing that this\ngame is PSpace-complete if it is limited to $M$ moves and taking a brief look\nat some potential ways to simplify the problem and work out how many attackers\nare needed to capture the King on different types of graphs.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 06:12:56 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2012 19:31:10 GMT"}], "update_date": "2012-09-07", "authors_parsed": [["Stewart", "Fraser", ""]]}, {"id": "1207.3586", "submitter": "Gregory Gutin", "authors": "Robert Crowston, Gregory Gutin, Mark Jones", "title": "Directed Acyclic Subgraph Problem Parameterized above the Poljak-Turzik\n  Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An oriented graph is a directed graph without directed 2-cycles. Poljak and\nTurz\\'{i}k (1986) proved that every connected oriented graph $G$ on $n$\nvertices and $m$ arcs contains an acyclic subgraph with at least\n$\\frac{m}{2}+\\frac{n-1}{4}$ arcs. Raman and Saurabh (2006) gave another proof\nof this result and left it as an open question to establish the parameterized\ncomplexity of the following problem: does $G$ have an acyclic subgraph with\nleast $\\frac{m}{2}+\\frac{n-1}{4}+k$ arcs, where $k$ is the parameter? We answer\nthis question by showing that the problem can be solved by an algorithm of\nruntime $(12k)!n^{O(1)}$. Thus, the problem is fixed-parameter tractable. We\nalso prove that there is a polynomial time algorithm that either establishes\nthat the input instance of the problem is a Yes-instance or reduces the input\ninstance to an equivalent one of size $O(k^2)$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 06:36:56 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2012 13:10:18 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Crowston", "Robert", ""], ["Gutin", "Gregory", ""], ["Jones", "Mark", ""]]}, {"id": "1207.3622", "submitter": "Liam Roditty", "authors": "Liam Roditty and Virginia Vassilevska Williams", "title": "Approximating the diameter of a graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the fundamental problem of approximating the\ndiameter $D$ of directed or undirected graphs. In a seminal paper, Aingworth,\nChekuri, Indyk and Motwani [SIAM J. Comput. 1999] presented an algorithm that\ncomputes in $\\Ot(m\\sqrt n + n^2)$ time an estimate $\\hat{D}$ for the diameter\nof an $n$-node, $m$-edge graph, such that $\\lfloor 2/3 D \\rfloor \\leq \\hat{D}\n\\leq D$. In this paper we present an algorithm that produces the same estimate\nin $\\Ot(m\\sqrt n)$ expected running time. We then provide strong evidence that\na better approximation may be hard to obtain if we insist on an $O(m^{2-\\eps})$\nrunning time. In particular, we show that if there is some constant $\\eps>0$ so\nthat there is an algorithm for undirected unweighted graphs that runs in\n$O(m^{2-\\eps})$ time and produces an approximation $\\hat{D}$ such that $\n(2/3+\\eps) D \\leq \\hat{D} \\leq D$, then SAT for CNF formulas on $n$ variables\ncan be solved in $O^{*}((2-\\delta)^{n})$ time for some constant $\\delta>0$, and\nthe strong exponential time hypothesis of [Impagliazzo, Paturi, Zane JCSS'01]\nis false.\n  Motivated by this somewhat negative result, we study whether it is possible\nto obtain a better approximation for specific cases. For unweighted directed or\nundirected graphs, we show that if $D=3h+z$, where $h\\geq 0$ and $z\\in\n{0,1,2}$, then it is possible to report in $\\tilde{O}(\\min{m^{2/3}\nn^{4/3},m^{2-1/(2h+3)}})$ time an estimate $\\hat{D}$ such that $2h+z \\leq\n\\hat{D}\\leq D$, thus giving a better than 3/2 approximation whenever $z\\neq 0$.\nThis is significant for constant values of $D$ which is exactly when the\ndiameter approximation problem is hardest to solve. For the case of unweighted\nundirected graphs we present an $\\tilde{O}(m^{2/3} n^{4/3})$ time algorithm\nthat reports an estimate $\\hat{D}$ such that $\\lfloor 4D/5\\rfloor \\leq\n\\hat{D}\\leq D$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 10:25:13 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Roditty", "Liam", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1207.3880", "submitter": "Abuzer Yakaryilmaz", "authors": "Abuzer Yakaryilmaz", "title": "One-counter verifiers for decidable languages", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Condon and Lipton (FOCS 1989) showed that the class of languages having a\nspace-bounded interactive proof system (IPS) is a proper subset of decidable\nlanguages, where the verifier is a probabilistic Turing machine. In this paper,\nwe show that if we use architecturally restricted verifiers instead of\nrestricting the working memory, i.e. replacing the working tape(s) with a\nsingle counter, we can define some IPS's for each decidable language. Such\nverifiers are called two-way probabilistic one-counter automata (2pca's). Then,\nwe show that by adding a fixed-size quantum memory to a 2pca, called a two-way\none-counter automaton with quantum and classical states (2qcca), the protocol\ncan be space efficient. As a further result, if the 2qcca can use a quantum\ncounter instead of a classical one, then the protocol can even be public, also\nknown as Arthur-Merlin games.\n  We also investigate the computational power of 2pca's and 2qcca's as language\nrecognizers. We show that bounded-error 2pca's can be more powerful than their\ndeterministic counterparts by giving a bounded-error simulation of their\nnondeterministic counterparts. Then, we present a new programming technique for\nbounded-error 2qcca's and show that they can recognize a language which seems\nnot to be recognized by any bounded-error 2pca. We also obtain some interesting\nresults for bounded-error 1-pebble quantum finite automata based on this new\ntechnique. Lastly, we prove a conjecture posed by Ravikumar (FSTTCS 1992)\nregarding 1-pebble probabilistic finite automata, i.e. they can recognize some\nnonstochastic languages with bounded error.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 05:17:02 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Yakaryilmaz", "Abuzer", ""]]}, {"id": "1207.4537", "submitter": "Mirmojtaba Gharibi", "authors": "Mirmojtaba Gharibi", "title": "Reduction from non-injective hidden shift problem to injective hidden\n  shift problem", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple tool that can be used to reduce non-injective instances\nof the hidden shift problem over arbitrary group to injective instances over\nthe same group. In particular, we show that the average-case non-injective\nhidden shift problem admit this reduction. We show similar results for\n(non-injective) hidden shift problem for bent functions. We generalize the\nnotion of influence and show how it relates to applicability of this tool for\ndoing reductions. In particular, these results can be used to simplify the main\nresults by Gavinsky, Roetteler, and Roland about the hidden shift problem for\nthe Boolean-valued functions and bent functions, and also to generalize their\nresults to non-Boolean domains (thereby answering an open question that they\npose).\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 02:54:56 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2012 04:47:11 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Gharibi", "Mirmojtaba", ""]]}, {"id": "1207.4694", "submitter": "Martin R. Schuster", "authors": "Maciej Liskiewicz and Martin R. Schuster", "title": "A New Upper Bound for the Traveling Salesman Problem in Cubic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new upper bound for traveling salesman problem (TSP) in cubic\ngraphs, i.e. graphs with maximum vertex degree three, and prove that the\nproblem for an $n$-vertex graph can be solved in $O(1.2553^n)$ time and in\nlinear space. We show that the exact TSP algorithm of Eppstein, with some minor\nmodifications, yields the stated result. The previous best known upper bound\n$O(1.251^n)$ was claimed by Iwama and Nakashima [Proc. COCOON 2007].\nUnfortunately, their analysis contains several mistakes that render the proof\nfor the upper bound invalid.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 14:58:30 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2012 13:44:09 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Liskiewicz", "Maciej", ""], ["Schuster", "Martin R.", ""]]}, {"id": "1207.4710", "submitter": "Dror Fried", "authors": "Dror Fried, Solomon Eyal Shimony, Amit Benbassat, Cenny Wenner", "title": "Complexity of Canadian Traveler Problem Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Canadian traveler problem (CTP) is the problem of traversing a given\ngraph, where some of the edges may be blocked - a state which is revealed only\nupon reaching an incident vertex. Originally stated by Papadimitriou and\nYannakakis (1991), the adversarial version of CTP was shown to be\nPSPACE-complete, with the stochastic version shown to be #P-hard. We show that\nstochastic CTP is also PSPACE-complete: initially proving PSPACE-hardness for\nthe dependent version of stochastic CTP,and proceeding with gadgets that allow\nus to extend the proof to the independent case. Since for disjoint-path graphs,\nCTP can be solved in polynomial time, we examine the complexity of the more\ngeneral remote-sensing CTP, and show that it is NP-hard even for disjoint-path\ngraphs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 15:39:52 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Fried", "Dror", ""], ["Shimony", "Solomon Eyal", ""], ["Benbassat", "Amit", ""], ["Wenner", "Cenny", ""]]}, {"id": "1207.4715", "submitter": "Tomislav Petrovi\\'c dipl. ing.", "authors": "Tomislav Petrovi\\'c", "title": "\"Two betting strategies that predict all compressible sequences\"\n  presentation", "comments": "the prezentacija.tex file also contains text that goes with each\n  slide, it's in the comments at the end of the file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presentation for a talk \"Two betting strategies that predict all compressible\nsequences\" given at Seventh International Conference on Computability,\nComplexity and Randomness (CCR 2012)\nhttp://www.newton.ac.uk/programmes/SAS/seminars/070217001.html\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 15:59:15 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Petrovi\u0107", "Tomislav", ""]]}, {"id": "1207.4783", "submitter": "Arnab Bhattacharyya", "authors": "Sanjeev Arora and Arnab Bhattacharyya and Rajsekar Manokaran and\n  Sushant Sachdeva", "title": "Testing Permanent Oracles -- Revisited", "comments": "Appears at RANDOM '12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we are given an oracle that claims to approximate the permanent for\nmost matrices X, where X is chosen from the Gaussian ensemble (the matrix\nentries are i.i.d. univariate complex Gaussians). Can we test that the oracle\nsatisfies this claim? This paper gives a polynomial-time algorithm for the\ntask. The oracle-testing problem is of interest because a recent paper of\nAaronson and Arkhipov showed that if there is a polynomial-time algorithm for\nsimulating boson-boson interactions in quantum mechanics, then an approximation\noracle for the permanent (of the type described above) exists in BPP^NP. Since\ncomputing the permanent of even 0/1 matrices is #P-complete, this seems to\ndemonstrate more computational power in quantum mechanics than Shor's factoring\nalgorithm does. However, unlike factoring, which is in NP, it was unclear\npreviously how to test the correctness of an approximation oracle for the\npermanent, and this is the contribution of the paper. The technical difficulty\novercome here is that univariate polynomial self-correction, which underlies\nsimilar oracle-testing algorithms for permanent over finite fields --- and\nwhose discovery led to a revolution in complexity theory --- does not seem to\ngeneralize to complex (or even, real) numbers. We believe that this tester will\nmotivate further progress on understanding the permanent of Gaussian matrices.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 19:54:55 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Arora", "Sanjeev", ""], ["Bhattacharyya", "Arnab", ""], ["Manokaran", "Rajsekar", ""], ["Sachdeva", "Sushant", ""]]}, {"id": "1207.4900", "submitter": "Bart M. P. Jansen", "authors": "Hans L. Bodlaender and Bart M. P. Jansen and Stefan Kratsch", "title": "Kernel Bounds for Structural Parameterizations of Pathwidth", "comments": "This paper contains the proofs omitted from the extended abstract\n  published in the proceedings of Algorithm Theory - SWAT 2012 - 13th\n  Scandinavian Symposium and Workshops, Helsinki, Finland, July 4-6, 2012", "journal-ref": "Lecture Notes in Computer Science 7357 (2012) 352-363", "doi": "10.1007/978-3-642-31155-0_31", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assuming the AND-distillation conjecture, the Pathwidth problem of\ndetermining whether a given graph G has pathwidth at most k admits no\npolynomial kernelization with respect to k. The present work studies the\nexistence of polynomial kernels for Pathwidth with respect to other,\nstructural, parameters. Our main result is that, unless NP is in coNP/poly,\nPathwidth admits no polynomial kernelization even when parameterized by the\nvertex deletion distance to a clique, by giving a cross-composition from\nCutwidth. The cross-composition works also for Treewidth, improving over\nprevious lower bounds by the present authors. For Pathwidth, our result rules\nout polynomial kernels with respect to the distance to various classes of\npolynomial-time solvable inputs, like interval or cluster graphs. This leads to\nthe question whether there are nontrivial structural parameters for which\nPathwidth does admit a polynomial kernelization. To answer this, we give a\ncollection of graph reduction rules that are safe for Pathwidth. We analyze the\nsuccess of these results and obtain polynomial kernelizations with respect to\nthe following parameters: the size of a vertex cover of the graph, the vertex\ndeletion distance to a graph where each connected component is a star, and the\nvertex deletion distance to a graph where each connected component has at most\nc vertices.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 10:09:36 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Jansen", "Bart M. P.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1207.5211", "submitter": "Danupon Nanongkai", "authors": "Michael Elkin and Hartmut Klauck and Danupon Nanongkai and Gopal\n  Pandurangan", "title": "Can Quantum Communication Speed Up Distributed Computation?", "comments": "Full version of PODC 2014 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is on {\\em quantum distributed} computation, where we\ninvestigate whether quantum communication can help in {\\em speeding up}\ndistributed network algorithms. Our main result is that for certain fundamental\nnetwork problems such as minimum spanning tree, minimum cut, and shortest\npaths, quantum communication {\\em does not} help in substantially speeding up\ndistributed algorithms for these problems compared to the classical setting.\n  In order to obtain this result, we extend the technique of Das Sarma et al.\n[SICOMP 2012] to obtain a uniform approach to prove non-trivial lower bounds\nfor quantum distributed algorithms for several graph optimization (both exact\nand approximate versions) as well as verification problems, some of which are\nnew even in the classical setting, e.g. tight randomized lower bounds for\nHamiltonian cycle and spanning tree verification, answering an open problem of\nDas Sarma et al., and a lower bound in terms of the weight aspect ratio,\nmatching the upper bounds of Elkin [STOC 2004]. Our approach introduces the\n{\\em Server model} and {\\em Quantum Simulation Theorem} which together provide\na connection between distributed algorithms and communication complexity. The\nServer model is the standard two-party communication complexity model augmented\nwith additional power; yet, most of the hardness in the two-party model is\ncarried over to this new model. The Quantum Simulation Theorem carries this\nhardness further to quantum distributed computing. Our techniques, except the\nproof of the hardness in the Server model, require very little knowledge in\nquantum computing, and this can help overcoming a usual impediment in proving\nbounds on quantum distributed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2012 09:55:59 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2012 07:15:40 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2013 03:27:09 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2013 12:09:07 GMT"}, {"version": "v5", "created": "Fri, 9 May 2014 01:19:39 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Elkin", "Michael", ""], ["Klauck", "Hartmut", ""], ["Nanongkai", "Danupon", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1207.5220", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "Integer factoring and modular square roots", "comments": "24 pages; to appear in Journal of Computer and System Sciences", "journal-ref": "Journal of Computer and System Sciences 82 (2016), no. 2, pp.\n  380--394", "doi": "10.1016/j.jcss.2015.08.001", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buresh-Oppenheim proved that the NP search problem to find nontrivial factors\nof integers of a special form belongs to Papadimitriou's class PPA, and is\nprobabilistically reducible to a problem in PPP. In this paper, we use ideas\nfrom bounded arithmetic to extend these results to arbitrary integers. We show\nthat general integer factoring is reducible in randomized polynomial time to a\nPPA problem and to the problem WEAKPIGEON in PPP. Both reductions can be\nderandomized under the assumption of the generalized Riemann hypothesis. We\nalso show (unconditionally) that PPA contains some related problems, such as\nsquare root computation modulo n, and finding quadratic nonresidues modulo n.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2012 12:19:38 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2012 14:38:13 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2015 15:37:55 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "1207.5321", "submitter": "Magnus Find", "authors": "Joan Boyar, Magnus Find", "title": "Cancellation-free circuits: An approach for proving superlinear lower\n  bounds for linear Boolean operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue to study the notion of cancellation-free linear circuits. We show\nthat every matrix can be computed by a cancellation- free circuit, and almost\nall of these are at most a constant factor larger than the optimum linear\ncircuit that computes the matrix. It appears to be easier to prove statements\nabout the structure of cancellation-free linear circuits than for linear\ncircuits in general. We prove two nontrivial superlinear lower bounds. We show\nthat a cancellation-free linear circuit computing the $n\\times n$ Sierpinski\ngasket matrix must use at least 1/2 n logn gates, and that this is tight. This\nsupports a conjecture by Aaronson. Furthermore we show that a proof strategy\nfor proving lower bounds on monotone circuits can be almost directly converted\nto prove lower bounds on cancellation-free linear circuits. We use this\ntogether with a result from extremal graph theory due to Andreev to prove a\nlower bound of {\\Omega}(n^(2- \\epsilon)) for infinitely many $n \\times n$\nmatrices for every $\\epsilon > 0$ for. These lower bounds for concrete matrices\nare almost optimal since all matrices can be computed with $O(n^2/\\log n)$\ngates.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 08:50:09 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Boyar", "Joan", ""], ["Find", "Magnus", ""]]}, {"id": "1207.5636", "submitter": "Archontia C. Giannopoulou", "authors": "Archontia C. Giannopoulou, Iosif Salem, Dimitris Zoros", "title": "Effective Computation of Immersion Obstructions for Unions of Graph\n  Classes", "comments": "An extended abstract of this paper has appeared in the proceedings of\n  the 13th Scandinavian Symposium and Workshops on Algorithm Theory (SWAT 2012)\n  that took place in Helsinki, Finland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In the final paper of the Graph Minors series N. Robertson and P. Seymour\nproved that graphs are well-quasi-ordered under the immersion ordering. A\ndirect implication of this theorem is that each class of graphs that is closed\nunder taking immersions can be fully characterized by forbidding a finite set\nof graphs (immersion obstruction set). However, as the proof of the\nwell-quasi-ordering theorem is non-constructive, there is no generic procedure\nfor computing such a set. Moreover, it remains an open issue to identify for\nwhich immersion-closed graph classes the computation of those sets can become\neffective. By adapting the tools that were introduced by I. Adler, M. Grohe and\nS. Kreutzer, for the effective computation of minor obstruction sets, we expand\nthe horizon of computability to immersion obstruction sets. In particular, our\nresults propagate the computability of immersion obstruction sets of\nimmersion-closed graph classes to immersion obstruction sets of finite unions\nof immersion closed graph classes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 09:43:09 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Giannopoulou", "Archontia C.", ""], ["Salem", "Iosif", ""], ["Zoros", "Dimitris", ""]]}, {"id": "1207.5696", "submitter": "Ond\\v{r}ej Such\\'y", "authors": "Matthias Mnich, Geevarghese Philip, Saket Saurabh, and Ond\\v{r}ej\n  Such\\'y", "title": "Beyond Max-Cut: \\lambda-Extendible Properties Parameterized Above the\n  Poljak-Turz\\'{i}k Bound", "comments": "23 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poljak and Turz\\'ik (Discrete Math. 1986) introduced the notion of\n\\lambda-extendible properties of graphs as a generalization of the property of\nbeing bipartite. They showed that for any 0<\\lambda<1 and \\lambda-extendible\nproperty \\Pi, any connected graph G on n vertices and m edges contains a\nsubgraph H \\in {\\Pi} with at least \\lambda m+ (1-\\lambda)/2 (n-1) edges. The\nproperty of being bipartite is 1/2-extendible, and thus this bound generalizes\nthe Edwards-Erd\\H{o}s bound for Max-Cut.\n  We define a variant, namely strong \\lambda-extendibility, to which the bound\napplies. For a strongly \\lambda-extendible graph property \\Pi, we define the\nparameterized Above Poljak- Turz\\'ik (APT) (\\Pi) problem as follows: Given a\nconnected graph G on n vertices and m edges and an integer parameter k, does\nthere exist a spanning subgraph H of G such that H \\in {\\Pi} and H has at least\n\\lambda m + (1-\\lambda)/2 (n - 1) + k edges? The parameter is k, the surplus\nover the number of edges guaranteed by the Poljak-Turz\\'ik bound.\n  We consider properties {\\Pi} for which APT (\\Pi) is fixed- parameter\ntractable (FPT) on graphs which are O(k) vertices away from being a graph in\nwhich each block is a clique. We show that for all such properties, APT (\\Pi)\nis FPT for all 0<\\lambda<1. Our results hold for properties of oriented graphs\nand graphs with edge labels. Our results generalize the result of Crowston et\nal. (ICALP 2012) on Max-Cut parameterized above the Edwards-Erd\\H{o}s bound,\nand yield FPT algorithms for several graph problems parameterized above lower\nbounds, e.g., Max q-Colorable Subgraph problem. Our results also imply that the\nparameterized above-guarantee Oriented Max Acyclic Digraph problem is FPT, thus\nsolving an open question of Raman and Saurabh (Theor. Comput. Sci. 2006).\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 13:34:31 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Mnich", "Matthias", ""], ["Philip", "Geevarghese", ""], ["Saurabh", "Saket", ""], ["Such\u00fd", "Ond\u0159ej", ""]]}, {"id": "1207.5884", "submitter": "Jinyu Huang", "authors": "Jinyu Huang", "title": "Black-box Identity Testing for Low Degree Unmixed\n  $\\Sigma\\Pi\\Sigma\\Pi(k)$ Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $\\Sigma\\Pi\\Sigma\\Pi(k)$ circuit\n$C=\\sum_{i=1}^kF_i=\\sum_{i=1}^k\\prod_{j=1}^{d_i}f_{ij}$ is unmixed if for each\n$i\\in[k]$, $F_i=f_{i1}(x_1)... f_{in}(x_n)$, where each $f_{ij}$ is a\nunivariate polynomial given in the sparse representation. In this paper, we\ngive a polynomial time black-box algorithm of identity testing for the low\ndegree unmixed $\\Sigma\\Pi\\Sigma\\Pi(k)$ circuits. In order to obtain the\nblack-box algorithm, we first show that a special class of low degree unmixed\n$\\Sigma\\Pi\\Sigma\\Pi(k)$ circuits of size $s$ is $s^{O(k^2)}$-sparse. Then we\nconstruct a hitting set $\\mathcal{H}$ in polynomial time for the low degree\nunmixed $\\Sigma\\Pi\\Sigma\\Pi(k)$ circuits from the sparsity result above. The\nconstructed hitting set is polynomial size. Thus we can test whether the\ncircuit or the polynomial $C$ is identically zero by checking whether $C(a)=0$\nfor each $a\\in\\mathcal{H}$. This is the first polynomial time black-box\nalgorithm for the low degree unmixed $\\Sigma\\Pi\\Sigma\\Pi(k)$ circuits, which\nalso partly answers a question of Saxena \\cite{SAX}.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 04:02:06 GMT"}], "update_date": "2012-07-26", "authors_parsed": [["Huang", "Jinyu", ""]]}, {"id": "1207.6188", "submitter": "Mahyuddin K. M.  Nasution", "authors": "Mahyuddin K. M. Nasution", "title": "Kolmogorov Complexity: Clustering Objects and Similarity", "comments": "13 pages; Bulletin of Mathematics, Vol. 3 (2011), No. 1: 1-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clustering objects has become one of themes in many studies, and do not\nfew researchers use the similarity to cluster the instances automatically.\nHowever, few research consider using Kommogorov Complexity to get information\nabout objects from documents, such as Web pages, where the rich information\nfrom an approach proved to be difficult to. In this paper, we proposed a\nsimilarity measure from Kolmogorov Complexity, and we demonstrate the\npossibility of exploiting features from Web based on hit counts for objects of\nIndonesia Intellectual.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 07:35:53 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Nasution", "Mahyuddin K. M.", ""]]}, {"id": "1207.6260", "submitter": "Andrej Bogdanov", "authors": "Andrej Bogdanov, Siyao Guo", "title": "Sparse extractor families for all the entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of extracting entropy by sparse transformations,\nnamely functions with a small number of overall input-output dependencies. In\ncontrast to previous works, we seek extractors for essentially all the entropy\nwithout any assumption on the underlying distribution beyond a min-entropy\nrequirement. We give two simple constructions of sparse extractor families,\nwhich are collections of sparse functions such that for any distribution X on\ninputs of sufficiently high min-entropy, the output of most functions from the\ncollection on a random input chosen from X is statistically close to uniform.\n  For strong extractor families (i.e., functions in the family do not take\nadditional randomness) we give upper and lower bounds on the sparsity that are\ntight up to a constant factor for a wide range of min-entropies. We then prove\nthat for some min-entropies weak extractor families can achieve better\nsparsity.\n  We show how this construction can be used towards more efficient parallel\ntransformation of (non-uniform) one-way functions into pseudorandom generators.\nMore generally, sparse extractor families can be used instead of pairwise\nindependence in various randomized or nonuniform settings where preserving\nlocality (i.e., parallelism) is of interest.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 13:00:44 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Bogdanov", "Andrej", ""], ["Guo", "Siyao", ""]]}, {"id": "1207.6692", "submitter": "Stanislav Zivny", "authors": "David A. Cohen, Martin C. Cooper, Paidi Creed, Peter G. Jeavons,\n  Stanislav Zivny", "title": "An Algebraic Theory of Complexity for Discrete Optimisation", "comments": "26 pages, full version of three conference papers: CP'06, MFCS'11,\n  and CP'11", "journal-ref": "SIAM Journal on Computing 42(5) 1915-1939 (2013)", "doi": "10.1137/130906398", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete optimisation problems arise in many different areas and are studied\nunder many different names. In many such problems the quantity to be optimised\ncan be expressed as a sum of functions of a restricted form. Here we present a\nunifying theory of complexity for problems of this kind. We show that the\ncomplexity of a finite-domain discrete optimisation problem is determined by\ncertain algebraic properties of the objective function, which we call weighted\npolymorphisms. We define a Galois connection between sets of rational-valued\nfunctions and sets of weighted polymorphisms and show how the closed sets of\nthis Galois connection can be characterised.\n  These results provide a new approach to studying the complexity of discrete\noptimisation. We use this approach to identify certain maximal tractable\nsubproblems of the general problem, and hence derive a complete classification\nof complexity for the Boolean case.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2012 09:01:36 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Cohen", "David A.", ""], ["Cooper", "Martin C.", ""], ["Creed", "Paidi", ""], ["Jeavons", "Peter G.", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1207.6696", "submitter": "Hubie Chen", "authors": "Hubie Chen (Univ. Pompeu Fabra), Moritz M\\\"uller (Kurt G\\\"odel\n  Research Center, Universit\\\"at Wien)", "title": "An Algebraic Preservation Theorem for Aleph-Zero Categorical Quantified\n  Constraint Satisfaction", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 1 (March 29,\n  2013) lmcs:1009", "doi": "10.2168/LMCS-9(1:15)2013", "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an algebraic preservation theorem for positive Horn definability in\naleph-zero categorical structures. In particular, we define and study a\nconstruction which we call the periodic power of a structure, and define a\nperiomorphism of a structure to be a homomorphism from the periodic power of\nthe structure to the structure itself. Our preservation theorem states that,\nover an aleph-zero categorical structure, a relation is positive Horn definable\nif and only if it is preserved by all periomorphisms of the structure. We give\napplications of this theorem, including a new proof of the known complexity\nclassification of quantified constraint satisfaction on equality templates.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2012 11:36:09 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2013 17:41:12 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2013 20:39:09 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Chen", "Hubie", "", "Univ. Pompeu Fabra"], ["M\u00fcller", "Moritz", "", "Kurt G\u00f6del\n  Research Center, Universit\u00e4t Wien"]]}, {"id": "1207.6864", "submitter": "Junhao Peng Dr", "authors": "Junhao Peng, Guoai Xu", "title": "Tutte polynomial of pseudofractal scale-free web", "comments": "19pages,7figures. arXiv admin note: text overlap with arXiv:1006.5333", "journal-ref": "Journal of Statistical Physics, 2015", "doi": "10.1007/s10955-015-1225-x", "report-no": "159:1196--1215", "categories": "math-ph cs.CC math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tutte polynomial of a graph is a 2-variable polynomial which is quite\nimportant in both combinatorics and statistical physics. It contains various\nnumerical invariants and polynomial invariants, such as the number of spanning\ntrees, the number of spanning forests, the number of acyclic orientations, the\nreliability polynomial, chromatic polynomial and flow polynomial. In this\npaper, we study and gain recursive formulas for the Tutte polynomial of\npseudofractal scale-free web (PSW) which implies logarithmic complexity\nalgorithm is obtained to calculate the Tutte polynomial of PSW although it is\nNP-hard for general graph. We also obtain the rigorous solution for the the\nnumber of spanning trees of PSW by solving the recurrence relations derived\nfrom Tutte polynomial, which give an alternative approach for explicitly\ndetermining the number of spanning trees of PSW. Further more, we analysis the\nall-terminal reliability of PSW and compare the results with that of Sierpinski\ngasket which has the same number of nodes and edges with PSW. In contrast with\nthe well-known conclusion that scale-free networks are more robust against\nremoval of nodes than homogeneous networks (e.g., exponential networks and\nregular networks). Our results show that Sierpinski gasket (which is a regular\nnetwork) are more robust against random edge failures than PSW (which is a\nscale-free network). Whether it is true for any regular networks and scale-free\nnetworks, is still a unresolved problem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 08:21:41 GMT"}, {"version": "v2", "created": "Sat, 25 May 2013 01:57:18 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Peng", "Junhao", ""], ["Xu", "Guoai", ""]]}, {"id": "1207.6945", "submitter": "Jonathan Ullman", "authors": "Jonathan Ullman", "title": "Answering n^{2+o(1)} Counting Queries with Differential Privacy is Hard", "comments": "Full version of our STOC'13 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in differentially private data analysis is how to design\nefficient algorithms capable of answering large numbers of counting queries on\na sensitive database. Counting queries of the form \"What fraction of individual\nrecords in the database satisfy the property q?\" We prove that if one-way\nfunctions exist, then there is no algorithm that takes as input a database D in\n({0,1}^d)^n, and k = n^{2+o(1)} arbitrary efficiently computable counting\nqueries, runs in time poly(d, n), and returns an approximate answer to each\nquery, while satisfying differential privacy. We also consider the complexity\nof answering \"simple\" counting queries, and make some progress in this\ndirection by showing that the above result holds even when we require that the\nqueries are computable by constant depth (AC-0) circuits.\n  Our result is almost tight in the sense that nearly n^2 counting queries can\nbe answered efficiently while satisfying differential privacy. Moreover,\nsuper-polynomially many queries can be answered in exponential time.\n  We prove our results by extending the connection between differentially\nprivate counting query release and cryptographic traitor-tracing schemes to the\nsetting where the queries are given to the sanitizer as input, and by\nconstructing a traitor-tracing scheme that is secure in this setting.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 14:34:26 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2012 14:35:50 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2013 13:23:21 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Ullman", "Jonathan", ""]]}, {"id": "1207.7034", "submitter": "Steven Kelk", "authors": "Steven Kelk and Celine Scornavacca", "title": "Towards the fixed parameter tractability of constructing minimal\n  phylogenetic networks from arbitrary sets of nonbinary trees", "comments": "have fixed a number of small typo's etc", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has remained an open question for some time whether, given a set of not\nnecessarily binary (i.e. \"nonbinary\") trees T on a set of taxa X, it is\npossible to determine in time f(r).poly(m) whether there exists a phylogenetic\nnetwork that displays all the trees in T, where r refers to the reticulation\nnumber of the network and m=|X|+|T|. Here we show that this holds if one or\nboth of the following conditions holds: (1) |T| is bounded by a function of r;\n(2) the maximum degree of the nodes in T is bounded by a function of r. These\nsufficient conditions absorb and significantly extend known special cases,\nnamely when all the trees in T are binary, or T contains exactly two nonbinary\ntrees. We believe this result is an important step towards settling the issue\nfor an arbitrarily large and complex set of nonbinary trees. For completeness\nwe show that the problem is certainly solveable in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 18:41:21 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2012 16:08:14 GMT"}], "update_date": "2012-08-03", "authors_parsed": [["Kelk", "Steven", ""], ["Scornavacca", "Celine", ""]]}, {"id": "1207.7134", "submitter": "Gabriel Istrate", "authors": "Cosmin Bonchis and Gabriel Istrate", "title": "Improved approximation algorithms for low-density instances of the\n  Minimum Entropy Set Cover Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximability of instances of the minimum entropy set cover\nproblem, parameterized by the average frequency of a random element in the\ncovering sets. We analyze an algorithm combining a greedy approach with another\none biased towards large sets. The algorithm is controled by the percentage of\nelements to which we apply the biased approach. The optimal parameter choice\nhas a phase transition around average density $e$ and leads to improved\napproximation guarantees when average element frequency is less than $e$.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 23:38:52 GMT"}], "update_date": "2012-08-01", "authors_parsed": [["Bonchis", "Cosmin", ""], ["Istrate", "Gabriel", ""]]}, {"id": "1207.7148", "submitter": "EPTCS", "authors": "Nachum Dershowitz (Tel Aviv University), Evgenia Falkovich (Tel Aviv\n  University)", "title": "A Formalization and Proof of the Extended Church-Turing Thesis -Extended\n  Abstract-", "comments": "In Proceedings DCM 2011, arXiv:1207.6821", "journal-ref": "EPTCS 88, 2012, pp. 72-78", "doi": "10.4204/EPTCS.88.6", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the Extended Church-Turing Thesis: Every effective algorithm can be\nefficiently simulated by a Turing machine. This is accomplished by emulating an\neffective algorithm via an abstract state machine, and simulating such an\nabstract state machine by a random access machine, representing data as a\nminimal term graph.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 02:06:43 GMT"}], "update_date": "2012-08-01", "authors_parsed": [["Dershowitz", "Nachum", "", "Tel Aviv University"], ["Falkovich", "Evgenia", "", "Tel Aviv\n  University"]]}, {"id": "1207.7184", "submitter": "Alexandru I. Tomescu", "authors": "Martin Milani\\v{c}, Romeo Rizzi, Alexandru I. Tomescu", "title": "Set graphs. II. Complexity of set graph recognition and similar problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph $G$ is said to be a `set graph' if it admits an acyclic orientation\nthat is also `extensional', in the sense that the out-neighborhoods of its\nvertices are pairwise distinct. Equivalently, a set graph is the underlying\ngraph of the digraph representation of a hereditarily finite set. In this\npaper, we continue the study of set graphs and related topics, focusing on\ncomputational complexity aspects. We prove that set graph recognition is\nNP-complete, even when the input is restricted to bipartite graphs with exactly\ntwo leaves. The problem remains NP-complete if, in addition, we require that\nthe extensional acyclic orientation be also `slim', that is, that the digraph\nobtained by removing any arc from it is not extensional. We also show that the\ncounting variants of the above problems are #P-complete, and prove similar\ncomplexity results for problems related to a generalization of extensional\nacyclic digraphs, the so-called `hyper-extensional digraphs', which were\nproposed by Aczel to describe hypersets. Our proofs are based on reductions\nfrom variants of the Hamiltonian Path problem. We also consider a variant of\nthe well-known notion of a separating code in a digraph, the so-called\n`open-out-separating code', and show that it is NP-complete to determine\nwhether an input extensional acyclic digraph contains an open-out-separating\ncode of given size.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 08:41:33 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Milani\u010d", "Martin", ""], ["Rizzi", "Romeo", ""], ["Tomescu", "Alexandru I.", ""]]}, {"id": "1207.7213", "submitter": "Vladimir Kolmogorov", "authors": "Vladimir Kolmogorov", "title": "The power of linear programming for valued CSPs: a constructive\n  characterization", "comments": "added Remark 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A class of valued constraint satisfaction problems (VCSPs) is characterised\nby a valued constraint language, a fixed set of cost functions on a finite\ndomain. An instance of the problem is specified by a sum of cost functions from\nthe language with the goal to minimise the sum.\n  We study which classes of finite-valued languages can be solved exactly by\nthe basic linear programming relaxation (BLP). Thapper and Zivny showed [20]\nthat if BLP solves the language then the language admits a binary commutative\nfractional polymorphism. We prove that the converse is also true. This leads to\na necessary and a sufficient condition which can be checked in polynomial time\nfor a given language. In contrast, the previous necessary and sufficient\ncondition due to [20] involved infinitely many inequalities.\n  More recently, Thapper and Zivny [21] showed (using, in particular, a\ntechnique introduced in this paper) that core languages that do not satisfy our\ncondition are NP-hard. Taken together, these results imply that a finite-valued\nlanguage can either be solved using Linear Programming or is NP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 11:44:23 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2012 12:06:35 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2012 13:22:11 GMT"}, {"version": "v4", "created": "Mon, 26 Nov 2012 14:52:44 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Kolmogorov", "Vladimir", ""]]}]