[{"id": "1605.00058", "submitter": "Tselil Schramm", "authors": "Prasad Raghavendra, Satish Rao, Tselil Schramm", "title": "Strongly Refuting Random CSPs Below the Spectral Threshold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random constraint satisfaction problems (CSPs) are known to exhibit threshold\nphenomena: given a uniformly random instance of a CSP with $n$ variables and\n$m$ clauses, there is a value of $m = \\Omega(n)$ beyond which the CSP will be\nunsatisfiable with high probability. Strong refutation is the problem of\ncertifying that no variable assignment satisfies more than a constant fraction\nof clauses; this is the natural algorithmic problem in the unsatisfiable regime\n(when $m/n = \\omega(1)$).\n  Intuitively, strong refutation should become easier as the clause density\n$m/n$ grows, because the contradictions introduced by the random clauses become\nmore locally apparent. For CSPs such as $k$-SAT and $k$-XOR, there is a\nlong-standing gap between the clause density at which efficient strong\nrefutation algorithms are known, $m/n \\ge \\widetilde O(n^{k/2-1})$, and the\nclause density at which instances become unsatisfiable with high probability,\n$m/n = \\omega (1)$.\n  In this paper, we give spectral and sum-of-squares algorithms for strongly\nrefuting random $k$-XOR instances with clause density $m/n \\ge \\widetilde\nO(n^{(k/2-1)(1-\\delta)})$ in time $\\exp(\\widetilde O(n^{\\delta}))$ or in\n$\\widetilde O(n^{\\delta})$ rounds of the sum-of-squares hierarchy, for any\n$\\delta \\in [0,1)$ and any integer $k \\ge 3$. Our algorithms provide a smooth\ntransition between the clause density at which polynomial-time algorithms are\nknown at $\\delta = 0$, and brute-force refutation at the satisfiability\nthreshold when $\\delta = 1$. We also leverage our $k$-XOR results to obtain\nstrong refutation algorithms for SAT (or any other Boolean CSP) at similar\nclause densities. Our algorithms match the known sum-of-squares lower bounds\ndue to Grigoriev and Schonebeck, up to logarithmic factors.\n  Additionally, we extend our techniques to give new results for certifying\nupper bounds on the injective tensor norm of random tensors.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 02:53:31 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 17:00:53 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Raghavendra", "Prasad", ""], ["Rao", "Satish", ""], ["Schramm", "Tselil", ""]]}, {"id": "1605.00263", "submitter": "J\\\"urgen Koslowski", "authors": "Jan Krajicek and Igor C. Oliveira", "title": "Unprovability of circuit upper bounds in Cook's theory PV", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 1 (February\n  3, 2017) lmcs:3119", "doi": "10.23638/LMCS-13(1:4)2017", "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish unconditionally that for every integer $k \\geq 1$ there is a\nlanguage $L \\in \\mbox{P}$ such that it is consistent with Cook's theory PV that\n$L \\notin Size(n^k)$. Our argument is non-constructive and does not provide an\nexplicit description of this language.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 15:11:04 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2016 07:52:31 GMT"}, {"version": "v3", "created": "Wed, 1 Feb 2017 12:04:47 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Krajicek", "Jan", ""], ["Oliveira", "Igor C.", ""]]}, {"id": "1605.00313", "submitter": "Konstantin Kobylkin S.", "authors": "Konstantin Kobylkin", "title": "Stabbing line segments with disks: complexity and approximation\n  algorithms", "comments": "12 pages, 1 appendix, 15 bibliography items, 6th International\n  Conference on Analysis of Images, Social Networks and Texts (AIST-2017)", "journal-ref": "Kobylkin K.Stabbing Line Segments with Disks: Complexity and\n  Approximation Algorithms. // Lecture Notes in Computer Science, 2018. vol\n  10716. pp 356-367 Springer", "doi": "10.1007/978-3-319-73013-4_33", "report-no": "Eng21", "categories": "cs.CG cs.CC cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computational complexity and approximation algorithms are reported for a\nproblem of stabbing a set of straight line segments with the least cardinality\nset of disks of fixed radii $r>0$ where the set of segments forms a straight\nline drawing $G=(V,E)$ of a planar graph without edge crossings. Close\ngeometric problems arise in network security applications. We give strong\nNP-hardness of the problem for edge sets of Delaunay triangulations, Gabriel\ngraphs and other subgraphs (which are often used in network design) for $r\\in\n[d_{\\min},\\eta d_{\\max}]$ and some constant $\\eta$ where $d_{\\max}$ and\n$d_{\\min}$ are Euclidean lengths of the longest and shortest graph edges\nrespectively. Fast $O(|E|\\log|E|)$-time $O(1)$-approximation algorithm is\nproposed within the class of straight line drawings of planar graphs for which\nthe inequality $r\\geq \\eta d_{\\max}$ holds uniformly for some constant\n$\\eta>0,$ i.e. when lengths of edges of $G$ are uniformly bounded from above by\nsome linear function of $r.$\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 21:54:15 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 14:06:50 GMT"}, {"version": "v3", "created": "Tue, 26 Jul 2016 09:32:56 GMT"}, {"version": "v4", "created": "Thu, 20 Jul 2017 08:56:24 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Kobylkin", "Konstantin", ""]]}, {"id": "1605.00532", "submitter": "Ignasi Sau", "authors": "Didem G\\\"oz\\\"upek, Sibel \\\"Ozkan, Christophe Paul, Ignasi Sau,\n  Mordechai Shalom", "title": "Parameterized complexity of the MINCCA problem on graphs of bounded\n  decomposability", "comments": "25 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an edge-colored graph, the cost incurred at a vertex on a path when two\nincident edges with different colors are traversed is called reload or\nchangeover cost. The \"Minimum Changeover Cost Arborescence\" (MINCCA) problem\nconsists in finding an arborescence with a given root vertex such that the\ntotal changeover cost of the internal vertices is minimized. It has been\nrecently proved by G\\\"oz\\\"upek et al. [TCS 2016] that the problem is FPT when\nparameterized by the treewidth and the maximum degree of the input graph. In\nthis article we present the following results for the MINCCA problem:\n  - the problem is W[1]-hard parameterized by the treedepth of the input graph,\neven on graphs of average degree at most 8. In particular, it is W[1]-hard\nparameterized by the treewidth of the input graph, which answers the main open\nproblem of G\\\"oz\\\"upek et al. [TCS 2016];\n  - it is W[1]-hard on multigraphs parameterized by the tree-cutwidth of the\ninput multigraph;\n  - it is FPT parameterized by the star tree-cutwidth of the input graph, which\nis a slightly restricted version of tree-cutwidth. This result strictly\ngeneralizes the FPT result given in G\\\"oz\\\"upek et al. [TCS 2016];\n  - it remains NP-hard on planar graphs even when restricted to instances with\nat most 6 colors and 0/1 symmetric costs, or when restricted to instances with\nat most 8 colors, maximum degree bounded by 4, and 0/1 symmetric costs.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 15:39:50 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["G\u00f6z\u00fcpek", "Didem", ""], ["\u00d6zkan", "Sibel", ""], ["Paul", "Christophe", ""], ["Sau", "Ignasi", ""], ["Shalom", "Mordechai", ""]]}, {"id": "1605.00565", "submitter": "Marcin Kozik", "authors": "Marcin Kozik", "title": "Weaker consistency notions for all the CSPs of bounded width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characterization of all the Constraint Satisfaction Problems of bounded\nwidth, proposed by Feder and Vardi [SICOMP'98], was confirmed in [Bulatov'09]\nand independently in [FOCS'09, JACM'14]. Both proofs are based on the\n(2,3)-consistency (using Prague consistency in [FOCS'09], directly in\n[Bulatov'09]) which is costly to verify.\n  We introduce a new consistency notion, Singleton Linear Arc Consistency\n(SLAC), and show that it solves the same family of problems. SLAC is weaker\nthan Singleton Arc Consistency (SAC) and thus the result answers the question\nfrom [JLC'13] by showing that SAC solves all the problems of bounded width. At\nthe same time the problem of verifying weaker consistency (even SAC) offers\nsignificant computational advantages over the problem of verifying\n(2,3)-consistency which improves the algorithms solving the CSPs of bounded\nwidth.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 16:52:45 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2016 20:53:55 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Kozik", "Marcin", ""]]}, {"id": "1605.00619", "submitter": "Lijie Chen", "authors": "Lijie Chen", "title": "A Note on Oracle Separations for BQP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2009, using the $\\textsf{Fourier Checking}$ problem, Aaronson claimed to\nconstruct the relativized worlds such that $\\textsf{BQP} \\not\\subset\n\\mathsf{BPP_{path}}$ and $\\textsf{BQP} \\not\\subset \\textsf{SZK}$. However,\nthere are subtle errors in the original proof. In this paper, we point out the\nissues, and rescue these two separations by using more sophisticated\nconstructions.\n  Meanwhile, we take the opportunity to study the complexity classes\n$\\mathsf{BPP_{path}}$ and $\\textsf{SZK}$. We give general ways to construct\nfunctions which are hard for $\\textsf{SZK}$ and $\\mathsf{BPP_{path}}$ (in the\nquery complexity sense). Using these techniques, we give alternative\nconstruction for the oracle separation $\\textsf{BQP} \\not\\subset \\textsf{SZK}$,\nusing only Simon's problem. We also give new oracle separations for\n$\\textsf{P}^{\\textsf{SZK}}$ from $\\mathsf{BPP_{path}}$ and\n$\\textsf{P}^{\\textsf{SZK}}$ from $\\textsf{QSK}$. The latter result suggests\nthat $\\textsf{P}^{\\textsf{SZK}}$ might be strictly larger than $\\textsf{SZK}$.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 19:04:14 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Chen", "Lijie", ""]]}, {"id": "1605.00903", "submitter": "Vijay Bhattiprolu", "authors": "Vijay Bhattiprolu, Venkatesan Guruswami, Euiwoong Lee", "title": "Sum-of-Squares Certificates for Maxima of Random Tensors on the Sphere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an $n$-variate order-$d$ tensor $A$, define $ A_{\\max} := \\sup_{\\| x \\|_2\n= 1} \\langle A , x^{\\otimes d} \\rangle$ to be the maximum value taken by the\ntensor on the unit sphere. It is known that for a random tensor with i.i.d $\\pm\n1$ entries, $A_{\\max} \\lesssim \\sqrt{n\\cdot d\\cdot\\log d}$ w.h.p. We study the\nproblem of efficiently certifying upper bounds on $A_{\\max}$ via the natural\nrelaxation from the Sum of Squares (SoS) hierarchy. Our results include:\n  - When $A$ is a random order-$q$ tensor, we prove that $q$ levels of SoS\ncertifies an upper bound $B$ on $A_{\\max}$ that satisfies \\[ B ~~~~\\leq~~\n  A_{\\max} \\cdot \\biggl(\\frac{n}{q^{\\,1-o(1)}}\\biggr)^{q/4-1/2} \\quad\n\\text{w.h.p.} \\] Our upper bound improves a result of Montanari and Richard\n(NIPS 2014) when $q$ is large.\n  - We show the above bound is the best possible up to lower order terms,\nnamely the optimum of the level-$q$ SoS relaxation is at least \\[ A_{\\max}\n\\cdot \\biggl(\\frac{n}{q^{\\,1+o(1)}}\\biggr)^{q/4-1/2} \\ . \\]\n  - When $A$ is a random order-$d$ tensor, we prove that $q$ levels of SoS\ncertifies an upper bound $B$ on $A_{\\max}$ that satisfies \\[\n  B ~~\\leq ~~ A_{\\max} \\cdot \\biggl(\\frac{\\widetilde{O}(n)}{q}\\biggr)^{d/4 -\n1/2} \\quad \\text{w.h.p.} \\] For growing $q$, this improves upon the bound\ncertified by constant levels of SoS. This answers in part, a question posed by\nHopkins, Shi, and Steurer (COLT 2015), who established the tight\ncharacterization for constant levels of SoS.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 13:39:18 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 12:59:47 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Bhattiprolu", "Vijay", ""], ["Guruswami", "Venkatesan", ""], ["Lee", "Euiwoong", ""]]}, {"id": "1605.01142", "submitter": "Robin Kothari", "authors": "Anurag Anshu, Aleksandrs Belovs, Shalev Ben-David, Mika G\\\"o\\\"os,\n  Rahul Jain, Robin Kothari, Troy Lee, Miklos Santha", "title": "Separations in communication complexity using cheat sheets and\n  information complexity", "comments": "v1: 36 pages, 1 figure; v2: Added separation between exact quantum\n  and bounded-error randomized communication, 39 pages, 2 figures", "journal-ref": "Proceedings of the 57th Annual IEEE Symposium on Foundations of\n  Computer Science (FOCS 2016), pp. 555-564 (2016)", "doi": "10.1109/FOCS.2016.66", "report-no": "MIT-CTP #4801", "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While exponential separations are known between quantum and randomized\ncommunication complexity for partial functions (Raz, STOC 1999), the best known\nseparation between these measures for a total function is quadratic, witnessed\nby the disjointness function. We give the first super-quadratic separation\nbetween quantum and randomized communication complexity for a total function,\ngiving an example exhibiting a power 2.5 gap. We further present a 1.5 power\nseparation between exact quantum and randomized communication complexity,\nimproving on the previous ~1.15 separation by Ambainis (STOC 2013). Finally, we\npresent a nearly optimal quadratic separation between randomized communication\ncomplexity and the logarithm of the partition number, improving upon the\nprevious best power 1.5 separation due to G\\\"o\\\"os, Jayram, Pitassi, and\nWatson.\n  Our results are the communication analogues of separations in query\ncomplexity proved using the recent cheat sheet framework of Aaronson,\nBen-David, and Kothari (STOC 2016). Our main technical results are randomized\ncommunication and information complexity lower bounds for a family of\nfunctions, called lookup functions, that generalize and port the cheat sheet\nframework to communication complexity.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 04:42:08 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2016 18:19:41 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Anshu", "Anurag", ""], ["Belovs", "Aleksandrs", ""], ["Ben-David", "Shalev", ""], ["G\u00f6\u00f6s", "Mika", ""], ["Jain", "Rahul", ""], ["Kothari", "Robin", ""], ["Lee", "Troy", ""], ["Santha", "Miklos", ""]]}, {"id": "1605.01207", "submitter": "Stanislav Kikot", "authors": "Meghyn Bienvenu, Stanislav Kikot, Roman Kontchakov, Vladimir Podolskii\n  and Michael Zakharyaschev", "title": "Ontology-Mediated Queries: Combined Complexity and Succinctness of\n  Rewritings via Circuit Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give solutions to two fundamental computational problems in ontology-based\ndata access with the W3C standard ontology language OWL 2 QL: the succinctness\nproblem for first-order rewritings of ontology-mediated queries (OMQs), and the\ncomplexity problem for OMQ answering. We classify OMQs according to the shape\nof their conjunctive queries (treewidth, the number of leaves) and the\nexistential depth of their ontologies. For each of these classes, we determine\nthe combined complexity of OMQ answering, and whether all OMQs in the class\nhave polynomial-size first-order, positive existential, and nonrecursive\ndatalog rewritings. We obtain the succinctness results using hypergraph\nprograms, a new computational model for Boolean functions, which makes it\npossible to connect the size of OMQ rewritings and circuit complexity.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 10:10:37 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Bienvenu", "Meghyn", ""], ["Kikot", "Stanislav", ""], ["Kontchakov", "Roman", ""], ["Podolskii", "Vladimir", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1605.01519", "submitter": "Anatol Slissenko", "authors": "Anatol Slissenko", "title": "On entropic convergence of algorithms in terms of domain partitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper describes an approach to measuring convergence of an algorithm to\nits result in terms of an entropy-like function of partitions of its inputs of\na given length. The goal is to look at the algorithmic data processing from the\nviewpoint of information transformation, with a hope to better understand the\nwork of algorithm, and maybe its complexity. The entropy is a measure of\nuncertainty, it does not correspond to our intuitive understanding of\ninformation. However, it is what we have in this area. In order to realize this\napproach we introduce a measure on the inputs of a given length based on the\nPrinciple of Maximal Uncertainty: all results should be equiprobable to the\nalgorithm at the beginning. An algorithm is viewed as a set of events, each\nevent is an application of a command. The commands are very basic. To measure\nthe convergence we introduce a measure that is called entropic weight of events\nof the algorithm. The approach is illustrated by two examples.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 07:36:43 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Slissenko", "Anatol", ""]]}, {"id": "1605.01695", "submitter": "Kasper Green Larsen", "authors": "Kasper Green Larsen and Ryan Williams", "title": "Faster Online Matrix-Vector Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Online Boolean Matrix-Vector Multiplication (OMV) problem\nstudied by Henzinger et al. [STOC'15]: given an $n \\times n$ Boolean matrix\n$M$, we receive $n$ Boolean vectors $v_1,\\ldots,v_n$ one at a time, and are\nrequired to output $M v_i$ (over the Boolean semiring) before seeing the vector\n$v_{i+1}$, for all $i$. Previous known algorithms for this problem are\ncombinatorial, running in $O(n^3/\\log^2 n)$ time. Henzinger et al. conjecture\nthere is no $O(n^{3-\\varepsilon})$ time algorithm for OMV, for all $\\varepsilon\n> 0$; their OMV conjecture is shown to imply strong hardness results for many\nbasic dynamic problems.\n  We give a substantially faster method for computing OMV, running in\n$n^3/2^{\\Omega(\\sqrt{\\log n})}$ randomized time. In fact, after seeing\n$2^{\\omega(\\sqrt{\\log n})}$ vectors, we already achieve\n$n^2/2^{\\Omega(\\sqrt{\\log n})}$ amortized time for matrix-vector\nmultiplication. Our approach gives a way to reduce matrix-vector multiplication\nto solving a version of the Orthogonal Vectors problem, which in turn reduces\nto \"small\" algebraic matrix-matrix multiplication. Applications include faster\nindependent set detection, partial match retrieval, and 2-CNF evaluation.\n  We also show how a modification of our method gives a cell probe data\nstructure for OMV with worst case $O(n^{7/4}/\\sqrt{w})$ time per query vector,\nwhere $w$ is the word size. This result rules out an unconditional proof of the\nOMV conjecture using purely information-theoretic arguments.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 19:16:27 GMT"}, {"version": "v2", "created": "Fri, 6 May 2016 17:56:17 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Larsen", "Kasper Green", ""], ["Williams", "Ryan", ""]]}, {"id": "1605.01718", "submitter": "Johannes Bausch", "authors": "Johannes Bausch, Toby Cubitt, Maris Ozols", "title": "The Complexity of Translationally-Invariant Spin Chains with Low Local\n  Dimension", "comments": "69 pages", "journal-ref": "Ann. Henri Poincar\\'e (2017) 18(11), 3449-3513", "doi": "10.1007/s00023-017-0609-7", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that estimating the ground state energy of a\ntranslationally-invariant, nearest-neighbour Hamiltonian on a 1D spin chain is\nQMAEXP-complete, even for systems of low local dimension (roughly 40). This is\nan improvement over the best previously-known result by several orders of\nmagnitude, and it shows that spin-glass-like frustration can occur in\ntranslationally-invariant quantum systems with a local dimension comparable to\nthe smallest-known non-translationally-invariant systems with similar\nbehaviour.\n  While previous constructions of such systems rely on standard models of\nquantum computation, we construct a new model that is particularly well-suited\nfor encoding quantum computation into the ground state of a\ntranslationally-invariant system. This allows us to shift the proof burden from\noptimizing the Hamiltonian encoding a standard computational model to proving\nuniversality of a simple model.\n  Previous techniques for encoding quantum computation into the ground state of\na local Hamiltonian allow only a linear sequence of gates, hence only a linear\n(or nearly linear) path in the graph of all computational states. We extend\nthese techniques by allowing significantly more general paths, including\nbranching and cycles, thus enabling a highly efficient encoding of our\ncomputational model. However, this requires more sophisticated techniques for\nanalysing the spectrum of the resulting Hamiltonian. To address this, we\nintroduce a framework of graphs with unitary edge labels. After relating our\nHamiltonian to the Laplacian of such a unitary labelled graph, we analyse its\nspectrum by combining matrix analysis and spectral graph theory techniques.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 19:58:24 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2017 20:38:07 GMT"}, {"version": "v3", "created": "Sat, 9 Sep 2017 13:51:58 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Bausch", "Johannes", ""], ["Cubitt", "Toby", ""], ["Ozols", "Maris", ""]]}, {"id": "1605.01828", "submitter": "Debajyoti Bera", "authors": "Debajyoti Bera", "title": "Two-sided Quantum Amplitude Amplification and Exact-Error Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Amplitude amplification is a central tool used in Grover's quantum search\nalgorithm and has been used in various forms in numerous quantum algorithms\nsince then. It has been shown to completely eliminate one-sided error of\nquantum search algorithms where input is accessed in the form of black-box\nqueries. We generalize amplitude amplification for two-sided error quantum\nalgorithm for decision problems in the familiar form where input is accessed in\nthe form of initial states of quantum circuits and where arbitrary projective\nmeasurements may be used to ascertain success or failure. This generalization\nallows us to derive interesting applications of amplitude amplification for\ndistinguishing between two given distributions based on their samples,\ndetection of faults in quantum circuits and eliminating error of one and\ntwo-sided quantum algorithms with exact errors.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 05:42:22 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Bera", "Debajyoti", ""]]}, {"id": "1605.02156", "submitter": "Massimo Cairo", "authors": "Massimo Cairo and Romeo Rizzi", "title": "The Complexity of Simulation and Matrix Multiplication", "comments": "Submitted. Changed in v2: This is a major rewrite of the paper. The\n  introduction has been expanded considerably, some notation has been\n  simplified, proofs of general results on reachability games have been moved\n  to the appendix, more intuitive arguments for proofs have been provided,\n  moving the formal arguments to the appendix, more references have been added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the simulation preorder of a given Kripke structure (i.e., a\ndirected graph with $n$ labeled vertices) has crucial applications in model\nchecking of temporal logic. It amounts to solving a specific two-players\nreachability game, called simulation game. We offer the first conditional lower\nbounds for this problem, and we relate its complexity (for computation,\nverification, and certification) to some variants of $n\\times n$ matrix\nmultiplication.\n  We show that any $O(n^{\\alpha})$-time algorithm for simulation games, even\nrestricting to acyclic games/structures, can be used to compute $n\\times n$\nboolean matrix multiplication (BMM) in $O(n^{\\alpha})$ time. This is the first\nevidence that improving the existing $O(n^{3})$-time solutions may be\ndifficult, without resorting to fast matrix multiplication. In the acyclic\ncase, we match this lower bound presenting the first subcubic algorithm, based\non fast BMM, and running in $n^{\\omega+o(1)}$ time (where $\\omega<2.376$ is the\nexponent of matrix multiplication).\n  For both acyclic and cyclic structures, we point out the existence of natural\nand canonical $O(n^{2})$-size certificates, that can be verified in truly\nsubcubic time. In the acyclic case, $O(n^{2})$ time is sufficient, employing\nstandard matrix product verification. In the cyclic case, a $\\max$-semi-boolean\nmatrix multiplication (MSBMM) is used, i.e., a matrix multiplication on the\nsemi-ring $(\\max,\\times)$ where one matrix contains only $0$'s and $1$'s. This\nMSBMM is computable (hence verifiable) in truly subcubic\n$n^{(3+\\omega)/2+o(1)}$ time by reduction to $(\\max,\\min)$-multiplication.\n  Finally, we show a reduction from MSBMM to cyclic simulation games which\nimplies a separation between the cyclic and the acyclic cases, unless MSBMM can\nbe verified in $n^{\\omega+o(1)}$ time.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 08:18:31 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2016 15:51:14 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Cairo", "Massimo", ""], ["Rizzi", "Romeo", ""]]}, {"id": "1605.02210", "submitter": "Adrian Onet", "authors": "Adrian Onet", "title": "Inference-based semantics in Data Exchange", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Exchange is an old problem that was firstly studied from a theoretical\npoint of view only in 2003. Since then many approaches were considered when it\ncame to the language describing the relationship between the source and the\ntarget schema. These approaches focus on what it makes a target instance a\n\"good\" solution for data-exchange. In this paper we propose the inference-based\nsemantics that solves many certain-answer anomalies existing in current\ndata-exchange semantics. To this we introduce a new mapping language between\nthe source and the target schema based on annotated bidirectional dependencies\n(abd) and, consequently define the semantics for this new language. It is shown\nthat the ABD-semantics can properly represent the inference-based semantics,\nfor any source-to-target mappings. We discovered three dichotomy results under\nthe new semantics for solution-existence, solution-check and UCQ evaluation\nproblems. These results rely on two factors describing the annotation used in\nthe mappings (density and cardinality). Finally we also investigate the\ncertain-answers evaluation problem under ABD-semantics and discover many\ntractable classes for non-UCQ queries even for a subclass of CQ with negation.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 16:28:40 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Onet", "Adrian", ""]]}, {"id": "1605.02701", "submitter": "Ilya Razenshteyn", "authors": "Alexandr Andoni, Thijs Laarhoven, Ilya Razenshteyn, Erik Waingarten", "title": "Lower Bounds on Time-Space Trade-Offs for Approximate Near Neighbors", "comments": "47 pages, 2 figures; v2: substantially revised introduction, lots of\n  small corrections; subsumed by arXiv:1608.03580 [cs.DS] (along with\n  arXiv:1511.07527 [cs.DS])", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show tight lower bounds for the entire trade-off between space and query\ntime for the Approximate Near Neighbor search problem. Our lower bounds hold in\na restricted model of computation, which captures all hashing-based approaches.\nIn articular, our lower bound matches the upper bound recently shown in\n[Laarhoven 2015] for the random instance on a Euclidean sphere (which we show\nin fact extends to the entire space $\\mathbb{R}^d$ using the techniques from\n[Andoni, Razenshteyn 2015]).\n  We also show tight, unconditional cell-probe lower bounds for one and two\nprobes, improving upon the best known bounds from [Panigrahy, Talwar, Wieder\n2010]. In particular, this is the first space lower bound (for any static data\nstructure) for two probes which is not polynomially smaller than for one probe.\nTo show the result for two probes, we establish and exploit a connection to\nlocally-decodable codes.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 19:13:06 GMT"}, {"version": "v2", "created": "Sat, 25 Jun 2016 22:23:46 GMT"}, {"version": "v3", "created": "Thu, 18 Aug 2016 22:03:33 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Andoni", "Alexandr", ""], ["Laarhoven", "Thijs", ""], ["Razenshteyn", "Ilya", ""], ["Waingarten", "Erik", ""]]}, {"id": "1605.02815", "submitter": "Youming Qiao", "authors": "Joshua A. Grochow, Ketan D. Mulmuley, Youming Qiao", "title": "Boundaries of VP and VNP", "comments": "31 pages. A preliminary version of this paper appears in ICALP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG math.CO math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One fundamental question in the context of the geometric complexity theory\napproach to the VP vs. VNP conjecture is whether VP = $\\overline{\\textrm{VP}}$,\nwhere VP is the class of families of polynomials that are of polynomial degree\nand can be computed by arithmetic circuits of polynomial size, and\n$\\overline{\\textrm{VP}}$ is the class of families of polynomials that are of\npolynomial degree and can be approximated infinitesimally closely by arithmetic\ncircuits of polynomial size. The goal of this article is to study the\nconjecture in (Mulmuley, FOCS 2012) that $\\overline{\\textrm{VP}}$ is not\ncontained in VP.\n  Towards that end, we introduce three degenerations of VP (i.e., sets of\npoints in $\\overline{\\textrm{VP}}$), namely the stable degeneration Stable-VP,\nthe Newton degeneration Newton-VP, and the p-definable one-parameter\ndegeneration VP*. We also introduce analogous degenerations of VNP. We show\nthat Stable-VP $\\subseteq$ Newton-VP $\\subseteq$ VP* $\\subseteq$ VNP, and\nStable-VNP = Newton-VNP = VNP* = VNP. The three notions of degenerations and\nthe proof of this result shed light on the problem of separating\n$\\overline{\\textrm{VP}}$ from VP.\n  Although we do not yet construct explicit candidates for the polynomial\nfamilies in $\\overline{\\textrm{VP}}\\setminus$VP, we prove results which tell us\nwhere not to look for such families. Specifically, we demonstrate that the\nfamilies in Newton-VP $\\setminus$ VP based on semi-invariants of quivers would\nhave to be non-generic by showing that, for many finite quivers (including some\nwild ones), any Newton degeneration of a generic semi-invariant can be computed\nby a circuit of polynomial size. We also show that the Newton degenerations of\nperfect matching Pfaffians, monotone arithmetic circuits over the reals, and\nSchur polynomials have polynomial-size circuits.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 01:06:40 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Grochow", "Joshua A.", ""], ["Mulmuley", "Ketan D.", ""], ["Qiao", "Youming", ""]]}, {"id": "1605.03019", "submitter": "Samuli Lepp\\\"anen", "authors": "Adam Kurpisz, Samuli Lepp\\\"anen, Monaldo Mastrolilli", "title": "Tight Sum-of-Squares lower bounds for binary polynomial optimization\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give two results concerning the power of the Sum-of-Squares(SoS)/Lasserre\nhierarchy. For binary polynomial optimization problems of degree $2d$ and an\nodd number of variables $n$, we prove that $\\frac{n+2d-1}{2}$ levels of the\nSoS/Lasserre hierarchy are necessary to provide the exact optimal value. This\nmatches the recent upper bound result by Sakaue, Takeda, Kim and Ito.\n  Additionally, we study a conjecture by Laurent, who considered the linear\nrepresentation of a set with no integral points. She showed that the\nSherali-Adams hierarchy requires $n$ levels to detect the empty integer hull,\nand conjectured that the SoS/Lasserre rank for the same problem is $n-1$. We\ndisprove this conjecture and derive lower and upper bounds for the rank.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 14:03:44 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Kurpisz", "Adam", ""], ["Lepp\u00e4nen", "Samuli", ""], ["Mastrolilli", "Monaldo", ""]]}, {"id": "1605.03045", "submitter": "Micha{\\l} Pilipczuk", "authors": "Miko{\\l}aj Boja\\'nczyk and Micha{\\l} Pilipczuk", "title": "Definability equals recognizability for graphs of bounded treewidth", "comments": "21 pages, an extended abstract will appear in the proceedings of LICS\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a conjecture of Courcelle, which states that a graph property is\ndefinable in MSO with modular counting predicates on graphs of constant\ntreewidth if, and only if it is recognizable in the following sense:\nconstant-width tree decompositions of graphs satisfying the property can be\nrecognized by tree automata. While the forward implication is a classic fact\nknown as Courcelle's theorem, the converse direction remained open\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 15:03:07 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", ""], ["Pilipczuk", "Micha\u0142", ""]]}, {"id": "1605.03063", "submitter": "Stefan Neumann", "authors": "Stefan Neumann and Andreas Wiese", "title": "This House Proves that Debating is Harder than Soccer", "comments": "18 pages, to appear at FUN 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last twenty years, a lot of research was conducted on the sport\nelimination problem: Given a sports league and its remaining matches, we have\nto decide whether a given team can still possibly win the competition, i.e.,\nplace first in the league at the end. Previously, the computational complexity\nof this problem was investigated only for games with two participating teams\nper game. In this paper we consider Debating Tournaments and Debating Leagues\nin the British Parliamentary format, where four teams are participating in each\ngame. We prove that it is NP-hard to decide whether a given team can win a\nDebating League, even if at most two matches are remaining for each team. This\ncontrasts settings like football where two teams play in each game since there\nthis case is still polynomial time solvable. We prove our result even for a\nfictitious restricted setting with only three teams per game. On the other\nhand, for the common setting of Debating Tournaments we show that this problem\nis fixed parameter tractable if the parameter is the number of remaining rounds\n$k$. This also holds for the practically very important question of whether a\nteam can still qualify for the knock-out phase of the tournament and the\ncombined parameter $k + b$ where $b$ denotes the threshold rank for qualifying.\nFinally, we show that the latter problem is polynomial time solvable for any\nconstant $k$ and arbitrary values $b$ that are part of the input.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 15:34:42 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Neumann", "Stefan", ""], ["Wiese", "Andreas", ""]]}, {"id": "1605.03243", "submitter": "Moustapha Diaby", "authors": "Moustapha Diaby, Mark H. Karwan, and Lei Sun", "title": "On \"Exponential Lower Bounds for Polytopes in Combinatorial\n  Optimization\" by Fiorini et al. (2015): A Refutation For Models With Disjoint\n  Sets of Descriptive Variables", "comments": "7 pages; Minor typos fixed; Presentation of counter-example\n  simplified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a numerical refutation of the developments of Fiorini et al.\n(2015)* for models with disjoint sets of descriptive variables. We also provide\nan insight into the meaning of the existence of a one-to-one linear map between\nsolutions of such models.\n  *: Fiorini, S., S. Massar, S. Pokutta, H.R. Tiwary, and R. de Wolf (2015).\nExponential Lower Bounds for Polytopes in Combinatorial Optimization. Journal\nof the ACM 62:2, Article No. 17.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 23:23:20 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 12:11:29 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Diaby", "Moustapha", ""], ["Karwan", "Mark H.", ""], ["Sun", "Lei", ""]]}, {"id": "1605.03266", "submitter": "Dave Bacon", "authors": "Dave Bacon", "title": "A Quantum Approach to the Unique Sink Orientation Problem", "comments": "5 pages, 2 figures", "journal-ref": "Phys. Rev. A 96, 012323 (2017)", "doi": "10.1103/PhysRevA.96.012323", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider quantum algorithms for the unique sink orientation problem on\ncubes. This problem is widely considered to be of intermediate computational\ncomplexity. This is because there no known polynomial algorithm (classical or\nquantum) from the problem and yet it arrises as part of a series of problems\nfor which it being intractable would imply complexity theoretic collapses. We\ngive a reduction which proves that if one can efficiently evaluate the kth\npower of the unique sink orientation outmap, then there exists a polynomial\ntime quantum algorithm for the unique sink orientation problem on cubes.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 03:07:35 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 17:14:04 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Bacon", "Dave", ""]]}, {"id": "1605.03480", "submitter": "Sandra Kiefer", "authors": "Sandra Kiefer, Pascal Schweitzer", "title": "Upper Bounds on the Quantifier Depth for Graph Differentiation in\n  First-Order Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (May 30,\n  2019) lmcs:5522", "doi": "10.23638/LMCS-15(2:19)2019", "report-no": null, "categories": "cs.LO cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that on graphs with n vertices, the 2-dimensional Weisfeiler-Leman\nalgorithm requires at most O(n^2/log(n)) iterations to reach stabilization.\nThis in particular shows that the previously best, trivial upper bound of\nO(n^2) is asymptotically not tight. In the logic setting, this translates to\nthe statement that if two graphs of size n can be distinguished by a formula in\nfirst-order logic with counting with 3 variables (i.e., in C3), then they can\nalso be distinguished by a C3-formula that has quantifier depth at most\nO(n^2/log(n)).\n  To prove the result we define a game between two players that enables us to\ndecouple the causal dependencies between the processes happening simultaneously\nover several iterations of the algorithm. This allows us to treat large color\nclasses and small color classes separately. As part of our proof we show that\nfor graphs with bounded color class size, the number of iterations until\nstabilization is at most linear in the number of vertices. This also yields a\ncorresponding statement in first-order logic with counting.\n  Similar results can be obtained for the respective logic without counting\nquantifiers, i.e., for the logic L3.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 15:28:46 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 00:30:00 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 20:49:04 GMT"}, {"version": "v4", "created": "Sun, 26 May 2019 15:25:39 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kiefer", "Sandra", ""], ["Schweitzer", "Pascal", ""]]}, {"id": "1605.03546", "submitter": "Bernd G\\\"artner", "authors": "J\\'er\\^ome Dohrau, Bernd G\\\"artner, Manuel Kohler, Ji\\v{r}\\'i\n  Matou\\v{s}ek, Emo Welzl", "title": "ARRIVAL: A zero-player graph game in NP $\\cap$ coNP", "comments": "6 pages, 3 figures; final version is due to be published in the\n  collection of papers \"A Journey through Discrete Mathematics. A Tribute to\n  Ji\\v{r}\\'i Matou\\v{s}ek\" edited by Martin Loebl, Jaroslav Ne\\v{s}et\\v{r}il\n  and Robin Thomas, due to be published by Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that a train is running along a railway network, starting from a\ndesignated origin, with the goal of reaching a designated destination. The\nnetwork, however, is of a special nature: every time the train traverses a\nswitch, the switch will change its position immediately afterwards. Hence, the\nnext time the train traverses the same switch, the other direction will be\ntaken, so that directions alternate with each traversal of the switch. Given a\nnetwork with origin and destination, what is the complexity of deciding whether\nthe train, starting at the origin, will eventually reach the destination? It is\neasy to see that this problem can be solved in exponential time, but we are not\naware of any polynomial-time method. In this short paper, we prove that the\nproblem is in NP $\\cap$ coNP. This raises the question whether we have just\nfailed to find a (simple) polynomial-time solution, or whether the complexity\nstatus is more subtle, as for some other well-known (two-player) graph games.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 18:56:46 GMT"}, {"version": "v2", "created": "Mon, 3 Oct 2016 11:51:15 GMT"}, {"version": "v3", "created": "Thu, 24 Nov 2016 10:30:30 GMT"}, {"version": "v4", "created": "Fri, 23 Jun 2017 17:40:57 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Dohrau", "J\u00e9r\u00f4me", ""], ["G\u00e4rtner", "Bernd", ""], ["Kohler", "Manuel", ""], ["Matou\u0161ek", "Ji\u0159\u00ed", ""], ["Welzl", "Emo", ""]]}, {"id": "1605.03613", "submitter": "Huck Bennett", "authors": "Huck Bennett, Daniel Dadush, Noah Stephens-Davidowitz", "title": "On the Lattice Distortion Problem", "comments": "This is the full version of a paper that appeared in ESA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study the \\emph{Lattice Distortion Problem} (LDP). LDP asks\nhow \"similar\" two lattices are. I.e., what is the minimal distortion of a\nlinear bijection between the two lattices? LDP generalizes the Lattice\nIsomorphism Problem (the lattice analogue of Graph Isomorphism), which simply\nasks whether the minimal distortion is one.\n  As our first contribution, we show that the distortion between any two\nlattices is approximated up to a $n^{O(\\log n)}$ factor by a simple function of\ntheir successive minima. Our methods are constructive, allowing us to compute\nlow-distortion mappings that are within a $2^{O(n \\log \\log n/\\log n)}$ factor\nof optimal in polynomial time and within a $n^{O(\\log n)}$ factor of optimal in\nsingly exponential time. Our algorithms rely on a notion of basis reduction\nintroduced by Seysen (Combinatorica 1993), which we show is intimately related\nto lattice distortion. Lastly, we show that LDP is NP-hard to approximate to\nwithin any constant factor (under randomized reductions), by a reduction from\nthe Shortest Vector Problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 20:31:01 GMT"}, {"version": "v2", "created": "Sun, 5 Jun 2016 19:54:46 GMT"}, {"version": "v3", "created": "Sun, 30 Oct 2016 10:54:32 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Bennett", "Huck", ""], ["Dadush", "Daniel", ""], ["Stephens-Davidowitz", "Noah", ""]]}, {"id": "1605.03797", "submitter": "S{\\o}ren Dahlgaard", "authors": "Amir Abboud and S{\\o}ren Dahlgaard", "title": "Popular Conjectures as a Barrier for Dynamic Planar Graph Algorithms", "comments": "20 pages, 4 figures. Abstract has been truncated to fit arXiv limits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamic shortest paths problem on planar graphs asks us to preprocess a\nplanar graph $G$ such that we may support insertions and deletions of edges in\n$G$ as well as distance queries between any two nodes $u,v$ subject to the\nconstraint that the graph remains planar at all times. This problem has been\nextensively studied in both the theory and experimental communities over the\npast decades and gets solved millions of times every day by companies like\nGoogle, Microsoft, and Uber. The best known algorithm performs queries and\nupdates in $\\tilde{O}(n^{2/3})$ time, based on ideas of a seminal paper by\nFakcharoenphol and Rao [FOCS'01]. A $(1+\\varepsilon)$-approximation algorithm\nof Abraham et al. [STOC'12] performs updates and queries in\n$\\tilde{O}(\\sqrt{n})$ time. An algorithm with $O(polylog(n))$ runtime would be\na major breakthrough. However, such runtimes are only known for a\n$(1+\\varepsilon)$-approximation in a model where only restricted weight updates\nare allowed due to Abraham et al. [SODA'16], or for easier problems like\nconnectivity.\n  In this paper, we follow a recent and very active line of work on showing\nlower bounds for polynomial time problems based on popular conjectures,\nobtaining the first such results for natural problems in planar graphs. Such\nresults were previously out of reach due to the highly non-planar nature of\nknown reductions and the impossibility of \"planarizing gadgets\". We introduce a\nnew framework which is inspired by techniques from the literatures on distance\nlabelling schemes and on parameterized complexity.\n  Using our framework, we show that no algorithm for dynamic shortest paths or\nmaximum weight bipartite matching in planar graphs can support both updates and\nqueries in amortized $O(n^{\\frac{1}{2}-\\varepsilon})$ time, for\n$\\varepsilon>0$, unless the classical APSP problem can be solved in truly\nsubcubic time, [...]\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 13:12:58 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["Abboud", "Amir", ""], ["Dahlgaard", "S\u00f8ren", ""]]}, {"id": "1605.03871", "submitter": "Hendrik Molter", "authors": "Anne-Sophie Himmel and Hendrik Molter and Rolf Niedermeier and Manuel\n  Sorge", "title": "Adapting the Bron-Kerbosch Algorithm for Enumerating Maximal Cliques in\n  Temporal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamics of interactions play an increasingly important role in the analysis\nof complex networks. A modeling framework to capture this are temporal graphs\nwhich consist of a set of vertices (entities in the network) and a set of\ntime-stamped binary interactions between the vertices. We focus on enumerating\ndelta-cliques, an extension of the concept of cliques to temporal graphs: for a\ngiven time period delta, a delta-clique in a temporal graph is a set of\nvertices and a time interval such that all vertices interact with each other at\nleast after every delta time steps within the time interval. Viard, Latapy, and\nMagnien [ASONAM 2015, TCS 2016] proposed a greedy algorithm for enumerating all\nmaximal delta-cliques in temporal graphs. In contrast to this approach, we\nadapt the Bron-Kerbosch algorithm - an efficient, recursive backtracking\nalgorithm which enumerates all maximal cliques in static graphs - to the\ntemporal setting. We obtain encouraging results both in theory (concerning\nworst-case running time analysis based on the parameter \"delta-slice\ndegeneracy\" of the underlying graph) as well as in practice with experiments on\nreal-world data. The latter culminates in an improvement for most interesting\ndelte-values concerning running time in comparison with the algorithm of Viard,\nLatapy, and Magnien.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 15:59:48 GMT"}, {"version": "v2", "created": "Tue, 2 May 2017 16:02:55 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Himmel", "Anne-Sophie", ""], ["Molter", "Hendrik", ""], ["Niedermeier", "Rolf", ""], ["Sorge", "Manuel", ""]]}, {"id": "1605.04000", "submitter": "Yaroslav Shitov", "authors": "Yaroslav Shitov", "title": "The nonnegative rank of a matrix: Hard problems, easy solutions", "comments": "A union of v1 and 1605.07173v1", "journal-ref": "SIAM Review 59 (2017) 794-800", "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using elementary linear algebra, we develop a technique that leads to\nsolutions of two widely known problems on nonnegative matrices. First, we give\na short proof of the result by Vavasis stating that the nonnegative rank of a\nmatrix is NP-hard to compute. This proof is essentially contained in the paper\nby Jiang and Ravikumar, who discussed this topic in different terms fifteen\nyears before the work of Vavasis. Secondly, we present a solution of the\nproblem of Cohen and Rothblum on rational nonnegative factorizations, which was\nposed in 1993 and remained open.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 22:40:03 GMT"}, {"version": "v2", "created": "Thu, 28 Dec 2017 21:02:54 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Shitov", "Yaroslav", ""]]}, {"id": "1605.04122", "submitter": "Richard Moot", "authors": "Richard Moot (LaBRI), Christian Retor\\'e (TEXTE)", "title": "Natural Language Semantics and Computability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a reflexion on the computability of natural language semantics.\nIt does not contain a new model or new results in the formal semantics of\nnatural language: it is rather a computational analysis of the logical models\nand algorithms currently used in natural language semantics, defined as the\nmapping of a statement to logical formulas - formulas, because a statement can\nbe ambiguous. We argue that as long as possible world semantics is left out,\none can compute the semantic representation(s) of a given statement, including\naspects of lexical meaning. We also discuss the algorithmic complexity of this\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 10:46:22 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Moot", "Richard", "", "LaBRI"], ["Retor\u00e9", "Christian", "", "TEXTE"]]}, {"id": "1605.04194", "submitter": "Thomas Vidick", "authors": "Kai-Min Chung, Gil Cohen, Thomas Vidick, Xiaodi Wu", "title": "Quantum-Proof Extractors: Optimal up to Constant Factors", "comments": "The paper has been withdrawn due to an error in the proof of Lemma\n  3.4 (step going from second-last to last centered equations), which\n  invalidates the main result", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first construction of a family of quantum-proof extractors that\nhas optimal seed length dependence $O(\\log(n/\\varepsilon))$ on the input length\n$n$ and error $\\varepsilon$. Our extractors support any min-entropy\n$k=\\Omega(\\log{n} + \\log^{1+\\alpha}(1/\\varepsilon))$ and extract\n$m=(1-\\alpha)k$ bits that are $\\varepsilon$-close to uniform, for any desired\nconstant $\\alpha > 0$. Previous constructions had a quadratically worse seed\nlength or were restricted to very large input min-entropy or very few output\nbits.\n  Our result is based on a generic reduction showing that any strong classical\ncondenser is automatically quantum-proof, with comparable parameters. The\nexistence of such a reduction for extractors is a long-standing open question,\nhere we give an affirmative answer for condensers. Once this reduction is\nestablished, to obtain our quantum-proof extractors one only needs to consider\nhigh entropy sources. We construct quantum-proof extractors with the desired\nparameters for such sources by extending a classical approach to extractor\nconstruction, based on the use of block-sources and sampling, to the quantum\nsetting.\n  Our extractors can be used to obtain improved protocols for\ndevice-independent randomness expansion and for privacy amplification.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 14:42:05 GMT"}, {"version": "v2", "created": "Mon, 1 Aug 2016 01:47:35 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Chung", "Kai-Min", ""], ["Cohen", "Gil", ""], ["Vidick", "Thomas", ""], ["Wu", "Xiaodi", ""]]}, {"id": "1605.04207", "submitter": "Mrinal Kumar", "authors": "Michael A. Forbes, Mrinal Kumar and Ramprasad Saptharishi", "title": "Functional lower bounds for arithmetic circuits and connections to\n  boolean circuit complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We say that a circuit $C$ over a field $F$ functionally computes an\n$n$-variate polynomial $P$ if for every $x \\in \\{0,1\\}^n$ we have that $C(x) =\nP(x)$. This is in contrast to syntactically computing $P$, when $C \\equiv P$ as\nformal polynomials. In this paper, we study the question of proving lower\nbounds for homogeneous depth-$3$ and depth-$4$ arithmetic circuits for\nfunctional computation. We prove the following results :\n  1. Exponential lower bounds homogeneous depth-$3$ arithmetic circuits for a\npolynomial in $VNP$.\n  2. Exponential lower bounds for homogeneous depth-$4$ arithmetic circuits\nwith bounded individual degree for a polynomial in $VNP$.\n  Our main motivation for this line of research comes from our observation that\nstrong enough functional lower bounds for even very special depth-$4$\narithmetic circuits for the Permanent imply a separation between ${\\#}P$ and\n$ACC$. Thus, improving the second result to get rid of the bounded individual\ndegree condition could lead to substantial progress in boolean circuit\ncomplexity. Besides, it is known from a recent result of Kumar and Saptharishi\n[KS15] that over constant sized finite fields, strong enough average case\nfunctional lower bounds for homogeneous depth-$4$ circuits imply\nsuperpolynomial lower bounds for homogeneous depth-$5$ circuits.\n  Our proofs are based on a family of new complexity measures called shifted\nevaluation dimension, and might be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 15:13:31 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Forbes", "Michael A.", ""], ["Kumar", "Mrinal", ""], ["Saptharishi", "Ramprasad", ""]]}, {"id": "1605.04284", "submitter": "Michael Dinitz", "authors": "Eden Chlamt\\'a\\v{c}, Michael Dinitz, Christian Konrad, Guy Kortsarz,\n  and George Rabanca", "title": "The Densest k-Subhypergraph Problem", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Densest $k$-Subgraph (D$k$S) problem, and its corresponding minimization\nproblem Smallest $p$-Edge Subgraph (S$p$ES), have come to play a central role\nin approximation algorithms. This is due both to their practical importance,\nand their usefulness as a tool for solving and establishing approximation\nbounds for other problems. These two problems are not well understood, and it\nis widely believed that they do not an admit a subpolynomial approximation\nratio (although the best known hardness results do not rule this out).\n  In this paper we generalize both D$k$S and S$p$ES from graphs to hypergraphs.\nWe consider the Densest $k$-Subhypergraph problem (given a hypergraph $(V, E)$,\nfind a subset $W\\subseteq V$ of $k$ vertices so as to maximize the number of\nhyperedges contained in $W$) and define the Minimum $p$-Union problem (given a\nhypergraph, choose $p$ of the hyperedges so as to minimize the number of\nvertices in their union). We focus in particular on the case where all\nhyperedges have size 3, as this is the simplest non-graph setting. For this\ncase we provide an $O(n^{4(4-\\sqrt{3})/13 + \\epsilon}) \\leq\nO(n^{0.697831+\\epsilon})$-approximation (for arbitrary constant $\\epsilon > 0$)\nfor Densest $k$-Subhypergraph and an $\\tilde O(n^{2/5})$-approximation for\nMinimum $p$-Union. We also give an $O(\\sqrt{m})$-approximation for Minimum\n$p$-Union in general hypergraphs. Finally, we examine the interesting special\ncase of interval hypergraphs (instances where the vertices are a subset of the\nnatural numbers and the hyperedges are intervals of the line) and prove that\nboth problems admit an exact polynomial time solution on these instances.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 18:57:39 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Chlamt\u00e1\u010d", "Eden", ""], ["Dinitz", "Michael", ""], ["Konrad", "Christian", ""], ["Kortsarz", "Guy", ""], ["Rabanca", "George", ""]]}, {"id": "1605.04715", "submitter": "Abdallah Saffidine", "authors": "\\'Edouard Bonnet, Florian Jamain, Abdallah Saffidine", "title": "On the Complexity of Connection Games", "comments": "Subsumes and extends https://arxiv.org/abs/1403.6518 significantly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study three connection games among the most widely played:\nHavannah, Twixt, and Slither. We show that determining the outcome of an\narbitrary input position is PSPACE-complete in all three cases. Our reductions\nare based on the popular graph problem Generalized Geography and on Hex itself.\nWe also consider the complexity of generalizations of Hex parameterized by the\nlength of the solution and establish that while Short Generalized Hex is\nW[1]-hard, Short Hex is FPT. Finally, we prove that the ultra-weak solution to\nthe empty starting position in hex cannot be fully adapted to any of these\nthree games.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 10:26:38 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Jamain", "Florian", ""], ["Saffidine", "Abdallah", ""]]}, {"id": "1605.05798", "submitter": "James Johndrow", "authors": "James E. Johndrow, Aaron Smith, Natesh Pillai, David B. Dunson", "title": "MCMC for Imbalanced Categorical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern applications collect highly imbalanced categorical data, with\nsome categories relatively rare. Bayesian hierarchical models combat data\nsparsity by borrowing information, while also quantifying uncertainty. However,\nposterior computation presents a fundamental barrier to routine use; a single\nclass of algorithms does not work well in all settings and practitioners waste\ntime trying different types of MCMC approaches. This article was motivated by\nan application to quantitative advertising in which we encountered extremely\npoor computational performance for common data augmentation MCMC algorithms but\nobtained excellent performance for adaptive Metropolis. To obtain a deeper\nunderstanding of this behavior, we give strong theory results on computational\ncomplexity in an infinitely imbalanced asymptotic regime. Our results show\ncomputational complexity of Metropolis is logarithmic in sample size, while\ndata augmentation is polynomial in sample size. The root cause of poor\nperformance of data augmentation is a discrepancy between the rates at which\nthe target density and MCMC step sizes concentrate. In general, MCMC algorithms\nthat have a similar discrepancy will fail in large samples - a result with\nsubstantial practical impact.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 02:45:46 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 15:06:27 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Johndrow", "James E.", ""], ["Smith", "Aaron", ""], ["Pillai", "Natesh", ""], ["Dunson", "David B.", ""]]}, {"id": "1605.05836", "submitter": "Radu Iosif", "authors": "Radu Iosif, Arnaud Sangnier", "title": "How hard is it to verify flat affine counter systems with the finite\n  monoid property ?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several decision problems for counter systems with guards defined by\nconvex polyhedra and updates defined by affine transformations. In general, the\nreachability problem is undecidable for such systems. Decidability can be\nachieved by imposing two restrictions: (i) the control structure of the counter\nsystem is flat, meaning that nested loops are forbidden, and (ii) the set of\nmatrix powers is finite, for any affine update matrix in the system. We provide\ntight complexity bounds for several decision problems of such systems, by\nproving that reachability and model checking for Past Linear Temporal Logic are\ncomplete for the second level of the polynomial hierarchy $\\Sigma^P_2$, while\nmodel checking for First Order Logic is PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 07:34:40 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Iosif", "Radu", ""], ["Sangnier", "Arnaud", ""]]}, {"id": "1605.05838", "submitter": "George Barmpalias Dr", "authors": "George Barmpalias and Douglas Cenzer and Christopher P. Porter", "title": "Random numbers as probabilities of machine behaviour", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fruitful way of obtaining meaningful, possibly concrete, algorithmically\nrandom numbers is to consider a potential behaviour of a Turing machine and its\nprobability with respect to a measure (or semi-measure) on the input space of\nbinary codes. For example, Chaitin's Omega is a well known Martin-Loef random\nnumber that is obtained by considering the halting probability of a universal\nprefix-free machine. In the last decade, similar examples have been obtained\nfor higher forms of randomness, i.e. randomness relative to strong oracles. In\nthis work we obtain characterizations of the algorithmically random reals in\nhigher randomness classes, as probabilities of certain events that can happen\nwhen an oracle universal machine runs probabilistically on a random oracle.\nMoreover we apply our analysis to different machine models, including oracle\nTuring machines, prefix-free machines, and models for infinite online\ncomputation. We find that in many cases the arithmetical complexity of a\nproperty is directly reflected in the strength of the algorithmic randomness of\nthe probability with which it occurs, on any given universal machine. On the\nother hand, we point to many examples where this does not happen and the\nprobability is a number whose algorithmic randomness is not the maximum\npossible (with respect to its arithmetical complexity). Finally we find that,\nunlike the halting probability of a universal machine, the probabilities of\nmore complex properties like totality, cofinality, computability or\ncompleteness do not necessarily have the same Turing degree when they are\ndefined with respect to different universal machines.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 07:58:51 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 04:02:28 GMT"}, {"version": "v3", "created": "Wed, 1 Feb 2017 22:53:45 GMT"}, {"version": "v4", "created": "Mon, 12 Jun 2017 03:12:29 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Barmpalias", "George", ""], ["Cenzer", "Douglas", ""], ["Porter", "Christopher P.", ""]]}, {"id": "1605.06692", "submitter": "Andrey Nikiforov", "authors": "Elena V. Djukova, Andrey G. Nikiforov, Petr A. Prokofyev", "title": "Parallelizing asymptotically optimal algorithms for large-scale\n  dualization problems", "comments": "17 pages, 3 figures (5 images)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dualization is a key discrete enumeration problem. It is not known whether or\nnot this problem is polynomial-time solvable. Asymptotically optimal\ndualization algorithms are the fastest among the known dualization algorithms,\nwhich is supported by new experiments with various data described in this\npaper. A theoretical justification of the efficiency of these algorithms on the\naverage was given by E.V. Djukova more than 30 years ago. In this paper, new\nresults on the construction of parallel algorithms for intractable enumeration\nproblems are presented. A new static parallelization scheme for asymptotically\noptimal dualization algorithms is developed and tested. The scheme is based on\nstatistical estimations of subtasks size.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 19:48:26 GMT"}, {"version": "v2", "created": "Sat, 28 May 2016 20:21:41 GMT"}, {"version": "v3", "created": "Tue, 31 May 2016 06:01:31 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Djukova", "Elena V.", ""], ["Nikiforov", "Andrey G.", ""], ["Prokofyev", "Petr A.", ""]]}, {"id": "1605.06801", "submitter": "Svenja Huntemann", "authors": "Kyle Burke, Silvia Heubach, Melissa Huggan, and Svenja Huntemann", "title": "Keeping Your Distance is Hard", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of distance games, a class of\ncombinatorial games played on graphs. A move consists of colouring an\nuncoloured vertex subject to it not being at certain distances determined by\ntwo sets, D and S. D is the set of forbidden distances for colouring vertices\nin different colors, while S is the set of forbidden distances for the same\ncolour. The last player to move wins. Well-known examples of distance games are\nNode-Kayles, Snort, and Col, whose complexities were shown to be PSPACE-hard.\nWe show that many more distance games are also PSPACE-hard.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 14:41:51 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 19:30:51 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Burke", "Kyle", ""], ["Heubach", "Silvia", ""], ["Huggan", "Melissa", ""], ["Huntemann", "Svenja", ""]]}, {"id": "1605.06814", "submitter": "Will Rosenbaum", "authors": "Rafail Ostrovsky, Mor Perry, Will Rosenbaum", "title": "Space-Time Tradeoffs for Distributed Verification", "comments": "Pre-proceedings version of paper presented at the 24th International\n  Colloquium on Structural Information and Communication Complexity (SIROCCO\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying that a network configuration satisfies a given boolean predicate is\na fundamental problem in distributed computing. Many variations of this problem\nhave been studied, for example, in the context of proof labeling schemes (PLS),\nlocally checkable proofs (LCP), and non-deterministic local decision (NLD). In\nall of these contexts, verification time is assumed to be constant. Korman,\nKutten and Masuzawa [PODC 2011] presented a proof-labeling scheme for MST, with\npoly-logarithmic verification time, and logarithmic memory at each vertex.\n  In this paper we introduce the notion of a $t$-PLS, which allows the\nverification procedure to run for super-constant time. Our work analyzes the\ntradeoffs of $t$-PLS between time, label size, message length, and computation\nspace. We construct a universal $t$-PLS and prove that it uses the same amount\nof total communication as a known one-round universal PLS, and $t$ factor\nsmaller labels. In addition, we provide a general technique to prove lower\nbounds for space-time tradeoffs of $t$-PLS. We use this technique to show an\noptimal tradeoff for testing that a network is acyclic (cycle free). Our\noptimal $t$-PLS for acyclicity uses label size and computation space $O((\\log\nn)/t)$. We further describe a recursive $O(\\log^* n)$ space verifier for\nacyclicity which does not assume previous knowledge of the run-time $t$.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 16:13:24 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 03:28:23 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Ostrovsky", "Rafail", ""], ["Perry", "Mor", ""], ["Rosenbaum", "Will", ""]]}, {"id": "1605.06848", "submitter": "Stefan Kiefer", "authors": "Dmitry Chistikov, Stefan Kiefer, Ines Maru\\v{s}i\\'c, Mahsa\n  Shirmohammadi, James Worrell", "title": "Nonnegative Matrix Factorization Requires Irrationality", "comments": "Journal version, to appear in the SIAM Journal on Applied Algebra and\n  Geometry (SIAGA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is the problem of decomposing a given\nnonnegative $n \\times m$ matrix $M$ into a product of a nonnegative $n \\times\nd$ matrix $W$ and a nonnegative $d \\times m$ matrix $H$. A longstanding open\nquestion, posed by Cohen and Rothblum in 1993, is whether a rational matrix $M$\nalways has an NMF of minimal inner dimension $d$ whose factors $W$ and $H$ are\nalso rational. We answer this question negatively, by exhibiting a matrix for\nwhich $W$ and $H$ require irrational entries.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 20:17:24 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 22:03:17 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Chistikov", "Dmitry", ""], ["Kiefer", "Stefan", ""], ["Maru\u0161i\u0107", "Ines", ""], ["Shirmohammadi", "Mahsa", ""], ["Worrell", "James", ""]]}, {"id": "1605.07061", "submitter": "Stefan Kiefer", "authors": "Dmitry Chistikov, Stefan Kiefer, Ines Maru\\v{s}i\\'c, Mahsa\n  Shirmohammadi, James Worrell", "title": "On Restricted Nonnegative Matrix Factorization", "comments": "Full version of an ICALP'16 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is the problem of decomposing a given\nnonnegative $n \\times m$ matrix $M$ into a product of a nonnegative $n \\times\nd$ matrix $W$ and a nonnegative $d \\times m$ matrix $H$. Restricted NMF\nrequires in addition that the column spaces of $M$ and $W$ coincide. Finding\nthe minimal inner dimension $d$ is known to be NP-hard, both for NMF and\nrestricted NMF. We show that restricted NMF is closely related to a question\nabout the nature of minimal probabilistic automata, posed by Paz in his seminal\n1971 textbook. We use this connection to answer Paz's question negatively, thus\nfalsifying a positive answer claimed in 1974. Furthermore, we investigate\nwhether a rational matrix $M$ always has a restricted NMF of minimal inner\ndimension whose factors $W$ and $H$ are also rational. We show that this holds\nfor matrices $M$ of rank at most $3$ and we exhibit a rank-$4$ matrix for which\n$W$ and $H$ require irrational entries.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 15:26:26 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Chistikov", "Dmitry", ""], ["Kiefer", "Stefan", ""], ["Maru\u0161i\u0107", "Ines", ""], ["Shirmohammadi", "Mahsa", ""], ["Worrell", "James", ""]]}, {"id": "1605.07084", "submitter": "Shalev Ben-David", "authors": "Shalev Ben-David, Pooya Hatami, Avishay Tal", "title": "Low-Sensitivity Functions from Unambiguous Certificates", "comments": "25 pages. This version expands the results and adds Pooya Hatami and\n  Avishay Tal as authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new query complexity separations against sensitivity for total\nBoolean functions: a power $3$ separation between deterministic (and even\nrandomized or quantum) query complexity and sensitivity, and a power $2.22$\nseparation between certificate complexity and sensitivity. We get these\nseparations by using a new connection between sensitivity and a seemingly\nunrelated measure called one-sided unambiguous certificate complexity\n($UC_{min}$). We also show that $UC_{min}$ is lower-bounded by fractional block\nsensitivity, which means we cannot use these techniques to get a\nsuper-quadratic separation between $bs(f)$ and $s(f)$. We also provide a\nquadratic separation between the tree-sensitivity and decision tree complexity\nof Boolean functions, disproving a conjecture of Gopalan, Servedio, Tal, and\nWigderson (CCC 2016).\n  Along the way, we give a power $1.22$ separation between certificate\ncomplexity and one-sided unambiguous certificate complexity, improving the\npower $1.128$ separation due to G\\\"o\\\"os (FOCS 2015). As a consequence, we\nobtain an improved $\\Omega(\\log^{1.22} n)$ lower-bound on the\nco-nondeterministic communication complexity of the Clique vs. Independent Set\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 16:38:40 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 23:26:28 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Ben-David", "Shalev", ""], ["Hatami", "Pooya", ""], ["Tal", "Avishay", ""]]}, {"id": "1605.07503", "submitter": "Carlos Barron-Romero Prof.", "authors": "Carlos Barr\\'on-Romero", "title": "A novel algorithm for solving the Decision Boolean Satisfiability\n  Problem without algebra", "comments": "arXiv admin note: text overlap with arXiv:1602.06867 Published in\n  COMTEL 2016 (http://www.comtel.pe/memoriacomtel/COMTEL2016.pdf) See in\n  http://academicos.azc.uam.mx/cbr/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper depicts an algorithm for solving the Decision Boolean\nSatisfiability Problem using the binary numerical properties of a Special\nDecision Satisfiability Problem, parallel execution, object oriented, and short\ntermination. The two operations: expansion and simplification are used to\nexplains why using algebra grows the resolution steps. It is proved that its\ncomplexity has an upper bound of $2^{n-1}$ where $n$ is the number of logical\nvariables of the given problem.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 02:06:46 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 20:46:29 GMT"}, {"version": "v3", "created": "Sat, 28 May 2016 09:03:36 GMT"}, {"version": "v4", "created": "Tue, 31 May 2016 00:18:18 GMT"}, {"version": "v5", "created": "Mon, 16 Jan 2017 02:13:50 GMT"}, {"version": "v6", "created": "Sun, 26 Nov 2017 21:36:45 GMT"}, {"version": "v7", "created": "Sat, 14 Apr 2018 08:58:50 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Barr\u00f3n-Romero", "Carlos", ""]]}, {"id": "1605.07959", "submitter": "Tom\\'a\\v{s} Toufar", "authors": "Tom\\'a\\v{s} Masa\\v{r}\\'ik, Tom\\'a\\v{s} Toufar", "title": "Parameterized complexity of fair deletion problems", "comments": "17 pages. The hardness results from v1 were extended to FO logic", "journal-ref": "Discrete Applied Mathematics 278 (2020) 51-61", "doi": "10.1016/j.dam.2019.06.001", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deletion problems are those where given a graph $G$ and a graph property\n$\\pi$, the goal is to find a subset of edges such that after its removal the\ngraph $G$ will satisfy the property $\\pi$. Typically, we want to minimize the\nnumber of elements removed. In fair deletion problems we change the objective:\nwe minimize the maximum number of deletions in a neighborhood of a single\nvertex.\n  We study the parameterized complexity of fair deletion problems with respect\nto the structural parameters of the tree-width, the path-width, the size of a\nminimum feedback vertex set, the neighborhood diversity, and the size of\nminimum vertex cover of graph $G$. We prove the W[1]-hardness of the fair FO\nvertex-deletion problem with respect to the first three parameters combined.\nMoreover, we show that there is no algorithm for fair FO vertex-deletion\nproblem running in time $n^{o(k^{1/3})}$, where $n$ is the size of the graph\nand $k$ is the sum of the first three mentioned parameters, provided that the\nExponential Time Hypothesis holds.\n  On the other hand, we provide an FPT algorithm for the fair MSO edge-deletion\nproblem parameterized by the size of minimum vertex cover and an FPT algorithm\nfor the fair MSO vertex-deletion problem parameterized by the neighborhood\ndiversity\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 16:34:29 GMT"}, {"version": "v2", "created": "Wed, 4 Jan 2017 15:43:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Masa\u0159\u00edk", "Tom\u00e1\u0161", ""], ["Toufar", "Tom\u00e1\u0161", ""]]}, {"id": "1605.08738", "submitter": "R\\'emi Watrigant", "authors": "Jason Crampton, Gregory Gutin, Martin Kouteck\\'y and R\\'emi Watrigant", "title": "Parameterized Resiliency Problems via Integer Linear Programming", "comments": "This paper is based on two papers published in conference proceedings\n  of AAIM 2016 and CIAC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension of decision problems called resiliency problems. In\nresiliency problems, the goal is to decide whether an instance remains positive\nafter any (appropriately defined) perturbation has been applied to it. To\ntackle these kinds of problems, some of which might be of practical interest,\nwe introduce a notion of resiliency for Integer Linear Programs (ILP) and show\nhow to use a result of Eisenbrand and Shmonin (Math. Oper. Res., 2008) on\nParametric Linear Programming to prove that ILP Resiliency is fixed-parameter\ntractable (FPT) under a certain parameterization. To demonstrate the utility of\nour result, we consider natural resiliency versions of several concrete\nproblems, and prove that they are FPT under natural parameterizations. Our\nfirst results concern a four-variate problem which generalizes the Disjoint Set\nCover problem and which is of interest in access control. We obtain a complete\nparameterized complexity classification for every possible combination of the\nparameters. Then, we introduce and study a resiliency version of the Closest\nString problem, for which we extend an FPT result of Gramm et al.\n(Algorithmica, 2003). We also consider problems in the fields of scheduling and\nsocial choice. We believe that many other problems can be tackled by our\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 18:15:50 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 15:53:49 GMT"}, {"version": "v3", "created": "Mon, 14 Nov 2016 08:36:42 GMT"}, {"version": "v4", "created": "Tue, 8 Aug 2017 11:37:17 GMT"}, {"version": "v5", "created": "Thu, 3 May 2018 12:13:43 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Crampton", "Jason", ""], ["Gutin", "Gregory", ""], ["Kouteck\u00fd", "Martin", ""], ["Watrigant", "R\u00e9mi", ""]]}, {"id": "1605.08951", "submitter": "Oscar Temprano", "authors": "Oscar Temprano", "title": "A handle is enough for a hard game of Pull", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We are going to show that some variants of a puzzle called Pull in which the\nboxes have handles (i.e. we can only pull the boxes in certain directions) are\nNP-hard\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 00:02:16 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 01:13:01 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Temprano", "Oscar", ""]]}, {"id": "1605.09013", "submitter": "C\\'ecilia Lancien", "authors": "C\\'ecilia Lancien, Andreas Winter", "title": "Flexible constrained de Finetti reductions and applications", "comments": "19 pages", "journal-ref": "J. Math. Phys, 58, 092203 (2017)", "doi": "10.1063/1.5003633", "report-no": null, "categories": "quant-ph cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De Finetti theorems show how sufficiently exchangeable states are\nwell-approximated by convex combinations of i.i.d. states. Recently, it was\nshown that in many quantum information applications a more relaxed de Finetti\nreduction (i.e. only a matrix inequality between the symmetric state and one of\nde Finetti form) is enough, and that it leads to more concise and elegant\narguments. Here we show several uses and general flexible applicability of a\nconstrained de Finetti reduction in quantum information theory, which was\nrecently discovered by Duan, Severini and Winter. In particular we show that\nthe technique can accommodate other symmetries commuting with the permutation\naction, and permutation-invariant linear constraints. We then demonstrate that,\nin some cases, it is also fruitful with convex constraints, in particular\nseparability in a bipartite setting. This is a constraint particularly\ninteresting in the context of the complexity class $\\mathrm{QMA}(2)$ of\ninteractive quantum Merlin-Arthur games with unentangled provers, and our\nresults relate to the soundness gap amplification of $\\mathrm{QMA}(2)$\nprotocols by parallel repetition. It is also relevant for the regularization of\ncertain entropic channel parameters. Finally, we explore an extension to\ninfinite-dimensional systems, which usually pose inherent problems to de\nFinetti techniques in the quantum case.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 14:55:23 GMT"}, {"version": "v2", "created": "Sun, 24 Jul 2016 17:09:32 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Lancien", "C\u00e9cilia", ""], ["Winter", "Andreas", ""]]}, {"id": "1605.09071", "submitter": "Robin Kothari", "authors": "Shalev Ben-David and Robin Kothari", "title": "Randomized query complexity of sabotaged and composed functions", "comments": "v1: 22 pages; v2: 23 pages, minor changes", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2016.60", "report-no": "MIT-CTP #4806", "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the composition question for bounded-error randomized query\ncomplexity: Is R(f o g) = Omega(R(f) R(g)) for all Boolean functions f and g?\nWe show that inserting a simple Boolean function h, whose query complexity is\nonly Theta(log R(g)), in between f and g allows us to prove R(f o h o g) =\nOmega(R(f) R(h) R(g)).\n  We prove this using a new lower bound measure for randomized query complexity\nwe call randomized sabotage complexity, RS(f). Randomized sabotage complexity\nhas several desirable properties, such as a perfect composition theorem, RS(f o\ng) >= RS(f) RS(g), and a composition theorem with randomized query complexity,\nR(f o g) = Omega(R(f) RS(g)). It is also a quadratically tight lower bound for\ntotal functions and can be quadratically superior to the partition bound, the\nbest known general lower bound for randomized query complexity.\n  Using this technique we also show implications for lifting theorems in\ncommunication complexity. We show that a general lifting theorem for zero-error\nrandomized protocols implies a general lifting theorem for bounded-error\nprotocols.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 22:46:12 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 00:17:20 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Ben-David", "Shalev", ""], ["Kothari", "Robin", ""]]}, {"id": "1605.09646", "submitter": "Quentin Berthet", "authors": "Tengyao Wang, Quentin Berthet, Yaniv Plan", "title": "Average-case Hardness of RIP Certification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The restricted isometry property (RIP) for design matrices gives guarantees\nfor optimal recovery in sparse linear models. It is of high interest in\ncompressed sensing and statistical learning. This property is particularly\nimportant for computationally efficient recovery methods. As a consequence,\neven though it is in general NP-hard to check that RIP holds, there have been\nsubstantial efforts to find tractable proxies for it. These would allow the\nconstruction of RIP matrices and the polynomial-time verification of RIP given\nan arbitrary matrix. We consider the framework of average-case certifiers, that\nnever wrongly declare that a matrix is RIP, while being often correct for\nrandom instances. While there are such functions which are tractable in a\nsuboptimal parameter regime, we show that this is a computationally hard task\nin any better regime. Our results are based on a new, weaker assumption on the\nproblem of detecting dense subgraphs.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 14:38:03 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Wang", "Tengyao", ""], ["Berthet", "Quentin", ""], ["Plan", "Yaniv", ""]]}]