[{"id": "1102.0072", "submitter": "Michael Forbes", "authors": "Boris Alexeev, Michael Forbes, Jacob Tsimerman", "title": "Tensor Rank: Some Lower and Upper Bounds", "comments": "27 pages", "journal-ref": "IEEE Conference on Computational Complexity 26 (2011), 283-291", "doi": "10.1109/CCC.2011.28", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The results of Strassen and Raz show that good enough tensor rank lower\nbounds have implications for algebraic circuit/formula lower bounds.\n  We explore tensor rank lower and upper bounds, focusing on explicit tensors.\nFor odd d, we construct field-independent explicit 0/1 tensors T:[n]^d->F with\nrank at least 2n^(floor(d/2))+n-Theta(d log n). This matches (over F_2) or\nimproves (all other fields) known lower bounds for d=3 and improves (over any\nfield) for odd d>3.\n  We also explore a generalization of permutation matrices, which we denote\npermutation tensors. We show, by counting, that there exists an order-3\npermutation tensor with super-linear rank. We also explore a natural class of\npermutation tensors, which we call group tensors. For any group G, we define\nthe group tensor T_G^d:G^d->F, by T_G^d(g_1,...,g_d)=1 iff g_1 x ... x g_d=1_G.\nWe give two upper bounds for the rank of these tensors. The first uses\nrepresentation theory and works over large fields F, showing (among other\nthings) that rank_F(T_G^d)<= |G|^(d/2). We also show that if this upper bound\nis tight, then super-linear tensor rank lower bounds would follow. The second\nupper bound uses interpolation and only works for abelian G, showing that over\nany field F that rank_F(T_G^d)<= O(|G|^(1+log d)log^(d-1)|G|). In either case,\nthis shows that many permutation tensors have far from maximal rank, which is\nvery different from the matrix case and thus eliminates many natural candidates\nfor high tensor rank.\n  We also explore monotone tensor rank. We give explicit 0/1 tensors T:[n]^d->F\nthat have tensor rank at most dn but have monotone tensor rank exactly n^(d-1).\nThis is a nearly optimal separation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 03:42:55 GMT"}], "update_date": "2012-03-05", "authors_parsed": [["Alexeev", "Boris", ""], ["Forbes", "Michael", ""], ["Tsimerman", "Jacob", ""]]}, {"id": "1102.0378", "submitter": "Abuzer Yakaryilmaz", "authors": "Abuzer Yakaryilmaz", "title": "Classical and quantum computation with small space bounds (PhD thesis)", "comments": "Bogazici University (Istanbul) PhD thesis, 183 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we introduce a new quantum Turing machine (QTM) model that\nsupports general quantum operators, together with its pushdown, counter, and\nfinite automaton variants, and examine the computational power of classical and\nquantum machines using small space bounds in many different cases. The main\ncontributions are summarized below.\n  Firstly, we consider QTMs in the unbounded error setting: (i) in some cases\nof sublogarithmic space bounds, the class of languages recognized by QTMs is\nshown to be strictly larger than that of classical ones; (ii) in constant space\nbounds, the same result can still be obtained for restricted QTMs; (iii) the\ncomplete characterization of the class of languages recognized by realtime\nconstant space nondeterministic QTMs is given.\n  Secondly, we consider constant space-bounded QTMs in the bounded error\nsetting: (i) we introduce a new type of quantum and probabilistic finite\nautomata (QFAs and PFAs, respectively,) with a special two-way input head which\nis not allowed to be stationary or move to the left but has the capability to\nreset itself to its starting position; (ii) the computational power of this\ntype of quantum machine is shown to be superior to that of the probabilistic\nmachine; (iii) based on these models, two-way PFAs and two-way classical-head\nQFAs are shown to be more succinct than two-way nondeterministic finite\nautomata and their one-way variants; (iv) we also introduce PFAs and QFAs with\npostselection with their bounded error language classes, and give many\ncharacterizations of them.\n  Thirdly, the computational power of realtime QFAs augmented with a write-only\nmemory is investigated by showing many simulation results for different kinds\nof counter automata.\n  Finally, some lower bounds of realtime classical Turing machines in order to\nrecognize a nonregular language are shown to be tight.\n", "versions": [{"version": "v1", "created": "Wed, 2 Feb 2011 08:14:30 GMT"}], "update_date": "2011-02-03", "authors_parsed": [["Yakaryilmaz", "Abuzer", ""]]}, {"id": "1102.0580", "submitter": "Benjamin Weitz", "authors": "Benjamin Weitz", "title": "An Improvement on Ranks of Explicit Tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give constructions of n^k x n^k x n tensors of rank at least 2n^k -\nO(n^(k-1)). As a corollary we obtain an [n]^r shaped tensor with rank at least\n2n^(r/2) - O(n^(r/2)-1) when r is odd. The tensors are constructed from a\nsimple recursive pattern, and the lower bounds are proven using a partitioning\ntheorem developed by Brockett and Dobkin. These two bounds are improvements\nover the previous best-known explicit tensors that had ranks n^k and n^(r/2)\nrespectively\n", "versions": [{"version": "v1", "created": "Wed, 2 Feb 2011 22:48:58 GMT"}, {"version": "v2", "created": "Thu, 10 Feb 2011 00:31:46 GMT"}], "update_date": "2011-02-11", "authors_parsed": [["Weitz", "Benjamin", ""]]}, {"id": "1102.0666", "submitter": "Abuzer Yakaryilmaz", "authors": "Abuzer Yakaryilmaz and A. C. Cem Say", "title": "Probabilistic and quantum finite automata with postselection", "comments": "24 pages. A preliminary version of this paper appeared in the\n  Proceedings of Randomized and Quantum Computation (satellite workshop of MFCS\n  and CSL 2010), pages 14--24, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that endowing a real-time probabilistic or quantum computer with the\nability of postselection increases its computational power. For this purpose,\nwe provide a new model of finite automata with postselection, and compare it\nwith the model of L\\={a}ce et al. We examine the related language classes, and\nalso establish separations between the classical and quantum versions, and\nbetween the zero-error vs. bounded-error modes of recognition in this model.\n", "versions": [{"version": "v1", "created": "Thu, 3 Feb 2011 12:48:53 GMT"}], "update_date": "2011-02-04", "authors_parsed": [["Yakaryilmaz", "Abuzer", ""], ["Say", "A. C. Cem", ""]]}, {"id": "1102.0686", "submitter": "Antoine Taveneaux", "authors": "Antoine Taveneaux", "title": "Towards an axiomatic system for Kolmogorov complexity", "comments": null, "journal-ref": "Computability in Europe 2011 Springer LNCS volume", "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.LO math.IT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [She82], it is shown that four basic functional properties are enough to\ncharacterize plain Kolmogorov complexity, hence obtaining an axiomatic\ncharacterization of this notion. In this paper, we try to extend this work,\nboth by looking at alternative axiomatic systems for plain complexity and by\nconsidering potential axiomatic systems for other types of complexity. First we\nshow that the axiomatic system given by Shen cannot be weakened (at least in\nany natural way). We then give an analogue of Shen's axiomatic system for\nconditional complexity. In a the second part of the paper, we look at\nprefix-free complexity and try to construct an axiomatic system for it. We show\nhowever that the natural analogues of Shen's axiomatic systems fails to\ncharacterize prefix-free complexity.\n", "versions": [{"version": "v1", "created": "Thu, 3 Feb 2011 13:58:28 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2011 06:23:54 GMT"}], "update_date": "2011-04-01", "authors_parsed": [["Taveneaux", "Antoine", ""]]}, {"id": "1102.0908", "submitter": "Somnath Sikdar", "authors": "Alexander Langer and Peter Rossmanith and Somnath Sikdar", "title": "Linear-Time Algorithms for Graphs of Bounded Rankwidth: A Fresh Look\n  Using Game Theory", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternative proof of a theorem by Courcelle, Makowski and\nRotics which states that problems expressible in MSO are solvable in linear\ntime for graphs of bounded rankwidth. Our proof uses a game-theoretic approach\nand has the advantage of being self-contained, intuitive, and fairly easy to\nfollow. In particular, our presentation does not assume any background in logic\nor automata theory. We believe that it is good to have alternative proofs of\nthis important result. Moreover our approach can be generalized to prove other\nresults of a similar flavor, for example, that of Courcelle's Theorem for\ntreewidth.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 13:28:09 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["Langer", "Alexander", ""], ["Rossmanith", "Peter", ""], ["Sikdar", "Somnath", ""]]}, {"id": "1102.0969", "submitter": "Bhaskar DasGupta", "authors": "Bhaskar DasGupta and Devendra Desai", "title": "On the Complexity of Newman's Community Finding Approach for Biological\n  and Social Networks", "comments": "Journal of Computer and System Sciences, 2012", "journal-ref": "Journal of Computer & System Sciences, 79, 50-67, 2013", "doi": "10.1016/j.jcss.2012.04.003", "report-no": null, "categories": "physics.soc-ph cs.CC cs.DM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph of interactions, a module (also called a community or cluster)\nis a subset of nodes whose fitness is a function of the statistical\nsignificance of the pairwise interactions of nodes in the module. The topic of\nthis paper is a model-based community finding approach, commonly referred to as\nmodularity clustering, that was originally proposed by Newman and has\nsubsequently been extremely popular in practice. Various heuristic methods are\ncurrently employed for finding the optimal solution. However, the exact\ncomputational complexity of this approach is still largely unknown.\n  To this end, we initiate a systematic study of the computational complexity\nof modularity clustering. Due to the specific quadratic nature of the\nmodularity function, it is necessary to study its value on sparse graphs and\ndense graphs separately. Our main results include a (1+\\eps)-inapproximability\nfor dense graphs and a logarithmic approximation for sparse graphs. We make use\nof several combinatorial properties of modularity to get these results. These\nare the first non-trivial approximability results beyond the previously known\nNP-hardness results.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 16:56:58 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2012 02:17:37 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["DasGupta", "Bhaskar", ""], ["Desai", "Devendra", ""]]}, {"id": "1102.1006", "submitter": "Bhaskar DasGupta", "authors": "Mary Ashley and Tanya Berger-Wolf and Piotr Berman and Wanpracha\n  Chaovalitwongse and Bhaskar DasGupta and Ming-Yang Kao", "title": "On Approximating Four Covering and Packing Problems", "comments": "25 pages", "journal-ref": "Journal of Computer and System Sciences, 75, 287-302, 2009", "doi": "10.1016/j.jcss.2009.01.002", "report-no": null, "categories": "cs.CC cs.DM cs.DS q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider approximability issues of the following four\nproblems: triangle packing, full sibling reconstruction, maximum profit\ncoverage and 2-coverage. All of them are generalized or specialized versions of\nset-cover and have applications in biology ranging from full-sibling\nreconstructions in wild populations to biomolecular clusterings; however, as\nthis paper shows, their approximability properties differ considerably. Our\ninapproximability constant for the triangle packing problem improves upon the\nprevious results; this is done by directly transforming the inapproximability\ngap of Haastad for the problem of maximizing the number of satisfied equations\nfor a set of equations over GF(2) and is interesting in its own right. Our\napproximability results on the full siblings reconstruction problems answers\nquestions originally posed by Berger-Wolf et al. and our results on the maximum\nprofit coverage problem provides almost matching upper and lower bounds on the\napproximation ratio, answering a question posed by Hassin and Or.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 19:59:12 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["Ashley", "Mary", ""], ["Berger-Wolf", "Tanya", ""], ["Berman", "Piotr", ""], ["Chaovalitwongse", "Wanpracha", ""], ["DasGupta", "Bhaskar", ""], ["Kao", "Ming-Yang", ""]]}, {"id": "1102.1096", "submitter": "Lance Fortnow", "authors": "Michele Budinich and Lance Fortnow", "title": "Repeated Matching Pennies with Limited Randomness", "comments": "To appear in Proceedings of the 12th ACM Conference on Electronic\n  Commerce. ACM, New York, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a repeated Matching Pennies game in which players have limited\naccess to randomness. Playing the (unique) Nash equilibrium in this n-stage\ngame requires n random bits. Can there be Nash equilibria that use less than n\nrandom coins?\n  Our main results are as follows: We give a full characterization of\napproximate equilibria, showing that, for any e in [0, 1], the game has a\ne-Nash equilibrium if and only if both players have (1 - e)n random coins. When\nplayers are bound to run in polynomial time, Nash equilibria can exist if and\nonly if one-way functions exist. It is possible to trade-off randomness for\nrunning time. In particular, under reasonable assumptions, if we give one\nplayer only O(log n) random coins but allow him to run in arbitrary polynomial\ntime and we restrict his opponent to run in time n^k, for some fixed k, then we\ncan sustain an Nash equilibrium. When the game is played for an infinite amount\nof rounds with time discounted utilities, under reasonable assumptions, we can\nreduce the amount of randomness required to achieve a e-Nash equilibrium to n,\nwhere n is the number of random coins necessary to achieve an approximate Nash\nequilibrium in the general case.\n", "versions": [{"version": "v1", "created": "Sat, 5 Feb 2011 19:46:56 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2011 23:24:44 GMT"}], "update_date": "2011-03-30", "authors_parsed": [["Budinich", "Michele", ""], ["Fortnow", "Lance", ""]]}, {"id": "1102.1122", "submitter": "Golnaz Ghasemiesfeh", "authors": "Golnaz Ghasemiesfeh, Amir Daneshgar", "title": "New Definition for Fuzzy Constraint Satisfaction Problem and its\n  Applications", "comments": "This article has been withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article has been withdrawn.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 04:44:59 GMT"}, {"version": "v2", "created": "Thu, 24 Feb 2011 00:17:18 GMT"}, {"version": "v3", "created": "Mon, 28 Feb 2011 05:22:25 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Ghasemiesfeh", "Golnaz", ""], ["Daneshgar", "Amir", ""]]}, {"id": "1102.1140", "submitter": "Carola Winzen", "authors": "Benjamin Doerr, Carola Winzen", "title": "Ranking-Based Black-Box Complexity", "comments": "This is an extended version of our CSR 2011 paper. 31 pages. The\n  journal version is to appear in Algorithmica, DOI: 10.1007/s00453-012-9684-9", "journal-ref": null, "doi": "10.1007/s00453-012-9684-9", "report-no": null, "categories": "cs.NE cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized search heuristics such as evolutionary algorithms, simulated\nannealing, and ant colony optimization are a broadly used class of\ngeneral-purpose algorithms. Analyzing them via classical methods of theoretical\ncomputer science is a growing field. While several strong runtime analysis\nresults have appeared in the last 20 years, a powerful complexity theory for\nsuch algorithms is yet to be developed. We enrich the existing notions of\nblack-box complexity by the additional restriction that not the actual\nobjective values, but only the relative quality of the previously evaluated\nsolutions may be taken into account by the black-box algorithm. Many randomized\nsearch heuristics belong to this class of algorithms.\n  We show that the new ranking-based model gives more realistic complexity\nestimates for some problems. For example, the class of all binary-value\nfunctions has a black-box complexity of $O(\\log n)$ in the previous black-box\nmodels, but has a ranking-based complexity of $\\Theta(n)$.\n  For the class of all OneMax functions, we present a ranking-based black-box\nalgorithm that has a runtime of $\\Theta(n / \\log n)$, which shows that the\nOneMax problem does not become harder with the additional ranking-basedness\nrestriction.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 11:13:25 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2011 22:14:26 GMT"}, {"version": "v3", "created": "Mon, 3 Sep 2012 08:10:26 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Doerr", "Benjamin", ""], ["Winzen", "Carola", ""]]}, {"id": "1102.1161", "submitter": "Frederic Magniez", "authors": "Frederic Magniez and Michel de Rougemont and Miklos Santha and Xavier\n  Zeitoun", "title": "The complexity of approximate Nash equilibrium in congestion games with\n  negative delays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the study of the complexity of finding an $\\eps$-approximate Nash\nequilibrium in congestion games from the case of positive delay functions to\ndelays of arbitrary sign. We first prove that in symmetric games with\n$\\alpha$-bounded jump the $\\eps$-Nash dynamic converges in polynomial time when\nall delay functions are negative, similarly to the case of positive delays. We\nthen establish a hardness result for symmetric games with $\\alpha$-bounded jump\nand with arbitrary delay functions: in that case finding an $\\eps$-Nash\nequilibrium becomes $\\PLS$-complete.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 15:46:36 GMT"}], "update_date": "2011-02-08", "authors_parsed": [["Magniez", "Frederic", ""], ["de Rougemont", "Michel", ""], ["Santha", "Miklos", ""], ["Zeitoun", "Xavier", ""]]}, {"id": "1102.1199", "submitter": "Abuzer Yakaryilmaz", "authors": "A. C. Cem Say and Abuzer Yakaryilmaz", "title": "Computation with narrow CTCs", "comments": "16 pages. A few typo was corrected", "journal-ref": null, "doi": "10.1007/978-3-642-21341-0_23", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine some variants of computation with closed timelike curves (CTCs),\nwhere various restrictions are imposed on the memory of the computer, and the\ninformation carrying capacity and range of the CTC. We give full\ncharacterizations of the classes of languages recognized by polynomial time\nprobabilistic and quantum computers that can send a single classical bit to\ntheir own past. Such narrow CTCs are demonstrated to add the power of limited\nnondeterminism to deterministic computers, and lead to exponential speedup in\nconstant-space probabilistic and quantum computation. We show that, given a\ntime machine with constant negative delay, one can implement CTC-based\ncomputations without the need to know about the runtime beforehand.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 20:36:49 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2011 12:40:39 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Say", "A. C. Cem", ""], ["Yakaryilmaz", "Abuzer", ""]]}, {"id": "1102.1208", "submitter": "Karolina So{\\l}tys", "authors": "Karolina So{\\l}tys", "title": "The hardness of Median in the synchronized bit communication model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The synchronized bit communication model, defined recently by Impagliazzo and\nWilliams in \\emph{Communication complexity with synchronized clocks}, CCC '10,\nis a communication model which allows the participants to share a common clock.\nThe main open problem posed in this paper was the following: does the\nsynchronized bit model allow a logarithmic speed-up for all functions over the\nstandard deterministic model of communication? We resolve this question in the\nnegative by showing that the Median function, whose communication complexity is\n$O(\\log n)$, does not admit polytime synchronized bit protocol with\ncommunication complexity $O\\left(\\log^{1-\\epsilon} n\\right)$ for any $\\epsilon\n> 0$. Our results follow by a new round-communication trade-off for the Median\nfunction in the standard model, which easily translates to its hardness in the\nsynchronized bit model.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 22:53:32 GMT"}], "update_date": "2011-02-08", "authors_parsed": [["So\u0142tys", "Karolina", ""]]}, {"id": "1102.1747", "submitter": "Maria Polukarov", "authors": "Thomas D. Voice, Maria Polukarov, Nicholas R. Jennings", "title": "Graph Coalition Structure Generation", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first analysis of the computational complexity of {\\it coalition\nstructure generation over graphs}. Given an undirected graph $G=(N,E)$ and a\nvaluation function $v:2^N\\rightarrow\\RR$ over the subsets of nodes, the problem\nis to find a partition of $N$ into connected subsets, that maximises the sum of\nthe components' values. This problem is generally NP--complete; in particular,\nit is hard for a defined class of valuation functions which are {\\it\nindependent of disconnected members}---that is, two nodes have no effect on\neach other's marginal contribution to their vertex separator. Nonetheless, for\nall such functions we provide bounds on the complexity of coalition structure\ngeneration over general and minor free graphs. Our proof is constructive and\nyields algorithms for solving corresponding instances of the problem.\nFurthermore, we derive polynomial time bounds for acyclic, $K_{2,3}$ and $K_4$\nminor free graphs. However, as we show, the problem remains NP--complete for\nplanar graphs, and hence, for any $K_k$ minor free graphs where $k\\geq 5$.\nMoreover, our hardness result holds for a particular subclass of valuation\nfunctions, termed {\\it edge sum}, where the value of each subset of nodes is\nsimply determined by the sum of given weights of the edges in the induced\nsubgraph.\n", "versions": [{"version": "v1", "created": "Tue, 8 Feb 2011 23:13:58 GMT"}], "update_date": "2011-02-10", "authors_parsed": [["Voice", "Thomas D.", ""], ["Polukarov", "Maria", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1102.1783", "submitter": "Mihai Patrascu", "authors": "Mihai Patrascu and Mikkel Thorup", "title": "Don't Rush into a Union: Take Time to Find Your Roots", "comments": "To appear in STOC'11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new threshold phenomenon in data structure lower bounds where\nslightly reduced update times lead to exploding query times. Consider\nincremental connectivity, letting t_u be the time to insert an edge and t_q be\nthe query time. For t_u = Omega(t_q), the problem is equivalent to the\nwell-understood union-find problem: InsertEdge(s,t) can be implemented by\nUnion(Find(s), Find(t)). This gives worst-case time t_u = t_q = O(lg n / lglg\nn) and amortized t_u = t_q = O(alpha(n)).\n  By contrast, we show that if t_u = o(lg n / lglg n), the query time explodes\nto t_q >= n^{1-o(1)}. In other words, if the data structure doesn't have time\nto find the roots of each disjoint set (tree) during edge insertion, there is\nno effective way to organize the information!\n  For amortized complexity, we demonstrate a new inverse-Ackermann type\ntrade-off in the regime t_u = o(t_q).\n  A similar lower bound is given for fully dynamic connectivity, where an\nupdate time of o(\\lg n) forces the query time to be n^{1-o(1)}. This lower\nbound allows for amortization and Las Vegas randomization, and comes close to\nthe known O(lg n * poly(lglg n)) upper bound.\n", "versions": [{"version": "v1", "created": "Wed, 9 Feb 2011 05:07:47 GMT"}, {"version": "v2", "created": "Sun, 27 Mar 2011 17:20:00 GMT"}], "update_date": "2011-03-29", "authors_parsed": [["Patrascu", "Mihai", ""], ["Thorup", "Mikkel", ""]]}, {"id": "1102.2095", "submitter": "Satyadev Nandakumar", "authors": "Xiaoyang Gu, Jack H. Lutz, Satyadev Nandakumar, James S. Royer", "title": "Axiomatizing Resource Bounds for Measure", "comments": "Changed one reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource-bounded measure is a generalization of classical Lebesgue measure\nthat is useful in computational complexity. The central parameter of\nresource-bounded measure is the {\\it resource bound} $\\Delta$, which is a class\nof functions. When $\\Delta$ is unrestricted, i.e., contains all functions with\nthe specified domains and codomains, resource-bounded measure coincides with\nclassical Lebesgue measure. On the other hand, when $\\Delta$ contains functions\nsatisfying some complexity constraint, resource-bounded measure imposes\ninternal measure structure on a corresponding complexity class.\n  Most applications of resource-bounded measure use only the\n\"measure-zero/measure-one fragment\" of the theory. For this fragment, $\\Delta$\ncan be taken to be a class of type-one functions (e.g., from strings to\nrationals). However, in the full theory of resource-bounded measurability and\nmeasure, the resource bound $\\Delta$ also contains type-two functionals. To\ndate, both the full theory and its zero-one fragment have been developed in\nterms of a list of example resource bounds chosen for their apparent utility.\n  This paper replaces this list-of-examples approach with a careful\ninvestigation of the conditions that suffice for a class $\\Delta$ to be a\nresource bound. Our main theorem says that every class $\\Delta$ that has the\nclosure properties of Mehlhorn's basic feasible functionals is a resource bound\nfor measure.\n  We also prove that the type-2 versions of the time and space hierarchies that\nhave been extensively used in resource-bounded measure have these closure\nproperties. In the course of doing this, we prove theorems establishing that\nthese time and space resource bounds are all robust.\n", "versions": [{"version": "v1", "created": "Thu, 10 Feb 2011 12:24:01 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2012 13:55:13 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Gu", "Xiaoyang", ""], ["Lutz", "Jack H.", ""], ["Nandakumar", "Satyadev", ""], ["Royer", "James S.", ""]]}, {"id": "1102.2300", "submitter": "Alexandra Kolla", "authors": "Alexandra Kolla", "title": "Spectral Algorithms for Unique Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithm for Unique Games which is based on purely {\\em\nspectral} techniques, in contrast to previous work in the area, which relies\nheavily on semidefinite programming (SDP). Given a highly satisfiable instance\nof Unique Games, our algorithm is able to recover a good assignment. The\napproximation guarantee depends only on the completeness of the game, and not\non the alphabet size, while the running time depends on spectral properties of\nthe {\\em Label-Extended} graph associated with the instance of Unique Games.\n  We further show that on input the integrality gap instance of Khot and\nVishnoi, our algorithm runs in quasi-polynomial time and decides that the\ninstance if highly unsatisfiable. Notably, when run on this instance, the\nstandard SDP relaxation of Unique Games {\\em fails}. As a special case, we also\nre-derive a polynomial time algorithm for Unique Games on expander constraint\ngraphs.\n  The main ingredient of our algorithm is a technique to effectively use the\nfull spectrum of the underlying graph instead of just the second eigenvalue,\nwhich is of independent interest. The question of how to take advantage of the\nfull spectrum of a graph in the design of algorithms has been often studied,\nbut no significant progress was made prior to this work.\n", "versions": [{"version": "v1", "created": "Fri, 11 Feb 2011 08:15:10 GMT"}], "update_date": "2011-02-14", "authors_parsed": [["Kolla", "Alexandra", ""]]}, {"id": "1102.2468", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Algorithmic Randomness as Foundation of Inductive Reasoning and\n  Artificial Intelligence", "comments": "9 LaTeX pages", "journal-ref": "Chapter 12 in Randomness through Computation: Some Answers, More\n  Questions (2011) pages 159-169", "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is a brief personal account of the past, present, and future of\nalgorithmic randomness, emphasizing its role in inductive inference and\nartificial intelligence. It is written for a general audience interested in\nscience and philosophy. Intuitively, randomness is a lack of order or\npredictability. If randomness is the opposite of determinism, then algorithmic\nrandomness is the opposite of computability. Besides many other things, these\nconcepts have been used to quantify Ockham's razor, solve the induction\nproblem, and define intelligence.\n", "versions": [{"version": "v1", "created": "Sat, 12 Feb 2011 01:48:49 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "1102.2719", "submitter": "Cem Say", "authors": "Cem Say (Bogazici University), Abuzer Yakaryilmaz (University of\n  Latvia)", "title": "Finite state verifiers with constant randomness", "comments": "17 pages. An improved version", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 3 (August\n  19, 2014) lmcs:724", "doi": "10.2168/LMCS-10(3:6)2014", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new characterization of $\\mathsf{NL}$ as the class of languages\nwhose members have certificates that can be verified with small error in\npolynomial time by finite state machines that use a constant number of random\nbits, as opposed to its conventional description in terms of deterministic\nlogarithmic-space verifiers. It turns out that allowing two-way interaction\nwith the prover does not change the class of verifiable languages, and that no\npolynomially bounded amount of randomness is useful for constant-memory\ncomputers when used as language recognizers, or public-coin verifiers. A\ncorollary of our main result is that the class of outcome problems\ncorresponding to O(log n)-space bounded games of incomplete information where\nthe universal player is allowed a constant number of moves equals NL.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 10:17:49 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2012 12:16:28 GMT"}, {"version": "v3", "created": "Thu, 10 Jul 2014 11:12:21 GMT"}, {"version": "v4", "created": "Sun, 17 Aug 2014 21:45:28 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Say", "Cem", "", "Bogazici University"], ["Yakaryilmaz", "Abuzer", "", "University of\n  Latvia"]]}, {"id": "1102.2782", "submitter": "Markus Lohrey", "authors": "Markus Lohrey and Christian Mathissen", "title": "Isomorphism of regular trees and words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of the isomorphism problem for regular trees,\nregular linear orders, and regular words is analyzed. A tree is regular if it\nis isomorphic to the prefix order on a regular language. In case regular\nlanguages are represented by NFAs (DFAs), the isomorphism problem for regular\ntrees turns out to be EXPTIME-complete (resp. P-complete). In case the input\nautomata are acyclic NFAs (acyclic DFAs), the corresponding trees are\n(succinctly represented) finite trees, and the isomorphism problem turns out to\nbe PSPACE-complete (resp. P-complete). A linear order is regular if it is\nisomorphic to the lexicographic order on a regular language. A polynomial time\nalgorithm for the isomorphism problem for regular linear orders (and even\nregular words, which generalize the latter) given by DFAs is presented. This\nsolves an open problem by Esik and Bloom.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 14:34:38 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Lohrey", "Markus", ""], ["Mathissen", "Christian", ""]]}, {"id": "1102.2789", "submitter": "Johannes Mittmann", "authors": "Malte Beecken, Johannes Mittmann and Nitin Saxena", "title": "Algebraic Independence and Blackbox Identity Testing", "comments": "32 pages, preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic independence is an advanced notion in commutative algebra that\ngeneralizes independence of linear polynomials to higher degree. Polynomials\n{f_1, ..., f_m} \\subset \\F[x_1, ..., x_n] are called algebraically independent\nif there is no non-zero polynomial F such that F(f_1, ..., f_m) = 0. The\ntranscendence degree, trdeg{f_1, ..., f_m}, is the maximal number r of\nalgebraically independent polynomials in the set. In this paper we design\nblackbox and efficient linear maps \\phi that reduce the number of variables\nfrom n to r but maintain trdeg{\\phi(f_i)}_i = r, assuming f_i's sparse and\nsmall r. We apply these fundamental maps to solve several cases of blackbox\nidentity testing:\n  (1) Given a polynomial-degree circuit C and sparse polynomials f_1, ..., f_m\nwith trdeg r, we can test blackbox D := C(f_1, ..., f_m) for zeroness in\npoly(size(D))^r time.\n  (2) Define a spsp_\\delta(k,s,n) circuit C to be of the form \\sum_{i=1}^k\n\\prod_{j=1}^s f_{i,j}, where f_{i,j} are sparse n-variate polynomials of degree\nat most \\delta. For k = 2 we give a poly(sn\\delta)^{\\delta^2} time blackbox\nidentity test.\n  (3) For a general depth-4 circuit we define a notion of rank. Assuming there\nis a rank bound R for minimal simple spsp_\\delta(k,s,n) identities, we give a\npoly(snR\\delta)^{Rk\\delta^2} time blackbox identity test for spsp_\\delta(k,s,n)\ncircuits. This partially generalizes the state of the art of depth-3 to depth-4\ncircuits.\n  The notion of trdeg works best with large or zero characteristic, but we also\ngive versions of our results for arbitrary fields.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 15:00:16 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Beecken", "Malte", ""], ["Mittmann", "Johannes", ""], ["Saxena", "Nitin", ""]]}, {"id": "1102.2880", "submitter": "Johan Thapper", "authors": "Peter Jonsson, Fredrik Kuivinen, Johan Thapper", "title": "Min CSP on Four Elements: Moving Beyond Submodularity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report new results on the complexity of the valued constraint satisfaction\nproblem (VCSP). Under the unique games conjecture, the approximability of\nfinite-valued VCSP is fairly well-understood. However, there is yet no\ncharacterisation of VCSPs that can be solved exactly in polynomial time. This\nis unsatisfactory, since such results are interesting from a combinatorial\noptimisation perspective; there are deep connections with, for instance,\nsubmodular and bisubmodular minimisation. We consider the Min and Max CSP\nproblems (i.e. where the cost functions only attain values in {0,1}) over\nfour-element domains and identify all tractable fragments. Similar\nclassifications were previously known for two- and three-element domains. In\nthe process, we introduce a new class of tractable VCSPs based on a\ngeneralisation of submodularity. We also extend and modify a graph-based\ntechnique by Kolmogorov and Zivny (originally introduced by Takhanov) for\nefficiently obtaining hardness results in our setting. This allow us to prove\nthe result without relying on computer-assisted case analyses (which otherwise\nare fairly common when studying the complexity and approximability of VCSPs.)\nThe hardness results are further simplified by the introduction of powerful\nreduction techniques.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 20:41:09 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2011 08:51:34 GMT"}], "update_date": "2011-04-29", "authors_parsed": [["Jonsson", "Peter", ""], ["Kuivinen", "Fredrik", ""], ["Thapper", "Johan", ""]]}, {"id": "1102.2932", "submitter": "Yang D. Li", "authors": "Yang D. Li", "title": "Applications of Monotone Rank to Complexity Theory", "comments": "A bug was fixed. Submitted to IEEE complexity 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raz's recent result \\cite{Raz2010} has rekindled people's interest in the\nstudy of \\emph{tensor rank}, the generalization of matrix rank to high\ndimensions, by showing its connections to arithmetic formulas. In this paper,\nwe follow Raz's work and show that \\emph{monotone rank}, the monotone variant\nof tensor rank and matrix rank, has applications in algebraic complexity,\nquantum computing and communication complexity. This paper differs from Raz's\npaper in that it leverages existing results to show unconditional bounds while\nRaz's result relies on some assumptions.\n  We show a super-exponential separation between monotone and non-monotone\ncomputation in the non-commutative model, and thus provide a strong solution to\nNisan's question \\cite{Nis1991} in algebraic complexity. More specifically, we\nexhibit that there exists a homogeneous algebraic function $f$ of degree $d$\n($d$ even) on $n$ variables with the monotone algebraic branching program (ABP)\ncomplexity $\\Omega(d^2\\log n)$ and the non-monotone ABP complexity $O(d^2)$.\n  In Bell's theorem\\cite{Bel1964, CHSH1969}, a basic assumption is that players\nhave free will, and under such an assumption, local hidden variable theory\nstill cannot predict the correlations produced by quantum mechanics. Using\ntools from monotone rank, we show that even if we disallow the players to have\nfree will, local hidden variable theory still cannot predict the correlations\nproduced by quantum mechanics.\n  We generalize the log-rank conjecture \\cite{LS1988} in communication\ncomplexity to the multiparty case, and prove that for super-polynomial parties,\nthere is a super-polynomial separation between the deterministic communication\ncomplexity and the logarithm of the rank of the communication tensor. This\nmeans that the log-rank conjecture does not hold in high dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 00:07:03 GMT"}, {"version": "v2", "created": "Sat, 19 Nov 2011 05:55:10 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Li", "Yang D.", ""]]}, {"id": "1102.3093", "submitter": "Abuzer Yakaryilmaz", "authors": "Abuzer Yakaryilmaz", "title": "Superiority of one-way and realtime quantum machines and new directions", "comments": "A revised edition with some corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In automata theory, the quantum computation has been widely examined for\nfinite state machines, known as quantum finite automata (QFAs), and less\nattention has been given to the QFAs augmented with counters or stacks.\nMoreover, to our knowledge, there is no result related to QFAs having more than\none input head. In this paper, we focus on such generalizations of QFAs whose\ninput head(s) operate(s) in one-way or realtime mode and present many\nsuperiority of them to their classical counterparts. Furthermore, we propose\nsome open problems and conjectures in order to investigate the power of\nquantumness better. We also give some new results on classical computation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 15:00:22 GMT"}, {"version": "v2", "created": "Mon, 9 May 2011 08:45:21 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Yakaryilmaz", "Abuzer", ""]]}, {"id": "1102.3129", "submitter": "Georg Moser", "authors": "Nao Hirokawa, Georg Moser", "title": "Automated Complexity Analysis Based on the Dependency Pair Method", "comments": "37 pages, submitted to Information & Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This article is concerned with automated complexity analysis of term rewrite\nsystems. Since these systems underlie much of declarative programming, time\ncomplexity of functions defined by rewrite systems is of particular interest.\nAmong other results, we present a variant of the dependency pair method for\nanalysing runtime complexities of term rewrite systems automatically. The\nestablished results significantly extent previously known techniques: we give\nexamples of rewrite systems subject to our methods that could previously not\nbeen analysed automatically. Furthermore, the techniques have been implemented\nin the Tyrolean Complexity Tool. We provide ample numerical data for assessing\nthe viability of the method.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 17:16:23 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2011 18:19:59 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Hirokawa", "Nao", ""], ["Moser", "Georg", ""]]}, {"id": "1102.3151", "submitter": "Arno Pauly", "authors": "Arno Pauly", "title": "Many-one reductions and the category of multivalued functions", "comments": "an earlier version was titled \"Many-one reductions between search\n  problems\". in Mathematical Structures in Computer Science, 2015", "journal-ref": null, "doi": "10.1017/S0960129515000262", "report-no": null, "categories": "cs.CC math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-valued functions are common in computable analysis (built upon the Type\n2 Theory of Effectivity), and have made an appearance in complexity theory\nunder the moniker search problems leading to complexity classes such as PPAD\nand PLS being studied. However, a systematic investigation of the resulting\ndegree structures has only been initiated in the former situation so far (the\nWeihrauch-degrees).\n  A more general understanding is possible, if the category-theoretic\nproperties of multi-valued functions are taken into account. In the present\npaper, the category-theoretic framework is established, and it is demonstrated\nthat many-one degrees of multi-valued functions form a distributive lattice\nunder very general conditions, regardless of the actual reducibility notions\nused (e.g. Cook, Karp, Weihrauch).\n  Beyond this, an abundance of open questions arises. Some classic results for\nreductions between functions carry over to multi-valued functions, but others\ndo not. The basic theme here again depends on category-theoretic differences\nbetween functions and multi-valued functions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 18:36:13 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2015 15:58:23 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Pauly", "Arno", ""]]}, {"id": "1102.3245", "submitter": "Swapnoneel  Roy", "authors": "Swapnoneel Roy", "title": "On Sorting by Bounded Block Interchanges", "comments": "This paper has been withdrawn by the author due to a bug in the\n  reduction. Would be available again after it is fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider a restricted case of the well studied Sorting by\nBlock Interchanges problem. We put an upper bound k on the length of the blocks\n(substrings) to be interchanged at each step. We call the problem Sorting by\nk-Block Interchanges. We show the problem to be NP-Hard for k=1. The problem is\neasy for k=n-1, where n is the length of the permutation (the unbounded case).\nSorting by Block Interchanges is a very important and widely studied problem\nwith applications in comparative genomics.\n", "versions": [{"version": "v1", "created": "Wed, 16 Feb 2011 05:45:04 GMT"}, {"version": "v2", "created": "Fri, 18 Feb 2011 05:24:15 GMT"}, {"version": "v3", "created": "Tue, 1 Mar 2011 22:37:48 GMT"}, {"version": "v4", "created": "Sun, 6 Mar 2011 20:00:05 GMT"}, {"version": "v5", "created": "Wed, 5 Oct 2011 04:01:20 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Roy", "Swapnoneel", ""]]}, {"id": "1102.3310", "submitter": "Simon DeDeo", "authors": "Jon Machta, Simon DeDeo, Stephan Mertens and Cristopher Moore", "title": "Parallel Complexity of Random Boolean Circuits", "comments": "16 pages, 10 figures, matches published version", "journal-ref": "J. Stat. Mech. (2011) P04015", "doi": "10.1088/1742-5468/2011/04/P04015", "report-no": "SFI Working Paper #11-06-020", "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random instances of feedforward Boolean circuits are studied both\nanalytically and numerically. Evaluating these circuits is known to be a\nP-complete problem and thus, in the worst case, believed to be impossible to\nperform, even given a massively parallel computer, in time much less than the\ndepth of the circuit. Nonetheless, it is found that for some ensembles of\nrandom circuits, saturation to a fixed truth value occurs rapidly so that\nevaluation of the circuit can be accomplished in much less parallel time than\nthe depth of the circuit. For other ensembles saturation does not occur and\ncircuit evaluation is apparently hard. In particular, for some random circuits\ncomposed of connectives with five or more inputs, the number of true outputs at\neach level is a chaotic sequence. Finally, while the average case complexity\ndepends on the choice of ensemble, it is shown that for all ensembles it is\npossible to simultaneously construct a typical circuit together with its\nsolution in polylogarithmic parallel time.\n", "versions": [{"version": "v1", "created": "Wed, 16 Feb 2011 11:40:33 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2011 23:08:23 GMT"}], "update_date": "2011-07-25", "authors_parsed": [["Machta", "Jon", ""], ["DeDeo", "Simon", ""], ["Mertens", "Stephan", ""], ["Moore", "Cristopher", ""]]}, {"id": "1102.3463", "submitter": "Barnaby Martin", "authors": "Barnaby Martin", "title": "Low-level dichotomy for Quantified Constraint Satisfaction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on a result of Larose and Tesson for constraint satisfaction\nproblems (CSP s), we uncover a dichotomy for the quantified constraint\nsatisfaction problem QCSP(B), where B is a finite structure that is a core.\nSpecifically, such problems are either in ALogtime or are L-hard. This involves\ndemonstrating that if CSP(B) is first-order expressible, and B is a core, then\nQCSP(B) is in ALogtime.\n  We show that the class of B such that CSP(B) is first-order expressible\n(indeed, trivially true) is a microcosm for all QCSPs. Specifically, for any B\nthere exists a C such that CSP(C) is trivially true, yet QCSP(B) and QCSP(C)\nare equivalent under logspace reductions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 01:00:31 GMT"}], "update_date": "2011-02-18", "authors_parsed": [["Martin", "Barnaby", ""]]}, {"id": "1102.3527", "submitter": "Kenneth Shum", "authors": "Ho Yuet Kwan, Kenneth W. Shum and Chi Wan Sung", "title": "Generation of Innovative and Sparse Encoding Vectors for Broadcast\n  Systems with Feedback", "comments": "5 pages, 4 figures, accepted for publication in the Proc. of IEEE\n  ISIT 2011", "journal-ref": null, "doi": "10.1109/ISIT.2011.6033715", "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the application of linear network coding to wireless broadcasting with\nfeedback, we prove that the problem of determining the existence of an\ninnovative encoding vector is NP-complete when the finite field size is two.\nWhen the finite field size is larger than or equal to the number of users, it\nis shown that we can always find an encoding vector which is both innovative\nand sparse. The sparsity can be utilized in speeding up the decoding process.\nAn efficient algorithm to generate innovative and sparse encoding vectors is\ndeveloped. Simulations show that the delay performance of our scheme with\nbinary finite field outperforms a number of existing schemes in terms of\naverage and worst-case delay.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 09:01:45 GMT"}, {"version": "v2", "created": "Tue, 24 May 2011 06:48:37 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Kwan", "Ho Yuet", ""], ["Shum", "Kenneth W.", ""], ["Sung", "Chi Wan", ""]]}, {"id": "1102.3766", "submitter": "Masaki Yamamoto", "authors": "Kazuhisa Makino, Suguru Tamaki, Masaki Yamamoto", "title": "Derandomizing HSSW Algorithm for 3-SAT", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a (full) derandomization of HSSW algorithm for 3-SAT, proposed by\nHofmeister, Sch\\\"oning, Schuler, and Watanabe in [STACS'02]. Thereby, we obtain\nan O(1.3303^n)-time deterministic algorithm for 3-SAT, which is currently\nfastest.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 07:18:36 GMT"}], "update_date": "2011-02-21", "authors_parsed": [["Makino", "Kazuhisa", ""], ["Tamaki", "Suguru", ""], ["Yamamoto", "Masaki", ""]]}, {"id": "1102.4005", "submitter": "Bhaskar DasGupta", "authors": "Piotr Berman and Bhaskar DasGupta", "title": "Approximating the Online Set Multicover Problems Via Randomized\n  Winnowing", "comments": "22 pages", "journal-ref": "Theoretical Computer Science, 393 (1-3), 54-71, 2008", "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the weighted online set k-multicover problem. In\nthis problem, we have a universe V of elements, a family S of subsets of V with\na positive real cost for every set in S and a \"coverage factor\" (positive\ninteger) k. A subset of elements are presented online in an arbitrary order.\nWhen each element, say i, is presented, we are also told the collection of all\n(at least k) sets and their costs to which i belongs and we need to select\nadditional sets from these sets containing i, if necessary, such that our\ncollection of selected sets contains at least k sets that contain the element\ni. The goal is to minimize the total cost of the selected sets (our algorithm\nand competitive ratio bounds can be extended to the case when a set can be\nselected at most a pre-specified number of times instead of just once; we do\nnot report these extensions for simplicity and also because they have no\nrelevance to the biological applications that motivated our work). In this\npaper, we describe a new randomized algorithm for the online multicover problem\nbased on a randomized version of the winnowing approach of Littlestone. This\nalgorithm generalizes and improves some earlier results by N. Alon, B.\nAwerbuch, Y. Azar, N. Buchbinder, and J. Naor. We also discuss lower bounds on\ncompetitive ratios for deterministic algorithms for general $k$.\n", "versions": [{"version": "v1", "created": "Sat, 19 Feb 2011 17:11:56 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Berman", "Piotr", ""], ["DasGupta", "Bhaskar", ""]]}, {"id": "1102.4121", "submitter": "EPTCS", "authors": "Laurent Doyen (LSV, ENS Cachan & CNRS, France), Thierry Massart\n  (Universit\\'e Libre de Bruxelles, Belgium), Mahsa Shirmohammadi (Universit\\'e\n  Libre de Bruxelles, Belgium)", "title": "Synchronizing Objectives for Markov Decision Processes", "comments": "In Proceedings iWIGP 2011, arXiv:1102.3741", "journal-ref": "EPTCS 50, 2011, pp. 61-75", "doi": "10.4204/EPTCS.50.5", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce synchronizing objectives for Markov decision processes (MDP).\nIntuitively, a synchronizing objective requires that eventually, at every step\nthere is a state which concentrates almost all the probability mass. In\nparticular, it implies that the probabilistic system behaves in the long run\nlike a deterministic system: eventually, the current state of the MDP can be\nidentified with almost certainty.\n  We study the problem of deciding the existence of a strategy to enforce a\nsynchronizing objective in MDPs. We show that the problem is decidable for\ngeneral strategies, as well as for blind strategies where the player cannot\nobserve the current state of the MDP. We also show that pure strategies are\nsufficient, but memory may be necessary.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 02:30:55 GMT"}], "update_date": "2011-02-22", "authors_parsed": [["Doyen", "Laurent", "", "LSV, ENS Cachan & CNRS, France"], ["Massart", "Thierry", "", "Universit\u00e9 Libre de Bruxelles, Belgium"], ["Shirmohammadi", "Mahsa", "", "Universit\u00e9\n  Libre de Bruxelles, Belgium"]]}, {"id": "1102.4129", "submitter": "Swapnoneel  Roy", "authors": "Swapnoneel Roy and Atri Rudra", "title": "An FPTAS for the Lead-Based Multiple Video Transmission LMVT Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lead-Based Multiple Video Transmission (LMVT) problem is motivated by\napplications in managing the quality of experience (QoE) of video streaming for\nmobile clients. In an earlier work, the LMVT problem has been shown to be\nNP-hard for a specific bit-to-lead conversion function $\\phi$. In this work, we\nshow the problem to be NP-hard even if the function $\\phi$ is linear. We then\ndesign a fully polynomial time approximation scheme (FPTAS) for the problem.\nThis problem is exactly equivalent to the Santa Clause Problem on which there\nhas been a lot of work done off-late.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 04:21:32 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2011 19:58:08 GMT"}, {"version": "v3", "created": "Wed, 5 Oct 2011 03:57:51 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Roy", "Swapnoneel", ""], ["Rudra", "Atri", ""]]}, {"id": "1102.4346", "submitter": "Rooholah Majdodin", "authors": "Rooholah Majdodin", "title": "BPP is in NP and coNP", "comments": "This paper has been withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the class BPP is in NP and coNP. This paper has been withdrawn\nby the author because B and B' are probabilistic and nonequalities 10 cannot be\nchecked in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 21:08:57 GMT"}, {"version": "v2", "created": "Thu, 24 Feb 2011 10:20:01 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["Majdodin", "Rooholah", ""]]}, {"id": "1102.4699", "submitter": "Shengyu Zhang", "authors": "Rahul Jain, Shengyu Zhang", "title": "The influence lower bound via query elimination", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simpler proof, via query elimination, of a result due to O'Donnell,\nSaks, Schramm and Servedio, which shows a lower bound on the zero-error\nrandomized query complexity of a function f in terms of the maximum influence\nof any variable of f. Our lower bound also applies to the two-sided error\ndistributional query complexity of f, and it allows an immediate extension\nwhich can be used to prove stronger lower bounds for some functions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 09:38:14 GMT"}], "update_date": "2011-02-24", "authors_parsed": [["Jain", "Rahul", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1102.4712", "submitter": "Aleksandr Chuklin", "authors": "Aleksandr Chuklin", "title": "Effective protocols for low-distance file synchronization", "comments": "Russian language, 25 pages, survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we have two similar files stored on different computers. We need\nto send the file from the first computer to the second one trying to minimize\nthe number of bits transmitted. This article presents a survey of results known\nfor this communication complexity problem in the case when files are \"similar\"\nin the sense of Hamming distance. We mainly systematize earlier results\nobtained by various authors in 1990s and 2000s and discuss its connection with\ncoding theory, hashing algorithms and other domains of computer science. In\nparticular cases we propose some improvements of previous constructions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 11:08:47 GMT"}], "update_date": "2011-02-24", "authors_parsed": [["Chuklin", "Aleksandr", ""]]}, {"id": "1102.4922", "submitter": "Minghao Yin", "authors": "Minghao Yin and Ping Huang", "title": "Counting Solutions of Constraint Satisfiability Problems:Exact Phase\n  Transitions and Approximate Algorithm", "comments": "submitted to AAAI-11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of phase transition phenomenon of NP complete problems plays an\nimportant role in understanding the nature of hard problems. In this paper, we\nfollow this line of research by considering the problem of counting solutions\nof Constraint Satisfaction Problems (#CSP). We consider the random model, i.e.\nRB model. We prove that phase transition of #CSP does exist as the number of\nvariables approaches infinity and the critical values where phase transitions\noccur are precisely located. Preliminary experimental results also show that\nthe critical point coincides with the theoretical derivation. Moreover, we\npropose an approximate algorithm to estimate the expectation value of the\nsolutions number of a given CSP instance of RB model.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 08:07:54 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["Yin", "Minghao", ""], ["Huang", "Ping", ""]]}, {"id": "1102.4925", "submitter": "Minghao Yin", "authors": "Minghao Yin", "title": "Worst-Case Upper Bound for (1, 2)-QSAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rigorous theoretical analysis of the algorithm for a subclass of QSAT,\ni.e. (1, 2)-QSAT, has been proposed in the literature. (1, 2)-QSAT, first\nintroduced in SAT'08, can be seen as quantified extended 2-CNF formulas. Until\nnow, within our knowledge, there exists no algorithm presenting the worst upper\nbound for (1, 2)-QSAT. Therefore in this paper, we present an exact algorithm\nto solve (1, 2)-QSAT. By analyzing the algorithms, we obtain a worst-case upper\nbound O(1.4142m), where m is the number of clauses.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 08:24:04 GMT"}, {"version": "v2", "created": "Sat, 26 Mar 2011 03:20:14 GMT"}], "update_date": "2011-03-29", "authors_parsed": [["Yin", "Minghao", ""]]}, {"id": "1102.4926", "submitter": "Minghao Yin", "authors": "Junping Zhou, Minghao Yin", "title": "New Worst-Case Upper Bound for X3SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rigorous theoretical analyses of algorithms for exact 3-satisfiability\n(X3SAT) have been proposed in the literature. As we know, previous algorithms\nfor solving X3SAT have been analyzed only regarding the number of variables as\nthe parameter. However, the time complexity for solving X3SAT instances depends\nnot only on the number of variables, but also on the number of clauses.\nTherefore, it is significant to exploit the time complexity from the other\npoint of view, i.e. the number of clauses. In this paper, we present algorithms\nfor solving X3SAT with rigorous complexity analyses using the number of clauses\nas the parameter. By analyzing the algorithms, we obtain the new worst-case\nupper bounds O(1.15855m), where m is the number of clauses.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 08:26:15 GMT"}, {"version": "v2", "created": "Sat, 26 Mar 2011 03:19:01 GMT"}], "update_date": "2011-03-29", "authors_parsed": [["Zhou", "Junping", ""], ["Yin", "Minghao", ""]]}, {"id": "1102.5152", "submitter": "A. Peter Young", "authors": "Marco Guidetti, A. P. Young", "title": "Complexity of several constraint satisfaction problems using the\n  heuristic, classical, algorithm, WalkSAT", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": "10.1103/PhysRevE.84.011102", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the complexity of several constraint satisfaction problems using\nthe heuristic algorithm, WalkSAT. At large sizes N, the complexity increases\nexponentially with N in all cases. Perhaps surprisingly, out of all the models\nstudied, the hardest for WalkSAT is the one for which there is a polynomial\ntime algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 25 Feb 2011 04:03:31 GMT"}], "update_date": "2013-05-29", "authors_parsed": [["Guidetti", "Marco", ""], ["Young", "A. P.", ""]]}, {"id": "1102.5309", "submitter": "Jeremy Hurwitz", "authors": "Jeremy Hurwitz", "title": "A Nearly-Quadratic Gap Between Adaptive and Non-Adaptive Property\n  Testers", "comments": "Keywords: Sublinear-Time Algorithms, Property Testing, Dense-Graph\n  Model, Adaptive vs Nonadaptive Queries, Hierarchy Theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for all integers $t\\geq 8$ and arbitrarily small $\\epsilon>0$,\nthere exists a graph property $\\Pi$ (which depends on $\\epsilon$) such that\n$\\epsilon$-testing $\\Pi$ has non-adaptive query complexity\n$Q=\\~{\\Theta}(q^{2-2/t})$, where $q=\\~{\\Theta}(\\epsilon^{-1})$ is the adaptive\nquery complexity. This resolves the question of how beneficial adaptivity is,\nin the context of proximity-dependent properties\n(\\cite{benefits-of-adaptivity}). This also gives evidence that the canonical\ntransformation of Goldreich and Trevisan (\\cite{canonical-testers}) is\nessentially optimal when converting an adaptive property tester to a\nnon-adaptive property tester.\n  To do so, we provide optimal adaptive and non-adaptive testers for the\ncombined property of having maximum degree $O(\\epsilon N)$ and being a\n\\emph{blow-up collection} of an arbitrary base graph $H$.\n", "versions": [{"version": "v1", "created": "Fri, 25 Feb 2011 18:54:33 GMT"}, {"version": "v2", "created": "Tue, 15 Mar 2011 23:51:50 GMT"}, {"version": "v3", "created": "Fri, 24 Jun 2011 18:46:54 GMT"}], "update_date": "2011-06-27", "authors_parsed": [["Hurwitz", "Jeremy", ""]]}, {"id": "1102.5389", "submitter": "Hector Zenil", "authors": "Joost J. Joosten, Fernando Soler-Toscano, Hector Zenil", "title": "Program-Size Versus Time Complexity, Speed-Up and Slowdown Phenomena in\n  Small Turing Machines", "comments": "Proceedings of the 3rd. International workshop on Physics and\n  Computation 2010 on the Nile, Egypt, pages 175-198, 2010. Forthcoming in the\n  International Journal of Unconventional Computing (IJUC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to undertake an experimental investigation of the\ntrade-offs between program-size and time computational complexity. The\ninvestigation includes an exhaustive exploration and systematic study of the\nfunctions computed by the set of all 2-color Turing machines with 2, 3 and 4\nstates--denoted by (n,2) with n the number of states--with particular attention\nto the runtimes and space usages when the machines have access to larger\nresources (more states). We report that the average runtime of Turing machines\ncomputing a function almost surely increases as a function of the number of\nstates, indicating that machines not terminating (almost) immediately tend to\noccupy all the resources at hand. We calculated all time complexity classes to\nwhich the algorithms computing the functions found in both (2,2) and (3,2)\nbelong to, and made a comparison among these classes. For a selection of\nfunctions the comparison was extended to (4,2). Our study revealed various\nstructures in the micro-cosmos of small Turing machines. Most notably we\nobserved \"phase-transitions\" in the halting-probability distribution that we\nexplain. Moreover, it is observed that short initial segments fully define a\nfunction computed by a Turing machine.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 05:23:17 GMT"}, {"version": "v2", "created": "Sat, 16 Apr 2011 17:35:14 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Joosten", "Joost J.", ""], ["Soler-Toscano", "Fernando", ""], ["Zenil", "Hector", ""]]}, {"id": "1102.5415", "submitter": "David Zuckerman", "authors": "Yevgeniy Dodis and Xin Li and Trevor D. Wooley and David Zuckerman", "title": "Privacy Amplification and Non-Malleable Extractors Via Character Sums", "comments": "32 pages, full version of the same paper in FOCS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In studying how to communicate over a public channel with an active\nadversary, Dodis and Wichs introduced the notion of a non-malleable extractor.\nA non-malleable extractor dramatically strengthens the notion of a strong\nextractor. A strong extractor takes two inputs, a weakly-random x and a\nuniformly random seed y, and outputs a string which appears uniform, even given\ny. For a non-malleable extractor nmExt, the output nmExt(x,y) should appear\nuniform given y as well as nmExt(x,A(y)), where A is an arbitrary function with\nA(y) not equal to y.\n  We show that an extractor introduced by Chor and Goldreich is non-malleable\nwhen the entropy rate is above half. It outputs a linear number of bits when\nthe entropy rate is 1/2 + alpha, for any alpha>0. Previously, no nontrivial\nparameters were known for any non-malleable extractor. To achieve a polynomial\nrunning time when outputting many bits, we rely on a widely-believed conjecture\nabout the distribution of prime numbers in arithmetic progressions. Our\nanalysis involves a character sum estimate, which may be of independent\ninterest.\n  Using our non-malleable extractor, we obtain protocols for \"privacy\namplification\": key agreement between two parties who share a weakly-random\nsecret. Our protocols work in the presence of an active adversary with\nunlimited computational power, and have asymptotically optimal entropy loss.\nWhen the secret has entropy rate greater than 1/2, the protocol follows from a\nresult of Dodis and Wichs, and takes two rounds. When the secret has entropy\nrate delta for any constant delta>0, our new protocol takes a constant\n(polynomial in 1/delta) number of rounds. Our protocols run in polynomial time\nunder the above well-known conjecture about primes.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 14:17:27 GMT"}, {"version": "v2", "created": "Thu, 10 Mar 2011 18:07:42 GMT"}, {"version": "v3", "created": "Fri, 15 Apr 2011 04:35:36 GMT"}, {"version": "v4", "created": "Fri, 8 Jul 2011 16:56:44 GMT"}, {"version": "v5", "created": "Tue, 16 Aug 2011 17:06:06 GMT"}, {"version": "v6", "created": "Sat, 3 Sep 2011 16:20:59 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Dodis", "Yevgeniy", ""], ["Li", "Xin", ""], ["Wooley", "Trevor D.", ""], ["Zuckerman", "David", ""]]}, {"id": "1102.5425", "submitter": "Christoph Lenzen", "authors": "Christoph Lenzen and Roger Wattenhofer", "title": "Tight Bounds for Parallel Randomized Load Balancing", "comments": "39 pages, 2 figures. Extended abstract will be published at STOC'11", "journal-ref": null, "doi": null, "report-no": "TIK report number 324", "categories": "cs.CC cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the fundamental limits of distributed balls-into-bins algorithms.\nWe present an adaptive symmetric algorithm that achieves a bin load of two in\nlog* n+O(1) communication rounds using O(n) messages in total. Larger bin loads\ncan be traded in for smaller time complexities. We prove a matching lower bound\nof (1-o(1))log* n on the time complexity of symmetric algorithms that guarantee\nsmall bin loads at an asymptotically optimal message complexity of O(n). For\neach assumption of the lower bound, we provide an algorithm violating it, in\nturn achieving a constant maximum bin load in constant time.\n  As an application, we consider the following problem. Given a fully connected\ngraph of n nodes, where each node needs to send and receive up to n messages,\nand in each round each node may send one message over each link, deliver all\nmessages as quickly as possible to their destinations. We give a simple and\nrobust algorithm of time complexity O(log* n) for this task and provide a\ngeneralization to the case where all nodes initially hold arbitrary sets of\nmessages. A less practical algorithm terminates within asymptotically optimal\nO(1) rounds. All these bounds hold with high probability.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 15:45:45 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Lenzen", "Christoph", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1102.5471", "submitter": "Bhaskar DasGupta", "authors": "Mary V. Ashley and Tanya Y. Berger-Wolf and Wanpracha Chaovalitwongse\n  and Bhaskar DasGupta and Ashfaq Khokhar and Saad Sheikh", "title": "An Implicit Cover Problem in Wild Population Study", "comments": "11 pages", "journal-ref": "Discrete Mathematics, Algorithms and Applications, 2 (2), 21-31,\n  2010", "doi": null, "report-no": null, "categories": "cs.CC cs.DS q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an implicit combinatorial optimization problem, the constraints are not\nenumerated explicitly but rather stated implicitly through equations, other\nconstraints or auxiliary algorithms. An important subclass of such problems is\nthe implicit set cover (or, equivalently, hitting set) problem in which the\nsets are not given explicitly but rather defined implicitly For example, the\nwell-known minimum feedback arc set problem is such a problem. In this paper,\nwe consider such a cover problem that arises in the study of wild populations\nin biology in which the sets are defined implicitly via the Mendelian\nconstraints and prove approximability results for this problem.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 03:53:59 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Ashley", "Mary V.", ""], ["Berger-Wolf", "Tanya Y.", ""], ["Chaovalitwongse", "Wanpracha", ""], ["DasGupta", "Bhaskar", ""], ["Khokhar", "Ashfaq", ""], ["Sheikh", "Saad", ""]]}, {"id": "1102.5495", "submitter": "David Nowak", "authors": "Sylvain Heraud and David Nowak", "title": "A Formalization of Polytime Functions", "comments": "13 pages", "journal-ref": null, "doi": "10.1007/978-3-642-22863-6_11", "report-no": null, "categories": "cs.CC cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep embedding of Bellantoni and Cook's syntactic\ncharacterization of polytime functions. We prove formally that it is correct\nand complete with respect to the original characterization by Cobham that\nrequired a bound to be proved manually. Compared to the paper proof by\nBellantoni and Cook, we have been careful in making our proof fully contructive\nso that we obtain more precise bounding polynomials and more efficient\ntranslations between the two characterizations. Another difference is that we\nconsider functions on bitstrings instead of functions on positive integers.\nThis latter change is motivated by the application of our formalization in the\ncontext of formal security proofs in cryptography. Based on our core\nformalization, we have started developing a library of polytime functions that\ncan be reused to build more complex ones.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 11:56:00 GMT"}, {"version": "v2", "created": "Tue, 31 May 2011 07:27:18 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Heraud", "Sylvain", ""], ["Nowak", "David", ""]]}, {"id": "1102.5538", "submitter": "Andrei Romashchenko", "authors": "Andrei Romashchenko", "title": "Pseudo-random graphs and bit probe schemes with one-sided error", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study probabilistic bit-probe schemes for the membership problem. Given a\nset A of at most n elements from the universe of size m we organize such a\nstructure that queries of type \"Is x in A?\" can be answered very quickly.\nH.Buhrman, P.B.Miltersen, J.Radhakrishnan, and S.Venkatesh proposed a bit-probe\nscheme based on expanders. Their scheme needs space of $O(n\\log m)$ bits, and\nrequires to read only one randomly chosen bit from the memory to answer a\nquery. The answer is correct with high probability with two-sided errors. In\nthis paper we show that for the same problem there exists a bit-probe scheme\nwith one-sided error that needs space of $O(n\\log^2 m+\\poly(\\log m))$ bits. The\ndifference with the model of Buhrman, Miltersen, Radhakrishnan, and Venkatesh\nis that we consider a bit-probe scheme with an auxiliary word. This means that\nin our scheme the memory is split into two parts of different size: the main\nstorage of $O(n\\log^2 m)$ bits and a short word of $\\log^{O(1)}m$ bits that is\npre-computed once for the stored set A and `cached'. To answer a query \"Is x in\nA?\" we allow to read the whole cached word and only one bit from the main\nstorage. For some reasonable values of parameters our space bound is better\nthan what can be achieved by any scheme without cached data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 19:24:32 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2011 20:50:58 GMT"}, {"version": "v3", "created": "Thu, 3 Mar 2011 08:05:56 GMT"}, {"version": "v4", "created": "Thu, 15 Sep 2011 10:57:54 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Romashchenko", "Andrei", ""]]}, {"id": "1102.5605", "submitter": "Peng Cui", "authors": "Peng Cui", "title": "On Unique Games with Negative Weights", "comments": "7 pages, accepted by COCOA 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the author defines Generalized Unique Game Problem (GUGP),\nwhere weights of the edges are allowed to be negative. Two special types of\nGUGP are illuminated, GUGP-NWA, where the weights of all edges are negative,\nand GUGP-PWT($\\rho$), where the total weight of all edges are positive and the\nnegative-positive ratio is at most $\\rho$. The author investigates the\ncounterpart of the Unique Game Conjecture on GUGP-PWT($\\rho$). The author shows\nthat Unique Game Conjecture on GUGP-PWT(1) holds true, and Unique Game\nConjecture on GUGP-PWT(1/2) holds true, if the 2-to-1 Conjecture holds true.\nThe author poses an open problem whether Unique Game Conjecture holds true on\nGUGP-PWT($\\rho$) with $0<\\rho<1$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Feb 2011 06:25:21 GMT"}, {"version": "v2", "created": "Sat, 5 Mar 2011 02:06:45 GMT"}, {"version": "v3", "created": "Wed, 18 May 2011 23:33:45 GMT"}, {"version": "v4", "created": "Thu, 14 Mar 2013 10:15:57 GMT"}], "update_date": "2013-03-15", "authors_parsed": [["Cui", "Peng", ""]]}, {"id": "1102.5761", "submitter": "Christophe Garban", "authors": "Christophe Garban and Jeffrey E. Steif", "title": "Lectures on noise sensitivity and percolation", "comments": "151 pages, 29 figures, minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC cs.DM math-ph math.CA math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present text provides the lecture notes for the course \"noise sensitivity\nand percolation\" given at the 2010 Clay Summer School in Buzios, Brazil.\n", "versions": [{"version": "v1", "created": "Mon, 28 Feb 2011 20:12:13 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2011 14:57:14 GMT"}, {"version": "v3", "created": "Tue, 29 May 2012 15:25:19 GMT"}], "update_date": "2012-05-30", "authors_parsed": [["Garban", "Christophe", ""], ["Steif", "Jeffrey E.", ""]]}]