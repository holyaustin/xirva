[{"id": "1101.0129", "submitter": "Jason Morton", "authors": "Jason Morton", "title": "Pfaffian Circuits", "comments": "33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It remains an open question whether the apparent additional power of quantum\ncomputation derives inherently from quantum mechanics, or merely from the\nflexibility obtained by \"lifting\" Boolean functions to linear operators and\nevaluating their composition cleverly. Holographic algorithms provide a useful\navenue for exploring this question. We describe a new, simplified construction\nof holographic algorithms in terms of Pfaffian circuits. Novel proofs of some\nkey results are provided, and we extend the approach of [34] to nonsymmetric,\nodd, and homogenized signatures, circuits, and various models of execution\nflow. This shows our approach is as powerful as the matchgate approach.\nHolographic algorithms provide in general $O(n^{\\omega_p})$ time algorithms,\nwhere $\\omega_p$ is the order of Pfaffian evaluation in the ring of interest\n(with $1.19 \\leq \\omega_p \\leq 3$ depending on the ring) and $n$ is the number\nof inclusions of variables into clauses. Our approach often requires just the\nevaluation of an $n \\times n$ Pfaffian, and at most needs an additional two\nrows per gate, whereas the matchgate approach is quartic in the arity of the\nlargest gate. We give examples (even before any change of basis) including\nefficient algorithms for certain lattice path problems and an $O(n^{\\omega_p})$\nalgorithm for evaluation of Tutte polynomials of lattice path matroids. Finally\nwe comment on some of the geometric considerations in analyzing Pfaffian\ncircuits under arbitrary basis change. Connections are made to the sum-product\nalgorithm, classical simulation of quantum computation, and SLOCC equivalent\nentangled states.\n", "versions": [{"version": "v1", "created": "Thu, 30 Dec 2010 18:34:05 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Morton", "Jason", ""]]}, {"id": "1101.0160", "submitter": "Carlos Barron-Romero", "authors": "Carlos Barron-Romero", "title": "The Complexity of Euclidian 2 Dimension Travelling Salesman Problem\n  versus General Assign Problem, NP is not P", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the differences between two NP problems. It focuses in\nthe Euclidian 2 Dimension Travelling Salesman Problems and General Assign\nProblems. The main results are the triangle reduction to verify the solution in\npolynomial time for the former and for the later the solution to the Noted\nConjecture of the NP-Class, NP is not P.\n", "versions": [{"version": "v1", "created": "Thu, 30 Dec 2010 21:05:23 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Barron-Romero", "Carlos", ""]]}, {"id": "1101.0403", "submitter": "Scott Aaronson", "authors": "Scott Aaronson", "title": "Impossibility of Succinct Quantum Proofs for Collision-Freeness", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any quantum algorithm to decide whether a function f:[n]->[n] is\na permutation or far from a permutation must make Omega(n^{1/3}/w) queries to\nf, even if the algorithm is given a w-qubit quantum witness in support of f\nbeing a permutation. This implies that there exists an oracle A such that SZK^A\nis not contained in QMA^A, answering an eight-year-old open question of the\nauthor. Indeed, we show that relative to some oracle, SZK is not in the\ncounting class A0PP defined by Vyalyi. The proof is a fairly simple extension\nof the quantum lower bound for the collision problem.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jan 2011 13:03:34 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Aaronson", "Scott", ""]]}, {"id": "1101.0523", "submitter": "Hartmut Klauck", "authors": "Hartmut Klauck", "title": "On Arthur Merlin Games in Communication Complexity", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show several results related to interactive proof modes of communication\ncomplexity. First we show lower bounds for the QMA-communication complexity of\nthe functions Inner Product and Disjointness. We describe a general method to\nprove lower bounds for QMA-communication complexity, and show how one can\n'transfer' hardness under an analogous measure in the query complexity model to\nthe communication model using Sherstov's pattern matrix method. Combining a\nresult by Vereshchagin and the pattern matrix method we find a communication\nproblem with AM-communication complexity $O(\\log n)$, PP-communication\ncomplexity $\\Omega(n^{1/3})$, and QMA-communication complexity\n$\\Omega(n^{1/6})$. Hence in the world of communication complexity\nnoninteractive quantum proof systems are not able to efficiently simulate\nco-nondeterminism or interaction. These results imply that the related\nquestions in Turing machine complexity theory cannot be resolved by\n'algebrizing' techniques. Finally we show that in MA-protocols there is an\nexponential gap between one-way protocols and two-way protocols (this refers to\nthe interaction between Alice and Bob). This is in contrast to\nnondeterministic, AM-, and QMA-protocols, where one-way communication is\nessentially optimal.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jan 2011 13:41:07 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Klauck", "Hartmut", ""]]}, {"id": "1101.0768", "submitter": "Markus Jalsenius", "authors": "Raphael Clifford and Markus Jalsenius", "title": "Tight Cell-Probe Bounds for Online Integer Multiplication and\n  Convolution", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show tight bounds for both online integer multiplication and convolution\nin the cell-probe model with word size w. For the multiplication problem, one\npair of digits, each from one of two n digit numbers that are to be multiplied,\nis given as input at step i. The online algorithm outputs a single new digit\nfrom the product of the numbers before step i+1. We give a Theta((d/w)*log n)\nbound on average per output digit for this problem where 2^d is the maximum\nvalue of a digit. In the convolution problem, we are given a fixed vector V of\nlength n and we consider a stream in which numbers arrive one at a time. We\noutput the inner product of V and the vector that consists of the last n\nnumbers of the stream. We show a Theta((d/w)*log n) bound for the number of\nprobes required per new number in the stream. All the bounds presented hold\nunder randomisation and amortisation. Multiplication and convolution are\ncentral problems in the study of algorithms which also have the widest range of\npractical applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 17:08:23 GMT"}, {"version": "v2", "created": "Wed, 9 Feb 2011 16:38:12 GMT"}, {"version": "v3", "created": "Tue, 30 Aug 2011 17:38:06 GMT"}, {"version": "v4", "created": "Thu, 23 Feb 2012 22:08:51 GMT"}], "update_date": "2012-02-27", "authors_parsed": [["Clifford", "Raphael", ""], ["Jalsenius", "Markus", ""]]}, {"id": "1101.1169", "submitter": "Prahladh Harsha", "authors": "Steve Chien and Prahladh Harsha and Alistair Sinclair and Srikanth\n  Srinivasan", "title": "Almost Settling the Hardness of Noncommutative Determinant", "comments": "20 pages, 3 figures", "journal-ref": "In Proc. 43rd ACM Symp. on Theory of Computing (STOC), pages\n  499-508, 2011", "doi": "10.1145/1993636.1993703", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the complexity of computing the determinant of a\nmatrix over a non-commutative algebra. In particular, we ask the question,\n\"over which algebras, is the determinant easier to compute than the permanent?\"\nTowards resolving this question, we show the following hardness and easiness of\nnoncommutative determinant computation.\n  * [Hardness] Computing the determinant of an n \\times n matrix whose entries\nare themselves 2 \\times 2 matrices over a field is as hard as computing the\npermanent over the field. This extends the recent result of Arvind and\nSrinivasan, who proved a similar result which however required the entries to\nbe of linear dimension.\n  * [Easiness] Determinant of an n \\times n matrix whose entries are themselves\nd \\times d upper triangular matrices can be computed in poly(n^d) time.\n  Combining the above with the decomposition theorem of finite dimensional\nalgebras (in particular exploiting the simple structure of 2 \\times 2 matrix\nalgebras), we can extend the above hardness and easiness statements to more\ngeneral algebras as follows. Let A be a finite dimensional algebra over a\nfinite field with radical R(A).\n  * [Hardness] If the quotient A/R(A) is non-commutative, then computing the\ndeterminant over the algebra A is as hard as computing the permanent.\n  * [Easiness] If the quotient A/R(A) is commutative and furthermore, R(A) has\nnilpotency index d (i.e., the smallest d such that R(A)d = 0), then there\nexists a poly(n^d)-time algorithm that computes determinants over the algebra\nA.\n  In particular, for any constant dimensional algebra A over a finite field,\nsince the nilpotency index of R(A) is at most a constant, we have the following\ndichotomy theorem: if A/R(A) is commutative, then efficient determinant\ncomputation is feasible and otherwise determinant is as hard as permanent.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jan 2011 09:14:42 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Chien", "Steve", ""], ["Harsha", "Prahladh", ""], ["Sinclair", "Alistair", ""], ["Srinivasan", "Srikanth", ""]]}, {"id": "1101.1507", "submitter": "Kyle Burke", "authors": "Kyle Burke, Olivia George", "title": "A PSPACE-complete Graph Nim", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build off the game, NimG to create a version named Neighboring Nim. By\nreducing from Geography, we show that this game is PSPACE-hard. The games\ncreated by the reduction share strong similarities with Undirected (Vertex)\nGeography and regular Nim, both of which are in P. We show how to construct\nPSPACE-complete versions with nim heaps *1 and *2. This application of graphs\ncan be used as a form of game sum with any games, not only Nim.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 19:19:42 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2011 03:34:54 GMT"}, {"version": "v3", "created": "Tue, 7 Oct 2014 11:40:08 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Burke", "Kyle", ""], ["George", "Olivia", ""]]}, {"id": "1101.1710", "submitter": "Aditya Bhaskara", "authors": "Aditya Bhaskara, Moses Charikar, Rajsekar Manokaran, Aravindan\n  Vijayaraghavan", "title": "On Quadratic Programming with a Ratio Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic Programming (QP) is the well-studied problem of maximizing over\n{-1,1} values the quadratic form \\sum_{i \\ne j} a_{ij} x_i x_j. QP captures\nmany known combinatorial optimization problems, and assuming the unique games\nconjecture, semidefinite programming techniques give optimal approximation\nalgorithms. We extend this body of work by initiating the study of Quadratic\nProgramming problems where the variables take values in the domain {-1,0,1}.\nThe specific problems we study are\n  QP-Ratio : \\max_{\\{-1,0,1\\}^n} \\frac{\\sum_{i \\not = j} a_{ij} x_i x_j}{\\sum\nx_i^2}, and Normalized QP-Ratio : \\max_{\\{-1,0,1\\}^n} \\frac{\\sum_{i \\not = j}\na_{ij} x_i x_j}{\\sum d_i x_i^2}, where d_i = \\sum_j |a_{ij}|\n  We consider an SDP relaxation obtained by adding constraints to the natural\neigenvalue (or SDP) relaxation for this problem. Using this, we obtain an\n$\\tilde{O}(n^{1/3})$ algorithm for QP-ratio. We also obtain an\n$\\tilde{O}(n^{1/4})$ approximation for bipartite graphs, and better algorithms\nfor special cases. As with other problems with ratio objectives (e.g. uniform\nsparsest cut), it seems difficult to obtain inapproximability results based on\nP!=NP. We give two results that indicate that QP-Ratio is hard to approximate\nto within any constant factor. We also give a natural distribution on instances\nof QP-Ratio for which an n^\\epsilon approximation (for \\epsilon roughly 1/10)\nseems out of reach of current techniques.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jan 2011 05:57:39 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2011 23:29:30 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Bhaskara", "Aditya", ""], ["Charikar", "Moses", ""], ["Manokaran", "Rajsekar", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1101.2018", "submitter": "Ruijia Liao", "authors": "Ruijia Liao", "title": "The Complexity of 3SAT_N and the P versus NP Problem", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We introduce the NP-complete problem 3SAT_N and extend Tovey's results to a\nclassification theorem for this problem. This theorem leads us to generalize\nthe concept of truth assignments for SAT to aggressive truth assignments for\n3SAT_N. We introduce the concept of a set compatible with the P and NP problem,\nand prove that all aggressive truth assignments are pseudo-algorithms. We\ncombine algorithm, pseudo-algorithm and diagonalization method to study the\ncomplexity of 3SAT_N and the P versus NP problem. The main result is P != NP.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jan 2011 04:27:55 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2011 03:21:35 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2012 03:50:55 GMT"}, {"version": "v4", "created": "Mon, 11 Nov 2013 03:19:21 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Liao", "Ruijia", ""]]}, {"id": "1101.2170", "submitter": "Simone Linz", "authors": "Maria Luisa Bonet, Simone Linz, and Katherine St. John", "title": "The Complexity of Finding Multiple Solutions to Betweenness and Quartet\n  Compatibility", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that two important problems that have applications in computational\nbiology are ASP-complete, which implies that, given a solution to a problem, it\nis NP-complete to decide if another solution exists. We show first that a\nvariation of Betweenness, which is the underlying problem of questions related\nto radiation hybrid mapping, is ASP-complete. Subsequently, we use that result\nto show that Quartet Compatibility, a fundamental problem in phylogenetics that\nasks whether a set of quartets can be represented by a parent tree, is also\nASP-complete. The latter result shows that Steel's \\sc Quartet Challenge, which\nasks whether a solution to Quartet Compatibility is unique, is coNP-complete.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jan 2011 17:48:54 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2011 07:57:11 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Bonet", "Maria Luisa", ""], ["Linz", "Simone", ""], ["John", "Katherine St.", ""]]}, {"id": "1101.2637", "submitter": "Gautam Prakriya", "authors": "Samir Datta and Gautam Prakriya", "title": "Planarity Testing Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planarity Testing is the problem of determining whether a given graph is\nplanar while planar embedding is the corresponding construction problem. The\nbounded space complexity of these problems has been determined to be exactly\nLogspace by Allender and Mahajan with the aid of Reingold's result.\nUnfortunately, the algorithm is quite daunting and generalizing it to say, the\nbounded genus case seems a tall order.\n  In this work, we present a simple planar embedding algorithm running in\nlogspace. We hope this algorithm will be more amenable to generalization. The\nalgorithm is based on the fact that 3-connected planar graphs have a unique\nembedding, a variant of Tutte's criterion on conflict graphs of cycles and an\nexplicit change of cycle basis.% for planar graphs.\n  We also present a logspace algorithm to find obstacles to planarity, viz. a\nKuratowski minor, if the graph is non-planar. To the best of our knowledge this\nis the first logspace algorithm for this problem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jan 2011 19:19:11 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Datta", "Samir", ""], ["Prakriya", "Gautam", ""]]}, {"id": "1101.2642", "submitter": "J. Maurice Rojas", "authors": "Osbert Bastani, Christopher J. Hillar, Dimitar Popov, and J. Maurice\n  Rojas", "title": "Randomization, Sums of Squares, and Faster Real Root Counting for\n  Tetranomials and Beyond", "comments": "20 pages, 5 figures, submitted to a refereed conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose f is a real univariate polynomial of degree D with exactly 4 monomial\nterms. We present an algorithm, with complexity polynomial in log D on average\n(relative to the stable log-uniform measure), for counting the number of real\nroots of f. The best previous algorithms had complexity super-linear in D. We\nalso discuss connections to sums of squares and A-discriminants, including\nexplicit obstructions to expressing positive definite sparse polynomials as\nsums of squares of few sparse polynomials. Our key tool is the introduction of\nefficiently computable chamber cones, bounding regions in coefficient space\nwhere the number of real roots of f can be computed easily. Much of our theory\nextends to n-variate (n+3)-nomials.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jan 2011 19:44:50 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Bastani", "Osbert", ""], ["Hillar", "Christopher J.", ""], ["Popov", "Dimitar", ""], ["Rojas", "J. Maurice", ""]]}, {"id": "1101.2705", "submitter": "Dustin Wehr", "authors": "Dustin Wehr", "title": "Lower bound for deterministic semantic-incremental branching programs\n  solving GEN", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer a problem posed in (G\\'al, Kouck\\'y, McKenzie 2008) regarding a\nrestricted model of small-space computation, tailored for solving the GEN\nproblem. They define two variants of \"incremental branching programs\", the\nsyntactic variant defined by a restriction on the graph-theoretic paths in the\nprogram, and the more-general semantic variant in which the same restriction is\nenforced only on the consistent paths - those that are followed by at least one\ninput. They show that exponential size is required for the syntactic variant,\nbut leave open the problem of superpolynomial lower bounds for the semantic\nvariant. Here we give an exponential lower bound for the semantic variant by\ngeneralizing lower bound arguments, from earlier work, for a similar restricted\nmodel tailored for solving a special case of GEN called Tree Evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jan 2011 01:27:20 GMT"}], "update_date": "2011-01-17", "authors_parsed": [["Wehr", "Dustin", ""]]}, {"id": "1101.2812", "submitter": "David Monniaux", "authors": "Thomas Martin Gawlitza (VERIMAG - IMAG), David Monniaux (VERIMAG -\n  IMAG)", "title": "Improving Strategies via SMT Solving", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-19718-5_13", "report-no": null, "categories": "cs.PL cs.CC cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing numerical invariants of programs by\nabstract interpretation. Our method eschews two traditional sources of\nimprecision: (i) the use of widening operators for enforcing convergence within\na finite number of iterations (ii) the use of merge operations (often, convex\nhulls) at the merge points of the control flow graph. It instead computes the\nleast inductive invariant expressible in the domain at a restricted set of\nprogram points, and analyzes the rest of the code en bloc. We emphasize that we\ncompute this inductive invariant precisely. For that we extend the strategy\nimprovement algorithm of [Gawlitza and Seidl, 2007]. If we applied their method\ndirectly, we would have to solve an exponentially sized system of abstract\nsemantic equations, resulting in memory exhaustion. Instead, we keep the system\nimplicit and discover strategy improvements using SAT modulo real linear\narithmetic (SMT). For evaluating strategies we use linear programming. Our\nalgorithm has low polynomial space complexity and performs for contrived\nexamples in the worst case exponentially many strategy improvement steps; this\nis unsurprising, since we show that the associated abstract reachability\nproblem is Pi-p-2-complete.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jan 2011 13:59:06 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Gawlitza", "Thomas Martin", "", "VERIMAG - IMAG"], ["Monniaux", "David", "", "VERIMAG -\n  IMAG"]]}, {"id": "1101.3521", "submitter": "Amit Hagar", "authors": "Amit Hagar and Giuseppe Sergioli", "title": "Counting Steps: A New Approach to Objective Probability in Physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new interpretation of objective deterministic chances in\nstatistical physics based on physical computational complexity. This notion\napplies to a single physical system (be it an experimental set--up in the lab,\nor a subsystem of the universe), and quantifies (1) the difficulty to realize a\nphysical state given another, (2) the `distance' (in terms of physical\nresources) of a physical state from another, and (3) the size of the set of\ntime--complexity functions that are compatible with the physical resources\nrequired to reach a physical state from another. This view (a) exorcises\n\"ignorance\" from statistical physics, and (b) underlies a new interpretation to\nnon--relativistic quantum mechanics.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jan 2011 18:40:17 GMT"}, {"version": "v2", "created": "Thu, 20 Jan 2011 02:30:02 GMT"}, {"version": "v3", "created": "Sun, 23 Jan 2011 15:38:14 GMT"}, {"version": "v4", "created": "Fri, 24 Jun 2011 12:37:10 GMT"}, {"version": "v5", "created": "Tue, 19 Mar 2013 13:52:06 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Hagar", "Amit", ""], ["Sergioli", "Giuseppe", ""]]}, {"id": "1101.3837", "submitter": "Abuzer Yakaryilmaz", "authors": "Andris Ambainis and Abuzer Yakaryilmaz", "title": "Superiority of exact quantum automata for promise problems", "comments": "A completely new version. 6 pages. (The previous version contains\n  some errata.)", "journal-ref": "Information Processing Letters, Volume 112, Issue 7, 31 March\n  2012, Pages 289-291", "doi": "10.1016/j.ipl.2012.01.001", "report-no": null, "categories": "cs.CC cs.FL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we present an infinite family of promise problems which can be\nsolved exactly by just tuning transition amplitudes of a two-state quantum\nfinite automata operating in realtime mode, whereas the size of the\ncorresponding classical automata grow without bound.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 08:17:25 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2011 13:50:08 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Ambainis", "Andris", ""], ["Yakaryilmaz", "Abuzer", ""]]}, {"id": "1101.3884", "submitter": "Sevag Gharibian", "authors": "Sevag Gharibian and Julia Kempe", "title": "Approximation algorithms for QMA-complete problems", "comments": "22 pages, comments welcome", "journal-ref": "SIAM Journal on Computing 41(4): 1028-1050, 2012. Also in\n  Proceedings of 26th IEEE Conference on Computational Complexity (CCC),\n  178-188, 2011", "doi": "10.1137/110842272", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximation algorithms for classical constraint satisfaction problems are\none of the main research areas in theoretical computer science. Here we define\na natural approximation version of the QMA-complete local Hamiltonian problem\nand initiate its study. We present two main results. The first shows that a\nnon-trivial approximation ratio can be obtained in the class NP using product\nstates. The second result (which builds on the first one), gives a polynomial\ntime (classical) algorithm providing a similar approximation ratio for dense\ninstances of the problem. The latter result is based on an adaptation of the\n\"exhaustive sampling method\" by Arora et al. [J. Comp. Sys. Sci. 58, p.193\n(1999)] to the quantum setting, and might be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 12:42:53 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Gharibian", "Sevag", ""], ["Kempe", "Julia", ""]]}, {"id": "1101.3970", "submitter": "Iddo Tzameret", "authors": "Sebastian M\\\"uller and Iddo Tzameret", "title": "Short Propositional Refutations for Dense Random 3CNF Formulas", "comments": "62 pages; improved introduction and abstract, and a changed title.\n  Fixed some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random 3CNF formulas constitute an important distribution for measuring the\naverage-case behavior of propositional proof systems. Lower bounds for random\n3CNF refutations in many propositional proof systems are known. Most notably\nare the exponential-size resolution refutation lower bounds for random 3CNF\nformulas with $\\Omega(n^{1.5-\\epsilon}) $ clauses [Chvatal and Szemeredi\n(1988), Ben-Sasson and Wigderson (2001)]. On the other hand, the only known\nnon-trivial upper bound on the size of random 3CNF refutations in a\nnon-abstract propositional proof system is for resolution with\n$\\Omega(n^{2}/\\log n) $ clauses, shown by Beame et al. (2002). In this paper we\nshow that already standard propositional proof systems, within the hierarchy of\nFrege proofs, admit short refutations for random 3CNF formulas, for\nsufficiently large clause-to-variable ratio. Specifically, we demonstrate\npolynomial-size propositional refutations whose lines are $TC^0$ formulas\n(i.e., $TC^0$-Frege proofs) for random 3CNF formulas with $ n $ variables and $\n\\Omega(n^{1.4}) $ clauses.\n  The idea is based on demonstrating efficient propositional correctness proofs\nof the random 3CNF unsatisfiability witnesses given by Feige, Kim and Ofek\n(2006). Since the soundness of these witnesses is verified using spectral\ntechniques, we develop an appropriate way to reason about eigenvectors in\npropositional systems. To carry out the full argument we work inside weak\nformal systems of arithmetic and use a general translation scheme to\npropositional proofs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 17:09:14 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2011 07:45:20 GMT"}], "update_date": "2011-06-06", "authors_parsed": [["M\u00fcller", "Sebastian", ""], ["Tzameret", "Iddo", ""]]}, {"id": "1101.4555", "submitter": "Shengyu Zhang", "authors": "Ming Lam Leung, Yang Li, Shengyu Zhang", "title": "Tight bounds on the randomized communication complexity of symmetric XOR\n  functions in one-way and SMP models", "comments": null, "journal-ref": "TAMC11', Proceedings of the 8th Theory and Applications of Models\n  of Computation Lecture Notes in Computer Science, 2011, Volume 6648/2011,\n  pages 403-408", "doi": "10.1007/978-3-642-20877-5_39", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the communication complexity of symmetric XOR functions, namely\nfunctions $f: \\{0,1\\}^n \\times \\{0,1\\}^n \\rightarrow \\{0,1\\}$ that can be\nformulated as $f(x,y)=D(|x\\oplus y|)$ for some predicate $D: \\{0,1,...,n\\}\n\\rightarrow \\{0,1\\}$, where $|x\\oplus y|$ is the Hamming weight of the bitwise\nXOR of $x$ and $y$. We give a public-coin randomized protocol in the\nSimultaneous Message Passing (SMP) model, with the communication cost matching\nthe known lower bound for the \\emph{quantum} and \\emph{two-way} model up to a\nlogarithm factor. As a corollary, this closes a quadratic gap between quantum\nlower bound and randomized upper bound for the one-way model, answering an open\nquestion raised in Shi and Zhang \\cite{SZ09}.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 14:53:10 GMT"}], "update_date": "2011-11-01", "authors_parsed": [["Leung", "Ming Lam", ""], ["Li", "Yang", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1101.4795", "submitter": "Hector Zenil", "authors": "Jean-Paul Delahaye, Hector Zenil", "title": "Numerical Evaluation of Algorithmic Complexity for Short Strings: A\n  Glance into the Innermost Structure of Randomness", "comments": "29 pages, 5 figures. Version as accepted by the journal Applied\n  Mathematics and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an alternative method (to compression) that combines several\ntheoretical and experimental results to numerically approximate the algorithmic\n(Kolmogorov-Chaitin) complexity of all $\\sum_{n=1}^82^n$ bit strings up to 8\nbits long, and for some between 9 and 16 bits long. This is done by an\nexhaustive execution of all deterministic 2-symbol Turing machines with up to 4\nstates for which the halting times are known thanks to the Busy Beaver problem,\nthat is 11019960576 machines. An output frequency distribution is then\ncomputed, from which the algorithmic probability is calculated and the\nalgorithmic complexity evaluated by way of the (Levin-Zvonkin-Chaitin) coding\ntheorem.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jan 2011 12:50:23 GMT"}, {"version": "v2", "created": "Tue, 15 Mar 2011 14:42:10 GMT"}, {"version": "v3", "created": "Sat, 16 Apr 2011 17:41:13 GMT"}, {"version": "v4", "created": "Mon, 2 May 2011 20:02:51 GMT"}, {"version": "v5", "created": "Wed, 5 Oct 2011 22:46:28 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Delahaye", "Jean-Paul", ""], ["Zenil", "Hector", ""]]}, {"id": "1101.4824", "submitter": "Steffen Kopecki", "authors": "Volker Diekert and Steffen Kopecki", "title": "It Is NL-complete to Decide Whether a Hairpin Completion of Regular\n  Languages Is Regular", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hairpin completion is an operation on formal languages which is inspired\nby the hairpin formation in biochemistry. Hairpin formations occur naturally\nwithin DNA-computing. It has been known that the hairpin completion of a\nregular language is linear context-free, but not regular, in general. However,\nfor some time it is was open whether the regularity of the hairpin completion\nof a regular language is is decidable. In 2009 this decidability problem has\nbeen solved positively by providing a polynomial time algorithm. In this paper\nwe improve the complexity bound by showing that the decision problem is\nactually NL-complete. This complexity bound holds for both, the one-sided and\nthe two-sided hairpin completions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jan 2011 14:35:12 GMT"}], "update_date": "2011-01-26", "authors_parsed": [["Diekert", "Volker", ""], ["Kopecki", "Steffen", ""]]}, {"id": "1101.4848", "submitter": "Philippe Moser", "authors": "Philippe Moser", "title": "A zero-one SUBEXP-dimension law for BPP", "comments": "to be published in information processing letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that BPP has either SUBEXP-dimension zero (randomness is easy) or\nBPP=EXP (randomness is intractable).\n", "versions": [{"version": "v1", "created": "Tue, 25 Jan 2011 15:22:48 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Moser", "Philippe", ""]]}, {"id": "1101.5227", "submitter": "Abuzer Yakaryilmaz", "authors": "Abuzer Yakaryilmaz and A. C. Cem Say", "title": "NP has log-space verifiers with fixed-size public quantum registers", "comments": "9 pages. A revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical Arthur-Merlin games, the class of languages whose membership\nproofs can be verified by Arthur using logarithmic space (AM(log-space))\ncoincides with the class P \\cite{Co89}. In this note, we show that if Arthur\nhas a fixed-size quantum register (the size of the register does not depend on\nthe length of the input) instead of another source of random bits, membership\nin any language in NP can be verified with any desired error bound.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jan 2011 09:02:25 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2011 06:33:59 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2012 11:49:00 GMT"}], "update_date": "2012-04-06", "authors_parsed": [["Yakaryilmaz", "Abuzer", ""], ["Say", "A. C. Cem", ""]]}, {"id": "1101.5355", "submitter": "Scott Aaronson", "authors": "Scott Aaronson and Andrew Drucker", "title": "Advice Coins for Classical and Quantum Computation", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the power of classical and quantum algorithms equipped with\nnonuniform advice, in the form of a coin whose bias encodes useful information.\nThis question takes on particular importance in the quantum case, due to a\nsurprising result that we prove: a quantum finite automaton with just two\nstates can be sensitive to arbitrarily small changes in a coin's bias. This\ncontrasts with classical probabilistic finite automata, whose sensitivity to\nchanges in a coin's bias is bounded by a classic 1970 result of Hellman and\nCover. Despite this finding, we are able to bound the power of advice coins for\nspace-bounded classical and quantum computation. We define the classes\nBPPSPACE/coin and BQPSPACE/coin, of languages decidable by classical and\nquantum polynomial-space machines with advice coins. Our main theorem is that\nboth classes coincide with PSPACE/poly. Proving this result turns out to\nrequire substantial machinery. We use an algorithm due to Neff for finding\nroots of polynomials in NC; a result from algebraic geometry that lower-bounds\nthe separation of a polynomial's roots; and a result on fixed-points of\nsuperoperators due to Aaronson and Watrous, originally proved in the context of\nquantum computing with closed timelike curves.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jan 2011 18:09:21 GMT"}], "update_date": "2011-01-28", "authors_parsed": [["Aaronson", "Scott", ""], ["Drucker", "Andrew", ""]]}, {"id": "1101.5444", "submitter": "EPTCS", "authors": "Reinhard Kahle (CENTRIA and DM, FCT, Universidade Nova de Lisboa),\n  Isabel Oitavem (CMAF, Universidade de Lisboa and DM, FCT, Universidade Nova\n  de Lisboa)", "title": "An applicative theory for FPH", "comments": "In Proceedings CL&C 2010, arXiv:1101.5200", "journal-ref": "EPTCS 47, 2011, pp. 44-56", "doi": "10.4204/EPTCS.47.6", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce an applicative theory which characterizes the\npolynomial hierarchy of time.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jan 2011 04:25:48 GMT"}], "update_date": "2011-01-31", "authors_parsed": [["Kahle", "Reinhard", "", "CENTRIA and DM, FCT, Universidade Nova de Lisboa"], ["Oitavem", "Isabel", "", "CMAF, Universidade de Lisboa and DM, FCT, Universidade Nova\n  de Lisboa"]]}, {"id": "1101.5455", "submitter": "Satyadev Nandakumar", "authors": "Jack Lutz", "title": "Resource Bounded Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general theory of resource-bounded measurability and measure is developed.\nStarting from any feasible probability measure $\\nu$ on the Cantor space $\\C$\nand any suitable complexity class $C \\subseteq \\C$, the theory identifies the\nsubsets of $\\C$ that are $\\nu$-measurable in $C$ and assigns measures to these\nsets, thereby endowing $C$ with internal measure-theoretic structure. Classes\nto which the theory applies include various exponential time and space\ncomplexity classes, the class of all decidable languages, and the Cantor space\nitself, on which the resource-bounded theory is shown to agree with the\nclassical theory.\n  The sets that are $\\nu$-measurable in $C$ are shown to form an algebra\nrelative to which $\\nu$-measure is well-behaved. This algebra is also shown to\nbe complete and closed under sufficiently uniform infinitary unions and\nintersections, and $\\nu$-measure in $C$ is shown to have the appropriate\nadditivity and monotone convergence properties with respect to such infinitary\noperations.\n  A generalization of the classical Kolmogorov zero-one law is proven, showing\nthat when $\\nu$ is any feasible coin-toss probability measure on $\\C$, every\nset that is $\\nu$-measurable in $C$ and (like most complexity classes)\ninvariant under finite alterations must have $\\nu$-measure 0 or $\\nu$-measure 1\nin $C$.\n  The theory is presented here is based on resource-bounded martingale\nsplitting operators, which are type-2 functionals, each of which maps $\\N\n\\times {\\cal D}_\\nu$ into ${\\cal D}_\\nu \\times {\\cal D}_\\nu$, where ${\\cal\nD}_\\nu$ is the set of all $\\nu$-martingales. This type-2 aspect of the theory\nappears to be essential for general $\\nu$-measure in complexity classes $C$,\nbut the sets of $\\nu$-measure 0 or 1 in C are shown to be characterized by the\nsuccess conditions for martingales (type-1 functions) that have been used in\nresource-bounded measure to date.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jan 2011 05:28:57 GMT"}, {"version": "v2", "created": "Sun, 6 Feb 2011 04:02:19 GMT"}, {"version": "v3", "created": "Mon, 7 Mar 2011 09:30:00 GMT"}, {"version": "v4", "created": "Tue, 31 Jan 2012 13:17:24 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Lutz", "Jack", ""]]}, {"id": "1101.6038", "submitter": "Jose Antonio Martin H", "authors": "Jose Antonio Martin H", "title": "A polynomial 3-colorability algorithm with automatic generation of NO\n  3-colorability (i.e. Co-NP) short proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an algorithm for determining 3-colorability, i.e. the decision\nproblem (YES/NO), in planar graphs is presented. The algorithm, although not\nexact (it could produce false positives) has two very important features: (i)\nit has polynomial complexity and (ii) for every \"NO\" answer, a \"short\" proof is\ngenerated, which is of much interest since 3-colorability is a NP-complete\nproblem and thus its complementary problem is in Co-NP. Hence the algorithm is\nexact when it determines that a given planar graph is not 3-colorable since\nthis is verifiable via an automatic generation of short formal proofs (also\nhuman-readable).\n", "versions": [{"version": "v1", "created": "Mon, 31 Jan 2011 17:47:39 GMT"}], "update_date": "2011-02-01", "authors_parsed": [["H", "Jose Antonio Martin", ""]]}]