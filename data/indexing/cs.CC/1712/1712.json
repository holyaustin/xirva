[{"id": "1712.00200", "submitter": "Jonathan Noel", "authors": "Richard C. Brewster and Jae-Baek Lee and Benjamin Moore and Jonathan\n  A. Noel and Mark Siggers", "title": "Graph Homomorphism Reconfiguration and Frozen $H$-Colourings", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a fixed graph $H$, the reconfiguration problem for $H$-colourings (i.e.\nhomomorphisms to $H$) asks: given a graph $G$ and two $H$-colourings $\\varphi$\nand $\\psi$ of $G$, does there exist a sequence $f_0,\\dots,f_m$ of\n$H$-colourings such that $f_0=\\varphi$, $f_m=\\psi$ and $f_i(u)f_{i+1}(v)\\in\nE(H)$ for every $0\\leq i<m$ and $uv\\in E(G)$? If the graph $G$ is loop-free,\nthen this is the equivalent to asking whether it possible to transform\n$\\varphi$ into $\\psi$ by changing the colour of one vertex at a time such that\nall intermediate mappings are $H$-colourings. In the affirmative, we say that\n$\\varphi$ reconfigures to $\\psi$. Currently, the complexity of deciding whether\nan $H$-colouring $\\varphi$ reconfigures to an $H$-colouring $\\psi$ is only\nknown when $H$ is a clique, a circular clique, a $C_4$-free graph, or in a few\nother cases which are easily derived from these. We show that this problem is\nPSPACE-complete when $H$ is an odd wheel.\n  An important notion in the study of reconfiguration problems for\n$H$-colourings is that of a frozen $H$-colouring; i.e. an $H$-colouring\n$\\varphi$ such that $\\varphi$ does not reconfigure to any $H$-colouring $\\psi$\nsuch that $\\psi\\neq \\varphi$. We obtain an explicit dichotomy theorem for the\nproblem of deciding whether a given graph $G$ admits a frozen $H$-colouring.\nThe hardness proof involves a reduction from a CSP problem which is shown to be\nNP-complete by establishing the non-existence of a certain type of\npolymorphism.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 05:45:40 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Brewster", "Richard C.", ""], ["Lee", "Jae-Baek", ""], ["Moore", "Benjamin", ""], ["Noel", "Jonathan A.", ""], ["Siggers", "Mark", ""]]}, {"id": "1712.00232", "submitter": "Cesar A. Uribe", "authors": "C\\'esar A. Uribe and Soomin Lee and Alexander Gasnikov and Angelia\n  Nedi\\'c", "title": "Optimal Algorithms for Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.MA cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the optimal convergence rate for distributed convex\noptimization problems in networks. We model the communication restrictions\nimposed by the network as a set of affine constraints and provide optimal\ncomplexity bounds for four different setups, namely: the function $F(\\xb)\n\\triangleq \\sum_{i=1}^{m}f_i(\\xb)$ is strongly convex and smooth, either\nstrongly convex or smooth or just convex. Our results show that Nesterov's\naccelerated gradient descent on the dual problem can be executed in a\ndistributed manner and obtains the same optimal rates as in the centralized\nversion of the problem (up to constant or logarithmic factors) with an\nadditional cost related to the spectral gap of the interaction matrix. Finally,\nwe discuss some extensions to the proposed setup such as proximal friendly\nfunctions, time-varying graphs, improvement of the condition numbers.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 08:41:28 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 15:55:45 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 20:17:30 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Uribe", "C\u00e9sar A.", ""], ["Lee", "Soomin", ""], ["Gasnikov", "Alexander", ""], ["Nedi\u0107", "Angelia", ""]]}, {"id": "1712.00810", "submitter": "Ioannis Kokkinis", "authors": "Ioannis Kokkinis", "title": "The Complexity of Satisfiability in Non-Iterated and Iterated\n  Probabilistic Logics", "comments": null, "journal-ref": "Annals of Mathematics and Artificial Intelligence, August 2018,\n  Volume 83, Issue 3-4, pp 351-382", "doi": "10.1007/s10472-018-9593-y", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let L be some extension of classical propositional logic. The non-iterated\nprobabilistic logic over L, is the logic PL that is defined by adding\nnon-nested probabilistic operators in the language of L. For example in PL we\ncan express a statement like \"the probability of truthfulness of A is at 0.3\"\nwhere A is a formula of L. The iterated probabilistic logic over L is the logic\nPPL, where the probabilistic operators may be iterated (nested). For example,\nin PPL we can express a statement like \"this coin is counterfeit with\nprobability 0.6\". In this paper we investigate the influence of probabilistic\noperators in the complexity of satisfiability in PL and PPL. We obtain\ncomplexity bounds, for the aforementioned satisfiability problem, which are\nparameterized in the complexity of satisfiability of conjunctions of positive\nand negative formulas that have neither a probabilistic nor a classical\noperator as a top-connective. As an application of our results we obtain tight\ncomplexity bounds for the satisfiability problem in PL and PPL when L is\nclassical propositional logic or justification logic.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 18:34:24 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 08:05:28 GMT"}, {"version": "v3", "created": "Sun, 10 Feb 2019 12:00:01 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kokkinis", "Ioannis", ""]]}, {"id": "1712.00942", "submitter": "Noah Stephens-Davidowitz", "authors": "Divesh Aggarwal and Noah Stephens-Davidowitz", "title": "(Gap/S)ETH Hardness of SVP", "comments": null, "journal-ref": "STOC 2018", "doi": "10.1145/3188745.3188840", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $ \\newcommand{\\problem}[1]{\\ensuremath{\\mathrm{#1}} }\n\\newcommand{\\SVP}{\\problem{SVP}} \\newcommand{\\ensuremath}[1]{#1} $We prove the\nfollowing quantitative hardness results for the Shortest Vector Problem in the\n$\\ell_p$ norm ($\\SVP_p$), where $n$ is the rank of the input lattice.\n  $\\bullet$ For \"almost all\" $p > p_0 \\approx 2.1397$, there no\n$2^{n/C_p}$-time algorithm for $\\SVP_p$ for some explicit constant $C_p > 0$\nunless the (randomized) Strong Exponential Time Hypothesis (SETH) is false.\n  $\\bullet$ For any $p > 2$, there is no $2^{o(n)}$-time algorithm for $\\SVP_p$\nunless the (randomized) Gap-Exponential Time Hypothesis (Gap-ETH) is false.\nFurthermore, for each $p > 2$, there exists a constant $\\gamma_p > 1$ such that\nthe same result holds even for $\\gamma_p$-approximate $\\SVP_p$.\n  $\\bullet$ There is no $2^{o(n)}$-time algorithm for $\\SVP_p$ for any $1 \\leq\np \\leq 2$ unless either (1) (non-uniform) Gap-ETH is false; or (2) there is no\nfamily of lattices with exponential kissing number in the $\\ell_2$ norm.\nFurthermore, for each $1 \\leq p \\leq 2$, there exists a constant $\\gamma_p > 1$\nsuch that the same result holds even for $\\gamma_p$-approximate $\\SVP_p$.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 07:50:40 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Aggarwal", "Divesh", ""], ["Stephens-Davidowitz", "Noah", ""]]}, {"id": "1712.01149", "submitter": "DeVon Ingram", "authors": "DeVon Ingram", "title": "An Upper Bound on the GKS Game via Max Bipartite Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sensitivity conjecture is a longstanding conjecture concerning the\nrelationship between the degree and sensitivity of a Boolean function. In 2015,\na communication game was formulated by Justin Gilmer, Michal Kouck\\'{y}, and\nMichael Saks to attempt to make progress on this conjecture. Andrew Drucker\nindependently formulated this game. Shortly after the creation of the GKS game,\nNisan Szegedy obtained a protocol for the game with a cost of $O(n^{.4732})$.\nWe improve Szegedy's result to a cost of $O(n^{.4696})$ by providing a\ntechnique to identify whether a set of codewords can be used as a viable\nstrategy in this game.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 15:33:35 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Ingram", "DeVon", ""]]}, {"id": "1712.01178", "submitter": "Gerald Friedland", "authors": "Gerald Friedland, Alfredo Metere", "title": "Principle of Conservation of Computational Complexity", "comments": "This version of the article improves on the previous versions by\n  generalizing to a general principle. This way, the very technical reduction\n  of the halting problem to SAT_syntax is unnecessary. The authors would like\n  to thank their peers for feedback and arxiv.org for enabling it. Feedback is\n  always encouraged", "journal-ref": null, "doi": null, "report-no": "LLNL-JRNL-743757", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, we derive the principle of conservation of computational\ncomplexity. We measure computational complexity as the number of binary\ncomputations (decisions) required to solve a problem. Every problem then\ndefines a unique solution space measurable in bits. For an exact result,\ndecisions in the solution space can neither be predicted nor discarded, only\ntransferred between input and algorithm. We demonstrate and explain this\nprinciple using the example of the propositional logic satisfiability problem\n($SAT$). It inevitably follows that $SAT \\not\\in P \\Rightarrow P\\neq NP$. We\nalso provide an alternative explanation for the undecidability of the halting\nproblem based on the principle.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 16:25:42 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 20:26:26 GMT"}, {"version": "v3", "created": "Wed, 3 Jan 2018 19:09:32 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Friedland", "Gerald", ""], ["Metere", "Alfredo", ""]]}, {"id": "1712.01330", "submitter": "Yining Chen", "authors": "Amit Chakrabarti, Yining Chen", "title": "Time-Space Tradeoffs for the Memory Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A single-player game of Memory is played with $n$ distinct pairs of cards,\nwith the cards in each pair bearing identical pictures. The cards are laid\nface-down. A move consists of revealing two cards, chosen adaptively. If these\ncards match, i.e., they bear the same picture, they are removed from play;\notherwise, they are turned back to face down. The object of the game is to\nclear all cards while minimizing the number of moves. Past works have\nthoroughly studied the expected number of moves required, assuming optimal play\nby a player has that has perfect memory. In this work, we study the Memory game\nin a space-bounded setting.\n  We prove two time-space tradeoff lower bounds on algorithms (strategies for\nthe player) that clear all cards in $T$ moves while using at most $S$ bits of\nmemory. First, in a simple model where the pictures on the cards may only be\ncompared for equality, we prove that $ST = \\Omega(n^2 \\log n)$. This is tight:\nit is easy to achieve $ST = O(n^2 \\log n)$ essentially everywhere on this\ntradeoff curve. Second, in a more general model that allows arbitrary\ncomputations, we prove that $ST^2 = \\Omega(n^3)$. We prove this latter tradeoff\nby modeling strategies as branching programs and extending a classic counting\nargument of Borodin and Cook with a novel probabilistic argument. We conjecture\nthat the stronger tradeoff $ST = \\widetilde{\\Omega}(n^2)$ in fact holds even in\nthis general model.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 20:16:53 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 22:02:41 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Chakrabarti", "Amit", ""], ["Chen", "Yining", ""]]}, {"id": "1712.01834", "submitter": "Diptarka Chakraborty", "authors": "Diptarka Chakraborty, Debarati Das, Michal Kouck\\'y, Nitin Saurabh", "title": "Optimal Quasi-Gray Codes: The Alphabet Matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quasi-Gray code of dimension $n$ and length $\\ell$ over an alphabet\n$\\Sigma$ is a sequence of distinct words $w_1,w_2,\\dots,w_\\ell$ from $\\Sigma^n$\nsuch that any two consecutive words differ in at most $c$ coordinates, for some\nfixed constant $c>0$. In this paper we are interested in the read and write\ncomplexity of quasi-Gray codes in the bit-probe model, where we measure the\nnumber of symbols read and written in order to transform any word $w_i$ into\nits successor $w_{i+1}$.\n  We present construction of quasi-Gray codes of dimension $n$ and length $3^n$\nover the ternary alphabet $\\{0,1,2\\}$ with worst-case read complexity $O(\\log\nn)$ and write complexity $2$. This generalizes to arbitrary odd-size alphabets.\nFor the binary alphabet, we present quasi-Gray codes of dimension $n$ and\nlength at least $2^n - 20n$ with worst-case read complexity $6+\\log n$ and\nwrite complexity $2$. This complements a recent result by Raskin [Raskin '17]\nwho shows that any quasi-Gray code over binary alphabet of length $2^n$ has\nread complexity $\\Omega(n)$.\n  Our results significantly improve on previously known constructions and for\nthe odd-size alphabets we break the $\\Omega(n)$ worst-case barrier for\nspace-optimal (non-redundant) quasi-Gray codes with constant number of writes.\nWe obtain our results via a novel application of algebraic tools together with\nthe principles of catalytic computation [Buhrman et al. '14, Ben-Or and Cleve\n'92, Barrington '89, Coppersmith and Grossman '75].\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 14:43:45 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 12:44:18 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Chakraborty", "Diptarka", ""], ["Das", "Debarati", ""], ["Kouck\u00fd", "Michal", ""], ["Saurabh", "Nitin", ""]]}, {"id": "1712.02103", "submitter": "Lei Shang", "authors": "Lei Shang", "title": "Exact Algorithms With Worst-case Guarantee For Scheduling: From Theory\n  to Practice", "comments": "156 pages, PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This PhD thesis summarizes research works on the design of exact algorithms\nthat provide a worst-case (time or space) guarantee for NP-hard scheduling\nproblems. Both theoretical and practical aspects are considered with three main\nresults reported. The first one is about a Dynamic Programming algorithm which\nsolves the F3Cmax problem in O*(3^n) time and space. The algorithm is easily\ngeneralized to other flowshop problems and single machine scheduling problems.\nThe second contribution is about a search tree method called Branch & Merge\nwhich solves the 1||SumTi problem with the time complexity converging to\nO*(2^n) and in polynomial space. Our third contribution aims to improve the\npractical efficiency of exact search tree algorithms solving scheduling\nproblems. First we realized that a better way to implement the idea of Branch &\nMerge is to use a technique called Memorization. By the finding of a new\nalgorithmic paradox and the implementation of a memory cleaning strategy, the\nmethod succeeded to solve instances with 300 more jobs with respect to the\nstate-of-the-art algorithm for the 1||SumTi problem. Then the treatment is\nextended to another three problems 1|ri|SumCi, 1|dtilde|SumwiCi and F2||SumCi.\nThe results of the four problems all together show the power of the\nMemorization paradigm when applied on sequencing problems. We name it Branch &\nMemorize to promote a systematic consideration of Memorization as an essential\nbuilding block in branching algorithms like Branch and Bound. The method can\nsurely also be used to solve other problems, which are not necessarily\nscheduling problems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 09:42:34 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Shang", "Lei", ""]]}, {"id": "1712.02447", "submitter": "Daniel Paulusma", "authors": "Konrad Dabrowski, Daniel Paulusma", "title": "On Colouring $(2P_2,H)$-Free and $(P_5,H)$-Free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Colouring problem asks whether the vertices of a graph can be coloured\nwith at most $k$ colours for a given integer $k$ in such a way that no two\nadjacent vertices receive the same colour. A graph is $(H_1,H_2)$-free if it\nhas no induced subgraph isomorphic to $H_1$ or $H_2$. A connected graph $H_1$\nis almost classified if Colouring on $(H_1,H_2)$-free graphs is known to be\npolynomial-time solvable or NP-complete for all but finitely many connected\ngraphs $H_2$. We show that every connected graph $H_1$ apart from the claw\n$K_{1,3}$ and the $5$-vertex path $P_5$ is almost classified. We also prove a\nnumber of new hardness results for Colouring on $(2P_2,H)$-free graphs. This\nenables us to list all graphs $H$ for which the complexity of Colouring is open\non $(2P_2,H)$-free graphs and all graphs $H$ for which the complexity of\nColouring is open on $(P_5,H)$-free graphs. In fact we show that these two\nlists coincide. Moreover, we show that the complexities of Colouring for\n$(2P_2,H)$-free graphs and for $(P_5,H)$-free graphs are the same for all known\ncases.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 23:45:33 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Dabrowski", "Konrad", ""], ["Paulusma", "Daniel", ""]]}, {"id": "1712.03158", "submitter": "Thijs Laarhoven", "authors": "Thijs Laarhoven", "title": "Graph-based time-space trade-offs for approximate near neighbors", "comments": "26 pages, 4 figures", "journal-ref": "34th International Symposium on Computational Geometry (SoCG), pp.\n  57:1-57:14, 2018", "doi": "10.4230/LIPIcs.SoCG.2018.57", "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take a first step towards a rigorous asymptotic analysis of graph-based\napproaches for finding (approximate) nearest neighbors in high-dimensional\nspaces, by analyzing the complexity of (randomized) greedy walks on the\napproximate near neighbor graph. For random data sets of size $n = 2^{o(d)}$ on\nthe $d$-dimensional Euclidean unit sphere, using near neighbor graphs we can\nprovably solve the approximate nearest neighbor problem with approximation\nfactor $c > 1$ in query time $n^{\\rho_q + o(1)}$ and space $n^{1 + \\rho_s +\no(1)}$, for arbitrary $\\rho_q, \\rho_s \\geq 0$ satisfying \\begin{align} (2c^2 -\n1) \\rho_q + 2 c^2 (c^2 - 1) \\sqrt{\\rho_s (1 - \\rho_s)} \\geq c^4. \\end{align}\nGraph-based near neighbor searching is especially competitive with hash-based\nmethods for small $c$ and near-linear memory, and in this regime the asymptotic\nscaling of a greedy graph-based search matches the recent optimal hash-based\ntrade-offs of Andoni-Laarhoven-Razenshteyn-Waingarten [SODA'17]. We further\nstudy how the trade-offs scale when the data set is of size $n =\n2^{\\Theta(d)}$, and analyze asymptotic complexities when applying these results\nto lattice sieving.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 16:26:22 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Laarhoven", "Thijs", ""]]}, {"id": "1712.03714", "submitter": "Yann Strozecki", "authors": "Arnaud Mary and Yann Strozecki", "title": "Efficient enumeration of solutions produced by closure operations", "comments": "30 pages, 1 figure. Long version of the article arXiv:1509.05623 of\n  the same name which appeared in STACS 2016. Final version for DMTCS journal", "journal-ref": "Discrete Mathematics & Theoretical Computer Science, Vol. 21 no. 3\n  , Discrete Algorithms (June 13, 2019) dmtcs:5549", "doi": "10.23638/DMTCS-21-3-22", "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of generating all elements obtained by\nthe saturation of an initial set by some operations. More precisely, we prove\nthat we can generate the closure of a boolean relation (a set of boolean\nvectors) by polymorphisms with a polynomial delay. Therefore we can compute\nwith polynomial delay the closure of a family of sets by any set of \"set\noperations\": union, intersection, symmetric difference, subsets, supersets\n$\\dots$). To do so, we study the $Membership_{\\mathcal{F}}$ problem: for a set\nof operations $\\mathcal{F}$, decide whether an element belongs to the closure\nby $\\mathcal{F}$ of a family of elements. In the boolean case, we prove that\n$Membership_{\\mathcal{F}}$ is in P for any set of boolean operations\n$\\mathcal{F}$. When the input vectors are over a domain larger than two\nelements, we prove that the generic enumeration method fails, since\n$Membership_{\\mathcal{F}}$ is NP-hard for some $\\mathcal{F}$. We also study the\nproblem of generating minimal or maximal elements of closures and prove that\nsome of them are related to well known enumeration problems such as the\nenumeration of the circuits of a matroid or the enumeration of maximal\nindependent sets of a hypergraph. This article improves on previous works of\nthe same authors.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 10:52:13 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 19:59:50 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2019 10:24:03 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 12:49:09 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Mary", "Arnaud", ""], ["Strozecki", "Yann", ""]]}, {"id": "1712.04043", "submitter": "Iyad Kanj", "authors": "Eduard Eiben, Iyad Kanj", "title": "How to navigate through obstacles?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of obstacles and two points, is there a path between the two\npoints that does not cross more than $k$ different obstacles? This is a\nfundamental problem that has undergone a tremendous amount of work. It is known\nto be NP-hard, even when the obstacles are very simple geometric shapes (e.g.,\nunit-length line segments). The problem can be generalized into the following\ngraph problem: Given a planar graph $G$ whose vertices are colored by color\nsets, two designated vertices $s, t \\in V(G)$, and $k \\in \\mathbb{N}$, is there\nan $s$-$t$ path in $G$ that uses at most $k$ colors? If each obstacle is\nconnected, the resulting graph satisfies the color-connectivity property,\nnamely that each color induces a connected subgraph.\n  We study the complexity and design algorithms for the above graph problem\nwith an eye on its geometric applications. We prove that without the\ncolor-connectivity property, the problem is W[SAT]-hard parameterized by $k$. A\ncorollary of this result is that, unless W[2] $=$ FPT, the problem cannot be\napproximated in FPT time to within a factor that is a function of $k$. By\ndescribing a generic plane embedding of the graph instances, we show that our\nhardness results translate to the geometric instances of the problem.\n  We then focus on graphs satisfying the color-connectivity property. By\nexploiting the planarity of the graph and the connectivity of the colors, we\ndevelop topological results to \"represent\" the valid $s$-$t$ paths containing\nsubsets of colors from any vertex $v$. We employ these results to design an FPT\nalgorithm for the problem parameterized by both $k$ and the treewidth of the\ngraph, and extend this result to obtain an FPT algorithm for the\nparameterization by both $k$ and the length of the path. The latter result\ndirectly implies previous FPT results for various obstacle shapes, such as unit\ndisks and fat regions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 21:46:36 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Eiben", "Eduard", ""], ["Kanj", "Iyad", ""]]}, {"id": "1712.04281", "submitter": "Magnus Bakke Botnan", "authors": "H{\\aa}vard Bakke Bjerkevik, Magnus Bakke Botnan", "title": "Computational Complexity of the Interleaving Distance", "comments": "Discussion related to the characteristic of the field added. Paper\n  accepted to the 34th International Symposium on Computational Geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interleaving distance is arguably the most prominent distance measure in\ntopological data analysis. In this paper, we provide bounds on the\ncomputational complexity of determining the interleaving distance in several\nsettings. We show that the interleaving distance is NP-hard to compute for\npersistence modules valued in the category of vector spaces. In the specific\nsetting of multidimensional persistent homology we show that the problem is at\nleast as hard as a matrix invertibility problem. Furthermore, this allows us to\nconclude that the interleaving distance of interval decomposable modules\ndepends on the characteristic of the field. Persistence modules valued in the\ncategory of sets are also studied. As a corollary, we obtain that the\nisomorphism problem for Reeb graphs is graph isomorphism complete.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 13:25:04 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 13:11:55 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Bjerkevik", "H\u00e5vard Bakke", ""], ["Botnan", "Magnus Bakke", ""]]}, {"id": "1712.04496", "submitter": "Matthew Ferland", "authors": "Matthew Ferland and Kyle Burke", "title": "Computational Properties of Slime Trail", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the combinatorial game Slime Trail.This game is played on a\ngraph with a starting piece in a node. Each player's objective is to reach one\nof their own goal nodes. Every turn the current player moves the piece and\ndeletes the node they came from. We show that the game is PSPACE-complete when\nplayed on a planar graph.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 20:20:51 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Ferland", "Matthew", ""], ["Burke", "Kyle", ""]]}, {"id": "1712.04595", "submitter": "Vijay Sridhar", "authors": "Anastasios Sidiropoulos, Kritika Singhal, Vijay Sridhar", "title": "Fractal dimension and lower bounds for geometric problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of geometric problems on spaces of low fractal\ndimension. It was recently shown by [Sidiropoulos & Sridhar, SoCG 2017] that\nseveral problems admit improved solutions when the input is a pointset in\nEuclidean space with fractal dimension smaller than the ambient dimension. In\nthis paper we prove nearly-matching lower bounds, thus establishing\nnearly-optimal bounds for various problems as a function of the fractal\ndimension.\n  More specifically, we show that for any set of $n$ points in $d$-dimensional\nEuclidean space, of fractal dimension $\\delta\\in (1,d)$, for any $\\epsilon >0$\nand $c\\geq 1$, any $c$-spanner must have treewidth at least $\\Omega \\left(\n\\frac{n^{1-1/(\\delta - \\epsilon)}}{c^{d-1}} \\right)$, matching the previous\nupper bound. The construction used to prove this lower bound on the treewidth\nof spanners can also be used to derive lower bounds on the running time of\nalgorithms for various problems, assuming the Exponential Time Hypothesis. We\nprovide two prototypical results of this type. For any $\\delta \\in (1,d)$ and\nany $\\epsilon >0$ we show that:\n  1) $d$-dimensional Euclidean TSP on $n$ points with fractal dimension at most\n$\\delta$ cannot be solved in time $2^{O\\left(n^{1-1/(\\delta - \\epsilon)}\n\\right)}$. The best-known upper bound is $2^{O(n^{1-1/\\delta} \\log n)}$.\n  2) The problem of finding $k$-pairwise non-intersecting $d$-dimensional unit\nballs/axis parallel unit cubes with centers having fractal dimension at most\n$\\delta$ cannot be solved in time $f(k)n^{O \\left(k^{1-1/(\\delta -\n\\epsilon)}\\right)}$ for any computable function $f$. The best-known upper bound\nis $n^{O(k^{1-1/\\delta} \\log n)}$.\n  The above results nearly match previously known upper bounds from\n[Sidiropoulos & Sridhar, SoCG 2017], and generalize analogous lower bounds for\nthe case of ambient dimension due to [Marx & Sidiropoulos, SoCG 2014].\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 03:01:56 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Sidiropoulos", "Anastasios", ""], ["Singhal", "Kritika", ""], ["Sridhar", "Vijay", ""]]}, {"id": "1712.05142", "submitter": "Tillmann Miltzow", "authors": "Michael G. Dobbins and Linda Kleist and Tillmann Miltzow and Pawe{\\l}\n  Rz\\k{a}\\.zewski", "title": "$\\forall \\exists \\mathbb{R}$-completeness and area-universality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the study of geometric problems, the complexity class $\\exists \\mathbb{R}$\nturned out to play a crucial role. It exhibits a deep connection between purely\ngeometric problems and real algebra, and is sometimes referred to as the \"real\nanalogue\" to the class NP. While NP can be considered as a class of\ncomputational problems that deals with existentially quantified boolean\nvariables, $\\exists \\mathbb{R}$ deals with existentially quantified real\nvariables. In analogy to $\\Pi_2^p$ and $\\Sigma_2^p$ in the famous polynomial\nhierarchy, we introduce and motivate the complexity classes $\\forall\\exists\n\\mathbb{R}$ and $\\exists \\forall \\mathbb{R}$ with real variables. Our main\ninterest is focused on the Area Universality problem, where we are given a\nplane graph $G$, and ask if for each assignment of areas to the inner faces of\n$G$ there is an area-realizing straight-line drawing of $G$. We conjecture that\nthe problem Area Universality is $\\forall\\exists \\mathbb{R}$-complete and\nsupport this conjecture by a series of partial results, where we prove $\\exists\n\\mathbb{R}$- and $\\forall\\exists \\mathbb{R}$-completeness of variants of Area\nUniversality. To do so, we also introduce first tools to study $\\forall\\exists\n\\mathbb{R}$, such as restricted variants of UETR, which are $\\forall\\exists\n\\mathbb{R}$-complete. Finally, we present geometric problems as candidates for\n$\\forall\\exists \\mathbb{R}$-complete problems. These problems have connections\nto the concepts of imprecision, robustness, and extendability.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 09:42:24 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Dobbins", "Michael G.", ""], ["Kleist", "Linda", ""], ["Miltzow", "Tillmann", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "1712.05310", "submitter": "Hans van Ditmarsch", "authors": "Hans van Ditmarsch, Tim French", "title": "Quantifying over Boolean announcements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various extensions of public announcement logic have been proposed with\nquantification over announcements. The best-known extension is called arbitrary\npublic announcement logic, APAL. It contains a primitive language construct Box\nphi intuitively expressing that 'after every public announcement of a formula,\nformula phi is true.' The logic APAL is undecidable and it has an infinitary\naxiomatization. Now consider restricting the APAL quantification to public\nannouncements of Boolean formulas only, such that Box phi intuitively expresses\nthat 'after every public announcement of a Boolean formula, formula phi is\ntrue.' This logic can therefore called Boolean arbitrary public announcement\nlogic, BAPAL. The logic BAPAL is the subject of this work. It is decidable and\nit has a finitary axiomatization. These results may be considered of interest,\nas for various applications quantification over Booleans is sufficient in\nformal specifications.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 16:07:13 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 12:15:09 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 12:03:39 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["van Ditmarsch", "Hans", ""], ["French", "Tim", ""]]}, {"id": "1712.05735", "submitter": "Krishnamoorthy Dinesh", "authors": "Krishnamoorthy Dinesh and Jayalal Sarma", "title": "Alternation, Sparsity and Sensitivity : Bounds and Exponential Gaps", "comments": "19 pages, 1 figure, Journal version", "journal-ref": null, "doi": "10.1016/j.tcs.2018.11.015", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\newcommand{\\sp}{\\mathsf{sparsity}}\\newcommand{\\s}{\\mathsf{s}}\\newcommand{\\al}{\\mathsf{alt}}$\nThe well-known Sensitivity Conjecture states that for any Boolean function $f$,\nblock sensitivity of $f$ is at most polynomial in sensitivity of $f$ (denoted\nby $\\s(f)$). The XOR Log-Rank Conjecture states that for any $n$ bit Boolean\nfunction, $f$ the communication complexity of a related function $f^{\\oplus}$\non $2n$ bits, (defined as $f^{\\oplus}(x,y)=f(x\\oplus y)$) is at most polynomial\nin logarithm of the sparsity of $f$ (denoted by $\\sp(f)$). A recent result of\nLin and Zhang (2017) implies that to confirm the above conjectures it suffices\nto upper bound alternation of $f$ (denoted $\\al(f)$) for all Boolean functions\n$f$ by polynomial in $\\s(f)$ and logarithm of $\\sp(f)$, respectively. In this\ncontext, we show the following :\n  * There exists a family of Boolean functions for which $\\al(f)$ is at least\nexponential in $\\s(f)$ and $\\al(f)$ is at least exponential in $\\log \\sp(f)$.\nEn route to the proof, we also show an exponential gap between $\\al(f)$ and the\ndecision tree complexity of $f$, which might be of independent interest.\n  * As our main result, we show that, despite the above gap between $\\al(f)$\nand $\\log \\sp(f)$, the XOR Log-Rank Conjecture is true for functions with the\nalternation upper bounded by $poly(\\log n)$. It is easy to observe that the\nSensitivity Conjecture is also true for this class of functions.\n  * The starting point for the above result is the observation (derived from\nLin and Zhang (2017)) that for any Boolean function $f$ and $m \\ge 2$,\n$deg(f)\\le \\al(f)deg_2(f)deg_m(f)$ where $deg(f)$, $deg_2(f)$ and $deg_m(f)$\nare the degrees of $f$ over $\\mathbb{R}$, $\\mathbb{F}_2$ and $\\mathbb{Z}_m$\nrespectively. We also show three further applications of this observation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 16:27:26 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 13:42:38 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Dinesh", "Krishnamoorthy", ""], ["Sarma", "Jayalal", ""]]}, {"id": "1712.05766", "submitter": "Ralph Christian Bottesch", "authors": "Ralph C. Bottesch", "title": "On W[1]-Hardness as Evidence for Intractability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central conjecture of parameterized complexity states that FPT is not\nequal to W[1], and is generally regarded as the parameterized counterpart to P\n!= NP. We revisit the issue of the plausibility of FPT != W[1], focusing on two\naspects: the difficulty of proving the conjecture (assuming it holds), and how\nthe relation between the two classes might differ from the one between P and\nNP.\n  Regarding the first aspect, we give new evidence that separating FPT from\nW[1] would be considerably harder than doing the same for P and NP. Our main\nresult regarding the relation between FPT and W[1] states that the closure of\nW[1] under relativization with FPT-oracles is precisely the class W[P],\nimplying that either FPT is not low for W[1], or the W-Hierarchy collapses.\nThis theorem also has consequences for the A-Hierarchy (a parameterized version\nof the Polynomial Hierarchy), namely that unless W[P] is a subset of some level\nA[t], there are structural differences between the A-Hierarchy and the\nPolynomial Hierarchy. We also prove that under the unlikely assumption that\nW[P] collapses to W[1] in a specific way, the collapse of any two consecutive\nlevels of the A-Hierarchy implies the collapse of the entire hierarchy to a\nfinite level; this extends a result of Chen, Flum, and Grohe (2005).\n  Finally, we give weak (oracle-based) evidence that the inclusion of W[t] in\nA[t] is strict for t>1, and that the W-Hierarchy is proper. The latter result\nanswers a question of Downey and Fellows (1993).\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 17:47:59 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 16:47:04 GMT"}, {"version": "v3", "created": "Thu, 19 Jul 2018 11:09:58 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Bottesch", "Ralph C.", ""]]}, {"id": "1712.05880", "submitter": "Tianyu Liu", "authors": "Jin-Yi Cai, Tianyu Liu, Pinyan Lu", "title": "Approximability of the Six-vertex Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we take the first step toward a classification of the\napproximation complexity of the six-vertex model, an object of extensive\nresearch in statistical physics. Our complexity results conform to the phase\ntransition phenomenon from physics. We show that the approximation complexity\nof the six-vertex model behaves dramatically differently on the two sides\nseparated by the phase transition threshold. Furthermore, we present structural\nproperties of the six-vertex model on planar graphs for parameter settings that\nhave known relations to the Tutte polynomial $T(G, x, y)$.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 00:16:00 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Liu", "Tianyu", ""], ["Lu", "Pinyan", ""]]}, {"id": "1712.06239", "submitter": "Xiao-Shan Gao", "authors": "Yu-Ao Chen and Xiao-Shan Gao", "title": "Quantum Algorithms for Boolean Equation Solving and Quantum Algebraic\n  Attack on Cryptosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision of whether a Boolean equation system has a solution is an NPC\nproblem and finding a solution is NP hard. In this paper, we present a quantum\nalgorithm to decide whether a Boolean equation system FS has a solution and\ncompute one if FS does have solutions with any given success probability. The\nruntime complexity of the algorithm is polynomial in the size of FS and the\ncondition number of FS. As a consequence, we give a polynomial-time quantum\nalgorithm for solving Boolean equation systems if their condition numbers are\nsmall, say polynomial in the size of FS. We apply our quantum algorithm for\nsolving Boolean equations to the cryptanalysis of several important\ncryptosystems: the stream cipher Trivum, the block cipher AES, the hash\nfunction SHA-3/Keccak, and the multivariate public key cryptosystems, and show\nthat they are secure under quantum algebraic attack only if the condition\nnumbers of the corresponding equation systems are large. This leads to a new\ncriterion for designing cryptosystems that can against the attack of quantum\ncomputers: their corresponding equation systems must have large condition\nnumbers.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 03:34:10 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 09:17:31 GMT"}, {"version": "v3", "created": "Mon, 6 Aug 2018 02:33:16 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Chen", "Yu-Ao", ""], ["Gao", "Xiao-Shan", ""]]}, {"id": "1712.06309", "submitter": "Dmitry Gribanov", "authors": "D.V. Gribanov, D.S. Malyshev, P.M. Pardalos, S.I. Veselov", "title": "FPT-algorithms for some problems related to integer programming", "comments": "arXiv admin note: text overlap with arXiv:1710.00321 From author:\n  some minor corrections has been done", "journal-ref": "J Comb Optim (2018) 35: 1128", "doi": "10.1007/s10878-018-0264-z", "report-no": null, "categories": "math.OC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present FPT-algorithms for special cases of the shortest\nlattice vector, integer linear programming, and simplex width computation\nproblems, when matrices included in the problems' formulations are near square.\nThe parameter is the maximum absolute value of rank minors of the corresponding\nmatrices. Additionally, we present FPT-algorithms with respect to the same\nparameter for the problems, when the matrices have no singular rank\nsub-matrices.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 09:30:12 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 04:37:37 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Gribanov", "D. V.", ""], ["Malyshev", "D. S.", ""], ["Pardalos", "P. M.", ""], ["Veselov", "S. I.", ""]]}, {"id": "1712.06349", "submitter": "Andris Ambainis", "authors": "Andris Ambainis", "title": "Understanding Quantum Algorithms via Query Complexity", "comments": "20 page survey of recent results, for Proceedings of International\n  Congress of Mathematicians'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query complexity is a model of computation in which we have to compute a\nfunction $f(x_1, \\ldots, x_N)$ of variables $x_i$ which can be accessed via\nqueries. The complexity of an algorithm is measured by the number of queries\nthat it makes. Query complexity is widely used for studying quantum algorithms,\nfor two reasons. First, it includes many of the known quantum algorithms\n(including Grover's quantum search and a key subroutine of Shor's factoring\nalgorithm). Second, one can prove lower bounds on the query complexity,\nbounding the possible quantum advantage. In the last few years, there have been\nmajor advances on several longstanding problems in the query complexity. In\nthis talk, we survey these results and related work, including:\n  - the biggest quantum-vs-classical gap for partial functions (a problem\nsolvable with 1 query quantumly but requiring $\\Omega(\\sqrt{N})$ queries\nclassically);\n  - the biggest quantum-vs-determistic and quantum-vs-probabilistic gaps for\ntotal functions (for example, a problem solvable with $M$ queries quantumly but\nrequiring $\\tilde{\\Omega}(M^{2.5})$ queries probabilistically);\n  - the biggest probabilistic-vs-deterministic gap for total functions (a\nproblem solvable with $M$ queries probabilistically but requiring\n$\\tilde{\\Omega}(M^{2})$ queries deterministically);\n  - the bounds on the gap that can be achieved for subclasses of functions (for\nexample, symmetric functions);\n  - the connections between query algorithms and approximations by low-degree\npolynomials.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 11:36:40 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Ambainis", "Andris", ""]]}, {"id": "1712.07246", "submitter": "Josh Alman", "authors": "Josh Alman and Virginia Vassilevska Williams", "title": "Further limitations of the known approaches for matrix multiplication", "comments": "16 pages. To appear in 9th Innovations in Theoretical Computer\n  Science Conference (ITCS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the techniques behind the current best algorithms for matrix\nmultiplication. Our results are threefold.\n  (1) We provide a unifying framework, showing that all known matrix\nmultiplication running times since 1986 can be achieved from a single very\nnatural tensor - the structural tensor $T_q$ of addition modulo an integer $q$.\n  (2) We show that if one applies a generalization of the known techniques\n(arbitrary zeroing out of tensor powers to obtain independent matrix products\nin order to use the asymptotic sum inequality of Sch\\\"{o}nhage) to an arbitrary\nmonomial degeneration of $T_q$, then there is an explicit lower bound,\ndepending on $q$, on the bound on the matrix multiplication exponent $\\omega$\nthat one can achieve. We also show upper bounds on the value $\\alpha$ that one\ncan achieve, where $\\alpha$ is such that $n\\times n^\\alpha \\times n$ matrix\nmultiplication can be computed in $n^{2+o(1)}$ time.\n  (3) We show that our lower bound on $\\omega$ approaches $2$ as $q$ goes to\ninfinity. This suggests a promising approach to improving the bound on\n$\\omega$: for variable $q$, find a monomial degeneration of $T_q$ which, using\nthe known techniques, produces an upper bound on $\\omega$ as a function of $q$.\nThen, take $q$ to infinity. It is not ruled out, and hence possible, that one\ncan obtain $\\omega=2$ in this way.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 22:40:49 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Alman", "Josh", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "1712.07276", "submitter": "Friederike Anna Dziemba", "authors": "Friederike Anna Dziemba", "title": "Uniform Diagonalization Theorem for Complexity Classes of Promise\n  Problems including Randomized and Quantum Classes", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagonalization in the spirit of Cantor's diagonal arguments is a widely used\ntool in theoretical computer sciences to obtain structural results about\ncomputational problems and complexity classes by indirect proofs. The Uniform\nDiagonalization Theorem allows the construction of problems outside complexity\nclasses while still being reducible to a specific decision problem. This paper\nprovides a generalization of the Uniform Diagonalization Theorem by extending\nit to promise problems and the complexity classes they form, e.g. randomized\nand quantum complexity classes. The theorem requires from the underlying\ncomputing model not only the decidability of its acceptance and rejection\nbehaviour but also of its promise-contradicting indifferent behaviour - a\nproperty that we will introduce as \"total decidability\" of promise problems.\n  Implications of the Uniform Diagonalization Theorem are mainly of two kinds:\n1. Existence of intermediate problems (e.g. between BQP and QMA) - also known\nas Ladner's Theorem - and 2. Undecidability if a problem of a complexity class\nis contained in a subclass (e.g. membership of a QMA-problem in BQP). Like the\noriginal Uniform Diagonalization Theorem the extension applies besides BQP and\nQMA to a large variety of complexity class pairs, including combinations from\ndeterministic, randomized and quantum classes.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 00:28:19 GMT"}, {"version": "v2", "created": "Sun, 14 Jan 2018 12:11:16 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 15:29:38 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Dziemba", "Friederike Anna", ""]]}, {"id": "1712.07476", "submitter": "Renato Portugal", "authors": "A. Abreu, L. Cunha, T. Fernandes, C. de Figueiredo, L. Kowada, F.\n  Marquezino, D. Posner, R. Portugal", "title": "The graph tessellation cover number: extremal bounds, efficient\n  algorithms and hardness", "comments": "13 pages, 5 figs, accepted in Latin 2018", "journal-ref": "Theoretical Computer Science 801, 175-191, 2020", "doi": "10.1016/j.tcs.2019.09.013", "report-no": null, "categories": "cs.DM cs.CC math.CO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tessellation of a graph is a partition of its vertices into vertex disjoint\ncliques. A tessellation cover of a graph is a set of tessellations that covers\nall of its edges. The $t$-tessellability problem aims to decide whether there\nis a tessellation cover of the graph with $t$ tessellations. This problem is\nmotivated by its applications to quantum walk models, in especial, the\nevolution operator of the staggered model is obtained from a graph tessellation\ncover. We establish upper bounds on the tessellation cover number given by the\nminimum between the chromatic index of the graph and the chromatic number of\nits clique graph and we show graph classes for which these bounds are tight. We\nprove $\\mathcal{NP}$-completeness for $t$-tessellability if the instance is\nrestricted to planar graphs, chordal (2,1)-graphs, (1,2)-graphs, diamond-free\ngraphs with diameter five, or for any fixed $t$ at least 3. On the other hand,\nwe improve the complexity for 2-tessellability to a linear-time algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 13:32:29 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Abreu", "A.", ""], ["Cunha", "L.", ""], ["Fernandes", "T.", ""], ["de Figueiredo", "C.", ""], ["Kowada", "L.", ""], ["Marquezino", "F.", ""], ["Posner", "D.", ""], ["Portugal", "R.", ""]]}, {"id": "1712.07880", "submitter": "Markus Kr\\\"oll", "authors": "Nofar Carmeli and Markus Kr\\\"oll", "title": "Enumeration Complexity of Conjunctive Queries with Functional\n  Dependencies", "comments": "Full version of an article to be published in ICDT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of enumerating the answers of Conjunctive Queries\n(CQs) in the presence of Functional Dependencies (FDs). Our focus is on the\nability to list output tuples with a constant delay in between, following a\nlinear-time preprocessing. A known dichotomy classifies the acyclic\nself-join-free CQs into those that admit such enumeration, and those that do\nnot. However, this classification no longer holds in the common case where the\ndatabase exhibits dependencies among attributes. That is, some queries that are\nclassified as hard are in fact tractable if dependencies are accounted for. We\nestablish a generalization of the dichotomy to accommodate FDs; hence, our\nclassification determines which combination of a CQ and a set of FDs admits\nconstant-delay enumeration with a linear-time preprocessing.\n  In addition, we generalize a hardness result for cyclic CQs to accommodate a\ncommon type of FDs. Further conclusions of our development include a dichotomy\nfor enumeration with linear delay, and a dichotomy for CQs with disequalities.\nFinally, we show that all our results apply to the known class of \"cardinality\ndependencies\" that generalize FDs (e.g., by stating an upper bound on the\nnumber of genres per movies, or friends per person).\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 11:15:55 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Carmeli", "Nofar", ""], ["Kr\u00f6ll", "Markus", ""]]}, {"id": "1712.08362", "submitter": "Daniel Paulusma", "authors": "Matthew Johnson and Giacomo Paesani and Daniel Paulusma", "title": "Connected Vertex Cover for $(sP_1+P_5)$-Free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Connected Vertex Cover problem is to decide if a graph G has a vertex\ncover of size at most $k$ that induces a connected subgraph of $G$. This is a\nwell-studied problem, known to be NP-complete for restricted graph classes,\nand, in particular, for $H$-free graphs if $H$ is not a linear forest (a graph\nis $H$-free if it does not contain $H$ as an induced subgraph). It is easy to\nsee that Connected Vertex Cover is polynomial-time solvable for $P_4$-free\ngraphs. We continue the search for tractable graph classes: we prove that it is\nalso polynomial-time solvable for $(sP_1+P_5)$-free graphs for every integer\n$s\\geq 0$.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 09:18:52 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 14:43:30 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2018 16:37:04 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Johnson", "Matthew", ""], ["Paesani", "Giacomo", ""], ["Paulusma", "Daniel", ""]]}, {"id": "1712.08373", "submitter": "Tom\\'a\\v{s} Masa\\v{r}\\'ik", "authors": "Minki Kim, Bernard Lidick\\'y, Tom\\'a\\v{s} Masa\\v{r}\\'ik, Florian\n  Pfender", "title": "Notes on complexity of packing coloring", "comments": "9 pages, 2 figures", "journal-ref": "Information Processing Letters 137 (2018) 6-10", "doi": "10.1016/j.ipl.2018.04.012", "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A packing $k$-coloring for some integer $k$ of a graph $G=(V,E)$ is a mapping\n  $\\varphi:V\\to\\{1,\\ldots,k\\}$ such that any two vertices $u, v$ of color\n$\\varphi(u)=\\varphi(v)$ are in distance at least $\\varphi(u)+1$. This concept\nis motivated by frequency assignment problems. The \\emph{packing chromatic\nnumber} of $G$ is the smallest $k$ such that there exists a packing\n$k$-coloring of $G$.\n  Fiala and Golovach showed that determining the packing chromatic number for\nchordal graphs is \\NP-complete for diameter exactly 5. While the problem is\neasy to solve for diameter 2, we show \\NP-completeness for any diameter at\nleast 3. Our reduction also shows that the packing chromatic number is hard to\napproximate within $n^{{1/2}-\\varepsilon}$ for any $\\varepsilon > 0$.\n  In addition, we design an \\FPT algorithm for interval graphs of bounded\ndiameter. This leads us to exploring the problem of finding a partial coloring\nthat maximizes the number of colored vertices.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 10:00:07 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Kim", "Minki", ""], ["Lidick\u00fd", "Bernard", ""], ["Masa\u0159\u00edk", "Tom\u00e1\u0161", ""], ["Pfender", "Florian", ""]]}, {"id": "1712.08749", "submitter": "Maxime Crochemore", "authors": "Maxime Crochemore and Luis M. S. Russo", "title": "Cartesian trees and Lyndon trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article describes the structural and algorithmic relations between\nCartesian trees and Lyndon Trees. This leads to a uniform presentation of the\nLyndon table of a word corresponding to the Next Nearest Smaller table of a\nsequence of numbers. It shows how to efficiently compute runs, that is, maximal\nperiodicities occurring in a word.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 10:01:09 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Crochemore", "Maxime", ""], ["Russo", "Luis M. S.", ""]]}, {"id": "1712.08939", "submitter": "Sebastian Skritek", "authors": "Stefan Mengel, Sebastian Skritek", "title": "On tractable query evaluation for SPARQL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite much work within the last decade on foundational properties of SPARQL\n- the standard query language for RDF data - rather little is known about the\nexact limits of tractability for this language. In particular, this is the case\nfor SPARQL queries that contain the OPTIONAL-operator, even though it is one of\nthe most intensively studied features of SPARQL. The aim of our work is to\nprovide a more thorough picture of tractable classes of SPARQL queries.\n  In general, SPARQL query evaluation is PSPACE-complete in combined\ncomplexity, and it remains PSPACE-hard already for queries containing only the\nOPTIONAL-operator. To amend this situation, research has focused on\n\"well-designed SPARQL queries\" and their recent generalization \"weakly\nwell-designed SPARQL queries\". For these two fragments the evaluation problem\nis coNP-complete in the absence of projection and SigmaP2-complete otherwise.\nMoreover, they have been shown to contain most SPARQL queries asked in\npractical settings.\n  In this paper, we study tractable classes of weakly well-designed queries in\nparameterized complexity considering the equivalent formulation as pattern\ntrees. We give a complete characterization of the tractable classes in the case\nwithout projection. Moreover, we show a characterization of all tractable\nclasses of simple well-designed pattern trees in the presence of projection.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 15:40:08 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Mengel", "Stefan", ""], ["Skritek", "Sebastian", ""]]}, {"id": "1712.09617", "submitter": "Sevag Gharibian", "authors": "Marco Aldi, Niel de Beaudrap, Sevag Gharibian, Seyran Saeedi", "title": "On efficiently solvable cases of Quantum k-SAT", "comments": "50 pages, 19 figures, comments welcome. v2: added explicit runtime\n  analysis for parameterized algorithm, and a family of hypergraphs on which\n  the algorithm achieves an exponential speedup over brute force\n  diagonalization. v3: Long published journal version (CMP 2021, open access)", "journal-ref": "Communications in Mathematical Physics, vol 381, 209-256 (2021).\n  Short version in Proceedings of 43rd International Symposium on Mathematical\n  Foundations of Computer Science (MFCS 2018)", "doi": "10.1007/s00220-020-03843-9", "report-no": null, "categories": "quant-ph cs.CC math.AG math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The constraint satisfaction problems k-SAT and Quantum k-SAT (k-QSAT) are\ncanonical NP-complete and QMA_1-complete problems (for k>=3), respectively,\nwhere QMA_1 is a quantum generalization of NP with one-sided error. Whereas\nk-SAT has been well-studied for special tractable cases, as well as from a\nparameterized complexity perspective, much less is known in similar settings\nfor k-QSAT. Here, we study the open problem of computing satisfying assignments\nto k-QSAT instances which have a \"matching\" or \"dimer covering\"; this is an NP\nproblem whose decision variant is trivial, but whose search complexity remains\nopen.\n  Our results fall into three directions, all of which relate to the \"matching\"\nsetting: (1) We give a polynomial-time classical algorithm for k-QSAT when all\nqubits occur in at most two clauses. (2) We give a parameterized algorithm for\nk-QSAT instances from a certain non-trivial class, which allows us to obtain\nexponential speedups over brute force methods in some cases. This is achieved\nby reducing the problem to solving for a single root of a single univariate\npolynomial. (3) We conduct a structural graph theoretic study of 3-QSAT\ninteraction graphs which have a \"matching\". We remark that the results of (2),\nin particular, introduce a number of new tools to the study of Quantum SAT,\nincluding graph theoretic concepts such as transfer filtrations and blow-ups\nfrom algebraic geometry.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 16:34:48 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 20:44:41 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 08:25:05 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Aldi", "Marco", ""], ["de Beaudrap", "Niel", ""], ["Gharibian", "Sevag", ""], ["Saeedi", "Seyran", ""]]}, {"id": "1712.09619", "submitter": "Abdolah Sepahvand", "authors": "Mohammadreza Razzazi, Abdolah Sepahvand", "title": "Finding Two Disjoint Simple Paths on Two Sets of Points is NP-Complete", "comments": null, "journal-ref": "scientiairanica.sharif.edu/article_4116.html 2017", "doi": "10.24200/SCI.2017.4116", "report-no": null, "categories": "cs.CC cs.CG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Finding two disjoint simple paths on two given sets of points is a geometric\nproblem introduced by Jeff Erickson. This problem has various applications in\ncomputational geometry, like robot motion planning, generating polygon etc. We\nwill present a reduction from planar Hamiltonian path to this problem, and\nprove that it is NP-Complete. To the best of our knowledge, no study has\nconsidered its complexity up until now. We also present a reduction from planar\nHamiltonian path problem to the problem of finding a path on given points in\nthe presence of arbitrary obstacles and prove that it is NP-Complete too. Also,\nwe present a heuristic algorithm with time complexity of O(n4) to solve this\nproblem. The proposed algorithm first calculates the convex hull for each of\nthe entry points and then produces two simple paths on the two entry point sets\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 16:36:50 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Razzazi", "Mohammadreza", ""], ["Sepahvand", "Abdolah", ""]]}, {"id": "1712.09630", "submitter": "Per Austrin", "authors": "Per Austrin, Petteri Kaski and Kaie Kubjas", "title": "Tensor network complexity of multilinear maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study tensor networks as a model of arithmetic computation for evaluating\nmultilinear maps. These capture any algorithm based on low border rank tensor\ndecompositions, such as $O(n^{\\omega+\\epsilon})$ time matrix multiplication,\nand in addition many other algorithms such as $O(n \\log n)$ time discrete\nFourier transform and $O^*(2^n)$ time for computing the permanent of a matrix.\nHowever tensor networks sometimes yield faster algorithms than those that\nfollow from low-rank decompositions. For instance the fastest known\n$O(n^{(\\omega +\\epsilon)t})$ time algorithms for counting $3t$-cliques can be\nimplemented with tensor networks, even though the underlying tensor has border\nrank $n^{3t}$ for all $t \\ge 2$. For counting homomorphisms of a general\npattern graph $P$ into a host graph on $n$ vertices we obtain an upper bound of\n$O(n^{(\\omega+\\epsilon)\\operatorname{bw}(P)/2})$ where $\\operatorname{bw}(P)$\nis the branchwidth of $P$. This essentially matches the bound for counting\ncliques, and yields small improvements over previous algorithms for many\nchoices of $P$.\n  While powerful, the model still has limitations, and we are able to show a\nnumber of unconditional lower bounds for various multilinear maps, including:\n  (a) an $\\Omega(n^{\\operatorname{bw}(P)})$ time lower bound for counting\nhomomorphisms from $P$ to an $n$-vertex graph, matching the upper bound if\n$\\omega = 2$. In particular for $P$ a $v$-clique this yields an\n$\\Omega(n^{\\lceil 2v/3 \\rceil})$ time lower bound for counting $v$-cliques, and\nfor $P$ a $k$-uniform $v$-hyperclique we obtain an $\\Omega(n^v)$ time lower\nbound for $k \\ge 3$, ruling out tensor networks as an approach to obtaining\nnon-trivial algorithms for hyperclique counting and the Max-$3$-CSP problem.\n  (b) an $\\Omega(2^{0.918n})$ time lower bound for the permanent of an $n\n\\times n$ matrix.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 17:03:56 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 11:24:27 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 12:36:55 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Austrin", "Per", ""], ["Kaski", "Petteri", ""], ["Kubjas", "Kaie", ""]]}, {"id": "1712.09710", "submitter": "Laurent Bienvenu", "authors": "Laurent Bienvenu and Rod Downey", "title": "On low for speed oracles", "comments": "A preliminary version of this paper was published in the proceedings\n  of the STACS 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Relativizing computations of Turing machines to an oracle is a central\nconcept in the theory of computation, both in complexity theory and in\ncomputability theory(!). Inspired by lowness notions from computability theory,\nAllender introduced the concept of \"low for speed\" oracles. An oracle A is low\nfor speed if relativizing to A has essentially no effect on computational\ncomplexity, meaning that if a decidable language can be decided in time $f(n)$\nwith access to oracle A, then it can be decided in time poly(f(n)) without any\noracle. The existence of non-computable such A's was later proven by Bayer and\nSlaman, who even constructed a computably enumerable one, and exhibited a\nnumber of properties of these oracles as well as interesting connections with\ncomputability theory. In this paper, we pursue this line of research, answering\nthe questions left by Bayer and Slaman and give further evidence that the\nstructure of the class of low for speed oracles is a very rich one.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 23:27:47 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Bienvenu", "Laurent", ""], ["Downey", "Rod", ""]]}, {"id": "1712.09738", "submitter": "Neng Huang", "authors": "Xiaoyu He, Neng Huang, Xiaoming Sun", "title": "On the Decision Tree Complexity of String Matching", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String matching is one of the most fundamental problems in computer science.\nA natural problem is to determine the number of characters that need to be\nqueried (i.e. the decision tree complexity) in a string in order to decide\nwhether this string contains a certain pattern. Rivest showed that for every\npattern $p$, in the worst case any deterministic algorithm needs to query at\nleast $n-|p|+1$ characters, where $n$ is the length of the string and $|p|$ is\nthe length of the pattern. He further conjectured that this bound is tight. By\nusing the adversary method, Tuza disproved this conjecture and showed that more\nthan one half of binary patterns are {\\em evasive}, i.e. any algorithm needs to\nquery all the characters (see Section 1.1 for more details).\n  In this paper, we give a query algorithm which settles the decision tree\ncomplexity of string matching except for a negligible fraction of patterns. Our\nalgorithm shows that Tuza's criteria of evasive patterns are almost complete.\nUsing the algebraic approach of Rivest and Vuillemin, we also give a new\nsufficient condition for the evasiveness of patterns, which is beyond Tuza's\ncriteria. In addition, our result reveals an interesting connection to\n\\emph{Skolem's Problem} in mathematics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 02:17:49 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 11:33:31 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["He", "Xiaoyu", ""], ["Huang", "Neng", ""], ["Sun", "Xiaoming", ""]]}, {"id": "1712.09967", "submitter": "Michael A. Forbes", "authors": "Michael A. Forbes and Amir Shpilka", "title": "A PSPACE Construction of a Hitting Set for the Closure of Small\n  Algebraic Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the complexity of constructing a hitting set for the\nclosure of VP, the class of polynomials that can be infinitesimally\napproximated by polynomials that are computed by polynomial sized algebraic\ncircuits, over the real or complex numbers. Specifically, we show that there is\na PSPACE algorithm that given n,s,r in unary outputs a set of n-tuples over the\nrationals of size poly(n,s,r), with poly(n,s,r) bit complexity, that hits all\nn-variate polynomials of degree-r that are the limit of size-s algebraic\ncircuits. Previously it was known that a random set of this size is a hitting\nset, but a construction that is certified to work was only known in EXPSPACE\n(or EXPH assuming the generalized Riemann hypothesis). As a corollary we get\nthat a host of other algebraic problems such as Noether Normalization Lemma,\ncan also be solved in PSPACE deterministically, where earlier only randomized\nalgorithms and EXPSPACE algorithms (or EXPH assuming the generalized Riemann\nhypothesis) were known.\n  The proof relies on the new notion of a robust hitting set which is a set of\ninputs such that any nonzero polynomial that can be computed by a polynomial\nsize algebraic circuit, evaluates to a not too small value on at least one\nelement of the set. Proving the existence of such a robust hitting set is the\nmain technical difficulty in the proof.\n  Our proof uses anti-concentration results for polynomials, basic tools from\nalgebraic geometry and the existential theory of the reals.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 18:23:01 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Forbes", "Michael A.", ""], ["Shpilka", "Amir", ""]]}, {"id": "1712.10052", "submitter": "Anand Kumar Narayanan", "authors": "Anand Kumar Narayanan and Matthew Weidner", "title": "Subquadratic time encodable codes beating the Gilbert-Varshamov bound", "comments": null, "journal-ref": null, "doi": "10.1109/TIT.2019.2930538", "report-no": null, "categories": "cs.IT cs.CC math.IT math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct explicit algebraic geometry codes built from the\nGarcia-Stichtenoth function field tower beating the Gilbert-Varshamov bound for\nalphabet sizes at least 192. Messages are identied with functions in certain\nRiemann-Roch spaces associated with divisors supported on multiple places.\nEncoding amounts to evaluating these functions at degree one places. By\nexploiting algebraic structures particular to the Garcia-Stichtenoth tower, we\ndevise an intricate deterministic \\omega/2 < 1.19 runtime exponent encoding and\n1+\\omega/2 < 2.19 expected runtime exponent randomized (unique and list)\ndecoding algorithms. Here \\omega < 2.373 is the matrix multiplication exponent.\nIf \\omega = 2, as widely believed, the encoding and decoding runtimes are\nrespectively nearly linear and nearly quadratic. Prior to this work, encoding\n(resp. decoding) time of code families beating the Gilbert-Varshamov bound were\nquadratic (resp. cubic) or worse.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 20:47:00 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 02:44:15 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Narayanan", "Anand Kumar", ""], ["Weidner", "Matthew", ""]]}, {"id": "1712.10194", "submitter": "Aleksandrs Belovs", "authors": "Aleksandrs Belovs and Ansis Rosmanis", "title": "Quantum Lower Bounds for Tripartite Versions of the Hidden Shift and the\n  Set Equality Problems", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study quantum query complexity of the following rather\nnatural tripartite generalisations (in the spirit of the 3-sum problem) of the\nhidden shift and the set equality problems, which we call the 3-shift-sum and\nthe 3-matching-sum problems.\n  The 3-shift-sum problem is as follows: given a table of $3\\times n$ elements,\nis it possible to circularly shift its rows so that the sum of the elements in\neach column becomes zero? It is promised that, if this is not the case, then no\n3 elements in the table sum up to zero. The 3-matching-sum problem is defined\nsimilarly, but it is allowed to arbitrarily permute elements within each row.\nFor these problems, we prove lower bounds of $\\Omega(n^{1/3})$ and\n$\\Omega(\\sqrt n)$, respectively. The second lower bound is tight.\n  The lower bounds are proven by a novel application of the dual learning graph\nframework and by using representation-theoretic tools.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 11:54:32 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 10:58:30 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Belovs", "Aleksandrs", ""], ["Rosmanis", "Ansis", ""]]}]