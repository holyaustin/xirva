[{"id": "1303.0041", "submitter": "Barnaby Martin", "authors": "Florent Madelaine and Barnaby Martin", "title": "QCSP on partially reflexive cycles - the wavy line of tractability", "comments": "Extended abstract at CSR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the (non-uniform) quantified constraint satisfaction problem QCSP(H)\nas H ranges over partially reflexive cycles. We obtain a complexity-theoretic\ndichotomy: QCSP(H) is either in NL or is NP-hard. The separating conditions are\nsomewhat esoteric hence the epithet \"wavy line of tractability\".\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 23:18:19 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["Madelaine", "Florent", ""], ["Martin", "Barnaby", ""]]}, {"id": "1303.0084", "submitter": "Michael Forbes", "authors": "Michael A. Forbes and Amir Shpilka", "title": "Explicit Noether Normalization for Simultaneous Conjugation via\n  Polynomial Identity Testing", "comments": "30 pages; updated to reflect that Theorem 4.1 (of the first version)\n  is already known, as pointed out to us by Josh Grochow", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.SC math.AG math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mulmuley recently gave an explicit version of Noether's Normalization lemma\nfor ring of invariants of matrices under simultaneous conjugation, under the\nconjecture that there are deterministic black-box algorithms for polynomial\nidentity testing (PIT). He argued that this gives evidence that constructing\nsuch algorithms for PIT is beyond current techniques. In this work, we show\nthis is not the case. That is, we improve Mulmuley's reduction and\ncorrespondingly weaken the conjecture regarding PIT needed to give explicit\nNoether Normalization. We then observe that the weaker conjecture has recently\nbeen nearly settled by the authors, who gave quasipolynomial size hitting sets\nfor the class of read-once oblivious algebraic branching programs (ROABPs).\nThis gives the desired explicit Noether Normalization unconditionally, up to\nquasipolynomial factors.\n  As a consequence of our proof we give a deterministic parallel\npolynomial-time algorithm for deciding if two matrix tuples have intersecting\norbit closures, under simultaneous conjugation.\n  We also study the strength of conjectures that Mulmuley requires to obtain\nsimilar results as ours. We prove that his conjectures are stronger, in the\nsense that the computational model he needs PIT algorithms for is equivalent to\nthe well-known algebraic branching program (ABP) model, which is provably\nstronger than the ROABP model.\n  Finally, we consider the depth-3 diagonal circuit model as defined by Saxena,\nas PIT algorithms for this model also have implications in Mulmuley's work.\nPrevious work have given quasipolynomial size hitting sets for this model. In\nthis work, we give a much simpler construction of such hitting sets, using\ntechniques of Shpilka and Volkovich.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2013 04:44:00 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2013 05:34:47 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Forbes", "Michael A.", ""], ["Shpilka", "Amir", ""]]}, {"id": "1303.0266", "submitter": "Maria Isabel Herrero", "authors": "Mar\\'ia Isabel Herrero, Gabriela Jeronimo, Juan Sabia", "title": "Elimination for generic sparse polynomial systems", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC cs.SC math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new probabilistic symbolic algorithm that, given a variety\ndefined in an n-dimensional affine space by a generic sparse system with fixed\nsupports, computes the Zariski closure of its projection to an l-dimensional\ncoordinate affine space with l < n. The complexity of the algorithm depends\npolynomially on combinatorial invariants associated to the supports.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2013 20:12:54 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2013 17:20:47 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2014 17:22:58 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Herrero", "Mar\u00eda Isabel", ""], ["Jeronimo", "Gabriela", ""], ["Sabia", "Juan", ""]]}, {"id": "1303.0478", "submitter": "Shenshi Chen", "authors": "Shenshi Chen", "title": "Monomial Testing and Applications", "comments": "17 pages, 4 figures, submitted FAW-AAIM 2013. arXiv admin note:\n  substantial text overlap with arXiv:1302.5898; and text overlap with\n  arXiv:1007.2675, arXiv:1007.2678, arXiv:1007.2673 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we devise two algorithms for the problem of testing\n$q$-monomials of degree $k$ in any multivariate polynomial represented by a\ncircuit, regardless of the primality of $q$. One is an $O^*(2^k)$ time\nrandomized algorithm. The other is an $O^*(12.8^k)$ time deterministic\nalgorithm for the same $q$-monomial testing problem but requiring the\npolynomials to be represented by tree-like circuits. Several applications of\n$q$-monomial testing are also given, including a deterministic $O^*(12.8^{mk})$\nupper bound for the $m$-set $k$-packing problem.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2013 09:11:24 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2013 02:34:39 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Chen", "Shenshi", ""]]}, {"id": "1303.0798", "submitter": "EPTCS", "authors": "Bastien Maubert, Sophie Pinchinat, Laura Bozzelli", "title": "The Complexity of Synthesizing Uniform Strategies", "comments": "In Proceedings SR 2013, arXiv:1303.0071", "journal-ref": "EPTCS 112, 2013, pp. 115-122", "doi": "10.4204/EPTCS.112.17", "report-no": null, "categories": "cs.GT cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate uniformity properties of strategies. These properties involve\nsets of plays in order to express useful constraints on strategies that are not\n\\mu-calculus definable. Typically, we can state that a strategy is\nobservation-based. We propose a formal language to specify uniformity\nproperties, interpreted over two-player turn-based arenas equipped with a\nbinary relation between plays. This way, we capture e.g. games with winning\nconditions expressible in epistemic temporal logic, whose underlying\nequivalence relation between plays reflects the observational capabilities of\nagents (for example, synchronous perfect recall). Our framework naturally\ngeneralizes many other situations from the literature. We establish that the\nproblem of synthesizing strategies under uniformity constraints based on\nregular binary relations between plays is non-elementary complete.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 19:07:11 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Maubert", "Bastien", ""], ["Pinchinat", "Sophie", ""], ["Bozzelli", "Laura", ""]]}, {"id": "1303.1347", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami", "title": "Constant Unary Constraints and Symmetric Real-Weighted Counting\n  Constraint Satisfaction Problems", "comments": "10pt, A4, 21 pages. This is a complete version of the paper (under a\n  slightly concise title) that appeared in the Proceedings of the 23rd\n  International Symposium on Algorithms and Computation (ISAAC 2012), Taipei,\n  Taiwan, December 19-21, 2012, Lecture Notes in Computer Science,\n  Springer-Verlag, vol.7676, pp.237-246, 2012", "journal-ref": "Theory of Computing Systems, vol. 55, pp. 170-201, 2014", "doi": "10.1007/s00224-013-9518-4", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A unary constraint (on the Boolean domain) is a function from {0,1} to the\nset of real numbers. A free use of auxiliary unary constraints given besides\ninput instances has proven to be useful in establishing a complete\nclassification of the computational complexity of approximately solving\nweighted counting Boolean constraint satisfaction problems (or #CSPs). In\nparticular, two special constant unary constraints are a key to an arity\nreduction of arbitrary constraints, sufficient for the desired classification.\nIn an exact counting model, both constant unary constraints are always assumed\nto be available since they can be eliminated efficiently using an arbitrary\nnonempty set of constraints. In contrast, we demonstrate in an approximate\ncounting model, that at least one of them is efficiently approximated and thus\neliminated approximately by a nonempty constraint set. This fact directly leads\nto an efficient construction of polynomial-time randomized\napproximation-preserving Turing reductions (or AP-reductions) from #CSPs with\ndesignated constraints to any given #CSPs composed of symmetric real-valued\nconstraints of arbitrary arities even in the presence of arbitrary extra unary\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2013 15:07:08 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2013 12:35:42 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Yamakami", "Tomoyuki", ""]]}, {"id": "1303.1691", "submitter": "Anja Rey", "authors": "Anja Rey and J\\\"org Rothe", "title": "False-Name Manipulation in Weighted Voting Games is Hard for\n  Probabilistic Polynomial Time", "comments": null, "journal-ref": null, "doi": "10.1613/jair.4293", "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  False-name manipulation refers to the question of whether a player in a\nweighted voting game can increase her power by splitting into several players\nand distributing her weight among these false identities. Analogously to this\nsplitting problem, the beneficial merging problem asks whether a coalition of\nplayers can increase their power in a weighted voting game by merging their\nweights. Aziz et al. [ABEP11] analyze the problem of whether merging or\nsplitting players in weighted voting games is beneficial in terms of the\nShapley-Shubik and the normalized Banzhaf index, and so do Rey and Rothe [RR10]\nfor the probabilistic Banzhaf index. All these results provide merely\nNP-hardness lower bounds for these problems, leaving the question about their\nexact complexity open. For the Shapley--Shubik and the probabilistic Banzhaf\nindex, we raise these lower bounds to hardness for PP, \"probabilistic\npolynomial time\", and provide matching upper bounds for beneficial merging and,\nwhenever the number of false identities is fixed, also for beneficial\nsplitting, thus resolving previous conjectures in the affirmative. It follows\nfrom our results that beneficial merging and splitting for these two power\nindices cannot be solved in NP, unless the polynomial hierarchy collapses,\nwhich is considered highly unlikely.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 14:05:03 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Rey", "Anja", ""], ["Rothe", "J\u00f6rg", ""]]}, {"id": "1303.1717", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami", "title": "Oracle Pushdown Automata, Nondeterministic Reducibilities, and the CFL\n  Hierarchy over the Family of Context-Free Languages", "comments": "This is a complete version of an extended abstract that appeared\n  under a slightly different title in the Proceedings of the 40th International\n  Conference on Current Trends in Theory and Practice of Computer Science\n  (SOFSEM 2014), High Tatras, Slovakia, January 25-30, 2014, Lecture Notes in\n  Computer Science, Springer-Verlag, vol.8327, pp.514-525, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To expand a fundamental theory of context-free languages, we equip\nnondeterministic one-way pushdown automata with additional oracle mechanisms,\nwhich naturally induce various nondeterministic reducibilities among formal\nlanguages. As a natural restriction of NP-reducibility, we introduce a notion\nof many-one CFL reducibility and conduct a ground work to formulate a coherent\nframework for further expositions. Two more powerful reducibilities--bounded\ntruth-table and Turing CFL-reducibilities--are also discussed in comparison.\nThe Turing CFL-reducibility, in particular, helps us introduce an exquisite\nhierarchy, called the CFL hierarchy, built over the family CFL of context-free\nlanguages. For each level of this hierarchy, its basic structural properties\nare proven and three alternative characterizations are presented. The second\nlevel is not included in NC(2) unless NP= NC(2). The first and second levels of\nthe hierarchy are different. The rest of the hierarchy (more strongly, the\nBoolean hierarchy built over each level of the hierarchy) is also infinite\nunless the polynomial hierarchy over NP collapses. This follows from a\ncharacterization of the Boolean hierarchy over the k-th level of the polynomial\nhierarchy in terms of the Boolean hierarchy over the k+1st level of the CFL\nhierarchy using log-space many-one reductions. Similarly, the complexity class\nTheta(k) is related to the closure of the k-th level of the CFL hierarchy under\nlog-space truth-table reductions. We also argue that the CFL hierarchy\ncoincides with a hierarchy over CFL built by application of many-one\nCFL-reductions. We show that BPCFL--a bounded-error probabilistic version of\nCFL--is not included in CFL even in the presence of advice. Employing a known\ncircuit lower bound and a switching lemma, we exhibit a relativized world where\nBPCFL is not located within the second level of the CFL hierarchy.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 15:26:50 GMT"}, {"version": "v2", "created": "Sat, 23 May 2015 18:33:10 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Yamakami", "Tomoyuki", ""]]}, {"id": "1303.1754", "submitter": "Robert Luce", "authors": "Robert Luce, Esmond Ng", "title": "On the minimum FLOPs problem in the sparse Cholesky factorization", "comments": "Fix various spelling errors, move auxiliary proof to appendix, add\n  two figures", "journal-ref": "SIAM. J. Matrix Anal. & Appl. 35-1 (2014), pp. 1-21", "doi": "10.1137/130912438", "report-no": null, "categories": "math.NA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior to computing the Cholesky factorization of a sparse, symmetric positive\ndefinite matrix, a reordering of the rows and columns is computed so as to\nreduce both the number of fill elements in Cholesky factor and the number of\narithmetic operations (FLOPs) in the numerical factorization. These two metrics\nare clearly somehow related and yet it is suspected that these two problems are\ndifferent. However, no rigorous theoretical treatment of the relation of these\ntwo problems seems to have been given yet. In this paper we show by means of an\nexplicit, scalable construction that the two problems are different in a very\nstrict sense. In our construction no ordering, that is optimal for the fill, is\noptimal with respect to the number of FLOPs, and vice versa.\n  Further, it is commonly believed that minimizing the number of FLOPs is no\neasier than minimizing the fill (in the complexity sense), but so far no proof\nappears to be known. We give a reduction chain that shows the NP hardness of\nminimizing the number of arithmetic operations in the Cholesky factorization.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 17:17:47 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2013 15:53:11 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Luce", "Robert", ""], ["Ng", "Esmond", ""]]}, {"id": "1303.1969", "submitter": "Stefan Mengel", "authors": "Stefan Mengel", "title": "Arithmetic Branching Programs with Memory", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the well known characterization of $\\vpws$ as the class of\npolynomials computed by polynomial size arithmetic branching programs to other\ncomplexity classes. In order to do so we add additional memory to the\ncomputation of branching programs to make them more expressive. We show that\nallowing different types of memory in branching programs increases the\ncomputational power even for constant width programs. In particular, this leads\nto very natural and robust characterizations of $\\vp$ and $\\vnp$ by branching\nprograms with memory.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 12:23:55 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Mengel", "Stefan", ""]]}, {"id": "1303.2413", "submitter": "Haijun Zhou", "authors": "Lu-Lu Wu, Hai-Jun Zhou, Mikko Alava, Erik Aurell and Pekka Orponen", "title": "Witness of unsatisfiability for a random 3-satisfiability formula", "comments": "9 pages, 7 figures included. Submitted to Physical Review E", "journal-ref": "Physical Review E 87, 052807 (2013)", "doi": "10.1103/PhysRevE.87.052807", "report-no": null, "categories": "cs.CC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random 3-satisfiability (3-SAT) problem is in the unsatisfiable (UNSAT)\nphase when the clause density $\\alpha$ exceeds a critical value $\\alpha_s\n\\approx 4.267$. However, rigorously proving the unsatisfiability of a given\nlarge 3-SAT instance is extremely difficult. In this paper we apply the\nmean-field theory of statistical physics to the unsatisfiability problem, and\nshow that a specific type of UNSAT witnesses (Feige-Kim-Ofek witnesses) can in\nprinciple be constructed when the clause density $\\alpha > 19$. We then\nconstruct Feige-Kim-Ofek witnesses for single 3-SAT instances through a simple\nrandom sampling algorithm and a focused local search algorithm. The random\nsampling algorithm works only when $\\alpha$ scales at least linearly with the\nvariable number $N$, but the focused local search algorithm works for clause\ndensty $\\alpha > c N^{b}$ with $b \\approx 0.59$ and prefactor $c \\approx 8$.\nThe exponent $b$ can be further decreased by enlarging the single parameter $S$\nof the focused local search algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 02:47:07 GMT"}], "update_date": "2013-07-29", "authors_parsed": [["Wu", "Lu-Lu", ""], ["Zhou", "Hai-Jun", ""], ["Alava", "Mikko", ""], ["Aurell", "Erik", ""], ["Orponen", "Pekka", ""]]}, {"id": "1303.2416", "submitter": "Alexandra Keenan", "authors": "Alexandra Keenan, Robert Schweller, Michael Sherman, Xingsi Zhong", "title": "Fast Arithmetic in Algorithmic Self-Assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the time complexity of computing the sum and\nproduct of two $n$-bit numbers within the tile self-assembly model. The\n(abstract) tile assembly model is a mathematical model of self-assembly in\nwhich system components are square tiles with different glue types assigned to\ntile edges. Assembly is driven by the attachment of singleton tiles to a\ngrowing seed assembly when the net force of glue attraction for a tile exceeds\nsome fixed threshold. Within this frame work, we examine the time complexity of\ncomputing the sum or product of 2 n-bit numbers, where the input numbers are\nencoded in an initial seed assembly, and the output is encoded in the final,\nterminal assembly of the system. We show that the problems of addition and\nmultiplication have worst case lower bounds of $\\Omega(\\sqrt{n})$ in 2D\nassembly, and $\\Omega(\\sqrt[3]{n})$ in 3D assembly. In the case of addition, we\ndesign algorithms for both 2D and 3D that meet this bound with worst case run\ntimes of $O(\\sqrt{n})$ and $O(\\sqrt[3]{n})$ respectively, which beats the\nprevious best known upper bound of O(n). Further, we consider average case\ncomplexity of addition over uniformly distributed n-bit strings and show how to\nachieve $O(\\log n)$ average case time with a simultaneous $O(\\sqrt{n})$ worst\ncase run time in 2D. For multiplication, we present an $O(n^{5/6})$ time\nmultiplication algorithm which works in 3D, which beats the previous best known\nupper bound of O(n). As additional evidence for the speed of our algorithms, we\nimplement our addition algorithms, along with the simpler O(n) time addition\nalgorithm, into a probabilistic run-time simulator and compare the timing\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 03:09:38 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2013 17:43:46 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Keenan", "Alexandra", ""], ["Schweller", "Robert", ""], ["Sherman", "Michael", ""], ["Zhong", "Xingsi", ""]]}, {"id": "1303.2580", "submitter": "Bagram Kochkarev", "authors": "B.S. Kochkarev", "title": "Proof of the hypothesis Edmonds's, not polynomial of NPC-problems and\n  classification of the problems with polynomial certificates", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the affirmation $P\\subseteq NP$ (in computer science)\nerroneously and we prove the justice of the hypotesis J.Edmonds's $P\\neq NP$.\nWe show further that all the $NP$-complete problems is not polynomial and we\ngive the classification of the problems with the polynomial certificates.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 11:24:04 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Kochkarev", "B. S.", ""]]}, {"id": "1303.2974", "submitter": "Ed Blakey", "authors": "Ed Blakey", "title": "Complexity-Style Resources in Cryptography", "comments": "21 pages. 4 figures. To appear in Information and Computation\n  (special issue on Information Security as a Resource)", "journal-ref": "Information and Computation, vol. 226, pp. 3 - 15, 2013", "doi": "10.1016/j.ic.2013.03.002", "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previously, the author has developed a framework within which to quantify and\ncompare the resources consumed during computational-especially unconventional\ncomputational-processes (adding to the familiar resources of run-time and\nmemory space such non-standard resources as precision and energy); it is\nnatural and beneficial in this framework to employ various complexity-theoretic\ntools and techniques. Here, we seek an analogous treatment not of computational\nprocesses but of cryptographic protocols and similar, so as to be able to apply\nthe existing arsenal of complexity-theoretic methods in new ways, in the\nderivation and verification of protocols in a wider, cryptographic context.\nAccordingly, we advocate a framework in which one may view as resources the\ncosts-which may be related to computation, communication, information\n(including side-channel information) or availability of primitives, for\nexample-incurred when executing cryptographic protocols, coin-tossing schemes,\netc. The ultimate aim is to formulate as a resource, and be able to analyse\ncomplexity-theoretically, the security of these protocols and schemes.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 18:14:09 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Blakey", "Ed", ""]]}, {"id": "1303.2981", "submitter": "Ventsislav Chonev", "authors": "Ventsislav Chonev, Jo\\\"el Ouaknine and James Worrell", "title": "On the Complexity of the Orbit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider higher-dimensional versions of Kannan and Lipton's Orbit\nProblem---determining whether a target vector space V may be reached from a\nstarting point x under repeated applications of a linear transformation A.\nAnswering two questions posed by Kannan and Lipton in the 1980s, we show that\nwhen V has dimension one, this problem is solvable in polynomial time, and when\nV has dimension two or three, the problem is in NP^{RP}.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 18:35:29 GMT"}, {"version": "v2", "created": "Sun, 30 Mar 2014 18:26:18 GMT"}, {"version": "v3", "created": "Wed, 22 Jun 2016 12:16:33 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Chonev", "Ventsislav", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Worrell", "James", ""]]}, {"id": "1303.3166", "submitter": "Massimo Lauria", "authors": "Massimo Lauria, Pavel Pudl\\'ak, Vojt\\v{e}ch R\\\"odl and Neil Thapen", "title": "The complexity of proving that a graph is Ramsey", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We say that a graph with $n$ vertices is $c$-Ramsey if it does not contain\neither a clique or an independent set of size $c \\log n$. We define a CNF\nformula which expresses this property for a graph $G$. We show a\nsuperpolynomial lower bound on the length of resolution proofs that $G$ is\n$c$-Ramsey, for every graph $G$. Our proof makes use of the fact that every\nRamsey graph must contain a large subgraph with some of the statistical\nproperties of the random graph.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 14:15:31 GMT"}], "update_date": "2013-03-14", "authors_parsed": [["Lauria", "Massimo", ""], ["Pudl\u00e1k", "Pavel", ""], ["R\u00f6dl", "Vojt\u011bch", ""], ["Thapen", "Neil", ""]]}, {"id": "1303.3708", "submitter": "Trung Van Pham", "authors": "K\\'evin Perrot, Trung Van Pham", "title": "Feedback arc set problem and NP-hardness of minimum recurrent\n  configuration problem of Chip-firing game on directed graphs", "comments": "18 pages, 6 figures", "journal-ref": "Ann. Comb. 19 (2015), no. 2, 373-396", "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present further studies of recurrent configurations of\nChip-firing games on Eulerian directed graphs (simple digraphs), a class on the\nway from undirected graphs to general directed graphs. A computational problem\nthat arises naturally from this model is to find the minimum number of chips of\na recurrent configuration, which we call the minimum recurrent configuration\n(MINREC) problem. We point out a close relationship between MINREC and the\nminimum feedback arc set (MINFAS) problem on Eulerian directed graphs, and\nprove that both problems are NP-hard.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2013 09:07:55 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2013 06:06:38 GMT"}, {"version": "v3", "created": "Fri, 26 Apr 2013 03:05:30 GMT"}, {"version": "v4", "created": "Thu, 16 May 2013 03:26:41 GMT"}, {"version": "v5", "created": "Fri, 30 Aug 2013 02:52:34 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Perrot", "K\u00e9vin", ""], ["Van Pham", "Trung", ""]]}, {"id": "1303.4315", "submitter": "Karunakaran Murali Krishnan", "authors": "Gaurav Sood and K. Murali Krishnan", "title": "On the computational complexity of Data Flow Analysis", "comments": "7 pages 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Data Flow Analysis over monotone data flow\nframeworks with a finite lattice. The problem of computing the Maximum Fixed\nPoint (MFP) solution is shown to be P-complete even when the lattice has just\nfour elements. This shows that the problem is unlikely to be efficiently\nparallelizable. It is also shown that the problem of computing the Meet Over\nall Paths (MOP) solution is NL-complete (and hence efficiently parallelizable)\nwhen the lattice is finite even for non-monotone data flow frameworks. These\nresults appear in contrast with the fact that when the lattice is not finite,\nsolving the MOP problem is undecidable and hence significantly harder than the\nMFP problem which is polynomial time computable for lattices of finite height.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2013 16:44:20 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Sood", "Gaurav", ""], ["Krishnan", "K. Murali", ""]]}, {"id": "1303.4408", "submitter": "Antony Van der Mude", "authors": "Antony Van der Mude", "title": "Computing in the Limit", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a class of functions termed \"Computable in the Limit\", based on the\nMachine Learning paradigm of \"Identification in the Limit\". A function is\nComputable in the Limit if it defines a property P_p of a recursively\nenumerable class A of recursively enumerable data sequences S in A, such that\neach data sequence S is generated by a total recursive function s that\nenumerates . Let the index s represent the data sequence S. The property\nP_p(s)=x is computed by a partial recursive function f_p(s,t) such that there\nexists a u where f_p(s,u)=x and for all t>=u, f_p(s,t)=x if it converges. Since\nthe index s is known, this is not an identification problem - instead it is\ncomputing a common property of the sequences in A. We give a Normal Form\nTheorem for properties that are Computable in the Limit, similar to Kleene's\nNormal Form Theorem. We also give some examples of sets that are Computable in\nthe Limit, and derive some properties of Canonical and Complexity Bound\nEnumerations of classes of total functions, and show that no full enumeration\nof all indices of Turing machines TM_i that compute a given total function can\nbe Computable in the Limit.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2013 20:24:03 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2013 15:40:28 GMT"}, {"version": "v3", "created": "Mon, 5 Sep 2016 18:09:35 GMT"}, {"version": "v4", "created": "Sat, 18 Feb 2017 18:26:44 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Van der Mude", "Antony", ""]]}, {"id": "1303.4443", "submitter": "Mateus de Oliveira Oliveira", "authors": "Mateus de Oliveira Oliveira", "title": "Subgraphs Satisfying MSO Properties on z-Topologically Orderable\n  Digraphs", "comments": "12 pages body, 11 pages of references + appendix + 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of z-topological orderings for digraphs. We prove\nthat given a digraph G on n vertices admitting a z-topological order- ing,\ntogether with such an ordering, one may count the number of subgraphs of G that\nat the same time satisfy a monadic second order formula {\\phi} and are the\nunion of k directed paths, in time f ({\\phi}, k, z) * n^O(k*z) . Our result\nimplies the polynomial time solvability of many natural counting problems on\ndigraphs admitting z-topological orderings for constant values of z and k.\nConcerning the relationship between z-topological orderability and other\ndigraph width measures, we observe that any digraph of directed path-width d\nhas a z- topological ordering for z <= 2d + 1. On the other hand, there are\ndigraphs on n vertices admitting a z-topological order for z = 2, but whose\ndirected path-width is {\\Theta}(log n). Since graphs of bounded directed\npath-width can have both arbitrarily large undirected tree-width and\narbitrarily large clique width, our result provides for the first time a\nsuitable way of partially trans- posing metatheorems developed in the context\nof the monadic second order logic of graphs of constant undirected tree-width\nand constant clique width to the realm of digraph width measures that are\nclosed under taking subgraphs and whose constant levels incorporate families of\ngraphs of arbitrarily large undirected tree-width and arbitrarily large clique\nwidth.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2013 22:09:37 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 18:04:23 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Oliveira", "Mateus de Oliveira", ""]]}, {"id": "1303.5305", "submitter": "Remi Gribonval", "authors": "Andreas M. Tillmann, R\\'emi Gribonval (INRIA - IRISA), Marc E. Pfetsch", "title": "Projection onto the Cosparse Set is NP-Hard", "comments": "to appear in ICASSP 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of a problem arising in the context of sparse\noptimization is considered, namely, the projection onto the set of $k$-cosparse\nvectors w.r.t. some given matrix $\\Omeg$. It is shown that this projection\nproblem is (strongly) \\NP-hard, even in the special cases in which the matrix\n$\\Omeg$ contains only ternary or bipolar coefficients. Interestingly, this is\nin contrast to the projection onto the set of $k$-sparse vectors, which is\ntrivially solved by keeping only the $k$ largest coefficients.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2013 15:42:18 GMT"}, {"version": "v2", "created": "Tue, 11 Mar 2014 15:28:23 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Tillmann", "Andreas M.", "", "INRIA - IRISA"], ["Gribonval", "R\u00e9mi", "", "INRIA - IRISA"], ["Pfetsch", "Marc E.", ""]]}, {"id": "1303.5601", "submitter": "Micha{\\l} Adamaszek", "authors": "Michal Adamaszek", "title": "The smallest nonevasive graph property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A property of n-vertex graphs is called evasive if every algorithm testing\nthis property by asking questions of the form \"is there an edge between\nvertices u and v\" requires, in the worst case, to ask about all pairs of\nvertices. Most \"natural\" graph properties are either evasive or conjectured to\nbe such, and of the few examples of nontrivial nonevasive properties scattered\nin the literature the smallest one has n=6. We exhibit a nontrivial, nonevasive\nproperty of 5-vertex graphs and show that it is essentially the unique such\nwith n at most 5.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2013 12:48:47 GMT"}], "update_date": "2013-03-25", "authors_parsed": [["Adamaszek", "Michal", ""]]}, {"id": "1303.5887", "submitter": "Hector Zenil", "authors": "Hector Zenil", "title": "A Behavioural Foundation for Natural Computing and a Programmability\n  Test", "comments": "37 pages, 4 figures. Based on an invited Talk at the Symposium on\n  Natural/Unconventional Computing and its Philosophical Significance, Alan\n  Turing World Congress 2012, Birmingham, UK.\n  http://link.springer.com/article/10.1007/s13347-012-0095-2 Ref. glitch fixed\n  in 2nd. version; Philosophy & Technology (special issue on History and\n  Philosophy of Computing), Springer, 2013", "journal-ref": null, "doi": "10.1007/s13347-012-0095-2", "report-no": null, "categories": "cs.IT cs.AI cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does it mean to claim that a physical or natural system computes? One\nanswer, endorsed here, is that computing is about programming a system to\nbehave in different ways. This paper offers an account of what it means for a\nphysical system to compute based on this notion. It proposes a behavioural\ncharacterisation of computing in terms of a measure of programmability, which\nreflects a system's ability to react to external stimuli. The proposed measure\nof programmability is useful for classifying computers in terms of the apparent\nalgorithmic complexity of their evolution in time. I make some specific\nproposals in this connection and discuss this approach in the context of other\nbehavioural approaches, notably Turing's test of machine intelligence. I also\nanticipate possible objections and consider the applicability of these\nproposals to the task of relating abstract computation to nature-like\ncomputation.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2013 21:44:08 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 12:02:27 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Zenil", "Hector", ""]]}, {"id": "1303.6129", "submitter": "\\\"Ozlem Salehi", "authors": "\\\"Ozlem Salehi, Abuzer Yakary{\\i}lmaz, A. C. Cem Say", "title": "Real-Time Vector Automata", "comments": "14 pages", "journal-ref": null, "doi": "10.1007/978-3-642-40164-0_28", "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational power of real-time finite automata that have been\naugmented with a vector of dimension k, and programmed to multiply this vector\nat each step by an appropriately selected $k \\times k$ matrix. Only one entry\nof the vector can be tested for equality to 1 at any time. Classes of languages\nrecognized by deterministic, nondeterministic, and \"blind\" versions of these\nmachines are studied and compared with each other, and the associated classes\nfor multicounter automata, automata with multiplication, and generalized finite\nautomata.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 13:48:49 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Salehi", "\u00d6zlem", ""], ["Yakary\u0131lmaz", "Abuzer", ""], ["Say", "A. C. Cem", ""]]}, {"id": "1303.6424", "submitter": "Julian-Steffen M\\\"uller", "authors": "Julian-Steffen M\\\"uller and Heribert Vollmer", "title": "Model Checking for Modal Dependence Logic: An Approach Through Post's\n  Lattice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate an extended version of modal dependence logic by\nallowing arbitrary Boolean connectives. Modal dependence logic was recently\nintroduced by Jouko V\\\"a\\\"an\\\"anen by extending modal logic by a the dependence\natom dep(.). In this paper we study the computational complexity of the model\nchecking problem. For a complete classification of arbitrary Boolean functions\nwe are using a Lattice approach introduced by Emil Post. This classification is\ndone for all fragments of the logical language allowing modalities $\\Diamond$\nand $\\Box$, the dependence atom, and logical symbols for arbitrary Boolean\nfunctions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 10:20:42 GMT"}], "update_date": "2013-03-27", "authors_parsed": [["M\u00fcller", "Julian-Steffen", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1303.6437", "submitter": "Richard Schmied", "authors": "Marek Karpinski, Michael Lampis and Richard Schmied", "title": "New Inapproximability Bounds for TSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the approximability of the metric Traveling Salesman\nProblem (TSP) and prove new explicit inapproximability bounds for that problem.\nThe best up to now known hardness of approximation bounds were 185/184 for the\nsymmetric case (due to Lampis) and 117/116 for the asymmetric case (due to\nPapadimitriou and Vempala). We construct here two new bounded occurrence CSP\nreductions which improve these bounds to 123/122 and 75/74, respectively. The\nlatter bound is the first improvement in more than a decade for the case of the\nasymmetric TSP. One of our main tools, which may be of independent interest, is\na new construction of a bounded degree wheel amplifier used in the proof of our\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 11:23:04 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2013 20:14:43 GMT"}], "update_date": "2013-06-12", "authors_parsed": [["Karpinski", "Marek", ""], ["Lampis", "Michael", ""], ["Schmied", "Richard", ""]]}, {"id": "1303.6555", "submitter": "Victor Marek", "authors": "D. Cenzer, V.W. Marek and J.B. Remmel", "title": "Index sets for Finite Normal Predicate Logic Programs", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  <Q>_e is the effective list of all finite predicate logic programs. <T_e> is\nthe list of recursive trees. We modify constructions of Marek, Nerode, and\nRemmel [25] to construct recursive functions f and g such that for all indices\ne, (i) there is a one-to-one degree preserving correspondence between the set\nof stable models of Q_e and the set of infinite paths through T_{f(e)} and (ii)\nthere is a one-to-one degree preserving correspondence between the set of\ninfinite paths through T_e and the set of stable models of Q_{g(e)}. We use\nthese two recursive functions to reduce the problem of finding the complexity\nof the index set I_P for various properties P of normal finite predicate logic\nprograms to the problem of computing index sets for primitive recursive trees\nfor which there is a large variety of results [6], [8], [16], [17], [18], [19].\nWe use our correspondences to determine the complexity of the index sets of all\nprograms and of certain special classes of finite predicate logic programs of\nproperties such as (i) having no stable models, (ii) having at least one stable\nmodel, (iii) having exactly c stable models for any given positive integer c,\n(iv) having only finitely many stable models, or (vi) having infinitely many\nstable models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 16:41:25 GMT"}], "update_date": "2013-03-27", "authors_parsed": [["Cenzer", "D.", ""], ["Marek", "V. W.", ""], ["Remmel", "J. B.", ""]]}, {"id": "1303.6729", "submitter": "Aaron Gorenstein", "authors": "Jin-Yi Cai, Aaron Gorenstein", "title": "Matchgates Revisited", "comments": "28 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a collection of concepts and theorems that laid the foundation of\nmatchgate computation. This includes the signature theory of planar matchgates,\nand the parallel theory of characters of not necessarily planar matchgates. Our\naim is to present a unified and, whenever possible, simplified account of this\nchallenging theory. Our results include: (1) A direct proof that Matchgate\nIdentities (MGI) are necessary and sufficient conditions for matchgate\nsignatures. This proof is self-contained and does not go through the character\ntheory. More importantly it rectifies a gap in the existing proof. (2) A proof\nthat Matchgate Identities already imply the Parity Condition. (3) A simplified\nconstruction of a crossover gadget. This is used in the proof of sufficiency of\nMGI for matchgate signatures. This is also used to give a proof of equivalence\nbetween the signature theory and the character theory which permits omittable\nnodes. (4) A direct construction of matchgates realizing all\nmatchgate-realizable symmetric signatures.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 02:29:59 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2013 15:16:30 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Gorenstein", "Aaron", ""]]}, {"id": "1303.7037", "submitter": "Jonathan Spreer", "authors": "Benjamin A. Burton, Thomas Lewiner, Jo\\~ao Paix\\~ao, Jonathan Spreer", "title": "Parameterized Complexity of Discrete Morse Theory", "comments": "To appear in Proceedings of the Twenty-Ninth Annual Symposium on\n  Computational Geometry (SoCG). 25 pages, 8 figures, 2 tables", "journal-ref": "ACM Trans. Math. Softw., 42(1):24 pages, 2016", "doi": "10.1145/2738034", "report-no": null, "categories": "cs.CG cs.CC math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Morse matchings reveal essential structures of cell complexes which\nlead to powerful tools to study discrete geometrical objects, in particular\ndiscrete 3-manifolds. However, such matchings are known to be NP-hard to\ncompute on 3-manifolds, through a reduction to the erasability problem.\n  Here, we refine the study of the complexity of problems related to discrete\nMorse theory in terms of parameterized complexity. On the one hand we prove\nthat the erasability problem is W[P]-complete on the natural parameter. On the\nother hand we propose an algorithm for computing optimal Morse matchings on\ntriangulations of 3-manifolds which is fixed-parameter tractable in the\ntreewidth of the bipartite graph representing the adjacency of the 1- and\n2-simplexes. This algorithm also shows fixed parameter tractability for\nproblems such as erasability and maximum alternating cycle-free matching. We\nfurther show that these results are also true when the treewidth of the dual\ngraph of the triangulated 3-manifold is bounded. Finally, we investigate the\nrespective treewidths of simplicial and generalized triangulations of\n3-manifolds.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 04:49:25 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Burton", "Benjamin A.", ""], ["Lewiner", "Thomas", ""], ["Paix\u00e3o", "Jo\u00e3o", ""], ["Spreer", "Jonathan", ""]]}, {"id": "1303.7122", "submitter": "Fabi\\'an Riquelme", "authors": "Andreas Polym\\'eris and Fabi\\'an Riquelme", "title": "On the Complexity of the Decisive Problem in Simple, Regular and\n  Weighted Games", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of an important property of simple,\nregular and weighted games, which is decisiveness. We show that this concept\ncan naturally be represented in the context of hypergraph theory, and that\ndecisiveness can be decided for simple games in quasi-polynomial time, and for\nregular and weighted games in polynomial time. The strongness condition poses\nthe main difficulties, while properness reduces the complexity of the problem,\nespecially if it is amplified by regularity. On the other hand, regularity also\nallows to specify the problem instances much more economically, implying a\nreconsideration of the corresponding complexity measure that, as we prove, has\nimportant structural as well as algorithmic consequences.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 13:51:25 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2013 11:44:39 GMT"}], "update_date": "2013-07-10", "authors_parsed": [["Polym\u00e9ris", "Andreas", ""], ["Riquelme", "Fabi\u00e1n", ""]]}, {"id": "1303.7328", "submitter": "EPTCS", "authors": "Mauricio Ayala-Rinc\\'on (Universidade de Bras\\'ilia), Maribel\n  Fern\\'andez (King's College London), Daniele Nantes-Sobrinho (Universidade de\n  Bras\\'ilia)", "title": "Elementary Deduction Problem for Locally Stable Theories with Normal\n  Forms", "comments": "In Proceedings LSFA 2012, arXiv:1303.7136", "journal-ref": "EPTCS 113, 2013, pp. 45-60", "doi": "10.4204/EPTCS.113.7", "report-no": null, "categories": "cs.LO cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm to decide the intruder deduction problem (IDP) for a\nclass of locally stable theories enriched with normal forms. Our result relies\non a new and efficient algorithm to solve a restricted case of higher-order\nassociative-commutative matching, obtained by combining the Distinct\nOccurrences of AC- matching algorithm and a standard algorithm to solve systems\nof linear Diophantine equations. A translation between natural deduction and\nsequent calculus allows us to use the same approach to decide the\n\\emphelementary deduction problem for locally stable theories. As an\napplication, we model the theory of blind signatures and derive an algorithm to\ndecide IDP in this context, extending previous decidability results.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 09:01:51 GMT"}], "update_date": "2013-04-01", "authors_parsed": [["Ayala-Rinc\u00f3n", "Mauricio", "", "Universidade de Bras\u00edlia"], ["Fern\u00e1ndez", "Maribel", "", "King's College London"], ["Nantes-Sobrinho", "Daniele", "", "Universidade de\n  Bras\u00edlia"]]}, {"id": "1303.7361", "submitter": "Zhiguo Fu", "authors": "Zhiguo Fu, Fengqin Yang", "title": "Holographaic Alogorithms on Bases of Rank 2", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential problem in the design of holographic algorithms is to decide\nwhether the required signatures can be realized by matchgates under a suitable\nbasis transformation (SRP). For holographic algorithms on domain size 2, [1, 2,\n4, 5] have built a systematical theory. In this paper, we reduce SRP on domain\nsize k>2 to SRP on domain size 2 for holographic algorithms on bases of rank 2.\nFurthermore, we generalize the collapse theorem of [3] to domain size k>2.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 11:03:40 GMT"}], "update_date": "2013-04-01", "authors_parsed": [["Fu", "Zhiguo", ""], ["Yang", "Fengqin", ""]]}, {"id": "1303.7455", "submitter": "Lek-Heng Lim", "authors": "Lek-Heng Lim", "title": "Self-concordance is NP-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an elementary proof of a somewhat curious result, namely, that\ndeciding whether a convex function is self-concordant is in general an\nintractable problem.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 18:37:06 GMT"}], "update_date": "2013-04-01", "authors_parsed": [["Lim", "Lek-Heng", ""]]}]