[{"id": "0906.0205", "submitter": "Forrest Sheng Bao", "authors": "Yuanlin Zhang and Forrest Sheng Bao", "title": "A Survey of Tree Convex Sets Test", "comments": "13 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Tree convex sets refer to a collection of sets such that each set in the\ncollection is a subtree of a tree whose nodes are the elements of these sets.\nThey extend the concept of row convex sets each of which is an interval over a\ntotal ordering of the elements of those sets. They have been applied to\nidentify tractable Constraint Satisfaction Problems and Combinatorial Auction\nProblems. Recently, polynomial algorithms have been proposed to recognize tree\nconvex sets. In this paper, we review the materials that are the key to a\nlinear recognition algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 03:54:42 GMT"}], "update_date": "2009-06-03", "authors_parsed": [["Zhang", "Yuanlin", ""], ["Bao", "Forrest Sheng", ""]]}, {"id": "0906.0687", "submitter": "Olga Holtz", "authors": "Olga Holtz, Noam Shomron", "title": "Computational Complexity and Numerical Stability of Linear Problems", "comments": "16 pages; updated to reflect referees' remarks; to appear in\n  Proceedings of the 5th European Congress of Mathematics", "journal-ref": "European Congress of Mathematics Amsterdam, 14-18 July, 2008, EMS\n  Publishing House, pp. 381-400", "doi": "10.4171/077-1/16", "report-no": null, "categories": "cs.CC cs.DS cs.NA math.HO math.NA math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey classical and recent developments in numerical linear algebra,\nfocusing on two issues: computational complexity, or arithmetic costs, and\nnumerical stability, or performance under roundoff error. We present a brief\naccount of the algebraic complexity theory as well as the general error\nanalysis for matrix multiplication and related problems. We emphasize the\ncentral role played by the matrix multiplication problem and discuss historical\nand modern approaches to its solution.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2009 10:51:40 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2009 00:59:14 GMT"}], "update_date": "2010-06-22", "authors_parsed": [["Holtz", "Olga", ""], ["Shomron", "Noam", ""]]}, {"id": "0906.1084", "submitter": "Arto Annila", "authors": "Arto Annila", "title": "Physical portrayal of computational complexity", "comments": "16, pages, 7 figures", "journal-ref": "ISRN Computational Mathematics 2012 ID: 321372, 1-15", "doi": "10.5402/2012/321372", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational complexity is examined using the principle of increasing\nentropy. To consider computation as a physical process from an initial instance\nto the final acceptance is motivated because many natural processes have been\nrecognized to complete in non-polynomial time (NP). The irreversible process\nwith three or more degrees of freedom is found intractable because, in terms of\nphysics, flows of energy are inseparable from their driving forces. In\ncomputational terms, when solving problems in the class NP, decisions will\naffect subsequently available sets of decisions. The state space of a\nnon-deterministic finite automaton is evolving due to the computation itself\nhence it cannot be efficiently contracted using a deterministic finite\nautomaton that will arrive at a solution in super-polynomial time. The solution\nof the NP problem itself is verifiable in polynomial time (P) because the\ncorresponding state is stationary. Likewise the class P set of states does not\ndepend on computational history hence it can be efficiently contracted to the\naccepting state by a deterministic sequence of dissipative transformations.\nThus it is concluded that the class P set of states is inherently smaller than\nthe set of class NP. Since the computational time to contract a given set is\nproportional to dissipation, the computational complexity class P is a subset\nof NP.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2009 10:56:00 GMT"}], "update_date": "2012-03-20", "authors_parsed": [["Annila", "Arto", ""]]}, {"id": "0906.1226", "submitter": "Jianhua Fan", "authors": "Jorg Peters and Jianhua Fan", "title": "On the Complexity of Smooth Spline Surfaces from Quad Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper derives strong relations that boundary curves of a smooth complex\nof patches have to obey when the patches are computed by local averaging. These\nrelations restrict the choice of reparameterizations for geometric continuity.\nIn particular, when one bicubic tensor-product B-spline patch is associated\nwith each facet of a quadrilateral mesh with n-valent vertices and we do not\nwant segments of the boundary curves forced to be linear, then the relations\ndictate the minimal number and multiplicity of knots: For general data, the\ntensor-product spline patches must have at least two internal double knots per\nedge to be able to model a G^1-conneced complex of C^1 splines. This lower\nbound on the complexity of any construction is proven to be sharp by suitably\ninterpreting an existing surface construction. That is, we have a tight bound\non the complexity of smoothing quad meshes with bicubic tensor-product B-spline\npatches.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2009 22:57:04 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Peters", "Jorg", ""], ["Fan", "Jianhua", ""]]}, {"id": "0906.1370", "submitter": "Emanuele Viola", "authors": "Emanuele Viola", "title": "Cell-Probe Lower Bounds for Prefix Sums", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that to store n bits x so that each prefix-sum query Sum(i) :=\nsum_{k < i} x_k can be answered by non-adaptively probing q cells of log n\nbits, one needs memory > n + n/log^{O(q)} n. Our bound matches a recent upper\nbound of n + n/log^{Omega(q)} n by Patrascu (FOCS 2008), also non-adaptive. We\nalso obtain a n + n/log^{2^{O(q)}} n lower bound for storing a string of\nbalanced brackets so that each Match(i) query can be answered by non-adaptively\nprobing q cells. To obtain these bounds we show that a too efficient data\nstructure allows us to break the correlations between query answers.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2009 17:25:27 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Viola", "Emanuele", ""]]}, {"id": "0906.1399", "submitter": "Alexander A. Sherstov", "authors": "Alexander A. Sherstov", "title": "On Quantum-Classical Equivalence for Composed Communication Problems", "comments": "Journal version", "journal-ref": "Quantum Information & Computation, 10(5-6):435-455, 2010", "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open problem in communication complexity proposed by several authors is to\nprove that for every Boolean function f, the task of computing f(x AND y) has\npolynomially related classical and quantum bounded-error complexities. We solve\na variant of this question. For every f, we prove that the task of computing,\non input x and y, both of the quantities f(x AND y) and f(x OR y) has\npolynomially related classical and quantum bounded-error complexities. We\nfurther show that the quantum bounded-error complexity is polynomially related\nto the classical deterministic complexity and the block sensitivity of f. This\nresult holds regardless of prior entanglement.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2009 01:00:23 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2009 01:58:29 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2010 14:15:33 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Sherstov", "Alexander A.", ""]]}, {"id": "0906.1489", "submitter": "Martin Mundhenk", "authors": "Arne Meier, Martin Mundhenk, Thomas Schneider, Michael Thomas, Volker\n  Weber, Felix Weiss", "title": "The Complexity of Satisfiability for Fragments of Hybrid Logic -- Part I", "comments": null, "journal-ref": null, "doi": "10.1016/j.jal.2010.08.001", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The satisfiability problem of hybrid logics with the downarrow binder is\nknown to be undecidable. This initiated a research program on decidable and\ntractable fragments. In this paper, we investigate the effect of restricting\nthe propositional part of the language on decidability and on the complexity of\nthe satisfiability problem over arbitrary, transitive, total frames, and frames\nbased on equivalence relations. We also consider different sets of modal and\nhybrid operators. We trace the border of decidability and give the precise\ncomplexity of most fragments, in particular for all fragments including\nnegation. For the monotone fragments, we are able to distinguish the easy from\nthe hard cases, depending on the allowed set of operators.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2009 13:17:35 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Meier", "Arne", ""], ["Mundhenk", "Martin", ""], ["Schneider", "Thomas", ""], ["Thomas", "Michael", ""], ["Weber", "Volker", ""], ["Weiss", "Felix", ""]]}, {"id": "0906.1702", "submitter": "Alexander Russell", "authors": "Cristopher Moore and Alexander Russell", "title": "Approximating the Permanent via Nonabelian Determinants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Celebrated work of Jerrum, Sinclair, and Vigoda has established that the\npermanent of a {0,1} matrix can be approximated in randomized polynomial time\nby using a rapidly mixing Markov chain. A separate strand of the literature has\npursued the possibility of an alternate, purely algebraic, polynomial-time\napproximation scheme. These schemes work by replacing each 1 with a random\nelement of an algebra A, and considering the determinant of the resulting\nmatrix. When A is noncommutative, this determinant can be defined in several\nways. We show that for estimators based on the conventional determinant, the\ncritical ratio of the second moment to the square of the first--and therefore\nthe number of trials we need to obtain a good estimate of the permanent--is (1\n+ O(1/d))^n when A is the algebra of d by d matrices. These results can be\nextended to group algebras, and semi-simple algebras in general. We also study\nthe symmetrized determinant of Barvinok, showing that the resulting estimator\nhas small variance when d is large enough. However, for constant d--the only\ncase in which an efficient algorithm is known--we show that the critical ratio\nexceeds 2^{n} / n^{O(d)}. Thus our results do not provide a new polynomial-time\napproximation scheme for the permanent. Indeed, they suggest that the algebraic\napproach to approximating the permanent faces significant obstacles.\n  We obtain these results using diagrammatic techniques in which we express\nmatrix products as contractions of tensor products. When these matrices are\nrandom, in either the Haar measure or the Gaussian measure, we can evaluate the\ntrace of these products in terms of the cycle structure of a suitably random\npermutation. In the symmetrized case, our estimates are then derived by a\nconnection with the character theory of the symmetric group.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2009 11:55:41 GMT"}], "update_date": "2009-06-10", "authors_parsed": [["Moore", "Cristopher", ""], ["Russell", "Alexander", ""]]}, {"id": "0906.2154", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze (School of Computer Science and Technology, Shandong\n  University, Department of Co)", "title": "From formulas to cirquents in computability logic", "comments": "LMCS 7 (2:1) 2011", "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 2 (April 21,\n  2011) lmcs:1121", "doi": "10.2168/LMCS-7(2:1)2011", "report-no": null, "categories": "cs.LO cs.AI cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computability logic (CoL) (see http://www.cis.upenn.edu/~giorgi/cl.html) is a\nrecently introduced semantical platform and ambitious program for redeveloping\nlogic as a formal theory of computability, as opposed to the formal theory of\ntruth that logic has more traditionally been. Its expressions represent\ninteractive computational tasks seen as games played by a machine against the\nenvironment, and \"truth\" is understood as existence of an algorithmic winning\nstrategy. With logical operators standing for operations on games, the\nformalism of CoL is open-ended, and has already undergone series of extensions.\nThis article extends the expressive power of CoL in a qualitatively new way,\ngeneralizing formulas (to which the earlier languages of CoL were limited) to\ncircuit-style structures termed cirquents. The latter, unlike formulas, are\nable to account for subgame/subtask sharing between different parts of the\noverall game/task. Among the many advantages offered by this ability is that it\nallows us to capture, refine and generalize the well known\nindependence-friendly logic which, after the present leap forward, naturally\nbecomes a conservative fragment of CoL, just as classical logic had been known\nto be a conservative fragment of the formula-based version of CoL. Technically,\nthis paper is self-contained, and can be read without any prior familiarity\nwith CoL.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2009 16:34:51 GMT"}, {"version": "v2", "created": "Tue, 17 Aug 2010 10:16:42 GMT"}, {"version": "v3", "created": "Sat, 1 Jan 2011 22:31:55 GMT"}, {"version": "v4", "created": "Wed, 20 Apr 2011 16:44:25 GMT"}, {"version": "v5", "created": "Fri, 22 Apr 2011 07:31:58 GMT"}, {"version": "v6", "created": "Mon, 25 Apr 2011 21:46:55 GMT"}, {"version": "v7", "created": "Wed, 27 Apr 2011 16:46:20 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Japaridze", "Giorgi", "", "School of Computer Science and Technology, Shandong\n  University, Department of Co"]]}, {"id": "0906.2812", "submitter": "Kohtaro Tadaki", "authors": "Kohtaro Tadaki", "title": "Partial randomness and dimension of recursively enumerable reals", "comments": "12 pages, no figures, to appear in the Proceedings of the 34st\n  International Symposium on Mathematical Foundations of Computer Science (MFCS\n  2009), Novy Smokovec, High Tatras, Slovakia, August 24 - 28, 2009", "journal-ref": null, "doi": "10.1007/978-3-642-03816-7_58", "report-no": null, "categories": "cs.CC cs.IT math.IT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A real \\alpha is called recursively enumerable (\"r.e.\" for short) if there\nexists a computable, increasing sequence of rationals which converges to\n\\alpha. It is known that the randomness of an r.e. real \\alpha can be\ncharacterized in various ways using each of the notions; program-size\ncomplexity, Martin-L\\\"{o}f test, Chaitin \\Omega number, the domination and\n\\Omega-likeness of \\alpha, the universality of a computable, increasing\nsequence of rationals which converges to \\alpha, and universal probability. In\nthis paper, we generalize these characterizations of randomness over the notion\nof partial randomness by parameterizing each of the notions above by a real T\nin (0,1], where the notion of partial randomness is a stronger representation\nof the compression rate by means of program-size complexity. As a result, we\npresent ten equivalent characterizations of the partial randomness of an r.e.\nreal. The resultant characterizations of partial randomness are powerful and\nhave many important applications. One of them is to present equivalent\ncharacterizations of the dimension of an individual r.e. real. The equivalence\nbetween the notion of Hausdorff dimension and compression rate by program-size\ncomplexity (or partial randomness) has been established at present by a series\nof works of many researchers over the last two decades. We present ten\nequivalent characterizations of the dimension of an individual r.e. real.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2009 21:40:00 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Tadaki", "Kohtaro", ""]]}, {"id": "0906.3051", "submitter": "EPTCS", "authors": "Markus Holzer, Martin Kutrib, Andreas Malcher", "title": "Multi-Head Finite Automata: Characterizations, Concepts and Open\n  Problems", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 93-107", "doi": "10.4204/EPTCS.1.9", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-head finite automata were introduced in (Rabin, 1964) and (Rosenberg,\n1966). Since that time, a vast literature on computational and descriptional\ncomplexity issues on multi-head finite automata documenting the importance of\nthese devices has been developed. Although multi-head finite automata are a\nsimple concept, their computational behavior can be already very complex and\nleads to undecidable or even non-semi-decidable problems on these devices such\nas, for example, emptiness, finiteness, universality, equivalence, etc. These\nstrong negative results trigger the study of subclasses and alternative\ncharacterizations of multi-head finite automata for a better understanding of\nthe nature of non-recursive trade-offs and, thus, the borderline between\ndecidable and undecidable problems. In the present paper, we tour a fragment of\nthis literature.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 14:58:16 GMT"}], "update_date": "2009-06-19", "authors_parsed": [["Holzer", "Markus", ""], ["Kutrib", "Martin", ""], ["Malcher", "Andreas", ""]]}, {"id": "0906.3119", "submitter": "EPTCS", "authors": "Alexander Krassovitskiy, Yurii Rogozhin, Sergey Verlan", "title": "Computational Power of P Systems with Small Size Insertion and Deletion\n  Rules", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 108-117", "doi": "10.4204/EPTCS.1.10", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent investigations show insertion-deletion systems of small size that are\nnot complete and cannot generate all recursively enumerable languages. However,\nif additional computational distribution mechanisms like P systems are added,\nthen the computational completeness is achieved in some cases. In this article\nwe take two insertion-deletion systems that are not computationally complete,\nconsider them in the framework of P systems and show that the computational\npower is strictly increased by proving that any recursively enumerable language\ncan be generated. At the end some open problems are presented.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 14:44:01 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Krassovitskiy", "Alexander", ""], ["Rogozhin", "Yurii", ""], ["Verlan", "Sergey", ""]]}, {"id": "0906.3162", "submitter": "Yonatan Bilu", "authors": "Yonatan Bilu, Nathan Linial", "title": "Are stable instances easy?", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of a stable instance for a discrete optimization\nproblem, and argue that in many practical situations only sufficiently stable\ninstances are of interest. The question then arises whether stable instances of\nNP--hard problems are easier to solve. In particular, whether there exist\nalgorithms that solve correctly and in polynomial time all sufficiently stable\ninstances of some NP--hard problem. The paper focuses on the Max--Cut problem,\nfor which we show that this is indeed the case.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 12:43:41 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Bilu", "Yonatan", ""], ["Linial", "Nathan", ""]]}, {"id": "0906.3186", "submitter": "EPTCS", "authors": "Philippe Moser", "title": "A General Notion of Useful Information", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 164-171", "doi": "10.4204/EPTCS.1.16", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a general framework for defining the depth of a\nsequence with respect to a class of observers. We show that our general\nframework captures all depth notions introduced in complexity theory so far. We\nreview most such notions, show how they are particular cases of our general\ndepth framework, and review some classical results about the different depth\nnotions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 14:09:03 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Moser", "Philippe", ""]]}, {"id": "0906.3197", "submitter": "EPTCS", "authors": "Maurice Margenstern", "title": "On the injectivity of the global function of a cellular automaton in the\n  hyperbolic plane (extended abstract)", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 153-163", "doi": "10.4204/EPTCS.1.15", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we look at the following question. We consider cellular\nautomata in the hyperbolic plane, (see Margenstern, 2000, 2007 and Margenstern,\nMorita, 2001) and we consider the global function defined on all possible\nconfigurations. Is the injectivity of this function undecidable? The problem\nwas answered positively in the case of the Euclidean plane by Jarkko Kari, in\n1994. In the present paper, we show that the answer is also positive for the\nhyperbolic plane: the problem is undecidable.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 14:33:32 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Margenstern", "Maurice", ""]]}, {"id": "0906.3199", "submitter": "EPTCS", "authors": "Manfred Kudlek", "title": "Some Considerations on Universality", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 118-122", "doi": "10.4204/EPTCS.1.11", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper puts into discussion the concept of universality, in particular for\nstructures not of the power of Turing computability. The question arises if for\nsuch structures a universal structure of the same kind exists or not. For that\nthe construction of universal Turing machines and those with some constraints\nare presented in some detail.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 14:39:20 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Kudlek", "Manfred", ""]]}, {"id": "0906.3208", "submitter": "EPTCS", "authors": "Alexander Okhotin", "title": "Representing a P-complete problem by small trellis automata", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 185-198", "doi": "10.4204/EPTCS.1.18", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A restricted case of the Circuit Value Problem known as the Sequential NOR\nCircuit Value Problem was recently used to obtain very succinct examples of\nconjunctive grammars, Boolean grammars and language equations representing\nP-complete languages (Okhotin, http://dx.doi.org/10.1007/978-3-540-74593-8_23\n\"A simple P-complete problem and its representations by language equations\",\nMCU 2007). In this paper, a new encoding of the same problem is proposed, and a\ntrellis automaton (one-way real-time cellular automaton) with 11 states solving\nthis problem is constructed.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 15:21:41 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Okhotin", "Alexander", ""]]}, {"id": "0906.3213", "submitter": "EPTCS", "authors": "Nicolas Ollinger", "title": "Intrinsically Universal Cellular Automata", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 199-204", "doi": "10.4204/EPTCS.1.19", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This talk advocates intrinsic universality as a notion to identify simple\ncellular automata with complex computational behavior. After an historical\nintroduction and proper definitions of intrinsic universality, which is\ndiscussed with respect to Turing and circuit universality, we discuss\nconstruction methods for small intrinsically universal cellular automata before\ndiscussing techniques for proving non universality.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 15:24:44 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Ollinger", "Nicolas", ""]]}, {"id": "0906.3225", "submitter": "EPTCS", "authors": "J\\'er\\^ome Durand-Lose", "title": "Small Turing universal signal machines", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 70-80", "doi": "10.4204/EPTCS.1.7", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article aims at providing signal machines as small as possible able to\nperform any computation (in the classical understanding). After presenting\nsignal machines, it is shown how to get universal ones from Turing machines,\ncellular-automata and cyclic tag systems. Finally a halting universal signal\nmachine with 13 meta-signals and 21 collision rules is presented.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 16:08:47 GMT"}], "update_date": "2009-06-22", "authors_parsed": [["Durand-Lose", "J\u00e9r\u00f4me", ""]]}, {"id": "0906.3227", "submitter": "EPTCS", "authors": "Nicolas Ollinger, Ga\\'etan Richard", "title": "A Particular Universal Cellular Automaton", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 205-214", "doi": "10.4204/EPTCS.1.20", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signals are a classical tool used in cellular automata constructions that\nproved to be useful for language recognition or firing-squad synchronisation.\nParticles and collisions formalize this idea one step further, describing\nregular nets of colliding signals. In the present paper, we investigate the use\nof particles and collisions for constructions involving an infinite number of\ninteracting particles. We obtain a high-level construction for a new smallest\nintrinsically universal cellular automaton with 4 states.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 16:11:12 GMT"}], "update_date": "2009-06-22", "authors_parsed": [["Ollinger", "Nicolas", ""], ["Richard", "Ga\u00e9tan", ""]]}, {"id": "0906.3228", "submitter": "EPTCS", "authors": "Klaus Sutner", "title": "Computational Processes and Incompleteness", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 226-234", "doi": "10.4204/EPTCS.1.22", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a formal definition of Wolfram's notion of computational process\nbased on cellular automata, a physics-like model of computation. There is a\nnatural classification of these processes into decidable, intermediate and\ncomplete. It is shown that in the context of standard finite injury priority\narguments one cannot establish the existence of an intermediate computational\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 16:13:53 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Sutner", "Klaus", ""]]}, {"id": "0906.3231", "submitter": "EPTCS", "authors": "Sergey Verlan, Yurii Rogozhin", "title": "New Choice for Small Universal Devices: Symport/Antiport P Systems", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 235-242", "doi": "10.4204/EPTCS.1.23", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symport/antiport P systems provide a very simple machinery inspired by\ncorresponding operations in the living cell. It turns out that systems of small\ndescriptional complexity are needed to achieve the universality by these\nsystems. This makes them a good candidate for small universal devices replacing\nregister machines for different simulations, especially when a simulating\nparallel machinery is involved. This article contains survey of these systems\nand presents different trade-offs between parameters.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 16:14:54 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Verlan", "Sergey", ""], ["Rogozhin", "Yurii", ""]]}, {"id": "0906.3248", "submitter": "EPTCS", "authors": "Matthew Cook", "title": "A Concrete View of Rule 110 Computation", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 31-55", "doi": "10.4204/EPTCS.1.4", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule 110 is a cellular automaton that performs repeated simultaneous updates\nof an infinite row of binary values. The values are updated in the following\nway: 0s are changed to 1s at all positions where the value to the right is a 1,\nwhile 1s are changed to 0s at all positions where the values to the left and\nright are both 1. Though trivial to define, the behavior exhibited by Rule 110\nis surprisingly intricate, and in (Cook, 2004) we showed that it is capable of\nemulating the activity of a Turing machine by encoding the Turing machine and\nits tape into a repeating left pattern, a central pattern, and a repeating\nright pattern, which Rule 110 then acts on. In this paper we provide an\nexplicit compiler for converting a Turing machine into a Rule 110 initial\nstate, and we present a general approach for proving that such constructions\nwill work as intended. The simulation was originally assumed to require\nexponential time, but surprising results of Neary and Woods (2006) have shown\nthat in fact, only polynomial time is required. We use the methods of Neary and\nWoods to exhibit a direct simulation of a Turing machine by a tag system in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 17:01:54 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Cook", "Matthew", ""]]}, {"id": "0906.3251", "submitter": "EPTCS", "authors": "David Doty, Matthew J. Patitz, Scott M. Summers", "title": "Limitations of Self-Assembly at Temperature One (extended abstract)", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 67-69", "doi": "10.4204/EPTCS.1.6", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that if a subset X of the integer Cartesian plane weakly\nself-assembles at temperature 1 in a deterministic (Winfree) tile assembly\nsystem satisfying a natural condition known as *pumpability*, then X is a\nfinite union of doubly periodic sets. This shows that only the most simple of\ninfinite shapes and patterns can be constructed using pumpable temperature 1\ntile assembly systems, and gives strong evidence for the thesis that\ntemperature 2 or higher is required to carry out general-purpose computation in\na tile assembly system. Finally, we show that general-purpose computation is\npossible at temperature 1 if negative glue strengths are allowed in the tile\nassembly model.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 17:06:51 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Doty", "David", ""], ["Patitz", "Matthew J.", ""], ["Summers", "Scott M.", ""]]}, {"id": "0906.3284", "submitter": "Niall Murphy", "authors": "Eric Goles, Pierre-Etienne Meunier, Ivan Rapaport and Guillaume\n  Theyssier", "title": "Communications in cellular automata", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 81-92", "doi": "10.4204/EPTCS.1.8", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to show why the framework of communication\ncomplexity seems suitable for the study of cellular automata. Researchers have\ntackled different algorithmic problems ranging from the complexity of\npredicting to the decidability of different dynamical properties of cellular\nautomata. But the difference here is that we look for communication protocols\narising in the dynamics itself. Our work is guided by the following idea: if we\nare able to give a protocol describing a cellular automaton, then we can\nunderstand its behavior.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 19:52:34 GMT"}], "update_date": "2009-06-22", "authors_parsed": [["Goles", "Eric", ""], ["Meunier", "Pierre-Etienne", ""], ["Rapaport", "Ivan", ""], ["Theyssier", "Guillaume", ""]]}, {"id": "0906.3306", "submitter": "Niall Murphy", "authors": "Matthew J. Patitz and Scott M. Summers", "title": "Self-Assembly of Infinite Structures", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 215-225", "doi": "10.4204/EPTCS.1.21", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some recent results related to the self-assembly of infinite\nstructures in the Tile Assembly Model. These results include impossibility\nresults, as well as novel tile assembly systems in which shapes and patterns\nthat represent various notions of computation self-assemble. Several open\nquestions are also presented and motivated.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 20:33:07 GMT"}], "update_date": "2009-06-19", "authors_parsed": [["Patitz", "Matthew J.", ""], ["Summers", "Scott M.", ""]]}, {"id": "0906.3327", "submitter": "EPTCS", "authors": "Niall Murphy, Damien Woods", "title": "On acceptance conditions for membrane systems: characterisations of L\n  and NL", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 172-184", "doi": "10.4204/EPTCS.1.17", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the affect of various acceptance conditions on\nrecogniser membrane systems without dissolution. We demonstrate that two\nparticular acceptance conditions (one easier to program, the other easier to\nprove correctness) both characterise the same complexity class, NL. We also\nfind that by restricting the acceptance conditions we obtain a characterisation\nof L. We obtain these results by investigating the connectivity properties of\ndependency graphs that model membrane system computations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2009 01:04:51 GMT"}], "update_date": "2009-06-19", "authors_parsed": [["Murphy", "Niall", ""], ["Woods", "Damien", ""]]}, {"id": "0906.3329", "submitter": "EPTCS", "authors": "Liesbeth De Mol", "title": "On the boundaries of solvability and unsolvability in tag systems.\n  Theoretical and Experimental Results", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 56-66", "doi": "10.4204/EPTCS.1.5", "report-no": null, "categories": "cs.CC cs.DM cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several older and more recent results on the boundaries of solvability and\nunsolvability in tag systems are surveyed. Emphasis will be put on the\nsignificance of computer experiments in research on very small tag systems.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2009 01:15:00 GMT"}], "update_date": "2009-06-22", "authors_parsed": [["De Mol", "Liesbeth", ""]]}, {"id": "0906.3332", "submitter": "EPTCS", "authors": "Matteo Cavaliere, Peter Leupold", "title": "Complexity through the Observation of Simple Systems", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 22-30", "doi": "10.4204/EPTCS.1.3", "report-no": null, "categories": "cs.CC cs.DM cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey work on the paradigm called \"computing by observing.\" Its central\nfeature is that one considers the behavior of an evolving system as the result\nof a computation. To this end an observer records this behavior. It has turned\nout that the observed behavior of computationally simple systems can be very\ncomplex, when an appropriate observer is used. For example, a restricted\nversion of context-free grammars with regular observers suffices to obtain\ncomputational completeness. As a second instantiation presented here, we apply\nan observer to sticker systems. Finally, some directions for further research\nare proposed.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2009 01:15:53 GMT"}], "update_date": "2009-06-22", "authors_parsed": [["Cavaliere", "Matteo", ""], ["Leupold", "Peter", ""]]}, {"id": "0906.3469", "submitter": "Panos Giannopoulos", "authors": "Panos Giannopoulos, Christian Knauer, Gunter Rote, Daniel Werner", "title": "The parameterized complexity of some geometric problems in unbounded\n  dimension", "comments": null, "journal-ref": "Proc. 4th Int. Workshop on Parameterized and Exact\n  Computation-IWPEC 2009, Copenhagen, September 2009, Herausgeber: Jianer Chen\n  und Fedor V. Fomin, Lecture Notes in Computer Science, 5917, Springer-Verlag,\n  2009, pp. 198-209", "doi": "10.1007/978-3-642-11269-0_16", "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of the following fundamental geometric\nproblems with respect to the dimension $d$: i) Given $n$ points in $\\Rd$,\ncompute their minimum enclosing cylinder. ii) Given two $n$-point sets in\n$\\Rd$, decide whether they can be separated by two hyperplanes. iii) Given a\nsystem of $n$ linear inequalities with $d$ variables, find a maximum-size\nfeasible subsystem. We show that (the decision versions of) all these problems\nare W[1]-hard when parameterized by the dimension $d$. %and hence not solvable\nin ${O}(f(d)n^c)$ time, for any computable function $f$ and constant $c$\n%(unless FPT=W[1]). Our reductions also give a $n^{\\Omega(d)}$-time lower bound\n(under the Exponential Time Hypothesis).\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2009 15:44:18 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Giannopoulos", "Panos", ""], ["Knauer", "Christian", ""], ["Rote", "Gunter", ""], ["Werner", "Daniel", ""]]}, {"id": "0906.3554", "submitter": "Hector Zenil", "authors": "Hector Zenil, Jean-Paul Delahaye", "title": "On the Algorithmic Nature of the World", "comments": "Book chapter in Gordana Dodig-Crnkovic and Mark Burgin (eds.)\n  Information and Computation by World Scientific, 2010.\n  (http://www.idt.mdh.se/ECAP-2005/INFOCOMPBOOK/). Paper website:\n  http://www.mathrix.org/experimentalAIT/", "journal-ref": "Gordana Dodig-Crnkovic and Mark Burgin (eds.) Information and\n  Computation by World Scientific, 2010", "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a test based on the theory of algorithmic complexity and an\nexperimental evaluation of Levin's universal distribution to identify evidence\nin support of or in contravention of the claim that the world is algorithmic in\nnature. To this end we have undertaken a statistical comparison of the\nfrequency distributions of data from physical sources on the one\nhand--repositories of information such as images, data stored in a hard drive,\ncomputer programs and DNA sequences--and the frequency distributions generated\nby purely algorithmic means on the other--by running abstract computing devices\nsuch as Turing machines, cellular automata and Post Tag systems. Statistical\ncorrelations were found and their significance measured.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2009 00:08:50 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2010 15:59:00 GMT"}, {"version": "v3", "created": "Wed, 11 Aug 2010 07:30:19 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Zenil", "Hector", ""], ["Delahaye", "Jean-Paul", ""]]}, {"id": "0906.3643", "submitter": "Haris Aziz", "authors": "Haris Aziz, Oded Lachish, Mike Paterson and Rahul Savani", "title": "Spanning connectivity games", "comments": "AAIM 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Banzhaf index, Shapley-Shubik index and other voting power indices\nmeasure the importance of a player in a coalitional game. We consider a simple\ncoalitional game called the spanning connectivity game (SCG) based on an\nundirected, unweighted multigraph, where edges are players. We examine the\ncomputational complexity of computing the voting power indices of edges in the\nSCG. It is shown that computing Banzhaf values and Shapley-Shubik indices is\n#P-complete for SCGs. Interestingly, Holler indices and Deegan-Packel indices\ncan be computed in polynomial time. Among other results, it is proved that\nBanzhaf indices can be computed in polynomial time for graphs with bounded\ntreewidth. It is also shown that for any reasonable representation of a simple\ngame, a polynomial time algorithm to compute the Shapley-Shubik indices implies\na polynomial time algorithm to compute the Banzhaf indices. As a corollary,\ncomputing the Shapley value is #P-complete for simple games represented by the\nset of minimal winning coalitions, Threshold Network Flow Games, Vertex\nConnectivity Games and Coalitional Skill Games.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2009 11:29:41 GMT"}], "update_date": "2009-06-22", "authors_parsed": [["Aziz", "Haris", ""], ["Lachish", "Oded", ""], ["Paterson", "Mike", ""], ["Savani", "Rahul", ""]]}, {"id": "0906.3765", "submitter": "Hunter Monroe", "authors": "Hunter Monroe", "title": "Speedup for Natural Problems and Noncomputability", "comments": "8 pages", "journal-ref": "Theor. Comput. Sci. 412 (2011) 478-481", "doi": "10.1016/j.tcs.2010.09.029", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A resource-bounded version of the statement \"no algorithm recognizes all\nnon-halting Turing machines\" is equivalent to an infinitely often (i.o.)\nsuperpolynomial speedup for the time required to accept any coNP-complete\nlanguage and also equivalent to a superpolynomial speedup in proof length in\npropositional proof systems for tautologies, each of which implies P!=NP. This\nsuggests a correspondence between the properties 'has no algorithm at all' and\n'has no best algorithm' which seems relevant to open problems in computational\nand proof complexity.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2009 02:58:26 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2012 18:57:03 GMT"}, {"version": "v3", "created": "Fri, 21 Sep 2012 00:33:41 GMT"}], "update_date": "2012-09-24", "authors_parsed": [["Monroe", "Hunter", ""]]}, {"id": "0906.4162", "submitter": "EPTCS", "authors": "Jack H. Lutz", "title": "A Divergence Formula for Randomness and Dimension (Short Version)", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 149-152", "doi": "10.4204/EPTCS.1.14", "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If $S$ is an infinite sequence over a finite alphabet $\\Sigma$ and $\\beta$ is\na probability measure on $\\Sigma$, then the {\\it dimension} of $ S$ with\nrespect to $\\beta$, written $\\dim^\\beta(S)$, is a constructive version of\nBillingsley dimension that coincides with the (constructive Hausdorff)\ndimension $\\dim(S)$ when $\\beta$ is the uniform probability measure. This paper\nshows that $\\dim^\\beta(S)$ and its dual $\\Dim^\\beta(S)$, the {\\it strong\ndimension} of $S$ with respect to $\\beta$, can be used in conjunction with\nrandomness to measure the similarity of two probability measures $\\alpha$ and\n$\\beta$ on $\\Sigma$. Specifically, we prove that the {\\it divergence formula}\n$$\\dim^\\beta(R) = \\Dim^\\beta(R) =\\CH(\\alpha) / (\\CH(\\alpha) + \\D(\\alpha ||\n\\beta))$$ holds whenever $\\alpha$ and $\\beta$ are computable, positive\nprobability measures on $\\Sigma$ and $R \\in \\Sigma^\\infty$ is random with\nrespect to $\\alpha$. In this formula, $\\CH(\\alpha)$ is the Shannon entropy of\n$\\alpha$, and $\\D(\\alpha||\\beta)$ is the Kullback-Leibler divergence between\n$\\alpha$ and $\\beta$.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 10:15:31 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Lutz", "Jack H.", ""]]}, {"id": "0906.4216", "submitter": "Viswanath Kasturi", "authors": "Venkata Rao Kuchibhotla, Viswanath Kasturi", "title": "On the Definition of Non-deterministic Mechanisms", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here three different approaches to the problem of modeling\nmathematically the concept of a non-deterministic mechanism. Each of these\nthree approaches leads to a mathematical definition. We then show that all the\nthree mathematical concepts are equivalent to one another. This insight gives\nus the option of approaching the wp-formalism of Dijkstra from a different\nviewpoint that is easier to understand and to teach.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 10:27:40 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Kuchibhotla", "Venkata Rao", ""], ["Kasturi", "Viswanath", ""]]}, {"id": "0906.4291", "submitter": "Alexander A. Sherstov", "authors": "Alexander A. Sherstov", "title": "The Pattern Matrix Method (Journal Version)", "comments": "Revised and expanded version of the STOC'08 article. To appear in\n  SIAM J. Comput., 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel and powerful technique for communication lower bounds, the\npattern matrix method. Specifically, fix an arbitrary function f:{0,1}^n->{0,1}\nand let A_f be the matrix whose columns are each an application of f to some\nsubset of the variables x_1,x_2,...,x_{4n}. We prove that A_f has bounded-error\ncommunication complexity Omega(d), where d is the approximate degree of f. This\nresult remains valid in the quantum model, regardless of prior entanglement. In\nparticular, it gives a new and simple proof of Razborov's breakthrough quantum\nlower bounds for disjointness and other symmetric predicates. We further\ncharacterize the discrepancy, approximate rank, and approximate trace norm of\nA_f in terms of well-studied analytic properties of f, broadly generalizing\nseveral recent results on small-bias communication and agnostic learning. The\nmethod of this paper has recently enabled important progress in multiparty\ncommunication complexity.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 15:51:36 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Sherstov", "Alexander A.", ""]]}, {"id": "0906.4431", "submitter": "Joerg Rothe", "authors": "Daniel Binkele-Raible, G\\'abor Erd\\'elyi, Henning Fernau, Judy\n  Goldsmith, Nicholas Mattei, and J\\\"org Rothe", "title": "The Complexity of Probabilistic Lobbying", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose models for lobbying in a probabilistic environment, in which an\nactor (called \"The Lobby\") seeks to influence voters' preferences of voting for\nor against multiple issues when the voters' preferences are represented in\nterms of probabilities. In particular, we provide two evaluation criteria and\ntwo bribery methods to formally describe these models, and we consider the\nresulting forms of lobbying with and without issue weighting. We provide a\nformal analysis for these problems of lobbying in a stochastic environment, and\ndetermine their classical and parameterized complexity depending on the given\nbribery/evaluation criteria and on various natural parameterizations.\nSpecifically, we show that some of these problems can be solved in polynomial\ntime, some are NP-complete but fixed-parameter tractable, and some are\nW[2]-complete. Finally, we provide approximability and inapproximability\nresults for these problems and several variants.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2009 10:14:13 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2009 22:10:34 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2009 12:11:55 GMT"}, {"version": "v4", "created": "Sat, 26 Feb 2011 21:29:30 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Binkele-Raible", "Daniel", ""], ["Erd\u00e9lyi", "G\u00e1bor", ""], ["Fernau", "Henning", ""], ["Goldsmith", "Judy", ""], ["Mattei", "Nicholas", ""], ["Rothe", "J\u00f6rg", ""]]}, {"id": "0906.4612", "submitter": "EPTCS", "authors": "Turlough Neary, Damien Woods, Anthony K. Seda, Niall Murphy", "title": "Proceedings International Workshop on The Complexity of Simple Programs", "comments": null, "journal-ref": "EPTCS 1, 2009", "doi": "10.4204/EPTCS.1", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the first volume of Electronic Proceedings in Theoretical Computer\nScience (EPTCS), a free international refereed open access venue for the rapid\nelectronic publication of the proceedings of workshops and conferences, and of\nfestschriften, etc, in the general area of theoretical computer science,\nbroadly construed.\n  It contains the proceedings of the International Workshop on The Complexity\nof Simple Programs, which was hosted at University College Cork on the 6th and\n7th of December, 2008. All speakers were invited and all of the papers went\nthrough a thorough peer-review process.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 16:32:39 GMT"}], "update_date": "2009-10-13", "authors_parsed": [["Neary", "Turlough", ""], ["Woods", "Damien", ""], ["Seda", "Anthony K.", ""], ["Murphy", "Niall", ""]]}, {"id": "0906.4816", "submitter": "Assaf Naor", "authors": "Subhash Khot and Assaf Naor", "title": "Sharp kernel clustering algorithms and their associated Grothendieck\n  inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the kernel clustering problem we are given a (large) $n\\times n$ symmetric\npositive semidefinite matrix $A=(a_{ij})$ with $\\sum_{i=1}^n\\sum_{j=1}^n\na_{ij}=0$ and a (small) $k\\times k$ symmetric positive semidefinite matrix\n$B=(b_{ij})$. The goal is to find a partition $\\{S_1,...,S_k\\}$ of $\\{1,...\nn\\}$ which maximizes $ \\sum_{i=1}^k\\sum_{j=1}^k (\\sum_{(p,q)\\in S_i\\times\nS_j}a_{pq})b_{ij}$.\n  We design a polynomial time approximation algorithm that achieves an\napproximation ratio of $\\frac{R(B)^2}{C(B)}$, where $R(B)$ and $C(B)$ are\ngeometric parameters that depend only on the matrix $B$, defined as follows: if\n$b_{ij} = < v_i, v_j>$ is the Gram matrix representation of $B$ for some\n$v_1,...,v_k\\in \\R^k$ then $R(B)$ is the minimum radius of a Euclidean ball\ncontaining the points $\\{v_1, ..., v_k\\}$. The parameter $C(B)$ is defined as\nthe maximum over all measurable partitions $\\{A_1,...,A_k\\}$ of $\\R^{k-1}$ of\nthe quantity $\\sum_{i=1}^k\\sum_{j=1}^k b_{ij}< z_i,z_j>$, where for $i\\in\n\\{1,...,k\\}$ the vector $z_i\\in \\R^{k-1}$ is the Gaussian moment of $A_i$,\ni.e., $z_i=\\frac{1}{(2\\pi)^{(k-1)/2}}\\int_{A_i}xe^{-\\|x\\|_2^2/2}dx$. We also\nshow that for every $\\eps > 0$, achieving an approximation guarantee of\n$(1-\\e)\\frac{R(B)^2}{C(B)}$ is Unique Games hard.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 23:10:44 GMT"}], "update_date": "2009-06-29", "authors_parsed": [["Khot", "Subhash", ""], ["Naor", "Assaf", ""]]}, {"id": "0906.5112", "submitter": "Javaid Aslam", "authors": "Javaid Aslam", "title": "Response to Refutation of Aslam's Proof that NP = P", "comments": "Total 9 pages, including the figures. Have further minimized the\n  overlap, with only references to the main paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a further refinement to the previous response by\nintroducing new structures and algorithms for counting VMPs of common\n\\emph{Edge Requirement} (ER) and hence for counting the perfect matchings.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2009 16:07:06 GMT"}, {"version": "v2", "created": "Fri, 23 Jan 2015 20:54:52 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2015 00:58:51 GMT"}, {"version": "v4", "created": "Sat, 7 Oct 2017 03:38:30 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Aslam", "Javaid", ""]]}, {"id": "0906.5475", "submitter": "Yong-Hyuk Kim", "authors": "Yong-Hyuk Kim and Yourim Yoon", "title": "A Note on Mathematical Modelling of Practical Multicampaign Assignment\n  and Its Computational Complexity", "comments": "14 pages, 1 figure", "journal-ref": "Proceedings of the 2010 ACM Symposium on Applied Computing (SAC),\n  pages 94-98, 2010", "doi": null, "report-no": null, "categories": "cs.CC cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within personalized marketing, a recommendation issue known as multicampaign\nassignment is to overcome a critical problem, known as the multiple\nrecommendation problem which occurs when running several personalized campaigns\nsimultaneously. This paper mainly deals with the hardness of multicampaign\nassignment, which is treated as a very challenging problem in marketing. The\nobjective in this problem is to find a customer-campaign matrix which maximizes\nthe effectiveness of multiple campaigns under some constraints. We present a\nrealistic response suppression function, which is designed to be more\npractical, and explain how this can be learned from historical data. Moreover,\nwe provide a proof that this more realistic version of the problem is NP-hard,\nthus justifying to use of heuristics presented in previous work.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2009 13:53:03 GMT"}], "update_date": "2010-05-04", "authors_parsed": [["Kim", "Yong-Hyuk", ""], ["Yoon", "Yourim", ""]]}]