[{"id": "1808.00425", "submitter": "Inbal Livni Navon", "authors": "Irit Dinur and Prahladh Harsha and Tali Kaufman and Inbal Livni Navon\n  and Amnon Ta Shma", "title": "List Decoding with Double Samplers", "comments": null, "journal-ref": "In Proc. 30th ACM-SIAM Symposium on Discrete Algorithms (SODA)\n  (San Diego, 6-9 January), pages 2134-2153, 2019", "doi": "10.1137/1.9781611975482.129", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We strengthen the notion of \"double samplers\", first introduced by Dinur and\nKaufman [Proc. 58th FOCS, 2017], which are samplers with additional\ncombinatorial properties, and whose existence we prove using high dimensional\nexpanders.\n  The ABNNR code construction [IEEE Trans. Inform. Theory, 38(2):509--516,\n1992] achieves large distance by starting with a base code $C$ with moderate\ndistance, and then amplifying the distance using a sampler. We show that if the\nsampler is part of a larger double sampler then the construction has an\nefficient list-decoding algorithm. Our algorithm works even if the ABNNR\nconstruction is not applied to a base code $C$ but to any string. In this case\nthe resulting code is approximate-list-decodable, i.e. the output list contains\nan approximation to the original input.\n  Our list-decoding algorithm works as follows: it uses a local voting scheme\nfrom which it constructs a unique games constraint graph. The constraint graph\nis an expander, so we can solve unique games efficiently. These solutions are\nthe output of the list decoder. This is a novel use of a unique games algorithm\nas a subroutine in a decoding procedure, as opposed to the more common\nsituation in which unique games are used for demonstrating hardness results.\n  Double samplers and high dimensional expanders are akin to pseudorandom\nobjects in their utility, but they greatly exceed random objects in their\ncombinatorial properties. We believe that these objects hold significant\npotential for coding theoretic constructions and view this work as\ndemonstrating the power of double samplers in this context.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 17:10:42 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 13:15:33 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Dinur", "Irit", ""], ["Harsha", "Prahladh", ""], ["Kaufman", "Tali", ""], ["Navon", "Inbal Livni", ""], ["Shma", "Amnon Ta", ""]]}, {"id": "1808.00460", "submitter": "Jacob Biamonte", "authors": "Jacob D. Biamonte and Mauro E.S. Morales and Dax Enshan Koh", "title": "Entanglement Scaling in Quantum Advantage Benchmarks", "comments": "updates and improvements from the review process; 8 pages; 3 figures", "journal-ref": "Phys. Rev. A 101, 012349 (2020)", "doi": "10.1103/PhysRevA.101.012349", "report-no": null, "categories": "quant-ph cond-mat.other cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A contemporary technological milestone is to build a quantum device\nperforming a computational task beyond the capability of any classical\ncomputer, an achievement known as quantum adversarial advantage. In what ways\ncan the entanglement realized in such a demonstration be quantified? Inspired\nby the area law of tensor networks, we derive an upper bound for the minimum\nrandom circuit depth needed to generate the maximal bipartite entanglement\ncorrelations between all problem variables (qubits). This bound is (i) lattice\ngeometry dependent and (ii) makes explicit a nuance implicit in other proposals\nwith physical consequence. The hardware itself should be able to support\nsuper-logarithmic ebits of entanglement across some poly($n$) number of\nqubit-bipartitions, otherwise the quantum state itself will not possess\nvolumetric entanglement scaling and full-lattice-range correlations. Hence, as\nwe present a connection between quantum advantage protocols and quantum\nentanglement, the entanglement implicitly generated by such protocols can be\ntested separately to further ascertain the validity of any quantum advantage\nclaim.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 18:00:01 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 10:43:47 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 11:30:16 GMT"}, {"version": "v4", "created": "Wed, 1 Jan 2020 00:27:28 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Biamonte", "Jacob D.", ""], ["Morales", "Mauro E. S.", ""], ["Koh", "Dax Enshan", ""]]}, {"id": "1808.01313", "submitter": "Martin Milani\\v{c}", "authors": "Ratko Darda and Martin Milani\\v{c} and Miguel Piza\\~na", "title": "Searching for square-complementary graphs: non-existence results and\n  complexity of recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is square-complementary (squco, for short) if its square and\ncomplement are isomorphic. We prove that there are no squco graphs with girth\n6, that every bipartite graph is an induced subgraph of a squco bipartite\ngraph, that the problem of recognizing squco graphs is graph isomorphism\ncomplete, and that no nontrivial squco graph is both bipartite and planar.\nThese results resolve three of the open problems posed in Discrete Math. 327\n(2014) 62-75.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 19:13:05 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Darda", "Ratko", ""], ["Milani\u010d", "Martin", ""], ["Piza\u00f1a", "Miguel", ""]]}, {"id": "1808.01701", "submitter": "Abel Molina", "authors": "Abel Molina and John Watrous", "title": "Revisiting the simulation of quantum Turing machines by quantum circuits", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": "10.1098/rspa.2018.0767", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yao (1993) proved that quantum Turing machines and uniformly generated\nquantum circuits are polynomially equivalent computational models: $t \\geq n$\nsteps of a quantum Turing machine running on an input of length $n$ can be\nsimulated by a uniformly generated family of quantum circuits with size\nquadratic in $t$, and a polynomial-time uniformly generated family of quantum\ncircuits can be simulated by a quantum Turing machine running in polynomial\ntime. We revisit the simulation of quantum Turing machines with uniformly\ngenerated quantum circuits, which is the more challenging of the two simulation\ntasks, and present a variation on the simulation method employed by Yao\ntogether with an analysis of it. This analysis reveals that the simulation of\nquantum Turing machines can be performed by quantum circuits having depth\nlinear in $t$, rather than quadratic depth, and can be extended to variants of\nquantum Turing machines, such as ones having multi-dimensional tapes. Our\nanalysis is based on an extension of a method of Arrighi, Nesme, and Werner\n(2011) that allows for the localization of causal unitary evolutions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 00:08:55 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Molina", "Abel", ""], ["Watrous", "John", ""]]}, {"id": "1808.02336", "submitter": "Nina Holden", "authors": "Nina Holden and Russell Lyons", "title": "Lower bounds for trace reconstruction", "comments": "Minor changes. 23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the trace reconstruction problem, an unknown bit string ${\\bf x}\\in\\{0,1\n\\}^n$ is sent through a deletion channel where each bit is deleted\nindependently with some probability $q\\in(0,1)$, yielding a contracted string\n$\\widetilde{\\bf x}$. How many i.i.d.\\ samples of $\\widetilde{\\bf x}$ are needed\nto reconstruct $\\bf x$ with high probability? We prove that there exist ${\\bf\nx},{\\bf y} \\in\\{0,1 \\}^n$ such that at least $c\\, n^{5/4}/\\sqrt{\\log n}$ traces\nare required to distinguish between ${\\bf x}$ and ${\\bf y}$ for some absolute\nconstant $c$, improving the previous lower bound of $c\\,n$. Furthermore, our\nresult improves the previously known lower bound for reconstruction of random\nstrings from $c \\log^2 n$ to $c \\log^{9/4}n/\\sqrt{\\log \\log n} $.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 05:45:19 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 14:35:48 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Holden", "Nina", ""], ["Lyons", "Russell", ""]]}, {"id": "1808.02359", "submitter": "Till Fluschnik", "authors": "Max-Jonathan Luckow and Till Fluschnik", "title": "On the Computational Complexity of Length- and Neighborhood-Constrained\n  Path Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding paths in graphs is a fundamental graph-theoretic task. In this work,\nwe we are concerned with finding a path with some constraints on its length and\nthe number of vertices neighboring the path, that is, being outside of and\nincident with the path. Herein, we consider short and long paths on the one\nside, and small and large neighborhoods on the other side---yielding four\ndecision problems. We show that all four problems are NP-complete, even in\nplanar graphs with small maximum degree. Moreover, we study all four variants\nwhen parameterized by a bound $k$ on the length of the path, by a bound $\\ell$\non the size of neighborhood, and by $k + \\ell$.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 13:32:31 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 12:07:11 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Luckow", "Max-Jonathan", ""], ["Fluschnik", "Till", ""]]}, {"id": "1808.02420", "submitter": "Scott Aaronson", "authors": "Scott Aaronson", "title": "Quantum Lower Bound for Approximate Counting Via Laurent Polynomials", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following problem: estimate the size of a nonempty set\n$S\\subseteq\\left[ N\\right] $, given both quantum queries to a membership oracle\nfor $S$, and a device that generates equal superpositions $\\left\\vert\nS\\right\\rangle $ over $S$ elements. We show that, if $\\left\\vert S\\right\\vert $\nis neither too large nor too small, then approximate counting with these\nresources is still quantumly hard. More precisely, any quantum algorithm needs\neither $\\Omega\\left( \\sqrt{N/\\left\\vert S\\right\\vert}\\right) $ queries or else\n$\\Omega\\left( \\min\\left\\{ \\left\\vert S\\right\\vert ^{1/4},\\sqrt{N/\\left\\vert\nS\\right\\vert }\\right\\} \\right)$ copies of $\\left\\vert S\\right\\rangle $. This\nmeans that, in the black-box setting, quantum sampling does not imply\napproximate counting. The proof uses a novel generalization of the polynomial\nmethod of Beals et al. to Laurent polynomials, which can have negative\nexponents.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 15:26:26 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Aaronson", "Scott", ""]]}, {"id": "1808.02821", "submitter": "Valentin Bura", "authors": "Valentin Bura", "title": "Positive 1-in-3-SAT admits a non-trivial Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We illustrate the strength of Algebraic Methods, adapting Gaussian\nElimination and Substitution to the problem of Exact Boolean Satisfiability.\nFor 1-in-3 SAT with non-negated literals we are able to obtain considerably\nsmaller equivalent instances of 0/1 Integer Programming restricted to Equality\nonly.\n  Both Gaussian Elimination and Substitution may be used in a processing step,\nfollowed by a type of brute-force approach on the kernel thus obtained.\n  Our method shows that Positive instances of 1-in-3 SAT may be reduced to\nsignificantly smaller instances of I.P.E. in the following sense. Any such\ninstance of $|V|$ variables and $|C|$ clauses can be polynomial-time reduced to\nan instance of 0/1 Integer Programming with Equality, of size at most $2/3|V|$\nvariables and at most $|C|$ clauses.\n  We obtain an upper bound for the complexity of counting, $O(2\\kappa r\n2^{(1-\\kappa) r})$ for number of variables $r$ and clauses to variables ratio\n$\\kappa$.\n  We proceed to define formally the notion of a non-trivial kernel, defining\nthe problems considered as Constraint Satisfaction Problems.\n  We conclude showing the methods presented here, giving a non-trivial kernel\nfor positive 1-in-3 SAT, imply the existence of a non-trivial kernel for 1-in-3\nSAT.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 15:23:08 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 19:04:57 GMT"}, {"version": "v3", "created": "Sun, 10 Mar 2019 21:21:10 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 14:46:00 GMT"}, {"version": "v5", "created": "Sun, 9 Jun 2019 03:46:31 GMT"}, {"version": "v6", "created": "Fri, 30 Oct 2020 15:29:14 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Bura", "Valentin", ""]]}, {"id": "1808.02859", "submitter": "Xianghui Zhong", "authors": "Stefan Hougardy and Xianghui Zhong", "title": "Hard to Solve Instances of the Euclidean Traveling Salesman Problem", "comments": null, "journal-ref": null, "doi": "10.1007/s12532-020-00184-5", "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well known $4/3$ conjecture states that the integrality ratio of the\nsubtour LP is at most $4/3$ for metric Traveling Salesman instances. We present\na family of Euclidean Traveling Salesman instances for which we prove that the\nintegrality ratio of the subtour LP converges to $4/3$. These instances (using\nthe rounded Euclidean norm) turn out to be hard to solve exactly with Concorde,\nthe fastest existing exact TSP solver. For a 200 vertex instance from our\nfamily of Euclidean Traveling Salesman instances Concorde needs several days of\nCPU time. This is more than 1,000,000 times the runtime for a TSPLIB instance\nof similar size. Thus our new family of Euclidean Traveling Salesman instances\nmay serve as new benchmark instances for TSP algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 16:58:56 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 16:15:05 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 17:35:23 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Hougardy", "Stefan", ""], ["Zhong", "Xianghui", ""]]}, {"id": "1808.02974", "submitter": "Fuchun Lin", "authors": "Fuchun Lin, Mahdi Cheraghchi, Venkatesan Guruswami, Reihaneh\n  Safavi-Naini, Huaxiong Wang", "title": "Secret Sharing with Binary Shares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shamir's celebrated secret sharing scheme provides an efficient method for\nencoding a secret of arbitrary length $\\ell$ among any $N \\leq 2^\\ell$ players\nsuch that for a threshold parameter $t$, (i) the knowledge of any $t$ shares\ndoes not reveal any information about the secret and, (ii) any choice of $t+1$\nshares fully reveals the secret. It is known that any such threshold secret\nsharing scheme necessarily requires shares of length $\\ell$, and in this sense\nShamir's scheme is optimal. The more general notion of ramp schemes requires\nthe reconstruction of secret from any $t+g$ shares, for a positive integer gap\nparameter $g$. Ramp secret sharing scheme necessarily requires shares of length\n$\\ell/g$. Other than the bound related to secret length $\\ell$, the share\nlengths of ramp schemes can not go below a quantity that depends only on the\ngap ratio $g/N$. In this work, we study secret sharing in the extremal case of\nbit-long shares and arbitrarily small gap ratio $g/N$, where standard ramp\nsecret sharing becomes impossible. We show, however, that a slightly relaxed\nbut equally effective notion of semantic security for the secret, and\nnegligible reconstruction error probability, eliminate the impossibility.\nMoreover, we provide explicit constructions of such schemes. One of the\nconsequences of our relaxation is that, unlike standard ramp schemes with\nperfect secrecy, adaptive and non-adaptive adversaries need different analysis\nand construction. For non-adaptive adversaries, we explicitly construct secret\nsharing schemes that provide secrecy against any $\\tau$ fraction of observed\nshares, and reconstruction from any $\\rho$ fraction of shares, for any choices\nof $0 \\leq \\tau < \\rho \\leq 1$. Our construction achieves secret length\n$N(\\rho-\\tau-o(1))$, which we show to be optimal. For adaptive adversaries, we\nconstruct explicit schemes attaining a secret length $\\Omega(N(\\rho-\\tau))$.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 00:25:14 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 08:38:58 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 01:41:49 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Lin", "Fuchun", ""], ["Cheraghchi", "Mahdi", ""], ["Guruswami", "Venkatesan", ""], ["Safavi-Naini", "Reihaneh", ""], ["Wang", "Huaxiong", ""]]}, {"id": "1808.03043", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "Hunting for Tractable Languages for Judgment Aggregation", "comments": "To appear in the Proceedings of the 16th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Judgment aggregation is a general framework for collective decision making\nthat can be used to model many different settings. Due to its general nature,\nthe worst case complexity of essentially all relevant problems in this\nframework is very high. However, these intractability results are mainly due to\nthe fact that the language to represent the aggregation domain is overly\nexpressive. We initiate an investigation of representation languages for\njudgment aggregation that strike a balance between (1) being limited enough to\nyield computational tractability results and (2) being expressive enough to\nmodel relevant applications. In particular, we consider the languages of Krom\nformulas, (definite) Horn formulas, and Boolean circuits in decomposable\nnegation normal form (DNNF). We illustrate the use of the positive complexity\nresults that we obtain for these languages with a concrete application: voting\non how to spend a budget (i.e., participatory budgeting).\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 07:16:56 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1808.03387", "submitter": "Janardan Misra", "authors": "Janardan Misra", "title": "Computational Complexity of Observing Evolution in Artificial-Life Forms", "comments": "arXiv admin note: substantial text overlap with arXiv:0901.1610", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observations are an essential component of the simulation based studies on\nartificial-evolutionary systems (AES) by which entities are identified and\ntheir behavior is observed to uncover higher-level \"emergent\" phenomena.\nBecause of the heterogeneity of AES models and implicit nature of observations,\nprecise characterization of the observation process, independent of the\nunderlying micro-level reaction semantics of the model, is a difficult problem.\nBuilding upon the multiset based algebraic framework to characterize\nstate-space trajectory of AES model simulations, we estimate bounds on\ncomputational resource requirements of the process of automatically discovering\nlife-like evolutionary behavior in AES models during simulations. For\nillustration, we consider the case of Langton's Cellular Automata model and\ncharacterize the worst case computational complexity bounds for identifying\nentity and population level reproduction.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 04:18:55 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Misra", "Janardan", ""]]}, {"id": "1808.03494", "submitter": "Kamil Khadiev", "authors": "Kamil Khadiev, Dmitry Kravchenko", "title": "On the Complexity of Solving Subtraction Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algorithms for solving Subtraction games, which sometimes are\nreferred to as one-heap Nim games. We describe a quantum algorithm which is\napplicable to any game on DAG, and show that its query compexity for solving an\narbitrary Subtraction game of $n$ stones is $O(n^{3/2}\\log n)$. The best known\ndeterministic algorithms for solving such games are based on the dynamic\nprogramming approach. We show that this approach is asymptotically optimal and\nthat classical query complexity for solving a Subtraction game is generally\n$\\Theta(n^2)$. This paper perhaps is the first explicit \"quantum\" contribution\nto algorithmic game theory.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 11:45:22 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Khadiev", "Kamil", ""], ["Kravchenko", "Dmitry", ""]]}, {"id": "1808.03598", "submitter": "Henok Ghebrechristos", "authors": "Henok Ghebrechristos, Drew Miller", "title": "Overarching Computation Model (OCM)", "comments": "We present a framework and use it to shed light on the p vs np\n  problem. More precisely we provide a proof for separating deterministic and\n  non-deterministic algorithms with underlying concept that the two processes\n  are fundamental and inherently different", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing models of computation, such as a Turing machine (hereafter, TM), do\nnot consider the agent involved in interpreting the outcome of the computation.\nWe argue that a TM, or any other computation model, has no significance if its\noutput is not interpreted by some agent. Furthermore, we argue that including\nthe interpreter in the model definition sheds light on some of the difficult\nproblems faced in computation and mathematics. We provide an analytic process\nframework to address this limitation. The framework can be overlaid on existing\nconcepts of computation to address many practical and philosophical concerns\nsuch as the P vs NP problem. In addition, we argue that the P vs NP problem is\nreminiscent of existing computation model which does not account for the person\nthat initiates the computation and interprets the intermediate and final\noutput. We utilize the observation that deterministic computational procedures\nlack fundamental capacity to fully simulate their non-deterministic variant to\nconclude that the set NP cannot be fully contained in P. Deterministic\nprocedure can approximate non-deterministic variant to some degree. However,\nthe logical implication of the fundamental differences between determinism and\nnon-determinism is that equivalence of the two classes is impossible to\nestablish.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 14:48:59 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 17:26:08 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Ghebrechristos", "Henok", ""], ["Miller", "Drew", ""]]}, {"id": "1808.03852", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "A Parameterized Complexity View on Description Logic Reasoning", "comments": "To appear in the Proceedings of the 16th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description logics are knowledge representation languages that have been\ndesigned to strike a balance between expressivity and computational\ntractability. Many different description logics have been developed, and\nnumerous computational problems for these logics have been studied for their\ncomputational complexity. However, essentially all complexity analyses of\nreasoning problems for description logics use the one-dimensional framework of\nclassical complexity theory. The multi-dimensional framework of parameterized\ncomplexity theory is able to provide a much more detailed image of the\ncomplexity of reasoning problems.\n  In this paper we argue that the framework of parameterized complexity has a\nlot to offer for the complexity analysis of description logic reasoning\nproblems---when one takes a progressive and forward-looking view on\nparameterized complexity tools. We substantiate our argument by means of three\ncase studies. The first case study is about the problem of concept\nsatisfiability for the logic ALC with respect to nearly acyclic TBoxes. The\nsecond case study concerns concept satisfiability for ALC concepts\nparameterized by the number of occurrences of union operators and the number of\noccurrences of full existential quantification. The third case study offers a\ncritical look at data complexity results from a parameterized complexity point\nof view. These three case studies are representative for the wide range of uses\nfor parameterized complexity methods for description logic problems.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 19:25:04 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1808.03978", "submitter": "Sandip Sinha", "authors": "Sandip Sinha and Omri Weinstein", "title": "Local Decodability of the Burrows-Wheeler Transform", "comments": "The following two technical typos were fixed: (1) On page 2,\n  following Theorem 1, the decoding time of a contiguous substring of size\n  $\\ell$ was corrected from $O(t + \\ell)$ to $O(t + \\ell \\cdot \\lg t)$. (2) In\n  the statement of Theorem 2, the query time to count occurrences of patterns\n  of length $\\ell$ was corrected to $O(t \\ell)$, independent of the number of\n  occurrences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Burrows-Wheeler Transform (BWT) is among the most influential discoveries\nin text compression and DNA storage. It is a reversible preprocessing step that\nrearranges an $n$-letter string into runs of identical characters (by\nexploiting context regularities), resulting in highly compressible strings, and\nis the basis of the \\texttt{bzip} compression program. Alas, the decoding\nprocess of BWT is inherently sequential and requires $\\Omega(n)$ time even to\nretrieve a \\emph{single} character.\n  We study the succinct data structure problem of locally decoding short\nsubstrings of a given text under its \\emph{compressed} BWT, i.e., with small\nadditive redundancy $r$ over the \\emph{Move-To-Front} (\\texttt{bzip})\ncompression. The celebrated BWT-based FM-index (FOCS '00), as well as other\nrelated literature, yield a trade-off of $r=\\tilde{O}(n/\\sqrt{t})$ bits, when a\nsingle character is to be decoded in $O(t)$ time. We give a near-quadratic\nimprovement $r=\\tilde{O}(n\\lg(t)/t)$. As a by-product, we obtain an\n\\emph{exponential} (in $t$) improvement on the redundancy of the FM-index for\ncounting pattern-matches on compressed text. In the interesting regime where\nthe text compresses to $n^{1-o(1)}$ bits, these results provide an $\\exp(t)$\n\\emph{overall} space reduction. For the local decoding problem of BWT, we also\nprove an $\\Omega(n/t^2)$ cell-probe lower bound for \"symmetric\" data\nstructures.\n  We achieve our main result by designing a compressed partial-sums (Rank) data\nstructure over BWT. The key component is a \\emph{locally-decodable}\nMove-to-Front (MTF) code: with only $O(1)$ extra bits per block of length\n$n^{\\Omega(1)}$, the decoding time of a single character can be decreased from\n$\\Omega(n)$ to $O(\\lg n)$. This result is of independent interest in\nalgorithmic information theory.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 18:16:59 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 06:09:03 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Sinha", "Sandip", ""], ["Weinstein", "Omri", ""]]}, {"id": "1808.04035", "submitter": "Li-Yang Tan", "authors": "Ryan O'Donnell, Rocco A. Servedio, Li-Yang Tan", "title": "Fooling Polytopes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a pseudorandom generator that fools $m$-facet polytopes over\n$\\{0,1\\}^n$ with seed length $\\mathrm{polylog}(m) \\cdot \\log n$. The previous\nbest seed length had superlinear dependence on $m$. An immediate consequence is\na deterministic quasipolynomial time algorithm for approximating the number of\nsolutions to any $\\{0,1\\}$-integer program.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 01:34:13 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["O'Donnell", "Ryan", ""], ["Servedio", "Rocco A.", ""], ["Tan", "Li-Yang", ""]]}, {"id": "1808.04213", "submitter": "Samuel Epstein", "authors": "Samuel Epstein", "title": "Algorithmic No-Cloning Theorem", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notions of algorithmic mutual information and rarity of\nquantum states. These definitions enjoy conservation inequalities over unitary\ntransformations and partial traces. We show that a large majority of pure\nstates have minute self algorithmic information. We provide an algorithmic\nvariant to the no-cloning theorem, by showing that only a small minority of\nquantum pure states can clone a non negligible amount of algorithmic\ninformation. We also provide a chain rule inequality for quantum algorithmic\nentropy. We show that rarity does not increase under POVM measurements.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 15:48:14 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 14:36:47 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 17:49:25 GMT"}, {"version": "v4", "created": "Sun, 10 Jan 2021 17:57:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Epstein", "Samuel", ""]]}, {"id": "1808.04448", "submitter": "Debajyoti Bera", "authors": "Debajyoti Bera and Subhamoy Maitra and SAPV Tharrmashastha", "title": "Efficient Quantum Algorithms related to Autocorrelation Spectrum", "comments": "Accepted in Indocrypt 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose efficient probabilistic algorithms for several\nproblems regarding the autocorrelation spectrum. First, we present a quantum\nalgorithm that samples from the Walsh spectrum of any derivative of $f()$.\nInformally, the autocorrelation coefficient of a Boolean function $f()$ at some\npoint $a$ measures the average correlation among the values $f(x)$ and $f(x\n\\oplus a)$. The derivative of a Boolean function is an extension of\nautocorrelation to correlation among multiple values of $f()$. The Walsh\nspectrum is well-studied primarily due to its connection to the quantum circuit\nfor the Deutsch-Jozsa problem. We extend the idea to \"Higher-order\nDeutsch-Jozsa\" quantum algorithm to obtain points corresponding to large\nabsolute values in the Walsh spectrum of a certain derivative of $f()$.\nFurther, we design an algorithm to sample the input points according to squares\nof the autocorrelation coefficients. Finally we provide a different set of\nalgorithms for estimating the square of a particular coefficient or cumulative\nsum of their squares.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 17:15:41 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 12:11:25 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Bera", "Debajyoti", ""], ["Maitra", "Subhamoy", ""], ["Tharrmashastha", "SAPV", ""]]}, {"id": "1808.04539", "submitter": "Lingfei Jin", "authors": "Venkatesan Guruswami, Lingfei Jin and Chaoping Xing", "title": "Constructions of maximally recoverable local reconstruction codes via\n  function fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DM math.IT math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Reconstruction Codes (LRCs) allow for recovery from a small number of\nerasures in a local manner based on just a few other codeword symbols. A\nmaximally recoverable (MR) LRC offers the best possible blend of such local and\nglobal fault tolerance, guaranteeing recovery from all erasure patterns which\nare information-theoretically correctable given the presence of local recovery\ngroups. In an $(n,r,h,a)$-LRC, the $n$ codeword symbols are partitioned into\n$r$ disjoint groups each of which include $a$ local parity checks capable of\nlocally correcting $a$ erasures.\n  MR LRCs have received much attention recently, with many explicit\nconstructions covering different regimes of parameters. Unfortunately, all\nknown constructions require a large field size that exponential in $h$ or $a$,\nand it is of interest to obtain MR LRCs of minimal possible field size. In this\nwork, we develop an approach based on function fields to construct MR LRCs. Our\nmethod recovers, and in most parameter regimes improves, the field size of\nprevious approaches. For instance, for the case of small $r \\ll \\epsilon \\log\nn$ and large $h \\ge \\Omega(n^{1-\\epsilon})$, we improve the field size from\nroughly $n^h$ to $n^{\\epsilon h}$. For the case of $a=1$ (one local parity\ncheck), we improve the field size quadratically from $r^{h(h+1)}$ to $r^{h\n\\lfloor (h+1)/2 \\rfloor}$ for some range of $r$. The improvements are modest,\nbut more importantly are obtained in a unified manner via a promising new idea.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 05:47:46 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Jin", "Lingfei", ""], ["Xing", "Chaoping", ""]]}, {"id": "1808.04925", "submitter": "Chih-Hung Chang Lucius", "authors": "J. C. Ban and C. H. Chang and Y. Z. Huang", "title": "Complexity of Shift Spaces on Semigroups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G=\\left\\langle S|R_{A}\\right\\rangle $ be a semigroup with generating set\n$ S$ and equivalences $R_{A}$ among $S$ determined by a matrix $A$. This paper\ninvestigates the complexity of $G$-shift spaces by yielding the topological\nentropies. After revealing the existence of topological entropy of $G$-shift of\nfinite type ($G$-SFT), the calculation of topological entropy of $G$-SFT is\nequivalent to solving a system of nonlinear recurrence equations. The complete\ncharacterization of topological entropies of $G$-SFTs on two symbols is\naddressed, which extends [Ban and Chang, arXiv:1803.03082] in which $G$ is a\nfree semigroup.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 23:56:36 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Ban", "J. C.", ""], ["Chang", "C. H.", ""], ["Huang", "Y. Z.", ""]]}, {"id": "1808.05578", "submitter": "Guillaume Chevalier", "authors": "Guillaume Chevalier", "title": "LARNN: Linear Attention Recurrent Neural Network", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Linear Attention Recurrent Neural Network (LARNN) is a recurrent\nattention module derived from the Long Short-Term Memory (LSTM) cell and ideas\nfrom the consciousness Recurrent Neural Network (RNN). Yes, it LARNNs. The\nLARNN uses attention on its past cell state values for a limited window size\n$k$. The formulas are also derived from the Batch Normalized LSTM (BN-LSTM)\ncell and the Transformer Network for its Multi-Head Attention Mechanism. The\nMulti-Head Attention Mechanism is used inside the cell such that it can query\nits own $k$ past values with the attention window. This has the effect of\naugmenting the rank of the tensor with the attention mechanism, such that the\ncell can perform complex queries to question its previous inner memories, which\nshould augment the long short-term effect of the memory. With a clever trick,\nthe LARNN cell with attention can be easily used inside a loop on the cell\nstate, just like how any other Recurrent Neural Network (RNN) cell can be\nlooped linearly through time series. This is due to the fact that its state,\nwhich is looped upon throughout time steps within time series, stores the inner\nstates in a \"first in, first out\" queue which contains the $k$ most recent\nstates and on which it is easily possible to add static positional encoding\nwhen the queue is represented as a tensor. This neural architecture yields\nbetter results than the vanilla LSTM cells. It can obtain results of 91.92% for\nthe test accuracy, compared to the previously attained 91.65% using vanilla\nLSTM cells. Note that this is not to compare to other research, where up to\n93.35% is obtained, but costly using 18 LSTM cells rather than with 2 to 3\ncells as analyzed here. Finally, an interesting discovery is made, such that\nadding activation within the multi-head attention mechanism's linear layers can\nyield better results in the context researched hereto.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 16:48:56 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Chevalier", "Guillaume", ""]]}, {"id": "1808.05676", "submitter": "Bhaskar DasGupta", "authors": "Bhaskar DasGupta, Mano Vikash Janardhanan and Farzane Yahyanejad", "title": "Why did the shape of your network change? (On detecting network\n  anomalies via non-local curvatures)", "comments": "Final revised version; to appear in Algorithmica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $Anomaly$ $detection$ problems (also called $change$-$point$ $detection$\nproblems) have been studied in data mining, statistics and computer science\nover the last several decades in applications such as medical condition\nmonitoring and weather change detection. In recent days, however, anomaly\ndetection problems have become increasing more relevant in the context of\n$network$ $science$ since useful insights for many complex systems in biology,\nfinance and social science are often obtained by representing them via\nnetworks. Notions of local and non-local curvatures of higher-dimensional\ngeometric shapes and topological spaces play a $fundamental$ role in physics\nand mathematics in characterizing anomalous behaviours of these higher\ndimensional entities. However, using curvature measures to detect anomalies in\nnetworks is not yet very common. To this end, a main goal in this paper to\nformulate and analyze curvature analysis methods to provide the foundations of\nsystematic approaches to find $critical$ $components$ and $detect$ $anomalies$\nin networks. For this purpose, we use two measures of network curvatures which\ndepend on non-trivial global properties, such as distributions of geodesics and\nhigher-order correlations among nodes, of the given network. Based on these\nmeasures, we precisely formulate several computational problems related to\nanomaly detection in static or dynamic networks, and provide non-trivial\ncomputational complexity results for these problems. This paper must $not$ be\nviewed as delivering the final word on appropriateness and suitability of\nspecific curvature measures. Instead, it is our hope that this paper will\nstimulate and motivate further theoretical or empirical research concerning the\nexciting interplay between notions of curvatures from network and non-network\ndomains, a $much$ desired goal in our opinion.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 20:41:27 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 21:42:01 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 20:20:04 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["DasGupta", "Bhaskar", ""], ["Janardhanan", "Mano Vikash", ""], ["Yahyanejad", "Farzane", ""]]}, {"id": "1808.06265", "submitter": "Michael A. Forbes", "authors": "Michael A. Forbes and Zander Kelley", "title": "Pseudorandom Generators for Read-Once Branching Programs, in any Order", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central question in derandomization is whether randomized logspace (RL)\nequals deterministic logspace (L). To show that RL=L, it suffices to construct\nexplicit pseudorandom generators (PRGs) that fool polynomial-size read-once\n(oblivious) branching programs (roBPs). Starting with the work of Nisan,\npseudorandom generators with seed-length $O(\\log^2 n)$ were constructed.\nUnfortunately, improving on this seed-length in general has proven challenging\nand seems to require new ideas.\n  A recent line of inquiry has suggested focusing on a particular limitation of\nthe existing PRGs, which is that they only fool roBPs when the variables are\nread in a particular known order, such as $x_1<\\cdots<x_n$. In comparison,\nexistentially one can obtain logarithmic seed-length for fooling the set of\npolynomial-size roBPs that read the variables under any fixed unknown\npermutation $x_{\\pi(1)}<\\cdots<x_{\\pi(n)}$. While recent works have established\nnovel PRGs in this setting for subclasses of roBPs, there were no known\n$n^{o(1)}$ seed-length explicit PRGs for general polynomial-size roBPs in this\nsetting.\n  In this work, we follow the \"bounded independence plus noise\" paradigm of\nHaramaty, Lee and Viola, and give an improved analysis in the general roBP\nunknown-order setting. With this analysis we obtain an explicit PRG with\nseed-length $O(\\log^3 n)$ for polynomial-size roBPs reading their bits in an\nunknown order. Plugging in a recent Fourier tail bound of Chattopadhyay,\nHatami, Reingold, and Tal, we can obtain a $\\widetilde{O}(\\log^2 n)$\nseed-length when the roBP is of constant width.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 22:17:54 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Forbes", "Michael A.", ""], ["Kelley", "Zander", ""]]}, {"id": "1808.06407", "submitter": "Emmanouil Zampetakis", "authors": "Katerina Sotiraki, Manolis Zampetakis, Giorgos Zirdelis", "title": "PPP-Completeness with Connections to Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polynomial Pigeonhole Principle (PPP) is an important subclass of TFNP with\nprofound connections to the complexity of the fundamental cryptographic\nprimitives: collision-resistant hash functions and one-way permutations. In\ncontrast to most of the other subclasses of TFNP, no complete problem is known\nfor PPP. Our work identifies the first PPP-complete problem without any circuit\nor Turing Machine given explicitly in the input, and thus we answer a\nlongstanding open question from [Papadimitriou1994]. Specifically, we show that\nconstrained-SIS (cSIS), a generalized version of the well-known Short Integer\nSolution problem (SIS) from lattice-based cryptography, is PPP-complete.\n  In order to give intuition behind our reduction for constrained-SIS, we\nidentify another PPP-complete problem with a circuit in the input but closely\nrelated to lattice problems. We call this problem BLICHFELDT and it is the\ncomputational problem associated with Blichfeldt's fundamental theorem in the\ntheory of lattices.\n  Building on the inherent connection of PPP with collision-resistant hash\nfunctions, we use our completeness result to construct the first natural hash\nfunction family that captures the hardness of all collision-resistant hash\nfunctions in a worst-case sense, i.e. it is natural and universal in the\nworst-case. The close resemblance of our hash function family with SIS, leads\nus to the first candidate collision-resistant hash function that is both\nnatural and universal in an average-case sense.\n  Finally, our results enrich our understanding of the connections between PPP,\nlattice problems and other concrete cryptographic assumptions, such as the\ndiscrete logarithm problem over general groups.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 11:54:09 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Sotiraki", "Katerina", ""], ["Zampetakis", "Manolis", ""], ["Zirdelis", "Giorgos", ""]]}, {"id": "1808.06655", "submitter": "Ilya Volkovich", "authors": "Vishwas Bhargava, Shubhangi Saraf, Ilya Volkovich", "title": "Deterministic Factorization of Sparse Polynomials with Bounded\n  Individual Degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of deterministic factorization of sparse\npolynomials. We show that if $f \\in \\mathbb{F}[x_{1},x_{2},\\ldots ,x_{n}]$ is a\npolynomial with $s$ monomials, with individual degrees of its variables bounded\nby $d$, then $f$ can be deterministically factored in time $s^{\\mathrm{poly}(d)\n\\log n}$. Prior to our work, the only efficient factoring algorithms known for\nthis class of polynomials were randomized, and other than for the cases of\n$d=1$ and $d=2$, only exponential time deterministic factoring algorithms were\nknown.\n  A crucial ingredient in our proof is a quasi-polynomial sparsity bound for\nfactors of sparse polynomials of bounded individual degree. In particular we\nshow if $f$ is an $s$-sparse polynomial in $n$ variables, with individual\ndegrees of its variables bounded by $d$, then the sparsity of each factor of\n$f$ is bounded by $s^{O({d^2\\log{n}})}$. This is the first nontrivial bound on\nfactor sparsity for $d>2$. Our sparsity bound uses techniques from convex\ngeometry, such as the theory of Newton polytopes and an approximate version of\nthe classical Carath\\'eodory's Theorem.\n  Our work addresses and partially answers a question of von zur Gathen and\nKaltofen (JCSS 1985) who asked whether a quasi-polynomial bound holds for the\nsparsity of factors of sparse polynomials.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 19:10:39 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Bhargava", "Vishwas", ""], ["Saraf", "Shubhangi", ""], ["Volkovich", "Ilya", ""]]}, {"id": "1808.06717", "submitter": "Mert Sa\\u{g}lam", "authors": "Mert Sa\\u{g}lam", "title": "Near log-convexity of measured heat in (discrete) time and consequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $u,v \\in \\mathbb{R}^\\Omega_+$ be positive unit vectors and\n$S\\in\\mathbb{R}^{\\Omega\\times\\Omega}_+$ be a symmetric substochastic matrix.\nFor an integer $t\\ge 0$, let $m_t = \\smash{\\left\\langle v,S^tu\\right\\rangle}$,\nwhich we view as the heat measured by $v$ after an initial heat configuration\n$u$ is let to diffuse for $t$ time steps according to $S$. Since $S$ is entropy\nimproving, one may intuit that $m_t$ should not change too rapidly over time.\nWe give the following formalizations of this intuition.\n  We prove that $m_{t+2} \\ge m_t^{1+2/t}\\!,$ an inequality studied earlier by\nBlakley and Dixon (also Erd\\H{o}s and Simonovits) for $u=v$ and shown true\nunder the restriction $m_t\\ge e^{-4t}$. Moreover we prove that for any\n$\\epsilon>0$, a stronger inequality $m_{t+2} \\ge t^{1-\\epsilon}\\cdot\n\\smash{m_t^{1+2/t}}$ holds unless $m_{t+2}m_{t-2}\\ge \\delta m_t^2$ for some\n$\\delta$ that depends on $\\epsilon$ only. Phrased differently, $\\forall\n\\epsilon> 0, \\exists \\delta> 0$ such that $\\forall S,u,v$ \\begin{equation*}\n\\frac{m_{t+2}}{m_{t}^{1+2/t}}\\ge \\min\\left\\{t^{1-\\epsilon},\n\\delta\\frac{m_t^{1-2/t}}{m_{t-2}}\\right\\}, \\quad \\forall t \\ge 2,\n\\end{equation*} which can be viewed as a truncated log-convexity statement.\n  Using this inequality, we answer two related open questions in complexity\ntheory: Any property tester for $k$-linearity requires $\\Omega(k\\log k)$\nqueries and the randomized communication complexity of the $k$-Hamming distance\nproblem is $\\Omega(k\\log k)$. Further we show that any randomized parity\ndecision tree computing $k$-Hamming weight has size $\\exp\\left(\\Omega(k\\log\nk)\\right)$.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 23:07:10 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Sa\u011flam", "Mert", ""]]}, {"id": "1808.06921", "submitter": "Marieke van der Wegen", "authors": "Hans L. Bodlaender, Marieke van der Wegen and Tom C. van der Zanden", "title": "Stable divisorial gonality is in NP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Divisorial gonality and stable divisorial gonality are graph parameters,\nwhich have an origin in algebraic geometry. Divisorial gonality of a connected\ngraph $G$ can be defined with help of a chip firing game on $G$. The stable\ndivisorial gonality of $G$ is the minimum divisorial gonality over all\nsubdivisions of edges of $G$.\n  In this paper we prove that deciding whether a given connected graph has\nstable divisorial gonality at most a given integer $k$ belongs to the class NP.\nCombined with the result that (stable) divisorial gonality is NP-hard by\nGijswijt, we obtain that stable divisorial gonality is NP-complete. The proof\nconsist of a partial certificate that can be verified by solving an Integer\nLinear Programming instance. As a corollary, we have that the number of\nsubdivisions needed for minimum stable divisorial gonality of a graph with $n$\nvertices is bounded by $2^{p(n)}$ for a polynomial $p$.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 14:29:22 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["van der Wegen", "Marieke", ""], ["van der Zanden", "Tom C.", ""]]}, {"id": "1808.07199", "submitter": "Krishnamoorthy Dinesh", "authors": "Krishnamoorthy Dinesh, Samir Otiv, Jayalal Sarma", "title": "New Bounds for Energy Complexity of Boolean Functions", "comments": "25 pages, 4 figures. Improved presentation of Theorem 1.5. Added an\n  improvement due to Sun et.al. and a comparison to their result (in Section 6)", "journal-ref": null, "doi": "10.1016/j.tcs.2020.09.003", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\newcommand{\\EC}{\\mathsf{EC}}\\newcommand{\\KW}{\\mathsf{KW}}\\newcommand{\\DT}{\\mathsf{DT}}\\newcommand{\\psens}{\\mathsf{psens}}\n\\newcommand{\\calB}{{\\cal B}} $ For a Boolean function $f:\\{0,1\\}^n \\to \\{0,1\\}$\ncomputed by a circuit $C$ over a finite basis $\\mathcal{B}$, the energy\ncomplexity of $C$ (denoted by $\\EC_{\\calB}(C)$) is the maximum over all inputs\n$\\{0,1\\}^n$ the numbers of gates of the circuit $C$ (excluding the inputs) that\noutput a one. Energy Complexity of a Boolean function over a finite basis\n$\\calB$ denoted by $\\EC_\\calB(f):= \\min_C \\EC_{\\calB}(C)$ where $C$ is a\ncircuit over $\\calB$ computing $f$.\n  We study the case when $\\calB = \\{\\land_2, \\lor_2, \\lnot\\}$, the standard\nBoolean basis. It is known that any Boolean function can be computed by a\ncircuit (with potentially large size) with an energy of at most\n$3n(1+\\epsilon(n))$ for a small $ \\epsilon(n)$(which we observe is improvable\nto $3n-1$). We show several new results and connections between energy\ncomplexity and other well-studied parameters of Boolean functions.\n  * For all Boolean functions $f$, $\\EC(f) \\le O(\\DT(f)^3)$ where $\\DT(f)$ is\nthe optimal decision tree depth of $f$.\n  * We define a parameter \\textit{positive sensitivity} (denoted by $\\psens$),\na quantity that is smaller than sensitivity and defined in a similar way, and\nshow that for any Boolean circuit $C$ computing a Boolean function $f$, $\n\\EC(C) \\ge \\psens(f)/3$.\n  * For a monotone function $f$, we show that $\\EC(f) = \\Omega(\\KW^+(f))$ where\n$\\KW^+(f)$ is the cost of monotone Karchmer-Wigderson game of $f$.\n  * Restricting the above notion of energy complexity to Boolean formulas, we\nshow $\\EC(F) = \\Omega\\left (\\sqrt{L(F)}-depth(F)\\right )$ where $L(F)$ is the\nsize and $depth(F)$ is the depth of a formula $F$.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 03:11:38 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 04:37:28 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Dinesh", "Krishnamoorthy", ""], ["Otiv", "Samir", ""], ["Sarma", "Jayalal", ""]]}, {"id": "1808.08772", "submitter": "Manuel Sorge", "authors": "Iyad Kanj, Christian Komusiewicz, Manuel Sorge, Erik Jan van Leeuwen", "title": "Solving Partition Problems Almost Always Requires Pushing Many Vertices\n  Around", "comments": "Full version of the corresponding article in the Proceedings of the\n  26th Annual European Symposium on Algorithms (ESA '18), 35 pages, 7 figures", "journal-ref": null, "doi": "10.4230/LIPIcs.ESA.2018.51", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental graph problem is to recognize whether the vertex set of a graph\n$G$ can be bipartitioned into sets $A$ and $B$ such that $G[A]$ and $G[B]$\nsatisfy properties $\\Pi_A$ and $\\Pi_B$, respectively. This so-called\n$(\\Pi_A,\\Pi_B)$-Recognition problem generalizes amongst others the recognition\nof $3$-colorable, bipartite, split, and monopolar graphs. In this paper, we\nstudy whether certain fixed-parameter tractable $(\\Pi_A,\\Pi_B)$-Recognition\nproblems admit polynomial kernels. In our study, we focus on the first level\nabove triviality, where $\\Pi_A$ is the set of $P_3$-free graphs (disjoint\nunions of cliques, or cluster graphs), the parameter is the number of clusters\nin the cluster graph $G[A]$, and $\\Pi_B$ is characterized by a set\n$\\mathcal{H}$ of connected forbidden induced subgraphs. We prove that, under\nthe assumption that NP is not a subset of coNP/poly,\n\\textsc{$(\\Pi_A,\\Pi_B)$-Recognition} admits a polynomial kernel if and only if\n$\\mathcal{H}$ contains a graph with at most $2$ vertices. In both the\nkernelization and the lower bound results, we exploit the properties of a\npushing process, which is an algorithmic technique used recently by Heggerness\net al. and by Kanj et al. to obtain fixed-parameter algorithms for many cases\nof $(\\Pi_A,\\Pi_B)$-Recognition, as well as several other problems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 10:34:22 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 18:07:27 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kanj", "Iyad", ""], ["Komusiewicz", "Christian", ""], ["Sorge", "Manuel", ""], ["van Leeuwen", "Erik Jan", ""]]}, {"id": "1808.08817", "submitter": "Martin Milani\\v{c}", "authors": "Ademir Hujdurovi\\'c, Martin Milani\\v{c}, Bernard Ries", "title": "Detecting strong cliques", "comments": "arXiv admin note: text overlap with arXiv:1609.06961", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strong clique in a graph is a clique intersecting every maximal independent\nset. We study the computational complexity of six algorithmic decision problems\nrelated to strong cliques in graphs and almost completely determine their\ncomplexity in the classes of chordal graphs, weakly chordal graphs, line graphs\nand their complements, and graphs of maximum degree at most three. Our results\nrely on connections with matchings and relate to several graph properties\nstudied in the literature, including well-covered graphs, localizable graphs,\nand general partition graphs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 16:09:02 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Hujdurovi\u0107", "Ademir", ""], ["Milani\u010d", "Martin", ""], ["Ries", "Bernard", ""]]}, {"id": "1808.08905", "submitter": "Soledad Villar", "authors": "Richard Kueng and Dustin G. Mixon and Soledad Villar", "title": "Fair redistricting is hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gerrymandering is a long-standing issue within the U.S. political system, and\nit has received scrutiny recently by the U.S. Supreme Court. In this note, we\nprove that deciding whether there exists a fair redistricting among legal maps\nis NP-hard. To make this precise, we use simplified notions of \"legal\" and\n\"fair\" that account for desirable traits such as geographic compactness of\ndistricts and sufficient representation of voters. The proof of our result is\ninspired by the work of Mahanjan, Minbhorkar and Varadarajan that proves that\nplanar k-means is NP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 16:17:25 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Kueng", "Richard", ""], ["Mixon", "Dustin G.", ""], ["Villar", "Soledad", ""]]}, {"id": "1808.08913", "submitter": "Mahsa Eftekhari Hesari", "authors": "David Doty and Mahsa Eftekhari", "title": "Efficient size estimation and impossibility of termination in uniform\n  dense population protocols", "comments": "Using leaderless phase clock", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study uniform population protocols: networks of anonymous agents whose\npairwise interactions are chosen at random, where each agent uses an identical\ntransition algorithm that does not depend on the population size $n$. Many\nexisting polylog$(n)$ time protocols for leader election and majority\ncomputation are nonuniform: to operate correctly, they require all agents to be\ninitialized with an approximate estimate of $n$ (specifically, the exact value\n$\\lfloor \\log n \\rfloor$). Our first main result is a uniform protocol for\ncalculating $\\log(n) \\pm O(1)$ with high probability in $O(\\log^2 n)$ time and\n$O(\\log^4 n)$ states ($O(\\log \\log n)$ bits of memory). The protocol is\nconverging but not terminating: it does not signal when the estimate is close\nto the true value of $\\log n$. If it could be made terminating, this would\nallow composition with protocols, such as those for leader election or\nmajority, that require a size estimate initially, to make them uniform (though\nwith a small probability of failure). We do show how our main protocol can be\nindirectly composed with others in a simple and elegant way, based on the\nleaderless phase clock, demonstrating that those protocols can in fact be made\nuniform. However, our second main result implies that the protocol cannot be\nmade terminating, a consequence of a much stronger result: a uniform protocol\nfor any task requiring more than constant time cannot be terminating even with\nprobability bounded above 0, if infinitely many initial configurations are\ndense: any state present initially occupies $\\Omega(n)$ agents. (In particular,\nno leader is allowed.) Crucially, the result holds no matter the memory or time\npermitted. Finally, we show that with an initial leader, our size-estimation\nprotocol can be made terminating with high probability, with the same\nasymptotic time and space bounds.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 16:29:15 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 21:29:28 GMT"}, {"version": "v3", "created": "Wed, 17 Apr 2019 18:48:51 GMT"}, {"version": "v4", "created": "Sun, 28 Jul 2019 18:02:26 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Doty", "David", ""], ["Eftekhari", "Mahsa", ""]]}, {"id": "1808.09194", "submitter": "Pierre Guillon", "authors": "Pierre Guillon (I2M), Emmanuel Jeandel (CARTE), Jarkko Kari, Pascal\n  Vanier (LACL)", "title": "Undecidable word problem in subshift automorphism groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.DS math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies the complexity of the word problem in groups of\nautomorphisms of subshifts. We show in particular that for any Turing degree,\nthere exists a subshift whose automorphism group contains a subgroup whose word\nproblem has exactly this degree.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 09:31:41 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 06:29:25 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Guillon", "Pierre", "", "I2M"], ["Jeandel", "Emmanuel", "", "CARTE"], ["Kari", "Jarkko", "", "LACL"], ["Vanier", "Pascal", "", "LACL"]]}, {"id": "1808.09226", "submitter": "Julian M\\\"uller", "authors": "Julian M\\\"uller, Sven Kosub", "title": "A Note on the Complexity of Manipulating Weighted Schulze Voting", "comments": "Accepted manuscript; proof of Lemma 8 corrected", "journal-ref": "Information Processing Letters, 162:105989, 2020", "doi": "10.1016/j.ipl.2020.105989", "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the constructive weighted coalitional manipulation problem for\nthe Schulze voting rule can be solved in polynomial time for an unbounded\nnumber of candidates and an unbounded number of manipulators.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 11:21:13 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 20:30:40 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["M\u00fcller", "Julian", ""], ["Kosub", "Sven", ""]]}, {"id": "1808.09586", "submitter": "Mee Seong Im", "authors": "Venkat R. Dasari, Mee Seong Im, Billy Geerhart", "title": "Complexity and mission computability of adaptive computing systems", "comments": "6 pages, 3 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.CL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a subset of computational problems that are computable in polynomial\ntime for which an existing algorithm may not complete due to a lack of high\nperformance technology on a mission field. We define a subclass of\ndeterministic polynomial time complexity class called mission class, as many\npolynomial problems are not computable in mission time. By focusing on such\nsubclass of languages in the context for successful military applications, we\nalso discuss their computational and communicational constraints. We\ninvestigate feasible (non)linear models that will minimize energy and maximize\nmemory, efficiency, and computational power, and also provide an approximate\nsolution obtained within a pre-determined length of computation time using\nlimited resources so that an optimal solution to a language could be\ndetermined.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 00:03:04 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Dasari", "Venkat R.", ""], ["Im", "Mee Seong", ""], ["Geerhart", "Billy", ""]]}, {"id": "1808.09669", "submitter": "Ankit Garg", "authors": "Ankit Garg and Rafael Oliveira", "title": "Recent progress on scaling algorithms and applications", "comments": "Survey written for EATCS complexity column; issue June 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling problems have a rich and diverse history, and thereby have found\nnumerous applications in several fields of science and engineering. For\ninstance, the matrix scaling problem has had applications ranging from\ntheoretical computer science to telephone forecasting, economics, statistics,\noptimization, among many other fields. Recently, a generalization of matrix\nscaling known as operator scaling has found applications in non-commutative\nalgebra, invariant theory, combinatorics and algebraic complexity; and a\nfurther generalization (tensor scaling) has found more applications in quantum\ninformation theory, geometric complexity theory and invariant theory. In this\nsurvey, we will describe in detail the scaling problems mentioned above,\nshowing how alternating minimization algorithms naturally arise in this\nsetting, and we shall present a general framework to rigorously analyze such\nalgorithms. These simple problems and algorithms are not just applicable to\ndiverse mathematical and CS areas, but also serve to bring out deep connections\nbetween them. As this framework makes extensive use of concepts from invariant\ntheory, we also provide a very gentle introduction to basic concepts of\ninvariant theory and how they are used to analyze alternating minimization\nalgorithms for the scaling problems. This survey is intended for a general\ncomputer science audience, and the only background required is basic knowledge\nof calculus and linear algebra, thereby making it accessible to graduate\nstudents and even to advanced undergraduates.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 07:54:51 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Garg", "Ankit", ""], ["Oliveira", "Rafael", ""]]}, {"id": "1808.10068", "submitter": "Manuel Bodirsky", "authors": "Manuel Bodirsky and Marcello Mamino", "title": "A polynomial-time algorithm for median-closed semilinear constraints", "comments": "19 pages, 8 figures; in v2, several mistakes in proofs have been\n  fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A subset of Q^n is called semilinear (or piecewise linear) if it is Boolean\ncombination of linear half-spaces. We study the computational complexity of the\nconstraint satisfaction problem (CSP) over the rationals when all the\nconstraints are semilinear. When the sets are convex the CSP is polynomial-time\nequivalent to linear programming. A semilinear relation is convex if and only\nif it is preserved by taking averages. Our main result is a polynomial-time\nalgorithm for the CSP of semilinear constraints that are preserved by applying\nmedians. We also prove that this class is maximally tractable in the sense that\nany larger class of semilinear relations has an NP-hard CSP. To illustrate, our\nclass contains all relations that can be expressed by linear inequalities with\nat most two variables (so-called TVPI constraints), but it also contains many\nnon-convex relations, for example constraints of the form x in S for arbitrary\nfinite subset S of Q, or more generally disjunctive constraints of the form x <\nc or y < d for constants c and d.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 23:34:17 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 09:58:33 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mamino", "Marcello", ""]]}, {"id": "1808.10137", "submitter": "David Tankus", "authors": "David Tankus", "title": "Recognizing Generating Subgraphs in Graphs without Cycles of Lengths 6\n  and 7", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $B$ be an induced complete bipartite subgraph of $G$ on vertex sets of\nbipartition $B_{X}$ and $B_{Y}$. The subgraph $B$ is {\\it generating} if there\nexists an independent set $S$ such that each of $S \\cup B_{X}$ and $S \\cup\nB_{Y}$ is a maximal independent set in the graph. If $B$ is generating, it\n\\textit{produces} the restriction $w(B_{X})=w(B_{Y})$. Let $w:V(G)\n\\longrightarrow\\mathbb{R}$ be a weight function. We say that $G$ is\n$w$-well-covered if all maximal independent sets are of the same weight. The\ngraph $G$ is $w$-well-covered if and only if $w$ satisfies all restrictions\nproduced by all generating subgraphs of $G$. Therefore, generating subgraphs\nplay an important role in characterizing weighted well-covered graphs. It is an\n\\textbf{NP}-complete problem to decide whether a subgraph is generating, even\nwhen the subgraph is isomorphic to $K_{1,1}$ \\cite{bnz:related}. We present a\npolynomial algorithm for recognizing generating subgraphs for graphs without\ncycles of lengths 6 and 7.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 06:35:49 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Tankus", "David", ""]]}, {"id": "1808.10191", "submitter": "Krishnamoorthy Dinesh", "authors": "Krishnamoorthy Dinesh and Jayalal Sarma", "title": "Sensitivity, Affine Transforms and Quantum Communication Complexity", "comments": "19 pages, 1 figure. Added a new lower bound for shifted alternation\n  (in Section 3) and an application to the existence of family of functions\n  under linear transforms (in Section 5)", "journal-ref": null, "doi": "10.1016/j.tcs.2020.05.048", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\newcommand{\\F}{\\mathbb{F}}$We study the Boolean function parameters\nsensitivity ($s$), block sensitivity ($bs$), and alternation ($alt$) under\nspecially designed affine transforms. For a function $f:\\F_2^n\\to \\{0,1\\}$, and\n$A=Mx+b$ for $M \\in \\F_2^{n\\times n}$ and $b\\in \\F_2^n$, the result of the\ntransformation $g$ is defined as $\\forall x\\in\\F_2^n, g(x)=f(Mx+b)$.\n  We study alternation under linear shifts ($M$ is the identity matrix) called\nthe shift invariant alternation (denoted by $salt(f)$). We exhibit an explicit\nfamily of functions for which $salt(f)$ is $2^{\\Omega(s(f))}$. We show an\naffine transform $A$, such that the corresponding function $g$ satisfies\n$bs(f,0^n) \\le s(g)$, using which we proving that for $F(x,y)=f(x\\land y)$, the\nbounded error quantum communication complexity of $F$ with prior entanglement,\n$Q^*_{1/3}(F)=\\Omega(\\sqrt{bs(f,0^n)})$. Our proof builds on ideas from\nSherstov (2010) where we use specific properties of the above affine\ntransformation. We show,\n  * For a prime $p$ and $0<\\epsilon<1$, any $f$ with\n$deg_p(f)\\le(1-\\epsilon)\\log n$ must satisfy $Q^*_{1/3}(F) =\n\\Omega(\\frac{n^{\\epsilon/2}}{\\log n})$. Here, $deg_p(f)$ denotes the degree of\nthe multilinear polynomial of $f$ over $\\F_p$.\n  * For any $f$ such that there exists primes $p$ and $q$ with $deg_q(f) \\ge\n\\Omega(deg_p(f)^\\delta)$ for $\\delta > 2$, the deterministic communication\ncomplexity - $D(F)$ and $Q^*_{1/3}(F)$ are polynomially related. In particular,\nthis holds when $deg_p(f) = O(1)$. Thus, for this class of functions, this\nanswers an open question (see Buhrman and deWolf (2001)) about the relation\nbetween the two measures.\n  We construct linear transformation $A$, such that $g$ satisfies, $alt(f) \\le\n2s(g)+1$. Using this, we exhibit a family of Boolean functions that rule out a\npotential approach to settle the XOR Log-Rank conjecture via a proof of\nSensitivity conjecture [Hao Huang (2019)].\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 09:09:30 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 04:24:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Dinesh", "Krishnamoorthy", ""], ["Sarma", "Jayalal", ""]]}, {"id": "1808.10531", "submitter": "J. Maurice Rojas", "authors": "Leann Kopp, Natalie Randall, J. Maurice Rojas, and Yuyu Zhu", "title": "Randomized Polynomial-Time Root Counting in Prime Power Rings", "comments": "11 pages, 3 figures. Qi Cheng just pointed out that [3, Cor. 4, Pg.\n  16] proves a generalization of the main result (Theorem 1.1), and gives a\n  sharper complexity bound. Nevertheless, the underlying algorithms are\n  approached differently, so the development of our paper (the recursion tree\n  structure, in particular) may still be of value", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose $k,p\\!\\in\\!\\mathbb{N}$ with $p$ prime and $f\\!\\in\\!\\mathbb{Z}[x]$ is\na univariate polynomial with degree $d$ and all coefficients having absolute\nvalue less than $p^k$. We give a Las Vegas randomized algorithm that computes\nthe number of roots of $f$ in $\\mathbb{Z}/\\!\\left(p^k\\right)$ within time\n$d^3(k\\log p)^{2+o(1)}$. (We in fact prove a more intricate complexity bound\nthat is slightly better.) The best previous general algorithm had\n(deterministic) complexity exponential in $k$. We also present some\nexperimental data evincing the potential practicality of our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 21:50:17 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 19:15:48 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Kopp", "Leann", ""], ["Randall", "Natalie", ""], ["Rojas", "J. Maurice", ""], ["Zhu", "Yuyu", ""]]}]