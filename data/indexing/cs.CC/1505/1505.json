[{"id": "1505.00058", "submitter": "David Tian", "authors": "Wenhong Tian, GuoZhong Li, Xinyang Wang, Qin Xiong, Yaqiu Jiang", "title": "Transforming NP to P: An Approach to Solve NP Complete Problems", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  NP complete problem is one of the most challenging issues. The question of\nwhether all problems in NP are also in P is generally considered one of the\nmost important open questions in mathematics and theoretical computer science\nas it has far-reaching consequences to other problems in mathematics, computer\nscience, biology, philosophy and cryptography. There are intensive research on\nproving `NP not equal to P' and `NP equals to P'. However, none of the `proved'\nresults is commonly accepted by the research community up to now. In this\npaper, instead of proving either one, we aim to provide new perspective:\ntransforming two typical NP complete problems to exactly solvable P problems in\npolynomial time. This approach helps to solve originally NP complete problems\nwith practical applications. It may shine light on solving other NP complete\nproblems in similar way.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 18:27:10 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Tian", "Wenhong", ""], ["Li", "GuoZhong", ""], ["Wang", "Xinyang", ""], ["Xiong", "Qin", ""], ["Jiang", "Yaqiu", ""]]}, {"id": "1505.00090", "submitter": "Paul Beame", "authors": "Paul Beame and Vincent Liew and Mihai P\\v{a}tra\\c{s}cu", "title": "Finding the Median (Obliviously) with Bounded Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that any oblivious algorithm using space $S$ to find the median of a\nlist of $n$ integers from $\\{1,...,2n\\}$ requires time $\\Omega(n \\log\\log_S\nn)$. This bound also applies to the problem of determining whether the median\nis odd or even. It is nearly optimal since Chan, following Munro and Raman, has\nshown that there is a (randomized) selection algorithm using only $s$\nregisters, each of which can store an input value or $O(\\log n)$-bit counter,\nthat makes only $O(\\log\\log_s n)$ passes over the input. The bound also implies\na size lower bound for read-once branching programs computing the low order bit\nof the median and implies the analog of $P \\ne NP \\cap coNP$ for length $o(n\n\\log\\log n)$ oblivious branching programs.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2015 05:12:23 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Beame", "Paul", ""], ["Liew", "Vincent", ""], ["P\u01cetra\u015fcu", "Mihai", ""]]}, {"id": "1505.00107", "submitter": "Eshan Chattopadhyay", "authors": "Eshan Chattopadhyay, Vipul Goyal, Xin Li", "title": "Non-Malleable Extractors and Codes, with their Many Tampered Extensions", "comments": "50 pages; see paper for full abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomness extractors and error correcting codes are fundamental objects in\ncomputer science. Recently, there have been several natural generalizations of\nthese objects, in the context and study of tamper resilient cryptography. These\nare seeded non-malleable extractors, introduced in [DW09]; seedless\nnon-malleable extractors, introduced in [CG14b]; and non-malleable codes,\nintroduced in [DPW10].\n  However, explicit constructions of non-malleable extractors appear to be\nhard, and the known constructions are far behind their non-tampered\ncounterparts.\n  In this paper we make progress towards solving the above problems. Our\ncontributions are as follows.\n  (1) We construct an explicit seeded non-malleable extractor for min-entropy\n$k \\geq \\log^2 n$. This dramatically improves all previous results and gives a\nsimpler 2-round privacy amplification protocol with optimal entropy loss,\nmatching the best known result in [Li15b].\n  (2) We construct the first explicit non-malleable two-source extractor for\nmin-entropy $k \\geq n-n^{\\Omega(1)}$, with output size $n^{\\Omega(1)}$ and\nerror $2^{-n^{\\Omega(1)}}$.\n  (3) We initiate the study of two natural generalizations of seedless\nnon-malleable extractors and non-malleable codes, where the sources or the\ncodeword may be tampered many times. We construct the first explicit\nnon-malleable two-source extractor with tampering degree $t$ up to\n$n^{\\Omega(1)}$, which works for min-entropy $k \\geq n-n^{\\Omega(1)}$, with\noutput size $n^{\\Omega(1)}$ and error $2^{-n^{\\Omega(1)}}$. We show that we can\nefficiently sample uniformly from any pre-image. By the connection in [CG14b],\nwe also obtain the first explicit non-malleable codes with tampering degree $t$\nup to $n^{\\Omega(1)}$, relative rate $n^{\\Omega(1)}/n$, and error\n$2^{-n^{\\Omega(1)}}$.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2015 07:18:34 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Chattopadhyay", "Eshan", ""], ["Goyal", "Vipul", ""], ["Li", "Xin", ""]]}, {"id": "1505.00118", "submitter": "Jan Krajicek", "authors": "Jan Krajicek", "title": "Expansions of pseudofinite structures and circuit and proof complexity", "comments": "Preliminary version May 2015", "journal-ref": "Tributes Ser. Vol.30, College Publications, London, (2016),\n  pp.195-203", "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I shall describe a general model-theoretic task to construct expansions of\npseudofinite structures and discuss several examples of particular relevance to\ncomputational complexity. Then I will present one specific situation where\nfinding a suitable expansion would imply that, assuming a one-way permutation\nexists, the computational class NP is not closed under complementation.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2015 08:24:10 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Krajicek", "Jan", ""]]}, {"id": "1505.00388", "submitter": "Mark Bun", "authors": "Mark Bun and Mark Zhandry", "title": "Order-Revealing Encryption and the Hardness of Private Learning", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An order-revealing encryption scheme gives a public procedure by which two\nciphertexts can be compared to reveal the ordering of their underlying\nplaintexts. We show how to use order-revealing encryption to separate\ncomputationally efficient PAC learning from efficient $(\\epsilon,\n\\delta)$-differentially private PAC learning. That is, we construct a concept\nclass that is efficiently PAC learnable, but for which every efficient learner\nfails to be differentially private. This answers a question of Kasiviswanathan\net al. (FOCS '08, SIAM J. Comput. '11).\n  To prove our result, we give a generic transformation from an order-revealing\nencryption scheme into one with strongly correct comparison, which enables the\nconsistent comparison of ciphertexts that are not obtained as the valid\nencryption of any message. We believe this construction may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2015 02:23:49 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Bun", "Mark", ""], ["Zhandry", "Mark", ""]]}, {"id": "1505.00612", "submitter": "P{\\aa}l Gr{\\o}n{\\aa}s Drange", "authors": "P{\\aa}l Gr{\\o}n{\\aa}s Drange and Markus Sortland Dregi and Daniel\n  Lokshtanov and Blair D. Sullivan", "title": "On the Threshold of Intractability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of the graph modification problems\nThreshold Editing and Chain Editing, adding and deleting as few edges as\npossible to transform the input into a threshold (or chain) graph. In this\narticle, we show that both problems are NP-complete, resolving a conjecture by\nNatanzon, Shamir, and Sharan (Discrete Applied Mathematics, 113(1):109--128,\n2001). On the positive side, we show the problem admits a quadratic vertex\nkernel. Furthermore, we give a subexponential time parameterized algorithm\nsolving Threshold Editing in $2^{O(\\surd k \\log k)} + \\text{poly}(n)$ time,\nmaking it one of relatively few natural problems in this complexity class on\ngeneral graphs. These results are of broader interest to the field of social\nnetwork analysis, where recent work of Brandes (ISAAC, 2014) posits that the\nminimum edit distance to a threshold graph gives a good measure of consistency\nfor node centralities. Finally, we show that all our positive results extend to\nthe related problem of Chain Editing, as well as the completion and deletion\nvariants of both problems.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2015 12:46:20 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Drange", "P\u00e5l Gr\u00f8n\u00e5s", ""], ["Dregi", "Markus Sortland", ""], ["Lokshtanov", "Daniel", ""], ["Sullivan", "Blair D.", ""]]}, {"id": "1505.00619", "submitter": "Arnab Bhattacharyya", "authors": "Arnab Bhattacharyya and Abhishek Bhowmick", "title": "Using higher-order Fourier analysis over general fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.IT math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order Fourier analysis, developed over prime fields, has been recently\nused in different areas of computer science, including list decoding,\nalgorithmic decomposition and testing. We extend the tools of higher-order\nFourier analysis to analyze functions over general fields. Using these new\ntools, we revisit the results in the above areas.\n  * For any fixed finite field $\\mathbb{K}$, we show that the list decoding\nradius of the generalized Reed Muller code over $\\mathbb{K}$ equals the minimum\ndistance of the code. Previously, this had been proved over prime fields [BL14]\nand for the case when $|\\mathbb{K}|-1$ divides the order of the code [GKZ08].\n  * For any fixed finite field $\\mathbb{K}$, we give a polynomial time\nalgorithm to decide whether a given polynomial $P: \\mathbb{K}^n \\to \\mathbb{K}$\ncan be decomposed as a particular composition of lesser degree polynomials.\nThis had been previously established over prime fields [Bha14, BHT15].\n  * For any fixed finite field $\\mathbb{K}$, we prove that all locally\ncharacterized affine-invariant properties of functions $f: \\mathbb{K}^n \\to\n\\mathbb{K}$ are testable with one-sided error. The same result was known when\n$\\mathbb{K}$ is prime [BFHHL13] and when the property is linear [KS08].\nMoreover, we show that for any fixed finite field $\\mathbb{F}$, an\naffine-invariant property of functions $f: \\mathbb{K}^n \\to \\mathbb{F}$, where\n$\\mathbb{K}$ is a growing field extension over $\\mathbb{F}$, is testable if it\nis locally characterized by constraints of bounded weight.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2015 13:05:20 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Bhowmick", "Abhishek", ""]]}, {"id": "1505.00731", "submitter": "Laurent Bienvenu", "authors": "Laurent Bienvenu (LIAFA - CNRS and Universit\\'e Paris 7), Damien\n  Desfontaines (Google Inc, Zurich), Alexander Shen (LIRMM - CNRS and\n  Universit\\'e Montpellier 2)", "title": "Generic algorithms for halting problem and optimal machines revisited", "comments": "a preliminary version was presented at the ICALP 2015 conference", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 2 (April 5,\n  2016) lmcs:1633", "doi": "10.2168/LMCS-12(2:1)2016", "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The halting problem is undecidable --- but can it be solved for \"most\"\ninputs? This natural question was considered in a number of papers, in\ndifferent settings. We revisit their results and show that most of them can be\neasily proven in a natural framework of optimal machines (considered in\nalgorithmic information theory) using the notion of Kolmogorov complexity. We\nalso consider some related questions about this framework and about asymptotic\nproperties of the halting problem. In particular, we show that the fraction of\nterminating programs cannot have a limit, and all limit points are Martin-L\\\"of\nrandom reals. We then consider mass problems of finding an approximate solution\nof halting problem and probabilistic algorithms for them, proving both positive\nand negative results. We consider the fraction of terminating programs that\nrequire a long time for termination, and describe this fraction using the busy\nbeaver function. We also consider approximate versions of separation problems,\nand revisit Schnorr's results about optimal numberings showing how they can be\ngeneralized.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2015 17:59:56 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 18:25:13 GMT"}, {"version": "v3", "created": "Mon, 4 Apr 2016 12:12:07 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Bienvenu", "Laurent", "", "LIAFA - CNRS and Universit\u00e9 Paris 7"], ["Desfontaines", "Damien", "", "Google Inc, Zurich"], ["Shen", "Alexander", "", "LIRMM - CNRS and\n  Universit\u00e9 Montpellier 2"]]}, {"id": "1505.01340", "submitter": "Damien Desfontaines", "authors": "Cristian S. Calude, Damien Desfontaines", "title": "Universality and Almost Decidability", "comments": null, "journal-ref": "Fundamenta Informaticae XXI (2014) 1001-1008", "doi": "10.3233/FI-2012-0000", "report-no": "CDMTCS-462", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and study new definitions of universal and programmable universal\nunary functions and consider a new simplicity criterion: almost decidability of\nthe halting set. A set of positive integers S is almost decidable if there\nexists a decidable and generic (i.e. a set of natural density one) set whose\nintersection with S is decidable. Every decidable set is almost decidable, but\nthe converse implication is false. We prove the existence of infinitely many\nuniversal functions whose halting sets are generic (negligible, i.e. have\ndensity zero) and (not) almost decidable. One result - namely, the existence of\ninfinitely many universal functions whose halting sets are generic (negligible)\nand not almost decidable - solves an open problem in [9]. We conclude with some\nopen problems.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 12:32:07 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Calude", "Cristian S.", ""], ["Desfontaines", "Damien", ""]]}, {"id": "1505.01358", "submitter": "Jakob Nordstr\\\"om", "authors": "Mladen Mik\\v{s}a and Jakob Nordstr\\\"om", "title": "A Generalized Method for Proving Polynomial Calculus Degree Lower Bounds", "comments": "Full-length version of paper to appear in Proceedings of the 30th\n  Annual Computational Complexity Conference (CCC '15), June 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of obtaining lower bounds for polynomial calculus (PC)\nand polynomial calculus resolution (PCR) on proof degree, and hence by\n[Impagliazzo et al. '99] also on proof size. [Alekhnovich and Razborov '03]\nestablished that if the clause-variable incidence graph of a CNF formula F is a\ngood enough expander, then proving that F is unsatisfiable requires high PC/PCR\ndegree. We further develop the techniques in [AR03] to show that if one can\n\"cluster\" clauses and variables in a way that \"respects the structure\" of the\nformula in a certain sense, then it is sufficient that the incidence graph of\nthis clustered version is an expander. As a corollary of this, we prove that\nthe functional pigeonhole principle (FPHP) formulas require high PC/PCR degree\nwhen restricted to constant-degree expander graphs. This answers an open\nquestion in [Razborov '02], and also implies that the standard CNF encoding of\nthe FPHP formulas require exponential proof size in polynomial calculus\nresolution. Thus, while Onto-FPHP formulas are easy for polynomial calculus, as\nshown in [Riis '93], both FPHP and Onto-PHP formulas are hard even when\nrestricted to bounded-degree expanders.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 13:34:47 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Mik\u0161a", "Mladen", ""], ["Nordstr\u00f6m", "Jakob", ""]]}, {"id": "1505.01616", "submitter": "Nick Brettell", "authors": "Pierre Aboulker, Nick Brettell, Fr\\'ed\\'eric Havet, D\\'aniel Marx,\n  Nicolas Trotignon", "title": "Colouring graphs with constraints on connectivity", "comments": "The latest version has minor corrections and clarifications", "journal-ref": null, "doi": "10.1002/jgt.22109", "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph $G$ has maximal local edge-connectivity $k$ if the maximum number of\nedge-disjoint paths between every pair of distinct vertices $x$ and $y$ is at\nmost $k$. We prove Brooks-type theorems for $k$-connected graphs with maximal\nlocal edge-connectivity $k$, and for any graph with maximal local\nedge-connectivity 3. We also consider several related graph classes defined by\nconstraints on connectivity. In particular, we show that there is a\npolynomial-time algorithm that, given a 3-connected graph $G$ with maximal\nlocal connectivity 3, outputs an optimal colouring for $G$. On the other hand,\nwe prove, for $k \\ge 3$, that $k$-colourability is NP-complete when restricted\nto minimally $k$-connected graphs, and 3-colourability is NP-complete when\nrestricted to $(k-1)$-connected graphs with maximal local connectivity $k$.\nFinally, we consider a parameterization of $k$-colourability based on the\nnumber of vertices of degree at least $k+1$, and prove that, even when $k$ is\npart of the input, the corresponding parameterized problem is FPT.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2015 08:11:23 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2016 01:01:19 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Aboulker", "Pierre", ""], ["Brettell", "Nick", ""], ["Havet", "Fr\u00e9d\u00e9ric", ""], ["Marx", "D\u00e1niel", ""], ["Trotignon", "Nicolas", ""]]}, {"id": "1505.01964", "submitter": "Arne Meier", "authors": "Andreas Krebs and Arne Meier and Jonni Virtema", "title": "A Team Based Variant of CTL", "comments": "TIME 2015 conference version, modified title and motiviation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two variants of computation tree logic CTL based on team\nsemantics: an asynchronous one and a synchronous one. For both variants we\ninvestigate the computational complexity of the satisfiability as well as the\nmodel checking problem. The satisfiability problem is shown to be\nEXPTIME-complete. Here it does not matter which of the two semantics are\nconsidered. For model checking we prove a PSPACE-completeness for the\nsynchronous case, and show P-completeness for the asynchronous case.\nFurthermore we prove several interesting fundamental properties of both\nsemantics.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 09:25:41 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 12:15:40 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Krebs", "Andreas", ""], ["Meier", "Arne", ""], ["Virtema", "Jonni", ""]]}, {"id": "1505.02205", "submitter": "Tristram Bogart", "authors": "Jarod Alper, Tristram Bogart, Mauricio Velasco", "title": "A lower bound for the determinantal complexity of a hypersurface", "comments": "7 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the determinantal complexity of a hypersurface of degree $d >\n2$ is bounded below by one more than the codimension of the singular locus,\nprovided that this codimension is at least $5$. As a result, we obtain that the\ndeterminantal complexity of the $3 \\times 3$ permanent is $7$. We also prove\nthat for $n> 3$, there is no nonsingular hypersurface in $\\mathbf{P}^n$ of\ndegree $d$ that has an expression as a determinant of a $d \\times d$ matrix of\nlinear forms while on the other hand for $n \\le 3$, a general determinantal\nexpression is nonsingular. Finally, we answer a question of Ressayre by showing\nthat the determinantal complexity of the unique (singular) cubic surface\ncontaining a single line is $5$.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 23:01:13 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Alper", "Jarod", ""], ["Bogart", "Tristram", ""], ["Velasco", "Mauricio", ""]]}, {"id": "1505.02322", "submitter": "Tuomo Lempi\\\"ainen", "authors": "Tuomo Lempi\\\"ainen", "title": "Ability to Count Is Worth $\\Theta(\\Delta)$ Rounds", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hella et al. (PODC 2012, Distributed Computing 2015) identified seven\ndifferent models of distributed computing - one of which is the port-numbering\nmodel - and provided a complete classification of their computational power\nrelative to each other. However, one of their simulation results involves an\nadditive overhead of $2\\Delta-2$ communication rounds, and it was not clear, if\nthis is actually optimal. In this paper we give a positive answer: there is a\nmatching linear-in-$\\Delta$ lower bound. This closes the final gap in our\nunderstanding of the models, with respect to the number of communication\nrounds.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2015 22:03:32 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Lempi\u00e4inen", "Tuomo", ""]]}, {"id": "1505.02372", "submitter": "Dmitry Zakablukov", "authors": "Dmitry V. Zakablukov", "title": "On Asymptotic Gate Complexity and Depth of Reversible Circuits With\n  Additional Memory", "comments": "In English, 27 pages, 12 figures. Submission to the Computational\n  Complexity journal. arXiv admin note: text overlap with arXiv:1504.06876", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reversible logic can be used in various research areas, e.g. quantum\ncomputation, cryptography and signal processing. In the paper we study\nreversible logic circuits with additional inputs, which consist of NOT, CNOT\nand C\\textsuperscript{2}NOT gates. We consider a set $F(n,q)$ of all\ntransformations $\\mathbb B^n \\to \\mathbb B^n$ that can be realized by\nreversible circuits with $(n+q)$ inputs. An analogue of Lupanov's method for\nthe synthesis of reversible logic circuits with additional inputs is described.\nWe prove upper asymptotic bounds for the Shannon gate complexity function\n$L(n,q)$ and the depth function $D(n,q)$ in case of $q > 0$: $L(n,q_0) \\lesssim\n2^n$ if $q_0 \\sim n 2^{n-o(n)}$ and $D(n,q_1) \\lesssim 3n$ if $q_1 \\sim 2^n$.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2015 11:58:36 GMT"}, {"version": "v2", "created": "Sat, 30 May 2015 18:30:18 GMT"}, {"version": "v3", "created": "Sat, 19 Mar 2016 17:13:25 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Zakablukov", "Dmitry V.", ""]]}, {"id": "1505.02993", "submitter": "Tyson Williams", "authors": "Jin-Yi Cai, Zhiguo Fu, Heng Guo, Tyson Williams", "title": "A Holant Dichotomy: Is the FKT Algorithm Universal?", "comments": "128 pages, 36 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a complexity dichotomy for complex-weighted Holant problems with an\narbitrary set of symmetric constraint functions on Boolean variables. This\ndichotomy is specifically to answer the question: Is the FKT algorithm under a\nholographic transformation a \\emph{universal} strategy to obtain\npolynomial-time algorithms for problems over planar graphs that are intractable\nin general? This dichotomy is a culmination of previous ones, including those\nfor Spin Systems, Holant, and #CSP. A recurring theme has been that a\nholographic reduction to FKT is a universal strategy. Surprisingly, for planar\nHolant, we discover new planar tractable problems that are not expressible by a\nholographic reduction to FKT.\n  In previous work, an important tool was a dichotomy for #CSP^d, which denotes\n#CSP where every variable appears a multiple of d times. However its proof\nviolates planarity. We prove a dichotomy for planar #CSP^2. We apply this\nplanar #CSP^2 dichotomy in the proof of the planar Holant dichotomy.\n  As a special case of our new planar tractable problems, counting perfect\nmatchings (#PM) over k-uniform hypergraphs is polynomial-time computable when\nthe incidence graph is planar and k >= 5. The same problem is #P-hard when k=3\nor k=4, which is also a consequence of our dichotomy. When k=2, it becomes #PM\nover planar graphs and is tractable again. More generally, over hypergraphs\nwith specified hyperedge sizes and the same planarity assumption, #PM is\npolynomial-time computable if the greatest common divisor of all hyperedge\nsizes is at least 5.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2015 13:08:25 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Fu", "Zhiguo", ""], ["Guo", "Heng", ""], ["Williams", "Tyson", ""]]}, {"id": "1505.03110", "submitter": "Young Kun Ko", "authors": "Mark Braverman, Ankit Garg, Young Kun Ko, Jieming Mao, Dave Touchette", "title": "Near-optimal bounds on bounded-round quantum communication complexity of\n  disjointness", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a near optimal round-communication tradeoff for the two-party\nquantum communication complexity of disjointness. For protocols with $r$\nrounds, we prove a lower bound of $\\tilde{\\Omega}(n/r + r)$ on the\ncommunication required for computing disjointness of input size $n$, which is\noptimal up to logarithmic factors. The previous best lower bound was\n$\\Omega(n/r^2 + r)$ due to Jain, Radhakrishnan and Sen [JRS03]. Along the way,\nwe develop several tools for quantum information complexity, one of which is a\nlower bound for quantum information complexity in terms of the generalized\ndiscrepancy method. As a corollary, we get that the quantum communication\ncomplexity of any boolean function $f$ is at most $2^{O(QIC(f))}$, where\n$QIC(f)$ is the prior-free quantum information complexity of $f$ (with error\n$1/3$).\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2015 18:23:54 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Braverman", "Mark", ""], ["Garg", "Ankit", ""], ["Ko", "Young Kun", ""], ["Mao", "Jieming", ""], ["Touchette", "Dave", ""]]}, {"id": "1505.03218", "submitter": "Ilya Kapovich", "authors": "Ilya Kapovich", "title": "Musings on generic-case complexity", "comments": "9 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.GR math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a more general definition of generic-case complexity, based on\nusing a random process for generating inputs of an algorithm and using the time\nneeded to generate an input as a way of measuring the size of that input.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 02:08:12 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Kapovich", "Ilya", ""]]}, {"id": "1505.03334", "submitter": "Frederic Magniez", "authors": "Nathana\\\"el Fran\\c{c}ois and Fr\\'ed\\'eric Magniez and Michel de\n  Rougemont and Olivier Serre", "title": "Streaming Property Testing of Visibly Pushdown Languages", "comments": "23 pages. Major modifications in the presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of language recognition, we demonstrate the superiority of\nstreaming property testers against streaming algorithms and property testers,\nwhen they are not combined. Initiated by Feigenbaum et al., a streaming\nproperty tester is a streaming algorithm recognizing a language under the\nproperty testing approximation: it must distinguish inputs of the language from\nthose that are $\\varepsilon$-far from it, while using the smallest possible\nmemory (rather than limiting its number of input queries).\n  Our main result is a streaming $\\varepsilon$-property tester for visibly\npushdown languages (VPL) with one-sided error using memory space\n$\\mathrm{poly}((\\log n) / \\varepsilon)$.\n  This constructions relies on a (non-streaming) property tester for weighted\nregular languages based on a previous tester by Alon et al. We provide a simple\napplication of this tester for streaming testing special cases of instances of\nVPL that are already hard for both streaming algorithms and property testers.\n  Our main algorithm is a combination of an original simulation of visibly\npushdown automata using a stack with small height but possible items of linear\nsize. In a second step, those items are replaced by small sketches. Those\nsketches relies on a notion of suffix-sampling we introduce. This sampling is\nthe key idea connecting our streaming tester algorithm to property testers.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 11:21:39 GMT"}, {"version": "v2", "created": "Sun, 24 May 2015 12:49:08 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2015 09:15:36 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2015 10:22:10 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Fran\u00e7ois", "Nathana\u00ebl", ""], ["Magniez", "Fr\u00e9d\u00e9ric", ""], ["de Rougemont", "Michel", ""], ["Serre", "Olivier", ""]]}, {"id": "1505.03424", "submitter": "Aravindan Vijayaraghavan", "authors": "Boaz Barak, Ankur Moitra, Ryan O'Donnell, Prasad Raghavendra, Oded\n  Regev, David Steurer, Luca Trevisan, Aravindan Vijayaraghavan, David Witmer\n  and John Wright", "title": "Beating the random assignment on constraint satisfaction problems of\n  bounded degree", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for any odd $k$ and any instance of the Max-kXOR constraint\nsatisfaction problem, there is an efficient algorithm that finds an assignment\nsatisfying at least a $\\frac{1}{2} + \\Omega(1/\\sqrt{D})$ fraction of\nconstraints, where $D$ is a bound on the number of constraints that each\nvariable occurs in. This improves both qualitatively and quantitatively on the\nrecent work of Farhi, Goldstone, and Gutmann (2014), which gave a\n\\emph{quantum} algorithm to find an assignment satisfying a $\\frac{1}{2} +\n\\Omega(D^{-3/4})$ fraction of the equations.\n  For arbitrary constraint satisfaction problems, we give a similar result for\n\"triangle-free\" instances; i.e., an efficient algorithm that finds an\nassignment satisfying at least a $\\mu + \\Omega(1/\\sqrt{D})$ fraction of\nconstraints, where $\\mu$ is the fraction that would be satisfied by a uniformly\nrandom assignment.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 15:27:16 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2015 14:18:26 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Barak", "Boaz", ""], ["Moitra", "Ankur", ""], ["O'Donnell", "Ryan", ""], ["Raghavendra", "Prasad", ""], ["Regev", "Oded", ""], ["Steurer", "David", ""], ["Trevisan", "Luca", ""], ["Vijayaraghavan", "Aravindan", ""], ["Witmer", "David", ""], ["Wright", "John", ""]]}, {"id": "1505.03587", "submitter": "Bj{\\o}rn Kjos-Hanssen", "authors": "Malihe Alikhani, Bj{\\o}rn Kjos-Hanssen, Amirarsalan Pakravan, and\n  Babak Saadat", "title": "Pricing complexity options", "comments": null, "journal-ref": "Algorithmic Finance (2015), 4:3-4, 127-137", "doi": "10.3233/AF-150050", "report-no": null, "categories": "q-fin.PR cs.CC cs.FL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider options that pay the complexity deficiency of a sequence of up\nand down ticks of a stock upon exercise. We study the price of European and\nAmerican versions of this option numerically for automatic complexity, and\ntheoretically for Kolmogorov complexity. We also consider run complexity, which\nis a restricted form of automatic complexity.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2015 01:01:51 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2016 01:00:43 GMT"}], "update_date": "2016-04-01", "authors_parsed": [["Alikhani", "Malihe", ""], ["Kjos-Hanssen", "Bj\u00f8rn", ""], ["Pakravan", "Amirarsalan", ""], ["Saadat", "Babak", ""]]}, {"id": "1505.03931", "submitter": "James Lathrop", "authors": "Titus H. Klinge, James I. Lathrop, Jack H. Lutz", "title": "Robust Biomolecular Finite Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.ET cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a uniform method for translating an arbitrary nondeterministic\nfinite automaton (NFA) into a deterministic mass action input/output chemical\nreaction network (I/O CRN) that simulates it. The I/O CRN receives its input as\na continuous time signal consisting of concentrations of chemical species that\nvary to represent the NFA's input string in a natural way. The I/O CRN exploits\nthe inherent parallelism of chemical kinetics to simulate the NFA in real time\nwith a number of chemical species that is linear in the size of the NFA. We\nprove that the simulation is correct and that it is robust with respect to\nperturbations of the input signal, the initial concentrations of species, the\noutput (decision), and the rate constants of the reactions of the I/O CRN.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 00:52:08 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 16:16:53 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Klinge", "Titus H.", ""], ["Lathrop", "James I.", ""], ["Lutz", "Jack H.", ""]]}, {"id": "1505.04274", "submitter": "Yushi Uno", "authors": "Stefan Langerman and Yushi Uno", "title": "Threes!, Fives, 1024!, and 2048 are Hard", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the computational complexity of the popular computer games\nThrees!, 1024!, 2048 and many of their variants. For most known versions\nexpanded to an m x n board, we show that it is NP-hard to decide whether a\ngiven starting position can be played to reach a specific (constant) tile\nvalue.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2015 13:39:07 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Langerman", "Stefan", ""], ["Uno", "Yushi", ""]]}, {"id": "1505.04383", "submitter": "David Witmer", "authors": "Sarah R. Allen, Ryan O'Donnell, David Witmer", "title": "How to refute a random CSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a $k$-ary predicate over a finite alphabet. Consider a random\nCSP$(P)$ instance $I$ over $n$ variables with $m$ constraints. When $m \\gg n$\nthe instance $I$ will be unsatisfiable with high probability, and we want to\nfind a refutation - i.e., a certificate of unsatisfiability. When $P$ is the\n$3$-ary OR predicate, this is the well studied problem of refuting random\n$3$-SAT formulas, and an efficient algorithm is known only when $m \\gg\nn^{3/2}$. Understanding the density required for refutation of other predicates\nis important in cryptography, proof complexity, and learning theory.\nPreviously, it was known that for a $k$-ary predicate, having $m \\gg n^{\\lceil\nk/2 \\rceil}$ constraints suffices for refutation. We give a criterion for\npredicates that often yields efficient refutation algorithms at much lower\ndensities. Specifically, if $P$ fails to support a $t$-wise uniform\ndistribution, then there is an efficient algorithm that refutes random CSP$(P)$\ninstances $I$ whp when $m \\gg n^{t/2}$. Indeed, our algorithm will \"somewhat\nstrongly\" refute $I$, certifying $\\mathrm{Opt}(I) \\leq 1-\\Omega_k(1)$, if $t =\nk$ then we get the strongest possible refutation, certifying $\\mathrm{Opt}(I)\n\\leq \\mathrm{E}[P] + o(1)$. This last result is new even in the context of\nrandom $k$-SAT. Regarding the optimality of our $m \\gg n^{t/2}$ requirement,\nprior work on SDP hierarchies has given some evidence that efficient refutation\nof random CSP$(P)$ may be impossible when $m \\ll n^{t/2}$. Thus there is an\nindication our algorithm's dependence on $m$ is optimal for every $P$, at least\nin the context of SDP hierarchies. Along these lines, we show that our\nrefutation algorithm can be carried out by the $O(1)$-round SOS SDP hierarchy.\nFinally, as an application of our result, we falsify assumptions used to show\nhardness-of-learning results in recent work of Daniely, Linial, and\nShalev-Shwartz.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2015 11:35:12 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2015 21:44:21 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2015 06:18:55 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Allen", "Sarah R.", ""], ["O'Donnell", "Ryan", ""], ["Witmer", "David", ""]]}, {"id": "1505.04969", "submitter": "Vangelis Paschos", "authors": "N. Bourgeois and R. Catellier and T. Denat and V. Th. Paschos", "title": "Average-case complexity of a branch-and-bound algorithm for maximum\n  independent set, under the $\\mathcal{G}(n,p)$ random model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study average-case complexity of branch-and-bound for maximum independent\nset in random graphs under the $\\mathcal{G}(n,p)$ distribution. In this model\nevery pair $(u,v)$ of vertices belongs to $E$ with probability $p$\nindependently on the existence of any other edge. We make a precise case\nanalysis, providing phase transitions between subexponential and exponential\ncomplexities depending on the probability $p$ of the random model.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 12:40:31 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Bourgeois", "N.", ""], ["Catellier", "R.", ""], ["Denat", "T.", ""], ["Paschos", "V. Th.", ""]]}, {"id": "1505.05079", "submitter": "Cameron Farnsworth", "authors": "Cameron Farnsworth", "title": "Koszul-Young Flattenings and Symmetric Border Rank of the Determinant", "comments": "11 pages. Additions to acknowledgements. Accepted to the Journal of\n  Algebra", "journal-ref": null, "doi": "10.1016/j.jalgebra.2015.11.011", "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new lower bounds for the symmetric border rank of the n x n\ndeterminant for all n. Further lower bounds are given for the 3 x 3 permanent.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 16:52:44 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2015 20:06:59 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Farnsworth", "Cameron", ""]]}, {"id": "1505.05800", "submitter": "Amit Daniely", "authors": "Amit Daniely", "title": "Complexity Theoretic Limitations on Learning Halfspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of agnostically learning halfspaces which is defined by\na fixed but unknown distribution $\\mathcal{D}$ on $\\mathbb{Q}^n\\times \\{\\pm\n1\\}$. We define $\\mathrm{Err}_{\\mathrm{HALF}}(\\mathcal{D})$ as the least error\nof a halfspace classifier for $\\mathcal{D}$. A learner who can access\n$\\mathcal{D}$ has to return a hypothesis whose error is small compared to\n$\\mathrm{Err}_{\\mathrm{HALF}}(\\mathcal{D})$.\n  Using the recently developed method of the author, Linial and Shalev-Shwartz\nwe prove hardness of learning results under a natural assumption on the\ncomplexity of refuting random $K$-$\\mathrm{XOR}$ formulas. We show that no\nefficient learning algorithm has non-trivial worst-case performance even under\nthe guarantees that $\\mathrm{Err}_{\\mathrm{HALF}}(\\mathcal{D}) \\le \\eta$ for\narbitrarily small constant $\\eta>0$, and that $\\mathcal{D}$ is supported in\n$\\{\\pm 1\\}^n\\times \\{\\pm 1\\}$. Namely, even under these favorable conditions\nits error must be $\\ge \\frac{1}{2}-\\frac{1}{n^c}$ for every $c>0$. In\nparticular, no efficient algorithm can achieve a constant approximation ratio.\nUnder a stronger version of the assumption (where $K$ can be poly-logarithmic\nin $n$), we can take $\\eta = 2^{-\\log^{1-\\nu}(n)}$ for arbitrarily small\n$\\nu>0$. Interestingly, this is even stronger than the best known lower bounds\n(Arora et. al. 1993, Feldamn et. al. 2006, Guruswami and Raghavendra 2006) for\nthe case that the learner is restricted to return a halfspace classifier (i.e.\nproper learning).\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 17:30:54 GMT"}, {"version": "v2", "created": "Sun, 13 Mar 2016 06:23:35 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Daniely", "Amit", ""]]}, {"id": "1505.05900", "submitter": "Vijay  Menon", "authors": "Vijay Menon and Kate Larson", "title": "Complexity of Manipulation in Elections with Top-truncated Ballots", "comments": "19 pages; additional results; added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the computational social choice literature, there has been great interest\nin understanding how computational complexity can act as a barrier against\nmanipulation of elections. Much of this literature, however, makes the\nassumption that the voters or agents specify a complete preference ordering\nover the set of candidates. There are many multiagent systems applications, and\neven real-world elections, where this assumption is not warranted, and this in\nturn raises the question \"How hard is it to manipulate elections if the agents\nreveal only partial preference orderings?\" It is this question we try to\naddress in this paper. In particular, we look at the weighted manipulation\nproblem -- both constructive and destructive manipulation -- when the voters\nare allowed to specify any top-truncated ordering over the set of candidates.\nWe provide general results for all scoring rules, for elimination versions of\nall scoring rules, for the plurality with runoff rule, for a family of election\nsystems known as Copeland$^{\\alpha}$, and for the maximin protocol. Finally, we\nalso look at the impact on complexity of manipulation when there is uncertainty\nabout the non-manipulators' votes.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 21:01:10 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2015 15:42:46 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Menon", "Vijay", ""], ["Larson", "Kate", ""]]}, {"id": "1505.06025", "submitter": "Etienne Birmele", "authors": "Ricardo Andrade (LBBE Lyon / INRIA Grenoble Rh\\^one-Alpes), Etienne\n  Birmel\\'e (MAP5), Arnaud Mary, Thomas Picchetti (MAP5), Marie-France Sagot\n  (LBBE Lyon / INRIA Grenoble Rh\\^one-Alpes)", "title": "Incremental complexity of a bi-objective hypergraph transversal problem", "comments": null, "journal-ref": null, "doi": null, "report-no": "MAP5 2015-16", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypergraph transversal problem has been intensively studied, from both a\ntheoretical and a practical point of view. In particular , its incremental\ncomplexity is known to be quasi-polynomial in general and polynomial for\nbounded hypergraphs. Recent applications in computational biology however\nrequire to solve a generalization of this problem, that we call bi-objective\ntransversal problem. The instance is in this case composed of a pair of\nhypergraphs (A, B), and the aim is to find minimal sets which hit all the\nhyperedges of A while intersecting a minimal set of hyperedges of B. In this\npaper, we formalize this problem, link it to a problem on monotone boolean\n$\\land$ -- $\\lor$ formulae of depth 3 and study its incremental complexity.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2015 11:06:52 GMT"}], "update_date": "2015-05-25", "authors_parsed": [["Andrade", "Ricardo", "", "LBBE Lyon / INRIA Grenoble Rh\u00f4ne-Alpes"], ["Birmel\u00e9", "Etienne", "", "MAP5"], ["Mary", "Arnaud", "", "MAP5"], ["Picchetti", "Thomas", "", "MAP5"], ["Sagot", "Marie-France", "", "LBBE Lyon / INRIA Grenoble Rh\u00f4ne-Alpes"]]}, {"id": "1505.06146", "submitter": "Andreas Galanis", "authors": "Andreas Galanis and Leslie Ann Goldberg", "title": "The complexity of approximately counting in 2-spin systems on\n  $k$-uniform bounded-degree hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important recent developments in the complexity of\napproximate counting is the classification of the complexity of approximating\nthe partition functions of antiferromagnetic 2-spin systems on bounded-degree\ngraphs. This classification is based on a beautiful connection to the so-called\nuniqueness phase transition from statistical physics on the infinite\n$\\Delta$-regular tree. Our objective is to study the impact of this\nclassification on unweighted 2-spin models on $k$-uniform hypergraphs. As has\nalready been indicated by Yin and Zhao, the connection between the uniqueness\nphase transition and the complexity of approximate counting breaks down in the\nhypergraph setting. Nevertheless, we show that for every non-trivial symmetric\n$k$-ary Boolean function $f$ there exists a degree bound $\\Delta_0$ so that for\nall $\\Delta \\geq \\Delta_0$ the following problem is NP-hard: given a\n$k$-uniform hypergraph with maximum degree at most $\\Delta$, approximate the\npartition function of the hypergraph 2-spin model associated with $f$. It is\nNP-hard to approximate this partition function even within an exponential\nfactor. By contrast, if $f$ is a trivial symmetric Boolean function (e.g., any\nfunction $f$ that is excluded from our result), then the partition function of\nthe corresponding hypergraph 2-spin model can be computed exactly in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2015 17:00:46 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2015 15:48:19 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2015 16:54:17 GMT"}, {"version": "v4", "created": "Mon, 20 Jun 2016 13:53:18 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Galanis", "Andreas", ""], ["Goldberg", "Leslie Ann", ""]]}, {"id": "1505.06284", "submitter": "Ahmed Younes Dr.", "authors": "Ahmed Younes", "title": "A Bounded-error Quantum Polynomial Time Algorithm for Two Graph\n  Bisection Problems", "comments": "17 Pages, 5 figures", "journal-ref": null, "doi": "10.1007/s11128-015-1069-y", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the paper is to propose a bounded-error quantum polynomial time\n(BQP) algorithm for the max-bisection and the min-bisection problems. The\nmax-bisection and the min-bisection problems are fundamental NP-hard problems.\nGiven a graph with even number of vertices, the aim of the max-bisection\nproblem is to divide the vertices into two subsets of the same size to maximize\nthe number of edges between the two subsets, while the aim of the min-bisection\nproblem is to minimize the number of edges between the two subsets. The\nproposed algorithm runs in $O(m^2)$ for a graph with $m$ edges and in the worst\ncase runs in $O(n^4)$ for a dense graph with $n$ vertices. The proposed\nalgorithm targets a general graph by representing both problems as Boolean\nconstraint satisfaction problems where the set of satisfied constraints are\nsimultaneously maximized/minimized using a novel iterative partial negation and\npartial measurement technique. The algorithm is shown to achieve an arbitrary\nhigh probability of success of $1-\\epsilon$ for small $\\epsilon>0$ using a\npolynomial space resources.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 07:54:39 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Younes", "Ahmed", ""]]}, {"id": "1505.06362", "submitter": "Prahladh Harsha", "authors": "Irit Dinur and Prahladh Harsha and Guy Kindler", "title": "Polynomially Low Error PCPs with polyloglog n Queries via Modular\n  Composition", "comments": null, "journal-ref": "In Proc. 47th ACM Symp. on Theory of Computing (STOC), pages\n  267-276, 2015", "doi": "10.1145/2746539.2746630", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every language in NP has a PCP verifier that tosses $O(\\log n)$\nrandom coins, has perfect completeness, and a soundness error of at most\n$1/\\text{poly}(n)$, while making at most $O(\\text{poly}\\log\\log n)$ queries\ninto a proof over an alphabet of size at most $n^{1/\\text{poly}\\log\\log n}$.\nPrevious constructions that obtain $1/\\text{poly}(n)$ soundness error used\neither $\\text{poly}\\log n $ queries or an exponential sized alphabet, i.e. of\nsize $2^{n^c}$ for some $c>0$. Our result is an exponential improvement in both\nparameters simultaneously.\n  Our result can be phrased as a polynomial-gap hardness for approximate CSPs\nwith arity $\\text{poly}\\log\\log n$ and alphabet size $n^{1/\\text{poly}\\log n}$.\nThe ultimate goal, in this direction, would be to prove polynomial hardness for\nCSPs with constant arity and polynomial alphabet size (aka the sliding scale\nconjecture for inverse polynomial soundness error).\n  Our construction is based on a modular generalization of previous PCP\nconstructions in this parameter regime, which involves a composition theorem\nthat uses an extra `consistency' query but maintains the inverse polynomial\nrelation between the soundness error and the alphabet size.\n  Our main technical/conceptual contribution is a new notion of soundness,\nwhich we refer to as {\\em distributional soundness}, that replaces the previous\nnotion of \"list decoding soundness\", and that allows us to prove a modular\ncomposition theorem with tighter parameters. This new notion of soundness\nallows us to invoke composition a super-constant number of times without\nincurring a blow-up in the soundness error.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 18:56:33 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Dinur", "Irit", ""], ["Harsha", "Prahladh", ""], ["Kindler", "Guy", ""]]}, {"id": "1505.06506", "submitter": "Edward Haeusler", "authors": "Edward Hermann Haeusler", "title": "Every super-polynomial proof in purely implicational minimal logic has a\n  polynomially sized proof in classical implicational propositional logic", "comments": "This paper has been withdrawn by the author due to a fatal error in\n  the general form of the deduction used for proved the main proposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this article we show how any formula A with a proof in minimal\nimplicational logic that is super-polynomially sized has a polynomially-sized\nproof in classical implicational propositional logic . This fact provides an\nargument in favor that any classical propositional tautology has short proofs,\ni.e., NP=CoNP.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 01:02:14 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2015 01:16:00 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2015 16:55:32 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Haeusler", "Edward Hermann", ""]]}, {"id": "1505.06508", "submitter": "Scott Garrabrant", "authors": "Scott Garrabrant and Igor Pak", "title": "Pattern avoidance is not P-recursive", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $F \\subset S_k$ be a finite set of permutations and let $C_n(F)$ denote\nthe number of permutations $\\sigma$ in $S_n$ avoiding the set of patterns $F$.\nThe Noonan-Zeilberger conjecture states that the sequence ${C_n(F)}$ is\nP-recursive. We use Computability Theory to disprove this conjecture.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 01:11:09 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Garrabrant", "Scott", ""], ["Pak", "Igor", ""]]}, {"id": "1505.06595", "submitter": "David Stanovsk\\'y", "authors": "Andrew Fish, Alexei Lisitsa, David Stanovsk\\'y", "title": "A combinatorial approach to knot recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a report on our ongoing research on a combinatorial approach to knot\nrecognition, using coloring of knots by certain algebraic objects called\nquandles. The aim of the paper is to summarize the mathematical theory of knot\ncoloring in a compact, accessible manner, and to show how to use it for\ncomputational purposes. In particular, we address how to determine colorability\nof a knot, and propose to use SAT solving to search for colorings. The\ncomputational complexity of the problem, both in theory and in our\nimplementation, is discussed. In the last part, we explain how coloring can be\nutilized in knot recognition.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 11:22:24 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Fish", "Andrew", ""], ["Lisitsa", "Alexei", ""], ["Stanovsk\u00fd", "David", ""]]}, {"id": "1505.06802", "submitter": "Wei Xu", "authors": "Wei Xu, Pan Zhang, Tian Liu, and Fuzhou Gong", "title": "Solution space structure of random constraint satisfaction problems with\n  growing domains", "comments": "8 pages, 1 figures", "journal-ref": null, "doi": "10.1088/1742-5468/2015/12/P12006", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the solution space structure of model RB, a standard\nprototype of Constraint Satisfaction Problem (CSPs) with growing domains. Using\nrigorous the first and the second moment method, we show that in the solvable\nphase close to the satisfiability transition, solutions are clustered into\nexponential number of well-separated clusters, with each cluster contains\nsub-exponential number of solutions. As a consequence, the system has a\nclustering (dynamical) transition but no condensation transition. This picture\nof phase diagram is different from other classic random CSPs with fixed domain\nsize, such as random K-Satisfiability (K-SAT) and graph coloring problems,\nwhere condensation transition exists and is distinct from satisfiability\ntransition. Our result verifies the non-rigorous results obtained using cavity\nmethod from spin glass theory, and sheds light on the structures of solution\nspaces of problems with a large number of states.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 04:42:53 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2015 15:04:45 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2015 05:03:20 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Xu", "Wei", ""], ["Zhang", "Pan", ""], ["Liu", "Tian", ""], ["Gong", "Fuzhou", ""]]}, {"id": "1505.06818", "submitter": "EPTCS", "authors": "Aart Middeldorp (University of Innsbruck), Femke van Raamsdonk (VU\n  University Amsterdam)", "title": "Proceedings 8th International Workshop on Computing with Terms and\n  Graphs", "comments": null, "journal-ref": "EPTCS 183, 2015", "doi": "10.4204/EPTCS.183", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the post-proceedings of the 8th International Workshop\non Computing with Terms and Graphs (TERMGRAPH 2014). The workshop took place in\nVienna on July 13, 2014 and was affiliated with the joint RTA and TLCA\nconference, which was part of the Federated Logic Conference (FLoC), which in\nturn participated in the Vienna Summer of Logic (VSL) 2014.\n  The four regular papers in these proceedings are significantly extended\nversions of their pre-proceedings version. They were subjected to an additional\nround of reviewing. The paper by Samuel Mimram is an invited contribution.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 06:25:48 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Middeldorp", "Aart", "", "University of Innsbruck"], ["van Raamsdonk", "Femke", "", "VU\n  University Amsterdam"]]}, {"id": "1505.07163", "submitter": "EPTCS", "authors": "Naohi Eguchi (Chiba University)", "title": "Complexity Analysis of Precedence Terminating Infinite Graph Rewrite\n  Systems", "comments": "In Proceedings TERMGRAPH 2014, arXiv:1505.06818. arXiv admin note:\n  text overlap with arXiv:1404.6196", "journal-ref": "EPTCS 183, 2015, pp. 33-47", "doi": "10.4204/EPTCS.183.3", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general form of safe recursion (or ramified recurrence) can be expressed\nby an infinite graph rewrite system including unfolding graph rewrite rules\nintroduced by Dal Lago, Martini and Zorzi, in which the size of every normal\nform by innermost rewriting is polynomially bounded. Every unfolding graph\nrewrite rule is precedence terminating in the sense of Middeldorp, Ohsaki and\nZantema. Although precedence terminating infinite rewrite systems cover all the\nprimitive recursive functions, in this paper we consider graph rewrite systems\nprecedence terminating with argument separation, which form a subclass of\nprecedence terminating graph rewrite systems. We show that for any precedence\nterminating infinite graph rewrite system G with a specific argument\nseparation, both the runtime complexity of G and the size of every normal form\nin G can be polynomially bounded. As a corollary, we obtain an alternative\nproof of the original result by Dal Lago et al.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 00:48:05 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Eguchi", "Naohi", "", "Chiba University"]]}, {"id": "1505.07416", "submitter": "Stephen A. Fenner", "authors": "Stephen A. Fenner, John Rogers", "title": "Combinatorial Game Complexity: An Introduction with Poset Games", "comments": "48 pages, 8 figures. This is the extended version of an article\n  appearing in the Bulletin of the EATCS, 2015. New results (Lemma 2.21 and\n  Proposition 2.30) and reference added", "journal-ref": null, "doi": null, "report-no": "CSE-TR-2015-001", "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poset games have been the object of mathematical study for over a century,\nbut little has been written on the computational complexity of determining\nimportant properties of these games. In this introduction we develop the\nfundamentals of combinatorial game theory and focus for the most part on poset\ngames, of which Nim is perhaps the best-known example. We present the\ncomplexity results known to date, some discovered very recently.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 17:49:10 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2015 20:29:33 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Fenner", "Stephen A.", ""], ["Rogers", "John", ""]]}, {"id": "1505.07432", "submitter": "Zhengfeng Ji", "authors": "Zhengfeng Ji", "title": "Classical Verification of Quantum Proofs", "comments": "36 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a classical interactive protocol that verifies the validity of a\nquantum witness state for the local Hamiltonian problem. It follows from this\nprotocol that approximating the non-local value of a multi-player one-round\ngame to inverse polynomial precision is QMA-hard. Our work makes an interesting\nconnection between the theory of QMA-completeness and Hamiltonian complexity on\none hand and the study of non-local games and Bell inequalities on the other.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 18:46:24 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Ji", "Zhengfeng", ""]]}]