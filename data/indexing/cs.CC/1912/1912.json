[{"id": "1912.00143", "submitter": "Siddhartha Jain", "authors": "Siddhartha Jain", "title": "Inapproximability of Additive Weak Contraction under SSEH and Strong UGC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Succinct representations of a graph have been objects of central study in\ncomputer science for decades. In this paper, we study the operation called\n\\emph{Distance Preserving Graph Contractions}, which was introduced by\nBernstein et al. (ITCS, 2018). This operation gives a minor as a succinct\nrepresentation of a graph that preserves all the distances of the original (up\nto some factor). The graph minor given from contractions can be seen as a dual\nof spanners as the distances can only shrink (while distances are stretched in\nthe case of spanners). Bernstein et al. proved inapproximability results for\nthe problems of finding maximum subset of edges that yields distance preserving\ngraph contractions for almost major classes of graphs except for that of\nAdditive Weak Contraction.\n  The main result in this paper is filling the gap in the paper of Bernstein et\nal. We show that the Maximum Additive Weak Contraction problem on a graph with\n$n$ vertices is inapproximable up to a factor of $n^{1-\\epsilon}$ for every\nconstant $\\epsilon>0$. Our hardness results follow from that of the Maximum\nEdge Biclique (\\textsc{MEB}) problem whose inapproximability of\n$n^{1-\\epsilon}$ has been recently shown by Manurangsi (ICALP, 2017) under the\n\\textsc{Small Set Expansion Hypothesis (SSEH)} and by Bhangale et al. (APPROX,\n2016) under the \\textsc{Strong Unique Games Conjecture (SUGC)} (both results\nalso assume $\\mathrm{NP}\\not\\subseteq\\mathrm{BPP}$).\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 06:47:34 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Jain", "Siddhartha", ""]]}, {"id": "1912.00284", "submitter": "Neil Lutz", "authors": "Jack H. Lutz and Neil Lutz", "title": "Who Asked Us? How the Theory of Computing Answers Questions about\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fractal dimensions -- constructs of computability theory -- have\nrecently been used to answer open questions in classical geometric measure\ntheory, questions of mathematical analysis whose statements do not involve\ncomputability theory or logic. We survey these developments and the prospects\nfor future such results.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 23:35:28 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lutz", "Jack H.", ""], ["Lutz", "Neil", ""]]}, {"id": "1912.00345", "submitter": "Igor Shparlinski", "authors": "Andrzej D\\k{a}browski, Jacek Pomyka{\\l}a and Igor E. Shparlinski", "title": "On oracle factoring of integers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an oracle factorisation algorithm which finds a nontrivial factor\nof almost all squarefree positive integers $n$ based on the knowledge of the\nnumber of points on certain elliptic curves in residue rings modulo $n$.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 07:38:10 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 23:35:53 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["D\u0105browski", "Andrzej", ""], ["Pomyka\u0142a", "Jacek", ""], ["Shparlinski", "Igor E.", ""]]}, {"id": "1912.00534", "submitter": "Kilian Risse", "authors": "Susanna F. de Rezende, Jakob Nordstr\\\"om, Kilian Risse, Dmitry Sokolov", "title": "Exponential Resolution Lower Bounds for Weak Pigeonhole Principle and\n  Perfect Matching Formulas over Sparse Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show exponential lower bounds on resolution proof length for pigeonhole\nprinciple (PHP) formulas and perfect matching formulas over highly unbalanced,\nsparse expander graphs, thus answering the challenge to establish strong lower\nbounds in the regime between balanced constant-degree expanders as in\n[Ben-Sasson and Wigderson '01] and highly unbalanced, dense graphs as in [Raz\n'04] and [Razborov '03, '04]. We obtain our results by revisiting Razborov's\npseudo-width method for PHP formulas over dense graphs and extending it to\nsparse graphs. This further demonstrates the power of the pseudo-width method,\nand we believe it could potentially be useful for attacking also other\nlongstanding open problems for resolution and other proof systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 01:04:40 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["de Rezende", "Susanna F.", ""], ["Nordstr\u00f6m", "Jakob", ""], ["Risse", "Kilian", ""], ["Sokolov", "Dmitry", ""]]}, {"id": "1912.00837", "submitter": "Xiaojin Zhang", "authors": "Xiaojin Zhang", "title": "Improved Algorithm for Tolerant Junta Testing", "comments": "Will refine this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of tolerant junta testing for boolean\nfunction. Compared with the prior work by Blais et al., we provide improved\nresults in terms of both the parameter gap and query complexity. Compared with\nthe prior work by De et al., our work did not close the parameter gap, but we\nremoved the $2^k$ term of the query complexity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 14:59:51 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 13:52:48 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zhang", "Xiaojin", ""]]}, {"id": "1912.01155", "submitter": "Matthew Groff S.", "authors": "Matt Groff", "title": "The Polynomial Transform", "comments": "6 pages, 3 figures, 1 algorithm figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.NT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We explore a new form of DFT, which we call the Polynomial Transform. It\nfunctions over finite fields, and a size $n$ transform takes $O(n)$ operations.\nIn the multitape Turing machine model, it allows us to multiply two $n$ bit\nnumbers in time $n(k^{\\log^*{n}} + \\log{p})$, where $k$ is a constant and\n$\\log^*{n}$ is the iterated logarithm. One important consequence is that the\nNetwork Coding Conjecture is false.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:24:19 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 04:57:23 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Groff", "Matt", ""]]}, {"id": "1912.01382", "submitter": "Utkan Gezer", "authors": "M. Utkan Gezer", "title": "Windable Heads & Recognizing NL with Constant Randomness", "comments": "12 pages, accepted and to be published in Language and Automata\n  Theory and Applications - LATA 2020 Alberto Leporati, Carlos Mart\\'in-Vide,\n  Dana Shapira, Claudio Zandron (Eds.)", "journal-ref": null, "doi": "10.1007/978-3-030-40608-0_12", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every language in NL has a $k$-head two-way nondeterministic finite automaton\n(2nfa($k$)) recognizing it. It is known how to build a constant-space verifier\nalgorithm from a 2nfa($k$) for the same language with constant-randomness, but\nwith error probability $\\tfrac{k^2-1}{2k^2}$ that can not be reduced further by\nrepetition. We have defined the unpleasant characteristic of the heads that\ncauses the high error as the property of being \"windable\". With a tweak on the\nprevious verification algorithm, the error is improved to\n$\\tfrac{k_{\\textrm{W}}^2-1}{2k_{\\textrm{W}}^2}$, where $k_{\\textrm{W}} \\le k$\nis the number of windable heads. Using this new algorithm, a subset of\nlanguages in NL that have a 2nfa($k$) recognizer with $k_{\\textrm{W}} \\le 1$\ncan be verified with arbitrarily reducible error using constant space and\nrandomness.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 14:14:29 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Gezer", "M. Utkan", ""]]}, {"id": "1912.01430", "submitter": "Beate Bollig", "authors": "Beate Bollig and Martin Farenholtz", "title": "On the relation between structured $d$-DNNFs and SDDs", "comments": "16 pages. The main result of the paper generalizes one of the results\n  from paper arXiv:1802.04544 where unambiguous nondeterministic OBDDs are\n  considered which can be seen as restricted structured $d$-DNNFs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured $d$-DNNFs and SDDs are restricted negation normal form circuits\nused in knowledge compilation as target languages into which propositional\ntheories are compiled. Structuredness is imposed by so-called vtrees. By\ndefinition SDDs are restricted structured $d$-DNNFs. Beame and Liew (2015) as\nwell as Bova and Szeider (2017) mentioned the question whether structured\n$d$-DNNFs are really more general than SDDs w.r.t. polynomial-size\nrepresentations (w.r.t. the number of Boolean variables the represented\nfunctions are defined on.) The main result in the paper is the proof that a\nfunction can be represented by SDDs of polynomial size if the function and its\ncomplement have polynomial-size structured $d$-DNNFs that respect the same\nvtree.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:23:47 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Bollig", "Beate", ""], ["Farenholtz", "Martin", ""]]}, {"id": "1912.02021", "submitter": "Pascal Koiran", "authors": "Pascal Koiran and Mateusz Skomra", "title": "Derandomization and absolute reconstruction for sums of powers of linear\n  forms", "comments": "This version takes the referee's comments into account", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the decomposition of multivariate polynomials as sums of powers of\nlinear forms.\n  As one of our main results we give an algorithm for the following problem:\ngiven a homogeneous polynomial of degree 3, decide whether it can be written as\na sum of cubes of linearly independent linear forms with complex coefficients.\nCompared to previous algorithms for the same problem, the two main novel\nfeatures of this algorithm are:\n  (i) It is an algebraic algorithm, i.e., it performs only arithmetic\noperations and equality tests on the coefficients of the input polynomial. In\nparticular, it does not make any appeal to polynomial factorization.\n  (ii) For an input polynomial with rational coefficients, the algorithm runs\nin polynomial time when implemented in the bit model of computation.\n  The algorithm relies on methods from linear and multilinear algebra\n(symmetric tensor decomposition by simultaneous diagonalization).\n  We also give a version of our algorithm for decomposition over the field of\nreal numbers. In this case, the algorithm performs arithmetic operations and\ncomparisons on the input coefficients.\n  Finally we give several related derandomization results on black box\npolynomial identity testing, the minimization of the number of variables in a\npolynomial, the computation of Lie algebras and factorization into products of\nlinear forms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:38:49 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 17:13:38 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 13:25:29 GMT"}, {"version": "v4", "created": "Wed, 8 Jul 2020 07:58:20 GMT"}, {"version": "v5", "created": "Wed, 14 Jul 2021 14:43:02 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Koiran", "Pascal", ""], ["Skomra", "Mateusz", ""]]}, {"id": "1912.02176", "submitter": "Yixin Shen", "authors": "Kamil Khadiev, Yixin Shen", "title": "Quantum Query Complexity of Dyck Languages with Bounded Height", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of determining if a sequence of parentheses is well\nparenthesized, with a depth of at most h. We denote this language as $Dyck_h$.\nWe study the quantum query complexity of this problem for different h as\nfunction of the length n of the word. It has been known from a recent paper by\nAaronson et al. that, for any constant h, since $Dyck_h$ is star-free, it has\nquantum query complexity $\\tilde{\\Theta}(\\sqrt{n})$, where the hidden logarithm\nfactors in $\\tilde{\\Theta}$ depend on h. Their proof does not give rise to an\nalgorithm. When h is not a constant, $Dyck_h$ is not even context-free. We give\nan algorithm with $O\\left(\\sqrt{n}\\log(n)^{0.5h}\\right)$ quantum queries for\n$Dyck_h$ for all h. This is better than the trival upper bound $n$ when\n$h=o(\\frac{\\log(n)}{\\log\\log n})$. We also obtain lower bounds: we show that\nfor every $0<\\epsilon\\leq 0.37$, there exists $c>0$ such that\n$Q(\\text{Dyck}_{c\\log(n)}(n))=\\Omega(n^{1-\\epsilon})$. When\n$h=\\omega(\\log(n))$, the quantum query complexity is close to $n$, i.e.\n$Q(\\text{Dyck}_h(n))=\\omega(n^{1-\\epsilon})$ for all $\\epsilon>0$. Furthermore\nwhen $h=\\Omega(n^\\epsilon)$ for some $\\epsilon>0$,\n$Q(\\text{Dyck}_{h}(n))=\\Theta(n)$.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:57:11 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 19:16:14 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 22:25:17 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Khadiev", "Kamil", ""], ["Shen", "Yixin", ""]]}, {"id": "1912.02278", "submitter": "Ivor van der Hoog", "authors": "Jeff Erickson, Ivor van der Hoog, Tillmann Miltzow", "title": "Smoothing the gap between NP and ER", "comments": "43 pages, 13 figures, accepted to FOCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algorithmic problems that belong to the complexity class of the\nexistential theory of the reals (ER). A problem is ER-complete if it is as hard\nas the problem ETR and if it can be written as an ETR formula. Traditionally,\nthese problems are studied in the real RAM, a model of computation that assumes\nthat the storage and comparison of real-valued numbers can be done in constant\nspace and time, with infinite precision. The complexity class ER is often\ncalled a real RAM analogue of NP, since the problem ETR can be viewed as the\nreal-valued variant of SAT.\n  In this paper we prove a real RAM analogue to the Cook-Levin theorem which\nshows that ER membership is equivalent to having a verification algorithm that\nruns in polynomial-time on a real RAM. This gives an easy proof of\nER-membership, as verification algorithms on a real RAM are much more versatile\nthan ETR-formulas. We use this result to construct a framework to study\nER-complete problems under smoothed analysis. We show that for a wide class of\nER-complete problems, its witness can be represented with logarithmic\ninput-precision by using smoothed analysis on its real RAM verification\nalgorithm. This shows in a formal way that the boundary between NP and ER\n(formed by inputs whose solution witness needs high input-precision) consists\nof contrived input. We apply our framework to well-studied ER-complete\nrecognition problems which have the exponential bit phenomenon such as the\nrecognition of realizable order types or the Steinitz problem in fixed\ndimension.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:12:17 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 11:28:42 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Erickson", "Jeff", ""], ["van der Hoog", "Ivor", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "1912.02728", "submitter": "Xi Li", "authors": "Xi Li, Mingyou Wu and Hanwu Chen", "title": "Algorithm for Finding the Maximum Clique Based on Continuous Time\n  Quantum Walk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the application of continuous time quantum\nwalking(CTQW) to the Maximum Clique(MC) Problem. Performing CTQW on graphs will\ngenerate distinct periodic probability amplitude for different vertices. We\nwill show that the intensity of the probability amplitude at frequency indeed\nimplies the clique structure of some special kinds of graph. And recursive\nalgorithms with time complexity $O(N^5)$ in classical computers for finding the\nmaximum clique are proposed. We have experimented on random graphs where each\nedge exists with probabilities 0.3, 0.5 and 0.7. Although counter examples are\nnot found for random graphs, whether these algorithms are universal is not\nknown to us.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:08:37 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 07:48:56 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 08:09:23 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Li", "Xi", ""], ["Wu", "Mingyou", ""], ["Chen", "Hanwu", ""]]}, {"id": "1912.02820", "submitter": "Vikram Sharma", "authors": "Prashant Batra, Vikram Sharma", "title": "Complexity of a Root Clustering Algorithm", "comments": "52 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximating the roots of a holomorphic function in an input box is a\nfundamental problem in many domains. Most algorithms in the literature for\nsolving this problem are conditional, i.e., they make some simplifying\nassumptions, such as, all the roots are simple or there are no roots on the\nboundary of the input box, or the underlying machine model is Real RAM. Root\nclustering is a generalization of the root approximation problem that allows\nfor errors in the computation and makes no assumption on the multiplicity of\nthe roots. An unconditional algorithm for computing a root clustering of a\nholomorphic function was given by Yap, Sagraloff and Sharma in 2013. They\nproposed a subdivision based algorithm using effective predicates based on\nPellet's test while avoiding any comparison with zeros (using soft zero\ncomparisons instead). In this paper, we analyze the running time of their\nalgorithm. We use the continuous amortization framework to derive an upper\nbound on the size of the subdivision tree. We specialize this bound to the case\nof polynomials and some simple transcendental functions such as exponential and\ntrigonometric sine. We show that the algorithm takes exponential time even for\nthese simple functions, unlike the case of polynomials. We also derive a bound\non the bit-precision used by the algorithm. To the best of our knowledge, this\nis the first such result for holomorphic functions. We introduce new geometric\nparameters, such as the relative growth of the function on the input box, for\nanalyzing the algorithm. Thus, our estimates naturally generalize the known\nresults, i.e., for the case of polynomials.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 08:59:16 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Batra", "Prashant", ""], ["Sharma", "Vikram", ""]]}, {"id": "1912.02953", "submitter": "Diego Maldonado", "authors": "Eric Goles, Diego Maldonado, Pedro Montealegre, Nicolas Ollinger", "title": "On the Complexity of the Stability Problem of Binary Freezing Totalistic\n  Cellular Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the family of two-state Totalistic Freezing Cellular\nAutomata (TFCA) defined over the triangular and square grids with von Neumann\nneighborhoods. We say that a Cellular Automaton is Freezing and Totalistic if\nthe active cells remain unchanged, and the new value of an inactive cell\ndepends only on the sum of its active neighbors. We classify all the Cellular\nAutomata in the class of TFCA, grouping them in five different classes: the\nTrivial rules, Turing Universal rules,Algebraic rules, Topological rules and\nFractal Growing rules. At the same time, we study in this family the Stability\nproblem, consisting in deciding whether an inactive cell becomes active, given\nan initial configuration.We exploit the properties of the automata in each\ngroup to show that:\n  - For Algebraic and Topological Rules the Stability problem is in\n$\\text{NC}$.\n  - For Turing Universal rules the Stability problem is $\\text{P}$-Complete.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 02:39:31 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Goles", "Eric", ""], ["Maldonado", "Diego", ""], ["Montealegre", "Pedro", ""], ["Ollinger", "Nicolas", ""]]}, {"id": "1912.03013", "submitter": "Pavel Pudlak", "authors": "Pavel Pudlak", "title": "The canonical pairs of bounded depth Frege systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The canonical pair of a proof system $P$ is the pair of disjoint NP sets\nwhere one set is the set of all satisfiable CNF formulas and the other is the\nset of CNF formulas that have $P$-proofs bounded by some polynomial. We give a\ncombinatorial characterization of the canonical pairs of depth~$d$ Frege\nsystems. Our characterization is based on certain games, introduced in this\narticle, that are parametrized by a number~$k$, also called the depth. We show\nthat the canonical pair of a depth~$d$ Frege system is polynomially equivalent\nto the pair $(A_{d+2},B_{d+2})$ where $A_{d+2}$ (respectively, $B_{d+1}$) are\ndepth {$d+1$} games in which Player~I (Player II) has a positional winning\nstrategy. Although this characterization is stated in terms of games, we will\nshow that these combinatorial structures can be viewed as generalizations of\nmonotone Boolean circuits. In particular, depth~1 games are essentially\nmonotone Boolean circuits. Thus we get a generalization of the monotone\nfeasible interpolation for Resolution, which is a property that enables one to\nreduce the task of proving lower bounds on the size of refutations to lower\nbounds on the size of monotone Boolean circuits. However, we do not have a\nmethod yet for proving lower bounds on the size of depth~$d$ games for $d>1$.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 08:11:30 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Pudlak", "Pavel", ""]]}, {"id": "1912.03042", "submitter": "Li-Yang Tan", "authors": "Guy Blanc, Jane Lange, Li-Yang Tan", "title": "Constructive derandomization of query algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give efficient deterministic algorithms for converting randomized query\nalgorithms into deterministic ones. We first give an algorithm that takes as\ninput a randomized $q$-query algorithm $R$ with description length $N$ and a\nparameter $\\varepsilon$, runs in time $\\mathrm{poly}(N) \\cdot\n2^{O(q/\\varepsilon)}$, and returns a deterministic $O(q/\\varepsilon)$-query\nalgorithm $D$ that $\\varepsilon$-approximates the acceptance probabilities of\n$R$. These parameters are near-optimal: runtime $N + 2^{\\Omega(q/\\varepsilon)}$\nand query complexity $\\Omega(q/\\varepsilon)$ are necessary.\n  Next, we give algorithms for instance-optimal and online versions of the\nproblem:\n  $\\circ$ Instance optimal: Construct a deterministic $q^\\star_R$-query\nalgorithm $D$, where $q^\\star_R$ is minimum query complexity of any\ndeterministic algorithm that $\\varepsilon$-approximates $R$.\n  $\\circ$ Online: Deterministically approximate the acceptance probability of\n$R$ for a specific input $\\underline{x}$ in time\n$\\mathrm{poly}(N,q,1/\\varepsilon)$, without constructing $D$ in its entirety.\n  Applying the techniques we develop for these extensions, we constructivize\nclassic results that relate the deterministic, randomized, and quantum query\ncomplexities of boolean functions (Nisan, STOC 1989; Beals et al., FOCS 1998).\nThis has direct implications for the Turing machine model of computation:\nsublinear-time algorithms for total decision problems can be efficiently\nderandomized and dequantized with a subexponential-time preprocessing step.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 09:41:10 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Blanc", "Guy", ""], ["Lange", "Jane", ""], ["Tan", "Li-Yang", ""]]}, {"id": "1912.03127", "submitter": "Paul Ouvrard", "authors": "Marthe Bonamy (LaBRI), Paul Dorbec, Paul Ouvrard (LaBRI)", "title": "Dominating sets reconfiguration under token sliding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a graph and $D_s$ and $D_t$ be two dominating sets of $G$ of size\n$k$. Does there exist a sequence $\\langle D_0 = D_s, D_1, \\ldots, D_{\\ell-1},\nD_\\ell = D_t \\rangle$ of dominating sets of $G$ such that $D_{i+1}$ can be\nobtained from $D_i$ by replacing one vertex with one of its neighbors? In this\npaper, we investigate the complexity of this decision problem. We first prove\nthat this problem is PSPACE-complete, even when restricted to split, bipartite\nor bounded treewidth graphs. On the other hand, we prove that it can be solved\nin polynomial time on dually chordal graphs (a superclass of both trees and\ninterval graphs) or cographs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 14:03:14 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 11:01:57 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Bonamy", "Marthe", "", "LaBRI"], ["Dorbec", "Paul", "", "LaBRI"], ["Ouvrard", "Paul", "", "LaBRI"]]}, {"id": "1912.03514", "submitter": "Ibrahim Kurban Ozaslan", "authors": "Ibrahim Kurban Ozaslan, Mert Pilanci, Orhan Arikan", "title": "M-IHS: An Accelerated Randomized Preconditioning Method Avoiding Costly\n  Matrix Decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum Iterative Hessian Sketch (M-IHS) techniques, a group of solvers for\nlarge scale regularized linear Least Squares (LS) problems, are proposed and\nanalyzed in detail. Proposed M-IHS techniques are obtained by incorporating the\nHeavy Ball Acceleration into the Iterative Hessian Sketch algorithm and they\nprovide significant improvements over the randomized preconditioning\ntechniques. By using approximate solvers along with the iterations, the\nproposed techniques are capable of avoiding all matrix decompositions and\ninversions, which is one of the main advantages over the alternative solvers\nsuch as the Blendenpik and the LSRN. Similar to the Chebyshev semi-iterations,\nthe M-IHS variants do not use any inner products and eliminate the\ncorresponding synchronization steps in hierarchical or distributed memory\nsystems, yet the M-IHS converges faster than the Chebyshev Semi-iteration based\nsolvers. Lower bounds on the required sketch size for various randomized\ndistributions are established through the error analyses. Unlike the previously\nproposed approaches to produce a solution approximation, the proposed M-IHS\ntechniques can use sketch sizes that are proportional to the statistical\ndimension which is always smaller than the rank of the coefficient matrix. The\nrelative computational saving gets more significant as the regularization\nparameter or the singular value decay rate of the coefficient matrix increase.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 14:53:42 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 15:56:06 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ozaslan", "Ibrahim Kurban", ""], ["Pilanci", "Mert", ""], ["Arikan", "Orhan", ""]]}, {"id": "1912.03729", "submitter": "Alexandros Hollender", "authors": "Alexandros Hollender", "title": "The Classes PPA-k: Existence from Arguments Modulo k", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity classes PPA-$k$, $k \\geq 2$, have recently emerged as the main\ncandidates for capturing the complexity of important problems in fair division,\nin particular Alon's Necklace-Splitting problem with $k$ thieves. Indeed, the\nproblem with two thieves has been shown complete for PPA = PPA-2. In this work,\nwe present structural results which provide a solid foundation for the further\nstudy of these classes. Namely, we investigate the classes PPA-$k$ in terms of\n(i) equivalent definitions, (ii) inner structure, (iii) relationship to each\nother and to other TFNP classes, and (iv) closure under Turing reductions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 18:00:16 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Hollender", "Alexandros", ""]]}, {"id": "1912.03824", "submitter": "Enric Boix Adser\\`a", "authors": "Enric Boix-Adser\\`a, Lior Eldar, Saeed Mehraban", "title": "Approximating the Determinant of Well-Conditioned Matrices by Shallow\n  Circuits", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The determinant can be computed by classical circuits of depth $O(\\log^2 n)$,\nand therefore it can also be computed in classical space $O(\\log^2 n)$. Recent\nprogress by Ta-Shma [Ta13] implies a method to approximate the determinant of\nHermitian matrices with condition number $\\kappa$ in quantum space $O(\\log n +\n\\log \\kappa)$. However, it is not known how to perform the task in less than\n$O(\\log^2 n)$ space using classical resources only. In this work, we show that\nthe condition number of a matrix implies an upper bound on the depth complexity\n(and therefore also on the space complexity) for this task: the determinant of\nHermitian matrices with condition number $\\kappa$ can be approximated to\ninverse polynomial relative error with classical circuits of depth $\\tilde\nO(\\log n \\cdot \\log \\kappa)$, and in particular one can approximate the\ndeterminant for sufficiently well-conditioned matrices in depth $\\tilde{O}(\\log\nn)$. Our algorithm combines Barvinok's recent complex-analytic approach for\napproximating combinatorial counting problems [Bar16] with the\nValiant-Berkowitz-Skyum-Rackoff depth-reduction theorem for low-degree\narithmetic circuits [Val83].\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 02:57:12 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Boix-Adser\u00e0", "Enric", ""], ["Eldar", "Lior", ""], ["Mehraban", "Saeed", ""]]}, {"id": "1912.03841", "submitter": "Xishun Zhao", "authors": "Kexu Wang and Xishun Zhao", "title": "A Logic that Captures $\\beta$P on Ordered Structures", "comments": "15 pages. This article was reported with a title \"Logarithmic-Bounded\n  Second-Order Quantifiers and Limited Nondeterminism\" in National Conference\n  on Modern Logic 2019, on November 9 in Beijing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the inflationary fixed-point logic, IFP, with a new kind of\nsecond-order quantifiers which have (poly-)logarithmic bounds. We prove that on\nordered structures the new logic $\\exists^{\\log^{\\omega}}\\text{IFP}$ captures\nthe limited nondeterminism class $\\beta\\text{P}$. In order to study its\nexpressive power, we also design a new version of Ehrenfeucht-Fra\\\"iss\\'e game\nfor this logic and show that our capturing result will not hold on the general\ncase, i.e. on all the finite structures.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 04:26:59 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 14:39:29 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Wang", "Kexu", ""], ["Zhao", "Xishun", ""]]}, {"id": "1912.04392", "submitter": "Andrej Sajenko", "authors": "Klaus Heeger, Anne-Sophie Himmel, Frank Kammer, Rolf Niedermeier,\n  Malte Renken, Andrej Sajenko", "title": "Multistage Graph Problems on a Global Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-evolving or temporal graphs gain more and more popularity when studying\nthe behavior of complex networks. In this context, the multistage view on\ncomputational problems is among the most natural frameworks. Roughly speaking,\nherein one studies the different (time) layers of a temporal graph (effectively\nmeaning that the edge set may change over time, but the vertex set remains\nunchanged), and one searches for a solution of a given graph problem for each\nlayer. The twist in the multistage setting is that the solutions found must not\ndiffer too much between subsequent layers. We relax on this already established\nnotion by introducing a global instead of the local budget view studied so far.\nMore specifically, we allow for few disruptive changes between subsequent\nlayers but request that overall, that is, summing over all layers, the degree\nof change is moderate. Studying several classical graph problems (both NP-hard\nand polynomial-time solvable ones) from a parameterized complexity angle, we\nencounter both fixed-parameter tractability and parameterized hardness results.\nSomewhat surprisingly, we find that sometimes the global multistage versions of\nNP-hard problems such as Vertex Cover turn out to be computationally more\ntractable than the ones of polynomial-time solvable problems such as Matching.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 21:54:00 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 09:50:18 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 13:39:57 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Heeger", "Klaus", ""], ["Himmel", "Anne-Sophie", ""], ["Kammer", "Frank", ""], ["Niedermeier", "Rolf", ""], ["Renken", "Malte", ""], ["Sajenko", "Andrej", ""]]}, {"id": "1912.04467", "submitter": "Emmanouil Zampetakis", "authors": "Mika G\\\"o\\\"os and Pritish Kamath and Katerina Sotiraki and Manolis\n  Zampetakis", "title": "On the Complexity of Modulo-q Arguments and the Chevalley-Warning\n  Theorem", "comments": "To appear at the Computational Complexity Conference (CCC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the search problem class $\\mathrm{PPA}_q$ defined as a modulo-$q$\nanalog of the well-known $\\textit{polynomial parity argument}$ class\n$\\mathrm{PPA}$ introduced by Papadimitriou '94. Our first result shows that\nthis class can be characterized in terms of $\\mathrm{PPA}_p$ for prime $p$.\n  Our main result is to establish that an $\\textit{explicit}$ version of a\nsearch problem associated to the Chevalley--Warning theorem is complete for\n$\\mathrm{PPA}_p$ for prime $p$. This problem is $\\textit{natural}$ in that it\ndoes not explicitly involve circuits as part of the input. It is the first such\ncomplete problem for $\\mathrm{PPA}_p$ when $p \\ge 3$.\n  Finally we discuss connections between Chevalley-Warning theorem and the\nwell-studied $\\textit{short integer solution}$ problem and survey the\nstructural properties of $\\mathrm{PPA}_q$.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 03:11:35 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 02:01:28 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["G\u00f6\u00f6s", "Mika", ""], ["Kamath", "Pritish", ""], ["Sotiraki", "Katerina", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "1912.04524", "submitter": "Jack Murtagh", "authors": "AmirMahdi Ahmadinejad, Jonathan Kelner, Jack Murtagh, John Peebles,\n  Aaron Sidford, and Salil Vadhan", "title": "High-precision Estimation of Random Walks in Small Space", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a deterministic $\\tilde{O}(\\log N)$-space algorithm for estimating\nrandom walk probabilities on undirected graphs, and more generally Eulerian\ndirected graphs, to within inverse polynomial additive error\n($\\epsilon=1/\\mathrm{poly}(N)$) where $N$ is the length of the input.\nPreviously, this problem was known to be solvable by a randomized algorithm\nusing space $O(\\log N)$ (following Aleliunas et al., FOCS 79) and by a\ndeterministic algorithm using space $O(\\log^{3/2} N)$ (Saks and Zhou, FOCS 95\nand JCSS 99), both of which held for arbitrary directed graphs but had not been\nimproved even for undirected graphs. We also give improvements on the space\ncomplexity of both of these previous algorithms for non-Eulerian directed\ngraphs when the error is negligible ($\\epsilon=1/N^{\\omega(1)}$), generalizing\nwhat Hoza and Zuckerman (FOCS 18) recently showed for the special case of\ndistinguishing whether a random walk probability is $0$ or greater than\n$\\epsilon$.\n  We achieve these results by giving new reductions between powering Eulerian\nrandom-walk matrices and inverting Eulerian Laplacian matrices, providing a new\nnotion of spectral approximation for Eulerian graphs that is preserved under\npowering, and giving the first deterministic $\\tilde{O}(\\log N)$-space\nalgorithm for inverting Eulerian Laplacian matrices. The latter algorithm\nbuilds on the work of Murtagh et al. (FOCS 17) that gave a deterministic\n$\\tilde{O}(\\log N)$-space algorithm for inverting undirected Laplacian\nmatrices, and the work of Cohen et al. (FOCS 19) that gave a randomized\n$\\tilde{O}(N)$-time algorithm for inverting Eulerian Laplacian matrices. A\nrunning theme throughout these contributions is an analysis of \"cycle-lifted\ngraphs\", where we take a graph and \"lift\" it to a new graph whose adjacency\nmatrix is the tensor product of the original adjacency matrix and a directed\ncycle (or variants of one).\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 06:12:50 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 04:08:54 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ahmadinejad", "AmirMahdi", ""], ["Kelner", "Jonathan", ""], ["Murtagh", "Jack", ""], ["Peebles", "John", ""], ["Sidford", "Aaron", ""], ["Vadhan", "Salil", ""]]}, {"id": "1912.05406", "submitter": "Rohan Karthikeyan", "authors": "Rohan Karthikeyan, Siddharth Sinha, Vallabh Patil", "title": "On the resolution of the sensitivity conjecture", "comments": "25 pages; added new section on open problems, typos corrected,\n  submitted for publication", "journal-ref": "Bull. Amer. Math. Soc. 57 (2020), 615-638", "doi": "10.1090/bull/1697", "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sensitivity Conjecture is a long-standing problem in theoretical computer\nscience that seeks to fit the sensitivity of a Boolean function into a unified\nframework formed by the other complexity measures of Boolean functions, such as\nblock sensitivity and certificate complexity. After more than thirty years of\nattacks on this Conjecture, Hao Huang (2019) gave a very succinct proof of the\nConjecture. In this survey, we explore the ideas that inspired the proof of\nthis Conjecture by an exposition of four papers that had the most impact on the\nConjecture. We also discuss progress on further research directions that the\nConjecture leads us to.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 16:04:41 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 15:27:27 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 13:50:23 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Karthikeyan", "Rohan", ""], ["Sinha", "Siddharth", ""], ["Patil", "Vallabh", ""]]}, {"id": "1912.06526", "submitter": "Johannes de Fine Licht", "authors": "Johannes de Fine Licht, Grzegorz Kwasniewski, Torsten Hoefler", "title": "Flexible Communication Avoiding Matrix Multiplication on FPGA with\n  High-Level Synthesis", "comments": null, "journal-ref": "In Proceedings of the 2020 ACM/SIGDA International Symposium on\n  Field-Programmable Gate Arrays (FPGA'20), February 23-25, 2020, Seaside, CA,\n  USA", "doi": "10.1145/3373087.3375296", "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data movement is the dominating factor affecting performance and energy in\nmodern computing systems. Consequently, many algorithms have been developed to\nminimize the number of I/O operations for common computing patterns. Matrix\nmultiplication is no exception, and lower bounds have been proven and\nimplemented both for shared and distributed memory systems. Reconfigurable\nhardware platforms are a lucrative target for I/O minimizing algorithms, as\nthey offer full control of memory accesses to the programmer. While bounds\ndeveloped in the context of fixed architectures still apply to these platforms,\nthe spatially distributed nature of their computational and memory resources\nrequires a decentralized approach to optimize algorithms for maximum hardware\nutilization. We present a model to optimize matrix multiplication for FPGA\nplatforms, simultaneously targeting maximum performance and minimum off-chip\ndata movement, within constraints set by the hardware. We map the model to a\nconcrete architecture using a high-level synthesis tool, maintaining a high\nlevel of abstraction, allowing us to support arbitrary data types, and enables\nmaintainability and portability across FPGA devices. Kernels generated from our\narchitecture are shown to offer competitive performance in practice, scaling\nwith both compute and memory resources. We offer our design as an open source\nproject to encourage the open development of linear algebra and I/O minimizing\nalgorithms on reconfigurable hardware platforms.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 14:28:42 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 13:39:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Licht", "Johannes de Fine", ""], ["Kwasniewski", "Grzegorz", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1912.06966", "submitter": "Bin Sheng", "authors": "Bin Sheng", "title": "FPT algorithms for generalized feedback vertex set problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An r-pseudoforest is a graph in which each component can be made into a\nforest by deleting at most r edges, and a d-quasi-forest is a graph in which\neach component can be made into a forest by deleting at most d vertices. In\nthis paper, we study the parameterized tractability of deleting minimum number\nof vertices to obtain r-pseudoforest and d-quasi-forest, generalizing the well\nstudied feedback vertex set problem. We first provide improved FPT algorithm\nand kernelization results for the r-pseudoforest deletion problem and then we\nshow that the d-quasi-forest deletion problem is also FPT.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 02:42:36 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Sheng", "Bin", ""]]}, {"id": "1912.07168", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Michael. I. Jordan", "title": "A Control-Theoretic Perspective on Optimal High-Order Optimization", "comments": "Improve the paper significantly; 45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a control-theoretic perspective on optimal tensor algorithms for\nminimizing a convex function in a finite-dimensional Euclidean space. Given a\nfunction $\\Phi: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ that is convex and twice\ncontinuously differentiable, we study a closed-loop control system that is\ngoverned by the operators $\\nabla \\Phi$ and $\\nabla^2 \\Phi$ together with a\nfeedback control law $\\lambda(\\cdot)$ satisfying the algebraic equation\n$(\\lambda(t))^p\\|\\nabla\\Phi(x(t))\\|^{p-1} = \\theta$ for some $\\theta \\in (0,\n1)$. Our first contribution is to prove the existence and uniqueness of a local\nsolution to this system via the Banach fixed-point theorem. We present a simple\nyet nontrivial Lyapunov function that allows us to establish the existence and\nuniqueness of a global solution under certain regularity conditions and analyze\nthe convergence properties of trajectories. The rate of convergence is\n$O(1/t^{(3p+1)/2})$ in terms of objective function gap and $O(1/t^{3p})$ in\nterms of squared gradient norm. Our second contribution is to provide two\nalgorithmic frameworks obtained from discretization of our continuous-time\nsystem, one of which generalizes the large-step A-HPE framework and the other\nof which leads to a new optimal $p$-th order tensor algorithm. While our\ndiscrete-time analysis can be seen as a simplification and generalization of\nexisiting analysis, it is largely motivated by the aforementioned\ncontinuous-time analysis, demonstrating the fundamental role that the feedback\ncontrol plays in optimal acceleration and the clear advantage that the\ncontinuous-time perspective brings to algorithmic design. A highlight of our\nanalysis is that we show that all of the $p$-th order optimal tensor algorithms\nthat we discuss minimize the squared gradient norm at a rate of $O(k^{-3p})$,\nwhich complements the recent analysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 02:46:47 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 20:28:15 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Lin", "Tianyi", ""], ["Jordan", "Michael. I.", ""]]}, {"id": "1912.07992", "submitter": "Nathan Grosshans", "authors": "Nathan Grosshans", "title": "The Power of Programs over Monoids in J and Threshold Dot-depth One\n  Languages", "comments": "Journal version of this submission, still under preparation. The\n  conference version has been substantially extended in that the algebraic\n  characterisation of threshold dot-depth one languages that was only\n  conjectured now has a complete proof (hence the new title). The proofs\n  previously left in the appendix were also included in the body of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model of programs over (finite) monoids, introduced by Barrington and\nTh\\'erien, gives an interesting way to characterise the circuit complexity\nclass $\\mathsf{NC^1}$ and its subclasses and showcases deep connections with\nalgebraic automata theory. In this article, we investigate the computational\npower of programs over monoids in $\\mathbf{J}$, a small variety of finite\naperiodic monoids. First, we give a fine hierarchy within the class of\nlanguages recognised by programs over monoids from $\\mathbf{J}$, based on the\nlength of programs but also some parametrisation of $\\mathbf{J}$. Second, and\nmost importantly, we make progress in understanding what regular languages can\nbe recognised by programs over monoids in $\\mathbf{J}$. To this end, we\nintroduce a new class of restricted dot-depth one languages, threshold\ndot-depth one languages. We show that programs over monoids in $\\mathbf{J}$\nactually can recognise all languages from this class, using a non-trivial\ntrick, and conjecture that threshold dot-depth one languages with additional\npositional modular counting suffice to characterise the regular languages\nrecognised by programs over monoids in $\\mathbf{J}$. Finally, using a result by\nJ. C. Costa, we give an algebraic characterisation of threshold dot-depth one\nlanguages that supports that conjecture and is of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 13:15:30 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 15:50:41 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Grosshans", "Nathan", ""]]}, {"id": "1912.08032", "submitter": "Janosch D\\\"ocker", "authors": "Janosch D\\\"ocker", "title": "Monotone 3-Sat-(2,2) is NP-complete", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Monotone 3-Sat remains NP-complete if (i) each clause contains\nexactly three distinct variables, (ii) each clause is unique, i.e., there are\nno duplicates of the same clause, and (iii), amongst the clauses, each variable\nappears unnegated exactly twice and negated exactly twice. Darmann and D\\\"ocker\n[6] recently showed that this variant of Monotone 3-Sat is either trivial or\nNP-complete. In the first part of the paper, we construct an unsatisfiable\ninstance which answers one of their open questions (Challenge 1) and places the\nproblem in the latter category.\n  Then, we adapt gadgets used in the construction to (1) sketch two reductions\nthat establish NP-completeness in a more direct way, and (2), to show that\n$\\forall\\exists$ 3-SAT remains $\\Pi_2^P$-complete for quantified Boolean\nformulas with the following properties: (a) each clause is monotone (i.e., no\nclause contains an unnegated and a negated variable) and contains exactly three\ndistinct variables, (b) each universal variable appears exactly once unnegated\nand exactly once negated, (c) each existential variable appears exactly twice\nunnegated and exactly twice negated, and (d) the number of universal and\nexistential variables is equal. Furthermore, we show that the variant where (b)\nis replaced with (b') each universal variable appears exactly twice unnegated\nand exactly twice negated, and where (a), (c) and (d) are unchanged, is\n$\\Pi_2^P$-complete as well. Thereby, we improve upon two recent results by\nD\\\"ocker et al. [8] that establish $\\Pi_2^P$-completeness of these variants in\nthe non-monotone setting.\n  We also discuss a special case of Monotone 3-Sat-(2,2) that corresponds to a\nvariant of Not-All-Equal Sat, and we show that all such instances are\nsatisfiable.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 14:24:30 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["D\u00f6cker", "Janosch", ""]]}, {"id": "1912.08045", "submitter": "Lorenzo De Stefani", "authors": "Lorenzo De Stefani", "title": "On the I/O complexity of hybrid algorithms for Integer Multiplication", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.12804", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost asymptotically tight lower bounds are derived for the Input/Output\n(I/O) complexity $IO_\\mathcal{A}\\left(n,M\\right)$ of a general class of hybrid\nalgorithms computing the product of two integers, each represented with $n$\ndigits in a given base $s$, in a two-level storage hierarchy with $M$ words of\nfast memory, with different digits stored in different memory words. The\nconsidered hybrid algorithms combine the Toom-Cook-$k$ (or Toom-$k$) fast\ninteger multiplication approach with computational complexity\n$\\Theta\\left(c_kn^{\\log_k \\left(2k-1\\right)}\\right)$, and \"standard\" integer\nmultiplication algorithms which compute $\\Omega\\left(n^2\\right)$ digit\nmultiplications. We present an\n$\\Omega\\left(\\left(n/\\max\\{M,n_0\\}\\right)^{\\log_k\n\\left(2k-1\\right)}\\left(\\max\\{1,n_0/M\\}\\right)^2M\\right)$ lower bound for the\nI/O complexity of a class of \"uniform, non-stationary\" hybrid algorithms, where\n$n_0$ denotes the threshold size of sub-problems which are computed using\nstandard algorithms with algebraic complexity $\\Omega\\left(n^2\\right)$. As a\nspecial case, our result yields an asymptotically tight\n$\\Theta\\left(n^2/M\\right)$ lower bound for the I/O complexity of any standard\ninteger multiplication algorithm. As some sequential hybrid algorithms from\nthis class exhibit I/O cost within a $\\mathcal{O}\\left(k^2\\right)$\nmultiplicative term of the corresponding lower bounds, the proposed lower\nbounds are almost asymptotically tight and indeed tight for constant values of\n$k$. By extending these results to a distributed memory model with $n_0$\nprocessors, we obtain both memory-dependent and memory-independent I/O lower\nbounds for parallel versions of hybrid integer multiplication algorithms. All\nthe lower bounds are derived for the more general class of \"non-uniform,\nnon-stationary\" hybrid algorithms that allow recursive calls to have a\ndifferent structure.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 00:39:58 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 14:45:15 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["De Stefani", "Lorenzo", ""]]}, {"id": "1912.08277", "submitter": "Michel de Rougemont", "authors": "Richard Lassaigne and Michel de Rougemont", "title": "Testing Membership for Timed Automata", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a timed automata which admits thick components and a timed word $x$, we\npresent a tester which decides if $x$ is in the language of the automaton or if\n$x$ is $\\epsilon$-far from the language, using finitely many samples taken from\nthe weighted time distribution $\\mu$ associated with an input $x$. We introduce\na distance between timed words, the {\\em timed edit distance}, which\ngeneralizes the classical edit distance. A timed word $x$ is $\\epsilon$-far\nfrom a timed language if its relative distance to the language is greater than\n$\\epsilon$.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:24:41 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 15:55:15 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Lassaigne", "Richard", ""], ["de Rougemont", "Michel", ""]]}, {"id": "1912.08482", "submitter": "Simon Kn\\\"auer", "authors": "Manuel Bodirsky and Simon Kn\\\"auer", "title": "Hardness of Network Satisfaction for Relation Algebras with Normal\n  Representations", "comments": "11 pages. Accepted for publication in the proceedings of RAMICS 2020\n  published by Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of the general network satisfaction\nproblem for a finite relation algebra $A$ with a normal representation $B$. If\n$B$ contains a non-trivial equivalence relation with a finite number of\nequivalence classes, then the network satisfaction problem for $A$ is NP-hard.\nAs a second result, we prove hardness if $B$ has domain size at least three and\ncontains no non-trivial equivalence relations but a symmetric atom $a$ with a\nforbidden triple $(a,a,a)$, that is, $a \\not\\leq a \\circ a$. We illustrate how\nto apply our conditions on two small relation algebras.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 09:38:32 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 15:59:51 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Kn\u00e4uer", "Simon", ""]]}, {"id": "1912.08674", "submitter": "Tillmann Miltzow", "authors": "Mikkel Abrahamsen and Tillmann Miltzow", "title": "Dynamic Toolbox for ETRINV", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, various natural algorithmic problems have been shown to be $\\exists\n\\mathbb{R}$-complete. The reduction relied in many cases on the $\\exists\n\\mathbb{R}$-completeness of the problem ETR-INV, which served as a useful\nintermediate problem. Often some strengthening and modification of ETR-INV was\nrequired. This lead to a cluttered situation where no paper included all the\nprevious details. Here, we give a streamlined exposition in a self-contained\nmanner. We also explain and prove various universality results regarding\nETR-INV. These notes should not be seen as a research paper with new results.\nHowever, we do describe some refinements of earlier results which might be\nuseful for future research. We plan to extend and update this exposition as\nseems fit.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 15:46:01 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Abrahamsen", "Mikkel", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "1912.08805", "submitter": "Jorge Garza-Vargas", "authors": "Jess Banks, Jorge Garza-Vargas, Archit Kulkarni, Nikhil Srivastava", "title": "Pseudospectral Shattering, the Sign Function, and Diagonalization in\n  Nearly Matrix Multiplication Time", "comments": "78 pages, 3 figures, comments welcome. Slightly edited intro from\n  previous version + explicit statement of forward error Theorem (Corolary\n  1.7). Minor corrections made", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC cs.DS cs.NA math.FA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exhibit a randomized algorithm which given a square $n\\times n$ complex\nmatrix $A$ with $\\|A\\| \\le 1$ and $\\delta>0$, computes with high probability\ninvertible $V$ and diagonal $D$ such that $$\\|A-VDV^{-1}\\|\\le \\delta $$ and\n$\\|V\\|\\|V^{-1}\\| \\le O(n^{2.5}/\\delta)$ in $O(T_{MM}\\>(n)\\log^2(n/\\delta))$\narithmetic operations on a floating point machine with $O(\\log^4(n/\\delta)\\log\nn)$ bits of precision. Here $T_{MM}\\>(n)$ is the number of arithmetic\noperations required to multiply two $n\\times n$ complex matrices numerically\nstably, with $T_{MM}\\,\\,(n)=O(n^{\\omega+\\eta}\\>\\>)$ for every $\\eta>0$, where\n$\\omega$ is the exponent of matrix multiplication. The algorithm is a variant\nof the spectral bisection algorithm in numerical linear algebra (Beavers and\nDenman, 1974). This running time is optimal up to polylogarithmic factors, in\nthe sense that verifying that a given similarity diagonalizes a matrix requires\nat least matrix multiplication time. It significantly improves best previously\nprovable running times of $O(n^{10}/\\delta^2)$ arithmetic operations for\ndiagonalization of general matrices (Armentano et al., 2018), and (w.r.t.\ndependence on $n$) $O(n^3)$ arithmetic operations for Hermitian matrices\n(Parlett, 1998).\n  The proof rests on two new ingredients. (1) We show that adding a small\ncomplex Gaussian perturbation to any matrix splits its pseudospectrum into $n$\nsmall well-separated components. This implies that the eigenvalues of the\nperturbation have a large minimum gap, a property of independent interest in\nrandom matrix theory. (2) We rigorously analyze Roberts' Newton iteration\nmethod for computing the matrix sign function in finite arithmetic, itself an\nopen problem in numerical analysis since at least 1986. This is achieved by\ncontrolling the evolution the iterates' pseudospectra using a carefully chosen\nsequence of shrinking contour integrals in the complex plane.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:59:08 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 17:58:01 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 18:22:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Banks", "Jess", ""], ["Garza-Vargas", "Jorge", ""], ["Kulkarni", "Archit", ""], ["Srivastava", "Nikhil", ""]]}, {"id": "1912.09051", "submitter": "Alexander He", "authors": "Benjamin A. Burton, Alexander He", "title": "On the hardness of finding normal surfaces", "comments": "28 pages, 17 figures; v2: the results are the same except for a\n  slight strengthening of Theorem 18, the exposition has changed significantly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many fundamental problems in computational topology, such as unknot\nrecognition and $3$-sphere recognition, the existence of a polynomial-time\nsolution remains unknown. A major algorithmic tool behind some of the best\nknown algorithms for these problems is normal surface theory. However, we\ncurrently have a poor understanding of the computational complexity of problems\nin normal surface theory: many such problems are still not known to have\npolynomial-time algorithms, yet proofs of $\\mathrm{NP}$-hardness also remain\nscarce. We give three results that provide some insight on this front.\n  A number of modern normal surface theoretic algorithms depend critically on\nthe operation of finding a non-trivial normal sphere or disc in a\n$3$-dimensional triangulation. We formulate an abstract problem that captures\nthe algebraic and combinatorial aspects of this operation, and show that this\nabstract problem is $\\mathrm{NP}$-hard. Assuming $\\mathrm{P}\\neq\\mathrm{NP}$,\nthis result suggests that any polynomial-time procedure for finding a\nnon-trivial normal sphere or disc will need to exploit some geometric or\ntopological intuition.\n  Another key operation, which applies to a much wider range of topological\nproblems, involves finding a vertex normal surface of a certain type. We study\ntwo closely-related problems that can be solved using this operation. For one\nof these problems, we give a simple alternative solution that runs in\npolynomial time; for the other, we prove $\\mathrm{NP}$-completeness.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 08:05:39 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 09:23:05 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Burton", "Benjamin A.", ""], ["He", "Alexander", ""]]}, {"id": "1912.09236", "submitter": "Tianyu Zhang", "authors": "Tianyu Zhang, Lei Zhu, Qian Zhao, and Kilho Shin", "title": "Neural Networks Weights Quantization: Target None-retraining Ternary\n  (TNT)", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization of weights of deep neural networks (DNN) has proven to be an\neffective solution for the purpose of implementing DNNs on edge devices such as\nmobiles, ASICs and FPGAs, because they have no sufficient resources to support\ncomputation involving millions of high precision weights and\nmultiply-accumulate operations. This paper proposes a novel method to compress\nvectors of high precision weights of DNNs to ternary vectors, namely a cosine\nsimilarity based target non-retraining ternary (TNT) compression method. Our\nmethod leverages cosine similarity instead of Euclidean distances as commonly\nused in the literature and succeeds in reducing the size of the search space to\nfind optimal ternary vectors from 3N to N, where N is the dimension of target\nvectors. As a result, the computational complexity for TNT to find\ntheoretically optimal ternary vectors is only O(N log(N)). Moreover, our\nexperiments show that, when we ternarize models of DNN with high precision\nparameters, the obtained quantized models can exhibit sufficiently high\naccuracy so that re-training models is not necessary.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 02:24:39 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zhang", "Tianyu", ""], ["Zhu", "Lei", ""], ["Zhao", "Qian", ""], ["Shin", "Kilho", ""]]}, {"id": "1912.09298", "submitter": "Caterina Viola", "authors": "Manuel Bodirsky, Marcello Mamino, Caterina Viola", "title": "Piecewise Linear Valued CSPs Solvable by Linear Programming Relaxation", "comments": "45 pages. arXiv admin note: substantial text overlap with\n  arXiv:1804.01710", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valued constraint satisfaction problems (VCSPs) are a large class of\ncombinatorial optimisation problems. The computational complexity of VCSPs\ndepends on the set of allowed cost functions in the input. Recently, the\ncomputational complexity of all VCSPs for finite sets of cost functions over\nfinite domains has been classified. Many natural optimisation problems,\nhowever, cannot be formulated as VCSPs over a finite domain. We initiate the\nsystematic investigation of infinite-domain VCSPs by studying the complexity of\nVCSPs for piecewise linear homogeneous cost functions. Such VCSPs can be solved\nin polynomial time if the cost functions are improved by fully symmetric\nfractional operations of all arities. We show this by reducing the problem to a\nfinite-domain VCSP which can be solved using the basic linear program\nrelaxation. It follows that VCSPs for submodular PLH cost functions can be\nsolved in polynomial time; in fact, we show that submodular PLH functions form\na maximally tractable class of PLH cost functions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 10:56:45 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mamino", "Marcello", ""], ["Viola", "Caterina", ""]]}, {"id": "1912.09389", "submitter": "Michael Walter", "authors": "Christian Ikenmeyer and Michael Walter", "title": "Hyperpfaffians and Geometric Complexity Theory", "comments": "4 pages; results merged into arXiv:1910.01251", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.RA math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hyperpfaffian polynomial was introduced by Barvinok in 1995 as a natural\ngeneralization of the well-known Pfaffian polynomial to higher order tensors.\nWe prove that the hyperpfaffian is the unique smallest degree SL-invariant on\nthe space of higher order tensors. We then study the hyperpfaffian's\ncomputational complexity and prove that it is VNP-complete. This disproves a\nconjecture of Mulmuley in geometric complexity theory about the computational\ncomplexity of invariant rings.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 17:06:14 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 19:45:26 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ikenmeyer", "Christian", ""], ["Walter", "Michael", ""]]}, {"id": "1912.09815", "submitter": "Thomas Quinn-Gregson", "authors": "Manuel Bodirsky and Thomas Quinn-Gregson", "title": "Solving Equation Systems in $\\omega$-categorical Algebras", "comments": "28 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of deciding whether a given set of term\nequalities and inequalities has a solution in an $\\omega$-categorical algebra\n$\\mathfrak{A}$. There are $\\omega$-categorical groups where this problem is\nundecidable. We show that if $\\mathfrak{A}$ is an $\\omega$-categorical\nsemilattice or an abelian group, then the problem is in P or NP-hard. The hard\ncases are precisely those where Pol$(\\mathfrak{A},\\neq)$ has a uniformly\ncontinuous minor-preserving map to the clone of projections on a two-element\nset. The results provide information about algebras $\\mathfrak{A}$ such that\nPol$(\\mathfrak{A},\\neq)$ does not satisfy this condition, and they are of\nindependent interest in universal algebra. In our proofs we rely on the\nBarto-Pinsker theorem about the existence of pseudo-Siggers polymorphisms. To\nthe best of our knowledge, this is the first time that the pseudo-Siggers\nidentity has been used to prove a complexity dichotomy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 13:33:00 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 09:40:18 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Quinn-Gregson", "Thomas", ""]]}, {"id": "1912.10140", "submitter": "Blerina Sinaimeri", "authors": "Angelo Monti and Blerina Sinaimeri", "title": "String factorisations with maximum or minimum dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider two problems concerning string factorisation.\nSpecifically given a string $w$ and an integer $k$ find a factorisation of $w$\nwhere each factor has length bounded by $k$ and has the minimum (the FmD\nproblem) or the maximum (the FMD problem) number of different factors. The FmD\nhas been proved to be NP-hard even if $k=2$ in [9] and for this case we provide\na $3/2$-approximation algorithm. The FMD problem, up to our knowledge has not\nbeen considered in the literature. We show that this problem is NP-hard for any\n$k\\geq 3$. In view of this we propose a $2$-approximation algorithm (for any\n$k$) an exact exponential algorithm. We conclude with some open problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 23:12:09 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Monti", "Angelo", ""], ["Sinaimeri", "Blerina", ""]]}, {"id": "1912.10217", "submitter": "Ilia Ponomarenko", "authors": "Ilia Ponomarenko and Andrey Vasil'ev", "title": "Two-closure of supersolvable permutation group in polynomial time", "comments": "20 pages", "journal-ref": "Computational Complexity, 29, No. 5 (2020) (MR4118452)", "doi": "10.1007/s00037-020-00195-7", "report-no": null, "categories": "math.GR cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $2$-closure $\\overline{G}$ of a permutation group $G$ on $\\Omega$ is\ndefined to be the largest permutation group on $\\Omega$, having the same orbits\non $\\Omega\\times\\Omega$ as $G$. It is proved that if $G$ is supersolvable, then\n$\\overline{G}$ can be found in polynomial time in $|\\Omega|$. As a byproduct of\nour technique, it is shown that the composition factors of $\\overline{G}$ are\ncyclic or alternating of prime degree.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 07:31:53 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ponomarenko", "Ilia", ""], ["Vasil'ev", "Andrey", ""]]}, {"id": "1912.10349", "submitter": "Xueliang Li", "authors": "You Chen, Ping Li, Xueliang Li, Yindi Weng", "title": "Complexity results for two kinds of colored disconnections of graphs", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of rainbow disconnection number of graphs was introduced by\nChartrand et al. in 2018. Inspired by this concept, we put forward the concepts\nof rainbow vertex-disconnection and proper disconnection in graphs. In this\npaper, we first show that it is $NP$-complete to decide whether a given\nedge-colored graph $G$ with maximum degree $\\Delta(G)=4$ is proper\ndisconnected. Then, for a graph $G$ with $\\Delta(G)\\leq 3$ we show that\n$pd(G)\\leq 2$ and determine the graphs with $pd(G)=1$ and $2$, respectively.\nFurthermore, we show that for a general graph $G$, deciding whether $pd(G)=1$\nis $NP$-complete, even if $G$ is bipartite. We also show that it is\n$NP$-complete to decide whether a given vertex-colored graph $G$ is rainbow\nvertex-disconnected, even though the graph $G$ has $\\Delta(G)=3$ or is\nbipartite.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 22:21:53 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 05:54:32 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Chen", "You", ""], ["Li", "Ping", ""], ["Li", "Xueliang", ""], ["Weng", "Yindi", ""]]}, {"id": "1912.11275", "submitter": "Hartmut Klauck", "authors": "Hartmut Klauck and Debbie Lim", "title": "The aBc Problem and Equator Sampling Renyi Divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of approximating the product $a^TBc$, where\n$a,c\\in S^{n-1}$ and $B\\in O_n$, in models of communication complexity and\nstreaming algorithms. The worst meaningful approximation is to simply decide\nwhether the product is 1 or -1, given the promise that it is either. We call\nthat problem the aBc problem. This is a modification of computing approximate\ninner products, by allowing a basis change. While very efficient streaming\nalgorithms and one-way communication protocols are known for simple inner\nproducts (approximating $a^Tc$) we show that no efficient one-way\nprotocols/streaming algorithms exist for the aBc problem. In communication\ncomplexity we consider the 3-player number-in-hand model.\n  1) In communication complexity $a^TBc$ can be approximated within additive\nerror $\\epsilon$ with communication $O(\\sqrt n/\\epsilon^2)$ by a one-way\nprotocol Charlie to Bob to Alice.\n  2) The $aBc$ problem has a streaming algorithm that uses space $O(\\sqrt n\n\\log n)$.\n  3) Any one-way communication protocol for $aBc$ needs communication at least\n$\\Omega(n^{1/3})$, and we prove a tight results regarding a communication\ntradeoff: if Charlie and Bob communicate over many rounds such that Charlie\ncommunicates $o(n^{2/3})$ and Bob $o(n^{1/3})$, and then the transcript is sent\nto Alice, the error will be large.\n  4) To establish our lower bound we show concentration results for Renyi\ndivergences under the event of restricting a density function on the sphere to\na random equator and subsequently normalizing the restricted density function.\nThis extends previous results by Klartag and Regev for set sizes to Renyi\ndivergences of arbitrary density functions.\n  5) We show a strong concentration result for conditional Renyi divergences on\nbipartite systems for all $\\alpha>1$.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 10:14:28 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Klauck", "Hartmut", ""], ["Lim", "Debbie", ""]]}, {"id": "1912.11396", "submitter": "Nathana\\\"el Fijalkow", "authors": "Nathana\\\"el Fijalkow", "title": "Lower bounds for the state complexity of probabilistic languages and the\n  language of prime numbers", "comments": "Submitted to the Journal of Logic and Computation, Special Issue on\n  LFCS'2016) (Logical Foundations of Computer Science). Guest Editors: S.\n  Artemov and A. Nerode. This journal version extends two conference papers:\n  the first published in the proceedings of LFCS'2016 and the second in the\n  proceedings of LICS'2018. arXiv admin note: substantial text overlap with\n  arXiv:1607.00259", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the complexity of languages of finite words using automata\ntheory. To go beyond the class of regular languages, we consider infinite\nautomata and the notion of state complexity defined by Karp. Motivated by the\nseminal paper of Rabin from 1963 introducing probabilistic automata, we study\nthe (deterministic) state complexity of probabilistic languages and prove that\nprobabilistic languages can have arbitrarily high deterministic state\ncomplexity. We then look at alternating automata as introduced by Chandra,\nKozen and Stockmeyer: such machines run independent computations on the word\nand gather their answers through boolean combinations. We devise a lower bound\ntechnique relying on boundedly generated lattices of languages, and give two\napplications of this technique. The first is a hierarchy theorem, stating that\nthere are languages of arbitrarily high polynomial alternating state\ncomplexity, and the second is a linear lower bound on the alternating state\ncomplexity of the prime numbers written in binary. This second result\nstrengthens a result of Hartmanis and Shank from 1968, which implies an\nexponentially worse lower bound for the same model.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 15:28:38 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", ""]]}, {"id": "1912.11611", "submitter": "Yupan Liu", "authors": "Ayal Green, Guy Kindler, Yupan Liu", "title": "Towards a quantum-inspired proof for IP = PSPACE", "comments": "10 pages", "journal-ref": "Quantum Inf. Comput. 21(5&6): 377-386 (2021)", "doi": "10.26421/QIC21.5-6-2", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore quantum-inspired interactive proof systems where the prover is\nlimited. Namely, we improve on a result by [AG17] showing a quantum-inspired\ninteractive protocol ($\\sf IP$) for $\\sf PreciseBQP$ where the prover is only\nassumed to be a $\\sf PreciseBQP$ machine, and show that the result can be\nstrengthened to show an $\\sf IP$ for $\\sf NP^{PP}$ with a prover which is only\nassumed to be an $\\sf NP^{PP}$ machine - which was not known before. We also\nshow how the protocol can be used to directly verify $\\sf QMA$ computations,\nthus connecting the sum-check protocol by [AAV13] with the result of [AG17,\nLFKN90]. Our results shed light on a quantum-inspired proof for ${\\sf IP} =\n{\\sf PSPACE}$, as $\\sf PreciseQMA$ captures the full $\\sf PSPACE$ power.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 07:21:57 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 21:14:46 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Green", "Ayal", ""], ["Kindler", "Guy", ""], ["Liu", "Yupan", ""]]}, {"id": "1912.11819", "submitter": "Natalia Berloff", "authors": "Kirill P. Kalinin and Natalia G. Berloff", "title": "Nonlinear systems for unconventional computing", "comments": "To appear in the book \"Nonlinear Science: A 20/20 Vision\" (Springer:\n  Nonlinear science and Complexity) Eds. Kevrekidis, Saxena, Maraver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cond-mat.dis-nn cond-mat.soft cs.CC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for new computational machines beyond the traditional von Neumann\narchitecture has given rise to a modern area of nonlinear science --\ndevelopment of unconventional computing -- requiring the efforts of\nmathematicians, physicists and engineers. Many analogue physical systems\nincluding nonlinear oscillator networks, lasers, and condensates were proposed\nand realised to address hard computational problems from various areas of\nsocial and physical sciences and technology. The analogue systems emulate spin\nHamiltonians with continuous or discrete degrees of freedom to which actual\noptimisation problems can be mapped. Understanding the underlying physical\nprocess by which the system finds the ground state often leads to new classes\nof system-inspired or quantum-inspired algorithms for hard optimisation.\nTogether physical platforms and related algorithms can be combined to form a\nhybrid architecture that may one day compete with conventional computing. In\nthis Chapter, we review some of the systems and physically-inspired algorithms\nthat show such promise.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 09:47:23 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Kalinin", "Kirill P.", ""], ["Berloff", "Natalia G.", ""]]}, {"id": "1912.11906", "submitter": "Logan Smith", "authors": "Logan A. Smith, David T. Mildebrath, and Illya V. Hicks", "title": "A Polynomial Time Algorithm for Computing the Strong Rainbow Connection\n  Numbers of Odd Cacti", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the strong rainbow connection number\n$src(G)$ for cactus graphs $G$ in which all cycles have odd length. We present\na formula to calculate $src(G)$ for such odd cacti which can be evaluated in\nlinear time, as well as an algorithm for computing the corresponding optimal\nstrong rainbow edge coloring, with polynomial worst case run time complexity.\nAlthough computing $src(G)$ is NP-hard in general, previous work has\ndemonstrated that it may be computed in polynomial time for certain classes of\ngraphs, including cycles, trees and block clique graphs. This work extends the\nclass of graphs for which $src(G)$ may be computed in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 17:45:53 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Smith", "Logan A.", ""], ["Mildebrath", "David T.", ""], ["Hicks", "Illya V.", ""]]}, {"id": "1912.11927", "submitter": "J. M. Landsberg", "authors": "J.M. Landsberg and Mateusz Micha{\\l}ek", "title": "Towards finding hay in a haystack: explicit tensors of border rank\n  greater than $2.02m$ in $C^m\\otimes C^m\\otimes C^m$", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We write down an explicit sequence of tensors in $C^m\\otimes C^m\\otimes C^m$,\nfor all $m$ sufficiently large, having border rank at least $2.02m$, overcoming\na longstanding barrier. We obtain our lower bounds via the border substitution\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 20:30:36 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Landsberg", "J. M.", ""], ["Micha\u0142ek", "Mateusz", ""]]}, {"id": "1912.12430", "submitter": "Theofilos Triommatis", "authors": "Theofilos Triommatis and Aris Pagourtzis", "title": "Approximate #Knapsack Computations to Count Semi-Fair Allocations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we study the problem of counting the number of different\nknapsack solutions with a prescribed cardinality. We present an FPTAS for this\nproblem, based on dynamic programming. We also introduce two different types of\nsemi-fair allocations of indivisible goods between two players. By semi-fair\nallocations, we mean allocations that ensure that at least one of the two\nplayers will be free of envy. We study the problem of counting such allocations\nand we provide FPTASs for both types, by employing our FPTAS for the prescribed\ncardinality knapsack problem.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 09:48:32 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Triommatis", "Theofilos", ""], ["Pagourtzis", "Aris", ""]]}, {"id": "1912.12561", "submitter": "Avishay Tal", "authors": "Avishay Tal", "title": "Towards Optimal Separations between Quantum and Randomized Query\n  Complexities", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The query model offers a concrete setting where quantum algorithms are\nprovably superior to randomized algorithms. Beautiful results by\nBernstein-Vazirani, Simon, Aaronson, and others presented partial Boolean\nfunctions that can be computed by quantum algorithms making much fewer queries\ncompared to their randomized analogs. To date, separations of $O(1)$ vs.\n$\\sqrt{N}$ between quantum and randomized query complexities remain the\nstate-of-the-art (where $N$ is the input length), leaving open the question of\nwhether $O(1)$ vs. $N^{1/2+\\Omega(1)}$ separations are possible? We answer this\nquestion in the affirmative. Our separating problem is a variant of the\nAaronson-Ambainis $k$-fold Forrelation problem. We show that our variant:\n  (1) Can be solved by a quantum algorithm making $2^{O(k)}$ queries to the\ninputs.\n  (2) Requires at least $\\tilde{\\Omega}(N^{2(k-1)/(3k-1)})$ queries for any\nrandomized algorithm.\n  For any constant $\\varepsilon>0$, this gives a $O(1)$ vs.\n$N^{2/3-\\varepsilon}$ separation between the quantum and randomized query\ncomplexities of partial Boolean functions. Our proof is Fourier analytical and\nuses new bounds on the Fourier spectrum of classical decision trees, which\ncould be of independent interest. Looking forward, we conjecture that the\nFourier bounds could be further improved in a precise manner, and show that\nsuch conjectured bounds imply optimal $O(1)$ vs. $N^{1-\\varepsilon}$\nseparations between the quantum and randomized query complexities of partial\nBoolean functions.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 01:42:31 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Tal", "Avishay", ""]]}, {"id": "1912.12820", "submitter": "Ambros Gleixner", "authors": "Ambros Gleixner and Daniel E. Steffy", "title": "Linear Programming using Limited-Precision Oracles", "comments": null, "journal-ref": "Mathematical Programming, 2019", "doi": "10.1007/s10107-019-01444-6", "report-no": "ZIB-Report 19-57", "categories": "math.OC cs.CC cs.NA cs.SC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the elimination algorithm of Fourier and Motzkin, many different\nmethods have been developed for solving linear programs. When analyzing the\ntime complexity of LP algorithms, it is typically either assumed that\ncalculations are performed exactly and bounds are derived on the number of\nelementary arithmetic operations necessary, or the cost of all arithmetic\noperations is considered through a bit-complexity analysis. Yet in practice,\nimplementations typically use limited-precision arithmetic. In this paper we\nintroduce the idea of a limited-precision LP oracle and study how such an\noracle could be used within a larger framework to compute exact precision\nsolutions to LPs. Under mild assumptions, it is shown that a polynomial number\nof calls to such an oracle and a polynomial number of bit operations, is\nsufficient to compute an exact solution to an LP. This work provides a\nfoundation for understanding and analyzing the behavior of the methods that are\ncurrently most effective in practice for solving LPs exactly.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 05:37:16 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gleixner", "Ambros", ""], ["Steffy", "Daniel E.", ""]]}]