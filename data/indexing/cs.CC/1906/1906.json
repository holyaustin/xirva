[{"id": "1906.00029", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Santosh Vempala, Manuel Blum", "title": "Human-Usable Password Schemas: Beyond Information-Theoretic Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Password users frequently employ passwords that are too simple, or they just\nreuse passwords for multiple websites. A common complaint is that utilizing\nsecure passwords is too difficult. One possible solution to this problem is to\nuse a password schema. Password schemas are deterministic functions which map\nchallenges (typically the website name) to responses (passwords). Previous work\nhas been done on developing and analyzing publishable schemas, but these\nanalyses have been information-theoretic, not complexity-theoretic; they\nconsider an adversary with infinite computing power.\n  We perform an analysis with respect to adversaries having currently\nachievable computing capabilities, assessing the realistic practical security\nof such schemas. We prove for several specific schemas that a computer is no\nworse off than an infinite adversary and that it can successfully extract all\ninformation from leaked challenges and their respective responses, known as\nchallenge-response pairs. We also show that any schema that hopes to be secure\nagainst adversaries with bounded computation should obscure information in a\nvery specific way, by introducing many possible constraints with each\nchallenge-response pair. These surprising results put the analyses of password\nschemas on a more solid and practical footing.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 18:51:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Vempala", "Santosh", ""], ["Blum", "Manuel", ""]]}, {"id": "1906.00294", "submitter": "Robert Busa-Fekete", "authors": "Robert Busa-Fekete, Krzysztof Dembczynski, Alexander Golovnev, Kalina\n  Jasinska, Mikhail Kuznetsov, Maxim Sviridenko and Chao Xu", "title": "On the computational complexity of the probabilistic label tree\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label tree-based algorithms are widely used to tackle multi-class and\nmulti-label problems with a large number of labels. We focus on a particular\nsubclass of these algorithms that use probabilistic classifiers in the tree\nnodes. Examples of such algorithms are hierarchical softmax (HSM), designed for\nmulti-class classification, and probabilistic label trees (PLTs) that\ngeneralize HSM to multi-label problems. If the tree structure is given,\nlearning of PLT can be solved with provable regret guaranties [Wydmuch et.al.\n2018]. However, to find a tree structure that results in a PLT with a low\ntraining and prediction computational costs as well as low statistical error\nseems to be a very challenging problem, not well-understood yet.\n  In this paper, we address the problem of finding a tree structure that has\nlow computational cost. First, we show that finding a tree with optimal\ntraining cost is NP-complete, nevertheless there are some tractable special\ncases with either perfect approximation or exact solution that can be obtained\nin linear time in terms of the number of labels $m$. For the general case, we\nobtain $O(\\log m)$ approximation in linear time too. Moreover, we prove an\nupper bound on the expected prediction cost expressed in terms of the expected\ntraining cost. We also show that under additional assumptions the prediction\ncost of a PLT is $O(\\log m)$.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 21:27:36 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Busa-Fekete", "Robert", ""], ["Dembczynski", "Krzysztof", ""], ["Golovnev", "Alexander", ""], ["Jasinska", "Kalina", ""], ["Kuznetsov", "Mikhail", ""], ["Sviridenko", "Maxim", ""], ["Xu", "Chao", ""]]}, {"id": "1906.00324", "submitter": "Bin Cheng", "authors": "Bin Cheng and Man-Hong Yung", "title": "Ubiquitous Complexity of Entanglement Spectra", "comments": "Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the entanglement spectra of quantum states have been\nidentified to be highly valuable for improving our understanding on many\nproblems in quantum physics, such as classification of topological phases,\nsymmetry-breaking phases, and eigenstate thermalization, etc. However, it\nremains a major challenge to fully characterize the entanglement spectrum of a\ngiven quantum state. An outstanding problem is whether the difficulty is\nintrinsically technical or fundamental? Here using the tools in computational\ncomplexity, we perform a rigorous analysis to pin down the counting complexity\nof entanglement spectra of (i) states generated by polynomial-time quantum\ncircuits, (ii) ground states of gapped 5-local Hamiltonians, and (iii)\nprojected entangled-pair states (PEPS). We prove that despite the state\ncomplexity, the problems of counting the number of sizable elements in the\nentanglement spectra all belong to the class $\\mathsf{\\# P}$-complete, which is\nas hard as calculating the partition functions of Ising models. Our result\nsuggests that the absence of an efficient method for solving the problem is\nfundamental in nature, from the point of view of computational complexity\ntheory.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 01:50:19 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cheng", "Bin", ""], ["Yung", "Man-Hong", ""]]}, {"id": "1906.00326", "submitter": "Nikhil Mande", "authors": "Andrej Bogdanov, Nikhil S. Mande, Justin Thaler, Christopher\n  Williamson", "title": "Approximate degree, secret sharing, and concentration phenomena", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\epsilon$-approximate degree $deg_\\epsilon(f)$ of a Boolean function $f$\nis the least degree of a real-valued polynomial that approximates $f$ pointwise\nto error $\\epsilon$. The approximate degree of $f$ is at least $k$ iff there\nexists a pair of probability distributions, also known as a dual polynomial,\nthat are perfectly $k$-wise indistinguishable, but are distinguishable by $f$\nwith advantage $1 - \\epsilon$. Our contributions are:\n  We give a simple new construction of a dual polynomial for the AND function,\ncertifying that $deg_\\epsilon(f) \\geq \\Omega(\\sqrt{n \\log 1/\\epsilon})$. This\nconstruction is the first to extend to the notion of weighted degree, and\nyields the first explicit certificate that the $1/3$-approximate degree of any\nread-once DNF is $\\Omega(\\sqrt{n})$.\n  We show that any pair of symmetric distributions on $n$-bit strings that are\nperfectly $k$-wise indistinguishable are also statistically $K$-wise\nindistinguishable with error at most $K^{3/2} \\cdot \\exp(-\\Omega(k^2/K))$ for\nall $k < K < n/64$. This implies that any symmetric function $f$ is a\nreconstruction function with constant advantage for a ramp secret sharing\nscheme that is secure against size-$K$ coalitions with statistical error\n$K^{3/2} \\exp(-\\Omega(deg_{1/3}(f)^2/K))$ for all values of $K$ up to $n/64$\nsimultaneously. Previous secret sharing schemes required that $K$ be determined\nin advance, and only worked for $f=$ AND.\n  Our analyses draw new connections between approximate degree and\nconcentration phenomena.\n  As a corollary, we show that for any $d < n/64$, any degree $d$ polynomial\napproximating a symmetric function $f$ to error $1/3$ must have $\\ell_1$-norm\nat least $K^{-3/2} \\exp({\\Omega(deg_{1/3}(f)^2/d)})$, which we also show to be\ntight for any $d > deg_{1/3}(f)$. These upper and lower bounds were also\npreviously only known in the case $f=$ AND.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 02:17:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bogdanov", "Andrej", ""], ["Mande", "Nikhil S.", ""], ["Thaler", "Justin", ""], ["Williamson", "Christopher", ""]]}, {"id": "1906.00659", "submitter": "Philipp Zschoche", "authors": "Till Fluschnik, Rolf Niedermeier, Valentin Rohm, Philipp Zschoche", "title": "Multistage Vertex Cover", "comments": "An extended abstract of this paper appeared in Proc. of IPEC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covering all edges of a graph by a small number of vertices, this is the\nNP-complete Vertex Cover problem. It is among the most fundamental\ngraph-algorithmic problems. Following a recent trend in studying temporal\ngraphs (a sequence of graphs, so-called layers, over the same vertex set but,\nover time, changing edge sets), we initiate the study of Multistage Vertex\nCover. Herein, given a temporal graph, the goal is to find for each layer of\nthe temporal graph a small vertex cover and to guarantee that two vertex cover\nsets of every two consecutive layers differ not too much (specified by a given\nparameter). We show that, different from classic Vertex Cover and some other\ndynamic or temporal variants of it, Multistage Vertex Cover is computationally\nhard even in fairly restricted settings. On the positive side, however, we also\nspot several fixed-parameter tractability results based on some of the most\nnatural parameterizations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 09:30:25 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 15:15:51 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 09:34:06 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Fluschnik", "Till", ""], ["Niedermeier", "Rolf", ""], ["Rohm", "Valentin", ""], ["Zschoche", "Philipp", ""]]}, {"id": "1906.00703", "submitter": "Arne Meier", "authors": "Yasir Mahmood, Arne Meier, Johannes Schmidt", "title": "Parameterised Complexity of Abduction in Schaefer's Framework", "comments": "gave a more precise title and corrected proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abductive reasoning is a non-monotonic formalism stemming from the work of\nPeirce. It describes the process of deriving the most plausible explanations of\nknown facts. Considering the positive version asking for sets of variables as\nexplanations, we study, besides asking for existence of the set of\nexplanations, two explanation size limited variants of this reasoning problem\n(less than or equal to, and equal to). In this paper, we present a thorough\ntwo-dimensional classification of these problems. The first dimension is\nregarding the parameterised complexity under a wealth of different\nparameterisations. The second dimension spans through all possible Boolean\nfragments of these problems in Schaefer's constraint satisfaction framework\nwith co-clones (STOC 1978). Thereby, we almost complete the parameterised\npicture started by Fellows et al. (AAAI 2012), partially building on results of\nNordh and Zanuttini (Artif. Intell. 2008). In this process, we outline a\nfine-grained analysis of the inherent parameterised intractability of these\nproblems and pinpoint their FPT parts. As the standard algebraic approach is\nnot applicable to our problems, we develop an alternative method that makes the\nalgebraic tools partially available again.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 10:58:35 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 13:03:03 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Mahmood", "Yasir", ""], ["Meier", "Arne", ""], ["Schmidt", "Johannes", ""]]}, {"id": "1906.00908", "submitter": "Cristiano Chesi", "authors": "Cristiano Chesi", "title": "Phase-based Minimalist Parsing and complexity in non-local dependencies", "comments": null, "journal-ref": "Proceedings of CLiC-it 2017. CEUR WORKSHOP PROCEEDINGS, ROMA:CEUR\n  Workshop Proceedings, ISBN: 9788899982768, ISSN: 1613-0073, Rome, 11-13\n  December 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A cognitively plausible parsing algorithm should perform like the human\nparser in critical contexts. Here I propose an adaptation of Earley's parsing\nalgorithm, suitable for Phase-based Minimalist Grammars (PMG, Chesi 2012), that\nis able to predict complexity effects in performance. Focusing on self-paced\nreading experiments of object clefts sentences (Warren & Gibson 2005) I will\nassociate to parsing a complexity metric based on cued features to be retrieved\nat the verb segment (Feature Retrieval & Encoding Cost, FREC). FREC is\ncrucially based on the usage of memory predicted by the discussed parsing\nalgorithm and it correctly fits with the reading time revealed.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 16:20:04 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 14:03:08 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chesi", "Cristiano", ""]]}, {"id": "1906.01228", "submitter": "Piyush Srivastava", "authors": "Jingcheng Liu and Alistair Sinclair and Piyush Srivastava", "title": "Correlation decay and partition function zeros: Algorithms and phase\n  transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cond-mat.stat-mech cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore connections between the phenomenon of correlation decay and the\nlocation of Lee-Yang and Fisher zeros for various spin systems. In particular\nwe show that, in many instances, proofs showing that weak spatial mixing on the\nBethe lattice (infinite $\\Delta$-regular tree) implies strong spatial mixing on\nall graphs of maximum degree $\\Delta$ can be lifted to the complex plane,\nestablishing the absence of zeros of the associated partition function in a\ncomplex neighborhood of the region in parameter space corresponding to strong\nspatial mixing. This allows us to give unified proofs of several recent results\nof this kind, including the resolution by Peters and Regts of the Sokal\nconjecture for the partition function of the hard core lattice gas. It also\nallows us to prove new results on the location of Lee-Yang zeros of the\nanti-ferromagnetic Ising model.\n  We show further that our methods extend to the case when weak spatial mixing\non the Bethe lattice is not known to be equivalent to strong spatial mixing on\nall graphs. In particular, we show that results on strong spatial mixing in the\nanti-ferromagnetic Potts model can be lifted to the complex plane to give new\nzero-freeness results for the associated partition function. This extension\nallows us to give the first deterministic FPTAS for counting the number of\n$q$-colorings of a graph of maximum degree $\\Delta$ provided only that $q\\ge\n2\\Delta$. This matches the natural bound for randomized algorithms obtained by\na straightforward application of Markov chain Monte Carlo. We also give an\nimproved version of this result for triangle-free graphs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 06:52:47 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 16:05:20 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 15:31:51 GMT"}, {"version": "v4", "created": "Sun, 28 Jun 2020 23:28:32 GMT"}, {"version": "v5", "created": "Wed, 9 Dec 2020 19:26:06 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Liu", "Jingcheng", ""], ["Sinclair", "Alistair", ""], ["Srivastava", "Piyush", ""]]}, {"id": "1906.01437", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Nhat Ho, Michael I. Jordan", "title": "On the Efficiency of the Sinkhorn and Greenkhorn Algorithms and Their\n  Acceleration for Optimal Transport", "comments": "A preliminary version [arXiv:1901.06482] of this paper, with a subset\n  of the results that are presented here, was presented at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new complexity results for several algorithms that approximately\nsolve the regularized optimal transport (OT) problem between two discrete\nprobability measures with at most $n$ atoms. First, we show that a greedy\nvariant of the classical Sinkhorn algorithm, known as the \\textit{Greenkhorn}\nalgorithm, achieves the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^2\\varepsilon^{-2})$, which improves the best known\nbound $\\widetilde{\\mathcal{O}}(n^2\\varepsilon^{-3})$. Notably, this matches the\nbest known complexity bound of the Sinkhorn algorithm and explains the superior\nperformance of the Greenkhorn algorithm in practice. Furthermore, we generalize\nan adaptive primal-dual accelerated gradient descent (APDAGD) algorithm with\nmirror mapping $\\phi$ and show that the resulting \\textit{adaptive primal-dual\naccelerated mirror descent} (APDAMD) algorithm achieves the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^2\\sqrt{\\delta}\\varepsilon^{-1})$ where $\\delta>0$\ndepends on $\\phi$. We point out that an existing complexity bound for the\nAPDAGD algorithm is not valid in general using a simple counterexample and then\nestablish the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^{5/2}\\varepsilon^{-1})$ by exploiting the connection\nbetween the APDAMD and APDAGD algorithms. Moreover, we introduce accelerated\nSinkhorn and Greenkhorn algorithms that achieve the complexity bound of\n$\\widetilde{\\mathcal{O}}(n^{7/3}\\varepsilon^{-1})$, which improves on the\ncomplexity bounds $\\widetilde{\\mathcal{O}}(n^2\\varepsilon^{-2})$ of Sinkhorn\nand Greenkhorn algorithms in terms of $\\varepsilon$. Experimental results on\nsynthetic and real datasets demonstrate the favorable performance of new\nalgorithms in practice.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 05:33:05 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 07:16:49 GMT"}, {"version": "v3", "created": "Sat, 22 Jun 2019 04:21:58 GMT"}, {"version": "v4", "created": "Sun, 4 Aug 2019 18:15:07 GMT"}, {"version": "v5", "created": "Thu, 17 Oct 2019 23:25:15 GMT"}, {"version": "v6", "created": "Tue, 24 Mar 2020 02:50:47 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Lin", "Tianyi", ""], ["Ho", "Nhat", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1906.01521", "submitter": "Benjamin Blanchette", "authors": "Benjamin Blanchette", "title": "Quasi-automatic groups are asynchronously automatic", "comments": "Short note, 5 pages, complementing a previous paper named\n  Quasi-automatic Semigroups by Blanchette, Choffrut and Reutenauer", "journal-ref": null, "doi": "10.1016/j.tcs.2019.05.026", "report-no": null, "categories": "math.GR cs.CC cs.FL math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quasi-automatic semigroup is a finitely generated semigroup with a rational\nset of representatives such that the graph of right multiplication by any\ngenerator is a rational relation. A asynchronously automatic semigroup is a\nquasi-automatic semigroup for which these rational relations are also\nrecognisable by two-tape automata. We show that when such a semigroup happens\nto be a group, the converse actually holds, meaning quasi-automatic groups are\nasynchronously automatic.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:34:16 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Blanchette", "Benjamin", ""]]}, {"id": "1906.01681", "submitter": "Alhussein Fawzi", "authors": "Alhussein Fawzi and Mateusz Malinowski and Hamza Fawzi and Omar Fawzi", "title": "Learning dynamic polynomial proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polynomial inequalities lie at the heart of many mathematical disciplines. In\nthis paper, we consider the fundamental computational task of automatically\nsearching for proofs of polynomial inequalities. We adopt the framework of\nsemi-algebraic proof systems that manipulate polynomial inequalities via\nelementary inference rules that infer new inequalities from the premises. These\nproof systems are known to be very powerful, but searching for proofs remains a\nmajor difficulty. In this work, we introduce a machine learning based method to\nsearch for a dynamic proof within these proof systems. We propose a deep\nreinforcement learning framework that learns an embedding of the polynomials\nand guides the choice of inference rules, taking the inherent symmetries of the\nproblem as an inductive bias. We compare our approach with powerful and\nwidely-studied linear programming hierarchies based on static proof systems,\nand show that our method reduces the size of the linear program by several\norders of magnitude while also improving performance. These results hence pave\nthe way towards augmenting powerful and well-studied semi-algebraic proof\nsystems with machine learning guiding strategies for enhancing the expressivity\nof such proof systems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:58:40 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Fawzi", "Alhussein", ""], ["Malinowski", "Mateusz", ""], ["Fawzi", "Hamza", ""], ["Fawzi", "Omar", ""]]}, {"id": "1906.01745", "submitter": "Cristobal Rojas", "authors": "Silvere Gangloff, Alonso Herrera, Cristobal Rojas, Mathieu Sablik", "title": "On the computability properties of topological entropy: a general\n  approach", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of symbolic systems, such as multidimensional subshifts of\nfinite type or cellular automata, are known to be closely related to\ncomputability theory. In particular, the appropriate tools to describe and\nclassify topological entropy for this kind of systems turned out to be of\ncomputational nature. Part of the great importance of these symbolic systems\nrelies on the role they have played in understanding more general systems over\nnon-symbolic spaces. The aim of this article is to investigate topological\nentropy from a computability point of view in this more general, not\nnecessarily symbolic setting. In analogy to effective subshifts, we consider\ncomputable maps over effective compact sets in general metric spaces, and study\nthe computability properties of their topological entropies. We show that even\nin this general setting, the entropy is always a $\\Sigma_2$-computable number.\nWe then study how various dynamical and analytical constrains affect this upper\nbound, and prove that it can be lowered in different ways depending on the\nconstraint considered. In particular, we obtain that all $\\Sigma_2$-computable\nnumbers can already be realized within the class of surjective computable maps\nover $\\{0,1\\}^{\\mathbb{N}}$, but that this bound decreases to $\\Pi_{1}$(or\nupper)-computable numbers when restricted to expansive maps. On the other hand,\nif we change the geometry of the ambient space from the symbolic\n$\\{0,1\\}^{\\mathbb{N}}$ to the unit interval $[0,1]$, then we find a quite\ndifferent situation -- we show that the possible entropies of computable\nsystems over $[0,1]$ are exactly the $\\Sigma_{1}$(or lower)-computable numbers\nand that this characterization switches down to precisely the computable\nnumbers when we restrict the class of system to the quadratic family.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 22:26:02 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Gangloff", "Silvere", ""], ["Herrera", "Alonso", ""], ["Rojas", "Cristobal", ""], ["Sablik", "Mathieu", ""]]}, {"id": "1906.02511", "submitter": "Pavel Hrubes", "authors": "Pavel Hrubes", "title": "On the distribution of runners on a circle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider $n$ runners running on a circular track of unit length with constant\nspeeds such that $k$ of the speeds are distinct. We show that, at some time,\nthere will exist a sector $S$ which contains at least $|S|n+ \\Omega(\\sqrt{k})$\nrunners. The result can be generalized as follows. Let $f(x,y)$ be a complex\nbivariate polynomial whose Newton polytope has $k$ vertices. Then there exists\n$a\\in {\\mathbb C}\\setminus\\{0\\}$ and a complex sector $S=\\{re^{\\imath \\theta}:\nr>0, \\alpha\\leq \\theta \\leq \\beta\\}$ such that the univariate polynomial\n$f(x,a)$ contains at least $\\frac{\\beta-\\alpha}{2\\pi}n+\\Omega(\\sqrt{k})$\nnon-zero roots in $S$ (where $n$ is the total number of such roots and $0\\leq\n(\\beta-\\alpha)\\leq 2\\pi$). This shows that the Real $\\tau$-Conjecture of Koiran\nimplies the conjecture on Newton polytopes of Koiran et al.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 10:45:28 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 14:52:58 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Hrubes", "Pavel", ""]]}, {"id": "1906.02842", "submitter": "Benjamin Blanchette", "authors": "Benjamin Blanchette, Christian Choffrut, Christophe Reutenauer", "title": "Quasi-automatic semigroups", "comments": "17 pages. In press. Theoretical Computer Science, 2019", "journal-ref": null, "doi": "10.1016/j.tcs.2019.01.002", "report-no": null, "categories": "math.GR cs.CC cs.FL math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quasi-automatic semigroup is defined by a finite set of generators, a\nrational (regular) set of representatives, such that if a is a generator or\nneutral, then the graph of right multiplication by a on the set of\nrepresentatives is a rational relation. This class of semigroups contains\npreviously considered semigroups and groups (Sakarovitch, Epstein et al.,\nCampbell et al.). Membership of a semigroup to this class does not depend on\nthe choice of the generators. These semigroups are rationally presented.\nRepresentatives may be computed in exponential time. Their word problem is\ndecidable in exponential time. They enjoy a property similar to the so-called\nLipschitz property, or fellow traveler property. If graded, they are automatic.\nIn the case of groups, they are finitely presented with an exponential\nisoperimetric inequality and they are characterized by the weak Lipschitz\nproperty.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 23:42:34 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 18:38:46 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Blanchette", "Benjamin", ""], ["Choffrut", "Christian", ""], ["Reutenauer", "Christophe", ""]]}, {"id": "1906.03676", "submitter": "Sophie Pinchinat", "authors": "Abdallah Saffidine, S\\'ebastien L\\^e Cong, Sophie Pinchinat, and\n  Fran\\c{c}ois Schwarzentruber", "title": "The Packed Interval Covering Problem is NP-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new decision problem, called Packed Interval Covering (PIC)\nand show that it is NP-complete.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 17:15:43 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Saffidine", "Abdallah", ""], ["Cong", "S\u00e9bastien L\u00ea", ""], ["Pinchinat", "Sophie", ""], ["Schwarzentruber", "Fran\u00e7ois", ""]]}, {"id": "1906.03743", "submitter": "Rohit Agrawal", "authors": "Rohit Agrawal", "title": "Coin Theorems and the Fourier Expansion", "comments": "15 pages, 1 figure", "journal-ref": "Chic. J. Theoret. Comput. Sci. 2020, Art. 4", "doi": "10.4086/cjtcs.2020.004", "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note we compare two measures of the complexity of a class $\\mathcal\nF$ of Boolean functions studied in (unconditional) pseudorandomness: $\\mathcal\nF$'s ability to distinguish between biased and uniform coins (the coin\nproblem), and the norms of the different levels of the Fourier expansion of\nfunctions in $\\mathcal F$ (the Fourier growth). We show that for coins with low\nbias $\\varepsilon = o(1/n)$, a function's distinguishing advantage in the coin\nproblem is essentially equivalent to $\\varepsilon$ times the sum of its level\n$1$ Fourier coefficients, which in particular shows that known level $1$ and\ntotal influence bounds for some classes of interest (such as constant-width\nread-once branching programs) in fact follow as a black-box from the\ncorresponding coin theorems, thereby simplifying the proofs of some known\nresults in the literature. For higher levels, it is well-known that Fourier\ngrowth bounds on all levels of the Fourier spectrum imply coin theorems, even\nfor large $\\varepsilon$, and we discuss here the possibility of a converse.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 00:28:51 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 16:47:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Agrawal", "Rohit", ""]]}, {"id": "1906.04178", "submitter": "Abhinav Deshpande", "authors": "Nishad Maskara, Abhinav Deshpande, Adam Ehrenberg, Minh C. Tran, Bill\n  Fefferman, and Alexey V. Gorshkov", "title": "Complexity phase diagram for interacting and long-range bosonic\n  Hamiltonians", "comments": "15 pages, 5 figures. v2: 19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.quant-gas cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify phases of a bosonic lattice model based on the computational\ncomplexity of classically simulating the system. We show that the system\ntransitions from being classically simulable to classically hard to simulate as\nit evolves in time, extending previous results to include on-site\nnumber-conserving interactions and long-range hopping. Specifically, we\nconstruct a \"complexity phase diagram\" with \"easy\" and \"hard\" phases, and\nderive analytic bounds on the location of the phase boundary with respect to\nthe evolution time and the degree of locality. We find that the location of the\nphase transition is intimately related to upper bounds on the spread of quantum\ncorrelations and protocols to transfer quantum information. Remarkably,\nalthough the location of the transition point is unchanged by on-site\ninteractions, the nature of the transition point changes dramatically.\nSpecifically, we find that there are two kinds of transitions, sharp and\ncoarse, broadly corresponding to interacting and noninteracting bosons,\nrespectively. Our work motivates future studies of complexity in many-body\nsystems and its interplay with the associated physical phenomena.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 18:00:00 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 18:00:00 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Maskara", "Nishad", ""], ["Deshpande", "Abhinav", ""], ["Ehrenberg", "Adam", ""], ["Tran", "Minh C.", ""], ["Fefferman", "Bill", ""], ["Gorshkov", "Alexey V.", ""]]}, {"id": "1906.04213", "submitter": "Noam Nisan", "authors": "Noam Nisan", "title": "The Demand Query Model for Bipartite Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a `concrete complexity' model for studying algorithms for\nmatching in bipartite graphs. The model is based on the \"demand query\" model\nused for combinatorial auctions. Most (but not all) known algorithms for\nbipartite matching seem to be translatable into this model including exact,\napproximate, sequential, parallel, and online ones. A perfect matching in a\nbipartite graph can be found in this model with O(n^{3/2}) demand queries (in a\nbipartite graph with n vertices on each side) and our main open problem is to\neither improve the upper bound or prove a lower bound. An improved upper bound\ncould yield \"normal\" algorithms whose running time is better than the fastest\nones known, while a lower bound would rule out a faster algorithm for bipartite\nmatching from within a large class of algorithms. Our main result is a lower\nbound for finding an approximately maximum size matching in parallel: A\ndeterministic algorithm that runs in n^{o(1)} rounds, where each round can make\nat most n^{1.99} demand queries cannot find a matching whose size is within\nn^{o(1)} factor of the maximum. This is in contrast to randomized algorithms\nthat can find a matching whose size is $99\\%$ of the maximum in O(\\log n)\nrounds, each making n demand queries.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 18:17:27 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Nisan", "Noam", ""]]}, {"id": "1906.04321", "submitter": "Nicolas Boumal", "authors": "Chris Criscitiello and Nicolas Boumal", "title": "Efficiently escaping saddle points on manifolds", "comments": "18 pages, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smooth, non-convex optimization problems on Riemannian manifolds occur in\nmachine learning as a result of orthonormality, rank or positivity constraints.\nFirst- and second-order necessary optimality conditions state that the\nRiemannian gradient must be zero, and the Riemannian Hessian must be positive\nsemidefinite. Generalizing Jin et al.'s recent work on perturbed gradient\ndescent (PGD) for optimization on linear spaces [How to Escape Saddle Points\nEfficiently (2017), Stochastic Gradient Descent Escapes Saddle Points\nEfficiently (2019)], we propose a version of perturbed Riemannian gradient\ndescent (PRGD) to show that necessary optimality conditions can be met\napproximately with high probability, without evaluating the Hessian.\nSpecifically, for an arbitrary Riemannian manifold $\\mathcal{M}$ of dimension\n$d$, a sufficiently smooth (possibly non-convex) objective function $f$, and\nunder weak conditions on the retraction chosen to move on the manifold, with\nhigh probability, our version of PRGD produces a point with gradient smaller\nthan $\\epsilon$ and Hessian within $\\sqrt{\\epsilon}$ of being positive\nsemidefinite in $O((\\log{d})^4 / \\epsilon^{2})$ gradient queries. This matches\nthe complexity of PGD in the Euclidean case. Crucially, the dependence on\ndimension is low. This matters for large-scale applications including PCA and\nlow-rank matrix completion, which both admit natural formulations on manifolds.\nThe key technical idea is to generalize PRGD with a distinction between two\ntypes of gradient steps: \"steps on the manifold\" and \"perturbed steps in a\ntangent space of the manifold.\" Ultimately, this distinction makes it possible\nto extend Jin et al.'s analysis seamlessly.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 23:25:50 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 18:39:47 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 01:37:32 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Criscitiello", "Chris", ""], ["Boumal", "Nicolas", ""]]}, {"id": "1906.05005", "submitter": "Ishay Haviv", "authors": "Ishay Haviv", "title": "Approximating the Orthogonality Dimension of Graphs and Hypergraphs", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $t$-dimensional orthogonal representation of a hypergraph is an assignment\nof nonzero vectors in $\\mathbb{R}^t$ to its vertices, such that every hyperedge\ncontains two vertices whose vectors are orthogonal. The orthogonality dimension\nof a hypergraph $H$, denoted by $\\overline{\\xi}(H)$, is the smallest integer\n$t$ for which there exists a $t$-dimensional orthogonal representation of $H$.\nIn this paper we study computational aspects of the orthogonality dimension of\ngraphs and hypergraphs. We prove that for every $k \\geq 4$, it is\n$\\mathsf{NP}$-hard (resp. quasi-$\\mathsf{NP}$-hard) to distinguish $n$-vertex\n$k$-uniform hypergraphs $H$ with $\\overline{\\xi}(H) \\leq 2$ from those\nsatisfying $\\overline{\\xi}(H) \\geq \\Omega(\\log^\\delta n)$ for some constant\n$\\delta>0$ (resp. $\\overline{\\xi}(H) \\geq \\Omega(\\log^{1-o(1)} n)$). For\ngraphs, we relate the $\\mathsf{NP}$-hardness of approximating the orthogonality\ndimension to a variant of a long-standing conjecture of Stahl. We also consider\nthe algorithmic problem in which given a graph $G$ with $\\overline{\\xi}(G) \\leq\n3$ the goal is to find an orthogonal representation of $G$ of as low dimension\nas possible, and provide a polynomial time approximation algorithm based on\nsemidefinite programming.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 08:42:58 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Haviv", "Ishay", ""]]}, {"id": "1906.05170", "submitter": "Graham Campbell", "authors": "Graham Campbell", "title": "Efficient Graph Rewriting", "comments": "BSc Thesis, Department of Computer Science, University of York, 54\n  pages, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.PL cs.SC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Graph transformation is the rule-based modification of graphs, and is a\ndiscipline dating back to the 1970s. The declarative nature of graph rewriting\nrules comes at a cost. In general, to match the left-hand graph of a fixed rule\nwithin a host graph requires polynomial time. To improve matching performance,\nD\\\"orr proposed to equip rules and host graphs with distinguished root nodes.\nThis model was implemented by Plump and Bak, but unfortunately, is not\ninvertible. We address this problem by defining rootedness using a partial\nfunction onto a two-point set rather than pointing graphs with root nodes. We\nshow a new result that the graph class of trees can be recognised by a rooted\nGT system in linear time, given an input graph of bounded degree. Finally, we\ndefine a new notion of confluence modulo garbage and non-garbage critical\npairs, showing it is sufficient to require strong joinability of only the\nnon-garbage critical pairs to establish confluence modulo garbage.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:50:57 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 11:46:20 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Campbell", "Graham", ""]]}, {"id": "1906.05266", "submitter": "Manuel Lafond", "authors": "Manuel Lafond, Binhai Zhu, Peng Zou", "title": "The Tandem Duplication Distance is NP-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computational biology, tandem duplication is an important biological\nphenomenon which can occur either at the genome or at the DNA level. A tandem\nduplication takes a copy of a genome segment and inserts it right after the\nsegment - this can be represented as the string operation $AXB \\Rightarrow\nAXXB$. For example, Tandem exon duplications have been found in many species\nsuch as human, fly or worm, and have been largely studied in computational\nbiology. The Tandem Duplication (TD) distance problem we investigate in this\npaper is defined as follows: given two strings $S$ and $T$ over the same\nalphabet, compute the smallest sequence of tandem duplications required to\nconvert $S$ to $T$. The natural question of whether the TD distance can be\ncomputed in polynomial time was posed in 2004 by Leupold et al. and had\nremained open, despite the fact that tandem duplications have received much\nattention ever since. In this paper, we prove that this problem is NP-hard. We\nfurther show that this hardness holds even if all characters of $S$ are\ndistinct. This is known as the exemplar TD distance, which is of special\nrelevance in bioinformatics. One of the tools we develop for the reduction is a\nnew problem called the Cost-Effective Subgraph, for which we obtain\nW[1]-hardness results that might be of independent interest. We finally show\nthat computing the exemplar TD distance between $S$ and $T$ is fixed-parameter\ntractable. Our results open the door to many other questions, and we conclude\nwith several open problems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:47:17 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Lafond", "Manuel", ""], ["Zhu", "Binhai", ""], ["Zou", "Peng", ""]]}, {"id": "1906.05458", "submitter": "Arijit Ghosh", "authors": "Arijit Bishnu and Arijit Ghosh and Sudeshna Kolay and Gopinath Mishra\n  and Saket Saurabh", "title": "Structural Parameterization for Graph Deletion Problems over Data\n  Streams", "comments": "Title and introduction changed to better reflect the content of the\n  paper; 27 pages; 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The study of parameterized streaming complexity on graph problems was\ninitiated by Fafianie et al. (MFCS'14) and Chitnis et al. (SODA'15 and\nSODA'16). Simply put, the main goal is to design streaming algorithms for\nparameterized problems such that $O\\left(f(k)\\log^{O(1)}n\\right)$ space is\nenough, where $f$ is an arbitrary computable function depending only on the\nparameter $k$. However, in the past few years, very few positive results have\nbeen established. Most of the graph problems that do have streaming algorithms\nof the above nature are ones where localized checking is required, like Vertex\nCover or Maximum Matching parameterized by the size $k$ of the solution we are\nseeking. Many important parameterized problems that form the backbone of\ntraditional parameterized complexity are known to require $\\Omega(n)$ bits for\nany streaming algorithm; e.g., Feedback Vertex Set, Even/Odd Cycle Transversal,\nTriangle Deletion or the more general ${\\cal F}$-Subgraph Deletion when\nparameterized by solution size $k$.\n  Our main conceptual contribution is to overcome the obstacles to efficient\nparameterized streaming algorithms by utilizing the power of parameterization.\nTo the best of our knowledge, this is the first work in parameterized streaming\ncomplexity that considers structural parameters instead of the solution size as\na parameter. We focus on the vertex cover size $K$ as the parameter for the\nparameterized graph deletion problems we consider. At the same time, most of\nthe previous work in parameterized streaming complexity was restricted to the\nEA (edge arrival) or DEA (dynamic edge arrival) models. In this work, we\nconsider the above mentioned graph deletion problems in the four most\nwell-studied streaming models, i.e., the EA, DEA, VA (vertex arrival) and AL\n(adjacency list) models.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 02:24:36 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 13:30:54 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Bishnu", "Arijit", ""], ["Ghosh", "Arijit", ""], ["Kolay", "Sudeshna", ""], ["Mishra", "Gopinath", ""], ["Saurabh", "Saket", ""]]}, {"id": "1906.05565", "submitter": "Huib Donkers", "authors": "Huib Donkers, Bart M.P. Jansen", "title": "A Turing Kernelization Dichotomy for Structural Parameterizations of\n  $\\mathcal{F}$-Minor-Free Deletion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a fixed finite family of graphs $\\mathcal{F}$, the\n$\\mathcal{F}$-Minor-Free Deletion problem takes as input a graph $G$ and an\ninteger $\\ell$ and asks whether there exists a set $X \\subseteq V(G)$ of size\nat most $\\ell$ such that $G-X$ is $\\mathcal{F}$-minor-free. For\n$\\mathcal{F}=\\{K_2\\}$ and $\\mathcal{F}=\\{K_3\\}$ this encodes Vertex Cover and\nFeedback Vertex Set respectively. When parameterized by the feedback vertex\nnumber of $G$ these two problems are known to admit a polynomial kernelization.\nSuch a polynomial kernelization also exists for any $\\mathcal{F}$ containing a\nplanar graph but no forests. In this paper we show that\n$\\mathcal{F}$-Minor-Free Deletion parameterized by the feedback vertex number\nis MK[2]-hard for $\\mathcal{F} = \\{P_3\\}$. This rules out the existence of a\npolynomial kernel assuming $NP \\subseteq coNP/poly$, and also gives evidence\nthat the problem does not admit a polynomial Turing kernel. Our hardness result\ngeneralizes to any $\\mathcal{F}$ not containing a $P_3$-subgraph-free graph,\nusing as parameter the vertex-deletion distance to treewidth\n$mintw(\\mathcal{F})$, where $mintw(\\mathcal{F})$ denotes the minimum treewidth\nof the graphs in $\\mathcal{F}$. For the other case, where $\\mathcal{F}$\ncontains a $P_3$-subgraph-free graph, we present a polynomial Turing\nkernelization. Our results extend to $\\mathcal{F}$-Subgraph-Free Deletion.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 09:32:52 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 10:52:04 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Donkers", "Huib", ""], ["Jansen", "Bart M. P.", ""]]}, {"id": "1906.05736", "submitter": "Jialin Zhang", "authors": "Xiaoming Sun, David P. Woodruff, Guang Yang, Jialin Zhang", "title": "Querying a Matrix through Matrix-Vector Products", "comments": "28 pages, to appear in ICALP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider algorithms with access to an unknown matrix $M\\in\\mathbb{F}^{n\n\\times d}$ via matrix-vector products, namely, the algorithm chooses vectors\n$\\mathbf{v}^1, \\ldots, \\mathbf{v}^q$, and observes $M\\mathbf{v}^1,\\ldots,\nM\\mathbf{v}^q$. Here the $\\mathbf{v}^i$ can be randomized as well as chosen\nadaptively as a function of $ M\\mathbf{v}^1,\\ldots,M\\mathbf{v}^{i-1}$.\nMotivated by applications of sketching in distributed computation, linear\nalgebra, and streaming models, as well as connections to areas such as\ncommunication complexity and property testing, we initiate the study of the\nnumber $q$ of queries needed to solve various fundamental problems. We study\nproblems in three broad categories, including linear algebra, statistics\nproblems, and graph problems. For example, we consider the number of queries\nrequired to approximate the rank, trace, maximum eigenvalue, and norms of a\nmatrix $M$; to compute the AND/OR/Parity of each column or row of $M$, to\ndecide whether there are identical columns or rows in $M$ or whether $M$ is\nsymmetric, diagonal, or unitary; or to compute whether a graph defined by $M$\nis connected or triangle-free. We also show separations for algorithms that are\nallowed to obtain matrix-vector products only by querying vectors on the right,\nversus algorithms that can query vectors on both the left and the right. We\nalso show separations depending on the underlying field the matrix-vector\nproduct occurs in. For graph problems, we show separations depending on the\nform of the matrix (bipartite adjacency versus signed edge-vertex incidence\nmatrix) to represent the graph.\n  Surprisingly, this fundamental model does not appear to have been studied on\nits own, and we believe a thorough investigation of problems in this model\nwould be beneficial to a number of different application areas.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 14:55:50 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 01:14:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Sun", "Xiaoming", ""], ["Woodruff", "David P.", ""], ["Yang", "Guang", ""], ["Zhang", "Jialin", ""]]}, {"id": "1906.05815", "submitter": "Mohammad Mahmoody", "authors": "Dimitrios I. Diochnos, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Lower Bounds for Adversarially Robust PAC Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we initiate a formal study of probably approximately correct\n(PAC) learning under evasion attacks, where the adversary's goal is to\n\\emph{misclassify} the adversarially perturbed sample point $\\widetilde{x}$,\ni.e., $h(\\widetilde{x})\\neq c(\\widetilde{x})$, where $c$ is the ground truth\nconcept and $h$ is the learned hypothesis. Previous work on PAC learning of\nadversarial examples have all modeled adversarial examples as corrupted inputs\nin which the goal of the adversary is to achieve $h(\\widetilde{x}) \\neq c(x)$,\nwhere $x$ is the original untampered instance. These two definitions of\nadversarial risk coincide for many natural distributions, such as images, but\nare incomparable in general.\n  We first prove that for many theoretically natural input spaces of high\ndimension $n$ (e.g., isotropic Gaussian in dimension $n$ under $\\ell_2$\nperturbations), if the adversary is allowed to apply up to a sublinear\n$o(||x||)$ amount of perturbations on the test instances, PAC learning requires\nsample complexity that is exponential in $n$. This is in contrast with results\nproved using the corrupted-input framework, in which the sample complexity of\nrobust learning is only polynomially more.\n  We then formalize hybrid attacks in which the evasion attack is preceded by a\npoisoning attack. This is perhaps reminiscent of \"trapdoor attacks\" in which a\npoisoning phase is involved as well, but the evasion phase here uses the\nerror-region definition of risk that aims at misclassifying the perturbed\ninstances. In this case, we show PAC learning is sometimes impossible all\ntogether, even when it is possible without the attack (e.g., due to the bounded\nVC dimension).\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:01:19 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Diochnos", "Dimitrios I.", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1906.06732", "submitter": "Sidhanth Mohanty", "authors": "Sidhanth Mohanty, Ryan O'Donnell, Pedro Paredes", "title": "The SDP value for random two-eigenvalue CSPs", "comments": "50 pages excluding title page and table of contents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We precisely determine the SDP value (equivalently, quantum value) of large\nrandom instances of certain kinds of constraint satisfaction problems,\n``two-eigenvalue 2CSPs''. We show this SDP value coincides with the spectral\nrelaxation value, possibly indicating a computational threshold. Our analysis\nextends the previously resolved cases of random regular $\\mathsf{2XOR}$ and\n$\\textsf{NAE-3SAT}$, and includes new cases such as random $\\mathsf{Sort}_4$\n(equivalently, $\\mathsf{CHSH}$) and $\\mathsf{Forrelation}$ CSPs. Our techniques\ninclude new generalizations of the nonbacktracking operator, the Ihara--Bass\nFormula, and the Friedman/Bordenave proof of Alon's Conjecture.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 17:30:46 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Mohanty", "Sidhanth", ""], ["O'Donnell", "Ryan", ""], ["Paredes", "Pedro", ""]]}, {"id": "1906.06873", "submitter": "Chao Qian", "authors": "Chao Bian, Chao Qian, Ke Tang", "title": "Running Time Analysis of the (1+1)-EA for Robust Linear Optimization", "comments": "17 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms (EAs) have found many successful real-world\napplications, where the optimization problems are often subject to a wide range\nof uncertainties. To understand the practical behaviors of EAs theoretically,\nthere are a series of efforts devoted to analyzing the running time of EAs for\noptimization under uncertainties. Existing studies mainly focus on noisy and\ndynamic optimization, while another common type of uncertain optimization,\ni.e., robust optimization, has been rarely touched. In this paper, we analyze\nthe expected running time of the (1+1)-EA solving robust linear optimization\nproblems (i.e., linear problems under robust scenarios) with a cardinality\nconstraint $k$. Two common robust scenarios, i.e., deletion-robust and\nworst-case, are considered. Particularly, we derive tight ranges of the robust\nparameter $d$ or budget $k$ allowing the (1+1)-EA to find an optimal solution\nin polynomial running time, which disclose the potential of EAs for robust\noptimization.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 07:18:58 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Bian", "Chao", ""], ["Qian", "Chao", ""], ["Tang", "Ke", ""]]}, {"id": "1906.06965", "submitter": "Markus Schmid", "authors": "Florin Manea, Markus L. Schmid", "title": "Matching Patterns with Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pattern p (i.e., a string of variables and terminals) matches a word w, if\nw can be obtained by uniformly replacing the variables of p by terminal words.\nThe respective matching problem, i.e., deciding whether or not a given pattern\nmatches a given word, is generally NP-complete, but can be solved in\npolynomial-time for classes of patterns with restricted structure. In this\npaper we overview a series of recent results related to efficient matching for\npatterns with variables, as well as a series of extensions of this problem.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 11:38:42 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 14:45:41 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Manea", "Florin", ""], ["Schmid", "Markus L.", ""]]}, {"id": "1906.07031", "submitter": "Victor Lagerkvist Dr.", "authors": "Victor Lagerkvist and Gustav Nordh", "title": "On the Strength of Uniqueness Quantification in Primitive Positive\n  Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniqueness quantification ($\\exists !$) is a quantifier in first-order logic\nwhere one requires that exactly one element exists satisfying a given property.\nIn this paper we investigate the strength of uniqueness quantification when it\nis used in place of existential quantification in conjunctive formulas over a\ngiven set of relations $\\Gamma$, so-called primitive positive definitions\n(pp-definitions). We fully classify the Boolean sets of relations where\nuniqueness quantification has the same strength as existential quantification\nin pp-definitions and give several results valid for arbitrary finite domains.\nWe also consider applications of $\\exists !$-quantified pp-definitions in\ncomputer science, which can be used to study the computational complexity of\nproblems where the number of solutions is important. Using our classification\nwe give a new and simplified proof of the trichotomy theorem for the unique\nsatisfiability problem, and prove a general result for the unique constraint\nsatisfaction problem.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 13:39:16 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lagerkvist", "Victor", ""], ["Nordh", "Gustav", ""]]}, {"id": "1906.07398", "submitter": "Arijit Ghosh", "authors": "Arijit Bishnu, Arijit Ghosh, Gopinath Mishra, Manaswi Paraashar", "title": "Inner Product Oracle can Estimate and Sample", "comments": "This work was submitted to RANDOM-APPROX 2019 on 3 May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Edge estimation problem in unweighted graphs using local and sometimes global\nqueries is a fundamental problem in sublinear algorithms. It has been observed\nby Goldreich and Ron (Random Structures & Algorithms, 2008), that weighted edge\nestimation for weighted graphs require $\\Omega(n)$ local queries, where $n$\ndenotes the number of vertices in the graph. To handle this problem, we\nintroduce a new inner product query on matrices. Inner product query\ngeneralizes and unifies all previously used local queries on graphs used for\nestimating edges. With this new query, we show that weighted edge estimation in\ngraphs with particular kind of weights can be solved using sublinear queries,\nin terms of the number of vertices. We also show that using this query we can\nsolve the problem of the bilinear form estimation, and the problem of weighted\nsampling of entries of matrices induced by bilinear forms. This work is the\nfirst step towards weighted edge estimation mentioned in Goldreich and Ron\n(Random Structures & Algorithms, 2008).\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 06:25:18 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Bishnu", "Arijit", ""], ["Ghosh", "Arijit", ""], ["Mishra", "Gopinath", ""], ["Paraashar", "Manaswi", ""]]}, {"id": "1906.08308", "submitter": "Lane A. Hemaspaandra", "authors": "Edith Hemaspaandra, Lane A. Hemaspaandra, Joerg Rothe", "title": "The Complexity of Online Bribery in Sequential Elections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on the complexity of bribery assumes that the bribery happens\nsimultaneously, and that the briber has full knowledge of all voters' votes.\nBut neither of those assumptions always holds. In many real-world settings,\nvotes come in sequentially, and the briber may have a use-it-or-lose-it moment\nto decide whether to bribe/alter a given vote, and at the time of making that\ndecision, the briber may not know what votes remaining voters are planning on\ncasting.\n  In this paper, we introduce a model for, and initiate the study of, bribery\nin such an online, sequential setting. We show that even for election systems\nwhose winner-determination problem is polynomial-time computable, an online,\nsequential setting may vastly increase the complexity of bribery, in fact\njumping the problem up to completeness for high levels of the polynomial\nhierarchy or even PSPACE. On the other hand, we show that for some natural,\nimportant election systems, such a dramatic complexity increase does not occur,\nand we pinpoint the complexity of their bribery problems in the online,\nsequential setting.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 19:04:09 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""], ["Rothe", "Joerg", ""]]}, {"id": "1906.08371", "submitter": "Pawe{\\l} Rz\\k{a}\\.zewski", "authors": "Karolina Okrasa, Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Fine-grained complexity of the graph homomorphism problem for\n  bounded-treewidth graphs", "comments": "An extended abstract of this paper appeared on SODA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For graphs $G$ and $H$, a \\emph{homomorphism} from $G$ to $H$ is an\nedge-preserving mapping from the vertex set of $G$ to the vertex set of $H$.\nFor a fixed graph $H$, by \\textsc{Hom($H$)} we denote the computational problem\nwhich asks whether a given graph $G$ admits a homomorphism to $H$. If $H$ is a\ncomplete graph with $k$ vertices, then \\textsc{Hom($H$)} is equivalent to the\n$k$-\\textsc{Coloring} problem, so graph homomorphisms can be seen as\ngeneralizations of colorings. It is known that \\textsc{Hom($H$)} is\npolynomial-time solvable if $H$ is bipartite or has a vertex with a loop, and\nNP-complete otherwise [Hell and Ne\\v{s}et\\v{r}il, JCTB 1990]. In this paper we\nare interested in the complexity of the problem, parameterized by the treewidth\nof the input graph $G$. If $G$ has $n$ vertices and is given along with its\ntree decomposition of width $\\mathrm{tw}(G)$, then the problem can be solved in\ntime $|V(H)|^{\\mathrm{tw}(G)} \\cdot n^{\\mathcal{O}(1)}$, using a\nstraightforward dynamic programming. We explore whether this bound can be\nimproved. We show that if $H$ is a \\emph{projective core}, then the existence\nof such a faster algorithm is unlikely: assuming the Strong Exponential Time\nHypothesis (SETH), the \\textsc{Hom($H$)} problem cannot be solved in time\n$(|V(H)|-\\epsilon)^{\\mathrm{tw}(G)} \\cdot n^{\\mathcal{O}(1)}$, for any\n$\\epsilon > 0$. This result provides a full complexity characterization for a\nlarge class of graphs $H$, as almost all graphs are projective cores. We also\nnotice that the naive algorithm can be improved for some graphs $H$, and show a\ncomplexity classification for all graphs $H$, assuming two conjectures from\nalgebraic graph theory. In particular, there are no known graphs $H$ which are\nnot covered by our result. In order to prove our results, we bring together\nsome tools and techniques from algebra and from fine-grained complexity.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 21:41:06 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 14:09:29 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 23:36:24 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Okrasa", "Karolina", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "1906.08890", "submitter": "Robin Kothari", "authors": "Adam Bene Watts, Robin Kothari, Luke Schaeffer, Avishay Tal", "title": "Exponential separation between shallow quantum circuits and unbounded\n  fan-in shallow classical circuits", "comments": null, "journal-ref": "Proceedings of the 51st Annual Symposium on Theory of Computing,\n  STOC 2019, Pages 515-526", "doi": "10.1145/3313276.3316404", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Bravyi, Gosset, and K\\\"{o}nig (Science, 2018) exhibited a search\nproblem called the 2D Hidden Linear Function (2D HLF) problem that can be\nsolved exactly by a constant-depth quantum circuit using bounded fan-in gates\n(or QNC^0 circuits), but cannot be solved by any constant-depth classical\ncircuit using bounded fan-in AND, OR, and NOT gates (or NC^0 circuits). In\nother words, they exhibited a search problem in QNC^0 that is not in NC^0.\n  We strengthen their result by proving that the 2D HLF problem is not\ncontained in AC^0, the class of classical, polynomial-size, constant-depth\ncircuits over the gate set of unbounded fan-in AND and OR gates, and NOT gates.\nWe also supplement this worst-case lower bound with an average-case result:\nThere exists a simple distribution under which any AC^0 circuit (even of nearly\nexponential size) has exponentially small correlation with the 2D HLF problem.\nOur results are shown by constructing a new problem in QNC^0, which we call the\nRelaxed Parity Halving Problem, which is easier to work with. We prove our AC^0\nlower bounds for this problem, and then show that it reduces to the 2D HLF\nproblem.\n  As a step towards even stronger lower bounds, we present a search problem\nthat we call the Parity Bending Problem, which is in QNC^0/qpoly (QNC^0\ncircuits that are allowed to start with a quantum state of their choice that is\nindependent of the input), but is not even in AC^0[2] (the class AC^0 with\nunbounded fan-in XOR gates).\n  All the quantum circuits in our paper are simple, and the main difficulty\nlies in proving the classical lower bounds. For this we employ a host of\ntechniques, including a refinement of H{\\aa}stad's switching lemmas for\nmulti-output circuits that may be of independent interest, the\nRazborov-Smolensky AC^0[2] lower bound, Vazirani's XOR lemma, and lower bounds\nfor non-local games.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 22:53:06 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Watts", "Adam Bene", ""], ["Kothari", "Robin", ""], ["Schaeffer", "Luke", ""], ["Tal", "Avishay", ""]]}, {"id": "1906.08902", "submitter": "Heliang Huang", "authors": "Chen Ding, Tian-Yi Bao, He-Liang Huang", "title": "Quantum-Inspired Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machine (SVM) is a particularly powerful and flexible\nsupervised learning model that analyzes data for both classification and\nregression, whose usual algorithm complexity scales polynomially with the\ndimension of data space and the number of data points. To tackle the big data\nchallenge, a quantum SVM algorithm was proposed, which is claimed to achieve\nexponential speedup for least squares SVM (LS-SVM). Here, inspired by the\nquantum SVM algorithm, we present a quantum-inspired classical algorithm for\nLS-SVM. In our approach, a improved fast sampling technique, namely indirect\nsampling, is proposed for sampling the kernel matrix and classifying. We first\nconsider the LS-SVM with a linear kernel, and then discuss the generalization\nof our method to non-linear kernels. Theoretical analysis shows our algorithm\ncan make classification with arbitrary success probability in logarithmic\nruntime of both the dimension of data space and the number of data points for\nlow rank, low condition number and high dimensional data matrix, matching the\nruntime of the quantum SVM.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 01:00:07 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 15:41:56 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 11:07:10 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 02:35:34 GMT"}, {"version": "v5", "created": "Tue, 16 Mar 2021 01:54:20 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ding", "Chen", ""], ["Bao", "Tian-Yi", ""], ["Huang", "He-Liang", ""]]}, {"id": "1906.09226", "submitter": "Marcelo Arenas", "authors": "Marcelo Arenas, Luis Alberto Croquevielle, Rajesh Jayaram, Cristian\n  Riveros", "title": "$\\text{#NFA}$ admits an FPRAS: Efficient Enumeration, Counting, and\n  Uniform Generation for Logspace Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study two simple yet general complexity classes, based on\nlogspace Turing machines, which provide a unifying framework for efficient\nquery evaluation in areas like information extraction and graph databases,\namong others. We investigate the complexity of three fundamental algorithmic\nproblems for these classes: enumeration, counting and uniform generation of\nsolutions, and show that they have several desirable properties in this\nrespect.\n  Both complexity classes are defined in terms of non-deterministic logspace\ntransducers (NL transducers). For the first class, we consider the case of\nunambiguous NL transducers, and we prove constant delay enumeration, and both\ncounting and uniform generation of solutions in polynomial time. For the second\nclass, we consider unrestricted NL transducers, and we obtain polynomial delay\nenumeration, approximate counting in polynomial time, and polynomial-time\nrandomized algorithms for uniform generation. More specifically, we show that\neach problem in this second class admits a fully polynomial-time randomized\napproximation scheme (FPRAS) and a polynomial-time Las Vegas algorithm for\nuniform generation. Interestingly, the key idea to prove these results is to\nshow that the fundamental problem $\\text{#NFA}$ admits an FPRAS, where\n$\\text{#NFA}$ is the problem of counting the number of strings of length $n$\n(given in unary) accepted by a non-deterministic finite automaton (NFA). While\nthis problem is known to be $\\text{#P}$-complete and, more precisely,\n$\\text{SpanL}$-complete, it was open whether this problem admits an FPRAS. In\nthis work, we solve this open problem, and obtain as a welcome corollary that\nevery function in $\\text{SpanL}$ admits an FPRAS.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:22:53 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 17:49:06 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 01:26:48 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 16:25:32 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Arenas", "Marcelo", ""], ["Croquevielle", "Luis Alberto", ""], ["Jayaram", "Rajesh", ""], ["Riveros", "Cristian", ""]]}, {"id": "1906.09873", "submitter": "Rasoul Ramezanian", "authors": "Rasoul Ramezanian", "title": "Computer-Simulation Model Theory (P= NP is not provable)", "comments": "18 pages. arXiv admin note: text overlap with arXiv:1205.5994", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simulation hypothesis says that all the materials and events in the\nreality (including the universe, our body, our thinking, walking and etc) are\ncomputations, and the reality is a computer simulation program like a video\ngame. All works we do (talking, reasoning, seeing and etc) are computations\nperformed by the universe-computer which runs the simulation program. Inspired\nby the view of the simulation hypothesis (but independent of this hypothesis),\nwe propose a new method of logical reasoning named \"Computer-Simulation Model\nTheory\", CSMT. Computer-Simulation Model Theory is an extension of Mathematical\nModel Theory where instead of mathematical-structures, computer-simulations are\nreplaced, and the activity of reasoning and computing of the reasoner is also\nsimulated in the model. (CSMT) argues that:\n  For a formula $\\phi$, construct a computer simulation model $S$, such that\n  1- $\\phi$ does not hold in $S$, and\n  2- the reasoner $I$ $($human being, the one who lives inside the reality$)$\ncannot distinguish $S$ from the reality $(R)$,\n  then $I$ cannot prove $\\phi$ in reality.\n  Although $\\mathrm{CSMT}$ is inspired by the simulation hypothesis, but this\nreasoning method is independent of the acceptance of this hypothesis. As we\nargue in this part, one may do not accept the simulation hypothesis, but knows\n$\\mathrm{CSMT}$ a valid reasoning method. As an application of\nComputer-Simulation Model Theory, we study the famous problem P vs NP. We let\n$\\phi \\equiv\\mathrm{ [P= NP]} $ and construct a computer simulation model $E$\nsuch that $\\mathrm{P= NP}$ does not hold in $E$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 05:11:45 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ramezanian", "Rasoul", ""]]}, {"id": "1906.10047", "submitter": "Geoffrey Hamilton", "authors": "Amir M. Ben-Amram and Geoff Hamilton", "title": "Tight Polynomial Worst-Case Bounds for Loop Programs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 2 (May 14,\n  2020) lmcs:6477", "doi": "10.23638/LMCS-16(2:4)2020", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In 2008, Ben-Amram, Jones and Kristiansen showed that for a simple\nprogramming language - representing non-deterministic imperative programs with\nbounded loops, and arithmetics limited to addition and multiplication - it is\npossible to decide precisely whether a program has certain growth-rate\nproperties, in particular whether a computed value, or the program's running\ntime, has a polynomial growth rate.\n  A natural and intriguing problem was to move from answering the decision\nproblem to giving a quantitative result, namely, a tight polynomial upper\nbound. This paper shows how to obtain asymptotically-tight, multivariate,\ndisjunctive polynomial bounds for this class of programs. This is a complete\nsolution: whenever a polynomial bound exists it will be found.\n  A pleasant surprise is that the algorithm is quite simple; but it relies on\nsome subtle reasoning. An important ingredient in the proof is the forest\nfactorization theorem, a strong structural result on homomorphisms into a\nfinite monoid.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 16:11:40 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 20:29:17 GMT"}, {"version": "v3", "created": "Sat, 28 Mar 2020 12:57:29 GMT"}, {"version": "v4", "created": "Tue, 12 May 2020 08:06:30 GMT"}, {"version": "v5", "created": "Wed, 13 May 2020 12:45:40 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ben-Amram", "Amir M.", ""], ["Hamilton", "Geoff", ""]]}, {"id": "1906.10078", "submitter": "Fabian Frei", "authors": "Elisabet Burjons and Fabian Frei and Edith Hemaspaandra and Dennis\n  Komm and David Wehner", "title": "Finding Optimal Solutions With Neighborly Help", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we efficiently compute optimal solutions to instances of a hard problem\nfrom optimal solutions to neighboring (i.e., locally modified) instances? For\nexample, can we efficiently compute an optimal coloring for a graph from\noptimal colorings for all one-edge-deleted subgraphs? Studying such questions\nnot only gives detailed insight into the structure of the problem itself, but\nalso into the complexity of related problems; most notably graph theory's core\nnotion of critical graphs (e.g., graphs whose chromatic number decreases under\ndeletion of an arbitrary edge) and the complexity-theoretic notion of\nminimality problems (also called criticality problems, e.g., recognizing graphs\nthat become 3-colorable when an arbitrary edge is deleted).\n  We focus on two prototypical graph problems, Colorability and Vertex Cover.\nFor example, we show that it is NP-hard to compute an optimal coloring for a\ngraph from optimal colorings for all its one-vertex-deleted subgraphs, and that\nthis remains true even when optimal solutions for all one-edge-deleted\nsubgraphs are given. In contrast, computing an optimal coloring from all (or\neven just two) one-edge-added supergraphs is in P. We observe that Vertex Cover\nexhibits a remarkably different behavior, demonstrating the power of our model\nto delineate problems from each other more precisely on a structural level.\n  Moreover, we provide a number of new complexity results for minimality and\ncriticality problems. For example, we prove that Minimal-3-UnColorability is\ncomplete for DP (differences of NP sets), which was previously known only for\nthe more amenable case of deleting vertices rather than edges. For Vertex\nCover, we show that recognizing beta-vertex-critical graphs is complete for\nTheta_2^p (parallel access to NP), obtaining the first completeness result for\na criticality problem for this class.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 16:57:47 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 07:37:24 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Burjons", "Elisabet", ""], ["Frei", "Fabian", ""], ["Hemaspaandra", "Edith", ""], ["Komm", "Dennis", ""], ["Wehner", "David", ""]]}, {"id": "1906.10495", "submitter": "Joshua Cook", "authors": "Joshua Alan Cook", "title": "Approximating Unitary Preparations of Orthogonal Black Box States", "comments": "A Class project Paper for CS395T Quantum Complexity Theory at UT\n  Austin in Spring 2019 under Scott Aaronson", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, I take a step toward answering the following question: for m\ndifferent small circuits that compute m orthogonal n qubit states, is there a\nsmall circuit that will map m computational basis states to these m states\nwithout any input leaving any auxiliary bits changed. While this may seem\nsimple, the constraint that auxiliary bits always be returned to 0 on any input\n(even ones besides the m we care about) led me to use sophisticated techniques.\nI give an approximation of such a unitary in the m = 2 case that has size\npolynomial in the approximation error, and the number of qubits n.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 01:21:52 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Cook", "Joshua Alan", ""]]}, {"id": "1906.10705", "submitter": "Jacob Biamonte", "authors": "H. Philathong, V. Akshay, I. Zacharov, J. Biamonte", "title": "Computational Phase Transition Signature in Gibbs Sampling", "comments": "feedback welcome; RevTeX; 7 pages; 2 composite figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.dis-nn cond-mat.stat-mech cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs sampling is fundamental to a wide range of computer algorithms. Such\nalgorithms are set to be replaced by physics based processors$-$be it quantum\nor stochastic annealing devices$-$which embed problem instances and evolve a\nphysical system into an ensemble to recover a probability distribution. At a\ncritical constraint to variable ratio, decision problems$-$such as\npropositional satisfiability$-$appear to statistically exhibit an abrupt\ntransition in required computational resources. This so called, algorithmic or\ncomputational phase transition signature, has yet-to-be observed in\ncontemporary physics based processors. We found that the computational phase\ntransition admits a signature in Gibbs' distributions and hence we predict and\nprescribe the physical observation of this effect. We simulate such an\nexperiment, that when realized experimentally, we believe would represent a\nmilestone in the physical theory of computation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 18:00:12 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Philathong", "H.", ""], ["Akshay", "V.", ""], ["Zacharov", "I.", ""], ["Biamonte", "J.", ""]]}, {"id": "1906.10837", "submitter": "Muthuramakrishnan Venkitasubramaniam", "authors": "Rafael Pass and Muthuramakrishnan Venkitasubramaniam", "title": "Is it Easier to Prove Theorems that are Guaranteed to be True?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following two fundamental open problems in complexity theory:\n(a) Does a hard-on-average language in NP imply the existence of one-way\nfunctions?, or (b) Does a hard-on-average language in NP imply a\nhard-on-average problem in TFNP (i.e., the class of total NP search problem)?\nOur main result is that the answer to (at least) one of these questions is yes.\nBoth one-way functions and problems in TFNP can be interpreted as promise-true\ndistributional NP search problems---namely, distributional search problems\nwhere the sampler only samples true statements. As a direct corollary of the\nabove result, we thus get that the existence of a hard-on-average\ndistributional NP search problem implies a hard-on-average promise-true\ndistributional NP search problem. In other words, \"It is no easier to find\nwitnesses (a.k.a. proofs) for efficiently-sampled statements (theorems) that\nare guaranteed to be true.\" This result follows from a more general study of\ninteractive puzzles---a generalization of average-case hardness in NP---and in\nparticular, a novel round-collapse theorem for computationally-sound protocols,\nanalogous to Babai-Moran's celebrated round-collapse theorem for\ninformation-theoretically sound protocols. As another consequence of this\ntreatment, we show that the existence of O(1)-round public-coin non-trivial\narguments (i.e., argument systems that are not proofs) imply the existence of a\nhard-on-average problem in NP/poly.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 04:07:58 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 20:43:28 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Pass", "Rafael", ""], ["Venkitasubramaniam", "Muthuramakrishnan", ""]]}, {"id": "1906.11185", "submitter": "Ueverton Souza", "authors": "Claudson F. Bornstein and Martin Charles Golumbic and Tanilson D.\n  Santos and U\\'everton S. Souza and Jayme L. Szwarcfiter", "title": "The Complexity of Helly-$B_{1}$ EPG Graph Recognition", "comments": null, "journal-ref": "Discrete Mathematics & Theoretical Computer Science, vol. 22 no.\n  1, Graph Theory (June 4, 2020) dmtcs:6506", "doi": "10.23638/DMTCS-22-1-19", "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Golumbic, Lipshteyn, and Stern defined in 2009 the class of EPG graphs, the\nintersection graph class of edge paths on a grid. An EPG graph $G$ is a graph\nthat admits a representation where its vertices correspond to paths in a grid\n$Q$, such that two vertices of $G$ are adjacent if and only if their\ncorresponding paths in $Q$ have a common edge. If the paths in the\nrepresentation have at most $k$ bends, we say that it is a $B_k$-EPG\nrepresentation. A collection $C$ of sets satisfies the Helly property when\nevery sub-collection of $C$ that is pairwise intersecting has at least one\ncommon element. In this paper, we show that given a graph $G$ and an integer\n$k$, the problem of determining whether $G$ admits a $B_k$-EPG representation\nwhose edge-intersections of paths satisfy the Helly property, so-called\nHelly-$B_k$-EPG representation, is in NP, for every $k$ bounded by a polynomial\nfunction of $|V(G)|$. Moreover, we show that the problem of recognizing\nHelly-$B_1$-EPG graphs is NP-complete, and it remains NP-complete even when\nrestricted to 2-apex and 3-degenerate graphs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 16:06:16 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 14:38:39 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 16:44:33 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bornstein", "Claudson F.", ""], ["Golumbic", "Martin Charles", ""], ["Santos", "Tanilson D.", ""], ["Souza", "U\u00e9verton S.", ""], ["Szwarcfiter", "Jayme L.", ""]]}, {"id": "1906.11385", "submitter": "Ray Li", "authors": "Ray Li, Percy Liang, Stephen Mussmann", "title": "A Tight Analysis of Greedy Yields Subexponential Time Approximation for\n  Uniform Decision Tree", "comments": "40 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision Tree is a classic formulation of active learning: given $n$\nhypotheses with nonnegative weights summing to 1 and a set of tests that each\npartition the hypotheses, output a decision tree using the provided tests that\nuniquely identifies each hypothesis and has minimum (weighted) average depth.\nPrevious works showed that the greedy algorithm achieves a $O(\\log n)$\napproximation ratio for this problem and it is NP-hard beat a $O(\\log n)$\napproximation, settling the complexity of the problem.\n  However, for Uniform Decision Tree, i.e. Decision Tree with uniform weights,\nthe story is more subtle. The greedy algorithm's $O(\\log n)$ approximation\nratio was the best known, but the largest approximation ratio known to be\nNP-hard is $4-\\varepsilon$. We prove that the greedy algorithm gives a\n$O(\\frac{\\log n}{\\log C_{OPT}})$ approximation for Uniform Decision Tree, where\n$C_{OPT}$ is the cost of the optimal tree and show this is best possible for\nthe greedy algorithm. As a corollary, we resolve a conjecture of Kosaraju,\nPrzytycka, and Borgstrom. Leveraging this result, for all $\\alpha\\in(0,1)$, we\nexhibit a $\\frac{9.01}{\\alpha}$ approximation algorithm to Uniform Decision\nTree running in subexponential time $2^{\\tilde O(n^\\alpha)}$. As a corollary,\nachieving any super-constant approximation ratio on Uniform Decision Tree is\nnot NP-hard, assuming the Exponential Time Hypothesis. This work therefore adds\napproximating Uniform Decision Tree to a small list of natural problems that\nhave subexponential time algorithms but no known polynomial time algorithms.\nAll our results hold for Decision Tree with weights not too far from uniform. A\nkey technical contribution of our work is showing a connection between greedy\nalgorithms for Uniform Decision Tree and for Min Sum Set Cover.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 23:34:46 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:56:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Li", "Ray", ""], ["Liang", "Percy", ""], ["Mussmann", "Stephen", ""]]}, {"id": "1906.11985", "submitter": "Nimit Sohoni", "authors": "Oliver Hinder and Aaron Sidford and Nimit Sharad Sohoni", "title": "Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide near-optimal accelerated first-order methods for\nminimizing a broad class of smooth nonconvex functions that are strictly\nunimodal on all lines through a minimizer. This function class, which we call\nthe class of smooth quasar-convex functions, is parameterized by a constant\n$\\gamma \\in (0,1]$, where $\\gamma = 1$ encompasses the classes of smooth convex\nand star-convex functions, and smaller values of $\\gamma$ indicate that the\nfunction can be \"more nonconvex.\" We develop a variant of accelerated gradient\ndescent that computes an $\\epsilon$-approximate minimizer of a smooth\n$\\gamma$-quasar-convex function with at most $O(\\gamma^{-1} \\epsilon^{-1/2}\n\\log(\\gamma^{-1} \\epsilon^{-1}))$ total function and gradient evaluations. We\nalso derive a lower bound of $\\Omega(\\gamma^{-1} \\epsilon^{-1/2})$ on the\nnumber of gradient evaluations required by any deterministic first-order method\nin the worst case, showing that, up to a logarithmic factor, no deterministic\nfirst-order algorithm can improve upon ours.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 22:39:35 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Hinder", "Oliver", ""], ["Sidford", "Aaron", ""], ["Sohoni", "Nimit Sharad", ""]]}, {"id": "1906.12297", "submitter": "Paloma Thome De Lima", "authors": "Esther Galby and Paloma T. Lima and Bernard Ries", "title": "Blocking dominating sets for $H$-free graphs via edge contractions", "comments": "arXiv admin note: text overlap with arXiv:1903.01800", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the following problem: given a connected graph\n$G$, can we reduce the domination number of $G$ by one by using only one edge\ncontraction? We show that the problem is $\\mathsf{NP}$-hard when restricted to\n$\\{P_6,P_4+P_2\\}$-free graphs and that it is $\\mathsf{coNP}$-hard when\nrestricted to subcubic claw-free graphs and $2P_3$-free graphs. As a\nconsequence, we are able to establish a complexity dichotomy for the problem on\n$H$-free graphs when $H$ is connected.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 16:40:10 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 12:17:32 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Galby", "Esther", ""], ["Lima", "Paloma T.", ""], ["Ries", "Bernard", ""]]}]