[{"id": "1602.00349", "submitter": "Jaroslav Hor\\'a\\v{c}ek", "authors": "Jaroslav Hor\\'a\\v{c}ek, Milan Hlad\\'ik and Michal \\v{C}ern\\'y", "title": "Interval Linear Algebra and Computational Complexity", "comments": "Submitted to Mat Triad 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work connects two mathematical fields - computational complexity and\ninterval linear algebra. It introduces the basic topics of interval linear\nalgebra - regularity and singularity, full column rank, solving a linear\nsystem, deciding solvability of a linear system, computing inverse matrix,\neigenvalues, checking positive (semi)definiteness or stability. We discuss\nthese problems and relations between them from the view of computational\ncomplexity. Many problems in interval linear algebra are intractable, hence we\nemphasize subclasses of these problems that are easily solvable or decidable.\nThe aim of this work is to provide a basic insight into this field and to\nprovide materials for further reading and research.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 00:00:15 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Hor\u00e1\u010dek", "Jaroslav", ""], ["Hlad\u00edk", "Milan", ""], ["\u010cern\u00fd", "Michal", ""]]}, {"id": "1602.00398", "submitter": "Seunghoon Lee", "authors": "Seunghoon Lee", "title": "A Short Note on Improved Logic Circuits in a Hexagonal Minesweeper", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to present an advanced version of PP-hardness proof of\nMinesweeper by Bondt. The advancement includes improved Minesweeper\nconfigurations for 'logic circuits' in a hexagonal Minesweeper. To do so, I\ndemonstrate logical uncertainty in Minesweeper, which ironically allows a\npossibility to make some Boolean operators.\n  The fact that existing hexagonal logic circuits did not clearly distinguish\nthe true and false signal needs an improved form of a hexagonal wire. I\nintroduce new forms of logic circuits such as NOT, AND, OR gates, a curve and a\nsplitter of wires. Moreover, these new logic circuits complement Bondt's proof\nfor PP-hardness of Minesweeper by giving a new figure.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 06:11:35 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Lee", "Seunghoon", ""]]}, {"id": "1602.00546", "submitter": "Amaury Pouly", "authors": "Olivier Bournez, Daniel Gra\\c{c}a, Amaury Pouly", "title": "On the Functions Generated by the General Purpose Analog Computer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the General Purpose Analog Computer (GPAC), introduced by Claude\nShannon in 1941 as a mathematical model of Differential Analysers, that is to\nsay as a model of continuous-time analog (mechanical, and later one electronic)\nmachines of that time. We extend the model properly to a model of computation\nnot restricted to univariate functions (i.e. functions $f: \\mathbb{R} \\to\n\\mathbb{R}$) but also to the multivariate case of (i.e. functions $f:\n\\mathbb{R}^n \\to \\mathbb{R}^m$), and establish some basic properties. In\nparticular, we prove that a very wide class of (continuous and discontinuous)\nfunctions can be uniformly approximated over their full domain. Technically: we\ngeneralize some known results about the GPAC to the multidimensional case: we\nextend naturally the notion of \\emph{generable} function, from the\nunidimensional to the multidimensional case. We prove a few stability\nproperties of this class, mostly stability by arithmetic operations,\ncomposition and ODE solving. We establish that generable functions are always\nanalytic. We prove that generable functions include some basic (useful)\ngenerable functions, and that we can (uniformly) approximate a wide range of\nfunctions this way. This extends some of the results from \\cite{Sha41} to the\nmultidimensional case, and this also strengths the approximation result from\n\\cite{Sha41} over a compact domain to a uniform approximation result over\nunbounded domains. We also discuss the issue of constants, and we prove that\ninvolved constants can basically assumed to always be polynomial time\ncomputable numbers.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 15:16:24 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 14:01:39 GMT"}, {"version": "v3", "created": "Sat, 20 Jan 2018 13:14:26 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Bournez", "Olivier", ""], ["Gra\u00e7a", "Daniel", ""], ["Pouly", "Amaury", ""]]}, {"id": "1602.01065", "submitter": "Quentin Bramas", "authors": "Quentin Bramas (NPA, LIP6, UPMC, LINCS), Toshimitsu Masuzawa\n  (Department of Information and Computer sciences Osaka University),\n  S\\'ebastien Tixeuil (NPA, LIP6, UPMC, LINCS)", "title": "Distributed Online Data Aggregation in Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating data in a dynamic graph, that is,\naggregating the data that originates from all nodes in the graph to a specific\nnode, the sink. We are interested in giving lower bounds for this problem,\nunder different kinds of adversaries. In our model, nodes are endowed with\nunlimited memory and unlimited computational power. Yet, we assume that\ncommunications between nodes are carried out with pairwise interactions, where\nnodes can exchange control information before deciding whether they transmit\ntheir data or not, given that each node is allowed to transmit its data at most\nonce. When a node receives a data from a neighbor, the node may aggregate it\nwith its own data. We consider three possible adversaries: the online adaptive\nadversary, the oblivious adversary , and the randomized adversary that chooses\nthe pairwise interactions uniformly at random. For the online adaptive and the\noblivious adversary, we give impossibility results when nodes have no knowledge\nabout the graph and are not aware of the future. Also, we give several tight\nbounds depending on the knowledge (be it topology related or time related) of\nthe nodes. For the randomized adversary, we show that the Gathering algorithm,\nwhich always commands a node to transmit, is optimal if nodes have no knowledge\nat all. Also, we propose an algorithm called Waiting Greedy, where a node\neither waits or transmits depending on some parameter, that is optimal when\neach node knows its future pairwise interactions with the sink.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 19:58:11 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 14:30:15 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Bramas", "Quentin", "", "NPA, LIP6, UPMC, LINCS"], ["Masuzawa", "Toshimitsu", "", "Department of Information and Computer sciences Osaka University"], ["Tixeuil", "S\u00e9bastien", "", "NPA, LIP6, UPMC, LINCS"]]}, {"id": "1602.01295", "submitter": "Petteri Kaski", "authors": "Andreas Bj\\\"orklund and Petteri Kaski", "title": "How proofs are prepared at Camelot", "comments": "42 pp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a design framework for robust, independently verifiable, and\nworkload-balanced distributed algorithms working on a common input. An\nalgorithm based on the framework is essentially a distributed encoding\nprocedure for a Reed--Solomon code, which enables (a) robustness against\nbyzantine failures with intrinsic error-correction and identification of failed\nnodes, and (b) independent randomized verification to check the entire\ncomputation for correctness, which takes essentially no more resources than\neach node individually contributes to the computation. The framework builds on\nrecent Merlin--Arthur proofs of batch evaluation of Williams~[{\\em Electron.\\\nColloq.\\ Comput.\\ Complexity}, Report TR16-002, January 2016] with the\nobservation that {\\em Merlin's magic is not needed} for batch evaluation---mere\nKnights can prepare the proof, in parallel, and with intrinsic\nerror-correction.\n  The contribution of this paper is to show that in many cases the verifiable\nbatch evaluation framework admits algorithms that match in total resource\nconsumption the best known sequential algorithm for solving the problem. As our\nmain result, we show that the $k$-cliques in an $n$-vertex graph can be counted\n{\\em and} verified in per-node $O(n^{(\\omega+\\epsilon)k/6})$ time and space on\n$O(n^{(\\omega+\\epsilon)k/6})$ compute nodes, for any constant $\\epsilon>0$ and\npositive integer $k$ divisible by $6$, where $2\\leq\\omega<2.3728639$ is the\nexponent of matrix multiplication. This matches in total running time the best\nknown sequential algorithm, due to Ne{\\v{s}}et{\\v{r}}il and Poljak [{\\em\nComment.~Math.~Univ.~Carolin.}~26 (1985) 415--419], and considerably improves\nits space usage and parallelizability. Further results include novel algorithms\nfor counting triangles in sparse graphs, computing the chromatic polynomial of\na graph, and computing the Tutte polynomial of a graph.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 13:45:12 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Bj\u00f6rklund", "Andreas", ""], ["Kaski", "Petteri", ""]]}, {"id": "1602.01385", "submitter": "Till Fluschnik", "authors": "Till Fluschnik and Manuel Sorge", "title": "The Minimum Shared Edges Problem on Planar Graphs", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Minimum Shared Edges problem introduced by Omran et al. [Journal\nof Combinatorial Optimization, 2015] on planar graphs: Planar MSE asks, given a\nplanar graph G = (V,E), two distinct vertices s,t in V , and two integers p, k,\nwhether there are p s-t paths in G that share at most k edges, where an edges\nis called shared if it appears in at least two of the p s-t paths. We show that\nPlanar MSE is NP-hard by reduction from Vertex Cover. We make use of a\ngrid-like structure, where the alignment (horizontal/vertical) of the edges in\nthe grid correspond to selection and validation gadgets respectively.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 17:38:15 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Fluschnik", "Till", ""], ["Sorge", "Manuel", ""]]}, {"id": "1602.01530", "submitter": "Kuan Cheng", "authors": "Kuan Cheng and Xin Li", "title": "Randomness Extraction in AC0 and with Small Locality", "comments": "62 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomness extractors, which extract high quality (almost-uniform) random\nbits from biased random sources, are important objects both in theory and in\npractice. While there have been significant progress in obtaining near optimal\nconstructions of randomness extractors in various settings, the computational\ncomplexity of randomness extractors is still much less studied. In particular,\nit is not clear whether randomness extractors with good parameters can be\ncomputed in several interesting complexity classes that are much weaker than P.\n  In this paper we study randomness extractors in the following two models of\ncomputation: (1) constant-depth circuits (AC0), and (2) the local computation\nmodel. Previous work in these models, such as [Vio05a], [GVW15] and [BG13],\nonly achieve constructions with weak parameters. In this work we give explicit\nconstructions of randomness extractors with much better parameters. As an\napplication, we use our AC0 extractors to study pseudorandom generators in AC0,\nand show that we can construct both cryptographic pseudorandom generators\n(under reasonable computational assumptions) and unconditional pseudorandom\ngenerators for space bounded computation with very good parameters.\n  Our constructions combine several previous techniques in randomness\nextractors, as well as introduce new techniques to reduce or preserve the\ncomplexity of extractors, which may be of independent interest. These include\n(1) a general way to reduce the error of strong seeded extractors while\npreserving the AC0 property and small locality, and (2) a seeded randomness\ncondenser with small locality.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 01:33:45 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2016 20:07:47 GMT"}, {"version": "v3", "created": "Tue, 5 Apr 2016 22:21:38 GMT"}, {"version": "v4", "created": "Fri, 11 Nov 2016 23:55:48 GMT"}, {"version": "v5", "created": "Tue, 23 Jan 2018 15:38:11 GMT"}, {"version": "v6", "created": "Wed, 24 Jan 2018 17:05:49 GMT"}, {"version": "v7", "created": "Fri, 20 Apr 2018 04:34:59 GMT"}, {"version": "v8", "created": "Sat, 9 Jun 2018 01:09:44 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Cheng", "Kuan", ""], ["Li", "Xin", ""]]}, {"id": "1602.01739", "submitter": "Till Fluschnik", "authors": "Till Fluschnik, Stefan Kratsch, Rolf Niedermeier, and Manuel Sorge", "title": "The Parameterized Complexity of the Minimum Shared Edges Problem", "comments": "35 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the NP-complete Minimum Shared Edges (MSE) problem. Given an\nundirected graph, a source and a sink vertex, and two integers p and k, the\nquestion is whether there are p paths in the graph connecting the source with\nthe sink and sharing at most k edges. Herein, an edge is shared if it appears\nin at least two paths. We show that MSE is W[1]-hard when parameterized by the\ntreewidth of the input graph and the number k of shared edges combined. We show\nthat MSE is fixed-parameter tractable with respect to p, but does not admit a\npolynomial-size kernel (unless NP is contained in coNP/poly). In the proof of\nthe fixed-parameter tractability of MSE parameterized by p, we employ the\ntreewidth reduction technique due to Marx, O'Sullivan, and Razgon [ACM TALG\n2013].\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 16:40:49 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Fluschnik", "Till", ""], ["Kratsch", "Stefan", ""], ["Niedermeier", "Rolf", ""], ["Sorge", "Manuel", ""]]}, {"id": "1602.01819", "submitter": "Jesper Nederlof", "authors": "Jesper Nederlof", "title": "A short note on Merlin-Arthur protocols for subset sum", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the subset sum problem we are given n positive integers along with a\ntarget integer t. A solution is a subset of these integers summing to t. In\nthis short note we show that for a given subset sum instance there is a proof\nof size $O^*(\\sqrt{t})$ of what the number of solutions is that can be\nconstructed in $O^*(t)$ time and can be probabilistically verified in time\n$O^*(\\sqrt{t})$ with at most constant error probability. Here, the $O^*()$\nnotation omits factors polynomial in the input size $n\\log(t)$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 20:32:51 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Nederlof", "Jesper", ""]]}, {"id": "1602.02129", "submitter": "Michele Borassi", "authors": "Michele Borassi", "title": "A Note on the Complexity of Computing the Number of Reachable Vertices\n  in a Digraph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the following problem: given a digraph $G=(V,E)$,\nfor each vertex $v$, we want to compute the number of vertices reachable from\n$v$. In other words, we want to compute the out-degree of each vertex in the\ntransitive closure of $G$. We show that this problem is not solvable in time\n$\\mathcal{O}\\left(|E|^{2-\\epsilon}\\right)$ for any $\\epsilon>0$, unless the\nStrong Exponential Time Hypothesis is false. This result still holds if $G$ is\nassumed to be acyclic.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 19:31:09 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Borassi", "Michele", ""]]}, {"id": "1602.02211", "submitter": "Mohamed El Halaby", "authors": "Mohamed El Halaby, Areeg Abdalla", "title": "Fuzzy Maximum Satisfiability", "comments": "10 pages", "journal-ref": null, "doi": "10.1145/2908446.2908476", "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend the Maximum Satisfiability (MaxSAT) problem to\n{\\L}ukasiewicz logic. The MaxSAT problem for a set of formulae {\\Phi} is the\nproblem of finding an assignment to the variables in {\\Phi} that satisfies the\nmaximum number of formulae. Three possible solutions (encodings) are proposed\nto the new problem: (1) Disjunctive Linear Relations (DLRs), (2) Mixed Integer\nLinear Programming (MILP) and (3) Weighted Constraint Satisfaction Problem\n(WCSP). Like its Boolean counterpart, the extended fuzzy MaxSAT will have\nnumerous applications in optimization problems that involve vagueness.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 03:57:57 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Halaby", "Mohamed El", ""], ["Abdalla", "Areeg", ""]]}, {"id": "1602.02432", "submitter": "Robert Gilman", "authors": "Robert H Gilman", "title": "A Finitely presented group whose word problem has sampleable hard\n  instances", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hard instances of natural computational problems are often elusive. In this\nnote we present an example of a natural decision problem, the word problem for\na certain finitely presented group, whose hard instances are easy to find. More\nprecisely the problem has a complexity core sampleable in linear time.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 22:05:57 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Gilman", "Robert H", ""]]}, {"id": "1602.02445", "submitter": "Armin Wei{\\ss}", "authors": "Armin Wei{\\ss}", "title": "A Logspace Solution to the Word and Conjugacy problem of Generalized\n  Baumslag-Solitar Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Baumslag-Solitar groups were introduced in 1962 by Baumslag and Solitar as\nexamples for finitely presented non-Hopfian two-generator groups. Since then,\nthey served as examples for a wide range of purposes. As Baumslag-Solitar\ngroups are HNN extensions, there is a natural generalization in terms of graph\nof groups.\n  Concerning algorithmic aspects of generalized Baumslag-Solitar groups,\nseveral decidability results are known. Indeed, a straightforward application\nof standard algorithms leads to a polynomial time solution of the word problem\n(the question whether some word over the generators represents the identity of\nthe group). The conjugacy problem (the question whether two given words\nrepresent conjugate group elements) is more complicated; still decidability has\nbeen established by Anshel and Stebe for ordinary Baumslag-Solitar groups and\nfor generalized Baumslag-Solitar groups independently by Lockhart and Beeker.\nHowever, up to now no precise complexity estimates have been given.\n  In this work, we give a LOGSPACE algorithm for both problems. More precisely,\nwe describe a uniform TC^0 many-one reduction of the word problem to the word\nproblem of the free group. Then we refine the known techniques for the\nconjugacy problem and show that it can be solved in LOGSPACE. Moreover, for\nordinary Baumslag-Solitar groups also conjugacy is AC^0-Turing-reducible to the\nword problem of the free group.\n  Finally, we consider uniform versions (where also the graph of groups is part\nof the input) of both word and conjugacy problem: while the word problem still\nis solvable in LOGSPACE, the conjugacy problem becomes EXPSPACE-complete.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 01:07:24 GMT"}, {"version": "v2", "created": "Mon, 29 Feb 2016 02:43:38 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Wei\u00df", "Armin", ""]]}, {"id": "1602.02743", "submitter": "Michael Brand", "authors": "Michael Brand and David L. Dowe", "title": "The IMP game: Learnability, approximability and adversarial learning\n  beyond $\\Sigma^0_1$", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a problem set-up we call the Iterated Matching Pennies (IMP)\ngame and show that it is a powerful framework for the study of three problems:\nadversarial learnability, conventional (i.e., non-adversarial) learnability and\napproximability. Using it, we are able to derive the following theorems. (1) It\nis possible to learn by example all of $\\Sigma^0_1 \\cup \\Pi^0_1$ as well as\nsome supersets; (2) in adversarial learning (which we describe as a\npursuit-evasion game), the pursuer has a winning strategy (in other words,\n$\\Sigma^0_1$ can be learned adversarially, but $\\Pi^0_1$ not); (3) some\nlanguages in $\\Pi^0_1$ cannot be approximated by any language in $\\Sigma^0_1$.\n  We show corresponding results also for $\\Sigma^0_i$ and $\\Pi^0_i$ for\narbitrary $i$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 04:17:17 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Brand", "Michael", ""], ["Dowe", "David L.", ""]]}, {"id": "1602.02788", "submitter": "Divesh Aggarwal", "authors": "Divesh Aggarwal and Jop Bri\\\"et", "title": "Revisiting the Sanders-Freiman-Ruzsa Theorem in $\\mathbb{F}_p^n$ and its\n  Application to Non-malleable Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-malleable codes (NMCs) protect sensitive data against degrees of\ncorruption that prohibit error detection, ensuring instead that a corrupted\ncodeword decodes correctly or to something that bears little relation to the\noriginal message. The split-state model, in which codewords consist of two\nblocks, considers adversaries who tamper with either block arbitrarily but\nindependently of the other. The simplest construction in this model, due to\nAggarwal, Dodis, and Lovett (STOC'14), was shown to give NMCs sending k-bit\nmessages to $O(k^7)$-bit codewords. It is conjectured, however, that the\nconstruction allows linear-length codewords. Towards resolving this conjecture,\nwe show that the construction allows for code-length $O(k^5)$. This is achieved\nby analysing a special case of Sanders's Bogolyubov-Ruzsa theorem for general\nAbelian groups. Closely following the excellent exposition of this result for\nthe group $\\mathbb{F}_2^n$ by Lovett, we expose its dependence on $p$ for the\ngroup $\\mathbb{F}_p^n$, where $p$ is a prime.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 21:20:21 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Aggarwal", "Divesh", ""], ["Bri\u00ebt", "Jop", ""]]}, {"id": "1602.02863", "submitter": "Saber Mirzaei", "authors": "Saber Mirzaei, Assaf Kfoury", "title": "Efficient Reassembling of Graphs, Part 2: The Balanced Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reassembling of a simple connected graph G = (V,E) is an abstraction of a\nproblem arising in earlier studies of network analysis. The reassembling\nprocess has a simple formulation (there are several equivalent formulations)\nrelative to a binary tree B (reassembling tree), with root node at the top and\n$n$ leaf nodes at the bottom, where every cross-section corresponds to a\npartition of V such that:\n  - the bottom (or first) cross-section (all the leaves) is the finest\npartition of V with n one-vertex blocks,\n  - the top (or last) cross-section (the root) is the coarsest partition with a\nsingle block, the entire set V,\n  - a node (or block) in an intermediate cross-section (or partition) is the\nresult of merging its two children nodes (or blocks) in the cross-section (or\npartition) below it.\n  The maximum edge-boundary degree encountered during the reassembling process\nis what we call the alpha-measure of the reassembling, and the sum of all\nedge-boundary degrees is its beta-measure. The alpha-optimization (resp.\nbeta-optimization) of the reassembling of G is to determine a reassembling tree\nB that minimizes its alpha-measure (resp. beta-measure).\n  There are different forms of reassembling. In an earlier report, we studied\nlinear reassembling, which is the case when the height of B is (n-1). In this\nreport, we study balanced reassembling, when B has height [log n].\n  The two main results in this report are the NP-hardness of alpha-optimization\nand beta-optimization of balanced reassembling. The first result is obtained by\na sequence of polynomial-time reductions from minimum bisection of graphs\n(known to be NP-hard), and the second by a sequence of polynomial-time\nreductions from clique cover of graphs (known to be NP-hard).\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 05:15:51 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Mirzaei", "Saber", ""], ["Kfoury", "Assaf", ""]]}, {"id": "1602.03050", "submitter": "Martin L\\\"uck", "authors": "Martin L\\\"uck", "title": "Complete Problems of Propositional Logic for the Exponential Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large complexity classes, like the exponential time hierarchy, received\nlittle attention in terms of finding complete problems. In this work a\ngeneralization of propositional logic is investigated which fills this gap with\nthe introduction of Boolean higher-order quantifiers or equivalently Boolean\nSkolem functions. This builds on the important results of Wrathall and\nStockmeyer regarding complete problems, namely QBF and QBF-k, for the\npolynomial hierarchy. Furthermore it generalizes the Dependency QBF problem\nintroduced by Peterson, Reif and Azhar which is complete for NEXP, the first\nlevel of the exponential hierarchy. Also it turns out that the hardness results\ndo not collapse at the consideration of conjunctive and disjunctive normal\nforms, in contrast to plain QBF.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 16:14:46 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 13:28:42 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["L\u00fcck", "Martin", ""]]}, {"id": "1602.03124", "submitter": "Alexandr Kazda", "authors": "Alexandr Kazda, Vladimir Kolmogorov, Michal Rol\\'inek", "title": "Even Delta-Matroids and the Complexity of Planar Boolean CSPs", "comments": "33 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main result of this paper is a generalization of the classical blossom\nalgorithm for finding perfect matchings. Our algorithm can efficiently solve\nBoolean CSPs where each variable appears in exactly two constraints (we call it\nedge CSP) and all constraints are even $\\Delta$-matroid relations (represented\nby lists of tuples). As a consequence of this, we settle the complexity\nclassification of planar Boolean CSPs started by Dvorak and Kupec.\n  Using a reduction to even $\\Delta$-matroids, we then extend the tractability\nresult to larger classes of $\\Delta$-matroids that we call efficiently\ncoverable. It properly includes classes that were known to be tractable before,\nnamely co-independent, compact, local, linear and binary, with the following\ncaveat: we represent $\\Delta$-matroids by lists of tuples, while the last two\nuse a representation by matrices. Since an $n\\times n$ matrix can represent\nexponentially many tuples, our tractability result is not strictly stronger\nthan the known algorithm for linear and binary $\\Delta$-matroids.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 19:13:03 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2016 20:52:40 GMT"}, {"version": "v3", "created": "Sun, 5 Jun 2016 11:19:42 GMT"}, {"version": "v4", "created": "Sun, 27 Nov 2016 21:42:36 GMT"}, {"version": "v5", "created": "Wed, 15 Feb 2017 21:22:40 GMT"}, {"version": "v6", "created": "Thu, 14 Jun 2018 10:12:13 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Kazda", "Alexandr", ""], ["Kolmogorov", "Vladimir", ""], ["Rol\u00ednek", "Michal", ""]]}, {"id": "1602.03208", "submitter": "George Barmpalias Dr", "authors": "George Barmpalias and Nan Fang and Andrew Lewis-Pye", "title": "Optimal asymptotic bounds on the oracle use in computations from\n  Chaitin's Omega", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chaitin's number Omega is the halting probability of a universal prefix-free\nmachine, and although it depends on the underlying enumeration of prefix-free\nmachines, it is always Turing-complete. It can be observed, in fact, that for\nevery computably enumerable (c.e.) real, there exists a Turing functional via\nwhich Omega computes it, and such that the number of bits of omega that are\nneeded for the computation of the first n bits of the given number (i.e. the\nuse on argument n) is bounded above by a computable function h(n) = n+o(n). We\ncharacterise the asymptotic upper bounds on the use of Chaitin's omega in\noracle computations of halting probabilities (i.e. c.e. reals). We show that\nthe following two conditions are equivalent for any computable function h such\nthat h(n)-n is non-decreasing: (1) h(n)-n is an information content measure,\n(2) for every c.e. real there exists a Turing functional via which omega\ncomputes the real with use bounded by h. We also give a similar\ncharacterisation with respect to computations of c.e. sets from Omega, by\nshowing that the following are equivalent for any computable non-decreasing\nfunction g: (1) g is an information-content measure, (2) for every c.e. set A,\nOmega computes A with use bounded by g. Further results and some connections\nwith Solovay functions are given.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 08:59:56 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 08:29:04 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Barmpalias", "George", ""], ["Fang", "Nan", ""], ["Lewis-Pye", "Andrew", ""]]}, {"id": "1602.03332", "submitter": "Philippe Moser", "authors": "Philippe Moser", "title": "Polynomial Depth, Highness and Lowness for E", "comments": "To be published in I&C", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relations between the notions of highness, lowness and logical\ndepth in the setting of complexity theory. We introduce a new notion of polylog\ndepth based on time bounded Kolmogorov complexity. We show polylog depth\nsatisfies all basic logical depth properties, namely sets in P are not polylog\ndeep, sets with (time bounded)-Kolmogorov complexity greater than polylog are\nnot polylog deep, and only polylog deep sets can polynomially Turing compute a\npolylog deep set. We prove that if NP does not have p-measure zero, then NP\ncontains polylog deep sets. We show that every high set for E contains a\npolylog deep set in its polynomial Turing degree, and that there exist\nlow(E,EXP) polylog deep sets. Keywords: algorithmic information theory;\nKolmogorov complexity; Bennett logical depth.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 11:40:14 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 15:39:53 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Moser", "Philippe", ""]]}, {"id": "1602.03985", "submitter": "Andreas Galanis", "authors": "Andreas Galanis, Leslie Ann Goldberg and Mark Jerrum", "title": "A complexity trichotomy for approximately counting list H-colourings", "comments": "To appear in ACM Transactions on Computation Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the computational complexity of approximately counting the list\nH-colourings of a graph. We discover a natural graph-theoretic trichotomy based\non the structure of the graph H. If H is an irreflexive bipartite graph or a\nreflexive complete graph then counting list H-colourings is trivially in\npolynomial time. Otherwise, if H is an irreflexive bipartite permutation graph\nor a reflexive proper interval graph then approximately counting list\nH-colourings is equivalent to #BIS, the problem of approximately counting\nindependent sets in a bipartite graph. This is a well-studied problem which is\nbelieved to be of intermediate complexity -- it is believed that it does not\nhave an FPRAS, but that it is not as difficult as approximating the most\ndifficult counting problems in #P. For every other graph H, approximately\ncounting list H-colourings is complete for #P with respect to\napproximation-preserving reductions (so there is no FPRAS unless NP=RP). Two\npleasing features of the trichotomy are (i) it has a natural formulation in\nterms of hereditary graph classes, and (ii) the proof is largely self-contained\nand does not require any universal algebra (unlike similar dichotomies in the\nweighted case). We are able to extend the hardness results to the\nbounded-degree setting, showing that all hardness results apply to input graphs\nwith maximum degree at most 6.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 09:14:23 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2016 05:01:35 GMT"}, {"version": "v3", "created": "Wed, 20 Apr 2016 22:42:40 GMT"}, {"version": "v4", "created": "Fri, 18 Nov 2016 11:11:25 GMT"}, {"version": "v5", "created": "Fri, 16 Dec 2016 15:40:31 GMT"}, {"version": "v6", "created": "Thu, 5 Jan 2017 18:33:12 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Galanis", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}, {"id": "1602.04145", "submitter": "Adam Bouland", "authors": "Adam Bouland, Laura Man\\v{c}inska, Xue Zhang", "title": "Complexity classification of two-qubit commuting hamiltonians", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify two-qubit commuting Hamiltonians in terms of their computational\ncomplexity. Suppose one has a two-qubit commuting Hamiltonian H which one can\napply to any pair of qubits, starting in a computational basis state. We prove\na dichotomy theorem: either this model is efficiently classically simulable or\nit allows one to sample from probability distributions which cannot be sampled\nfrom classically unless the polynomial hierarchy collapses. Furthermore, the\nonly simulable Hamiltonians are those which fail to generate entanglement. This\nshows that generic two-qubit commuting Hamiltonians can be used to perform\ncomputational tasks which are intractable for classical computers under\nplausible assumptions. Our proof makes use of new postselection gadgets and Lie\ntheory.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 18:17:26 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Bouland", "Adam", ""], ["Man\u010dinska", "Laura", ""], ["Zhang", "Xue", ""]]}, {"id": "1602.04275", "submitter": "Yonghui Guan", "authors": "Yonghui Guan", "title": "Equations for secant varieties of Chow varieties", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Chow variety of polynomials that decompose as a product of linear forms\nhas been studied for more than 100 years. Finding equations in the ideal of\nsecant varieties of Chow varieties would enable one to measure the complexity\nthe permanent to prove Valiant's conjecture $\\mathbf{VP\\neq VNP}$. In this\narticle, I use the method of prolongation to obtain equations for secant\nvarieties of Chow varieties as $GL(V)$-modules.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 03:17:40 GMT"}, {"version": "v2", "created": "Sun, 24 Apr 2016 00:59:13 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Guan", "Yonghui", ""]]}, {"id": "1602.04353", "submitter": "Michael Pinsker", "authors": "Libor Barto, Michael Pinsker", "title": "The algebraic dichotomy conjecture for infinite domain Constraint\n  Satisfaction Problems", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that an $\\omega$-categorical core structure primitively positively\ninterprets all finite structures with parameters if and only if some stabilizer\nof its polymorphism clone has a homomorphism to the clone of projections, and\nthat this happens if and only if its polymorphism clone does not contain\noperations $\\alpha$, $\\beta$, $s$ satisfying the identity $\\alpha\ns(x,y,x,z,y,z) \\approx \\beta s(y,x,z,x,z,y)$.\n  This establishes an algebraic criterion equivalent to the conjectured\nborderline between P and NP-complete CSPs over reducts of finitely bounded\nhomogenous structures, and accomplishes one of the steps of a proposed strategy\nfor reducing the infinite domain CSP dichotomy conjecture to the finite case.\n  Our theorem is also of independent mathematical interest, characterizing a\ntopological property of any $\\omega$-categorical core structure (the existence\nof a continuous homomorphism of a stabilizer of its polymorphism clone to the\nprojections) in purely algebraic terms (the failure of an identity as above).\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 16:38:37 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Barto", "Libor", ""], ["Pinsker", "Michael", ""]]}, {"id": "1602.04560", "submitter": "Markus Lohrey", "authors": "Moses Ganardi, Danny Hucke, Daniel K\\\"onig, and Markus Lohrey", "title": "Circuit Evaluation for Finite Semirings", "comments": "Some proof details from the previous version are simplified in the\n  new version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of the circuit evaluation problem for finite\nsemirings is considered, where semirings are not assumed to have an additive or\nmultiplicative identity. The following dichotomy is shown: If a finite semiring\nis such that (i) the multiplicative semigroup is solvable and (ii) it does not\ncontain a subsemiring with an additive identity $0$ and a multiplicative\nidentity $1 \\neq 0$, then the circuit evaluation problem for the semiring is in\n$\\mathsf{DET} \\subseteq \\mathsf{NC}^2$. In all other cases, the circuit\nevaluation problem is $\\mathsf{P}$-complete.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 04:41:16 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2016 11:18:16 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Ganardi", "Moses", ""], ["Hucke", "Danny", ""], ["K\u00f6nig", "Daniel", ""], ["Lohrey", "Markus", ""]]}, {"id": "1602.04581", "submitter": "Yury Kartynnik", "authors": "Yury Kartynnik, Andrew Ryzhikov", "title": "On Minimum Maximal Distance-k Matchings", "comments": "15 pages, 4 figures", "journal-ref": "Discrete Mathematics & Theoretical Computer Science, Vol. 20 no.\n  1, Graph Theory (January 11, 2018) dmtcs:4199", "doi": "10.23638/DMTCS-20-1-3", "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of several problems connected with\nfinding a maximal distance-$k$ matching of minimum cardinality or minimum\nweight in a given graph. We introduce the class of $k$-equimatchable graphs\nwhich is an edge analogue of $k$-equipackable graphs. We prove that the\nrecognition of $k$-equimatchable graphs is co-NP-complete for any fixed $k \\ge\n2$. We provide a simple characterization for the class of strongly chordal\ngraphs with equal $k$-packing and $k$-domination numbers. We also prove that\nfor any fixed integer $\\ell \\ge 1$ the problem of finding a minimum weight\nmaximal distance-$2\\ell$ matching and the problem of finding a minimum weight\n$(2 \\ell - 1)$-independent dominating set cannot be approximated in polynomial\ntime in chordal graphs within a factor of $\\delta \\ln |V(G)|$ unless\n$\\mathrm{P} = \\mathrm{NP}$, where $\\delta$ is a fixed constant (thereby\nimproving the NP-hardness result of Chang for the independent domination case).\nFinally, we show the NP-hardness of the minimum maximal induced matching and\nindependent dominating set problems in large-girth planar graphs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 07:34:18 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 20:56:21 GMT"}, {"version": "v3", "created": "Fri, 7 Apr 2017 19:50:51 GMT"}, {"version": "v4", "created": "Fri, 10 Nov 2017 20:20:03 GMT"}, {"version": "v5", "created": "Tue, 9 Jan 2018 21:39:15 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kartynnik", "Yury", ""], ["Ryzhikov", "Andrew", ""]]}, {"id": "1602.04732", "submitter": "Abuzer Yakaryilmaz", "authors": "Alejandro D\\'iaz-Caro and Abuzer Yakary{\\i}lmaz", "title": "Affine computation and affine automaton", "comments": "23 pages. New results were added. Accepted to CSR2016!", "journal-ref": "LNCS 9691:146-160, 2016", "doi": "10.1007/978-3-319-34171-2_11", "report-no": null, "categories": "cs.FL cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a quantum-like classical computational model, called affine\ncomputation, as a generalization of probabilistic computation. After giving the\nbasics of affine computation, we define affine finite automata (AfA) and\ncompare it with quantum and probabilistic finite automata (QFA and PFA,\nrespectively) with respect to three basic language recognition modes. We show\nthat, in the cases of bounded and unbounded error, AfAs are more powerful than\nQFAs and PFAs, and, in the case of nondeterministic computation, AfAs are more\npowerful than PFAs but equivalent to QFAs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 16:41:54 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2016 14:38:47 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["D\u00edaz-Caro", "Alejandro", ""], ["Yakary\u0131lmaz", "Abuzer", ""]]}, {"id": "1602.04781", "submitter": "Mathias Hauptmann", "authors": "Mathias Hauptmann", "title": "On Alternation and the Union Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the assumption $P=\\Sigma_2^p$, we prove a new variant of the Union\nTheorem of McCreight and Meyer for the class $\\Sigma_2^p$. This yields a union\nfunction $F$ which is computable in time $F(n)^c$ for some constant $c$ and\nsatisfies $P=DTIME(F)=\\Sigma_2(F)=\\Sigma_2^p$ with respect to a subfamily\n$(\\tilde{S}_i)$ of $\\Sigma_2$-machines. We show that this subfamily does not\nchange the complexity classes $P$ and $\\Sigma_2^p$. Moreover, a padding\nconstruction shows that this also implies $DTIME(F^c)=\\Sigma_2(F^c)$. On the\nother hand, we prove a variant of Gupta's result who showed that\n$DTIME(t)\\subsetneq\\Sigma_2(t)$ for time-constructible functions $t(n)$. Our\nvariant of this result holds with respect to the subfamily $(\\tilde{S}_i)$ of\n$\\Sigma_2$-machines. We show that these two results contradict each other.\nHence the assumption $P=\\Sigma_2^p$ cannot hold.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 19:56:58 GMT"}, {"version": "v2", "created": "Thu, 17 Mar 2016 14:15:46 GMT"}, {"version": "v3", "created": "Fri, 3 Jun 2016 10:27:37 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Hauptmann", "Mathias", ""]]}, {"id": "1602.04934", "submitter": "Arne Meier", "authors": "Arne Meier and Sebastian Ordyniak and M. S. Ramanujan and Irena\n  Schindler", "title": "Strong Backdoors for Linear Temporal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we introduce the notion of strong backdoors into the\nfield of temporal logic for the CNF-fragment of linear temporal logic\nintroduced by Fisher. We study the parameterised complexity of the\nsatisfiability problem parameterised by the size of the backdoor. We\ndistinguish between backdoor detection and evaluation of backdoors into the\nfragments of horn and krom formulas. Here we classify the operator fragments of\nglobally-operators for past or future, and the combination of both. Detection\nis shown to be in FPT whereas the complexity of evaluation behaves different.\nWe show that for krom formulas the problem is paraNP-complete. For horn\nformulas the complexity is shown to be either fixed parameter tractable or\nparaNP-complete depending on the considered operator fragment.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 08:03:41 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Meier", "Arne", ""], ["Ordyniak", "Sebastian", ""], ["Ramanujan", "M. S.", ""], ["Schindler", "Irena", ""]]}, {"id": "1602.04955", "submitter": "Elnaser Abdelwahab", "authors": "Elnaserledinellah Mahmood Abdelwahab", "title": "Constructive Patterns of Logical Truth", "comments": "Originally received June 22 2016 - accepted June 30 2016 - published\n  July 1 2016 J.Acad.(N.Y.)6,2:99-199 (100 pages 80 figures) - Theoretical\n  Computer Science", "journal-ref": "J.Acad.(N.Y.)6,2:99-199 2016", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simplified linguistic relation between syntax and semantics as intrinsic\nproperty of classic Arabic motivates a dedicated look at P vs. NP in light of\nefforts and solutions presented by ancient Arab- and Muslim scholars to\nfacilitate logical- and mathematical deduction. In Islamic Jurisprudence (Fikh)\nit has recently been shown [Abdelwahab et al. 2014] that if a formal system\nexpressing Fikh is chosen in such a way that it is both, logically complete and\ndecidable, the question of a complete and consistent legislation is decidable.\nIf this formal Fikh-system is additionally chosen to be at least as expressive\nas propositional logic, the deduction of detailed sentences is efficient while\nthe deduction of general rules is NP-complete. Further investigation reveals\nthat ancient scholars adopted a very efficient approach for checking the\nvalidity of assertions with regard to both, language and logical argument which\nwas mainly characterized by the extensive use of syntactical patterns already\nexistent in input-variables. Accordingly, this paper introduces efficient\npattern-oriented procedures for 3-SAT as well as 2-approximation algorithms for\nMinFBDD. It opens up the possibility of constructing polynomial sized FBDDs for\nall Boolean functions expressed in a compact way. Eventually, an application of\nthis new 3-SAT-solver is shown to enable polynomial upper bounds of the number\nof nodes in FBDDs constructed for finite projective planes problems overhauling\nthe currently known exponential lower bounds.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 09:16:25 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 17:00:34 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Abdelwahab", "Elnaserledinellah Mahmood", ""]]}, {"id": "1602.05059", "submitter": "Dmitry Gavinsky", "authors": "Dmitry Gavinsky", "title": "Entangled simultaneity versus classical interactivity in communication\n  complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1999 Raz demonstrated a partial function that had an efficient quantum\ntwo-way communication protocol but no efficient classical two-way protocol and\nasked, whether there existed a function with an efficient quantum one-way\nprotocol, but still no efficient classical two-way protocol. In 2010 Klartag\nand Regev demonstrated such a function and asked, whether there existed a\nfunction with an efficient quantum simultaneous-messages protocol, but still no\nefficient classical two-way protocol.\n  In this work we answer the latter question affirmatively and present a\npartial function Shape, which can be computed by a protocol sending entangled\nsimultaneous messages of poly-logarithmic size, and whose classical two-way\ncomplexity is lower bounded by a polynomial.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 15:42:55 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 21:32:26 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Gavinsky", "Dmitry", ""]]}, {"id": "1602.05150", "submitter": "Tillmann Miltzow", "authors": "Tillmann Miltzow, Lothar Narins, Yoshio Okamoto, G\\\"unter Rote,\n  Antonis Thomas, Takeaki Uno", "title": "Approximation and Hardness for Token Swapping", "comments": "19 pages, 10 figures", "journal-ref": "Algorithms-ESA 2016, Proc. 24th Annual European Symposium on\n  Algorithms, Aarhus, 2016, Leibniz International Proceedings in Informatics\n  (LIPIcs), pp. 185:1-185:15", "doi": "10.4230/LIPIcs.ESA.2016.185", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G=(V,E)$ with $V=\\{1,\\ldots,n\\}$, we place on every vertex a\ntoken $T_1,\\ldots,T_n$. A swap is an exchange of tokens on adjacent vertices.\nWe consider the algorithmic question of finding a shortest sequence of swaps\nsuch that token $T_i$ is on vertex $i$. We are able to achieve essentially\nmatching upper and lower bounds, for exact algorithms and approximation\nalgorithms. For exact algorithms, we rule out any $2^{o(n)}$ algorithm under\nthe ETH. This is matched with a simple $2^{O(n\\log n)}$ algorithm based on a\nbreadth-first search in an auxiliary graph. We show one general\n$4$-approximation and show APX-hardness. Thus, there is a small constant\n$\\delta>1$ such that every polynomial time approximation algorithm has\napproximation factor at least $\\delta$. Our results also hold for a generalized\nversion, where tokens and vertices are colored. In this generalized version\neach token must go to a vertex with the same color.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 19:44:30 GMT"}, {"version": "v2", "created": "Sat, 2 Jul 2016 15:12:14 GMT"}, {"version": "v3", "created": "Tue, 2 Aug 2016 16:53:30 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Miltzow", "Tillmann", ""], ["Narins", "Lothar", ""], ["Okamoto", "Yoshio", ""], ["Rote", "G\u00fcnter", ""], ["Thomas", "Antonis", ""], ["Uno", "Takeaki", ""]]}, {"id": "1602.05152", "submitter": "Maria Ercsey-Ravasz", "authors": "R\\'obert Sumi, Melinda Varga, Zolt\\'an Toroczkai, M\\'aria\n  Ercsey-Ravasz", "title": "Order-to-chaos transition in the hardness of random Boolean\n  satisfiability problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transient chaos is an ubiquitous phenomenon characterizing the dynamics of\nphase space trajectories evolving towards a steady state attractor in physical\nsystems as diverse as fluids, chemical reactions and condensed matter systems.\nHere we show that transient chaos also appears in the dynamics of certain\nefficient algorithms searching for solutions of constraint satisfaction\nproblems that include scheduling, circuit design, routing, database problems or\neven Sudoku. In particular, we present a study of the emergence of hardness in\nBoolean satisfiability ($k$-SAT), a canonical class of constraint satisfaction\nproblems, by using an analog deterministic algorithm based on a system of\nordinary differential equations. Problem hardness is defined through the escape\nrate $\\kappa$, an invariant measure of transient chaos of the dynamical system\ncorresponding to the analog algorithm, and it expresses the rate at which the\ntrajectory approaches a solution.We show that for a given density of\nconstraints and fixed number of Boolean variables $N$, the hardness of formulas\nin random $k$-SAT ensembles has a wide variation, approximable by a lognormal\ndistribution. We also show that when increasing the density of constraints\n$\\alpha$, hardness appears through a second-order phase transition at\n$\\alpha_{\\chi}$ in the random 3-SAT ensemble where dynamical trajectories\nbecome transiently chaotic. A similar behavior is found in 4-SAT as well,\nhowever, such transition does not occur for 2-SAT. This behavior also implies a\nnovel type of transient chaos in which the escape rate has an\nexponential-algebraic dependence on the critical parameter $\\kappa \\sim\nN^{B|\\alpha - \\alpha_{\\chi}|^{1-\\gamma}}$ with $0< \\gamma < 1$. We demonstrate\nthat the transition is generated by the appearance of metastable basins in the\nsolution space as the density of constraints $\\alpha$ is increased.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 19:50:30 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2016 18:21:15 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Sumi", "R\u00f3bert", ""], ["Varga", "Melinda", ""], ["Toroczkai", "Zolt\u00e1n", ""], ["Ercsey-Ravasz", "M\u00e1ria", ""]]}, {"id": "1602.05161", "submitter": "Ran Raz", "authors": "Ran Raz", "title": "Fast Learning Requires Good Memory: A Time-Space Lower Bound for Parity\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that any algorithm for learning parities requires either a memory of\nquadratic size or an exponential number of samples. This proves a recent\nconjecture of Steinhardt, Valiant and Wager and shows that for some learning\nproblems a large storage space is crucial.\n  More formally, in the problem of parity learning, an unknown string $x \\in\n\\{0,1\\}^n$ was chosen uniformly at random. A learner tries to learn $x$ from a\nstream of samples $(a_1, b_1), (a_2, b_2) \\ldots$, where each~$a_t$ is\nuniformly distributed over $\\{0,1\\}^n$ and $b_t$ is the inner product of $a_t$\nand $x$, modulo~2. We show that any algorithm for parity learning, that uses\nless than $\\frac{n^2}{25}$ bits of memory, requires an exponential number of\nsamples.\n  Previously, there was no non-trivial lower bound on the number of samples\nneeded, for any learning problem, even if the allowed memory size is $O(n)$\n(where $n$ is the space needed to store one sample).\n  We also give an application of our result in the field of bounded-storage\ncryptography. We show an encryption scheme that requires a private key of\nlength $n$, as well as time complexity of $n$ per encryption/decription of each\nbit, and is provenly and unconditionally secure as long as the attacker uses\nless than $\\frac{n^2}{25}$ memory bits and the scheme is used at most an\nexponential number of times. Previous works on bounded-storage cryptography\nassumed that the memory size used by the attacker is at most linear in the time\nneeded for encryption/decription.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 20:13:55 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Raz", "Ran", ""]]}, {"id": "1602.05432", "submitter": "Abuzer Yakaryilmaz", "authors": "Marcos Villagra and Abuzer Yakary{\\i}lmaz", "title": "Language recognition power and succintness of affine automata", "comments": "19 pages. New results are added. A shorter version will appear in the\n  proceedings of the 15th International Conference on Unconventional\n  Computation and Natural Computation (UCNC 2016)", "journal-ref": "Natural Computing (2017)", "doi": "10.1007/s11047-017-9652-z", "report-no": null, "categories": "cs.FL cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study a non-linear generalization based on affine\ntransformations of probabilistic and quantum automata proposed recently by\nD\\'iaz-Caro and Yakary{\\i}lmaz \\cite{DCY16A} referred as affine automata.\nFirst, we present efficient simulations of probabilistic and quantum automata\nby means of affine automata which allows us to characterize the class of\nexclusive stochastic languages. Then, we initiate a study on the succintness of\naffine automata. In particular, we show that an infinite family of unary\nregular languages can be recognized by 2-state affine automata but the state\nnumbers of quantum and probabilistic automata cannot be bounded. Finally, we\npresent the characterization of all (regular) unary languages recognized by\ntwo-state affine automata.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 14:34:29 GMT"}, {"version": "v2", "created": "Mon, 2 May 2016 06:35:37 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Villagra", "Marcos", ""], ["Yakary\u0131lmaz", "Abuzer", ""]]}, {"id": "1602.05555", "submitter": "Jochen Burghardt", "authors": "Jochen Burghardt", "title": "Repetition-Free Derivability from a Regular Grammar is NP-Hard", "comments": "Technical report; 13 pages; 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the NP-hardness of the problem whether a given word can be derived\nfrom a given regular grammar without repeated occurrence of any nonterminal.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 20:05:27 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2016 13:01:02 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Burghardt", "Jochen", ""]]}, {"id": "1602.05622", "submitter": "Michael Horton", "authors": "Kevin Buchin, Maike Buchin, Joachim Gudmundsson, Michael Horton, Stef\n  Sijben", "title": "Compact Flow Diagrams for State Sequences", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": "10.1145/3150525", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of compactly representing a large number of state\nsequences, e.g., sequences of activities, as a flow diagram. We argue that the\nflow diagram representation gives an intuitive summary that allows the user to\ndetect patterns among large sets of state sequences. Simplified, our aim is to\ngenerate a small flow diagram that models the flow of states of all the state\nsequences given as input. For a small number of state sequences we present\nefficient algorithms to compute a minimal flow diagram. For a large number of\nstate sequences we show that it is unlikely that efficient algorithms exist.\nMore specifically, the problem is W[1]-hard if the number of state sequences is\ntaken as a parameter. We thus introduce several heuristics for this problem. We\nargue about the usefulness of the flow diagram by applying the algorithms to\ntwo problems in sports analysis. We evaluate the performance of our algorithms\non a football data set and generated data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 22:56:59 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Buchin", "Kevin", ""], ["Buchin", "Maike", ""], ["Gudmundsson", "Joachim", ""], ["Horton", "Michael", ""], ["Sijben", "Stef", ""]]}, {"id": "1602.05657", "submitter": "Shunichi Matsubara", "authors": "Shunichi Matsubara", "title": "The Computational Complexity of the Frobenius Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, as a main theorem, we prove that the decision version of the\nFrobenius problem is Sigma_2^P-complete under Karp reductions.Given a finite\nset A of coprime positive integers, we call the greatest integer that cannot be\nrepresented as a nonnegative integer combination of A the Frobenius number, and\nwe denote it as g(A). We call a problem of finding g(A) for a given A the\nFrobenius problem; moreover, we call a problem of determining whether g(A) >= k\nfor a given pair (A, k) the decision version of the Frobenius problem, where A\nis a finite set of coprime positive integers and k is a positive integer. For\nthe proof, we construct two Karp reductions. First, we reduce a 2-alternating\nversion of the 3-dimensional matching problem, which is known to be\nPi_2^P-complete, to a 2-alternating version of the integer knapsack problem.\nThen, we reduce the variant of the integer knapsack problem to the complement\nof the decision version of the Frobenius problem. As a corollary, we obtain the\nmain theorem.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 02:19:26 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 07:43:04 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Matsubara", "Shunichi", ""]]}, {"id": "1602.05819", "submitter": "Michael Pinsker", "authors": "Manuel Bodirsky, Barnaby Martin, Michael Pinsker, Andr\\'as Pongr\\'acz", "title": "Constraint satisfaction problems for reducts of homogeneous graphs", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For $n\\geq 3$, let $(H_n, E)$ denote the $n$-th Henson graph, i.e., the\nunique countable homogeneous graph with exactly those finite graphs as induced\nsubgraphs that do not embed the complete graph on $n$ vertices. We show that\nfor all structures $\\Gamma$ with domain $H_n$ whose relations are first-order\ndefinable in $(H_n,E)$ the constraint satisfaction problem for $\\Gamma$ is\neither in P or is NP-complete.\n  We moreover show a similar complexity dichotomy for all structures whose\nrelations are first-order definable in a homogeneous graph whose reflexive\nclosure is an equivalence relation.\n  Together with earlier results, in particular for the random graph, this\ncompletes the complexity classification of constraint satisfaction problems of\nstructures first-order definable in countably infinite homogeneous graphs: all\nsuch problems are either in P or NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 14:50:13 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 17:36:47 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 11:33:59 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Martin", "Barnaby", ""], ["Pinsker", "Michael", ""], ["Pongr\u00e1cz", "Andr\u00e1s", ""]]}, {"id": "1602.05837", "submitter": "Arturs Backurs", "authors": "Arturs Backurs and Nishanth Dikkala and Christos Tzamos", "title": "Tight Hardness Results for Maximum Weight Rectangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $n$ weighted points (positive or negative) in $d$ dimensions, what is\nthe axis-aligned box which maximizes the total weight of the points it\ncontains?\n  The best known algorithm for this problem is based on a reduction to a\nrelated problem, the Weighted Depth problem [T. M. Chan, FOCS'13], and runs in\ntime $O(n^d)$. It was conjectured [Barbay et al., CCCG'13] that this runtime is\ntight up to subpolynomial factors. We answer this conjecture affirmatively by\nproviding a matching conditional lower bound. We also provide conditional lower\nbounds for the special case when points are arranged in a grid (a well studied\nproblem known as Maximum Subarray problem) as well as for other related\nproblems.\n  All our lower bounds are based on assumptions that the best known algorithms\nfor the All-Pairs Shortest Paths problem (APSP) and for the Max-Weight k-Clique\nproblem in edge-weighted graphs are essentially optimal.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 15:24:22 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2016 00:12:38 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Backurs", "Arturs", ""], ["Dikkala", "Nishanth", ""], ["Tzamos", "Christos", ""]]}, {"id": "1602.05897", "submitter": "Amit Daniely", "authors": "Amit Daniely and Roy Frostig and Yoram Singer", "title": "Toward Deeper Understanding of Neural Networks: The Power of\n  Initialization and a Dual View on Expressivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general duality between neural networks and compositional\nkernels, striving towards a better understanding of deep learning. We show that\ninitial representations generated by common random initializations are\nsufficiently rich to express all functions in the dual kernel space. Hence,\nthough the training objective is hard to optimize in the worst case, the\ninitial weights form a good starting point for optimization. Our dual view also\nreveals a pragmatic and aesthetic perspective of neural networks and\nunderscores their expressive power.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 18:14:19 GMT"}, {"version": "v2", "created": "Fri, 19 May 2017 18:39:00 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Daniely", "Amit", ""], ["Frostig", "Roy", ""], ["Singer", "Yoram", ""]]}, {"id": "1602.06012", "submitter": "Kyle Burke", "authors": "Kyle Burke, Bob Hearn", "title": "PSPACE-Complete Two-Color Placement Games", "comments": "16 Pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that three placement games, Col, NoGo, and Fjords, are\nPSPACE-complete on planar graphs. The hardness of Col and Fjords is shown via a\nreduction from Bounded 2-Player Constraint Logic and NoGo is shown to be hard\ndirectly from Col.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 00:51:06 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Burke", "Kyle", ""], ["Hearn", "Bob", ""]]}, {"id": "1602.06052", "submitter": "Johannes Klaus Fichte", "authors": "Johannes K. Fichte and Arne Meier and Irina Schindler", "title": "Strong Backdoors for Default Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a notion of backdoors to Reiter's propositional\ndefault logic and study structural properties of it. Also we consider the\nproblems of backdoor detection (parameterised by the solution size) as well as\nbackdoor evaluation (parameterised by the size of the given backdoor), for\nvarious kinds of target classes (cnf, horn, krom, monotone, identity). We show\nthat backdoor detection is fixed-parameter tractable for the considered target\nclasses, and backdoor evaluation is either fixed-parameter tractable, in\npara-DP2 , or in para-NP, depending on the target class.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 06:42:48 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Meier", "Arne", ""], ["Schindler", "Irina", ""]]}, {"id": "1602.06073", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae, Harumichi Nishimura, Francois Le Gall", "title": "Modified group non-membership is in AWPP", "comments": "12 pages", "journal-ref": "Quantum Information and Computation 17, 0242 (2017)", "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the group non-membership problem is in QMA relative to any\ngroup oracle and in ${\\rm SPP}\\cap{\\rm BQP}$ relative to group oracles for\nsolvable groups. We consider a modified version of the group non-membership\nproblem where the order of the group is also given as an additional input. We\nshow that the problem is in AWPP relative to any group oracle. To show the\nresult, we use the idea of the postselected quantum computing.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 08:18:23 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Morimae", "Tomoyuki", ""], ["Nishimura", "Harumichi", ""], ["Gall", "Francois Le", ""]]}, {"id": "1602.06079", "submitter": "Sagnik Mukhopadhyay", "authors": "Arkadev Chattopadhyay, Sagnik Mukhopadhyay", "title": "Tribes Is Hard in the Message Passing Model", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.STACS.2015.224", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the point-to-point message passing model of communication in\nwhich there are $k$ processors with individual private inputs, each $n$-bit\nlong. Each processor is located at the node of an underlying undirected graph\nand has access to private random coins. An edge of the graph is a private\nchannel of communication between its endpoints. The processors have to compute\na given function of all their inputs by communicating along these channels.\nWhile this model has been widely used in distributed computing, strong lower\nbounds on the amount of communication needed to compute simple functions have\njust begun to appear. In this work, we prove a tight lower bound of\n$\\Omega(kn)$ on the communication needed for computing the Tribes function,\nwhen the underlying graph is a star of $k+1$ nodes that has $k$ leaves with\ninputs and a center with no input. Lower bound on this topology easily implies\ncomparable bounds for others. Our lower bounds are obtained by building upon\nthe recent information theoretic techniques of Braverman et.al (FOCS'13) and\ncombining it with the earlier work of Jayram, Kumar and Sivakumar (STOC'03).\nThis approach yields information complexity bounds that is of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 08:54:48 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Chattopadhyay", "Arkadev", ""], ["Mukhopadhyay", "Sagnik", ""]]}, {"id": "1602.06166", "submitter": "Benjamin Hellouin De Menibus", "authors": "Silv\\`ere Gangloff and Benjamin Hellouin de Menibus", "title": "Effect of quantified irreducibility on the computability of subshift\n  entropy", "comments": "28 pages, 5 figures, 1 table, submitted to Discrete & Continuous\n  Dynamical Systems. There was an error in the previous preprint version. This\n  version presents a more involved construction", "journal-ref": "Discrete and continuous dynamical systems 2018", "doi": null, "report-no": null, "categories": "math.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the difficulty of computing topological entropy of subshifts\nsubjected to mixing restrictions. This problem is well-studied for\nmultidimensional subshifts of finite type : there exists a threshold in the\nirreducibility rate where the difficulty jumps from computable to uncomputable,\nbut its location is an open problem. In this paper, we establish the location\nof this threshold for a more general class, subshifts with decidable languages,\nin any dimension.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 14:36:51 GMT"}, {"version": "v2", "created": "Sat, 18 Feb 2017 00:22:25 GMT"}, {"version": "v3", "created": "Sun, 25 Feb 2018 16:36:34 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Gangloff", "Silv\u00e8re", ""], ["de Menibus", "Benjamin Hellouin", ""]]}, {"id": "1602.06260", "submitter": "Carlo Comin", "authors": "Carlo Comin and Romeo Rizzi", "title": "Checking Dynamic Consistency of Conditional Hyper Temporal Networks via\n  Mean Payoff Games (Hardness and (pseudo) Singly-Exponential Time Algorithm)", "comments": "arXiv admin note: text overlap with arXiv:1505.00828", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce the \\emph{Conditional Hyper Temporal Network\n(CHyTN)} model, which is a natural extension and generalization of both the\n\\CSTN and the \\HTN model. Our contribution goes as follows. We show that\ndeciding whether a given \\CSTN or CHyTN is dynamically consistent is\n\\coNP-hard. Then, we offer a proof that deciding whether a given CHyTN is\ndynamically consistent is \\PSPACE-hard, provided that the input instances are\nallowed to include both multi-head and multi-tail hyperarcs. In light of this,\nwe continue our study by focusing on CHyTNs that allow only multi-head or only\nmulti-tail hyperarcs, and we offer the first deterministic (pseudo)\nsingly-exponential time algorithm for the problem of checking the\ndynamic-consistency of such CHyTNs, also producing a dynamic execution strategy\nwhenever the input CHyTN is dynamically consistent. Since \\CSTN{s} are a\nspecial case of CHyTNs, this provides as a byproduct the first\nsound-and-complete (pseudo) singly-exponential time algorithm for checking\ndynamic-consistency in CSTNs. The proposed algorithm is based on a novel\nconnection between CSTN{s}/CHyTN{s} and Mean Payoff Games. The presentation of\nthe connection between \\CSTN{s}/CHyTNs and \\MPG{s} is mediated by the \\HTN\nmodel. In order to analyze the algorithm, we introduce a refined notion of\ndynamic-consistency, named $\\epsilon$-dynamic-consistency, and present a sharp\nlower bounding analysis on the critical value of the reaction time\n$\\hat{\\varepsilon}$ where a \\CSTN/CHyTN transits from being, to not being,\ndynamically consistent. The proof technique introduced in this analysis of\n$\\hat{\\varepsilon}$ is applicable more generally when dealing with linear\ndifference constraints which include strict inequalities.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 19:42:16 GMT"}, {"version": "v2", "created": "Sat, 15 Apr 2017 19:54:54 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Comin", "Carlo", ""], ["Rizzi", "Romeo", ""]]}, {"id": "1602.06323", "submitter": "Stanislav Zivny", "authors": "Peter Fulla, Stanislav Zivny", "title": "On Planar Valued CSPs", "comments": "A full version of an MFCS'16 paper. Improved presentation compared to\n  v1 and v2", "journal-ref": "Journal of Computer and System Sciences 87 104-118 (2017)", "doi": "10.1016/j.jcss.2017.03.005", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of planar valued constraint\nsatisfaction problems (VCSPs), which require the incidence graph of the\ninstance be planar. First, we show that intractable Boolean VCSPs have to be\nself-complementary to be tractable in the planar setting, thus extending a\ncorresponding result of Dvorak and Kupec [ICALP'15] from CSPs to VCSPs. Second,\nwe give a complete complexity classification of conservative planar VCSPs on\narbitrary finite domains. In this case planarity does not lead to any new\ntractable cases and thus our classification is a sharpening of the\nclassification of conservative VCSPs by Kolmogorov and Zivny [JACM'13].\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 21:42:39 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 17:43:31 GMT"}, {"version": "v3", "created": "Sat, 11 Mar 2017 10:03:27 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Fulla", "Peter", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1602.06395", "submitter": "George Barmpalias Dr", "authors": "George Barmpalias and Andrew Lewis-Pye", "title": "Computing halting probabilities from other halting probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The halting probability of a Turing machine is the probability that the\nmachine will halt if it starts with a random stream written on its one-way\ninput tape. When the machine is universal, this probability is referred to as\nChaitin's omega number, and is the most well known example of a real which is\nrandom in the sense of Martin-L\\\"{o}f. Although omega numbers depend on the\nunderlying universal Turing machine, they are robust in the sense that they all\nhave the same Turing degree, namely the degree of the halting problem. In this\npaper we give precise bounds on the redundancy growth rate that is generally\nrequired for the computation of an omega number from another omega number. We\nshow that for each $\\epsilon >1$, any pair of omega numbers compute each other\nwith redundancy $\\epsilon \\log n$. On the other hand, this is not true for\n$\\epsilon=1$. In fact, we show that for each omega number there exists another\nomega number which is not computable from the first one with redundancy $\\log\nn$. This latter result improves an older result of Frank Stephan.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 10:33:47 GMT"}, {"version": "v2", "created": "Sun, 2 Oct 2016 09:12:23 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Barmpalias", "George", ""], ["Lewis-Pye", "Andrew", ""]]}, {"id": "1602.06627", "submitter": "Chengyu Lin", "authors": "Chengyu Lin, Shengyu Zhang", "title": "Sensitivity Conjecture and Log-rank Conjecture for functions with small\n  alternating numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sensitivity Conjecture and the Log-rank Conjecture are among the most\nimportant and challenging problems in concrete complexity. Incidentally, the\nSensitivity Conjecture is known to hold for monotone functions, and so is the\nLog-rank Conjecture for $f(x \\wedge y)$ and $f(x\\oplus y)$ with monotone\nfunctions $f$, where $\\wedge$ and $\\oplus$ are bit-wise AND and XOR,\nrespectively. In this paper, we extend these results to functions $f$ which\nalternate values for a relatively small number of times on any monotone path\nfrom $0^n$ to $1^n$. These deepen our understandings of the two conjectures,\nand contribute to the recent line of research on functions with small\nalternating numbers.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 02:14:26 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 06:12:25 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Lin", "Chengyu", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1602.06867", "submitter": "Carlos Barron-Romero Prof.", "authors": "Carlos Barr\\'on-Romero", "title": "Lower bound for the Complexity of the Boolean Satisfiability Problem", "comments": "arXiv admin note: text overlap with arXiv:1510.02682", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper depicts algorithms for solving the decision Boolean Satisfiability\nProblem. An extreme problem is formulated to analyze the complexity of\nalgorithms and the complexity for solving it. A novel and easy reformulation as\na lottery for an extreme case is presented to determine a stable complexity\naround $2^n$. The reformulation point out that the decision Boolean\nSatisfiability Problem can only be solved in exponential time. This implies\nthere is not an efficient algorithm for the NP Class.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 20:11:54 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2016 06:23:45 GMT"}, {"version": "v3", "created": "Sat, 2 Apr 2016 15:48:04 GMT"}, {"version": "v4", "created": "Thu, 14 Apr 2016 02:56:37 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Barr\u00f3n-Romero", "Carlos", ""]]}, {"id": "1602.07113", "submitter": "George Barmpalias Dr", "authors": "George Barmpalias and Andrew Lewis-Pye and Jason Teutsch", "title": "Lower bounds on the redundancy in computations from random oracles via\n  betting strategies with restricted wagers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ku\\v{c}era-G\\'acs theorem is a landmark result in algorithmic randomness\nasserting that every real is computable from a Martin-L\\\"of random real. If the\ncomputation of the first $n$ bits of a sequence requires $n+h(n)$ bits of the\nrandom oracle, then $h$ is the redundancy of the computation. Ku\\v{c}era\nimplicitly achieved redundancy $n\\log n$ while G\\'acs used a more elaborate\ncoding procedure which achieves redundancy $\\sqrt{n}\\log n$. A similar upper\nbound is implicit in the later proof by Merkle and Mihailovi\\'c. In this paper\nwe obtain strict optimal lower bounds on the redundancy in computations from\nMartin-L\\\"of random oracles. We show that any nondecreasing computable function\n$g$ such that $\\sum_n 2^{-g(n)}=\\infty$ is not a general upper bound on the\nredundancy in computations from Martin-L\\\"of random oracles. In fact, there\nexists a real $X$ such that the redundancy $g$ of any computation of $X$ from a\nMartin-L\\\"of random oracle satisfies $\\sum_n 2^{-g(n)}<\\infty$. Moreover, the\nclass of such reals is comeager and includes a $\\Delta^0_2$ real as well as all\nweakly 2-generic reals. This excludes many slow growing functions such as $\\log\nn$ from bounding the redundancy in computations from random oracles for a large\nclass of reals. On the other hand it was recently shown that if $\\sum_n\n2^{-g(n)}<\\infty$ then $g$ is a general upper bound for the redundancy in\ncomputations of any real from some Martin-L\\\"of random oracle. Our results are\nobtained as an application of a theory of effective betting strategies with\nrestricted wagers which we develop.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 10:51:30 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2016 03:56:08 GMT"}, {"version": "v3", "created": "Thu, 22 Sep 2016 01:58:16 GMT"}, {"version": "v4", "created": "Sun, 11 Jun 2017 05:16:43 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Barmpalias", "George", ""], ["Lewis-Pye", "Andrew", ""], ["Teutsch", "Jason", ""]]}, {"id": "1602.07210", "submitter": "Nils Kriege", "authors": "Andre Droschinsky, Nils M. Kriege, Petra Mutzel", "title": "Faster Algorithms for the Maximum Common Subtree Isomorphism Problem", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.MFCS.2016.33", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum common subtree isomorphism problem asks for the largest possible\nisomorphism between subtrees of two given input trees. This problem is a\nnatural restriction of the maximum common subgraph problem, which is ${\\sf\nNP}$-hard in general graphs. Confining to trees renders polynomial time\nalgorithms possible and is of fundamental importance for approaches on more\ngeneral graph classes. Various variants of this problem in trees have been\nintensively studied. We consider the general case, where trees are neither\nrooted nor ordered and the isomorphism is maximum w.r.t. a weight function on\nthe mapped vertices and edges. For trees of order $n$ and maximum degree\n$\\Delta$ our algorithm achieves a running time of $\\mathcal{O}(n^2\\Delta)$ by\nexploiting the structure of the matching instances arising as subproblems. Thus\nour algorithm outperforms the best previously known approaches. No faster\nalgorithm is possible for trees of bounded degree and for trees of unbounded\ndegree we show that a further reduction of the running time would directly\nimprove the best known approach to the assignment problem. Combining a\npolynomial-delay algorithm for the enumeration of all maximum common subtree\nisomorphisms with central ideas of our new algorithm leads to an improvement of\nits running time from $\\mathcal{O}(n^6+Tn^2)$ to $\\mathcal{O}(n^3+Tn\\Delta)$,\nwhere $n$ is the order of the larger tree, $T$ is the number of different\nsolutions, and $\\Delta$ is the minimum of the maximum degrees of the input\ntrees. Our theoretical results are supplemented by an experimental evaluation\non synthetic and real-world instances.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 15:48:25 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 15:32:22 GMT"}, {"version": "v3", "created": "Mon, 13 Jun 2016 15:01:42 GMT"}, {"version": "v4", "created": "Fri, 12 Aug 2016 15:08:46 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Droschinsky", "Andre", ""], ["Kriege", "Nils M.", ""], ["Mutzel", "Petra", ""]]}, {"id": "1602.07407", "submitter": "Fatemeh Keshavarz-Kohjerdi", "authors": "Fatemeh Keshavarz-Kohjerdi and Alireza Bagheri", "title": "Hamiltonian Paths in C-shaped Grid Graphs", "comments": "28 pages, 31 figures, and 20 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Hamiltonian path problem in C-shaped grid graphs, and present\nthe necessary and sufficient conditions for the existence of a Hamiltonian path\nbetween two given vertices in these graphs. We also give a linear-time\nalgorithm for finding a Hamiltonian path between two given vertices of a\nC-shaped grid graph, if it exists.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 06:05:53 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Keshavarz-Kohjerdi", "Fatemeh", ""], ["Bagheri", "Alireza", ""]]}, {"id": "1602.07616", "submitter": "Anindya De", "authors": "Anindya De and Michael Saks and Sijian Tang", "title": "Noisy population recovery in polynomial time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the noisy population recovery problem of Dvir et al., the goal is to learn\nan unknown distribution $f$ on binary strings of length $n$ from noisy samples.\nFor some parameter $\\mu \\in [0,1]$, a noisy sample is generated by flipping\neach coordinate of a sample from $f$ independently with probability\n$(1-\\mu)/2$. We assume an upper bound $k$ on the size of the support of the\ndistribution, and the goal is to estimate the probability of any string to\nwithin some given error $\\varepsilon$. It is known that the algorithmic\ncomplexity and sample complexity of this problem are polynomially related to\neach other.\n  We show that for $\\mu > 0$, the sample complexity (and hence the algorithmic\ncomplexity) is bounded by a polynomial in $k$, $n$ and $1/\\varepsilon$\nimproving upon the previous best result of $\\mathsf{poly}(k^{\\log\\log\nk},n,1/\\varepsilon)$ due to Lovett and Zhang.\n  Our proof combines ideas from Lovett and Zhang with a \\emph{noise attenuated}\nversion of M\\\"{o}bius inversion. In turn, the latter crucially uses the\nconstruction of \\emph{robust local inverse} due to Moitra and Saks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 17:46:30 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["De", "Anindya", ""], ["Saks", "Michael", ""], ["Tang", "Sijian", ""]]}, {"id": "1602.07716", "submitter": "Franklin Marquezino", "authors": "S. A. Grillo, F. L. Marquezino", "title": "Quantum Query as a State Decomposition", "comments": "30 pages, 2 figures. In this version, we changed title, corrected\n  typos, and added a new lower-bound result (Sec. 6)", "journal-ref": "Theoretical Computer Science (2018)", "doi": "10.1016/j.tcs.2018.03.017", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quantum Query Model is a framework that allows us to express most known\nquantum algorithms. Algorithms represented by this model consist on a set of\nunitary operators acting over a finite Hilbert space, and a final measurement\nstep consisting on a set of projectors. In this work, we prove that the\napplication of these unitary operators before the measurement step is\nequivalent to decomposing a unit vector into a sum of vectors and then\ninverting some of their relative phases. We also prove that the vectors of that\nsum must fulfill a list of properties and we call such vectors a Block Set. If\nwe define the measurement step for the Block Set Formulation similarly to the\nQuantum Query Model, then we prove that both formulations give the same Gram\nmatrix of output states, although the Block Set Formulation allows a much more\nexplicit form. Therefore, the Block Set reformulation of the Quantum Query\nModel gives us an alternative interpretation on how quantum algorithms works.\nFinally, we apply our approach to the analysis and complexity of quantum exact\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 21:22:21 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 18:36:04 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Grillo", "S. A.", ""], ["Marquezino", "F. L.", ""]]}, {"id": "1602.07796", "submitter": "Xu Jin", "authors": "Jin Xu", "title": "Probe Machine", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel computing model, called \\emph{Probe Machine}, is proposed in this\npaper. Different from Turing Machine, Probe Machine is a fully-parallel\ncomputing model in the sense that it can simultaneously process multiple pairs\nof data, rather than sequentially process every pair of linearly-adjacent data.\nIn this paper, we establish the mathematical model of Probe Machine as a\n9-tuple consisting of data library, probe library, data controller, probe\ncontroller, probe operation, computing platform, detector, true solution\nstorage, and residue collector. We analyze the computation capability of the\nProbe Machine model, and in particular we show that Turing Machine is a special\ncase of Probe Machine. We revisit two NP-complete problems---i.e., the Graph\nColoring and Hamilton Cycle problems, and devise two algorithms on basis of the\nestablished Probe Machine model, which can enumerate all solutions to each of\nthese problems by only one probe operation. Furthermore, we show that Probe\nMachine can be implemented by leveraging the nano-DNA probe technologies. The\ncomputational power of an electronic computer based on Turing Machine is known\nfar more than that of the human brain. A question naturally arises: will a\nfuture computer based on Probe Machine outperform the human brain in more ways\nbeyond the computational power?\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 03:08:21 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2016 05:32:05 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Xu", "Jin", ""]]}, {"id": "1602.07827", "submitter": "Mayssam Mohammadi Nevisi", "authors": "Pavol Hell and Mayssam Mohammadi Nevisi", "title": "Minimum Cost Homomorphisms with Constrained Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimum cost homomorphism problems can be viewed as a generalization of list\nhomomorphism problems. They also extend two well-known graph colouring\nproblems: the minimum colour sum problem and the optimum cost chromatic\npartition problem. In both of these problems, the cost function meets an\nadditional constraint: the cost of using a specific colour is the same for\nevery vertex of the input graph. We study minimum cost homomorphism problems\nwith cost functions constrained to have this property. Clearly, when the\nstandard minimum cost homomorphism problem is polynomial, then the problem with\nconstrained costs is also polynomial. We expect that the same may hold for the\ncases when the standard minimum cost homomorphism problem is NP-complete. We\nprove that this is the case for trees $H$: we obtain a dichotomy of minimum\nconstrained cost homomorphism problems which coincides with the dichotomy of\nstandard minimum cost homomorphism problems. For general graphs $H$, we prove a\npartial dichotomy: the problem is polynomial if $H$ is a proper interval graph\nand NP-complete when $H$ is not chordal bipartite.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 07:34:37 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2016 08:54:02 GMT"}, {"version": "v3", "created": "Mon, 22 Aug 2016 06:47:14 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Hell", "Pavol", ""], ["Nevisi", "Mayssam Mohammadi", ""]]}, {"id": "1602.07876", "submitter": "Jan Arne Telle", "authors": "Serge Gaspers, Christos Papadimitriou, Sigve Hortemo Saether, Jan Arne\n  Telle", "title": "On Satisfiability Problems with a Linear Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was recently shown \\cite{STV} that satisfiability is polynomially solvable\nwhen the incidence graph is an interval bipartite graph (an interval graph\nturned into a bipartite graph by omitting all edges within each partite set).\nHere we relax this condition in several directions: First, we show that it\nholds for $k$-interval bigraphs, bipartite graphs which can be converted to\ninterval bipartite graphs by adding to each node of one side at most $k$ edges;\nthe same result holds for the counting and the weighted maximization version of\nsatisfiability. Second, given two linear orders, one for the variables and one\nfor the clauses, we show how to find, in polynomial time, the smallest $k$ such\nthat there is a $k$-interval bigraph compatible with these two orders. On the\nnegative side we prove that, barring complexity collapses, no such extensions\nare possible for CSPs more general than satisfiability. We also show\nNP-hardness of recognizing 1-interval bigraphs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 10:40:28 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Gaspers", "Serge", ""], ["Papadimitriou", "Christos", ""], ["Saether", "Sigve Hortemo", ""], ["Telle", "Jan Arne", ""]]}, {"id": "1602.07967", "submitter": "Abuzer Yakaryilmaz", "authors": "Aleksandrs Belovs and Juan Andres Montoya and Abuzer Yakary{\\i}lmaz", "title": "Can one quantum bit separate any pair of words with zero-error?", "comments": "17 pages!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the minimum number of states required by a finite automaton to\nseparate a given pair of different words is an important problem. In this\npaper, we consider this problem for quantum automata (QFAs). We show that\n2-state QFAs can separate any pair of words in nondeterministic acceptance mode\nand conjecture that they can separate any pair also with zero-error. Then, we\nfocus on (a more general problem) separating a pair of two disjoint finite set\nof words. We show that QFAs can separate them efficiently in nondeterministic\nacceptance mode, i.e. the number of states is two to the power of the size of\nthe small set. Additionally, we examine affine finite automata (AfAs) and show\nthat two states are enough to separate any pair with zero-error. Moreover, AfAs\ncan separate any pair of disjoint finite sets of words with one-sided bounded\nerror efficiently like QFAs in nondeterministic mode.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 15:38:12 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Belovs", "Aleksandrs", ""], ["Montoya", "Juan Andres", ""], ["Yakary\u0131lmaz", "Abuzer", ""]]}, {"id": "1602.08034", "submitter": "Hiroki Morizumi", "authors": "Hiroki Morizumi", "title": "Zero-Suppressed Computation: A New Computation Inspired by ZDDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-suppressed binary decision diagrams (ZDDs) are a data structure\nrepresenting Boolean functions, and one of the most successful variants of\nbinary decision diagrams (BDDs). On the other hand, BDDs are also called\nbranching programs in computational complexity theory, and have been studied as\na computation model. In this paper, we consider ZDDs from the viewpoint of\ncomputational complexity theory. Our main proposal of this paper is that we\nregard the basic idea of ZDDs as a new computation, which we call\nzero-suppressed computation. We consider the zero-suppressed version of two\nclassical computation models, decision trees and branching programs, and show\nsome results. Although this paper is mainly written from the viewpoint of\ncomputational complexity theory, the concept of zero-suppressed computation can\nbe widely applied to various areas.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 18:58:28 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Morizumi", "Hiroki", ""]]}, {"id": "1602.08166", "submitter": "Yi-Jun Chang", "authors": "Yi-Jun Chang and Tsvi Kopelowitz and Seth Pettie", "title": "An Exponential Separation Between Randomized and Deterministic\n  Complexity in the LOCAL Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past 30 years numerous algorithms have been designed for symmetry\nbreaking problems in the LOCAL model, such as maximal matching, MIS, vertex\ncoloring, and edge-coloring. For most problems the best randomized algorithm is\nat least exponentially faster than the best deterministic algorithm. In this\npaper we prove that these exponential gaps are necessary and establish\nconnections between the deterministic and randomized complexities in the LOCAL\nmodel. Each result has a very compelling take-away message:\n  1. Fast $\\Delta$-coloring of trees requires random bits: Building on the\nrecent lower bounds of Brandt et al., we prove that the randomized complexity\nof $\\Delta$-coloring a tree with maximum degree $\\Delta\\ge 55$ is\n$\\Theta(\\log_\\Delta\\log n)$, whereas its deterministic complexity is\n$\\Theta(\\log_\\Delta n)$ for any $\\Delta\\ge 3$. This also establishes a large\nseparation between the deterministic complexity of $\\Delta$-coloring and\n$(\\Delta+1)$-coloring trees.\n  2. Randomized lower bounds imply deterministic lower bounds: We prove that\nany deterministic algorithm for a natural class of problems that runs in\n$O(1)+o(\\log_\\Delta n)$ rounds can be transformed to run in\n$O(\\log^*n-\\log^*\\Delta+1)$ rounds. If the transformed algorithm violates a\nlower bound (even allowing randomization), then one can conclude that the\nproblem requires $\\Omega(\\log_\\Delta n)$ time deterministically.\n  3. Deterministic lower bounds imply randomized lower bounds: We prove that\nthe randomized complexity of any natural problem on instances of size $n$ is at\nleast its deterministic complexity on instances of size $\\sqrt{\\log n}$. This\nshows that a deterministic $\\Omega(\\log_\\Delta n)$ lower bound for any problem\nimplies a randomized $\\Omega(\\log_\\Delta\\log n)$ lower bound. It also\nillustrates that the graph shattering technique is absolutely essential to the\nLOCAL model.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 01:31:56 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 00:11:49 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Chang", "Yi-Jun", ""], ["Kopelowitz", "Tsvi", ""], ["Pettie", "Seth", ""]]}, {"id": "1602.08369", "submitter": "Mikael Gast", "authors": "Mikael Gast, Mathias Hauptmann and Marek Karpinski", "title": "Approximation Complexity of Max-Cut on Power Law Graphs", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the MAX-CUT problem on power law graphs (PLGs) with\npower law exponent $\\beta$. We prove some new approximability results on that\nproblem. In particular we show that there exist polynomial time approximation\nschemes (PTAS) for MAX-CUT on PLGs for the power law exponent $\\beta$ in the\ninterval $(0,2)$. For $\\beta>2$ we show that for some $\\epsilon>0$, MAX-CUT is\nNP-hard to approximate within approximation ratio $1+\\epsilon$, ruling out the\nexistence of a PTAS in this case. Moreover we give an approximation algorithm\nwith improved constant approximation ratio for the case of $\\beta>2$.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 15:32:29 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Gast", "Mikael", ""], ["Hauptmann", "Mathias", ""], ["Karpinski", "Marek", ""]]}, {"id": "1602.08620", "submitter": "Daniel Fremont", "authors": "Nathan Mull, Daniel J. Fremont, Sanjit A. Seshia", "title": "On the Hardness of SAT with Community Structure", "comments": "23 pages. Full version of a SAT 2016 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent attempts to explain the effectiveness of Boolean satisfiability (SAT)\nsolvers based on conflict-driven clause learning (CDCL) on large industrial\nbenchmarks have focused on the concept of community structure. Specifically,\nindustrial benchmarks have been empirically found to have good community\nstructure, and experiments seem to show a correlation between such structure\nand the efficiency of CDCL. However, in this paper we establish hardness\nresults suggesting that community structure is not sufficient to explain the\nsuccess of CDCL in practice. First, we formally characterize a property shared\nby a wide class of metrics capturing community structure, including\n\"modularity\". Next, we show that the SAT instances with good community\nstructure according to any metric with this property are still NP-hard.\nFinally, we study a class of random instances generated from the\n\"pseudo-industrial\" community attachment model of Gir\\'aldez-Cru and Levy. We\nprove that, with high probability, instances from this model that have\nrelatively few communities but are still highly modular require exponentially\nlong resolution proofs and so are hard for CDCL. We also present experimental\nevidence that our result continues to hold for instances with many more\ncommunities. This indicates that actual industrial instances easily solved by\nCDCL may have some other relevant structure not captured by the community\nattachment model.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2016 17:48:21 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2016 00:15:00 GMT"}, {"version": "v3", "created": "Mon, 30 May 2016 16:47:37 GMT"}, {"version": "v4", "created": "Sat, 13 Aug 2016 17:22:18 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Mull", "Nathan", ""], ["Fremont", "Daniel J.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1602.08648", "submitter": "Y. William Yu", "authors": "Y. William Yu", "title": "Approximation hardness of Shortest Common Superstring variants", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shortest common superstring (SCS) problem has been studied at great\nlength because of its connections to the de novo assembly problem in\ncomputational genomics. The base problem is APX-complete, but several\ngeneralizations of the problem have also been studied. In particular, previous\nresults include that SCS with Negative strings (SCSN) is in Log-APX (though\nthere is no known hardness result) and SCS with Wildcards (SCSW) is\nPoly-APX-hard. Here, we prove two new hardness results: (1) SCSN is\nLog-APX-hard (and therefore Log-APX-complete) by a reduction from Minimum Set\nCover and (2) SCS with Negative strings and Wildcards (SCSNW) is NPOPB-hard by\na reduction from Minimum Ones 3SAT.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2016 23:21:55 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Yu", "Y. William", ""]]}, {"id": "1602.08656", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae", "title": "Quantum Arthur-Merlin with single-qubit measurements", "comments": "11 pages, 1 figure", "journal-ref": "Phys. Rev. A 93, 062333 (2016)", "doi": "10.1103/PhysRevA.93.062333", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the class QAM does not change even if the verifier's ability is\nrestricted to only single-qubit measurements. To show the result, we use the\nidea of the measurement-based quantum computing: the verifier, who can do only\nsingle-qubit measurements, can test the graph state sent from the prover and\nuse it for his measurement-based quantum computing. We also introduce a new\nQMA-complete problem related to the stabilizer test.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 01:36:31 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Morimae", "Tomoyuki", ""]]}, {"id": "1602.09022", "submitter": "Hubie Chen", "authors": "Hubie Chen and Moritz M\\\"uller", "title": "The parameterized space complexity of embedding along a path", "comments": "Final publication in Theory of Computing Systems. The final\n  publication is available at Springer via\n  http://dx.doi.org/10.1007/s00224-016-9728-7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The embedding problem is to decide, given an ordered pair of structures,\nwhether or not there is an injective homomorphism from the first structure to\nthe second. We study this problem using an established perspective in\nparameterized complexity theory: the universe size of the first structure is\ntaken to be the parameter, and we define the embedding problem relative to a\nclass ${\\cl A}$ of structures to be the restricted version of the general\nproblem where the first structure must come from ${\\cl A}$. We initiate a\nsystematic complexity study of this problem family, by considering classes\nwhose structures are what we call rooted path structures; these structures have\npaths as Gaifman graphs. Our main theorem is a dichotomy theorem on classes of\nrooted path structures.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 16:12:03 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2017 03:05:31 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Chen", "Hubie", ""], ["M\u00fcller", "Moritz", ""]]}]