[{"id": "2105.00287", "submitter": "Andr\\'es Herrera-Poyatos", "authors": "Andreas Galanis, Leslie Ann Goldberg and Andr\\'es Herrera-Poyatos", "title": "The complexity of approximating the complex-valued Ising model on\n  bounded degree graphs", "comments": "49 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of approximating the partition function\n$Z_{\\mathrm{Ising}}(G; \\beta)$ of the Ising model in terms of the relation\nbetween the edge interaction $\\beta$ and a parameter $\\Delta$ which is an upper\nbound on the maximum degree of the input graph $G$. Following recent trends in\nboth statistical physics and algorithmic research, we allow the edge\ninteraction $\\beta$ to be any complex number. Many recent partition function\nresults focus on complex parameters, both because of physical relevance and\nbecause of the key role of the complex case in delineating the\ntractability/intractability phase transition of the approximation problem.\n  In this work we establish both new tractability results and new\nintractability results. Our tractability results show that\n$Z_{\\mathrm{Ising}}(-; \\beta)$ has an FPTAS when $\\lvert \\beta - 1 \\rvert /\n\\lvert \\beta + 1 \\rvert < \\tan(\\pi / (4 \\Delta - 4))$. The core of the proof is\nshowing that there are no inputs~$G$ that make the partition function $0$ when\n$\\beta$ is in this range. Our result significantly extends the known zero-free\nregion of the Ising model (and hence the known approximation results).\n  Our intractability results show that it is $\\mathrm{\\#P}$-hard to\nmultiplicatively approximate the norm and to additively approximate the\nargument of $Z_{\\mathrm{Ising}}(-; \\beta)$ when $\\beta \\in \\mathbb{C}$ is an\nalgebraic number such that $\\beta \\not \\in \\mathbb{R} \\cup \\{i, -i\\}$ and\n$\\lvert \\beta - 1\\rvert / \\lvert \\beta + 1 \\rvert > 1 / \\sqrt{\\Delta - 1}$.\nThese are the first results to show intractability of approximating\n$Z_{\\mathrm{Ising}}(-, \\beta)$ on bounded degree graphs with complex $\\beta$.\nMoreover, we demonstrate situations in which zeros of the partition function\nimply hardness of approximation in the Ising model.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 15:38:13 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 13:16:01 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Galanis", "Andreas", ""], ["Goldberg", "Leslie Ann", ""], ["Herrera-Poyatos", "Andr\u00e9s", ""]]}, {"id": "2105.00299", "submitter": "Jesse Racicot", "authors": "Hovhannes Harutyunyan, Denis Pankratov, Jesse Racicot", "title": "Online Domination: The Value of Getting to Know All your Neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the dominating set problem in an online setting. An algorithm is\nrequired to guarantee competitiveness against an adversary that reveals the\ninput graph one node at a time. When a node is revealed, the algorithm learns\nabout the entire neighborhood of the node (including those nodes that have not\nyet been revealed). Furthermore, the adversary is required to keep the revealed\nportion of the graph connected at all times. We present an algorithm that\nachieves 2-competitiveness on trees and prove that this competitive ratio\ncannot be improved by any other algorithm. We also present algorithms that\nachieve 2.5-competitiveness on cactus graphs, $(t-1)$-competitiveness on\n$K_{1,t}$-free graphs, and $\\Theta(\\sqrt{\\Delta})$ for maximum degree $\\Delta$\ngraphs. We show that all of those competitive ratios are tight. Then, we study\nseveral more general classes of graphs, such as threshold, bipartite planar,\nand series-parallel graphs, and show that they do not admit competitive\nalgorithms (that is, when competitive ratio is independent of the input size).\nPreviously, the dominating set problem was considered in a slightly different\ninput model, where a vertex is revealed alongside its restricted neighborhood:\nthose neighbors that are among already revealed vertices. Thus, conceptually,\nour results quantify the value of knowing the entire neighborhood at the time a\nvertex is revealed as compared to the restricted neighborhood. For instance, it\nwas known in the restricted neighborhood model that 3-competitiveness is\noptimal for trees, whereas knowing the neighbors allows us to improve it to\n2-competitiveness.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 16:41:43 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Harutyunyan", "Hovhannes", ""], ["Pankratov", "Denis", ""], ["Racicot", "Jesse", ""]]}, {"id": "2105.00443", "submitter": "Ilkka T\\\"orm\\\"a", "authors": "Ilkka T\\\"orm\\\"a", "title": "Fixed Point Constructions in Tilings and Cellular Automata", "comments": "15 pages. To be presented at AUTOMATA 2021 as an invited talk", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.CC math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The fixed point construction is a method for designing tile sets and cellular\nautomata with highly nontrivial dynamical and computational properties. It\nproduces an infinite hierarchy of systems where each layer simulates the next\none. The simulations are implemented entirely by computations of Turing\nmachines embedded in the tilings or spacetime diagrams. We present an overview\nof the construction and list its applications in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 11:15:50 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["T\u00f6rm\u00e4", "Ilkka", ""]]}, {"id": "2105.00603", "submitter": "Atsuya Hasegawa", "authors": "Atsuya Hasegawa and Fran\\c{c}ois Le Gall", "title": "Quantum Advantage with Shallow Circuits under Arbitrary Corruption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works by Bravyi, Gosset and K\\\"onig (Science 2018), Bene Watts et al.\n(STOC 2019), Coudron, Stark and Vidick (QIP 2019) and Le Gall (CCC 2019) have\nshown unconditional separations between the computational powers of shallow\n(i.e., small-depth) quantum and classical circuits: quantum circuits can solve\nin constant depth computational problems that require logarithmic depth to\nsolve with classical circuits. Using quantum error correction, Bravyi, Gosset,\nK\\\"onig and Tomamichel (Nature Physics 2020) further proved that a similar\nseparation still persists even if quantum circuits are subject to local\nstochastic noise.\n  We prove that this quantum advantage persists even if the quantum circuits\ncan be subject to arbitrary corruption: in this paper we assume that any\nconstant fraction of the qubits (for instance, huge blocks of qubits) may be\narbitrarily corrupted at the end of the computation. We show that even in this\nmodel, quantum circuits can still solve in constant depth computational\nproblems that require logarithmic depth to solve with bounded fan-in classical\ncircuits. This gives another compelling evidence of the computational power of\nquantum shallow circuits.\n  In order to show our result, we consider the Graph State Sampling problem\n(which was also used in prior works) on expander graphs. We exploit the\n\"robustness\" of expander graphs against vertex corruption to show that a\nsubproblem hard for small-depth classical circuits can still be extracted from\nthe output of the corrupted quantum circuit.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 02:31:11 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 01:11:26 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Hasegawa", "Atsuya", ""], ["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "2105.00689", "submitter": "Michael Kompatscher", "authors": "Michael Kompatscher", "title": "CSAT and CEQV for nilpotent Maltsev algebras of Fitting length > 2", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.RA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The circuit satisfaction problem CSAT(A) of an algebra A is the problem of\ndeciding whether an equation over A (encoded by two circuits) has a solution or\nnot. While solving systems of equations over finite algebras is either in P or\nNP-complete, no such dichotomy result is known for CSAT(A). In fact, Idziak,\nKawalek and Krzaczkowski constructed examples of nilpotent Maltsev algebras A,\nfor which, under the assumption of ETH and an open conjecture in circuit\ntheory, CSAT(A) can be solved in quasipolynomial, but not polynomial time. The\nsame is true for the circuit equivalence problem CEQV(A).\n  In this paper we generalize their result to all nilpotent Maltsev algebras of\nFitting length >2. This not only advances the project of classifying the\ncomplexity of CSAT (and CEQV) for algebras from congruence modular varieties,\nbut we also believe that the tools we developed are of independent interest in\nthe study of nilpotent algebras.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 08:51:57 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kompatscher", "Michael", ""]]}, {"id": "2105.00761", "submitter": "Noam Mazor", "authors": "Dror Chawin, Iftach Haitner, Noam Mazor", "title": "Lower Bounds on the Time/Memory Tradeoff of Function Inversion", "comments": "A preliminary version appeared in TCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study time/memory tradeoffs of function inversion: an algorithm, i.e., an\ninverter, equipped with an s-bit advice on a randomly chosen function $f : [n]\n-> [n]$ and using $q$ oracle queries to $f$, tries to invert a randomly chosen\noutput $y$ of $f$, i.e., to find $x\\in f^{-1}(y)$. Much progress was done\nregarding adaptive function inversion - the inverter is allowed to make\nadaptive oracle queries. Hellman [IEEE transactions on Information Theory 80]\npresented an adaptive inverter that inverts with high probability a random $f$.\nFiat and Naor [SICOMP 00] proved that for any $s$, $q$ with $s^3q = n$\n(ignoring low-order terms), an $s$-advice, $q$-query variant of Hellmans\nalgorithm inverts a constant fraction of the image points of any function. Yao\n[STOC 90] proved a lower bound of $sq \\geq n$ for this problem. Closing the gap\nbetween the above lower and upper bounds is a long-standing open question. Very\nlittle is known for the non-adaptive variant of the question. The only known\nupper bounds, i.e., inverters, are the trivial ones (with $s+q = n$), and the\nonly lower bound is the above bound of Yao. In a recent work, Corrigan-Gibbs\nand Kogan [TCC 19] partially justified the difficulty of finding lower bounds\non non-adaptive inverters, showing that a lower bound on the time/memory\ntradeoff of non-adaptive inverters implies a lower bound on low-depth Boolean\ncircuits. Bounds that, for a strong enough choice of parameters, are\nnotoriously hard to prove. We make progress on the above intriguing question,\nboth for the adaptive and the non-adaptive case, proving the following lower\nbounds on restricted families of inverters.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 11:38:42 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 12:46:19 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 08:08:45 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 12:54:08 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Chawin", "Dror", ""], ["Haitner", "Iftach", ""], ["Mazor", "Noam", ""]]}, {"id": "2105.00770", "submitter": "Noam Mazor", "authors": "Iftach Haitner, Noam Mazor, Ronen Shaltiel, Jad Silbak", "title": "Channels of Small Log-Ratio Leakage and Characterization of Two-Party\n  Differentially Private Computation", "comments": "A preliminary version appeared in TCC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a PPT two-party protocol $\\pi=(A,B)$ in which the parties get no\nprivate inputs and obtain outputs $O^A,O^B\\in \\{0,1\\}$, and let $V^A$ and $V^B$\ndenote the parties' individual views. Protocol $\\pi$ has $\\alpha$-agreement if\n$Pr[O^A=O^B]=1/2+\\alpha$. The leakage of $\\pi$ is the amount of information a\nparty obtains about the event $\\{O^A=O^B\\}$; that is, the leakage $\\epsilon$ is\nthe maximum, over $P\\in\\{A,B\\}$, of the distance between $V^P|OA=OB$ and\n$V^P|OA\\neq OB$. Typically, this distance is measured in statistical distance,\nor, in the computational setting, in computational indistinguishability. For\nthis choice, Wullschleger [TCC 09] showed that if $\\alpha>>\\epsilon$ then the\nprotocol can be transformed into an OT protocol.\n  We consider measuring the protocol leakage by the log-ratio distance (which\nwas popularized by its use in the differential privacy framework). The\nlog-ratio distance between X,Y over domain \\Omega is the minimal $\\epsilon>0$\nfor which, for every $v\\in\\Omega$, $log(Pr[X=v]/Pr[Y=v])\\in\n[-\\epsilon,\\epsilon]$. In the computational setting, we use computational\nindistinguishability from having log-ratio distance $\\epsilon$. We show that a\nprotocol with (noticeable) accuracy $\\alpha\\in\\Omega(\\epsilon^2)$ can be\ntransformed into an OT protocol (note that this allows $\\epsilon>>\\alpha$). We\ncomplete the picture, in this respect, showing that a protocol with $\\alpha\\in\no(\\epsilon^2)$ does not necessarily imply OT. Our results hold for both the\ninformation theoretic and the computational settings, and can be viewed as a\n\"fine grained\" approach to \"weak OT amplification\".\n  We then use the above result to fully characterize the complexity of\ndifferentially private two-party computation for the XOR function, answering\nthe open question put by Goyal, Khurana, Mironov, Pandey, and Sahai [ICALP 16]\nand Haitner, Nissim, Omri, Shaltiel, and Silbak [FOCS 18].\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 11:55:00 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 12:44:32 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 12:40:40 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Haitner", "Iftach", ""], ["Mazor", "Noam", ""], ["Shaltiel", "Ronen", ""], ["Silbak", "Jad", ""]]}, {"id": "2105.01149", "submitter": "Akhil Jalan", "authors": "Akhil Jalan, Dana Moshkovitz", "title": "Near-Optimal Cayley Expanders for Abelian Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We give an efficient deterministic algorithm that outputs an expanding\ngenerating set for any finite abelian group. The size of the generating set is\nclose to the randomized construction of Alon and Roichman (1994), improving\nupon various deterministic constructions in both the dependence on the\ndimension and the spectral gap. By obtaining optimal dependence on the\ndimension we resolve a conjecture of Azar, Motwani, and Naor (1998) in the\naffirmative. Our technique is an extension of the bias amplification technique\nof Ta-Shma (2017), who used random walks on expanders to obtain expanding\ngenerating sets over the additive group of n-bit strings. As a consequence, we\nobtain (i) randomness-efficient constructions of almost k-wise independent\nvariables, (ii) a faster deterministic algorithm for the Remote Point Problem,\n(iii) randomness-efficient low-degree tests, and (iv) randomness-efficient\nverification of matrix multiplication.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 20:07:03 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Jalan", "Akhil", ""], ["Moshkovitz", "Dana", ""]]}, {"id": "2105.01161", "submitter": "Alexander Golovnev", "authors": "Chi-Ning Chou, Alexander Golovnev, Madhu Sudan, and Santhoshini\n  Velusamy", "title": "Approximability of all finite CSPs in the dynamic streaming setting", "comments": "arXiv admin note: text overlap with arXiv:2102.12351", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A constraint satisfaction problem (CSP), Max-CSP$({\\cal F})$, is specified by\na finite set of constraints ${\\cal F} \\subseteq \\{[q]^k \\to \\{0,1\\}\\}$ for\npositive integers $q$ and $k$. An instance of the problem on $n$ variables is\ngiven by $m$ applications of constraints from ${\\cal F}$ to subsequences of the\n$n$ variables, and the goal is to find an assignment to the variables that\nsatisfies the maximum number of constraints. In the\n$(\\gamma,\\beta)$-approximation version of the problem for parameters $0 \\leq\n\\beta < \\gamma \\leq 1$, the goal is to distinguish instances where at least\n$\\gamma$ fraction of the constraints can be satisfied from instances where at\nmost $\\beta$ fraction of the constraints can be satisfied.\n  In this work we consider the approximability of this problem in the context\nof streaming algorithms and give a dichotomy result in the dynamic setting,\nwhere constraints can be inserted or deleted. Specifically, for every family\n${\\cal F}$ and every $\\beta < \\gamma$, we show that either the approximation\nproblem is solvable with polylogarithmic space in the dynamic setting, or not\nsolvable with $o(\\sqrt{n})$ space. We also establish tight inapproximability\nresults for a broad subclass in the streaming insertion-only setting. Our work\nbuilds on, and significantly extends previous work by the authors who consider\nthe special case of Boolean variables ($q=2$), singleton families ($|{\\cal F}|\n= 1$) and where constraints may be placed on variables or their negations. Our\nframework extends non-trivially the previous work allowing us to appeal to\nricher norm estimation algorithms to get our algorithmic results. For our\nnegative results we introduce new variants of the communication problems\nstudied in the previous work, build new reductions for these problems, and\nextend the technical parts of previous works.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 20:34:08 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 19:41:26 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 15:39:03 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Chou", "Chi-Ning", ""], ["Golovnev", "Alexander", ""], ["Sudan", "Madhu", ""], ["Velusamy", "Santhoshini", ""]]}, {"id": "2105.01193", "submitter": "Mehdi Soleimanifar", "authors": "Anurag Anshu, David Gosset, Karen J. Morenz Korol, Mehdi Soleimanifar", "title": "Improved approximation algorithms for bounded-degree local Hamiltonians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of approximating the ground state energy of two-local\nquantum Hamiltonians on bounded-degree graphs. Most existing algorithms\noptimize the energy over the set of product states. Here we describe a family\nof shallow quantum circuits that can be used to improve the approximation ratio\nachieved by a given product state. The algorithm takes as input an $n$-qubit\nproduct state $|v\\rangle$ with mean energy $e_0=\\langle v|H|v\\rangle$ and\nvariance $\\mathrm{Var}=\\langle v|(H-e_0)^2|v\\rangle$, and outputs a state with\nan energy that is lower than $e_0$ by an amount proportional to\n$\\mathrm{Var}^2/n$. In a typical case, we have $\\mathrm{Var}=\\Omega(n)$ and the\nenergy improvement is proportional to the number of edges in the graph. When\napplied to an initial random product state, we recover and generalize the\nperformance guarantees of known algorithms for bounded-occurrence classical\nconstraint satisfaction problems. We extend our results to $k$-local\nHamiltonians and entangled initial states.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 22:23:47 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Anshu", "Anurag", ""], ["Gosset", "David", ""], ["Korol", "Karen J. Morenz", ""], ["Soleimanifar", "Mehdi", ""]]}, {"id": "2105.01427", "submitter": "Yihan Zhang", "authors": "Nikita Polyanskii, Yihan Zhang", "title": "Codes for the Z-channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.CO math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is a collection of results on combinatorial properties of codes\nfor the Z-channel. A Z-channel with error fraction $\\tau$ takes as input a\nlength-$n$ binary codeword and injects in an adversarial manner $n\\tau$\nasymmetric errors, i.e., errors that only zero out bits but do not flip $0$'s\nto $1$'s. It is known that the largest $(L-1)$-list-decodable code for the\nZ-channel with error fraction $\\tau$ has exponential (in $n$) size if $\\tau$ is\nless than a critical value that we call the Plotkin point and has constant size\nif $\\tau$ is larger than the threshold. The $(L-1)$-list-decoding Plotkin point\nis known to be $ L^{-\\frac{1}{L-1}} - L^{-\\frac{L}{L-1}} $, which equals $1/4$\nfor unique-decoding with $ L-1=1 $. In this paper, we derive various results\nfor the size of the largest codes above and below the list-decoding Plotkin\npoint. In particular, we show that the largest $(L-1)$-list-decodable code\n$\\epsilon$-above the Plotkin point has size $\\Theta_L(\\epsilon^{-3/2})$ for any\n$L-1\\ge1$. We also devise upper and lower bounds on the exponential size of\ncodes below the list-decoding Plotkin point.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 11:31:47 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Polyanskii", "Nikita", ""], ["Zhang", "Yihan", ""]]}, {"id": "2105.01459", "submitter": "Iftach Haitner", "authors": "Iftach Haitner and Thomas Holenstein and Omer Reingold and Salil\n  Vadhan and Hoeteck Wee", "title": "Inaccessible Entropy II: IE Functions and Universal One-Way Hashing", "comments": "This is the final draft of this paper. The full version was published\n  in the Theory of Computing 2020. An extended abstract of this work appeared\n  appeared as \"Universal One-Way Hash Functions via Inaccessible Entropy\" in\n  Eurocrypt 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses a variant of the notion of \\emph{inaccessible entropy}\n(Haitner, Reingold, Vadhan and Wee, STOC 2009), to give an alternative\nconstruction and proof for the fundamental result, first proved by Rompel (STOC\n1990), that \\emph{Universal One-Way Hash Functions (UOWHFs)} can be based on\nany one-way functions. We observe that a small tweak of any one-way function\n$f$ is already a weak form of a UOWHF: consider the function $F(x,i)$ that\nreturns the $i$-bit-long prefix of $f(x)$. If $F$ were a UOWHF then given a\nrandom $x$ and $i$ it would be hard to come up with $x'\\neq x$ such that\n$F(x,i)=F(x',i)$. While this may not be the case, we show (rather easily) that\nit is hard to sample $x'$ with almost full entropy among all the possible such\nvalues of $x'$. The rest of our construction simply amplifies and exploits this\nbasic property.Combined with other recent work, the construction of three\nfundamental cryptographic primitives (Pseudorandom Generators, Statistically\nHiding Commitments and UOWHFs) out of one-way functions is now to a large\nextent unified. In particular, all three constructions rely on and manipulate\ncomputational notions of entropy in similar ways. Pseudorandom Generators rely\non the well-established notion of pseudoentropy, whereas Statistically Hiding\nCommitments and UOWHFs rely on the newer notion of inaccessible entropy.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 12:40:53 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Haitner", "Iftach", ""], ["Holenstein", "Thomas", ""], ["Reingold", "Omer", ""], ["Vadhan", "Salil", ""], ["Wee", "Hoeteck", ""]]}, {"id": "2105.01465", "submitter": "Karol W\\k{e}grzycki", "authors": "Jesper Nederlof, Micha{\\l} Pilipczuk, C\\'eline M. F. Swennenhuis,\n  Karol W\\k{e}grzycki", "title": "Isolation schemes for problems on decomposable graphs", "comments": "54 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Isolation Lemma of Mulmuley, Vazirani and Vazirani [Combinatorica'87]\nprovides a self-reduction scheme that allows one to assume that a given\ninstance of a problem has a unique solution, provided a solution exists at all.\nSince its introduction, much effort has been dedicated towards derandomization\nof the Isolation Lemma for specific classes of problems. So far, the focus was\nmainly on problems solvable in polynomial time.\n  In this paper, we study a setting that is more typical for\n$\\mathsf{NP}$-complete problems, and obtain partial derandomizations in the\nform of significantly decreasing the number of required random bits. In\nparticular, motivated by the advances in parameterized algorithms, we focus on\nproblems on decomposable graphs. For example, for the problem of detecting a\nHamiltonian cycle, we build upon the rank-based approach from [Bodlaender et\nal., Inf. Comput.'15] and design isolation schemes that use\n  - $O(t\\log n + \\log^2{n})$ random bits on graphs of treewidth at most $t$;\n  - $O(\\sqrt{n})$ random bits on planar or $H$-minor free graphs; and\n  - $O(n)$-random bits on general graphs.\n  In all these schemes, the weights are bounded exponentially in the number of\nrandom bits used. As a corollary, for every fixed $H$ we obtain an algorithm\nfor detecting a Hamiltonian cycle in an $H$-minor-free graph that runs in\ndeterministic time $2^{O(\\sqrt{n})}$ and uses polynomial space; this is the\nfirst algorithm to achieve such complexity guarantees. For problems of more\nlocal nature, such as finding an independent set of maximum size, we obtain\nisolation schemes on graphs of treedepth at most $d$ that use $O(d)$ random\nbits and assign polynomially-bounded weights.\n  We also complement our findings with several unconditional and conditional\nlower bounds, which show that many of the results cannot be significantly\nimproved.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 12:46:51 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Nederlof", "Jesper", ""], ["Pilipczuk", "Micha\u0142", ""], ["Swennenhuis", "C\u00e9line M. F.", ""], ["W\u0119grzycki", "Karol", ""]]}, {"id": "2105.01469", "submitter": "Heng Guo", "authors": "Heng Guo and Mark Jerrum", "title": "Counting vertices of integer polytopes defined by facets", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a number of complexity results concerning the problem of counting\nvertices of an integral polytope defined by a system of linear inequalities.\nThe focus is on polytopes with small integer vertices, particularly 0/1\npolytopes and half-integral polytopes.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 12:51:57 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Guo", "Heng", ""], ["Jerrum", "Mark", ""]]}, {"id": "2105.01751", "submitter": "Ilya Volkovich", "authors": "Vishwas Bhargava, Shubhangi Saraf, Ilya Volkovich", "title": "Reconstruction Algorithms for Low-Rank Tensors and Depth-3 Multilinear\n  Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give new and efficient black-box reconstruction algorithms for some\nclasses of depth-$3$ arithmetic circuits. As a consequence, we obtain the first\nefficient algorithm for computing the tensor rank and for finding the optimal\ntensor decomposition as a sum of rank-one tensors when then input is a\nconstant-rank tensor. More specifically, we provide efficient learning\nalgorithms that run in randomized polynomial time over general fields and in\ndeterministic polynomial time over the reals and the complex numbers for the\nfollowing classes:\n  (1) Set-multilinear depth-$3$ circuits of constant top fan-in\n$\\Sigma\\Pi\\Sigma\\{\\sqcup_j X_j\\}(k)$ circuits). As a consequence of our\nalgorithm, we obtain the first polynomial time algorithm for tensor rank\ncomputation and optimal tensor decomposition of constant-rank tensors. This\nresult holds for $d$ dimensional tensors for any $d$, but is interesting even\nfor $d=3$.\n  (2) Sums of powers of constantly many linear forms ($\\Sigma\\wedge\\Sigma$\ncircuits). As a consequence we obtain the first polynomial-time algorithm for\ntensor rank computation and optimal tensor decomposition of constant-rank\nsymmetric tensors.\n  (3) Multilinear depth-3 circuits of constant top fan-in (multilinear\n$\\Sigma\\Pi\\Sigma(k)$ circuits). Our algorithm works over all fields of\ncharacteristic 0 or large enough characteristic. Prior to our work the only\nefficient algorithms known were over polynomially-sized finite fields (see.\nKarnin-Shpilka 09').\n  Prior to our work, the only polynomial-time or even subexponential-time\nalgorithms known (deterministic or randomized) for subclasses of\n$\\Sigma\\Pi\\Sigma(k)$ circuits that also work over large/infinite fields were\nfor the setting when the top fan-in $k$ is at most $2$ (see Sinha 16' and Sinha\n20').\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 20:45:07 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Bhargava", "Vishwas", ""], ["Saraf", "Shubhangi", ""], ["Volkovich", "Ilya", ""]]}, {"id": "2105.01782", "submitter": "Noah Singer", "authors": "Noah Singer and Madhu Sudan and Santhoshini Velusamy", "title": "Streaming approximation resistance of every ordering CSP", "comments": "23 pages, 1 figure. Replaces earlier version with $o(\\sqrt{n})$ lower\n  bound, using new bounds from arXiv:2106.13078. To appear in APPROX'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ordering constraint satisfaction problem (OCSP) is given by a positive\ninteger $k$ and a constraint predicate $\\Pi$ mapping permutations on\n$\\{1,\\ldots,k\\}$ to $\\{0,1\\}$. Given an instance of OCSP$(\\Pi)$ on $n$\nvariables and $m$ constraints, the goal is to find an ordering of the $n$\nvariables that maximizes the number of constraints that are satisfied, where a\nconstraint specifies a sequence of $k$ distinct variables and the constraint is\nsatisfied by an ordering on the $n$ variables if the ordering induced on the\n$k$ variables in the constraint satisfies $\\Pi$. OCSPs capture natural problems\nincluding \"Maximum acyclic subgraph (MAS)\" and \"Betweenness\".\n  In this work we consider the task of approximating the maximum number of\nsatisfiable constraints in the (single-pass) streaming setting, where an\ninstance is presented as a stream of constraints. We show that for every $\\Pi$,\nOCSP$(\\Pi)$ is approximation-resistant to $o(n)$-space streaming algorithms.\nThis space bound is tight up to polylogarithmic factors. In the case of MAS our\nresult shows that for every $\\epsilon>0$, MAS is not\n$1/2+\\epsilon$-approximable in $o(n)$ space. The previous best\ninapproximability result only ruled out a $3/4$-approximation in $o(\\sqrt n)$\nspace.\n  Our results build on recent works of Chou, Golovnev, Sudan, Velingker, and\nVelusamy who show tight, linear-space inapproximability results for a broad\nclass of (non-ordering) constraint satisfaction problems over arbitrary\n(finite) alphabets. We design a family of appropriate CSPs (one for every $q$)\nfrom any given OCSP, and apply their work to this family of CSPs. We show that\nthe hard instances from this earlier work have a particular \"small-set\nexpansion\" property. By exploiting this combinatorial property, in combination\nwith the hardness results of the resulting families of CSPs, we give optimal\ninapproximability results for all OCSPs.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 22:18:04 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 18:37:51 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Singer", "Noah", ""], ["Sudan", "Madhu", ""], ["Velusamy", "Santhoshini", ""]]}, {"id": "2105.01963", "submitter": "Nikhil Mande", "authors": "Nikhil S. Mande, Swagato Sanyal", "title": "One-way communication complexity and non-adaptive decision trees", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the relationship between various one-way communication complexity\nmeasures of a composed function with the analogous decision tree complexity of\nthe outer function. We consider two gadgets: the AND function on 2 inputs, and\nthe Inner Product on a constant number of inputs. Let $IP$ denote Inner Product\non $2b$ bits.\n  1) If $f$ is a total Boolean function that depends on all of its inputs, the\nbounded-error one-way quantum communication complexity of $f \\circ IP$ equals\n$\\Omega(n(b-1))$.\n  2) If $f$ is a partial Boolean function, the deterministic one-way\ncommunication complexity of $f \\circ IP$ is at least $\\Omega(b \\cdot\nD_{dt}^{\\rightarrow}(f))$, where $D_{dt}^{\\rightarrow}(f)$ denotes the\nnon-adaptive decision tree complexity of $f$.\n  For our quantum lower bound, we show a lower bound on the VC-dimension of $f\n\\circ IP$, and then appeal to a result of Klauck [STOC'00]. Our deterministic\nlower bound relies on a combinatorial result due to Frankl and Tokushige\n[Comb.'99].\n  It is known due to a result of Montanaro and Osborne [arXiv'09] that the\ndeterministic one-way communication complexity of $f \\circ XOR_2$ equals the\nnon-adaptive parity decision tree complexity of $f$. In contrast, we show the\nfollowing with the gadget $AND_2$.\n  1) There exists a function for which even the randomized non-adaptive AND\ndecision tree complexity of $f$ is exponentially large in the deterministic\none-way communication complexity of $f \\circ AND_2$.\n  2) For symmetric functions $f$, the non-adaptive AND decision tree complexity\nof $f$ is at most quadratic in the (even two-way) communication complexity of\n$f \\circ AND_2$.\n  In view of the first point, a lower bound on non-adaptive AND decision tree\ncomplexity of $f$ does not lift to a lower bound on one-way communication\ncomplexity of $f \\circ AND_2$. The proof of the first point above uses the\nwell-studied Odd-Max-Bit function.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 10:20:26 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 17:13:40 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Mande", "Nikhil S.", ""], ["Sanyal", "Swagato", ""]]}, {"id": "2105.02681", "submitter": "Abuzer Yakaryilmaz", "authors": "Fran\\c{c}ois Le Gall, Harumichi Nishimura, and Abuzer Yakary{\\i}lmaz", "title": "Quantum Logarithmic Space and Post-selection", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-selection, the power of discarding all runs of a computation in which an\nundesirable event occurs, is an influential concept introduced to the field of\nquantum complexity theory by Aaronson (Proceedings of the Royal Society A,\n2005). In the present paper, we initiate the study of post-selection for\nspace-bounded quantum complexity classes. Our main result shows the identity\n$\\sf PostBQL=PL$, i.e., the class of problems that can be solved by a\nbounded-error (polynomial-time) logarithmic-space quantum algorithm with\npost-selection ($\\sf PostBQL$) is equal to the class of problems that can be\nsolved by unbounded-error logarithmic-space classical algorithms ($\\sf PL$).\nThis result gives a space-bounded version of the well-known result $\\sf\nPostBQP=PP$ proved by Aaronson for polynomial-time quantum computation. As a\nby-product, we also show that $\\sf PL$ coincides with the class of problems\nthat can be solved by bounded-error logarithmic-space quantum algorithms that\nhave no time bound.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:02:01 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""], ["Nishimura", "Harumichi", ""], ["Yakary\u0131lmaz", "Abuzer", ""]]}, {"id": "2105.02722", "submitter": "Gabriele Di Stefano", "authors": "Gabriele Di Stefano", "title": "Mutual Visibility in Graphs", "comments": "Added comparisons with general position set and general position\n  number concepts. Results achieved in the first version are still valid, but\n  sometime refined. Added new references. 23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Let $G=(V,E)$ be a graph and $P\\subseteq V$ a set of points. Two points are\nmutually visible if there is a shortest path between them without further\npoints. $P$ is a mutual-visibility set if its points are pairwise mutually\nvisible. The mutual-visibility number of $G$ is the size of any largest\nmutual-visibility set. In this paper we start the study about this new\ninvariant and the mutual-visibility sets in undirected graphs. We introduce the\nmutual-visibility problem which asks to find a mutual-visibility set with a\nsize larger than a given number. We show that this problem is NP-complete,\nwhereas, to check whether a given set of points is a mutual-visibility set is\nsolvable in polynomial time. Then we study mutual-visibility sets and\nmutual-visibility numbers on special classes of graphs, such as block graphs,\ntrees, grids, tori, complete bipartite graphs, cographs. We also provide some\nrelations of the mutual-visibility number of a graph with other invariants.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:41:13 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 10:02:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Di Stefano", "Gabriele", ""]]}, {"id": "2105.02736", "submitter": "Daniel Paulusma", "authors": "Giacomo Paesani and Dani\\\"el Paulusma and Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Feedback Vertex Set and Even Cycle Transversal for H-Free Graphs:\n  Finding Large Block Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove new complexity results for Feedback Vertex Set and Even Cycle\nTransversal on $H$-free graphs, that is, graphs that do not contain some fixed\ngraph $H$ as an induced subgraph. In particular, we prove that both problems\nare polynomial-time solvable for $sP_3$-free graphs for every integer $s\\geq\n1$. Our results show that both problems exhibit the same behaviour on $H$-free\ngraphs (subject to some open cases). This is in part explained by a new general\nalgorithm we design for finding in a graph $G$ a largest induced subgraph whose\nblocks belong to some finite class ${\\cal C}$ of graphs. We also compare our\nresults with the state-of-the-art results for the Odd Cycle Transversal\nproblem, which is known to behave differently on $H$-free graphs.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:56:38 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Paesani", "Giacomo", ""], ["Paulusma", "Dani\u00ebl", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "2105.02837", "submitter": "Kevin Buchin", "authors": "Kevin Buchin, Mart Hagedoorn, Irina Kostitsyna, Max van Mulken", "title": "Dots & Boxes is PSPACE-complete", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exactly 20 years ago at MFCS, Demaine posed the open problem whether the game\nof Dots & Boxes is PSPACE-complete. Dots & Boxes has been studied extensively,\nwith for instance a chapter in Berlekamp et al. \"Winning Ways for Your\nMathematical Plays\", a whole book on the game \"The Dots and Boxes Game:\nSophisticated Child's Play\" by Berlekamp, and numerous articles in the \"Games\nof No Chance\" series. While known to be NP-hard, the question of its complexity\nremained open. We resolve this question, proving that the game is\nPSPACE-complete by a reduction from a game played on propositional formulas.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:26:23 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Buchin", "Kevin", ""], ["Hagedoorn", "Mart", ""], ["Kostitsyna", "Irina", ""], ["van Mulken", "Max", ""]]}, {"id": "2105.02908", "submitter": "Zeyu Guo", "authors": "Zeyu Guo", "title": "Variety Evasive Subspace Families", "comments": "CCC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of constructing explicit variety evasive subspace\nfamilies. Given a family $\\mathcal{F}$ of subvarieties of a projective or\naffine space, a collection $\\mathcal{H}$ of projective or affine $k$-subspaces\nis $(\\mathcal{F},\\epsilon)$-evasive if for every $\\mathcal{V}\\in\\mathcal{F}$,\nall but at most $\\epsilon$-fraction of $W\\in\\mathcal{H}$ intersect every\nirreducible component of $\\mathcal{V}$ with (at most) the expected dimension.\nThe problem of constructing such an explicit subspace family generalizes both\ndeterministic black-box polynomial identity testing (PIT) and the problem of\nconstructing explicit (weak) lossless rank condensers.\n  Using Chow forms, we construct explicit $k$-subspace families of polynomial\nsize that are evasive for all varieties of bounded degree in a projective or\naffine $n$-space. As one application, we obtain a complete derandomization of\nNoether's normalization lemma for varieties of bounded degree in a projective\nor affine $n$-space. In another application, we obtain a simple polynomial-time\nblack-box PIT algorithm for depth-4 arithmetic circuits with bounded top fan-in\nand bottom fan-in that are not in the Sylvester-Gallai configuration, improving\nand simplifying a result of Gupta (ECCC TR 14-130).\n  As a complement of our explicit construction, we prove a lower bound for the\nsize of $k$-subspace families that are evasive for degree-$d$ varieties in a\nprojective $n$-space. When $n-k=\\Omega(n)$, the lower bound is superpolynomial\nunless $d$ is bounded. The proof uses a dimension-counting argument on Chow\nvarieties that parametrize projective subvarieties.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 18:14:08 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Guo", "Zeyu", ""]]}, {"id": "2105.03028", "submitter": "Shyan Akmal", "authors": "Shyan Akmal and Virginia Vassilevska Williams", "title": "Improved Approximation for Longest Common Subsequence over Small\n  Alphabets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the approximability of the Longest Common Subsequence\n(LCS) problem. The fastest algorithm for solving the LCS problem exactly runs\nin essentially quadratic time in the length of the input, and it is known that\nunder the Strong Exponential Time Hypothesis the quadratic running time cannot\nbe beaten. There are no such limitations for the approximate computation of the\nLCS however, except in some limited scenarios. There is also a scarcity of\napproximation algorithms. When the two given strings are over an alphabet of\nsize $k$, returning the subsequence formed by the most frequent symbol\noccurring in both strings achieves a $1/k$ approximation for the LCS. It is an\nopen problem whether a better than $1/k$ approximation can be achieved in truly\nsubquadratic time ($O(n^{2-\\delta})$ time for constant $\\delta>0$).\n  A recent result [Rubinstein and Song SODA'2020] showed that a $1/2+\\epsilon$\napproximation for the LCS over a binary alphabet is possible in truly\nsubquadratic time, provided the input strings have the same length. In this\npaper we show that if a $1/2+\\epsilon$ approximation (for $\\epsilon>0$) is\nachievable for binary LCS in truly subquadratic time when the input strings can\nbe unequal, then for every constant $k$, there is a truly subquadratic time\nalgorithm that achieves a $1/k+\\delta$ approximation for $k$-ary alphabet LCS\nfor some $\\delta>0$. Thus the binary case is the hardest. We also show that for\nevery constant $k$, if one is given two strings of \\emph{equal} length over a\n$k$-ary alphabet, one can obtain a $1/k+\\epsilon$ approximation for some\nconstant $\\epsilon>0$ in truly subquadratic time, thus extending the Rubinstein\nand Song result to all alphabets of constant size.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 01:44:13 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Akmal", "Shyan", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "2105.03249", "submitter": "Yuri I. Ozhigov", "authors": "Yuri I. Ozhigov", "title": "The complexity of a quantum system and the accuracy of its description", "comments": "Latex, 20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC nlin.CD physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The complexity of the quantum state of a multi particle system and the\nmaximum possible accuracy of its quantum description are connected by a\nrelation similar to the coordinate-momentum uncertainty relation. The\ncoefficient in this relation is equal to the maximum physically adequate\ndimension of the Hilbert space of states. This value is the binary exponent of\nthe maximum number of qubits whose dynamics can be adequately described by\nquantum theory, and therefore it can be determined experimentally through\nGrover search algorithm. Such a restriction of the Copenhagen formalism is\nrelevant for complex systems; it gives a natural description of unitary\ndynamics together with decoherence and measurement, but also implies the\nexistence of a minimum non-zero amplitude size, as well as a restriction on the\nequality of bases in the state space. The quantization of the amplitude allows\nus to formally introduce a certain kind of determinism into quantum evolution,\nwhich is important for complex systems.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 09:16:40 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Ozhigov", "Yuri I.", ""]]}, {"id": "2105.03273", "submitter": "Daniel Karapetyan Dr", "authors": "Daniel Karapetyan and Gregory Gutin", "title": "Solving the Workflow Satisfiability Problem using General Purpose\n  Solvers", "comments": "Associated data: http://doi.org/10.17639/nott.7116", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workflow satisfiability problem (WSP) is a well-studied problem in access\ncontrol seeking allocation of authorised users to every step of the workflow,\nsubject to workflow specification constraints. It was noticed that the number\n$k$ of steps is typically small compared to the number of users in the\nreal-world instances of WSP; therefore $k$ is considered as the parameter in\nWSP parametrised complexity research. While WSP in general was shown to be\nW[1]-hard, WSP restricted to a special case of user-independent (UI)\nconstraints is fixed-parameter tractable (FPT). However, restriction to the UI\nconstraints might be impractical.\n  To efficiently handle non-UI constraints, we introduce the notion of\nbranching factor of a constraint. As long as the branching factors of the\nconstraints are relatively small and the number of non-UI constraints is\nreasonable, WSP can be solved in FPT time.\n  Extending the results from Karapetyan et al. (2019), we demonstrate that\ngeneral-purpose solvers are capable of achieving FPT-like performance on WSP\nwith arbitrary constraints when used with appropriate formulations. This\nenables one to tackle most of practical WSP instances. While important on its\nown, we hope that this result will also motivate researchers to look for\nFPT-aware formulations of other FPT problems.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 13:59:30 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Gutin", "Gregory", ""]]}, {"id": "2105.03531", "submitter": "Tajana Ban Kirigin", "authors": "Max Kanovich, Tajana Ban Kirigin, Vivek Nigam, Andre Scedrov, and\n  Carolyn Talcott", "title": "On the Complexity of Verification of Time-Sensitive Distributed Systems:\n  Technical Report", "comments": "This Technical Report updates and subsumes the technical report\n  arXiv:1606.07886", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops a Multiset Rewriting language with explicit time for\nspecifying and analyzing Time-Sensitive Distributed Systems (TSDS). Goals are\noften specified using explicit time constraints. A good trace is an infinite\ntrace in which goals are perpetually satisfied, in spite of a possible\nenvironment interference. In our previous work (FORMATS 2016) we discussed two\ndesirable properties of TSDSes, realizability (there exists a good trace) and\nsurvivability (where, in addition, all admissible traces are good). Here we\nconsider two further properties, recoverability (all compliant traces do not\nreach points-of-no-return) and reliability (system can always continue\nfunctioning using a good trace). Following our previous work (FORMATS 2016), we\nfocus on a class of systems called Progressing Timed Systems (PTS), where\nintuitively only a finite number of actions can be carried out in a bounded\ntime period. We prove that for this class of systems the properties of\nrecoverability and reliability coincide and are PSPACE-complete. Furthermore,\nif we impose a bound on time (as in bounded model-checking), we show that for\nPTS, the reliability property is in the $\\Delta_2^p$ class of the polynomial\nhierarchy, a subclass of PSPACE. We also show that bounded survivability is\nboth NP-hard and coNP-hard.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 22:44:23 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 17:23:36 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kanovich", "Max", ""], ["Kirigin", "Tajana Ban", ""], ["Nigam", "Vivek", ""], ["Scedrov", "Andre", ""], ["Talcott", "Carolyn", ""]]}, {"id": "2105.03697", "submitter": "Subhayan Roy Moulik", "authors": "Marcel Dall'Agnol, Tom Gur, Subhayan Roy Moulik, Justin Thaler", "title": "Quantum Proofs of Proximity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the systematic study of QMA algorithms in the setting of property\ntesting, to which we refer as QMA proofs of proximity (QMAPs). These are\nquantum query algorithms that receive explicit access to a sublinear-size\nuntrusted proof and are required to accept inputs having a property $\\Pi$ and\nreject inputs that are $\\varepsilon$-far from $\\Pi$, while only probing a\nminuscule portion of their input. Our algorithmic results include a\ngeneral-purpose theorem that enables quantum speedups for testing an expressive\nclass of properties, namely, those that are succinctly decomposable.\nFurthermore, we show quantum speedups for properties that lie outside of this\nfamily, such as graph bipartitneness. We also investigate the complexity\nlandscape of this model, showing that QMAPs can be exponentially stronger than\nboth classical proofs of proximity and quantum testers. To this end, we extend\nthe methodology of Blais, Brody and Matulef (Computational Complexity, 2012) to\nprove quantum property testing lower bounds via reductions from communication\ncomplexity, thereby resolving a problem raised by Montanaro and de Wolf (Theory\nof Computing, 2016).\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 13:15:30 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Dall'Agnol", "Marcel", ""], ["Gur", "Tom", ""], ["Moulik", "Subhayan Roy", ""], ["Thaler", "Justin", ""]]}, {"id": "2105.03831", "submitter": "Guangyan Zhou", "authors": "Guangyan Zhou, Wei Xu", "title": "Super Solutions of the Model RB", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of super solution is a special type of generalized solutions with\ncertain degree of robustness and stability. In this paper we consider the\n$(1,1)$-super solutions of the model RB. Using the first moment method, we\nestablish a \"threshold\" such that as the constraint density crosses this value,\nthe expected number of $(1,1)$-super solutions goes from $0$ to infinity.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 04:17:34 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhou", "Guangyan", ""], ["Xu", "Wei", ""]]}, {"id": "2105.04588", "submitter": "Daniel Paulusma", "authors": "Christoph Brause and Petr Golovach and Barnaby Martin and Dani\\\"el\n  Paulusma and Siani Smith", "title": "Partitioning H-Free Graphs of Bounded Diameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural way of increasing our understanding of NP-complete graph problems\nis to restrict the input to a special graph class. Classes of $H$-free graphs,\nthat is, graphs that do not contain some graph $H$ as an induced subgraph, have\nproven to be an ideal testbed for such a complexity study. However, if the\nforbidden graph $H$ contains a cycle or claw, then these problems often stay\nNP-complete. A recent complexity study on the $k$-Colouring problem shows that\nwe may still obtain tractable results if we also bound the diameter of the\n$H$-free input graph. We continue this line of research by initiating a\ncomplexity study on the impact of bounding the diameter for a variety of\nclassical vertex partitioning problems restricted to $H$-free graphs. We prove\nthat bounding the diameter does not help for Independent Set, but leads to new\ntractable cases for problems closely related to 3-Colouring. That is, we show\nthat Near-Bipartiteness, Independent Feedback Vertex Set, Independent Odd Cycle\nTransversal, Acyclic 3-Colouring and Star 3-Colouring are all polynomial-time\nsolvable for chair-free graphs of bounded diameter. To obtain these results we\nexploit a new structural property of 3-colourable chair-free graphs.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 18:02:48 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Brause", "Christoph", ""], ["Golovach", "Petr", ""], ["Martin", "Barnaby", ""], ["Paulusma", "Dani\u00ebl", ""], ["Smith", "Siani", ""]]}, {"id": "2105.04649", "submitter": "Modjtaba Shokrian Zini", "authors": "Michael H. Freedman, Matthew B. Hastings, Modjtaba Shokrian Zini", "title": "Symmetry Protected Quantum Computation", "comments": "Changed the template and fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a model of quantum computation using qubits where it is possible\nto measure whether a given pair are in a singlet (total spin $0$) or triplet\n(total spin $1$) state. The physical motivation is that we can do these\nmeasurements in a way that is protected against revealing other information so\nlong as all terms in the Hamiltonian are $SU(2)$-invariant. We conjecture that\nthis model is equivalent to BQP. Towards this goal, we show: (1) this model is\ncapable of universal quantum computation with polylogarithmic overhead if it is\nsupplemented by single qubit $X$ and $Z$ gates. (2) Without any additional\ngates, it is at least as powerful as the weak model of \"permutational quantum\ncomputation\" of Jordan[1, 2]. (3) With postselection, the model is equivalent\nto PostBQP.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:09:27 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 17:31:25 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Freedman", "Michael H.", ""], ["Hastings", "Matthew B.", ""], ["Zini", "Modjtaba Shokrian", ""]]}, {"id": "2105.04661", "submitter": "Michael Rathjen", "authors": "Michael Rathjen", "title": "No speedup for geometric theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric theories based on classical logic are conservative over their\nintuitionistic counterparts for geometric implications. The latter result\n(sometimes referred to as Barr's theorem) is squarely a consequence of\nGentzen's Hauptsatz. Prima facie though, cut elimination can result in\nsuperexponentially longer proofs. In this paper it is shown that the\ntransformation of a classical proof of a geometric implication in a geometric\ntheory into an intuitionistic proof can be achieved in feasibly many steps.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:39:09 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 09:37:48 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Rathjen", "Michael", ""]]}, {"id": "2105.04856", "submitter": "Leon Kellerhals", "authors": "Leon Kellerhals, Malte Renken and Philipp Zschoche", "title": "Parameterized Algorithms for Diverse Multistage Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world is rarely static -- many problems need not only be solved once but\nrepeatedly, under changing conditions. This setting is addressed by the\n\"multistage\" view on computational problems. We study the \"diverse multistage\"\nvariant, where consecutive solutions of large variety are preferable to similar\nones, e.g. for reasons of fairness or wear minimization. While some aspects of\nthis model have been tackled before, we introduce a framework allowing us to\nprove that a number of diverse multistage problems are fixed-parameter\ntractable by diversity, namely Perfect Matching, s-t Path, Matroid Independent\nSet, and Plurality Voting. This is achieved by first solving special, colored\nvariants of these problems, which might also be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 08:15:14 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kellerhals", "Leon", ""], ["Renken", "Malte", ""], ["Zschoche", "Philipp", ""]]}, {"id": "2105.05062", "submitter": "Karl Bringmann", "authors": "Karl Bringmann and Jasper Slusallek", "title": "Current Algorithms for Detecting Subgraphs of Bounded Treewidth are\n  Probably Optimal", "comments": "Full version of ICALP 2021 paper, 55 pages, abstract shortened to fit\n  ArXiv requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Subgraph Isomorphism problem is of considerable importance in computer\nscience. We examine the problem when the pattern graph H is of bounded\ntreewidth, as occurs in a variety of applications. This problem has a\nwell-known algorithm via color-coding that runs in time $O(n^{tw(H)+1})$ [Alon,\nYuster, Zwick'95], where $n$ is the number of vertices of the host graph $G$.\nWhile there are pattern graphs known for which Subgraph Isomorphism can be\nsolved in an improved running time of $O(n^{tw(H)+1-\\varepsilon})$ or even\nfaster (e.g. for $k$-cliques), it is not known whether such improvements are\npossible for all patterns. The only known lower bound rules out time\n$n^{o(tw(H) / \\log(tw(H)))}$ for any class of patterns of unbounded treewidth\nassuming the Exponential Time Hypothesis [Marx'07].\n  In this paper, we demonstrate the existence of maximally hard pattern graphs\n$H$ that require time $n^{tw(H)+1-o(1)}$. Specifically, under the Strong\nExponential Time Hypothesis (SETH), a standard assumption from fine-grained\ncomplexity theory, we prove the following asymptotic statement for large\ntreewidth $t$: For any $\\varepsilon > 0$ there exists $t \\ge 3$ and a pattern\ngraph $H$ of treewidth $t$ such that Subgraph Isomorphism on pattern $H$ has no\nalgorithm running in time $O(n^{t+1-\\varepsilon})$.\n  Under the more recent 3-uniform Hyperclique hypothesis, we even obtain tight\nlower bounds for each specific treewidth $t \\ge 3$: For any $t \\ge 3$ there\nexists a pattern graph $H$ of treewidth $t$ such that for any $\\varepsilon>0$\nSubgraph Isomorphism on pattern $H$ has no algorithm running in time\n$O(n^{t+1-\\varepsilon})$.\n  In addition to these main results, we explore (1) colored and uncolored\nproblem variants (and why they are equivalent for most cases), (2) Subgraph\nIsomorphism for $tw < 3$, (3) Subgraph Isomorphism parameterized by pathwidth,\nand (4) a weighted problem variant.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 14:12:43 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Bringmann", "Karl", ""], ["Slusallek", "Jasper", ""]]}, {"id": "2105.05431", "submitter": "Silvano Colombo Tosatto", "authors": "Silvano Colombo Tosatto, Guido Governatori, Nick van Beest", "title": "Proving Regulatory Compliance: A Computational Complexity Analysis of\n  Elementary Variants", "comments": "submission for Funamenta Informaticae", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organisations model their processes using so-called business process models,\nto allow for verification of their correctness with respect to regulatory\nrequirements and business rules. Automated methods for checking compliance,\nhowever, have to deal with the high complexity of the requirements as well as\nthe significant size and quantity of process models in an organisation, which\nmay prevent process models from being checked efficiently and timely. This\npaper provides a computational complexity analysis of the problem of proving\nregulatory compliance of process models. We investigate the computational\ncomplexity of each variant of the problem resulting from a combination of three\nbinary properties associated to the regulatory framework, determining the\nregulatory requirements that a process model needs to follow to be compliant.\nThese binary properties are whether the framework contains one or multiple\nobligations, whether the obligations are global or conditional, and whether\nonly literals or formulae can be used to describe the obligations. For each\nvariant of the problem we study the computational complexity of proving full\ncompliance, partial compliance, and non-compliance. This analysis allows to\nunderstand the specific features of the problem leading to intractability\nissues, thus potentially guiding future research towards developing feasible\nsolutions for the problem in practical settings.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 05:04:18 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Tosatto", "Silvano Colombo", ""], ["Governatori", "Guido", ""], ["van Beest", "Nick", ""]]}, {"id": "2105.05500", "submitter": "Francois Le Gall", "authors": "Shuichi Hirahara and Fran\\c{c}ois Le Gall", "title": "Test of Quantumness with Small-Depth Quantum Circuits", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Brakerski, Christiano, Mahadev, Vazirani and Vidick (FOCS 2018) have\nshown how to construct a test of quantumness based on the learning with errors\n(LWE) assumption: a test that can be solved efficiently by a quantum computer\nbut cannot be solved by a classical polynomial-time computer under the LWE\nassumption. This test has lead to several cryptographic applications. In\nparticular, it has been applied to producing certifiable randomness from a\nsingle untrusted quantum device, self-testing a single quantum device and\ndevice-independent quantum key distribution.\n  In this paper, we show that this test of quantumness, and essentially all the\nabove applications, can actually be implemented by a very weak class of quantum\ncircuits: constant-depth quantum circuits combined with logarithmic-depth\nclassical computation. This reveals novel complexity-theoretic properties of\nthis fundamental test of quantumness and gives new concrete evidence of the\nsuperiority of small-depth quantum circuits over classical computation.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 08:16:20 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Hirahara", "Shuichi", ""], ["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "2105.05879", "submitter": "Dustin Mixon", "authors": "Tim Fuchs, David Gross, Felix Krahmer, Richard Kueng, Dustin G. Mixon", "title": "Sketching with Kerdock's crayons: Fast sparsifying transforms for\n  arbitrary linear maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given an arbitrary matrix $A\\in\\mathbb{R}^{n\\times n}$, we consider the\nfundamental problem of computing $Ax$ for any $x\\in\\mathbb{R}^n$ such that $Ax$\nis $s$-sparse. While fast algorithms exist for particular choices of $A$, such\nas the discrete Fourier transform, there is currently no $o(n^2)$ algorithm\nthat treats the unstructured case. In this paper, we devise a randomized\napproach to tackle the unstructured case. Our method relies on a representation\nof $A$ in terms of certain real-valued mutually unbiased bases derived from\nKerdock sets. In the preprocessing phase of our algorithm, we compute this\nrepresentation of $A$ in $O(n^3\\log n)$ operations. Next, given any unit vector\n$x\\in\\mathbb{R}^n$ such that $Ax$ is $s$-sparse, our randomized fast transform\nuses this representation of $A$ to compute the entrywise $\\epsilon$-hard\nthreshold of $Ax$ with high probability in only $O(sn +\n\\epsilon^{-2}\\|A\\|_{2\\to\\infty}^2n\\log n)$ operations. In addition to a\nperformance guarantee, we provide numerical results that demonstrate the\nplausibility of real-world implementation of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 18:14:33 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Fuchs", "Tim", ""], ["Gross", "David", ""], ["Krahmer", "Felix", ""], ["Kueng", "Richard", ""], ["Mixon", "Dustin G.", ""]]}, {"id": "2105.05984", "submitter": "Nick Fischer", "authors": "Karl Bringmann, Nick Fischer, Vasileios Nakos", "title": "Sparse Nonnegative Convolution Is Equivalent to Dense Nonnegative\n  Convolution", "comments": "44 pages, appears in STOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computing the convolution $A\\star B$ of two length-$n$ vectors $A,B$ is an\nubiquitous computational primitive. Applications range from string problems to\nKnapsack-type problems, and from 3SUM to All-Pairs Shortest Paths. These\napplications often come in the form of nonnegative convolution, where the\nentries of $A,B$ are nonnegative integers. The classical algorithm to compute\n$A\\star B$ uses the Fast Fourier Transform and runs in time $O(n\\log n)$.\n  However, often $A$ and $B$ satisfy sparsity conditions, and hence one could\nhope for significant improvements. The ideal goal is an $O(k\\log k)$-time\nalgorithm, where $k$ is the number of non-zero elements in the output, i.e.,\nthe size of the support of $A\\star B$. This problem is referred to as sparse\nnonnegative convolution, and has received considerable attention in the\nliterature; the fastest algorithms to date run in time $O(k\\log^2 n)$.\n  The main result of this paper is the first $O(k\\log k)$-time algorithm for\nsparse nonnegative convolution. Our algorithm is randomized and assumes that\nthe length $n$ and the largest entry of $A$ and $B$ are subexponential in $k$.\nSurprisingly, we can phrase our algorithm as a reduction from the sparse case\nto the dense case of nonnegative convolution, showing that, under some mild\nassumptions, sparse nonnegative convolution is equivalent to dense nonnegative\nconvolution for constant-error randomized algorithms. Specifically, if $D(n)$\nis the time to convolve two nonnegative length-$n$ vectors with success\nprobability $2/3$, and $S(k)$ is the time to convolve two nonnegative vectors\nwith output size $k$ with success probability $2/3$, then\n$S(k)=O(D(k)+k(\\log\\log k)^2)$.\n  Our approach uses a variety of new techniques in combination with some old\nmachinery from linear sketching and structured linear algebra, as well as new\ninsights on linear hashing, the most classical hash function.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 21:58:37 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 11:59:01 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Bringmann", "Karl", ""], ["Fischer", "Nick", ""], ["Nakos", "Vasileios", ""]]}, {"id": "2105.06030", "submitter": "Dieyan Liang", "authors": "Dieyan Liang, Hong Shen", "title": "Changeable Sweep Coverage Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sweep coverage is to realize the periodic coverage of targets by planning the\nperiodic sweeping paths of mobile sensors. It is difficult for sensors to\nreduce energy consumption by reducing the moving distances. Therefore, charging\ntechnology is the best way to extend the lifetime of the sweep coverage\nnetwork. This paper studies the sweep coverage of rechargeable sensors: the\nsensors are rechargeable, constantly sweep between the target points and the\ncharging stations not only tp meet the periodic coverage requirement of the\ntarget points, but also need to return to the charging stations during the\ncharging period to avoid running out of energy. This paper proposes the general\ndefinition of Chargeable Sweep Coverage (CSC) problem for the first time, and\nstudies the complexity of the CSC problem by analyzing CSC problems under\ndifferent constraints, and then proposes two kinds of CSC problems under\nspecial constraints: 1) The sensors need to return to their original charging\nstations for charging; 2) The sensors can go to different charging stations for\ncharging, and the number of charging stations is 2. Both of these problems are\nNP-hard. In this paper, these two problems are modeled as the maximum set\ncoverage problem, and the approximation algorithms are obtained by reducing the\nnumber of candidate paths to polynomials. The validity and scalability of the\nproposed algorithms is proved by theoretical proof and experimental simulation.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 01:39:48 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Liang", "Dieyan", ""], ["Shen", "Hong", ""]]}, {"id": "2105.06349", "submitter": "Daniel Paulusma", "authors": "Walter Kern and Barnaby Martin and Dani\\\"el Paulusma and Siani Smith\n  and Erik Jan van Leeuwen", "title": "Disjoint Paths and Connected Subgraphs for H-Free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known Disjoint Paths problem is to decide if a graph contains k\npairwise disjoint paths, each connecting a different terminal pair from a set\nof k distinct pairs. We determine, with an exception of two cases, the\ncomplexity of the Disjoint Paths problem for $H$-free graphs. If $k$ is fixed,\nwe obtain the $k$-Disjoint Paths problem, which is known to be polynomial-time\nsolvable on the class of all graphs for every $k \\geq 1$. The latter does no\nlonger hold if we need to connect vertices from terminal sets instead of\nterminal pairs. We completely classify the complexity of $k$-Disjoint Connected\nSubgraphs for $H$-free graphs, and give the same almost-complete classification\nfor Disjoint Connected Subgraphs for $H$-free graphs as for Disjoint Paths.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 15:06:50 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Kern", "Walter", ""], ["Martin", "Barnaby", ""], ["Paulusma", "Dani\u00ebl", ""], ["Smith", "Siani", ""], ["van Leeuwen", "Erik Jan", ""]]}, {"id": "2105.06744", "submitter": "Navid Talebanfard", "authors": "Michal Kouck\\'y, Vojt\\v{e}ch R\\\"odl, Navid Talebanfard", "title": "A Separator Theorem for Hypergraphs and a CSP-SAT Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that for every $r \\ge 2$ there exists $\\epsilon_r > 0$ such that any\n$r$-uniform hypergraph on $m$ edges with bounded vertex degree has a set of at\nmost $(\\frac{1}{2} - \\epsilon_r)m$ edges the removal of which breaks the\nhypergraph into connected components with at most $m/2$ edges. We use this to\ngive an algorithm running in time $d^{(1 - \\epsilon_r)m}$ that decides\nsatisfiability of $m$-variable $(d, k)$-CSPs in which every variable appears in\nat most $r$ constraints, where $\\epsilon_r$ depends only on $r$ and $k\\in\no(\\sqrt{m})$. Furthermore our algorithm solves the corresponding #CSP-SAT and\nMax-CSP-SAT of these CSPs. We also show that CNF representations of\nunsatisfiable $(2, k)$-CSPs with variable frequency $r$ can be refuted in\ntree-like resolution in size $2^{(1 - \\epsilon_r)m}$. Furthermore for Tseitin\nformulas on graphs with degree at most $k$ (which are $(2, k)$-CSPs) we give a\ndeterministic algorithm finding such a refutation.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 10:09:18 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Kouck\u00fd", "Michal", ""], ["R\u00f6dl", "Vojt\u011bch", ""], ["Talebanfard", "Navid", ""]]}, {"id": "2105.06935", "submitter": "Mauro Mezzini", "authors": "Mauro Mezzini, Fernando L. Pelayo, Fernando Cuartero", "title": "Quantum algorithm for doubling the amplitude of the search problem's\n  solution states", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a quantum algorithm which increases the amplitude of\nthe states corresponding to the solutions of the search problem by a factor of\nalmost two.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 16:23:54 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Mezzini", "Mauro", ""], ["Pelayo", "Fernando L.", ""], ["Cuartero", "Fernando", ""]]}, {"id": "2105.07120", "submitter": "Akinori Kawachi", "authors": "Akinori Kawachi and Harumichi Nishimura", "title": "Communication Complexity of Private Simultaneous Quantum Messages\n  Protocols", "comments": "19 pages, to be published in Proc. ITC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The private simultaneous messages model is a non-interactive version of the\nmultiparty secure computation, which has been intensively studied to examine\nthe communication cost of the secure computation. We consider its quantum\ncounterpart, the private simultaneous quantum messages (PSQM) model, and\nexamine the advantages of quantum communication and prior entanglement of this\nmodel. In the PSQM model, $k$ parties $P_1,\\ldots,P_k$ initially share a common\nrandom string (or entangled states in a stronger setting), and they have\nprivate classical inputs $x_1,\\ldots, x_k$. Every $P_i$ generates a quantum\nmessage from the private input $x_i$ and the shared random string (entangled\nstates), and then sends it to the referee $R$. Receiving the messages, $R$\ncomputes $F(x_1,\\ldots,x_k)$. Then, $R$ learns nothing except for\n$F(x_1,\\ldots,x_k)$ as the privacy condition. We obtain the following results\nfor this PSQM model. (1) We demonstrate that the privacy condition inevitably\nincreases the communication cost in the two-party PSQM model as well as in the\nclassical case presented by Applebaum, Holenstein, Mishra, and Shayevitz. In\nparticular, we prove a lower bound $(3-o(1))n$ of the communication complexity\nin PSQM protocols with a shared random string for random Boolean functions of\n$2n$-bit input, which is larger than the trivial upper bound $2n$ of the\ncommunication complexity without the privacy condition. (2) We demonstrate a\nfactor two gap between the communication complexity of PSQM protocols with\nshared entangled states and with shared random strings by designing a\nmultiparty PSQM protocol with shared entangled states for a total function that\nextends the two-party equality function. (3) We demonstrate an exponential gap\nbetween the communication complexity of PSQM protocols with shared entangled\nstates and with shared random strings for a two-party partial function.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 03:08:01 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kawachi", "Akinori", ""], ["Nishimura", "Harumichi", ""]]}, {"id": "2105.07203", "submitter": "Grzegorz Kwasniewski", "authors": "Grzegorz Kwasniewski, Tal Ben-Nun, Lukas Gianinazzi, Alexandru\n  Calotoiu, Timo Schneider, Alexandros Nikolaos Ziogas, Maciej Besta, Torsten\n  Hoefler", "title": "Pebbles, Graphs, and a Pinch of Combinatorics: Towards Tight I/O Lower\n  Bounds for Statically Analyzable Programs", "comments": "13 pages, 4 figures, published at Proceedings of the 33rd ACM\n  Symposium on Parallelism in Algorithms and Architectures (SPAA'21)", "journal-ref": null, "doi": "10.1145/3409964.3461796", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining I/O lower bounds is a crucial step in obtaining\ncommunication-efficient parallel algorithms, both across the memory hierarchy\nand between processors. Current approaches either study specific algorithms\nindividually, disallow programmatic motifs such as recomputation, or produce\nasymptotic bounds that exclude important constants. We propose a novel approach\nfor obtaining precise I/O lower bounds on a general class of programs, which we\ncall Simple Overlap Access Programs (SOAP). SOAP analysis covers a wide variety\nof algorithms, from ubiquitous computational kernels to full scientific\ncomputing applications. Using the red-blue pebble game and combinatorial\nmethods, we are able to bound the I/O of the SOAP-induced Computational\nDirected Acyclic Graph (CDAG), taking into account multiple statements,\ninput/output reuse, and optimal tiling. To deal with programs that are outside\nof our representation (e.g., non-injective access functions), we describe\nmethods to approximate them with SOAP. To demonstrate our method, we analyze 38\ndifferent applications, including kernels from the Polybench benchmark suite,\ndeep learning operators, and -- for the first time -- applications in\nunstructured physics simulations, numerical weather prediction stencil\ncompositions, and full deep neural networks. We derive tight I/O bounds for\nseveral linear algebra kernels, such as Cholesky decomposition, improving the\nexisting reported bounds by a factor of two. For stencil applications, we\nimprove the existing bounds by a factor of up to 14. We implement our method as\nan open-source tool, which can derive lower bounds directly from provided C\ncode.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 11:35:00 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kwasniewski", "Grzegorz", ""], ["Ben-Nun", "Tal", ""], ["Gianinazzi", "Lukas", ""], ["Calotoiu", "Alexandru", ""], ["Schneider", "Timo", ""], ["Ziogas", "Alexandros Nikolaos", ""], ["Besta", "Maciej", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2105.07480", "submitter": "Dario Paccagnan", "authors": "Dario Paccagnan, Martin Gairing", "title": "In Congestion Games, Taxes Achieve Optimal Approximation", "comments": "To appear at the 22nd ACM Conference on Economics & Computation\n  (EC'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing social cost in atomic congestion games\nand show, perhaps surprisingly, that efficiently computed taxation mechanisms\nyield the same performance achievable by the best polynomial time algorithm,\neven when the latter has full control over the players' actions. It follows\nthat no other tractable approach geared at incentivizing desirable system\nbehavior can improve upon this result, regardless of whether it is based on\ntaxations, coordination mechanisms, information provision, or any other\nprinciple. In short: Judiciously chosen taxes achieve optimal approximation.\n  Three technical contributions underpin this conclusion. First, we show that\ncomputing the minimum social cost is NP-hard to approximate within a given\nfactor depending solely on the admissible resource costs. Second, we design a\ntractable taxation mechanism whose efficiency (price of anarchy) matches this\nhardness factor, and thus is optimal. As these results extend to coarse\ncorrelated equilibria, any no-regret algorithm inherits the same performances,\nallowing us to devise polynomial time algorithms with optimal approximation.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 16:45:52 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Paccagnan", "Dario", ""], ["Gairing", "Martin", ""]]}, {"id": "2105.07517", "submitter": "Peter Manohar", "authors": "Pravesh K. Kothari and Peter Manohar", "title": "A Stress-Free Sum-of-Squares Lower Bound for Coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that with high probability over the choice of a random graph $G$\nfrom the Erd\\H{o}s-R\\'enyi distribution $G(n,1/2)$, a natural\n$n^{O(\\varepsilon^2 \\log n)}$-time, degree $O(\\varepsilon^2 \\log n)$\nsum-of-squares semidefinite program cannot refute the existence of a valid\n$k$-coloring of $G$ for $k = n^{1/2 +\\varepsilon}$. Our result implies that the\nrefutation guarantee of the basic semidefinite program (a close variant of the\nLov\\'asz theta function) cannot be appreciably improved by a natural $o(\\log\nn)$-degree sum-of-squares strengthening, and this is tight up to a $n^{o(1)}$\nslack in $k$. To the best of our knowledge, this is the first lower bound for\ncoloring $G(n,1/2)$ for even a single round strengthening of the basic SDP in\nany SDP hierarchy.\n  Our proof relies on a new variant of instance-preserving non-pointwise\ncomplete reduction within SoS from coloring a graph to finding large\nindependent sets in it. Our proof is (perhaps surprisingly) short, simple and\ndoes not require complicated spectral norm bounds on random matrices with\ndependent entries that have been otherwise necessary in the proofs of many\nsimilar results [BHK+16, HKP+17, KB19, GJJ+20, MRX20].\n  Our result formally holds for a constraint system where vertices are allowed\nto belong to multiple color classes; we leave the extension to the formally\nstronger formulation of coloring, where vertices must belong to unique colors\nclasses, as an outstanding open problem.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 21:28:34 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kothari", "Pravesh K.", ""], ["Manohar", "Peter", ""]]}, {"id": "2105.07525", "submitter": "Tuomas Hakoniemi", "authors": "Tuomas Hakoniemi", "title": "Monomial-size vs. Bit-complexity in Sums-of-Squares and Polynomial\n  Calculus", "comments": "To appear in the Proceedings of the 36th Annual ACM/IEEE Symposium on\n  Logic in Computer Science (LICS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we consider the relationship between monomial-size and\nbit-complexity in Sums-of-Squares (SOS) in Polynomial Calculus Resolution over\nrationals (PCR/$\\mathbb{Q}$). We show that there is a set of polynomial\nconstraints $Q_n$ over Boolean variables that has both SOS and PCR/$\\mathbb{Q}$\nrefutations of degree 2 and thus with only polynomially many monomials, but for\nwhich any SOS or PCR/$\\mathbb{Q}$ refutation must have exponential\nbit-complexity, when the rational coefficients are represented with their\nreduced fractions written in binary.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 21:50:31 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Hakoniemi", "Tuomas", ""]]}, {"id": "2105.07529", "submitter": "Nikita Kurilenko", "authors": "Nikita V. Kurilenko", "title": "Infinitely growing configurations in Emil Post's tag system problem", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Emil Post's tag system problem is the question of whether or not a tag system\n$\\{N=3, P(0)=00, P(1)=1101\\}$ has a configuration, simulation of which will\nnever halt or end up in a loop. For the past decades, there were several\nattempts to find an answer to this question, including a recent study by\nWolfram (2021), during which the first $2^{84}$ initial configurations were\nchecked. This paper presents a family of configurations of this type in a form\nof strings $a^{n} b c^{m}$, that evolve to $a^{n+1} b c^{m+1}$ after a finite\namount of steps. The proof of this behavior for all non-negative $n$ and $m$ is\ndescribed further in a paper as a finite verification procedure, which is\ncomputationally bounded by 20000 iterations of tag. All corresponding code can\nbe found at\nhttps://github.com/nikitakurilenko/post-tag-infinitely-growing-configurations.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 22:12:10 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kurilenko", "Nikita V.", ""]]}, {"id": "2105.07531", "submitter": "Iddo Tzameret", "authors": "Fedor Part, Neil Thapen, Iddo Tzameret", "title": "First-Order Reasoning and Efficient Semi-Algebraic Proofs", "comments": "A preliminary version of this work appears in 36th Ann. Symp. Logic\n  Comput. Science (LICS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semi-algebraic proof systems such as sum-of-squares (SoS) have attracted a\nlot of attention recently due to their relation to approximation algorithms:\nconstant degree semi-algebraic proofs lead to conjecturally optimal\npolynomial-time approximation algorithms for important NP-hard optimization\nproblems. Motivated by the need to allow a more streamlined and uniform\nframework for working with SoS proofs than the restrictive propositional level,\nwe initiate a systematic first-order logical investigation into the kinds of\nreasoning possible in algebraic and semi-algebraic proof systems. Specifically,\nwe develop first-order theories that capture in a precise manner constant\ndegree algebraic and semi-algebraic proof systems: every statement of a certain\nform that is provable in our theories translates into a family of constant\ndegree polynomial calculus or SoS refutations, respectively; and using a\nreflection principle, the converse also holds.\n  This places algebraic and semi-algebraic proof systems in the established\nframework of bounded arithmetic, while providing theories corresponding to\nsystems that vary quite substantially from the usual propositional-logic ones.\n  We give examples of how our semi-algebraic theory proves statements such as\nthe pigeonhole principle, we provide a separation between algebraic and\nsemi-algebraic theories, and we describe initial attempts to go beyond these\ntheories by introducing extensions that use the inequality symbol, identifying\nalong the way which extensions lead outside the scope of constant degree SoS.\nMoreover, we prove new results for propositional proofs, and specifically\nextend Berkholz's dynamic-by-static simulation of polynomial calculus (PC) by\nSoS to PC with the radical rule.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 22:20:55 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 23:23:58 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Part", "Fedor", ""], ["Thapen", "Neil", ""], ["Tzameret", "Iddo", ""]]}, {"id": "2105.08309", "submitter": "Leila Taghavi", "authors": "Salman Beigi, Leila Taghavi, Artin Tajdini", "title": "Time and Query Optimal Quantum Algorithms Based on Decision Trees", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has recently been shown that starting with a classical query algorithm\n(decision tree) and a guessing algorithm that tries to predict the query\nanswers, we can design a quantum algorithm with query complexity $O(\\sqrt{GT})$\nwhere $T$ is the query complexity of the classical algorithm (depth of the\ndecision tree) and $G$ is the maximum number of wrong answers by the guessing\nalgorithm [arXiv:1410.0932, arXiv:1905.13095]. In this paper we show that,\ngiven some constraints on the classical algorithms, this quantum algorithm can\nbe implemented in time $\\tilde O(\\sqrt{GT})$. Our algorithm is based on\nnon-binary span programs and their efficient implementation. We conclude that\nvarious graph theoretic problems including bipartiteness, cycle detection and\ntopological sort can be solved in time $O(n^{3/2}\\log n)$ and with $O(n^{3/2})$\nquantum queries. Moreover, finding a maximal matching can be solved with\n$O(n^{3/2})$ quantum queries in time $O(n^{3/2}\\log n)$, and maximum bipartite\nmatching can be solved in time $O(n^2\\log n)$.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 06:51:11 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Beigi", "Salman", ""], ["Taghavi", "Leila", ""], ["Tajdini", "Artin", ""]]}, {"id": "2105.08356", "submitter": "Guillaume Theyssier", "authors": "Mart\\'in R\\'ios Wilson (LIS), Guillaume Theyssier (I2M)", "title": "On Symmetry versus Asynchronism: at the Edge of Universality in Automata\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automata network (AN) is a finite graph where each node holds a state from\na finite alphabet and is equipped with a local map defining the evolution of\nthe state of the node depending on its neighbors. The global dynamics of the\nnetwork is then induced by an update scheme describing which nodes are updated\nat each time step. We study how update schemes can compensate the limitations\ncoming from symmetric local interactions. Our approach is based on intrinsic\nsimulations and universality and we study both dynamical and computational\ncomplexity. By considering several families of concrete symmetric AN under\nseveral different update schemes, we explore the edge of universality in this\ntwo-dimensional landscape. On the way, we develop a proof technique based on an\noperation of glueing of networks, which allows to produce complex orbits in\nlarge networks from compatible pseudo-orbits in small networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 08:28:45 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Wilson", "Mart\u00edn R\u00edos", "", "LIS"], ["Theyssier", "Guillaume", "", "I2M"]]}, {"id": "2105.08490", "submitter": "Noleen K\\\"ohler", "authors": "Isolde Adler, Noleen K\\\"ohler and Pan Peng", "title": "GSF-locality is not sufficient for proximity-oblivious testing", "comments": "28 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Property Testing, proximity-oblivious testers (POTs) form a class of\nparticularly simple testing algorithms, where a basic test is performed a\nnumber of times that may depend on the proximity parameter, but the basic test\nitself is independent of the proximity parameter. In their seminal work,\nGoldreich and Ron [STOC 2009; SICOMP 2011] show that the graph properties that\nallow constant-query proximity-oblivious testing in the bounded-degree model\nare precisely the properties that can be expressed as a generalised subgraph\nfreeness (GSF) property that satisfies the non-propagation condition. It is\nleft open whether the non-propagation condition is necessary. Indeed, calling\nproperties expressible as a generalised subgraph freeness property GSF-local\nproperties, they ask whether all GSF-local properties are non-propagating. We\ngive a negative answer by exhibiting a property of graphs that is GSF-local and\npropagating. Hence in particular, our property does not admit a POT, despite\nbeing GSF-local. We prove our result by exploiting a recent work of the authors\nwhich constructed a first-order (FO) property that is not testable [SODA 2021],\nand a new connection between FO properties and GSF-local properties via\nneighbourhood profiles.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 13:08:35 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Adler", "Isolde", ""], ["K\u00f6hler", "Noleen", ""], ["Peng", "Pan", ""]]}, {"id": "2105.08540", "submitter": "Zack Fitzsimmons", "authors": "Zack Fitzsimmons and Edith Hemaspaandra", "title": "Kemeny Consensus Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational study of election problems generally focuses on questions\nrelated to the winner or set of winners of an election. But social preference\nfunctions such as Kemeny rule output a full ranking of the candidates (a\nconsensus). We study the complexity of consensus-related questions, with a\nparticular focus on Kemeny and its qualitative version Slater. The simplest of\nthese questions is the problem of determining whether a ranking is a consensus,\nand we show that this problem is coNP-complete. We also study the natural\nquestion of the complexity of manipulative actions that have a specific\nconsensus as a goal. Though determining whether a ranking is a Kemeny consensus\nis hard, the optimal action for manipulators is to simply vote their desired\nconsensus. We provide evidence that this simplicity is caused by the\ncombination of election system (Kemeny), manipulative action (manipulation),\nand manipulative goal (consensus). In the process we provide the first\ncompleteness results at the second level of the polynomial hierarchy for\nelectoral manipulation and for optimal solution recognition.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 14:15:03 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Fitzsimmons", "Zack", ""], ["Hemaspaandra", "Edith", ""]]}, {"id": "2105.08549", "submitter": "Anthony Perez", "authors": "Ma\\\"el Dumas, Anthony Perez, Ioan Todinca", "title": "A cubic vertex-kernel for Trivially Perfect Editing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the Trivially Perfect Editing problem, where one is given an\nundirected graph $G = (V,E)$ and a parameter $k \\in \\mathbb{N}$ and seeks to\nedit (add or delete) at most $k$ edges from $G$ to obtain a trivially perfect\ngraph. The related Trivially Perfect Completion and Trivially Perfect Deletion\nproblems are obtained by only allowing edge additions or edge deletions,\nrespectively. Trivially perfect graphs are both chordal and cographs, and have\napplications related to the tree-depth width parameter and to social network\nanalysis. All variants of the problem are known to be NP-Complete and to admit\nso-called polynomial kernels. More precisely, the existence of an $O(k^3)$\nvertex-kernel for Trivially Perfect Completion was announced by Guo (ISAAC\n2007) but without a stand-alone proof. More recently, Drange and Pilipczuk\n(Algorithmica 2018) provided $O(k^7)$ vertex-kernels for these problems and\nleft open the existence of cubic vertex-kernels. In this work, we answer\npositively to this question for all three variants of the problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 14:35:12 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Dumas", "Ma\u00ebl", ""], ["Perez", "Anthony", ""], ["Todinca", "Ioan", ""]]}, {"id": "2105.08675", "submitter": "Christoph Hertrich", "authors": "Vincent Froese, Christoph Hertrich, Rolf Niedermeier", "title": "The Computational Complexity of ReLU Network Training Parameterized by\n  Data Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the computational complexity of training simple neural networks\nwith rectified linear units (ReLUs) has recently been a subject of intensive\nresearch. Closing gaps and complementing results from the literature, we\npresent several results on the parameterized complexity of training two-layer\nReLU networks with respect to various loss functions. After a brief discussion\nof other parameters, we focus on analyzing the influence of the dimension $d$\nof the training data on the computational complexity. We provide running time\nlower bounds in terms of W[1]-hardness for parameter $d$ and prove that known\nbrute-force strategies are essentially optimal (assuming the Exponential Time\nHypothesis). In comparison with previous work, our results hold for a broad(er)\nrange of loss functions, including $\\ell^p$-loss for all $p\\in[0,\\infty]$. In\nparticular, we extend a known polynomial-time algorithm for constant $d$ and\nconvex loss functions to a more general class of loss functions, matching our\nrunning time lower bounds also in these cases.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:05:26 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 08:32:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Froese", "Vincent", ""], ["Hertrich", "Christoph", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "2105.08980", "submitter": "Philipp Schepper", "authors": "D\\'aniel Marx, Govind S. Sankar, Philipp Schepper", "title": "Degrees and Gaps: Tight Complexity Results of General Factor Problems\n  Parameterized by Treewidth and Cutwidth", "comments": "Full version of the paper accepted for ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For the General Factor problem we are given an undirected graph $G$ and for\neach vertex $v\\in V(G)$ a finite set $B_v$ of non-negative integers. The task\nis to decide if there is a subset $S\\subseteq E(G)$ such that $deg_S(v)\\in B_v$\nfor all vertices $v$ of $G$. The maxgap of a finite integer set $B$ is the\nlargest $d\\ge 0$ such that there is an $a\\ge 0$ with $[a,a+d+1]\\cap\nB=\\{a,a+d+1\\}$. Cornu\\'ejols (1988) showed that if the maxgap of all sets $B_v$\nis at most 1, then the decision version of General Factor is poly-time\nsolvable. Dudycz and Paluch (2018) extended this result for the minimization\nand maximization versions. Using convolution techniques from van Rooij (2020),\nwe improve upon the previous algorithm by Arulselvan et al. (2018) and present\nan algorithm counting the number of solutions of a certain size in time\n$O^*((M+1)^k)$, given a tree decomposition of width $k$, where $M=\\max_v \\max\nB_v$.\n  We prove that this algorithm is essentially optimal for all cases that are\nnot polynomial time solvable for the decision, minimization or maximization\nversions. We prove that such improvements are not possible even for $B$-Factor,\nwhich is General Factor on graphs where all sets $B_v$ agree with the fixed set\n$B$. We show that for every fixed $B$ where the problem is NP-hard, our new\nalgorithm cannot be significantly improved: assuming the Strong Exponential\nTime Hypothesis (SETH), no algorithm can solve $B$-Factor in time $O^*((\\max\nB+1-\\epsilon)^k)$ for any $\\epsilon>0$. We extend this bound to the counting\nversion of $B$-Factor for arbitrary, non-trivial sets $B$, assuming #SETH.\n  We also investigate the parameterization of the problem by cutwidth. Unlike\nfor treewidth, a larger set $B$ does not make the problem harder: Given a\nlinear layout of width $k$ we give a $O^*(2^k)$ algorithm for any $B$ and\nprovide a matching lower bound that this is optimal for the NP-hard cases.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 08:26:18 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Marx", "D\u00e1niel", ""], ["Sankar", "Govind S.", ""], ["Schepper", "Philipp", ""]]}, {"id": "2105.09145", "submitter": "Thomas Orton", "authors": "Thomas Orton", "title": "Modeling Precomputation In Games Played Under Computational Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the properties of games played under computational constraints\nremains challenging. For example, how do we expect rational (but\ncomputationally bounded) players to play games with a prohibitively large\nnumber of states, such as chess? This paper presents a novel model for the\nprecomputation (preparing moves in advance) aspect of computationally\nconstrained games. A fundamental trade-off is shown between randomness of play,\nand susceptibility to precomputation, suggesting that randomization is\nnecessary in games with computational constraints. We present efficient\nalgorithms for computing how susceptible a strategy is to precomputation, and\ncomputing an $\\epsilon$-Nash equilibrium of our model. Numerical experiments\nmeasuring the trade-off between randomness and precomputation are provided for\nStockfish (a well-known chess playing algorithm).\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 14:06:46 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Orton", "Thomas", ""]]}, {"id": "2105.10742", "submitter": "Ajinkya Ramdas Gaikwad", "authors": "Ajinkya Gaikwad, Soumen Maity, Shuvam Kant Tripathi", "title": "Parameterized Complexity of Locally Minimal Defensive Alliances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Defensive Alliance problem has been studied extensively during the last\ntwenty years. A set $S$ of vertices of a graph is a defensive alliance if, for\neach element of $S$, the majority of its neighbours is in $S$. We consider the\nnotion of local minimality in this paper. We are interested in locally minimal\ndefensive alliance of maximum size. This problem is known to be NP-hard but its\nparameterized complexity remains open until now. We enhance our understanding\nof the problem from the viewpoint of parameterized complexity. The main results\nof the paper are the following: (1) when the input graph happens to be a tree,\nConnected Locally Minimal Strong Defensive Alliance} can be solved in\npolynomial time, (2) the Locally Minimal Defensive Alliance problem is\nNP-complete, even when restricted to planar graphs, (3) a color coding\nalgorithm for Exact Connected Locally Minimal Defensive Alliance, (4) the\nLocally Minimal Defensive Alliance problem is fixed parameter tractable (FPT)\nwhen parametrized by neighbourhood diversity, (5) the Exact Connected Locally\nMinimal Defensive Alliance problem parameterized by treewidth is W[1]-hard and\nthus not FPT (unless FPT=W[1]), (6) Locally Minimal Defensive Alliance can be\nsolved in polynomial time for graphs of bounded treewidth.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 14:59:40 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Gaikwad", "Ajinkya", ""], ["Maity", "Soumen", ""], ["Tripathi", "Shuvam Kant", ""]]}, {"id": "2105.11250", "submitter": "Subhashis Majumder", "authors": "Biswajit Sanyal, Subhashis Majumder, Priya Ranjan Sinha Mahapatra", "title": "Efficient Reporting of Top-k Subset Sums", "comments": "21 pages, 7 figures, 2 tables, 2 algorithms, 3 functions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer science, the \"Subset Sum problem\" is a very well known\nNP-complete problem. In this article, we consider its top-k variation - the\n\"Top-k Subset Sums problem\" that has wide application in recommendation\nsystems, where instead of k best objects they require k best subsets of objects\nwith lowest (or highest) overall scores. Given any input set R of n real\nnumbers, and a positive integer k, our target is to generate the k best subsets\n(top-k Subset Sums) of R, whose sum of elements is minimized. The direct\nsolution for this problem is prohibitively expensive since it requires\nenumerating all the possible subsets, which is exponential to the value of n.\nIn this article, our method is based on constructing a metadata structure G for\nn. Each node of G stores a bit vector of size n from which a subset of R can be\nretrieved. We finally show that we do not need to explicitly construct G as a\nwhole, rather to answer a query, we traverse only the required portion of G on\ndemand that obviously helps to bypass the high space requirement of the\npre-processing step.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 13:01:18 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Sanyal", "Biswajit", ""], ["Majumder", "Subhashis", ""], ["Mahapatra", "Priya Ranjan Sinha", ""]]}, {"id": "2105.11845", "submitter": "Ivo Fagundes David De Oliveira", "authors": "I. F. D. Oliveira and R. H. C. Takahashi", "title": "An incremental descent method for multi-objective optimization", "comments": "paper pre-submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current state-of-the-art multi-objective optimization solvers, by computing\ngradients of all $m$ objective functions per iteration, produce after $k$\niterations a measure of proximity to critical conditions that is upper-bounded\nby $O(1/\\sqrt{k})$ when the objective functions are assumed to have\n$L-$Lipschitz continuous gradients; i.e. they require $O(m/\\epsilon^2)$\ngradient and function computations to produce a measure of proximity to\ncritical conditions bellow some target $\\epsilon$. We reduce this to\n$O(1/\\epsilon^2)$ with a method that requires only a constant number of\ngradient and function computations per iteration; and thus, we obtain for the\nfirst time a multi-objective descent-type method with a query complexity cost\nthat is unaffected by increasing values of $m$. For this, a brand new\nmulti-objective descent direction is identified, which we name the\n\\emph{central descent direction}, and, an incremental approach is proposed.\nRobustness properties of the central descent direction are established,\nmeasures of proximity to critical conditions are derived, and, the incremental\nstrategy for finding solutions to the multi-objective problem is shown to\nattain convergence properties unattained by previous methods. To the best of\nour knowledge, this is the first method to achieve this with no additional\na-priori information on the structure of the problem, such as done by\nscalarizing techniques, and, with no pre-known information on the regularity of\nthe objective functions other than Lipschitz continuity of the gradients.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 11:39:02 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Oliveira", "I. F. D.", ""], ["Takahashi", "R. H. C.", ""]]}, {"id": "2105.11919", "submitter": "Ivo Fagundes David De Oliveira", "authors": "I. F. D. Oliveira and R. H. C. Takahashi", "title": "Minmax-optimal list searching with $O(\\log_2\\log_2 n)$ average cost", "comments": "under consideration by the Journal of Computer and System Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We find a searching method on ordered lists that surprisingly outperforms\nbinary searching with respect to average query complexity while retaining\nminmax optimality. The method is shown to require $O(\\log_2\\log_2 n)$ queries\non average while never exceeding $\\lceil \\log_2 n \\rceil$ queries in the worst\ncase, i.e. the minmax bound of binary searching. Our average results assume a\nuniform distribution hypothesis similar to those of prevous authors under which\nthe expected query complexity of interpolation search of $O(\\log_2\\log_2 n)$ is\nknown to be optimal. Hence our method turns out to be optimal with respect to\nboth minmax and average performance. We further provide robustness guarantees\nand perform several numerical experiments with both artificial and real data.\nOur results suggest that time savings range roughly from a constant factor of\n10\\% to 50\\% to a logarithmic factor spanning orders of magnitude when\ndifferent metrics are considered.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 13:22:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Oliveira", "I. F. D.", ""], ["Takahashi", "R. H. C.", ""]]}, {"id": "2105.11996", "submitter": "Navid Talebanfard", "authors": "Pavel Hrube\\v{s}, Navid Talebanfard", "title": "On the extension complexity of polytopes separating subsets of the\n  Boolean cube", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that\n  1. for every $A\\subseteq \\{0, 1\\}^n$, there exists a polytope $P\\subseteq\n\\mathbb{R}^n$ with $P \\cap \\{0, 1\\}^n = A$ and extension complexity\n$O(2^{n/2})$,\n  2. there exists an $A\\subseteq \\{0, 1\\}^n$ such that the extension complexity\nof any $P$ with $P\\cap \\{0, 1\\}^n = A$ must be at least\n$2^{\\frac{n}{3}(1-o(1))}$.\n  We also remark that the extension complexity of any 0/1-polytope in\n$\\mathbb{R}^n$ is at most $O(2^n/n)$ and pose the problem whether the upper\nbound can be improved to $O(2^{cn})$, for $c<1$.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:59:02 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Hrube\u0161", "Pavel", ""], ["Talebanfard", "Navid", ""]]}, {"id": "2105.12237", "submitter": "Yatong Bai", "authors": "Yatong Bai, Tanmay Gautam, Yu Gai, Somayeh Sojoudi", "title": "Practical Convex Formulation of Robust One-hidden-layer Neural Network\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that the training of a one-hidden-layer, scalar-output\nfully-connected ReLU neural network can be reformulated as a finite-dimensional\nconvex program. Unfortunately, the scale of such a convex program grows\nexponentially in data size. In this work, we prove that a stochastic procedure\nwith a linear complexity well approximates the exact formulation. Moreover, we\nderive a convex optimization approach to efficiently solve the \"adversarial\ntraining\" problem, which trains neural networks that are robust to adversarial\ninput perturbations. Our method can be applied to binary classification and\nregression, and provides an alternative to the current adversarial training\nmethods, such as Fast Gradient Sign Method (FGSM) and Projected Gradient\nDescent (PGD). We demonstrate in experiments that the proposed method achieves\na noticeably better adversarial robustness and performance than the existing\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 22:06:27 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Bai", "Yatong", ""], ["Gautam", "Tanmay", ""], ["Gai", "Yu", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "2105.12994", "submitter": "Danijela Protic", "authors": "Danijela Protic and Miomir Stankovic", "title": "The q-Gauss-Newton method for unconstrained nonlinear optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A q-Gauss-Newton algorithm is an iterative procedure that solves nonlinear\nunconstrained optimization problems based on minimization of the sum squared\nerrors of the objective function residuals. Main advantage of the algorithm is\nthat it approximates matrix of q-second order derivatives with the first-order\nq-Jacobian matrix. For that reason, the algorithm is much faster than\nq-steepest descent algorithms. The convergence of q-GN method is assured only\nwhen the initial guess is close enough to the solution. In this paper the\ninfluence of the parameter q to the non-linear problem solving is presented\nthrough three examples. The results show that the q-GD algorithm finds an\noptimal solution and speeds up the iterative procedure.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 08:28:48 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Protic", "Danijela", ""], ["Stankovic", "Miomir", ""]]}, {"id": "2105.13615", "submitter": "Amir Yehudayoff", "authors": "Gal Yehuda and Amir Yehudayoff", "title": "A lower bound for essential covers of the cube", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Essential covers were introduced by Linial and Radhakrishnan as a model that\ncaptures two complementary properties: (1) all variables must be included and\n(2) no element is redundant. In their seminal paper, they proved that every\nessential cover of the $n$-dimensional hypercube must be of size at least\n$\\Omega(n^{0.5})$. Later on, this notion found several applications in\ncomplexity theory. We improve the lower bound to $\\Omega(n^{0.52})$, and\ndescribe two applications.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 06:52:52 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Yehuda", "Gal", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "2105.14369", "submitter": "Walter Forkel", "authors": "Stefan Borgwardt, Walter Forkel, Alisa Kovtunova", "title": "Temporal Minimal-World Semantics for Sparse ABoxes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-mediated query answering is a popular paradigm for enriching answers\nto user queries with background knowledge. For querying the absence of\ninformation, however, there exist only few ontology-based approaches. Moreover,\nthese proposals conflate the closed-domain and closed-world assumption, and\ntherefore are not suited to deal with the anonymous objects that are common in\nontological reasoning. Many real-world applications, like processing electronic\nhealth records (EHRs), also contain a temporal dimension, and require efficient\nreasoning algorithms. Moreover, since medical data is not recorded on a regular\nbasis, reasoners must deal with sparse data with potentially large temporal\ngaps. Our contribution consists of two main parts: In the first part we\nintroduce a new closed-world semantics for answering conjunctive queries with\nnegation over ontologies formulated in the description logic ELHb, which is\nbased on the minimal canonical model. We propose a rewriting strategy for\ndealing with negated query atoms, which shows that query answering is possible\nin polynomial time in data complexity. In the second part, we extend this\nminimal-world semantics for answering metric temporal conjunctive queries with\nnegation over the lightweight temporal logic TELHb and obtain similar\nrewritability and complexity results. This paper is under consideration in\nTheory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 20:20:13 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Borgwardt", "Stefan", ""], ["Forkel", "Walter", ""], ["Kovtunova", "Alisa", ""]]}, {"id": "2105.14882", "submitter": "Carla Groenland", "authors": "Hans L. Bodlaender and Carla Groenland and Jesper Nederlof and\n  C\\'eline M. F. Swennenhuis", "title": "Parameterized Problems Complete for Nondeterministic FPT time and\n  Logarithmic Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let XNLP be the class of parameterized problems such that an instance of size\n$n$ with parameter $k$ can be solved nondeterministically in time\n$f(k)n^{O(1)}$ and space $f(k)\\log(n)$ (for some computable function $f$). We\ngive a wide variety of XNLP-complete problems, such as {\\sc List Coloring} and\n{\\sc Precoloring Extension} with pathwidth as parameter, {\\sc Scheduling of\nJobs with Precedence Constraints}, with both number of machines and partial\norder width as parameter, {\\sc Bandwidth} and variants of {\\sc Weighted\nCNF-Satisfiability} and reconfiguration problems. In particular, this implies\nthat all these problems are $W[t]$-hard for all $t$. This also answers a long\nstanding question on the parameterized complexity of the {\\sc Bandwidth}\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 11:08:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Groenland", "Carla", ""], ["Nederlof", "Jesper", ""], ["Swennenhuis", "C\u00e9line M. F.", ""]]}, {"id": "2105.14887", "submitter": "Yasir Mahmood", "authors": "Yasir Mahmood and Jonni Virtema", "title": "Parameterised Complexity of Propositional Logic in Team Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we analyse the parameterised complexity of propositional\ninclusion (PINC) and independence logic (PIND). The problems of interest are\nmodel checking (MC) and satisfiability (SAT). The complexity of these problems\nis well understood in the classical (non-parameterised) setting. Mahmood and\nMeier (FoIKS 2020) recently studied the parameterised complexity of\npropositional dependence logic (PDL). As a continuation of their work, we\nclassify inclusion and independence logic and thereby come closer to completing\nthe picture with respect to the parametrised complexity for the three most\nstudied logics in the propositional team semantics setting. We present results\nfor each problem with respect to 8 different parameterisations. It turns out\nthat for a team-based logic L such that L-atoms can be evaluated in polynomial\ntime, then MC parameterised by teamsize is FPT. As a corollary, we get an FPT\nmembership under the following parameterisations: formula-size, formula-depth,\ntreewidth, and number of variables. The parameter teamsize shows interesting\nbehavior for SAT. For PINC, the parameter teamsize is not meaningful, whereas\nfor PDL and PIND the satisfiability is paraNP-complete. Finally, we prove that\nwhen parameterised by arity, both MC and SAT are paraNP-complete for each of\nthe considered logics.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 11:21:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Mahmood", "Yasir", ""], ["Virtema", "Jonni", ""]]}]