[{"id": "1811.00817", "submitter": "Miriam Backens", "authors": "Miriam Backens and Leslie Ann Goldberg", "title": "Holant clones and the approximability of conservative holant problems", "comments": "46+9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a theory of holant clones to capture the notion of\nexpressibility in the holant framework. Their role is analogous to the role\nplayed by functional clones in the study of weighted counting Constraint\nSatisfaction Problems. We explore the landscape of conservative holant clones\nand determine the situations in which a set $\\mathcal{F}$ of functions is\n\"universal in the conservative case\", which means that all functions are\ncontained in the holant clone generated by $\\mathcal{F}$ together with all\nunary functions. When $\\mathcal{F}$ is not universal in the conservative case,\nwe give concise generating sets for the clone. We demonstrate the usefulness of\nthe holant clone theory by using it to give a complete complexity-theory\nclassification for the problem of approximating the solution to conservative\nholant problems. We show that approximation is intractable exactly when\n$\\mathcal{F}$ is universal in the conservative case.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 11:01:09 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 17:08:47 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Backens", "Miriam", ""], ["Goldberg", "Leslie Ann", ""]]}, {"id": "1811.00824", "submitter": "Marc Goerigk", "authors": "Marc Goerigk and Stephen J. Maher", "title": "Generating Hard Instances for Robust Combinatorial Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DM cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While research in robust optimization has attracted considerable interest\nover the last decades, its algorithmic development has been hindered by several\nfactors. One of them is a missing set of benchmark instances that make\nalgorithm performance better comparable, and makes reproducing instances\nunnecessary. Such a benchmark set should contain hard instances in particular,\nbut so far, the standard approach to produce instances has been to sample\nvalues randomly from a uniform distribution.\n  In this paper we introduce a new method to produce hard instances for min-max\ncombinatorial optimization problems, which is based on an optimization model\nitself. Our approach does not make any assumptions on the problem structure and\ncan thus be applied to any combinatorial problem. Using the Selection and\nTraveling Salesman problems as examples, we show that it is possible to produce\ninstances which are up to 500 times harder to solve for a mixed-integer\nprogramming solver than the current state-of-the-art instances.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 11:20:04 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 16:16:07 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Goerigk", "Marc", ""], ["Maher", "Stephen J.", ""]]}, {"id": "1811.00970", "submitter": "Jakub Opr\\v{s}al", "authors": "Libor Barto, Jakub Bul\\'in, Andrei Krokhin, Jakub Opr\\v{s}al", "title": "Algebraic approach to promise constraint satisfaction", "comments": "Extended version (73 pages). Preliminary versions of parts of this\n  paper were published in the proceedings of STOC 2019 and LICS 2019", "journal-ref": "J. ACM 68, 4, Article 28 (July 2021), 66 pages", "doi": "10.1145/3457606", "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity and approximability of the constraint satisfaction problem\n(CSP) has been actively studied over the last 20 years. A new version of the\nCSP, the promise CSP (PCSP) has recently been proposed, motivated by open\nquestions about the approximability of variants of satisfiability and graph\ncolouring. The PCSP significantly extends the standard decision CSP. The\ncomplexity of CSPs with a fixed constraint language on a finite domain has\nrecently been fully classified, greatly guided by the algebraic approach, which\nuses polymorphisms --- high-dimensional symmetries of solution spaces --- to\nanalyse the complexity of problems. The corresponding classification for PCSPs\nis wide open and includes some long-standing open questions, such as the\ncomplexity of approximate graph colouring, as special cases.\n  The basic algebraic approach to PCSP was initiated by Brakensiek and\nGuruswami, and in this paper we significantly extend it and lift it from\nconcrete properties of polymorphisms to their abstract properties. We introduce\na new class of problems that can be viewed as algebraic versions of the (Gap)\nLabel Cover problem, and show that every PCSP with a fixed constraint language\nis equivalent to a problem of this form. This allows us to identify a \"measure\nof symmetry\" that is well suited for comparing and relating the complexity of\ndifferent PCSPs via the algebraic approach. We demonstrate how our theory can\nbe applied by improving the state-of-the-art in approximate graph colouring: we\nshow that, for any $k\\geq 3$, it is NP-hard to find a $(2k-1)$-colouring of a\ngiven $k$-colourable graph.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:35:36 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 14:38:43 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 11:42:46 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Barto", "Libor", ""], ["Bul\u00edn", "Jakub", ""], ["Krokhin", "Andrei", ""], ["Opr\u0161al", "Jakub", ""]]}, {"id": "1811.01216", "submitter": "Anindya De", "authors": "Anindya De, Ryan O'Donnell and Rocco Servedio", "title": "Learning sparse mixtures of rankings from noisy information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning an unknown mixture of $k$ rankings over $n$\nelements, given access to noisy samples drawn from the unknown mixture. We\nconsider a range of different noise models, including natural variants of the\n\"heat kernel\" noise framework and the Mallows model. For each of these noise\nmodels we give an algorithm which, under mild assumptions, learns the unknown\nmixture to high accuracy and runs in $n^{O(\\log k)}$ time. The best previous\nalgorithms for closely related problems have running times which are\nexponential in $k$.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 13:36:12 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["De", "Anindya", ""], ["O'Donnell", "Ryan", ""], ["Servedio", "Rocco", ""]]}, {"id": "1811.01220", "submitter": "Philippe Toint", "authors": "Coralia Cartis and Nick I. M. Gould and Philippe L. Toint", "title": "Sharp worst-case evaluation complexity bounds for arbitrary-order\n  nonconvex optimization with inexpensive constraints", "comments": "30 pages", "journal-ref": "SIAM Journal on Optimization,, vol. 30(1), pp. 513-541, 2020", "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.CC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide sharp worst-case evaluation complexity bounds for nonconvex\nminimization problems with general inexpensive constraints, i.e.\\ problems\nwhere the cost of evaluating/enforcing of the (possibly nonconvex or even\ndisconnected) constraints, if any, is negligible compared to that of evaluating\nthe objective function. These bounds unify, extend or improve all known upper\nand lower complexity bounds for unconstrained and convexly-constrained\nproblems. It is shown that, given an accuracy level $\\epsilon$, a degree of\nhighest available Lipschitz continuous derivatives $p$ and a desired optimality\norder $q$ between one and $p$, a conceptual regularization algorithm requires\nno more than $O(\\epsilon^{-\\frac{p+1}{p-q+1}})$ evaluations of the objective\nfunction and its derivatives to compute a suitably approximate $q$-th order\nminimizer. With an appropriate choice of the regularization, a similar result\nalso holds if the $p$-th derivative is merely H\\\"older rather than Lipschitz\ncontinuous. We provide an example that shows that the above complexity bound is\nsharp for unconstrained and a wide class of constrained problems, we also give\nreasons for the optimality of regularization methods from a worst-case\ncomplexity point of view, within a large class of algorithms that use the same\nderivative information.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 14:04:35 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Cartis", "Coralia", ""], ["Gould", "Nick I. M.", ""], ["Toint", "Philippe L.", ""]]}, {"id": "1811.01235", "submitter": "David Doty", "authors": "Amanda Belleville, David Doty, and David Soloveichik", "title": "Hardness of computing and approximating predicates and functions with\n  leaderless population protocols", "comments": "published in Proceedings of ICALP 2017", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2017.141", "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population protocols are a distributed computing model appropriate for\ndescribing massive numbers of agents with limited computational power. A\npopulation protocol \"has an initial leader\" if every valid initial\nconfiguration contains a single agent in a special \"leader\" state that helps to\ncoordinate the computation. Although the class of predicates and functions\ncomputable with probability 1 is the same whether or not there is an initial\nleader (semilinear functions and predicates), it is not known whether a leader\nis necessary for fast computation. Efficient population protocols are generally\ndefined as those computing in polylogarithmic in $n$ (parallel) time. We\nconsider leaderless population protocols, regarding the computation finished\nwhen a configuration is reached from which a different output is no longer\nreachable.\n  In this setting we show that a wide class of functions and predicates\ncomputable by population protocols are not efficiently computable (they require\nat least linear time to stabilize on a correct answer), nor are some linear\nfunctions even efficiently approximable. For example, the widely studied\nparity, majority, and equality predicates cannot be computed in sublinear time.\nMoreover, it requires at least linear time for a population protocol even to\napproximate any linear function with a coefficient outside of $\\mathbb{N}$: for\nsufficiently small $\\gamma > 0$, the output of a sublinear time protocol can\nstabilize outside the interval $f(m) (1 \\pm \\gamma)$ on infinitely many inputs\n$m$. We also show that it requires linear time to exactly compute a wide range\nof semilinear functions (e.g., $f(m)=m$ if $m$ is even and $2m$ if $m$ is odd).\n  Finally, we show that with a sufficiently large value of $\\gamma$, a\npopulation protocol can approximate any linear $f$ with nonnegative rational\ncoefficients, within approximation factor $\\gamma$, in $O(\\log n)$ time.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 15:36:30 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Belleville", "Amanda", ""], ["Doty", "David", ""], ["Soloveichik", "David", ""]]}, {"id": "1811.01313", "submitter": "Kasper Green Larsen", "authors": "Alireza Farhadi, MohammadTaghi Hajiaghayi, Kasper Green Larsen, Elaine\n  Shi", "title": "Lower Bounds for External Memory Integer Sorting via Network Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DB cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorting extremely large datasets is a frequently occuring task in practice.\nThese datasets are usually much larger than the computer's main memory; thus\nexternal memory sorting algorithms, first introduced by Aggarwal and Vitter\n(1988), are often used. The complexity of comparison based external memory\nsorting has been understood for decades by now, however the situation remains\nelusive if we assume the keys to be sorted are integers. In internal memory,\none can sort a set of $n$ integer keys of $\\Theta(\\lg n)$ bits each in $O(n)$\ntime using the classic Radix Sort algorithm, however in external memory, there\nare no faster integer sorting algorithms known than the simple comparison based\nones. In this paper, we present a tight conditional lower bound on the\ncomplexity of external memory sorting of integers. Our lower bound is based on\na famous conjecture in network coding by Li and Li, who conjectured that\nnetwork coding cannot help anything beyond the standard multicommodity flow\nrate in undirected graphs. The only previous work connecting the Li and Li\nconjecture to lower bounds for algorithms is due to Adler et al. Adler et al.\nindeed obtain relatively simple lower bounds for oblivious algorithms (the\nmemory access pattern is fixed and independent of the input data).\nUnfortunately obliviousness is a strong limitations, especially for integer\nsorting: we show that the Li and Li conjecture implies an $\\Omega(n \\log n)$\nlower bound for internal memory oblivious sorting when the keys are $\\Theta(\\lg\nn)$ bits. This is in sharp contrast to the classic (non-oblivious) Radix Sort\nalgorithm. Indeed going beyond obliviousness is highly non-trivial; we need to\nintroduce several new methods and involved techniques, which are of their own\ninterest, to obtain our tight lower bound for external memory integer sorting.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 02:41:43 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Farhadi", "Alireza", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Larsen", "Kasper Green", ""], ["Shi", "Elaine", ""]]}, {"id": "1811.01347", "submitter": "Hiroki Morizumi", "authors": "Hiroki Morizumi", "title": "Some Results on the Circuit Complexity of Bounded Width Circuits and\n  Nondeterministic Circuits", "comments": "Major revision (1st part, new: 2nd part, almost same to v1: 3rd part,\n  revised)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider bounded width circuits and nondeterministic\ncircuits in three somewhat new directions. In the first part of this paper, we\nmainly consider bounded width circuits. The main purpose of this part is to\nprove that there is a Boolean function $f$ which cannot be computed by any\nnondeterministic circuit of size $O(n)$ and width $o(n)$. To the best of our\nknowledge, this is the first result on the lower bound of (nonuniform) bounded\nwidth circuits computing an explicit Boolean function, even for deterministic\ncircuits. Actually, we prove a more generalized lower bound. Our proof outline\nfor the lower bound also provides a satisfiability algorithm for\nnondeterministic bounded width circuits. In the second part of this paper, we\nconsider the power of nondeterministic circuits. We prove that there is a\nBoolean function $f$ such that the nondeterministic $U_2$-circuit complexity of\n$f$ is at most $2n + o(n)$ and the deterministic $U_2$-circuit complexity of\n$f$ is $3n - o(n)$. This is the first separation on the power of deterministic\nand nondeterministic circuits for general circuits. In the third part of this\npaper, we show a relation between deterministic bounded width circuits and\nnondeterministic bounded width circuits. As the main consequence, we prove that\n$\\mathsf{L/quasipoly} \\supseteq \\mathsf{NL/poly}$. As a corollary, we obtain\nthat $\\mathsf{L/quasipoly} \\supset \\mathsf{NL}$. To the best of our knowledge,\nthis is the first result on $\\mathsf{L}$ with large (more precisely,\nsuperpolynomial size) advice.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 10:25:25 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 05:50:02 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Morizumi", "Hiroki", ""]]}, {"id": "1811.01351", "submitter": "Albert Atserias", "authors": "Albert Atserias and Tuomas Hakoniemi", "title": "Size-Degree Trade-Offs for Sums-of-Squares and Positivstellensatz Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if a system of degree-$k$ polynomial constraints on~$n$ Boolean\nvariables has a Sums-of-Squares (SOS) proof of unsatisfiability with at\nmost~$s$ many monomials, then it also has one whose degree is of the order of\nthe square root of~$n \\log s$ plus~$k$. A similar statement holds for the more\ngeneral Positivstellensatz (PS) proofs. This establishes size-degree trade-offs\nfor SOS and PS that match their analogues for weaker proof systems such as\nResolution, Polynomial Calculus, and the proof systems for the LP and SDP\nhierarchies of Lov\\'asz and Schrijver. As a corollary to this, and to the known\ndegree lower bounds, we get optimal integrality gaps for exponential size SOS\nproofs for sparse random instances of the standard NP-hard constraint\noptimization problems. We also get exponential size SOS lower bounds for\nTseitin and Knapsack formulas. The proof of our main result relies on a\nzero-gap duality theorem for pre-ordered vector spaces that admit an order\nunit, whose specialization to PS and SOS may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 11:45:21 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 14:49:15 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Atserias", "Albert", ""], ["Hakoniemi", "Tuomas", ""]]}, {"id": "1811.01427", "submitter": "Hadley Black", "authors": "Hadley Black, Deeparnab Chakrabarty, C. Seshadhri", "title": "Domain Reduction for Monotonicity Testing: A $o(d)$ Tester for Boolean\n  Functions in $d$-Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a $\\tilde{O}(d^{5/6})$-query monotonicity tester for Boolean\nfunctions $f:[n]^d \\to \\{0,1\\}$ on the $n$-hypergrid. This is the first $o(d)$\nmonotonicity tester with query complexity independent of $n$. Motivated by this\nindependence of $n$, we initiate the study of monotonicity testing of\nmeasurable Boolean functions $f:\\mathbb{R}^d \\to \\{0,1\\}$ over the continuous\ndomain, where the distance is measured with respect to a product distribution\nover $\\mathbb{R}^d$. We give a $\\tilde{O}(d^{5/6})$-query monotonicity tester\nfor such functions.\n  Our main technical result is a domain reduction theorem for monotonicity. For\nany function $f:[n]^d \\to \\{0,1\\}$, let $\\epsilon_f$ be its distance to\nmonotonicity. Consider the restriction $\\hat{f}$ of the function on a random\n$[k]^d$ sub-hypergrid of the original domain. We show that for $k =\n\\text{poly}(d/\\epsilon)$, the expected distance of the restriction is\n$\\mathbb{E}[\\epsilon_{\\hat{f}}] = \\Omega(\\epsilon_f)$. Previously, such a\nresult was only known for $d=1$ (Berman-Raskhodnikova-Yaroslavtsev, STOC 2014).\nOur result for testing Boolean functions over $[n]^d$ then follows by applying\nthe $d^{5/6}\\cdot \\text{poly}(1/\\epsilon,\\log n, \\log d)$-query hypergrid\ntester of Black-Chakrabarty-Seshadhri (SODA 2018).\n  To obtain the result for testing Boolean functions over $\\mathbb{R}^d$, we\nuse standard measure theoretic tools to reduce monotonicity testing of a\nmeasurable function $f$ to monotonicity testing of a discretized version of $f$\nover a hypergrid domain $[N]^d$ for large, but finite, $N$ (that may depend on\n$f$). The independence of $N$ in the hypergrid tester is crucial to getting the\nfinal tester over $\\mathbb{R}^d$.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 20:00:01 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 03:15:55 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 03:29:38 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Black", "Hadley", ""], ["Chakrabarty", "Deeparnab", ""], ["Seshadhri", "C.", ""]]}, {"id": "1811.01442", "submitter": "Zhao Song", "authors": "Zhao Song, David P. Woodruff, Peilin Zhong", "title": "Towards a Zero-One Law for Column Subset Selection", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are a number of approximation algorithms for NP-hard versions of low\nrank approximation, such as finding a rank-$k$ matrix $B$ minimizing the sum of\nabsolute values of differences to a given $n$-by-$n$ matrix $A$,\n$\\min_{\\textrm{rank-}k~B}\\|A-B\\|_1$, or more generally finding a rank-$k$\nmatrix $B$ which minimizes the sum of $p$-th powers of absolute values of\ndifferences, $\\min_{\\textrm{rank-}k~B}\\|A-B\\|_p^p$. Many of these algorithms\nare linear time columns subset selection algorithms, returning a subset of\n$\\mathrm{poly}(k \\log n)$ columns whose cost is no more than a\n$\\mathrm{poly}(k)$ factor larger than the cost of the best rank-$k$ matrix. The\nabove error measures are special cases of the following general entrywise low\nrank approximation problem: given an arbitrary function $g:\\mathbb{R}\n\\rightarrow \\mathbb{R}_{\\geq 0}$, find a rank-$k$ matrix $B$ which minimizes\n$\\|A-B\\|_g = \\sum_{i,j}g(A_{i,j}-B_{i,j})$. A natural question is which\nfunctions $g$ admit efficient approximation algorithms? Indeed, this is a\ncentral question of recent work studying generalized low rank models. In this\nwork we give approximation algorithms for $\\textit{every}$ function $g$ which\nis approximately monotone and satisfies an approximate triangle inequality, and\nwe show both of these conditions are necessary. Further, our algorithm is\nefficient if the function $g$ admits an efficient approximate regression\nalgorithm. Our approximation algorithms handle functions which are not even\nscale-invariant, such as the Huber loss function, which we show have very\ndifferent structural properties than $\\ell_p$-norms, e.g., one can show the\nlack of scale-invariance causes any column subset selection algorithm to\nprovably require a $\\sqrt{\\log n}$ factor larger number of columns than\n$\\ell_p$-norms; nevertheless we design the first efficient column subset\nselection algorithms for such error measures.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 21:43:55 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 23:53:54 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Song", "Zhao", ""], ["Woodruff", "David P.", ""], ["Zhong", "Peilin", ""]]}, {"id": "1811.01643", "submitter": "Dennis Olivetti", "authors": "Alkida Balliu, Juho Hirvonen, Dennis Olivetti, Jukka Suomela", "title": "Hardness of minimal symmetry breaking in distributed computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is weakly $2$-colored if the nodes are labeled with colors black and\nwhite such that each black node is adjacent to at least one white node and vice\nversa. In this work we study the distributed computational complexity of weak\n$2$-coloring in the standard LOCAL model of distributed computing, and how it\nis related to the distributed computational complexity of other graph problems.\nFirst, we show that weak $2$-coloring is a minimal distributed\nsymmetry-breaking problem for regular even-degree trees and high-girth graphs:\nif there is any non-trivial locally checkable labeling problem that is solvable\nin $o(\\log^* n)$ rounds with a distributed graph algorithm in the middle of a\nregular even-degree tree, then weak $2$-coloring is also solvable in $o(\\log^*\nn)$ rounds there. Second, we prove a tight lower bound of $\\Omega(\\log^* n)$\nfor the distributed computational complexity of weak $2$-coloring in regular\ntrees; previously only a lower bound of $\\Omega(\\log \\log^* n)$ was known. By\nminimality, the same lower bound holds for any non-trivial locally checkable\nproblem inside regular even-degree trees.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 12:39:00 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 11:59:54 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 14:52:28 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Balliu", "Alkida", ""], ["Hirvonen", "Juho", ""], ["Olivetti", "Dennis", ""], ["Suomela", "Jukka", ""]]}, {"id": "1811.01651", "submitter": "Nils Donselaar", "authors": "Nils Donselaar", "title": "Probabilistic Parameterized Polynomial Time", "comments": "To be presented at SOFSEM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a parameterized complexity class for randomized computation where\nonly the error bound and not the full runtime is allowed to depend more than\npolynomially on the parameter, based on a proposal by Kwisthout in [15,16]. We\nprove that this class, for which we propose the shorthand name PPPT, has a\nrobust definition and is in fact equal to the intersection of the classes\nparaBPP and PP. This result is accompanied by a Cook-style proof of\ncompleteness for the corresponding promise class (under a suitable notion of\nreduction) for parameterized approximation versions of the inference problem in\nBayesian networks, which is known to be PP-complete. With these definitions and\nresults in place, we proceed by showing how it follows from this that\nderandomization is equivalent to efficient deterministic approximation methods\nfor the inference problem. Furthermore, we observe as a straightforward\napplication of a result due to Drucker in [8] that these problems cannot have\npolynomial size randomized kernels unless the polynomial hierarchy collapses to\nthe third level. We conclude by indicating potential avenues for further\nexploration and application of this framework.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 12:59:45 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Donselaar", "Nils", ""]]}, {"id": "1811.01670", "submitter": "Valentin Touzeau", "authors": "Claire Ma\\\"iza (VERIMAG - IMAG), Valentin Touzeau (VERIMAG - IMAG),\n  David Monniaux (VERIMAG - IMAG), Jan Reineke", "title": "Fast and exact analysis for LRU caches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For applications in worst-case execution time analysis and in security, it is\ndesirable to statically classify memory accesses into those that result in\ncache hits, and those that result in cache misses. Among cache replacement\npolicies, the least recently used (LRU) policy has been studied the most and is\nconsidered to be the most predictable. The state-of-the-art in LRU cache\nanalysis presents a tradeoff between precision and analysis efficiency: The\nclassical approach to analyzing programs running on LRU caches, an abstract\ninterpretation based on a range abstraction, is very fast but can be imprecise.\nAn exact analysis was recently presented, but, as a last resort, it calls a\nmodel checker, which is expensive. In this paper, we develop an analysis based\non abstract interpretation that comes close to the efficiency of the classical\napproach, while achieving exact classification of all memory accesses as the\nmodel-checking approach. Compared with the model-checking approach we observe\nspeedups of several orders of magnitude. As a secondary contribution we show\nthat LRU cache analysis problems are in general NP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 13:34:21 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 08:57:26 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Ma\u00efza", "Claire", "", "VERIMAG - IMAG"], ["Touzeau", "Valentin", "", "VERIMAG - IMAG"], ["Monniaux", "David", "", "VERIMAG - IMAG"], ["Reineke", "Jan", ""]]}, {"id": "1811.01740", "submitter": "David Monniaux", "authors": "David Monniaux (VERIMAG - IMAG), Valentin Touzeau (VERIMAG - IMAG)", "title": "On the complexity of cache analysis for different replacement policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern processors use cache memory: a memory access that \"hits\" the cache\nreturns early, while a \"miss\" takes more time. Given a memory access in a\nprogram, cache analysis consists in deciding whether this access is always a\nhit, always a miss, or is a hit or a miss depending on execution. Such an\nanalysis is of high importance for bounding the worst-case execution time of\nsafety-critical real-time programs.There exist multiple possible policies for\nevicting old data from the cache when new data are brought in, and different\npolicies, though apparently similar in goals and performance, may be very\ndifferent from the analysis point of view. In this paper, we explore these\ndifferences from a complexity-theoretical point of view. Specifically, we show\nthat, among the common replacement policies, LRU (Least Recently Used) is the\nonly one whose analysis is NP-complete, whereas the analysis problems for the\nother policies are PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:38:14 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 09:45:45 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Monniaux", "David", "", "VERIMAG - IMAG"], ["Touzeau", "Valentin", "", "VERIMAG - IMAG"]]}, {"id": "1811.02725", "submitter": "Alexander Golovnev", "authors": "Zeev Dvir, Alexander Golovnev, Omri Weinstein", "title": "Static Data Structure Lower Bounds Imply Rigidity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that static data structure lower bounds in the group (linear) model\nimply semi-explicit lower bounds on matrix rigidity. In particular, we prove\nthat an explicit lower bound of $t \\geq \\omega(\\log^2 n)$ on the cell-probe\ncomplexity of linear data structures in the group model, even against\narbitrarily small linear space $(s= (1+\\varepsilon)n)$, would already imply a\nsemi-explicit ($\\bf P^{NP}\\rm$) construction of rigid matrices with\nsignificantly better parameters than the current state of art (Alon, Panigrahy\nand Yekhanin, 2009). Our results further assert that polynomial ($t\\geq\nn^{\\delta}$) data structure lower bounds against near-optimal space, would\nimply super-linear circuit lower bounds for log-depth linear circuits (a\nfour-decade open question). In the succinct space regime $(s=n+o(n))$, we show\nthat any improvement on current cell-probe lower bounds in the linear model\nwould also imply new rigidity bounds. Our results rely on a new connection\nbetween the \"inner\" and \"outer\" dimensions of a matrix (Paturi and Pudlak,\n2006), and on a new reduction from worst-case to average-case rigidity, which\nis of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 02:11:39 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 19:38:23 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 23:40:39 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Dvir", "Zeev", ""], ["Golovnev", "Alexander", ""], ["Weinstein", "Omri", ""]]}, {"id": "1811.03019", "submitter": "Rajendra Kumar", "authors": "Shashank K Mehta, Mahesh Sreekumar Rajasree and Rajendra Kumar", "title": "Maximum Distance Sub-Lattice Problem", "comments": "17 pages, No figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define a problem on lattices called the Maximum Distance\nSub-lattice Problem (MDSP). The decision version of this problem is shown to be\nin NP. We prove that MDSP is isomorphic to a well-known problem called closest\nvector problem (CVP). We give an exact and a heuristic algorithm for MDSP.\nUsing experimental results we show that the LLL algorithm can be accelerated\nwhen it is combined with the heuristic algorithm for MDSP.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 17:12:02 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Mehta", "Shashank K", ""], ["Rajasree", "Mahesh Sreekumar", ""], ["Kumar", "Rajendra", ""]]}, {"id": "1811.03031", "submitter": "Aleksandr Maksimenko", "authors": "Aleksandr Maksimenko", "title": "Branch and bound algorithm for the traveling salesman problem is not a\n  direct type algorithm", "comments": "14 pages, in Russian, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the notion of a direct type algorithm introduced\nby V.A. Bondarenko in 1983. A direct type algorithm is a linear decision tree\nwith some special properties. Until recently, it was thought that the class of\ndirect type algorithms is wide and includes many classical combinatorial\nalgorithms, including the branch and bound algorithm for the traveling salesman\nproblem, proposed by J.D.C. Little, K.G. Murty, D.W. Sweeney, C. Karel in 1963.\nWe show that this algorithm is not a direct type algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 17:33:26 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Maksimenko", "Aleksandr", ""]]}, {"id": "1811.03126", "submitter": "Tianyu Liu", "authors": "Jin-Yi Cai, Tianyu Liu, Pinyan Lu, Jing Yu", "title": "Approximability of the Eight-vertex Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a study of the classification of approximation complexity of the\neight-vertex model defined over 4-regular graphs. The eight-vertex model,\ntogether with its special case the six-vertex model, is one of the most\nextensively studied models in statistical physics, and can be stated as a\nproblem of counting weighted orientations in graph theory. Our result concerns\nthe approximability of the partition function on all 4-regular graphs,\nclassified according to the parameters of the model. Our complexity results\nconform to the phase transition phenomenon from physics.\n  We introduce a quantum decomposition of the eight-vertex model and prove a\nset of closure properties in various regions of the parameter space.\nFurthermore, we show that there are extra closure properties on 4-regular\nplanar graphs. These regions of the parameter space are concordant with the\nphase transition threshold. Using these closure properties, we derive\npolynomial time approximation algorithms via Markov chain Monte Carlo. We also\nshow that the eight-vertex model is NP-hard to approximate on the other side of\nthe phase transition threshold.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 19:43:02 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Liu", "Tianyu", ""], ["Lu", "Pinyan", ""], ["Yu", "Jing", ""]]}, {"id": "1811.03491", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane", "title": "Degree-$d$ Chow Parameters Robustly Determine Degree-$d$ PTFs (and\n  Algorithmic Applications)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The degree-$d$ Chow parameters of a Boolean function $f: \\{-1,1\\}^n \\to\n\\mathbb{R}$ are its degree at most $d$ Fourier coefficients. It is well-known\nthat degree-$d$ Chow parameters uniquely characterize degree-$d$ polynomial\nthreshold functions (PTFs) within the space of all bounded functions. In this\npaper, we prove a robust version of this theorem: For $f$ any Boolean\ndegree-$d$ PTF and $g$ any bounded function, if the degree-$d$ Chow parameters\nof $f$ are close to the degree-$d$ Chow parameters of $g$ in $\\ell_2$-norm,\nthen $f$ is close to $g$ in $\\ell_1$-distance. Notably, our bound relating the\ntwo distances is completely independent of the dimension $n$. That is, we show\nthat Boolean degree-$d$ PTFs are {\\em robustly identifiable} from their\ndegree-$d$ Chow parameters. Results of this form had been shown for the $d=1$\ncase~\\cite{OS11:chow, DeDFS14}, but no non-trivial bound was previously known\nfor $d >1$.\n  Our robust identifiability result gives the following algorithmic\napplications: First, we show that Boolean degree-$d$ PTFs can be efficiently\napproximately reconstructed from approximations to their degree-$d$ Chow\nparameters. This immediately implies that degree-$d$ PTFs are efficiently\nlearnable in the uniform distribution $d$-RFA\nmodel~\\cite{BenDavidDichterman:98}. As a byproduct of our approach, we also\nobtain the first low integer-weight approximations of degree-$d$ PTFs, for\n$d>1$. As our second application, our robust identifiability result gives the\nfirst efficient algorithm, with dimension-independent error guarantees, for\nmalicious learning of Boolean degree-$d$ PTFs under the uniform distribution.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 17:59:16 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""]]}, {"id": "1811.03831", "submitter": "Philippe Toint", "authors": "S. Bellavia and G. Gurioli and B. Morini and Ph.L. Toint", "title": "Adaptive Regularization Algorithms with Inexact Evaluations for\n  Nonconvex Optimization", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regularization algorithm using inexact function values and inexact\nderivatives is proposed and its evaluation complexity analyzed. This algorithm\nis applicable to unconstrained problems and to problems with inexpensive\nconstraints (that is constraints whose evaluation and enforcement has\nnegligible cost) under the assumption that the derivative of highest degree is\n$\\beta$-H\\\"{o}lder continuous. It features a very flexible adaptive mechanism\nfor determining the inexactness which is allowed, at each iteration, when\ncomputing objective function values and derivatives. The complexity analysis\ncovers arbitrary optimality order and arbitrary degree of available approximate\nderivatives. It extends results of Cartis, Gould and Toint (2018) on the\nevaluation complexity to the inexact case: if a $q$th order minimizer is sought\nusing approximations to the first $p$ derivatives, it is proved that a suitable\napproximate minimizer within $\\epsilon$ is computed by the proposed algorithm\nin at most $O(\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ iterations and at most\n$O(|\\log(\\epsilon)|\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ approximate\nevaluations. An algorithmic variant, although more rigid in practice, can be\nproved to find such an approximate minimizer in\n$O(|\\log(\\epsilon)|+\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ evaluations.While\nthe proposed framework remains so far conceptual for high degrees and orders,\nit is shown to yield simple and computationally realistic inexact methods when\nspecialized to the unconstrained and bound-constrained first- and second-order\ncases. The deterministic complexity results are finally extended to the\nstochastic context, yielding adaptive sample-size rules for subsampling methods\ntypical of machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 09:39:53 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 09:01:24 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 13:17:04 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Bellavia", "S.", ""], ["Gurioli", "G.", ""], ["Morini", "B.", ""], ["Toint", "Ph. L.", ""]]}, {"id": "1811.03841", "submitter": "John Fearnley", "authors": "John Fearnley, Spencer Gordon, Ruta Mehta, Rahul Savani", "title": "Unique End of Potential Line", "comments": "This paper substantially revises and extends the work described in\n  our previous preprint \"End of Potential Line'' (arXiv:1804.03450). The\n  abstract has been shortened to meet the arXiv character limit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the complexity of problems in PPAD $\\cap$ PLS that have\nunique solutions. Three well-known examples of such problems are the problem of\nfinding a fixpoint of a contraction map, finding the unique sink of a Unique\nSink Orientation (USO), and solving the P-matrix Linear Complementarity Problem\n(P-LCP). Each of these are promise-problems, and when the promise holds, they\nalways possess unique solutions.\n  We define the complexity class UEOPL to capture problems of this type. We\nfirst define a class that we call EOPL, which consists of all problems that can\nbe reduced to End-of-Potential-Line. This problem merges the canonical\nPPAD-complete problem End-of-Line, with the canonical PLS-complete problem\nSink-of-Dag, and so EOPL captures problems that can be solved by a\nline-following algorithm that also simultaneously decreases a potential\nfunction.\n  Promise-UEOPL is a promise-subclass of EOPL in which the line in the\nEnd-of-Potential-Line instance is guaranteed to be unique via a promise. We\nturn this into a non-promise class UEOPL, by adding an extra solution type to\nEOPL that captures any pair of points that are provably on two different lines.\n  We show that UEOPL $\\subseteq$ EOPL $\\subseteq$ CLS, and that all of our\nmotivating problems are contained in UEOPL: specifically USO, P-LCP, and\nfinding a fixpoint of a Piecewise-Linear Contraction under an $\\ell_p$-norm all\nlie in UEOPL. Our results also imply that parity games, mean-payoff games,\ndiscounted games, and simple-stochastic games lie in UEOPL.\n  All of our containment results are proved via a reduction to a problem that\nwe call One-Permutation Discrete Contraction (OPDC). This problem is motivated\nby a discretized version of contraction, but it is also closely related to the\nUSO problem. We show that OPDC lies in UEOPL, and we are also able to show that\nOPDC is UEOPL-complete.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 10:06:17 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Fearnley", "John", ""], ["Gordon", "Spencer", ""], ["Mehta", "Ruta", ""], ["Savani", "Rahul", ""]]}, {"id": "1811.03966", "submitter": "Lars Jaffke", "authors": "Lars Jaffke and Paloma T. Lima", "title": "A Complexity Dichotomy for Critical Values of the b-Chromatic Number of\n  Graphs", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $b$-coloring of a graph $G$ is a proper coloring of its vertices such that\neach color class contains a vertex that has at least one neighbor in all the\nother color classes. The b-Coloring problem asks whether a graph $G$ has a\n$b$-coloring with $k$ colors. The $b$-chromatic number of a graph $G$, denoted\nby $\\chi_b(G)$, is the maximum number $k$ such that $G$ admits a $b$-coloring\nwith $k$ colors. We consider the complexity of the b-Coloring problem, whenever\nthe value of $k$ is close to one of two upper bounds on $\\chi_b(G)$: The\nmaximum degree $\\Delta(G)$ plus one, and the $m$-degree, denoted by $m(G)$,\nwhich is defined as the maximum number $i$ such that $G$ has $i$ vertices of\ndegree at least $i-1$. We obtain a dichotomy result stating that for fixed $k\n\\in \\{\\Delta(G) + 1 - p, m(G) - p\\}$, the problem is polynomial-time solvable\nwhenever $p \\in \\{0, 1\\}$ and, even when $k = 3$, it is NP-complete whenever $p\n\\ge 2$. We furthermore consider parameterizations of the b-Coloring problem\nthat involve the maximum degree $\\Delta(G)$ of the input graph $G$ and give two\nFPT-algorithms. First, we show that deciding whether a graph $G$ has a\n$b$-coloring with $m(G)$ colors is FPT parameterized by $\\Delta(G)$. Second, we\nshow that b-Coloring is FPT parameterized by $\\Delta(G) + \\ell_k(G)$, where\n$\\ell_k(G)$ denotes the number of vertices of degree at least $k$.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 15:22:35 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 15:04:17 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Jaffke", "Lars", ""], ["Lima", "Paloma T.", ""]]}, {"id": "1811.04010", "submitter": "Dmitry Gavinsky", "authors": "D. Gavinsky", "title": "The layer complexity of Arthur-Merlin-like communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In communication complexity the Arthur-Merlin (AM) model is the most natural\none that allows both randomness and non-determinism. Presently we do not have\nany super-logarithmic lower bound for the AM-complexity of an explicit\nfunction. Obtaining such a bound is a fundamental challenge to our\nunderstanding of communication phenomena. In this work we explore the gap\nbetween the known techniques and the complexity class AM.\n  In the first part we define a new natural class Small-advantage Layered\nArthur-Merlin (SLAM) that have the following properties:\n  - SLAM is (strictly) included in AM and includes all previously known sub-AM\nclasses with non-trivial lower bounds.\n  - SLAM is qualitatively stronger than the union of those classes.\n  - SLAM is a subject to the discrepancy bound: in particular, the inner\nproduct function does not have an efficient SLAM-protocol.\n  Structurally this can be summarised as\n  SBP $\\cup$ UAM $\\subset$ SLAM $\\subseteq$ AM $\\cap$ PP.\n  In the second part we ask why proving a lower bound of $\\omega(\\sqrt n)$ on\nthe MA-complexity of an explicit function seems to be difficult.\n  Both of these results are related to the notion of layer complexity, which\nis, informally, the number of \"layers of non-determinism\" used by a protocol.\nWe believe that further investigation of this concept may lead to better\nunderstanding of the communication model AM and to non-trivial lower bounds\nagainst it.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 16:58:35 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Gavinsky", "D.", ""]]}, {"id": "1811.04313", "submitter": "Iddo Tzameret", "authors": "Iddo Tzameret, Stephen A. Cook", "title": "Uniform, Integral and Feasible Proofs for the Determinant Identities", "comments": "76 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming to provide weak as possible axiomatic assumptions in which one can\ndevelop basic linear algebra, we give a uniform and integral version of the\nshort propositional proofs for the determinant identities demonstrated over\n$GF(2)$ in Hrubes-Tzameret [SICOMP'15]. Specifically, we show that the\nmultiplicativity of the determinant function and the Cayley-Hamilton theorem\nover the integers are provable in the bounded arithmetic theory\n$\\mathbf{VNC}^2$; the latter is a first-order theory corresponding to the\ncomplexity class $\\mathbf{NC}^2$ consisting of problems solvable by uniform\nfamilies of polynomial-size circuits and $O(\\log ^2 n)$-depth. This also\nestablishes the existence of uniform polynomial-size $\\mathbf{NC}^2$-Frege\nproofs of the basic determinant identities over the integers (previous\npropositional proofs hold only over the two element field).\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 20:49:38 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Tzameret", "Iddo", ""], ["Cook", "Stephen A.", ""]]}, {"id": "1811.04607", "submitter": "Runzhou Tao", "authors": "Venkatesan Guruswami, Runzhou Tao", "title": "Streaming Hardness of Unique Games", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.APPROX-RANDOM.2019.5", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating the value of a Unique Game instance in\nthe streaming model. A simple count of the number of constraints divided by\n$p$, the alphabet size of the Unique Game, gives a trivial $p$-approximation\nthat can be computed in $O(\\log n)$ space. Meanwhile, with high probability, a\nsample of $\\tilde{O}(n)$ constraints suffices to estimate the optimal value to\n$(1+\\epsilon)$ accuracy. We prove that any single-pass streaming algorithm that\nachieves a $(p-\\epsilon)$-approximation requires $\\Omega_\\epsilon(\\sqrt{n})$\nspace. Our proof is via a reduction from lower bounds for a communication\nproblem that is a $p$-ary variant of the Boolean Hidden Matching problem\nstudied in the literature. Given the utility of Unique Games as a starting\npoint for reduction to other optimization problems, our strong hardness for\napproximating Unique Games could lead to down\\emph{stream} hardness results for\nstreaming approximability for other CSP-like problems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 08:56:28 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Tao", "Runzhou", ""]]}, {"id": "1811.04753", "submitter": "Hendrik Molter", "authors": "George B. Mertzios and Hendrik Molter and Viktor Zamaraev", "title": "Sliding Window Temporal Graph Coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph coloring is one of the most famous computational problems with\napplications in a wide range of areas such as planning and scheduling, resource\nallocation, and pattern matching. So far coloring problems are mostly studied\non static graphs, which often stand in stark contrast to practice where data is\ninherently dynamic and subject to discrete changes over time. A temporal graph\nis a graph whose edges are assigned a set of integer time labels, indicating at\nwhich discrete time steps the edge is active. In this paper we present a\nnatural temporal extension of the classical graph coloring problem. Given a\ntemporal graph and a natural number $\\Delta$, we ask for a coloring sequence\nfor each vertex such that (i) in every sliding time window of $\\Delta$\nconsecutive time steps, in which an edge is active, this edge is properly\ncolored (i.e. its endpoints are assigned two different colors) at least once\nduring that time window, and (ii) the total number of different colors is\nminimized. This sliding window temporal coloring problem abstractly captures\nmany realistic graph coloring scenarios in which the underlying network changes\nover time, such as dynamically assigning communication channels to moving\nagents. We present a thorough investigation of the computational complexity of\nthis temporal coloring problem. More specifically, we prove strong\ncomputational hardness results, complemented by efficient exact and\napproximation algorithms. Some of our algorithms are linear-time\nfixed-parameter tractable with respect to appropriate parameters, while others\nare asymptotically almost optimal under the Exponential Time Hypothesis (ETH).\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 14:51:54 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 18:23:28 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Mertzios", "George B.", ""], ["Molter", "Hendrik", ""], ["Zamaraev", "Viktor", ""]]}, {"id": "1811.04800", "submitter": "Michael Morak", "authors": "Wolfgang Faber, Michael Morak, Stefan Woltran", "title": "Strong Equivalence for Epistemic Logic Programs Made Easy (Extended\n  Version)", "comments": "Long version of paper published at AAAI'19, extended with full proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Epistemic Logic Programs (ELPs), that is, Answer Set Programming (ASP)\nextended with epistemic operators, have received renewed interest in recent\nyears, which led to a flurry of new research, as well as efficient solvers. An\nimportant question is under which conditions a sub-program can be replaced by\nanother one without changing the meaning, in any context. This problem is known\nas strong equivalence, and is well-studied for ASP. For ELPs, this question has\nbeen approached by embedding them into epistemic extensions of equilibrium\nlogics. In this paper, we consider a simpler, more direct characterization that\nis directly applicable to the language used in state-of-the-art ELP solvers.\nThis also allows us to give tight complexity bounds, showing that strong\nequivalence for ELPs remains coNP-complete, as for ASP. We further use our\nresults to provide syntactic characterizations for tautological rules and rule\nsubsumption for ELPs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 15:36:39 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Faber", "Wolfgang", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "1811.04801", "submitter": "Oleg Verbitsky", "authors": "V. Arvind, Frank Fuhlbr\\\"uck, Johannes K\\\"obler, Oleg Verbitsky", "title": "On Weisfeiler-Leman Invariance: Subgraph Counts and Related Graph\n  Properties", "comments": "The results on fractional graph parameters are excluded from this\n  version and will appear as a separate paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-dimensional Weisfeiler-Leman algorithm ($k$-WL) is a fruitful\napproach to the Graph Isomorphism problem. 2-WL corresponds to the original\nalgorithm suggested by Weisfeiler and Leman over 50 years ago. 1-WL is the\nclassical color refinement routine. Indistinguishability by $k$-WL is an\nequivalence relation on graphs that is of fundamental importance for\nisomorphism testing, descriptive complexity theory, and graph similarity\ntesting which is also of some relevance in artificial intelligence. Focusing on\ndimensions $k=1,2$, we investigate subgraph patterns whose counts are $k$-WL\ninvariant, and whose occurrence is $k$-WL invariant. We achieve a complete\ndescription of all such patterns for dimension $k=1$ and considerably extend\nthe previous results known for $k=2$.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 15:44:43 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 07:45:21 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 12:47:29 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Arvind", "V.", ""], ["Fuhlbr\u00fcck", "Frank", ""], ["K\u00f6bler", "Johannes", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "1811.04826", "submitter": "Tajana Ban Kirigin", "authors": "Max Kanovich, Tajana Ban Kirigin, Vivek Nigam, Andre Scedrov and\n  Carolyn Talcott", "title": "Compliance in Real Time Multiset Rewriting Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of compliance in Multiset Rewriting Models (MSR) has been\nintroduced for untimed models and for models with discrete time. In this paper\nwe revisit the notion of compliance and adapt it to fit with additional\nnondeterminism specific for dense time domains. Existing MSR with dense time\nare extended with critical configurations and non-critical traces, that is,\ntraces involving no critical configurations. Complexity of related {\\em\nnon-critical reachability problem} is investigated. Although this problem is\nundecidable in general, we prove that for balanced MSR with dense time the\nnon-critical reachability problem is PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 16:11:45 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Kanovich", "Max", ""], ["Kirigin", "Tajana Ban", ""], ["Nigam", "Vivek", ""], ["Scedrov", "Andre", ""], ["Talcott", "Carolyn", ""]]}, {"id": "1811.04828", "submitter": "Alexander Golovnev", "authors": "Alexander Golovnev and Alexander S. Kulikov and R. Ryan Williams", "title": "Circuit Depth Reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best known size lower bounds against unrestricted circuits have remained\naround $3n$ for several decades. Moreover, the only known technique for proving\nlower bounds in this model, gate elimination, is inherently limited to proving\nlower bounds of less than $5n$. In this work, we propose a non-gate-elimination\napproach for obtaining circuit lower bounds, via certain depth-three lower\nbounds. We prove that every (unbounded-depth) circuit of size $s$ can be\nexpressed as an OR of $2^{s/3.9}$ $16$-CNFs. For DeMorgan formulas, the best\nknown size lower bounds have been stuck at around $n^{3-o(1)}$ for decades.\nUnder a plausible hypothesis about probabilistic polynomials, we show that\n$n^{4-\\varepsilon}$-size DeMorgan formulas have\n$2^{n^{1-\\Omega(\\varepsilon)}}$-size depth-3 circuits which are approximate\nsums of $n^{1-\\Omega(\\varepsilon)}$-degree polynomials over ${\\mathbb F}_2$.\nWhile these structural results do not immediately lead to new lower bounds,\nthey do suggest new avenues of attack on these longstanding lower bound\nproblems.\n  Our results complement the classical depth-$3$ reduction results of Valiant,\nwhich show that logarithmic-depth circuits of linear size can be computed by an\nOR of $2^{\\varepsilon n}$ $n^{\\delta}$-CNFs, and slightly stronger results for\nseries-parallel circuits. It is known that no purely graph-theoretic reduction\ncould yield interesting depth-3 circuits from circuits of super-logarithmic\ndepth. We overcome this limitation (for small-size circuits) by taking into\naccount both the graph-theoretic and functional properties of circuits and\nformulas.\n  We show that improvements of the following pseudorandom constructions imply\nnew circuit lower bounds: dispersers for varieties, correlation with constant\ndegree polynomials, matrix rigidity, and hardness for depth-$3$ circuits with\nconstant bottom fan-in.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 16:14:19 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 21:25:53 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 15:30:45 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 19:19:51 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Golovnev", "Alexander", ""], ["Kulikov", "Alexander S.", ""], ["Williams", "R. Ryan", ""]]}, {"id": "1811.05115", "submitter": "Kshitij Gajjar", "authors": "Kshitij Gajjar, Jaikumar Radhakrishnan", "title": "Parametric Shortest Paths in Planar Graphs", "comments": "39 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a family of planar graphs $\\{G_n\\}_{n\\geq 4}$, where $G_n$ has\n$n$ vertices including a source vertex $s$ and a sink vertex $t$, and edge\nweights that change linearly with a parameter $\\lambda$ such that, as $\\lambda$\nvaries in $(-\\infty,+\\infty)$, the piece-wise linear cost of the shortest path\nfrom $s$ to $t$ has $n^{\\Omega(\\log n)}$ pieces. This shows that lower bounds\nobtained earlier by Carstensen (1983) and Mulmuley \\& Shah (2001) for general\ngraphs also hold for planar graphs, thereby refuting a conjecture of Nikolova\n(2009). Gusfield (1980) and Dean (2009) showed that the number of pieces for\nevery $n$-vertex graph with linear edge weights is $n^{\\log n + O(1)}$. We\ngeneralize this result in two ways. (i) If the edge weights vary as a\npolynomial of degree at most $d$, then the number of pieces is $n^{\\log n +\n(\\alpha(n)+O(1))^d}$, where $\\alpha(n)$ is the slow growing inverse Ackermann\nfunction. (ii) If the edge weights are linear forms of three parameters, then\nthe number of pieces, appropriately defined for $\\mathbb{R}^3$, is $n^{(\\log\nn)^2+O(\\log n)}$.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 05:35:47 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 05:49:08 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 07:56:19 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Gajjar", "Kshitij", ""], ["Radhakrishnan", "Jaikumar", ""]]}, {"id": "1811.05385", "submitter": "Qipeng Liu", "authors": "Qipeng Liu and Mark Zhandry", "title": "On Finding Quantum Multi-collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $k$-collision for a compressing hash function $H$ is a set of $k$ distinct\ninputs that all map to the same output. In this work, we show that for any\nconstant $k$, $\\Theta\\left(N^{\\frac{1}{2}(1-\\frac{1}{2^k-1})}\\right)$ quantum\nqueries are both necessary and sufficient to achieve a $k$-collision with\nconstant probability. This improves on both the best prior upper bound\n(Hosoyamada et al., ASIACRYPT 2017) and provides the first non-trivial lower\nbound, completely resolving the problem.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 16:22:52 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 01:11:58 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Liu", "Qipeng", ""], ["Zhandry", "Mark", ""]]}, {"id": "1811.05438", "submitter": "Zack Fitzsimmons", "authors": "Zack Fitzsimmons, Edith Hemaspaandra, Alexander Hoover, David E.\n  Narv\\'aez", "title": "Very Hard Electoral Control Problems", "comments": "A version of this paper will appear in the Proceedings of AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to understand how the outcome of an election can be modified\nby an agent with control over the structure of the election. Electoral control\nhas been studied for many election systems, but for all studied systems the\nwinner problem is in P, and so control is in NP. There are election systems,\nsuch as Kemeny, that have many desirable properties, but whose winner problems\nare not in NP. Thus for such systems control is not in NP, and in fact we show\nthat it is typically complete for $\\Sigma_2^p$ (i.e., ${\\rm NP}^{\\rm NP}$, the\nsecond level of the polynomial hierarchy). This is a very high level of\ncomplexity. Approaches that perform quite well for solving NP problems do not\nnecessarily work for $\\Sigma_2^p$-complete problems. However, answer set\nprogramming is suited to express problems in $\\Sigma_2^p$, and we present an\nencoding for Kemeny control.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 18:04:53 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Fitzsimmons", "Zack", ""], ["Hemaspaandra", "Edith", ""], ["Hoover", "Alexander", ""], ["Narv\u00e1ez", "David E.", ""]]}, {"id": "1811.05511", "submitter": "Fulvio Gesmundo", "authors": "Austin Conner, Fulvio Gesmundo, Joseph M. Landsberg, Emanuele Ventura,\n  Yao Wang", "title": "Towards a Geometric Approach to Strassen's Asymptotic Rank Conjecture", "comments": "Final version. Revisions in Section 1 and Section 3", "journal-ref": "Collectanea Mathematica, 2020", "doi": "10.1007/s13348-020-00280-8", "report-no": "BCSim-2018-s09", "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make a first geometric study of three varieties in $\\mathbb{C}^m \\otimes\n\\mathbb{C}^m \\otimes \\mathbb{C}^m$ (for each $m$), including the Zariski\nclosure of the set of tight tensors, the tensors with continuous regular\nsymmetry. Our motivation is to develop a geometric framework for Strassen's\nAsymptotic Rank Conjecture that the asymptotic rank of any tight tensor is\nminimal. In particular, we determine the dimension of the set of tight tensors.\nWe prove that this dimension equals the dimension of the set of oblique\ntensors, a less restrictive class introduced by Strassen.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 19:48:02 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 05:41:46 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 12:46:34 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Conner", "Austin", ""], ["Gesmundo", "Fulvio", ""], ["Landsberg", "Joseph M.", ""], ["Ventura", "Emanuele", ""], ["Wang", "Yao", ""]]}, {"id": "1811.05630", "submitter": "Xin-Chuan Wu", "authors": "Xin-Chuan Wu, Sheng Di, Franck Cappello, Hal Finkel, Yuri Alexeev, and\n  Frederic T. Chong", "title": "Memory-Efficient Quantum Circuit Simulation by Using Lossy Data\n  Compression", "comments": "2 pages, 2 figures. The 3rd International Workshop on Post-Moore Era\n  Supercomputing (PMES)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to evaluate, validate, and refine the design of new quantum\nalgorithms or quantum computers, researchers and developers need methods to\nassess their correctness and fidelity. This requires the capabilities of\nquantum circuit simulations. However, the number of quantum state amplitudes\nincreases exponentially with the number of qubits, leading to the exponential\ngrowth of the memory requirement for the simulations. In this work, we present\nour memory-efficient quantum circuit simulation by using lossy data\ncompression. Our empirical data shows that we reduce the memory requirement to\n16.5% and 2.24E-06 of the original requirement for QFT and Grover's search,\nrespectively. This finding further suggests that we can simulate deep quantum\ncircuits up to 63 qubits with 0.8 petabytes memory.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 04:10:31 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 04:12:01 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Wu", "Xin-Chuan", ""], ["Di", "Sheng", ""], ["Cappello", "Franck", ""], ["Finkel", "Hal", ""], ["Alexeev", "Yuri", ""], ["Chong", "Frederic T.", ""]]}, {"id": "1811.06072", "submitter": "Chunjiang Zhu", "authors": "Chun Jiang Zhu, Tan Zhu, Kam-Yiu Lam, Song Han, Jinbo Bi", "title": "Communication-Optimal Distributed Dynamic Graph Clustering", "comments": "Accepted and to appear in AAAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of clustering graph nodes over large-scale dynamic\ngraphs, such as citation networks, images and web networks, when graph updates\nsuch as node/edge insertions/deletions are observed distributively. We propose\ncommunication-efficient algorithms for two well-established communication\nmodels namely the message passing and the blackboard models. Given a graph with\n$n$ nodes that is observed at $s$ remote sites over time $[1,t]$, the two\nproposed algorithms have communication costs $\\tilde{O}(ns)$ and\n$\\tilde{O}(n+s)$ ($\\tilde{O}$ hides a polylogarithmic factor), almost matching\ntheir lower bounds, $\\Omega(ns)$ and $\\Omega(n+s)$, respectively, in the\nmessage passing and the blackboard models. More importantly, we prove that at\neach time point in $[1,t]$ our algorithms generate clustering quality nearly as\ngood as that of centralizing all updates up to that time and then applying a\nstandard centralized clustering algorithm. We conducted extensive experiments\non both synthetic and real-life datasets which confirmed the communication\nefficiency of our approach over baseline algorithms while achieving comparable\nclustering results.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 21:33:45 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Zhu", "Chun Jiang", ""], ["Zhu", "Tan", ""], ["Lam", "Kam-Yiu", ""], ["Han", "Song", ""], ["Bi", "Jinbo", ""]]}, {"id": "1811.06336", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami", "title": "State Complexity Characterizations of Parameterized Degree-Bounded Graph\n  Connectivity, Sub-Linear Space Computation, and the Linear Space Hypothesis", "comments": "(26 pages, 10pt, A4 size) This paper extends and corrects a\n  preliminary report that has appeared in the Proceedings of the 20th\n  International Conference on Descriptional Complexity of Formal Systems (DCFS\n  2018), Halifax, Canada, July 25-27, 2018. Lecture Notes in Computer Science,\n  Springer, vol. 10952, pp. 237-249, 2018", "journal-ref": "(journal version) Theoretical Computer Science vol. 798, pp.2-22,\n  2019", "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear space hypothesis is a practical working hypothesis, which\noriginally states the insolvability of a restricted 2CNF Boolean formula\nsatisfiability problem parameterized by the number of Boolean variables. From\nthis hypothesis, it naturally follows that the degree-3 directed graph\nconnectivity problem (3DSTCON) parameterized by the number of vertices in a\ngiven graph cannot belong to PsubLIN, composed of all parameterized decision\nproblems computable by polynomial-time, sub-linear-space deterministic Turing\nmachines. This hypothesis immediately implies L$\\neq$NL and it was used as a\nsolid foundation to obtain new lower bounds on the computational complexity of\nvarious NL search and NL optimization problems. The state complexity of\ntransformation refers to the cost of converting one type of finite automata to\nanother type, where the cost is measured in terms of the increase of the number\nof inner states of the converted automata from that of the original automata.\nWe relate the linear space hypothesis to the state complexity of transforming\nrestricted 2-way nondeterministic finite automata to computationally equivalent\n2-way alternating finite automata having narrow computation graphs. For this\npurpose, we present state complexity characterizations of 3DSTCON and PsubLIN.\nWe further characterize a nonuniform version of the linear space hypothesis in\nterms of the state complexity of transformation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 13:28:59 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 11:01:20 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Yamakami", "Tomoyuki", ""]]}, {"id": "1811.06418", "submitter": "Ilya Razenshteyn", "authors": "S\\'ebastien Bubeck, Yin Tat Lee, Eric Price, Ilya Razenshteyn", "title": "Adversarial Examples from Cryptographic Pseudo-Random Generators", "comments": "4 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our recent work (Bubeck, Price, Razenshteyn, arXiv:1805.10204) we argued\nthat adversarial examples in machine learning might be due to an inherent\ncomputational hardness of the problem. More precisely, we constructed a binary\nclassification task for which (i) a robust classifier exists; yet no\nnon-trivial accuracy can be obtained with an efficient algorithm in (ii) the\nstatistical query model. In the present paper we significantly strengthen both\n(i) and (ii): we now construct a task which admits (i') a maximally robust\nclassifier (that is it can tolerate perturbations of size comparable to the\nsize of the examples themselves); and moreover we prove computational hardness\nof learning this task under (ii') a standard cryptographic assumption.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 15:08:12 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Lee", "Yin Tat", ""], ["Price", "Eric", ""], ["Razenshteyn", "Ilya", ""]]}, {"id": "1811.06787", "submitter": "Thomas Seiller", "authors": "Luc Pellissier and Thomas Seiller", "title": "PRAMs over integers do not compute maxflow efficiently", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new semantic method for proving lower bounds in\ncomputational complexity. We use it to prove that $\\mathbf{maxflow}$, a\n$\\mathbf{Ptime}$-complete problem, is not computable in polylogarithmic time on\nparallel random access machines (PRAMs) working with integers, showing that\n$\\mathbf{NC}_{\\mathbb{Z}}\\neq\\mathbf{Ptime}$, where $\\mathbf{NC}_{\\mathbb{Z}}$\nis the complexity class defined by such machines, and $\\mathbf{Ptime}$ is the\nstandard class of polynomial time computable problems (on, say, a Turing\nmachine). On top of showing this new separation result, we show our method\ncaptures previous lower bounds results from the literature: Steele and Yao's\nlower bounds for algebraic decision trees, Ben-Or's lower bounds for algebraic\ncomputation trees, Cucker's proof that $\\mathbf{NC}_{\\mathbb{R}}$ is not equal\nto $\\mathbf{Ptime}_{\\mathbb{R}}$, and Mulmuley's lower bounds for \"PRAMs\nwithout bit operations\".\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 12:55:40 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 15:54:15 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Pellissier", "Luc", ""], ["Seiller", "Thomas", ""]]}, {"id": "1811.07312", "submitter": "Davide Cirillo", "authors": "Davide Cirillo, Miguel Ponce-de-Leon, Alfonso Valencia", "title": "Algorithmic complexity in computational biology: basics, challenges and\n  limitations", "comments": "17 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Computational problems can be classified according to their algorithmic\ncomplexity, which is defined based on how the resources needed to solve the\nproblem, e.g. the execution time, scale with the problem size. Many problems in\ncomputational biology are computationally infeasible in the sense that the\nexhaustive search for the optimal solution is prohibitive in practical terms.\nAs a consequence, these problems are tackled through heuristics and\napproximations aiming to overcome the exceeding computational requirements at\nthe cost of providing suboptimal solutions. The importance of defining the\ncomputational complexity of computational biology algorithms is a topic rarely\nsurveyed for broad audiences of bioinformaticians and users of bioinformatics\ntools. However, recognizing the underlying complexity of any algorithm is\nessential for understanding their potential and limitations. Thus, the aim of\nthis review is to survey the main algorithmic solutions to intractable problems\nin computational biology, highlighting the importance of High-Performance\nComputing in this area.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 10:45:20 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 09:49:08 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Cirillo", "Davide", ""], ["Ponce-de-Leon", "Miguel", ""], ["Valencia", "Alfonso", ""]]}, {"id": "1811.07401", "submitter": "Antonios Syreloglou", "authors": "Antonios Syreloglou", "title": "The problematic nature of potentially polynomial-time algorithms solving\n  the subset-sum problem", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main purpose of this paper is to study the NP-complete subset-sum\nproblem, not in the usual context of time-complexity-based classification of\nthe algorithms (exponential/polynomial), but through a new kind of algorithmic\nclassification which we introduce based on a property that all known\nexponential-time algorithms share. We then construct a theoretical mathematical\nenvironment within which we compare the two classes that are produced from the\nnew classification; one class is characterized by a normal mathematical nature,\nwhereas the other by a problematic one. These results are transferred to\nexponential/polynomial algorithms, through a conjecture that links the two\nclassifications. As for the mathematical environment, it consists of a simple\nrandom experiment designed in such a way that the algorithmic operation is\nlinked to it. We study the random experiment with a stochastic process which is\nthe main tool for the comparison of the two classes.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 21:01:39 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Syreloglou", "Antonios", ""]]}, {"id": "1811.07515", "submitter": "Ruosong Wang", "authors": "Lijie Chen, Ruosong Wang", "title": "Classical Algorithms from Quantum and Arthur-Merlin Communication\n  Protocols", "comments": "To appear in ITCS 2019. Abstract is shortened to meet the constraint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polynomial method from circuit complexity has been applied to several\nfundamental problems and obtains the state-of-the-art running times. As\nobserved in [Alman and Williams, STOC 2017], almost all applications of the\npolynomial method in algorithm design ultimately rely on certain low-rank\ndecompositions of the computation matrices corresponding to key subroutines.\nThey suggest that making use of low-rank decompositions directly could lead to\nmore powerful algorithms, as the polynomial method is just one way to derive\nsuch a decomposition. Inspired by their observation, in this paper, we study\nanother way of systematically constructing low-rank decompositions of matrices\nwhich could be used by algorithms. It is known that various types of\ncommunication protocols lead to certain low-rank decompositions (e.g.,\n$\\mathsf{P}$ protocols/rank, $\\mathsf{BQP}$ protocols/approximate rank). These\nare usually interpreted as approaches for proving communication lower bounds,\nwhile in this work we explore the other direction.\n  We have the two generic algorithmic applications of communication protocols.\nThe first connection is that a fast $\\mathsf{BQP}$ communication protocol for a\nfunction $f$ implies a fast deterministic additive approximate counting\nalgorithm for a related pair counting problem. The second connection is that a\nfast $\\mathsf{AM}^{\\mathsf{cc}}$ protocol for a function $f$ implies a\nfaster-than-bruteforce algorithm for $f\\textsf{-Satisfying-Pair}$.\n  We also apply our second connection to shed some light on long-standing open\nproblems in communication complexity. We show that if the Longest Common\nSubsequence problem admits an efficient $\\mathsf{AM}^{\\mathsf{cc}}$ protocol,\nthen polynomial-size Formula-$\\textsf{SAT}$ admits a $2^{n - n^{1-\\delta}}$\ntime algorithm for any constant $\\delta > 0$.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 06:05:54 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Chen", "Lijie", ""], ["Wang", "Ruosong", ""]]}, {"id": "1811.07649", "submitter": "Arash Vaezi", "authors": "Arash Vaezi, Mohammad Ghodsi", "title": "Visibility Extension via Reflective Edges to an Exact Quantity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider extending the visibility polygon of a given point $q$, inside a\nsimple polygon $P$ by converting some edges of $P$ to mirrors. We will show\nthat several variations of the problem of finding mirror-edges to add precisely\n$k$ units of area to $VP(q)$ are NP-complete. The optimal cases are NP-hard. We\nare unaware of any result on adding an exact number to a polygon, or covering\nan area with an exact surface. We deal with both single and multiple reflecting\nmirrors for both specular or diffuse types of reflections.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 12:36:08 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Vaezi", "Arash", ""], ["Ghodsi", "Mohammad", ""]]}, {"id": "1811.08097", "submitter": "Akinori Hosoyamada", "authors": "Akinori Hosoyamada, Yu Sasaki, Seiichiro Tani, Keita Xagawa", "title": "Improved Quantum Multicollision-Finding Algorithm", "comments": "To appear at PQCrypto 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper improves the number of queries of the previous quantum\nmulti-collision finding algorithms presented by Hosoyamada et al. at Asiacrypt\n2017. Let an $l$-collision be a tuple of $l$ distinct inputs that result in the\nsame output of a target function. In cryptology, it is important to study how\nmany queries are required to find $l$-collisions for random functions of which\ndomains are larger than ranges. The previous algorithm finds an $l$-collision\nfor a random function by recursively calling the algorithm for finding\n$(l-1)$-collisions, and it achieves the average quantum query complexity of\n$O(N^{(3^{l-1}-1) / (2 \\cdot 3^{l-1})})$, where $N$ is the range size of target\nfunctions. The new algorithm removes the redundancy of the previous recursive\nalgorithm so that different recursive calls can share a part of computations.\nThe new algorithm finds an $l$-collision for random functions with the average\nquantum query complexity of $O(N^{(2^{l-1}-1) / (2^{l}-1)})$, which improves\nthe previous bound for all $l\\ge 3$ (the new and previous algorithms achieve\nthe optimal bound for $l=2$). More generally, the new algorithm achieves the\naverage quantum query complexity of $O\\left(c^{3/2}_N N^{\\frac{2^{l-1}-1}{\n2^{l}-1}}\\right)$ for a random function $f\\colon X\\to Y$ such that $|X| \\geq l\n\\cdot |Y| / c_N$ for any $1\\le c_N \\in o(N^{\\frac{1}{2^l - 1}})$. With the same\nquery complexity, it also finds a multiclaw for random functions, which is\nharder to find than a multicollision.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 07:10:45 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 11:56:56 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 09:37:23 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Hosoyamada", "Akinori", ""], ["Sasaki", "Yu", ""], ["Tani", "Seiichiro", ""], ["Xagawa", "Keita", ""]]}, {"id": "1811.08237", "submitter": "Pierre-Jean Spaenlehauer", "authors": "Aude Le Gluher and Pierre-Jean Spaenlehauer", "title": "A Fast Randomized Geometric Algorithm for Computing Riemann-Roch Spaces", "comments": null, "journal-ref": "Mathematics of Computation 89 (2020), 2399-2433", "doi": "10.1090/mcom/3517", "report-no": null, "categories": "cs.SC cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic variant of Brill-Noether's algorithm for computing\na basis of the Riemann-Roch space $L(D)$ associated to a divisor $D$ on a\nprojective nodal plane curve $\\mathcal C$ over a sufficiently large perfect\nfield $k$. Our main result shows that this algorithm requires at most\n$O(\\max(\\mathrm{deg}(\\mathcal C)^{2\\omega}, \\mathrm{deg}(D_+)^\\omega))$\narithmetic operations in $k$, where $\\omega$ is a feasible exponent for matrix\nmultiplication and $D_+$ is the smallest effective divisor such that $D_+\\geq\nD$. This improves the best known upper bounds on the complexity of computing\nRiemann-Roch spaces. Our algorithm may fail, but we show that provided that a\nfew mild assumptions are satisfied, the failure probability is bounded by\n$O(\\max(\\mathrm{deg}(\\mathcal C)^4, \\mathrm{deg}(D_+)^2)/\\lvert \\mathcal\nE\\rvert)$, where $\\mathcal E$ is a finite subset of $k$ in which we pick\nelements uniformly at random. We provide a freely available C++/NTL\nimplementation of the proposed algorithm and we present experimental data. In\nparticular, our implementation enjoys a speedup larger than 6 on many examples\n(and larger than 200 on some instances over large finite fields) compared to\nthe reference implementation in the Magma computer algebra system. As a\nby-product, our algorithm also yields a method for computing the group law on\nthe Jacobian of a smooth plane curve of genus $g$ within $O(g^\\omega)$\noperations in $k$, which equals the best known complexity for this problem.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:28:38 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 09:57:16 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 12:40:15 GMT"}, {"version": "v4", "created": "Thu, 16 May 2019 08:59:27 GMT"}, {"version": "v5", "created": "Tue, 8 Oct 2019 09:44:54 GMT"}, {"version": "v6", "created": "Fri, 6 Dec 2019 13:49:21 GMT"}, {"version": "v7", "created": "Tue, 10 Dec 2019 15:09:54 GMT"}, {"version": "v8", "created": "Mon, 19 Oct 2020 12:34:26 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Gluher", "Aude Le", ""], ["Spaenlehauer", "Pierre-Jean", ""]]}, {"id": "1811.08506", "submitter": "Jan Marcinkowski", "authors": "Szymon Dudycz, Mateusz Lewandowski, and Jan Marcinkowski (University\n  of Wroc{\\l}aw, Poland)", "title": "Tight Approximation Ratio for Minimum Maximal Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a combinatorial problem called Minimum Maximal Matching, where we\nare asked to find in a general graph the smallest that can not be extended. We\nshow that this problem is hard to approximate with a constant smaller than 2,\nassuming the Unique Games Conjecture.\n  As a corollary we show, that Minimum Maximal Matching in bipartite graphs is\nhard to approximate with constant smaller than $\\frac{4}{3}$, with the same\nassumption. With a stronger variant of the Unique Games Conjecture --- that is\nSmall Set Expansion Hypothesis --- we are able to improve the hardness result\nup to the factor of $\\frac{3}{2}$.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 22:04:59 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Dudycz", "Szymon", "", "University\n  of Wroc\u0142aw, Poland"], ["Lewandowski", "Mateusz", "", "University\n  of Wroc\u0142aw, Poland"], ["Marcinkowski", "Jan", "", "University\n  of Wroc\u0142aw, Poland"]]}, {"id": "1811.09649", "submitter": "Hamza Fawzi", "authors": "Hamza Fawzi", "title": "On polyhedral approximations of the positive semidefinite cone", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $D$ be the set of $n\\times n$ positive semidefinite matrices of trace\nequal to one, also known as the set of density matrices. We prove two results\non the hardness of approximating $D$ with polytopes. First, we show that if $0\n< \\epsilon < 1$ and $A$ is an arbitrary matrix of trace equal to one, any\npolytope $P$ such that $(1-\\epsilon)(D-A) \\subset P \\subset D-A$ must have\nlinear programming extension complexity at least $\\exp(c\\sqrt{n})$ where $c >\n0$ is a constant that depends on $\\epsilon$. Second, we show that any polytope\n$P$ such that $D \\subset P$ and such that the Gaussian width of $P$ is at most\ntwice the Gaussian width of $D$ must have extension complexity at least\n$\\exp(cn^{1/3})$. The main ingredient of our proofs is hypercontractivity of\nthe noise operator on the hypercube.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 19:28:24 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Fawzi", "Hamza", ""]]}, {"id": "1811.10090", "submitter": "Makrand Sinha", "authors": "Makrand Sinha, Ronald de Wolf", "title": "Exponential Separation between Quantum Communication and Logarithm of\n  Approximate Rank", "comments": "The same lower bound has been obtained independently and\n  simultaneously by Anurag Anshu, Naresh Goud Boddu and Dave Touchette", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chattopadhyay, Mande and Sherif (ECCC 2018) recently exhibited a total\nBoolean function, the sink function, that has polynomial approximate rank and\npolynomial randomized communication complexity. This gives an exponential\nseparation between randomized communication complexity and logarithm of the\napproximate rank, refuting the log-approximate-rank conjecture. We show that\neven the quantum communication complexity of the sink function is polynomial,\nthus also refuting the quantum log-approximate-rank conjecture.\n  Our lower bound is based on the fooling distribution method introduced by Rao\nand Sinha (ECCC 2015) for the classical case and extended by Anshu, Touchette,\nYao and Yu (STOC 2017) for the quantum case. We also give a new proof of the\nclassical lower bound using the fooling distribution method.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 20:47:16 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Sinha", "Makrand", ""], ["de Wolf", "Ronald", ""]]}, {"id": "1811.10525", "submitter": "Anurag Anshu", "authors": "Anurag Anshu and Naresh Goud Boddu and Dave Touchette", "title": "Quantum Log-Approximate-Rank Conjecture is also False", "comments": "21 pages. The same lower bound has been obtained independently and\n  simultaneously by Makrand Sinha and Ronald de Wolf. Part of the preliminaries\n  taken from arXiv:1611.05754", "journal-ref": "2019 IEEE 60th Annual Symposium on Foundations of Computer Science\n  (FOCS)", "doi": "10.1109/FOCS.2019.00063", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent breakthrough result, Chattopadhyay, Mande and Sherif [ECCC\nTR18-17] showed an exponential separation between the log approximate rank and\nrandomized communication complexity of a total function $f$, hence refuting the\nlog approximate rank conjecture of Lee and Shraibman [2009]. We provide an\nalternate proof of their randomized communication complexity lower bound using\nthe information complexity approach. Using the intuition developed there, we\nderive a polynomially-related quantum communication complexity lower bound\nusing the quantum information complexity approach, thus providing an\nexponential separation between the log approximate rank and quantum\ncommunication complexity of $f$. Previously, the best known separation between\nthese two measures was (almost) quadratic, due to Anshu, Ben-David, Garg, Jain,\nKothari and Lee [CCC, 2017]. This settles one of the main question left open by\nChattopadhyay, Mande and Sherif, and refutes the quantum log approximate rank\nconjecture of Lee and Shraibman [2009]. Along the way, we develop a\nShearer-type protocol embedding for product input distributions that might be\nof independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 17:29:00 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Anshu", "Anurag", ""], ["Boddu", "Naresh Goud", ""], ["Touchette", "Dave", ""]]}, {"id": "1811.10752", "submitter": "Troy Lee", "authors": "Dmitry Gavinsky, Troy Lee, Miklos Santha, Swagato Sanyal", "title": "A composition theorem for randomized query complexity via max conflict\n  complexity", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Let $R_\\epsilon(\\cdot)$ stand for the bounded-error randomized query\ncomplexity with error $\\epsilon > 0$. For any relation $f \\subseteq \\{0,1\\}^n\n\\times S$ and partial Boolean function $g \\subseteq \\{0,1\\}^m \\times \\{0,1\\}$,\nwe show that $R_{1/3}(f \\circ g^n) \\in \\Omega(R_{4/9}(f) \\cdot\n\\sqrt{R_{1/3}(g)})$, where $f \\circ g^n \\subseteq (\\{0,1\\}^m)^n \\times S$ is\nthe composition of $f$ and $g$. We give an example of a relation $f$ and\npartial Boolean function $g$ for which this lower bound is tight.\n  We prove our composition theorem by introducing a new complexity measure, the\nmax conflict complexity $\\bar \\chi(g)$ of a partial Boolean function $g$. We\nshow $\\bar \\chi(g) \\in \\Omega(\\sqrt{R_{1/3}(g)})$ for any (partial) function\n$g$ and $R_{1/3}(f \\circ g^n) \\in \\Omega(R_{4/9}(f) \\cdot \\bar \\chi(g))$; these\ntwo bounds imply our composition result. We further show that $\\bar \\chi(g)$ is\nalways at least as large as the sabotage complexity of $g$, introduced by\nBen-David and Kothari.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 00:11:08 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Gavinsky", "Dmitry", ""], ["Lee", "Troy", ""], ["Santha", "Miklos", ""], ["Sanyal", "Swagato", ""]]}, {"id": "1811.10909", "submitter": "He Sun", "authors": "Huan Li and He Sun and Luca Zanetti", "title": "Hermitian Laplacians and a Cheeger inequality for the Max-2-Lin problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study spectral approaches for the MAX-2-LIN(k) problem, in which we are\ngiven a system of $m$ linear equations of the form $x_i - x_j \\equiv c_{ij}\\mod\nk$, and required to find an assignment to the $n$ variables $\\{x_i\\}$ that\nmaximises the total number of satisfied equations.\n  We consider Hermitian Laplacians related to this problem, and prove a Cheeger\ninequality that relates the smallest eigenvalue of a Hermitian Laplacian to the\nmaximum number of satisfied equations of a MAX-2-LIN(k) instance $\\mathcal{I}$.\nWe develop an $\\widetilde{O}(kn^2)$ time algorithm that, for any\n$(1-\\varepsilon)$-satisfiable instance, produces an assignment satisfying a\n$\\left(1 - O(k)\\sqrt{\\varepsilon}\\right)$-fraction of equations. We also\npresent a subquadratic-time algorithm that, when the graph associated with\n$\\mathcal{I}$ is an expander, produces an assignment satisfying a $\\left(1-\nO(k^2)\\varepsilon \\right)$-fraction of the equations. Our Cheeger inequality\nand first algorithm can be seen as generalisations of the Cheeger inequality\nand algorithm for MAX-CUT developed by Trevisan.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 11:02:36 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Li", "Huan", ""], ["Sun", "He", ""], ["Zanetti", "Luca", ""]]}, {"id": "1811.11488", "submitter": "Ishay Haviv", "authors": "Ishay Haviv", "title": "Topological Bounds on the Dimension of Orthogonal Representations of\n  Graphs", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An orthogonal representation of a graph is an assignment of nonzero real\nvectors to its vertices such that distinct non-adjacent vertices are assigned\nto orthogonal vectors. We prove general lower bounds on the dimension of\northogonal representations of graphs using the Borsuk-Ulam theorem from\nalgebraic topology. Our bounds strengthen the Kneser conjecture, proved by\nLov\\'asz in 1978, and some of its extensions due to B\\'ar\\'any, Schrijver,\nDol'nikov, and Kriz. As applications, we determine the integrality gap of\nfractional upper bounds on the Shannon capacity of graphs and the quantum\none-round communication complexity of certain promise equality problems.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 10:38:30 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Haviv", "Ishay", ""]]}, {"id": "1811.11593", "submitter": "Nikolaos Bikakis", "authors": "Nikos Bikakis, Vana Kalogeraki, Dimitrios Gunupulos", "title": "Attendance Maximization for Successful Social Event Planning", "comments": "This paper appears in 22nd Intl. Conf. on Extending Database\n  Technology (EDBT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social event planning has received a great deal of attention in recent years\nwhere various entities, such as event planners and marketing companies,\norganizations, venues, or users in Event-based Social Networks, organize\nnumerous social events (e.g., festivals, conferences, promotion parties).\nRecent studies show that \"attendance\" is the most common metric used to capture\nthe success of social events, since the number of attendees has great impact on\nthe event's expected gains (e.g., revenue, artist/brand publicity). In this\nwork, we study the Social Event Scheduling (SES) problem which aims at\nidentifying and assigning social events to appropriate time slots, so that the\nnumber of events attendees is maximized. We show that, even in highly\nrestricted instances, the SES problem is NP-hard to be approximated over a\nfactor. To solve the SES problem, we design three efficient and scalable\nalgorithms. These algorithms exploit several novel schemes that we design. We\nconduct extensive experiments using several real and synthetic datasets, and\ndemonstrate that the proposed algorithms perform on average half the\ncomputations compared to the existing solution and, in several cases, are 3-5\ntimes faster.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 14:35:22 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Bikakis", "Nikos", ""], ["Kalogeraki", "Vana", ""], ["Gunupulos", "Dimitrios", ""]]}, {"id": "1811.11667", "submitter": "J. M. Landsberg", "authors": "Joseph M. Landsberg", "title": "The complexity of matrix multiplication: developments since 2014.\n  Extended abstract of 2018 Oberwolfach Complexity meeting plenary lecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an overview of recent developments regarding the complexity of matrix\nmultiplication, with an emphasis on the uses of algebraic geometry and\nrepresentation theory in complexity theory.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 16:47:28 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Landsberg", "Joseph M.", ""]]}, {"id": "1811.11939", "submitter": "Xueliang Li", "authors": "Zhong Huang, Xueliang Li", "title": "Hardness results for rainbow disconnection of graphs", "comments": "8 pages. In the second version we made some correction for the proof\n  of our main Lemma 2.4", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a nontrivial connected, edge-colored graph. An edge-cut $S$ of $G$\nis called a rainbow cut if no two edges in $S$ are colored with a same color.\nAn edge-coloring of $G$ is a rainbow disconnection coloring if for every two\ndistinct vertices $s$ and $t$ of $G$, there exists a rainbow cut $S$ in $G$\nsuch that $s$ and $t$ belong to different components of $G\\setminus S$. For a\nconnected graph $G$, the {\\it rainbow disconnection number} of $G$, denoted by\n$rd(G)$, is defined as the smallest number of colors such that $G$ has a\nrainbow disconnection coloring by using this number of colors. In this paper,\nwe show that for a connected graph $G$, computing $rd(G)$ is NP-hard. In\nparticular, it is already NP-complete to decide if $rd(G)=3$ for a connected\ncubic graph. Moreover, we prove that for a given edge-colored (with an\nunbounded number of colors) connected graph $G$ it is NP-complete to decide\nwhether $G$ is rainbow disconnected.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 03:34:31 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 08:29:05 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Huang", "Zhong", ""], ["Li", "Xueliang", ""]]}, {"id": "1811.12369", "submitter": "Moti Medina", "authors": "Johannes Bund, Christoph Lenzen, Moti Medina", "title": "Small Hazard-free Transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, an unconditional exponential separation between the hazard-free\ncomplexity and (standard) circuit complexity of explicit functions has been\nshown~\\cite{ikenmeyer18complexity}. This raises the question: which classes of\nfunctions permit efficient hazard-free circuits?\n  Our main result is as follows. A \\emph{transducer} is a finite state machine\nthat transcribes, symbol by symbol, an input string of length $n$ into an\noutput string of length $n$. We prove that any function arising from a\ntransducer with $s$ states receiving input symbols encoded by $\\ell$ bits has a\nhazard-free circuit of size $2^{O(s+\\ell)}\\cdot n$ and depth $O(\\ell+ s\\cdot\n\\log n)$; in particular, if $s, \\ell\\in O(1)$, size and depth are\nasymptotically optimal.\n  We utilize our main result to derive efficient circuits for\n\\emph{$k$-recoverable addition}. Informally speaking, a code is\n\\emph{$k$-recoverable} if it does not increase uncertainty regarding the\nencoded value, so long as it is guaranteed that it is from\n$\\{x,x+1,\\ldots,x+k\\}$ for some $x\\in \\mathbb{N}_0$. We provide an\nasymptotically optimal $k$-recoverable code. We also realize a transducer with\n$O(k)$ states that adds two codewords from this $k$-recoverable code. Combined\nwith our main result, we obtain a hazard-free adder circuit of size $2^{O(k)}n$\nand depth $O(k\\log n)$ with respect to this code, i.e., a $k$-recoverable adder\ncircuit that adds two codewords of $n$ bits each. In other words,\n$k$-recoverable addition is fixed-parameter tractable with respect to $k$. We\nthen reduce the maximum size of the state machines involved to $O(1)$,\nresulting in a circuit for $k$-recoverable addition of size $O(n+k\\log k)$ and\ndepth $O(\\log n)$. Thus, if the uncertainties of each of the addends span\nintervals of length $O(n/\\log n)$, there is an \\emph{asymptotically optimal}\nadder that attains the best possible output uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:27:25 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 10:16:58 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Bund", "Johannes", ""], ["Lenzen", "Christoph", ""], ["Medina", "Moti", ""]]}]