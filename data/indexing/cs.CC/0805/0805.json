[{"id": "0805.0154", "submitter": "Kohtaro Tadaki", "authors": "Kohtaro Tadaki", "title": "The Tsallis entropy and the Shannon entropy of a universal probability", "comments": "5 pages, to appear in the Proceedings of the 2008 IEEE International\n  Symposium on Information Theory, Toronto, ON, Canada, July 6 - 11, 2008", "journal-ref": "2008 IEEE International Symposium on Information Theory, Toronto,\n  ON (2008) 2111-2115", "doi": "10.1109/ISIT.2008.4595362", "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the properties of Tsallis entropy and Shannon entropy from the point\nof view of algorithmic randomness. In algorithmic information theory, there are\ntwo equivalent ways to define the program-size complexity K(s) of a given\nfinite binary string s. In the standard way, K(s) is defined as the length of\nthe shortest input string for the universal self-delimiting Turing machine to\noutput s. In the other way, the so-called universal probability m is introduced\nfirst, and then K(s) is defined as -log_2 m(s) without reference to the concept\nof program-size. In this paper, we investigate the properties of the Shannon\nentropy, the power sum, and the Tsallis entropy of a universal probability by\nmeans of the notion of program-size complexity. We determine the convergence or\ndivergence of each of these three quantities, and evaluate its degree of\nrandomness if it converges.\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2008 21:32:09 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tadaki", "Kohtaro", ""]]}, {"id": "0805.0389", "submitter": "Chaitanya Swamy", "authors": "Chaitanya Swamy", "title": "Algorithms for Probabilistically-Constrained Models of Risk-Averse\n  Stochastic Optimization with Black-Box Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider various stochastic models that incorporate the notion of\nrisk-averseness into the standard 2-stage recourse model, and develop novel\ntechniques for solving the algorithmic problems arising in these models. A key\nnotable feature of our work that distinguishes it from work in some other\nrelated models, such as the (standard) budget model and the (demand-) robust\nmodel, is that we obtain results in the black-box setting, that is, where one\nis given only sampling access to the underlying distribution. Our first model,\nwhich we call the risk-averse budget model, incorporates the notion of\nrisk-averseness via a probabilistic constraint that restricts the probability\n(according to the underlying distribution) with which the second-stage cost may\nexceed a given budget B to at most a given input threshold \\rho. We also a\nconsider a closely-related model that we call the risk-averse robust model,\nwhere we seek to minimize the first-stage cost and the (1-\\rho)-quantile of the\nsecond-stage cost.\n  We obtain approximation algorithms for a variety of combinatorial\noptimization problems including the set cover, vertex cover, multicut on trees,\nmin cut, and facility location problems, in the risk-averse budget and robust\nmodels with black-box distributions. We obtain near-optimal solutions that\npreserve the budget approximately and incur a small blow-up of the probability\nthreshold (both of which are unavoidable). To the best of our knowledge, these\nare the first approximation results for problems involving probabilistic\nconstraints and black-box distributions. A major component of our results is a\nfully polynomial approximation scheme for solving the LP-relaxation of the\nrisk-averse problem.\n", "versions": [{"version": "v1", "created": "Sun, 4 May 2008 03:57:52 GMT"}], "update_date": "2008-05-06", "authors_parsed": [["Swamy", "Chaitanya", ""]]}, {"id": "0805.0498", "submitter": "Martin Mundhenk", "authors": "Michael Bauland (Knipp GmbH, Germany), Martin Mundhenk (Univ. Jena,\n  Germany), Thomas Schneider (Univ. of Manchester, UK), Henning Schnoor (Univ.\n  Kiel, Germany), Ilka Schnoor (Univ. Luebeck, Germany), Heribert Vollmer\n  (Univ. Hannover, Germany)", "title": "The Tractability of Model-Checking for LTL: The Good, the Bad, and the\n  Ugly Fragments", "comments": "27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": "ECCC Report TR08-028", "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a seminal paper from 1985, Sistla and Clarke showed that the\nmodel-checking problem for Linear Temporal Logic (LTL) is either NP-complete or\nPSPACE-complete, depending on the set of temporal operators used. If, in\ncontrast, the set of propositional operators is restricted, the complexity may\ndecrease. This paper systematically studies the model-checking problem for LTL\nformulae over restricted sets of propositional and temporal operators. For\nalmost all combinations of temporal and propositional operators, we determine\nwhether the model-checking problem is tractable (in P) or intractable\n(NP-hard). We then focus on the tractable cases, showing that they all are\nNL-complete or even logspace solvable. This leads to a surprising gap in\ncomplexity between tractable and intractable cases. It is worth noting that our\nanalysis covers an infinite set of problems, since there are infinitely many\nsets of propositional operators.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2008 09:48:23 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Bauland", "Michael", "", "Knipp GmbH, Germany"], ["Mundhenk", "Martin", "", "Univ. Jena,\n  Germany"], ["Schneider", "Thomas", "", "Univ. of Manchester, UK"], ["Schnoor", "Henning", "", "Univ.\n  Kiel, Germany"], ["Schnoor", "Ilka", "", "Univ. Luebeck, Germany"], ["Vollmer", "Heribert", "", "Univ. Hannover, Germany"]]}, {"id": "0805.0517", "submitter": "Jerrald Meek", "authors": "Jerrald Meek", "title": "Analysis of the Deterministic Polynomial Time Solvability of the\n  0-1-Knapsack Problem", "comments": "14 Pages; The author is delaying submission for publication so that\n  counter arguments may be proposed.\n  ftp://ftp%40micrognu%2ecom:anon%40anon@ftp.micrognu.com/pnenp/knapsack.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previously the author has demonstrated that a representative polynomial\nsearch partition is required to solve a NP-complete problem in deterministic\npolynomial time. It has also been demonstrated that finding such a partition\ncan only be done in deterministic polynomial time if the form of the problem\nprovides a simple method for producing the partition. It is the purpose of this\narticle to demonstrate that no deterministic polynomial time method exists to\nproduce a representative polynomial search partition for the Knapsack problem.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2008 12:34:27 GMT"}, {"version": "v2", "created": "Thu, 8 May 2008 18:03:10 GMT"}, {"version": "v3", "created": "Mon, 25 Aug 2008 15:11:52 GMT"}, {"version": "v4", "created": "Fri, 5 Sep 2008 18:51:28 GMT"}, {"version": "v5", "created": "Sat, 6 Sep 2008 23:13:44 GMT"}], "update_date": "2008-09-07", "authors_parsed": [["Meek", "Jerrald", ""]]}, {"id": "0805.0615", "submitter": "Yingquan Wu", "authors": "Yingquan Wu", "title": "On Expanded Cyclic Codes", "comments": "23 pages. Submitted for publication in IEEE Trans. Inform. Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper has a threefold purpose. The first purpose is to present an\nexplicit description of expanded cyclic codes defined in $\\GF(q^m)$. The\nproposed explicit construction of expanded generator matrix and expanded parity\ncheck matrix maintains the symbol-wise algebraic structure and thus keeps many\nimportant original characteristics. The second purpose of this paper is to\nidentify a class of constant-weight cyclic codes. Specifically, we show that a\nwell-known class of $q$-ary BCH codes excluding the all-zero codeword are\nconstant-weight cyclic codes. Moreover, we show this class of codes achieve the\nPlotkin bound. The last purpose of the paper is to characterize expanded cyclic\ncodes utilizing the proposed expanded generator matrix and parity check matrix.\nWe characterize the properties of component codewords of a codeword and\nparticularly identify the precise conditions under which a codeword can be\nrepresented by a subbasis. Our developments reveal an alternative while more\ngeneral view on the subspace subcodes of Reed-Solomon codes. With the new\ninsights, we present an improved lower bound on the minimum distance of an\nexpanded cyclic code by exploiting the generalized concatenated structure. We\nalso show that the fixed-rate binary expanded Reed-Solomon codes are\nasymptotically \"bad\", in the sense that the ratio of minimum distance over code\nlength diminishes with code length going to infinity. It overturns the\nprevalent conjecture that they are \"good\" codes and deviates from the ensemble\nof generalized Reed-Solomon codes which asymptotically achieves the\nGilbert-Varshamov bound.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2008 22:51:12 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2008 16:53:04 GMT"}], "update_date": "2008-07-08", "authors_parsed": [["Wu", "Yingquan", ""]]}, {"id": "0805.0851", "submitter": "Sebastien Tixeuil", "authors": "Samuel Bernard (LIP6), St\\'ephane Devismes (LRI), Maria Gradinariu\n  Potop-Butucaru (LIP6, INRIA Rocquencourt), S\\'ebastien Tixeuil (LIP6)", "title": "Bounds for self-stabilization in unidirectional networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-6524", "categories": "cs.DS cs.CC cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed algorithm is self-stabilizing if after faults and attacks hit\nthe system and place it in some arbitrary global state, the systems recovers\nfrom this catastrophic situation without external intervention in finite time.\nUnidirectional networks preclude many common techniques in self-stabilization\nfrom being used, such as preserving local predicates. In this paper, we\ninvestigate the intrinsic complexity of achieving self-stabilization in\nunidirectional networks, and focus on the classical vertex coloring problem.\nWhen deterministic solutions are considered, we prove a lower bound of $n$\nstates per process (where $n$ is the network size) and a recovery time of at\nleast $n(n-1)/2$ actions in total. We present a deterministic algorithm with\nmatching upper bounds that performs in arbitrary graphs. When probabilistic\nsolutions are considered, we observe that at least $\\Delta + 1$ states per\nprocess and a recovery time of $\\Omega(n)$ actions in total are required (where\n$\\Delta$ denotes the maximal degree of the underlying simple undirected graph).\nWe present a probabilistically self-stabilizing algorithm that uses\n$\\mathtt{k}$ states per process, where $\\mathtt{k}$ is a parameter of the\nalgorithm. When $\\mathtt{k}=\\Delta+1$, the algorithm recovers in expected\n$O(\\Delta n)$ actions. When $\\mathtt{k}$ may grow arbitrarily, the algorithm\nrecovers in expected O(n) actions in total. Thus, our algorithm can be made\noptimal with respect to space or time complexity.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2008 07:39:14 GMT"}, {"version": "v2", "created": "Tue, 13 May 2008 08:06:10 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Bernard", "Samuel", "", "LIP6"], ["Devismes", "St\u00e9phane", "", "LRI"], ["Potop-Butucaru", "Maria Gradinariu", "", "LIP6, INRIA Rocquencourt"], ["Tixeuil", "S\u00e9bastien", "", "LIP6"]]}, {"id": "0805.0954", "submitter": "Shmuel Onn", "authors": "Jon Lee, Shmuel Onn, Robert Weismantel", "title": "Nonlinear Optimization over a Weighted Independence System", "comments": null, "journal-ref": "SIAM Journal on Discrete Mathematics, 23:1667--1681, 2009", "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimizing a nonlinear objective function over a\nweighted independence system presented by a linear-optimization oracle. We\nprovide a polynomial-time algorithm that determines an r-best solution for\nnonlinear functions of the total weight of an independent set, where r is a\nconstant that depends on certain Frobenius numbers of the individual weights\nand is independent of the size of the ground set. In contrast, we show that\nfinding an optimal (0-best) solution requires exponential time even in a very\nspecial case of the problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2008 11:05:01 GMT"}], "update_date": "2009-11-21", "authors_parsed": [["Lee", "Jon", ""], ["Onn", "Shmuel", ""], ["Weismantel", "Robert", ""]]}, {"id": "0805.1030", "submitter": "Martin Mann", "authors": "Stephane Zampelli, Martin Mann, Yves Deville and Rolf Backofen", "title": "Decomposition Techniques for Subgraph Matching", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": "INGI2008/03", "categories": "cs.CC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the constraint programming framework, state-of-the-art static and dynamic\ndecomposition techniques are hard to apply to problems with complete initial\nconstraint graphs. For such problems, we propose a hybrid approach of these\ntechniques in the presence of global constraints. In particular, we solve the\nsubgraph isomorphism problem. Further we design specific heuristics for this\nhard problem, exploiting its special structure to achieve decomposition. The\nunderlying idea is to precompute a static heuristic on a subset of its\nconstraint network, to follow this static ordering until a first problem\ndecomposition is available, and to switch afterwards to a fully propagated,\ndynamically decomposing search. Experimental results show that, for sparse\ngraphs, our decomposition method solves more instances than dedicated,\nstate-of-the-art matching algorithms or standard constraint programming\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2008 17:41:47 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Zampelli", "Stephane", ""], ["Mann", "Martin", ""], ["Deville", "Yves", ""], ["Backofen", "Rolf", ""]]}, {"id": "0805.1292", "submitter": "Martin Ziegler", "authors": "Martin Ziegler", "title": "Physically-Relativized Church-Turing Hypotheses", "comments": "interdisciplinary paper: philosophy of physics, computational\n  physics, computational complexity and computability", "journal-ref": "pp.1431-1447 in Applied Mathematics and Computation vol.215:4\n  (2009)", "doi": "10.1016/j.amc.2009.04.062", "report-no": null, "categories": "physics.comp-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We turn `the' Church-Turing Hypothesis from an ambiguous source of\nsensational speculations into a (collection of) sound and well-defined\nscientific problem(s):\n  Examining recent controversies, and causes for misunderstanding, concerning\nthe state of the Church-Turing Hypothesis (CTH), suggests to study the CTH\nrelative to an arbitrary but specific physical theory--rather than vaguely\nreferring to ``nature'' in general. To this end we combine (and compare)\nphysical structuralism with (models of computation in) complexity theory. The\nbenefit of this formal framework is illustrated by reporting on some previous,\nand giving one new, example result(s) of computability and complexity in\ncomputational physics.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2008 07:27:37 GMT"}], "update_date": "2010-05-10", "authors_parsed": [["Ziegler", "Martin", ""]]}, {"id": "0805.1385", "submitter": "Timothy Y. Chow", "authors": "Timothy Y. Chow", "title": "Almost-natural proofs", "comments": "Journal version; main result has been strengthened, using a stronger\n  version of Razborov--Rudich; new proof of main result by Salil Vadhan added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Razborov and Rudich have shown that so-called \"natural proofs\" are not useful\nfor separating P from NP unless hard pseudorandom number generators do not\nexist. This famous result is widely regarded as a serious barrier to proving\nstrong lower bounds in circuit complexity theory.\n  By definition, a natural combinatorial property satisfies two conditions,\nconstructivity and largeness. Our main result is that if the largeness\ncondition is weakened slightly, then not only does the Razborov-Rudich proof\nbreak down, but such \"almost-natural\" (and useful) properties provably exist.\nSpecifically, under the same pseudorandomness assumption that Razborov and\nRudich make, a simple, explicit property that we call \"discrimination\" suffices\nto separate P/poly from NP; discrimination is nearly linear-time computable and\nalmost large, having density 2^{-q(n)} where q is a quasi-polynomial function.\nFor those who hope to separate P from NP using random function properties in\nsome sense, discrimination is interesting, because it is constructive, yet may\nbe thought of as a minor alteration of a property of a random function.\n  The proof relies heavily on the self-defeating character of natural proofs.\nOur proof technique also yields an unconditional result, namely that there\nexist almost-large and useful properties that are constructive, if we are\nallowed to call non-uniform low-complexity classes \"constructive.\" We note,\nthough, that this unconditional result can also be proved by a more\nconventional counting argument.\n  Finally, we give an alternative proof, communicated to us by Salil Vadhan at\nFOCS 2008, of one of our theorems, and we make some speculative remarks on the\nfuture prospects for proving strong circuit lower bounds.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2008 18:14:43 GMT"}, {"version": "v2", "created": "Fri, 8 Aug 2008 14:37:34 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2009 15:37:23 GMT"}], "update_date": "2009-03-30", "authors_parsed": [["Chow", "Timothy Y.", ""]]}, {"id": "0805.1457", "submitter": "Nicolas Markey", "authors": "Patricia Bouyer, Kim G. Larsen, and Nicolas Markey", "title": "Model Checking One-clock Priced Timed Automata", "comments": "28 pages", "journal-ref": "Logical Methods in Computer Science, Volume 4, Issue 2 (June 20,\n  2008) lmcs:828", "doi": "10.2168/LMCS-4(2:9)2008", "report-no": null, "categories": "cs.LO cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the model of priced (a.k.a. weighted) timed automata, an\nextension of timed automata with cost information on both locations and\ntransitions, and we study various model-checking problems for that model based\non extensions of classical temporal logics with cost constraints on modalities.\nWe prove that, under the assumption that the model has only one clock,\nmodel-checking this class of models against the logic WCTL, CTL with\ncost-constrained modalities, is PSPACE-complete (while it has been shown\nundecidable as soon as the model has three clocks). We also prove that\nmodel-checking WMTL, LTL with cost-constrained modalities, is decidable only if\nthere is a single clock in the model and a single stopwatch cost variable\n(i.e., whose slopes lie in {0,1}).\n", "versions": [{"version": "v1", "created": "Sat, 10 May 2008 08:56:07 GMT"}, {"version": "v2", "created": "Fri, 20 Jun 2008 10:43:10 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bouyer", "Patricia", ""], ["Larsen", "Kim G.", ""], ["Markey", "Nicolas", ""]]}, {"id": "0805.1464", "submitter": "Guillaume Burel", "authors": "Guillaume Burel (Max Planck Institute for Informatics)", "title": "Efficiently Simulating Higher-Order Arithmetic by a First-Order Theory\n  Modulo", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 1 (March 17,\n  2011) lmcs:861", "doi": "10.2168/LMCS-7(1:3)2011", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deduction modulo, a theory is not represented by a set of axioms but by a\ncongruence on propositions modulo which the inference rules of standard\ndeductive systems---such as for instance natural deduction---are applied.\nTherefore, the reasoning that is intrinsic of the theory does not appear in the\nlength of proofs. In general, the congruence is defined through a rewrite\nsystem over terms and propositions. We define a rigorous framework to study\nproof lengths in deduction modulo, where the congruence must be computed in\npolynomial time. We show that even very simple rewrite systems lead to\narbitrary proof-length speed-ups in deduction modulo, compared to using axioms.\nAs higher-order logic can be encoded as a first-order theory in deduction\nmodulo, we also study how to reinterpret, thanks to deduction modulo, the\nspeed-ups between higher-order and first-order arithmetics that were stated by\nG\\\"odel. We define a first-order rewrite system with a congruence decidable in\npolynomial time such that proofs of higher-order arithmetic can be linearly\ntranslated into first-order arithmetic modulo that system. We also present the\nwhole higher-order arithmetic as a first-order system without resorting to any\naxiom, where proofs have the same length as in the axiomatic presentation.\n", "versions": [{"version": "v1", "created": "Sat, 10 May 2008 10:42:54 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2010 10:12:20 GMT"}, {"version": "v3", "created": "Wed, 13 Oct 2010 13:08:40 GMT"}, {"version": "v4", "created": "Thu, 13 Jan 2011 08:25:47 GMT"}, {"version": "v5", "created": "Wed, 16 Mar 2011 20:55:57 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Burel", "Guillaume", "", "Max Planck Institute for Informatics"]]}, {"id": "0805.1765", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Homin K. Lee, Kevin Matulef, Rocco A. Servedio,\n  Andrew Wan", "title": "Efficiently Testing Sparse GF(2) Polynomials", "comments": "Full version of ICALP 2008 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first algorithm that is both query-efficient and time-efficient\nfor testing whether an unknown function $f: \\{0,1\\}^n \\to \\{0,1\\}$ is an\n$s$-sparse GF(2) polynomial versus $\\eps$-far from every such polynomial. Our\nalgorithm makes $\\poly(s,1/\\eps)$ black-box queries to $f$ and runs in time $n\n\\cdot \\poly(s,1/\\eps)$. The only previous algorithm for this testing problem\n\\cite{DLM+:07} used poly$(s,1/\\eps)$ queries, but had running time exponential\nin $s$ and super-polynomial in $1/\\eps$.\n  Our approach significantly extends the ``testing by implicit learning''\nmethodology of \\cite{DLM+:07}. The learning component of that earlier work was\na brute-force exhaustive search over a concept class to find a hypothesis\nconsistent with a sample of random examples. In this work, the learning\ncomponent is a sophisticated exact learning algorithm for sparse GF(2)\npolynomials due to Schapire and Sellie \\cite{SchapireSellie:96}. A crucial\nelement of this work, which enables us to simulate the membership queries\nrequired by \\cite{SchapireSellie:96}, is an analysis establishing new\nproperties of how sparse GF(2) polynomials simplify under certain restrictions\nof ``low-influence'' sets of variables.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2008 00:51:30 GMT"}], "update_date": "2008-05-14", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Lee", "Homin K.", ""], ["Matulef", "Kevin", ""], ["Servedio", "Rocco A.", ""], ["Wan", "Andrew", ""]]}, {"id": "0805.2027", "submitter": "Christos Dimitrakakis", "authors": "Christos Dimitrakakis and Michail G. Lagoudakis", "title": "Rollout Sampling Approximate Policy Iteration", "comments": "18 pages, 2 figures, to appear in Machine Learning 72(3). Presented\n  at EWRL08, to be presented at ECML 2008", "journal-ref": null, "doi": "10.1007/s10994-008-5069-3", "report-no": null, "categories": "cs.LG cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several researchers have recently investigated the connection between\nreinforcement learning and classification. We are motivated by proposals of\napproximate policy iteration schemes without value functions which focus on\npolicy representation using classifiers and address policy learning as a\nsupervised learning problem. This paper proposes variants of an improved policy\niteration scheme which addresses the core sampling problem in evaluating a\npolicy through simulation as a multi-armed bandit machine. The resulting\nalgorithm offers comparable performance to the previous algorithm achieved,\nhowever, with significantly less computational effort. An order of magnitude\nimprovement is demonstrated experimentally in two standard reinforcement\nlearning domains: inverted pendulum and mountain-car.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2008 11:19:19 GMT"}, {"version": "v2", "created": "Sun, 6 Jul 2008 17:36:33 GMT"}], "update_date": "2008-07-06", "authors_parsed": [["Dimitrakakis", "Christos", ""], ["Lagoudakis", "Michail G.", ""]]}, {"id": "0805.2081", "submitter": "Genta Ito", "authors": "Genta Ito", "title": "Least change in the Determinant or Permanent of a matrix under\n  perturbation of a single element: continuous and discrete cases", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate the problem of finding the probability that the determinant of a\nmatrix undergoes the least change upon perturbation of one of its elements,\nprovided that most or all of the elements of the matrix are chosen at random\nand that the randomly chosen elements have a fixed probability of being\nnon-zero. Also, we show that the procedure for finding the probability that the\ndeterminant undergoes the least change depends on whether the random variables\nfor the matrix elements are continuous or discrete.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2008 15:01:46 GMT"}], "update_date": "2008-05-15", "authors_parsed": [["Ito", "Genta", ""]]}, {"id": "0805.2083", "submitter": "Genta Ito", "authors": "Genta Ito", "title": "Approximate formulation of the probability that the Determinant or\n  Permanent of a matrix undergoes the least change under perturbation of a\n  single element", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an earlier paper, we discussed the probability that the determinant of a\nmatrix undergoes the least change upon perturbation of one of its elements,\nprovided that most or all of the elements of the matrix are chosen at random\nand that the randomly chosen elements have a fixed probability of being\nnon-zero. In this paper, we derive approximate formulas for that probability by\nassuming that the terms in the permanent of a matrix are independent of one\nanother, and we apply that assumption to several classes of matrices. In the\ncourse of deriving those formulas, we identified several integer sequences that\nare not listed on Sloane's Web site.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2008 15:05:44 GMT"}], "update_date": "2008-05-15", "authors_parsed": [["Ito", "Genta", ""]]}, {"id": "0805.2135", "submitter": "Alexander A. Sherstov", "authors": "Alexander A. Sherstov", "title": "Communication Lower Bounds Using Dual Polynomials", "comments": "35 pages. Invited survey for The Bulletin of the European Association\n  for Theoretical Computer Science (EATCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations of Boolean functions by real polynomials play an important\nrole in complexity theory. Typically, one is interested in the least degree of\na polynomial p(x_1,...,x_n) that approximates or sign-represents a given\nBoolean function f(x_1,...,x_n). This article surveys a new and growing body of\nwork in communication complexity that centers around the dual objects, i.e.,\npolynomials that certify the difficulty of approximating or sign-representing a\ngiven function. We provide a unified guide to the following results, complete\nwith all the key proofs:\n  (1) Sherstov's Degree/Discrepancy Theorem, which translates lower bounds on\nthe threshold degree of a Boolean function into upper bounds on the discrepancy\nof a related function;\n  (2) Two different methods for proving lower bounds on bounded-error\ncommunication based on the approximate degree: Sherstov's pattern matrix method\nand Shi and Zhu's block composition method;\n  (3) Extension of the pattern matrix method to the multiparty model, obtained\nby Lee and Shraibman and by Chattopadhyay and Ada, and the resulting improved\nlower bounds for DISJOINTNESS;\n  (4) David and Pitassi's separation of NP and BPP in multiparty communication\ncomplexity for k=(1-eps)log n players.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2008 18:52:06 GMT"}], "update_date": "2008-05-15", "authors_parsed": [["Sherstov", "Alexander A.", ""]]}, {"id": "0805.2170", "submitter": "Jerrald Meek", "authors": "Jerrald Meek", "title": "Independence of P vs. NP in regards to oracle relativizations", "comments": "14 Pages;\n  ftp://ftp%40micrognu.com:anon%40anon@ftp.micrognu.com/pnenp/oracle.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the third article in a series of four articles dealing with the P vs.\nNP question. The purpose of this work is to demonstrate that the methods used\nin the first two articles of this series are not affected by oracle\nrelativizations. Furthermore, the solution to the P vs. NP problem is actually\nindependent of oracle relativizations.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2008 21:10:55 GMT"}, {"version": "v2", "created": "Fri, 16 May 2008 18:30:31 GMT"}, {"version": "v3", "created": "Tue, 20 May 2008 18:57:59 GMT"}, {"version": "v4", "created": "Wed, 21 May 2008 19:45:03 GMT"}, {"version": "v5", "created": "Sat, 23 Aug 2008 00:37:44 GMT"}, {"version": "v6", "created": "Thu, 4 Sep 2008 02:45:30 GMT"}], "update_date": "2008-09-04", "authors_parsed": [["Meek", "Jerrald", ""]]}, {"id": "0805.2421", "submitter": "Martin Gairing", "authors": "Martin Gairing", "title": "Malicious Bayesian Congestion Games", "comments": "18 pages, submitted to WAOA'08", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce malicious Bayesian congestion games as an\nextension to congestion games where players might act in a malicious way. In\nsuch a game each player has two types. Either the player is a rational player\nseeking to minimize her own delay, or - with a certain probability - the player\nis malicious in which case her only goal is to disturb the other players as\nmuch as possible.\n  We show that such games do in general not possess a Bayesian Nash equilibrium\nin pure strategies (i.e. a pure Bayesian Nash equilibrium). Moreover, given a\ngame, we show that it is NP-complete to decide whether it admits a pure\nBayesian Nash equilibrium. This result even holds when resource latency\nfunctions are linear, each player is malicious with the same probability, and\nall strategy sets consist of singleton sets. For a slightly more restricted\nclass of malicious Bayesian congestion games, we provide easy checkable\nproperties that are necessary and sufficient for the existence of a pure\nBayesian Nash equilibrium.\n  In the second part of the paper we study the impact of the malicious types on\nthe overall performance of the system (i.e. the social cost). To measure this\nimpact, we use the Price of Malice. We provide (tight) bounds on the Price of\nMalice for an interesting class of malicious Bayesian congestion games.\nMoreover, we show that for certain congestion games the advent of malicious\ntypes can also be beneficial to the system in the sense that the social cost of\nthe worst case equilibrium decreases. We provide a tight bound on the maximum\nfactor by which this happens.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2008 23:00:44 GMT"}, {"version": "v2", "created": "Thu, 5 Jun 2008 19:02:21 GMT"}], "update_date": "2008-06-05", "authors_parsed": [["Gairing", "Martin", ""]]}, {"id": "0805.2691", "submitter": "Kohtaro Tadaki", "authors": "Kohtaro Tadaki", "title": "Equivalent characterizations of partial randomness for a recursively\n  enumerable real", "comments": "19 pages, LaTeX2e, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A real number \\alpha is called recursively enumerable if there exists a\ncomputable, increasing sequence of rational numbers which converges to \\alpha.\nThe randomness of a recursively enumerable real \\alpha can be characterized in\nvarious ways using each of the notions; program-size complexity, Martin-L\\\"{o}f\ntest, Chaitin's \\Omega number, the domination and \\Omega-likeness of \\alpha,\nthe universality of a computable, increasing sequence of rational numbers which\nconverges to \\alpha, and universal probability. In this paper, we generalize\nthese characterizations of randomness over the notion of partial randomness by\nparameterizing each of the notions above by a real number T\\in(0,1]. We thus\npresent several equivalent characterizations of partial randomness for a\nrecursively enumerable real number.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2008 17:44:34 GMT"}], "update_date": "2008-05-20", "authors_parsed": [["Tadaki", "Kohtaro", ""]]}, {"id": "0805.3058", "submitter": "Silvano Di Zenzo", "authors": "Silvano Di Zenzo", "title": "A New Structural Property of SAT", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review a minimum set of notions from our previous paper on structural\nproperties of SAT at arXiv:0802.1790 that will allow us to define and discuss\nthe \"complete internal independence\" of a decision problem. This property is\nstrictly stronger than the independence property that was called \"strong\ninternal independence\" in cited paper. We show that SAT exhibits this property.\nWe argue that this form of independence of a decision problem is the strongest\npossible for a problem. By relying upon this maximally strong form of internal\nindependence, we reformulate in more strict terms the informal remarks on\npossible exponentiality of SAT that concluded our previous paper. The net\nresult of that reformulation is a hint for a proof for SAT being exponential.\nWe conjecture that a complete proof of that proposition can be obtained by\nstrictly following the line of given hint of proof.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2008 12:07:51 GMT"}], "update_date": "2008-05-21", "authors_parsed": [["Di Zenzo", "Silvano", ""]]}, {"id": "0805.4049", "submitter": "Zhi Xu", "authors": "Zhi Xu, J. Shallit", "title": "An NP-hardness Result on the Monoid Frobenius Problem", "comments": "2 pages, working paper; an error in Problem 5 is corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following problem is NP-hard: given a regular expression $E$, decide if\n$E^*$ is not co-finite.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2008 16:18:19 GMT"}, {"version": "v2", "created": "Tue, 27 May 2008 22:51:22 GMT"}, {"version": "v3", "created": "Mon, 30 Jun 2008 15:00:26 GMT"}], "update_date": "2008-06-30", "authors_parsed": [["Xu", "Zhi", ""], ["Shallit", "J.", ""]]}, {"id": "0805.4072", "submitter": "Michael Thomas", "authors": "Pierre McKenzie, Michael Thomas and Heribert Vollmer", "title": "Extensional Uniformity for Boolean Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imposing an extensional uniformity condition on a non-uniform circuit\ncomplexity class C means simply intersecting C with a uniform class L. By\ncontrast, the usual intensional uniformity conditions require that a\nresource-bounded machine be able to exhibit the circuits in the circuit family\ndefining C. We say that (C,L) has the \"Uniformity Duality Property\" if the\nextensionally uniform class C \\cap L can be captured intensionally by means of\nadding so-called \"L-numerical predicates\" to the first-order descriptive\ncomplexity apparatus describing the connection language of the circuit family\ndefining C.\n  This paper exhibits positive instances and negative instances of the\nUniformity Duality Property.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2008 08:49:36 GMT"}, {"version": "v2", "created": "Wed, 28 May 2008 07:31:01 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["McKenzie", "Pierre", ""], ["Thomas", "Michael", ""], ["Vollmer", "Heribert", ""]]}, {"id": "0805.4718", "submitter": "Radoslaw Hofman", "authors": "Radoslaw Hofman", "title": "Report on article The Travelling Salesman Problem: A Linear Programming\n  Formulation", "comments": "Counter example for extended version of Diaby model for his\n  publication in arXiv:0803.4354v1 [cs.DM]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes counter example prepared in order to prove that linear\nformulation of TSP problem proposed in [arXiv:0803.4354] is incorrect (it\napplies also to QAP problem formulation in [arXiv:0802.4307]). Article refers\nnot only to model itself, but also to ability of extension of proposed model to\nbe correct.\n", "versions": [{"version": "v1", "created": "Fri, 30 May 2008 10:22:45 GMT"}, {"version": "v2", "created": "Mon, 2 Jun 2008 07:04:11 GMT"}], "update_date": "2008-06-02", "authors_parsed": [["Hofman", "Radoslaw", ""]]}]