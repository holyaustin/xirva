[{"id": "0712.0084", "submitter": "Gilles Champenois", "authors": "Gilles Champenois", "title": "From vectors to mnesors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mnesor theory is the adaptation of vectors to artificial intelligence.\nThe scalar field is replaced by a lattice. Addition becomes idempotent and\nmultiplication is interpreted as a selection operation. We also show that\nmnesors can be the foundation for a linear calculus.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2007 14:37:07 GMT"}, {"version": "v2", "created": "Thu, 8 May 2008 21:26:54 GMT"}, {"version": "v3", "created": "Wed, 23 Jul 2008 07:38:39 GMT"}, {"version": "v4", "created": "Sun, 24 May 2009 17:12:25 GMT"}], "update_date": "2009-05-24", "authors_parsed": [["Champenois", "Gilles", ""]]}, {"id": "0712.0165", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "On the Accepting Power of 2-Tape B\\\"uchi Automata", "comments": null, "journal-ref": "23rd International Symposium on Theoretical Aspects of Computer\n  Science, STACS 2006, France (2006)", "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": null, "abstract": "  We show that, from a topological point of view, 2-tape B\\\"uchi automata have\nthe same accepting power than Turing machines equipped with a B\\\"uchi\nacceptance condition. In particular, we show that for every non null recursive\nordinal alpha, there exist some Sigma^0_alpha-complete and some\nPi^0_alpha-complete infinitary rational relations accepted by 2-tape B\\\"uchi\nautomata. This very surprising result gives answers to questions of W. Thomas\n[Automata and Quantifier Hierarchies, in: Formal Properties of Finite automata\nand Applications, Ramatuelle, 1988, LNCS 386, Springer, 1989, p.104-119], of P.\nSimonnet [Automates et Th\\'eorie Descriptive, Ph. D. Thesis, Universit\\'e Paris\n7, March 1992], and of H. Lescow and W. Thomas [Logical Specifications of\nInfinite Computations, In: \"A Decade of Concurrency\", LNCS 803, Springer, 1994,\np. 583-621].\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2007 18:36:34 GMT"}], "update_date": "2007-12-04", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}, {"id": "0712.0171", "submitter": "Elchanan Mossel", "authors": "Amin Coja-Oghlan and Elchanan Mossel and Dan Vilenchik", "title": "A Spectral Approach to Analyzing Belief Propagation for 3-Coloring", "comments": null, "journal-ref": "Combinatorics, Probability and Computing 18 (2009) 881 - 912", "doi": "10.1017/S096354830900981X", "report-no": null, "categories": "cs.CC cs.AI cs.DM", "license": null, "abstract": "  Contributing to the rigorous understanding of BP, in this paper we relate the\nconvergence of BP to spectral properties of the graph. This encompasses a\nresult for random graphs with a ``planted'' solution; thus, we obtain the first\nrigorous result on BP for graph coloring in the case of a complex graphical\nstructure (as opposed to trees). In particular, the analysis shows how Belief\nPropagation breaks the symmetry between the $3!$ possible permutations of the\ncolor classes.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2007 19:34:59 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Coja-Oghlan", "Amin", ""], ["Mossel", "Elchanan", ""], ["Vilenchik", "Dan", ""]]}, {"id": "0712.0451", "submitter": "Alejandro Chinea Manrique De Lara", "authors": "Alejandro Chinea Manrique De Lara", "title": "A Reactive Tabu Search Algorithm for Stimuli Generation in\n  Psycholinguistics", "comments": "Artificial Intelligence in Science and Technology AISAT 2004\n  Conference. 8 pages, 5 figures, 3 tables", "journal-ref": "Artificial Intelligence in Science and Technology AISAT 2004\n  Conference", "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DM cs.LG", "license": null, "abstract": "  The generation of meaningless \"words\" matching certain statistical and/or\nlinguistic criteria is frequently needed for experimental purposes in\nPsycholinguistics. Such stimuli receive the name of pseudowords or nonwords in\nthe Cognitive Neuroscience literatue. The process for building nonwords\nsometimes has to be based on linguistic units such as syllables or morphemes,\nresulting in a numerical explosion of combinations when the size of the\nnonwords is increased. In this paper, a reactive tabu search scheme is proposed\nto generate nonwords of variables size. The approach builds pseudowords by\nusing a modified Metaheuristic algorithm based on a local search procedure\nenhanced by a feedback-based scheme. Experimental results show that the new\nalgorithm is a practical and effective tool for nonword generation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2007 08:52:46 GMT"}], "update_date": "2007-12-05", "authors_parsed": [["De Lara", "Alejandro Chinea Manrique", ""]]}, {"id": "0712.1363", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "Undecidable Problems About Timed Automata", "comments": null, "journal-ref": "Dans Proceedings of the 4th International Conference on Formal\n  Modelling and Analysis of Timed Systems - FORMATS'06, France (2006)", "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": null, "abstract": "  We solve some decision problems for timed automata which were recently raised\nby S. Tripakis in [ Folk Theorems on the Determinization and Minimization of\nTimed Automata, in the Proceedings of the International Workshop FORMATS'2003,\nLNCS, Volume 2791, p. 182-188, 2004 ] and by E. Asarin in [ Challenges in Timed\nLanguages, From Applied Theory to Basic Theory, Bulletin of the EATCS, Volume\n83, p. 106-120, 2004 ]. In particular, we show that one cannot decide whether a\ngiven timed automaton is determinizable or whether the complement of a timed\nregular language is timed regular. We show that the problem of the minimization\nof the number of clocks of a timed automaton is undecidable. It is also\nundecidable whether the shuffle of two timed regular languages is timed\nregular. We show that in the case of timed B\\\"uchi automata accepting infinite\ntimed words some of these problems are Pi^1_1-hard, hence highly undecidable\n(located beyond the arithmetical hierarchy).\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2007 20:11:42 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}, {"id": "0712.1402", "submitter": "Allan Sly", "authors": "Guy Bresler, Elchanan Mossel, Allan Sly", "title": "Reconstruction of Markov Random Fields from Samples: Some Easy\n  Observations and Algorithms", "comments": "14 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov random fields are used to model high dimensional distributions in a\nnumber of applied areas. Much recent interest has been devoted to the\nreconstruction of the dependency structure from independent samples from the\nMarkov random fields. We analyze a simple algorithm for reconstructing the\nunderlying graph defining a Markov random field on $n$ nodes and maximum degree\n$d$ given observations. We show that under mild non-degeneracy conditions it\nreconstructs the generating graph with high probability using $\\Theta(d\n\\epsilon^{-2}\\delta^{-4} \\log n)$ samples where $\\epsilon,\\delta$ depend on the\nlocal interactions. For most local interaction $\\eps,\\delta$ are of order\n$\\exp(-O(d))$.\n  Our results are optimal as a function of $n$ up to a multiplicative constant\ndepending on $d$ and the strength of the local interactions. Our results seem\nto be the first results for general models that guarantee that {\\em the}\ngenerating model is reconstructed. Furthermore, we provide explicit $O(n^{d+2}\n\\epsilon^{-2}\\delta^{-4} \\log n)$ running time bound. In cases where the\nmeasure on the graph has correlation decay, the running time is $O(n^2 \\log n)$\nfor all fixed $d$. We also discuss the effect of observing noisy samples and\nshow that as long as the noise level is low, our algorithm is effective. On the\nother hand, we construct an example where large noise implies\nnon-identifiability even for generic noise and interactions. Finally, we\nbriefly show that in some simple cases, models with hidden nodes can also be\nrecovered.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 06:50:36 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2010 19:30:26 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Bresler", "Guy", ""], ["Mossel", "Elchanan", ""], ["Sly", "Allan", ""]]}, {"id": "0712.1499", "submitter": "Klaus Aehlig", "authors": "Klaus Aehlig, Arnold Beckmann", "title": "On the computational complexity of cut-reduction", "comments": "41 pages, technical report (CS, Swansea University)", "journal-ref": null, "doi": null, "report-no": "CSR15-2007", "categories": "cs.LO cs.CC", "license": null, "abstract": "  Using appropriate notation systems for proofs, cut-reduction can often be\nrendered feasible on these notations, and explicit bounds can be given.\nDeveloping a suitable notation system for Bounded Arithmetic, and applying\nthese bounds, all the known results on definable functions of certain such\ntheories can be reobtained in a uniform way.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 14:58:27 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Aehlig", "Klaus", ""], ["Beckmann", "Arnold", ""]]}, {"id": "0712.1532", "submitter": "Peter Jonsson", "authors": "Peter Jonsson, Andrei Krokhin, Fredrik Kuivinen", "title": "Hard constraint satisfaction problems have hard gaps at location 1", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  An instance of Max CSP is a finite collection of constraints on a set of\nvariables, and the goal is to assign values to the variables that maximises the\nnumber of satisfied constraints. Max CSP captures many well-known problems\n(such as Max k-SAT and Max Cut) and is consequently NP-hard. Thus, it is\nnatural to study how restrictions on the allowed constraint types (or\nconstraint languages) affect the complexity and approximability of Max CSP. The\nPCP theorem is equivalent to the existence of a constraint language for which\nMax CSP has a hard gap at location 1, i.e. it is NP-hard to distinguish between\nsatisfiable instances and instances where at most some constant fraction of the\nconstraints are satisfiable. All constraint languages, for which the CSP\nproblem (i.e., the problem of deciding whether all constraints can be\nsatisfied) is currently known to be NP-hard, have a certain algebraic property.\nWe prove that any constraint language with this algebraic property makes Max\nCSP have a hard gap at location 1 which, in particular, implies that such\nproblems cannot have a PTAS unless P = NP. We then apply this result to Max CSP\nrestricted to a single constraint type; this class of problems contains, for\ninstance, Max Cut and Max DiCut. Assuming P $\\neq$ NP, we show that such\nproblems do not admit PTAS except in some trivial cases. Our results hold even\nif the number of occurrences of each variable is bounded by a constant. We use\nthese results to partially answer open questions and strengthen results by\nEngebretsen et al. [Theor. Comput. Sci., 312 (2004), pp. 17--45], Feder et al.\n[Discrete Math., 307 (2007), pp. 386--392], Krokhin and Larose [Proc.\nPrinciples and Practice of Constraint Programming (2005), pp. 388--402], and\nJonsson and Krokhin [J. Comput. System Sci., 73 (2007), pp. 691--702]\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2007 16:42:18 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Jonsson", "Peter", ""], ["Krokhin", "Andrei", ""], ["Kuivinen", "Fredrik", ""]]}, {"id": "0712.1996", "submitter": "Walied Othman", "authors": "Bart Kuijpers, Walied Othman, Rafael Grimson", "title": "A case study of the difficulty of quantifier elimination in constraint\n  databases: the alibi query in moving object databases", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DB", "license": null, "abstract": "  In the constraint database model, spatial and spatio-temporal data are stored\nby boolean combinations of polynomial equalities and inequalities over the real\nnumbers. The relational calculus augmented with polynomial constraints is the\nstandard first-order query language for constraint databases. Although the\nexpressive power of this query language has been studied extensively, the\ndifficulty of the efficient evaluation of queries, usually involving some form\nof quantifier elimination, has received considerably less attention. The\ninefficiency of existing quantifier-elimination software and the intrinsic\ndifficulty of quantifier elimination have proven to be a bottle-neck for for\nreal-world implementations of constraint database systems. In this paper, we\nfocus on a particular query, called the \\emph{alibi query}, that asks whether\ntwo moving objects whose positions are known at certain moments in time, could\nhave possibly met, given certain speed constraints. This query can be seen as a\nconstraint database query and its evaluation relies on the elimination of a\nblock of three existential quantifiers. Implementations of general purpose\nelimination algorithms are in the specific case, for practical purposes, too\nslow in answering the alibi query and fail completely in the parametric case.\nThe main contribution of this paper is an analytical solution to the parametric\nalibi query, which can be used to answer this query in the specific case in\nconstant time. We also give an analytic solution to the alibi query at a fixed\nmoment in time. The solutions we propose are based on geometric argumentation\nand they illustrate the fact that some practical problems require creative\nsolutions, where at least in theory, existing systems could provide a solution.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2007 18:05:41 GMT"}], "update_date": "2007-12-13", "authors_parsed": [["Kuijpers", "Bart", ""], ["Othman", "Walied", ""], ["Grimson", "Rafael", ""]]}, {"id": "0712.2595", "submitter": "Bill Rosgen", "authors": "Bill Rosgen", "title": "Distinguishing Short Quantum Computations", "comments": "12 pages, 4 figures, to be published in the proceedings of STACS 2008", "journal-ref": null, "doi": "10.4230/LIPIcs.STACS.2008.1322", "report-no": null, "categories": "quant-ph cs.CC", "license": null, "abstract": "  Distinguishing logarithmic depth quantum circuits on mixed states is shown to\nbe complete for QIP, the class of problems having quantum interactive proof\nsystems. Circuits in this model can represent arbitrary quantum processes, and\nthus this result has implications for the verification of implementations of\nquantum algorithms. The distinguishability problem is also complete for QIP on\nconstant depth circuits containing the unbounded fan-out gate. These results\nare shown by reducing a QIP-complete problem to a logarithmic depth version of\nitself using a parallelization technique.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2007 21:40:41 GMT"}], "update_date": "2010-06-02", "authors_parsed": [["Rosgen", "Bill", ""]]}, {"id": "0712.2644", "submitter": "Cyrille Bertelle", "authors": "Rawan Ghnemat (LITIS), Saleh Oqeili (IT), Cyrille Bertelle (LITIS),\n  G\\'erard Henry Edmond Duchamp (LIPN)", "title": "Automata-based Adaptive Behavior for Economical Modelling Using Game\n  Theory", "comments": null, "journal-ref": "Emergent Properties in Natural and Artificial Dynamical Systems,\n  Springer (Ed.) (2006) 171-183", "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": null, "abstract": "  In this chapter, we deal with some specific domains of applications to game\ntheory. This is one of the major class of models in the new approaches of\nmodelling in the economic domain. For that, we use genetic automata which allow\nto build adaptive strategies for the players. We explain how the automata-based\nformalism proposed - matrix representation of automata with multiplicities -\nallows to define semi-distance between the strategy behaviors. With that tools,\nwe are able to generate an automatic processus to compute emergent systems of\nentities whose behaviors are represented by these genetic automata.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2007 07:07:54 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Ghnemat", "Rawan", "", "LITIS"], ["Oqeili", "Saleh", "", "IT"], ["Bertelle", "Cyrille", "", "LITIS"], ["Duchamp", "G\u00e9rard Henry Edmond", "", "LIPN"]]}, {"id": "0712.3137", "submitter": "Lucas Lacasa", "authors": "Lucas Lacasa, Bartolo Luque, Octavio Miramontes", "title": "Phase transition and computational complexity in a stochastic prime\n  number generator", "comments": "Submitted to New Journal of Physics", "journal-ref": "New Journal of Physics 10 (2008) 023009", "doi": "10.1088/1367-2630/10/2/023009", "report-no": null, "categories": "cs.CC physics.comp-ph", "license": null, "abstract": "  We introduce a prime number generator in the form of a stochastic algorithm.\nThe character of such algorithm gives rise to a continuous phase transition\nwhich distinguishes a phase where the algorithm is able to reduce the whole\nsystem of numbers into primes and a phase where the system reaches a frozen\nstate with low prime density. In this paper we firstly pretend to give a broad\ncharacterization of this phase transition, both in terms of analytical and\nnumerical analysis. Critical exponents are calculated, and data collapse is\nprovided. Further on we redefine the model as a search problem, fitting it in\nthe hallmark of computational complexity theory. We suggest that the system\nbelongs to the class NP. The computational cost is maximal around the\nthreshold, as common in many algorithmic phase transitions, revealing the\npresence of an easy-hard-easy pattern. We finally relate the nature of the\nphase transition to an average-case classification of the problem.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2007 10:00:32 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Lacasa", "Lucas", ""], ["Luque", "Bartolo", ""], ["Miramontes", "Octavio", ""]]}, {"id": "0712.3203", "submitter": "Wan ChangLin", "authors": "Changlin Wan, Zhongzhi Shi", "title": "Solving Medium-Density Subset Sum Problems in Expected Polynomial Time:\n  An Enumeration Approach", "comments": "11 pages, 1 figure", "journal-ref": "Changlin Wan, Zhongzhi Shi: Solving Medium-Density Subset Sum\n  Problems in Expected Polynomial Time: An Enumeration Approach. FAW 2008:\n  300-310", "doi": "10.1007/978-3-540-69311-6_31", "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subset sum problem (SSP) can be briefly stated as: given a target integer\n$E$ and a set $A$ containing $n$ positive integer $a_j$, find a subset of $A$\nsumming to $E$. The \\textit{density} $d$ of an SSP instance is defined by the\nratio of $n$ to $m$, where $m$ is the logarithm of the largest integer within\n$A$. Based on the structural and statistical properties of subset sums, we\npresent an improved enumeration scheme for SSP, and implement it as a complete\nand exact algorithm (EnumPlus). The algorithm always equivalently reduces an\ninstance to be low-density, and then solve it by enumeration. Through this\napproach, we show the possibility to design a sole algorithm that can\nefficiently solve arbitrary density instance in a uniform way. Furthermore, our\nalgorithm has considerable performance advantage over previous algorithms.\nFirstly, it extends the density scope, in which SSP can be solved in expected\npolynomial time. Specifically, It solves SSP in expected $O(n\\log{n})$ time\nwhen density $d \\geq c\\cdot \\sqrt{n}/\\log{n}$, while the previously best\ndensity scope is $d \\geq c\\cdot n/(\\log{n})^{2}$. In addition, the overall\nexpected time and space requirement in the average case are proven to be\n$O(n^5\\log n)$ and $O(n^5)$ respectively. Secondly, in the worst case, it\nslightly improves the previously best time complexity of exact algorithms for\nSSP. Specifically, the worst-case time complexity of our algorithm is proved to\nbe $O((n-6)2^{n/2}+n)$, while the previously best result is $O(n2^{n/2})$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2007 14:43:50 GMT"}, {"version": "v2", "created": "Mon, 23 Jun 2008 02:00:12 GMT"}], "update_date": "2008-06-23", "authors_parsed": [["Wan", "Changlin", ""], ["Shi", "Zhongzhi", ""]]}, {"id": "0712.3348", "submitter": "Xin Li", "authors": "Xin Li, Tian Liu", "title": "On Exponential Time Lower Bound of Knapsack under Backtracking", "comments": "This paper supersedes the result of arXiv:cs/0606064", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": null, "abstract": "  M.Aleknovich et al. have recently proposed a model of algorithms, called BT\nmodel, which generalizes both the priority model of Borodin, Nielson and\nRackoff, as well as a simple dynamic programming model by Woeginger. BT model\ncan be further divided into three kinds of fixed, adaptive and fully adaptive\nones. They have proved exponential time lower bounds of exact and approximation\nalgorithms under adaptive BT model for Knapsack problem. Their exact lower\nbound is $\\Omega(2^{0.5n}/\\sqrt{n})$, in this paper, we slightly improve the\nexact lower bound to about $\\Omega(2^{0.69n}/\\sqrt{n})$, by the same technique,\nwith related parameters optimized.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2007 09:15:17 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2007 13:46:53 GMT"}], "update_date": "2007-12-25", "authors_parsed": [["Li", "Xin", ""], ["Liu", "Tian", ""]]}, {"id": "0712.4027", "submitter": "Olga Holtz", "authors": "James Demmel, Ioana Dumitriu, Olga Holtz, Plamen Koev", "title": "Accurate and Efficient Expression Evaluation and Linear Algebra", "comments": "49 pages, 6 figures, 1 table", "journal-ref": "Acta Numerica, Volume 17, May 2008, pp 87-145", "doi": "10.1017/S0962492906350015", "report-no": null, "categories": "math.NA cs.CC cs.DS math.RA", "license": null, "abstract": "  We survey and unify recent results on the existence of accurate algorithms\nfor evaluating multivariate polynomials, and more generally for accurate\nnumerical linear algebra with structured matrices. By \"accurate\" we mean that\nthe computed answer has relative error less than 1, i.e., has some correct\nleading digits. We also address efficiency, by which we mean algorithms that\nrun in polynomial time in the size of the input. Our results will depend\nstrongly on the model of arithmetic: Most of our results will use the so-called\nTraditional Model (TM). We give a set of necessary and sufficient conditions to\ndecide whether a high accuracy algorithm exists in the TM, and describe\nprogress toward a decision procedure that will take any problem and provide\neither a high accuracy algorithm or a proof that none exists. When no accurate\nalgorithm exists in the TM, it is natural to extend the set of available\naccurate operations by a library of additional operations, such as $x+y+z$, dot\nproducts, or indeed any enumerable set which could then be used to build\nfurther accurate algorithms. We show how our accurate algorithms and decision\nprocedure for finding them extend to this case. Finally, we address other\nmodels of arithmetic, and the relationship between (im)possibility in the TM\nand (in)efficient algorithms operating on numbers represented as bit strings.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2007 20:14:50 GMT"}], "update_date": "2008-05-21", "authors_parsed": [["Demmel", "James", ""], ["Dumitriu", "Ioana", ""], ["Holtz", "Olga", ""], ["Koev", "Plamen", ""]]}, {"id": "0712.4279", "submitter": "Troy Lee", "authors": "Troy Lee, Adi Shraibman", "title": "Disjointness is hard in the multi-party number on the forehead model", "comments": "23 pages. Added background to method and references to more recent\n  work. Journal version to appear in Computational Complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that disjointness requires randomized communication\nOmega(n^{1/(k+1)}/2^{2^k}) in the general k-party number-on-the-forehead model\nof complexity. The previous best lower bound for k >= 3 was log(n)/(k-1). Our\nresults give a separation between nondeterministic and randomized multiparty\nnumber-on-the-forehead communication complexity for up to k=log log n - O(log\nlog log n) many players. Also by a reduction of Beame, Pitassi, and Segerlind,\nthese results imply subexponential lower bounds on the size of proofs needed to\nrefute certain unsatisfiable CNFs in a broad class of proof systems, including\ntree-like Lovasz-Schrijver proofs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2007 20:45:53 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2009 12:15:09 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Lee", "Troy", ""], ["Shraibman", "Adi", ""]]}]