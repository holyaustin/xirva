[{"id": "1001.0018", "submitter": "Ashley Montanaro", "authors": "Ashley Montanaro", "title": "Nonadaptive quantum query complexity", "comments": "9 pages; v2: new title, updated with new results on learning", "journal-ref": "Information Processing Letters 110 (2010), pp. 1110-1113", "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the power of nonadaptive quantum query algorithms, which are\nalgorithms whose queries to the input do not depend on the result of previous\nqueries. First, we show that any bounded-error nonadaptive quantum query\nalgorithm that computes some total boolean function depending on n variables\nmust make Omega(n) queries to the input in total. Second, we show that, if\nthere exists a quantum algorithm that uses k nonadaptive oracle queries to\nlearn which one of a set of m boolean functions it has been given, there exists\na nonadaptive classical algorithm using O(k log m) queries to solve the same\nproblem. Thus, in the nonadaptive setting, quantum algorithms can achieve at\nmost a very limited speed-up over classical query algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 21:04:25 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2010 08:38:16 GMT"}], "update_date": "2010-12-20", "authors_parsed": [["Montanaro", "Ashley", ""]]}, {"id": "1001.0041", "submitter": "Stanislaw Szarek", "authors": "Piotr Indyk and Stanislaw Szarek", "title": "Almost-Euclidean subspaces of $\\ell_1^N$ via tensor products: a simple\n  approach to randomness reduction", "comments": "11 pages; title change, abstract and references added, other minor\n  changes", "journal-ref": "RANDOM 2010, LNCS 6302, Springer 2010, 632-641", "doi": "10.1007/978-3-642-15369-3_47", "report-no": null, "categories": "math.MG cs.CC math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been known since 1970's that the N-dimensional $\\ell_1$-space contains\nnearly Euclidean subspaces whose dimension is $\\Omega(N)$. However, proofs of\nexistence of such subspaces were probabilistic, hence non-constructive, which\nmade the results not-quite-suitable for subsequently discovered applications to\nhigh-dimensional nearest neighbor search, error-correcting codes over the\nreals, compressive sensing and other computational problems. In this paper we\npresent a \"low-tech\" scheme which, for any $a > 0$, allows to exhibit nearly\nEuclidean $\\Omega(N)$-dimensional subspaces of $\\ell_1^N$ while using only\n$N^a$ random bits. Our results extend and complement (particularly) recent work\nby Guruswami-Lee-Wigderson. Characteristic features of our approach include (1)\nsimplicity (we use only tensor products) and (2) yielding \"almost Euclidean\"\nsubspaces with arbitrarily small distortions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 22:48:35 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2010 22:25:01 GMT"}], "update_date": "2010-09-14", "authors_parsed": [["Indyk", "Piotr", ""], ["Szarek", "Stanislaw", ""]]}, {"id": "1001.0117", "submitter": "John Hitchcock", "authors": "Xiaoyang Gu, John M. Hitchcock, and A. Pavan", "title": "Collapsing and Separating Completeness Notions under Average-Case and\n  Worst-Case Hypotheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper presents the following results on sets that are complete for NP.\n  1. If there is a problem in NP that requires exponential time at almost all\nlengths, then every many-one NP-complete set is complete under\nlength-increasing reductions that are computed by polynomial-size circuits. 2.\nIf there is a problem in coNP that cannot be solved by polynomial-size\nnondeterministic circuits, then every many-one complete set is complete under\nlength-increasing reductions that are computed by polynomial-size circuits. 3.\nIf there exist a one-way permutation that is secure against subexponential-size\ncircuits and there is a hard tally language in NP intersect coNP, then there is\na Turing complete language for NP that is not many-one complete. Our first two\nresults use worst-case hardness hypotheses whereas earlier work that showed\nsimilar results relied on average-case or almost-everywhere hardness\nassumptions. The use of average-case and worst-case hypotheses in the last\nresult is unique as previous results obtaining the same consequence relied on\nalmost-everywhere hardness results.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2010 20:55:05 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 11:55:29 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Gu", "Xiaoyang", ""], ["Hitchcock", "John M.", ""], ["Pavan", "A.", ""]]}, {"id": "1001.0208", "submitter": "Matthew Patitz", "authors": "David Doty, Jack H. Lutz, Matthew J. Patitz, Scott M. Summers, Damien\n  Woods", "title": "Intrinsic Universality in Self-Assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Tile Assembly Model exhibits a strong notion of universality\nwhere the goal is to give a single tile assembly system that simulates the\nbehavior of any other tile assembly system. We give a tile assembly system that\nis capable of simulating a very wide class of tile systems, including itself.\nSpecifically, we give a tile set that simulates the assembly of any tile\nassembly system in a class of systems that we call \\emph{locally consistent}:\neach tile binds with exactly the strength needed to stay attached, and that\nthere are no glue mismatches between tiles in any produced assembly.\n  Our construction is reminiscent of the studies of \\emph{intrinsic\nuniversality} of cellular automata by Ollinger and others, in the sense that\nour simulation of a tile system $T$ by a tile system $U$ represents each tile\nin an assembly produced by $T$ by a $c \\times c$ block of tiles in $U$, where\n$c$ is a constant depending on $T$ but not on the size of the assembly $T$\nproduces (which may in fact be infinite). Also, our construction improves on\nearlier simulations of tile assembly systems by other tile assembly systems (in\nparticular, those of Soloveichik and Winfree, and of Demaine et al.) in that we\nsimulate the actual process of self-assembly, not just the end result, as in\nSoloveichik and Winfree's construction, and we do not discriminate against\ninfinite structures. Both previous results simulate only temperature 1 systems,\nwhereas our construction simulates tile assembly systems operating at\ntemperature 2.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2010 15:39:54 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 11:18:29 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Doty", "David", ""], ["Lutz", "Jack H.", ""], ["Patitz", "Matthew J.", ""], ["Summers", "Scott M.", ""], ["Woods", "Damien", ""]]}, {"id": "1001.0236", "submitter": "Alexander Wolff", "authors": "Mark de Berg and Fred van Nijnatten and Ren\\'e Sitters and Gerhard J.\n  Woeginger and Alexander Wolff", "title": "The Traveling Salesman Problem Under Squared Euclidean Distances", "comments": "12 pages, 4 figures. (v2) Minor linguistic changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of points in $\\mathbb{R}^d$, and let $\\alpha \\ge 1$ be a\nreal number. We define the distance between two points $p,q\\in P$ as\n$|pq|^{\\alpha}$, where $|pq|$ denotes the standard Euclidean distance between\n$p$ and $q$. We denote the traveling salesman problem under this distance\nfunction by TSP($d,\\alpha$). We design a 5-approximation algorithm for TSP(2,2)\nand generalize this result to obtain an approximation factor of\n$3^{\\alpha-1}+\\sqrt{6}^{\\alpha}/3$ for $d=2$ and all $\\alpha\\ge2$.\n  We also study the variant Rev-TSP of the problem where the traveling salesman\nis allowed to revisit points. We present a polynomial-time approximation scheme\nfor Rev-TSP$(2,\\alpha)$ with $\\alpha\\ge2$, and we show that Rev-TSP$(d,\n\\alpha)$ is APX-hard if $d\\ge3$ and $\\alpha>1$. The APX-hardness proof carries\nover to TSP$(d, \\alpha)$ for the same parameter ranges.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2010 14:00:06 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2010 14:47:06 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2010 11:17:20 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["de Berg", "Mark", ""], ["van Nijnatten", "Fred", ""], ["Sitters", "Ren\u00e9", ""], ["Woeginger", "Gerhard J.", ""], ["Wolff", "Alexander", ""]]}, {"id": "1001.0383", "submitter": "Fabian Wagner", "authors": "Bireswar Das, Jacobo Toran, Fabian Wagner", "title": "Restricted Space Algorithms for Isomorphism on Bounded Treewidth Graphs", "comments": "STACS conference 2010, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Graph Isomorphism problem restricted to graphs of bounded treewidth or\nbounded tree distance width are known to be solvable in polynomial time\n[Bod90],[YBFT99]. We give restricted space algorithms for these problems\nproving the following results: - Isomorphism for bounded tree distance width\ngraphs is in L and thus complete for the class. We also show that for this kind\nof graphs a canon can be computed within logspace. - For bounded treewidth\ngraphs, when both input graphs are given together with a tree decomposition,\nthe problem of whether there is an isomorphism which respects the\ndecompositions (i.e. considering only isomorphisms mapping bags in one\ndecomposition blockwise onto bags in the other decomposition) is in L. - For\nbounded treewidth graphs, when one of the input graphs is given with a tree\ndecomposition the isomorphism problem is in LogCFL. - As a corollary the\nisomorphism problem for bounded treewidth graphs is in LogCFL. This improves\nthe known TC1 upper bound for the problem given by Grohe and Verbitsky\n[GroVer06].\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2010 15:44:56 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 11:16:10 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Das", "Bireswar", ""], ["Toran", "Jacobo", ""], ["Wagner", "Fabian", ""]]}, {"id": "1001.0464", "submitter": "Michael Kowalczyk", "authors": "Michael Kowalczyk and Jin-Yi Cai", "title": "Holant Problems for Regular Graphs with Complex Edge Functions", "comments": "19 pages, 4 figures, added proofs for full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We prove a complexity dichotomy theorem for Holant Problems on 3-regular\ngraphs with an arbitrary complex-valued edge function. Three new techniques are\nintroduced: (1) higher dimensional iterations in interpolation; (2) Eigenvalue\nShifted Pairs, which allow us to prove that a pair of combinatorial gadgets in\ncombination succeed in proving #P-hardness; and (3) algebraic symmetrization,\nwhich significantly lowers the symbolic complexity of the proof for\ncomputational complexity. With holographic reductions the classification\ntheorem also applies to problems beyond the basic model.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2010 12:33:25 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 13:00:44 GMT"}, {"version": "v3", "created": "Mon, 8 Aug 2011 15:50:52 GMT"}], "update_date": "2011-08-09", "authors_parsed": [["Kowalczyk", "Michael", ""], ["Cai", "Jin-Yi", ""]]}, {"id": "1001.0529", "submitter": "Felix Fischer", "authors": "Felix Brandt, Felix Fischer, Markus Holzer", "title": "On Iterated Dominance, Matrix Elimination, and Matched Paths", "comments": "12 pages, 3 figures, 27th International Symposium on Theoretical\n  Aspects of Computer Science (STACS)", "journal-ref": null, "doi": "10.4230/LIPIcs.STACS.2010.2448", "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study computational problems arising from the iterated removal of weakly\ndominated actions in anonymous games. Our main result shows that it is\nNP-complete to decide whether an anonymous game with three actions can be\nsolved via iterated weak dominance. The two-action case can be reformulated as\na natural elimination problem on a matrix, the complexity of which turns out to\nbe surprisingly difficult to characterize and ultimately remains open. We\nhowever establish connections to a matching problem along paths in a directed\ngraph, which is computationally hard in general but can also be used to\nidentify tractable cases of matrix elimination. We finally identify different\nclasses of anonymous games where iterated dominance is in P and NP-complete,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2010 15:09:53 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 17:50:03 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Brandt", "Felix", ""], ["Fischer", "Felix", ""], ["Holzer", "Markus", ""]]}, {"id": "1001.0595", "submitter": "Michael Shapiro", "authors": "Michael Shapiro and Edgar Delgado-Eckert", "title": "Finding an individual's probability of infection in an SIR network is\n  NP-hard", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Kermack-McKendric model of epidemics studies the transmission\nof a disease in a population where each individual is initially susceptible\n(S), may become infective (I) and then removed or recovered (R) and plays no\nfurther epidemiological role. This ODE model arises as the limiting case of a\nnetwork model where each individual has an equal chance of infecting every\nother. More recent work gives explicit consideration to the network of social\ninteraction and attendant probability of transmission for each interacting\npair. The state of such a network is an assignment of the values {S,I,R} to its\nmembers. Given such a network, an initial state and a particular susceptible\nindividual, we would like to compute their probability of becoming infected in\nthe course of an epidemic. It turns out that this problem is NP-hard. In\nparticular, it belongs in a class of problems all of whose known solutions\nrequire an exponential amount of computation and for which it is unlikely that\nthere will be more efficient solutions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2010 22:34:00 GMT"}, {"version": "v2", "created": "Tue, 11 May 2010 18:24:03 GMT"}, {"version": "v3", "created": "Sun, 22 Aug 2010 03:15:14 GMT"}, {"version": "v4", "created": "Tue, 27 Sep 2011 16:11:14 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Shapiro", "Michael", ""], ["Delgado-Eckert", "Edgar", ""]]}, {"id": "1001.0746", "submitter": "Ryan Williams", "authors": "Ryan Williams", "title": "Alternation-Trading Proofs, Linear Programming, and Lower Bounds", "comments": "To appear in STACS 2010, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A fertile area of recent research has demonstrated concrete polynomial time\nlower bounds for solving natural hard problems on restricted computational\nmodels. Among these problems are Satisfiability, Vertex Cover, Hamilton Path,\nMod6-SAT, Majority-of-Majority-SAT, and Tautologies, to name a few. The proofs\nof these lower bounds follow a certain proof-by-contradiction strategy that we\ncall alternation-trading. An important open problem is to determine how\npowerful such proofs can possibly be.\n  We propose a methodology for studying these proofs that makes them amenable\nto both formal analysis and automated theorem proving. We prove that the search\nfor better lower bounds can often be turned into a problem of solving a large\nseries of linear programming instances. Implementing a small-scale theorem\nprover based on this result, we extract new human-readable time lower bounds\nfor several problems. This framework can also be used to prove concrete\nlimitations on the current techniques.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2010 19:19:21 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2010 02:48:01 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2010 14:04:36 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Williams", "Ryan", ""]]}, {"id": "1001.1139", "submitter": "Gonzalo Abal", "authors": "G. Abal, R. Donangelo, F.L. Marquezino, R. Portugal", "title": "Spatial search in a honeycomb network", "comments": "10 pages, 2 figures; Minor typos corrected, one Reference added.\n  accepted in Math. Structures in Computer Science, special volume on Quantum\n  Computing", "journal-ref": "Mathematical Structures in Computer Science, v. 20, p. 999-1009,\n  2010", "doi": "10.1017/S0960129510000332", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial search problem consists in minimizing the number of steps\nrequired to find a given site in a network, under the restriction that only\noracle queries or translations to neighboring sites are allowed. In this paper,\na quantum algorithm for the spatial search problem on a honeycomb lattice with\n$N$ sites and torus-like boundary conditions. The search algorithm is based on\na modified quantum walk on a hexagonal lattice and the general framework\nproposed by Ambainis, Kempe and Rivosh is used to show that the time complexity\nof this quantum search algorithm is $O(\\sqrt{N \\log N})$.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2010 19:22:59 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2010 18:57:06 GMT"}, {"version": "v3", "created": "Fri, 28 May 2010 19:39:15 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Abal", "G.", ""], ["Donangelo", "R.", ""], ["Marquezino", "F. L.", ""], ["Portugal", "R.", ""]]}, {"id": "1001.1593", "submitter": "Yi Wu", "authors": "P. Gopalan, R. O'Donnell, Y. Wu, D. Zuckerman", "title": "Fooling functions of halfspaces under product distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct pseudorandom generators that fool functions of halfspaces\n(threshold functions) under a very broad class of product distributions. This\nclass includes not only familiar cases such as the uniform distribution on the\ndiscrete cube, the uniform distribution on the solid cube, and the multivariate\nGaussian distribution, but also includes any product of discrete distributions\nwith probabilities bounded away from 0.\n  Our first main result shows that a recent pseudorandom generator construction\nof Meka and Zuckerman [MZ09], when suitably modifed, can fool arbitrary\nfunctions of d halfspaces under product distributions where each coordinate has\nbounded fourth moment. To eps-fool any size-s, depth-d decision tree of\nhalfspaces, our pseudorandom generator uses seed length O((d log(ds/eps)+log n)\nlog(ds/eps)). For monotone functions of d halfspaces, the seed length can be\nimproved to O((d log(d/eps)+log n) log(d/eps)). We get better bounds for larger\neps; for example, to 1/polylog(n)-fool all monotone functions of (log n)= log\nlog n halfspaces, our generator requires a seed of length just O(log n). Our\nsecond main result generalizes the work of Diakonikolas et al. [DGJ+09] to show\nthat bounded independence suffices to fool functions of halfspaces under\nproduct distributions. Assuming each coordinate satisfies a certain stronger\nmoment condition, we show that any function computable by a size-s, depth-d\ndecision tree of halfspaces is eps-fooled by O(d^4s^2/eps^2)-wise independence.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2010 06:11:56 GMT"}], "update_date": "2010-01-12", "authors_parsed": [["Gopalan", "P.", ""], ["O'Donnell", "R.", ""], ["Wu", "Y.", ""], ["Zuckerman", "D.", ""]]}, {"id": "1001.1960", "submitter": "Lila Fontes", "authors": "Lila Fontes", "title": "Formal Theories for Logspace Counting", "comments": "33 pages, uses newalg.sty (file included)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two-sorted theories in the style of Cook and Nguyen for the\ncomplexity classes ParityL and DET, whose complete problems include\ndeterminants over GF(2) and Z, respectively. The definable functions in these\ntheories are the functions in the corresponding complexity classes; thus each\ntheory formalizes reasoning using concepts from its corresponding complexity\nclass.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 17:59:31 GMT"}], "update_date": "2010-01-13", "authors_parsed": [["Fontes", "Lila", ""]]}, {"id": "1001.2034", "submitter": "Raghunath Tewari", "authors": "Aduri Pavan and Raghunath Tewari and N. V. Vinodchandran", "title": "On the Power of Unambiguity in Logspace", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report progress on the \\NL vs \\UL problem. [-] We show unconditionally\nthat the complexity class $\\ReachFewL\\subseteq\\UL$. This improves on the\nearlier known upper bound $\\ReachFewL \\subseteq \\FewL$. [-] We investigate the\ncomplexity of min-uniqueness - a central notion in studying the \\NL vs \\UL\nproblem. We show that min-uniqueness is necessary and sufficient for showing\n$\\NL =\\UL$. We revisit the class $\\OptL[\\log n]$ and show that {\\sc\nShortestPathLength} - computing the length of the shortest path in a DAG, is\ncomplete for $\\OptL[\\log n]$. We introduce $\\UOptL[\\log n]$, an unambiguous\nversion of $\\OptL[\\log n]$, and show that (a) $\\NL =\\UL$ if and only if\n$\\OptL[\\log n] = \\UOptL[\\log n]$, (b) $\\LogFew \\leq \\UOptL[\\log n] \\leq \\SPL$.\n[-] We show that the reachability problem over graphs embedded on 3 pages is\ncomplete for \\NL. This contrasts with the reachability problem over graphs\nembedded on 2 pages which is logspace equivalent to the reachability problem in\nplanar graphs and hence is in \\UL.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 22:13:31 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Pavan", "Aduri", ""], ["Tewari", "Raghunath", ""], ["Vinodchandran", "N. V.", ""]]}, {"id": "1001.2052", "submitter": "Andrew Drucker", "authors": "Andrew Drucker", "title": "Block Sensitivity of Minterm-Transitive Functions", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean functions with symmetry properties are interesting from a complexity\ntheory perspective; extensive research has shown that these functions, if\nnonconstant, must have high `complexity' according to various measures.\n  In recent work of this type, Sun gave bounds on the block sensitivity of\nnonconstant Boolean functions invariant under a transitive permutation group.\nSun showed that all such functions satisfy bs(f) = Omega(N^{1/3}), and that\nthere exists such a function for which bs(f) = O(N^{3/7}ln N). His example\nfunction belongs to a subclass of transitively invariant functions called the\nminterm-transitive functions (defined in earlier work by Chakraborty).\n  We extend these results in two ways. First, we show that nonconstant\nminterm-transitive functions satisfy bs(f) = Omega(N^{3/7}). Thus Sun's example\nfunction has nearly minimal block sensitivity for this subclass. Second, we\ngive an improved example: a minterm-transitive function for which bs(f) =\nO(N^{3/7}ln^{1/7}N).\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 20:29:28 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Drucker", "Andrew", ""]]}, {"id": "1001.2314", "submitter": "Cristopher Moore", "authors": "Cristopher Moore and Alexander Russell", "title": "Circuit partitions and #P-complete products of inner products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple, natural #P-complete problem. Let G be a directed graph,\nand let k be a positive integer. We define q(G;k) as follows. At each vertex v,\nwe place a k-dimensional complex vector x_v. We take the product, over all\nedges (u,v), of the inner product <x_u,x_v>. Finally, q(G;k) is the expectation\nof this product, where the x_v are chosen uniformly and independently from all\nvectors of norm 1 (or, alternately, from the Gaussian distribution). We show\nthat q(G;k) is proportional to G's cycle partition polynomial, and therefore\nthat it is #P-complete for any k>1.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 21:23:45 GMT"}], "update_date": "2010-01-15", "authors_parsed": [["Moore", "Cristopher", ""], ["Russell", "Alexander", ""]]}, {"id": "1001.2331", "submitter": "Sriram Vishwanath", "authors": "Sriram Vishwanath", "title": "Information Theoretic Bounds for Low-Rank Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the low-rank matrix completion problem from an information\ntheoretic perspective. The completion problem is rephrased as a communication\nproblem of an (uncoded) low-rank matrix source over an erasure channel. The\npaper then uses achievability and converse arguments to present order-wise\noptimal bounds for the completion problem.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2010 20:54:22 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Vishwanath", "Sriram", ""]]}, {"id": "1001.2572", "submitter": "Martin Grohe", "authors": "Martin Grohe", "title": "Fixed-Point Definability and Polynomial Time on Chordal Graphs and Line\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of whether there is a logic that captures polynomial time was\nformulated by Yuri Gurevich in 1988. It is still wide open and regarded as one\nof the main open problems in finite model theory and database theory. Partial\nresults have been obtained for specific classes of structures. In particular,\nit is known that fixed-point logic with counting captures polynomial time on\nall classes of graphs with excluded minors. The introductory part of this paper\nis a short survey of the state-of-the-art in the quest for a logic capturing\npolynomial time.\n  The main part of the paper is concerned with classes of graphs defined by\nexcluding induced subgraphs. Two of the most fundamental such classes are the\nclass of chordal graphs and the class of line graphs. We prove that capturing\npolynomial time on either of these classes is as hard as capturing it on the\nclass of all graphs. In particular, this implies that fixed-point logic with\ncounting does not capture polynomial time on these classes. Then we prove that\nfixed-point logic with counting does capture polynomial time on the class of\nall graphs that are both chordal and line graphs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2010 22:14:00 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2010 14:32:32 GMT"}], "update_date": "2010-04-30", "authors_parsed": [["Grohe", "Martin", ""]]}, {"id": "1001.2613", "submitter": "Aditya Bhaskara", "authors": "Aditya Bhaskara, Aravindan Vijayaraghavan", "title": "Approximating Matrix p-norms", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the q->p norm of a matrix A, which is\ndefined for p,q \\ge 1, as |A|_{q->p} = max_{x !=0 } |Ax|_p / |x|_q. This is in\ngeneral a non-convex optimization problem, and is a natural generalization of\nthe well-studied question of computing singular values (this corresponds to\np=q=2). Different settings of parameters give rise to a variety of known\ninteresting problems (such as the Grothendieck problem when p=1 and q=\\infty).\nHowever, very little is understood about the approximability of the problem for\ndifferent values of p,q. Our first result is an efficient algorithm for\ncomputing the q->p norm of matrices with non-negative entries, when q \\ge p \\ge\n1. The algorithm we analyze is based on a natural fixed point iteration, which\ncan be seen as an analog of power iteration for computing eigenvalues. We then\npresent an application of our techniques to the problem of constructing a\nscheme for oblivious routing in the l_p norm. This makes constructive a recent\nexistential result of Englert and R\\\"acke [ER] on O(log n)-competitive\noblivious routing schemes (which they make constructive only for p=2). On the\nother hand, when we do not have any restrictions on the entries (such as\nnon-negativity), we prove that the problem is NP-hard to approximate to any\nconstant factor, for 2 < p \\le q, and p \\le q < 2 (these are precisely the\nranges of p,q with p\\le q, where constant factor approximations are not known).\nIn this range, our techniques also show that if NP does not have\nquasi-polynomial time algorithms, the q->p cannot be approximated to a factor\n2^{(log n)^{1-eps}}, for any \\eps>0.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2010 05:48:21 GMT"}, {"version": "v2", "created": "Sun, 2 May 2010 19:19:42 GMT"}], "update_date": "2010-05-04", "authors_parsed": [["Bhaskara", "Aditya", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1001.2735", "submitter": "Bhaskar DasGupta", "authors": "Bhaskar DasGupta and S. Muthukrishnan", "title": "Stochastic Budget Optimization in Internet Advertising", "comments": "FINAL version", "journal-ref": "Algorithmica, 65 (3), 634-661, 2013", "doi": "10.1007/s00453-012-9614-x", "report-no": null, "categories": "cs.CC cs.GT cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet advertising is a sophisticated game in which the many advertisers\n\"play\" to optimize their return on investment. There are many \"targets\" for the\nadvertisements, and each \"target\" has a collection of games with a potentially\ndifferent set of players involved. In this paper, we study the problem of how\nadvertisers allocate their budget across these \"targets\". In particular, we\nfocus on formulating their best response strategy as an optimization problem.\nAdvertisers have a set of keywords (\"targets\") and some stochastic information\nabout the future, namely a probability distribution over scenarios of cost vs\nclick combinations. This summarizes the potential states of the world assuming\nthat the strategies of other players are fixed. Then, the best response can be\nabstracted as stochastic budget optimization problems to figure out how to\nspread a given budget across these keywords to maximize the expected number of\nclicks.\n  We present the first known non-trivial poly-logarithmic approximation for\nthese problems as well as the first known hardness results of getting better\nthan logarithmic approximation ratios in the various parameters involved. We\nalso identify several special cases of these problems of practical interest,\nsuch as with fixed number of scenarios or with polynomial-sized parameters\nrelated to cost, which are solvable either in polynomial time or with improved\napproximation ratios. Stochastic budget optimization with scenarios has\nsophisticated technical structure. Our approximation and hardness results come\nfrom relating these problems to a special type of (0/1, bipartite) quadratic\nprograms inherent in them. Our research answers some open problems raised by\nthe authors in (Stochastic Models for Budget Optimization in Search-Based\nAdvertising, Algorithmica, 58 (4), 1022-1044, 2010).\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2010 16:56:37 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2011 05:31:44 GMT"}, {"version": "v3", "created": "Thu, 19 Jan 2012 00:00:22 GMT"}, {"version": "v4", "created": "Mon, 4 Feb 2013 03:57:42 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["DasGupta", "Bhaskar", ""], ["Muthukrishnan", "S.", ""]]}, {"id": "1001.2778", "submitter": "Michalis Vafopoulos n", "authors": "Michalis Vafopoulos, Efstathios Amarantidis, Ioannis Antoniou", "title": "Modeling Web Evolution", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web is the largest human information construct in history transforming\nour society. How can we understand, measure and model the Web evolution in\norder to design effective policies and optimize its social benefit? Early\nmeasurements of the Internet traffic and the Web graph indicated the scale-free\nstructure of the Web and other Complex Networks. Going a step further\nKouroupas, Koutsoupias, Papadimitriou and Sideri (KKPS) presented an\neconomic-inspired model which explains the scale-free behavior as the\ninteraction of Documents, Users and Search engines. The purpose of this paper\nis to clarify the open issues arising within the KKPS model through analysis\nand simulations and to highlight future research developments in Web modeling,\nwhich is the backbone of Web Science.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2010 21:46:46 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Vafopoulos", "Michalis", ""], ["Amarantidis", "Efstathios", ""], ["Antoniou", "Ioannis", ""]]}, {"id": "1001.2888", "submitter": "Brad Shutters", "authors": "Jack H. Lutz, Brad Shutters", "title": "Approximate Self-Assembly of the Sierpinski Triangle", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-13962-8_32", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tile Assembly Model is a Turing universal model that Winfree introduced\nin order to study the nanoscale self-assembly of complex (typically aperiodic)\nDNA crystals. Winfree exhibited a self-assembly that tiles the first quadrant\nof the Cartesian plane with specially labeled tiles appearing at exactly the\npositions of points in the Sierpinski triangle. More recently, Lathrop, Lutz,\nand Summers proved that the Sierpinski triangle cannot self-assemble in the\n\"strict\" sense in which tiles are not allowed to appear at positions outside\nthe target structure. Here we investigate the strict self-assembly of sets that\napproximate the Sierpinski triangle. We show that every set that does strictly\nself-assemble disagrees with the Sierpinski triangle on a set with fractal\ndimension at least that of the Sierpinski triangle (roughly 1.585), and that no\nsubset of the Sierpinski triangle with fractal dimension greater than 1\nstrictly self-assembles. We show that our bounds are tight, even when\nrestricted to supersets of the Sierpinski triangle, by presenting a strict\nself-assembly that adds communication fibers to the fractal structure without\ndisturbing it. To verify this strict self-assembly we develop a generalization\nof the local determinism method of Soloveichik and Winfree.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 08:41:11 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Lutz", "Jack H.", ""], ["Shutters", "Brad", ""]]}, {"id": "1001.3116", "submitter": "Vicky Choi", "authors": "Vicky Choi", "title": "Minor-embedding in adiabatic quantum computation: II. Minor-universal\n  graph design", "comments": "10 pages, 5 figures", "journal-ref": "Quantum Information Processing: Volume 10, Issue 3 (2011), Page\n  343", "doi": "10.1007/s11128-010-0200-3", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [Choi08], we introduced the notion of minor-embedding in adiabatic quantum\noptimization. A minor-embedding of a graph G in a quantum hardware graph U is a\nsubgraph of U such that G can be obtained from it by contracting edges. In this\npaper, we describe the intertwined adiabatic quantum architecture design\nproblem, which is to construct a hardware graph U that satisfies all known\nphysical constraints and, at the same time, permits an efficient\nminor-embedding algorithm. We illustrate an optimal complete-graph-minor\nhardware graph. Given a family F of graphs, a (host) graph U is called\nF-minor-universal if for each graph G in F, U contains a minor-embedding of G.\nThe problem for designing a F-minor-universal hardware graph U_{sparse} in\nwhich F consists of a family of sparse graphs (e.g., bounded degree graphs) is\nopen.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 18:09:22 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2010 01:11:33 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Choi", "Vicky", ""]]}, {"id": "1001.3242", "submitter": "Gopal Pandurangan", "authors": "Jen-Yeu Chen and Gopal Pandurangan", "title": "Optimal Gossip-Based Aggregate Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first provably almost-optimal gossip-based algorithms for\naggregate computation that are both time optimal and message-optimal. Given a\n$n$-node network, our algorithms guarantee that all the nodes can compute the\ncommon aggregates (such as Min, Max, Count, Sum, Average, Rank etc.) of their\nvalues in optimal $O(\\log n)$ time and using $O(n \\log \\log n)$ messages. Our\nresult improves on the algorithm of Kempe et al. \\cite{kempe} that is\ntime-optimal, but uses $O(n \\log n)$ messages as well as on the algorithm of\nKashyap et al. \\cite{efficient-gossip} that uses $O(n \\log \\log n)$ messages,\nbut is not time-optimal (takes $O(\\log n \\log \\log n)$ time). Furthermore, we\nshow that our algorithms can be used to improve gossip-based aggregate\ncomputation in sparse communication networks, such as in peer-to-peer networks.\n  The main technical ingredient of our algorithm is a technique called {\\em\ndistributed random ranking (DRR)} that can be useful in other applications as\nwell. DRR gives an efficient distributed procedure to partition the network\ninto a forest of (disjoint) trees of small size.\n  Our algorithms are non-address oblivious. In contrast, we show a lower bound\nof $\\Omega(n\\log n)$ on the message complexity of any address-oblivious\nalgorithm for computing aggregates. This shows that non-address oblivious\nalgorithms are needed to obtain significantly better message complexity. Our\nlower bound holds regardless of the number of rounds taken or the size of the\nmessages used. Our lower bound is the first non-trivial lower bound for\ngossip-based aggregate computation and also gives the first formal proof that\ncomputing aggregates is strictly harder than rumor spreading in the\naddress-oblivious model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 09:51:48 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Chen", "Jen-Yeu", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1001.3251", "submitter": "George Mertzios", "authors": "George B. Mertzios, Ignasi Sau, Shmuel Zaks", "title": "The Recognition of Tolerance and Bounded Tolerance Graphs", "comments": "12 pages, 4 figures, 1 algorithm, Proceedings of the 27th\n  International Symposium on Theoretical Aspects of Computer Science (STACS),\n  Nancy, France, March 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Tolerance graphs model interval relations in such a way that intervals can\ntolerate a certain degree of overlap without being in conflict. This subclass\nof perfect graphs has been extensively studied, due to both its interesting\nstructure and its numerous applications. Several efficient algorithms for\noptimization problems that are NP-hard on general graphs have been designed for\ntolerance graphs. In spite of this, the recognition of tolerance graphs -\nnamely, the problem of deciding whether a given graph is a tolerance graph - as\nwell as the recognition of their main subclass of bounded tolerance graphs,\nhave been the most fundamental open problems on this class of graphs (cf. the\nbook on tolerance graphs \\cite{GolTol04}) since their introduction in 1982\n\\cite{GoMo82}. In this article we prove that both recognition problems are\nNP-complete, even in the case where the input graph is a trapezoid graph. The\npresented results are surprising because, on the one hand, most subclasses of\nperfect graphs admit polynomial recognition algorithms and, on the other hand,\nbounded tolerance graphs were believed to be efficiently recognizable as they\nare a natural special case of trapezoid graphs (which can be recognized in\npolynomial time) and share a very similar structure with them. For our\nreduction we extend the notion of an \\emph{acyclic orientation} of permutation\nand trapezoid graphs. Our main tool is a new algorithm that uses \\emph{vertex\nsplitting} to transform a given trapezoid graph into a permutation graph, while\npreserving this new acyclic orientation property. This method of vertex\nsplitting is of independent interest; very recently, it has been proved a\npowerful tool also in the design of efficient recognition algorithms for other\nclasses of graphs \\cite{MC-Trapezoid}.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 10:24:34 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 13:36:00 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Mertzios", "George B.", ""], ["Sau", "Ignasi", ""], ["Zaks", "Shmuel", ""]]}, {"id": "1001.3263", "submitter": "Bernd Schuh", "authors": "Bernd R. Schuh", "title": "A Real World Mechanism for Testing Satisfiability in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether the satisfiability of any formula F of propositional calculus can be\ndetermined in polynomial time is an open question. I propose a simple procedure\nbased on some real world mechanisms to tackle this problem. The main result is\nthe blueprint for a machine which is able to test any formula in conjunctive\nnormal form (CNF) for satisfiability in linear time. The device uses light and\nsome electrochemical properties to function. It adapts itself to the scope of\nthe problem without growing exponentially in mass with the size of the formula.\nIt requires infinite precision in its components instead.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 11:18:54 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Schuh", "Bernd R.", ""]]}, {"id": "1001.3485", "submitter": "William Jackson", "authors": "Weiling Chang, Binxing Fang, Xiaochun Yun, Shupeng Wang, Xiangzhan Yu", "title": "Randomness Testing of Compressed Data", "comments": null, "journal-ref": "Journal of Computing, Vol. 2, Issue 1, January 2010", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Number Generators play a critical role in a number of important\napplications. In practice, statistical testing is employed to gather evidence\nthat a generator indeed produces numbers that appear to be random. In this\npaper, we reports on the studies that were conducted on the compressed data\nusing 8 compression algorithms or compressors. The test results suggest that\nthe output of compression algorithms or compressors has bad randomness, the\ncompression algorithms or compressors are not suitable as random number\ngenerator. We also found that, for the same compression algorithm, there exists\npositive correlation relationship between compression ratio and randomness,\nincreasing the compression ratio increases randomness of compressed data. As\ntime permits, additional randomness testing efforts will be conducted.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2010 07:43:47 GMT"}], "update_date": "2010-03-25", "authors_parsed": [["Chang", "Weiling", ""], ["Fang", "Binxing", ""], ["Yun", "Xiaochun", ""], ["Wang", "Shupeng", ""], ["Yu", "Xiangzhan", ""]]}, {"id": "1001.3749", "submitter": "Sourav Chakraborty", "authors": "Eldar Fischer, Oded Lachish, Raphael Yuster", "title": "Two-phase algorithms for the parametric shortest path problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A {\\em parametric weighted graph} is a graph whose edges are labeled with\ncontinuous real functions of a single common variable. For any instantiation of\nthe variable, one obtains a standard edge-weighted graph. Parametric weighted\ngraph problems are generalizations of weighted graph problems, and arise in\nvarious natural scenarios. Parametric weighted graph algorithms consist of two\nphases. A {\\em preprocessing phase} whose input is a parametric weighted graph,\nand whose output is a data structure, the advice, that is later used by the\n{\\em instantiation phase}, where a specific value for the variable is given.\nThe instantiation phase outputs the solution to the (standard) weighted graph\nproblem that arises from the instantiation. The goal is to have the running\ntime of the instantiation phase supersede the running time of any algorithm\nthat solves the weighted graph problem from scratch, by taking advantage of the\nadvice.\n  In this paper we construct several parametric algorithms for the shortest\npath problem. For the case of linear function weights we present an algorithm\nfor the single source shortest path problem.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2010 09:35:46 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 12:34:18 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Fischer", "Eldar", ""], ["Lachish", "Oded", ""], ["Yuster", "Raphael", ""]]}, {"id": "1001.3816", "submitter": "Rakesh Dube Dr.", "authors": "Rakesh Dube", "title": "The P versus NP Problem", "comments": "Removed by arXiv administration due to plagiarism from Stephen Cook's\n  description of the problem for the Clay Mathematics Institute. See\n  http://gauss.claymath.org:8888/millennium/P_vs_NP/pvsnp.pdf for the original\n  text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Removed by arXiv administration.\n  This article was plagiarized directly from Stephen Cook's description of the\nproblem for the Clay Mathematics Institute. See\nhttp://gauss.claymath.org:8888/millennium/P_vs_NP/pvsnp.pdf for the original\ntext.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2010 14:37:36 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2010 03:19:25 GMT"}], "update_date": "2010-01-22", "authors_parsed": [["Dube", "Rakesh", ""]]}, {"id": "1001.4003", "submitter": "Robert Bredereck", "authors": "Robert Bredereck", "title": "Fixed-Parameter Algorithms for Computing Kemeny Scores - Theory and\n  Practice", "comments": "Studienarbeit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central problem in this work is to compute a ranking of a set of elements\nwhich is \"closest to\" a given set of input rankings of the elements. We define\n\"closest to\" in an established way as having the minimum sum of Kendall-Tau\ndistances to each input ranking. Unfortunately, the resulting problem Kemeny\nconsensus is NP-hard for instances with n input rankings, n being an even\ninteger greater than three. Nevertheless this problem plays a central role in\nmany rank aggregation problems. It was shown that one can compute the\ncorresponding Kemeny consensus list in f(k) + poly(n) time, being f(k) a\ncomputable function in one of the parameters \"score of the consensus\", \"maximum\ndistance between two input rankings\", \"number of candidates\" and \"average\npairwise Kendall-Tau distance\" and poly(n) a polynomial in the input size. This\nwork will demonstrate the practical usefulness of the corresponding algorithms\nby applying them to randomly generated and several real-world data. Thus, we\nshow that these fixed-parameter algorithms are not only of theoretical\ninterest. In a more theoretical part of this work we will develop an improved\nfixed-parameter algorithm for the parameter \"score of the consensus\" having a\nbetter upper bound for the running time than previous algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2010 14:19:04 GMT"}], "update_date": "2011-08-11", "authors_parsed": [["Bredereck", "Robert", ""]]}, {"id": "1001.4252", "submitter": "J. Maurice Rojas", "authors": "Martin Avendano, Ashraf Ibrahim, J. Maurice Rojas, Korben Rusek", "title": "Near NP-Completeness for Detecting p-adic Rational Roots in One Variable", "comments": "8 pages in 2 column format, 1 illustration. Submitted to a conference", "journal-ref": "proceedings of International Symposium on Symbolic and Algebraic\n  Computation (ISSAC 2010, July 25-28, 2010, Munchen), pp. 331-338, ACM Press,\n  2010", "doi": null, "report-no": null, "categories": "math.NT cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that deciding whether a sparse univariate polynomial has a p-adic\nrational root can be done in NP for most inputs. We also prove a\npolynomial-time upper bound for trinomials with suitably generic p-adic Newton\npolygon. We thus improve the best previous complexity upper bound of EXPTIME.\nWe also prove an unconditional complexity lower bound of NP-hardness with\nrespect to randomized reductions for general univariate polynomials. The best\nprevious lower bound assumed an unproved hypothesis on the distribution of\nprimes in arithmetic progression. We also discuss how our results complement\nanalogous results over the real numbers.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2010 16:15:23 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Avendano", "Martin", ""], ["Ibrahim", "Ashraf", ""], ["Rojas", "J. Maurice", ""], ["Rusek", "Korben", ""]]}, {"id": "1001.4255", "submitter": "Arne Meier", "authors": "Arne Meier and Thomas Schneider", "title": "The Complexity of Satisfiability for Sub-Boolean Fragments of ALC", "comments": "17 pages, accepted (in short version) to Description Logic Workshop\n  2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard reasoning problem, concept satisfiability, in the basic\ndescription logic ALC is PSPACE-complete, and it is EXPTIME-complete in the\npresence of unrestricted axioms. Several fragments of ALC, notably logics in\nthe FL, EL, and DL-Lite family, have an easier satisfiability problem;\nsometimes it is even tractable. All these fragments restrict the use of Boolean\noperators in one way or another. We look at systematic and more general\nrestrictions of the Boolean operators and establish the complexity of the\nconcept satisfiability problem in the presence of axioms. We separate tractable\nfrom intractable cases.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2010 17:21:46 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2010 10:42:54 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2010 15:36:05 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2010 10:48:41 GMT"}, {"version": "v5", "created": "Fri, 19 Feb 2010 12:20:23 GMT"}, {"version": "v6", "created": "Mon, 29 Mar 2010 11:42:44 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Meier", "Arne", ""], ["Schneider", "Thomas", ""]]}, {"id": "1001.4462", "submitter": "Alexander Shen", "authors": "Mikhail Andreev, Ilya Razenshteyn, Alexander Shen", "title": "Not Every Domain of a Plain Decompressor Contains the Domain of a\n  Prefix-Free One", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  C.Calude, A.Nies, L.Staiger, and F.Stephan posed the following question about\nthe relation between plain and prefix Kolmogorov complexities (see their paper\nin DLT 2008 conference proceedings): does the domain of every optimal\ndecompressor contain the domain of some optimal prefix-free decompressor? In\nthis paper we provide a negative answer to this question.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 15:33:08 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2010 12:12:53 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["Andreev", "Mikhail", ""], ["Razenshteyn", "Ilya", ""], ["Shen", "Alexander", ""]]}, {"id": "1001.4649", "submitter": "Nicola Caporaso", "authors": "Nicola Caporaso", "title": "Is Space a Stronger Resource than Time? Positive Answer for the\n  Nondeterministic at-Least-Quadratic Time Case", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that all languages accepted in time f(n) >= n^2 can be accepted in\nspace O(f(n)^{1/2})_and_ in time O(f(n)). The proof is carried out by\nsimulation, based on the idea of guessing the sequences of internal states of\nthe simulated TM when entering certain critical cells, whose location is also\nguessed. Our method cannot be generalised easily to many-tapes TMs, and in no\ncase can it be relativised.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2010 12:22:33 GMT"}], "update_date": "2010-01-27", "authors_parsed": [["Caporaso", "Nicola", ""]]}, {"id": "1001.4687", "submitter": "Bruno Bauwens", "authors": "Bruno Bauwens", "title": "m-sophistication", "comments": "13 pages, draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The m-sophistication of a finite binary string x is introduced as a\ngeneralization of some parameter in the proof that complexity of complexity is\nrare. A probabilistic near sufficient statistic of x is given which length is\nupper bounded by the m-sophistication of x within small additive terms. This\nshows that m-sophistication is lower bounded by coarse sophistication and upper\nbounded by sophistication within small additive terms. It is also shown that\nm-sophistication and coarse sophistication can not be approximated by an upper\nor lower semicomputable function, not even within very large error.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2010 13:53:08 GMT"}], "update_date": "2010-01-27", "authors_parsed": [["Bauwens", "Bruno", ""]]}, {"id": "1001.4829", "submitter": "Raghav Kulkarni", "authors": "Laszlo Babai, Anandam Banerjee, Raghav Kulkarni, Vipul Naik", "title": "Evasiveness and the Distribution of Prime Numbers", "comments": "12 pages (conference version for STACS 2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We confirm the eventual evasiveness of several classes of monotone graph\nproperties under widely accepted number theoretic hypotheses. In particular we\nshow that Chowla's conjecture on Dirichlet primes implies that (a) for any\ngraph $H$, \"forbidden subgraph $H$\" is eventually evasive and (b) all\nnontrivial monotone properties of graphs with $\\le n^{3/2-\\epsilon}$ edges are\neventually evasive. ($n$ is the number of vertices.)\n  While Chowla's conjecture is not known to follow from the Extended Riemann\nHypothesis (ERH, the Riemann Hypothesis for Dirichlet's $L$ functions), we show\n(b) with the bound $O(n^{5/4-\\epsilon})$ under ERH.\n  We also prove unconditional results: (a$'$) for any graph $H$, the query\ncomplexity of \"forbidden subgraph $H$\" is $\\binom{n}{2} - O(1)$; (b$'$) for\nsome constant $c>0$, all nontrivial monotone properties of graphs with $\\le\ncn\\log n+O(1)$ edges are eventually evasive.\n  Even these weaker, unconditional results rely on deep results from number\ntheory such as Vinogradov's theorem on the Goldbach conjecture.\n  Our technical contribution consists in connecting the topological framework\nof Kahn, Saks, and Sturtevant (1984), as further developed by Chakrabarti,\nKhot, and Shi (2002), with a deeper analysis of the orbital structure of\npermutation groups and their connection to the distribution of prime numbers.\nOur unconditional results include stronger versions and generalizations of some\nresult of Chakrabarti et al.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 00:31:30 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 10:56:22 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Babai", "Laszlo", ""], ["Banerjee", "Anandam", ""], ["Kulkarni", "Raghav", ""], ["Naik", "Vipul", ""]]}, {"id": "1001.4987", "submitter": "David Richerby", "authors": "Martin E. Dyer, Leslie Ann Goldberg, Markus Jalsenius and David\n  Richerby", "title": "The Complexity of Approximating Bounded-Degree Boolean #CSP (Extended\n  Abstract)", "comments": "12-page conference version for STACS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The degree of a CSP instance is the maximum number of times that a variable\nmay appear in the scope of constraints. We consider the approximate counting\nproblem for Boolean CSPs with bounded-degree instances, for constraint\nlanguages containing the two unary constant relations {0} and {1}. When the\nmaximum degree is at least 25 we obtain a complete classification of the\ncomplexity of this problem. It is exactly solvable in polynomial-time if every\nrelation in the constraint language is affine. It is equivalent to the problem\nof approximately counting independent sets in bipartite graphs if every\nrelation can be expressed as conjunctions of {0}, {1} and binary implication.\nOtherwise, there is no FPRAS unless NP=RP. For lower degree bounds, additional\ncases arise in which the complexity is related to the complexity of\napproximately counting independent sets in hypergraphs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 17:07:40 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 08:45:07 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Dyer", "Martin E.", ""], ["Goldberg", "Leslie Ann", ""], ["Jalsenius", "Markus", ""], ["Richerby", "David", ""]]}, {"id": "1001.5019", "submitter": "Siamak Tazari", "authors": "Stephan Kreutzer and Siamak Tazari", "title": "Lower Bounds for the Complexity of Monadic Second-Order Logic", "comments": "Preliminary version appeared in proceedings of the 25th IEEE\n  symposium on Logic in Computer Science (LICS'10), Edinburgh, Scotland, UK,\n  pp. 189-198, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Courcelle's famous theorem from 1990 states that any property of graphs\ndefinable in monadic second-order logic (MSO) can be decided in linear time on\nany class of graphs of bounded treewidth, or in other words, MSO is\nfixed-parameter tractable in linear time on any such class of graphs. From a\nlogical perspective, Courcelle's theorem establishes a sufficient condition, or\nan upper bound, for tractability of MSO-model checking.\n  Whereas such upper bounds on the complexity of logics have received\nsignificant attention in the literature, almost nothing is known about\ncorresponding lower bounds. In this paper we establish a strong lower bound for\nthe complexity of monadic second-order logic. In particular, we show that if C\nis any class of graphs which is closed under taking subgraphs and whose\ntreewidth is not bounded by a polylogarithmic function (in fact, $\\log^c n$ for\nsome small c suffices) then MSO-model checking is intractable on C (under a\nsuitable assumption from complexity theory).\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 20:51:47 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2011 20:50:43 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Kreutzer", "Stephan", ""], ["Tazari", "Siamak", ""]]}, {"id": "1001.5056", "submitter": "Shmuel Onn", "authors": "Jon Lee, Shmuel Onn, Robert Weismantel", "title": "Intractability of approximate multi-dimensional nonlinear optimization\n  on independence systems", "comments": null, "journal-ref": "Discrete Mathematics, 311:780--783, 2011", "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimization of nonlinear objective functions that balance $d$\nlinear criteria over $n$-element independence systems presented by\nlinear-optimization oracles. For $d=1$, we have previously shown that an\n$r$-best approximate solution can be found in polynomial time. Here, using an\nextended Erd\\H{o}s-Ko-Rado theorem of Frankl, we show that for $d=2$, finding a\n$\\rho n$-best solution requires exponential time.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2010 14:28:46 GMT"}], "update_date": "2011-07-05", "authors_parsed": [["Lee", "Jon", ""], ["Onn", "Shmuel", ""], ["Weismantel", "Robert", ""]]}, {"id": "1001.5307", "submitter": "Seiichiro Tani", "authors": "Hirotada Kobayashi, Keiji Matsumoto, Seiichiro Tani", "title": "Computing on Anonymous Quantum Network", "comments": "25 pages", "journal-ref": "Chicago Journal of Theoretical Computer Science, vol.2014, article\n  10, 2014 (entitled \"Simpler Exact Leader Election via Quantum Reduction\")", "doi": "10.4086/cjtcs.2014.010", "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers distributed computing on an anonymous quantum network, a\nnetwork in which no party has a unique identifier and quantum communication and\ncomputation are available. It is proved that the leader election problem can\nexactly (i.e., without error in bounded time) be solved with at most the same\ncomplexity up to a constant factor as that of exactly computing symmetric\nfunctions (without intermediate measurements for a distributed and superposed\ninput), if the number of parties is given to every party. A corollary of this\nresult is a more efficient quantum leader election algorithm than existing\nones: the new quantum algorithm runs in O(n) rounds with bit complexity\nO(mn^2), on an anonymous quantum network with n parties and m communication\nlinks. Another corollary is the first quantum algorithm that exactly computes\nany computable Boolean function with round complexity O(n) and with smaller bit\ncomplexity than that of existing classical algorithms in the worst case over\nall (computable) Boolean functions and network topologies. More generally, any\nn-qubit state can be shared with that complexity on an anonymous quantum\nnetwork with n parties.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2010 01:12:45 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kobayashi", "Hirotada", ""], ["Matsumoto", "Keiji", ""], ["Tani", "Seiichiro", ""]]}, {"id": "1001.5404", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Georg Moser", "title": "Efficient Implementation of Rewriting Revisited Technical Report", "comments": "Submitted to RTA 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Recently, many techniques have been introduced that allow the (automated)\nclassification of the runtime complexity of term rewrite systems (TRSs for\nshort). In earlier work, the authors have shown that for confluent TRSs,\ninnermost polynomial runtime complexity induces polytime computability of the\nfunctions defined.\n  In this paper, we generalise the above result to full rewriting. Following\nour previous work, we exploit graph rewriting. We give a new proof of the\nadequacy of graph rewriting for full rewriting that allows for a precise\ncontrol of the resources copied. In sum we completely describe an\nimplementation of rewriting on a Turing machine (TM for short). We show that\nthe runtime complexity of the TRS and the runtime complexity of the TM is\npolynomially related. Our result strengthens the evidence that the complexity\nof a rewrite system is truthfully represented through the length of\nderivations. Moreover our result allows the classification of non-deterministic\npolytime-computation based on runtime complexity analysis of rewrite systems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2010 13:44:28 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2010 18:14:44 GMT"}, {"version": "v3", "created": "Wed, 8 Jun 2011 07:01:49 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Avanzini", "Martin", ""], ["Moser", "Georg", ""]]}]