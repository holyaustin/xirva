[{"id": "1312.0036", "submitter": "Scott Aaronson", "authors": "Scott Aaronson and Andris Ambainis and Kaspars Balodis and Mohammad\n  Bavarian", "title": "Weak Parity", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of Weak Parity: the problem of computing the\nparity of an n-bit input string, where one only has to succeed on a 1/2+eps\nfraction of input strings, but must do so with high probability on those inputs\nwhere one does succeed. It is well-known that n randomized queries and n/2\nquantum queries are needed to compute parity on all inputs. But surprisingly,\nwe give a randomized algorithm for Weak Parity that makes only\nO(n/log^0.246(1/eps)) queries, as well as a quantum algorithm that makes only\nO(n/sqrt(log(1/eps))) queries. We also prove a lower bound of\nOmega(n/log(1/eps)) in both cases; and using extremal combinatorics, prove\nlower bounds of Omega(log n) in the randomized case and Omega(sqrt(log n)) in\nthe quantum case for any eps>0. We show that improving our lower bounds is\nintimately related to two longstanding open problems about Boolean functions:\nthe Sensitivity Conjecture, and the relationships between query complexity and\npolynomial degree.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2013 22:49:00 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Aaronson", "Scott", ""], ["Ambainis", "Andris", ""], ["Balodis", "Kaspars", ""], ["Bavarian", "Mohammad", ""]]}, {"id": "1312.0355", "submitter": "Benjamin Rossman", "authors": "Benjamin Rossman", "title": "Formulas vs. Circuits for Small Distance Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first super-polynomial separation in the power of bounded-depth\nboolean formulas vs. circuits. Specifically, we consider the problem Distance\n$k(n)$ Connectivity, which asks whether two specified nodes in a graph of size\n$n$ are connected by a path of length at most $k(n)$. This problem is solvable\n(by the recursive doubling technique) on {\\bf circuits} of depth $O(\\log k)$\nand size $O(kn^3)$. In contrast, we show that solving this problem on {\\bf\nformulas} of depth $\\log n/(\\log\\log n)^{O(1)}$ requires size $n^{\\Omega(\\log\nk)}$ for all $k(n) \\leq \\log\\log n$. As corollaries:\n  (i) It follows that polynomial-size circuits for Distance $k(n)$ Connectivity\nrequire depth $\\Omega(\\log k)$ for all $k(n) \\leq \\log\\log n$. This matches the\nupper bound from recursive doubling and improves a previous $\\Omega(\\log\\log\nk)$ lower bound of Beame, Pitassi and Impagliazzo [BIP98].\n  (ii) We get a tight lower bound of $s^{\\Omega(d)}$ on the size required to\nsimulate size-$s$ depth-$d$ circuits by depth-$d$ formulas for all $s(n) =\nn^{O(1)}$ and $d(n) \\leq \\log\\log\\log n$. No lower bound better than\n$s^{\\Omega(1)}$ was previously known for any $d(n) \\nleq O(1)$.\n  Our proof technique is centered on a new notion of pathset complexity, which\nroughly speaking measures the minimum cost of constructing a set of (partial)\npaths in a universe of size $n$ via the operations of union and relational\njoin, subject to certain density constraints. Half of our proof shows that\nbounded-depth formulas solving Distance $k(n)$ Connectivity imply upper bounds\non pathset complexity. The other half is a combinatorial lower bound on pathset\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2013 07:10:02 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Rossman", "Benjamin", ""]]}, {"id": "1312.0496", "submitter": "David Gajser", "authors": "David Gajser", "title": "Verifying whether One-Tape Non-Deterministic Turing Machines Run in Time\n  $Cn+D$", "comments": "12 pages + 5 pages appendix", "journal-ref": null, "doi": "10.1016/j.jcss.2019.08.004", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the following family of problems, parameterized by integers $C\\geq\n2$ and $D\\geq 1$: Does a given one-tape non-deterministic $q$-state Turing\nmachine make at most $Cn+D$ steps on all computations on all inputs of length\n$n$, for all $n$?\n  Assuming a fixed tape and input alphabet, we show that these problems are\nco-NP-complete and we provide good non-deterministic and co-non-deterministic\nlower bounds. Specifically, these problems can not be solved in\n$o(q^{(C-1)/4})$ non-deterministic time by multi-tape Turing machines. We also\nshow that the complements of these problems can be solved in $O(q^{C+2})$\nnon-deterministic time and not in $o(q^{(C-1)/2})$ non-deterministic time by\nmulti-tape Turing machines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2013 16:14:48 GMT"}, {"version": "v2", "created": "Mon, 19 May 2014 08:29:17 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Gajser", "David", ""]]}, {"id": "1312.0903", "submitter": "Bettina Klinz", "authors": "Vladimir G. Deineko, Bettina Klinz, Gerhard J. Woeginger", "title": "Uniqueness in quadratic and hyperbolic 0-1 programming problems", "comments": "6 pages", "journal-ref": "Operations research letters 41, 2013, 633-635", "doi": "10.1016/j.orl.2013.08.013", "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the question of deciding whether a quadratic or a hyperbolic 0-1\nprogramming instance has a unique optimal solution. Both uniqueness questions\nare known to be NP-hard, but are unlikely to be contained in the class NP. We\nprecisely pinpoint their computational complexity by showing that they both are\ncomplete for the complexity class {\\mbox{$\\Delta_2$P}.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2013 18:52:47 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["Deineko", "Vladimir G.", ""], ["Klinz", "Bettina", ""], ["Woeginger", "Gerhard J.", ""]]}, {"id": "1312.1027", "submitter": "Mark Zhandry", "authors": "Mark Zhandry", "title": "A Note on the Quantum Collision and Set Equality Problems", "comments": "10 pages. v2: fixed typos. v3: added set equality result", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The results showing a quantum query complexity of $\\Theta(N^{1/3})$ for the\ncollision problem do not apply to random functions. The issues are two-fold.\nFirst, the $\\Omega(N^{1/3})$ lower bound only applies when the range is no\nlarger than the domain, which precludes many of the cryptographically\ninteresting applications. Second, most of the results in the literature only\napply to $r$-to-1 functions, which are quite different from random functions.\nUnderstanding the collision problem for random functions is of great importance\nto cryptography, and we seek to fill the gaps of knowledge for this problem. To\nthat end, we prove that, as expected, a quantum query complexity of\n$\\Theta(N^{1/3})$ holds for all interesting domain and range sizes. Our proofs\nare simple, and combine existing techniques with several novel tricks to obtain\nthe desired results. Using our techniques, we also give an optimal\n$\\Omega(N^{1/3})$ lower bound for the set equality problem. This new lower\nbound can be used to improve the relationship between classical randomized\nquery complexity and quantum query complexity for so-called\npermutation-symmetric functions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 05:37:09 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2013 20:20:56 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2013 00:48:58 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Zhandry", "Mark", ""]]}, {"id": "1312.1299", "submitter": "Pierre-Etienne Meunier", "authors": "Pierre-\\'Etienne Meunier", "title": "The self-assembly of paths and squares at temperature 1", "comments": "arXiv admin note: text overlap with arXiv:1306.6710 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the number of tile types required to build squares of size n x\nn, in Winfree's abstract Tile Assembly Model, when restricted to using only\nnon-cooperative tile bindings, is at least 2n-1, which is also the best known\nupper bound. Non-cooperative self-assembly, also known as temperature 1, is\nwhere tiles bind to each other if they match on one or more sides, whereas in\ncooperative binding, some tiles can bind only if they match on multiple sides.\n  Our proof introduces a new programming technique for temperature 1, that\ndisproves the very intuitive and commonly held belief that, in the same model,\nassembling paths between two points A and B cannot be done with less tile types\nthan the Manhattan distance between them. Then, we prove a necessary condition\nfor these \"efficient paths\" to be assembled, and show that this necessary\ncondition cannot hold in completely filled squares.\n  This result proves the oldest conjecture in algorithmic self-assembly,\npublished by Rothemund and Winfree in STOC 2000, in the case where growth\nstarts from a corner of the square. As a corollary, we establish n as a lower\nbound on the tile complexity of the general case. The problem of determining\nthe minimal number of tile types to self-assemble a shape is known to be\nSigma^p_2-complete.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2013 21:04:12 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2013 18:10:28 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Meunier", "Pierre-\u00c9tienne", ""]]}, {"id": "1312.1526", "submitter": "Saeed Akhoondian Amiri", "authors": "Saeed Amiri, Ali Golshani, Stephan Kreutzer, Sebastian Siebertz", "title": "Vertex Disjoint Path in Upward Planar Graphs", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-vertex disjoint paths problem is one of the most studied problems in\nalgorithmic graph theory. In 1994, Schrijver proved that the problem can be\nsolved in polynomial time for every fixed $k$ when restricted to the class of\nplanar digraphs and it was a long standing open question whether it is\nfixed-parameter tractable (with respect to parameter $k$) on this restricted\nclass. Only recently, \\cite{CMPP}.\\ achieved a major breakthrough and answered\nthe question positively. Despite the importance of this result (and the\nbrilliance of their proof), it is of rather theoretical importance. Their proof\ntechnique is both technically extremely involved and also has at least double\nexponential parameter dependence. Thus, it seems unrealistic that the algorithm\ncould actually be implemented. In this paper, therefore, we study a smaller\nclass of planar digraphs, the class of upward planar digraphs, a well studied\nclass of planar graphs which can be drawn in a plane such that all edges are\ndrawn upwards. We show that on the class of upward planar digraphs the problem\n(i) remains NP-complete and (ii) the problem is fixed-parameter tractable.\nWhile membership in FPT follows immediately from \\cite{CMPP}'s general result,\nour algorithm has only single exponential parameter dependency compared to the\ndouble exponential parameter dependence for general planar digraphs.\nFurthermore, our algorithm can easily be implemented, in contrast to the\nalgorithm in \\cite{CMPP}.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 12:47:28 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Amiri", "Saeed", ""], ["Golshani", "Ali", ""], ["Kreutzer", "Stephan", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1312.1661", "submitter": "Alexander Vasiliev", "authors": "Alexander Vasiliev", "title": "Quantum Communications Based on Quantum Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider an application of the recently proposed quantum\nhashing technique for computing Boolean functions in the quantum communication\nmodel. The combination of binary functions on non-binary quantum hash function\nis done via polynomial presentation, which we have called a characteristic of a\nBoolean function. Based on the characteristic polynomial presentation of\nBoolean functions and quantum hashing technique we present a method for\ncomputing Boolean functions in the quantum one-way communication model, where\none of the parties performs his computations and sends a message to the other\nparty, who must output the result after his part of computations. Some of the\nresults are also true in a more restricted Simultaneous Message Passing model\nwith no shared resources, in which communicating parties can interact only via\nthe referee. We give several examples of Boolean functions whose polynomial\npresentations have specific properties allowing for construction of quantum\ncommunication protocols that are provably exponentially better than classical\nones in the simultaneous message passing setting.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 20:00:35 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2016 14:52:19 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Vasiliev", "Alexander", ""]]}, {"id": "1312.1672", "submitter": "Ronald de Haan", "authors": "Ronald de Haan, Stefan Szeider", "title": "The Parameterized Complexity of Reasoning Problems Beyond NP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's propositional satisfiability (SAT) solvers are extremely powerful and\ncan be used as an efficient back-end for solving NP-complete problems. However,\nmany fundamental problems in knowledge representation and reasoning are located\nat the second level of the Polynomial Hierarchy or even higher, and hence\npolynomial-time transformations to SAT are not possible, unless the hierarchy\ncollapses. Recent research shows that in certain cases one can break through\nthese complexity barriers by fixed-parameter tractable (fpt) reductions which\nexploit structural aspects of problem instances in terms of problem parameters.\nIn this paper we develop a general theoretical framework that supports the\nclassification of parameterized problems on whether they admit such an\nfpt-reduction to SAT or not. This framework is based on several new\nparameterized complexity classes. As a running example, we use the framework to\nclassify the complexity of the consistency problem for disjunctive answer set\nprogramming, with respect to various natural parameters. We underpin the\nrobustness of our theory by providing a characterization of the new complexity\nclasses in terms of weighted QBF satisfiability, alternating Turing machines,\nand first-order model checking. In addition, we provide a compendium of\nparameterized problems that are complete for the new complexity classes,\nincluding problems related to Knowledge Representation and Reasoning, Logic,\nand Combinatorics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 20:20:06 GMT"}, {"version": "v2", "created": "Wed, 9 Jul 2014 13:01:25 GMT"}, {"version": "v3", "created": "Fri, 31 Oct 2014 16:33:04 GMT"}, {"version": "v4", "created": "Fri, 1 Jul 2016 17:37:52 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["de Haan", "Ronald", ""], ["Szeider", "Stefan", ""]]}, {"id": "1312.1674", "submitter": "Anand Kumar Narayanan", "authors": "Ming-Deh Huang and Anand Kumar Narayanan", "title": "On the relation generation method of Joux for computing discrete\n  logarithms", "comments": "arXiv admin note: substantial text overlap with arXiv:1304.1206", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In \\cite{joux}, Joux devised an algorithm to compute discrete logarithms\nbetween elements in a certain subset of the multiplicative group of an\nextension of the finite field $\\mathbb{F}_{p^n}$ in time polynomial in $p$ and\n$n$. Shortly after, Barbulescu, Gaudry, Joux and Thome \\cite{bgjt} proposed a\ndescent algorithm that in $(p n)^{\\mathcal{O}(\\log n)}$ time projects an\narbitrary element in $\\mathbb{F}_{p^n}^\\times$ as a product of powers of\nelements in the aforementioned subset. Together, these two algorithms yield a\nquasi-polynomial time algorithm for computing discrete logarithms in finite\nfields of small characteristic. The success of both the algorithms are reliant\non heuristic assumptions. We identify obstructions that prevent certain\nheuristic assumptions they make from being true in general. Further, we\ndescribe methods to overcome these obstructions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 20:31:28 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2013 19:51:29 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Huang", "Ming-Deh", ""], ["Narayanan", "Anand Kumar", ""]]}, {"id": "1312.1718", "submitter": "Bruno Bauwens", "authors": "Bruno Bauwens", "title": "Upper semicomputable sumtests for lower semicomputable semimeasures", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sumtest for a discrete semimeasure $P$ is a function $f$ mapping bitstrings\nto non-negative rational numbers such that \\[\n  \\sum P(x)f(x) \\le 1 \\,.\n  \\] Sumtests are the discrete analogue of Martin-L\\\"of tests. The behavior of\nsumtests for computable $P$ seems well understood, but for some applications\nlower semicomputable $P$ seem more appropriate. In the case of tests for\nindependence, it is natural to consider upper semicomputable tests (see\n[B.Bauwens and S.Terwijn, Theory of Computing Systems 48.2 (2011): 247-268]).\n  In this paper, we characterize upper semicomputable sumtests relative to any\nlower semicomputable semimeasures using Kolmogorov complexity. It is studied to\nwhat extend such tests are pathological: can upper semicomputable sumtests for\n$m(x)$ be large? It is shown that the logarithm of such tests does not exceed\n$\\log |x| + O(\\log^{(2)} |x|)$ (where $|x|$ denotes the length of $x$ and\n$\\log^{(2)} = \\log\\log$) and that this bound is tight, i.e. there is a test\nwhose logarithm exceeds $\\log |x| - O(\\log^{(2)} |x|$) infinitely often.\nFinally, it is shown that for each such test $e$ the mutual information of a\nstring with the Halting problem is at least $\\log e(x)-O(1)$; thus $e$ can only\nbe large for ``exotic'' strings.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 22:15:43 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Bauwens", "Bruno", ""]]}, {"id": "1312.1826", "submitter": "Arpita Korwar", "authors": "Manindra Agrawal and Rohit Gurjar and Arpita Korwar and Nitin Saxena", "title": "Hitting-sets for low-distance multilinear depth-3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The depth-$3$ model has recently gained much importance, as it has become a\nstepping-stone to understanding general arithmetic circuits. Its restriction to\nmultilinearity has known exponential lower bounds but no nontrivial blackbox\nidentity tests. In this paper we take a step towards designing such\nhitting-sets. We define a notion of distance for multilinear depth-$3$ circuits\n(say, in $n$ variables and $k$ product gates) that measures how far are the\npartitions from a mere refinement. The $1$-distance strictly subsumes the\nset-multilinear model, while $n$-distance captures general multilinear\ndepth-$3$. We design a hitting-set in time poly($n^{\\delta\\log k}$) for\n$\\delta$-distance. Further, we give an extension of our result to models where\nthe distance is large (close to $n$) but it is small when restricted to certain\nvariables. This implies the first subexponential whitebox PIT for the sum of\nconstantly many set-multilinear depth-$3$ circuits.\n  We also explore a new model of read-once algebraic branching programs (ROABP)\nwhere the factor-matrices are invertible (called invertible-factor ROABP). We\ndesign a hitting-set in time poly($\\text{size}^{w^2}$) for width-$w$\ninvertible-factor ROABP. Further, we could do without the invertibility\nrestriction when $w=2$. Previously, the best result for width-$2$ ROABP was\nquasi-polynomial time (Forbes-Saptharishi-Shpilka, arXiv 2013).\n  The common thread in all these results is the phenomenon of low-support `rank\nconcentration'. We exploit the structure of these models to prove\nrank-concentration after a `small shift' in the variables. Our proof techniques\nare stronger than the results of Agrawal-Saha-Saxena (STOC 2013) and\nForbes-Saptharishi-Shpilka (arXiv 2013); giving us quasi-polynomial-time\nhitting-sets for models where no subexponential whitebox algorithms were known\nbefore.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 10:46:21 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Agrawal", "Manindra", ""], ["Gurjar", "Rohit", ""], ["Korwar", "Arpita", ""], ["Saxena", "Nitin", ""]]}, {"id": "1312.1983", "submitter": "Andrew Wan", "authors": "Adi Livnat and Christos Papadimitriou and Aviad Rubinstein and Gregory\n  Valiant and Andrew Wan", "title": "Satisfiability and Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, if truth assignments on $n$ variables reproduce through\nrecombination so that satisfaction of a particular Boolean function confers a\nsmall evolutionary advantage, then a polynomially large population over\npolynomially many generations (polynomial in $n$ and the inverse of the initial\nsatisfaction probability) will end up almost certainly consisting exclusively\nof satisfying truth assignments. We argue that this theorem sheds light on the\nproblem of novelty in Evolution.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 19:59:41 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2013 18:48:23 GMT"}, {"version": "v3", "created": "Mon, 11 Aug 2014 23:35:24 GMT"}], "update_date": "2014-08-13", "authors_parsed": [["Livnat", "Adi", ""], ["Papadimitriou", "Christos", ""], ["Rubinstein", "Aviad", ""], ["Valiant", "Gregory", ""], ["Wan", "Andrew", ""]]}, {"id": "1312.2086", "submitter": "Raphael Machado", "authors": "H\\'elio B. Mac\\^edo Filho, Raphael C. S. Machado, Celina M. H. de\n  Figueiredo", "title": "Hierarchical complexity of 2-clique-colouring weakly chordal graphs and\n  perfect graphs having cliques of size at least 3", "comments": "An extended abstract of this work was accepted for presentation at\n  Latin 2014, the 11th Latin American Symposium on Theoretical Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A clique of a graph is a maximal set of vertices of size at least 2 that\ninduces a complete graph. A $k$-clique-colouring of a graph is a colouring of\nthe vertices with at most $k$ colours such that no clique is monochromatic.\nD\\'efossez proved that the 2-clique-colouring of perfect graphs is a\n$\\Sigma_2^P$-complete problem [J. Graph Theory 62 (2009) 139--156]. We\nstrengthen this result by showing that it is still $\\Sigma_2^P$-complete for\nweakly chordal graphs. We then determine a hierarchy of nested subclasses of\nweakly chordal graphs whereby each graph class is in a distinct complexity\nclass, namely $\\Sigma_2^P$-complete, $\\mathcal{NP}$-complete, and\n$\\mathcal{P}$. We solve an open problem posed by Kratochv\\'il and Tuza to\ndetermine the complexity of 2-clique-colouring of perfect graphs with all\ncliques having size at least 3 [J. Algorithms 45 (2002), 40--54], proving that\nit is a $\\Sigma_2^P$-complete problem. We then determine a hierarchy of nested\nsubclasses of perfect graphs with all cliques having size at least 3 whereby\neach graph class is in a distinct complexity class, namely\n$\\Sigma_2^P$-complete, $\\mathcal{NP}$-complete, and $\\mathcal{P}$.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2013 11:11:34 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2013 09:44:26 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Filho", "H\u00e9lio B. Mac\u00eado", ""], ["Machado", "Raphael C. S.", ""], ["de Figueiredo", "Celina M. H.", ""]]}, {"id": "1312.2141", "submitter": "Jenish Mehta", "authors": "Jenish C. Mehta", "title": "Dynamic Complexity of Planar 3-connected Graph Isomorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Complexity (as introduced by Patnaik and Immerman) tries to express\nhow hard it is to update the solution to a problem when the input is changed\nslightly. It considers the changes required to some stored data structure\n(possibly a massive database) as small quantities of data (or a tuple) are\ninserted or deleted from the database (or a structure over some vocabulary).\nThe main difference from previous notions of dynamic complexity is that instead\nof treating the update quantitatively by finding the the time/space trade-offs,\nit tries to consider the update qualitatively, by finding the complexity class\nin which the update can be expressed (or made). In this setting, DynFO, or\nDynamic First-Order, is one of the smallest and the most natural complexity\nclass (since SQL queries can be expressed in First-Order Logic), and contains\nthose problems whose solutions (or the stored data structure from which the\nsolution can be found) can be updated in First-Order Logic when the data\nstructure undergoes small changes.\n  Etessami considered the problem of isomorphism in the dynamic setting, and\nshowed that Tree Isomorphism can be decided in DynFO. In this work, we show\nthat isomorphism of Planar 3-connected graphs can be decided in DynFO+ (which\nis DynFO with some polynomial precomputation). We maintain a canonical\ndescription of 3-connected Planar graphs by maintaining a database which is\naccessed and modified by First-Order queries when edges are added to or deleted\nfrom the graph. We specifically exploit the ideas of Breadth-First Search and\nCanonical Breadth-First Search to prove the results. We also introduce a novel\nmethod for canonizing a 3-connected planar graph in First-Order Logic from\nCanonical Breadth-First Search Trees.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2013 20:49:44 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Mehta", "Jenish C.", ""]]}, {"id": "1312.2143", "submitter": "Li-Yang Tan", "authors": "Ryan O'Donnell, Xiaorui Sun, Li-Yang Tan, John Wright, Yu Zhao", "title": "A composition theorem for parity kill number", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the parity complexity measures\n${\\mathsf{C}^{\\oplus}_{\\min}}[f]$ and ${\\mathsf{DT^{\\oplus}}}[f]$.\n${\\mathsf{C}^{\\oplus}_{\\min}}[f]$ is the \\emph{parity kill number} of $f$, the\nfewest number of parities on the input variables one has to fix in order to\n\"kill\" $f$, i.e. to make it constant. ${\\mathsf{DT^{\\oplus}}}[f]$ is the depth\nof the shortest \\emph{parity decision tree} which computes $f$. These\ncomplexity measures have in recent years become increasingly important in the\nfields of communication complexity \\cite{ZS09, MO09, ZS10, TWXZ13} and\npseudorandomness \\cite{BK12, Sha11, CT13}.\n  Our main result is a composition theorem for ${\\mathsf{C}^{\\oplus}_{\\min}}$.\nThe $k$-th power of $f$, denoted $f^{\\circ k}$, is the function which results\nfrom composing $f$ with itself $k$ times. We prove that if $f$ is not a parity\nfunction, then ${\\mathsf{C}^{\\oplus}_{\\min}}[f^{\\circ k}] \\geq\n\\Omega({\\mathsf{C}_{\\min}}[f]^{k}).$ In other words, the parity kill number of\n$f$ is essentially supermultiplicative in the \\emph{normal} kill number of $f$\n(also known as the minimum certificate complexity).\n  As an application of our composition theorem, we show lower bounds on the\nparity complexity measures of $\\mathsf{Sort}^{\\circ k}$ and $\\mathsf{HI}^{\\circ\nk}$. Here $\\mathsf{Sort}$ is the sort function due to Ambainis \\cite{Amb06},\nand $\\mathsf{HI}$ is Kushilevitz's hemi-icosahedron function \\cite{NW95}. In\ndoing so, we disprove a conjecture of Montanaro and Osborne \\cite{MO09} which\nhad applications to communication complexity and computational learning theory.\nIn addition, we give new lower bounds for conjectures of \\cite{MO09,ZS10} and\n\\cite{TWXZ13}.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2013 21:40:43 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["O'Donnell", "Ryan", ""], ["Sun", "Xiaorui", ""], ["Tan", "Li-Yang", ""], ["Wright", "John", ""], ["Zhao", "Yu", ""]]}, {"id": "1312.2226", "submitter": "Mikhail Berlinkov", "authors": "Mikhail V. Berlinkov", "title": "On two Algorithmic Problems about Synchronizing Automata", "comments": "Revised and reviewed version, in particular, the result of complexity\n  of synchronization of partial automata was fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the assumption $\\mathcal{P} \\neq \\mathcal{NP}$, we prove that two\nnatural problems from the theory of synchronizing automata cannot be solved in\npolynomial time. The first problem is to decide whether a given reachable\npartial automaton is synchronizing. The second one is, given an $n$-state\nbinary complete synchronizing automaton, to compute its reset threshold within\nperformance ratio less than $d \\ln{(n)}$ for a specific constant $d>0$.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2013 15:24:47 GMT"}, {"version": "v2", "created": "Mon, 24 Mar 2014 16:07:15 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 05:33:07 GMT"}, {"version": "v4", "created": "Fri, 23 Mar 2018 03:16:44 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Berlinkov", "Mikhail V.", ""]]}, {"id": "1312.2367", "submitter": "Tali  Kaufman", "authors": "Tali Kaufman, Alexander Lubotzky", "title": "High Dimensional Expanders and Property Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the high dimensional expansion property as defined by Gromov,\nLinial and Meshulam, for simplicial complexes is a form of testability. Namely,\na simplicial complex is a high dimensional expander iff a suitable property is\ntestable. Using this connection, we derive several testability results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 10:23:53 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Kaufman", "Tali", ""], ["Lubotzky", "Alexander", ""]]}, {"id": "1312.2483", "submitter": "Robin K\\\"unzler", "authors": "Thomas Holenstein and Robin K\\\"unzler", "title": "A Protocol for Generating Random Elements with their Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an AM protocol that allows the verifier to sample elements x from a\nprobability distribution P, which is held by the prover. If the prover is\nhonest, the verifier outputs (x, P(x)) with probability close to P(x). In case\nthe prover is dishonest, one may hope for the following guarantee: if the\nverifier outputs (x, p), then the probability that the verifier outputs x is\nclose to p. Simple examples show that this cannot be achieved. Instead, we show\nthat the following weaker condition holds (in a well defined sense) on average:\nIf (x, p) is output, then p is an upper bound on the probability that x is\noutput. Our protocol yields a new transformation to turn interactive proofs\nwhere the verifier uses private random coins into proofs with public coins. The\nverifier has better running time compared to the well-known Goldwasser-Sipser\ntransformation (STOC, 1986). For constant-round protocols, we only lose an\narbitrarily small constant in soundness and completeness, while our public-coin\nverifier calls the private-coin verifier only once.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 16:02:40 GMT"}, {"version": "v2", "created": "Mon, 24 Mar 2014 09:23:01 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Holenstein", "Thomas", ""], ["K\u00fcnzler", "Robin", ""]]}, {"id": "1312.2490", "submitter": "Robin K\\\"unzler", "authors": "Thomas Holenstein and Robin K\\\"unzler", "title": "A New View on Worst-Case to Average-Case Reductions for NP Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the result by Bogdanov and Trevisan (FOCS, 2003), who show that\nunder reasonable assumptions, there is no non-adaptive worst-case to\naverage-case reduction that bases the average-case hardness of an NP-problem on\nthe worst-case complexity of an NP-complete problem. We replace the hiding and\nthe heavy samples protocol in [BT03] by employing the histogram verification\nprotocol of Haitner, Mahmoody and Xiao (CCC, 2010), which proves to be very\nuseful in this context. Once the histogram is verified, our hiding protocol is\ndirectly public-coin, whereas the intuition behind the original protocol\ninherently relies on private coins.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 16:13:26 GMT"}, {"version": "v2", "created": "Mon, 24 Mar 2014 09:20:05 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Holenstein", "Thomas", ""], ["K\u00fcnzler", "Robin", ""]]}, {"id": "1312.2496", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae, Keisuke Fujii, Joseph F. Fitzsimons", "title": "On the hardness of classically simulating the one clean qubit model", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. Lett. 112, 130502 (2014)", "doi": "10.1103/PhysRevLett.112.130502", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cond-mat.str-el cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deterministic quantum computation with one quantum bit (DQC1) is a model of\nquantum computing where the input restricted to containing a single qubit in a\npure state and with all other qubits in a completely-mixed state, with only a\nsingle qubit measurement at the end of the computation [E. Knill and R.\nLaflamme, Phys. Rev. Lett. {\\bf81}, 5672 (1998)]. While it is known that DQC1\ncan efficiently solve several problems for which no known classical efficient\nalgorithms exist, the question of whether DQC1 is really more powerful than\nclassical computation remains open. In this paper, we introduce a slightly\nmodified version of DQC1, which we call DQC1$_k$, where $k$ output qubits are\nmeasured, and show that DQC1$_k$ cannot be classically efficiently simulated\nfor any $k\\geq3$ unless the polynomial hierarchy collapses at the third level.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 16:22:25 GMT"}, {"version": "v2", "created": "Wed, 2 Apr 2014 22:56:28 GMT"}], "update_date": "2015-03-02", "authors_parsed": [["Morimae", "Tomoyuki", ""], ["Fujii", "Keisuke", ""], ["Fitzsimons", "Joseph F.", ""]]}, {"id": "1312.2915", "submitter": "Rishi Saket", "authors": "Rishi Saket", "title": "Hardness of Finding Independent Sets in 2-Colorable Hypergraphs and of\n  Satisfiable CSPs", "comments": "23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work revisits the PCP Verifiers used in the works of Hastad [Has01],\nGuruswami et al.[GHS02], Holmerin[Hol02] and Guruswami[Gur00] for satisfiable\nMax-E3-SAT and Max-Ek-Set-Splitting, and independent set in 2-colorable\n4-uniform hypergraphs. We provide simpler and more efficient PCP Verifiers to\nprove the following improved hardness results: Assuming that NP\\not\\subseteq\nDTIME(N^{O(loglog N)}),\n  There is no polynomial time algorithm that, given an n-vertex 2-colorable\n4-uniform hypergraph, finds an independent set of n/(log n)^c vertices, for\nsome constant c > 0.\n  There is no polynomial time algorithm that satisfies 7/8 + 1/(log n)^c\nfraction of the clauses of a satisfiable Max-E3-SAT instance of size n, for\nsome constant c > 0.\n  For any fixed k >= 4, there is no polynomial time algorithm that finds a\npartition splitting (1 - 2^{-k+1}) + 1/(log n)^c fraction of the k-sets of a\nsatisfiable Max-Ek-Set-Splitting instance of size n, for some constant c > 0.\n  Our hardness factor for independent set in 2-colorable 4-uniform hypergraphs\nis an exponential improvement over the previous results of Guruswami et\nal.[GHS02] and Holmerin[Hol02]. Similarly, our inapproximability of (log\nn)^{-c} beyond the random assignment threshold for Max-E3-SAT and\nMax-Ek-Set-Splitting is an exponential improvement over the previous bounds\nproved in [Has01], [Hol02] and [Gur00]. The PCP Verifiers used in our results\navoid the use of a variable bias parameter used in previous works, which leads\nto the improved hardness thresholds in addition to simplifying the analysis\nsubstantially. Apart from standard techniques from Fourier Analysis, for the\nfirst mentioned result we use a mixing estimate of Markov Chains based on\nuniform reverse hypercontractivity over general product spaces from the work of\nMossel et al.[MOS13].\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 19:04:24 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Saket", "Rishi", ""]]}, {"id": "1312.3003", "submitter": "Andrew Wan", "authors": "Andrew Wan and John Wright and Chenggang Wu", "title": "Decision Trees, Protocols, and the Fourier Entropy-Influence Conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $f:\\{-1, 1\\}^n \\rightarrow \\{-1, 1\\}$, define the \\emph{spectral\ndistribution} of $f$ to be the distribution on subsets of $[n]$ in which the\nset $S$ is sampled with probability $\\widehat{f}(S)^2$. Then the Fourier\nEntropy-Influence (FEI) conjecture of Friedgut and Kalai (1996) states that\nthere is some absolute constant $C$ such that $\\operatorname{H}[\\widehat{f}^2]\n\\leq C\\cdot\\operatorname{Inf}[f]$. Here, $\\operatorname{H}[\\widehat{f}^2]$\ndenotes the Shannon entropy of $f$'s spectral distribution, and\n$\\operatorname{Inf}[f]$ is the total influence of $f$. This conjecture is one\nof the major open problems in the analysis of Boolean functions, and settling\nit would have several interesting consequences.\n  Previous results on the FEI conjecture have been largely through direct\ncalculation. In this paper we study a natural interpretation of the conjecture,\nwhich states that there exists a communication protocol which, given subset $S$\nof $[n]$ distributed as $\\widehat{f}^2$, can communicate the value of $S$ using\nat most $C\\cdot\\operatorname{Inf}[f]$ bits in expectation.\n  Using this interpretation, we are able show the following results:\n  1. First, if $f$ is computable by a read-$k$ decision tree, then\n$\\operatorname{H}[\\widehat{f}^2] \\leq 9k\\cdot \\operatorname{Inf}[f]$.\n  2. Next, if $f$ has $\\operatorname{Inf}[f] \\geq 1$ and is computable by a\ndecision tree with expected depth $d$, then $\\operatorname{H}[\\widehat{f}^2]\n\\leq 12d\\cdot \\operatorname{Inf}[f]$.\n  3. Finally, we give a new proof of the main theorem of O'Donnell and Tan\n(ICALP 2013), i.e. that their FEI$^+$ conjecture composes.\n  In addition, we show that natural improvements to our decision tree results\nwould be sufficient to prove the FEI conjecture in its entirety. We believe\nthat our methods give more illuminating proofs than previous results about the\nFEI conjecture.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 00:15:28 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Wan", "Andrew", ""], ["Wright", "John", ""], ["Wu", "Chenggang", ""]]}, {"id": "1312.3024", "submitter": "Ali Sinop", "authors": "Venkatesan Guruswami and Ali Kemal Sinop", "title": "Rounding Lasserre SDPs using column selection and spectrum-based\n  approximation schemes for graph partitioning and Quadratic IPs", "comments": "This manuscript is a merged and definitive version of (Guruswami,\n  Sinop: FOCS 2011) and (Guruswami, Sinop: SODA 2013), with a significantly\n  revised presentation. arXiv admin note: substantial text overlap with\n  arXiv:1104.4746", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approximation scheme for minimizing certain Quadratic Integer\nProgramming problems with positive semidefinite objective functions and global\nlinear constraints. This framework includes well known graph problems such as\nMinimum graph bisection, Edge expansion, Sparsest Cut, and Small Set expansion,\nas well as the Unique Games problem. These problems are notorious for the\nexistence of huge gaps between the known algorithmic results and NP-hardness\nresults. Our algorithm is based on rounding semidefinite programs from the\nLasserre hierarchy, and the analysis uses bounds for low-rank approximations of\na matrix in Frobenius norm using columns of the matrix.\n  For all the above graph problems, we give an algorithm running in time\n$n^{O(r/\\epsilon^2)}$ with approximation ratio\n$\\frac{1+\\epsilon}{\\min\\{1,\\lambda_r\\}}$, where $\\lambda_r$ is the $r$'th\nsmallest eigenvalue of the normalized graph Laplacian $\\mathcal{L}$. In the\ncase of graph bisection and small set expansion, the number of vertices in the\ncut is within lower-order terms of the stipulated bound. Our results imply\n$(1+O(\\epsilon))$ factor approximation in time $n^{O(r^\\ast/\\epsilon^2)}$ where\nis the number of eigenvalues of $\\mathcal{L}$ smaller than $1-\\epsilon$ (for\nvariants of sparsest cut, $\\lambda_{r^\\ast} \\ge \\mathrm{OPT}/\\epsilon$ also\nsuffices, and as $\\mathrm{OPT}$ is usually $o(1)$ on interesting instances of\nthese problems, this requirement on $r^\\ast$ is typically weaker). For Unique\nGames, we give a factor $(1+\\frac{2+\\epsilon}{\\lambda_r})$ approximation for\nminimizing the number of unsatisfied constraints in $n^{O(r/\\epsilon)}$ time,\nimproving upon an earlier bound for solving Unique Games on expanders. We also\ngive an algorithm for independent sets in graphs that performs well when the\nLaplacian does not have too many eigenvalues bigger than $1+o(1)$.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 02:58:22 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Sinop", "Ali Kemal", ""]]}, {"id": "1312.3193", "submitter": "Eric Miles", "authors": "Eric Miles", "title": "Iterated group products and leakage resilience against NC^1", "comments": "ITCS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if NC$^1 \\neq$ L, then for every element $\\alpha$ of the\nalternating group $A_t$, circuits of depth $O(\\log t)$ cannot distinguish\nbetween a uniform vector over $(A_t)^t$ with product $= \\alpha$ and one with\nproduct $=$ identity. Combined with a recent construction by the author and\nViola in the setting of leakage-resilient cryptography [STOC '13], this gives a\ncompiler that produces circuits withstanding leakage from NC$^1$ (assuming\nNC$^1 \\neq$ L). For context, leakage from NC$^1$ breaks nearly all previous\nconstructions, and security against leakage from P is impossible. %In the\nmulti-query setting, circuits produced by this compiler use a simple secure\nhardware component.\n  We build on work by Cook and McKenzie [J.\\ Algorithms '87] establishing the\nrelationship between L $=$ logarithmic space and the symmetric group $S_t$. Our\ntechniques include a novel algorithmic use of commutators to manipulate the\ncycle structure of permutations in $A_t$.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 14:48:42 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Miles", "Eric", ""]]}, {"id": "1312.3248", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli, Yael Amsterdamer, Tova Milo", "title": "On the Complexity of Mining Itemsets from the Crowd Using Taxonomies", "comments": "18 pages, 2 figures. To be published to ICDT'13. Added missing\n  acknowledgement", "journal-ref": null, "doi": "10.5441/002/icdt.2014.06", "report-no": null, "categories": "cs.DB cs.CC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of frequent itemset mining in domains where data is not\nrecorded in a conventional database but only exists in human knowledge. We\nprovide examples of such scenarios, and present a crowdsourcing model for them.\nThe model uses the crowd as an oracle to find out whether an itemset is\nfrequent or not, and relies on a known taxonomy of the item domain to guide the\nsearch for frequent itemsets. In the spirit of data mining with oracles, we\nanalyze the complexity of this problem in terms of (i) crowd complexity, that\nmeasures the number of crowd questions required to identify the frequent\nitemsets; and (ii) computational complexity, that measures the computational\neffort required to choose the questions. We provide lower and upper complexity\nbounds in terms of the size and structure of the input taxonomy, as well as the\nsize of a concise description of the output itemsets. We also provide\nconstructive algorithms that achieve the upper bounds, and consider more\nefficient variants for practical situations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 17:15:39 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2013 11:50:11 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Amarilli", "Antoine", ""], ["Amsterdamer", "Yael", ""], ["Milo", "Tova", ""]]}, {"id": "1312.3537", "submitter": "Jacob Turner", "authors": "Jason Morton and Jacob Turner", "title": "Computing the Tutte Polynomial of Lattice Path Matroids Using\n  Determinantal Circuits", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2015.07.042", "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a quantum-inspired $O(n^4)$ algorithm computing the Tutte polynomial\nof a lattice path matroid, where $n$ is the size of the ground set of the\nmatroid. Furthermore, this can be improved to $O(n^2)$ arithmetic operations if\nwe evaluate the Tutte polynomial on a given input, fixing the values of the\nvariables. The best existing algorithm, found in 2004, was $O(n^5)$, and the\nproblem has only been known to be polynomial time since 2003. Conceptually, our\nalgorithm embeds the computation in a determinant using a recently demonstrated\nequivalence of categories useful for counting problems such as those that\nappear in simulating quantum systems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2013 16:32:33 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2015 16:30:41 GMT"}], "update_date": "2015-10-08", "authors_parsed": [["Morton", "Jason", ""], ["Turner", "Jacob", ""]]}, {"id": "1312.3892", "submitter": "Vittorio Bil\\`o", "authors": "Vittorio Bil\\`o, Michele Flammini, Gianpiero Monaco", "title": "Approximating the Revenue Maximization Problem with Sharp Demands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the revenue maximization problem with sharp multi-demand, in\nwhich $m$ indivisible items have to be sold to $n$ potential buyers. Each buyer\n$i$ is interested in getting exactly $d_i$ items, and each item $j$ gives a\nbenefit $v_{ij}$ to buyer $i$. We distinguish between unrelated and related\nvaluations. In the former case, the benefit $v_{ij}$ is completely arbitrary,\nwhile, in the latter, each item $j$ has a quality $q_j$, each buyer $i$ has a\nvalue $v_i$ and the benefit $v_{ij}$ is defined as the product $v_i q_j$. The\nproblem asks to determine a price for each item and an allocation of bundles of\nitems to buyers with the aim of maximizing the total revenue, that is, the sum\nof the prices of all the sold items. The allocation must be envy-free, that is,\neach buyer must be happy with her assigned bundle and cannot improve her\nutility. We first prove that, for related valuations, the problem cannot be\napproximated to a factor $O(m^{1-\\epsilon})$, for any $\\epsilon>0$, unless {\\sf\nP} = {\\sf NP} and that such result is asymptotically tight. In fact we provide\na simple $m$-approximation algorithm even for unrelated valuations. We then\nfocus on an interesting subclass of \"proper\" instances, that do not contain\nbuyers a priori known not being able to receive any item. For such instances,\nwe design an interesting $2$-approximation algorithm and show that no\n$(2-\\epsilon)$-approximation is possible for any $0<\\epsilon\\leq 1$, unless\n{\\sf P} $=$ {\\sf NP}. We observe that it is possible to efficiently check if an\ninstance is proper, and if discarding useless buyers is allowed, an instance\ncan be made proper in polynomial time, without worsening the value of its\noptimal solution.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2013 18:03:38 GMT"}], "update_date": "2013-12-16", "authors_parsed": [["Bil\u00f2", "Vittorio", ""], ["Flammini", "Michele", ""], ["Monaco", "Gianpiero", ""]]}, {"id": "1312.4075", "submitter": "Ebrahim Nasrabadi", "authors": "Ebrahim Nasrabadi, James B. Orlin", "title": "Robust optimization with incremental recourse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider an adaptive approach to address optimization\nproblems with uncertain cost parameters. Here, the decision maker selects an\ninitial decision, observes the realization of the uncertain cost parameters,\nand then is permitted to modify the initial decision. We treat the uncertainty\nusing the framework of robust optimization in which uncertain parameters lie\nwithin a given set. The decision maker optimizes so as to develop the best cost\nguarantee in terms of the worst-case analysis. The recourse decision is\n``incremental\"; that is, the decision maker is permitted to change the initial\nsolution by a small fixed amount. We refer to the resulting problem as the\nrobust incremental problem. We study robust incremental variants of several\noptimization problems. We show that the robust incremental counterpart of a\nlinear program is itself a linear program if the uncertainty set is polyhedral.\nHence, it is solvable in polynomial time. We establish the NP-hardness for\nrobust incremental linear programming for the case of a discrete uncertainty\nset. We show that the robust incremental shortest path problem is NP-complete\nwhen costs are chosen from a polyhedral uncertainty set, even in the case that\nonly one new arc may be added to the initial path. We also address the\ncomplexity of several special cases of the robust incremental shortest path\nproblem and the robust incremental minimum spanning tree problem.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2013 18:14:09 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Nasrabadi", "Ebrahim", ""], ["Orlin", "James B.", ""]]}, {"id": "1312.4125", "submitter": "Sudeepa Roy", "authors": "Paul Beame, Jerry Li, Sudeepa Roy, Dan Suciu", "title": "Model Counting of Query Expressions: Limitations of Propositional\n  Methods", "comments": "To appear in International Conference on Database Theory (ICDT) 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query evaluation in tuple-independent probabilistic databases is the problem\nof computing the probability of an answer to a query given independent\nprobabilities of the individual tuples in a database instance. There are two\nmain approaches to this problem: (1) in `grounded inference' one first obtains\nthe lineage for the query and database instance as a Boolean formula, then\nperforms weighted model counting on the lineage (i.e., computes the probability\nof the lineage given probabilities of its independent Boolean variables); (2)\nin methods known as `lifted inference' or `extensional query evaluation', one\nexploits the high-level structure of the query as a first-order formula.\nAlthough it is widely believed that lifted inference is strictly more powerful\nthan grounded inference on the lineage alone, no formal separation has\npreviously been shown for query evaluation. In this paper we show such a formal\nseparation for the first time.\n  We exhibit a class of queries for which model counting can be done in\npolynomial time using extensional query evaluation, whereas the algorithms used\nin state-of-the-art exact model counters on their lineages provably require\nexponential time. Our lower bounds on the running times of these exact model\ncounters follow from new exponential size lower bounds on the kinds of d-DNNF\nrepresentations of the lineages that these model counters (either explicitly or\nimplicitly) produce. Though some of these queries have been studied before, no\nnon-trivial lower bounds on the sizes of these representations for these\nqueries were previously known.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2013 09:06:32 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Beame", "Paul", ""], ["Li", "Jerry", ""], ["Roy", "Sudeepa", ""], ["Suciu", "Dan", ""]]}, {"id": "1312.4287", "submitter": "Guido Governatori", "authors": "Guido Governatori, Francesco Olivieri, Simone Scannapieco, Antonino\n  Rotolo, Matteo Cristani", "title": "Strategic Argumentation is NP-Complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the complexity of strategic argumentation for dialogue\ngames. A dialogue game is a 2-player game where the parties play arguments. We\nshow how to model dialogue games in a skeptical, non-monotonic formalism, and\nwe show that the problem of deciding what move (set of rules) to play at each\nturn is an NP-complete problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 10:09:06 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Governatori", "Guido", ""], ["Olivieri", "Francesco", ""], ["Scannapieco", "Simone", ""], ["Rotolo", "Antonino", ""], ["Cristani", "Matteo", ""]]}, {"id": "1312.4414", "submitter": "Sergey Verlan", "authors": "Sergiu Ivanov, Elisabeth Pelz, Sergey Verlan", "title": "Small Universal Petri Nets with Inhibitor Arcs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of construction of small-size universal Petri nets\nwith inhibitor arcs. We consider four descriptional complexity parameters: the\nnumber of places, transitions, inhibitor arcs, and the maximal degree of a\ntransition, each of which we try to minimize.\n  We give six constructions having the following values of parameters (listed\nin the above order): $(30,34,13,3)$, $(14, 31, 51, 8)$, $(11, 31, 79, 11)$,\n$(21,25,13,5)$, $(67, 64, 8, 3)$, $(58, 55, 8, 5)$ that improve the few known\nresults on this topic. Our investigation also highlights several interesting\ntrade-offs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 15:56:38 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Ivanov", "Sergiu", ""], ["Pelz", "Elisabeth", ""], ["Verlan", "Sergey", ""]]}, {"id": "1312.4428", "submitter": "Laszlo Egri", "authors": "Laszlo Egri", "title": "On Constraint Satisfaction Problems below P", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetric Datalog, a fragment of the logic programming language Datalog, is\nconjectured to capture all constraint satisfaction problems (CSP) in L.\nTherefore developing tools that help us understand whether or not a CSP can be\ndefined in symmetric Datalog is an important task. It is widely known that a\nCSP is definable in Datalog and linear Datalog if and only if that CSP has\nbounded treewidth and bounded pathwidth duality, respectively. In the case of\nsymmetric Datalog, Bulatov, Krokhin and Larose ask for such a duality (2008).\nWe provide two such dualities, and give applications. In particular, we give a\nshort and simple new proof of the result of Dalmau and Larose that \"Maltsev +\nDatalog -> symmetric Datalog\" (2008).\n  In the second part of the paper, we provide some evidence for the conjecture\nof Dalmau (2002) that every CSP in NL is definable in linear Datalog. Our\nresults also show that a wide class of CSPs-CSPs which do not have bounded\npathwidth duality (e.g., the P-complete Horn-3Sat problem)-cannot be defined by\nany polynomial size family of monotone read-once nondeterministic branching\nprograms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 16:59:49 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2013 15:02:02 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Egri", "Laszlo", ""]]}, {"id": "1312.4510", "submitter": "Pascal Weil", "authors": "Fr\\'ed\\'erique Bassino (LIPN), Cyril Nicaud (LIGM), Pascal Weil\n  (LaBRI)", "title": "On the genericity of Whitehead minimality", "comments": null, "journal-ref": "Journal of Group Theory 19 (2016) 137-159", "doi": "10.1515/jgth-2015-0030", "report-no": null, "categories": "math.GR cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a finitely generated subgroup of a free group, chosen uniformly\nat random, is strictly Whitehead minimal with overwhelming probability.\nWhitehead minimality is one of the key elements of the solution of the orbit\nproblem in free groups. The proofs strongly rely on combinatorial tools,\nnotably those of analytic combinatorics. The result we prove actually depends\nimplicitly on the choice of a distribution on finitely generated subgroups, and\nwe establish it for the two distributions which appear in the literature on\nrandom subgroups.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 20:34:06 GMT"}, {"version": "v2", "created": "Thu, 6 Mar 2014 08:48:49 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Bassino", "Fr\u00e9d\u00e9rique", "", "LIPN"], ["Nicaud", "Cyril", "", "LIGM"], ["Weil", "Pascal", "", "LaBRI"]]}, {"id": "1312.4524", "submitter": "Konrad W. Schwerdtfeger", "authors": "Konrad W. Schwerdtfeger", "title": "A Computational Trichotomy for Connectivity of Boolean Satisfiability", "comments": "27 pages; severe error in the proof of Lemma 19 (now Lemma 23)\n  corrected; all results remain true, but some new definitions and lemmas were\n  necessary; also, a further error of Gopalan et al.'s paper is explained and\n  corrected; several other improvements. Text overlap with arXiv:cs/0609072 due\n  to corrections of that paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For Boolean satisfiability problems, the structure of the solution space is\ncharacterized by the solution graph, where the vertices are the solutions, and\ntwo solutions are connected iff they differ in exactly one variable. In 2006,\nGopalan et al. studied connectivity properties of the solution graph and\nrelated complexity issues for CSPs, motivated mainly by research on\nsatisfiability algorithms and the satisfiability threshold. They proved\ndichotomies for the diameter of connected components and for the complexity of\nthe st-connectivity question, and conjectured a trichotomy for the connectivity\nquestion.\n  Building on this work, we here prove the trichotomy: Connectivity is either\nin P, coNP-complete, or PSPACE-complete. Also, we correct a minor mistake of\nGopalan et al., which leads to a slight shift of the boundaries towards the\nhard side.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 20:59:09 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2013 22:41:37 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2013 20:52:49 GMT"}, {"version": "v4", "created": "Mon, 30 Dec 2013 20:59:36 GMT"}, {"version": "v5", "created": "Mon, 20 Jul 2015 19:59:30 GMT"}, {"version": "v6", "created": "Sun, 25 Oct 2015 11:19:38 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Schwerdtfeger", "Konrad W.", ""]]}, {"id": "1312.4628", "submitter": "Victor Alvarez", "authors": "Victor Alvarez, Karl Bringmann, Radu Curticapean, Saurabh Ray", "title": "Counting Triangulations and other Crossing-free Structures via Onion\n  Layers", "comments": "33 pages, 10 figures, 9 tables. A preliminary version appeared at\n  SoCG 2012. This version contains experimental results comparing algorithms\n  for counting triangulations. This paper has been submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of $n$ points in the plane. A crossing-free structure on $P$\nis a plane graph with vertex set $P$. Examples of crossing-free structures\ninclude triangulations of $P$, spanning cycles of $P$, also known as\npolygonalizations of $P$, among others. In this paper we develop a general\ntechnique for computing the number of crossing-free structures of an input set\n$P$. We apply the technique to obtain algorithms for computing the number of\ntriangulations, matchings, and spanning cycles of $P$. The running time of our\nalgorithms is upper bounded by $n^{O(k)}$, where $k$ is the number of onion\nlayers of $P$. In particular, for $k = O(1)$ our algorithms run in polynomial\ntime. In addition, we show that our algorithm for counting triangulations is\nnever slower than $O^{*}(3.1414^{n})$, even when $k = \\Theta(n)$. Given that\nthere are several well-studied configurations of points with at least\n$\\Omega(3.464^{n})$ triangulations, and some even with $\\Omega(8^{n})$\ntriangulations, our algorithm asymptotically outperforms any enumeration\nalgorithm for such instances. In fact, it is widely believed that any set of\n$n$ points must have at least $\\Omega(3.464^{n})$ triangulations. If this is\ntrue, then our algorithm is strictly sub-linear in the number of triangulations\ncounted. We also show that our techniques are general enough to solve the\n\"Restricted-Triangulation-Counting-Problem\", which we prove to be $W[2]$-hard\nin the parameter $k$. This implies a \"no free lunch\" result: In order to be\nfixed-parameter tractable, our general algorithm must rely on additional\nproperties that are specific to the considered class of structures.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 03:41:41 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Alvarez", "Victor", ""], ["Bringmann", "Karl", ""], ["Curticapean", "Radu", ""], ["Ray", "Saurabh", ""]]}, {"id": "1312.4652", "submitter": "Vladimir Naidenko G.", "authors": "Vladimir Naidenko (Institute of Mathematics, National Academy of\n  Sciences of Belarus)", "title": "Logics for complexity classes", "comments": "This article has been accepted for publication in Logic Journal of\n  IGPL Published by Oxford University Press; 23 pages, 2 figures", "journal-ref": "Logic Journal of the IGPL (2014) 22 (6): 1075-1093", "doi": "10.1093/jigpal/jzu027", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new syntactic characterization of problems complete via Turing reductions\nis presented. General canonical forms are developed in order to define such\nproblems. One of these forms allows us to define complete problems on ordered\nstructures, and another form to define them on unordered non-Aristotelian\nstructures. Using the canonical forms, logics are developed for complete\nproblems in various complexity classes. Evidence is shown that there cannot be\nany complete problem on Aristotelian structures for several complexity classes.\nOur approach is extended beyond complete problems. Using a similar form, a\nlogic is developed to capture the complexity class $NP\\cap coNP$ which very\nlikely contains no complete problem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 05:54:04 GMT"}, {"version": "v2", "created": "Mon, 29 Sep 2014 10:01:02 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Naidenko", "Vladimir", "", "Institute of Mathematics, National Academy of\n  Sciences of Belarus"]]}, {"id": "1312.4673", "submitter": "Harumichi Nishimura", "authors": "Hirotada Kobayashi and Fran\\c{c}ois Le Gall and Harumichi Nishimura", "title": "Generalized Quantum Arthur-Merlin Games", "comments": "31 pages + cover page, the proof of Lemma 27 (Lemma 24 in v1) is\n  corrected, and a new completeness result is added", "journal-ref": "SIAM Journal on Computing 48(3), pp. 865-902, 2019", "doi": "10.1137/17M1160173", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the role of interaction and coins in public-coin\nquantum interactive proof systems (also called quantum Arthur-Merlin games).\nWhile prior works focused on classical public coins even in the quantum\nsetting, the present work introduces a generalized version of quantum\nArthur-Merlin games where the public coins can be quantum as well: the verifier\ncan send not only random bits, but also halves of EPR pairs. First, it is\nproved that the class of two-turn quantum Arthur-Merlin games with quantum\npublic coins, denoted qq-QAM in this paper, does not change by adding a\nconstant number of turns of classical interactions prior to the communications\nof the qq-QAM proof systems. This can be viewed as a quantum analogue of the\ncelebrated collapse theorem for AM due to Babai. To prove this collapse\ntheorem, this paper provides a natural complete problem for qq-QAM: deciding\nwhether the output of a given quantum circuit is close to a totally mixed\nstate. This complete problem is on the very line of the previous studies\ninvestigating the hardness of checking the properties related to quantum\ncircuits, and is of independent interest. It is further proved that the class\nqq-QAM_1 of two-turn quantum-public-coin quantum Arthur-Merlin proof systems\nwith perfect completeness gives new bounds for standard well-studied classes of\ntwo-turn interactive proof systems. Finally, the collapse theorem above is\nextended to comprehensively classify the role of interaction and public coins\nin quantum Arthur-Merlin games: it is proved that, for any constant m>1, the\nclass of problems having an m-turn quantum Arthur-Merlin proof system is either\nequal to PSPACE or equal to the class of problems having a two-turn quantum\nArthur-Merlin game of a specific type, which provides a complete set of quantum\nanalogues of Babai's collapse theorem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 07:33:33 GMT"}, {"version": "v2", "created": "Tue, 16 Sep 2014 04:18:47 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Kobayashi", "Hirotada", ""], ["Gall", "Fran\u00e7ois Le", ""], ["Nishimura", "Harumichi", ""]]}, {"id": "1312.4758", "submitter": "Andris Ambainis", "authors": "Andris Ambainis", "title": "On physical problems that are slightly more difficult than QMA", "comments": "25 pages, v2 various small changes, to appear in CCC'2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of computational problems from quantum physics.\nTypically, they are studied using the complexity class QMA (quantum counterpart\nof NP) but some natural computational problems appear to be slightly harder\nthan QMA. We introduce new complexity classes consisting of problems that are\nsolvable with a small number of queries to a QMA oracle and use these\ncomplexity classes to quantify the complexity of several natural computational\nproblems (for example, the complexity of estimating the spectral gap of a\nHamiltonian).\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 12:59:50 GMT"}, {"version": "v2", "created": "Thu, 10 Apr 2014 15:41:03 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Ambainis", "Andris", ""]]}, {"id": "1312.5280", "submitter": "Nicolas Gastineau", "authors": "Nicolas Gastineau", "title": "Dichotomies properties on computational complexity of S-packing coloring\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work establishes the complexity class of several instances of the\nS-packing coloring problem: for a graph G, a positive integer k and a non\ndecreasing list of integers S = (s\\_1 , ..., s\\_k ), G is S-colorable, if its\nvertices can be partitioned into sets S\\_i , i = 1,... , k, where each S\\_i\nbeing a s\\_i -packing (a set of vertices at pairwise distance greater than\ns\\_i). For a list of three integers, a dichotomy between NP-complete problems\nand polynomial time solvable problems is determined for subcubic graphs.\nMoreover, for an unfixed size of list, the complexity of the S-packing coloring\nproblem is determined for several instances of the problem. These properties\nare used in order to prove a dichotomy between NP-complete problems and\npolynomial time solvable problems for lists of at most four integers.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2013 19:28:43 GMT"}, {"version": "v2", "created": "Fri, 18 Jul 2014 08:10:59 GMT"}, {"version": "v3", "created": "Thu, 29 Jan 2015 19:34:17 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Gastineau", "Nicolas", ""]]}, {"id": "1312.5686", "submitter": "Sylvain Schmitz", "authors": "Sylvain Schmitz", "title": "Complexity Hierarchies Beyond Elementary", "comments": "Version 3 is the published version in TOCT 8(1:3), 2016. I will keep\n  updating the catalogue of problems from Section 6 in future revisions", "journal-ref": "ACM Transactions on Computation Theory vol. 8, number 1, article\n  3, 2016", "doi": "10.1145/2858784", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hierarchy of fast-growing complexity classes and show its\nsuitability for completeness statements of many non elementary problems. This\nhierarchy allows the classification of many decision problems with a\nnon-elementary complexity, which occur naturally in logic, combinatorics,\nformal languages, verification, etc., with complexities ranging from simple\ntowers of exponentials to Ackermannian and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 18:30:18 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2013 22:45:45 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2016 10:57:51 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Schmitz", "Sylvain", ""]]}, {"id": "1312.5937", "submitter": "Oleg Verbitsky", "authors": "Albert Atserias, Anuj Dawar, Oleg Verbitsky", "title": "On the dynamic width of the 3-colorability problem", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph $G$ is 3-colorable if and only if it maps homomorphically to the\ncomplete 3-vertex graph $K_3$. The last condition can be checked by a\n$k$-consistency algorithm where the parameter $k$ has to be chosen large\nenough, dependent on $G$. Let $W(G)$ denote the minimum $k$ sufficient for this\npurpose. For a non-3-colorable graph $G$, $W(G)$ is equal to the minimum $k$\nsuch that $G$ can be distinguished from $K_3$ in the $k$-variable\nexistential-positive first-order logic. We define the dynamic width of the\n3-colorability problem as the function $W(n)=\\max_G W(G)$, where the maximum is\ntaken over all non-3-colorable $G$ with $n$ vertices.\n  The assumption $\\mathrm{NP}\\ne\\mathrm{P}$ implies that $W(n)$ is unbounded.\nIndeed, a lower bound $W(n)=\\Omega(\\log\\log n/\\log\\log\\log n)$ follows\nunconditionally from the work of Nesetril and Zhu on bounded treewidth duality.\nThe Exponential Time Hypothesis implies a much stronger bound\n$W(n)=\\Omega(n/\\log n)$ and indeed we unconditionally prove that\n$W(n)=\\Omega(n)$. In fact, an even stronger statement is true: A first-order\nsentence distinguishing any 3-colorable graph on $n$ vertices from any\nnon-3-colorable graph on $n$ vertices must have $\\Omega(n)$ variables.\n  On the other hand, we observe that $W(G)\\le 3\\,\\alpha(G)+1$ and $W(G)\\le\nn-\\alpha(G)+1$ for every non-3-colorable graph $G$ with $n$ vertices, where\n$\\alpha(G)$ denotes the independence number of $G$. This implies that\n$W(n)\\le\\frac34\\,n+1$, improving on the trivial upper bound $W(n)\\le n$.\n  We also show that $W(G)>\\frac1{16}\\, g(G)$ for every non-3-colorable graph\n$G$, where $g(G)$ denotes the girth of $G$.\n  Finally, we consider the function $W(n)$ over planar graphs and prove that\n$W(n)=\\Theta(\\sqrt n)$ in the case.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 13:42:06 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2014 15:15:19 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Atserias", "Albert", ""], ["Dawar", "Anuj", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "1312.5972", "submitter": "Yu Hin Au", "authors": "Yu Hin Au and Levent Tun\\c{c}el", "title": "A Comprehensive Analysis of Polyhedral Lift-and-Project Methods", "comments": null, "journal-ref": "SIAM Journal on Discrete Mathematics 30(1) (2016), 411-451", "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider lift-and-project methods for combinatorial optimization problems\nand focus mostly on those lift-and-project methods which generate polyhedral\nrelaxations of the convex hull of integer solutions. We introduce many new\nvariants of Sherali--Adams and Bienstock--Zuckerberg operators. These new\noperators fill the spectrum of polyhedral lift-and-project operators in a way\nwhich makes all of them more transparent, easier to relate to each other, and\neasier to analyze. We provide new techniques to analyze the worst-case\nperformances as well as relative strengths of these operators in a unified way.\nIn particular, using the new techniques and a result of Mathieu and Sinclair\nfrom 2009, we prove that the polyhedral Bienstock--Zuckerberg operator requires\nat least $\\sqrt{2n}- \\frac{3}{2}$ iterations to compute the matching polytope\nof the $(2n+1)$-clique. We further prove that the operator requires\napproximately $\\frac{n}{2}$ iterations to reach the stable set polytope of the\n$n$-clique, if we start with the fractional stable set polytope. Lastly, we\nshow that some of the worst-case instances for the positive semidefinite\nLov\\'asz--Schrijver lift-and-project operator are also bad instances for the\nstrongest variants of the Sherali--Adams operator with positive semidefinite\nstrengthenings, and discuss some consequences for integrality gaps of convex\nrelaxations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 14:55:01 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2015 14:27:02 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2016 12:23:44 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Au", "Yu Hin", ""], ["Tun\u00e7el", "Levent", ""]]}, {"id": "1312.5978", "submitter": "Mrinal Kumar", "authors": "Mrinal Kumar and Shubhangi Saraf", "title": "Superpolynomial lower bounds for general homogeneous depth 4 arithmetic\n  circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove superpolynomial lower bounds for the class of\nhomogeneous depth 4 arithmetic circuits. We give an explicit polynomial in VNP\nof degree $n$ in $n^2$ variables such that any homogeneous depth 4 arithmetic\ncircuit computing it must have size $n^{\\Omega(\\log \\log n)}$.\n  Our results extend the works of Nisan-Wigderson [NW95] (which showed\nsuperpolynomial lower bounds for homogeneous depth 3 circuits),\nGupta-Kamath-Kayal-Saptharishi and Kayal-Saha-Saptharishi [GKKS13, KSS13]\n(which showed superpolynomial lower bounds for homogeneous depth 4 circuits\nwith bounded bottom fan-in), Kumar-Saraf [KS13a] (which showed superpolynomial\nlower bounds for homogeneous depth 4 circuits with bounded top fan-in) and\nRaz-Yehudayoff and Fournier-Limaye-Malod-Srinivasan [RY08, FLMS13] (which\nshowed superpolynomial lower bounds for multilinear depth 4 circuits). Several\nof these results in fact showed exponential lower bounds.\n  The main ingredient in our proof is a new complexity measure of {\\it bounded\nsupport} shifted partial derivatives. This measure allows us to prove\nexponential lower bounds for homogeneous depth 4 circuits where all the\nmonomials computed at the bottom layer have {\\it bounded support} (but possibly\nunbounded degree/fan-in), strengthening the results of Gupta et al and Kayal et\nal [GKKS13, KSS13]. This new lower bound combined with a careful \"random\nrestriction\" procedure (that transforms general depth 4 homogeneous circuits to\ndepth 4 circuits with bounded support) gives us our final result.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 15:03:16 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Kumar", "Mrinal", ""], ["Saraf", "Shubhangi", ""]]}, {"id": "1312.6242", "submitter": "Iddo Tzameret", "authors": "Fu Li and Iddo Tzameret", "title": "Generating Matrix Identities and Proof Complexity", "comments": "46 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the fundamental lower bounds questions in proof complexity, we\ninitiate the study of matrix identities as hard instances for strong proof\nsystems. A matrix identity of $d \\times d$ matrices over a field $\\mathbb{F}$,\nis a non-commutative polynomial $f(x_1,\\ldots,x_n)$ over $\\mathbb{F}$ such that\n$f$ vanishes on every $d \\times d$ matrix assignment to its variables.\n  We focus on arithmetic proofs, which are proofs of polynomial identities\noperating with arithmetic circuits and whose axioms are the polynomial-ring\naxioms (these proofs serve as an algebraic analogue of the Extended Frege\npropositional proof system; and over $GF(2)$ they constitute formally a\nsub-system of Extended Frege [HT12]). We introduce a decreasing in strength\nhierarchy of proof systems within arithmetic proofs, in which the $d$th level\nis a sound and complete proof system for proving $d \\times d$ matrix identities\n(over a given field). For each level $d>2$ in the hierarchy, we establish a\nproof-size lower bound in terms of the number of variables in the matrix\nidentity proved: we show the existence of a family of matrix identities $f_n$\nwith $n$ variables, such that any proof of $f_n=0$ requires $\\Omega(n^{2d})$\nnumber of lines. The lower bound argument uses fundamental results from the\ntheory of algebras with polynomial identities together with a generalization of\nthe arguments in [Hru11].\n  We then set out to study matrix identities as hard instances for (full)\narithmetic proofs. We present two conjectures, one about non-commutative\narithmetic circuit complexity and the other about proof complexity, under which\nup to exponential-size lower bounds on arithmetic proofs (in terms of the\narithmetic circuit size of the identities proved) hold. Finally, we discuss the\napplicability of our approach to strong propositional proof systems such as\nExtended Frege.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 11:32:41 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2014 19:16:49 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2014 19:31:10 GMT"}, {"version": "v4", "created": "Wed, 3 Sep 2014 10:44:20 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["Li", "Fu", ""], ["Tzameret", "Iddo", ""]]}, {"id": "1312.6547", "submitter": "J. Maurice Rojas", "authors": "Eleanor Anthony, Sheridan Grant, Peter Gritzmann, and J. Maurice Rojas", "title": "Polynomial-Time Amoeba Neighborhood Membership and Faster Localized\n  Solving", "comments": "15 pages, 9 figures. Submitted to a conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive efficient algorithms for coarse approximation of algebraic\nhypersurfaces, useful for estimating the distance between an input polynomial\nzero set and a given query point. Our methods work best on sparse polynomials\nof high degree (in any number of variables) but are nevertheless completely\ngeneral. The underlying ideas, which we take the time to describe in an\nelementary way, come from tropical geometry. We thus reduce a hard algebraic\nproblem to high-precision linear optimization, proving new upper and lower\ncomplexity estimates along the way.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 13:48:01 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Anthony", "Eleanor", ""], ["Grant", "Sheridan", ""], ["Gritzmann", "Peter", ""], ["Rojas", "J. Maurice", ""]]}, {"id": "1312.6582", "submitter": "Saugata Basu", "authors": "Saugata Basu and Cordian Riener", "title": "Bounding the equivariant Betti numbers of symmetric semi-algebraic sets", "comments": "Minor changes. Final version to appear in Advances in Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathrm{R}$ be a real closed field. The problem of obtaining tight\nbounds on the Betti numbers of semi-algebraic subsets of $\\mathrm{R}^k$ in\nterms of the number and degrees of the defining polynomials has been an\nimportant problem in real algebraic geometry with the first results due to\nOle{\\u\\i}nik and Petrovski{\\u\\i}, Thom and Milnor. These bounds are all\nexponential in the number of variables $k$. Motivated by several applications\nin real algebraic geometry, as well as in theoretical computer science, where\nsuch bounds have found applications, we consider in this paper the problem of\nbounding the equivariant Betti numbers of symmetric algebraic and\nsemi-algebraic subsets of $\\mathrm{R}^k$. We obtain several asymptotically\ntight upper bounds. In particular, we prove that if $S\\subset \\mathrm{R}^k$ is\na semi-algebraic subset defined by a finite set of $s$ symmetric polynomials of\ndegree at most $d$, then the sum of the $\\mathfrak{S}_k$-equivariant Betti\nnumbers of $S$ with coefficients in $\\mathbb{Q}$ is bounded by $(skd)^{O(d)}$.\nUnlike the classical bounds on the ordinary Betti numbers of real algebraic\nvarieties and semi-algebraic sets, the above bound is polynomial in $k$ when\nthe degrees of the defining polynomials are bounded by a constant. As an\napplication we improve the best known bound on the ordinary Betti numbers of\nthe projection of a compact algebraic set improving for any fixed degree the\nbest previously known bound for this problem due to Gabrielov, Vorobjov and\nZell.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 15:50:09 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2014 08:02:49 GMT"}, {"version": "v3", "created": "Sun, 24 Aug 2014 20:11:33 GMT"}, {"version": "v4", "created": "Thu, 4 Sep 2014 21:39:16 GMT"}, {"version": "v5", "created": "Fri, 19 Aug 2016 14:37:05 GMT"}, {"version": "v6", "created": "Wed, 5 Oct 2016 13:44:11 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Basu", "Saugata", ""], ["Riener", "Cordian", ""]]}, {"id": "1312.6668", "submitter": "Pierre-\\'Etienne Meunier", "authors": "Pierre-\\'Etienne Meunier, Damien Regnault", "title": "A pumping lemma for non-cooperative self-assembly", "comments": "Major rewriting: explicit pumping algorithm (+online program), and\n  bug fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the computational weakness of a model of tile assembly that has so\nfar resisted many attempts of formal analysis or positive constructions.\nSpecifically, we prove that, in Winfree's abstract Tile Assembly Model, when\nrestricted to use only noncooperative bindings, any long enough path that can\ngrow in all terminal assemblies is pumpable, meaning that this path can be\nextended into an infinite, ultimately periodic path.\n  This result can be seen as a geometric generalization of the pumping lemma of\nfinite state automata, and closes the question of what can be computed\ndeterministically in this model. Moreover, this question has motivated the\ndevelopment of a new method called visible glues. We believe that this method\ncan also be used to tackle other long-standing problems in computational\ngeometry, in relation for instance with self-avoiding paths.\n  Tile assembly (including non-cooperative tile assembly) was originally\nintroduced by Winfree and Rothemund in STOC 2000 to understand how to program\nshapes. The non-cooperative variant, also known as temperature 1 tile assembly,\nis the model where tiles are allowed to bind as soon as they match on one side,\nwhereas in cooperative tile assembly, some tiles need to match on several sides\nin order to bind. In this work, we prove that only very simple shapes can\nindeed be programmed, whereas exactly one known result (SODA 2014) showed a\nrestriction on the assemblies general non-cooperative self-assembly could\nachieve, without any implication on its computational expressiveness. With\nnon-square tiles (like polyominos, SODA 2015), other recent works have shown\nthat the model quickly becomes computationally powerful.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 20:42:04 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2014 20:50:07 GMT"}, {"version": "v3", "created": "Fri, 22 Aug 2014 11:30:17 GMT"}, {"version": "v4", "created": "Thu, 30 Jul 2015 14:35:27 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Meunier", "Pierre-\u00c9tienne", ""], ["Regnault", "Damien", ""]]}, {"id": "1312.6679", "submitter": "Konrad W. Schwerdtfeger", "authors": "Konrad W. Schwerdtfeger", "title": "The Connectivity of Boolean Satisfiability: Dichotomies for Formulas and\n  Circuits", "comments": "20 pages, several improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For Boolean satisfiability problems, the structure of the solution space is\ncharacterized by the solution graph, where the vertices are the solutions, and\ntwo solutions are connected iff they differ in exactly one variable. In 2006,\nGopalan et al. studied connectivity properties of the solution graph and\nrelated complexity issues for CSPs, motivated mainly by research on\nsatisfiability algorithms and the satisfiability threshold. They proved\ndichotomies for the diameter of connected components and for the complexity of\nthe st-connectivity question, and conjectured a trichotomy for the connectivity\nquestion. Recently, we were able to establish the trichotomy [arXiv:1312.4524].\n  Here, we consider connectivity issues of satisfiability problems defined by\nBoolean circuits and propositional formulas that use gates, resp. connectives,\nfrom a fixed set of Boolean functions. We obtain dichotomies for the diameter\nand the two connectivity problems: on one side, the diameter is linear in the\nnumber of variables, and both problems are in P, while on the other side, the\ndiameter can be exponential, and the problems are PSPACE-complete. For\npartially quantified formulas, we show an analogous dichotomy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 20:59:20 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2013 20:55:08 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2015 11:20:26 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Schwerdtfeger", "Konrad W.", ""]]}, {"id": "1312.6680", "submitter": "Ryan Williams", "authors": "Ryan Williams", "title": "Faster all-pairs shortest paths via circuit complexity", "comments": "24 pages. Updated version now has slightly faster running time. To\n  appear in ACM Symposium on Theory of Computing (STOC), 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a new randomized method for computing the min-plus product\n(a.k.a., tropical product) of two $n \\times n$ matrices, yielding a faster\nalgorithm for solving the all-pairs shortest path problem (APSP) in dense\n$n$-node directed graphs with arbitrary edge weights. On the real RAM, where\nadditions and comparisons of reals are unit cost (but all other operations have\ntypical logarithmic cost), the algorithm runs in time\n\\[\\frac{n^3}{2^{\\Omega(\\log n)^{1/2}}}\\] and is correct with high probability.\nOn the word RAM, the algorithm runs in $n^3/2^{\\Omega(\\log n)^{1/2}} +\nn^{2+o(1)}\\log M$ time for edge weights in $([0,M] \\cap {\\mathbb\nZ})\\cup\\{\\infty\\}$. Prior algorithms used either $n^3/(\\log^c n)$ time for\nvarious $c \\leq 2$, or $O(M^{\\alpha}n^{\\beta})$ time for various $\\alpha > 0$\nand $\\beta > 2$.\n  The new algorithm applies a tool from circuit complexity, namely the\nRazborov-Smolensky polynomials for approximately representing ${\\sf AC}^0[p]$\ncircuits, to efficiently reduce a matrix product over the $(\\min,+)$ algebra to\na relatively small number of rectangular matrix products over ${\\mathbb F}_2$,\neach of which are computable using a particularly efficient method due to\nCoppersmith. We also give a deterministic version of the algorithm running in\n$n^3/2^{\\log^{\\delta} n}$ time for some $\\delta > 0$, which utilizes the\nYao-Beigel-Tarui translation of ${\\sf AC}^0[m]$ circuits into \"nice\" depth-two\ncircuits.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 20:59:43 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 01:13:37 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Williams", "Ryan", ""]]}, {"id": "1312.7042", "submitter": "S Kapoor", "authors": "Sanjiv Kapoor and Hemanshu Kaul", "title": "Approximating Quadratic 0-1 Programming via SOCP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximating Quadratic O-1 Integer Programs with\nbounded number of constraints and non-negative constraint matrix entries, which\nwe term as PIQP.\n  We describe and analyze a randomized algorithm based on a program with\nhyperbolic constraints (a Second-Order Cone Programming -SOCP- formulation)\nthat achieves an approximation ratio of $O(a_{max} \\frac{n}{\\beta(n)})$, where\n$a_{max}$ is the maximum size of an entry in the constraint matrix and\n$\\beta(n) \\leq \\min_i{W_i} $, where $W_i$ are the constant terms that define\nthe constraint inequalities. We note that by appropriately choosing $\\beta(n)$\nthe randomized algorithm, when combined with other algorithms that achieve good\napproximations for smaller values of $ W_i$, allows better algorithms for the\ncomplete range of $W_i$. This, together with a greedy algorithm, provides a\n$O^*(a_{max} n^{1/2} )$ factor approximation, where $O^*$ hides logarithmic\nterms. Our solution is achieved by a randomization of the optimal solution to\nthe relaxed version of the hyperbolic program. We show that this solution\nprovides the approximation bounds using concentration bounds provided by\nChernoff-Hoeffding and Kim-Vu.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2013 02:31:45 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Kapoor", "Sanjiv", ""], ["Kaul", "Hemanshu", ""]]}, {"id": "1312.7222", "submitter": "Yixin Xu", "authors": "Well Y. Chiu, Mario Szegedy, Chengu Wang, Yixin Xu", "title": "The Garden Hose Complexity for the Equality Function", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The garden hose complexity is a new communication complexity introduced by H.\nBuhrman, S. Fehr, C. Schaffner and F. Speelman [BFSS13] to analyze\nposition-based cryptography protocols in the quantum setting. We focus on the\ngarden hose complexity of the equality function, and improve on the bounds of\nO. Margalit and A. Matsliah[MM12] with the help of a new approach and of our\nhandmade simulated annealing based solver. We have also found beautiful\nsymmetries of the solutions that have lead us to develop the notion of garden\nhose permutation groups. Then, exploiting this new concept, we get even\nfurther, although several interesting open problems remain.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 09:33:06 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2013 08:41:42 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Chiu", "Well Y.", ""], ["Szegedy", "Mario", ""], ["Wang", "Chengu", ""], ["Xu", "Yixin", ""]]}, {"id": "1312.7284", "submitter": "Naohi Eguchi", "authors": "Martin Avanzini and Naohi Eguchi", "title": "A New Term Rewriting Characterisation of ETIME functions", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adopting former term rewriting characterisations of polytime and\nexponential-time computable functions, we introduce a new reduction order, the\nPath Order for ETIME (POE* for short), that is sound and complete for ETIME\ncomputable functions. The proposed reduction order for ETIME makes contrasts to\nthose related complexity classes clear.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 15:38:47 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2013 12:52:51 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Avanzini", "Martin", ""], ["Eguchi", "Naohi", ""]]}, {"id": "1312.7305", "submitter": "Vasco Brattka", "authors": "Vasco Brattka, Guido Gherardi and Rupert H\\\"olzl", "title": "Probabilistic Computability and Choice", "comments": "Information and Computation (accepted for publication)", "journal-ref": "Information and Computation 242 (2015) 249-286", "doi": "10.1016/j.ic.2015.03.005", "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational power of randomized computations on infinite\nobjects, such as real numbers. In particular, we introduce the concept of a Las\nVegas computable multi-valued function, which is a function that can be\ncomputed on a probabilistic Turing machine that receives a random binary\nsequence as auxiliary input. The machine can take advantage of this random\nsequence, but it always has to produce a correct result or to stop the\ncomputation after finite time if the random advice is not successful. With\npositive probability the random advice has to be successful. We characterize\nthe class of Las Vegas computable functions in the Weihrauch lattice with the\nhelp of probabilistic choice principles and Weak Weak K\\H{o}nig's Lemma. Among\nother things we prove an Independent Choice Theorem that implies that Las Vegas\ncomputable functions are closed under composition. In a case study we show that\nNash equilibria are Las Vegas computable, while zeros of continuous functions\nwith sign changes cannot be computed on Las Vegas machines. However, we show\nthat the latter problem admits randomized algorithms with weaker failure\nrecognition mechanisms. The last mentioned results can be interpreted such that\nthe Intermediate Value Theorem is reducible to the jump of Weak Weak\nK\\H{o}nig's Lemma, but not to Weak Weak K\\H{o}nig's Lemma itself. These\nexamples also demonstrate that Las Vegas computable functions form a proper\nsuperclass of the class of computable functions and a proper subclass of the\nclass of non-deterministically computable functions. We also study the impact\nof specific lower bounds on the success probabilities, which leads to a strict\nhierarchy of classes. In particular, the classical technique of probability\namplification fails for computations on infinite objects. We also investigate\nthe dependency on the underlying probability space.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 18:07:46 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2014 16:07:08 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2015 15:37:50 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Brattka", "Vasco", ""], ["Gherardi", "Guido", ""], ["H\u00f6lzl", "Rupert", ""]]}, {"id": "1312.7306", "submitter": "Bhaskar DasGupta", "authors": "Satabdi Aditya, Bhaskar DasGupta, Marek Karpinski", "title": "Algorithmic Perspectives of Network Transitive Reduction Problems and\n  their Applications to Synthesis and Analysis of Biological Networks", "comments": null, "journal-ref": "Biology, 3 (1), 1-21, 2014", "doi": "10.3390/biology3010001", "report-no": null, "categories": "cs.CC cs.DS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey paper, we will present a number of core algorithmic questions\nconcerning several transitive reduction problems on network that have\napplications in network synthesis and analysis involving cellular processes.\nOur starting point will be the so-called minimum equivalent digraph problem, a\nclassic computational problem in combinatorial algorithms. We will subsequently\nconsider a few non-trivial extensions or generalizations of this problem\nmotivated by applications in systems biology. We will then discuss the\napplications of these algorithmic methodologies in the context of three major\nbiological research questions: synthesizing and simplifying signal transduction\nnetworks, analyzing disease networks, and measuring redundancy of biological\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 18:09:40 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Aditya", "Satabdi", ""], ["DasGupta", "Bhaskar", ""], ["Karpinski", "Marek", ""]]}, {"id": "1312.7468", "submitter": "Nikhil Balaji", "authors": "Nikhil Balaji, Samir Datta", "title": "Tree-width and Logspace: Determinants and Counting Euler Tours", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent result of [EJT10] showing that MSO properties are\nLogspace computable on graphs of bounded tree-width, we consider the complexity\nof computing the determinant of the adjacency matrix of a bounded tree-width\ngraph and prove that it is L-complete. It is important to notice that the\ndeterminant is neither an MSO-property nor counts the number of solutions of an\nMSO-predicate. We extend this technique to count the number of spanning\narborescences and directed Euler tours in bounded tree-width digraphs, and\nfurther to counting the number of spanning trees and the number of Euler tours\nin undirected graphs, all in L. Notice that undirected Euler tours are not\nknown to be MSO-expressible and the corresponding counting problem is in fact\n#P-hard for general graphs. Counting undirected Euler tours in bounded\ntree-width graphs was not known to be polynomial time computable till very\nrecently Chebolu et al [CCM13] gave a polynomial time algorithm for this\nproblem (concurrently and independently of this work). Finally, we also show\nsome linear algebraic extensions of the determinant algorithm to show how to\ncompute the charcteristic polynomial and trace of the powers of a bounded\ntree-width graph in L.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2013 19:59:01 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2013 02:57:24 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Balaji", "Nikhil", ""], ["Datta", "Samir", ""]]}, {"id": "1312.7605", "submitter": "Juraj Stacho", "authors": "Barnaby Martin, Juraj Stacho", "title": "Constraint Satisfaction with Counting Quantifiers 2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study constraint satisfaction problems (CSPs) in the presence of counting\nquantifiers $\\exists^{\\geq j}$, asserting the existence of $j$ distinct\nwitnesses for the variable in question. As a continuation of our previous (CSR\n2012) paper, we focus on the complexity of undirected graph templates. As our\nmain contribution, we settle the two principal open questions proposed in (CSR\n2012). Firstly, we complete the classification of clique templates by proving a\nfull trichotomy for all possible combinations of counting quantifiers and\nclique sizes, placing each case either in P, NP-complete or Pspace-complete.\nThis involves resolution of the cases in which we have the single quantifier\n$\\exists^{\\geq j}$ on the clique $K_{2j}$. Secondly, we confirm a conjecture\nfrom (CSR 2012), which proposes a full dichotomy for $\\exists$ and\n$\\exists^{\\geq 2}$ on all finite undirected graphs. The main thrust of this\nsecond result is the solution of the complexity for the infinite path which we\nprove is a polynomial-time solvable problem. By adapting the algorithm for the\ninfinite path we are then able to solve the problem for finite paths, and then\ntrees and forests. Thus as a corollary to this work, combining with the other\ncases from (CSR 2012), we obtain a full dichotomy for $\\exists$ and\n$\\exists^{\\geq 2}$ quantifiers on finite graphs, each such problem being either\nin P or NP-hard. Finally, we persevere with the work of (CSR 2012) in exploring\ncases in which there is dichotomy between P and Pspace-complete, in contrast\nwith situations in which the intermediate NP-completeness may appear.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 00:06:43 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Martin", "Barnaby", ""], ["Stacho", "Juraj", ""]]}, {"id": "1312.7615", "submitter": "EPTCS", "authors": "Mila Majster-Cederbaum (University Mannheim), Nils Semmelrock\n  (University Mannheim)", "title": "Reachability in Cooperating Systems with Architectural Constraints is\n  PSPACE-Complete", "comments": "In Proceedings GRAPHITE 2013, arXiv:1312.7062", "journal-ref": "EPTCS 138, 2013, pp. 1-11", "doi": "10.4204/EPTCS.138.1", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reachability problem in cooperating systems is known to be\nPSPACE-complete. We show here that this problem remains PSPACE-complete when we\nrestrict the communication structure between the subsystems in various ways.\nFor this purpose we introduce two basic and incomparable subclasses of\ncooperating systems that occur often in practice and provide respective\nreductions. The subclasses we consider consist of cooperating systems the\ncommunication structure of which forms a line respectively a star.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 03:13:09 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Majster-Cederbaum", "Mila", "", "University Mannheim"], ["Semmelrock", "Nils", "", "University Mannheim"]]}]