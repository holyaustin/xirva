[{"id": "1010.0522", "submitter": "Rahul Jain", "authors": "Rahul Jain", "title": "Strong direct product conjecture holds for all relations in public coin\n  randomized one-way communication complexity", "comments": "ver 2. 11 pages, proofs simplified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let f subset of X x Y x Z be a relation. Let the public coin one-way\ncommunication complexity of f, with worst case error 1/3, be denoted\nR^{1,pub}_{1/3}(f). We show that if for computing f^k (k independent copies of\nf), o(k R^{1,pub}_{1/3}(f)) communication is provided, then the success is\nexponentially small in k. This settles the strong direct product conjecture for\nall relations in public coin one-way communication complexity.\n  We show a new tight characterization of public coin one-way communication\ncomplexity which strengthens on the tight characterization shown in [J.,\nKlauck, Nayak 08]. We use the new characterization to show our direct product\nresult and this may also be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 09:57:55 GMT"}, {"version": "v2", "created": "Thu, 14 Oct 2010 14:34:47 GMT"}], "update_date": "2010-10-15", "authors_parsed": [["Jain", "Rahul", ""]]}, {"id": "1010.0846", "submitter": "Rahul Jain", "authors": "Rahul Jain", "title": "A strong direct product theorem for two-way public coin communication\n  complexity", "comments": "ver 2, 12 pages, application to set disjointness added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a direct product result for two-way public coin communication\ncomplexity of all relations in terms of a new complexity measure that we\ndefine. Our new measure is a generalization to non-product distributions of the\ntwo-way product subdistribution bound of [J, Klauck and Nayak 08], thereby our\nresult implying their direct product result in terms of the two-way product\nsubdistribution bound.\n  We show that our new complexity measure gives tight lower bound for the\nset-disjointness problem, as a result we reproduce strong direct product result\nfor this problem, which was previously shown by [Klauck 00].\n", "versions": [{"version": "v1", "created": "Tue, 5 Oct 2010 11:38:19 GMT"}, {"version": "v2", "created": "Fri, 26 Nov 2010 06:30:49 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Jain", "Rahul", ""]]}, {"id": "1010.1101", "submitter": "Alexey Pospelov", "authors": "Alexey Pospelov", "title": "Faster Polynomial Multiplication via Discrete Fourier Transforms", "comments": "26 pages, submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of polynomial multiplication over arbitrary fields.\nWe present a unified approach that generalizes all known asymptotically fastest\nalgorithms for this problem. In particular, the well-known algorithm for\nmultiplication of polynomials over fields supporting DFTs of large smooth\norders, Sch\\\"onhage-Strassen's algorithm over arbitrary fields of\ncharacteristic different from 2, Sch\\\"onhage's algorithm over fields of\ncharacteristic 2, and Cantor-Kaltofen's algorithm over arbitrary algebras---all\nappear to be instances of this approach. We also obtain faster algorithms for\npolynomial multiplication over certain fields which do not support DFTs of\nlarge smooth orders.\n  We prove that the Sch\\\"onhage-Strassen's upper bound cannot be improved\nfurther over the field of rational numbers if we consider only algorithms based\non consecutive applications of DFT, as all known fastest algorithms are. We\nalso explore the ways to transfer the recent F\\\"urer's algorithm for integer\nmultiplication to the problem of polynomial multiplication over arbitrary\nfields of positive characteristic.\n  This work is inspired by the recent improvement for the closely related\nproblem of complexity of integer multiplication by F\\\"urer and its consequent\nmodular arithmetic treatment due to De, Kurur, Saha, and Saptharishi. We\nexplore the barriers in transferring the techniques for solutions of one\nproblem to a solution of the other.\n", "versions": [{"version": "v1", "created": "Wed, 6 Oct 2010 09:29:34 GMT"}], "update_date": "2010-10-07", "authors_parsed": [["Pospelov", "Alexey", ""]]}, {"id": "1010.1128", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Naohi Eguchi and Georg Moser", "title": "A Path Order for Rewrite Systems that Compute Exponential Time Functions\n  (Technical Report)", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper we present a new path order for rewrite systems, the\nexponential path order EPOSTAR. Suppose a term rewrite system is compatible\nwith EPOSTAR, then the runtime complexity of this rewrite system is bounded\nfrom above by an exponential function. Furthermore, the class of function\ncomputed by a rewrite system compatible with EPOSTAR equals the class of\nfunctions computable in exponential time on a Turing maschine.\n", "versions": [{"version": "v1", "created": "Wed, 6 Oct 2010 11:48:44 GMT"}, {"version": "v2", "created": "Mon, 18 Oct 2010 15:07:45 GMT"}, {"version": "v3", "created": "Thu, 9 Jun 2011 07:40:54 GMT"}], "update_date": "2011-06-10", "authors_parsed": [["Avanzini", "Martin", ""], ["Eguchi", "Naohi", ""], ["Moser", "Georg", ""]]}, {"id": "1010.1221", "submitter": "Vicky Choi", "authors": "Vicky Choi", "title": "Different Adiabatic Quantum Optimization Algorithms for the NP-Complete\n  Exact Cover and 3SAT Problems", "comments": "This is the second part of article arXiv:quant-ph/1004.2226.\n  References added", "journal-ref": "Quantum Information and Computation, Vol. 11, No. 7&8 (2011)\n  0638-0648", "doi": "10.1073/pnas.1018310108", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important questions in studying quantum computation is:\nwhether a quantum computer can solve NP-complete problems more efficiently than\na classical computer? In 2000, Farhi, et al. (Science, 292(5516):472--476,\n2001) proposed the adiabatic quantum optimization (AQO), a paradigm that\ndirectly attacks NP-hard optimization problems. How powerful is AQO? Early on,\nvan Dam and Vazirani claimed that AQO failed (i.e. would take exponential time)\nfor a family of 3SAT instances they constructed. More recently, Altshuler, et\nal. (Proc Natl Acad Sci USA, 107(28): 12446--12450, 2010) claimed that AQO\nfailed also for random instances of the NP-complete Exact Cover problem. In\nthis paper, we make clear that all these negative results are only for a\nspecific AQO algorithm. We do so by demonstrating different AQO algorithms for\nthe same problem for which their arguments no longer hold. Whether AQO fails or\nsucceeds for solving the NP-complete problems (either the worst case or the\naverage case) requires further investigation. Our AQO algorithms for Exact\nCover and 3SAT are based on the polynomial reductions to the NP-complete\nMaximum-weight Independent Set (MIS) problem.\n", "versions": [{"version": "v1", "created": "Wed, 6 Oct 2010 18:20:24 GMT"}, {"version": "v2", "created": "Thu, 17 Feb 2011 21:40:33 GMT"}, {"version": "v3", "created": "Tue, 31 May 2011 04:57:04 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Choi", "Vicky", ""]]}, {"id": "1010.1328", "submitter": "Hector Zenil", "authors": "Joost J. Joosten, Fernando Soler-Toscano, Hector Zenil", "title": "Complejidad descriptiva y computacional en maquinas de Turing pequenas", "comments": "Art\\'iculo en espa\\~nol. Actas de las V Jornadas Ib\\'ericas, L\\'ogica\n  Universal e Unidade da Ciencia, CFCUL, 2010. 20 pages, 22 figures, 3 tables;\n  Keywords: small Turing machines, Program-size complexity, Kolmogorov-Chaitin\n  complexity, space-time complexity, computational complexity, algorithmic\n  complexity, geometric complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We start by an introduction to the basic concepts of computability theory and\nthe introduction of the concept of Turing machine and computation universality.\nThen se turn to the exploration of trade-offs between different measures of\ncomplexity, particularly algorithmic (program-size) and computational (time)\ncomplexity as a mean to explain these measure in a novel manner. The\ninvestigation proceeds by an exhaustive exploration and systematic study of the\nfunctions computed by a large set of small Turing machines with 2 and 3 states\nwith particular attention to runtimes, space-usages and patterns corresponding\nto the computed functions when the machines have access to larger resources\n(more states).\n  We report that the average runtime of Turing machines computing a function\nincreases as a function of the number of states, indicating that non-trivial\nmachines tend to occupy all the resources at hand. General slow-down was\nwitnessed and some incidental cases of (linear) speed-up were found. Throughout\nour study various interesting structures were encountered. We unveil a study of\nstructures in the micro-cosmos of small Turing machines.\n", "versions": [{"version": "v1", "created": "Thu, 7 Oct 2010 04:13:26 GMT"}, {"version": "v2", "created": "Fri, 15 Apr 2011 20:18:57 GMT"}], "update_date": "2011-04-19", "authors_parsed": [["Joosten", "Joost J.", ""], ["Soler-Toscano", "Fernando", ""], ["Zenil", "Hector", ""]]}, {"id": "1010.1481", "submitter": "Per Austrin", "authors": "Per Austrin and Subhash Khot", "title": "A Simple Deterministic Reduction for the Gap Minimum Distance of Code\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple deterministic gap-preserving reduction from SAT to the\nMinimum Distance of Code Problem over $\\F_2$. We also show how to extend the\nreduction to work over any finite field. Previously a randomized reduction was\nknown due to Dumer, Micciancio, and Sudan, which was recently derandomized by\nCheng and Wan. These reductions rely on highly non-trivial coding theoretic\nconstructions whereas our reduction is elementary.\n  As an additional feature, our reduction gives a constant factor hardness even\nfor asymptotically good codes, i.e., having constant rate and relative\ndistance. Previously it was not known how to achieve deterministic reductions\nfor such codes.\n", "versions": [{"version": "v1", "created": "Thu, 7 Oct 2010 16:40:59 GMT"}], "update_date": "2010-10-08", "authors_parsed": [["Austrin", "Per", ""], ["Khot", "Subhash", ""]]}, {"id": "1010.1982", "submitter": "Jing-wei Chen", "authors": "Jingwei Chen, Yong Feng, Xiaolin Qin and Jingzhong Zhang", "title": "Detecting Simultaneous Integer Relations for Several Real Vectors", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm which either finds an nonzero integer vector ${\\mathbf m}$ for\ngiven $t$ real $n$-dimensional vectors ${\\mathbf x}_1,...,{\\mathbf x}_t$ such\nthat ${\\mathbf x}_i^T{\\mathbf m}=0$ or proves that no such integer vector with\nnorm less than a given bound exists is presented in this paper. The cost of the\nalgorithm is at most ${\\mathcal O}(n^4 + n^3 \\log \\lambda(X))$ exact arithmetic\noperations in dimension $n$ and the least Euclidean norm $\\lambda(X)$ of such\ninteger vectors. It matches the best complexity upper bound known for this\nproblem. Experimental data show that the algorithm is better than an already\nexisting algorithm in the literature. In application, the algorithm is used to\nget a complete method for finding the minimal polynomial of an unknown complex\nalgebraic number from its approximation, which runs even faster than the\ncorresponding \\emph{Maple} built-in function.\n", "versions": [{"version": "v1", "created": "Mon, 11 Oct 2010 01:26:08 GMT"}], "update_date": "2010-10-12", "authors_parsed": [["Chen", "Jingwei", ""], ["Feng", "Yong", ""], ["Qin", "Xiaolin", ""], ["Zhang", "Jingzhong", ""]]}, {"id": "1010.2420", "submitter": "Nathanael Fijalkow", "authors": "Nathana\\\"el Fijalkow (LIAFA), Florian Horn (LIAFA)", "title": "The surprizing complexity of generalized reachability games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Games on graphs provide a natural and powerful model for reactive systems. In\nthis paper, we consider generalized reachability objectives, defined as\nconjunctions of reachability objectives. We first prove that deciding the\nwinner in such games is $\\PSPACE$-complete, although it is fixed-parameter\ntractable with the number of reachability objectives as parameter. Moreover, we\nconsider the memory requirements for both players and give matching upper and\nlower bounds on the size of winning strategies. In order to allow more\nefficient algorithms, we consider subclasses of generalized reachability games.\nWe show that bounding the size of the reachability sets gives two natural\nsubclasses where deciding the winner can be done efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 12 Oct 2010 15:27:15 GMT"}, {"version": "v2", "created": "Fri, 3 Feb 2012 07:35:03 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", "", "LIAFA"], ["Horn", "Florian", "", "LIAFA"]]}, {"id": "1010.2595", "submitter": "Marie Ferbus-Zanda", "authors": "Marie Ferbus-Zanda (LIAFA)", "title": "Kolmogorov Complexity in perspective. Part II: Classification,\n  Information Processing and Duality", "comments": "43 pages", "journal-ref": "Synthese / Synth\\`ese (2010) 00", "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.IT math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey diverse approaches to the notion of information: from Shannon\nentropy to Kolmogorov complexity. Two of the main applications of Kolmogorov\ncomplexity are presented: randomness and classification. The survey is divided\nin two parts published in a same volume. Part II is dedicated to the relation\nbetween logic and information system, within the scope of Kolmogorov\nalgorithmic information theory. We present a recent application of Kolmogorov\ncomplexity: classification using compression, an idea with provocative\nimplementation by authors such as Bennett, Vitanyi and Cilibrasi. This stresses\nhow Kolmogorov complexity, besides being a foundation to randomness, is also\nrelated to classification. Another approach to classification is also\nconsidered: the so-called \"Google classification\". It uses another original and\nattractive idea which is connected to the classification using compression and\nto Kolmogorov complexity from a conceptual point of view. We present and unify\nthese different approaches to classification in terms of Bottom-Up versus\nTop-Down operational modes, of which we point the fundamental principles and\nthe underlying duality. We look at the way these two dual modes are used in\ndifferent approaches to information system, particularly the relational model\nfor database introduced by Codd in the 70's. This allows to point out diverse\nforms of a fundamental duality. These operational modes are also reinterpreted\nin the context of the comprehension schema of axiomatic set theory ZF. This\nleads us to develop how Kolmogorov's complexity is linked to intensionality,\nabstraction, classification and information system.\n", "versions": [{"version": "v1", "created": "Wed, 13 Oct 2010 08:35:24 GMT"}], "update_date": "2010-10-15", "authors_parsed": [["Ferbus-Zanda", "Marie", "", "LIAFA"]]}, {"id": "1010.2597", "submitter": "Marie Ferbus-Zanda", "authors": "Marie Ferbus-Zanda (LIAFA), Serge Grigorieff (LIAFA)", "title": "ASMs and Operational Algorithmic Completeness of Lambda Calculus", "comments": "37 pages", "journal-ref": "Lecture notes in computer science LNCS 6300 (2010) 00", "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that lambda calculus is a computation model which can step by step\nsimulate any sequential deterministic algorithm for any computable function\nover integers or words or any datatype. More formally, given an algorithm above\na family of computable functions (taken as primitive tools, i.e., kind of\noracle functions for the algorithm), for every constant K big enough, each\ncomputation step of the algorithm can be simulated by exactly K successive\nreductions in a natural extension of lambda calculus with constants for\nfunctions in the above considered family. The proof is based on a fixed point\ntechnique in lambda calculus and on Gurevich sequential Thesis which allows to\nidentify sequential deterministic algorithms with Abstract State Machines. This\nextends to algorithms for partial computable functions in such a way that\nfinite computations ending with exceptions are associated to finite reductions\nleading to terms with a particular very simple feature.\n", "versions": [{"version": "v1", "created": "Wed, 13 Oct 2010 08:38:10 GMT"}], "update_date": "2010-10-15", "authors_parsed": [["Ferbus-Zanda", "Marie", "", "LIAFA"], ["Grigorieff", "Serge", "", "LIAFA"]]}, {"id": "1010.2921", "submitter": "Jonathan A. Kelner", "authors": "Paul Christiano, Jonathan A. Kelner, Aleksander Madry, Daniel A.\n  Spielman, Shang-Hua Teng", "title": "Electrical Flows, Laplacian Systems, and Faster Approximation of Maximum\n  Flow in Undirected Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to computing an approximately maximum s-t flow in\na capacitated, undirected graph. This flow is computed by solving a sequence of\nelectrical flow problems. Each electrical flow is given by the solution of a\nsystem of linear equations in a Laplacian matrix, and thus may be approximately\ncomputed in nearly-linear time.\n  Using this approach, we develop the fastest known algorithm for computing\napproximately maximum s-t flows. For a graph having n vertices and m edges, our\nalgorithm computes a (1-\\epsilon)-approximately maximum s-t flow in time\n\\tilde{O}(mn^{1/3} \\epsilon^{-11/3}). A dual version of our approach computes a\n(1+\\epsilon)-approximately minimum s-t cut in time\n\\tilde{O}(m+n^{4/3}\\eps^{-8/3}), which is the fastest known algorithm for this\nproblem as well. Previously, the best dependence on m and n was achieved by the\nalgorithm of Goldberg and Rao (J. ACM 1998), which can be used to compute\napproximately maximum s-t flows in time \\tilde{O}(m\\sqrt{n}\\epsilon^{-1}), and\napproximately minimum s-t cuts in time \\tilde{O}(m+n^{3/2}\\epsilon^{-3}).\n", "versions": [{"version": "v1", "created": "Thu, 14 Oct 2010 13:54:38 GMT"}, {"version": "v2", "created": "Tue, 19 Oct 2010 19:27:21 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Christiano", "Paul", ""], ["Kelner", "Jonathan A.", ""], ["Madry", "Aleksander", ""], ["Spielman", "Daniel A.", ""], ["Teng", "Shang-Hua", ""]]}, {"id": "1010.3007", "submitter": "Omar Fawzi", "authors": "Omar Fawzi, Patrick Hayden, Pranab Sen", "title": "From Low-Distortion Norm Embeddings to Explicit Uncertainty Relations\n  and Efficient Information Locking", "comments": "60 pages, 5 figures. v4: published version", "journal-ref": "Journal of the ACM, Vol. 60, No. 6, Article 44, November 2013", "doi": "10.1145/2518131", "report-no": null, "categories": "quant-ph cs.CC math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of quantum uncertainty relations is the essential reason that\nsome classically impossible cryptographic primitives become possible when\nquantum communication is allowed. One direct operational manifestation of these\nuncertainty relations is a purely quantum effect referred to as information\nlocking. A locking scheme can be viewed as a cryptographic protocol in which a\nuniformly random n-bit message is encoded in a quantum system using a classical\nkey of size much smaller than n. Without the key, no measurement of this\nquantum state can extract more than a negligible amount of information about\nthe message, in which case the message is said to be \"locked\". Furthermore,\nknowing the key, it is possible to recover, that is \"unlock\", the message. In\nthis paper, we make the following contributions by exploiting a connection\nbetween uncertainty relations and low-distortion embeddings of L2 into L1. We\nintroduce the notion of metric uncertainty relations and connect it to\nlow-distortion embeddings of L2 into L1. A metric uncertainty relation also\nimplies an entropic uncertainty relation. We prove that random bases satisfy\nuncertainty relations with a stronger definition and better parameters than\npreviously known. Our proof is also considerably simpler than earlier proofs.\nWe apply this result to show the existence of locking schemes with key size\nindependent of the message length. We give efficient constructions of metric\nuncertainty relations. The bases defining these metric uncertainty relations\nare computable by quantum circuits of almost linear size. This leads to the\nfirst explicit construction of a strong information locking scheme. Moreover,\nwe present a locking scheme that is close to being implementable with current\ntechnology. We apply our metric uncertainty relations to exhibit communication\nprotocols that perform quantum equality testing.\n", "versions": [{"version": "v1", "created": "Thu, 14 Oct 2010 19:14:10 GMT"}, {"version": "v2", "created": "Thu, 4 Nov 2010 19:55:00 GMT"}, {"version": "v3", "created": "Wed, 12 Jan 2011 03:30:42 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2013 11:07:53 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Fawzi", "Omar", ""], ["Hayden", "Patrick", ""], ["Sen", "Pranab", ""]]}, {"id": "1010.3060", "submitter": "Norbert Schuch", "authors": "Brielin Brown, Steven T. Flammia, Norbert Schuch", "title": "Computational Difficulty of Computing the Density of States", "comments": "v2: Accepted version. 9 pages, 1 figure", "journal-ref": "Phys. Rev. Lett. 107, 040501 (2011)", "doi": "10.1103/PhysRevLett.107.040501", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational difficulty of computing the ground state\ndegeneracy and the density of states for local Hamiltonians. We show that the\ndifficulty of both problems is exactly captured by a class which we call #BQP,\nwhich is the counting version of the quantum complexity class QMA. We show that\n#BQP is not harder than its classical counting counterpart #P, which in turn\nimplies that computing the ground state degeneracy or the density of states for\nclassical Hamiltonians is just as hard as it is for quantum Hamiltonians.\n", "versions": [{"version": "v1", "created": "Fri, 15 Oct 2010 01:19:15 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2011 21:46:11 GMT"}], "update_date": "2011-07-22", "authors_parsed": [["Brown", "Brielin", ""], ["Flammia", "Steven T.", ""], ["Schuch", "Norbert", ""]]}, {"id": "1010.3201", "submitter": "Marie Ferbus-Zanda", "authors": "Marie Ferbus-Zanda (LIAFA), Serge Grigorieff (LIAFA)", "title": "Kolmogorov Complexity in perspective. Part I: Information Theory and\n  Randomnes", "comments": "40 pages", "journal-ref": "Synthese / Synth\\`ese (2010) 00", "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey diverse approaches to the notion of information: from Shannon\nentropy to Kolmogorov complexity. Two of the main applications of Kolmogorov\ncomplexity are presented: randomness and classification. The survey is divided\nin two parts in the same volume. Part I is dedicated to information theory and\nthe mathematical formalization of randomness based on Kolmogorov complexity.\nThis last application goes back to the 60's and 70's with the work of\nMartin-L\\\"of, Schnorr, Chaitin, Levin, and has gained new impetus in the last\nyears.\n", "versions": [{"version": "v1", "created": "Fri, 15 Oct 2010 15:58:13 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Ferbus-Zanda", "Marie", "", "LIAFA"], ["Grigorieff", "Serge", "", "LIAFA"]]}, {"id": "1010.3783", "submitter": "Mihai Patrascu", "authors": "Mihai Patrascu", "title": "Unifying the Landscape of Cell-Probe Lower Bounds", "comments": "To appear in SIAM Journal on Computing (SICOMP). The conference\n  version appeared in FOCS'08 under the title \"(Data) Structures\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a large fraction of the data-structure lower bounds known today\nin fact follow by reduction from the communication complexity of lopsided\n(asymmetric) set disjointness. This includes lower bounds for:\n  * high-dimensional problems, where the goal is to show large space lower\nbounds.\n  * constant-dimensional geometric problems, where the goal is to bound the\nquery time for space O(n polylog n).\n  * dynamic problems, where we are looking for a trade-off between query and\nupdate time. (In this case, our bounds are slightly weaker than the originals,\nlosing a lglg n factor.)\n  Our reductions also imply the following new results:\n  * an Omega(lg n / lglg n) bound for 4-dimensional range reporting, given\nspace O(n polylog n). This is quite timely, since a recent result solved 3D\nreporting in O(lglg n) time, raising the prospect that higher dimensions could\nalso be easy.\n  * a tight space lower bound for the partial match problem, for constant query\ntime.\n  * the first lower bound for reachability oracles.\n  In the process, we prove optimal randomized lower bounds for lopsided set\ndisjointness.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 02:44:43 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Patrascu", "Mihai", ""]]}, {"id": "1010.4458", "submitter": "Andris Ambainis", "authors": "Andris Ambainis", "title": "Variable time amplitude amplification and a faster quantum algorithm for\n  solving systems of linear equations", "comments": "17 pages, no figures, v2: various small corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two new quantum algorithms. Our first algorithm is a\ngeneralization of amplitude amplification to the case when parts of the quantum\nalgorithm that is being amplified stop at different times.\n  Our second algorithm uses the first algorithm to improve the running time of\nHarrow et al. algorithm for solving systems of linear equations from O(kappa^2\nlog N) to O(kappa log^3 kappa log N) where \\kappa is the condition number of\nthe system of equations.\n", "versions": [{"version": "v1", "created": "Thu, 21 Oct 2010 12:51:54 GMT"}, {"version": "v2", "created": "Sun, 14 Nov 2010 23:31:15 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Ambainis", "Andris", ""]]}, {"id": "1010.4535", "submitter": "Barak Fishbain", "authors": "Dorit S. Hochbaum", "title": "Replacing spectral techniques for expander ratio, normalized cut and\n  conductance by combinatorial flow algorithms", "comments": "The paper was submitted to ArXiv system by author", "journal-ref": "Operations Research Vol. 61, No. 1, January-February 2013, pp.\n  184-198", "doi": null, "report-no": null, "categories": "math.OC cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several challenging problem in clustering, partitioning and imaging have\ntraditionally been solved using the \"spectral technique\". These problems\ninclude the normalized cut problem, the graph expander ratio problem, the\nCheeger constant problem and the conductance problem. These problems share\nseveral common features: all seek a bipartition of a set of elements; the\nproblems are formulated as a form of ratio cut; the formulation as discrete\noptimization is shown here to be equivalent to a quadratic ratio, sometimes\nreferred to as the Raleigh ratio, on discrete variables and a single sum\nconstraint which we call the balance or orthogonality constraint; when the\ndiscrete nature of the variables is disregarded, the continuous relaxation is\nsolved by the spectral method. Indeed the spectral relaxation technique is a\ndominant method providing an approximate solution to these problems.\n  We propose an algorithm for these problems which involves a relaxation of the\northogonality constraint only. This relaxation is shown here to be solved\noptimally, and in strongly polynomial time, in O(mn log((n^2) / m) for a graph\non $n$ nodes and $m$ edges. The algorithm, using HPF (Hochbaum's Pseudo-Flow)\nas subroutine, is efficient enough to be used to solve these bi-partitioning\nproblems on millions of elements and more than 300 million edges within less\nthan 10 minutes. It is also demonstrated, via a preliminary experimental study,\nthat the results of the combinatorial algorithm proposed often improve\ndramatically on the quality of the results of the spectral method.\n", "versions": [{"version": "v1", "created": "Thu, 21 Oct 2010 17:42:12 GMT"}, {"version": "v2", "created": "Tue, 16 Nov 2010 20:48:30 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Hochbaum", "Dorit S.", ""]]}, {"id": "1010.4855", "submitter": "Pulkit Grover", "authors": "Pulkit Grover, Kristen Ann Woyach and Anant Sahai", "title": "Towards a communication-theoretic understanding of system-level power\n  consumption", "comments": "24 pages, 13 figures, revision of our submission to JSAC Special\n  issue on energy-efficient wireless communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional communication theory focuses on minimizing transmit power.\nHowever, communication links are increasingly operating at shorter ranges where\ntransmit power can be significantly smaller than the power consumed in\ndecoding. This paper models the required decoding power and investigates the\nminimization of total system power from two complementary perspectives.\n  First, an isolated point-to-point link is considered. Using new lower bounds\non the complexity of message-passing decoding, lower bounds are derived on\ndecoding power. These bounds show that 1) there is a fundamental tradeoff\nbetween transmit and decoding power; 2) unlike the implications of the\ntraditional \"waterfall\" curve which focuses on transmit power, the total power\nmust diverge to infinity as error probability goes to zero; 3) Regular LDPCs,\nand not their known capacity-achieving irregular counterparts, can be shown to\nbe power order optimal in some cases; and 4) the optimizing transmit power is\nbounded away from the Shannon limit.\n  Second, we consider a collection of links. When systems both generate and\nface interference, coding allows a system to support a higher density of\ntransmitter-receiver pairs (assuming interference is treated as noise).\nHowever, at low densities, uncoded transmission may be more power-efficient in\nsome cases.\n", "versions": [{"version": "v1", "created": "Sat, 23 Oct 2010 07:53:18 GMT"}, {"version": "v2", "created": "Wed, 16 Feb 2011 20:49:35 GMT"}], "update_date": "2011-02-17", "authors_parsed": [["Grover", "Pulkit", ""], ["Woyach", "Kristen Ann", ""], ["Sahai", "Anant", ""]]}, {"id": "1010.5310", "submitter": "J. Maurice Rojas", "authors": "Mart\\'in Avenda\\~no, Ashraf Ibrahim, J. Maurice Rojas, Korben Rusek", "title": "Faster p-adic Feasibility for Certain Multivariate Sparse Polynomials", "comments": "31 pages, 3 figures, submitted for publication. This version corrects\n  various typos and clarifies the proof of Assertion (3)(c) of the main theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithms revealing new families of polynomials allowing\nsub-exponential detection of p-adic rational roots, relative to the sparse\nencoding. For instance, we show that the case of honest n-variate (n+1)-nomials\nis doable in NP and, for p exceeding the Newton polytope volume and not\ndividing any coefficient, in constant time. Furthermore, using the theory of\nlinear forms in p-adic logarithms, we prove that the case of trinomials in one\nvariable can be done in NP. The best previous complexity bounds for these\nproblems were EXPTIME or worse. Finally, we prove that detecting p-adic\nrational roots for sparse polynomials in one variable is NP-hard with respect\nto randomized reductions. The last proof makes use of an efficient construction\nof primes in certain arithmetic progressions. The smallest n where detecting\np-adic rational roots for n-variate sparse polynomials is NP-hard appears to\nhave been unknown.\n", "versions": [{"version": "v1", "created": "Tue, 26 Oct 2010 03:55:35 GMT"}, {"version": "v2", "created": "Sat, 6 Nov 2010 22:21:34 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Avenda\u00f1o", "Mart\u00edn", ""], ["Ibrahim", "Ashraf", ""], ["Rojas", "J. Maurice", ""], ["Rusek", "Korben", ""]]}, {"id": "1010.5470", "submitter": "Maria Lopez-Valdes", "authors": "Ricard Gavalda, Maria Lopez-Valdes, Elvira Mayordomo, N. V.\n  Vinodchandran", "title": "Resource-bounded Dimension in Computational Learning Theory", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the relation between computational learning theory and\nresource-bounded dimension. We intend to establish close connections between\nthe learnability/nonlearnability of a concept class and its corresponding size\nin terms of effective dimension, which will allow the use of powerful dimension\ntechniques in computational learning and viceversa, the import of learning\nresults into complexity via dimension. Firstly, we obtain a tight result on the\ndimension of online mistake-bound learnable classes. Secondly, in relation with\nPAC learning, we show that the polynomial-space dimension of PAC learnable\nclasses of concepts is zero. This provides a hypothesis on effective dimension\nthat implies the inherent unpredictability of concept classes (the classes that\nverify this property are classes not efficiently PAC learnable using any\nhypothesis). Thirdly, in relation to space dimension of classes that are\nlearnable by membership query algorithms, the main result proves that\npolynomial-space dimension of concept classes learnable by a membership-query\nalgorithm is zero.\n", "versions": [{"version": "v1", "created": "Tue, 26 Oct 2010 17:48:25 GMT"}, {"version": "v2", "created": "Fri, 14 Jan 2011 11:21:46 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Gavalda", "Ricard", ""], ["Lopez-Valdes", "Maria", ""], ["Mayordomo", "Elvira", ""], ["Vinodchandran", "N. V.", ""]]}, {"id": "1010.5951", "submitter": "Nagarajan Krishnamurthy Mr.", "authors": "Samir Datta (1) and Nagarajan Krishnamurthy (1) ((1) Chennai\n  Mathematical Institute, India.)", "title": "Some Tractable Win-Lose Games", "comments": "We have fixed an error in the proof of Lemma 4.5. The proof is in\n  Section 4.1 on \"Stitching cycles together\", pages 6-7. We have reworded the\n  statement of Lemma 4.5 as well (on page 6)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining a Nash equilibrium in a $2$-player non-zero sum game is known to\nbe PPAD-hard (Chen and Deng (2006), Chen, Deng and Teng (2009)). The problem,\neven when restricted to win-lose bimatrix games, remains PPAD-hard (Abbott,\nKane and Valiant (2005)). However, there do exist polynomial time tractable\nclasses of win-lose bimatrix games - such as, very sparse games (Codenotti,\nLeoncini and Resta (2006)) and planar games (Addario-Berry, Olver and Vetta\n(2007)).\n  We extend the results in the latter work to $K_{3,3}$ minor-free games and a\nsubclass of $K_5$ minor-free games. Both these classes of games strictly\ncontain planar games. Further, we sharpen the upper bound to unambiguous\nlogspace, a small complexity class contained well within polynomial time. Apart\nfrom these classes of games, our results also extend to a class of games that\ncontain both $K_{3,3}$ and $K_5$ as minors, thereby covering a large and\nnon-trivial class of win-lose bimatrix games. For this class, we prove an upper\nbound of nondeterministic logspace, again a small complexity class within\npolynomial time. Our techniques are primarily graph theoretic and use\nstructural characterizations of the considered minor-closed families.\n", "versions": [{"version": "v1", "created": "Thu, 28 Oct 2010 13:05:36 GMT"}, {"version": "v2", "created": "Fri, 29 Oct 2010 18:51:29 GMT"}], "update_date": "2010-11-01", "authors_parsed": [["Datta", "Samir", ""], ["Krishnamurthy", "Nagarajan", ""]]}, {"id": "1010.6112", "submitter": "EPTCS", "authors": "Yu-Fang Chen (Academia Sinica, Taiwan), Ahmed Rezine (Uppsala\n  University, Sweden)", "title": "Proceedings 12th International Workshop on Verification of\n  Infinite-State Systems", "comments": null, "journal-ref": "EPTCS 39, 2010", "doi": "10.4204/EPTCS.39", "report-no": null, "categories": "cs.FL cs.CC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the INFINITY workshop is to provide a forum for researchers\ninterested in the development of formal methods and algorithmic techniques for\nthe analysis of systems with infinitely many states, and their application in\nautomated verification of complex software and hardware systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Oct 2010 23:39:56 GMT"}], "update_date": "2010-11-01", "authors_parsed": [["Chen", "Yu-Fang", "", "Academia Sinica, Taiwan"], ["Rezine", "Ahmed", "", "Uppsala\n  University, Sweden"]]}, {"id": "1010.6231", "submitter": "Mark Jerrum", "authors": "Leslie Ann Goldberg and Mark Jerrum", "title": "A polynomial-time algorithm for estimating the partition function of the\n  ferromagnetic Ising model on a regular matroid", "comments": "New Lemma 4 provides a smoother derivation of the two lemmas now\n  numbered 5 and 6. The old Lemma 2 is not now needed, and the appendix is\n  shorter. Various clarifications have been made and typos corrected", "journal-ref": "SICOMP 42(3) 1132-1157 (2013)", "doi": "10.1137/110851213", "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computational difficulty of approximating the partition\nfunction of the ferromagnetic Ising model on a regular matroid. Jerrum and\nSinclair have shown that there is a fully polynomial randomised approximation\nscheme (FPRAS) for the class of graphic matroids. On the other hand, the\nauthors have previously shown, subject to a complexity-theoretic assumption,\nthat there is no FPRAS for the class of binary matroids, which is a proper\nsuperset of the class of graphic matroids. In order to map out the region where\napproximation is feasible, we focus on the class of regular matroids, an\nimportant class of matroids which properly includes the class of graphic\nmatroids, and is properly included in the class of binary matroids. Using\nSeymour's decomposition theorem, we give an FPRAS for the class of regular\nmatroids.\n", "versions": [{"version": "v1", "created": "Fri, 29 Oct 2010 14:45:20 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2013 11:43:01 GMT"}], "update_date": "2013-08-01", "authors_parsed": [["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}]