[{"id": "1512.00333", "submitter": "Till Fluschnik", "authors": "Till Fluschnik, Danny Hermelin, Andr\\'e Nichterlein, and Rolf\n  Niedermeier", "title": "Fractals for Kernelization Lower Bounds", "comments": "An extended abstract appeared in Proc. of the 43rd International\n  Colloquium on Automata, Languages, and Programming (ICALP 2016). A full\n  version will appear in SIAM Journal on Discrete Mathematics (SIDMA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The composition technique is a popular method for excluding polynomial-size\nproblem kernels for NP-hard parameterized problems. We present a new technique\nexploiting triangle-based fractal structures for extending the range of\napplicability of compositions. Our technique makes it possible to prove new\nno-polynomial-kernel results for a number of problems dealing with\nlength-bounded cuts. In particular, answering an open question of Golovach and\nThilikos [Discrete Optim. 2011], we show that, unless NP $\\subseteq$ coNP /\npoly, the NP-hard Length-Bounded Edge-Cut (LBEC) problem (delete at most $k$\nedges such that the resulting graph has no $s$-$t$ path of length shorter than\n$\\ell$) parameterized by the combination of $k$ and $\\ell$ has no\npolynomial-size problem kernel. Our framework applies to planar as well as\ndirected variants of the basic problems and also applies to both edge and\nvertex deletion problems. Along the way, we show that LBEC remains NP-hard on\nplanar graphs, a result which we believe is interesting in its own right.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 16:55:40 GMT"}, {"version": "v2", "created": "Wed, 27 Apr 2016 08:17:22 GMT"}, {"version": "v3", "created": "Fri, 22 Dec 2017 19:09:31 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Fluschnik", "Till", ""], ["Hermelin", "Danny", ""], ["Nichterlein", "Andr\u00e9", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "1512.00482", "submitter": "Henning Fernau", "authors": "Henning Fernau, Meenakshi Paramasivan, Markus L. Schmid, Vojt\\v{e}ch\n  Vorel", "title": "Characterization and Complexity Results on Jumping Finite Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a jumping finite automaton, the input head can jump to an arbitrary\nposition within the remaining input after reading and consuming a symbol.\n  We characterize the corresponding class of languages in terms of special\nshuffle expressions and survey other equivalent notions from the existing\nliterature.\n  Moreover, we present several results concerning computational hardness and\nalgorithms for parsing and other basic tasks concerning jumping finite\nautomata.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 21:11:39 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Fernau", "Henning", ""], ["Paramasivan", "Meenakshi", ""], ["Schmid", "Markus L.", ""], ["Vorel", "Vojt\u011bch", ""]]}, {"id": "1512.00661", "submitter": "Andris Ambainis", "authors": "Andris Ambainis and Martins Kokainis", "title": "Almost quadratic gap between partition complexity and\n  query/communication complexity", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show nearly quadratic separations between two pairs of complexity\nmeasures:\n  1. We show that there is a Boolean function $f$ with\n$D(f)=\\Omega((D^{sc}(f))^{2-o(1)})$ where $D(f)$ is the deterministic query\ncomplexity of $f$ and $D^{sc}$ is the subcube partition complexity of $f$;\n  2. As a consequence, we obtain that there is a communication task $f(x, y)$\nsuch that $D^{cc}(f)=\\Omega(\\log^{2-o(1)}\\chi(f))$ where $D^{cc}(f)$ is the\ndeterministic 2-party communication complexity of $f$ (in the standard 2-party\nmodel of communication) and $\\chi(f)$ is the partition number of $f$.\n  Both of those separations are nearly optimal: it is well known that\n$D(f)=O((D^{sc}(f))^{2})$ and $D^{cc}(f)=O(\\log^2\\chi(f))$.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 12:07:38 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Ambainis", "Andris", ""], ["Kokainis", "Martins", ""]]}, {"id": "1512.00766", "submitter": "Fulvio Gesmundo", "authors": "Fulvio Gesmundo", "title": "Geometric Aspects of Iterated Matrix Multiplication", "comments": "20 pages - minor typos have been fixed - final version to appear in\n  Journal of Algebra", "journal-ref": "J. Algebra - Vol. 461, pp. 42 - 64, 2016", "doi": "10.1016/j.jalgebra.2016.04.028", "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies geometric properties of the Iterated Matrix Multiplication\npolynomial and the hypersurface that it defines. We focus on geometric aspects\nthat may be relevant for complexity theory such as the symmetry group of the\npolynomial, the dual variety and the Jacobian loci of the hypersurface, that\nare computed with the aid of representation theory of quivers.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 16:31:51 GMT"}, {"version": "v2", "created": "Thu, 19 May 2016 14:27:44 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Gesmundo", "Fulvio", ""]]}, {"id": "1512.01150", "submitter": "Vincent Froese", "authors": "Vincent Froese, Ren\\'e van Bevern, Rolf Niedermeier, Manuel Sorge", "title": "Exploiting Hidden Structure in Selecting Dimensions that Distinguish\n  Vectors", "comments": "Accepted for publication in Journal of Computer and System Sciences\n  (Elsevier)", "journal-ref": "Journal of Computer and System Sciences, 82(3):521-535, 2016", "doi": "10.1016/j.jcss.2015.11.011", "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NP-hard Distinct Vectors problem asks to delete as many columns as\npossible from a matrix such that all rows in the resulting matrix are still\npairwise distinct. Our main result is that, for binary matrices, there is a\ncomplexity dichotomy for Distinct Vectors based on the maximum (H) and the\nminimum (h) pairwise Hamming distance between matrix rows: Distinct Vectors can\nbe solved in polynomial time if H <= 2 ceil(h/2) + 1, and is NP-complete\notherwise. Moreover, we explore connections of Distinct Vectors to hitting\nsets, thereby providing several fixed-parameter tractability and intractability\nresults also for general matrices.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 16:44:39 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2015 12:12:05 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Froese", "Vincent", ""], ["van Bevern", "Ren\u00e9", ""], ["Niedermeier", "Rolf", ""], ["Sorge", "Manuel", ""]]}, {"id": "1512.01157", "submitter": "Marcin Kozik", "authors": "Libor Barto, Marcin Kozik", "title": "Robustly Solvable Constraint Satisfaction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for a constraint satisfaction problem is called robust if it\noutputs an assignment satisfying at least $(1-g(\\varepsilon))$-fraction of the\nconstraints given a $(1-\\varepsilon)$-satisfiable instance, where\n$g(\\varepsilon) \\rightarrow 0$ as $\\varepsilon \\rightarrow 0$. Guruswami and\nZhou conjectured a characterization of constraint languages for which the\ncorresponding constraint satisfaction problem admits an efficient robust\nalgorithm. This paper confirms their conjecture.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 17:05:06 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Barto", "Libor", ""], ["Kozik", "Marcin", ""]]}, {"id": "1512.01210", "submitter": "Robin Kothari", "authors": "Robin Kothari", "title": "Nearly optimal separations between communication (or query) complexity\n  and partitions", "comments": "13 pages", "journal-ref": "31st Conference on Computational Complexity (CCC 2016), Leibniz\n  International Proceedings in Informatics (LIPIcs) 50, pp. 4:1-4:14 (2016)", "doi": "10.4230/LIPIcs.CCC.2016.4", "report-no": "MIT-CTP #4746", "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a nearly quadratic separation between deterministic communication\ncomplexity and the logarithm of the partition number, which is essentially\noptimal. This improves upon a recent power 1.5 separation of G\\\"o\\\"os, Pitassi,\nand Watson (FOCS 2015). In query complexity, we establish a nearly quadratic\nseparation between deterministic (and even randomized) query complexity and\nsubcube partition complexity, which is also essentially optimal. We also\nestablish a nearly power 1.5 separation between quantum query complexity and\nsubcube partition complexity, the first superlinear separation between the two\nmeasures. Lastly, we show a quadratic separation between quantum query\ncomplexity and one-sided subcube partition complexity.\n  Our query complexity separations use the recent cheat sheet framework of\nAaronson, Ben-David, and the author. Our query functions are built up in stages\nby alternating function composition with the cheat sheet construction. The\ncommunication complexity separation follows from lifting the query separation\nto communication complexity.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 20:02:00 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Kothari", "Robin", ""]]}, {"id": "1512.01256", "submitter": "Gaurav Sinha", "authors": "Gaurav Sinha", "title": "Reconstruction of depth-3, top fan-in two circuits over characteristic\n  zero fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of arithmetic circuits has been heavily studied in the past\nfew years and has connections to proving lower bounds and deterministic\nidentity testing. In this paper we present a polynomial time randomized\nalgorithm for reconstructing $\\Sigma\\Pi\\Sigma(2)$ circuits over $\\mathbb{F}$\n($char(\\mathbb{F})=0$), i.e. depth$-3$ circuits with fan-in $2$ at the top\naddition gate and having coefficients from a field of characteristic $0$. The\nalgorithm needs only a blackbox query access to the polynomial $f \\in\n\\mathbb{F}[x_1,\\ldots, x_n]$ of degree $d$, computable by a\n$\\Sigma\\Pi\\Sigma(2)$ circuit $C$. In addition, we assume that \"simple rank\" of\nthis polynomial (essential number of variables after removing gcd of the two\nmultiplication gates) is bigger than a constant. Our algorithm runs in time\n$poly(n, d)$ and returns an equivalent $\\Sigma\\Pi\\Sigma(2)$ circuit(with high\nprobability). The problem of reconstructing $\\Sigma\\Pi\\Sigma(2)$ circuits over\nfinite fields was first proposed by Shpilka in [24]. The generalization to\n$\\Sigma\\Pi\\Sigma(k)$ circuits, $k = O(1)$ (over finite fields) was addressed by\nKarnin and Shpilka in [15]. The techniques in these previous involve iterating\nover all objects of certain kinds over the ambient field and thus running time\ndepends on size of the field $\\mathbb{F}$. Their reconstruction algorithm uses\nlower bounds on the lengths of Linear Locally Decodable Codes with $2$ queries.\nIn our settings, such ideas immediately pose a problem and we need new ideas to\nhandle the case of the characteristic $0$ field $\\mathbb{F}$. Our main\ntechniques are based on the use of Quantitative Syslvester Gallai Theorems from\nthe work of Barak et.al. [3] to find a small collection of subspaces to project\nonto. The heart of our paper lies in subtle applications of Quantitative\nSylvester Gallai theorems to prove why projections w.r.t. these subspaces can\nbe glued.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 21:32:16 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 22:15:57 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Sinha", "Gaurav", ""]]}, {"id": "1512.01968", "submitter": "Prahladh Harsha", "authors": "Prahladh Harsha, Rahul Jain, Jaikumar Radhakrishnan", "title": "Partition bound is quadratically tight for product distributions", "comments": "The previous version of the paper erroneously stated the main result\n  in terms of relaxed partition number instead of partition number", "journal-ref": "In Proc. 43rd International Colloquium of Automata, Language and\n  Programming (ICALP) (Rome, Italy, 12-15 July), volume 55 of LiPiCS, pages\n  135:1-135:13, 2016", "doi": "10.4230/LIPIcs.ICALP.2016.135", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $f : \\{0,1\\}^n \\times \\{0,1\\}^n \\rightarrow \\{0,1\\}$ be a 2-party\nfunction. For every product distribution $\\mu$ on $\\{0,1\\}^n \\times \\{0,1\\}^n$,\nwe show that $$\\mathsf{CC}^\\mu_{0.49}(f) = O\\left(\\left(\\log\n\\mathsf{prt}_{1/8}(f) \\cdot \\log \\log \\mathsf{prt}_{1/8}(f)\\right)^2\\right),$$\nwhere $\\mathsf{CC}^\\mu_\\varepsilon(f)$ is the distributional communication\ncomplexity of $f$ with error at most $\\varepsilon$ under the distribution $\\mu$\nand $\\mathsf{prt}_{1/8}(f)$ is the {\\em partition bound} of $f$, as defined by\nJain and Klauck [{\\em Proc. 25th CCC}, 2010]. We also prove a similar bound in\nterms of $\\mathsf{IC}_{1/8}(f)$, the {\\em information complexity} of $f$,\nnamely, $$\\mathsf{CC}^\\mu_{0.49}(f) = O\\left(\\left(\\mathsf{IC}_{1/8}(f) \\cdot\n\\log \\mathsf{IC}_{1/8}(f)\\right)^2\\right).$$ The latter bound was recently and\nindependently established by Kol [{\\em Proc. 48th STOC}, 2016] using a\ndifferent technique.\n  We show a similar result for query complexity under product distributions.\nLet $g : \\{0,1\\}^n \\rightarrow \\{0,1\\}$ be a function. For every bit-wise\nproduct distribution $\\mu$ on $\\{0,1\\}^n$, we show that\n$$\\mathsf{QC}^\\mu_{0.49}(g) = O\\left(\\left( \\log \\mathsf{qprt}_{1/8}(g) \\cdot\n\\log \\log\\mathsf{qprt}_{1/8}(g) \\right)^2 \\right),$$ where\n$\\mathsf{QC}^\\mu_{\\varepsilon}(g)$ is the distributional query complexity of\n$f$ with error at most $\\varepsilon$ under the distribution $\\mu$ and\n$\\mathsf{qprt}_{1/8}(g))$ is the {\\em query partition bound} of the function\n$g$.\n  Partition bounds were introduced (in both communication complexity and query\ncomplexity models) to provide LP-based lower bounds for randomized\ncommunication complexity and randomized query complexity. Our results\ndemonstrate that these lower bounds are polynomially tight for {\\em product}\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 10:36:22 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2015 12:30:39 GMT"}, {"version": "v3", "created": "Fri, 15 Apr 2016 06:14:41 GMT"}, {"version": "v4", "created": "Tue, 26 Apr 2016 18:42:40 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Harsha", "Prahladh", ""], ["Jain", "Rahul", ""], ["Radhakrishnan", "Jaikumar", ""]]}, {"id": "1512.02090", "submitter": "Anand Natarajan", "authors": "Anand Natarajan and Thomas Vidick", "title": "Constant-Soundness Interactive Proofs for Local Hamiltonians", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $ \\newcommand{\\Xlin}{\\mathcal{X}} \\newcommand{\\Zlin}{\\mathcal{Z}}\n\\newcommand{\\C}{\\mathbb{C}} $We give a quantum multiprover interactive proof\nsystem for the local Hamiltonian problem in which there is a constant number of\nprovers, questions are classical of length polynomial in the number of qubits,\nand answers are of constant length. The main novelty of our protocol is that\nthe gap between completeness and soundness is directly proportional to the\npromise gap on the (normalized) ground state energy of the Hamiltonian. This\nresult can be interpreted as a concrete step towards a quantum PCP theorem\ngiving entangled-prover interactive proof systems for QMA-complete problems.\n  The key ingredient is a quantum version of the classical linearity test of\nBlum, Luby, and Rubinfeld, where the function $f:\\{0,1\\}^n\\to\\{0,1\\}$ is\nreplaced by a pair of functions $\\Xlin, \\Zlin:\\{0,1\\}^n\\to \\text{Obs}_d(\\C)$,\nthe set of $d$-dimensional Hermitian matrices that square to identity. The test\nenforces that (i) each function is exactly linear,\n$\\Xlin(a)\\Xlin(b)=\\Xlin(a+b)$ and $\\Zlin(a) \\Zlin(b)=\\Zlin(a+b)$, and (ii) the\ntwo functions are approximately complementary, $\\Xlin(a)\\Zlin(b)\\approx\n(-1)^{a\\cdot b} \\Zlin(b)\\Xlin(a)$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 15:33:23 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Natarajan", "Anand", ""], ["Vidick", "Thomas", ""]]}, {"id": "1512.02337", "submitter": "David Steurer", "authors": "Samuel B. Hopkins, Tselil Schramm, Jonathan Shi, David Steurer", "title": "Fast spectral algorithms from sum-of-squares proofs: tensor\n  decomposition and planted sparse vectors", "comments": "62 pages, title changed, to appear at STOC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two problems that arise in machine learning applications: the\nproblem of recovering a planted sparse vector in a random linear subspace and\nthe problem of decomposing a random low-rank overcomplete 3-tensor. For both\nproblems, the best known guarantees are based on the sum-of-squares method. We\ndevelop new algorithms inspired by analyses of the sum-of-squares method. Our\nalgorithms achieve the same or similar guarantees as sum-of-squares for these\nproblems but the running time is significantly faster.\n  For the planted sparse vector problem, we give an algorithm with running time\nnearly linear in the input size that approximately recovers a planted sparse\nvector with up to constant relative sparsity in a random subspace of $\\mathbb\nR^n$ of dimension up to $\\tilde \\Omega(\\sqrt n)$. These recovery guarantees\nmatch the best known ones of Barak, Kelner, and Steurer (STOC 2014) up to\nlogarithmic factors.\n  For tensor decomposition, we give an algorithm with running time close to\nlinear in the input size (with exponent $\\approx 1.086$) that approximately\nrecovers a component of a random 3-tensor over $\\mathbb R^n$ of rank up to\n$\\tilde \\Omega(n^{4/3})$. The best previous algorithm for this problem due to\nGe and Ma (RANDOM 2015) works up to rank $\\tilde \\Omega(n^{3/2})$ but requires\nquasipolynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2015 05:49:07 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2016 18:01:12 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Hopkins", "Samuel B.", ""], ["Schramm", "Tselil", ""], ["Shi", "Jonathan", ""], ["Steurer", "David", ""]]}, {"id": "1512.02379", "submitter": "Petr Hlin\\v{e}n\\'y", "authors": "Petr Hlin\\v{e}n\\'y and Marek Der\\v{n}\\'ar", "title": "Crossing Number is Hard for Kernelization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph crossing number problem, cr(G)<=k, asks for a drawing of a graph G\nin the plane with at most k edge crossings. Although this problem is in general\nnotoriously difficult, it is fixed- parameter tractable for the parameter k\n[Grohe]. This suggests a closely related question of whether this problem has a\npolynomial kernel, meaning whether every instance of cr(G)<=k can be in\npolynomial time reduced to an equivalent instance of size polynomial in k (and\nindependent of |G|). We answer this question in the negative. Along the proof\nwe show that the tile crossing number problem of twisted planar tiles is\nNP-hard, which has been an open problem for some time, too, and then employ the\ncomplexity technique of cross-composition. Our result holds already for the\nspecial case of graphs obtained from planar graphs by adding one edge.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2015 09:33:47 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2016 10:49:20 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Hlin\u011bn\u00fd", "Petr", ""], ["Der\u0148\u00e1r", "Marek", ""]]}, {"id": "1512.02510", "submitter": "Eva-Maria Hols", "authors": "Eva-Maria C. Hols and Stefan Kratsch", "title": "A randomized polynomial kernel for Subset Feedback Vertex Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Subset Feedback Vertex Set problem generalizes the classical Feedback\nVertex Set problem and asks, for a given undirected graph $G=(V,E)$, a set $S\n\\subseteq V$, and an integer $k$, whether there exists a set $X$ of at most $k$\nvertices such that no cycle in $G-X$ contains a vertex of $S$. It was\nindependently shown by Cygan et al. (ICALP '11, SIDMA '13) and Kawarabayashi\nand Kobayashi (JCTB '12) that Subset Feedback Vertex Set is fixed-parameter\ntractable for parameter $k$. Cygan et al. asked whether the problem also admits\na polynomial kernelization.\n  We answer the question of Cygan et al. positively by giving a randomized\npolynomial kernelization for the equivalent version where $S$ is a set of\nedges. In a first step we show that Edge Subset Feedback Vertex Set has a\nrandomized polynomial kernel parameterized by $|S|+k$ with $O(|S|^2k)$\nvertices. For this we use the matroid-based tools of Kratsch and Wahlstr\\\"om\n(FOCS '12) that for example were used to obtain a polynomial kernel for\n$s$-Multiway Cut. Next we present a preprocessing that reduces the given\ninstance $(G,S,k)$ to an equivalent instance $(G',S',k')$ where the size of\n$S'$ is bounded by $O(k^4)$. These two results lead to a polynomial kernel for\nSubset Feedback Vertex Set with $O(k^9)$ vertices.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2015 15:32:45 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Hols", "Eva-Maria C.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1512.03127", "submitter": "Marcel Jackson G", "authors": "Marcel Jackson", "title": "Flexible constraint satisfiability and a problem in semigroup theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine some flexible notions of constraint satisfaction, observing some\nrelationships between model theoretic notions of universal Horn class\nmembership and robust satisfiability. We show the \\texttt{NP}-completeness of\n$2$-robust monotone 1-in-3 3SAT in order to give very small examples of finite\nalgebras with \\texttt{NP}-hard variety membership problem. In particular we\ngive a $3$-element algebra with this property, and solve a widely stated\nproblem by showing that the $6$-element Brandt monoid has \\texttt{NP}-hard\nvariety membership problem. These are the smallest possible sizes for a general\nalgebra and a semigroup to exhibit \\texttt{NP}-hardness for the membership\nproblem of finite algebras in finitely generated varieties.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 02:31:37 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 09:41:53 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Jackson", "Marcel", ""]]}, {"id": "1512.03246", "submitter": "Clemens R\\\"osner", "authors": "Matthias Mnich, Heiko R\\\"oglin, Clemens R\\\"osner", "title": "New Deterministic Algorithms for Solving Parity Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study parity games in which one of the two players controls only a small\nnumber $k$ of nodes and the other player controls the $n-k$ other nodes of the\ngame. Our main result is a fixed-parameter algorithm that solves bipartite\nparity games in time $k^{O(\\sqrt{k})}\\cdot O(n^3)$, and general parity games in\ntime $(p+k)^{O(\\sqrt{k})} \\cdot O(pnm)$, where $p$ is the number of distinct\npriorities and $m$ is the number of edges. For all games with $k = o(n)$ this\nimproves the previously fastest algorithm by Jurdzi{\\'n}ski, Paterson, and\nZwick (SICOMP 2008). We also obtain novel kernelization results and an improved\ndeterministic algorithm for graphs with small average degree.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 13:21:30 GMT"}], "update_date": "2015-12-12", "authors_parsed": [["Mnich", "Matthias", ""], ["R\u00f6glin", "Heiko", ""], ["R\u00f6sner", "Clemens", ""]]}, {"id": "1512.03393", "submitter": "Viswambhara Makam", "authors": "Harm Derksen and Visu Makam", "title": "Polynomial degree bounds for matrix semi-invariants", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the left-right action of $\\operatorname{SL}_n \\times\n\\operatorname{SL}_n$ on $m$-tuples of $n \\times n$ matrices with entries in an\ninfinite field $K$. We show that invariants of degree $n^2- n$ define the null\ncone. Consequently, invariants of degree $\\leq n^6$ generate the ring of\ninvariants if $\\operatorname{char}(K)=0$. We also prove that for $m \\gg 0$,\ninvariants of degree at least $n\\lfloor \\sqrt{n+1}\\rfloor$ are required to\ndefine the null cone. We generalize our results to matrix invariants of\n$m$-tuples of $p\\times q$ matrices, and to rings of semi-invariants for\nquivers. For the proofs, we use new techniques such as the regularity lemma by\nIvanyos, Qiao and Subrahmanyam, and the concavity property of the tensor\nblow-ups of matrix spaces. We will discuss several applications to algebraic\ncomplexity theory, such as a deterministic polynomial time algorithm for\nnon-commutative rational identity testing, and the existence of small\ndivision-free formulas for non-commutative polynomials.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 20:12:47 GMT"}], "update_date": "2015-12-11", "authors_parsed": [["Derksen", "Harm", ""], ["Makam", "Visu", ""]]}, {"id": "1512.03531", "submitter": "G\\'abor Ivanyos", "authors": "G\\'abor Ivanyos, Youming Qiao, K. V. Subrahmanyam", "title": "Constructive noncommutative rank computation is in deterministic\n  polynomial time", "comments": "20 pages, accepted version (in Computational Complexity)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.AC math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend our techniques developed in our earlier paper appeared in\nComputational Complexity, 2017 (preprint: arXiv:1508.00690) to obtain a\ndeterministic polynomial time algorithm for computing the non-commutative rank\ntogether with certificates of linear spaces of matrices over sufficiently large\nbase fields.\n  The key new idea is a reduction procedure that keeps the blow-up parameter\nsmall, and there are two methods to implement this idea: the first one is a\ngreedy argument that removes certain rows and columns, and the second one is an\nefficient algorithmic version of a result of Derksen and Makam. Both methods\nrely crucially on the regularity lemma in our aforementioned paper, and in this\nmanuscript we also improve that lemma by removing a coprime condition there.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2015 05:47:56 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2015 03:37:18 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2016 23:05:31 GMT"}, {"version": "v4", "created": "Fri, 17 Jun 2016 09:32:14 GMT"}, {"version": "v5", "created": "Thu, 1 Feb 2018 14:07:03 GMT"}, {"version": "v6", "created": "Mon, 5 Feb 2018 17:00:56 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Ivanyos", "G\u00e1bor", ""], ["Qiao", "Youming", ""], ["Subrahmanyam", "K. V.", ""]]}, {"id": "1512.03547", "submitter": "Laszlo Babai", "authors": "L\\'aszl\\'o Babai", "title": "Graph Isomorphism in Quasipolynomial Time", "comments": "89 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO math.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the Graph Isomorphism (GI) problem and the related problems of\nString Isomorphism (under group action) (SI) and Coset Intersection (CI) can be\nsolved in quasipolynomial ($\\exp((\\log n)^{O(1)})$) time. The best previous\nbound for GI was $\\exp(O(\\sqrt{n\\log n}))$, where $n$ is the number of vertices\n(Luks, 1983); for the other two problems, the bound was similar,\n$\\exp(\\tilde{O}(\\sqrt{n}))$, where $n$ is the size of the permutation domain\n(Babai, 1983).\n  The algorithm builds on Luks's SI framework and attacks the barrier\nconfigurations for Luks's algorithm by group theoretic \"local certificates\" and\ncombinatorial canonical partitioning techniques. We show that in a well-defined\nsense, Johnson graphs are the only obstructions to effective canonical\npartitioning.\n  Luks's barrier situation is characterized by a homomorphism {\\phi} that maps\na given permutation group $G$ onto $S_k$ or $A_k$, the symmetric or alternating\ngroup of degree $k$, where $k$ is not too small. We say that an element $x$ in\nthe permutation domain on which $G$ acts is affected by {\\phi} if the\n{\\phi}-image of the stabilizer of $x$ does not contain $A_k$. The\naffected/unaffected dichotomy underlies the core \"local certificates\" routine\nand is the central divide-and-conquer tool of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2015 08:04:26 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 08:55:28 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Babai", "L\u00e1szl\u00f3", ""]]}, {"id": "1512.03607", "submitter": "Raghavendra Rao B V", "authors": "C. Ramya and B.V. Raghavendra Rao", "title": "Limitations of sum of products of Read-Once Polynomials", "comments": "Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study limitations of polynomials computed by depth two circuits built over\nread-once polynomials (ROPs) and depth three syntactically multi-linear\nformulas.\n  We prove an exponential lower bound for the size of the\n$\\Sigma\\Pi^{[N^{1/30}]}$ arithmetic circuits built over syntactically\nmulti-linear $\\Sigma\\Pi\\Sigma^{[N^{8/15}]}$ arithmetic circuits computing a\nproduct of variable disjoint linear forms on $N$ variables. We extend the\nresult to the case of $\\Sigma\\Pi^{[N^{1/30}]}$ arithmetic circuits built over\nROPs of unbounded depth, where the number of variables with $+$ gates as a\nparent in an proper sub formula is bounded by $N^{1/2+1/30}$. We show that the\nsame lower bound holds for the permanent polynomial. Finally we obtain an\nexponential lower bound for the sum of ROPs computing a polynomial in ${\\sf\nVP}$ defined by Raz and Yehudayoff.\n  Our results demonstrate a class of formulas of unbounded depth with\nexponential size lower bound against the permanent and can be seen as an\nexponential improvement over the multilinear formula size lower bounds given by\nRaz for a sub-class of multi-linear and non-multi-linear formulas.\n  Our proof techniques are built on the one developed by Raz and later extended\nby Kumar et. al.\\cite{KMS13} and are based on non-trivial analysis of ROPs\nunder random partitions. Further, our results exhibit strengths and limitations\nof the lower bound techniques introduced by Raz\\cite{Raz04a}.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2015 11:43:49 GMT"}], "update_date": "2015-12-14", "authors_parsed": [["Ramya", "C.", ""], ["Rao", "B. V. Raghavendra", ""]]}, {"id": "1512.03798", "submitter": "Christian Ikenmeyer", "authors": "Christian Ikenmeyer, Greta Panova", "title": "Rectangular Kronecker coefficients and plethysms in geometric complexity\n  theory", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that in the geometric complexity theory program the vanishing of\nrectangular Kronecker coefficients cannot be used to prove superpolynomial\ndeterminantal complexity lower bounds for the permanent polynomial.\n  Moreover, we prove the positivity of rectangular Kronecker coefficients for a\nlarge class of partitions where the side lengths of the rectangle are at least\nquadratic in the length of the partition. We also compare rectangular Kronecker\ncoefficients with their corresponding plethysm coefficients, which leads to a\nnew lower bound for rectangular Kronecker coefficients. Moreover, we prove that\nthe saturation of the rectangular Kronecker semigroup is trivial, we show that\nthe rectangular Kronecker positivity stretching factor is 2 for a long first\nrow, and we completely classify the positivity of rectangular limit Kronecker\ncoefficients that were introduced by Manivel in 2011.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2015 20:41:06 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 14:52:54 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Ikenmeyer", "Christian", ""], ["Panova", "Greta", ""]]}, {"id": "1512.04016", "submitter": "Shalev Ben-David", "authors": "Scott Aaronson, Shalev Ben-David", "title": "Sculpting Quantum Speedups", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a problem which is intractable for both quantum and classical\nalgorithms, can we find a sub-problem for which quantum algorithms provide an\nexponential advantage? We refer to this problem as the \"sculpting problem.\" In\nthis work, we give a full characterization of sculptable functions in the query\ncomplexity setting. We show that a total function f can be restricted to a\npromise P such that Q(f|_P)=O(polylog(N)) and R(f|_P)=N^{Omega(1)}, if and only\nif f has a large number of inputs with large certificate complexity. The proof\nuses some interesting techniques: for one direction, we introduce new\nrelationships between randomized and quantum query complexity in various\nsettings, and for the other direction, we use a recent result from\ncommunication complexity due to Klartag and Regev. We also characterize\nsculpting for other query complexity measures, such as R(f) vs. R_0(f) and\nR_0(f) vs. D(f).\n  Along the way, we prove some new relationships for quantum query complexity:\nfor example, a nearly quadratic relationship between Q(f) and D(f) whenever the\npromise of f is small. This contrasts with the recent super-quadratic query\ncomplexity separations, showing that the maximum gap between classical and\nquantum query complexities is indeed quadratic in various settings - just not\nfor total functions!\n  Lastly, we investigate sculpting in the Turing machine model. We show that if\nthere is any BPP-bi-immune language in BQP, then every language outside BPP can\nbe restricted to a promise which places it in PromiseBQP but not in PromiseBPP.\nUnder a weaker assumption, that some problem in BQP is hard on average for\nP/poly, we show that every paddable language outside BPP is sculptable in this\nway.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2015 08:29:18 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Aaronson", "Scott", ""], ["Ben-David", "Shalev", ""]]}, {"id": "1512.04138", "submitter": "Noah Stephens-Davidowitz", "authors": "Noah Stephens-Davidowitz", "title": "Search-to-Decision Reductions for Lattice Problems with Approximation\n  Factors (Slightly) Greater Than One", "comments": "Updated to acknowledge additional prior work", "journal-ref": "APPROX 2016", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show the first dimension-preserving search-to-decision reductions for\napproximate SVP and CVP. In particular, for any $\\gamma \\leq 1 + O(\\log n/n)$,\nwe obtain an efficient dimension-preserving reduction from $\\gamma^{O(n/\\log\nn)}$-SVP to $\\gamma$-GapSVP and an efficient dimension-preserving reduction\nfrom $\\gamma^{O(n)}$-CVP to $\\gamma$-GapCVP. These results generalize the known\nequivalences of the search and decision versions of these problems in the exact\ncase when $\\gamma = 1$. For SVP, we actually obtain something slightly stronger\nthan a search-to-decision reduction---we reduce $\\gamma^{O(n/\\log n)}$-SVP to\n$\\gamma$-unique SVP, a potentially easier problem than $\\gamma$-GapSVP.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2015 23:41:21 GMT"}, {"version": "v2", "created": "Sun, 13 Mar 2016 21:54:07 GMT"}, {"version": "v3", "created": "Wed, 20 Apr 2016 02:35:23 GMT"}, {"version": "v4", "created": "Sun, 3 Jul 2016 19:51:23 GMT"}, {"version": "v5", "created": "Mon, 24 Apr 2017 00:58:56 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Stephens-Davidowitz", "Noah", ""]]}, {"id": "1512.04375", "submitter": "Joseph Fitzsimons", "authors": "Joseph F. Fitzsimons and Michal Hajdu\\v{s}ek", "title": "Post hoc verification of quantum computation", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent progress on experimental quantum information processing, an\nimportant question has arisen as to whether it is possible to verify arbitrary\ncomputation performed on a quantum processor. A number of protocols have been\nproposed to achieve this goal, however all are interactive in nature, requiring\nthat the computation be performed in an interactive manner with back and forth\ncommunication between the verifier and one or more provers. Here we propose two\nmethods for verifying quantum computation in a non-interactive manner based on\nrecent progress in the understanding of the local Hamiltonian problem. Provided\nthat the provers compute certain witnesses for the computation, this allows the\nresult of a quantum computation to be verified after the fact, a property not\nseen in current verification protocols.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 15:52:45 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Fitzsimons", "Joseph F.", ""], ["Hajdu\u0161ek", "Michal", ""]]}, {"id": "1512.04386", "submitter": "Anuj Tawari", "authors": "Meena Mahajan and Anuj Tawari", "title": "Read-once polynomials: How many summands suffice?", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An arithmetic read-once formula (ROF) is a formula (circuit of fan-out 1)\nover $+, \\times$ where each variable labels at most one leaf. Every multilinear\npolynomial can be expressed as the sum of ROFs. In this work, we prove, for\ncertain multilinear polynomials, a tight lower bound on the number of summands\nin such an expression.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 16:16:44 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Mahajan", "Meena", ""], ["Tawari", "Anuj", ""]]}, {"id": "1512.04932", "submitter": "Aurko Roy", "authors": "G\\'abor Braun, Sebastian Pokutta, Aurko Roy", "title": "Strong reductions for extended formulations", "comments": "correct approx factor for sparsest cut, typos, update references", "journal-ref": "Math. Program. (2018) Vol 172(1-2) 591-620", "doi": "10.1007/s10107-018-1316-y, 10.1007/978-3-319-33461-5_29", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the reduction mechanism for linear programming problems and\nsemidefinite programming problems from [arXiv:1410.8816] in two ways 1)\nrelaxing the requirement of affineness and 2) extending to fractional\noptimization problems. As applications we provide several new LP-hardness and\nSDP-hardness results, e.g., for the SparsestCut problem, the BalancedSeparator\nproblem, the MaxCut problem and the Matching problem on 3-regular graphs. We\nalso provide a new, very strong Lasserre integrality gap result for the\nIndependentSet problem, which is strictly greater than the best known LP\napproximation, showing that the Lasserre hierarchy does not always provide the\ntightest SDP relaxation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 20:50:27 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2015 19:44:10 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2016 23:45:36 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Braun", "G\u00e1bor", ""], ["Pokutta", "Sebastian", ""], ["Roy", "Aurko", ""]]}, {"id": "1512.05064", "submitter": "Fabio Lorenzo Traversa Ph.D.", "authors": "Fabio L. Traversa, Massimiliano Di Ventra", "title": "Polynomial-time solution of prime factorization and NP-hard problems\n  with digital memcomputing machines", "comments": null, "journal-ref": "Chaos: an interdisciplinary journal of nonlinear science, vol. 27,\n  pag. 023107, year 2017", "doi": "10.1063/1.4975761", "report-no": null, "categories": "cs.ET cond-mat.mes-hall cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of digital machines we name Digital Memcomputing\nMachines (DMMs) able to solve a wide range of problems including\nNon-deterministic Polynomial (NP) ones with polynomial resources (in time,\nspace and energy). An abstract DMM with this power must satisfy a set of\ncompatible mathematical constraints underlying its practical realization. We\ninitially prove this by introducing the complexity classes for these machines.\nWe then make a connection with dynamical systems theory. This leads to the set\nof physical constraints for poly-resource resolvability. Once the mathematical\nrequirements have been assessed, we propose a practical scheme to solve the\nabove class of problems based on the novel concept of self-organizing logic\ngates and circuits (SOLCs). These are logic gates and circuits able to accept\ninput signals from any terminal, without distinction between conventional input\nand output terminals. They can solve boolean problems by self-organizing into\ntheir solution. They can be fabricated either with circuit elements with memory\n(such as memristors) and/or standard MOS technology. Using tools of functional\nanalysis, we prove mathematically the following constraints for the\npoly-resource resolvability: i) SOLCs possess a global attractor; ii) their\nonly equilibrium points are the solutions of the problems to solve; iii) the\nsystem converges exponentially fast to the solutions; iv) the equilibrium\nconvergence rate scales at most polynomially with input size. We finally\nprovide arguments that periodic orbits and strange attractors cannot coexist\nwith equilibria. As examples we show how to solve the prime factorization and\nthe NP-hard version of the subset-sum problem. Since DMMs map integers into\nintegers they are robust against noise, and hence scalable. We finally discuss\nthe implications of the DMM realization through SOLCs to the NP=P question\nrelated to...\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 06:35:32 GMT"}, {"version": "v2", "created": "Fri, 22 Apr 2016 10:42:48 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Traversa", "Fabio L.", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "1512.05199", "submitter": "Yoshihiko Kayama", "authors": "Yoshihiko Kayama", "title": "Extension of cellular automata by introducing an algorithm of recursive\n  estimation of neighbors", "comments": "5 pages,10 figures, 21st International Symposium on Artificial Life\n  and Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study focuses on an extended model of a standard cellular automaton (CA)\nthat includes an extra index consisting of a radius that defines a perception\narea for each cell in addition to the radius defined by the CA rule. Extended\nstandard CA rules form a sequence ordered by this index, which includes the CA\nrule as its first term. This extension aims at constructing a model that can be\nused within the CA framework to study the relationship between information\nprocessing and pattern formation in collective systems. Although the extension\npresented here is merely an extrapolation to a CA with a larger rule\nneighborhood, the extra radius can be interpreted as an individual difference\nof each cell, which provides a new perspective to CA. Some pattern formations\nin extended one-dimensional elementary CAs and two-dimensional Life-like CAs\nare presented. It is expected that the extended CA can be applied to various\nsimulations of complex systems and other fields.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 15:06:28 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2015 07:39:10 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Kayama", "Yoshihiko", ""]]}, {"id": "1512.05279", "submitter": "Omer Gold", "authors": "Omer Gold and Micha Sharir", "title": "Improved Bounds for 3SUM, $k$-SUM, and Linear Degeneracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of $n$ real numbers, the 3SUM problem is to decide whether there\nare three of them that sum to zero. Until a recent breakthrough by Gr{\\o}nlund\nand Pettie [FOCS'14], a simple $\\Theta(n^2)$-time deterministic algorithm for\nthis problem was conjectured to be optimal. Over the years many algorithmic\nproblems have been shown to be reducible from the 3SUM problem or its variants,\nincluding the more generalized forms of the problem, such as $k$-SUM and\n$k$-variate linear degeneracy testing ($k$-LDT). The conjectured hardness of\nthese problems have become extremely popular for basing conditional lower\nbounds for numerous algorithmic problems in P.\n  In this paper, we show that the randomized $4$-linear decision tree\ncomplexity of 3SUM is $O(n^{3/2})$, and that the randomized $(2k-2)$-linear\ndecision tree complexity of $k$-SUM and $k$-LDT is $O(n^{k/2})$, for any odd\n$k\\ge 3$. These bounds improve (albeit randomized) the corresponding\n$O(n^{3/2}\\sqrt{\\log n})$ and $O(n^{k/2}\\sqrt{\\log n})$ decision tree bounds\nobtained by Gr{\\o}nlund and Pettie. Our technique includes a specialized\nrandomized variant of fractional cascading data structure. Additionally, we\ngive another deterministic algorithm for 3SUM that runs in $O(n^2 \\log\\log n /\n\\log n )$ time. The latter bound matches a recent independent bound by Freund\n[Algorithmica 2017], but our algorithm is somewhat simpler, due to a better use\nof word-RAM model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 18:55:23 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 00:12:44 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Gold", "Omer", ""], ["Sharir", "Micha", ""]]}, {"id": "1512.05839", "submitter": "Giulio Chiribella", "authors": "Giulio Chiribella and Yuxiang Yang", "title": "Quantum superreplication of states and gates", "comments": "22 pages, 4 figures, published version", "journal-ref": "Frontiers of Physics 11(3), 110304 (2016)", "doi": "10.1007/s11467-016-0556-7", "report-no": null, "categories": "quant-ph cs.CC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the no-cloning theorem forbids the perfect replication of quantum\ninformation, it is sometimes possible to produce large numbers of replicas with\nvanishingly small error. This phenomenon, known as quantum superreplication,\ncan take place both for quantum states and quantum gates. The aim of this paper\nis to review the central features of quantum superreplication, providing a\nunified view on the existing results. The paper also includes new results. In\nparticular, we show that, when quantum superreplication can be achieved, it can\nbe achieved through estimation, up to an error vanishing with a power law.\nQuantum strategies still offer an advantage for superreplication, in that they\nallow for an exponentially faster reduction of the error. Using the relation\nwith estimation, we provide i) an alternative proof of the optimality of the\nHeisenberg scaling of quantum metrology, ii) a strategy to estimate arbitrary\nunitary gates with Heisenberg scaling, up to a logarithmic overhead, and iii) a\nprotocol that generates M nearly perfect copies of a generic pure state with a\nnumber of queries to the corresponding unitary gate scaling as the square root\nof M. Finally, we point out that superreplication can be achieved using\ninteractions among k systems, provided that k is large compared to square of\nthe ratio between the numbers of input and output copies.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 01:12:51 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2016 10:37:31 GMT"}, {"version": "v3", "created": "Sun, 13 Mar 2016 09:17:35 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Chiribella", "Giulio", ""], ["Yang", "Yuxiang", ""]]}, {"id": "1512.05948", "submitter": "Laurent Bartholdi", "authors": "Laurent Bartholdi, Dzmitry Dudko", "title": "Algorithmic aspects of branched coverings", "comments": "60-page announcement of 5-part text, to apper in Ann. Fac. Sci.\n  Toulouse. Minor typos corrected, and major rewrite of section 7.8, which was\n  studying a different map than claimed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.DS math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the announcement, and the long summary, of a series of articles on\nthe algorithmic study of Thurston maps. We describe branched coverings of the\nsphere in terms of group-theoretical objects called bisets, and develop a\ntheory of decompositions of bisets.\n  We introduce a canonical \"Levy\" decomposition of an arbitrary Thurston map\ninto homeomorphisms, metrically-expanding maps and maps doubly covered by torus\nendomorphisms. The homeomorphisms decompose themselves into finite-order and\npseudo-Anosov maps, and the expanding maps decompose themselves into rational\nmaps.\n  As an outcome, we prove that it is decidable when two Thurston maps are\nequivalent. We also show that the decompositions above are computable, both in\ntheory and in practice.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 13:38:15 GMT"}, {"version": "v2", "created": "Sun, 16 Oct 2016 20:13:40 GMT"}, {"version": "v3", "created": "Mon, 19 Jun 2017 08:54:57 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Bartholdi", "Laurent", ""], ["Dudko", "Dzmitry", ""]]}, {"id": "1512.05996", "submitter": "Christian Kudahl", "authors": "Dennis Komm, Rastislav Kr\\'alovi\\v{c}, Richard Kr\\'alovi\\v{c}, and\n  Christian Kudahl", "title": "Advice Complexity of the Online Induced Subgraph Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several well-studied graph problems aim to select a largest (or smallest)\ninduced subgraph with a given property of the input graph. Examples of such\nproblems include maximum independent set, maximum planar graph, and many\nothers. We consider these problems, where the vertices are presented online.\nWith each vertex, the online algorithm must decide whether to include it into\nthe constructed subgraph, based only on the subgraph induced by the vertices\npresented so far. We study the properties that are common to all these problems\nby investigating the generalized problem: for a hereditary property \\pty, find\nsome maximal induced subgraph having \\pty. We study this problem from the point\nof view of advice complexity. Using a result from Boyar et al. [STACS 2015], we\ngive a tight trade-off relationship stating that for inputs of length n roughly\nn/c bits of advice are both needed and sufficient to obtain a solution with\ncompetitive ratio c, regardless of the choice of \\pty, for any c (possibly a\nfunction of n). Surprisingly, a similar result cannot be obtained for the\nsymmetric problem: for a given cohereditary property \\pty, find a minimum\nsubgraph having \\pty. We show that the advice complexity of this problem varies\nsignificantly with the choice of \\pty.\n  We also consider preemptive online model, where the decision of the algorithm\nis not completely irreversible. In particular, the algorithm may discard some\nvertices previously assigned to the constructed set, but discarded vertices\ncannot be reinserted into the set again. We show that, for the maximum induced\nsubgraph problem, preemption cannot help much, giving a lower bound of\n$\\Omega(n/(c^2\\log c))$ bits of advice needed to obtain competitive ratio $c$,\nwhere $c$ is any increasing function bounded by \\sqrt{n/log n}. We also give a\nlinear lower bound for c close to 1.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 15:41:34 GMT"}], "update_date": "2015-12-21", "authors_parsed": [["Komm", "Dennis", ""], ["Kr\u00e1lovi\u010d", "Rastislav", ""], ["Kr\u00e1lovi\u010d", "Richard", ""], ["Kudahl", "Christian", ""]]}, {"id": "1512.06657", "submitter": "Pu Gao", "authors": "Pu Gao and Michael Molloy", "title": "Inside the clustering window for random linear equations", "comments": "25 pages. A major part of this paper has appeared in the preprint\n  arXiv:1309.6651", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a random system of cn linear equations over n variables in GF(2),\nwhere each equation contains exactly r variables; this is equivalent to\nr-XORSAT. Previous work has established a clustering threshold, c^*_r for this\nmodel: if c=c_r^*-\\epsilon for any constant \\epsilon>0 then with high\nprobability all solutions form a well-connected cluster; whereas if\nc=c^*_r+\\epsilon, then with high probability the solutions partition into\nwell-connected, well-separated clusters (with probability tending to 1 as n\ngoes to infinity). This is part of a general clustering phenomenon which is\nhypothesized to arise in most of the commonly studied models of random\nconstraint satisfaction problems, via sophisticated but mostly non-rigorous\ntechniques from statistical physics. We extend that study to the range\nc=c^*_r+o(1), and prove that the connectivity parameters of the r-XORSAT\nclusters undergo a smooth transition around the clustering threshold.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 03:16:39 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2017 00:00:04 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Gao", "Pu", ""], ["Molloy", "Michael", ""]]}, {"id": "1512.06678", "submitter": "Aur\\'elien Ooms", "authors": "Jean Cardinal and John Iacono and Aur\\'elien Ooms", "title": "Solving $k$-SUM using few linear queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-SUM problem is given $n$ input real numbers to determine whether any\n$k$ of them sum to zero. The problem is of tremendous importance in the\nemerging field of complexity theory within $P$, and it is in particular open\nwhether it admits an algorithm of complexity $O(n^c)$ with $c<\\lceil\n\\frac{k}{2} \\rceil$. Inspired by an algorithm due to Meiser (1993), we show\nthat there exist linear decision trees and algebraic computation trees of depth\n$O(n^3\\log^3 n)$ solving $k$-SUM. Furthermore, we show that there exists a\nrandomized algorithm that runs in $\\tilde{O}(n^{\\lceil \\frac{k}{2} \\rceil+8})$\ntime, and performs $O(n^3\\log^3 n)$ linear queries on the input. Thus, we show\nthat it is possible to have an algorithm with a runtime almost identical (up to\nthe $+8$) to the best known algorithm but for the first time also with the\nnumber of queries on the input a polynomial that is independent of $k$. The\n$O(n^3\\log^3 n)$ bound on the number of linear queries is also a tighter bound\nthan any known algorithm solving $k$-SUM, even allowing unlimited total time\noutside of the queries. By simultaneously achieving few queries to the input\nwithout significantly sacrificing runtime vis-\\`{a}-vis known algorithms, we\ndeepen the understanding of this canonical problem which is a cornerstone of\ncomplexity-within-$P$.\n  We also consider a range of tradeoffs between the number of terms involved in\nthe queries and the depth of the decision tree. In particular, we prove that\nthere exist $o(n)$-linear decision trees of depth $o(n^4)$.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 16:07:35 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2016 10:57:33 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Cardinal", "Jean", ""], ["Iacono", "John", ""], ["Ooms", "Aur\u00e9lien", ""]]}, {"id": "1512.07009", "submitter": "Alexandr Kazda", "authors": "Libor Barto, Alexandr Kazda", "title": "Deciding absorption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize absorption in finite idempotent algebras by means of\nJ\\'onsson absorption and cube term blockers. As an application we show that it\nis decidable whether a given subset is an absorbing subuniverse of an algebra\ngiven by the tables of its basic operations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 10:00:47 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Barto", "Libor", ""], ["Kazda", "Alexandr", ""]]}, {"id": "1512.07450", "submitter": "Hector Zenil", "authors": "Alyssa Adams, Hector Zenil, Eduardo Hermo Reyes, Joost Joosten", "title": "Interacting Behavior and Emerging Complexity", "comments": "11 pages, 5 figures (in this version a minor typo corrected).\n  Presented at AUTOMATA 2015 forthcoming in journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CC nlin.CG q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we quantify the change of complexity throughout evolutionary processes?\nWe attempt to address this question through an empirical approach. In very\ngeneral terms, we simulate two simple organisms on a computer that compete over\nlimited available resources. We implement Global Rules that determine the\ninteraction between two Elementary Cellular Automata on the same grid. Global\nRules change the complexity of the state evolution output which suggests that\nsome complexity is intrinsic to the interaction rules themselves. The largest\nincreases in complexity occurred when the interacting elementary rules had very\nlittle complexity, suggesting that they are able to accept complexity through\ninteraction only. We also found that some Class 3 or 4 CA rules are more\nfragile than others to Global Rules, while others are more robust, hence\nsuggesting some intrinsic properties of the rules independent of the Global\nRule choice. We provide statistical mappings of Elementary Cellular Automata\nexposed to Global Rules and different initial conditions onto different\ncomplexity classes.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 12:29:01 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2015 01:13:46 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2016 18:21:46 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Adams", "Alyssa", ""], ["Zenil", "Hector", ""], ["Reyes", "Eduardo Hermo", ""], ["Joosten", "Joost", ""]]}, {"id": "1512.07617", "submitter": "Eliahu Cohen", "authors": "Boaz Tamir and Eliahu Cohen", "title": "Notes on Adiabatic Quantum Computers", "comments": "To be published as an 'Additional Note' in the book entitled 'Quantum\n  Spin-glasses, Annealing & Computation', by S. Tanaka, R. Tamura & B. K.\n  Chakrabarti, Cambridge University Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss in this chapter the basics of adiabatic computation, as well as\nsome physical implementations. After a short introduction of the quantum\ncircuit model, we describe quantum adiabatic computation, quantum annealing,\nand the strong relations between the three. We conclude with a brief\npresentation of the D-Wave computer and some future challenges.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 20:23:22 GMT"}, {"version": "v2", "created": "Mon, 21 Mar 2016 20:03:03 GMT"}, {"version": "v3", "created": "Sun, 8 May 2016 19:34:43 GMT"}, {"version": "v4", "created": "Wed, 7 Dec 2016 21:37:58 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Tamir", "Boaz", ""], ["Cohen", "Eliahu", ""]]}, {"id": "1512.07892", "submitter": "Dax Enshan Koh", "authors": "Dax Enshan Koh", "title": "Further extensions of Clifford circuits and their classical simulation\n  complexities", "comments": "19 pages, 3 figures", "journal-ref": "Quantum Information and Computation, Vol. 17, No. 3&4 (2017)\n  0262-0282", "doi": "10.26421/QIC17.3-4-5", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extended Clifford circuits straddle the boundary between classical and\nquantum computational power. Whether such circuits are efficiently classically\nsimulable seems to depend delicately on the ingredients of the circuits. While\nsome combinations of ingredients lead to efficiently classically simulable\ncircuits, other combinations, which might just be slightly different, lead to\ncircuits which are likely not. We extend the results of Jozsa and Van den Nest\n[Quant. Info. Comput. 14, 633 (2014)] by studying two further extensions of\nClifford circuits. First, we consider how the classical simulation complexity\nchanges when we allow for more general measurements. Second, we investigate\ndifferent notions of what it means to \"classically simulate\" a quantum circuit.\nThese further extensions give us 24 new combinations of ingredients compared to\nJozsa and Van den Nest, and we give a complete classification of their\nclassical simulation complexities. Our results provide more examples where\nseemingly modest changes to the ingredients of Clifford circuits lead to\n\"large\" changes in the classical simulation complexities of the circuits, and\nalso include new examples of extended Clifford circuits that exhibit \"quantum\nsupremacy\", in the sense that it is not possible to efficiently classically\nsample from the output distributions of such circuits, unless the polynomial\nhierarchy collapses.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 19:42:32 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 03:36:45 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Koh", "Dax Enshan", ""]]}, {"id": "1512.08554", "submitter": "Hendrik Schawe", "authors": "Hendrik Schawe and Alexander K. Hartmann", "title": "Phase Transitions of Traveling Salesperson Problems solved with Linear\n  Programming and Cutting Planes", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": "10.1209/0295-5075/113/30004", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Traveling Salesperson problem asks for the shortest cyclic tour visiting\na set of cities given their pairwise distances and belongs to the NP-hard\ncomplexity class, which means that with all known algorithms in the worst case\ninstances are not solveable in polynomial time, i.e., the problem is hard.\nThough that does not mean, that there are not subsets of the problem which are\neasy to solve. To examine numerically transitions from an easy to a hard phase,\na random ensemble of cities in the Euclidean plane given a parameter {\\sigma},\nwhich governs the hardness, is introduced. Here, a linear programming approach\ntogether with suitable cutting planes is applied. Such algorithms operate\noutside the space of feasible solutions and are often used in practical\napplication but rarely studied in physics so far. We observe several\ntransitions. To characterize these transitions, scaling assumptions from\ncontinuous phase transitions are applied\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 23:10:18 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Schawe", "Hendrik", ""], ["Hartmann", "Alexander K.", ""]]}, {"id": "1512.08716", "submitter": "Ohad Asor", "authors": "Ohad Asor and Avishy Carmi", "title": "On Approximating Univariate NP-Hard Integrals", "comments": "Need to show more evidence to the claims", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximating a definite integral of product of cosines to within an accuracy\nof n binary digits where the integrand depends on input integers x[k] given in\nbinary radix, is equivalent to counting the number of equal-sum partitions of\nthe integers and is thus a #P problem. Similarly, integrating this function\nfrom zero to infinity and deciding whether the result is either zero or\ninfinity is an NP-Complete problem. Efficient numerical integration methods\nsuch as the double exponential formula and the sinc approximation have been\naround since the mid 70's. Noting the hardness of approximating the integral we\nargue that the proven rates of convergence of such methods cannot possibly be\ncorrect since they give rise to an anomalous result as P=#P.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2015 22:20:24 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2016 07:12:23 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2016 09:56:48 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Asor", "Ohad", ""], ["Carmi", "Avishy", ""]]}, {"id": "1512.08863", "submitter": "Shengjia Zhao", "authors": "Shengjia Zhao, Sorathan Chaturapruek, Ashish Sabharwal, Stefano Ermon", "title": "Closing the Gap Between Short and Long XORs for Model Counting", "comments": "The 30th Association for the Advancement of Artificial Intelligence\n  (AAAI-16) Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent algorithms for approximate model counting are based on a\nreduction to combinatorial searches over random subsets of the space defined by\nparity or XOR constraints. Long parity constraints (involving many variables)\nprovide strong theoretical guarantees but are computationally difficult. Short\nparity constraints are easier to solve but have weaker statistical properties.\nIt is currently not known how long these parity constraints need to be. We\nclose the gap by providing matching necessary and sufficient conditions on the\nrequired asymptotic length of the parity constraints. Further, we provide a new\nfamily of lower bounds and the first non-trivial upper bounds on the model\ncount that are valid for arbitrarily short XORs. We empirically demonstrate the\neffectiveness of these bounds on model counting benchmarks and in a\nSatisfiability Modulo Theory (SMT) application motivated by the analysis of\ncontingency tables in statistics.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 06:41:29 GMT"}, {"version": "v2", "created": "Fri, 9 Sep 2016 03:37:53 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Zhao", "Shengjia", ""], ["Chaturapruek", "Sorathan", ""], ["Sabharwal", "Ashish", ""], ["Ermon", "Stefano", ""]]}, {"id": "1512.09080", "submitter": "Emmanuel Abbe A", "authors": "Emmanuel Abbe and Colin Sandon", "title": "Detection in the stochastic block model with multiple clusters: proof of\n  the achievability conjectures, acyclic BP, and the information-computation\n  gap", "comments": "Extended version with further details on the algorithms and methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC cs.IT cs.LG cs.SI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a paper that initiated the modern study of the stochastic block model,\nDecelle et al., backed by Mossel et al., made the following conjecture: Denote\nby $k$ the number of balanced communities, $a/n$ the probability of connecting\ninside communities and $b/n$ across, and set\n$\\mathrm{SNR}=(a-b)^2/(k(a+(k-1)b)$; for any $k \\geq 2$, it is possible to\ndetect communities efficiently whenever $\\mathrm{SNR}>1$ (the KS threshold),\nwhereas for $k\\geq 4$, it is possible to detect communities\ninformation-theoretically for some $\\mathrm{SNR}<1$. Massouli\\'e, Mossel et\nal.\\ and Bordenave et al.\\ succeeded in proving that the KS threshold is\nefficiently achievable for $k=2$, while Mossel et al.\\ proved that it cannot be\ncrossed information-theoretically for $k=2$. The above conjecture remained open\nfor $k \\geq 3$.\n  This paper proves this conjecture, further extending the efficient detection\nto non-symmetrical SBMs with a generalized notion of detection and KS\nthreshold. For the efficient part, a linearized acyclic belief propagation\n(ABP) algorithm is developed and proved to detect communities for any $k$ down\nto the KS threshold in time $O(n \\log n)$. Achieving this requires showing\noptimality of ABP in the presence of cycles, a challenge for message passing\nalgorithms. The paper further connects ABP to a power iteration method with a\nnonbacktracking operator of generalized order, formalizing the interplay\nbetween message passing and spectral methods. For the information-theoretic\n(IT) part, a non-efficient algorithm sampling a typical clustering is shown to\nbreak down the KS threshold at $k=4$. The emerging gap is shown to be large in\nsome cases; if $a=0$, the KS threshold reads $b \\gtrsim k^2$ whereas the IT\nbound reads $b \\gtrsim k \\ln(k)$, making the SBM a good study-case for\ninformation-computation gaps.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 19:49:28 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2016 20:34:42 GMT"}, {"version": "v3", "created": "Tue, 14 Jun 2016 15:16:39 GMT"}, {"version": "v4", "created": "Thu, 15 Sep 2016 02:04:27 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Abbe", "Emmanuel", ""], ["Sandon", "Colin", ""]]}, {"id": "1512.09243", "submitter": "Saeed Mehraban", "authors": "Saeed Mehraban", "title": "Computational Complexity of Some Quantum Theories in $1+1$ Dimensions", "comments": "The material presented here is based on the author's Master's thesis,\n  advised by Scott Aaronson, submitted to the department of electrical\n  engineering and computer science at MIT on August 28, 2015. Editions and\n  modifications has been made to the original thesis, also a new chapter,\n  chapter 4 is added", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of certain integrable quantum theories\nin 1+1 dimensions. We formalize a model of quantum computation based on these\ntheories. In this model, distinguishable particles start out with known momenta\nand initial superposition of different configurations. Then the label of these\nparticles are measured at the end. We prove that additive approximation to\nsingle amplitudes of these models can be obtained by the one-clean-qubit model,\nif no initial superpositions are allowed. However, if arbitrary initial states\nand non-adaptive intermediate measurements are allowed, we show that\nconditioned on infinite polynomial hierarchy assumption it is hard to sample\nfrom the output distribution of these models on a classical randomized\ncomputer. A classical analogue of this model is also formalized and its\ncomputational power is pinned down within the complexity classes below BPP and\nNP.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 09:16:21 GMT"}], "update_date": "2016-01-01", "authors_parsed": [["Mehraban", "Saeed", ""]]}, {"id": "1512.09363", "submitter": "Valmir Barbosa", "authors": "Fabiano de S. Oliveira, Valmir C. Barbosa", "title": "Counting independent terms in big-oh notation", "comments": null, "journal-ref": "Optimization Letters 11 (2017), 1757-1765", "doi": "10.1007/s11590-016-1092-7", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of computational complexity is concerned both with the intrinsic\nhardness of computational problems and with the efficiency of algorithms to\nsolve them. Given such a problem, normally one designs an algorithm to solve it\nand sets about establishing bounds on its performance as functions of the\nalgorithm's variables, particularly upper bounds expressed via the big-oh\nnotation. But if we were given some inscrutable code and were asked to figure\nout its big-oh profile from performance data on a given set of inputs, how hard\nwould we have to grapple with the various possibilities before zooming in on a\nreasonably small set of candidates? Here we show that, even if we restricted\nour search to upper bounds given by polynomials, the number of possibilities\ncould be arbitrarily large for two or more variables. This is unexpected, given\nthe available body of examples on algorithmic efficiency, and serves to\nillustrate the many facets of the big-oh notation, as well as its\ncounter-intuitive twists.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 20:47:11 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Oliveira", "Fabiano de S.", ""], ["Barbosa", "Valmir C.", ""]]}]