[{"id": "1409.0375", "submitter": "Anatoly Panyukov", "authors": "Anatoly Panyukov", "title": "Polynomial solvability of $NP$-complete problems", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ${ NP}$-complete problem \"Hamiltonian cycle\"\\ for graph $G=(V,E)$ is extended\nto the \"Hamiltonian Complement of the Graph\"\\ problem of finding the minimal\ncardinality set $H$ containing additional edges so that graph $G=(V,E\\cup H)$\nis Hamiltonian. The solving of \"Hamiltonian Complement of a Graph\"\\ problem is\nreduced to the linear programming problem {\\bf P}, which has an optimal integer\nsolution. The optimal integer solution of {\\bf P} is found for any its optimal\nsolution by solving the linear assignment problem {\\bf L}. The existence of\npolynomial algorithms for problems {\\bf P} and {\\bf L} proves the polynomial\nsolvability of ${ NP}$-complete problems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 12:02:51 GMT"}, {"version": "v2", "created": "Thu, 4 Sep 2014 15:58:33 GMT"}, {"version": "v3", "created": "Sun, 23 Nov 2014 06:21:47 GMT"}, {"version": "v4", "created": "Mon, 6 Nov 2017 20:34:35 GMT"}, {"version": "v5", "created": "Fri, 24 Aug 2018 11:48:58 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Panyukov", "Anatoly", ""]]}, {"id": "1409.0451", "submitter": "Amaury Pouly", "authors": "Amaury Pouly, Daniel S. Gra\\c{c}a", "title": "Computational complexity of solving polynomial differential equations\n  over unbounded domains", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2016.02.002", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the computational complexity of solving ordinary\ndifferential equations (ODEs) $y^{\\prime}=p(y)$ over \\emph{unbounded time\ndomains}, where $p$ is a vector of polynomials. Contrarily to the bounded\n(compact) time case, this problem has not been well-studied, apparently due to\nthe \"intuition\" that it can always be reduced to the bounded case by using\nrescaling techniques. However, as we show in this paper, rescaling techniques\ndo not seem to provide meaningful insights on the complexity of this problem,\nsince the use of such techniques introduces a dependence on parameters which\nare hard to compute.\n  We present algorithms which numerically solve these ODEs over unbounded time\ndomains. These algorithms have guaranteed accuracy, i.e. given some arbitrarily\nlarge time $t$ and error bound $\\varepsilon$ as input, they will output a value\n$\\tilde{y}$ which satisfies $\\|y(t)-\\tilde{y}\\|\\leq\\varepsilon$. We analyze the\ncomplexity of these algorithms and show that they compute $\\tilde{y}$ in time\npolynomial in several quantities including the time $t$, the accuracy of the\noutput $\\varepsilon$ and the length of the curve $y$ from $0$ to $t$, assuming\nit exists until time $t$. We consider both algebraic complexity and bit\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 15:22:54 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2015 15:38:50 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2016 17:52:19 GMT"}, {"version": "v4", "created": "Wed, 4 May 2016 17:21:51 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Pouly", "Amaury", ""], ["Gra\u00e7a", "Daniel S.", ""]]}, {"id": "1409.0496", "submitter": "Marius Zimand", "authors": "Jason Teutsch and Marius Zimand", "title": "On approximate decidability of minimal programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An index $e$ in a numbering of partial-recursive functions is called minimal\nif every lesser index computes a different function from $e$. Since the 1960's\nit has been known that, in any reasonable programming language, no effective\nprocedure determines whether or not a given index is minimal. We investigate\nwhether the task of determining minimal indices can be solved in an approximate\nsense. Our first question, regarding the set of minimal indices, is whether\nthere exists an algorithm which can correctly label 1 out of $k$ indices as\neither minimal or non-minimal. Our second question, regarding the function\nwhich computes minimal indices, is whether one can compute a short list of\ncandidate indices which includes a minimal index for a given program. We give\nsome negative results and leave the possibility of positive results as open\nquestions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 18:10:29 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Teutsch", "Jason", ""], ["Zimand", "Marius", ""]]}, {"id": "1409.0742", "submitter": "Christian Engels", "authors": "Christian Engels and B. V. Raghavendra Rao", "title": "New Algorithms and Hard Instances for Non-Commutative Computation", "comments": "Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the recent developments on the complexity of\nnon-com\\-mu\\-ta\\-tive determinant and permanent [Chien et al.\\ STOC 2011,\nBl\\\"aser ICALP 2013, Gentry CCC 2014] we attempt at obtaining a tight\ncharacterization of hard instances of non-commutative permanent.\n  We show that computing Cayley permanent and determinant on weight\\-ed\nadjacency matrices of graphs of component size six is $\\#{\\sf P}$ complete on\nalgebras that contain $2\\times 2$ matrices and the permutation group $S_3$.\nAlso, we prove a lower bound of $2^{\\Omega(n)}$ on the size of branching\nprograms computing the Cayley permanent on adjacency matrices of graphs with\ncomponent size bounded by two. Further, we observe that the lower bound holds\nfor almost all graphs of component size two.\n  On the positive side, we show that the Cayley permanent on graphs of\ncomponent size $c$ can be computed in time $n^{c{\\sf poly}(t)}$, where $t$ is a\nparameter depending on the labels of the vertices.\n  Finally, we exhibit polynomials that are equivalent to the Cayley permanent\npolynomial but are easy to compute over commutative domains.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 15:05:07 GMT"}, {"version": "v2", "created": "Tue, 7 Oct 2014 15:05:38 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2015 09:34:37 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Engels", "Christian", ""], ["Rao", "B. V. Raghavendra", ""]]}, {"id": "1409.1060", "submitter": "Willem Fouch\\'e", "authors": "Willem L. Fouche", "title": "Kolmogorov complexity and the geometry of Brownian motion", "comments": "Paper accepted by Mathematical Structures in Computer Science", "journal-ref": "Math. Struct. Comp. Sci. 25 (2015) 1590-1606", "doi": "10.1017/S0960129513000273", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we continue the study of the geometry of Brownian motions\nwhich are encoded by Kolmogorov-Chaitin random reals (complex oscillations). We\nunfold Kolmogorov-Chaitin complexity in the context of Brownian motion and\nspecifically to phenomena emerging from the random geometric patterns generated\nby a Brownian motion.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 12:30:24 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Fouche", "Willem L.", ""]]}, {"id": "1409.1397", "submitter": "Tali  Kaufman", "authors": "Tali Kaufman, David Kazhdan, Alexander Lubotzky", "title": "Isoperimetric Inequalities for Ramanujan Complexes and Topological\n  Expanders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC math.GR math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expander graphs have been intensively studied in the last four decades. In\nrecent years a high dimensional theory of expanders has emerged, and several\nvariants have been studied. Among them stand out coboundary expansion and\ntopological expansion. It is known that for every $d$ there are unbounded\ndegree simplicial complexes of dimension $d$ with these properties. However, a\nmajor open problem, formulated by Gromov, is whether bounded degree high\ndimensional expanders exist for $d \\geq 2$.\n  We present an explicit construction of bounded degree complexes of dimension\n$d=2$ which are topological expanders, thus answering Gromov's question in the\naffirmative. Conditional on a conjecture of Serre on the congruence subgroup\nproperty, infinite sub-family of these give also a family of bounded degree\ncoboundary expanders.\n  The main technical tools are new isoperimetric inequalities for Ramanujan\nComplexes. We prove linear size bounds on $F_2$ systolic invariants of these\ncomplexes, which seem to be the first linear $F_2$ systolic bounds. The\nexpansion results are deduced from these isoperimetric inequalities.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 11:05:11 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Kaufman", "Tali", ""], ["Kazhdan", "David", ""], ["Lubotzky", "Alexander", ""]]}, {"id": "1409.1534", "submitter": "Saugata Basu", "authors": "Saugata Basu", "title": "Algorithms in Real Algebraic Geometry: A Survey", "comments": "41 pages, 4 figures. Based on survey talk given at the Real Algebraic\n  Geometry Conference, Rennes, June 20-24, 2011. Some references updated and\n  some newer material added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC cs.CG cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey both old and new developments in the theory of algorithms in real\nalgebraic geometry -- starting from effective quantifier elimination in the\nfirst order theory of reals due to Tarski and Seidenberg, to more recent\nalgorithms for computing topological invariants of semi-algebraic sets. We\nemphasize throughout the complexity aspects of these algorithms and also\ndiscuss the computational hardness of the underlying problems. We also describe\nsome recent results linking the computational hardness of decision problems in\nthe first order theory of the reals, with that of computing certain topological\ninvariants of semi-algebraic sets. Even though we mostly concentrate on exact\nalgorithms, we also discuss some numerical approaches involving semi-definite\nprogramming that have gained popularity in recent times.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 19:00:00 GMT"}], "update_date": "2014-09-05", "authors_parsed": [["Basu", "Saugata", ""]]}, {"id": "1409.2170", "submitter": "Michael Pinsker", "authors": "Manuel Bodirsky, David Bradley-Williams, Michael Pinsker, Andr\\'as\n  Pongr\\'acz", "title": "The universal homogeneous binary tree", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A partial order is called semilinear iff the upper bounds of each element are\nlinearly ordered and any two elements have a common upper bound. There exists,\nup to isomorphism, a unique countable existentially closed semilinear order,\nwhich we denote by S2. We study the reducts of S2, that is, the relational\nstructures with the same domain as S2 all of whose relations are first-order\ndefinable in S2. Our main result is a classification of the model-complete\ncores of the reducts of S2. From this, we also obtain a classification of\nreducts up to first-order interdefinability, which is equivalent to a\nclassification of all closed permutation groups that contain the automorphism\ngroup of S2.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 21:51:21 GMT"}, {"version": "v2", "created": "Thu, 26 Feb 2015 08:53:02 GMT"}, {"version": "v3", "created": "Mon, 18 Apr 2016 12:36:51 GMT"}, {"version": "v4", "created": "Sat, 12 Nov 2016 19:04:11 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Bradley-Williams", "David", ""], ["Pinsker", "Michael", ""], ["Pongr\u00e1cz", "Andr\u00e1s", ""]]}, {"id": "1409.2290", "submitter": "Alaa Saade", "authors": "Aur\\'elien Decelle, Janina H\\\"uttel, Alaa Saade, Cristopher Moore", "title": "Computational Complexity, Phase Transitions, and Message-Passing for\n  Community Detection", "comments": "Chapter of \"Statistical Physics, Optimization, Inference, and\n  Message-Passing Algorithms\", Eds.: F. Krzakala, F. Ricci-Tersenghi, L.\n  Zdeborova, R. Zecchina, E. W. Tramel, L. F. Cugliandolo (Oxford University\n  Press, to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.CC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take a whirlwind tour of problems and techniques at the boundary of\ncomputer science and statistical physics. We start with a brief description of\nP, NP, and NP-completeness. We then discuss random graphs, including the\nemergence of the giant component and the k-core, using techniques from\nbranching processes and differential equations. Using these tools as well as\nthe second moment method, we give upper and lower bounds on the critical clause\ndensity for random k-SAT. We end with community detection in networks,\nvariational methods, the Bethe free energy, belief propagation, the\ndetectability transition, and the non-backtracking matrix.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 10:51:55 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Decelle", "Aur\u00e9lien", ""], ["H\u00fcttel", "Janina", ""], ["Saade", "Alaa", ""], ["Moore", "Cristopher", ""]]}, {"id": "1409.2398", "submitter": "Sebastian Ordyniak", "authors": "Sebastian Ordyniak and Alexandru Popa", "title": "A Parameterized Study of Maximum Generalized Pattern Matching Problems", "comments": "to appear in Proc. IPEC'14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized function matching (GFM) problem has been intensively studied\nstarting with [Ehrenfeucht and Rozenberg, 1979]. Given a pattern p and a text\nt, the goal is to find a mapping from the letters of p to non-empty substrings\nof t, such that applying the mapping to p results in t. Very recently, the\nproblem has been investigated within the framework of parameterized complexity\n[Fernau, Schmid, and Villanger, 2013].\n  In this paper we study the parameterized complexity of the optimization\nvariant of GFM (called Max-GFM), which has been introduced in [Amir and Nor,\n2007]. Here, one is allowed to replace some of the pattern letters with some\nspecial symbols \"?\", termed wildcards or don't cares, which can be mapped to an\narbitrary substring of the text. The goal is to minimize the number of\nwildcards used.\n  We give a complete classification of the parameterized complexity of Max-GFM\nand its variants under a wide range of parameterizations, such as, the number\nof occurrences of a letter in the text, the size of the text alphabet, the\nnumber of occurrences of a letter in the pattern, the size of the pattern\nalphabet, the maximum length of a string matched to any pattern letter, the\nnumber of wildcards and the maximum size of a string that a wildcard can be\nmapped to.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 15:34:32 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Ordyniak", "Sebastian", ""], ["Popa", "Alexandru", ""]]}, {"id": "1409.2426", "submitter": "Jed Yang", "authors": "Jed Yang", "title": "Some NP-complete edge packing and partitioning problems in planar graphs", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph packing and partitioning problems have been studied in many contexts,\nincluding from the algorithmic complexity perspective. Consider the packing\nproblem of determining whether a graph contains a spanning tree and a cycle\nthat do not share edges. Bern\\'ath and Kir\\'aly proved that this decision\nproblem is NP-complete and asked if the same result holds when restricting to\nplanar graphs. Similarly, they showed that the packing problem with a spanning\ntree and a path between two distinguished vertices is NP-complete. They also\nestablished the NP-completeness of the partitioning problem of determining\nwhether the edge set of a graph can be partitioned into a spanning tree and a\n(not-necessarily spanning) tree. We prove that all three problems remain\nNP-complete even when restricted to planar graphs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 16:49:45 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Yang", "Jed", ""]]}, {"id": "1409.2433", "submitter": "Antonina Kolokolova", "authors": "Antonina Kolokolova, Renesa Nizamee", "title": "Approximating solution structure of the Weighted Sentence Alignment\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of approximating solution structure of the bijective\nweighted sentence alignment problem of DeNero and Klein (2008). In particular,\nwe consider the complexity of finding an alignment that has a significant\noverlap with an optimal alignment. We discuss ways of representing the solution\nfor the general weighted sentence alignment as well as phrases-to-words\nalignment problem, and show that computing a string which agrees with the\noptimal sentence partition on more than half (plus an arbitrarily small\npolynomial fraction) positions for the phrases-to-words alignment is NP-hard.\nFor the general weighted sentence alignment we obtain such bound from the\nagreement on a little over 2/3 of the bits. Additionally, we generalize the\nHamming distance approximation of a solution structure to approximating it with\nrespect to the edit distance metric, obtaining similar lower bounds.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 17:19:11 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Kolokolova", "Antonina", ""], ["Nizamee", "Renesa", ""]]}, {"id": "1409.2731", "submitter": "Jakob Nordstr\\\"om", "authors": "Albert Atserias, Massimo Lauria, Jakob Nordstr\\\"om", "title": "Narrow Proofs May Be Maximally Long", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that there are 3-CNF formulas over n variables that can be refuted\nin resolution in width w but require resolution proofs of size n^Omega(w). This\nshows that the simple counting argument that any formula refutable in width w\nmust have a proof in size n^O(w) is essentially tight. Moreover, our lower\nbound generalizes to polynomial calculus resolution (PCR) and Sherali-Adams,\nimplying that the corresponding size upper bounds in terms of degree and rank\nare tight as well. Our results do not extend all the way to Lasserre, however,\nwhere the formulas we study have proofs of constant rank and size polynomial in\nboth n and w.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 13:33:09 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Atserias", "Albert", ""], ["Lauria", "Massimo", ""], ["Nordstr\u00f6m", "Jakob", ""]]}, {"id": "1409.2978", "submitter": "Jakob Nordstr\\\"om", "authors": "Yuval Filmus, Massimo Lauria, Mladen Mik\\v{s}a, Jakob Nordstr\\\"om,\n  Marc Vinyals", "title": "From Small Space to Small Width in Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2003, Atserias and Dalmau resolved a major open question about the\nresolution proof system by establishing that the space complexity of CNF\nformulas is always an upper bound on the width needed to refute them. Their\nproof is beautiful but somewhat mysterious in that it relies heavily on tools\nfrom finite model theory. We give an alternative, completely elementary proof\nthat works by simple syntactic manipulations of resolution refutations. As a\nby-product, we develop a \"black-box\" technique for proving space lower bounds\nvia a \"static\" complexity measure that works against any resolution\nrefutation---previous techniques have been inherently adaptive. We conclude by\nshowing that the related question for polynomial calculus (i.e., whether space\nis an upper bound on degree) seems unlikely to be resolvable by similar\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2014 07:49:54 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Filmus", "Yuval", ""], ["Lauria", "Massimo", ""], ["Mik\u0161a", "Mladen", ""], ["Nordstr\u00f6m", "Jakob", ""], ["Vinyals", "Marc", ""]]}, {"id": "1409.3093", "submitter": "Gil Kalai", "authors": "Gil Kalai and Guy Kindler", "title": "Gaussian Noise Sensitivity and BosonSampling", "comments": "Version 2: A few corrections and additions", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sensitivity to noise of |permanent(X)|^2 for random real and\ncomplex n x n Gaussian matrices X, and show that asymptotically the correlation\nbetween the noisy and noiseless outcomes tends to zero when the noise level is\n{\\omega}(1)/n. This suggests that, under certain reasonable noise models, the\nprobability distributions produced by noisy BosonSampling are very sensitive to\nnoise. We also show that when the amount of noise is constant the noisy value\nof |permanent(X)|^2 can be approximated efficiently on a classical computer.\nThese results seem to weaken the possibility of demonstrating quantum-speedup\nvia BosonSampling without quantum fault-tolerance.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2014 14:47:40 GMT"}, {"version": "v2", "created": "Sat, 8 Nov 2014 20:29:15 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Kalai", "Gil", ""], ["Kindler", "Guy", ""]]}, {"id": "1409.3182", "submitter": "Sevag Gharibian", "authors": "Sevag Gharibian, Jamie Sikora", "title": "Ground state connectivity of local Hamiltonians", "comments": "31 pages; v3 is published journal version. Various minor updates over\n  v2, including observing that our QCMA-hardness result actually also holds for\n  frustration-free Hamiltonians (FF-GSCON). Thank you to anonymous referees for\n  their feedback", "journal-ref": "Proceedings of the 42nd International Colloquium on Automata,\n  Languages, and Programming (ICALP), volume 9134 of LNCS, p. 617-628, 2015,\n  and ACM Transactions on Computation Theory (TOCT), volume 10, issue 2, number\n  8, 2018", "doi": "10.1007/978-3-662-47672-7_50", "report-no": null, "categories": "quant-ph cond-mat.str-el cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of ground state energies of local Hamiltonians has played a\nfundamental role in quantum complexity theory. In this paper, we take a new\ndirection by introducing the physically motivated notion of \"ground state\nconnectivity\" of local Hamiltonians, which captures problems in areas ranging\nfrom quantum stabilizer codes to quantum memories. Roughly, \"ground state\nconnectivity\" corresponds to the natural question: Given two ground states\n|{\\psi}> and |{\\phi}> of a local Hamiltonian H, is there an \"energy barrier\"\n(with respect to H) along any sequence of local operations mapping |{\\psi}> to\n|{\\phi}>? We show that the complexity of this question can range from\nQCMA-complete to PSPACE-complete, as well as NEXP-complete for an appropriately\ndefined \"succinct\" version of the problem. As a result, we obtain a natural\nQCMA-complete problem, a goal which has generally proven difficult since the\nconception of QCMA over a decade ago. Our proofs rely on a new technical tool,\nthe Traversal Lemma, which analyzes the Hilbert space a local unitary evolution\nmust traverse under certain conditions. We show that this lemma is essentially\ntight with respect to the length of the unitary evolution in question.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2014 18:37:12 GMT"}, {"version": "v2", "created": "Thu, 19 Feb 2015 13:35:38 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 11:46:27 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Gharibian", "Sevag", ""], ["Sikora", "Jamie", ""]]}, {"id": "1409.3208", "submitter": "Juan Bermejo-Vega", "authors": "Juan Bermejo-Vega, Cedric Yen-Yu Lin and Maarten Van den Nest", "title": "Normalizer circuits and a Gottesman-Knill theorem for\n  infinite-dimensional systems", "comments": "54 pages + appendices. The discussion has been extended in this\n  version", "journal-ref": null, "doi": null, "report-no": "MIT-CTP/4583", "categories": "quant-ph cs.CC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\textit{Normalizer circuits}$ [1,2] are generalized Clifford circuits that\nact on arbitrary finite-dimensional systems $\\mathcal{H}_{d_1}\\otimes ...\n\\otimes \\mathcal{H}_{d_n}$ with a standard basis labeled by the elements of a\nfinite Abelian group $G=\\mathbb{Z}_{d_1}\\times... \\times \\mathbb{Z}_{d_n}$.\nNormalizer gates implement operations associated with the group $G$ and can be\nof three types: quantum Fourier transforms, group automorphism gates and\nquadratic phase gates. In this work, we extend the normalizer formalism [1,2]\nto infinite dimensions, by allowing normalizer gates to act on systems of the\nform $\\mathcal{H}_\\mathbb{Z}^{\\otimes a}$: each factor $\\mathcal{H}_\\mathbb{Z}$\nhas a standard basis labeled by $\\textit{integers}$ $\\mathbb{Z}$, and a Fourier\nbasis labeled by $\\textit{angles}$, elements of the circle group $\\mathbb{T}$.\nNormalizer circuits become hybrid quantum circuits acting both on continuous-\nand discrete-variable systems. We show that infinite-dimensional normalizer\ncircuits can be efficiently simulated classically with a generalized\n$\\textit{stabilizer formalism}$ for Hilbert spaces associated with groups of\nthe form $\\mathbb{Z}^a\\times \\mathbb{T}^b \\times\n\\mathbb{Z}_{d_1}\\times...\\times \\mathbb{Z}_{d_n}$. We develop new techniques to\ntrack stabilizer-groups based on normal forms for group automorphisms and\nquadratic functions. We use our normal forms to reduce the problem of\nsimulating normalizer circuits to that of finding general solutions of systems\nof mixed real-integer linear equations [3] and exploit this fact to devise a\nrobust simulation algorithm: the latter remains efficient even in pathological\ncases where stabilizer groups become infinite, uncountable and non-compact. The\ntechniques developed in this paper might find applications in the study of\nfault-tolerant quantum computation with superconducting qubits [4,5].\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2014 19:38:29 GMT"}, {"version": "v2", "created": "Tue, 20 Jan 2015 22:50:43 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Bermejo-Vega", "Juan", ""], ["Lin", "Cedric Yen-Yu", ""], ["Nest", "Maarten Van den", ""]]}, {"id": "1409.3319", "submitter": "Pattama Longani", "authors": "Pattama Longani", "title": "Square Grid Points Coveraged by Connected Sources with Coverage Radius\n  of One on a Two-Dimensional Grid", "comments": "20 pages, 10 figures, International Journal of Computer Science &\n  Information Technology (IJCSIT)", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 6, No 4, August 2014", "doi": "10.5121/ijcsit", "report-no": null, "categories": "cs.CC cs.NI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We take some parts of a theoretical mobility model in a two-dimension grid\nproposed by Greenlaw and Kantabutra to be our model. The model has eight\nnecessary factors that we commonly use in a mobile wireless network: sources or\nwireless signal providers, the directions that a source can move, users or\nmobile devices, the given directions which define a user's movement, the given\ndirections which define a source's movement, source's velocity, source's\ncoverage, and obstacles. However, we include only the sources, source's\ncoverage, and the obstacles in our model. We define Square Grid Points Coverage\n(SGPC) problem to minimize number of sources with coverage radius of one to\ncover a square grid point size of p with the restriction that all the sources\nmust be communicable and proof that SGPC is in NP-complete class. We also give\nan Approx-Square-Grid-Coverage (ASGC) algorithm to compute the approximate\nsolution of SGPC. ASGC uses the rule that any number can be obtained from the\naddition of 3, 4 and 5 and then combines 3-gadgets, 4-gadgets and 5-gadgets to\nspecify the position of sources to cover a square grid point size of p. We find\nthat the algorithm achieves an approximation ratio of . Moreover, we state\nabout the extension usage of our algorithm and show some examples. We show that\nif we use ASGC on a square grid size of p and if sources can be moved, the area\nunder the square grid can be covered in eight-time-steps movement. We also\nprove that if we extend our source coverage radius to 1.59, without any\nmovement the area under the square gird will also be covered. Further studies\nare also discussed and a list of some tentative problems is given in the\nconclusion.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2014 03:59:48 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Longani", "Pattama", ""]]}, {"id": "1409.3323", "submitter": "Shalev Ben-David", "authors": "Shalev Ben-David", "title": "The Structure of Promises in Quantum Speedups", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been known that in the usual black-box model, one cannot get\nsuper-polynomial quantum speedups without some promise on the inputs. In this\npaper, we examine certain types of symmetric promises, and show that they also\ncannot give rise to super-polynomial quantum speedups. We conclude that\nexponential quantum speedups only occur given \"structured\" promises on the\ninput.\n  Specifically, we show that there is a polynomial relationship of degree $12$\nbetween $D(f)$ and $Q(f)$ for any function $f$ defined on permutations\n(elements of $\\{0,1,\\dots, M-1\\}^n$ in which each alphabet element occurs\nexactly once). We generalize this result to all functions $f$ defined on orbits\nof the symmetric group action $S_n$ (which acts on an element of $\\{0,1,\\dots,\nM-1\\}^n$ by permuting its entries). We also show that when $M$ is constant, any\nfunction $f$ defined on a \"symmetric set\" - one invariant under $S_n$ -\nsatisfies $R(f)=O(Q(f)^{12(M-1)})$.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2014 04:44:45 GMT"}], "update_date": "2014-09-12", "authors_parsed": [["Ben-David", "Shalev", ""]]}, {"id": "1409.3558", "submitter": "Mathieu Brandeho BrandehoM", "authors": "Mathieu Brandeho and J\\'er\\'emie Roland", "title": "A universal adiabatic quantum query algorithm", "comments": "22 pages, compared to v1, includes a rigorous proof of the\n  correctness of the algorithm based on a version of the adiabatic theorem that\n  does not require a spectral gap", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum query complexity is known to be characterized by the so-called\nquantum adversary bound. While this result has been proved in the standard\ndiscrete-time model of quantum computation, it also holds for continuous-time\n(or Hamiltonian-based) quantum computation, due to a known equivalence between\nthese two query complexity models. In this work, we revisit this result by\nproviding a direct proof in the continuous-time model. One originality of our\nproof is that it draws new connections between the adversary bound, a modern\ntechnique of theoretical computer science, and early theorems of quantum\nmechanics. Indeed, the proof of the lower bound is based on Ehrenfest's\ntheorem, while the upper bound relies on the adiabatic theorem, as it goes by\nconstructing a universal adiabatic quantum query algorithm. Another originality\nis that we use for the first time in the context of quantum computation a\nversion of the adiabatic theorem that does not require a spectral gap.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2014 19:54:36 GMT"}, {"version": "v2", "created": "Mon, 16 Feb 2015 12:54:25 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2015 20:17:52 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Brandeho", "Mathieu", ""], ["Roland", "J\u00e9r\u00e9mie", ""]]}, {"id": "1409.3836", "submitter": "Guy Bresler", "authors": "Guy Bresler, David Gamarnik, and Devavrat Shah", "title": "Hardness of parameter estimation in graphical models", "comments": "15 pages. To appear in NIPS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.IT math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the canonical parameters specifying an\nundirected graphical model (Markov random field) from the mean parameters. For\ngraphical models representing a minimal exponential family, the canonical\nparameters are uniquely determined by the mean parameters, so the problem is\nfeasible in principle. The goal of this paper is to investigate the\ncomputational feasibility of this statistical task. Our main result shows that\nparameter estimation is in general intractable: no algorithm can learn the\ncanonical parameters of a generic pair-wise binary graphical model from the\nmean parameters in time bounded by a polynomial in the number of variables\n(unless RP = NP). Indeed, such a result has been believed to be true (see the\nmonograph by Wainwright and Jordan (2008)) but no proof was known.\n  Our proof gives a polynomial time reduction from approximating the partition\nfunction of the hard-core model, known to be hard, to learning approximate\nparameters. Our reduction entails showing that the marginal polytope boundary\nhas an inherent repulsive property, which validates an optimization procedure\nover the polytope that does not use any knowledge of its structure (as required\nby the ellipsoid method and others).\n", "versions": [{"version": "v1", "created": "Fri, 12 Sep 2014 19:57:59 GMT"}, {"version": "v2", "created": "Wed, 17 Sep 2014 19:57:51 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Bresler", "Guy", ""], ["Gamarnik", "David", ""], ["Shah", "Devavrat", ""]]}, {"id": "1409.3865", "submitter": "Vladimir Vyugin", "authors": "Vladimir V. V'yugin", "title": "On Stability Property of Probability Laws with Respect to Small\n  Violations of Algorithmic Randomness", "comments": "25 pages. arXiv admin note: substantial text overlap with\n  arXiv:1105.4274, arXiv:0806.4572", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a stability property of probability laws with respect to small\nviolations of algorithmic randomness. A sufficient condition of stability is\npresented in terms of Schnorr tests of algorithmic randomness. Most probability\nlaws, like the strong law of large numbers, the law of iterated logarithm, and\neven Birkhoff's pointwise ergodic theorem for ergodic transformations, are\nstable in this sense. Nevertheless, the phenomenon of instability occurs in\nergodic theory. Firstly, the stability property of the Birkhoff's ergodic\ntheorem is non-uniform. Moreover, a computable non-ergodic measure preserving\ntransformation can be constructed such that ergodic theorem is non-stable. We\nalso show that any universal data compression scheme is also non-stable with\nrespect to the class of all computable ergodic measures.\n", "versions": [{"version": "v1", "created": "Fri, 12 Sep 2014 21:06:48 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["V'yugin", "Vladimir V.", ""]]}, {"id": "1409.4035", "submitter": "Adi Shraibman", "authors": "Adi Shraibman", "title": "The Corruption Bound, Log Rank, and Communication Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove upper bounds on deterministic communication complexity in terms of\nlog of the rank and simple versions of the corruption bound.\n  Our bounds are a simplified version of the results of Gavinsky and Lovett,\nusing the same set of tools. We also give an elementary proof for the upper\nbound on communication complexity in terms of rank proved by Lovett.\n", "versions": [{"version": "v1", "created": "Sun, 14 Sep 2014 09:12:07 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 09:50:00 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Shraibman", "Adi", ""]]}, {"id": "1409.4080", "submitter": "Henrik Singmann", "authors": "Nicolas Gauvrit, Henrik Singmann, Fernando Soler-Toscano, Hector Zenil", "title": "Algorithmic complexity for psychology: A user-friendly implementation of\n  the coding theorem method", "comments": "to appear in \"Behavioral Research Methods\", 14 pages in journal\n  format, R package at http://cran.r-project.org/web/packages/acss/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kolmogorov-Chaitin complexity has long been believed to be impossible to\napproximate when it comes to short sequences (e.g. of length 5-50). However,\nwith the newly developed \\emph{coding theorem method} the complexity of strings\nof length 2-11 can now be numerically estimated. We present the theoretical\nbasis of algorithmic complexity for short strings (ACSS) and describe an\nR-package providing functions based on ACSS that will cover psychologists'\nneeds and improve upon previous methods in three ways: (1) ACSS is now\navailable not only for binary strings, but for strings based on up to 9\ndifferent symbols, (2) ACSS no longer requires time-consuming computing, and\n(3) a new approach based on ACSS gives access to an estimation of the\ncomplexity of strings of any length. Finally, three illustrative examples show\nhow these tools can be applied to psychology.\n", "versions": [{"version": "v1", "created": "Sun, 14 Sep 2014 17:31:40 GMT"}, {"version": "v2", "created": "Thu, 19 Feb 2015 22:22:13 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Gauvrit", "Nicolas", ""], ["Singmann", "Henrik", ""], ["Soler-Toscano", "Fernando", ""], ["Zenil", "Hector", ""]]}, {"id": "1409.4299", "submitter": "Giordano Da Lozzo", "authors": "Giordano Da Lozzo, V\\'it Jel\\'inek, Jan Kratochv\\'il, Ignaz Rutter", "title": "Planar Embeddings with Small and Uniform Faces", "comments": "23 pages, 5 figures, extended version of 'Planar Embeddings with\n  Small and Uniform Faces' (The 25th International Symposium on Algorithms and\n  Computation, 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by finding planar embeddings that lead to drawings with favorable\naesthetics, we study the problems MINMAXFACE and UNIFORMFACES of embedding a\ngiven biconnected multi-graph such that the largest face is as small as\npossible and such that all faces have the same size, respectively.\n  We prove a complexity dichotomy for MINMAXFACE and show that deciding whether\nthe maximum is at most $k$ is polynomial-time solvable for $k \\leq 4$ and\nNP-complete for $k \\geq 5$. Further, we give a 6-approximation for minimizing\nthe maximum face in a planar embedding. For UNIFORMFACES, we show that the\nproblem is NP-complete for odd $k \\geq 7$ and even $k \\geq 10$. Moreover, we\ncharacterize the biconnected planar multi-graphs admitting 3- and 4-uniform\nembeddings (in a $k$-uniform embedding all faces have size $k$) and give an\nefficient algorithm for testing the existence of a 6-uniform embedding.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 15:42:07 GMT"}], "update_date": "2014-09-17", "authors_parsed": [["Da Lozzo", "Giordano", ""], ["Jel\u00ednek", "V\u00edt", ""], ["Kratochv\u00edl", "Jan", ""], ["Rutter", "Ignaz", ""]]}, {"id": "1409.4379", "submitter": "Hamza Fawzi", "authors": "Hamza Fawzi, James Saunderson, Pablo A. Parrilo", "title": "Equivariant semidefinite lifts of regular polygons", "comments": "29 pages", "journal-ref": "Mathematics of Operations Research, Vol. 42, no. 2 (2016): 472-494", "doi": "10.1287/moor.2016.0813", "report-no": null, "categories": "math.OC cs.CC cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a polytope P in $\\mathbb{R}^n$, we say that P has a positive\nsemidefinite lift (psd lift) of size d if one can express P as the linear\nprojection of an affine slice of the positive semidefinite cone\n$\\mathbf{S}^d_+$. If a polytope P has symmetry, we can consider equivariant psd\nlifts, i.e. those psd lifts that respect the symmetry of P. One of the simplest\nfamilies of polytopes with interesting symmetries are regular polygons in the\nplane, which have played an important role in the study of linear programming\nlifts (or extended formulations). In this paper we study equivariant psd lifts\nof regular polygons. We first show that the standard Lasserre/sum-of-squares\nhierarchy for the regular N-gon requires exactly ceil(N/4) iterations and thus\nyields an equivariant psd lift of size linear in N. In contrast we show that\none can construct an equivariant psd lift of the regular 2^n-gon of size 2n-1,\nwhich is exponentially smaller than the psd lift of the sum-of-squares\nhierarchy. Our construction relies on finding a sparse sum-of-squares\ncertificate for the facet-defining inequalities of the regular 2^n-gon, i.e.,\none that only uses a small (logarithmic) number of monomials. Since any\nequivariant LP lift of the regular 2^n-gon must have size 2^n, this gives the\nfirst example of a polytope with an exponential gap between sizes of\nequivariant LP lifts and equivariant psd lifts. Finally we prove that our\nconstruction is essentially optimal by showing that any equivariant psd lift of\nthe regular N-gon must have size at least logarithmic in N.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 18:59:37 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Fawzi", "Hamza", ""], ["Saunderson", "James", ""], ["Parrilo", "Pablo A.", ""]]}, {"id": "1409.4391", "submitter": "Dave Touchette", "authors": "Dave Touchette", "title": "Direct Sum Theorem for Bounded Round Quantum Communication Complexity", "comments": "Incorrect statement of the substate theorem, affecting the main\n  compression result. Thanks to Anurag Anshu and Rahul Jain for pointing this\n  out", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a direct sum theorem for bounded round entanglement-assisted quantum\ncommunication complexity. To do so, we use the fully quantum definition for\ninformation cost and complexity that we recently introduced, and use both the\nfact that information is a lower bound on the communication, and the fact that\na direct sum property holds for quantum information complexity. We then give a\nprotocol for compressing a single copy of a protocol down to its quantum\ninformation cost, up to terms depending on the number of rounds and the allowed\nincrease in error. Two important tools to derive this protocol are a smooth\nconditional min-entropy bound for a one-shot quantum state redistribution\nprotocol, and the quantum substate theorem of Jain, Radhakrishnan and Sen\n(FOCS'02) to transform this bound into a von Neumann conditional entropy bound.\nThis result further establishes the newly introduced notions of quantum\ninformation cost and complexity as the correct quantum generalisations of the\nclassical ones in the standard communication complexity setting. Finding such a\nquantum generalization of information complexity was one of the open problem\nrecently raised by Braverman (STOC'12).\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 19:39:23 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 02:48:49 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Touchette", "Dave", ""]]}, {"id": "1409.4601", "submitter": "Michael Pinsker", "authors": "Manuel Bodirsky, Michael Pinsker, Andr\\'as Pongr\\'acz", "title": "Projective clone homomorphisms", "comments": "13 pages", "journal-ref": null, "doi": "10.1017/jsl.2019.23", "report-no": null, "categories": "math.LO cs.CC cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that a countable $\\omega$-categorical structure interprets all\nfinite structures primitively positively if and only if its polymorphism clone\nmaps to the clone of projections on a two-element set via a continuous clone\nhomomorphism. We investigate the relationship between the existence of a clone\nhomomorphism to the projection clone, and the existence of such a homomorphism\nwhich is continuous and thus meets the above criterion.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 12:06:50 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 13:24:00 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2021 19:25:23 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Pinsker", "Michael", ""], ["Pongr\u00e1cz", "Andr\u00e1s", ""]]}, {"id": "1409.4800", "submitter": "Juan Bermejo-Vega", "authors": "Juan Bermejo-Vega, Cedric Yen-Yu Lin, Maarten Van den Nest", "title": "The computational power of normalizer circuits over black-box groups", "comments": "40 pages + appendices", "journal-ref": null, "doi": null, "report-no": "MIT-CTP/4584", "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a precise connection between Clifford circuits, Shor's\nfactoring algorithm and several other famous quantum algorithms with\nexponential quantum speed-ups for solving Abelian hidden subgroup problems. We\nshow that all these different forms of quantum computation belong to a common\nnew restricted model of quantum operations that we call \\emph{black-box\nnormalizer circuits}. To define these, we extend the previous model of\nnormalizer circuits [arXiv:1201.4867v1,arXiv:1210.3637,arXiv:1409.3208], which\nare built of quantum Fourier transforms, group automorphism and quadratic phase\ngates associated to an Abelian group $G$. In previous works, the group $G$ is\nalways given in an explicitly decomposed form. In our model, we remove this\nassumption and allow $G$ to be a black-box group. While standard normalizer\ncircuits were shown to be efficiently classically simulable\n[arXiv:1201.4867v1,arXiv:1210.3637,arXiv:1409.3208], we find that normalizer\ncircuits are powerful enough to factorize and solve classically-hard problems\nin the black-box setting. We further set upper limits to their computational\npower by showing that decomposing finite Abelian groups is complete for the\nassociated complexity class. In particular, solving this problem renders\nblack-box normalizer circuits efficiently classically simulable by exploiting\nthe generalized stabilizer formalism in\n[arXiv:1201.4867v1,arXiv:1210.3637,arXiv:1409.3208]. Lastly, we employ our\nconnection to draw a few practical implications for quantum algorithm design:\nnamely, we give a no-go theorem for finding new quantum algorithms with\nblack-box normalizer circuits, a universality result for low-depth normalizer\ncircuits, and identify two other complete problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 20:46:15 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Bermejo-Vega", "Juan", ""], ["Lin", "Cedric Yen-Yu", ""], ["Nest", "Maarten Van den", ""]]}, {"id": "1409.4828", "submitter": "Damien Woods", "authors": "Ho-Lin Chen, David Doty, Dhiraj Holden, Chris Thachuk, Damien Woods,\n  Chun-Tao Yang", "title": "Fast algorithmic self-assembly of simple shapes using random agitation", "comments": "Conference version at DNA20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the power of uncontrolled random molecular movement in the nubot\nmodel of self-assembly. The nubot model is an asynchronous nondeterministic\ncellular automaton augmented with rigid-body movement rules (push/pull,\ndeterministically and programmatically applied to specific monomers) and random\nagitations (nondeterministically applied to every monomer and direction with\nequal probability all of the time). Previous work on the nubot model showed how\nto build simple shapes such as lines and squares quickly---in expected time\nthat is merely logarithmic of their size. These results crucially make use of\nthe programmable rigid-body movement rule: the ability for a single monomer to\ncontrol the movement of a large objects quickly, and only at a time and place\nof the programmers' choosing. However, in engineered molecular systems,\nmolecular motion is largely uncontrolled and fundamentally random. This raises\nthe question of whether similar results can be achieved in a more restrictive,\nand perhaps easier to justify, model where uncontrolled random movements, or\nagitations, are happening throughout the self-assembly process and are the only\nform of rigid-body movement. We show that this is indeed the case: we give a\npolylogarithmic expected time construction for squares using agitation, and a\nsublinear expected time construction to build a line. Such results are\nimpossible in an agitation-free (and movement-free) setting and thus show the\nbenefits of exploiting uncontrolled random movement.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 23:14:27 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Chen", "Ho-Lin", ""], ["Doty", "David", ""], ["Holden", "Dhiraj", ""], ["Thachuk", "Chris", ""], ["Woods", "Damien", ""], ["Yang", "Chun-Tao", ""]]}, {"id": "1409.5627", "submitter": "Heng Guo", "authors": "Leslie Ann Goldberg and Heng Guo", "title": "The complexity of approximating complex-valued Ising and Tutte partition\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of approximately evaluating the Ising and Tutte\npartition functions with complex parameters. Our results are partly motivated\nby the study of the quantum complexity classes BQP and IQP. Recent results show\nhow to encode quantum computations as evaluations of classical partition\nfunctions. These results rely on interesting and deep results about quantum\ncomputation in order to obtain hardness results about the difficulty of\n(classically) evaluating the partition functions for certain fixed parameters.\n  The motivation for this paper is to study more comprehensively the complexity\nof (classically) approximating the Ising and Tutte partition functions with\ncomplex parameters. Partition functions are combinatorial in nature and\nquantifying their approximation complexity does not require a detailed\nunderstanding of quantum computation. Using combinatorial arguments, we give\nthe first full classification of the complexity of multiplicatively\napproximating the norm and additively approximating the argument of the Ising\npartition function for complex edge interactions (as well as of approximating\nthe partition function according to a natural complex metric). We also study\nthe norm approximation problem in the presence of external fields, for which we\ngive a complete dichotomy when the parameters are roots of unity. Previous\nresults were known just for a few such points, and we strengthen these results\nfrom BQP-hardness to #P-hardness. Moreover, we show that computing the sign of\nthe Tutte polynomial is #P-hard at certain points related to the simulation of\nBQP. Using our classifications, we then revisit the connections to quantum\ncomputation, drawing conclusions that are a little different from (and\nincomparable to) ones in the quantum literature, but along similar lines.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 12:36:33 GMT"}, {"version": "v2", "created": "Mon, 27 Oct 2014 22:21:52 GMT"}, {"version": "v3", "created": "Wed, 25 Feb 2015 18:57:18 GMT"}, {"version": "v4", "created": "Sun, 22 Jan 2017 21:44:10 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Goldberg", "Leslie Ann", ""], ["Guo", "Heng", ""]]}, {"id": "1409.6011", "submitter": "Ben Cousins", "authors": "Ben Cousins and Santosh Vempala", "title": "Gaussian Cooling and O*(n^3) Algorithms for Volume and Gaussian Volume", "comments": "This paper is a combination of two previously published conference\n  papers: \"A Cubic Algorithm for Computing Gaussian Volume\" (SODA 2014,\n  arXiv:1306.5829) and \"Bypassing KLS: Gaussian Cooling and an $O^*(n^3)$\n  Volume Algorithm\" (STOC 2015). Additionally, this version has a major\n  simplification to the main proof in the latter conference paper. (Lemma 3.2\n  in this version) 36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an $O^*(n^3)$ randomized algorithm for estimating the volume of a\nwell-rounded convex body given by a membership oracle, improving on the\nprevious best complexity of $O^*(n^4)$. The new algorithmic ingredient is an\naccelerated cooling schedule where the rate of cooling increases with the\ntemperature. Previously, the known approach for potentially achieving this\nasymptotic complexity relied on a positive resolution of the KLS hyperplane\nconjecture, a central open problem in convex geometry.\n  We also obtain an $O^*(n^3)$ randomized algorithm for integrating a standard\nGaussian distribution over an arbitrary convex set containing the unit ball.\nBoth the volume and Gaussian volume algorithms use an improved algorithm for\nsampling a Gaussian distribution restricted to a convex body. In this latter\nsetting, as we show, the KLS conjecture holds and for a spherical Gaussian\ndistribution with variance $\\sigma^2$, the sampling complexity is\n$O^*(\\max\\{n^3, \\sigma^2n^2\\})$ for the first sample and $O^*(\\max\\{n^2,\n\\sigma^2n^2\\})$ for every subsequent sample.\n", "versions": [{"version": "v1", "created": "Sun, 21 Sep 2014 16:33:53 GMT"}, {"version": "v2", "created": "Mon, 29 Feb 2016 20:01:45 GMT"}, {"version": "v3", "created": "Mon, 5 Dec 2016 02:38:41 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Cousins", "Ben", ""], ["Vempala", "Santosh", ""]]}, {"id": "1409.6366", "submitter": "Thomas Rothvoss", "authors": "Thomas Rothvoss", "title": "A direct proof for Lovett's bound on the communication complexity of low\n  rank matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The log-rank conjecture in communication complexity suggests that the\ndeterministic communication complexity of any Boolean rank-r function is\nbounded by polylog(r). Recently, major progress was made by Lovett who proved\nthat the communication complexity is bounded by O(r^1/2 * log r). Lovett's\nproof is based on known estimates on the discrepancy of low-rank matrices. We\ngive a simple, direct proof based on a hyperplane rounding argument that in our\nopinion sheds more light on the reason why a root factor suffices and what is\nnecessary to improve on this factor.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2014 22:40:24 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Rothvoss", "Thomas", ""]]}, {"id": "1409.6777", "submitter": "Tomoyuki Morimae", "authors": "Keisuke Fujii, Hirotada Kobayashi, Tomoyuki Morimae, Harumichi\n  Nishimura, Shuhei Tamate, Seiichiro Tani", "title": "Impossibility of Classically Simulating One-Clean-Qubit Computation", "comments": "13 pages, 1 figure. New results and new authors have been added.\n  (DQC1_2 is improved to DQC1_1, and collapse of PH is improved from 3rd to 2nd\n  level.) Title is also changed", "journal-ref": "Phys. Rev. Lett. 120, 200502 (2018)", "doi": "10.1103/PhysRevLett.120.200502", "report-no": "YITP-18-54", "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deterministic quantum computation with one quantum bit (DQC1) is a restricted\nmodel of quantum computing where the input state is the completely mixed state\nexcept for a single clean qubit, and only a single output qubit is measured at\nthe end of the computing. It is proved that the restriction of quantum\ncomputation to the DQC1 model does not change the complexity classes NQP and\nSBQP. As a main consequence, it follows that the DQC1 model cannot be\nefficiently simulated by classical computers unless the polynomial-time\nhierarchy collapses to the second level (more precisely, to AM), which answers\nthe long-standing open problem posed by Knill and Laflamme under the very\nplausible complexity assumption. The argument developed in this paper also\nweakens the complexity assumption necessary for the existing impossibility\nresults on classical simulation of various sub-universal quantum computing\nmodels, such as the IQP model and the Boson sampling.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 00:05:10 GMT"}, {"version": "v2", "created": "Thu, 26 Feb 2015 06:15:33 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Fujii", "Keisuke", ""], ["Kobayashi", "Hirotada", ""], ["Morimae", "Tomoyuki", ""], ["Nishimura", "Harumichi", ""], ["Tamate", "Shuhei", ""], ["Tani", "Seiichiro", ""]]}, {"id": "1409.6792", "submitter": "Yasuhiro Takahashi", "authors": "Yasuhiro Takahashi, Seiichiro Tani, Takeshi Yamazaki, Kazuyuki Tanaka", "title": "Commuting Quantum Circuits with Few Outputs are Unlikely to be\n  Classically Simulatable", "comments": "19 pages, 6 figures; v2: Theorems 1 and 3 improved, proofs modified", "journal-ref": "Quantum Information and Computation, Vol. 16, No. 3&4, (2016)\n  0251-0270", "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the classical simulatability of commuting quantum circuits with n\ninput qubits and O(log n) output qubits, where a quantum circuit is classically\nsimulatable if its output probability distribution can be sampled up to an\nexponentially small additive error in classical polynomial time. First, we show\nthat there exists a commuting quantum circuit that is not classically\nsimulatable unless the polynomial hierarchy collapses to the third level. This\nis the first formal evidence that a commuting quantum circuit is not\nclassically simulatable even when the number of output qubits is exponentially\nsmall. Then, we consider a generalized version of the circuit and clarify the\ncondition under which it is classically simulatable. Lastly, we apply the\nargument for the above evidence to Clifford circuits in a similar setting and\nprovide evidence that such a circuit augmented by a depth-1 non-Clifford layer\nis not classically simulatable. These results reveal subtle differences between\nquantum and classical computation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 01:41:00 GMT"}, {"version": "v2", "created": "Wed, 17 Dec 2014 08:47:11 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Takahashi", "Yasuhiro", ""], ["Tani", "Seiichiro", ""], ["Yamazaki", "Takeshi", ""], ["Tanaka", "Kazuyuki", ""]]}, {"id": "1409.7261", "submitter": "Stefan Kratsch", "authors": "Gregory Gutin and Stefan Kratsch and Magnus Wahlstr\\\"om", "title": "Polynomial Kernels and User Reductions for the Workflow Satisfiability\n  Problem", "comments": "An extended abstract appears in the proceedings of IPEC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Workflow Satisfiability Problem (WSP) is a problem of practical interest\nthat arises whenever tasks need to be performed by authorized users, subject to\nconstraints defined by business rules. We are required to decide whether there\nexists a plan -- an assignment of tasks to authorized users -- such that all\nconstraints are satisfied.\n  The WSP is, in fact, the conservative Constraint Satisfaction Problem (i.e.,\nfor each variable, here called task, we have a unary authorization constraint)\nand is, thus, NP-complete. It was observed by Wang and Li (2010) that the\nnumber k of tasks is often quite small and so can be used as a parameter, and\nseveral subsequent works have studied the parameterized complexity of WSP\nregarding parameter k.\n  We take a more detailed look at the kernelization complexity of WSP(\\Gamma)\nwhen \\Gamma\\ denotes a finite or infinite set of allowed constraints. Our main\nresult is a dichotomy for the case that all constraints in \\Gamma\\ are regular:\n(1) We are able to reduce the number n of users to n' <= k. This entails a\nkernelization to size poly(k) for finite \\Gamma, and, under mild technical\nconditions, to size poly(k+m) for infinite \\Gamma, where m denotes the number\nof constraints. (2) Already WSP(R) for some R \\in \\Gamma\\ allows no polynomial\nkernelization in k+m unless the polynomial hierarchy collapses.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 14:03:18 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Gutin", "Gregory", ""], ["Kratsch", "Stefan", ""], ["Wahlstr\u00f6m", "Magnus", ""]]}, {"id": "1409.7410", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh and Russell Greiner", "title": "Revisiting Algebra and Complexity of Inference in Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the form and complexity of inference in graphical models\nusing the abstraction offered by algebraic structures. In particular, we\nbroadly formalize inference problems in graphical models by viewing them as a\nsequence of operations based on commutative semigroups. We then study the\ncomputational complexity of inference by organizing various problems into an\n\"inference hierarchy\". When the underlying structure of an inference problem is\na commutative semiring -- i.e. a combination of two commutative semigroups with\nthe distributive law -- a message passing procedure called belief propagation\ncan leverage this distributive law to perform polynomial-time inference for\ncertain problems. After establishing the NP-hardness of inference in any\ncommutative semiring, we investigate the relation between algebraic properties\nin this setting and further show that polynomial-time inference using\ndistributive law does not (trivially) extend to inference problems that are\nexpressed using more than two commutative semigroups. We then extend the\nalgebraic treatment of message passing procedures to survey propagation,\nproviding a novel perspective using a combination of two commutative semirings.\nThis formulation generalizes the application of survey propagation to new\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 20:18:47 GMT"}, {"version": "v2", "created": "Mon, 29 Sep 2014 15:26:27 GMT"}, {"version": "v3", "created": "Thu, 6 Nov 2014 17:52:35 GMT"}, {"version": "v4", "created": "Sun, 3 May 2015 23:38:03 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Greiner", "Russell", ""]]}, {"id": "1409.7688", "submitter": "Pablo Romero Rodr\\'iguez", "authors": "Eduardo Canale, Pablo Romero, Gerardo Rubino", "title": "Irrelevant Components and Exact Computation of the Diameter Constrained\n  Reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G=(V,E)$ be a simple graph with $|V|=n$ nodes and $|E|=m$ links, a\nsubset $K \\subseteq V$ of \\emph{terminals}, a vector $p=(p_1,...,p_m) \\in\n[0,1]^m$ and a positive integer $d$, called \\emph{diameter}. We assume nodes\nare perfect but links fail stochastically and independently, with probabilities\n$q_i=1-p_i$. The \\emph{diameter-constrained reliability} (DCR for short), is\nthe probability that the terminals of the resulting subgraph remain connected\nby paths composed by $d$ links, or less. This number is denoted by\n$R_{K,G}^{d}(p)$. The general computation of the parameter $R_{K,G}^{d}(p)$\nbelongs to the class of $\\mathcal{N}\\mathcal{P}$-Hard problems, since is\nsubsumes the complexity that a random graph is connected.\n  A discussion of the computational complexity for DCR-subproblems is provided\nin terms of the number of terminal nodes $k=|K|$ and diameter $d$. Either when\n$d=1$ or when $d=2$ and $k$ is fixed, the DCR is inside the class $\\mathcal{P}$\nof polynomial-time problems. The DCR turns $\\mathcal{N}\\mathcal{P}$-Hard even\nif $k \\geq 2$ and $d\\geq 3$ are fixed, or in an all-terminal scenario when\n$d=2$. The traditional approach is to design either exponential exact\nalgorithms or efficient solutions for particular graph classes.\n  The contributions of this paper are two-fold. First, a new recursive class of\ngraphs are shown to have efficient DCR computation. Second, we define a\nfactorization method in order to develop an exact DCR computation in general.\nThe approach is inspired in prior works related with the determination of\nirrelevant links and deletion-contraction formula.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 15:30:30 GMT"}, {"version": "v2", "created": "Wed, 1 Oct 2014 10:58:38 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Canale", "Eduardo", ""], ["Romero", "Pablo", ""], ["Rubino", "Gerardo", ""]]}, {"id": "1409.7790", "submitter": "Raghavendra Rao B V", "authors": "Ankit Chauhan and B. V. Raghavendra Rao", "title": "Parameterized Analogues of Probabilistic Computation", "comments": "Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study structural aspects of randomized parameterized computation. We\nintroduce a new class ${\\sf W[P]}$-${\\sf PFPT}$ as a natural parameterized\nanalogue of ${\\sf PP}$. Our definition uses the machine based characterization\nof the parameterized complexity class ${\\sf W[P]}$ obtained by Chen et.al [TCS\n2005]. We translate most of the structural properties and characterizations of\nthe class ${\\sf PP}$ to the new class ${W[P]}$-${\\sf PFPT}$.\n  We study a parameterization of the polynomial identity testing problem based\non the degree of the polynomial computed by the arithmetic circuit. We obtain a\nparameterized analogue of the well known Schwartz-Zippel lemma [Schwartz, JACM\n80 and Zippel, EUROSAM 79].\n  Additionally, we introduce a parameterized variant of permanent, and prove\nits $\\#W[1]$ completeness.\n", "versions": [{"version": "v1", "created": "Sat, 27 Sep 2014 10:39:15 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Chauhan", "Ankit", ""], ["Rao", "B. V. Raghavendra", ""]]}, {"id": "1409.8063", "submitter": "Noah Stephens-Davidowitz", "authors": "Daniel Dadush, Oded Regev, Noah Stephens-Davidowitz", "title": "On the Closest Vector Problem with a Distance Guarantee", "comments": "An early version of the paper was titled \"On Bounded Distance\n  Decoding and the Closest Vector Problem with Preprocessing\". Conference on\n  Computational Complexity (2014)", "journal-ref": "CCC 2014", "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a substantially more efficient variant, both in terms of running\ntime and size of preprocessing advice, of the algorithm by Liu, Lyubashevsky,\nand Micciancio for solving CVPP (the preprocessing version of the Closest\nVector Problem, CVP) with a distance guarantee. For instance, for any $\\alpha <\n1/2$, our algorithm finds the (unique) closest lattice point for any target\npoint whose distance from the lattice is at most $\\alpha$ times the length of\nthe shortest nonzero lattice vector, requires as preprocessing advice only $N\n\\approx \\widetilde{O}(n \\exp(\\alpha^2 n /(1-2\\alpha)^2))$ vectors, and runs in\ntime $\\widetilde{O}(nN)$.\n  As our second main contribution, we present reductions showing that it\nsuffices to solve CVP, both in its plain and preprocessing versions, when the\ninput target point is within some bounded distance of the lattice. The\nreductions are based on ideas due to Kannan and a recent sparsification\ntechnique due to Dadush and Kun. Combining our reductions with the LLM\nalgorithm gives an approximation factor of $O(n/\\sqrt{\\log n})$ for search\nCVPP, improving on the previous best of $O(n^{1.5})$ due to Lagarias, Lenstra,\nand Schnorr. When combined with our improved algorithm we obtain, somewhat\nsurprisingly, that only O(n) vectors of preprocessing advice are sufficient to\nsolve CVPP with (the only slightly worse) approximation factor of O(n).\n", "versions": [{"version": "v1", "created": "Mon, 29 Sep 2014 10:40:28 GMT"}, {"version": "v2", "created": "Fri, 26 Dec 2014 00:30:59 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Dadush", "Daniel", ""], ["Regev", "Oded", ""], ["Stephens-Davidowitz", "Noah", ""]]}, {"id": "1409.8228", "submitter": "Stefan Kiefer", "authors": "Christoph Haase and Stefan Kiefer", "title": "The Odds of Staying on Budget", "comments": "Technical report for an ICALP'15 paper. 30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given Markov chains and Markov decision processes (MDPs) whose transitions\nare labelled with non-negative integer costs, we study the computational\ncomplexity of deciding whether the probability of paths whose accumulated cost\nsatisfies a Boolean combination of inequalities exceeds a given threshold. For\nacyclic Markov chains, we show that this problem is PP-complete, whereas it is\nhard for the PosSLP problem and in PSPACE for general Markov chains. Moreover,\nfor acyclic and general MDPs, we prove PSPACE- and EXP-completeness,\nrespectively. Our results have direct implications on the complexity of\ncomputing reward quantiles in succinctly represented stochastic systems.\n", "versions": [{"version": "v1", "created": "Sun, 21 Sep 2014 17:49:56 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2015 19:50:20 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Haase", "Christoph", ""], ["Kiefer", "Stefan", ""]]}, {"id": "1409.8254", "submitter": "Rustem Valeyev", "authors": "Rustem Valeyev", "title": "About accuracy of the solution of NP-complete tasks", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On example of tasks of class NP the questions concerning accuracy of work of\nalready existing and possible in the future algorithms for the solution of\ntasks on discrete structures are considered.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 05:35:16 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Valeyev", "Rustem", ""]]}, {"id": "1409.8464", "submitter": "Friedrich Slivovsky", "authors": "Friedrich Slivovsky and Stefan Szeider", "title": "Model Counting for Formulas of Bounded Clique-Width", "comments": "Extended version of a paper published at ISAAC 2013", "journal-ref": "Proceedings of ISAAC 2013. Lecture Notes in Computer Science, vol.\n  8283, pp. 677-687, Springer, 2013", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that #SAT is polynomial-time tractable for classes of CNF formulas\nwhose incidence graphs have bounded symmetric clique-width (or bounded\nclique-width, or bounded rank-width). This result strictly generalizes\npolynomial-time tractability results for classes of formulas with signed\nincidence graphs of bounded clique-width and classes of formulas with incidence\ngraphs of bounded modular treewidth, which were the most general results of\nthis kind known so far.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 10:27:07 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Slivovsky", "Friedrich", ""], ["Szeider", "Stefan", ""]]}, {"id": "1409.8488", "submitter": "Mathieu Lauri\\`ere", "authors": "Iordanis Kerenidis, Mathieu Lauri\\`ere, Fran\\c{c}ois Le Gall and\n  Mathys Rennela", "title": "Privacy in Quantum Communication Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two-party quantum communication complexity, Alice and Bob receive some\nclassical inputs and wish to compute some function that depends on both these\ninputs, while minimizing the communication. This model has found numerous\napplications in many areas of computer science. One question that has received\na lot of attention recently is whether it is possible to perform such protocols\nin a private way. We show that defining privacy for quantum protocols is not so\nstraightforward and it depends on whether we assume that the registers where\nAlice and Bob receive their classical inputs are in fact classical registers\n(and hence unentangled with the rest of the protocol) or quantum registers (and\nhence can be entangled with the rest of the protocol or the environment). We\nprovide new quantum protocols for the Inner Product function and for Private\nInformation Retrieval, and show that the privacy assuming classical input\nregisters can be exponentially smaller than the privacy assuming quantum input\nregisters. We also argue that the right notion of privacy of a communication\nprotocol is the one assuming classical input registers, since otherwise the\nplayers can deviate considerably from the protocol.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 11:20:33 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Kerenidis", "Iordanis", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Gall", "Fran\u00e7ois Le", ""], ["Rennela", "Mathys", ""]]}, {"id": "1409.8524", "submitter": "Manuel Sorge", "authors": "Yann Disser, Stefan Kratsch, Manuel Sorge", "title": "The Minimum Feasible Tileset problem", "comments": "23 pages, 2 figures. An extended abstract of this article appeared at\n  the 12th Workshop on Approximation and Online Algorithms, Wroclaw, September\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study the Minimum Feasible Tileset problem: Given a set of\nsymbols and subsets of these symbols (scenarios), find a smallest possible\nnumber of pairs of symbols (tiles) such that each scenario can be formed by\nselecting at most one symbol from each tile. We show that this problem is\nAPX-hard and that it is NP-hard even if each scenario contains at most three\nsymbols. Our main result is a 4/3-approximation algorithm for the general case.\nIn addition, we show that the Minimum Feasible Tileset problem is\nfixed-parameter tractable both when parameterized with the number of scenarios\nand with the number of symbols.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 12:51:57 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 16:05:19 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Disser", "Yann", ""], ["Kratsch", "Stefan", ""], ["Sorge", "Manuel", ""]]}]