[{"id": "1401.0189", "submitter": "Suryajith Chillara", "authors": "Suryajith Chillara, Partha Mukhopadhyay", "title": "On the Limits of Depth Reduction at Depth 3 Over Small Finite Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recently, Gupta et.al. [GKKS2013] proved that over Q any $n^{O(1)}$-variate\nand $n$-degree polynomial in VP can also be computed by a depth three\n$\\Sigma\\Pi\\Sigma$ circuit of size $2^{O(\\sqrt{n}\\log^{3/2}n)}$. Over fixed-size\nfinite fields, Grigoriev and Karpinski proved that any $\\Sigma\\Pi\\Sigma$\ncircuit that computes $Det_n$ (or $Perm_n$) must be of size $2^{\\Omega(n)}$\n[GK1998]. In this paper, we prove that over fixed-size finite fields, any\n$\\Sigma\\Pi\\Sigma$ circuit for computing the iterated matrix multiplication\npolynomial of $n$ generic matrices of size $n\\times n$, must be of size\n$2^{\\Omega(n\\log n)}$. The importance of this result is that over fixed-size\nfields there is no depth reduction technique that can be used to compute all\nthe $n^{O(1)}$-variate and $n$-degree polynomials in VP by depth 3 circuits of\nsize $2^{o(n\\log n)}$. The result [GK1998] can only rule out such a possibility\nfor depth 3 circuits of size $2^{o(n)}$.\n  We also give an example of an explicit polynomial ($NW_{n,\\epsilon}(X)$) in\nVNP (not known to be in VP), for which any $\\Sigma\\Pi\\Sigma$ circuit computing\nit (over fixed-size fields) must be of size $2^{\\Omega(n\\log n)}$. The\npolynomial we consider is constructed from the combinatorial design. An\ninteresting feature of this result is that we get the first examples of two\npolynomials (one in VP and one in VNP) such that they have provably stronger\ncircuit size lower bounds than Permanent in a reasonably strong model of\ncomputation.\n  Next, we prove that any depth 4\n$\\Sigma\\Pi^{[O(\\sqrt{n})]}\\Sigma\\Pi^{[\\sqrt{n}]}$ circuit computing\n$NW_{n,\\epsilon}(X)$ (over any field) must be of size $2^{\\Omega(\\sqrt{n}\\log\nn)}$. To the best of our knowledge, the polynomial $NW_{n,\\epsilon}(X)$ is the\nfirst example of an explicit polynomial in VNP such that it requires\n$2^{\\Omega(\\sqrt{n}\\log n)}$ size depth four circuits, but no known matching\nupper bound.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 17:08:36 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Chillara", "Suryajith", ""], ["Mukhopadhyay", "Partha", ""]]}, {"id": "1401.0684", "submitter": "Michael Bekos", "authors": "Michael A. Bekos, Martin Gronemann, Chrysanthi N. Raftopoulou", "title": "Two-Page Book Embeddings of 4-Planar Graphs", "comments": "21 pages, 16 Figures. A shorter version is to appear at STACS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back in the Eighties, Heath showed that every 3-planar graph is\nsubhamiltonian and asked whether this result can be extended to a class of\ngraphs of degree greater than three. In this paper we affirmatively answer this\nquestion for the class of 4-planar graphs. Our contribution consists of two\nalgorithms: The first one is limited to triconnected graphs, but runs in linear\ntime and uses existing methods for computing hamiltonian cycles in planar\ngraphs. The second one, which solves the general case of the problem, is a\nquadratic-time algorithm based on the book-embedding viewpoint of the problem.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 17:28:56 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Bekos", "Michael A.", ""], ["Gronemann", "Martin", ""], ["Raftopoulou", "Chrysanthi N.", ""]]}, {"id": "1401.0758", "submitter": "Aaron Snook", "authors": "Aaron Snook, Grant Schoenebeck, Paolo Codenotti", "title": "Graph Isomorphism and the Lasserre Hierarchy", "comments": "22 pages, 3 figures, submitted to CCC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show lower bounds for a certain large class of algorithms\nsolving the Graph Isomorphism problem, even on expander graph instances.\nSpielman [25] shows an algorithm for isomorphism of strongly regular expander\ngraphs that runs in time exp(O(n^(1/3)) (this bound was recently improved to\nexpf O(n^(1/5) [5]). It has since been an open question to remove the\nrequirement that the graph be strongly regular. Recent algorithmic results show\nthat for many problems the Lasserre hierarchy works surprisingly well when the\nunderlying graph has expansion properties. Moreover, recent work of Atserias\nand Maneva [3] shows that k rounds of the Lasserre hierarchy is a\ngeneralization of the k-dimensional Weisfeiler-Lehman algorithm for Graph\nIsomorphism. These two facts combined make the Lasserre hierarchy a good\ncandidate for solving graph isomorphism on expander graphs. Our main result\nrules out this promising direction by showing that even Omega(n) rounds of the\nLasserre semidefinite program hierarchy fail to solve the Graph Isomorphism\nproblem even on expander graphs.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2014 00:16:48 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Snook", "Aaron", ""], ["Schoenebeck", "Grant", ""], ["Codenotti", "Paolo", ""]]}, {"id": "1401.0912", "submitter": "Ronald de Wolf", "authors": "Urmila Mahadev (UC Berkeley) and Ronald de Wolf (CWI and University of\n  Amsterdam)", "title": "Rational approximations and quantum algorithms with postselection", "comments": "v2: 12 pages LaTeX, to appear in Quantum Information and Computation.\n  Compared to version 1, the writing has been improved but the results are\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the close connection between rational functions that approximate a\ngiven Boolean function, and quantum algorithms that compute the same function\nusing postselection. We show that the minimal degree of the former equals (up\nto a factor of 2) the minimal query complexity of the latter. We give optimal\n(up to constant factors) quantum algorithms with postselection for the Majority\nfunction, slightly improving upon an earlier algorithm of Aaronson. Finally we\nshow how Newman's classic theorem about low-degree rational approximation of\nthe absolute-value function follows from these algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2014 16:43:11 GMT"}, {"version": "v2", "created": "Sat, 23 Aug 2014 11:52:10 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Mahadev", "Urmila", "", "UC Berkeley"], ["de Wolf", "Ronald", "", "CWI and University of\n  Amsterdam"]]}, {"id": "1401.0976", "submitter": "Nitin Saxena", "authors": "Nitin Saxena", "title": "Progress on Polynomial Identity Testing - II", "comments": "17 pages, 1 figure, survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.AC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey the area of algebraic complexity theory; with the focus being on\nthe problem of polynomial identity testing (PIT). We discuss the key ideas that\nhave gone into the results of the last few years.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 03:18:06 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Saxena", "Nitin", ""]]}, {"id": "1401.1059", "submitter": "Pulkit Grover", "authors": "Pulkit Grover", "title": "\"Information-Friction\" and its implications on minimum energy required\n  for communication", "comments": "Accepted in IEEE Trans. Information Theory; preliminary version\n  presented at ISIT '13", "journal-ref": null, "doi": "10.1109/TIT.2014.2365777", "report-no": null, "categories": "cs.IT cs.CC math-ph math.IT math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Just as there are frictional losses associated with moving masses on a\nsurface, what if there were frictional losses associated with moving\ninformation on a substrate? Indeed, many modes of communication suffer from\nsuch frictional losses. We propose to model these losses as proportional to\n\"bit-meters,\" i.e., the product of mass of information (i.e., the number of\nbits) and the distance of information transport. We use this \"information-\nfriction\" model to understand fundamental energy requirements on encoding and\ndecoding in communication circuitry. First, for communication across a binary\ninput AWGN channel, we arrive at fundamental limits on bit-meters (and thus\nenergy consumption) for decoding implementations that have a predetermined\ninput-independent length of messages. For encoding, we relax the fixed-length\nassumption and derive bounds for flexible-message- length implementations.\nUsing these lower bounds we show that the total (transmit + encoding +\ndecoding) energy-per-bit must diverge to infinity as the target error\nprobability is lowered to zero. Further, the closer the communication rate is\nmaintained to the channel capacity (as the target error-probability is lowered\nto zero), the faster the required decoding energy diverges to infinity.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 12:34:35 GMT"}, {"version": "v2", "created": "Mon, 1 Sep 2014 11:52:42 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Grover", "Pulkit", ""]]}, {"id": "1401.1125", "submitter": "Anuj Dawar", "authors": "Matthew Anderson and Anuj Dawar", "title": "On Symmetric Circuits and Fixed-Point Logics", "comments": "22 pages. Full version of a paper to appear in STACS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study properties of relational structures such as graphs that are decided\nby families of Boolean circuits. Circuits that decide such properties are\nnecessarily invariant to permutations of the elements of the input structures.\nWe focus on families of circuits that are symmetric, i.e., circuits whose\ninvariance is witnessed by automorphisms of the circuit induced by the\npermutation of the input structure. We show that the expressive power of such\nfamilies is closely tied to definability in logic. In particular, we show that\nthe queries defined on structures by uniform families of symmetric Boolean\ncircuits with majority gates are exactly those definable in fixed-point logic\nwith counting. This shows that inexpressibility results in the latter logic\nlead to lower bounds against polynomial-size families of symmetric circuits.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 15:54:42 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Anderson", "Matthew", ""], ["Dawar", "Anuj", ""]]}, {"id": "1401.1434", "submitter": "Stefan K\\\"onig", "authors": "Stefan K\\\"onig", "title": "Computational Aspects of the Hausdorff Distance in Unbounded Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of determining the Hausdorff distance\nof two polytopes given in halfspace- or vertex-presentation in arbitrary\ndimension. Subsequently, a matching problem is investigated where a convex body\nis allowed to be homothetically transformed in order to minimize its Hausdorff\ndistance to another one. For this problem, we characterize optimal solutions,\ndeduce a Helly-type theorem and give polynomial time (approximation) algorithms\nfor polytopes.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 16:37:02 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["K\u00f6nig", "Stefan", ""]]}, {"id": "1401.2187", "submitter": "James Long III", "authors": "James T. Long and Lee J. Stanley", "title": "A Busy Beaver Problem for Infinite-Time Turing Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note introduces a generalization to the setting of infinite-time\ncomputation of the busy beaver problem from classical computability theory, and\nproves some results concerning the growth rate of an associated function. In\nour view, these results indicate that the generalization is both natural and\npromising.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 22:07:37 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Long", "James T.", ""], ["Stanley", "Lee J.", ""]]}, {"id": "1401.2205", "submitter": "Quentin Berthet", "authors": "Quentin Berthet", "title": "Optimal Testing for Planted Satisfiability Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC math.PR stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We study the problem of detecting planted solutions in a random\nsatisfiability formula. Adopting the formalism of hypothesis testing in\nstatistical analysis, we describe the minimax optimal rates of detection. Our\nanalysis relies on the study of the number of satisfying assignments, for which\nwe prove new results. We also address algorithmic issues, and give a\ncomputationally efficient test with optimal statistical performance. This\nresult is compared to an average-case hypothesis on the hardness of refuting\nsatisfiability of random formulas.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 23:34:17 GMT"}, {"version": "v2", "created": "Fri, 23 May 2014 20:21:36 GMT"}, {"version": "v3", "created": "Sun, 8 Feb 2015 04:11:42 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Berthet", "Quentin", ""]]}, {"id": "1401.2436", "submitter": "John Wright", "authors": "Ryan O'Donnell, John Wright, Chenggang Wu, Yuan Zhou", "title": "Hardness of robust graph isomorphism, Lasserre gaps, and asymmetry of\n  random graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on work of Cai, F\\\"urer, and Immerman \\cite{CFI92}, we show two\nhardness results for the Graph Isomorphism problem. First, we show that there\nare pairs of nonisomorphic $n$-vertex graphs $G$ and $H$ such that any\nsum-of-squares (SOS) proof of nonisomorphism requires degree $\\Omega(n)$. In\nother words, we show an $\\Omega(n)$-round integrality gap for the Lasserre SDP\nrelaxation. In fact, we show this for pairs $G$ and $H$ which are not even\n$(1-10^{-14})$-isomorphic. (Here we say that two $n$-vertex, $m$-edge graphs\n$G$ and $H$ are $\\alpha$-isomorphic if there is a bijection between their\nvertices which preserves at least $\\alpha m$ edges.) Our second result is that\nunder the {\\sc R3XOR} Hypothesis \\cite{Fei02} (and also any of a class of\nhypotheses which generalize the {\\sc R3XOR} Hypothesis), the \\emph{robust}\nGraph Isomorphism problem is hard. I.e.\\ for every $\\epsilon > 0$, there is no\nefficient algorithm which can distinguish graph pairs which are\n$(1-\\epsilon)$-isomorphic from pairs which are not even\n$(1-\\epsilon_0)$-isomorphic for some universal constant $\\epsilon_0$. Along the\nway we prove a robust asymmetry result for random graphs and hypergraphs which\nmay be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 19:50:15 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["O'Donnell", "Ryan", ""], ["Wright", "John", ""], ["Wu", "Chenggang", ""], ["Zhou", "Yuan", ""]]}, {"id": "1401.2444", "submitter": "Ryan Williams", "authors": "Ryan Williams", "title": "New algorithms and lower bounds for circuits with linear threshold gates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $ACC \\circ THR$ be the class of constant-depth circuits comprised of AND,\nOR, and MOD$m$ gates (for some constant $m > 1$), with a bottom layer of gates\ncomputing arbitrary linear threshold functions. This class of circuits can be\nseen as a \"midpoint\" between $ACC$ (where we know nontrivial lower bounds) and\ndepth-two linear threshold circuits (where nontrivial lower bounds remain\nopen).\n  We give an algorithm for evaluating an arbitrary symmetric function of\n$2^{n^{o(1)}}$ $ACC \\circ THR$ circuits of size $2^{n^{o(1)}}$, on all possible\ninputs, in $2^n \\cdot poly(n)$ time. Several consequences are derived:\n  $\\bullet$ The number of satisfying assignments to an $ACC \\circ THR$ circuit\nof subexponential size can be computed in $2^{n-n^{\\varepsilon}}$ time (where\n$\\varepsilon > 0$ depends on the depth and modulus of the circuit).\n  $\\bullet$ $NEXP$ does not have quasi-polynomial size $ACC \\circ THR$\ncircuits, nor does $NEXP$ have quasi-polynomial size $ACC \\circ SYM$ circuits.\nNontrivial size lower bounds were not known even for $AND \\circ OR \\circ THR$\ncircuits.\n  $\\bullet$ Every 0-1 integer linear program with $n$ Boolean variables and $s$\nlinear constraints is solvable in $2^{n-\\Omega(n/((\\log M)(\\log s)^{5}))}\\cdot\npoly(s,n,M)$ time with high probability, where $M$ upper bounds the bit\ncomplexity of the coefficients. (For example, 0-1 integer programs with weights\nin $[-2^{poly(n)},2^{poly(n)}]$ and $poly(n)$ constraints can be solved in\n$2^{n-\\Omega(n/\\log^6 n)}$ time.)\n  We also present an algorithm for evaluating depth-two linear threshold\ncircuits (a.k.a., $THR \\circ THR$) with exponential weights and $2^{n/24}$ size\non all $2^n$ input assignments, running in $2^n \\cdot poly(n)$ time. This is\nevidence that non-uniform lower bounds for $THR \\circ THR$ are within reach.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 20:25:33 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Williams", "Ryan", ""]]}, {"id": "1401.2532", "submitter": "Yash Raj Shrestha", "authors": "Jiong Guo and Yash Raj Shrestha", "title": "Parameterized Complexity of Edge Interdiction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of interdiction problems in graphs. For\nan optimization problem on graphs, one can formulate an interdiction problem as\na game consisting of two players, namely, an interdictor and an evader, who\ncompete on an objective with opposing interests. In edge interdiction problems,\nevery edge of the input graph has an interdiction cost associated with it and\nthe interdictor interdicts the graph by modifying the edges in the graph, and\nthe number of such modifications is constrained by the interdictor's budget.\nThe evader then solves the given optimization problem on the modified graph.\nThe action of the interdictor must impede the evader as much as possible. We\nfocus on edge interdiction problems related to minimum spanning tree, maximum\nmatching and shortest paths. These problems arise in different real world\nscenarios. We derive several fixed-parameter tractability and W[1]-hardness\nresults for these interdiction problems with respect to various parameters.\nNext, we show close relation between interdiction problems and partial cover\nproblems on bipartite graphs where the goal is not to cover all elements but to\nminimize/maximize the number of covered elements with specific number of sets.\nHereby, we investigate the parameterized complexity of several partial cover\nproblems on bipartite graphs.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2014 14:24:12 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Guo", "Jiong", ""], ["Shrestha", "Yash Raj", ""]]}, {"id": "1401.2861", "submitter": "Arno Pauly", "authors": "Akitoshi Kawamura and Arno Pauly", "title": "Function spaces for second-order polynomial time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of second-order polynomial-time computability, we prove that\nthere is no general function space construction. We proceed to identify\nrestrictions on the domain or the codomain that do provide a function space\nwith polynomial-time function evaluation containing all polynomial-time\ncomputable functions of that type.\n  As side results we show that a polynomial-time counterpart to admissibility\nof a representation is not a suitable criterion for natural representations,\nand that the Weihrauch degrees embed into the polynomial-time Weihrauch\ndegrees.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 15:08:05 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2015 10:42:25 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Kawamura", "Akitoshi", ""], ["Pauly", "Arno", ""]]}, {"id": "1401.2929", "submitter": "Tomoyuki Yamakami", "authors": "Harumichi Nishimura and Tomoyuki Yamakami", "title": "Interactive Proofs with Quantum Finite Automata", "comments": "A4, 10pt, 2 figures, 20 pages. This paper is a complete version of\n  the second half part of the extended abstract appearing in the Proc. of CIAA\n  2004, LNCS vol.3317, pp.225-236. A complete version of the first half had\n  already appeared in JCSS, 2009. (*) Please note that there is a substantial\n  text overlap with arXiv:quant-ph/0410040 as explained as above", "journal-ref": "Theoretical Computer Science, vol. 568, pp. 1-18, 2015", "doi": "10.1016/j.tcs.2014.11.030", "report-no": null, "categories": "quant-ph cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following an early work of Dwork and Stockmeyer on interactive proof systems\nwhose verifiers are two-way probabilistic finite automata, the authors\ninitiated in 2004 a study on the computational power of quantum interactive\nproof systems whose verifiers are particularly limited to quantum finite\nautomata. As a follow-up to the authors' early journal publication [J. Comput.\nSystem Sci., vol.75, pp.255-269, 2009], we further investigate the quantum\nnature of interactions between provers and verifiers by studying how various\nrestrictions on quantum interactive proof systems affect the language\nrecognition power of the proof systems. In particular, we examine three\nintriguing restrictions that (i) provers always behave in a classical fashion,\n(ii) verifiers always reveal to provers the information on next moves, and\n(iii) the number of interactions between provers and verifiers is bounded.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 17:39:00 GMT"}, {"version": "v2", "created": "Fri, 15 Aug 2014 16:38:52 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Nishimura", "Harumichi", ""], ["Yamakami", "Tomoyuki", ""]]}, {"id": "1401.3063", "submitter": "Neil Lutz", "authors": "Jack H. Lutz and Neil Lutz", "title": "Lines Missing Every Random Point", "comments": "Added a section: \"Betting in Doubly Exponential Time.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that there is, in every direction in Euclidean space, a line that\nmisses every computably random point. We also prove that there exist, in every\ndirection in Euclidean space, arbitrarily long line segments missing every\ndouble exponential time random point.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 04:45:17 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2014 01:03:53 GMT"}, {"version": "v3", "created": "Thu, 24 Jul 2014 00:50:16 GMT"}], "update_date": "2014-07-25", "authors_parsed": [["Lutz", "Jack H.", ""], ["Lutz", "Neil", ""]]}, {"id": "1401.3467", "submitter": "Omer Gim\\'enez", "authors": "Omer Gim\\'enez, Anders Jonsson", "title": "Planning over Chain Causal Graphs for Variables with Domains of Size 5\n  Is NP-Hard", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 34, pages\n  675-706, 2009", "doi": "10.1613/jair.2742", "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, considerable focus has been given to the problem of determining the\nboundary between tractable and intractable planning problems. In this paper, we\nstudy the complexity of planning in the class C_n of planning problems,\ncharacterized by unary operators and directed path causal graphs. Although this\nis one of the simplest forms of causal graphs a planning problem can have, we\nshow that planning is intractable for C_n (unless P = NP), even if the domains\nof state variables have bounded size. In particular, we show that plan\nexistence for C_n^k is NP-hard for k>=5 by reduction from CNFSAT. Here, k\ndenotes the upper bound on the size of the state variable domains. Our result\nreduces the complexity gap for the class C_n^k to cases k=3 and k=4 only, since\nC_n^2 is known to be tractable.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 05:25:29 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Gim\u00e9nez", "Omer", ""], ["Jonsson", "Anders", ""]]}, {"id": "1401.3613", "submitter": "Hector Zenil", "authors": "Hector Zenil", "title": "Turing Minimalism and the Emergence of Complexity", "comments": "As accepted The Rutherford Journal - The New Zealand Journal for the\n  History and Philosophy of Science and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not only did Turing help found one of the most exciting areas of modern\nscience (computer science), but it may be that his contribution to our\nunderstanding of our physical reality is greater than we had hitherto supposed.\nHere I explore the path that Alan Turing would have certainly liked to follow,\nthat of complexity science, which was launched in the wake of his seminal work\non computability and structure formation. In particular, I will explain how the\ntheory of algorithmic probability based on Turing's universal machine can also\nexplain how structure emerges at the most basic level, hence reconnecting two\nof Turing's most cherished topics: computation and pattern formation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 14:49:28 GMT"}, {"version": "v2", "created": "Thu, 31 Jul 2014 00:24:46 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Zenil", "Hector", ""]]}, {"id": "1401.3687", "submitter": "Kyle Burke", "authors": "Kyle Burke", "title": "$2^3$ Quantified Boolean Formula Games and Their Complexities", "comments": "14 pages, 0 figures, for Integers 2013 Conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider QBF, the Quantified Boolean Formula problem, as a combinatorial game\nruleset. The problem is rephrased as determining the winner of the game where\ntwo opposing players take turns assigning values to boolean variables. In this\npaper, three common variations of games are applied to create seven new games:\nwhether each player is restricted to where they may play, which values they may\nset variables to, or the condition they are shooting for at the end of the\ngame. The complexity for determining which player can win is analyzed for all\ngames. Of the seven, two are trivially in P and the other five are\nPSPACE-complete. These varying properties are common for combinatorial games;\nreductions from these five hard games can simplify the process for showing the\nPSPACE-hardness of other games.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 17:55:42 GMT"}, {"version": "v2", "created": "Mon, 29 Dec 2014 23:25:09 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Burke", "Kyle", ""]]}, {"id": "1401.3714", "submitter": "Rafael Mendes de Oliveira", "authors": "Zeev Dvir, Rafael Oliveira, Amir Shpilka", "title": "Testing Equivalence of Polynomials under Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two polynomials $f, g \\in \\mathbb{F}[x_1, \\ldots, x_n]$ are called\nshift-equivalent if there exists a vector $(a_1, \\ldots, a_n) \\in \\mathbb{F}^n$\nsuch that the polynomial identity $f(x_1+a_1, \\ldots, x_n+a_n) \\equiv\ng(x_1,\\ldots,x_n)$ holds. Our main result is a new randomized algorithm that\ntests whether two given polynomials are shift equivalent. Our algorithm runs in\ntime polynomial in the circuit size of the polynomials, to which it is given\nblack box access. This complements a previous work of Grigoriev (Theoretical\nComputer Science, 1997) who gave a deterministic algorithm running in time\n$n^{O(d)}$ for degree $d$ polynomials.\n  Our algorithm uses randomness only to solve instances of the Polynomial\nIdentity Testing (PIT) problem. Hence, if one could de-randomize PIT (a\nlong-standing open problem in complexity) a de-randomization of our algorithm\nwould follow. This establishes an equivalence between de-randomizing\nshift-equivalence testing and de-randomizing PIT (both in the black-box and the\nwhite-box setting). For certain restricted models, such as Read Once Branching\nPrograms, we already obtain a deterministic algorithm using existing PIT\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 19:29:48 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2014 05:03:55 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Dvir", "Zeev", ""], ["Oliveira", "Rafael", ""], ["Shpilka", "Amir", ""]]}, {"id": "1401.3916", "submitter": "Sevag Gharibian", "authors": "Sevag Gharibian, Yichen Huang, Zeph Landau, Seung Woo Shin", "title": "Quantum Hamiltonian Complexity", "comments": "v4: published version, 127 pages, introduction expanded to include\n  brief introduction to quantum information, brief list of some recent\n  developments added, minor changes throughout", "journal-ref": "Foundations and Trends in Theoretical Computer Science: Vol. 10:\n  No. 3, pp 159-282, 2015", "doi": "10.1561/0400000066", "report-no": null, "categories": "quant-ph cond-mat.str-el cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint satisfaction problems are a central pillar of modern computational\ncomplexity theory. This survey provides an introduction to the rapidly growing\nfield of Quantum Hamiltonian Complexity, which includes the study of quantum\nconstraint satisfaction problems. Over the past decade and a half, this field\nhas witnessed fundamental breakthroughs, ranging from the establishment of a\n\"Quantum Cook-Levin Theorem\" to deep insights into the structure of 1D\nlow-temperature quantum systems via so-called area laws. Our aim here is to\nprovide a computer science-oriented introduction to the subject in order to\nhelp bridge the language barrier between computer scientists and physicists in\nthe field. As such, we include the following in this survey: (1) The\nmotivations and history of the field, (2) a glossary of condensed matter\nphysics terms explained in computer-science friendly language, (3) overviews of\ncentral ideas from condensed matter physics, such as indistinguishable\nparticles, mean field theory, tensor networks, and area laws, and (4) brief\nexpositions of selected computer science-based results in the area. For\nexample, as part of the latter, we provide a novel information theoretic\npresentation of Bravyi's polynomial time algorithm for Quantum 2-SAT.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 06:53:28 GMT"}, {"version": "v2", "created": "Fri, 12 Sep 2014 18:30:42 GMT"}, {"version": "v3", "created": "Mon, 15 Sep 2014 13:51:47 GMT"}, {"version": "v4", "created": "Mon, 4 Apr 2016 19:47:28 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Gharibian", "Sevag", ""], ["Huang", "Yichen", ""], ["Landau", "Zeph", ""], ["Shin", "Seung Woo", ""]]}, {"id": "1401.4512", "submitter": "Rahul Jain", "authors": "Rahul Jain, Troy Lee, Nisheeth K. Vishnoi", "title": "A quadratically tight partition bound for classical communication\n  complexity and query complexity", "comments": "8 pages, version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce, both for classical communication complexity and\nquery complexity, a modification of the 'partition bound' introduced by Jain\nand Klauck [2010]. We call it the 'public-coin partition bound'. We show that\n(the logarithm to the base two of) its communication complexity and query\ncomplexity versions form, for all relations, a quadratically tight lower bound\non the public-coin randomized communication complexity and randomized query\ncomplexity respectively.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2014 02:39:29 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Jain", "Rahul", ""], ["Lee", "Troy", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1401.4720", "submitter": "Bruno Grenet", "authors": "Bruno Grenet", "title": "Computing low-degree factors of lacunary polynomials: a Newton-Puiseux\n  approach", "comments": "22 pages", "journal-ref": "Proceedings of the 39th International Symposium on Symbolic and\n  Algebraic Computation (ISSAC'14), pp 224-231, ACM, 2014", "doi": "10.1145/2608628.2608649", "report-no": null, "categories": "cs.SC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for the computation of the irreducible factors of\ndegree at most $d$, with multiplicity, of multivariate lacunary polynomials\nover fields of characteristic zero. The algorithm reduces this computation to\nthe computation of irreducible factors of degree at most $d$ of univariate\nlacunary polynomials and to the factorization of low-degree multivariate\npolynomials. The reduction runs in time polynomial in the size of the input\npolynomial and in $d$. As a result, we obtain a new polynomial-time algorithm\nfor the computation of low-degree factors, with multiplicity, of multivariate\nlacunary polynomials over number fields, but our method also gives partial\nresults for other fields, such as the fields of $p$-adic numbers or for\nabsolute or approximate factorization for instance.\n  The core of our reduction uses the Newton polygon of the input polynomial,\nand its validity is based on the Newton-Puiseux expansion of roots of bivariate\npolynomials. In particular, we bound the valuation of $f(X,\\phi)$ where $f$ is\na lacunary polynomial and $\\phi$ a Puiseux series whose vanishing polynomial\nhas low degree.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2014 19:23:24 GMT"}, {"version": "v2", "created": "Tue, 24 Jun 2014 07:38:52 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Grenet", "Bruno", ""]]}, {"id": "1401.4879", "submitter": "Marcello Mamino", "authors": "Marcello Mamino", "title": "On the Computing Power of $+$, $-$, and $\\times$", "comments": "11 pages, final version accepted by CSL-LICS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modify the Blum-Shub-Smale model of computation replacing the permitted\ncomputational primitives (the real field operations) with any finite set $B$ of\nreal functions semialgebraic over the rationals. Consider the class of boolean\ndecision problems that can be solved in polynomial time in the new model by\nmachines with no machine constants. How does this class depend on $B$? We prove\nthat it is always contained in the class obtained for $B = \\{+, -, \\times\\}$.\nMoreover, if $B$ is a set of continuous semialgebraic functions containing $+$\nand $-$, and such that arbitrarily small numbers can be computed using $B$,\nthen we have the following dichotomy: either our class is $\\mathsf P$ or it\ncoincides with the class obtained for $B = \\{+, -, \\times\\}$.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 12:54:33 GMT"}, {"version": "v2", "created": "Tue, 15 Apr 2014 19:28:32 GMT"}], "update_date": "2014-04-16", "authors_parsed": [["Mamino", "Marcello", ""]]}, {"id": "1401.5269", "submitter": "Stephan Mertens", "authors": "Stephan Mertens", "title": "Stable Roommates Problem with Random Preferences", "comments": "14 pages, 6 figures, 4 algorithms, 1 table; Journal of Statistical\n  Mechanics: Theory and Experiment (2015) P01020", "journal-ref": null, "doi": "10.1088/1742-5468/2015/01/P01020", "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stable roommates problem with $n$ agents has worst case complexity\n$O(n^2)$ in time and space. Random instances can be solved faster and with less\nmemory, however. We introduce an algorithm that has average time and space\ncomplexity $O(n^\\frac{3}{2})$ for random instances. We use this algorithm to\nsimulate large instances of the stable roommates problem and to measure the\nprobabilty $p_n$ that a random instance of size $n$ admits a stable matching.\nOur data supports the conjecture that $p_n = \\Theta(n^{-1/4})$.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 11:16:51 GMT"}, {"version": "v2", "created": "Wed, 21 Jan 2015 11:54:09 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Mertens", "Stephan", ""]]}, {"id": "1401.5354", "submitter": "Tillmann Miltzow", "authors": "Andrei Asinowski, Bal\\'azs Keszegh and Tillmann Miltzow", "title": "Counting Houses of Pareto Optimal Matchings in the House Allocation\n  Problem", "comments": "24 pages 2 Figures revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A,B$ with $|A| = m$ and $|B| = n\\ge m$ be two sets. We assume that every\nelement $a\\in A$ has a reference list over all elements from $B$. We call an\ninjective mapping $\\tau$ from $A$ to $B$ a matching. A blocking coalition of\n$\\tau$ is a subset $A'$ of $A$ such that there exists a matching $\\tau'$ that\ndiffers from $\\tau$ only on elements of $A'$, and every element of $A'$\nimproves in $\\tau'$, compared to $\\tau$ according to its preference list. If\nthere exists no blocking coalition, we call the matching $\\tau$ an exchange\nstable matching (ESM). An element $b\\in B$ is reachable if there exists an\nexchange stable matching using $b$. The set of all reachable elements is\ndenoted by $E^*$. We show \\[|E^*| \\leq \\sum_{i = 1,\\ldots,\nm}{\\left\\lfloor\\frac{m}{i}\\right\\rfloor} = \\Theta(m\\log m).\\] This is\nasymptotically tight. A set $E\\subseteq B$ is reachable (respectively exactly\nreachable) if there exists an exchange stable matching $\\tau$ whose image\ncontains $E$ as a subset (respectively equals $E$). We give bounds for the\nnumber of exactly reachable sets. We find that our results hold in the more\ngeneral setting of multi-matchings, when each element $a$ of $A$ is matched\nwith $\\ell_a$ elements of $B$ instead of just one. Further, we give complexity\nresults and algorithms for corresponding algorithmic questions. Finally, we\ncharacterize unavoidable elements, i.e., elements of $B$ that are used by all\nESM's. This yields efficient algorithms to determine all unavoidable elements.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 15:44:22 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 14:53:54 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2015 14:27:53 GMT"}, {"version": "v4", "created": "Thu, 17 Mar 2016 10:59:11 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Asinowski", "Andrei", ""], ["Keszegh", "Bal\u00e1zs", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "1401.5512", "submitter": "Stefan Schneider", "authors": "Russell Impagliazzo, Shachar Lovett, Ramamohan Paturi, Stefan\n  Schneider", "title": "0-1 Integer Linear Programming with a Linear Number of Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an exact algorithm for the 0-1 Integer Linear Programming problem\nwith a linear number of constraints that improves over exhaustive search by an\nexponential factor. Specifically, our algorithm runs in time\n$2^{(1-\\text{poly}(1/c))n}$ where n is the number of variables and cn is the\nnumber of constraints. The key idea for the algorithm is a reduction to the\nVector Domination problem and a new algorithm for that subproblem.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 22:46:18 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2014 23:27:30 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Impagliazzo", "Russell", ""], ["Lovett", "Shachar", ""], ["Paturi", "Ramamohan", ""], ["Schneider", "Stefan", ""]]}, {"id": "1401.5781", "submitter": "Dmitry Gavinsky", "authors": "Dmitry Gavinsky, Pavel Pudl\\'ak", "title": "Partition Expanders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new concept, which we call partition expanders. The basic idea\nis to study quantitative properties of graphs in a slightly different way than\nit is in the standard definition of expanders. While in the definition of\nexpanders it is required that the number of edges between any pair of\nsufficiently large sets is close to the expected number, we consider partitions\nand require this condition only for most of the pairs of blocks. As a result,\nthe blocks can be substantially smaller.\n  We show that for some range of parameters, to be a partition expander a\nrandom graph needs exponentially smaller degree than any expander would require\nin order to achieve similar expanding properties.\n  We apply the concept of partition expanders in communication complexity.\nFirst, we give a PRG for the SMP model of the optimal seed length, n+O(log k).\nSecond, we compare the model of SMP to that of Simultaneous Two-Way\nCommunication, and give a new separation that is stronger both qualitatively\nand quantitatively than the previously known ones.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 20:40:28 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Gavinsky", "Dmitry", ""], ["Pudl\u00e1k", "Pavel", ""]]}, {"id": "1401.5855", "submitter": "Martin C. Cooper", "authors": "Martin C. Cooper, Stanislav \\v{Z}ivn\\'y", "title": "Tractable Triangles and Cross-Free Convexity in Discrete Optimisation", "comments": "arXiv admin note: text overlap with arXiv:1008.4035 by other authors", "journal-ref": "Journal Of Artificial Intelligence Research, Volume 44, pages\n  455-490, 2012", "doi": "10.1613/jair.3598", "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimisation problem of a sum of unary and pairwise functions of discrete\nvariables is a general NP-hard problem with wide applications such as computing\nMAP configurations in Markov Random Fields (MRF), minimising Gibbs energy, or\nsolving binary Valued Constraint Satisfaction Problems (VCSPs).\n  We study the computational complexity of classes of discrete optimisation\nproblems given by allowing only certain types of costs in every triangle of\nvariable-value assignments to three distinct variables. We show that for\nseveral computational problems, the only non- trivial tractable classes are the\nwell known maximum matching problem and the recently discovered joint-winner\nproperty. Our results, apart from giving complete classifications in the\nstudied cases, provide guidance in the search for hybrid tractable classes;\nthat is, classes of problems that are not captured by restrictions on the\nfunctions (such as submodularity) or the structure of the problem graph (such\nas bounded treewidth).\n  Furthermore, we introduce a class of problems with convex cardinality\nfunctions on cross-free sets of assignments. We prove that while imposing only\none of the two conditions renders the problem NP-hard, the conjunction of the\ntwo gives rise to a novel tractable class satisfying the cross-free convexity\nproperty, which generalises the joint-winner property to problems of unbounded\narity.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 02:45:30 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Cooper", "Martin C.", ""], ["\u017divn\u00fd", "Stanislav", ""]]}, {"id": "1401.6011", "submitter": "Michael Sagraloff", "authors": "Michael Sagraloff", "title": "A Near-Optimal Algorithm for Computing Real Roots of Sparse Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CC cs.SC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $p\\in\\mathbb{Z}[x]$ be an arbitrary polynomial of degree $n$ with $k$\nnon-zero integer coefficients of absolute value less than $2^\\tau$. In this\npaper, we answer the open question whether the real roots of $p$ can be\ncomputed with a number of arithmetic operations over the rational numbers that\nis polynomial in the input size of the sparse representation of $p$. More\nprecisely, we give a deterministic, complete, and certified algorithm that\ndetermines isolating intervals for all real roots of $p$ with\n$O(k^3\\cdot\\log(n\\tau)\\cdot \\log n)$ many exact arithmetic operations over the\nrational numbers.\n  When using approximate but certified arithmetic, the bit complexity of our\nalgorithm is bounded by $\\tilde{O}(k^4\\cdot n\\tau)$, where $\\tilde{O}(\\cdot)$\nmeans that we ignore logarithmic. Hence, for sufficiently sparse polynomials\n(i.e. $k=O(\\log^c (n\\tau))$ for a positive constant $c$), the bit complexity is\n$\\tilde{O}(n\\tau)$. We also prove that the latter bound is optimal up to\nlogarithmic factors.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 15:43:06 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Sagraloff", "Michael", ""]]}, {"id": "1401.6030", "submitter": "Sergey Sysoev", "authors": "Sergey Sysoev", "title": "The Effective Solving of the Tasks from NP by a Quantum Computer", "comments": "The paper is submitted to the IEEE Transactions on Information Theory\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new model of quantum computation is proposed, for which an effective\nalgorithm of solving any task in NP is described. The work is based and\ninspired be the Grover's algorithm for solving NP-tasks with quadratic speedup\ncompared to the classical computation model. The provided model and algorithm\nexhibit the exponential speedup over that described by Grover.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 16:10:16 GMT"}, {"version": "v2", "created": "Tue, 9 Dec 2014 14:35:41 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Sysoev", "Sergey", ""]]}, {"id": "1401.6189", "submitter": "Zeev Dvir", "authors": "Jean Bourgain, Zeev Dvir, Ethan Leeman", "title": "Affine extractors over large fields with exponential error", "comments": "To appear in Comput. Complex", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a construction of explicit affine extractors over large finite\nfields with exponentially small error and linear output length. Our\nconstruction relies on a deep theorem of Deligne giving tight estimates for\nexponential sums over smooth varieties in high dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 21:15:16 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Bourgain", "Jean", ""], ["Dvir", "Zeev", ""], ["Leeman", "Ethan", ""]]}, {"id": "1401.6307", "submitter": "Florent Capelli", "authors": "Florent Capelli, Arnaud Durand, Stefan Mengel", "title": "Hypergraph Acyclicity and Propositional Model Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the propositional model counting problem #SAT for CNF- formulas\nwith hypergraphs that allow a disjoint branches decomposition can be solved in\npolynomial time. We show that this class of hypergraphs is incomparable to\nhypergraphs of bounded incidence cliquewidth which were the biggest class of\nhypergraphs for which #SAT was known to be solvable in polynomial time so far.\nFurthermore, we present a polynomial time algorithm that computes a disjoint\nbranches decomposition of a given hypergraph if it exists and rejects\notherwise. Finally, we show that some slight extensions of the class of\nhypergraphs with disjoint branches decompositions lead to intractable #SAT,\nleaving open how to generalize the counting result of this paper.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 10:33:23 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Capelli", "Florent", ""], ["Durand", "Arnaud", ""], ["Mengel", "Stefan", ""]]}, {"id": "1401.6520", "submitter": "Peng Cui", "authors": "Peng Cui", "title": "Approximation Resistance by Disguising Biased Distributions", "comments": "6 pages, short note", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, the author shows that the gap problem of some 3-XOR is\nNP-hard and can be solved by running Charikar\\&Wirth's SDP algorithm for two\nrounds. To conclude, the author proves that $P=NP$.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 11:21:08 GMT"}, {"version": "v10", "created": "Thu, 12 Jun 2014 05:52:55 GMT"}, {"version": "v11", "created": "Thu, 7 Aug 2014 07:17:04 GMT"}, {"version": "v12", "created": "Thu, 14 Aug 2014 07:15:49 GMT"}, {"version": "v13", "created": "Fri, 12 Sep 2014 02:07:14 GMT"}, {"version": "v14", "created": "Tue, 30 Sep 2014 07:20:49 GMT"}, {"version": "v15", "created": "Thu, 1 Jan 2015 11:12:18 GMT"}, {"version": "v16", "created": "Sat, 28 Feb 2015 03:30:08 GMT"}, {"version": "v17", "created": "Wed, 29 Apr 2015 08:41:15 GMT"}, {"version": "v18", "created": "Mon, 1 Jun 2015 09:21:10 GMT"}, {"version": "v19", "created": "Thu, 2 Jul 2015 10:30:41 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2014 04:35:00 GMT"}, {"version": "v20", "created": "Tue, 11 Aug 2015 06:11:00 GMT"}, {"version": "v21", "created": "Wed, 7 Oct 2015 12:42:15 GMT"}, {"version": "v22", "created": "Wed, 14 Oct 2015 03:56:22 GMT"}, {"version": "v23", "created": "Mon, 19 Oct 2015 18:57:42 GMT"}, {"version": "v24", "created": "Mon, 9 Nov 2015 16:39:22 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2014 03:29:43 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2014 09:54:46 GMT"}, {"version": "v5", "created": "Sat, 22 Feb 2014 11:12:49 GMT"}, {"version": "v6", "created": "Mon, 31 Mar 2014 11:07:26 GMT"}, {"version": "v7", "created": "Mon, 7 Apr 2014 09:02:37 GMT"}, {"version": "v8", "created": "Mon, 14 Apr 2014 00:59:14 GMT"}, {"version": "v9", "created": "Thu, 1 May 2014 03:39:32 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Cui", "Peng", ""]]}, {"id": "1401.6686", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh, Russell Greiner", "title": "Perturbed Message Passing for Constraint Satisfaction Problems", "comments": null, "journal-ref": "JMLR 16(Jul):1249-1274, 2015", "doi": null, "report-no": null, "categories": "cs.AI cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an efficient message passing scheme for solving Constraint\nSatisfaction Problems (CSPs), which uses stochastic perturbation of Belief\nPropagation (BP) and Survey Propagation (SP) messages to bypass decimation and\ndirectly produce a single satisfying assignment. Our first CSP solver, called\nPerturbed Blief Propagation, smoothly interpolates two well-known inference\nprocedures; it starts as BP and ends as a Gibbs sampler, which produces a\nsingle sample from the set of solutions. Moreover we apply a similar\nperturbation scheme to SP to produce another CSP solver, Perturbed Survey\nPropagation. Experimental results on random and real-world CSPs show that\nPerturbed BP is often more successful and at the same time tens to hundreds of\ntimes more efficient than standard BP guided decimation. Perturbed BP also\ncompares favorably with state-of-the-art SP-guided decimation, which has a\ncomputational complexity that generally scales exponentially worse than our\nmethod (wrt the cardinality of variable domains and constraints). Furthermore,\nour experiments with random satisfiability and coloring problems demonstrate\nthat Perturbed SP can outperform SP-guided decimation, making it the best\nincomplete random CSP-solver in difficult regimes.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2014 20:32:35 GMT"}, {"version": "v2", "created": "Thu, 22 Jan 2015 00:05:44 GMT"}, {"version": "v3", "created": "Tue, 3 Feb 2015 00:13:28 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Greiner", "Russell", ""]]}, {"id": "1401.6835", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM, IMJ), Micha{\\l} Skrzypczak", "title": "On the Topological Complexity of omega-Languages of Non-Deterministic\n  Petri Nets", "comments": null, "journal-ref": "Information Processing Letters 114, 5 (2014) 229-233", "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there are $\\Sigma_3^0$-complete languages of infinite words\naccepted by non-deterministic Petri nets with B\\\"uchi acceptance condition, or\nequivalently by B\\\"uchi blind counter automata. This shows that omega-languages\naccepted by non-deterministic Petri nets are topologically more complex than\nthose accepted by deterministic Petri nets.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 12:58:10 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Finkel", "Olivier", "", "ELM, IMJ"], ["Skrzypczak", "Micha\u0142", ""]]}, {"id": "1401.6848", "submitter": "Scott Aaronson", "authors": "Scott Aaronson and Russell Impagliazzo and Dana Moshkovitz", "title": "AM with Multiple Merlins", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study a new model of interactive proofs: AM(k), or\nArthur-Merlin with k non-communicating Merlins. Unlike with the better-known\nMIP, here the assumption is that each Merlin receives an independent random\nchallenge from Arthur. One motivation for this model (which we explore in\ndetail) comes from the close analogies between it and the quantum complexity\nclass QMA(k), but the AM(k) model is also natural in its own right.\n  We illustrate the power of multiple Merlins by giving an AM(2) protocol for\n3SAT, in which the Merlins' challenges and responses consist of only\nn^{1/2+o(1)} bits each. Our protocol has the consequence that, assuming the\nExponential Time Hypothesis (ETH), any algorithm for approximating a dense CSP\nwith a polynomial-size alphabet must take n^{(log n)^{1-o(1)}} time. Algorithms\nnearly matching this lower bound are known, but their running times had never\nbeen previously explained. Brandao and Harrow have also recently used our 3SAT\nprotocol to show quasipolynomial hardness for approximating the values of\ncertain entangled games.\n  In the other direction, we give a simple quasipolynomial-time approximation\nalgorithm for free games, and use it to prove that, assuming the ETH, our 3SAT\nprotocol is essentially optimal. More generally, we show that multiple Merlins\nnever provide more than a polynomial advantage over one: that is, AM(k)=AM for\nall k=poly(n). The key to this result is a subsampling theorem for free games,\nwhich follows from powerful results by Alon et al. and Barak et al. on\nsubsampling dense CSPs, and which says that the value of any free game can be\nclosely approximated by the value of a logarithmic-sized random subgame.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 13:48:49 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Aaronson", "Scott", ""], ["Impagliazzo", "Russell", ""], ["Moshkovitz", "Dana", ""]]}, {"id": "1401.7480", "submitter": "Bruce Litow", "authors": "Bruce Litow", "title": "NP is contained in DTIME(n^O(log^{gamma}))", "comments": "This paper has been withdrawn due to a fatal flaw in the proof of\n  Lemma 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use existential Diophantine predicates carefully reinterpreted over the\nreals and the time complexity of Tarski algebra to show that 3-CNF SAT is in\nn^O(log^{gamma} n) time for an absolute positive constant gamma.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 12:07:54 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2014 20:41:46 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2014 17:51:20 GMT"}, {"version": "v4", "created": "Thu, 1 Mar 2018 19:57:17 GMT"}, {"version": "v5", "created": "Fri, 9 Mar 2018 21:24:25 GMT"}, {"version": "v6", "created": "Mon, 29 Jun 2020 20:14:38 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Litow", "Bruce", ""]]}, {"id": "1401.7714", "submitter": "Francois Le Gall", "authors": "Fran\\c{c}ois Le Gall", "title": "Powers of Tensors and Fast Matrix Multiplication", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method to analyze the powers of a given trilinear form\n(a special kind of algebraic constructions also called a tensor) and obtain\nupper bounds on the asymptotic complexity of matrix multiplication. Compared\nwith existing approaches, this method is based on convex optimization, and thus\nhas polynomial-time complexity. As an application, we use this method to study\npowers of the construction given by Coppersmith and Winograd [Journal of\nSymbolic Computation, 1990] and obtain the upper bound $\\omega<2.3728639$ on\nthe exponent of square matrix multiplication, which slightly improves the best\nknown upper bound.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 01:11:22 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "1401.8046", "submitter": "Nerio Borges", "authors": "Nerio Borges (Universidad Sim\\'on Bol\\'ivar), Blai Bonet (Universidad\n  Sim\\'on Bol\\'ivar)", "title": "Universal First-Order Logic is Superfluous for NL, P, NP and coNP", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 1 (March 3,\n  2014) lmcs:1011", "doi": "10.2168/LMCS-10(1:15)2014", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we continue the syntactic study of completeness that began with\nthe works of Immerman and Medina. In particular, we take a conjecture raised by\nMedina in his dissertation that says if a conjunction of a second-order and a\nfirst-order sentences defines an NP-complete problems via fops, then it must be\nthe case that the second-order conjoint alone also defines a NP-complete\nproblem. Although this claim looks very plausible and intuitive, currently we\ncannot provide a definite answer for it. However, we can solve in the\naffirmative a weaker claim that says that all ``consistent'' universal\nfirst-order sentences can be safely eliminated without the fear of losing\ncompleteness. Our methods are quite general and can be applied to complexity\nclasses other than NP (in this paper: to NLSPACE, PTIME, and coNP), provided\nthe class has a complete problem satisfying a certain combinatorial property.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 02:44:45 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2014 09:03:06 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Borges", "Nerio", "", "Universidad Sim\u00f3n Bol\u00edvar"], ["Bonet", "Blai", "", "Universidad\n  Sim\u00f3n Bol\u00edvar"]]}, {"id": "1401.8135", "submitter": "Sascha Kurz", "authors": "Sascha Kurz", "title": "Competitive learning of monotone Boolean functions", "comments": "5 pages, 2 figures, presented at APMOD 2012", "journal-ref": "Suhl, Leena; Mitra, Gautam et al. (ed.): Applied Mathematical\n  Optimization and Modelling, APMOD 2012, DS&OR Lab, Vol. 8, Pages 416-421", "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply competitive analysis onto the problem of minimizing the number of\nqueries to an oracle to completely reconstruct a given monotone Boolean\nfunction. Besides lower and upper bounds on the competitivity we determine\noptimal deterministic online algorithms for the smallest problem instances.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 11:23:52 GMT"}], "update_date": "2014-02-03", "authors_parsed": [["Kurz", "Sascha", ""]]}]