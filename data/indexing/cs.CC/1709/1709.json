[{"id": "1709.00596", "submitter": "D\\\"om\\\"ot\\\"or P\\'alv\\\"olgyi", "authors": "D\\\"om\\\"ot\\\"or P\\'alv\\\"olgyi", "title": "Complexity of Domination in Triangulated Plane Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that for a triangulated plane graph it is NP-complete to determine\nits domination number and its power domination number.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 15:21:07 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["P\u00e1lv\u00f6lgyi", "D\u00f6m\u00f6t\u00f6r", ""]]}, {"id": "1709.00735", "submitter": "Burhan Gulbahar", "authors": "Burhan Gulbahar", "title": "Quantum Path Computing: Computing Architecture with Propagation Paths in\n  Multiple Plane Diffraction of Classical Sources of Fermion and Boson\n  Particles", "comments": "This is a pre-print of an article published in Quantum Information\n  Processing. The final authenticated version is available online at:\n  https://doi.org/10.1007/s11128-019-2286-6. There are many important revisions\n  compared with the previous version", "journal-ref": "Quantum Inf Process (2019) 18: 167", "doi": "10.1007/s11128-019-2286-6", "report-no": null, "categories": "quant-ph cs.CC cs.IT math-ph math.IT math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing (QC) architectures utilizing classical or coherent\nresources with Gaussian transformations are classically simulable as an\nindicator of the lack of QC power. Simple optical set-ups utilizing\nwave-particle duality and interferometers achieve QC speed-up with the cost of\nexponential complexity of resources in time, space or energy. However, linear\noptical networks composed of single photon inputs and photon number\nmeasurements such as boson sampling achieve solving problems which are not\nefficiently solvable by classical computers while emphasizing the power of\nlinear optics. In this article, quantum path computing (QPC) set-up is\nintroduced as the simplest optical QC satisfying five fundamental properties\nall-in-one: exploiting only the coherent sources being either fermion or boson,\ni.e., Gaussian wave packet of standard laser, simple set-up of multiple plane\ndiffraction (MPD) with multiple slits by creating distinct propagation paths,\nstandard intensity measurement on the detector, energy efficient design and\npractical problem solving capability. MPD is unique with non-Gaussian\ntransformations by realizing an exponentially increasing number of highly\ninterfering propagation paths while making classical simulation significantly\nhard. It does not require single photon resources or number resolving detection\nmechanisms making the experimental implementation of QC significantly low\ncomplexity. QPC set-up is utilized for the solutions of specific instances of\ntwo practical and hard number theoretical problems: partial sum of Riemann\ntheta function and period finding to solve Diophantine approximation.\nQuantumness of MPD with negative volume of Wigner function is numerically\nanalyzed and open issues for the best utilization of QPC are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 15:36:58 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 07:12:42 GMT"}, {"version": "v3", "created": "Tue, 31 Oct 2017 17:02:29 GMT"}, {"version": "v4", "created": "Wed, 25 Dec 2019 18:25:35 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Gulbahar", "Burhan", ""]]}, {"id": "1709.00900", "submitter": "Stefan Neumann", "authors": "Stefan Neumann, Pauli Miettinen", "title": "Reductions for Frequency-Based Data Mining Problems", "comments": "This is an extended version of a paper of the same title to appear in\n  the Proceedings of the 17th IEEE International Conference on Data Mining\n  (ICDM'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the computational complexity of problems is one of the - if not the\n- fundamental questions in computer science. Yet, surprisingly little is known\nabout the computational complexity of many central problems in data mining. In\nthis paper we study frequency-based problems and propose a new type of\nreduction that allows us to compare the complexities of the maximal frequent\npattern mining problems in different domains (e.g. graphs or sequences). Our\nresults extend those of Kimelfeld and Kolaitis [ACM TODS, 2014] to a broader\nrange of data mining problems. Our results show that, by allowing constraints\nin the pattern space, the complexities of many maximal frequent pattern mining\nproblems collapse. These problems include maximal frequent subgraphs in\nlabelled graphs, maximal frequent itemsets, and maximal frequent subsequences\nwith no repetitions. In addition to theoretical interest, our results might\nyield more efficient algorithms for the studied problems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 11:12:55 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Neumann", "Stefan", ""], ["Miettinen", "Pauli", ""]]}, {"id": "1709.01241", "submitter": "Jayson Lynch", "authors": "Erik D. Demaine, Isaac Grosof, Jayson Lynch", "title": "Push-Pull Block Puzzles are Hard", "comments": "Full version of CIAC 2017 paper. 17 pages", "journal-ref": "Algorithms and Complexity: 10th International Conference, CIAC\n  2017, Athens, Greece, May 24-26, 2017, Proceedings", "doi": "10.1007/978-3-319-57586-516", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proves that push-pull block puzzles in 3D are PSPACE-complete to\nsolve, and push-pull block puzzles in 2D with thin walls are NP-hard to solve,\nsettling an open question by Zubaran and Ritt. Push-pull block puzzles are a\ntype of recreational motion planning problem, similar to Sokoban, that involve\nmoving a `robot' on a square grid with $1 \\times 1$ obstacles. The obstacles\ncannot be traversed by the robot, but some can be pushed and pulled by the\nrobot into adjacent squares. Thin walls prevent movement between two adjacent\nsquares. This work follows in a long line of algorithms and complexity work on\nsimilar problems. The 2D push-pull block puzzle shows up in the video games\nPukoban as well as The Legend of Zelda: A Link to the Past, giving another\nproof of hardness for the latter. This variant of block-pushing puzzles is of\nparticular interest because of its connections to reversibility, since any\naction (e.g., push or pull) can be inverted by another valid action (e.g., pull\nor push).\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 05:42:05 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Demaine", "Erik D.", ""], ["Grosof", "Isaac", ""], ["Lynch", "Jayson", ""]]}, {"id": "1709.01670", "submitter": "Ren\\'e van Bevern", "authors": "Matthias Mnich, Ren\\'e van Bevern", "title": "Parameterized complexity of machine scheduling: 15 open problems", "comments": "Version accepted to Computers & Operations Research", "journal-ref": "Computers & Operations Research, 100:254--261, 2018", "doi": "10.1016/j.cor.2018.07.020", "report-no": null, "categories": "math.OC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine scheduling problems are a long-time key domain of algorithms and\ncomplexity research. A novel approach to machine scheduling problems are\nfixed-parameter algorithms. To stimulate this thriving research direction, we\npropose 15 open questions in this area whose resolution we expect to lead to\nthe discovery of new approaches and techniques both in scheduling and\nparameterized complexity theory.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 04:40:02 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 09:03:03 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2018 01:05:59 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Mnich", "Matthias", ""], ["van Bevern", "Ren\u00e9", ""]]}, {"id": "1709.01805", "submitter": "Dax Enshan Koh", "authors": "Adam Bouland, Joseph F. Fitzsimons, Dax Enshan Koh", "title": "Complexity Classification of Conjugated Clifford Circuits", "comments": "31 pages", "journal-ref": null, "doi": "10.4230/LIPIcs.CCC.2018.21", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clifford circuits -- i.e. circuits composed of only CNOT, Hadamard, and\n$\\pi/4$ phase gates -- play a central role in the study of quantum computation.\nHowever, their computational power is limited: a well-known result of Gottesman\nand Knill states that Clifford circuits are efficiently classically simulable.\nWe show that in contrast, \"conjugated Clifford circuits\" (CCCs) -- where one\nadditionally conjugates every qubit by the same one-qubit gate $U$ -- can\nperform hard sampling tasks. In particular, we fully classify the computational\npower of CCCs by showing that essentially any non-Clifford conjugating unitary\n$U$ can give rise to sampling tasks which cannot be efficiently classically\nsimulated to constant multiplicative error, unless the polynomial hierarchy\ncollapses. Furthermore, by standard techniques, this hardness result can be\nextended to allow for the more realistic model of constant additive error,\nunder a plausible complexity-theoretic conjecture. This work can be seen as\nprogress towards classifying the computational power of all restricted quantum\ngate sets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 12:46:12 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 13:42:30 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Bouland", "Adam", ""], ["Fitzsimons", "Joseph F.", ""], ["Koh", "Dax Enshan", ""]]}, {"id": "1709.02034", "submitter": "Alexander Golovnev", "authors": "Alexander Golovnev, Mika G\\\"o\\\"os, Daniel Reichman, Igor Shinkar", "title": "String Matching: Communication, Circuits, and Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String matching is the problem of deciding whether a given $n$-bit string\ncontains a given $k$-bit pattern. We study the complexity of this problem in\nthree settings.\n  Communication complexity. For small $k$, we provide near-optimal upper and\nlower bounds on the communication complexity of string matching. For large $k$,\nour bounds leave open an exponential gap; we exhibit some evidence for the\nexistence of a better protocol.\n  Circuit complexity. We present several upper and lower bounds on the size of\ncircuits with threshold and DeMorgan gates solving the string matching problem.\nSimilarly to the above, our bounds are near-optimal for small $k$.\n  Learning. We consider the problem of learning a hidden pattern of length at\nmost $k$ relative to the classifier that assigns 1 to every string that\ncontains the pattern. We prove optimal bounds on the VC dimension and sample\ncomplexity of this problem.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 00:52:20 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 17:34:43 GMT"}, {"version": "v3", "created": "Tue, 24 Jul 2018 01:04:55 GMT"}, {"version": "v4", "created": "Tue, 19 Feb 2019 21:53:24 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Golovnev", "Alexander", ""], ["G\u00f6\u00f6s", "Mika", ""], ["Reichman", "Daniel", ""], ["Shinkar", "Igor", ""]]}, {"id": "1709.02094", "submitter": "EPTCS", "authors": "Laura Bozzelli (Univ. of Napoli \"Federico II\", IT), Alberto Molinari\n  (Univ. of Udine, IT), Angelo Montanari (Univ. of Udine, IT), Adriano Peron\n  (Univ. of Napoli \"Federico II\", IT)", "title": "On the Complexity of Model Checking for Syntactically Maximal Fragments\n  of the Interval Temporal Logic HS with Regular Expressions", "comments": "In Proceedings GandALF 2017, arXiv:1709.01761", "journal-ref": "EPTCS 256, 2017, pp. 31-45", "doi": "10.4204/EPTCS.256.3", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the model checking (MC) problem for Halpern and\nShoham's interval temporal logic HS. In the last years, interval temporal logic\nMC has received an increasing attention as a viable alternative to the\ntraditional (point-based) temporal logic MC, which can be recovered as a\nspecial case. Most results have been obtained under the homogeneity assumption,\nthat constrains a proposition letter to hold over an interval if and only if it\nholds over each component state. Recently, Lomuscio and Michaliszyn proposed a\nway to relax such an assumption by exploiting regular expressions to define the\nbehaviour of proposition letters over intervals in terms of their component\nstates. When homogeneity is assumed, the exact complexity of MC is a difficult\nopen question for full HS and for its two syntactically maximal fragments\nAA'BB'E' and AA'EB'E'. In this paper, we provide an asymptotically optimal\nbound to the complexity of these two fragments under the more expressive\nsemantic variant based on regular expressions by showing that their MC problem\nis AEXP_pol-complete, where AEXP_pol denotes the complexity class of problems\ndecided by exponential-time bounded alternating Turing Machines making a\npolynomially bounded number of alternations.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 06:54:30 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Bozzelli", "Laura", "", "Univ. of Napoli \"Federico II\", IT"], ["Molinari", "Alberto", "", "Univ. of Udine, IT"], ["Montanari", "Angelo", "", "Univ. of Udine, IT"], ["Peron", "Adriano", "", "Univ. of Napoli \"Federico II\", IT"]]}, {"id": "1709.02180", "submitter": "Ioannis Katsikarelis", "authors": "Ioannis Katsikarelis, Michael Lampis, Vangelis Th. Paschos", "title": "Structurally Parameterized d-Scattered Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In $d$-Scattered Set we are given an (edge-weighted) graph and are asked to\nselect at least $k$ vertices, so that the distance between any pair is at least\n$d$, thus generalizing Independent Set. We provide upper and lower bounds on\nthe complexity of this problem with respect to various standard graph\nparameters. In particular, we show the following:\n  - For any $d\\ge2$, an $O^*(d^{\\textrm{tw}})$-time algorithm, where\n$\\textrm{tw}$ is the treewidth of the input graph.\n  - A tight SETH-based lower bound matching this algorithm's performance. These\ngeneralize known results for Independent Set.\n  - $d$-Scattered Set is W[1]-hard parameterized by vertex cover (for\nedge-weighted graphs), or feedback vertex set (for unweighted graphs), even if\n$k$ is an additional parameter.\n  - A single-exponential algorithm parameterized by vertex cover for unweighted\ngraphs, complementing the above-mentioned hardness.\n  - A $2^{O(\\textrm{td}^2)}$-time algorithm parameterized by tree-depth\n($\\textrm{td}$), as well as a matching ETH-based lower bound, both for\nunweighted graphs.\n  We complement these mostly negative results by providing an FPT approximation\nscheme parameterized by treewidth. In particular, we give an algorithm which,\nfor any error parameter $\\epsilon > 0$, runs in time\n$O^*((\\textrm{tw}/\\epsilon)^{O(\\textrm{tw})})$ and returns a\n$d/(1+\\epsilon)$-scattered set of size $k$, if a $d$-scattered set of the same\nsize exists.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 10:54:30 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 11:09:37 GMT"}, {"version": "v3", "created": "Mon, 30 Jul 2018 18:10:30 GMT"}, {"version": "v4", "created": "Sat, 10 Nov 2018 18:43:23 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Katsikarelis", "Ioannis", ""], ["Lampis", "Michael", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "1709.02311", "submitter": "Radu Curticapean", "authors": "Radu Curticapean, Nathan Lindzey, Jesper Nederlof", "title": "A Tight Lower Bound for Counting Hamiltonian Cycles via Matrix Rank", "comments": "improved lower bounds modulo primes, improved figures, to appear in\n  SODA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For even $k$, the matchings connectivity matrix $\\mathbf{M}_k$ encodes which\npairs of perfect matchings on $k$ vertices form a single cycle. Cygan et al.\n(STOC 2013) showed that the rank of $\\mathbf{M}_k$ over $\\mathbb{Z}_2$ is\n$\\Theta(\\sqrt 2^k)$ and used this to give an $O^*((2+\\sqrt{2})^{\\mathsf{pw}})$\ntime algorithm for counting Hamiltonian cycles modulo $2$ on graphs of\npathwidth $\\mathsf{pw}$. The same authors complemented their algorithm by an\nessentially tight lower bound under the Strong Exponential Time Hypothesis\n(SETH). This bound crucially relied on a large permutation submatrix within\n$\\mathbf{M}_k$, which enabled a \"pattern propagation\" commonly used in previous\nrelated lower bounds, as initiated by Lokshtanov et al. (SODA 2011).\n  We present a new technique for a similar pattern propagation when only a\nblack-box lower bound on the asymptotic rank of $\\mathbf{M}_k$ is given; no\nstronger structural insights such as the existence of large permutation\nsubmatrices in $\\mathbf{M}_k$ are needed. Given appropriate rank bounds, our\ntechnique yields lower bounds for counting Hamiltonian cycles (also modulo\nfixed primes $p$) parameterized by pathwidth.\n  To apply this technique, we prove that the rank of $\\mathbf{M}_k$ over the\nrationals is $4^k / \\mathrm{poly}(k)$. We also show that the rank of\n$\\mathbf{M}_k$ over $\\mathbb{Z}_p$ is $\\Omega(1.97^k)$ for any prime $p\\neq 2$\nand even $\\Omega(2.15^k)$ for some primes.\n  As a consequence, we obtain that Hamiltonian cycles cannot be counted in time\n$O^*((6-\\epsilon)^{\\mathsf{pw}})$ for any $\\epsilon>0$ unless SETH fails. This\nbound is tight due to a $O^*(6^{\\mathsf{pw}})$ time algorithm by Bodlaender et\nal. (ICALP 2013). Under SETH, we also obtain that Hamiltonian cycles cannot be\ncounted modulo primes $p\\neq 2$ in time $O^*(3.97^\\mathsf{pw})$, indicating\nthat the modulus can affect the complexity in intricate ways.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 15:29:11 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 17:17:10 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Curticapean", "Radu", ""], ["Lindzey", "Nathan", ""], ["Nederlof", "Jesper", ""]]}, {"id": "1709.02500", "submitter": "Mark Amo-Boateng PhD.", "authors": "Mark Amo-Boateng", "title": "Super-speeds with Zero-RAM: Next Generation Large-Scale Optimization in\n  Your Laptop!", "comments": "7 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS cs.PF math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the novel breakthrough general purpose algorithm for\nlarge scale optimization problems. The novel algorithm is capable of achieving\nbreakthrough speeds for very large-scale optimization on general purpose\nlaptops and embedded systems. Application of the algorithm to the Griewank\nfunction was possible in up to 1 billion decision variables in double precision\ntook only 64485 seconds (~18 hours) to solve, while consuming 7,630 MB (7.6 GB)\nor RAM on a single threaded laptop CPU. It shows that the algorithm is\ncomputationally and memory (space) linearly efficient, and can find the optimal\nor near-optimal solution in a fraction of the time and memory that many\nconventional algorithms require. It is envisaged that this will open up new\npossibilities of real-time large-scale problems on personal laptops and\nembedded systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 01:47:56 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 01:14:46 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Amo-Boateng", "Mark", ""]]}, {"id": "1709.02850", "submitter": "Piotr Skowron", "authors": "Robert Bredereck, Piotr Faliszewski, Rolf Niedermeier, Piotr Skowron,\n  Nimrod Talmon", "title": "Mixed Integer Programming with Convex/Concave Constraints:\n  Fixed-Parameter Tractability and Applications to Multicovering and Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic result of Lenstra [Math.~Oper.~Res.~1983] says that an integer\nlinear program can be solved in fixed-parameter tractable (FPT) time for the\nparameter being the number of variables. We extend this result by incorporating\nnon-decreasing piecewise linear convex or concave functions to our (mixed)\ninteger programs. This general technique allows us to establish parameterized\ncomplexity of a number of classic computational problems. In particular, we\nprove that Weighted Set Multicover is in FPT when parameterized by the number\nof elements to cover, and that there exists an FPT-time approximation scheme\nfor Multiset Multicover for the same parameter. Further, we use our general\ntechnique to prove that a number of problems from computational social choice\n(e.g., problems related to bribery and control in elections) are in FPT when\nparameterized by the number of candidates. For bribery, this resolves a nearly\n10-year old family of open problems, and for weighted electoral control of\nApproval voting, this improves some previously known XP-memberships to\nFPT-memberships.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 20:11:50 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 22:45:36 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Bredereck", "Robert", ""], ["Faliszewski", "Piotr", ""], ["Niedermeier", "Rolf", ""], ["Skowron", "Piotr", ""], ["Talmon", "Nimrod", ""]]}, {"id": "1709.03053", "submitter": "Salman Beigi", "authors": "Salman Beigi, Andrej Bogdanov, Omid Etesami, Siyao Guo", "title": "Complete Classification of Generalized Santha-Vazirani Sources", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathcal{F}$ be a finite alphabet and $\\mathcal{D}$ be a finite set of\ndistributions over $\\mathcal{F}$. A Generalized Santha-Vazirani (GSV) source of\ntype $(\\mathcal{F}, \\mathcal{D})$, introduced by Beigi, Etesami and Gohari\n(ICALP 2015, SICOMP 2017), is a random sequence $(F_1, \\dots, F_n)$ in\n$\\mathcal{F}^n$, where $F_i$ is a sample from some distribution $d \\in\n\\mathcal{D}$ whose choice may depend on $F_1, \\dots, F_{i-1}$.\n  We show that all GSV source types $(\\mathcal{F}, \\mathcal{D})$ fall into one\nof three categories: (1) non-extractable; (2) extractable with error\n$n^{-\\Theta(1)}$; (3) extractable with error $2^{-\\Omega(n)}$. This rules out\nother error rates like $1/\\log n$ or $2^{-\\sqrt{n}}$.\n  We provide essentially randomness-optimal extraction algorithms for\nextractable sources. Our algorithm for category (2) sources extracts with error\n$\\varepsilon$ from $n = \\mathrm{poly}(1/\\varepsilon)$ samples in time linear in\n$n$. Our algorithm for category (3) sources extracts $m$ bits with error\n$\\varepsilon$ from $n = O(m + \\log 1/\\varepsilon)$ samples in time\n$\\min\\{O(nm2^m),n^{O(\\lvert\\mathcal{F}\\rvert)}\\}$.\n  We also give algorithms for classifying a GSV source type $(\\mathcal{F},\n\\mathcal{D})$: Membership in category (1) can be decided in $\\mathrm{NP}$,\nwhile membership in category (3) is polynomial-time decidable.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 06:30:38 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Beigi", "Salman", ""], ["Bogdanov", "Andrej", ""], ["Etesami", "Omid", ""], ["Guo", "Siyao", ""]]}, {"id": "1709.03068", "submitter": "Anamay Tengse", "authors": "Ramprasad Saptharishi and Anamay Tengse", "title": "Quasi-polynomial Hitting Sets for Circuits with Restricted Parse Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the class of non-commutative Unambiguous circuits or\nUnique-Parse-Tree (UPT) circuits, and a related model of Few-Parse-Trees\n(FewPT) circuits (which were recently introduced by Lagarde, Malod and Perifel\n[LMP16] and Lagarde, Limaye and Srinivasan [LLS17]) and give the following\nconstructions:\n  (1) An explicit hitting set of quasipolynomial size for UPT circuits,\n  (2) An explicit hitting set of quasipolynomial size for FewPT circuits\n(circuits with constantly many parse tree shapes),\n  (3) An explicit hitting set of polynomial size for UPT circuits (of known\nparse tree shape), when a parameter of preimage-width is bounded by a constant.\n  The above three results are extensions of the results of [AGKS15], [GKST15]\nand [GKS16] to the setting of UPT circuits, and hence also generalize their\nresults in the commutative world from read-once oblivious algebraic branching\nprograms (ROABPs) to UPT-set-multilinear circuits. The main idea is to study\nshufflings of non-commutative polynomials, which can then be used to prove\nsuitable depth reduction results for UPT circuits and thereby allow a careful\ntranslation of the ideas in [AGKS15], [GKST15] and [GKS16].\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 08:33:58 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 08:56:56 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Saptharishi", "Ramprasad", ""], ["Tengse", "Anamay", ""]]}, {"id": "1709.03198", "submitter": "Aaron Potechin", "authors": "Aaron Potechin and Liu Yang", "title": "A Note on Property Testing Sum of Squares and Multivariate Polynomial\n  Interpolation", "comments": "20 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate property testing whether or not a degree d\nmultivariate poly- nomial is a sum of squares or is far from a sum of squares.\nWe show that if we require that the property tester always accepts YES\ninstances and uses random samples, $n^{\\Omega(d)}$ samples are required, which\nis not much fewer than it would take to completely determine the polynomial. To\nprove this lower bound, we show that with high probability, multivariate\npolynomial in- terpolation matches arbitrary values on random points and the\nresulting polynomial has small norm. We then consider a particular polynomial\nwhich is non-negative yet not a sum of squares and use pseudo-expectation\nvalues to prove it is far from being a sum of squares.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 23:44:13 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Potechin", "Aaron", ""], ["Yang", "Liu", ""]]}, {"id": "1709.03294", "submitter": "Pascal Koiran", "authors": "Pascal Koiran (LIP)", "title": "Root Separation for Trinomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a separation bound for the complex roots of a trinomial $f \\in\n\\mathbb{Z}[X]$. The logarithm of the inverse of our separation bound is\npolynomial in the size of the sparse encoding of $f$; in particular, it is\npolynomial in $\\log (\\deg f)$. It is known that no such bound is possible for\n4-nomials (polynomials with 4 monomials). For trinomials, the classical results\n(which are based on the degree of $f$ rather than the number of monomials) give\nseparation bounds that are exponentially worse.As an algorithmic application,\nwe show that the number of real roots of a trinomial $f$ can be computed in\ntime polynomial in the size of the sparse encoding of~$f$. The same problem is\nopen for 4-nomials.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 08:42:01 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 15:13:16 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 12:03:36 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Koiran", "Pascal", "", "LIP"]]}, {"id": "1709.03663", "submitter": "Kenneth Ascher", "authors": "Kenneth Ascher, Connor Dub\\'e, Daniel Gershenson, Elaine Hou", "title": "Enumerating Hassett's wall and chamber decomposition of the moduli space\n  of weighted stable curves", "comments": "Minor corrections made and paper reorganized. Version to appear in\n  Experimental Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hassett constructed a class of modular compactifications of the moduli space\nof pointed curves by adding weights to the marked points. This leads to a\nnatural wall and chamber decomposition of the domain of admissible weights\nwhere the moduli space and universal family remain constant inside a chamber,\nand may change upon crossing a wall. The goal of this paper is to count the\nnumber of chambers in this decomposition. We relate these chambers to a class\nof boolean functions known as linear threshold functions (LTFs), and discover a\nsubclass of LTFs which are in bijection with the chambers. Using this relation,\nwe prove an asymptotic formula for the number of chambers, and compute the\nexact number of chambers for moduli spaces of weighted stable curves with at\nmost 9 points. In addition, we provide an algorithm for the enumeration of the\nchambers and prove results in computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 02:45:28 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 19:48:21 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Ascher", "Kenneth", ""], ["Dub\u00e9", "Connor", ""], ["Gershenson", "Daniel", ""], ["Hou", "Elaine", ""]]}, {"id": "1709.04262", "submitter": "Will Rosenbaum", "authors": "Talya Eden and Will Rosenbaum", "title": "Lower Bounds for Approximating Graph Parameters via Communication\n  Complexity", "comments": "Current version includes new section on graph connectivity, as well\n  as various improvements throughout", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a celebrated work, Blais, Brody, and Matulef developed a technique for\nproving property testing lower bounds via reductions from communication\ncomplexity. Their work focused on testing properties of functions, and yielded\nnew lower bounds as well as simplified analyses of known lower bounds. Here, we\ntake a further step in generalizing the methodology of Blais et al. to analyze\nthe query complexity of graph parameter estimation problems. In particular, our\ntechnique decouples the lower bound arguments from the representation of the\ngraph, allowing it to work with any query type.\n  We illustrate our technique by providing new simpler proofs of previously\nknown tight lower bounds for the query complexity of several graph problems:\nestimating the number of edges in a graph, sampling edges from an\nalmost-uniform distribution, estimating the number of triangles (and more\ngenerally, $r$-cliques) in a graph, and estimating the moments of the degree\ndistribution of a graph. We also prove new lower bounds for estimating the edge\nconnectivity of a graph and estimating the number of instances of any fixed\nsubgraph in a graph. We show that the lower bounds for estimating the number of\ntriangles and edge connectivity also hold in a strictly stronger computational\nmodel that allows access to uniformly random edge samples.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 11:53:21 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 13:39:47 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Eden", "Talya", ""], ["Rosenbaum", "Will", ""]]}, {"id": "1709.05182", "submitter": "Sandor Kisfaludi-Bak", "authors": "Mark de Berg, S\\'andor Kisfaludi-Bak, Gerhard Woeginger", "title": "The Dominating Set Problem in Geometric Intersection Graphs", "comments": "19 pages. Preliminary version appears in the proceedings of IPEC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of dominating sets in geometric\nintersection graphs. In one dimension, we investigate intersection graphs\ninduced by translates of a fixed pattern Q that consists of a finite number of\nintervals and a finite number of isolated points. We prove that Dominating Set\non such intersection graphs is polynomially solvable whenever Q contains at\nleast one interval, and whenever Q contains no intervals and for any two point\npairs in Q the distance ratio is rational. The remaining case where Q contains\nno intervals but does contain an irrational distance ratio is shown to be\nNP-complete and contained in FPT (when parameterized by the solution size). In\ntwo and higher dimensions, we prove that Dominating Set is contained in W[1]\nfor intersection graphs of semi-algebraic sets with constant description\ncomplexity. This generalizes known results from the literature. Finally, we\nestablish W[1]-hardness for a large class of intersection graphs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 13:03:48 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["de Berg", "Mark", ""], ["Kisfaludi-Bak", "S\u00e1ndor", ""], ["Woeginger", "Gerhard", ""]]}, {"id": "1709.05282", "submitter": "Ryan Williams", "authors": "Ryan Williams", "title": "On the Difference Between Closest, Furthest, and Orthogonal Pairs:\n  Nearly-Linear vs Barely-Subquadratic Complexity in Computational Geometry", "comments": "13 pages", "journal-ref": "In ACM-SIAM Symposium on Discrete Algorithms (SODA), 2018", "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point location problems for $n$ points in $d$-dimensional Euclidean space\n(and $\\ell_p$ spaces more generally) have typically had two kinds of\nrunning-time solutions:\n  * (Nearly-Linear) less than $d^{poly(d)} \\cdot n \\log^{O(d)} n$ time, or\n  * (Barely-Subquadratic) $f(d) \\cdot n^{2-1/\\Theta(d)}$ time, for various $f$.\n  For small $d$ and large $n$, \"nearly-linear\" running times are generally\nfeasible, while \"barely-subquadratic\" times are generally infeasible. For\nexample, in the Euclidean metric, finding a Closest Pair among $n$ points in\n${\\mathbb R}^d$ is nearly-linear, solvable in $2^{O(d)} \\cdot n \\log^{O(1)} n$\ntime, while known algorithms for Furthest Pair (the diameter of the point set)\nare only barely-subquadratic, requiring $\\Omega(n^{2-1/\\Theta(d)})$ time. Why\ndo these proximity problems have such different time complexities? Is there a\nbarrier to obtaining nearly-linear algorithms for problems which are currently\nonly barely-subquadratic?\n  We give a novel exact and deterministic self-reduction for the Orthogonal\nVectors problem on $n$ vectors in $\\{0,1\\}^d$ to $n$ vectors in ${\\mathbb\nZ}^{\\omega(\\log d)}$ that runs in $2^{o(d)}$ time. As a consequence,\nbarely-subquadratic problems such as Euclidean diameter, Euclidean bichromatic\nclosest pair, ray shooting, and incidence detection do not have\n$O(n^{2-\\epsilon})$ time algorithms (in Turing models of computation) for\ndimensionality $d = \\omega(\\log \\log n)^2$, unless the popular Orthogonal\nVectors Conjecture and the Strong Exponential Time Hypothesis are false. That\nis, while poly-log-log-dimensional Closest Pair is in $n^{1+o(1)}$ time, the\nanalogous case of Furthest Pair can encode larger-dimensional problems\nconjectured to require $n^{2-o(1)}$ time. We also show that the All-Nearest\nNeighbors problem in $\\omega(\\log n)$ dimensions requires $n^{2-o(1)}$ time to\nsolve, assuming either of the above conjectures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 15:53:59 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Williams", "Ryan", ""]]}, {"id": "1709.05294", "submitter": "Ryan Williams", "authors": "Daniel Kane, Ryan Williams", "title": "The Orthogonal Vectors Conjecture for Branching Programs and Formulas", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Orthogonal Vectors (OV) problem, we wish to determine if there is an\northogonal pair of vectors among $n$ Boolean vectors in $d$ dimensions. The OV\nConjecture (OVC) posits that OV requires $n^{2-o(1)}$ time to solve, for all\n$d=\\omega(\\log n)$. Assuming the OVC, optimal time lower bounds have been\nproved for many prominent problems in $P$.\n  We prove that OVC is true in several computational models of interest:\n  * For all sufficiently large $n$ and $d$, OV for $n$ vectors in $\\{0,1\\}^d$\nhas branching program complexity $\\tilde{\\Theta}(n\\cdot \\min(n,2^d))$. In\nparticular, the lower bounds match the upper bounds up to polylog factors.\n  * OV has Boolean formula complexity $\\tilde{\\Theta}(n\\cdot \\min(n,2^d))$,\nover all complete bases of $O(1)$ fan-in.\n  * OV requires $\\tilde{\\Theta}(n\\cdot \\min(n,2^d))$ wires, in formulas\ncomprised of gates computing arbitrary symmetric functions of unbounded fan-in.\n  Our lower bounds basically match the best known (quadratic) lower bounds for\nany explicit function in those models. Analogous lower bounds hold for many\nrelated problems shown to be hard under OVC, such as Batch Partial Match, Batch\nSubset Queries, and Batch Hamming Nearest Neighbors, all of which have very\nsuccinct reductions to OV.\n  The proofs use a certain kind of input restriction that is different from\ntypical random restrictions where variables are assigned independently. We give\na sense in which independent random restrictions cannot be used to show\nhardness, in that OVC is false in the \"average case\" even for $AC^0$ formulas:\n  * For every fixed $p \\in (0,1)$ there is an $\\epsilon_p > 0$ such that for\nevery $n$ and $d$, OV instances where input bits are independently set to $1$\nwith probability $p$ (and $0$ otherwise) can be solved with $AC^0$ formulas of\nsize $O(n^{2-\\epsilon_p})$, on all but a $o_n(1)$ fraction of instances.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 16:26:34 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Kane", "Daniel", ""], ["Williams", "Ryan", ""]]}, {"id": "1709.06036", "submitter": "Mitali Bafna", "authors": "Mitali Bafna, Srikanth Srinivasan, Madhu Sudan", "title": "Local decoding and testing of polynomials over grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known DeMillo-Lipton-Schwartz-Zippel lemma says that $n$-variate\npolynomials of total degree at most $d$ over grids, i.e. sets of the form $A_1\n\\times A_2 \\times \\cdots \\times A_n$, form error-correcting codes (of distance\nat least $2^{-d}$ provided $\\min_i\\{|A_i|\\}\\geq 2$). In this work we explore\ntheir local decodability and (tolerant) local testability. While these aspects\nhave been studied extensively when $A_1 = \\cdots = A_n = \\mathbb{F}_q$ are the\nsame finite field, the setting when $A_i$'s are not the full field does not\nseem to have been explored before.\n  In this work we focus on the case $A_i = \\{0,1\\}$ for every $i$. We show that\nfor every field (finite or otherwise) there is a test whose query complexity\ndepends only on the degree (and not on the number of variables). In contrast we\nshow that decodability is possible over fields of positive characteristic (with\nquery complexity growing with the degree of the polynomial and the\ncharacteristic), but not over the reals, where the query complexity must grow\nwith $n$. As a consequence we get a natural example of a code (one with a\ntransitive group of symmetries) that is locally testable but not locally\ndecodable.\n  Classical results on local decoding and testing of polynomials have relied on\nthe 2-transitive symmetries of the space of low-degree polynomials (under\naffine transformations). Grids do not possess this symmetry: So we introduce\nsome new techniques to overcome this handicap and in particular use the\nhypercontractivity of the (constant weight) noise operator on the Hamming cube.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 16:40:54 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 15:52:37 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Bafna", "Mitali", ""], ["Srinivasan", "Srikanth", ""], ["Sudan", "Madhu", ""]]}, {"id": "1709.06172", "submitter": "Mohamed Siala Dr", "authors": "Begum Genc, Mohamed Siala, Gilles Simonin, Barry O'Sullivan", "title": "On the Complexity of Robust Stable Marriage", "comments": "Accepted for publication in COCOA'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Stable Marriage (RSM) is a variant of the classical Stable Marriage\nproblem, where the robustness of a given stable matching is measured by the\nnumber of modifications required for repairing it in case an unforeseen event\noccurs. We focus on the complexity of finding an (a,b)-supermatch. An\n(a,b)-supermatch is defined as a stable matching in which if any 'a'\n(non-fixed) men/women break up it is possible to find another stable matching\nby changing the partners of those 'a' men/women and also the partners of at\nmost 'b' other couples. In order to show deciding if there exists an\n(a,b)-supermatch is NP-Complete, we first introduce a SAT formulation that is\nNP-Complete by using Schaefer's Dichotomy Theorem. Then, we show the\nequivalence between the SAT formulation and finding a (1,1)-supermatch on a\nspecific family of instances.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 21:32:52 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 13:30:33 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Genc", "Begum", ""], ["Siala", "Mohamed", ""], ["Simonin", "Gilles", ""], ["O'Sullivan", "Barry", ""]]}, {"id": "1709.06188", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli, Mika\\\"el Monet, Pierre Senellart", "title": "Connecting Width and Structure in Knowledge Compilation (Extended\n  Version)", "comments": "33 pages, no figures, 40 references. This is the full version with\n  proofs of the corresponding ICDT'18 publication, and it integrates all\n  reviewer feedback. Except for the additional appendices, and except for\n  formatting differences and inessential changes, the contents are the same as\n  in the conference version", "journal-ref": null, "doi": "10.4230/LIPIcs.ICDT.2018.6", "report-no": null, "categories": "cs.DB cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several query evaluation tasks can be done via knowledge compilation: the\nquery result is compiled as a lineage circuit from which the answer can be\ndetermined. For such tasks, it is important to leverage some width parameters\nof the circuit, such as bounded treewidth or pathwidth, to convert the circuit\nto structured classes, e.g., deterministic structured NNFs (d-SDNNFs) or OBDDs.\nIn this work, we show how to connect the width of circuits to the size of their\nstructured representation, through upper and lower bounds. For the upper bound,\nwe show how bounded-treewidth circuits can be converted to a d-SDNNF, in time\nlinear in the circuit size. Our bound, unlike existing results, is constructive\nand only singly exponential in the treewidth. We show a related lower bound on\nmonotone DNF or CNF formulas, assuming a constant bound on the arity (size of\nclauses) and degree (number of occurrences of each variable). Specifically, any\nd-SDNNF (resp., SDNNF) for such a DNF (resp., CNF) must be of exponential size\nin its treewidth; and the same holds for pathwidth when compiling to OBDDs. Our\nlower bounds, in contrast with most previous work, apply to any formula of this\nclass, not just a well-chosen family. Hence, for our language of DNF and CNF,\npathwidth and treewidth respectively characterize the efficiency of compiling\nto OBDDs and (d-)SDNNFs, that is, compilation is singly exponential in the\nwidth parameter. We conclude by applying our lower bound results to the task of\nquery evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 22:15:11 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 22:42:42 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 12:39:01 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Amarilli", "Antoine", ""], ["Monet", "Mika\u00ebl", ""], ["Senellart", "Pierre", ""]]}, {"id": "1709.06299", "submitter": "Arne Schmidt", "authors": "Aaron T. Becker, S\\'andor P. Fekete, Phillip Keldenich, Dominik\n  Krupke, Christian Rieck, Christian Scheffer, Arne Schmidt", "title": "Tilt Assembly: Algorithms for Micro-Factories That Build Objects with\n  Uniform External Forces", "comments": "17 pages, 17 figures, 1 table, full version of extended abstract that\n  is to appear in ISAAC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithmic results for the parallel assembly of many micro-scale\nobjects in two and three dimensions from tiny particles, which has been\nproposed in the context of programmable matter and self-assembly for building\nhigh-yield micro-factories. The underlying model has particles moving under the\ninfluence of uniform external forces until they hit an obstacle; particles can\nbond when being forced together with another appropriate particle. Due to the\nphysical and geometric constraints, not all shapes can be built in this manner;\nthis gives rise to the Tilt Assembly Problem (TAP) of deciding\nconstructibility. For simply-connected polyominoes $P$ in 2D consisting of $N$\nunit-squares (\"tiles\"), we prove that TAP can be decided in $O(N\\log N)$ time.\nFor the optimization variant MaxTAP (in which the objective is to construct a\nsubshape of maximum possible size), we show polyAPX-hardness: unless P=NP,\nMaxTAP cannot be approximated within a factor of $\\Omega(N^{\\frac{1}{3}})$; for\ntree-shaped structures, we give an $O(N^{\\frac{1}{2}})$-approximation\nalgorithm. For the efficiency of the assembly process itself, we show that any\nconstructible shape allows pipelined assembly, which produces copies of $P$ in\n$O(1)$ amortized time, i.e., $N$ copies of $P$ in $O(N)$ time steps. These\nconsiderations can be extended to three-dimensional objects: For the class of\npolycubes $P$ we prove that it is NP-hard to decide whether it is possible to\nconstruct a path between two points of $P$; it is also NP-hard to decide\nconstructibility of a polycube $P$. Moreover, it is expAPX-hard to maximize a\npath from a given start point.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 08:52:23 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Becker", "Aaron T.", ""], ["Fekete", "S\u00e1ndor P.", ""], ["Keldenich", "Phillip", ""], ["Krupke", "Dominik", ""], ["Rieck", "Christian", ""], ["Scheffer", "Christian", ""], ["Schmidt", "Arne", ""]]}, {"id": "1709.06805", "submitter": "Grzegorz Gu\\'spiel", "authors": "Grzegorz Gu\\'spiel", "title": "Complexity of Finding Perfect Bipartite Matchings Minimizing the Number\n  of Intersecting Edges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a problem where we are given a bipartite graph H with vertices\narranged on two horizontal lines in the plane, such that the two sets of\nvertices placed on the two lines form a bipartition of H. We additionally\nrequire that H admits a perfect matching and assume that edges of H are\nembedded in the plane as segments. The goal is to compute the minimal number of\nintersecting edges in a perfect matching in H. The problem stems from so-called\ntoken swapping problems, introduced by Yamanaka et al. [3] and generalized by\nBonnet, Miltzow and Rzazewski [1]. We show that our problem, equivalent to one\nof the special cases of one of the token swapping problems, is NP-complete.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 10:42:53 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 21:36:04 GMT"}, {"version": "v3", "created": "Fri, 22 Dec 2017 20:42:06 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Gu\u015bpiel", "Grzegorz", ""]]}, {"id": "1709.07480", "submitter": "Michael Albert", "authors": "Mathijs de Weerdt, Michael Albert, Vincent Conitzer", "title": "Complexity of Scheduling Charging in the Smart Grid", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2018/658", "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the smart grid, the intent is to use flexibility in demand, both to\nbalance demand and supply as well as to resolve potential congestion. A first\nprominent example of such flexible demand is the charging of electric vehicles,\nwhich do not necessarily need to be charged as soon as they are plugged in. The\nproblem of optimally scheduling the charging demand of electric vehicles within\nthe constraints of the electricity infrastructure is called the charge\nscheduling problem. The models of the charging speed, horizon, and charging\ndemand determine the computational complexity of the charge scheduling problem.\nFor about 20 variants, we show, using a dynamic programming approach, that the\nproblem is either in P or weakly NP-hard. We also show that about 10 variants\nof the problem are strongly NP-hard, presenting a potentially significant\nobstacle to their use in practical situations of scale.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 18:33:35 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["de Weerdt", "Mathijs", ""], ["Albert", "Michael", ""], ["Conitzer", "Vincent", ""]]}, {"id": "1709.07610", "submitter": "Valerio Varricchio", "authors": "Valerio Varricchio, Brian Paden, Dmitry Yershov, Emilio Frazzoli", "title": "Efficient Nearest-Neighbor Search for Dynamical Systems with\n  Nonholonomic Constraints", "comments": "16 pages, 3 figures, the 12th Workshop on the Algorithmic Foundations\n  of Robotics (WAFR) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest-neighbor search dominates the asymptotic complexity of sampling-based\nmotion planning algorithms and is often addressed with k-d tree data\nstructures. While it is generally believed that the expected complexity of\nnearest-neighbor queries is $O(log(N))$ in the size of the tree, this paper\nreveals that when a classic k-d tree approach is used with sub-Riemannian\nmetrics, the expected query complexity is in fact $\\Theta(N^p \\log(N))$ for a\nnumber $p \\in [0, 1)$ determined by the degree of nonholonomy of the system.\nThese metrics arise naturally in nonholonomic mechanical systems, including\nclassic wheeled robot models. To address this negative result, we propose novel\nk-d tree build and query strategies tailored to sub-Riemannian metrics and\ndemonstrate significant improvements in the running time of nearest-neighbor\nsearch queries.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 07:06:12 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Varricchio", "Valerio", ""], ["Paden", "Brian", ""], ["Yershov", "Dmitry", ""], ["Frazzoli", "Emilio", ""]]}, {"id": "1709.07635", "submitter": "Roei Tell", "authors": "Roei Tell", "title": "Quantified Derandomization of Linear Threshold Circuits", "comments": "Changes in this revision: An additional result (a PRG for quantified\n  derandomization of depth-2 LTF circuits); rewrite of some of the exposition;\n  minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the prominent current challenges in complexity theory is the attempt\nto prove lower bounds for $TC^0$, the class of constant-depth, polynomial-size\ncircuits with majority gates. Relying on the results of Williams (2013), an\nappealing approach to prove such lower bounds is to construct a non-trivial\nderandomization algorithm for $TC^0$. In this work we take a first step towards\nthe latter goal, by proving the first positive results regarding the\nderandomization of $TC^0$ circuits of depth $d>2$.\n  Our first main result is a quantified derandomization algorithm for $TC^0$\ncircuits with a super-linear number of wires. Specifically, we construct an\nalgorithm that gets as input a $TC^0$ circuit $C$ over $n$ input bits with\ndepth $d$ and $n^{1+\\exp(-d)}$ wires, runs in almost-polynomial-time, and\ndistinguishes between the case that $C$ rejects at most $2^{n^{1-1/5d}}$ inputs\nand the case that $C$ accepts at most $2^{n^{1-1/5d}}$ inputs. In fact, our\nalgorithm works even when the circuit $C$ is a linear threshold circuit, rather\nthan just a $TC^0$ circuit (i.e., $C$ is a circuit with linear threshold gates,\nwhich are stronger than majority gates).\n  Our second main result is that even a modest improvement of our quantified\nderandomization algorithm would yield a non-trivial algorithm for standard\nderandomization of all of $TC^0$, and would consequently imply that\n$NEXP\\not\\subseteq TC^0$. Specifically, if there exists a quantified\nderandomization algorithm that gets as input a $TC^0$ circuit with depth $d$\nand $n^{1+O(1/d)}$ wires (rather than $n^{1+\\exp(-d)}$ wires), runs in time at\nmost $2^{n^{\\exp(-d)}}$, and distinguishes between the case that $C$ rejects at\nmost $2^{n^{1-1/5d}}$ inputs and the case that $C$ accepts at most\n$2^{n^{1-1/5d}}$ inputs, then there exists an algorithm with running time\n$2^{n^{1-\\Omega(1)}}$ for standard derandomization of $TC^0$.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 08:37:51 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 08:00:22 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Tell", "Roei", ""]]}, {"id": "1709.07822", "submitter": "Nima Anari", "authors": "Nima Anari and Vijay V. Vazirani", "title": "Planar Graph Perfect Matching is in NC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is perfect matching in NC? That is, is there a deterministic fast parallel\nalgorithm for it? This has been an outstanding open question in theoretical\ncomputer science for over three decades, ever since the discovery of RNC\nmatching algorithms. Within this question, the case of planar graphs has\nremained an enigma: On the one hand, counting the number of perfect matchings\nis far harder than finding one (the former is #P-complete and the latter is in\nP), and on the other, for planar graphs, counting has long been known to be in\nNC whereas finding one has resisted a solution.\n  In this paper, we give an NC algorithm for finding a perfect matching in a\nplanar graph. Our algorithm uses the above-stated fact about counting matchings\nin a crucial way. Our main new idea is an NC algorithm for finding a face of\nthe perfect matching polytope at which $\\Omega(n)$ new conditions, involving\nconstraints of the polytope, are simultaneously satisfied. Several other ideas\nare also needed, such as finding a point in the interior of the minimum weight\nface of this polytope and finding a balanced tight odd set in NC.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 15:56:53 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 00:50:32 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 22:02:03 GMT"}, {"version": "v4", "created": "Sat, 21 Apr 2018 21:49:54 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Anari", "Nima", ""], ["Vazirani", "Vijay V.", ""]]}, {"id": "1709.07851", "submitter": "Jeroen Zuiddam", "authors": "Matthias Christandl, P\\'eter Vrana, Jeroen Zuiddam", "title": "Universal points in the asymptotic spectrum of tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asymptotic restriction problem for tensors is to decide, given tensors\n$s$ and $t$, whether the nth tensor power of $s$ can be obtained from the\n$(n+o(n))$th tensor power of t by applying linear maps to the tensor legs (this\nwe call restriction), when $n$ goes to infinity. In this context, Volker\nStrassen, striving to understand the complexity of matrix multiplication,\nintroduced in 1986 the asymptotic spectrum of tensors. Essentially, the\nasymptotic restriction problem for a family of tensors $X$, closed under direct\nsum and tensor product, reduces to finding all maps from $X$ to the reals that\nare monotone under restriction, normalised on diagonal tensors, additive under\ndirect sum and multiplicative under tensor product, which Strassen named\nspectral points. Strassen created the support functionals, which are spectral\npoints for oblique tensors, a strict subfamily of all tensors.\n  Universal spectral points are spectral points for the family of all tensors.\nThe construction of nontrivial universal spectral points has been an open\nproblem for more than thirty years. We construct for the first time a family of\nnontrivial universal spectral points over the complex numbers, using quantum\nentropy and covariants: the quantum functionals. In the process we connect the\nasymptotic spectrum to the quantum marginal problem and to the entanglement\npolytope.\n  To demonstrate the asymptotic spectrum, we reprove (in hindsight) recent\nresults on the cap set problem by reducing this problem to computing asymptotic\nspectrum of the reduced polynomial multiplication tensor, a prime example of\nStrassen. A better understanding of our universal spectral points construction\nmay lead to further progress on related questions. We additionally show that\nthe quantum functionals characterise asymptotic slice rank for complex tensors.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 17:07:59 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 17:48:56 GMT"}, {"version": "v3", "created": "Sat, 26 May 2018 10:28:03 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Christandl", "Matthias", ""], ["Vrana", "P\u00e9ter", ""], ["Zuiddam", "Jeroen", ""]]}, {"id": "1709.07869", "submitter": "Piotr Sankowski", "authors": "Piotr Sankowski", "title": "NC Algorithms for Weighted Planar Perfect Matching and Related Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a planar graph $G=(V,E)$ with polynomially bounded edge weight\nfunction $w:E\\to [0, poly(n)]$. The main results of this paper are NC\nalgorithms for the following problems:\n  - minimum weight perfect matching in $G$,\n  - maximum cardinality and maximum weight matching in $G$ when $G$ is\nbipartite,\n  - maximum multiple-source multiple-sink flow in $G$ where $c:E\\to [1,\npoly(n)]$ is a polynomially bounded edge capacity function,\n  - minimum weight $f$-factor in $G$ where $f:V\\to [1, poly(n)]$,\n  - min-cost flow in $G$ where $c:E\\to [1, poly(n)]$ is a polynomially bounded\nedge capacity function and $b:V\\to [1, poly(n)]$ is a polynomially bounded\nvertex demand function.\n  There have been no known NC algorithms for any of these problems previously\n(Before this and independent paper by Anari and Vazirani). In order to solve\nthese problems we develop a new relatively simple but versatile framework that\nis combinatorial in spirit. It handles the combinatorial structure of matchings\ndirectly and needs to only know weights of appropriately defined matchings from\nalgebraic subroutines.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 17:48:47 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 09:34:39 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 09:59:49 GMT"}, {"version": "v4", "created": "Wed, 18 Apr 2018 20:14:25 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Sankowski", "Piotr", ""]]}, {"id": "1709.07966", "submitter": "Monaldo Mastrolilli", "authors": "Monaldo Mastrolilli", "title": "High Degree Sum of Squares Proofs, Bienstock-Zuckerberg hierarchy and\n  Chvatal-Gomory cuts", "comments": "Revised version with some small typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chvatal-Gomory (CG) cuts and the Bienstock-Zuckerberg hierarchy capture\nuseful linear programs that the standard bounded degree Lasserre/Sum-of-Squares\nSOS hierarchy fails to capture.\n  In this paper we present a novel polynomial time SOS hierarchy for 0/1\nproblems with a custom subspace of high degree polynomials (not the standard\nsubspace of low-degree polynomials). We show that the new SOS hierarchy\nrecovers the Bienstock-Zuckerberg hierarchy. Our result implies a linear\nprogram that reproduces the Bienstock-Zuckerberg hierarchy as a polynomial\nsized, efficiently constructive extended formulation that satisfies all\nconstant pitch inequalities. The construction is also very simple, and it is\nfully defined by giving the supporting polynomials. Moreover, for a class of\npolytopes (e.g. set covering and packing problems), the resulting SOS hierarchy\noptimizes in polynomial time over the polytope resulting from any constant\nrounds of CG-cuts, up to an arbitrarily small error.\n  Arguably, this is the first example where different basis functions can be\nuseful in asymmetric situations to obtain a hierarchy of relaxations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 22:18:47 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 20:03:08 GMT"}, {"version": "v3", "created": "Thu, 12 Oct 2017 21:59:59 GMT"}, {"version": "v4", "created": "Fri, 24 Nov 2017 14:33:55 GMT"}, {"version": "v5", "created": "Mon, 17 Sep 2018 09:32:45 GMT"}, {"version": "v6", "created": "Thu, 4 Jul 2019 16:05:20 GMT"}, {"version": "v7", "created": "Mon, 23 Dec 2019 13:47:16 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Mastrolilli", "Monaldo", ""]]}, {"id": "1709.08216", "submitter": "Ankit Singh Rawat", "authors": "Ankit Singh Rawat and Itzhak Tamo and Venkatesan Guruswami and Klim\n  Efremenko", "title": "MDS Code Constructions with Small Sub-packetization and Near-optimal\n  Repair Bandwidth", "comments": "Significant overlap with arXiv:1608.00191", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of constructing MDS codes that enable exact\nrepair of each code block with small repair bandwidth, which refers to the\ntotal amount of information flow from the remaining code blocks during the\nrepair process. This problem naturally arises in the context of distributed\nstorage systems as the node repair problem [7]. The constructions of\nexact-repairable MDS codes with optimal repair-bandwidth require working with\nlarge sub-packetization levels, which restricts their employment in practice.\n  This paper presents constructions for MDS codes that simultaneously provide\nboth small repair bandwidth and small sub-packetization level. In particular,\nthis paper presents two general approaches to construct exact-repairable MDS\ncodes that aim at significantly reducing the required sub-packetization level\nat the cost of slightly sub-optimal repair bandwidth. The first approach gives\nMDS codes that have repair bandwidth at most twice the optimal\nrepair-bandwidth. Additionally, these codes also have the smallest possible\nsub-packetization level $\\ell = O(r)$, where $r$ denotes the number of parity\nblocks. This approach is then generalized to design codes that have their\nrepair bandwidth approaching the optimal repair-bandwidth at the cost of\ngraceful increment in the required sub-packetization level. The second approach\ntransforms an MDS code with optimal repair-bandwidth and large\nsub-packetization level into a longer MDS code with small sub-packetization\nlevel and near-optimal repair bandwidth. For a given $r$, the obtained codes\nhave their sub-packetization level scaling logarithmically with the code\nlength. In addition, the obtained codes require field size only linear in the\ncode length and ensure load balancing among the intact code blocks in terms of\nthe information downloaded from these blocks during the exact reconstruction of\na code block.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 16:21:50 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Rawat", "Ankit Singh", ""], ["Tamo", "Itzhak", ""], ["Guruswami", "Venkatesan", ""], ["Efremenko", "Klim", ""]]}, {"id": "1709.08409", "submitter": "Kamil Khadiev", "authors": "Kamil Khadiev, Aliya Khadieva and Ilnaz Mannapov", "title": "Quantum Online Algorithms with Respect to Space Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online algorithm is a well-known computational model. We introduce quantum\nonline algorithms and investigate them with respect to a competitive ratio in\ntwo points of view: space complexity and advice complexity. We start with\nexploring a model with restricted memory and show that quantum online\nalgorithms can be better than classical ones (deterministic or randomized) for\nsublogarithmic space (memory), and they can be better than deterministic online\nalgorithms without restriction for memory. Additionally, we consider\npolylogarithmic space case and show that in this case, quantum online\nalgorithms can be better than deterministic ones as well.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 09:55:12 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Khadiev", "Kamil", ""], ["Khadieva", "Aliya", ""], ["Mannapov", "Ilnaz", ""]]}, {"id": "1709.08510", "submitter": "Arne Meier", "authors": "Andreas Krebs and Arne Meier and Jonni Virtema and Martin Zimmermann", "title": "Team Semantics for the Specification and Verification of Hyperproperties", "comments": "Minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop team semantics for Linear Temporal Logic (LTL) to express\nhyperproperties, which have recently been identified as a key concept in the\nverification of information flow properties. Conceptually, we consider an\nasynchronous and a synchronous variant of team semantics. We study basic\nproperties of this new logic and classify the computational complexity of its\nsatisfiability, path, and model checking problem. Further, we examine how\nextensions of these basic logics react on adding other atomic operators.\nFinally, we compare its expressivity to the one of HyperLTL, another recently\nintroduced logic for hyperproperties. Our results show that LTL under team\nsemantics is a viable alternative to HyperLTL, which complements the\nexpressivity of HyperLTL and has partially better algorithmic properties.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 14:24:47 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 12:15:08 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 15:47:46 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 12:08:05 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Krebs", "Andreas", ""], ["Meier", "Arne", ""], ["Virtema", "Jonni", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1709.08792", "submitter": "Andre Nies", "authors": "Andre Nies and Frank Stephan", "title": "Closure of resource-bounded randomness notions under polynomial time\n  permutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An infinite bit sequence is called recursively random if no computable\nstrategy betting along the sequence has unbounded capital. It is well-known\nthat the property of recursive randomness is closed under computable\npermutations. We investigate analogous statements for randomness notions\ndefined by betting strategies that are computable within resource bounds.\nSuppose that S is a polynomial time computable permutation of the set of\nstrings over the unary alphabet (identified with N). If the inverse of S is not\npolynomially bounded, it is easy to build a polynomial time random bit sequence\nZ such that Z o S is not polynomial time random. So one should only consider\npermutations S satisfying the extra condition that the inverse is polynomially\nbounded. Now the closure depends on additional assumptions in complexity\ntheory.\n  Our first result shows that if BPP contains a superpolynomial deterministic\ntime class then polynomial time randomness is not preserved by some permutation\nS such that in fact both S and its inverse are in P. Our second result shows\nthat polynomial space randomness is preserved by polynomial time permutations\nwith polynomially boun\\-ded inverse, so if P=PSPACE then polynomial time\nrandomness is preserved.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 02:43:01 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Nies", "Andre", ""], ["Stephan", "Frank", ""]]}, {"id": "1709.08890", "submitter": "Igor Razgon", "authors": "Igor Razgon", "title": "Partial matching width and its application to lower bounds for branching\n  programs", "comments": "Fixed a typo that occurred several times in the abstract and the\n  introduction: the lower bound for NRBOP was stated as $n^{\\Omega(k \\log n)}$\n  instead of the correct $n^{\\Omega(k)}$", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new structural graph parameter called \\emph{partial matching\nwidth}. For each (sufficiently large) integer $k \\geq 1$, we introduce a class\n$\\mathcal{G}_k$ of graphs of treewidth at most $k$ and max-degree $7$ such that\nfor each $G \\in \\mathcal{G}_k$ and each (sufficiently large) $V \\subseteq\nV(G)$, the partial matching width of $V$ is $\\Omega(k \\log |V|)$.\n  We use the above lower bound to establish a lower bound on the size of\nnon-deterministic read-once branching programs (NROBPs). In particular, for\neach sufficiently large ineteger $k$, we introduce a class ${\\bf \\Phi}_k$ of\nCNFs of (primal graph) treewidth at most $k$ such that for any $\\varphi \\in\n{\\bf \\Phi}_k$ and any Boolean function $F \\subseteq \\varphi$ and such that\n$|\\varphi|/|F| \\leq 2^{\\sqrt{n}}$ (here the functions are regarded as sets of\nassignments on which they are true), a NROBP implementing $F$ is of size\n$n^{\\Omega(k)}$. This result significantly generalises an earlier result of the\nauthor showing a non-FPT lower bound for NROBPs representing CNFs of bounded\ntreewidth. Intuitively, we show that not only those CNFs but also their\narbitrary one side approximations with an exponential ratio still attain that\nlower bound.\n  The non-trivial aspect of this approximation is that due to a small number of\nsatisfying assignments for $F$, it seems difficult to establish a large\nbottleneck: the whole function can `sneak' through a single rectangle\ncorresponding to just \\emph{one} vertex of the purported bottleneck. We\novercome this problem by simultaneously exploring $\\sqrt{n}$ bottlenecks and\nshowing that at least one of them must be large. This approach might be useful\nfor establishing other lower bounds for branching programs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 08:46:06 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 17:48:40 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Razgon", "Igor", ""]]}, {"id": "1709.08985", "submitter": "Jevg\\=enijs Vihrovs", "authors": "Andris Ambainis, Martins Kokainis, Kri\\v{s}j\\=anis Pr\\=usis,\n  Jevg\\=enijs Vihrovs, Aleksejs Zajakins", "title": "All Classical Adversary Methods are Equivalent for Total Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that all known classical adversary lower bounds on randomized query\ncomplexity are equivalent for total functions, and are equal to the fractional\nblock sensitivity $\\text{fbs}(f)$. That includes the Kolmogorov complexity\nbound of Laplante and Magniez and the earlier relational adversary bound of\nAaronson. This equivalence also implies that for total functions, the\nrelational adversary is equivalent to a simpler lower bound, which we call\nrank-1 relational adversary. For partial functions, we show unbounded\nseparations between $\\text{fbs}(f)$ and other adversary bounds, as well as\nbetween the adversary bounds themselves.\n  We also show that, for partial functions, fractional block sensitivity cannot\ngive lower bounds larger than $\\sqrt{n \\cdot \\text{bs}(f)}$, where $n$ is the\nnumber of variables and $\\text{bs}(f)$ is the block sensitivity. Then we\nexhibit a partial function $f$ that matches this upper bound, $\\text{fbs}(f) =\n\\Omega(\\sqrt{n \\cdot \\text{bs}(f)})$.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 12:53:50 GMT"}, {"version": "v2", "created": "Mon, 2 Oct 2017 11:55:45 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 10:38:19 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Ambainis", "Andris", ""], ["Kokainis", "Martins", ""], ["Pr\u016bsis", "Kri\u0161j\u0101nis", ""], ["Vihrovs", "Jevg\u0113nijs", ""], ["Zajakins", "Aleksejs", ""]]}, {"id": "1709.09307", "submitter": "Georgina Hall", "authors": "Amir Ali Ahmadi and Georgina Hall", "title": "On the construction of converging hierarchies for polynomial\n  optimization based on certificates of global positivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS cs.SY math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, techniques based on convex optimization and real algebra\nthat produce converging hierarchies of lower bounds for polynomial minimization\nproblems have gained much popularity. At their heart, these hierarchies rely\ncrucially on Positivstellens\\\"atze from the late 20th century (e.g., due to\nStengle, Putinar, or Schm\\\"udgen) that certify positivity of a polynomial on an\narbitrary closed basic semialgebraic set. In this paper, we show that such\nhierarchies could in fact be designed from much more limited\nPositivstellens\\\"atze dating back to the early 20th century that only certify\npositivity of a polynomial globally. More precisely, we show that any inner\napproximation to the cone of positive homogeneous polynomials that is\narbitrarily tight can be turned into a converging hierarchy of lower bounds for\ngeneral polynomial minimization problems with compact feasible sets. This in\nparticular leads to a semidefinite programming-based hierarchy that relies\nsolely on Artin's solution to Hilbert's 17th problem. We also use a classical\nresult of Poly\\'a on global positivity of even forms to construct an\n\"optimization-free\" converging hierarchy for general polynomial minimization\nproblems. This hierarchy only requires polynomial multiplication and checking\nnonnegativity of coefficients of certain fixed polynomials. As a corollary, we\nobtain new linear programming and second-order cone programming-based\nhierarchies for polynomial minimization problems that rely on the recently\nintroduced concepts of dsos and sdsos polynomials. We remark that the scope of\nthis paper is theoretical at this stage as our hierarchies-though they involve\nat most two sum of squares constraints or only basic arithmetic at each\nlevel-require the use of bisection and increase the number of variables (resp.\ndegree) of the problem by the number of inequality constraints plus three\n(resp. by a factor of two).\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 02:11:51 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 10:02:40 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Hall", "Georgina", ""]]}, {"id": "1709.09464", "submitter": "Giuseppe Di Molfetta Prof.", "authors": "Giuseppe Di Molfetta, Diogo O. Soares-Pinto, Silvio M. Duarte Queiros", "title": "The Elephant Quantum Walk", "comments": "4 figures, any comments is welcome. Accepted in PRA", "journal-ref": "Phys. Rev. A 97, 062112 (2018)", "doi": "10.1103/PhysRevA.97.062112", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the impact of long-range memory on the properties of a family of\nquantum walks in a one-dimensional lattice and discrete time, which can be\nunderstood as the quantum version of the classical \"Elephant Random Walk\"\nnon-Markovian process. This Elephant Quantum Walk is robustly superballistic\nwith the standard deviation showing a constant exponent, $\\sigma \\propto t^{3/\n2}$ , whatever the quantum coin operator, on which the diffusion coefficient is\ndependent. On the one hand, this result indicates that contrarily to the\nclassical case, the degree of superdiffusivity in quantum non- Markovian\nprocesses of this kind is mainly ruled by the extension of memory rather than\nother microscopic parameters that explicitly define the process. On the other\nhand, these parameters reflect on the diffusion coefficient.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 12:03:43 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 14:41:02 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 21:04:33 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Di Molfetta", "Giuseppe", ""], ["Soares-Pinto", "Diogo O.", ""], ["Queiros", "Silvio M. Duarte", ""]]}, {"id": "1709.09484", "submitter": "Anisse Ismaili", "authors": "Anisse Ismaili", "title": "Routing Games over Time with FIFO policy", "comments": "Submission to WINE-2017 Deadline was August 2nd AoE, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study atomic routing games where every agent travels both along its\ndecided edges and through time. The agents arriving on an edge are first lined\nup in a \\emph{first-in-first-out} queue and may wait: an edge is associated\nwith a capacity, which defines how many agents-per-time-step can pop from the\nqueue's head and enter the edge, to transit for a fixed delay. We show that the\nbest-response optimization problem is not approximable, and that deciding the\nexistence of a Nash equilibrium is complete for the second level of the\npolynomial hierarchy. Then, we drop the rationality assumption, introduce a\nbehavioral concept based on GPS navigation, and study its worst-case efficiency\nratio to coordination.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 02:22:46 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Ismaili", "Anisse", ""]]}, {"id": "1709.09486", "submitter": "Barnaby Martin", "authors": "Benoit Larose, Barnaby Martin and Daniel Paulusma", "title": "Surjective H-Colouring over Reflexive Digraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Surjective H-Colouring problem is to test if a given graph allows a\nvertex-surjective homomorphism to a fixed graph H. The complexity of this\nproblem has been well studied for undirected (partially) reflexive graphs. We\nintroduce endo-triviality, the property of a structure that all of its\nendomorphisms that do not have range of size 1 are automorphisms, as a means to\nobtain complexity-theoretic classifications of Surjective H-Colouring in the\ncase of reflexive digraphs.\n  Chen [2014] proved, in the setting of constraint satisfaction problems, that\nSurjective H-Colouring is NP-complete if H has the property that all of its\npolymorphisms are essentially unary. We give the first concrete application of\nhis result by showing that every endo-trivial reflexive digraph H has this\nproperty. We then use the concept of endo-triviality to prove, as our main\nresult, a dichotomy for Surjective H-Colouring when H is a reflexive\ntournament: if H is transitive, then Surjective H-Colouring is in NL, otherwise\nit is NP-complete.\n  By combining this result with some known and new results we obtain a\ncomplexity classification for Surjective H-Colouring when H is a partially\nreflexive digraph of size at most 3.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 13:15:38 GMT"}, {"version": "v2", "created": "Thu, 28 Dec 2017 14:13:22 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Larose", "Benoit", ""], ["Martin", "Barnaby", ""], ["Paulusma", "Daniel", ""]]}, {"id": "1709.09876", "submitter": "Simina Br\\^anzei", "authors": "Simina Br\\^anzei and Noam Nisan", "title": "Communication Complexity of Cake Cutting", "comments": "Added efficient communication protocol for the monotone crossing\n  problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study classic cake-cutting problems, but in discrete models rather than\nusing infinite-precision real values, specifically, focusing on their\ncommunication complexity. Using general discrete simulations of classical\ninfinite-precision protocols (Robertson-Webb and moving-knife), we roughly\npartition the various fair-allocation problems into 3 classes: \"easy\" (constant\nnumber of rounds of logarithmic many bits), \"medium\" (poly-logarithmic total\ncommunication), and \"hard\". Our main technical result concerns two of the\n\"medium\" problems (perfect allocation for 2 players and equitable allocation\nfor any number of players) which we prove are not in the \"easy\" class. Our main\nopen problem is to separate the \"hard\" from the \"medium\" classes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 09:51:56 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 03:01:30 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Br\u00e2nzei", "Simina", ""], ["Nisan", "Noam", ""]]}, {"id": "1709.10063", "submitter": "Sebastian Kuhnert", "authors": "V. Arvind, Johannes K\\\"obler, Sebastian Kuhnert and Jacobo Toran", "title": "Finding Small Weight Isomorphisms with Additional Constraints is\n  Fixed-Parameter Tractable", "comments": "An extended abstract of this article appears in the proceedings of\n  IPEC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lubiw showed that several variants of Graph Isomorphism are NP-complete,\nwhere the solutions are required to satisfy certain additional constraints\n[SICOMP 10, 1981]. One of these, called Isomorphism With Restrictions, is to\ndecide for two given graphs $X_1=(V,E_1)$ and $X_2=(V,E_2)$ and a subset\n$R\\subseteq V\\times V$ of forbidden pairs whether there is an isomorphism $\\pi$\nfrom $X_1$ to $X_2$ such that $\\pi(i)\\neq j$ for all $(i,j)\\in R$. We prove\nthat this problem and several of its generalizations are in fact in FPT:\n  - The problem of deciding whether there is an isomorphism between two graphs\nthat moves k vertices and satisfies Lubiw-style constraints is in FPT, with k\nand the size of $R$ as parameters. The problem remains in FPT if a CNF of such\nconstraints is allowed. It follows that the problem to decide whether there is\nan isomorphism that moves exactly k vertices is in FPT. This solves a question\nleft open in our article on exact weight automorphisms [STACS 2017].\n  - When the weight and complexity are unrestricted, finding isomorphisms that\nsatisfy a CNF of Lubiw-style constraints can be solved in FPT with access to a\nGI oracle.\n  - Checking if there is an isomorphism $\\pi$ between two graphs with\ncomplexity t is also in FPT with t as parameter, where the complexity of a\npermutation is the Cayley measure defined as the minimum number t such that\n$\\pi$ can be expressed as a product of t transpositions.\n  - We consider a more general problem in which the vertex set of a graph X is\npartitioned into Red and Blue, and we are interested in an automorphism that\nstabilizes Red and Blue and moves exactly k vertices in Blue, where k is the\nparameter. This problem was introduced by [Downey and Fellows 1999], and we\nshowed [STACS 2017] that it is W[1]-hard even with color classes of size 4\ninside Red. Now, for color classes of size at most 3 inside Red, we show the\nproblem is in FPT.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:08:11 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Arvind", "V.", ""], ["K\u00f6bler", "Johannes", ""], ["Kuhnert", "Sebastian", ""], ["Toran", "Jacobo", ""]]}, {"id": "1709.10075", "submitter": "Adam Polak", "authors": "Lech Duraj, Marvin K\\\"unnemann, Adam Polak", "title": "Tight Conditional Lower Bounds for Longest Common Increasing Subsequence", "comments": "18 pages, full version of IPEC 2017 paper", "journal-ref": "Algorithmica 81, 3968-3992 (2019)", "doi": "10.4230/LIPIcs.IPEC.2017.15 10.1007/s00453-018-0485-7", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the canonical generalization of the well-studied Longest\nIncreasing Subsequence problem to multiple sequences, called $k$-LCIS: Given\n$k$ integer sequences $X_1,\\dots,X_k$ of length at most $n$, the task is to\ndetermine the length of the longest common subsequence of $X_1,\\dots,X_k$ that\nis also strictly increasing. Especially for the case of $k=2$ (called LCIS for\nshort), several algorithms have been proposed that require quadratic time in\nthe worst case.\n  Assuming the Strong Exponential Time Hypothesis (SETH), we prove a tight\nlower bound, specifically, that no algorithm solves LCIS in (strongly)\nsubquadratic time. Interestingly, the proof makes no use of normalization\ntricks common to hardness proofs for similar problems such as LCS. We further\nstrengthen this lower bound (1) to rule out $O((nL)^{1-\\varepsilon})$ time\nalgorithms for LCIS, where $L$ denotes the solution size, (2) to rule out\n$O(n^{k-\\varepsilon})$ time algorithms for $k$-LCIS, and (3) to follow already\nfrom weaker variants of SETH. We obtain the same conditional lower bounds for\nthe related Longest Common Weakly Increasing Subsequence problem.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:36:44 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Duraj", "Lech", ""], ["K\u00fcnnemann", "Marvin", ""], ["Polak", "Adam", ""]]}, {"id": "1709.10258", "submitter": "Brahim Chaourar", "authors": "Brahim Chaourar", "title": "An improved algorithm for recognizing matroids", "comments": "10 pages. arXiv admin note: substantial text overlap with\n  arXiv:1703.03744", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $M$ be a matroid defined on a finite set $E$ and $L\\subset E$. $L$ is\nlocked in $M$ if $M|L$ and $M^*|(E\\backslash L)$ are 2-connected, and\n$min\\{r(L), r^*(E\\backslash L)\\} \\geq 2$. Locked subsets characterize\nnontrivial facets of the bases polytope. In this paper, we give a new axiom\nsystem for matroids based on locked subsets. We deduce an algorithm for\nrecognizing matroids improving the running time complexity of the best known\ntill today. This algorithm induces a polynomial time algorithm for recognizing\nuniform matroids. This latter problem is intractable if we use an independence\noracle.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 07:19:57 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 03:00:15 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Chaourar", "Brahim", ""]]}, {"id": "1709.10453", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami", "title": "The 2CNF Boolean Formula Satisfiability Problem and the Linear Space\n  Hypothesis", "comments": "(A4, 10pt, 25 pages) This current article extends and corrects its\n  preliminary report in the Proc. of the 42nd International Symposium on\n  Mathematical Foundations of Computer Science (MFCS 2017), August 21-25, 2017,\n  Aalborg, Denmark, Leibniz International Proceedings in Informatics (LIPIcs),\n  Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik 2017, vol. 83, pp.\n  62:1-62:14, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at investigating the solvability/insolvability of nondeterministic\nlogarithmic-space (NL) decision, search, and optimization problems\nparameterized by size parameters using simultaneously polynomial time and\nsub-linear space on multi-tape deterministic Turing machines. We are\nparticularly focused on a special NL-complete problem, 2SAT---the 2CNF Boolean\nformula satisfiability problem---parameterized by the number of Boolean\nvariables. It is shown that 2SAT with $n$ variables and $m$ clauses can be\nsolved simultaneously polynomial time and $(n/2^{c\\sqrt{\\log{n}}})\\,\npolylog(m+n)$ space for an absolute constant $c>0$. This fact inspires us to\npropose a new, practical working hypothesis, called the linear space hypothesis\n(LSH), which states that 2SAT$_3$---a restricted variant of 2SAT in which each\nvariable of a given 2CNF formula appears at most 3 times in the form of\nliterals---cannot be solved simultaneously in polynomial time using strictly\n\"sub-linear\" (i.e., $m(x)^{\\varepsilon}\\, polylog(|x|)$ for a certain constant\n$\\varepsilon\\in(0,1)$) space on all instances $x$. An immediate consequence of\nthis working hypothesis is $\\mathrm{L}\\neq\\mathrm{NL}$. Moreover, we use our\nhypothesis as a plausible basis to lead to the insolvability of various NL\nsearch problems as well as the nonapproximability of NL optimization problems.\nFor our investigation, since standard logarithmic-space reductions may no\nlonger preserve polynomial-time sub-linear-space complexity, we need to\nintroduce a new, practical notion of \"short reduction.\" It turns out that,\nparameterized with the number of variables, $\\overline{\\mathrm{2SAT}_3}$ is\ncomplete for a syntactically restricted version of NL, called Syntactic\nNL$_{\\omega}$, under such short reductions. This fact supports the legitimacy\nof our working hypothesis.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 15:21:09 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 02:16:28 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Yamakami", "Tomoyuki", ""]]}]