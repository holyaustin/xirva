[{"id": "2002.00002", "submitter": "Jakkepalli Pavan Kumar", "authors": "Jakkepalli Pavan Kumar, P. Venkata Subba Reddy", "title": "Algorithmic Aspects of Some Variants of Domination in Graphs", "comments": "arXiv admin note: text overlap with arXiv:2001.11250", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set $S \\subseteq V$ is a dominating set in G if for every u \\in V \\ S,\nthere exists $v \\in S$ such that $(u,v) \\in E$, i.e., $N[S] = V$. A dominating\nset $S$ is an Isolate Dominating Set} (IDS) if the induced subgraph $G[S]$ has\nat least one isolated vertex. It is known that Isolate Domination Decision\nproblem (IDOM) is NP-complete for bipartite graphs. In this paper, we extend\nthis by showing that the IDOM is NP-complete for split graphs and perfect\nelimination bipartite graphs, a subclass of bipartite graphs. A set $S\n\\subseteq V$ is an independent set if G[S] has no edge. A set S \\subseteq V is\na secure dominating set of $G$ if, for each vertex $u \\in V \\setminus S$, there\nexists a vertex $v \\in S$ such that $ (u,v) \\in E $ and $(S \\ \\{v\\}) \\cup\n\\{u\\}$ is a dominating set of $G$. In addition, we initiate the study of a new\ndomination parameter called, independent secure domination. A set $S\\subseteq\nV$ is an Independent Secure Dominating Set (InSDS) if $S$ is an independent set\nand a secure dominating set of $G$. The minimum size of an InSDS in $G$ is\ncalled the independent secure domination number of $G$ and is denoted by\n$\\gamma_{is}(G)$. Given a graph $ G$ and a positive integer $ k,$ the InSDM\nproblem is to check whether $ G $ has an independent secure dominating set of\nsize at most $ k.$ We prove that InSDM is NP-complete for bipartite graphs and\nlinear time solvable for bounded tree-width graphs and threshold graphs, a\nsubclass of split graphs. The MInSDS problem is to find an independent secure\ndominating set of minimum size, in the input graph. Finally, we prove that the\nMInSDS problem is APX-hard for graphs with maximum degree $5.$\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 02:24:55 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 07:37:18 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kumar", "Jakkepalli Pavan", ""], ["Reddy", "P. Venkata Subba", ""]]}, {"id": "2002.00009", "submitter": "Thomas Seiller", "authors": "Thomas Seiller (LIPN, CNRS)", "title": "Probabilistic Complexity Classes through Semantics", "comments": "arXiv admin note: text overlap with arXiv:1609.07895", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.DS math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, the author has shown how Interaction Graphs models for\nlinear logic can be used to obtain implicit characterisations of\nnon-deterministic complexity classes. In this paper, we show how this semantic\napproach to Implicit Complexity Theory (ICC) can be used to characterise\ndeterministic and probabilistic models of computation. In doing so, we obtain\ncorrespondences between group actions and both deterministic and probabilistic\nhierarchies of complexity classes. As a particular case, we provide the first\nimplicit characterisations of the classes PLogspace (un-bounded error\nprobabilistic logarithmic space) and PPtime (unbounded error probabilistic\npolynomial time)\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:34:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Seiller", "Thomas", "", "LIPN, CNRS"]]}, {"id": "2002.00629", "submitter": "Massimo Equi", "authors": "Massimo Equi, Veli M\\\"akinen, Alexandru I. Tomescu", "title": "Graphs cannot be indexed in polynomial time for sub-quadratic time\n  string matching, unless SETH fails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following string matching problem on a node-labeled graph\n$G=(V,E)$: given a pattern string $P$, decide whether there exists a path in\n$G$ whose concatenation of node labels equals $P$. This is a basic primitive in\nvarious problems in bioinformatics, graph databases, or networks. The hardness\nresults of Backurs and Indyk (FOCS 2016) imply that this problem cannot be\nsolved in better than $O(|E||P|)$ time, under the Orthogonal Vectors Hypothesis\n(OVH), and this holds even under various restrictions on the graph (Equi et\nal., ICALP 2019).\n  In this paper we consider its offline version, namely the one in which we are\nallowed to index the graph in order to support time-efficient string matching\nqueries. Indeed, it was tantalizing in the string matching community to believe\nthat sub-quadratic time queries can be achieved, e.g. at the cost of a\nhigh-degree polynomial-time indexing.\n  We disprove this belief, showing that, under OVH, no polynomial-time index\ncan support querying $P$ in time $O(|E|^\\delta|P|^\\beta)$, with either $\\delta\n< 1$ or $\\beta < 1$. We prove this tight bound employing a known\nself-reducibility technique, e.g. from the field of dynamic algorithms, which\ntranslates conditional lower bounds for an online problem to its offline\nversion.\n  As a side-contribution, we formalize this technique with the notion of linear\nindependent-components reduction, allowing for a simple proof of our result. As\nanother illustration of our technique, we also translate the quadratic\nconditional lower bound of Backurs and Indyk (STOC 2015) for the problem of\nmatching a query string inside a text, under edit distance. We obtain an\nanalogous tight quadratic lower bound for its offline version, improving the\nrecent result of Cohen-Addad, Feuilloley and Starikovskaya (SODA 2019), but\nwith a slightly different boundary condition.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 10:01:34 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 12:27:06 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Equi", "Massimo", ""], ["M\u00e4kinen", "Veli", ""], ["Tomescu", "Alexandru I.", ""]]}, {"id": "2002.00713", "submitter": "Jakkepalli Pavan Kumar", "authors": "Jakkepalli Pavan Kumar, P. Venkata Subba Reddy, S. Arumugam", "title": "Algorithmic Complexity of Secure Connected Domination in Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G = (V,E)$ be a simple, undirected and connected graph. A connected\n(total) dominating set $S \\subseteq V$ is a secure connected (total) dominating\nset of $G$, if for each $ u \\in V \\setminus S$, there exists $v \\in S$ such\nthat $uv \\in E$ and $(S \\setminus \\lbrace v \\rbrace) \\cup \\lbrace u \\rbrace $\nis a connected (total) dominating set of $G$. The minimum cardinality of a\nsecure connected (total) dominating set of $G$ denoted by $ \\gamma_{sc} (G)\n(\\gamma_{st}(G))$, is called the secure connected (total) domination number of\n$G$. In this paper, we show that the decision problems corresponding to secure\nconnected domination number and secure total domination number are NP-complete\neven when restricted to split graphs or bipartite graphs. The NP-complete\nreductions also show that these problems are w[2]-hard. We also prove that the\nsecure connected domination problem is linear time solvable in block graphs and\nthreshold graphs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:26:07 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Kumar", "Jakkepalli Pavan", ""], ["Reddy", "P. Venkata Subba", ""], ["Arumugam", "S.", ""]]}, {"id": "2002.00788", "submitter": "Nick Fischer", "authors": "Nick Fischer and Christian Ikenmeyer", "title": "The Computational Complexity of Plethysm Coefficients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two papers, B\\\"urgisser and Ikenmeyer (STOC 2011, STOC 2013) used an\nadaption of the geometric complexity theory (GCT) approach by Mulmuley and\nSohoni (Siam J Comput 2001, 2008) to prove lower bounds on the border rank of\nthe matrix multiplication tensor. A key ingredient was information about\ncertain Kronecker coefficients. While tensors are an interesting test bed for\nGCT ideas, the far-away goal is the separation of algebraic complexity classes.\nThe role of the Kronecker coefficients in that setting is taken by the\nso-called plethysm coefficients: These are the multiplicities in the coordinate\nrings of spaces of polynomials. Even though several hardness results for\nKronecker coefficients are known, there are almost no results about the\ncomplexity of computing the plethysm coefficients or even deciding their\npositivity.\n  In this paper we show that deciding positivity of plethysm coefficients is\nNP-hard, and that computing plethysm coefficients is #P-hard. In fact, both\nproblems remain hard even if the inner parameter of the plethysm coefficient is\nfixed. In this way we obtain an inner versus outer contrast: If the outer\nparameter of the plethysm coefficient is fixed, then the plethysm coefficient\ncan be computed in polynomial time.\n  Moreover, we derive new lower and upper bounds and in special cases even\ncombinatorial descriptions for plethysm coefficients, which we consider to be\nof independent interest. Our technique uses discrete tomography in a more\nrefined way than the recent work on Kronecker coefficients by Ikenmeyer,\nMulmuley, and Walter (Comput Compl 2017). This makes our work the first to\napply techniques from discrete tomography to the study of plethysm\ncoefficients. Quite surprisingly, that interpretation also leads to new\nequalities between certain plethysm coefficients and Kronecker coefficients.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:37:19 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Fischer", "Nick", ""], ["Ikenmeyer", "Christian", ""]]}, {"id": "2002.00943", "submitter": "Yue Ruan", "authors": "Yue Ruan, Samuel Marsh, Xilin Xue, Xi Li, Zhihao Liu, and Jingbo Wang", "title": "Quantum approximate algorithm for NP optimization problems with\n  constraints", "comments": "27 pages, 10 figures(including 27 subfigurs) submitted to Quantum\n  Information Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quantum Approximate Optimization Algorithm (QAOA) is an algorithmic\nframework for finding approximate solutions to combinatorial optimization\nproblems, derived from an approximation to the Quantum Adiabatic Algorithm\n(QAA). In solving combinatorial optimization problems with constraints in the\ncontext of QAOA or QAA, one needs to find a way to encode problem constraints\ninto the scheme. In this paper, we formalize different constraint types to\nlinear equalities, linear inequalities, and arbitrary form. Based on this, we\npropose constraint-encoding schemes well-fitting into the QAOA framework for\nsolving NP combinatorial optimization problems. The implemented algorithms\ndemonstrate the effectiveness and efficiency of the proposed scheme by the\ntesting results of varied instances of some well-known NP optimization\nproblems. We argue that our work leads to a generalized framework for finding,\nin the context of QAOA, high-quality approximate solutions to combinatorial\nproblems with various types of constraints.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 04:45:41 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ruan", "Yue", ""], ["Marsh", "Samuel", ""], ["Xue", "Xilin", ""], ["Li", "Xi", ""], ["Liu", "Zhihao", ""], ["Wang", "Jingbo", ""]]}, {"id": "2002.01293", "submitter": "Manuel Sorge", "authors": "Marcin Pilipczuk, Manuel Sorge", "title": "A Double Exponential Lower Bound for the Distinct Vectors Problem", "comments": null, "journal-ref": "Discrete Mathematics & Theoretical Computer Science, vol. 22 no.\n  4, Discrete Algorithms (September 18, 2020) dmtcs:6789", "doi": "10.23638/DMTCS-22-4-7", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the (binary) Distinct Vectors problem we are given a binary matrix A with\npairwise different rows and want to select at most k columns such that,\nrestricting the matrix to these columns, all rows are still pairwise different.\nA result by Froese et al. [JCSS] implies a 2^2^(O(k)) * poly(|A|)-time\nbrute-force algorithm for Distinct Vectors. We show that this running time\nbound is essentially optimal by showing that there is a constant c such that\nthe existence of an algorithm solving Distinct Vectors with running time\n2^(O(2^(ck))) * poly(|A|) would contradict the Exponential Time Hypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 14:20:04 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 15:48:09 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 16:57:40 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Pilipczuk", "Marcin", ""], ["Sorge", "Manuel", ""]]}, {"id": "2002.01307", "submitter": "Dmitry Gribanov", "authors": "D.V. Gribanov, D.S. Malyshev, P.M. Pardalos", "title": "A note on the parametric integer programming in the average case:\n  sparsity, proximity, and FPT-algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Integer Linear Programming (ILP) problem $\\max\\{c^\\top x : A\nx \\leq b,\\, x \\in Z^n \\}$, parameterized by a right-hand side vector $b \\in\nZ^m$, where $A \\in Z^{m \\times n}$ is a matrix of the rank $n$. Let $v$ be an\noptimal vertex of the Linear Programming (LP) relaxation $\\max\\{c^\\top x : A x\n\\leq b\\}$ and $B$ be a corresponding optimal base. We show that, for almost all\n$b \\in Z^m$, an optimal point of the square ILP problem $\\max\\{c^\\top x : A_B x\n\\leq b_B,\\, x \\in Z^n \\}$ satisfies the constraints $A x \\leq b$ of the\noriginal problem. From works of R. Gomory it directly follows that the square\nILP problem $\\max\\{c^\\top x : A_B x \\leq b_B,\\, x \\in Z^n \\}$ can be solved by\nan algorithm of the arithmetic complexity $O(n \\cdot \\delta \\cdot \\log\n\\delta)$, where $\\delta = |\\det A_B|$. Consequently, it can be shown that, for\nalmost all $b \\in Z^m$, the original problem $\\max\\{c^\\top x : A x \\leq b,\\, x\n\\in Z^n \\}$ can be solved by an algorithm of the arithmetic complexity $O(n\n\\cdot \\Delta \\cdot \\log \\Delta)$, where $\\Delta$ is the maximum absolute value\nof $n \\times n$ minors of $A$. By the same technique, we give new inequalities\non the integrality gap and sparsity of a solution and slack variables.\n  Another ingredient is a known lemma that states the equality of the maximum\nabsolute values of rank minors of matrices with orthogonal columns. This lemma\ngives us a way to transform ILP problems of the type $\\max\\{c^\\top x : A x =\nb,\\, x \\in Z^n_+\\}$ to problems of the previous type, here we assume that\n$rank(A) = m$ and all the $m \\times m$ minors of $A$ are coprime. Consequently,\nit follows that, for almost all $b \\in Z^m$, there exists an algorithm with the\narithmetic complexity $O((n-m) \\cdot \\Delta \\cdot \\log \\Delta)$ to solve the\nproblem in the equality form. Sparsity and integrality gap bounds are also\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 12:40:45 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 09:34:57 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 12:09:48 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Gribanov", "D. V.", ""], ["Malyshev", "D. S.", ""], ["Pardalos", "P. M.", ""]]}, {"id": "2002.01377", "submitter": "Sergio Siccha", "authors": "Colva Roney-Dougal, Sergio Siccha", "title": "Normalisers of primitive permutation groups in quasipolynomial time", "comments": "11 pages", "journal-ref": null, "doi": "10.1112/blms.12330", "report-no": null, "categories": "math.GR cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that given generators for subgroups $G$ and $H$ of $\\mathrm{S}_n$, if\n$G$ is primitive then generators for $\\mathrm{N}_H(G)$ may be computed in\nquasipolynomial time, namely $2^{O(\\log^3 n)}$. The previous best known bound\nwas simply exponential.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:52:20 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Roney-Dougal", "Colva", ""], ["Siccha", "Sergio", ""]]}, {"id": "2002.01509", "submitter": "John Watrous", "authors": "Soumik Ghosh, John Watrous", "title": "Complexity limitations on one-turn quantum refereed games", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies complexity theoretic aspects of quantum refereed games,\nwhich are abstract games between two competing players that send quantum states\nto a referee, who performs an efficiently implementable joint measurement on\nthe two states to determine which of the player wins. The complexity class\n$\\mathrm{QRG}(1)$ contains those decision problems for which one of the players\ncan always win with high probability on yes-instances and the other player can\nalways win with high probability on no-instances, regardless of the opposing\nplayer's strategy. This class trivially contains $\\mathrm{QMA} \\cup\n\\text{co-}\\mathrm{QMA}$ and is known to be contained in $\\mathrm{PSPACE}$. We\nprove stronger containments on two restricted variants of this class.\nSpecifically, if one of the players is limited to sending a classical\n(probabilistic) state rather than a quantum state, the resulting complexity\nclass $\\mathrm{CQRG}(1)$ is contained in $\\exists\\cdot\\mathrm{PP}$ (the\nnondeterministic polynomial-time operator applied to $\\mathrm{PP}$); while if\nboth players send quantum states but the referee is forced to measure one of\nthe states first, and incorporates the classical outcome of this measurement\ninto a measurement of the second state, the resulting class $\\mathrm{MQRG}(1)$\nis contained in $\\mathrm{P}\\cdot\\mathrm{PP}$ (the unbounded-error probabilistic\npolynomial-time operator applied to $\\mathrm{PP}$).\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 19:28:03 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Ghosh", "Soumik", ""], ["Watrous", "John", ""]]}, {"id": "2002.01743", "submitter": "Tuomas Orponen", "authors": "Tuomas Orponen", "title": "Combinatorial proofs of two theorems of Lutz and Stull", "comments": "11 pages. v2: Incorporated referee suggestions", "journal-ref": null, "doi": "10.1017/S0305004120000328", "report-no": null, "categories": "math.CA cs.CC math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Lutz and Stull used methods from algorithmic information theory to\nprove two new Marstrand-type projection theorems, concerning subsets of\nEuclidean space which are not assumed to be Borel, or even analytic. One of the\ntheorems states that if $K \\subset \\mathbb{R}^{n}$ is any set with equal\nHausdorff and packing dimensions, then $$ \\dim_{\\mathrm{H}} \\pi_{e}(K) =\n\\min\\{\\dim_{\\mathrm{H}} K,1\\} $$ for almost every $e \\in S^{n - 1}$. Here\n$\\pi_{e}$ stands for orthogonal projection to $\\mathrm{span}(e)$.\n  The primary purpose of this paper is to present proofs for Lutz and Stull's\nprojection theorems which do not refer to information theoretic concepts.\nInstead, they will rely on combinatorial-geometric arguments, such as\ndiscretised versions of Kaufman's \"potential theoretic\" method, the pigeonhole\nprinciple, and a lemma of Katz and Tao. A secondary purpose is to slightly\ngeneralise Lutz and Stull's theorems: the versions in this paper apply to\northogonal projections to $m$-planes in $\\mathbb{R}^{n}$, for all $0 < m < n$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 12:05:37 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 10:48:42 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Orponen", "Tuomas", ""]]}, {"id": "2002.02021", "submitter": "Artem Govorov", "authors": "Artem Govorov, Jin-Yi Cai, Martin Dyer", "title": "A dichotomy for bounded degree graph homomorphisms with nonnegative\n  weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the complexity of counting weighted graph homomorphisms defined\nby a symmetric matrix $A$. Each symmetric matrix $A$ defines a graph\nhomomorphism function $Z_A(\\cdot)$, also known as the partition function. Dyer\nand Greenhill [10] established a complexity dichotomy of $Z_A(\\cdot)$ for\nsymmetric $\\{0, 1\\}$-matrices $A$, and they further proved that its #P-hardness\npart also holds for bounded degree graphs. Bulatov and Grohe [4] extended the\nDyer-Greenhill dichotomy to nonnegative symmetric matrices $A$. However, their\nhardness proof requires graphs of arbitrarily large degree, and whether the\nbounded degree part of the Dyer-Greenhill dichotomy can be extended has been an\nopen problem for 15 years. We resolve this open problem and prove that for\nnonnegative symmetric $A$, either $Z_A(G)$ is in polynomial time for all graphs\n$G$, or it is #P-hard for bounded degree (and simple) graphs $G$. We further\nextend the complexity dichotomy to include nonnegative vertex weights.\nAdditionally, we prove that the #P-hardness part of the dichotomy by Goldberg\net al. [12] for $Z_A(\\cdot)$ also holds for simple graphs, where $A$ is any\nreal symmetric matrix.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:21:53 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Govorov", "Artem", ""], ["Cai", "Jin-Yi", ""], ["Dyer", "Martin", ""]]}, {"id": "2002.02408", "submitter": "Jakkepalli Pavan Kumar", "authors": "J. Pavan Kumar, P.Venkata Subba Reddy", "title": "Algorithmic Aspects of 2-Secure Domination in Graphs", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.11250,\n  arXiv:2002.00002", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G(V,E)$ be a simple, undirected and connected graph. A dominating set $S\n\\subseteq V(G)$ is called a $2$-\\textit{secure dominating set} ($2$-SDS) in\n$G$, if for every pair of distinct vertices $u_1,u_2 \\in V(G)$ there exists a\npair of distinct vertices $v_1,v_2 \\in S$ such that $v_1 \\in N[u_1]$, $v_2 \\in\nN[u_2]$ and $(S \\setminus \\{v_1,v_2\\}) \\cup \\{u_1,u_2 \\}$ is a dominating set\nin $G$. The $2$\\textit{-secure domination number} denoted by $\\gamma_{2s}(G)$,\nequals the minimum cardinality of a $2$-SDS in $G$. Given a graph $ G$ and a\npositive integer $ k,$ the $ 2 $-Secure Domination ($ 2 $-SDM) problem is to\ncheck whether $ G $ has a $ 2 $-secure dominating set of size at most $ k.$ It\nis known that $ 2 $-SDM is NP-complete for bipartite graphs. In this paper, we\nprove that the $ 2 $-SDM problem is NP-complete for planar graphs and doubly\nchordal graphs, a subclass of chordal graphs. We strengthen the NP-complete\nresult for bipartite graphs, by proving this problem is NP-complete for some\nsubclasses of bipartite graphs namely, star convex bipartite, comb convex\nbipartite graphs. We prove that $ 2 $-SDM is linear time solvable for bounded\ntree-width graphs. We also show that the $ 2 $-SDM is W[2]-hard even for split\ngraphs. The Minimum $ 2 $-Secure Dominating Set (M2SDS) problem is to find a $\n2 $-secure dominating set of minimum size in the input graph. We propose a $\n\\Delta(G)+1 $ $ - $ approximation algorithm for M2SDS, where $ \\Delta(G) $ is\nthe maximum degree of the input graph $ G $ and prove that M2SDS cannot be\napproximated within $ (1 - \\epsilon) \\ln(| V | ) $ for any $ \\epsilon > 0 $\nunless $ NP \\subseteq DTIME(| V |^{ O(\\log \\log | V | )}) $. % even for\nbipartite graphs. A secure dominating set of a graph \\textit{defends} one\nattack at any vertex of the graph. Finally, we show that the M2SDS is\nAPX-complete for graphs with $\\Delta(G)=4.$\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:38:13 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Kumar", "J. Pavan", ""], ["Reddy", "P. Venkata Subba", ""]]}, {"id": "2002.02447", "submitter": "Francesco Tudisco", "authors": "Antoine Gautier, Matthias Hein, Francesco Tudisco", "title": "Computing the norm of nonnegative matrices and the log-Sobolev constant\n  of Markov chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the global convergence of the power iterates for the computation\nof a general mixed-subordinate matrix norm. We prove a new global convergence\ntheorem for a class of entrywise nonnegative matrices that generalizes and\nimproves a well-known results for mixed-subordinate $\\ell^p$ matrix norms. In\nparticular, exploiting the Birkoff--Hopf contraction ratio of nonnegative\nmatrices, we obtain novel and explicit global convergence guarantees for a\nrange of matrix norms whose computation has been recently proven to be NP-hard\nin the general case, including the case of mixed-subordinate norms induced by\nthe vector norms made by the sum of different $\\ell^p$-norms of subsets of\nentries. Finally, we use the new results combined with hypercontractive\ninequalities to prove a new lower bound on the logarithmic Sobolev constant of\na Markov chain.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:57:23 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Gautier", "Antoine", ""], ["Hein", "Matthias", ""], ["Tudisco", "Francesco", ""]]}, {"id": "2002.02728", "submitter": "Samuel Thiriot", "authors": "Samuel Thiriot", "title": "Impact of the Interaction Network on the Dynamics of Word-of-Mouth with\n  Information Seeking", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word-of-Mouth refers to the dynamics of interpersonal communication occurring\nduring the diffusion of innovations (novel practices, ideas or products).\nAccording to field studies, word-of-mouth is made of both information seeking\nand proactive communication: individuals first become aware of the existence of\nan innovation, then start actively seeking out for the expert knowledge\nrequired to evaluate the innovation; when they hold the expert knowledge, they\nmight start promoting it pro-actively. Successful diffusion of innovation\nrequires the individuals to hold both awareness and expert knowledge, so they\ncan evaluate the innovation and use it properly. A computational model\n\"USA/IPK\" was recently proposed to study the role and impact of information\nseeking on the dynamics of word-of-mouth. We propose here an analysis of the\nimpact of the network of interaction on the dynamics of this model. We compare\nthe dynamics of the model over networks generated with different algorithms\nwith the original dynamics. The results demonstrate the dynamics of the model\nare similar across tested networks, with the noticeable exception of the\nefficiency of the diffusion which varies between networks having similar\ndensities and sizes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 11:56:15 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Thiriot", "Samuel", ""]]}, {"id": "2002.02729", "submitter": "\\\"Oznur Ya\\c{s}ar Diner", "authors": "Josep D\\'iaz, \\\"Oznur Ya\\c{s}ar Diner, Maria Serna, Oriol Serra", "title": "On List k-Coloring Convex Bipartite Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  List k-Coloring (Li k-Col) is the decision problem asking if a given graph\nadmits a proper coloring compatible with a given list assignment to its\nvertices with colors in {1,2,..,k}. The problem is known to be NP-hard even for\nk=3 within the class of 3-regular planar bipartite graphs and for k=4 within\nthe class of chordal bipartite graphs. In 2015, Huang, Johnson and Paulusma\nasked for the complexity of Li 3-Col in the class of chordal bipartite graphs.\nIn this paper we give a partial answer to this question by showing that Li\nk-Col is polynomial in the class of convex bipartite graphs. We show first that\nbiconvex bipartite graphs admit a multichain ordering, extending the classes of\ngraphs where a polynomial algorithm of Enright, Stewart and Tardos (2014) can\nbe applied to the problem. We provide a dynamic programming algorithm to solve\nthe Li k-Col in the calss of convex bipartite graphs. Finally we show how our\nalgorithm can be modified to solve the more general Li H-Col problem on convex\nbipartite graphs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:06:41 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["D\u00edaz", "Josep", ""], ["Diner", "\u00d6znur Ya\u015far", ""], ["Serna", "Maria", ""], ["Serra", "Oriol", ""]]}, {"id": "2002.02789", "submitter": "Ioannis Caragiannis", "authors": "Ioannis Caragiannis, Stavros Ioannidis", "title": "Computing envy-freeable allocations with limited subsidies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair division has emerged as a very hot topic in multiagent systems, and\nenvy-freeness is among the most compelling fairness concepts. An allocation of\nindivisible items to agents is envy-free if no agent prefers the bundle of any\nother agent to his own in terms of value. As envy-freeness is rarely a feasible\ngoal, there is a recent focus on relaxations of its definition. An approach in\nthis direction is to complement allocations with payments (or subsidies) to the\nagents. A feasible goal then is to achieve envy-freeness in terms of the total\nvalue an agent gets from the allocation and the subsidies.\n  We consider the natural optimization problem of computing allocations that\nare {\\em envy-freeable} using the minimum amount of subsidies. As the problem\nis NP-hard, we focus on the design of approximation algorithms. On the positive\nside, we present an algorithm that, for a constant number of agents,\napproximates the minimum amount of subsidies within any required accuracy, at\nthe expense of a graceful increase in the running time. On the negative side,\nwe show that, for a super-constant number of agents, the problem of minimizing\nsubsidies for envy-freeness is not only hard to compute exactly (as a folklore\nargument shows) but also, more importantly, hard to approximate.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 11:57:59 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 08:28:41 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Caragiannis", "Ioannis", ""], ["Ioannidis", "Stavros", ""]]}, {"id": "2002.03293", "submitter": "Khiem Pham", "authors": "Khiem Pham and Khang Le and Nhat Ho and Tung Pham and Hung Bui", "title": "On Unbalanced Optimal Transport: An Analysis of Sinkhorn Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a computational complexity analysis for the Sinkhorn algorithm\nthat solves the entropic regularized Unbalanced Optimal Transport (UOT) problem\nbetween two measures of possibly different masses with at most $n$ components.\nWe show that the complexity of the Sinkhorn algorithm for finding an\n$\\varepsilon$-approximate solution to the UOT problem is of order\n$\\widetilde{\\mathcal{O}}(n^2/ \\varepsilon)$, which is near-linear time. To the\nbest of our knowledge, this complexity is better than the complexity of the\nSinkhorn algorithm for solving the Optimal Transport (OT) problem, which is of\norder $\\widetilde{\\mathcal{O}}(n^2/\\varepsilon^2)$. Our proof technique is\nbased on the geometric convergence of the Sinkhorn updates to the optimal dual\nsolution of the entropic regularized UOT problem and some properties of the\nprimal solution. It is also different from the proof for the complexity of the\nSinkhorn algorithm for approximating the OT problem since the UOT solution does\nnot have to meet the marginal constraints.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 06:03:36 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 04:02:46 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Pham", "Khiem", ""], ["Le", "Khang", ""], ["Ho", "Nhat", ""], ["Pham", "Tung", ""], ["Bui", "Hung", ""]]}, {"id": "2002.03443", "submitter": "Michal Wlodarczyk", "authors": "Bart M.P. Jansen and Micha{\\l} W{\\l}odarczyk", "title": "Optimal polynomial-time compression for Boolean Max CSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Boolean maximum constraint satisfaction problem - Max CSP$(\\Gamma)$ -\none is given a collection of weighted applications of constraints from a finite\nconstraint language $\\Gamma$, over a common set of variables, and the goal is\nto assign Boolean values to the variables so that the total weight of satisfied\nconstraints is maximized. There exists an elegant dichotomy theorem providing a\ncriterion on $\\Gamma$ for the problem to be polynomial-time solvable and\nstating that otherwise it becomes NP-hard. We study the NP hard cases through\nthe lens of kernelization and provide a complete characterization of Max\nCSP$(\\Gamma)$ with respect to the optimal compression size. Namely, we prove\nthat Max CSP$(\\Gamma)$ parameterized by the number of variables $n$ is either\npolynomial-time solvable, or there exists an integer $d \\ge 2$ depending on\n$\\Gamma$, such that\n  1. An instance of \\textsc{Max CSP$(\\Gamma)$} can be compressed into an\nequivalent instance with $O(n^d\\log n)$ bits in polynomial time,\n  2. Max CSP$(\\Gamma)$ does not admit such a compression to $O(n^{d-\\epsilon})$\nbits unless $\\text{NP} \\subseteq \\text{co-NP} / \\text{poly}$.\n  Our reductions are based on interpreting constraints as multilinear\npolynomials combined with the framework of constraint implementations. As\nanother application of our reductions, we reveal tight connections between\noptimal running times for solving Max CSP$(\\Gamma)$. More precisely, we show\nthat obtaining a running time of the form $O(2^{(1-\\epsilon)n})$ for particular\nclasses of Max CSPs is as hard as breaching this barrier for Max $d$-SAT for\nsome $d$.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 20:35:56 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Jansen", "Bart M. P.", ""], ["W\u0142odarczyk", "Micha\u0142", ""]]}, {"id": "2002.03725", "submitter": "Anatole Dahan", "authors": "Anatole Dahan and Anuj Dawar", "title": "Relativization of Gurevich's Conjectures", "comments": "accepted for publication in a volume of papers dedicated to Yuri\n  Gurevich's 80th birthday", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gurevich (1988) conjectured that there is no logic for $\\textsf{P}$ or for\n$\\textsf{NP}\\cap \\textsf{coNP}$. For the latter complexity class, he also\nshowed that the existence of a logic would imply that $\\textsf{NP} \\cap\n\\textsf{coNP}$ has a complete problem under polynomial time reductions. We show\nthat there is an oracle with respect to which $\\textsf P$ does have a logic and\n$\\textsf P \\ne\\textsf{NP}$. We also show that a logic for $\\textsf{NP} \\cap\n\\textsf{coNP}$ follows from the existence of a complete problem and a further\nassumption about canonical labelling. For intersection classes $\\Sigma^p_n \\cap\n\\Pi^p_n$ higher in the polynomial hierarchy, the existence of a logic is\nequivalent to the existence of complete problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:28:48 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Dahan", "Anatole", ""], ["Dawar", "Anuj", ""]]}, {"id": "2002.03887", "submitter": "Jeffrey Bosboom", "authors": "Jeffrey Bosboom, Charlotte Chen, Lily Chung, Spencer Compton, Michael\n  Coulombe, Erik D. Demaine, Martin L. Demaine, Ivan Tadeu Ferreira Antunes\n  Filho, Dylan Hendrickson, Adam Hesterberg, Calvin Hsu, William Hu, Oliver\n  Korten, Zhezheng Luo, Lillian Zhang", "title": "Edge Matching with Inequalities, Triangles, Unknown Shape, and Two\n  Players", "comments": "29 pages, 18 figures. Thorough revisions of Sections 4, 5, and 6/7\n  (merged)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the computational complexity of several new variants of\nedge-matching puzzles. First we analyze inequality (instead of equality)\nconstraints between adjacent tiles, proving the problem NP-complete for strict\ninequalities but polynomial for nonstrict inequalities. Second we analyze three\ntypes of triangular edge matching, of which one is polynomial and the other two\nare NP-complete; all three are #P-complete. Third we analyze the case where no\ntarget shape is specified, and we merely want to place the (square) tiles so\nthat edges match (exactly); this problem is NP-complete. Fourth we consider\nfour 2-player games based on $1 \\times n$ edge matching, all four of which are\nPSPACE-complete. Most of our NP-hardness reductions are parsimonious, newly\nproving #P and ASP-completeness for, e.g., $1 \\times n$ edge matching.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:59:25 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 16:16:26 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Bosboom", "Jeffrey", ""], ["Chen", "Charlotte", ""], ["Chung", "Lily", ""], ["Compton", "Spencer", ""], ["Coulombe", "Michael", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Filho", "Ivan Tadeu Ferreira Antunes", ""], ["Hendrickson", "Dylan", ""], ["Hesterberg", "Adam", ""], ["Hsu", "Calvin", ""], ["Hu", "William", ""], ["Korten", "Oliver", ""], ["Luo", "Zhezheng", ""], ["Zhang", "Lillian", ""]]}, {"id": "2002.04012", "submitter": "Pierre-\\'Etienne Meunier", "authors": "Pierre-\\'Etienne Meunier, Damien Regnault, Damien Woods", "title": "The program-size complexity of self-assembled paths", "comments": "Accepted to STOC2020 - the 52nd Annual ACM Symposium on Theory of\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.FL nlin.AO nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a Pumping Lemma for the noncooperative abstract Tile Assembly Model,\na model central to the theory of algorithmic self-assembly since the beginning\nof the field. This theory suggests, and our result proves, that small\ndifferences in the nature of adhesive bindings between abstract square\nmolecules gives rise to vastly different expressive capabilities.\n  In the cooperative abstract Tile Assembly Model, square tiles attach to each\nother using multi-sided cooperation of one, two or more sides. This precise\ncontrol of tile binding is directly exploited for algorithmic tasks including\ngrowth of specified shapes using very few tile types, as well as simulation of\nTuring machines and even self-simulation of self-assembly systems. But are\ncooperative bindings required for these computational tasks? The definitionally\nsimpler noncooperative (or Temperature 1) model has poor control over local\nbinding events: tiles stick if they bind on at least one side. This has led to\nthe conjecture that it is impossible for it to exhibit precisely controlled\ngrowth of computationally-defined shapes.\n  Here, we prove such an impossibility result. We show that any planar\nnoncooperative system that attempts to grow large algorithmically-controlled\ntile-efficient assemblies must also grow infinite non-algorithmic (pumped)\nstructures with a simple closed-form description, or else suffer blocking of\nintended algorithmic structures. Our result holds for both directed and\nnondirected systems, and gives an explicit upper bound of\n$(8|T|)^{4|T|+1}(5|\\sigma| + 6)$, where $|T|$ is the size of the tileset and\n$|\\sigma|$ is the size of the seed assembly, beyond which any path of tiles is\npumpable or blockable.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:38:43 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Meunier", "Pierre-\u00c9tienne", ""], ["Regnault", "Damien", ""], ["Woods", "Damien", ""]]}, {"id": "2002.04244", "submitter": "Pradipta Ghosh", "authors": "Pradipta Ghosh, Jonathan Bunton, Dimitrios Pylorof, Marcos Vieira,\n  Kevin Chan, Ramesh Govindan, Gaurav Sukhatme, Paulo Tabuada and Gunjan Verma", "title": "Rapid Top-Down Synthesis of Large-Scale IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in optimization and constraint satisfaction techniques, together\nwith the availability of elastic computing resources, have spurred interest in\nlarge-scale network verification and synthesis. Motivated by this, we consider\nthe top-down synthesis of ad-hoc IoT networks for disaster response and search\nand rescue operations. This synthesis problem must satisfy complex and\ncompeting constraints: sensor coverage, line-of-sight visibility, and network\nconnectivity. The central challenge in our synthesis problem is quickly scaling\nto large regions while producing cost-effective solutions. We explore two\nqualitatively different representations of the synthesis problems\nsatisfiability modulo convex optimization (SMC), and mixed-integer linear\nprogramming (MILP). The former is more expressive, for our problem, than the\nlatter, but is less well-suited for solving optimization problems like ours. We\nshow how to express our network synthesis in these frameworks, and, to scale to\nproblem sizes beyond what these frameworks are capable of, develop a\nhierarchical synthesis technique that independently synthesizes networks in\nsub-regions of the deployment area, then combines these. We find that, while\nMILP outperforms SMC in some settings for smaller problem sizes, the fact that\nSMC's expressivity matches our problem ensures that it uniformly generates\nbetter quality solutions at larger problem sizes.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:59:16 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 23:12:18 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Ghosh", "Pradipta", ""], ["Bunton", "Jonathan", ""], ["Pylorof", "Dimitrios", ""], ["Vieira", "Marcos", ""], ["Chan", "Kevin", ""], ["Govindan", "Ramesh", ""], ["Sukhatme", "Gaurav", ""], ["Tabuada", "Paulo", ""], ["Verma", "Gunjan", ""]]}, {"id": "2002.04590", "submitter": "Oleg Verbitsky", "authors": "Frank Fuhlbr\\\"uck, Johannes K\\\"obler, Oleg Verbitsky", "title": "Local WL Invariance and Hidden Shades of Regularity", "comments": "12 pages, 2 figures, 1 table. Section 5 of the preceding version is\n  moved to arxiv:2005.08887", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-dimensional Weisfeiler-Leman algorithm is a powerful tool in graph\nisomorphism testing. For an input graph $G$, the algorithm determines a\ncanonical coloring of $s$-tuples of vertices of $G$ for each $s$ between 1 and\n$k$. We say that a numerical parameter of $s$-tuples is $k$-WL-invariant if it\nis determined by the tuple color. As an application of Dvo\\v{r}\\'ak's result on\n$k$-WL-invariance of homomorphism counts, we spot some non-obvious regularity\nproperties of strongly regular graphs and related graph families. For example,\nif $G$ is a strongly regular graph, then the number of paths of length 6\nbetween vertices $x$ and $y$ in $G$ depends only on whether or not $x$ and $y$\nare adjacent (and the length 6 is here optimal). Or, the number of cycles of\nlength 7 passing through a vertex $x$ in $G$ is the same for every $x$ (where\nthe length 7 is also optimal).\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 18:32:02 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 16:36:47 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Fuhlbr\u00fcck", "Frank", ""], ["K\u00f6bler", "Johannes", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "2002.04778", "submitter": "Binhai Zhu", "authors": "Manuel Lafond and Binhai Zhu and Peng Zou", "title": "Genomic Problems Involving Copy Number Profiles: Complexity and\n  Algorithms", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to the genomic sequence analysis in several types of cancer,\nthe genomic data based on {\\em copy number profiles} ({\\em CNP} for short) are\ngetting more and more popular. A CNP is a vector where each component is a\nnon-negative integer representing the number of copies of a specific gene or\nsegment of interest.\n  In this paper, we present two streams of results. The first is the negative\nresults on two open problems regarding the computational complexity of the\nMinimum Copy Number Generation (MCNG) problem posed by Qingge et al. in 2018.\nIt was shown by Qingge et al. that the problem is NP-hard if the duplications\nare tandem and they left the open question of whether the problem remains\nNP-hard if arbitrary duplications are used. We answer this question\naffirmatively in this paper; in fact, we prove that it is NP-hard to even\nobtain a constant factor approximation. We also prove that the parameterized\nversion is W[1]-hard, answering another open question by Qingge et al.\n  The other result is positive and is based on a new (and more general) problem\nregarding CNP's. The \\emph{Copy Number Profile Conforming (CNPC)} problem is\nformally defined as follows: given two CNP's $C_1$ and $C_2$, compute two\nstrings $S_1$ and $S_2$ with $cnp(S_1)=C_1$ and $cnp(S_2)=C_2$ such that the\ndistance between $S_1$ and $S_2$, $d(S_1,S_2)$, is minimized. Here,\n$d(S_1,S_2)$ is a very general term, which means it could be any genome\nrearrangement distance (like reversal, transposition, and tandem duplication,\netc). We make the first step by showing that if $d(S_1,S_2)$ is measured by the\nbreakpoint distance then the problem is polynomially solvable.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 03:31:42 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Lafond", "Manuel", ""], ["Zhu", "Binhai", ""], ["Zou", "Peng", ""]]}, {"id": "2002.04783", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Nhat Ho, Xi Chen, Marco Cuturi, and Michael I. Jordan", "title": "Fixed-Support Wasserstein Barycenters: Computational Hardness and Fast\n  Algorithm", "comments": "Accepted by NeurIPS 2020; fix some confusing parts in the proof and\n  improve the empirical evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fixed-support Wasserstein barycenter problem (FS-WBP), which\nconsists in computing the Wasserstein barycenter of $m$ discrete probability\nmeasures supported on a finite metric space of size $n$. We show first that the\nconstraint matrix arising from the standard linear programming (LP)\nrepresentation of the FS-WBP is \\textit{not totally unimodular} when $m \\geq 3$\nand $n \\geq 3$. This result resolves an open question pertaining to the\nrelationship between the FS-WBP and the minimum-cost flow (MCF) problem since\nit proves that the FS-WBP in the standard LP form is not an MCF problem when $m\n\\geq 3$ and $n \\geq 3$. We also develop a provably fast \\textit{deterministic}\nvariant of the celebrated iterative Bregman projection (IBP) algorithm, named\n\\textsc{FastIBP}, with a complexity bound of\n$\\tilde{O}(mn^{7/3}\\varepsilon^{-4/3})$, where $\\varepsilon \\in (0, 1)$ is the\ndesired tolerance. This complexity bound is better than the best known\ncomplexity bound of $\\tilde{O}(mn^2\\varepsilon^{-2})$ for the IBP algorithm in\nterms of $\\varepsilon$, and that of $\\tilde{O}(mn^{5/2}\\varepsilon^{-1})$ from\naccelerated alternating minimization algorithm or accelerated primal-dual\nadaptive gradient algorithm in terms of $n$. Finally, we conduct extensive\nexperiments with both synthetic data and real images and demonstrate the\nfavorable performance of the \\textsc{FastIBP} algorithm in practice.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 03:40:52 GMT"}, {"version": "v10", "created": "Mon, 26 Jul 2021 17:26:50 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 13:08:33 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 20:13:25 GMT"}, {"version": "v4", "created": "Wed, 10 Jun 2020 11:16:44 GMT"}, {"version": "v5", "created": "Thu, 15 Oct 2020 03:38:29 GMT"}, {"version": "v6", "created": "Sat, 17 Oct 2020 02:19:25 GMT"}, {"version": "v7", "created": "Wed, 25 Nov 2020 23:08:14 GMT"}, {"version": "v8", "created": "Sun, 20 Dec 2020 11:25:02 GMT"}, {"version": "v9", "created": "Sat, 17 Jul 2021 06:25:08 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lin", "Tianyi", ""], ["Ho", "Nhat", ""], ["Chen", "Xi", ""], ["Cuturi", "Marco", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.04841", "submitter": "Harro Wimmel", "authors": "Uli Schlachter and Harro Wimmel", "title": "Optimal Label Splitting for Embedding an LTS into an arbitrary Petri Net\n  Reachability Graph is NP-complete", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given labelled transition system (LTS), synthesis is the task to find\nan unlabelled Petri net with an isomorphic reachability graph. Even when just\ndemanding an embedding into a reachability graph instead of an isomorphism, a\nsolution is not guaranteed. In such a case, label splitting is an option, i.e.\nrelabelling edges of the LTS such that differently labelled edges remain\ndifferent. With an appropriate label splitting, we can always obtain a solution\nfor the synthesis or embedding problem. Using the label splitting, we can\nconstruct a labelled Petri net with the intended bahaviour (e.g. embedding the\ngiven LTS in its reachability graph). As the labelled Petri net can have a\nlarge number of transitions, an optimisation may be desired, limiting the\nnumber of labels produced by the label splitting. We show that such a\nlimitation will turn the problem from being solvable in polynomial time into an\nNP-complete problem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:28:32 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Schlachter", "Uli", ""], ["Wimmel", "Harro", ""]]}, {"id": "2002.05056", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam, Reevu Maity", "title": "Quantum Boosting", "comments": "37 pages; v2: minor edits to improve presentation", "journal-ref": "Proceedings of ICML 2020", "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we have a weak learning algorithm $\\mathcal{A}$ for a Boolean-valued\nproblem: $\\mathcal{A}$ produces hypotheses whose bias $\\gamma$ is small, only\nslightly better than random guessing (this could, for instance, be due to\nimplementing $\\mathcal{A}$ on a noisy device), can we boost the performance of\n$\\mathcal{A}$ so that $\\mathcal{A}$'s output is correct on $2/3$ of the inputs?\n  Boosting is a technique that converts a weak and inaccurate machine learning\nalgorithm into a strong accurate learning algorithm. The AdaBoost algorithm by\nFreund and Schapire (for which they were awarded the G\\\"odel prize in 2003) is\none of the widely used boosting algorithms, with many applications in theory\nand practice. Suppose we have a $\\gamma$-weak learner for a Boolean concept\nclass $C$ that takes time $R(C)$, then the time complexity of AdaBoost scales\nas $VC(C)\\cdot poly(R(C), 1/\\gamma)$, where $VC(C)$ is the $VC$-dimension of\n$C$. In this paper, we show how quantum techniques can improve the time\ncomplexity of classical AdaBoost. To this end, suppose we have a $\\gamma$-weak\nquantum learner for a Boolean concept class $C$ that takes time $Q(C)$, we\nintroduce a quantum boosting algorithm whose complexity scales as\n$\\sqrt{VC(C)}\\cdot poly(Q(C),1/\\gamma);$ thereby achieving a quadratic quantum\nimprovement over classical AdaBoost in terms of $VC(C)$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:47:54 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 23:06:52 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Maity", "Reevu", ""]]}, {"id": "2002.05131", "submitter": "Justin Kopinsky", "authors": "Erik Demaine and Justin Kopinsky and Jayson Lynch", "title": "Recursed is not Recursive: A Jarring Result", "comments": "Submitted to MFCS2020, 21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursed is a 2D puzzle platform video game featuring treasure chests that,\nwhen jumped into, instantiate a room that can later be exited (similar to\nfunction calls), optionally generating a jar that returns back to that room\n(similar to continuations). We prove that Recursed is RE-complete and thus\nundecidable (not recursive) by a reduction from the Post Correspondence\nProblem. Our reduction is \"practical\": the reduction from PCP results in fully\nplayable levels that abide by all constraints governing levels (including the\n15x20 room size) designed for the main game. Our reduction is also \"efficient\":\na Turing machine can be simulated by a Recursed level whose size is linear in\nthe encoding size of the Turing machine and whose solution length is polynomial\nin the running time of the Turing machine.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:20:37 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 15:17:11 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Demaine", "Erik", ""], ["Kopinsky", "Justin", ""], ["Lynch", "Jayson", ""]]}, {"id": "2002.05156", "submitter": "Matteo Castiglioni", "authors": "Matteo Castiglioni, Andrea Celli, Nicola Gatti", "title": "Public Bayesian Persuasion: Being Almost Optimal and Almost Persuasive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persuasion studies how an informed principal may influence the behavior of\nagents by the strategic provision of payoff-relevant information. We focus on\nthe fundamental multi-receiver model by Arieli and Babichenko (2019), in which\nthere are no inter-agent externalities. Unlike prior works on this problem, we\nstudy the public persuasion problem in the general setting with: (i) arbitrary\nstate spaces; (ii) arbitrary action spaces; (iii) arbitrary sender's utility\nfunctions. We fully characterize the computational complexity of computing a\nbi-criteria approximation of an optimal public signaling scheme. In particular,\nwe show, in a voting setting of independent interest, that solving this problem\nrequires at least a quasi-polynomial number of steps even in settings with a\nbinary action space, assuming the Exponential Time Hypothesis. In doing so, we\nprove that a relaxed version of the Maximum Feasible Subsystem of Linear\nInequalities problem requires at least quasi-polynomial time to be solved.\nFinally, we close the gap by providing a quasi-polynomial time bi-criteria\napproximation algorithm for arbitrary public persuasion problems that, in\nspecific settings, yields a QPTAS.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:59:18 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 13:26:27 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Castiglioni", "Matteo", ""], ["Celli", "Andrea", ""], ["Gatti", "Nicola", ""]]}, {"id": "2002.05239", "submitter": "Matthias Lanzinger", "authors": "Georg Gottlob, Matthias Lanzinger, Reinhard Pichler, Igor Razgon", "title": "Complexity Analysis of Generalized and Fractional Hypertree\n  Decompositions", "comments": "This is a significantly extended and enhanced version of\n  arXiv:1611.01090", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypertree decompositions (HDs), as well as the more powerful generalized\nhypertree decompositions (GHDs), and the yet more general fractional hypertree\ndecompositions (FHDs) are hypergraph decomposition methods successfully used\nfor answering conjunctive queries and for solving constraint satisfaction\nproblems. Every hypergraph $H$ has a width relative to each of these methods:\nits hypertree width $hw(H)$, its generalized hypertree width $ghw(H)$, and its\nfractional hypertree width $fhw(H)$, respectively. It is known that $hw(H)\\leq\nk$ can be checked in polynomial time for fixed $k$, while checking $ghw(H)\\leq\nk$ is NP-complete for $k \\geq 3$. The complexity of checking $fhw(H)\\leq k$ for\na fixed $k$ has been open for over a decade.\n  We settle this open problem by showing that checking $fhw(H)\\leq k$ is\nNP-complete, even for $k=2$. The same construction allows us to prove also the\nNP-completeness of checking $ghw(H)\\leq k$ for $k=2$. After that, we identify\nmeaningful restrictions which make checking for bounded $ghw$ or $fhw$\ntractable or allow for an efficient approximation of the $fhw$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:21:05 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 13:18:58 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Gottlob", "Georg", ""], ["Lanzinger", "Matthias", ""], ["Pichler", "Reinhard", ""], ["Razgon", "Igor", ""]]}, {"id": "2002.05538", "submitter": "Jakkepalli Pavan Kumar", "authors": "Jakkepalli Pavan Kumar and P. Venkata Subba Reddy", "title": "Algorithmic Complexity of Isolate Secure Domination in Graphs", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.00002;\n  text overlap with arXiv:2001.11250", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dominating set $S$ is an Isolate Dominating Set (IDS) if the induced\nsubgraph $G[S]$ has at least one isolated vertex. In this paper, we initiate\nthe study of new domination parameter called, isolate secure domination. An\nisolate dominating set $S\\subseteq V$ is an isolate secure dominating set\n(ISDS), if for each vertex $u \\in V \\setminus S$, there exists a neighboring\nvertex $v$ of $u$ in $S$ such that $(S \\setminus \\{v\\}) \\cup \\{u\\}$ is an IDS\nof $G$. The minimum cardinality of an ISDS of $G$ is called as an isolate\nsecure domination number, and is denoted by $\\gamma_{0s}(G)$. Given a graph $\nG=(V,E)$ and a positive integer $ k,$ the ISDM problem is to check whether $ G\n$ has an isolate secure dominating set of size at most $ k.$ We prove that ISDM\nis NP-complete even when restricted to bipartite graphs and split graphs. We\nalso show that ISDM can be solved in linear time for graphs of bounded\ntree-width.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 07:42:51 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Kumar", "Jakkepalli Pavan", ""], ["Reddy", "P. Venkata Subba", ""]]}, {"id": "2002.06005", "submitter": "Corinna Coupette", "authors": "Corinna Coupette and Christoph Lenzen", "title": "A Breezing Proof of the KMW Bound", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their seminal paper from 2004, Kuhn, Moscibroda, and Wattenhofer (KMW)\nproved a hardness result for several fundamental graph problems in the LOCAL\nmodel: For any (randomized) algorithm, there are input graphs with $n$ nodes\nand maximum degree $\\Delta$ on which $\\Omega(\\min\\{\\sqrt{\\log n/\\log \\log\nn},\\log \\Delta/\\log \\log \\Delta\\})$ (expected) communication rounds are\nrequired to obtain polylogarithmic approximations to a minimum vertex cover,\nminimum dominating set, or maximum matching. Via reduction, this hardness\nextends to symmetry breaking tasks like finding maximal independent sets or\nmaximal matchings. Today, more than $15$ years later, there is still no proof\nof this result that is easy on the reader. Setting out to change this, in this\nwork, we provide a fully self-contained and $\\mathit{simple}$ proof of the KMW\nlower bound. The key argument is algorithmic, and it relies on an invariant\nthat can be readily verified from the generation rules of the lower bound\ngraphs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:49:15 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 06:34:38 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 07:55:10 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 20:19:18 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Coupette", "Corinna", ""], ["Lenzen", "Christoph", ""]]}, {"id": "2002.06078", "submitter": "Ignasi Sau", "authors": "R\\'emy Belmonte, Ignasi Sau", "title": "On the complexity of finding large odd induced subgraphs and odd\n  colorings", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of the problems of finding, given a graph $G$, a\nlargest induced subgraph of $G$ with all degrees odd (called an odd subgraph),\nand the smallest number of odd subgraphs that partition $V(G)$. We call these\nparameters ${\\sf mos}(G)$ and $\\chi_{{\\sf odd}}(G)$, respectively. We prove\nthat deciding whether $\\chi_{{\\sf odd}}(G) \\leq q$ is polynomial-time solvable\nif $q \\leq 2$, and NP-complete otherwise. We provide algorithms in time\n$2^{O({\\sf rw})} \\cdot n^{O(1)}$ and $2^{O(q \\cdot {\\sf rw})} \\cdot n^{O(1)}$\nto compute ${\\sf mos}(G)$ and to decide whether $\\chi_{{\\sf odd}}(G) \\leq q$ on\n$n$-vertex graphs of rank-width at most ${\\sf rw}$, respectively, and we prove\nthat the dependency on rank-width is asymptotically optimal under the ETH.\nFinally, we give some tight bounds for these parameters on restricted graph\nclasses or in relation to other parameters.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:31:51 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 22:21:05 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Belmonte", "R\u00e9my", ""], ["Sau", "Ignasi", ""]]}, {"id": "2002.06083", "submitter": "Alexandr Kazda", "authors": "Alexandr Kazda", "title": "Deciding the existence of quasi weak near unanimity terms in finite\n  algebras", "comments": "17 pages, number n fixed to k in the proof of Lemma 11", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for a fixed positive integer k one can efficiently decide if a\nfinite algebra A admits a k-ary weak near unanimity operation by looking at the\nlocal behavior of the terms of A. We also observe that the problem of deciding\nif a given finite algebra has a quasi Taylor operation is solvable in\npolynomial time by looking, essentially, for local quasi Siggers operations.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:38:37 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 14:00:46 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 23:44:21 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Kazda", "Alexandr", ""]]}, {"id": "2002.06451", "submitter": "Gregory Wilsenach", "authors": "Anuj Dawar and Gregory Wilsenach", "title": "Symmetric Arithmetic Circuits", "comments": "24 pages. A preliminary version of this work was presented at the\n  International Colloquium on Automata, Languages and Programming (ICALP) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce symmetric arithmetic circuits, i.e. arithmetic circuits with a\nnatural symmetry restriction. In the context of circuits computing polynomials\ndefined on a matrix of variables, such as the determinant or the permanent, the\nrestriction amounts to requiring that the shape of the circuit is invariant\nunder simultaneous row and column permutations of the matrix. We establish\nunconditional exponential lower bounds on the size of any symmetric circuit for\ncomputing the permanent. In contrast, we show that there are polynomial-size\nsymmetric circuits for computing the determinant over fields of characteristic\nzero.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 21:13:00 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 21:15:27 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Dawar", "Anuj", ""], ["Wilsenach", "Gregory", ""]]}, {"id": "2002.06683", "submitter": "Bruno Bauwens", "authors": "Bruno Bauwens, Ilya Blinnikov", "title": "The normalized algorithmic information distance can not be approximated", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the normalized algorithmic information distance $N$ is not\ncomputable and not semicomputable. We show that for all $\\epsilon < 1/2$, there\nexist no semicomputable functions that differ from $N$ by at most~$\\epsilon$.\nMoreover, for any computable function $f$ such that $|\\lim_t f(x,y,t) - N(x,y)|\n\\le \\epsilon$ and for all $n$, there exist strings $x,y$ of length $n$ such\nthat $\\sum_t |f(x,y,t+1) - f(x,y,t)| \\ge \\Omega(\\log n)$. This is optimal up to\nconstant factors. We also show that the maximal number of oscillations of a\nlimit approximation of $N$ is $\\Omega(n/\\log n)$. This strengthens the\n$\\omega(1)$ lower bound from [K. Ambos-Spies, W. Merkle, and S.A. Terwijn,\n2019, Normalized information distance and the oscillation hierarchy], see\narXiv:1708.03583 .\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 21:20:17 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bauwens", "Bruno", ""], ["Blinnikov", "Ilya", ""]]}, {"id": "2002.07054", "submitter": "Michael Pinsker", "authors": "Pierre Gillibert, Julius Jonu\\v{s}as, Michael Kompatscher, Antoine\n  Mottet, Michael Pinsker", "title": "When symmetries are not enough: a hierarchy of hard Constraint\n  Satisfaction Problems", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We produce a class of $\\omega$-categorical structures with finite signature\nby applying a model-theoretic construction -- a refinement of the\nHrushosvki-encoding -- to $\\omega$-categorical structures in a possibly\ninfinite signature. We show that the encoded structures retain desirable\nalgebraic properties of the original structures, but that the constraint\nsatisfaction problems (CSPs) associated with these structures can be badly\nbehaved in terms of computational complexity. This method allows us to\nsystematically generate $\\omega$-categorical templates whose CSPs are complete\nfor a variety of complexity classes of arbitrarily high complexity, and\n$\\omega$-categorical templates that show that membership in any given\ncomplexity class cannot be expressed by a set of identities on the\npolymorphisms. It moreover enables us to prove that recent results about the\nrelevance of topology on polymorphism clones of $\\omega$-categorical structures\nalso apply for CSP templates, i.e., structures in a finite language. Finally,\nwe obtain a concrete algebraic criterion which could constitute a description\nof the delineation between tractability and NP-hardness in the dichotomy\nconjecture for first-order reducts of finitely bounded homogeneous structures.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:49:00 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2021 19:54:03 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Gillibert", "Pierre", ""], ["Jonu\u0161as", "Julius", ""], ["Kompatscher", "Michael", ""], ["Mottet", "Antoine", ""], ["Pinsker", "Michael", ""]]}, {"id": "2002.07208", "submitter": "Jyun-Jie Liao", "authors": "Eshan Chattopadhyay, Jyun-Jie Liao", "title": "Optimal Error Pseudodistributions for Read-Once Branching Programs", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.CCC.2020.25", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a seminal work, Nisan (Combinatorica'92) constructed a pseudorandom\ngenerator for length $n$ and width $w$ read-once branching programs with seed\nlength $O(\\log n\\cdot \\log(nw)+\\log n\\cdot\\log(1/\\varepsilon))$ and error\n$\\varepsilon$. It remains a central question to reduce the seed length to\n$O(\\log (nw/\\varepsilon))$, which would prove that $\\mathbf{BPL}=\\mathbf{L}$.\nHowever, there has been no improvement on Nisan's construction for the case\n$n=w$, which is most relevant to space-bounded derandomization.\n  Recently, in a beautiful work, Braverman, Cohen and Garg (STOC'18) introduced\nthe notion of a pseudorandom pseudo-distribution (PRPD) and gave an explicit\nconstruction of a PRPD with seed length $\\tilde{O}(\\log n\\cdot\n\\log(nw)+\\log(1/\\varepsilon))$. A PRPD is a relaxation of a pseudorandom\ngenerator, which suffices for derandomizing $\\mathbf{BPL}$ and also implies a\nhitting set. Unfortunately, their construction is quite involved and\ncomplicated. Hoza and Zuckerman (FOCS'18) later constructed a much simpler\nhitting set generator with seed length $O(\\log n\\cdot\n\\log(nw)+\\log(1/\\varepsilon))$, but their techniques are restricted to hitting\nsets.\n  In this work, we construct a PRPD with seed length $$O(\\log n\\cdot \\log\n(nw)\\cdot \\log\\log(nw)+\\log(1/\\varepsilon)).$$ This improves upon the\nconstruction in [BCG18] by a $O(\\log\\log(1/\\varepsilon))$ factor, and is\noptimal in the small error regime. In addition, we believe our construction and\nanalysis to be simpler than the work of Braverman, Cohen and Garg.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:10:56 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 06:27:27 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 01:26:29 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 04:29:52 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Chattopadhyay", "Eshan", ""], ["Liao", "Jyun-Jie", ""]]}, {"id": "2002.07235", "submitter": "Sumegha Garg", "authors": "Sumegha Garg, Pravesh K. Kothari, Ran Raz", "title": "Time-Space Tradeoffs for Distinguishing Distributions and Applications\n  to Security of Goldreich's PRG", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we establish lower-bounds against memory bounded algorithms for\ndistinguishing between natural pairs of related distributions from samples that\narrive in a streaming setting.\n  In our first result, we show that any algorithm that distinguishes between\nuniform distribution on $\\{0,1\\}^n$ and uniform distribution on an\n$n/2$-dimensional linear subspace of $\\{0,1\\}^n$ with non-negligible advantage\nneeds $2^{\\Omega(n)}$ samples or $\\Omega(n^2)$ memory.\n  Our second result applies to distinguishing outputs of Goldreich's local\npseudorandom generator from the uniform distribution on the output domain.\nSpecifically, Goldreich's pseudorandom generator $G$ fixes a predicate\n$P:\\{0,1\\}^k \\rightarrow \\{0,1\\}$ and a collection of subsets $S_1, S_2,\n\\ldots, S_m \\subseteq [n]$ of size $k$. For any seed $x \\in \\{0,1\\}^n$, it\noutputs $P(x_{S_1}), P(x_{S_2}), \\ldots, P(x_{S_m})$ where $x_{S_i}$ is the\nprojection of $x$ to the coordinates in $S_i$. We prove that whenever $P$ is\n$t$-resilient (all non-zero Fourier coefficients of $(-1)^P$ are of degree $t$\nor higher), then no algorithm, with $<n^\\epsilon$ memory, can distinguish the\noutput of $G$ from the uniform distribution on $\\{0,1\\}^m$ with a large inverse\npolynomial advantage, for stretch $m \\le\n\\left(\\frac{n}{t}\\right)^{\\frac{(1-\\epsilon)}{36}\\cdot t}$ (barring some\nrestrictions on $k$). The lower bound holds in the streaming model where at\neach time step $i$, $S_i\\subseteq [n]$ is a randomly chosen (ordered) subset of\nsize $k$ and the distinguisher sees either $P(x_{S_i})$ or a uniformly random\nbit along with $S_i$.\n  Our proof builds on the recently developed machinery for proving time-space\ntrade-offs (Raz 2016 and follow-ups) for search/learning problems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:17:05 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Garg", "Sumegha", ""], ["Kothari", "Pravesh K.", ""], ["Raz", "Ran", ""]]}, {"id": "2002.07363", "submitter": "Yannai A. Gonczarowski", "authors": "Ehsan Emamjomeh-Zadeh, Yannai A. Gonczarowski, David Kempe", "title": "The Complexity of Interactively Learning a Stable Matching by Trial and\n  Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a stable matching setting, we consider a query model that allows for an\ninteractive learning algorithm to make precisely one type of query: proposing a\nmatching, the response to which is either that the proposed matching is stable,\nor a blocking pair (chosen adversarially) indicating that this matching is\nunstable. For one-to-one matching markets, our main result is an essentially\ntight upper bound of $O(n^2\\log n)$ on the deterministic query complexity of\ninteractively learning a stable matching in this coarse query model, along with\nan efficient randomized algorithm that achieves this query complexity with high\nprobability. For many-to-many matching markets in which participants have\nresponsive preferences, we first give an interactive learning algorithm whose\nquery complexity and running time are polynomial in the size of the market if\nthe maximum quota of each agent is bounded; our main result for many-to-many\nmarkets is that the deterministic query complexity can be made polynomial (more\nspecifically, $O(n^3 \\log n)$) in the size of the market even for arbitrary\n(e.g., linear in the market size) quotas.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 04:29:03 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 00:50:27 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 21:34:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Emamjomeh-Zadeh", "Ehsan", ""], ["Gonczarowski", "Yannai A.", ""], ["Kempe", "David", ""]]}, {"id": "2002.07444", "submitter": "Vladimir Podolskii", "authors": "Alexander Kozachinskiy and Vladimir Podolskii", "title": "Multiparty Karchmer-Wigderson Games and Threshold Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a generalization of Karchmer-Wigderson communication games to the\nmultiparty setting. Our generalization turns out to be tightly connected to\ncircuits consisting of threshold gates. This allows us to obtain new explicit\nconstructions of such circuits for several functions. In particular, we provide\nan explicit (polynomial-time computable) log-depth monotone formula for\nMajority function, consisting only of 3-bit majority gates and variables. This\nresolves a conjecture of Cohen et al. (CRYPTO 2013).\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 09:31:00 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kozachinskiy", "Alexander", ""], ["Podolskii", "Vladimir", ""]]}, {"id": "2002.07466", "submitter": "Clara Waldmann", "authors": "George Christodoulou, Martin Gairing, Yiannis Giannakopoulos, Diogo\n  Po\\c{c}as, Clara Waldmann", "title": "Existence and Complexity of Approximate Equilibria in Weighted\n  Congestion Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the existence of approximate pure Nash equilibria ($\\alpha$-PNE) in\nweighted atomic congestion games with polynomial cost functions of maximum\ndegree $d$. Previously it was known that $d$-approximate equilibria always\nexist, while nonexistence was established only for small constants, namely for\n$1.153$-PNE. We improve significantly upon this gap, proving that such games in\ngeneral do not have $\\tilde{\\Theta}(\\sqrt{d})$-approximate PNE, which provides\nthe first super-constant lower bound.\n  Furthermore, we provide a black-box gap-introducing method of combining such\nnonexistence results with a specific circuit gadget, in order to derive\nNP-completeness of the decision version of the problem. In particular,\ndeploying this technique we are able to show that deciding whether a weighted\ncongestion game has an $\\tilde{O}(\\sqrt{d})$-PNE is NP-complete. Previous\nhardness results were known only for the special case of exact equilibria and\narbitrary cost functions.\n  The circuit gadget is of independent interest and it allows us to also prove\nhardness for a variety of problems related to the complexity of PNE in\ncongestion games. For example, we demonstrate that the question of existence of\n$\\alpha$-PNE in which a certain set of players plays a specific strategy\nprofile is NP-hard for any $\\alpha < 3^{d/2}$, even for unweighted congestion\ngames.\n  Finally, we study the existence of approximate equilibria in weighted\ncongestion games with general (nondecreasing) costs, as a function of the\nnumber of players $n$. We show that $n$-PNE always exist, matched by an almost\ntight nonexistence bound of $\\tilde\\Theta(n)$ which we can again transform into\nan NP-completeness proof for the decision problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 10:06:15 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 11:56:25 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Christodoulou", "George", ""], ["Gairing", "Martin", ""], ["Giannakopoulos", "Yiannis", ""], ["Po\u00e7as", "Diogo", ""], ["Waldmann", "Clara", ""]]}, {"id": "2002.07569", "submitter": "Philipp Zschoche", "authors": "Till Fluschnik, Rolf Niedermeier, Carsten Schubert, and Philipp\n  Zschoche", "title": "Multistage s-t Path: Confronting Similarity with Dissimilarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Addressing a quest by Gupta et al. [ICALP'14], we provide a first,\ncomprehensive study of finding a short s-t path in the multistage graph model,\nreferred to as the Multistage s-t Path problem. Herein, given a sequence of\ngraphs over the same vertex set but changing edge sets, the task is to find\nshort s-t paths in each graph (\"snapshot\") such that in the found path sequence\nthe consecutive s-t paths are \"similar\". We measure similarity by the size of\nthe symmetric difference of either the vertex set (vertex-similarity) or the\nedge set (edge-similarity) of any two consecutive paths. We prove that these\ntwo variants of Multistage s-t Path are already NP-hard for an input sequence\nof only two graphs and maximum vertex degree four. Motivated by this fact and\nnatural applications of this scenario e.g. in traffic route planning, we\nperform a parameterized complexity analysis. Among other results, for both\nvariants, vertex- and edge-similarity, we prove parameterized hardness\n(W[1]-hardness) regarding the parameter path length (solution size) for both\nvariants, vertex- and edge-similarity. As a further conceptual study, we then\nmodify the multistage model by asking for dissimilar consecutive paths. As one\nof the main technical results (employing so-called representative sets known\nfrom non-temporal settings), we prove that dissimilarity allows for\nfixed-parameter tractability for the parameter solution size, contrasting our\nW[1]-hardness proof of the corresponding similarity case. We also provide\npartially positive results concerning efficient and effective data reduction\n(kernelization).\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 14:06:03 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 08:23:00 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 07:53:08 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Fluschnik", "Till", ""], ["Niedermeier", "Rolf", ""], ["Schubert", "Carsten", ""], ["Zschoche", "Philipp", ""]]}, {"id": "2002.07659", "submitter": "Jan Studen\\'y", "authors": "Yi-Jun Chang, Jan Studen\\'y, Jukka Suomela", "title": "Distributed graph problems through an automata-theoretic lens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The locality of a graph problem is the smallest distance $T$ such that each\nnode can choose its own part of the solution based on its radius-$T$\nneighborhood. In many settings, a graph problem can be solved efficiently with\na distributed or parallel algorithm if and only if it has a small locality.\n  In this work we seek to automate the study of solvability and locality: given\nthe description of a graph problem $\\Pi$, we would like to determine if $\\Pi$\nis solvable and what is the asymptotic locality of $\\Pi$ as a function of the\nsize of the graph. Put otherwise, we seek to automatically synthesize efficient\ndistributed and parallel algorithms for solving $\\Pi$.\n  We focus on locally checkable graph problems; these are problems in which a\nsolution is globally feasible if it looks feasible in all constant-radius\nneighborhoods. Prior work on such problems has brought primarily bad news:\nquestions related to locality are undecidable in general, and even if we focus\non the case of labeled paths and cycles, determining locality is\n$\\mathsf{PSPACE}$-hard (Balliu et al., PODC 2019).\n  We complement prior negative results with efficient algorithms for the cases\nof unlabeled paths and cycles and, as an extension, for rooted trees. We\nintroduce a new automata-theoretic perspective for studying locally checkable\ngraph problems. We represent a locally checkable problem $\\Pi$ as a\nnondeterministic finite automaton $\\mathcal{M}$ over a unary alphabet. We\nidentify polynomial-time-computable properties of the automaton $\\mathcal{M}$\nthat near-completely capture the solvability and locality of $\\Pi$ in cycles\nand paths, with the exception of one specific case that is\n$\\mbox{co-$\\mathsf{NP}$}$-complete.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:47:08 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 19:06:38 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Chang", "Yi-Jun", ""], ["Studen\u00fd", "Jan", ""], ["Suomela", "Jukka", ""]]}, {"id": "2002.07674", "submitter": "Paul Vitanyi", "authors": "Paul Vitanyi (CWI and University of Amsterdam)", "title": "How incomputable is Kolmogorov complexity?", "comments": "9 pages LaTeX", "journal-ref": null, "doi": "10.3390/e22040408", "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kolmogorov complexity is the length of the ultimately compressed version of a\nfile (that is, anything which can be put in a computer). Formally, it is the\nlength of a shortest program from which the file can be reconstructed. We\ndiscuss the incomputabilty of Kolmogorov complexity, which formal loopholes\nthis leaves us, recent approaches to compute or approximate Kolmogorov\ncomplexity, which approaches are problematic and which approaches are viable.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:02:46 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 14:20:54 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Vitanyi", "Paul", "", "CWI and University of Amsterdam"]]}, {"id": "2002.07695", "submitter": "Riccardo Dondi", "authors": "Riccardo Dondi, Danny Hermelin", "title": "Computing the k Densest Subgraphs of a Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing cohesive subgraphs is a central problem in graph theory. While many\nformulations of cohesive subgraphs lead to NP-hard problems, finding a densest\nsubgraph can be done in polynomial time. As such, the densest subgraph model\nhas emerged as the most popular notion of cohesiveness. Recently, the data\nmining community has started looking into the problem of computing k densest\nsubgraphs in a given graph, rather than one, with various restrictions on the\npossible overlap between the subgraphs. However, there seems to be very little\nknown on this important and natural generalization from a theoretical\nperspective. In this paper we hope to remedy this situation by analyzing three\nnatural variants of the k densest subgraphs problem. Each variant differs\ndepending on the amount of overlap that is allowed between the subgraphs. In\none extreme, when no overlap is allowed, we prove that the problem is NP-hard\nfor k >= 3. On the other extreme, when overlap is allowed without any\nrestrictions and the solution subgraphs only have to be distinct, we show that\nthe problem is fixed-parameter tractable with respect to k, and admits a PTAS\nfor constant k. Finally, when a limited of overlap is allowed between the\nsubgraphs, we prove that the problem is NP-hard for k = 2.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:18:54 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 15:55:35 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 13:49:47 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Dondi", "Riccardo", ""], ["Hermelin", "Danny", ""]]}, {"id": "2002.07741", "submitter": "P\\'al Andr\\'as Papp", "authors": "P\\'al Andr\\'as Papp, Roger Wattenhofer", "title": "Default Ambiguity: Finding the Best Solution to the Clearing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CC q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study financial networks with debt contracts and credit default swaps\nbetween specific pairs of banks. Given such a financial system, we want to\ndecide which of the banks are in default, and how much of their liabilities\nthese defaulting banks can pay. There can easily be multiple different\nsolutions to this problem, leading to a situation of default ambiguity and a\nrange of possible solutions to implement for a financial authority.\n  In this paper, we study the general properties of the solution space of such\nfinancial systems, and analyze a wide range of reasonable objective functions\nfor selecting from the set of solutions. Examples of such objective functions\ninclude minimizing the number of defaulting banks, minimizing the amount of\nunpaid debt, maximizing the number of satisfied banks, maximizing the equity of\na specific bank, finding the most balanced distribution of equity, and many\nothers. We show that for all of these objective functions, it is not only\nNP-hard to find the optimal solution, but it is also NP-hard to approximate\nthis optimum: for each objective function, we show an inapproximability either\nto an $n^{1/2-\\epsilon}$ or to an $n^{1/4-\\epsilon}$ factor for any\n$\\epsilon>0$, with $n$ denoting the number of banks in the system. Thus even if\nan authority has clear criteria to select a solution in case of default\nambiguity, it is computationally intractable to find a solution that is\nreasonably good in terms of this criteria. We also show that our hardness\nresults hold in a wide range of different model variants.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:17:15 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Papp", "P\u00e1l Andr\u00e1s", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2002.07745", "submitter": "Friedrich Eisenbrand", "authors": "Jana Cslovjecsek and Friedrich Eisenbrand and Christoph\n  Hunkenschr\\\"oder and Lars Rohwedder and Robert Weismantel", "title": "Block-Structured Integer and Linear Programming in Strongly Polynomial\n  and Near Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider integer and linear programming problems for which the linear\nconstraints exhibit a (recursive) block-structure: The problem decomposes into\nindependent and efficiently solvable sub-problems if a small number of\nconstraints is deleted. A prominent example are $n$-fold integer programming\nproblems and their generalizations which have received considerable attention\nin the recent literature. The previously known algorithms for these problems\nare based on the augmentation framework, a tailored integer programming variant\nof local search. In this paper we propose a different approach. Our algorithm\nrelies on parametric search and a new proximity bound. We show that\nblock-structured linear programming can be solved efficiently via an adaptation\nof a parametric search framework by Norton, Plotkin, and Tardos in combination\nwith Megiddo's multidimensional search technique. This also forms a subroutine\nof our algorithm for the integer programming case by solving a strong\nrelaxation of it. Then we show that, for any given optimal vertex solution of\nthis relaxation, there is an optimal integer solution within $\\ell_1$-distance\nindependent of the dimension of the problem. This in turn allows us to find an\noptimal integer solution efficiently. We apply our techniques to integer and\nlinear programming with $n$-fold structure or bounded dual treedepth, two\nbenchmark problems in this field. We obtain the first algorithms for these\ncases that are both near-linear in the dimension of the problem and strongly\npolynomial. Moreover, unlike the augmentation algorithms, our approach is\nhighly parallelizable.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:23:01 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 10:33:00 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Cslovjecsek", "Jana", ""], ["Eisenbrand", "Friedrich", ""], ["Hunkenschr\u00f6der", "Christoph", ""], ["Rohwedder", "Lars", ""], ["Weismantel", "Robert", ""]]}, {"id": "2002.08086", "submitter": "Michael Figelius", "authors": "Michael Figelius, Moses Ganardi, Markus Lohrey and Georg Zetzsche", "title": "The complexity of knapsack problems in wreath products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove new complexity results for computational problems in certain wreath\nproducts of groups and (as an application) for free solvable group. For a\nfinitely generated group we study the so-called power word problem (does a\ngiven expression $u_1^{k_1} \\ldots u_d^{k_d}$, where $u_1, \\ldots, u_d$ are\nwords over the group generators and $k_1, \\ldots, k_d$ are binary encoded\nintegers, evaluate to the group identity?) and knapsack problem (does a given\nequation $u_1^{x_1} \\ldots u_d^{x_d} = v$, where $u_1, \\ldots, u_d,v$ are words\nover the group generators and $x_1,\\ldots,x_d$ are variables, has a solution in\nthe natural numbers). We prove that the power word problem for wreath products\nof the form $G \\wr \\mathbb{Z}$ with $G$ nilpotent and iterated wreath products\nof free abelian groups belongs to $\\mathsf{TC}^0$. As an application of the\nlatter, the power word problem for free solvable groups is in $\\mathsf{TC}^0$.\nOn the other hand we show that for wreath products $G \\wr \\mathbb{Z}$, where\n$G$ is a so called uniformly strongly efficiently non-solvable group (which\nform a large subclass of non-solvable groups), the power word problem is\n$\\mathsf{coNP}$-hard. For the knapsack problem we show\n$\\mathsf{NP}$-completeness for iterated wreath products of free abelian groups\nand hence free solvable groups. Moreover, the knapsack problem for every wreath\nproduct $G \\wr \\mathbb{Z}$, where $G$ is uniformly efficiently non-solvable, is\n$\\Sigma^2_p$-hard.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 09:48:08 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Figelius", "Michael", ""], ["Ganardi", "Moses", ""], ["Lohrey", "Markus", ""], ["Zetzsche", "Georg", ""]]}, {"id": "2002.08199", "submitter": "Daniel Gra\\c{c}a", "authors": "Daniel S. Gra\\c{c}a and Ning Zhong", "title": "The set of hyperbolic equilibria and of invertible zeros on the unit\n  ball is computable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we construct an algorithm that, on input of a description of a\nstructurally stable planar dynamical flow defined on the unit disk, outputs the\nexact number of the (hyperbolic) equilibrium points as well the locations of\nall equilibriums with arbitrary precision. By arbitrary accuracy it is meant\nthat the accuracy is included in the input of the algorithm. As a consequence,\nwe obtain a root-finding algorithm that computes the set of all zeros of a\ncontinuously differentiable function $f$ defined on the unit ball of\n$\\mathbb{R}^{d}$ with arbitrary accuracy, provided that the Jacobian of $f$ is\ninvertible at each zero of $f$; moreover, the computation is uniform in $f$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 14:09:09 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Gra\u00e7a", "Daniel S.", ""], ["Zhong", "Ning", ""]]}, {"id": "2002.08216", "submitter": "Dennis Olivetti", "authors": "Sebastian Brandt, Dennis Olivetti", "title": "Truly Tight-in-$\\Delta$ Bounds for Bipartite Maximal Matching and\n  Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent breakthrough result, Balliu et al. [FOCS'19] proved a\ndeterministic $\\Omega(\\min(\\Delta,\\log n /\\log \\log n))$-round and a randomized\n$\\Omega(\\min(\\Delta,\\log \\log n/\\log \\log \\log n))$-round lower bound for the\ncomplexity of the bipartite maximal matching problem on $n$-node graphs in the\nLOCAL model of distributed computing.\n  Both lower bounds are asymptotically tight as a function of the maximum\ndegree $\\Delta$.\n  We provide truly tight bounds in $\\Delta$ for the complexity of bipartite\nmaximal matching and many natural variants, up to and including the additive\nconstant.\n  As a by-product, our results yield a considerably simplified version of the\nproof by Balliu et al.\n  We show that our results can be obtained via bounded automatic round\nelimination, a version of the recent automatic round elimination technique by\nBrandt [PODC'19] that is particularly suited for automatization from a\npractical perspective.\n  In this context, our work can be seen as another step towards the\nautomatization of lower bounds in the LOCAL model.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 14:42:39 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Brandt", "Sebastian", ""], ["Olivetti", "Dennis", ""]]}, {"id": "2002.08231", "submitter": "Prahladh Harsha", "authors": "Siddharth Bhandari, Prahladh Harsha", "title": "A note on the explicit constructions of tree codes over\n  polylogarithmic-sized alphabet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Cohen, Haeupler and Schulman gave an explicit construction of\nbinary tree codes over polylogarithmic-sized output alphabet based on\nPudl\\'{a}k's construction of maximum-distance-separable (MDS) tree codes using\ntotally-non-singular triangular matrices. In this short note, we give a unified\nand simpler presentation of Pudl\\'{a}k and Cohen-Haeupler-Schulman's\nconstructions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:12:25 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Bhandari", "Siddharth", ""], ["Harsha", "Prahladh", ""]]}, {"id": "2002.08240", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam, Alex B. Grilo, Henry Yuen", "title": "Quantum statistical query learning", "comments": "24 Pages. Version 2, minor edits to improve presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning model called the quantum statistical learning QSQ\nmodel, which extends the SQ learning model introduced by Kearns to the quantum\nsetting. Our model can be also seen as a restriction of the quantum PAC\nlearning model: here, the learner does not have direct access to quantum\nexamples, but can only obtain estimates of measurement statistics on them.\nTheoretically, this model provides a simple yet expressive setting to explore\nthe power of quantum examples in machine learning. From a practical\nperspective, since simpler operations are required, learning algorithms in the\nQSQ model are more feasible for implementation on near-term quantum devices. We\nprove a number of results about the QSQ learning model. We first show that\nparity functions, (log n)-juntas and polynomial-sized DNF formulas are\nefficiently learnable in the QSQ model, in contrast to the classical setting\nwhere these problems are provably hard. This implies that many of the\nadvantages of quantum PAC learning can be realized even in the more restricted\nquantum SQ learning model. It is well-known that weak statistical query\ndimension, denoted by WSQDIM(C), characterizes the complexity of learning a\nconcept class C in the classical SQ model. We show that log(WSQDIM(C)) is a\nlower bound on the complexity of QSQ learning, and furthermore it is tight for\ncertain concept classes C. Additionally, we show that this quantity provides\nstrong lower bounds for the small-bias quantum communication model under\nproduct distributions. Finally, we introduce the notion of private quantum PAC\nlearning, in which a quantum PAC learner is required to be differentially\nprivate. We show that learnability in the QSQ model implies learnability in the\nquantum private PAC model. Additionally, we show that in the private PAC\nlearning setting, the classical and quantum sample complexities are equal, up\nto constant factors.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:36:57 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 21:26:33 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Grilo", "Alex B.", ""], ["Yuen", "Henry", ""]]}, {"id": "2002.08311", "submitter": "Tom\\'a\\v{s} Masa\\v{r}\\'ik", "authors": "Jan Kratochv\\'il, Tom\\'a\\v{s} Masa\\v{r}\\'ik, Jana Novotn\\'a", "title": "U-Bubble Model for Mixed Unit Interval Graphs and its Applications: The\n  MaxCut Problem Revisited", "comments": "Accepted to Mathematical Foundations of Computer Science (MFCS 2020),\n  25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interval graphs, intersection graphs of segments on a real line (intervals),\nplay a key role in the study of algorithms and special structural properties.\nUnit interval graphs, their proper subclass, where each interval has a unit\nlength, has also been extensively studied. We study mixed unit interval\ngraphs---a generalization of unit interval graphs where each interval has still\na unit length, but intervals of more than one type (open, closed, semi-closed)\nare allowed. This small modification captures a much richer class of graphs. In\nparticular, mixed unit interval graphs are not claw-free, compared to unit\ninterval graphs.\n  Heggernes, Meister, and Papadopoulos defined a representation of unit\ninterval graphs called the bubble model which turned out to be useful in\nalgorithm design. We extend this model to the class of mixed unit interval\ngraphs and demonstrate the advantages of this generalized model by providing a\nsubexponential-time algorithm for solving the MaxCut problem on mixed unit\ninterval graphs. In addition, we derive a polynomial-time algorithm for certain\nsubclasses of mixed unit interval graphs. We point out a substantial mistake in\nthe proof of the polynomiality of the MaxCut problem on unit interval graphs by\nBoyaci, Ekim, and Shalom (2017). Hence, the time complexity of this problem on\nunit interval graphs remains open. We further provide a better algorithmic\nupper-bound on the clique-width of mixed unit interval graphs. Clique-width is\none of the most general structural graph parameters, where a large group of\nnatural problems is still solvable in the tractable time when an efficient\nrepresentation is given. Unfortunately, the exact computation of the\nclique-width representation is \\NP-hard. Therefore, good upper-bounds on\nclique-width are highly appreciated, in particular, when such a bound is\nalgorithmic.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:47:45 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 23:29:00 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Kratochv\u00edl", "Jan", ""], ["Masa\u0159\u00edk", "Tom\u00e1\u0161", ""], ["Novotn\u00e1", "Jana", ""]]}, {"id": "2002.08389", "submitter": "Shuchen Zhu", "authors": "Nikhil S. Mande, Justin Thaler and Shuchen Zhu", "title": "Improved Approximate Degree Bounds For k-distinctness", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.TQC.2020.2", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open problem that is widely regarded as one of the most important in\nquantum query complexity is to resolve the quantum query complexity of the\nk-distinctness function on inputs of size N. While the case of k=2 (also called\nElement Distinctness) is well-understood, there is a polynomial gap between the\nknown upper and lower bounds for all constants k>2. Specifically, the best\nknown upper bound is O(N^{(3/4)-1/(2^{k+2}-4)}) (Belovs, FOCS 2012), while the\nbest known lower bound for k >= 2 is Omega(N^{2/3} + N^{(3/4)-1/(2k)})\n(Aaronson and Shi, J.~ACM 2004; Bun, Kothari, and Thaler, STOC 2018).\n  For any constant k >= 4, we improve the lower bound to\nOmega(N^{(3/4)-1/(4k)}). This yields, for example, the first proof that\n4-distinctness is strictly harder than Element Distinctness. Our lower bound\napplies more generally to approximate degree.\n  As a secondary result, we give a simple construction of an approximating\npolynomial of degree O(N^{3/4}) that applies whenever k <= polylog(N).\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:04:44 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mande", "Nikhil S.", ""], ["Thaler", "Justin", ""], ["Zhu", "Shuchen", ""]]}, {"id": "2002.08533", "submitter": "Sajin Koroth Mr.", "authors": "Valentine Kabanets, Sajin Koroth, Zhenjian Lu, Dimitrios Myrisiotis,\n  Igor Oliveira", "title": "Algorithms and Lower Bounds for de Morgan Formulas of Low-Communication\n  Leaf Gates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class $FORMULA[s] \\circ \\mathcal{G}$ consists of Boolean functions\ncomputable by size-$s$ de Morgan formulas whose leaves are any Boolean\nfunctions from a class $\\mathcal{G}$. We give lower bounds and (SAT, Learning,\nand PRG) algorithms for $FORMULA[n^{1.99}]\\circ \\mathcal{G}$, for classes\n$\\mathcal{G}$ of functions with low communication complexity. Let\n$R^{(k)}(\\mathcal{G})$ be the maximum $k$-party NOF randomized communication\ncomplexity of $\\mathcal{G}$. We show:\n  (1) The Generalized Inner Product function $GIP^k_n$ cannot be computed in\n$FORMULA[s]\\circ \\mathcal{G}$ on more than $1/2+\\varepsilon$ fraction of inputs\nfor $$ s = o \\! \\left ( \\frac{n^2}{ \\left(k \\cdot 4^k \\cdot\n{R}^{(k)}(\\mathcal{G}) \\cdot \\log (n/\\varepsilon) \\cdot \\log(1/\\varepsilon)\n\\right)^{2}} \\right).$$ As a corollary, we get an average-case lower bound for\n$GIP^k_n$ against $FORMULA[n^{1.99}]\\circ PTF^{k-1}$.\n  (2) There is a PRG of seed length $n/2 + O\\left(\\sqrt{s} \\cdot\nR^{(2)}(\\mathcal{G}) \\cdot\\log(s/\\varepsilon) \\cdot \\log (1/\\varepsilon)\n\\right)$ that $\\varepsilon$-fools $FORMULA[s] \\circ \\mathcal{G}$. For\n$FORMULA[s] \\circ LTF$, we get the better seed length $O\\left(n^{1/2}\\cdot\ns^{1/4}\\cdot \\log(n)\\cdot \\log(n/\\varepsilon)\\right)$. This gives the first\nnon-trivial PRG (with seed length $o(n)$) for intersections of $n$ half-spaces\nin the regime where $\\varepsilon \\leq 1/n$.\n  (3) There is a randomized $2^{n-t}$-time $\\#$SAT algorithm for $FORMULA[s]\n\\circ \\mathcal{G}$, where $$t=\\Omega\\left(\\frac{n}{\\sqrt{s}\\cdot\\log^2(s)\\cdot\nR^{(2)}(\\mathcal{G})}\\right)^{1/2}.$$ In particular, this implies a nontrivial\n#SAT algorithm for $FORMULA[n^{1.99}]\\circ LTF$.\n  (4) The Minimum Circuit Size Problem is not in $FORMULA[n^{1.99}]\\circ XOR$.\nOn the algorithmic side, we show that $FORMULA[n^{1.99}] \\circ XOR$ can be\nPAC-learned in time $2^{O(n/\\log n)}$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:11:52 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kabanets", "Valentine", ""], ["Koroth", "Sajin", ""], ["Lu", "Zhenjian", ""], ["Myrisiotis", "Dimitrios", ""], ["Oliveira", "Igor", ""]]}, {"id": "2002.08580", "submitter": "Ishay Haviv", "authors": "Alexander Golovnev and Ishay Haviv", "title": "The (Generalized) Orthogonality Dimension of (Generalized) Kneser\n  Graphs: Bounds and Applications", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The orthogonality dimension of a graph $G=(V,E)$ over a field $\\mathbb{F}$ is\nthe smallest integer $t$ for which there exists an assignment of a vector $u_v\n\\in \\mathbb{F}^t$ with $\\langle u_v,u_v \\rangle \\neq 0$ to every vertex $v \\in\nV$, such that $\\langle u_v, u_{v'} \\rangle = 0$ whenever $v$ and $v'$ are\nadjacent vertices in $G$. The study of the orthogonality dimension of graphs is\nmotivated by various applications in information theory and in theoretical\ncomputer science. The contribution of the present work is two-fold.\n  First, we prove that there exists a constant $c$ such that for every\nsufficiently large integer $t$, it is $\\mathsf{NP}$-hard to decide whether the\northogonality dimension of an input graph over $\\mathbb{R}$ is at most $t$ or\nat least $3t/2-c$. At the heart of the proof lies a geometric result, which\nmight be of independent interest, on a generalization of the orthogonality\ndimension parameter for the family of Kneser graphs, analogously to a\nlong-standing conjecture of Stahl (J. Comb. Theo. Ser. B, 1976).\n  Second, we study the smallest possible orthogonality dimension over finite\nfields of the complement of graphs that do not contain certain fixed subgraphs.\nIn particular, we provide an explicit construction of triangle-free $n$-vertex\ngraphs whose complement has orthogonality dimension over the binary field at\nmost $n^{1-\\delta}$ for some constant $\\delta >0$. Our results involve\nconstructions from the family of generalized Kneser graphs and they are\nmotivated by the rigidity approach to circuit lower bounds. We use them to\nanswer a couple of questions raised by Codenotti, Pudl\\'{a}k, and Resta (Theor.\nComput. Sci., 2000), and in particular, to disprove their Odd Alternating Cycle\nConjecture over every finite field.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 06:16:15 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 06:35:47 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Golovnev", "Alexander", ""], ["Haviv", "Ishay", ""]]}, {"id": "2002.08626", "submitter": "Jacek Krzaczkowski", "authors": "Pawe{\\l} M. Idziak, Piotr Kawa{\\l}ek, Jacek Krzaczkowski", "title": "Intermediate problems in modular circuits satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In arXiv:1710.08163 a generalization of Boolean circuits to arbitrary finite\nalgebras had been introduced and applied to sketch P versus NP-complete\nborderline for circuits satisfiability over algebras from congruence modular\nvarieties. However the problem for nilpotent (which had not been shown to be\nNP-hard) but not supernilpotent algebras (which had been shown to be polynomial\ntime) remained open.\n  In this paper we provide a broad class of examples, lying in this grey area,\nand show that, under the Exponential Time Hypothesis and Strong Exponential\nSize Hypothesis (saying that Boolean circuits need exponentially many modular\ncounting gates to produce boolean conjunctions of any arity), satisfiability\nover these algebras have intermediate complexity between $\\Omega(2^{c\\log^{h-1}\nn})$ and $O(2^{c\\log^h n})$, where $h$ measures how much a nilpotent algebra\nfails to be supernilpotent. We also sketch how these examples could be used as\nparadigms to fill the nilpotent versus supernilpotent gap in general.\n  Our examples are striking in view of the natural strong connections between\ncircuits satisfiability and Constraint Satisfaction Problem for which the\ndichotomy had been shown by Bulatov and Zhuk.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:04:16 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 17:05:53 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Idziak", "Pawe\u0142 M.", ""], ["Kawa\u0142ek", "Piotr", ""], ["Krzaczkowski", "Jacek", ""]]}, {"id": "2002.08634", "submitter": "Jacek Krzaczkowski", "authors": "Piotr Kawa{\\l}ek, Jacek Krzaczkowski", "title": "Even faster algorithms for CSAT over~supernilpotent algebras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper two algorithms solving circuit satisfiability problem over\nsupernilpotent algebras are presented. The first one is deterministic and is\nfaster than fastest previous algorithm presented by Aichinger. The second one\nis probabilistic with linear time complexity. Application of the former\nalgorithm to finite groups provides time complexity that is usually lower than\nin previously best (given by F\\\"oldv\\'ari) and application of the latter leads\nto corollary, that circuit satisfiability problem for group G is either\ntractable in probabilistic linear time if G is nilpotent or is NP-complete if G\nfails to be nilpotent. The results are obtained, by translating equations\nbetween polynomials over supernilpotent algebras to bounded degree polynomial\nequations over finite fields.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:27:39 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kawa\u0142ek", "Piotr", ""], ["Krzaczkowski", "Jacek", ""]]}, {"id": "2002.08730", "submitter": "Ville Salo", "authors": "Ville Salo", "title": "Cutting Corners", "comments": "50 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.CC cs.DM math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study a class of subshifts of finite type (SFTs) defined by a\nfamily of allowed patterns of the same shape where, for any contents of the\nshape minus a corner, the number of ways to fill in the corner is the same. The\nmain results are that for such an SFT, a locally legal pattern of convex shape\nis globally legal, and there is a measure that samples uniformly on all convex\nsets. Under suitable computability assumptions, this measure can be sampled,\nand legal configurations counted and enumerated, effectively and efficiently.\nWe show by example that these subshifts need not admit a group (more generally\nunital magma or quasigroup) structure by shift-commuting continuous operations.\nOur approach to convexity is axiomatic, and only requires an abstract convex\ngeometry that is \"midpointed with respect to the shape\". We construct such\nconvex geometries on several groups, in particular all strongly polycyclic\ngroups and free groups. We also show some other methods for sampling finite\npatterns, one based on orderings and one based on contructing new \"independent\nsets\" from old. We also show a link to conjectures of Gottshalk and Kaplansky.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:53:00 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:05:33 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Salo", "Ville", ""]]}, {"id": "2002.08944", "submitter": "Yassine Hamoudi", "authors": "Yassine Hamoudi and Fr\\'ed\\'eric Magniez", "title": "Quantum Time-Space Tradeoff for Finding Multiple Collision Pairs", "comments": "21 pages; v3: title and presentation changed. Previous title:\n  \"Quantum Time-Space Tradeoffs by Recording Queries\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding $K$ collision pairs in a random function $f :\n[N] \\rightarrow [N]$ by using a quantum computer. We prove that the number of\nqueries to the function in the quantum random oracle model must increase\nsignificantly when the size of the available memory is limited. Namely, we\ndemonstrate that any algorithm using $S$ qubits of memory must perform a number\n$T$ of queries that satisfies the tradeoff $T^3 S \\geq \\Omega(K^3 N)$.\nClassically, the same question has only been settled recently by Dinur\n[Eurocrypt'20], who showed that the Parallel Collision Search algorithm of van\nOorschot and Wiener achieves the optimal time-space tradeoff of $T^2 S =\n\\Theta(K^2 N)$. Our result limits the extent to which quantum computing may\ndecrease this tradeoff. We further show that any improvement to our lower bound\nwould imply a breakthrough for a related question about the Element\nDistinctness problem. Our method is based on a novel application of Zhandry's\nrecording query technique [Crypto'19] for proving lower bounds in the\nexponentially small success probability regime.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:48:51 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 17:37:10 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 10:49:29 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Hamoudi", "Yassine", ""], ["Magniez", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2002.08992", "submitter": "Lu\\'is Felipe Ign\\'acio Cunha Cunha", "authors": "Alexandre Abreu, Lu\\'is Cunha, Celina de Figueiredo, Franklin\n  Marquezino, Daniel Posner, Renato Portugal", "title": "Total tessellation cover and quantum walk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the total staggered quantum walk model and the total tessellation\ncover of a graph. This model uses the concept of total tessellation cover to\ndescribe the motion of the walker who is allowed to hop both to vertices and\nedges of the graph, in contrast with previous models in which the walker hops\neither to vertices or edges. We establish bounds on $T_t(G)$, which is the\nsmallest number of tessellations required in a total tessellation cover of $G$.\nWe highlight two of these lower bounds $T_t(G) \\geq \\omega(G)$ and $T_t(G)\\geq\nis(G)+1$, where $\\omega(G)$ is the size of a maximum clique and $is(G)$ is the\nnumber of edges of a maximum induced star subgraph. Using these bounds, we\ndefine the good total tessellable graphs with either $T_t(G)=\\omega(G)$ or\n$T_t(G)=is(G)+1$. The $k$-total tessellability problem aims to decide whether a\ngiven graph $G$ has $T_t(G) \\leq k$. We show that $k$-total tessellability is\nin $\\mathcal{P}$ for good total tessellable graphs. We establish the\n$\\mathcal{NP}$-completeness of the following problems when restricted to the\nfollowing classes: ($is(G)+1$)-total tessellability for graphs with $\\omega(G)\n= 2$; $\\omega(G)$-total tessellability for graphs $G$ with $is(G)+1 = 3$;\n$k$-total tessellability for graphs $G$ with $\\max\\{\\omega(G), is(G)+1\\}$ far\nfrom $k$; and $4$-total tessellability for graphs $G$ with $\\omega(G) = is(G)+1\n= 4$. As a consequence, we establish hardness results for bipartite graphs,\nline graphs of triangle-free graphs, universal graphs, planar graphs, and\n$(2,1)$-chordal graphs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:53:35 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Abreu", "Alexandre", ""], ["Cunha", "Lu\u00eds", ""], ["de Figueiredo", "Celina", ""], ["Marquezino", "Franklin", ""], ["Posner", "Daniel", ""], ["Portugal", "Renato", ""]]}, {"id": "2002.09451", "submitter": "Jakub Rydval", "authors": "Manuel Bodirsky and Jakub Rydval", "title": "On the Descriptive Complexity of Temporal Constraint Satisfaction\n  Problems", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-domain constraint satisfaction problems are either solvable by\nDatalog, or not even expressible in fixed-point logic with counting. The border\nbetween the two regimes coincides with an important dichotomy in universal\nalgebra; in particular, the border can be described by a strong height-one\nMaltsev condition. For infinite-domain CSPs, the situation is more complicated\neven if the template structure of the CSP is model-theoretically tame. We prove\nthat there is no Maltsev condition that characterizes Datalog already for the\nCSPs of first-order reducts of (Q;<); such CSPs are called temporal CSPs and\nare of fundamental importance in infinite-domain constraint satisfaction. Our\nmain result is a complete classification of temporal CSPs that can be expressed\nin one of the following logical formalisms: Datalog, fixed-point logic (with or\nwithout counting), or fixed-point logic with the Boolean rank operator. The\nclassification shows that many of the equivalent conditions in the finite fail\nto capture expressibility in Datalog or fixed-point logic already for temporal\nCSPs.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:09:56 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 15:42:50 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 19:03:07 GMT"}, {"version": "v4", "created": "Thu, 25 Jun 2020 17:53:44 GMT"}, {"version": "v5", "created": "Mon, 12 Apr 2021 15:52:05 GMT"}, {"version": "v6", "created": "Thu, 6 May 2021 13:35:57 GMT"}, {"version": "v7", "created": "Fri, 2 Jul 2021 12:34:00 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Rydval", "Jakub", ""]]}, {"id": "2002.09472", "submitter": "Jeroen Zuiddam", "authors": "Swastik Kopparty, Guy Moshkovitz, Jeroen Zuiddam", "title": "Geometric rank of tensors and subrank of matrix multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by problems in algebraic complexity theory (e.g., matrix\nmultiplication) and extremal combinatorics (e.g., the cap set problem and the\nsunflower problem), we introduce the geometric rank as a new tool in the study\nof tensors and hypergraphs. We prove that the geometric rank is an upper bound\non the subrank of tensors and the independence number of hypergraphs. We prove\nthat the geometric rank is smaller than the slice rank of Tao, and relate\ngeometric rank to the analytic rank of Gowers and Wolf in an asymptotic\nfashion. As a first application, we use geometric rank to prove a tight upper\nbound on the (border) subrank of the matrix multiplication tensors, matching\nStrassen's well-known lower bound from 1987.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:56:13 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 17:37:20 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Kopparty", "Swastik", ""], ["Moshkovitz", "Guy", ""], ["Zuiddam", "Jeroen", ""]]}, {"id": "2002.09534", "submitter": "Eryk Kopczy\\'nski", "authors": "Eryk Kopczy\\'nski", "title": "Hyperbolic Minesweeper is in P", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, while Minesweeper is NP-complete, its hyperbolic variant is in\nP. Our proof does not rely on the rules of Minesweeper, but is valid for any\npuzzle based on satisfying local constraints on a graph embedded in the\nhyperbolic plane.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:05:04 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kopczy\u0144ski", "Eryk", ""]]}, {"id": "2002.09916", "submitter": "Rafael Melo", "authors": "Leopoldo E. C\\'ardenas-Barr\\'on, Rafael A. Melo, Marcio C. Santos", "title": "Extended formulation and valid inequalities for the multi-item inventory\n  lot-sizing problem with supplier selection", "comments": null, "journal-ref": null, "doi": "10.1016/j.cor.2021.105234", "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multi-item inventory lot-sizing problem with supplier\nselection. The problem consists of determining an optimal purchasing plan in\norder to satisfy dynamic deterministic demands for multiple items over a finite\nplanning horizon, considering that multiple suppliers are available to purchase\nfrom. As the complexity of the problem was an open question, we show that it is\nNP-hard. We propose a facility location extended formulation for the problem\nwhich can be preprocessed based on the cost structure and describe new valid\ninequalities in the original space of variables. Furthermore, we study the\nprojection of the extended formulation into the original space and show the\nconnection between the inequalities generated by this projection and the newly\nproposed inequalities. Additionally, we present a simple and easy to implement\nyet very effective MIP (mixed integer programming) heuristic using the extended\nformulation. Besides, we introduce two new benchmark sets of instances to\nassess the performance of the approaches under different cost structures.\nComputational results show that the preprocessing approach can significantly\nreduce the size of the formulation to be solved, allowing both an increase in\nthe number of instances solved to optimality within the time limit and a\nreduction on the average time to solve them. Moreover, the described\ninequalities can improve the performance of a standard formulation for nearly\nall instance groups. They can also be used to provide strong lower bounds for\ncertain large instances for which the preprocessed facility location\nformulation fails even to provide a linear relaxation bound due to memory\nlimitations. Furthermore, the proposed MIP heuristic outperforms the heuristics\navailable in the literature as it obtains solution values which at least match\nthose reported for all instance groups, strictly improving most of them.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 14:59:59 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 11:14:28 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["C\u00e1rdenas-Barr\u00f3n", "Leopoldo E.", ""], ["Melo", "Rafael A.", ""], ["Santos", "Marcio C.", ""]]}, {"id": "2002.10145", "submitter": "Armin Wei{\\ss}", "authors": "Armin Wei{\\ss}", "title": "Hardness of equations over finite solvable groups under the exponential\n  time hypothesis", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2020.102", "report-no": null, "categories": "cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goldmann and Russell (2002) initiated the study of the complexity of the\nequation satisfiability problem in finite groups by showing that it is in P for\nnilpotent groups while it is NP-complete for non-solvable groups. Since then,\nseveral results have appeared showing that the problem can be solved in\npolynomial time in certain solvable groups of Fitting length two. In this work,\nwe present the first lower bounds for the equation satisfiability problem in\nfinite solvable groups: under the assumption of the exponential time\nhypothesis, we show that it cannot be in P for any group of Fitting length at\nleast four and for certain groups of Fitting length three. Moreover, the same\nhardness result applies to the equation identity problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 10:26:34 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 15:45:23 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wei\u00df", "Armin", ""]]}, {"id": "2002.10304", "submitter": "Bruno Grenet", "authors": "Pascal Giorgi, Bruno Grenet, Daniel S. Roche", "title": "Fast In-place Algorithms for Polynomial Operations: Division,\n  Evaluation, Interpolation", "comments": null, "journal-ref": "Proc. ISSAC'20, pp 210-217, ACM, 2020", "doi": "10.1145/3373207.3404061", "report-no": null, "categories": "cs.SC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider space-saving versions of several important operations on\nunivariate polynomials, namely power series inversion and division, division\nwith remainder, multi-point evaluation, and interpolation. Now-classical\nresults show that such problems can be solved in (nearly) the same asymptotic\ntime as fast polynomial multiplication. However, these reductions, even when\napplied to an in-place variant of fast polynomial multiplication, yield\nalgorithms which require at least a linear amount of extra space for\nintermediate results. We demonstrate new in-place algorithms for the\naforementioned polynomial computations which require only constant extra space\nand achieve the same asymptotic running time as their out-of-place\ncounterparts. We also provide a precise complexity analysis so that all\nconstants are made explicit, parameterized by the space usage of the underlying\nmultiplication algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:27:58 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 16:08:18 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 13:04:27 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Giorgi", "Pascal", ""], ["Grenet", "Bruno", ""], ["Roche", "Daniel S.", ""]]}, {"id": "2002.10490", "submitter": "Seyed Sajjad Nezhadi", "authors": "Hamoon Mousavi, Seyed Sajjad Nezhadi, and Henry Yuen", "title": "On the complexity of zero gap MIP*", "comments": "Fixed typos and edited protocol to more smoothly follow from\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class $\\mathsf{MIP}^*$ is the set of languages decidable by multiprover\ninteractive proofs with quantum entangled provers. It was recently shown by Ji,\nNatarajan, Vidick, Wright and Yuen that $\\mathsf{MIP}^*$ is equal to\n$\\mathsf{RE}$, the set of recursively enumerable languages. In particular this\nshows that the complexity of approximating the quantum value of a non-local\ngame $G$ is equivalent to the complexity of the Halting problem.\n  In this paper we investigate the complexity of deciding whether the quantum\nvalue of a non-local game $G$ is exactly $1$. This problem corresponds to a\ncomplexity class that we call zero gap $\\mathsf{MIP}^*$, denoted by\n$\\mathsf{MIP}^*_0$, where there is no promise gap between the verifier's\nacceptance probabilities in the YES and NO cases. We prove that\n$\\mathsf{MIP}^*_0$ extends beyond the first level of the arithmetical hierarchy\n(which includes $\\mathsf{RE}$ and its complement $\\mathsf{coRE}$), and in fact\nis equal to $\\Pi_2^0$, the class of languages that can be decided by quantified\nformulas of the form $\\forall y \\, \\exists z \\, R(x,y,z)$.\n  Combined with the previously known result that $\\mathsf{MIP}^{co}_0$ (the\ncommuting operator variant of $\\mathsf{MIP}^*_0$) is equal to $\\mathsf{coRE}$,\nour result further highlights the fascinating connection between various models\nof quantum multiprover interactive proofs and different classes in\ncomputability theory.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:11:01 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 00:08:38 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Mousavi", "Hamoon", ""], ["Nezhadi", "Seyed Sajjad", ""], ["Yuen", "Henry", ""]]}, {"id": "2002.10553", "submitter": "Tolga Ergen", "authors": "Mert Pilanci, Tolga Ergen", "title": "Neural Networks are Convex Regularizers: Exact Polynomial-time Convex\n  Optimization Formulations for Two-layer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop exact representations of training two-layer neural networks with\nrectified linear units (ReLUs) in terms of a single convex program with number\nof variables polynomial in the number of training samples and the number of\nhidden neurons. Our theory utilizes semi-infinite duality and minimum norm\nregularization. We show that ReLU networks trained with standard weight decay\nare equivalent to block $\\ell_1$ penalized convex models. Moreover, we show\nthat certain standard convolutional linear networks are equivalent\nsemi-definite programs which can be simplified to $\\ell_1$ regularized linear\nmodels in a polynomial sized discrete Fourier feature space.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:32:41 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 05:26:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Pilanci", "Mert", ""], ["Ergen", "Tolga", ""]]}, {"id": "2002.10654", "submitter": "Mika G\\\"o\\\"os", "authors": "Andrew Bassilakis, Andrew Drucker, Mika G\\\"o\\\"os, Lunjia Hu, Weiyun\n  Ma, Li-Yang Tan", "title": "The Power of Many Samples in Query Complexity", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The randomized query complexity $R(f)$ of a boolean function\n$f\\colon\\{0,1\\}^n\\to\\{0,1\\}$ is famously characterized (via Yao's minimax) by\nthe least number of queries needed to distinguish a distribution $D_0$ over\n$0$-inputs from a distribution $D_1$ over $1$-inputs, maximized over all pairs\n$(D_0,D_1)$. We ask: Does this task become easier if we allow query access to\ninfinitely many samples from either $D_0$ or $D_1$? We show the answer is no:\nThere exists a hard pair $(D_0,D_1)$ such that distinguishing $D_0^\\infty$ from\n$D_1^\\infty$ requires $\\Theta(R(f))$ many queries. As an application, we show\nthat for any composed function $f\\circ g$ we have $R(f\\circ g) \\geq\n\\Omega(\\mathrm{fbs}(f)R(g))$ where $\\mathrm{fbs}$ denotes fractional block\nsensitivity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:42:24 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Bassilakis", "Andrew", ""], ["Drucker", "Andrew", ""], ["G\u00f6\u00f6s", "Mika", ""], ["Hu", "Lunjia", ""], ["Ma", "Weiyun", ""], ["Tan", "Li-Yang", ""]]}, {"id": "2002.10802", "submitter": "Shalev Ben-David", "authors": "Shalev Ben-David, Eric Blais", "title": "A New Minimax Theorem for Randomized Algorithms", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated minimax principle of Yao (1977) says that for any\nBoolean-valued function $f$ with finite domain, there is a distribution $\\mu$\nover the domain of $f$ such that computing $f$ to error $\\epsilon$ against\ninputs from $\\mu$ is just as hard as computing $f$ to error $\\epsilon$ on\nworst-case inputs. Notably, however, the distribution $\\mu$ depends on the\ntarget error level $\\epsilon$: the hard distribution which is tight for bounded\nerror might be trivial to solve to small bias, and the hard distribution which\nis tight for a small bias level might be far from tight for bounded error\nlevels.\n  In this work, we introduce a new type of minimax theorem which can provide a\nhard distribution $\\mu$ that works for all bias levels at once. We show that\nthis works for randomized query complexity, randomized communication\ncomplexity, some randomized circuit models, quantum query and communication\ncomplexities, approximate polynomial degree, and approximate logrank. We also\nprove an improved version of Impagliazzo's hardcore lemma.\n  Our proofs rely on two innovations over the classical approach of using Von\nNeumann's minimax theorem or linear programming duality. First, we use Sion's\nminimax theorem to prove a minimax theorem for ratios of bilinear functions\nrepresenting the cost and score of algorithms.\n  Second, we introduce a new way to analyze low-bias randomized algorithms by\nviewing them as \"forecasting algorithms\" evaluated by a proper scoring rule.\nThe expected score of the forecasting version of a randomized algorithm appears\nto be a more fine-grained way of analyzing the bias of the algorithm. We show\nthat such expected scores have many elegant mathematical properties: for\nexample, they can be amplified linearly instead of quadratically. We anticipate\nforecasting algorithms will find use in future work in which a fine-grained\nanalysis of small-bias algorithms is required.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 11:46:08 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 22:20:17 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Ben-David", "Shalev", ""], ["Blais", "Eric", ""]]}, {"id": "2002.10809", "submitter": "Shalev Ben-David", "authors": "Shalev Ben-David, Eric Blais", "title": "A Tight Composition Theorem for the Randomized Query Complexity of\n  Partial Functions", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove two new results about the randomized query complexity of composed\nfunctions. First, we show that the randomized composition conjecture is false:\nthere are families of partial Boolean functions $f$ and $g$ such that $R(f\\circ\ng)\\ll R(f) R(g)$. In fact, we show that the left hand side can be polynomially\nsmaller than the right hand side (though in our construction, both sides are\npolylogarithmic in the input size of $f$).\n  Second, we show that for all $f$ and $g$, $R(f\\circ\ng)=\\Omega(\\mathop{noisyR}(f)\\cdot R(g))$, where $\\mathop{noisyR}(f)$ is a\nmeasure describing the cost of computing $f$ on noisy oracle inputs. We show\nthat this composition theorem is the strongest possible of its type: for any\nmeasure $M(\\cdot)$ satisfying $R(f\\circ g)=\\Omega(M(f)R(g))$ for all $f$ and\n$g$, it must hold that $\\mathop{noisyR}(f)=\\Omega(M(f))$ for all $f$. We also\ngive a clean characterization of the measure $\\mathop{noisyR}(f)$: it satisfies\n$\\mathop{noisyR}(f)=\\Theta(R(f\\circ gapmaj_n)/R(gapmaj_n))$, where $n$ is the\ninput size of $f$ and $gapmaj_n$ is the $\\sqrt{n}$-gap majority function on $n$\nbits.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 11:58:14 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 09:52:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ben-David", "Shalev", ""], ["Blais", "Eric", ""]]}, {"id": "2002.10888", "submitter": "Thomas Seiller", "authors": "Luc Pellissier (LACL), Thomas Seiller (CNRS, LIPN)", "title": "Lower bounds for algebraic machines, semantically", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.06787", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new semantic method for proving lower bounds in\ncomputational complexity. We use it to prove that maxflow, a PTIME complete\nproblem, is not computable in polylogarithmic time on parallel random access\nmachines (PRAMs) working with integers, showing that NCZ \\neq PTIME, where NCZ\nis the complexity class defined by such machines, and PTIME is the standard\nclass of polynomial time computable problems (on, say, a Turing machine). On\ntop of showing this new separation result, we show our method captures previous\nlower bounds results from the literature: Steele and Yao's lower bounds for\nalgebraic decision trees, Ben-Or's lower bounds for algebraic computation\ntrees, Cucker's proof that NC is not equal to PTIME on the reals, and\nMulmuley's lower bounds for \"PRAMs without bit operations\".\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 10:48:00 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 08:21:20 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Pellissier", "Luc", "", "LACL"], ["Seiller", "Thomas", "", "CNRS, LIPN"]]}, {"id": "2002.10898", "submitter": "Tesshu Hanaka", "authors": "Hans L. Bodlaender, Tesshu Hanaka, Lars Jaffke, Hirotaka Ono, Yota\n  Otachi and Tom C. van der Zanden", "title": "Hedonic Seat Arrangement Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a variant of hedonic games, called \\textsc{Seat\nArrangement}. The model is defined by a bijection from agents with preferences\nto vertices in a graph. The utility of an agent depends on the neighbors\nassigned in the graph. More precisely, it is the sum over all neighbors of the\npreferences that the agent has towards the agent assigned to the neighbor. We\nfirst consider the price of stability and fairness for different classes of\npreferences. In particular, we show that there is an instance such that the\nprice of fairness ({\\sf PoF}) is unbounded in general. Moreover, we show an\nupper bound $\\tilde{d}(G)$ and an almost tight lower bound $\\tilde{d}(G)-1/4$\nof {\\sf PoF}, where $\\tilde{d}(G)$ is the average degree of an input graph.\nThen we investigate the computational complexity of problems to find certain\n``good'' seat arrangements, say \\textsc{Maximum Welfare Arrangement},\n\\textsc{Maximin Utility Arrangement}, \\textsc{Stable Arrangement}, and\n\\textsc{Envy-free Arrangement}. We give dichotomies of computational complexity\nof four \\textsc{Seat Arrangement} problems from the perspective of the maximum\norder of connected components in an input graph. For the parameterized\ncomplexity, \\textsc{Maximum Welfare Arrangement} can be solved in time\n$n^{O(\\gamma)}$, while it cannot be solved in time $f(\\gamma)^{o(\\gamma)}$\nunder ETH, where $\\gamma$ is the vertex cover number of an input graph.\nMoreover, we show that \\textsc{Maximin Utility Arrangement} and\n\\textsc{Envy-free Arrangement} are weakly NP-hard even on graphs of bounded\nvertex cover number. Finally, we prove that determining whether a stable\narrangement can be obtained from a given arrangement by $k$ swaps is W[1]-hard\nwhen parameterized by $k+\\gamma$, whereas it can be solved in time $n^{O(k)}$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 14:38:14 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Hanaka", "Tesshu", ""], ["Jaffke", "Lars", ""], ["Ono", "Hirotaka", ""], ["Otachi", "Yota", ""], ["van der Zanden", "Tom C.", ""]]}, {"id": "2002.11237", "submitter": "Jack Murtagh", "authors": "Dean Doron, Jack Murtagh, Salil Vadhan, David Zuckerman", "title": "Spectral Sparsification via Bounded-Independence Sampling", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a deterministic, nearly logarithmic-space algorithm for mild spectral\nsparsification of undirected graphs. Given a weighted, undirected graph $G$ on\n$n$ vertices described by a binary string of length $N$, an integer $k\\leq \\log\nn$, and an error parameter $\\epsilon > 0$, our algorithm runs in space\n$\\tilde{O}(k\\log (N\\cdot w_{\\mathrm{max}}/w_{\\mathrm{min}}))$ where\n$w_{\\mathrm{max}}$ and $w_{\\mathrm{min}}$ are the maximum and minimum edge\nweights in $G$, and produces a weighted graph $H$ with\n$\\tilde{O}(n^{1+2/k}/\\epsilon^2)$ edges that spectrally approximates $G$, in\nthe sense of Spielmen and Teng [ST04], up to an error of $\\epsilon$.\n  Our algorithm is based on a new bounded-independence analysis of Spielman and\nSrivastava's effective resistance based edge sampling algorithm [SS08] and uses\nresults from recent work on space-bounded Laplacian solvers [MRSV17]. In\nparticular, we demonstrate an inherent tradeoff (via upper and lower bounds)\nbetween the amount of (bounded) independence used in the edge sampling\nalgorithm, denoted by $k$ above, and the resulting sparsity that can be\nachieved.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 00:49:41 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 05:17:06 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Doron", "Dean", ""], ["Murtagh", "Jack", ""], ["Vadhan", "Salil", ""], ["Zuckerman", "David", ""]]}, {"id": "2002.11313", "submitter": "Stephane Breuils", "authors": "Stephane Breuils, Vincent Nozick, Akihiro Sugimoto", "title": "Computational Aspects of Geometric Algebra Products of Two Homogeneous\n  Multivectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on time and memory costs of products in geometric algebra have been\nlimited to cases where multivectors with multiple grades have only non-zero\nelements. This allows to design efficient algorithms for a generic purpose;\nhowever, it does not reflect the practical usage of geometric algebra. Indeed,\nin applications related to geometry, multivectors are likely to be full\nhomogeneous, having their non-zero elements over a single grade. In this paper,\nwe provide a complete computational study on geometric algebra products of two\nfull homogeneous multivectors, that is, the outer, inner, and geometric\nproducts of two full homogeneous multivectors. We show tight bounds on the\nnumber of the arithmetic operations required for these products. We also show\nthat algorithms exist that achieve this number of arithmetic operations.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 06:06:12 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Breuils", "Stephane", ""], ["Nozick", "Vincent", ""], ["Sugimoto", "Akihiro", ""]]}, {"id": "2002.11437", "submitter": "Alexandros Hollender", "authors": "Aris Filos-Ratsikas, Alexandros Hollender, Katerina Sotiraki, Manolis\n  Zampetakis", "title": "Consensus-Halving: Does It Ever Get Easier?", "comments": "41 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the $\\varepsilon$-Consensus-Halving problem, a fundamental problem in fair\ndivision, there are $n$ agents with valuations over the interval $[0,1]$, and\nthe goal is to divide the interval into pieces and assign a label \"$+$\" or\n\"$-$\" to each piece, such that every agent values the total amount of \"$+$\" and\nthe total amount of \"$-$\" almost equally. The problem was recently proven by\nFilos-Ratsikas and Goldberg [2019] to be the first \"natural\" complete problem\nfor the computational class PPA, answering a decade-old open question.\n  In this paper, we examine the extent to which the problem becomes easy to\nsolve, if one restricts the class of valuation functions. To this end, we\nprovide the following contributions. First, we obtain a strengthening of the\nPPA-hardness result of [Filos-Ratsikas and Goldberg, 2019], to the case when\nagents have piecewise uniform valuations with only two blocks. We obtain this\nresult via a new reduction, which is in fact conceptually much simpler than the\ncorresponding one in [Filos-Ratsikas and Goldberg, 2019]. Then, we consider the\ncase of single-block (uniform) valuations and provide a parameterized\npolynomial time algorithm for solving $\\varepsilon$-Consensus-Halving for any\n$\\varepsilon$, as well as a polynomial-time algorithm for $\\varepsilon=1/2$;\nthese are the first algorithmic results for the problem. Finally, an important\napplication of our new techniques is the first hardness result for a\ngeneralization of Consensus-Halving, the Consensus-$1/k$-Division problem. In\nparticular, we prove that $\\varepsilon$-Consensus-$1/3$-Division is PPAD-hard.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:43:56 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 16:24:58 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 22:43:26 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Filos-Ratsikas", "Aris", ""], ["Hollender", "Alexandros", ""], ["Sotiraki", "Katerina", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "2002.11594", "submitter": "Julian D\\\"orfler", "authors": "Markus Bl\\\"aser, Julian D\\\"orfler, Christian Ikenmeyer", "title": "On the complexity of evaluating highest weight vectors", "comments": "32 pages, full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric complexity theory (GCT) is an approach towards separating algebraic\ncomplexity classes through algebraic geometry and representation theory.\nOriginally Mulmuley and Sohoni proposed (SIAM J Comput 2001, 2008) to use\noccurrence obstructions to prove Valiant's determinant vs permanent conjecture,\nbut recently B\\\"urgisser, Ikenmeyer, and Panova (Journal of the AMS 2019)\nproved this impossible. However, fundamental theorems of algebraic geometry and\nrepresentation theory grant that every lower bound in GCT can be proved by the\nuse of so-called highest weight vectors (HWVs). In the setting of interest in\nGCT (namely in the setting of polynomials) we prove the NP-hardness of the\nevaluation of HWVs in general, and we give efficient algorithms if the\ntreewidth of the corresponding Young-diagram is small, where the point of\nevaluation is concisely encoded as a noncommutative algebraic branching\nprogram! In particular, this gives a large new class of separating functions\nthat can be efficiently evaluated at points with low (border) Waring rank.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:25:37 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 15:25:46 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Bl\u00e4ser", "Markus", ""], ["D\u00f6rfler", "Julian", ""], ["Ikenmeyer", "Christian", ""]]}, {"id": "2002.11679", "submitter": "Biaoshuai Tao", "authors": "Grant Schoenebeck, Biaoshuai Tao, Fang-Yi Yu", "title": "Limitations of Greed: Influence Maximization in Undirected Networks\n  Re-visited", "comments": "36 pages, 1 figure, accepted at AAMAS'20: International Conference on\n  Autonomous Agents and Multi-Agent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the influence maximization problem (selecting $k$ seeds in a\nnetwork maximizing the expected total influence) on undirected graphs under the\nlinear threshold model. On the one hand, we prove that the greedy algorithm\nalways achieves a $(1 - (1 - 1/k)^k + \\Omega(1/k^3))$-approximation, showing\nthat the greedy algorithm does slightly better on undirected graphs than the\ngeneric $(1- (1 - 1/k)^k)$ bound which also applies to directed graphs. On the\nother hand, we show that substantial improvement on this bound is impossible by\npresenting an example where the greedy algorithm can obtain at most a $(1- (1 -\n1/k)^k + O(1/k^{0.2}))$ approximation. This result stands in contrast to the\nprevious work on the independent cascade model. Like the linear threshold\nmodel, the greedy algorithm obtains a $(1-(1-1/k)^k)$-approximation on directed\ngraphs in the independent cascade model. However, Khanna and Lucier showed\nthat, in undirected graphs, the greedy algorithm performs substantially better:\na $(1-(1-1/k)^k + c)$ approximation for constant $c > 0$. Our results show\nthat, surprisingly, no such improvement occurs in the linear threshold model.\nFinally, we show that, under the linear threshold model, the approximation\nratio $(1 - (1 - 1/k)^k)$ is tight if 1) the graph is directed or 2) the\nvertices are weighted. In other words, under either of these two settings, the\ngreedy algorithm cannot achieve a $(1 - (1 - 1/k)^k + f(k))$-approximation for\nany positive function $f(k)$. The result in setting 2) is again in a sharp\ncontrast to Khanna and Lucier's $(1 - (1 - 1/k)^k + c)$-approximation result\nfor the independent cascade model, where the $(1 - (1 - 1/k)^k + c)$\napproximation guarantee can be extended to the setting where vertices are\nweighted. We also discuss extensions to more generalized settings including\nthose with edge-weighted graphs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:16:31 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Schoenebeck", "Grant", ""], ["Tao", "Biaoshuai", ""], ["Yu", "Fang-Yi", ""]]}, {"id": "2002.11795", "submitter": "Ashwin Nayak", "authors": "Frederic Magniez and Ashwin Nayak", "title": "Quantum Distributed Complexity of Set Disjointness on a Line", "comments": "21 pages, 2 figures. In v3, background on Theorem 3.5 (from prior\n  work) was included in an appendix. In v4, a detail in the statement of\n  Theorem 3.5 has been corrected, and corresponding changes have been made in\n  the rest of the paper. The results remain unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $x,y\\in\\{0,1\\}^n$, Set Disjointness consists in deciding whether\n$x_i=y_i=1$ for some index $i \\in [n]$. We study the problem of computing this\nfunction in a distributed computing scenario in which the inputs $x$ and $y$\nare given to the processors at the two extremities of a path of length $d$. Set\nDisjointness on a Line was introduced by Le Gall and Magniez (PODC 2018) for\nproving lower bounds on the quantum distributed complexity of computing the\ndiameter of an arbitrary network in the CONGEST model.\n  In this work, we prove an unconditional lower bound of\n$\\widetilde{\\Omega}(\\sqrt[3]{n d^2}+\\sqrt{n} )$ rounds for Set Disjointness on\na Line. This is the first non-trivial lower bound when there is no restriction\non the memory used by the processors. The result gives us a new lower bound of\n$\\widetilde{\\Omega} (\\sqrt[3]{n\\delta^2}+\\sqrt{n} )$ on the number of rounds\nrequired for computing the diameter $\\delta$ of any $n$-node network with\nquantum messages of size $O(\\log n)$ in the CONGEST model.\n  We draw a connection between the distributed computing scenario above and a\nnew model of query complexity. In this model, an algorithm computing a\nbi-variate function $f$ has access to the inputs $x$ and $y$ through two\nseparate oracles $O_x$ and $O_y$, respectively. The restriction is that the\nalgorithm is required to alternately make $d$ queries to $O_x$ and $d$ queries\nto $O_y$. The technique we use for deriving the round lower bound for Set\nDisjointness on a Line also applies to the number of rounds in this query\nmodel. We provide an algorithm for Set Disjointness in this query model with\nround complexity that matches the round lower bound stated above, up to a\npolylogarithmic factor. In this sense, the round lower bound we show for Set\nDisjointness on a Line is optimal.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:17:53 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 08:27:13 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 19:06:40 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 03:10:01 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Magniez", "Frederic", ""], ["Nayak", "Ashwin", ""]]}, {"id": "2002.11830", "submitter": "Nicolas Dupin", "authors": "Nicolas Dupin", "title": "Polynomial algorithms for p-dispersion problems in a 2d Pareto Front", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Having many best compromise solutions for bi-objective optimization problems,\nthis paper studies p-dispersion problems to select $p\\geqslant 2$\nrepresentative points in the Pareto Front(PF). Four standard variants of\np-dispersion are considered. A novel variant, denoted Max-Sum-Neighbor\np-dispersion, is introduced for the specific case of a 2d PF. Firstly, it is\nproven that $2$-dispersion and $3$-dispersion problems are solvable in $O(n)$\ntime in a 2d PF. Secondly, dynamic programming algorithms are designed for\nthree p-dispersion variants, proving polynomial complexities in a 2d PF. The\nMax-Min p-dispersion problem is proven solvable in $O(pn\\log n)$ time and\n$O(n)$ memory space. The Max-Sum-Min p-dispersion problem is proven solvable in\n$O(pn^3)$ time and $O(pn^2)$ space. The Max-Sum-Neighbor p-dispersion problem\nis proven solvable in $O(pn^2)$ time and $O(pn)$ space. Complexity results and\nparallelization issues are discussed in regards to practical implementation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:52:58 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Dupin", "Nicolas", ""]]}, {"id": "2002.11880", "submitter": "Soheil Behnezhad", "authors": "Soheil Behnezhad, Mahsa Derakhshan, MohammadTaghi Hajiaghayi", "title": "Stochastic Matching with Few Queries: $(1-\\varepsilon)$ Approximation", "comments": "A version of this paper is to appear at STOC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we are given an arbitrary graph $G=(V, E)$ and know that each\nedge in $E$ is going to be realized independently with some probability $p$.\nThe goal in the stochastic matching problem is to pick a sparse subgraph $Q$ of\n$G$ such that the realized edges in $Q$, in expectation, include a matching\nthat is approximately as large as the maximum matching among the realized edges\nof $G$. The maximum degree of $Q$ can depend on $p$, but not on the size of\n$G$.\n  This problem has been subject to extensive studies over the years and the\napproximation factor has been improved from $0.5$ to $0.5001$ to $0.6568$ and\neventually to $2/3$. In this work, we analyze a natural sampling-based\nalgorithm and show that it can obtain all the way up to $(1-\\epsilon)$\napproximation, for any constant $\\epsilon > 0$.\n  A key and of possible independent interest component of our analysis is an\nalgorithm that constructs a matching on a stochastic graph, which among some\nother important properties, guarantees that each vertex is matched\nindependently from the vertices that are sufficiently far. This allows us to\nbypass a previously known barrier towards achieving $(1-\\epsilon)$\napproximation based on existence of dense Ruzsa-Szemer\\'edi graphs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:33:03 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Behnezhad", "Soheil", ""], ["Derakhshan", "Mahsa", ""], ["Hajiaghayi", "MohammadTaghi", ""]]}, {"id": "2002.12119", "submitter": "Rahul Savani", "authors": "Argyrios Deligkas and John Fearnley and Rahul Savani", "title": "Tree Polymatrix Games are PPAD-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that it is PPAD-hard to compute a Nash equilibrium in a tree\npolymatrix game with twenty actions per player. This is the first PPAD hardness\nresult for a game with a constant number of actions per player where the\ninteraction graph is acyclic. Along the way we show PPAD-hardness for finding\nan $\\epsilon$-fixed point of a 2D LinearFIXP instance, when $\\epsilon$ is any\nconstant less than $(\\sqrt{2} - 1)/2 \\approx 0.2071$. This lifts the hardness\nregime from polynomially small approximations in $k$-dimensions to constant\napproximations in two-dimensions, and our constant is substantial when compared\nto the trivial upper bound of $0.5$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 14:34:59 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Deligkas", "Argyrios", ""], ["Fearnley", "John", ""], ["Savani", "Rahul", ""]]}, {"id": "2002.12771", "submitter": "Sergey Dovgal", "authors": "Maciej Bendkowski, Olivier Bodini, Sergey Dovgal", "title": "Tuning as convex optimisation: a polynomial tuner for multi-parametric\n  combinatorial samplers", "comments": "44 pages, an extended version of the paper \"Polynomial tuning of\n  multiparametric combinatorial samplers\" presented at ANALCO'18. arXiv admin\n  note: text overlap with arXiv:1708.01212", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial samplers are algorithmic schemes devised for the approximate-\nand exact-size generation of large random combinatorial structures, such as\ncontext-free words, various tree-like data structures, maps, tilings, or even\nRNA sequences. In their multi-parametric variants, combinatorial samplers are\nadapted to combinatorial specifications with additional parameters, allowing\nfor a more flexible control over the output profile of parametrised\ncombinatorial patterns. One can control, for instance, the number of leaves,\nprofile of node degrees in trees or the number of certain sub-patterns in\ngenerated strings. However, such a flexible control requires an additional and\nnontrivial tuning procedure.\n  Using techniques of convex optimisation, we present an efficient polynomial\ntuning algorithm for multi-parametric combinatorial specifications. For a given\ncombinatorial system of description length $L$ with $d$ tuning parameters and\ntarget size parameter value $n$, our algorithm runs in time $O(d^{3.5} L \\log\nn)$. We demonstrate the effectiveness of our method on a series of practical\nexamples, including rational, algebraic, and so-called P\\'olya specifications.\nWe show how our method can be adapted to a broad range of less typical\ncombinatorial constructions, including symmetric polynomials, labelled sets and\ncycles with cardinality lower bounds, simple increasing trees or substitutions.\nFinally, we discuss some practical aspects of our prototype tuner\nimplementation and provide its benchmark results.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 19:53:33 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Bendkowski", "Maciej", ""], ["Bodini", "Olivier", ""], ["Dovgal", "Sergey", ""]]}, {"id": "2002.12814", "submitter": "Alexandru Gheorghiu", "authors": "Alexandru Gheorghiu, Matty J. Hoban", "title": "Estimating the entropy of shallow circuit outputs is hard", "comments": "31 pages, 3 figures. Comments welcome. arXiv admin note: text overlap\n  with arXiv:1804.01082 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The decision problem version of estimating the Shannon entropy is the Entropy\nDifference problem (ED): given descriptions of two circuits, determine which\ncircuit produces more entropy in its output when acting on a uniformly random\ninput. The analogous problem with quantum circuits (QED) is to determine which\ncircuit produces the state with greater von Neumann entropy, when acting on a\nfixed input state and after tracing out part of the output. Based on plausible\ncomplexity-theoretic assumptions, both of these problems are believed to be\nintractable for polynomial-time quantum computation. In this paper, we\ninvestigate the hardness of these problems in the case where the input circuits\nhave logarithmic and constant depth, respectively. We show that, relative to an\noracle, these problems cannot be as hard as their counterparts with\npolynomial-size circuits. Furthermore, we show that if a certain type of\nreduction from QED to the log-depth version exists, it implies that any\npolynomial-time quantum computation can be performed in log depth. While this\nsuggests that having shallow circuits makes entropy estimation easier, we give\nindication that the problem remains intractable for polynomial-time quantum\ncomputation by proving a reduction from Learning-With-Errors (LWE) to\nconstant-depth ED. We then consider a potential application of our results to\nquantum gravity research. First, we introduce a Hamiltonian version of QED\nwhere one is given two local Hamiltonians and asked to estimate the\nentanglement entropy difference in their ground states. We show that this\nproblem is at least as hard as the circuit version and then discuss a potential\nexperiment that would make use of the AdS/CFT correspondence to solve LWE\nefficiently. We conjecture that unless the AdS/CFT bulk to boundary map is\nexponentially complex, this experiment would violate the intractability\nassumption of LWE.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 15:32:08 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Gheorghiu", "Alexandru", ""], ["Hoban", "Matty J.", ""]]}, {"id": "2002.12856", "submitter": "Anay Mehrotra", "authors": "Anay Mehrotra and Vibhor Porwal and Raghunath Tewari", "title": "Two Player Hidden Pointer Chasing and Multi-Pass Lower Bounds in\n  Turnstile Streams", "comments": "The authors have withdrawn this paper due to an error in the proof of\n  Lemma 3.4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The authors have withdrawn this paper due to an error in the proof of Lemma\n3.4.\n  --------------------------------------------------------------------------------------------\n  The authors have withdrawn this paper due to an error in the proof of Lemma\n3.4z(Assadi, Chen, and Khanna, 2019) define a 4-player hidden-pointer-chasing\n($\\mathsf{HPC}^4$), and using it, give strong multi-pass lower bounds for graph\nproblems in the streaming model of computation and a lower bound on the query\ncomplexity of sub-modular minimization. We present a two-player version\n($\\mathsf{HPC}^2$) of $\\mathsf{HPC}^4$ that has matching communication\ncomplexity to $\\mathsf{HPC}^4$. Our formulation allows us to lower bound its\ncommunication complexity with a simple direct-sum argument. Using this lower\nbound on the communication complexity of $\\mathsf{HPC}^2$, we retain the\nstreaming and query complexity lower bounds by (Assadi, Chen, and Khanna,\n2019).\n  Further, by giving reductions from $\\mathsf{HPC}^2$, we prove new multi-pass\nspace lower bounds for graph problems in turnstile streams. In particular, we\nshow that any algorithm which computes the exact weight of the maximum weighted\nmatching in an $n$-vertex graph requires $\\tilde{O}(n^{2})$ space unless it\nmakes $\\omega(\\log n)$ passes over the turnstile stream, and that any algorithm\nwhich computes the minimum $s\\text{-}t$ distance in an $n$-vertex graph\nrequires $n^{2-o(1)}$ space unless it makes $n^{\\Omega(1)}$ passes over the\nturnstile stream. Our reductions can be modified to use $\\mathsf{HPC}^4$ as\nwell.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 16:33:45 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 11:05:56 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Mehrotra", "Anay", ""], ["Porwal", "Vibhor", ""], ["Tewari", "Raghunath", ""]]}]