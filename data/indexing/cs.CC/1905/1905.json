[{"id": "1905.00091", "submitter": "Ramprasad Saptharishi", "authors": "Zeyu Guo, Mrinal Kumar, Ramprasad Saptharishi, Noam Solomon", "title": "Derandomization from Algebraic Hardness", "comments": "Incorporated some reviewer comments, extension of the main theorems\n  to HSGs from k-variate polynomials for small-enough k, connection to the\n  tau-conjecture of Shub-Smale", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hitting-set generator (HSG) is a polynomial map $G:\\mathbb{F}^k \\to\n\\mathbb{F}^n$ such that for all $n$-variate polynomials $C$ of small enough\ncircuit size and degree, if $C$ is nonzero, then $C\\circ G$ is nonzero. In this\npaper, we give a new construction of such an HSG assuming that we have an\nexplicit polynomial of sufficient hardness. Formally, we prove the following\nover any field of characteristic zero:\n  Let $k\\in \\mathbb{N}$ and $\\delta > 0$ be arbitrary constants. Suppose\n$\\{P_d\\}_{d\\in \\mathbb{N}}$ is an explicit family of $k$-variate polynomials\nsuch that $\\operatorname{deg} P_d = d$ and $P_d$ requires algebraic circuits of\nsize $d^\\delta$. Then, there are explicit hitting sets of polynomial size for\n$\\mathsf{VP}$.\n  This is the first HSG in the algebraic setting that yields a complete\nderandomization of polynomial identity testing (PIT) for general circuits from\na suitable algebraic hardness assumption. As a direct consequence, we show that\neven saving a single point from the \"trivial\" explicit, exponential sized\nhitting sets for constant-variate polynomials of low individual degree which\nare computable by small circuits, implies a deterministic polynomial time\nalgorithm for PIT. More precisely, we show the following:\n  Let $k\\in \\mathbb{N}$ and $\\delta > 0$ be arbitrary constants. Suppose for\nevery $s$ large enough, there is an explicit hitting set of size at most\n$((s+1)^k - 1)$ for the class of $k$-variate polynomials of individual degree\n$s$ that are computable by size $s^\\delta$ circuits. Then there is an explicit\nhitting set of size $\\operatorname{poly}(s)$ for the class of $s$-variate\npolynomials, of degree $s$, that are computable by size $s$ circuits.\n  As a consequence, we give a deterministic polynomial time construction of\nhitting sets for algebraic circuits, if a strengthening of the\n$\\tau$-Conjecture of Shub and Smale is true.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 20:12:13 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 19:29:51 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 06:12:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Guo", "Zeyu", ""], ["Kumar", "Mrinal", ""], ["Saptharishi", "Ramprasad", ""], ["Solomon", "Noam", ""]]}, {"id": "1905.00164", "submitter": "Marius Zimand", "authors": "Andrei Romashchenko and Marius Zimand", "title": "On a conditional inequality in Kolmogorov complexity and its\n  applications in communication complexity", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Romashchenko and Zimand~\\cite{rom-zim:c:mutualinfo} have shown that if we\npartition the set of pairs $(x,y)$ of $n$-bit strings into combinatorial\nrectangles, then $I(x:y) \\geq I(x:y \\mid t(x,y)) - O(\\log n)$, where $I$\ndenotes mutual information in the Kolmogorov complexity sense, and $t(x,y)$ is\nthe rectangle containing $(x,y)$. We observe that this inequality can be\nextended to coverings with rectangles which may overlap. The new inequality\nessentially states that in case of a covering with combinatorial rectangles,\n  $I(x:y) \\geq I(x:y \\mid t(x,y)) - \\log \\rho - O(\\log n)$, where $t(x,y)$ is\nany rectangle containing $(x,y)$ and $\\rho$ is the thickness of the covering,\nwhich is the maximum number of rectangles that overlap. We discuss applications\nto communication complexity of protocols that are nondeterministic, or\nrandomized, or Arthur-Merlin, and also to the information complexity of\ninteractive protocols.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 02:25:32 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Romashchenko", "Andrei", ""], ["Zimand", "Marius", ""]]}, {"id": "1905.00305", "submitter": "Astrid Pieterse", "authors": "Hans L. Bodlaender, Sudeshna Kolay, and Astrid Pieterse", "title": "Parameterized Complexity of Conflict-free Graph Coloring", "comments": "Accepted to WADS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph G, a q-open neighborhood conflict-free coloring or\nq-ONCF-coloring is a vertex coloring $c:V(G) \\rightarrow \\{1,2,\\ldots,q\\}$ such\nthat for each vertex $v \\in V(G)$ there is a vertex in $N(v)$ that is uniquely\ncolored from the rest of the vertices in $N(v)$. When we replace $N(v)$ by the\nclosed neighborhood $N[v]$, then we call such a coloring a q-closed\nneighborhood conflict-free coloring or simply q-CNCF-coloring. In this paper,\nwe study the NP-hard decision questions of whether for a constant q an input\ngraph has a q-ONCF-coloring or a q-CNCF-coloring. We will study these two\nproblems in the parameterized setting.\n  First of all, we study running time bounds on FPT-algorithms for these\nproblems, when parameterized by treewidth. We improve the existing upper\nbounds, and also provide lower bounds on the running time under ETH and SETH.\n  Secondly, we study the kernelization complexity of both problems, using\nvertex cover as the parameter. We show that both $(q \\geq 2)$-ONCF-coloring and\n$(q \\geq 3)$-CNCF-coloring cannot have polynomial kernels when parameterized by\nthe size of a vertex cover unless $NP \\in coNP/poly$. However, we obtain a\npolynomial kernel for 2-CNCF-coloring parameterized by vertex cover.\n  We conclude with some combinatorial results. Denote $\\chi_{ON}(G)$ and\n$\\chi_{CN}(G)$ to be the minimum number of colors required to ONCF-color and\nCNCF-color G, respectively. Upper bounds on $\\chi_{CN}(G)$ with respect to\nstructural parameters like minimum vertex cover size, minimum feedback vertex\nset size and treewidth are known. To the best of our knowledge only an upper\nbound on $\\chi_{ON}(G)$ with respect to minimum vertex cover size was known. We\nprovide tight bounds for $\\chi_{ON}(G)$ with respect to minimum vertex cover\nsize. Also, we provide the first upper bounds on $\\chi_{ON}(G)$ with respect to\nminimum feedback vertex set size and treewidth.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:23:30 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Bodlaender", "Hans L.", ""], ["Kolay", "Sudeshna", ""], ["Pieterse", "Astrid", ""]]}, {"id": "1905.00444", "submitter": "Salvatore Mandr\\`a", "authors": "Benjamin Villalonga, Dmitry Lyakh, Sergio Boixo, Hartmut Neven, Travis\n  S. Humble, Rupak Biswas, Eleanor G. Rieffel, Alan Ho, Salvatore Mandr\\`a", "title": "Establishing the Quantum Supremacy Frontier with a 281 Pflop/s\n  Simulation", "comments": "The paper has been published in Quantum Science and Technology", "journal-ref": "Quantum Science and Technology 5, 3 (2020)", "doi": "10.1088/2058-9565/ab7eeb", "report-no": null, "categories": "quant-ph cs.CC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy Intermediate-Scale Quantum (NISQ) computers are entering an era in\nwhich they can perform computational tasks beyond the capabilities of the most\npowerful classical computers, thereby achieving \"Quantum Supremacy\", a major\nmilestone in quantum computing. NISQ Supremacy requires comparison with a\nstate-of-the-art classical simulator. We report HPC simulations of hard random\nquantum circuits (RQC), which have been recently used as a benchmark for the\nfirst experimental demonstration of Quantum Supremacy, sustaining an average\nperformance of 281 Pflop/s (true single precision) on Summit, currently the\nfastest supercomputer in the World. These simulations were carried out using\nqFlex, a tensor-network-based classical high-performance simulator of RQCs. Our\nresults show an advantage of many orders of magnitude in energy consumption of\nNISQ devices over classical supercomputers. In addition, we propose a standard\nbenchmark for NISQ computers based on qFlex.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 18:42:19 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 02:34:59 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Villalonga", "Benjamin", ""], ["Lyakh", "Dmitry", ""], ["Boixo", "Sergio", ""], ["Neven", "Hartmut", ""], ["Humble", "Travis S.", ""], ["Biswas", "Rupak", ""], ["Rieffel", "Eleanor G.", ""], ["Ho", "Alan", ""], ["Mandr\u00e0", "Salvatore", ""]]}, {"id": "1905.01822", "submitter": "Pradeesha Ashok", "authors": "Akanksha Agrawal, Pradeesha Ashok, Meghana M Reddy, Saket Saurabh,\n  Dolly Yadav", "title": "FPT Algorithms for Conflict-free Coloring of Graphs and Chromatic\n  Terrain Guarding", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present fixed parameter tractable algorithms for the conflict-free\ncoloring problem on graphs. Given a graph $G=(V,E)$, \\emph{conflict-free\ncoloring} of $G$ refers to coloring a subset of $V$ such that for every vertex\n$v$, there is a color that is assigned to exactly one vertex in the closed\nneighborhood of $v$. The \\emph{k-Conflict-free Coloring} problem is to decide\nwhether $G$ can be conflict-free colored using at most $k$ colors. This problem\nis NP-hard even for $k=1$ and therefore under standard complexity theoretic\nassumptions, FPT algorithms do not exist when parameterised by the solution\nsize. We consider the \\emph{k-Conflict-free Coloring} problem parameterised by\nthe treewidth of the graph and show that this problem is fixed parameter\ntractable. We also initiate the study of \\emph{Strong Conflict-free Coloring}\nof graphs. Given a graph $G=(V,E)$, \\emph{strong conflict-free coloring} of $G$\nrefers to coloring a subset of $V$ such that every vertex $v$ has at least one\ncolored vertex in its closed neighborhood and moreover all the colored vertices\nin $v$'s neighborhood have distinct colors. We show that this problem is in FPT\nwhen parameterised by both the treewidth and the solution size. We further\napply these algorithms to get efficient algorithms for a geometric problem\nnamely the Terrain Guarding problem, when parameterised by a structural\nparameter.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 04:29:28 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Agrawal", "Akanksha", ""], ["Ashok", "Pradeesha", ""], ["Reddy", "Meghana M", ""], ["Saurabh", "Saket", ""], ["Yadav", "Dolly", ""]]}, {"id": "1905.02110", "submitter": "Shima Bab Hadiashar", "authors": "Shima Bab Hadiashar and Ashwin Nayak", "title": "On the Entanglement Cost of One-Shot Compression", "comments": "23 pages, 1 figure. The paper is the same as v3; only metadata are\n  updated. In v3: Main body reorganized; Thm 1.1 rephrased; a discussion of the\n  entanglement measure added to Sec. 4; several improvements to the text\n  throughout; Cor. 3.5 and Cor. 3.6 merged; Appendix created for the proofs of\n  Cor. 3.5 and another statement in the main body; typos fixed; three\n  references added", "journal-ref": "Quantum 4, 286 (2020)", "doi": "10.22331/q-2020-06-25-286", "report-no": null, "categories": "quant-ph cs.CC cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the task of visible compression of an ensemble of quantum states\nwith entanglement assistance in the one-shot setting. The protocols achieving\nthe best compression use many more qubits of shared entanglement than the\nnumber of qubits in the states in the ensemble. Other compression protocols,\nwith potentially larger communication cost, have entanglement cost bounded by\nthe number of qubits in the given states. This motivates the question as to\nwhether entanglement is truly necessary for compression, and if so, how much of\nit is needed.\n  Motivated by questions in communication complexity, we lift certain\nrestrictions that are placed on compression protocols in tasks such as\nstate-splitting and channel simulation. We show that an ensemble of the form\ndesigned by Jain, Radhakrishnan, and Sen (ICALP'03) saturates the known bounds\non the sum of communication and entanglement costs, even with the relaxed\ncompression protocols we study.\n  The ensemble and the associated one-way communication protocol have several\nremarkable properties. The ensemble is incompressible by more than a constant\nnumber of qubits without shared entanglement, even when constant error is\nallowed. Moreover, in the presence of shared entanglement, the communication\ncost of compression can be arbitrarily smaller than the entanglement cost. The\nquantum information cost of the protocol can thus be arbitrarily smaller than\nthe cost of compression without shared entanglement. The ensemble can also be\nused to show the impossibility of reducing, via compression, the shared\nentanglement used in two-party protocols for computing Boolean functions.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 15:47:10 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 20:05:08 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 18:18:49 GMT"}, {"version": "v4", "created": "Fri, 3 Jul 2020 02:32:57 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Hadiashar", "Shima Bab", ""], ["Nayak", "Ashwin", ""]]}, {"id": "1905.02270", "submitter": "Ray Li", "authors": "Ray Li and Mary Wootters", "title": "Lifted multiplicity codes and the disjoint repair group property", "comments": "22 pages; A previous version claimed that a lifted code is exactly\n  the span of all good monomials, but in fact the span of all good monomials\n  only forms a subset of the lifted code. This does not change our main result", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifted Reed Solomon Codes (Guo, Kopparty, Sudan 2013) were introduced in the\ncontext of locally correctable and testable codes. They are multivariate\npolynomials whose restriction to any line is a codeword of a Reed-Solomon code.\nWe consider a generalization of their construction, which we call lifted\nmultiplicity codes. These are multivariate polynomial codes whose restriction\nto any line is a codeword of a multiplicity code (Kopparty, Saraf, Yekhanin\n2014). We show that lifted multiplicity codes have a better trade-off between\nredundancy and a notion of locality called the $t$-disjoint-repair-group\nproperty than previously known constructions. More precisely, we show that\nlifted multiplicity codes with length $N$ and redundancy $O(t^{0.585}\n\\sqrt{N})$ have the property that any symbol of a codeword can be reconstructed\nin $t$ different ways, each using a disjoint subset of the other coordinates.\nThis gives the best known trade-off for this problem for any super-constant $t\n< \\sqrt{N}$. We also give an alternative analysis of lifted Reed Solomon codes\nusing dual codes, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 21:31:36 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 00:06:20 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 17:34:52 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 18:39:14 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Li", "Ray", ""], ["Wootters", "Mary", ""]]}, {"id": "1905.02518", "submitter": "Peter Brooksbank", "authors": "Peter A. Brooksbank, Joshua A. Grochow, Yinan Li, Youming Qiao, James\n  B. Wilson", "title": "Incorporating Weisfeiler-Leman into algorithms for group isomorphism", "comments": "42 pages; 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we combine many of the standard and more recent algebraic\ntechniques for testing isomorphism of finite groups (GpI) with combinatorial\ntechniques that have typically been applied to Graph Isomorphism. In\nparticular, we show how to combine several state-of-the-art GpI algorithms for\nspecific group classes into an algorithm for general GpI, namely: composition\nseries isomorphism (Rosenbaum-Wagner, Theoret. Comp. Sci., 2015; Luks, 2015),\nrecursively-refineable filters (Wilson, J. Group Theory, 2013), and low-genus\nGpI (Brooksbank-Maglione-Wilson, J. Algebra, 2017). Recursively-refineable\nfilters -- a generalization of subgroup series -- form the skeleton of this\nframework, and we refine our filter by building a hypergraph encoding low-genus\nquotients, to which we then apply a hypergraph variant of the k-dimensional\nWeisfeiler-Leman technique. Our technique is flexible enough to readily\nincorporate additional hypergraph invariants or additional characteristic\nsubgroups.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 16:34:20 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Brooksbank", "Peter A.", ""], ["Grochow", "Joshua A.", ""], ["Li", "Yinan", ""], ["Qiao", "Youming", ""], ["Wilson", "James B.", ""]]}, {"id": "1905.02687", "submitter": "Konstantin Ryutin", "authors": "K.S. Ryutin", "title": "The algorithm for the recovery of integer vector via linear measurements", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we continue the studies on the integer sparse recovery problem\nthat was introduced in \\cite{FKS} and studied in \\cite{K},\\cite{KS}. We provide\nan algorithm for the recovery of an unknown sparse integer vector for the\nmeasurement matrix described in \\cite{KS} and estimate the number of\narithmetical operations.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:46:24 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Ryutin", "K. S.", ""]]}, {"id": "1905.03124", "submitter": "Dima Grigoriev", "authors": "Rostislav Grigorchuk, Dima Grigoriev", "title": "Key-agreement based on automaton groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest several automaton groups as key-agreement platforms for\nAnshl-Anshel-Goldfeld metascheme, they include Grigorchuk and universal\nGrigorchuk groups, Hanoi 3-Towers group, Basilica group and a subgroup of the\naffine group with the unsolvable conjugacy problem\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 14:56:30 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Grigorchuk", "Rostislav", ""], ["Grigoriev", "Dima", ""]]}, {"id": "1905.03134", "submitter": "Ignasi Sau", "authors": "Guilherme C. M. Gomes, Ignasi Sau", "title": "Finding cuts of bounded degree: complexity, FPT and exact algorithms,\n  and kernelization", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matching cut is a partition of the vertex set of a graph into two sets $A$\nand $B$ such that each vertex has at most one neighbor in the other side of the\ncut. The MATCHING CUT problem asks whether a graph has a matching cut, and has\nbeen intensively studied in the literature. Motivated by a question posed by\nKomusiewicz et al. [IPEC 2018], we introduce a natural generalization of this\nproblem, which we call $d$-CUT: for a positive integer $d$, a $d$-cut is a\nbipartition of the vertex set of a graph into two sets $A$ and $B$ such that\neach vertex has at most $d$ neighbors across the cut. We generalize (and in\nsome cases, improve) a number of results for the MATCHING CUT problem. Namely,\nwe begin with an NP-hardness reduction for $d$-CUT on $(2d+2)$-regular graphs\nand a polynomial algorithm for graphs of maximum degree at most $d+2$. The\ndegree bound in the hardness result is unlikely to be improved, as it would\ndisprove a long-standing conjecture in the context of internal partitions. We\nthen give FPT algorithms for several parameters: the maximum number of edges\ncrossing the cut, treewidth, distance to cluster, and distance to co-cluster.\nIn particular, the treewidth algorithm improves upon the running time of the\nbest known algorithm for MATCHING CUT. Our main technical contribution,\nbuilding on the techniques of Komusiewicz et al. [IPEC 2018], is a polynomial\nkernel for $d$-CUT for every positive integer $d$, parameterized by the\ndistance to a cluster graph. We also rule out the existence of polynomial\nkernels when parameterizing simultaneously by the number of edges crossing the\ncut, the treewidth, and the maximum degree. Finally, we provide an exact\nexponential algorithm slightly faster than the naive brute force approach\nrunning in time $O^*(2^n)$.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:07:28 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Gomes", "Guilherme C. M.", ""], ["Sau", "Ignasi", ""]]}, {"id": "1905.03148", "submitter": "Jeroen Zuiddam", "authors": "Srinivasan Arunachalam, P\\'eter Vrana, Jeroen Zuiddam", "title": "The asymptotic induced matching number of hypergraphs: balanced binary\n  strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the asymptotic induced matching number of the $k$-partite\n$k$-uniform hypergraphs whose edges are the $k$-bit strings of Hamming weight\n$k/2$, for any large enough even number $k$. Our lower bound relies on the\nhigher-order extension of the well-known Coppersmith-Winograd method from\nalgebraic complexity theory, which was proven by Christandl, Vrana and Zuiddam.\nOur result is motivated by the study of the power of this method as well as of\nthe power of the Strassen support functionals (which provide upper bounds on\nthe asymptotic induced matching number), and the connections to questions in\ntensor theory, quantum information theory and theoretical computer science.\n  Phrased in the language of tensors, as a direct consequence of our result, we\ndetermine the asymptotic subrank of any tensor with support given by the\naforementioned hypergraphs. In the context of quantum information theory, our\nresult amounts to an asymptotically optimal $k$-party stochastic local\noperations and classical communication (slocc) protocol for the problem of\ndistilling GHZ-type entanglement from a subfamily of Dicke-type entanglement.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:23:22 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Vrana", "P\u00e9ter", ""], ["Zuiddam", "Jeroen", ""]]}, {"id": "1905.03610", "submitter": "Cristobal Rojas", "authors": "Mark Braverman, Cristobal Rojas and Jonathan Schneider", "title": "Space-bounded Church-Turing thesis and computational tractability of\n  closed systems", "comments": "6 pages", "journal-ref": "Physical Review Letters. 115, 098701. August 2015", "doi": "10.1103/PhysRevLett.115.098701", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a new limitation on the ability of physical systems to perform\ncomputation -- one that is based on generalizing the notion of memory, or\nstorage space, available to the system to perform the computation. Roughly, we\ndefine memory as the maximal amount of information that the evolving system can\ncarry from one instant to the next. We show that memory is a limiting factor in\ncomputation even in lieu of any time limitations on the evolving system - such\nas when considering its equilibrium regime. We call this limitation the\nSpace-Bounded Church Turing Thesis (SBCT). The SBCT is supported by a\nSimulation Assertion (SA), which states that predicting the long-term behavior\nof bounded-memory systems is computationally tractable. In particular, one\ncorollary of SA is an explicit bound on the computational hardness of the\nlong-term behavior of a discrete-time finite-dimensional dynamical system that\nis affected by noise. We prove such a bound explicitly.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 15:36:57 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Braverman", "Mark", ""], ["Rojas", "Cristobal", ""], ["Schneider", "Jonathan", ""]]}, {"id": "1905.03631", "submitter": "Astrid Pieterse", "authors": "Eva-Maria C. Hols, Stefan Kratsch, and Astrid Pieterse", "title": "Elimination Distances, Blocking Sets, and Kernels for Vertex Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Vertex Cover problem plays an essential role in the study of polynomial\nkernelization in parameterized complexity, i.e., the study of provable and\nefficient preprocessing for NP-hard problems. Motivated by the great variety of\npositive and negative results for kernelization for Vertex Cover subject to\ndifferent parameters and graph classes, we seek to unify and generalize them\nusing so-called blocking sets, which have played implicit and explicit roles in\nmany results.\n  We show that in the most-studied setting, parameterized by the size of a\ndeletion set to a specified graph class $\\mathcal{C}$, bounded minimal blocking\nset size is necessary but not sufficient to get a polynomial kernelization.\nUnder mild technical assumptions, bounded minimal blocking set size is showed\nto allow an essentially tight efficient reduction in the number of connected\ncomponents.\n  We then determine the exact maximum size of minimal blocking sets for graphs\nof bounded elimination distance to any hereditary class $\\mathcal{C}$,\nincluding the case of graphs of bounded treedepth. We get similar but not tight\nbounds for certain non-hereditary classes $\\mathcal{C}$, including the class\n$\\mathcal{C}_{LP}$ of graphs where integral and fractional vertex cover size\ncoincide. These bounds allow us to derive polynomial kernels for Vertex Cover\nparameterized by the size of a deletion set to graphs of bounded elimination\ndistance to, e.g., forest, bipartite, or $\\mathcal{C}_{LP}$ graphs.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:47:17 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hols", "Eva-Maria C.", ""], ["Kratsch", "Stefan", ""], ["Pieterse", "Astrid", ""]]}, {"id": "1905.04162", "submitter": "Alexandre Teiller", "authors": "Evripidis Bampis, Bruno Escoffier, Kevin Schewior, Alexandre Teiller", "title": "Online Multistage Subset Maximization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous combinatorial optimization problems (knapsack, maximum-weight\nmatching, etc.) can be expressed as \\emph{subset maximization problems}: One is\ngiven a ground set $N=\\{1,\\dots,n\\}$, a collection $\\mathcal{F}\\subseteq 2^N$\nof subsets thereof such that $\\emptyset\\in\\mathcal{F}$, and an objective\n(profit) function $p:\\mathcal{F}\\rightarrow\\mathbb{R}_+$. The task is to choose\na set $S\\in\\mathcal{F}$ that maximizes $p(S)$. We consider the\n\\emph{multistage} version (Eisenstat et al., Gupta et al., both ICALP 2014) of\nsuch problems: The profit function $p_t$ (and possibly the set of feasible\nsolutions $\\mathcal{F}_t$) may change over time. Since in many applications\nchanging the solution is costly, the task becomes to find a sequence of\nsolutions that optimizes the trade-off between good per-time solutions and\nstable solutions taking into account an additional similarity bonus. As\nsimilarity measure for two consecutive solutions, we consider either the size\nof the intersection of the two solutions or the difference of $n$ and the\nHamming distance between the two characteristic vectors. We study multistage\nsubset maximization problems in the \\emph{online} setting, that is, $p_t$\n(along with possibly $\\mathcal{F}_t$) only arrive one by one and, upon such an\narrival, the online algorithm has to output the corresponding solution without\nknowledge of the future. We develop general techniques for online multistage\nsubset maximization and thereby characterize those models (given by the type of\ndata evolution and the type of similarity measure) that admit a\nconstant-competitive online algorithm. When no constant competitive ratio is\npossible, we employ lookahead to circumvent this issue. When a constant\ncompetitive ratio is possible, we provide almost matching lower and upper\nbounds on the best achievable one.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:28:23 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Bampis", "Evripidis", ""], ["Escoffier", "Bruno", ""], ["Schewior", "Kevin", ""], ["Teiller", "Alexandre", ""]]}, {"id": "1905.04325", "submitter": "M. Amin Rahimian", "authors": "Dean Eckles, Hossein Esfandiari, Elchanan Mossel, M. Amin Rahimian", "title": "Seeding with Costly Network Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CC math.PR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of selecting $k$ nodes in a social network of size $n$, to\nseed a diffusion with maximum expected spread size, under the independent\ncascade model with cascade probability $p$. Most of the previous work on this\nproblem (known as influence maximization) focuses on efficient algorithms to\napproximate the optimal seed set with provable guarantees, given the knowledge\nof the entire network. However, in practice, obtaining full knowledge of the\nnetwork is very costly. To address this gap, we first study the achievable\nguarantees using $o(n)$ influence samples. We provide an approximation\nalgorithm with a tight $(1-1/e){\\mbox{OPT}}-\\epsilon n$ guarantee, using\n$O_{\\epsilon}(k^2\\log n)$ influence samples and show that this dependence on\n$k$ is asymptotically optimal. We then propose a probing algorithm that queries\n${O}_{\\epsilon}(p n^2\\log^4 n + \\sqrt{k p} n^{1.5}\\log^{5.5} n + k\nn\\log^{3.5}{n})$ edges from the graph and use them to find a seed set with the\nsame almost tight approximation guarantee. We also provide a matching (up to\nlogarithmic factors) lower-bound on the required number of edges. To address\nthe dependence of our probing algorithm on the independent cascade probability\n$p$, we show that it is impossible to maintain the same approximation\nguarantees by controlling the discrepancy between the probing and seeding\ncascade probabilities. Instead, we propose to down-sample the probed edges to\nmatch the seeding cascade probability, provided that it does not exceed that of\nprobing. Finally, we test our algorithms on real world data to quantify the\ntrade-off between the cost of obtaining more refined network information and\nthe benefit of the added information for guiding improved seeding strategies.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 18:11:48 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 18:15:49 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 16:59:29 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 17:12:30 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Eckles", "Dean", ""], ["Esfandiari", "Hossein", ""], ["Mossel", "Elchanan", ""], ["Rahimian", "M. Amin", ""]]}, {"id": "1905.04612", "submitter": "Bruce MacLennan", "authors": "Chengrui Li and Bruce J. MacLennan", "title": "Continuous-Time Systems for Solving 0-1 Integer Linear Programming\n  Feasibility Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 0-1 integer linear programming feasibility problem is an important\nNP-complete problem. This paper proposes a continuous-time dynamical system for\nsolving that problem without getting trapped in non-solution local minima.\nFirst, the problem is transformed to an easier form in linear time. Then, we\npropose an \"impulse algorithm\" to escape from local traps and show its\nperformance is better than randomization for escaping traps. Second, we present\nthe time-to-solution distribution of the impulse algorithm and compare it with\nexhaustive search to see its advantages. Third, we show that the fractional\nsize of the basin of attraction of the global minimum is significantly larger\nthan $2^{-N}$, the corresponding discrete probability for exhaustive search.\nFinally, we conduct a case study to show that the location of the basin is\nindependent of different dimensions. These findings reveal a better way to\nsolve the 0-1 integer linear programming feasibility problem continuously and\nshow that its cost could be less than discrete methods in average cases.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 00:01:07 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Li", "Chengrui", ""], ["MacLennan", "Bruce J.", ""]]}, {"id": "1905.04695", "submitter": "Juho Lauri", "authors": "Juho Lauri, Christodoulos Mitillos", "title": "Complexity of fall coloring for restricted graph classes", "comments": "To appear at the 30th International Workshop on Combinatorial\n  Algorithms (IWOCA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We strengthen a result by Laskar and Lyle (Discrete Appl. Math. (2009),\n330-338) by proving that it is NP-complete to decide whether a bipartite planar\ngraph can be partitioned into three independent dominating sets. In contrast,\nwe show that this is always possible for every maximal outerplanar graph with\nat least three vertices. Moreover, we extend their previous result by proving\nthat deciding whether a bipartite graph can be partitioned into $k$ independent\ndominating sets is NP-complete for every $k \\geq 3$. We also strengthen a\nresult by Henning et al. (Discrete Math. (2009), 6451-6458) by showing that it\nis NP-complete to determine if a graph has two disjoint independent dominating\nsets, even when the problem is restricted to triangle-free planar graphs.\nFinally, for every $k \\geq 3$, we show that there is some constant $t$\ndepending only on $k$ such that deciding whether a $k$-regular graph can be\npartitioned into $t$ independent dominating sets is NP-complete. We conclude by\nderiving moderately exponential-time algorithms for the problem.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 11:20:24 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lauri", "Juho", ""], ["Mitillos", "Christodoulos", ""]]}, {"id": "1905.04827", "submitter": "Oleksii Omelchenko", "authors": "Oleksii Omelchenko and Andrei A. Bulatov", "title": "Satisfiability Threshold for Power Law Random 2-SAT in Configuration\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Random Satisfiability problem has been intensively studied for decades.\nFor a number of reasons the focus of this study has mostly been on the model,\nin which instances are sampled uniformly at random from a set of formulas\nsatisfying some clear conditions, such as fixed density or the probability of a\nclause to occur. However, some non-uniform distributions are also of\nconsiderable interest. In this paper we consider Random 2-SAT problems, in\nwhich instances are sampled from a wide range of non-uniform distributions.\n  The model of random SAT we choose is the so-called configuration model, given\nby a distribution $\\xi$ for the degree (or the number of occurrences) of each\nvariable. Then to generate a formula the degree of each variable is sampled\nfrom $\\xi$, generating several \\emph{clones} of the variable. Then 2-clauses\nare created by choosing a random paritioning into 2-element sets on the set of\nclones and assigning the polarity of literals at random.\n  Here we consider the random 2-SAT problem in the configuration model for\npower-law-like distributions $\\xi$. More precisely, we assume that $\\xi$ is\nsuch that its right tail $F_{\\xi}(x)$ satisfies the conditions\n$W\\ell^{-\\alpha}\\le F_{\\xi}(\\ell)\\le V\\ell^{-\\alpha}$ for some constants $V,W$.\nThe main goal is to study the satisfiability threshold phenomenon depending on\nthe parameters $\\alpha,V,W$. We show that a satisfiability threshold exists and\nis determined by a simple relation between the first and second moments of\n$\\xi$.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 01:56:29 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Omelchenko", "Oleksii", ""], ["Bulatov", "Andrei A.", ""]]}, {"id": "1905.05094", "submitter": "Pascal Koiran", "authors": "Pascal Koiran", "title": "Orthogonal tensor decomposition and orbit closures from a linear\n  algebraic perspective", "comments": "Final version taking the referee's comments into account. In\n  particular, Theorem 34 (formerly Theorem 30) was strengthened", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study orthogonal decompositions of symmetric and ordinary tensors using\nmethods from linear algebra. For the field of real numbers we show that the\nsets of decomposable tensors can be defined be equations of degree 2. This\ngives a new proof of some of the results of Robeva and Boralevi et al.\nOrthogonal decompositions over the field of complex numbers had not been\nstudied previously; we give an explicit description of the set of decomposable\ntensors using polynomial equalities and inequalities, and we begin a study of\ntheir closures. The main open problem that arises from this work is to obtain a\ncomplete description of the closures. This question is akin to that of\ncharacterizing border rank of tensors in algebraic complexity. We give partial\nresults using in particular a connection with approximate simultaneous\ndiagonalization (the so-called \"ASD property\").\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 15:38:09 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 19:51:01 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 12:50:46 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Koiran", "Pascal", ""]]}, {"id": "1905.05114", "submitter": "Stefan Jaax", "authors": "Stefan Jaax, Stefan Kiefer", "title": "On Affine Reachability Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze affine reachability problems in dimensions 1 and 2. We show that\nthe reachability problem for 1-register machines over the integers with affine\nupdates is PSPACE-hard, hence PSPACE-complete, strengthening a result by Finkel\net al. that required polynomial updates. Building on recent results on\ntwo-dimensional integer matrices, we prove NP-completeness of the mortality\nproblem for 2-dimensional integer matrices with determinants +1 and 0.\nMotivated by tight connections with 1-dimensional affine reachability problems\nwithout control states, we also study the complexity of a number of\nreachability problems in finitely generated semigroups of 2-dimensional\nupper-triangular integer matrices.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:05:10 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 11:15:04 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 16:10:32 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Jaax", "Stefan", ""], ["Kiefer", "Stefan", ""]]}, {"id": "1905.05290", "submitter": "Romain Wallon", "authors": "Stefan Mengel and Romain Wallon", "title": "Graph Width Measures for CNF-Encodings with Auxiliary Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider bounded width CNF-formulas where the width is measured by popular\ngraph width measures on graphs associated to CNF-formulas. Such restricted\ngraph classes, in particular those of bounded treewidth, have been extensively\nstudied for their uses in the design of algorithms for various computational\nproblems on CNF-formulas. Here we consider the expressivity of these formulas\nin the model of clausal encodings with auxiliary variables. We first show that\nbounding the width for many of the measures from the literature leads to a\ndramatic loss of expressivity, restricting the formulas to such of low\ncommunication complexity. We then show that the width of optimal encodings with\nrespect to different measures is strongly linked: there are two classes of\nwidth measures, one containing primal treewidth and the other incidence\ncliquewidth, such that in each class the width of optimal encodings only\ndiffers by constant factors. Moreover, between the two classes the width\ndiffers at most by a factor logarithmic in the number of variables. Both these\nresults are in stark contrast to the setting without auxiliary variables where\nall width measures we consider here differ by more than constant factors and in\nmany cases even by linear factors.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 09:55:21 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 15:49:07 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Mengel", "Stefan", ""], ["Wallon", "Romain", ""]]}, {"id": "1905.05304", "submitter": "Philipp Zschoche", "authors": "George B. Mertzios, Hendrik Molter, Rolf Niedermeier, Viktor Zamaraev,\n  and Philipp Zschoche", "title": "Computing Maximum Matchings in Temporal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal graphs are graphs whose topology is subject to discrete changes over\ntime. Given a static underlying graph $G$, a temporal graph is represented by\nassigning a set of integer time-labels to every edge $e$ of $G$, indicating the\ndiscrete time steps at which $e$ is active. We introduce and study the\ncomplexity of a natural temporal extension of the classical graph problem\nMaximum Matching, taking into account the dynamic nature of temporal graphs. In\nour problem, Maximum Temporal Matching, we are looking for the largest possible\nnumber of time-labeled edges (simply time-edges) $(e,t)$ such that no vertex is\nmatched more than once within any time window of $\\Delta$ consecutive time\nslots, where $\\Delta \\in \\mathbb{N}$ is given. The requirement that a vertex\ncannot be matched twice in any $\\Delta$-window models some necessary \"recovery\"\nperiod that needs to pass for an entity (vertex) after being paired up for some\nactivity with another entity. We prove strong computational hardness results\nfor Maximum Temporal Matching, even for elementary cases. To cope with this\ncomputational hardness, we mainly focus on fixed-parameter algorithms with\nrespect to natural parameters, as well as on polynomial-time approximation\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 22:19:27 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 18:21:54 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 17:05:47 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 15:16:20 GMT"}, {"version": "v5", "created": "Fri, 10 Jul 2020 17:31:39 GMT"}, {"version": "v6", "created": "Tue, 29 Sep 2020 12:50:37 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mertzios", "George B.", ""], ["Molter", "Hendrik", ""], ["Niedermeier", "Rolf", ""], ["Zamaraev", "Viktor", ""], ["Zschoche", "Philipp", ""]]}, {"id": "1905.05334", "submitter": "Yan Ru Pei", "authors": "Yan Ru Pei, Haik Manukian, Massimiliano Di Ventra", "title": "Generating Weighted MAX-2-SAT Instances of Tunable Difficulty with\n  Frustrated Loops", "comments": "38 pages, 9 figures", "journal-ref": "Journal of Machine Learning Research 21(159), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DM physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many optimization problems can be cast into the maximum satisfiability\n(MAX-SAT) form, and many solvers have been developed for tackling such\nproblems. To evaluate a MAX-SAT solver, it is convenient to generate hard\nMAX-SAT instances with known solutions. Here, we propose a method of generating\nweighted MAX-2-SAT instances inspired by the frustrated-loop algorithm used by\nthe quantum annealing community. We extend the algorithm for instances of\ngeneral bipartite couplings, with the associated optimization problem being the\nminimization of the restricted Boltzmann machine (RBM) energy over the nodal\nvalues, which is useful for effectively pre-training the RBM. The hardness of\nthe generated instances can be tuned through a central parameter known as the\nfrustration index. Two versions of the algorithm are presented: the random- and\nstructured-loop algorithms. For the random-loop algorithm, we provide a\nthorough theoretical and empirical analysis on its mathematical properties from\nthe perspective of frustration, and observe empirically a double phase\ntransition behavior in the hardness scaling behavior driven by the frustration\nindex. For the structured-loop algorithm, we show that it offers an improvement\nin hardness over the random-loop algorithm in the regime of high loop density,\nwith the variation of hardness tunable through the concentration of frustrated\nweights.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 01:12:49 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 22:18:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pei", "Yan Ru", ""], ["Manukian", "Haik", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "1905.05669", "submitter": "David Wolpert", "authors": "David H. Wolpert", "title": "Stochastic thermodynamics of computation", "comments": "111 pages, no figures. arXiv admin note: text overlap with\n  arXiv:1901.00386", "journal-ref": "Invited article for special issue, \"Shannon's information theory:\n  70 years on\", Journal of Physics A: Mathematical and Theoretical, 2019", "doi": "10.1088/1751-8121/ab0850", "report-no": null, "categories": "cond-mat.stat-mech cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major resource requirements of computers - ranging from biological\ncells to human brains to high-performance (engineered) computers - is the\nenergy used to run them. Those costs of performing a computation have long been\na focus of research in physics, going back to the early work of Landauer. One\nof the most prominent aspects of computers is that they are inherently\nnonequilibrium systems. However, the early research was done when\nnonequilibrium statistical physics was in its infancy, which meant the work was\nformulated in terms of equilibrium statistical physics. Since then there have\nbeen major breakthroughs in nonequilibrium statistical physics, which are\nallowing us to investigate the myriad aspects of the relationship between\nstatistical physics and computation, extending well beyond the issue of how\nmuch work is required to erase a bit. In this paper I review some of this\nrecent work on the `stochastic thermodynamics of computation'. After reviewing\nthe salient parts of information theory, computer science theory, and\nstochastic thermodynamics, I summarize what has been learned about the entropic\ncosts of performing a broad range of computations, extending from bit erasure\nto loop-free circuits to logically reversible circuits to information ratchets\nto Turing machines. These results reveal new, challenging engineering problems\nfor how to design computers to have minimal thermodynamic costs. They also\nallow us to start to combine computer science theory and stochastic\nthermodynamics at a foundational level, thereby expanding both.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:28:05 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Wolpert", "David H.", ""]]}, {"id": "1905.05765", "submitter": "Arjun Kar", "authors": "Vijay Balasubramanian, Matthew DeCross, Arjun Kar, Onkar Parrikar", "title": "Quantum Complexity of Time Evolution with Chaotic Hamiltonians", "comments": "35+11 pages, 13 figures, improved motivation of cost factors,\n  improved discussion of superoperator corrections", "journal-ref": null, "doi": "10.1007/JHEP01(2020)134", "report-no": null, "categories": "hep-th cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantum complexity of time evolution in large-$N$ chaotic\nsystems, with the SYK model as our main example. This complexity is expected to\nincrease linearly for exponential time prior to saturating at its maximum\nvalue, and is related to the length of minimal geodesics on the manifold of\nunitary operators that act on Hilbert space. Using the Euler-Arnold formalism,\nwe demonstrate that there is always a geodesic between the identity and the\ntime evolution operator $e^{-iHt}$ whose length grows linearly with time. This\ngeodesic is minimal until there is an obstruction to its minimality, after\nwhich it can fail to be a minimum either locally or globally. We identify a\ncriterion - the Eigenstate Complexity Hypothesis (ECH) - which bounds the\noverlap between off-diagonal energy eigenstate projectors and the $k$-local\noperators of the theory, and use it to show that the linear geodesic will at\nleast be a local minimum for exponential time. We show numerically that the\nlarge-$N$ SYK model (which is chaotic) satisfies ECH and thus has no local\nobstructions to linear growth of complexity for exponential time, as expected\nfrom holographic duality. In contrast, we also study the case with $N=2$\nfermions (which is integrable) and find short-time linear complexity growth\nfollowed by oscillations. Our analysis relates complexity to familiar\nproperties of physical theories like their spectra and the structure of energy\neigenstates and has implications for the hypothesized computational complexity\nclass separations PSPACE $\\nsubseteq$ BQP/poly and PSPACE $\\nsubseteq$\nBQSUBEXP/subexp, and the \"fast-forwarding\" of quantum Hamiltonians.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 03:30:59 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 19:40:31 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Balasubramanian", "Vijay", ""], ["DeCross", "Matthew", ""], ["Kar", "Arjun", ""], ["Parrikar", "Onkar", ""]]}, {"id": "1905.06104", "submitter": "Stepan Margaryan", "authors": "Stepan Margaryan", "title": "About a certain NP complete problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we introduce the concept of special decomposition of a set\nand the concept of special covering of a set under such a decomposition. We\nstudy the conditions for existence of special coverings of the sets, under the\nspecial decomposition of the set. These conditions of formulated problem have\nimportant applications in the field of satisfiability of Boolean functions. Our\ngoal is to study the relationship between sat CNF problem and the problem of\nexistance of special covering of the set. We also study the relationship\nbetween classes of computational complexity by searching for special coverings\nof the sets. We prove, that the decidability of sat CNF problem, in polynomial\ntime reduces to the problem of existence of a special covering of a set. We\nalso prove, that the problem of existence of a special covering of a set, in\npolynomial time reduces to the decidability of the sat CNF problem. Therefore,\nthe mentioned problems are polynomially equivalent. And then, the problem of\nexistence of a special covering of a set is NP-complete problem.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:48:27 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 16:27:54 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Margaryan", "Stepan", ""]]}, {"id": "1905.06503", "submitter": "Patrick Lin", "authors": "Venkatesan Guruswami, Patrick Lin", "title": "Parameterized Inapproximability of Exact Cover and Nearest Codeword", "comments": "An error was discovered in the proof of Lemma 3.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-ExactCover problem is a parameterized version of the ExactCover\nproblem, in which we are given a universe $U$, a collection $S$ of subsets of\n$U$, and an integer $k$, and the task is to determine whether $U$ can be\npartitioned into $k$ sets in $S$. This is a natural extension of the\nwell-studied SetCover problem; though in the parameterized regime we know it to\nbe $W[1]$-complete in the exact case, its parameterized complexity with respect\nto approximability is not well understood.\n  We prove that, assuming ETH, for some $\\gamma > 0$ there is no time $f(k)\n\\cdot N^{\\gamma k}$ algorithm that can, given a $k$-ExactCover instance $I$,\ndistinguish between the case where $I$ has an exact cover of size $k$ and the\ncase where every set cover of $I$ has size at least $\\frac14\n\\sqrt[k]{\\frac{\\log N}{\\log \\log N}}$. This rules out even more than FPT\nalgorithms, and additionally rules out any algorithm whose approximation ratio\ndepends only on the parameter $k$. By assuming SETH, we instead improve the\nlower bound to requiring time $f(k) \\cdot N^{k - \\varepsilon}$, for any\n$\\varepsilon > 0$.\n  In this work we also extend the inapproximability result to the\n$k$-Nearest-Codeword ($k$-NCP) problem. Specifically, given a generator matrix\n$A \\in \\mathbb{F}_2^{m \\times n}$, a vector $y \\in \\mathbb{F}_2^m$, and the\nparameter $k$, we show that it is hard to distinguish between the case where\nthere exists a codeword with distance at most $k$ from $y$ and the case where\nevery codeword has distance at least $\\frac18 \\sqrt[k]{\\frac{\\log N}{\\log \\log\nN}}$ from $y$. This improves the best known parameterized inapproximability\nresult, which rules out approximations with a factor of $\\text{poly} (\\log k)$,\nbut requires us to assume ETH instead of $W[1] \\neq FPT$.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 02:28:14 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 12:10:55 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Lin", "Patrick", ""]]}, {"id": "1905.07135", "submitter": "Guang Yang", "authors": "David P. Woodruff, Guang Yang", "title": "Separating k-Player from t-Player One-Way Communication, with\n  Applications to Data Streams", "comments": "to appear in ICALP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a $k$-party communication problem, the $k$ players with inputs $x_1, x_2,\n\\ldots, x_k$, respectively, want to evaluate a function $f(x_1, x_2, \\ldots,\nx_k)$ using as little communication as possible. We consider the\nmessage-passing model, in which the inputs are partitioned in an arbitrary,\npossibly worst-case manner, among a smaller number $t$ of players ($t<k$). The\n$t$-player communication cost of computing $f$ can only be smaller than the\n$k$-player communication cost, since the $t$ players can trivially simulate the\n$k$-player protocol. But how much smaller can it be? We study deterministic and\nrandomized protocols in the one-way model, and provide separations for product\ninput distributions, which are optimal for low error probability protocols. We\nalso provide much stronger separations when the input distribution is\nnon-product.\n  A key application of our results is in proving lower bounds for data stream\nalgorithms. In particular, we give an optimal $\\Omega(\\varepsilon^{-2}\\log(N)\n\\log \\log(mM))$ bits of space lower bound for the fundamental problem of\n$(1\\pm\\varepsilon)$-approximating the number $\\|x\\|_0$ of non-zero entries of\nan $n$-dimensional vector $x$ after $m$ updates each of magnitude $M$, and with\nsuccess probability $\\ge 2/3$, in a strict turnstile stream. Our result matches\nthe best known upper bound when $\\varepsilon\\ge 1/\\mathsf{polylog}(mM)$. It\nalso improves on the prior $\\Omega(\\varepsilon^{-2}\\log(mM) )$ lower bound and\nseparates the complexity of approximating $L_0$ from approximating the $p$-norm\n$L_p$ for $p$ bounded away from $0$, since the latter has an\n$O(\\varepsilon^{-2}\\log (mM))$ bit upper bound.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:21:45 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Woodruff", "David P.", ""], ["Yang", "Guang", ""]]}, {"id": "1905.07448", "submitter": "Ahmed Shokry", "authors": "Ahmed Shokry", "title": "Shortest Path Algorithms between Theory and Practice", "comments": "Master thesis, Alexandria University 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilizing graph algorithms is a common activity in computer science.\nAlgorithms that perform computations on large graphs are not always efficient.\nThis work investigates the Single-Source Shortest Path (SSSP) problem, which is\nconsidered to be one of the most important and most studied graph problems.\nThis thesis contains a review of the SSSP problem in both theory and practice.\nIn addition, it discusses a new single-source shortest-path algorithm that\nachieves the same $O(n \\cdot m)$ time bound as the traditional\nBellman-Ford-Moore algorithm but outperforms it and other state-of-the-art\nalgorithms in practice.\n  The work is comprised of three parts. The first discusses some basic\nshortest-path and negative-cycle-detection algorithms in literature from the\ntheoretical and practical point of view. The second contains a discussion of a\nnew algorithm for the single-source shortest-path problem that outperforms most\nstate-of-the-art algorithms for several well-known families of graphs. The main\nidea behind the proposed algorithm is to select the fewest most-effective\nvertices to scan. We also propose a discussion of correctness, termination, and\nthe proof of the worst-case time bound of the proposed algorithm. This section\nalso suggests two different implementations for the proposed algorithm, the\nfirst runs faster while the second performs a fewer number of operations.\nFinally, an extensive computational study of the different shortest paths\nalgorithms is conducted. The results are proposed using a new evaluation metric\nfor shortest-path algorithms. A discussion of outcomes, strengths, and\nweaknesses of the various shortest path algorithms are also included in this\nwork.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 19:21:09 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Shokry", "Ahmed", ""]]}, {"id": "1905.07468", "submitter": "Yasamin Nazari", "authors": "Michael Dinitz, Yasamin Nazari, Zeyu Zhang", "title": "Lasserre Integrality Gaps for Graph Spanners and Related Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant recent progress on algorithms for approximating\ngraph spanners, i.e., algorithms which approximate the best spanner for a given\ninput graph. Essentially all of these algorithms use the same basic LP\nrelaxation, so a variety of papers have studied the limitations of this\napproach and proved integrality gaps for this LP in a variety of settings. We\nextend these results by showing that even the strongest lift-and-project\nmethods cannot help significantly, by proving polynomial integrality gaps even\nfor $n^{\\Omega(\\epsilon)}$ levels of the Lasserre hierarchy, for both the\ndirected and undirected spanner problems. We also extend these integrality gaps\nto related problems, notably Directed Steiner Network and Shallow-Light Steiner\nNetwork.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 20:44:10 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Dinitz", "Michael", ""], ["Nazari", "Yasamin", ""], ["Zhang", "Zeyu", ""]]}, {"id": "1905.07780", "submitter": "Lijie Chen", "authors": "Lijie Chen, Ofer Grossman", "title": "Broadcast Congested Clique: Planted Cliques and Pseudorandom Generators", "comments": "abstract shortened to meet the constraint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop techniques to prove lower bounds for the BCAST(log n) Broadcast\nCongested Clique model (a distributed message passing model where in each\nround, each processor can broadcast an O(log n)-sized message to all other\nprocessors). Our techniques are built to prove bounds for natural input\ndistributions. So far, all lower bounds for problems in the model relied on\nconstructing specifically tailored graph families for the specific problem at\nhand, resulting in lower bounds for artificially constructed inputs, instead of\nnatural input distributions.\n  One of our results is a lower bound for the directed planted clique problem.\nIn this problem, an input graph is either a random directed graph (each\ndirected edge is included with probability 1/2), or a random graph with a\nplanted clique of size k. That is, k randomly chosen vertices have all of the\nedges between them included, and all other edges in the graph appear with\nprobability 1/2. The goal is to determine whether a clique exists. We show that\nwhen k = n^(1/4 - eps), this problem requires a number of rounds polynomial in\nn.\n  Additionally, we construct a pseudo-random generator which fools the\nBroadcast Congested Clique. This allows us to show that every k round\nrandomized algorithm in which each processor uses up to n random bits can be\nefficiently transformed into an O(k)-round randomized algorithm in which each\nprocessor uses only up to O(k log n) random bits, while maintaining a high\nsuccess probability. The pseudo-random generator is simple to describe,\ncomputationally very cheap, and its seed size is optimal up to constant\nfactors. However, the analysis is quite involved, and is based on the new\ntechnique for proving lower bounds in the model.\n  The technique also allows us to prove the first average case lower bound for\nthe Broadcast Congested Clique, as well as an average-case time hierarchy.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 17:32:04 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Chen", "Lijie", ""], ["Grossman", "Ofer", ""]]}, {"id": "1905.08127", "submitter": "Mahdi Boroujeni", "authors": "Mahdi Boroujeni, Sina Dehghani, Soheil Ehsani, MohammadTaghi\n  HajiAghayi, Saeed Seddighin", "title": "Subcubic Equivalences Between Graph Centrality Measures and\n  Complementary Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite persistent efforts, there is no known technique for obtaining\nunconditional super-linear lower bounds for the computational complexity of the\nproblems in P. Vassilevska Williams and Williams introduce a fruitful approach\nto advance a better understanding of the computational complexity of the\nproblems in P. In particular, they consider All Pairs Shortest Paths (APSP) and\nother fundamental problems such as checking whether a matrix defines a metric,\nverifying the correctness of a matrix product, and detecting a negative\ntriangle in a graph. Abboud, Grandoni, and Vassilevska Williams study\nwell-known graph centrality problems such as Radius, Median, etc., and make a\nconnection between their computational complexity to that of two fundamental\nproblems, namely APSP and Diameter. They show any algorithm with subcubic\nrunning time for these centrality problems, implies a subcubic algorithm for\neither APSP or Diameter. In this paper, we define vertex versions for these\ncentrality problems and based on that we introduce new complementary problems.\nThe main open problem of Abboud et al. is whether or not APSP and Diameter are\nequivalent under subcubic reduction. One of the results of this paper is APSP\nand CoDiameter, which is the complementary version of Diameter, are equivalent.\nMoreover, for some of the problems in this set, we show that they are\nequivalent to their complementary versions. Considering the slight difference\nbetween a problem and its complementary version, these equivalences give us the\nimpression that every problem has such a property, and thus APSP and Diameter\nare equivalent. This paper is a step forward in showing a subcubic equivalence\nbetween APSP and Diameter, and we hope that the approach introduced in our\npaper can be helpful to make this breakthrough happen.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:08:12 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Boroujeni", "Mahdi", ""], ["Dehghani", "Sina", ""], ["Ehsani", "Soheil", ""], ["HajiAghayi", "MohammadTaghi", ""], ["Seddighin", "Saeed", ""]]}, {"id": "1905.08621", "submitter": "David K\\\"ubel", "authors": "Herman Haverkort, David K\\\"ubel, and Elmar Langetepe", "title": "Shortest-Path-Preserving Rounding", "comments": "20 pages, 5 figures, pre-print of an article presented at IWOCA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various applications of graphs, in particular applications related to finding\nshortest paths, naturally get inputs with real weights on the edges. However,\nfor algorithmic or visualization reasons, inputs with integer weights would\noften be preferable or even required. This raises the following question: given\nan undirected graph with non-negative real weights on the edges and an error\nthreshold $\\varepsilon$, how efficiently can we decide whether we can round all\nweights such that shortest paths are maintained, and the change of weight of\neach shortest path is less than $\\varepsilon$? So far, only for path-shaped\ngraphs a polynomial-time algorithm was known. In this paper we prove, by\nreduction from 3-SAT, that, in general, the problem is NP-hard. However, if the\ngraph is a tree with $n$ vertices, the problem can be solved in $O(n^2)$ time.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 13:30:37 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Haverkort", "Herman", ""], ["K\u00fcbel", "David", ""], ["Langetepe", "Elmar", ""]]}, {"id": "1905.09163", "submitter": "Jan Macdonald", "authors": "Stephan W\\\"aldchen, Jan Macdonald, Sascha Hauch, Gitta Kutyniok", "title": "The Computational Complexity of Understanding Network Decisions", "comments": "added acknowledgements, added a reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a Boolean function $\\Phi\\colon\\{0,1\\}^d\\to\\{0,1\\}$ and an assignment to\nits variables $\\mathbf{x}=(x_1, x_2, \\dots, x_d)$ we consider the problem of\nfinding the subsets of the variables that are sufficient to determine the\nfunction value with a given probability $\\delta$. This is motivated by the task\nof interpreting predictions of binary classifiers described as Boolean circuits\n(which can be seen as special cases of neural networks). We show that the\nproblem of deciding whether such subsets of relevant variables of limited size\n$k\\leq d$ exist is complete for the complexity class\n$\\mathsf{NP}^{\\mathsf{PP}}$ and thus generally unfeasible to solve. We\nintroduce a variant where it suffices to check whether a subset determines the\nfunction value with probability at least $\\delta$ or at most $\\delta-\\gamma$\nfor $0<\\gamma<\\delta$. This reduces the complexity to the class\n$\\mathsf{NP}^{\\mathsf{BPP}}$. Finally, we show that finding the minimal set of\nrelevant variables can not be reasonably approximated, i.e. with an\napproximation factor $d^{1-\\alpha}$ for $\\alpha > 0$, by a polynomial time\nalgorithm unless $\\mathsf{P} = \\mathsf{NP}$ (this holds even with the\nprobability gap).\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:20:54 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 11:04:32 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["W\u00e4ldchen", "Stephan", ""], ["Macdonald", "Jan", ""], ["Hauch", "Sascha", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "1905.09320", "submitter": "Zhenwei Luo", "authors": "Zhenwei Luo and Ye Zhang", "title": "Solving Random Systems of Quadratic Equations with Tanh Wirtinger Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving quadratic systems of equations in n variables and m measurements of\nthe form $y_i = |a^T_i x|^2$ , $i = 1, ..., m$ and $x \\in R^n$ , which is also\nknown as phase retrieval, is a hard nonconvex problem. In the case of standard\nGaussian measurement vectors, the wirtinger flow algorithm Chen and Candes\n(2015) is an efficient solution. In this paper, we proposed a new form of\nwirtinger flow and a new spectral initialization method based on this new\nalgorithm. We proved that the new wirtinger flow and initialization method\nachieve linear sample and computational complexities. We further extended the\nnew phasing algorithm by combining it with other existing methods. Finally, we\ndemonstrated the effectiveness of our new method in the low data to parameter\nratio settings where the number of measurements which is less than\ninformation-theoretic limit, namely, $m < 2n$, via numerical tests. For\ninstance, our method can solve the quadratic systems of equations with gaussian\nmeasurement vector with probability $\\ge 97\\%$ when $m/n = 1.7$ and $n = 1000$,\nand with probability $\\approx 60\\%$ when $m/n = 1.5$ and $n = 1000$.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 18:33:21 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Luo", "Zhenwei", ""], ["Zhang", "Ye", ""]]}, {"id": "1905.09401", "submitter": "Ibrahim Al-Nahhal Mr", "authors": "Ibrahim Al-Nahhal, Ertugrul Basar, Octavia A. Dobre, and Salama Ikki", "title": "Optimum Low-Complexity Decoder for Spatial Modulation", "comments": "12 pages, 15 figures. To appear on IEEE Journal on Selected Areas in\n  Communications", "journal-ref": null, "doi": "10.1109/JSAC.2019.2929454", "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a novel low-complexity detection algorithm for spatial\nmodulation (SM), referred to as the minimum-distance of maximum-length (m-M)\nalgorithm, is proposed and analyzed. The proposed m-M algorithm is a smart\nsearching method that is applied for the SM tree-search decoders. The behavior\nof the m-M algorithm is studied for three different scenarios: i) perfect\nchannel state information at the receiver side (CSIR), ii) imperfect CSIR of a\nfixed channel estimation error variance, and iii) imperfect CSIR of a variable\nchannel estimation error variance. Moreover, the complexity of the m-M\nalgorithm is considered as a random variable, which is carefully analyzed for\nall scenarios, using probabilistic tools. Based on a combination of the sphere\ndecoder (SD) and ordering concepts, the m-M algorithm guarantees to find the\nmaximum-likelihood (ML) solution with a significant reduction in the decoding\ncomplexity compared to SM-ML and existing SM-SD algorithms; it can reduce the\ncomplexity up to 94% and 85% in the perfect CSIR and the worst scenario of\nimperfect CSIR, respectively, compared to the SM-ML decoder. Monte Carlo\nsimulation results are provided to support our findings as well as the derived\nanalytical complexity reduction expressions.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 23:13:27 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 11:40:52 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Al-Nahhal", "Ibrahim", ""], ["Basar", "Ertugrul", ""], ["Dobre", "Octavia A.", ""], ["Ikki", "Salama", ""]]}, {"id": "1905.10017", "submitter": "Takuya Isomura", "authors": "Takuya Isomura", "title": "Computational cost for determining an approximate global minimum using\n  the selection and crossover algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the expected computational cost to determine an\napproximate global minimum of a class of cost functions characterized by the\nvariance of coefficients. The cost function takes $N$-dimensional binary states\nas arguments and has many local minima. Iterations in the order of $2^N$ are\nrequired to determine an approximate global minimum using random search. This\nwork analytically and numerically demonstrates that the selection and crossover\nalgorithm with random initialization can reduce the required computational cost\n(i.e., number of iterations) for identifying an approximate global minimum to\nthe order of $\\lambda^N$ with $\\lambda$ less than 2. The two best solutions,\nreferred to as parents, are selected from a pool of randomly sampled states.\nOffspring generated by crossovers of the parents' states are distributed with a\nmean cost lower than that of the original distribution that generated the\nparents. It is revealed that in contrast to the mean, the variance of the cost\nof the offspring is asymptotically the same as that of the original\ndistribution. Consequently, sampling from the offspring's distribution leads to\na higher chance of determining an approximate global minimum than sampling from\nthe original distribution, thereby accelerating the global search. This feature\nis distinct from the distribution obtained by a mixture of a large population\nof favorable states, which leads to a lower variance of offspring. These\nfindings demonstrate the advantage of the crossover between two favorable\nstates over a mixture of many favorable states for an efficient determination\nof an approximate global minimum.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 03:20:46 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Isomura", "Takuya", ""]]}, {"id": "1905.10682", "submitter": "Andrei Bulatov", "authors": "Amirhossein Kazeminia, Andrei A. Bulatov", "title": "Counting Homomorphisms Modulo a Prime Number", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting problems in general and counting graph homomorphisms in particular\nhave numerous applications in combinatorics, computer science, statistical\nphysics, and elsewhere. One of the most well studied problems in this area is\n#GraphHom(H) --- the problem of finding the number of homomorphisms from a\ngiven graph G to the graph H. Not only the complexity of this basic problem is\nknown, but also of its many variants for digraphs, more general relational\nstructures, graphs with weights, and others.\n  In this paper we consider a modification of #GraphHom(H), the #_p GraphHom(H)\nproblem, p a prime number: Given a graph G, find the number of homomorphisms\nfrom G to H modulo p. In a series of papers Faben and Jerrum, and Goebel et al.\ndetermined the complexity of #_2 GraphHom(H) in the case H (or, in fact, a\ncertain graph derived from H) is square-free, that is, does not contain a\n4-cycle. Also, Goebel et al. found the complexity of #_p GraphHom(H) for an\narbitrary prime p when H is a tree. Here we extend the above result to show\nthat the #_p GraphHom(H) problem is #_p P-hard whenever the derived graph\nassociated with H is square-free and is not a star, which completely classifies\nthe complexity of #_p GraphHom(H) for square-free graphs H.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:42:38 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Kazeminia", "Amirhossein", ""], ["Bulatov", "Andrei A.", ""]]}, {"id": "1905.10747", "submitter": "Igor Sergeev S.", "authors": "Igor S. Sergeev", "title": "On the monotone complexity of the shift operator", "comments": "7 pages (in English); 7 pages (in Russian); ver. 2: abstract\n  extended, and bibliography updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the complexity of minimal monotone circuits implementing a\nmonotone version of the permutation operator on $n$ boolean vectors of length\n$q$ is $\\Theta(qn\\log n)$. In particular, we obtain an alternative way to prove\nthe known complexity bound $\\Theta(n\\log n)$ for the monotone shift operator on\n$n$ boolean inputs.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 06:53:44 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 17:11:21 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Sergeev", "Igor S.", ""]]}, {"id": "1905.10867", "submitter": "Igor Razgon", "authors": "Andrea Cali and Igor Razgon", "title": "Regular resolution for CNF of bounded incidence treewidth with few long\n  clauses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that Regular Resolution is FPT for two restricted families of\nCNFs of bounded incidence treewidth. The first includes CNFs having at most $p$\nclauses whose removal results in a CNF of primal treewidth at most $k$. The\nparameters we use in this case are $p$ and $k$. The second class includes CNFs\nof bounded one-sided (incidence) treewdth, a new parameter generalizing both\nprimal treewidth and incidence pathwidth. The parameter we use in this case is\nthe one-sided treewidth.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 20:02:21 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cali", "Andrea", ""], ["Razgon", "Igor", ""]]}, {"id": "1905.11092", "submitter": "Jan Macdonald", "authors": "Jan Macdonald, Stephan W\\\"aldchen, Sascha Hauch, Gitta Kutyniok", "title": "A Rate-Distortion Framework for Explaining Neural Network Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalise the widespread idea of interpreting neural network decisions as\nan explicit optimisation problem in a rate-distortion framework. A set of input\nfeatures is deemed relevant for a classification decision if the expected\nclassifier score remains nearly constant when randomising the remaining\nfeatures. We discuss the computational complexity of finding small sets of\nrelevant features and show that the problem is complete for\n$\\mathsf{NP}^\\mathsf{PP}$, an important class of computational problems\nfrequently arising in AI tasks. Furthermore, we show that it even remains\n$\\mathsf{NP}$-hard to only approximate the optimal solution to within any\nnon-trivial approximation factor. Finally, we consider a continuous problem\nrelaxation and develop a heuristic solution strategy based on assumed density\nfiltering for deep ReLU neural networks. We present numerical experiments for\ntwo image classification data sets where we outperform established methods in\nparticular for sparse explanations of neural network decisions.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:58:08 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Macdonald", "Jan", ""], ["W\u00e4ldchen", "Stephan", ""], ["Hauch", "Sascha", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "1905.11166", "submitter": "Johannes Blum", "authors": "Johannes Blum", "title": "Hierarchy of Transportation Network Parameters and Hardness Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph parameters highway dimension and skeleton dimension were introduced\nto capture the properties of transportation networks. As many important\noptimization problems like Travelling Salesperson, Steiner Tree or $k$-Center\narise in such networks, it is worthwhile to study them on graphs of bounded\nhighway or skeleton dimension.\n  We investigate the relationships between mentioned parameters and how they\nare related to other important graph parameters that have been applied\nsuccessfully to various optimization problems. We show that the skeleton\ndimension is incomparable to any of the parameters distance to linear forest,\nbandwidth, treewidth and highway dimension and hence, it is worthwhile to study\nmentioned problems also on graphs of bounded skeleton dimension. Moreover, we\nprove that the skeleton dimension is upper bounded by the max leaf number and\nthat for any graph on at least three vertices there are edge weights such that\nboth parameters are equal.\n  Then we show that computing the highway dimension according to most recent\ndefinition is NP-hard, which answers an open question stated by Feldmann et al.\nFinally we prove that on graphs $G=(V,E)$ of skeleton dimension\n$\\mathcal{O}(\\log^2 \\vert V \\vert)$ it is NP-hard to approximate the $k$-Center\nproblem within a factor less than $2$.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 12:29:11 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 11:20:13 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 12:22:53 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Blum", "Johannes", ""]]}, {"id": "1905.11280", "submitter": "Alex B. Grilo", "authors": "Alex B. Grilo, William Slofstra, Henry Yuen", "title": "Perfect zero knowledge for quantum multiprover interactive proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the interplay between multiprover interactive\nproofs, quantum entanglement, and zero knowledge proofs - notions that are\ncentral pillars of complexity theory, quantum information and cryptography. In\nparticular, we study the relationship between the complexity class MIP$^*$, the\nset of languages decidable by multiprover interactive proofs with quantumly\nentangled provers, and the class PZKMIP$^*$, which is the set of languages\ndecidable by MIP$^*$ protocols that furthermore possess the perfect zero\nknowledge property.\n  Our main result is that the two classes are equal, i.e., MIP$^* =$\nPZKMIP$^*$. This result provides a quantum analogue of the celebrated result of\nBen-Or, Goldwasser, Kilian, and Wigderson (STOC 1988) who show that MIP $=$\nPZKMIP (in other words, all classical multiprover interactive protocols can be\nmade zero knowledge). We prove our result by showing that every MIP$^*$\nprotocol can be efficiently transformed into an equivalent zero knowledge\nMIP$^*$ protocol in a manner that preserves the completeness-soundness gap.\nCombining our transformation with previous results by Slofstra (Forum of\nMathematics, Pi 2019) and Fitzsimons, Ji, Vidick and Yuen (STOC 2019), we\nobtain the corollary that all co-recursively enumerable languages (which\ninclude undecidable problems as well as all decidable problems) have zero\nknowledge MIP$^*$ protocols with vanishing promise gap.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 15:00:11 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Grilo", "Alex B.", ""], ["Slofstra", "William", ""], ["Yuen", "Henry", ""]]}, {"id": "1905.11458", "submitter": "Valery Shchesnovich", "authors": "Valery Shchesnovich", "title": "Distinguishing noisy boson sampling from classical simulations", "comments": "Resubmission with clickable References (in the \"Quantum\" style\n  format). Minor misprint in Eq. (62) corrected", "journal-ref": "Quantum 5, 423 (2021)", "doi": "10.22331/q-2021-03-29-423", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Giving a convincing experimental evidence of the quantum supremacy over\nclassical simulations is a challenging goal. Noise is considered to be the main\nproblem in such a demonstration, hence it is urgent to understand the effect of\nnoise. Recently found classical algorithms can efficiently approximate, to any\nsmall error, the output of boson sampling with finite-amplitude noise. In this\nwork it is shown analytically and confirmed by numerical simulations that one\ncan efficiently distinguish the output distribution of such a noisy boson\nsampling from the approximations accounting for low-order quantum multiboson\ninterferences, what includes the mentioned classical algorithms. The number of\nsamples required to tell apart the quantum and classical output distributions\nis strongly affected by the previously unexplored parameter: density of bosons,\ni.e., the ratio of total number of interfering bosons to number of input ports\nof interferometer. Such critical dependence is strikingly reminiscent of the\nquantum-to-classical transition in systems of identical particles, which sets\nin when the system size scales up while density of particles vanishes.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:13:30 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 13:14:38 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 19:25:35 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 16:59:34 GMT"}, {"version": "v5", "created": "Thu, 18 Jun 2020 16:54:35 GMT"}, {"version": "v6", "created": "Tue, 16 Feb 2021 19:23:32 GMT"}, {"version": "v7", "created": "Thu, 25 Mar 2021 22:56:41 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Shchesnovich", "Valery", ""]]}, {"id": "1905.11564", "submitter": "Mohammad Mahmoody", "authors": "Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Adversarially Robust Learning Could Leverage Computational Hardness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over recent years, devising classification algorithms that are robust to\nadversarial perturbations has emerged as a challenging problem. In particular,\ndeep neural nets (DNNs) seem to be susceptible to small imperceptible changes\nover test instances. However, the line of work in provable robustness, so far,\nhas been focused on information-theoretic robustness, ruling out even the\nexistence of any adversarial examples. In this work, we study whether there is\na hope to benefit from algorithmic nature of an attacker that searches for\nadversarial examples, and ask whether there is any learning task for which it\nis possible to design classifiers that are only robust against polynomial-time\nadversaries. Indeed, numerous cryptographic tasks can only be secure against\ncomputationally bounded adversaries, and are indeed impossible for\ncomputationally unbounded attackers. Thus, it is natural to ask if the same\nstrategy could help robust learning.\n  We show that computational limitation of attackers can indeed be useful in\nrobust learning by demonstrating the possibility of a classifier for some\nlearning task for which computational and information theoretic adversaries of\nbounded perturbations have very different power. Namely, while computationally\nunbounded adversaries can attack successfully and find adversarial examples\nwith small perturbation, polynomial time adversaries are unable to do so unless\nthey can break standard cryptographic hardness assumptions. Our results,\ntherefore, indicate that perhaps a similar approach to cryptography (relying on\ncomputational hardness) holds promise for achieving computationally robust\nmachine learning. On the reverse directions, we also show that the existence of\nsuch learning task in which computational robustness beats information\ntheoretic robustness requires computational hardness by implying (average-case)\nhardness of NP.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 01:44:22 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 18:55:20 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Garg", "Sanjam", ""], ["Jha", "Somesh", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1905.11612", "submitter": "Arnab Bhattacharyya", "authors": "Arnab Bhattacharyya, Philips George John, Suprovat Ghoshal, Raghu Meka", "title": "Average Bias and Polynomial Sources", "comments": "We found out one of the main results has a much easier and direct\n  proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a new notion of pseudorandomness for randomness sources, which we\ncall the average bias. Given a distribution $Z$ over $\\{0,1\\}^n$, its average\nbias is: $b_{\\text{av}}(Z) =2^{-n} \\sum_{c \\in \\{0,1\\}^n} |\\mathbb{E}_{z \\sim\nZ}(-1)^{\\langle c, z\\rangle}|$. A source with average bias at most $2^{-k}$ has\nmin-entropy at least $k$, and so low average bias is a stronger condition than\nhigh min-entropy. We observe that the inner product function is an extractor\nfor any source with average bias less than $2^{-n/2}$.\n  The notion of average bias especially makes sense for polynomial sources,\ni.e., distributions sampled by low-degree $n$-variate polynomials over\n$\\mathbb{F}_2$. For the well-studied case of affine sources, it is easy to see\nthat min-entropy $k$ is exactly equivalent to average bias of $2^{-k}$. We show\nthat for quadratic sources, min-entropy $k$ implies that the average bias is at\nmost $2^{-\\Omega(\\sqrt{k})}$. We use this relation to design dispersers for\nseparable quadratic sources with a min-entropy guarantee.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 05:07:40 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 07:30:10 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["John", "Philips George", ""], ["Ghoshal", "Suprovat", ""], ["Meka", "Raghu", ""]]}, {"id": "1905.11635", "submitter": "Matthew Coudron", "authors": "Matthew Coudron, William Slofstra", "title": "Complexity lower bounds for computing the approximately-commuting\n  operator value of non-local games to high precision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating the commuting-operator value of a\ntwo-player non-local game. It is well-known that it is $\\mathrm{NP}$-complete\nto decide whether the classical value of a non-local game is 1 or $1-\n\\epsilon$. Furthermore, as long as $\\epsilon$ is small enough, this result does\nnot depend on the gap $\\epsilon$. In contrast, a recent result of Fitzsimons,\nJi, Vidick, and Yuen shows that the complexity of computing the quantum value\ngrows without bound as the gap $\\epsilon$ decreases. In this paper, we show\nthat this also holds for the commuting-operator value of a game. Specifically,\nin the language of multi-prover interactive proofs, we show that the power of\n$\\mathrm{MIP}^{co}(2,1,1,s)$ (proofs with two provers, one round, completeness\nprobability $1$, soundness probability $s$, and commuting-operator strategies)\ncan increase without bound as the gap $1-s$ gets arbitrarily small.\n  Our results also extend naturally in two ways, to perfect zero-knowledge\nprotocols, and to lower bounds on the complexity of computing the\napproximately-commuting value of a game. Thus we get lower bounds on the\ncomplexity class $\\mathrm{PZK}$-$\\mathrm{MIP}^{co}_{\\delta}(2,1,1,s)$ of\nperfect zero-knowledge multi-prover proofs with approximately-commuting\noperator strategies, as the gap $1-s$ gets arbitrarily small. While we do not\nknow any computable time upper bound on the class $\\mathrm{MIP}^{co}$, a result\nof the first author and Vidick shows that for $s = 1-1/\\text{poly}(f(n))$ and\n$\\delta = 1/\\text{poly}(f(n))$, the class $\\mathrm{MIP}^{co}_\\delta(2,1,1,s)$,\nwith constant communication from the provers, is contained in\n$\\mathrm{TIME}(\\exp(\\text{poly}(f(n))))$. We give a lower bound of\n$\\mathrm{coNTIME}(f(n))$ (ignoring constants inside the function) for this\nclass, which is tight up to polynomial factors assuming the exponential time\nhypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:46:27 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Coudron", "Matthew", ""], ["Slofstra", "William", ""]]}, {"id": "1905.12372", "submitter": "Michal Garl\\'ik", "authors": "Michal Garl\\'ik", "title": "Resolution Lower Bounds for Refutation Statements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any unsatisfiable CNF formula we give an exponential lower bound on the\nsize of resolution refutations of a propositional statement that the formula\nhas a resolution refutation. We describe three applications. (1) An open\nquestion in (Atserias, M\\\"uller 2019) asks whether a certain natural\npropositional encoding of the above statement is hard for Resolution. We answer\nby giving an exponential size lower bound. (2) We show exponential resolution\nsize lower bounds for reflection principles, thereby improving a result in\n(Atserias, Bonet 2004). (3) We provide new examples of CNFs that exponentially\nseparate Res(2) from Resolution (an exponential separation of these two proof\nsystems was originally proved in (Segerlind, Buss, Impagliazzo 2004)).\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:22:43 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Garl\u00edk", "Michal", ""]]}, {"id": "1905.12935", "submitter": "Igor Carboni Oliveira", "authors": "Jan Bydzovsky and Jan Krajicek and Igor C. Oliveira", "title": "Consistency of circuit lower bounds with bounded theories", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 2 (June 18,\n  2020) lmcs:6576", "doi": "10.23638/LMCS-16(2:12)2020", "report-no": null, "categories": "cs.CC math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proving that there are problems in $\\mathsf{P}^\\mathsf{NP}$ that require\nboolean circuits of super-linear size is a major frontier in complexity theory.\nWhile such lower bounds are known for larger complexity classes, existing\nresults only show that the corresponding problems are hard on infinitely many\ninput lengths. For instance, proving almost-everywhere circuit lower bounds is\nopen even for problems in $\\mathsf{MAEXP}$. Giving the notorious difficulty of\nproving lower bounds that hold for all large input lengths, we ask the\nfollowing question: Can we show that a large set of techniques cannot prove\nthat $\\mathsf{NP}$ is easy infinitely often? Motivated by this and related\nquestions about the interaction between mathematical proofs and computations,\nwe investigate circuit complexity from the perspective of logic.\n  Among other results, we prove that for any parameter $k \\geq 1$ it is\nconsistent with theory $T$ that computational class ${\\mathcal C} \\not\n\\subseteq \\textit{i.o.}\\mathrm{SIZE}(n^k)$, where $(T, \\mathcal{C})$ is one of\nthe pairs: $T = \\mathsf{T}^1_2$ and ${\\mathcal C} = \\mathsf{P}^\\mathsf{NP}$, $T\n= \\mathsf{S}^1_2$ and ${\\mathcal C} = \\mathsf{NP}$, $T = \\mathsf{PV}$ and\n${\\mathcal C} = \\mathsf{P}$. In other words, these theories cannot establish\ninfinitely often circuit upper bounds for the corresponding problems. This is\nof interest because the weaker theory $\\mathsf{PV}$ already formalizes\nsophisticated arguments, such as a proof of the PCP Theorem. These consistency\nstatements are unconditional and improve on earlier theorems of [KO17] and\n[BM18] on the consistency of lower bounds with $\\mathsf{PV}$.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:51:39 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 09:35:04 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 13:26:45 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 18:41:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bydzovsky", "Jan", ""], ["Krajicek", "Jan", ""], ["Oliveira", "Igor C.", ""]]}, {"id": "1905.12990", "submitter": "Vladislav Ryzhikov Dr", "authors": "Vladislav Ryzhikov, Przemyslaw Andrzej Walega, Michael Zakharyaschev", "title": "Data Complexity and Rewritability of Ontology-Mediated Queries in Metric\n  Temporal Logic under the Event-Based Semantics (Full Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the data complexity of answering queries mediated by metric\ntemporal logic ontologies under the event-based semantics assuming that data\ninstances are finite timed words timestamped with binary fractions. We identify\nclasses of ontology-mediated queries answering which can be done in AC0, NC1,\nL, NL, P, and coNP for data complexity, provide their rewritings to first-order\nlogic and its extensions with primitive recursion, transitive closure or\ndatalog, and establish lower complexity bounds.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:08:28 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 09:14:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Ryzhikov", "Vladislav", ""], ["Walega", "Przemyslaw Andrzej", ""], ["Zakharyaschev", "Michael", ""]]}]