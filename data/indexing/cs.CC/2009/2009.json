[{"id": "2009.00425", "submitter": "Aleksandr Cariow", "authors": "Aleksandr Cariow and Galina Cariowa", "title": "An algorithm for dividing quaternions", "comments": "9 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1608.07596", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a rationalized algorithm for calculating the quotient of two\nquaternions is presented which reduces the number of underlying real\nmultiplications. Hardware for fast multiplication is much more expensive than\nhardware for fast addition. Therefore, reducing the number of multiplications\nin VLSI processor design is usually a desirable task. The performing of a\nquaternion division using the naive method takes 16 multiplications, 15\nadditions, 4 squarings and 4 divisions of real numbers while the proposed\nalgorithm can compute the same result in only 8 multiplications (or multipliers\nin hardware implementation case), 31 additions, 4 squaring and 4 division of\nreal numbers.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 07:44:58 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Cariow", "Aleksandr", ""], ["Cariowa", "Galina", ""]]}, {"id": "2009.01139", "submitter": "Marsel Matdinov", "authors": "Marsel Matdinov", "title": "Circuit Satisfiability Problem for circuits of small complexity", "comments": "Translated into English, added one small section and a couple of\n  paragraphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following problem is considered. A Turing machine $M$, that accepts a\nstring of fixed length $t$ as input, runs for a time not exceeding a fixed\nvalue $n$ and is guaranteed to produce a binary output, is given. It's required\nto find a string $X$ such that $M(X) = 1$ effectively in terms of $t$, $n$, the\nsize of the alphabet of $M$ and the number of states of $M$. The problem is\nclose to the well-known Circuit Satisfiability Problem. The difference from\nCircuit Satisfiability Problem is that when reduced to Circuit Satisfiability\nProblem, we get circuits with a rich internal structure (in particular, these\nare circuits of small Kolmogorov complexity). The proof system, operating with\npotential proofs of the fact that, for a given machine $M$, the string $X$ does\nnot exist, is provided, its completeness is proved and the algorithm guaranteed\nto find a proof of the absence of the string $X$ in the case of its actual\nabsence is presented (in the worst case, the algorithm is exponential, but in a\nwide class of interesting cases it works in polynomial time). We present an\nalgorithm searching for the string $X$, for which its efficiency was neither\ntested, nor proven, and it may require serious improvement in the future, so it\ncan be regarded as an idea. We also discuss first steps towards solving a more\ncomplex problem similar to this one: a Turing machine $M$, that accepts two\nstrings $X$ and $Y$ of fixed length and running for a time that does not exceed\na fixed value, is given; it is required to build an algorithm $N$ that builds a\nstring $Y = N(X)$ for any string $X$, such that $M(X, Y) = 1$ (details in the\nintroduction).\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 15:25:34 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 16:23:47 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Matdinov", "Marsel", ""]]}, {"id": "2009.01145", "submitter": "Felipe S. Abrah\\~ao", "authors": "Felipe S. Abrah\\~ao, Klaus Wehmuth, Artur Ziviani", "title": "On the existence of hidden machines in computational time hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenging the standard notion of totality in computable functions, one has\nthat, given any sufficiently expressive formal axiomatic system, there are\ntotal functions that, although computable and \"intuitively\" understood as being\ntotal, cannot be proved to be total. In this article we show that this implies\nthe existence of an infinite hierarchy of time complexity classes whose\nrepresentative members are hidden from (or unknown by) the respective formal\naxiomatic systems. Although these classes contain total computable functions,\nthere are some of these functions for which the formal axiomatic system cannot\nrecognize as belonging to a time complexity class. This leads to incompleteness\nresults regarding formalizations of computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 15:46:09 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Abrah\u00e3o", "Felipe S.", ""], ["Wehmuth", "Klaus", ""], ["Ziviani", "Artur", ""]]}, {"id": "2009.01161", "submitter": "Sepehr Assadi", "authors": "Sepehr Assadi, Ran Raz", "title": "Near-Quadratic Lower Bounds for Two-Pass Graph Streaming Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that any two-pass graph streaming algorithm for the $s$-$t$\nreachability problem in $n$-vertex directed graphs requires near-quadratic\nspace of $n^{2-o(1)}$ bits. As a corollary, we also obtain near-quadratic space\nlower bounds for several other fundamental problems including maximum bipartite\nmatching and (approximate) shortest path in undirected graphs.\n  Our results collectively imply that a wide range of graph problems admit\nessentially no non-trivial streaming algorithm even when two passes over the\ninput is allowed. Prior to our work, such impossibility results were only known\nfor single-pass streaming algorithms, and the best two-pass lower bounds only\nruled out $o(n^{7/6})$ space algorithms, leaving open a large gap between\n(trivial) upper bounds and lower bounds.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 16:06:35 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Assadi", "Sepehr", ""], ["Raz", "Ran", ""]]}, {"id": "2009.01874", "submitter": "Chris Jones", "authors": "Mrinalkanti Ghosh, Fernando Granha Jeronimo, Chris Jones, Aaron\n  Potechin, Goutham Rajendran", "title": "Sum-of-Squares Lower Bounds for Sherrington-Kirkpatrick via Planted\n  Affine Planes", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sum-of-Squares (SoS) hierarchy is a semi-definite programming\nmeta-algorithm that captures state-of-the-art polynomial time guarantees for\nmany optimization problems such as Max-$k$-CSPs and Tensor PCA. On the flip\nside, a SoS lower bound provides evidence of hardness, which is particularly\nrelevant to average-case problems for which NP-hardness may not be available.\n  In this paper, we consider the following average case problem, which we call\nthe \\emph{Planted Affine Planes} (PAP) problem: Given $m$ random vectors\n$d_1,\\ldots,d_m$ in $\\mathbb{R}^n$, can we prove that there is no vector $v \\in\n\\mathbb{R}^n$ such that for all $u \\in [m]$, $\\langle v, d_u\\rangle^2 = 1$? In\nother words, can we prove that $m$ random vectors are not all contained in two\nparallel hyperplanes at equal distance from the origin? We prove that for $m\n\\leq n^{3/2-\\epsilon}$, with high probability, degree-$n^{\\Omega(\\epsilon)}$\nSoS fails to refute the existence of such a vector $v$.\n  When the vectors $d_1,\\ldots,d_m$ are chosen from the multivariate normal\ndistribution, the PAP problem is equivalent to the problem of proving that a\nrandom $n$-dimensional subspace of $\\mathbb{R}^m$ does not contain a boolean\nvector. As shown by Mohanty--Raghavendra--Xu [STOC 2020], a lower bound for\nthis problem implies a lower bound for the problem of certifying energy upper\nbounds on the Sherrington-Kirkpatrick Hamiltonian, and so our lower bound\nimplies a degree-$n^{\\Omega(\\epsilon)}$ SoS lower bound for the certification\nversion of the Sherrington-Kirkpatrick problem.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 18:39:53 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Ghosh", "Mrinalkanti", ""], ["Jeronimo", "Fernando Granha", ""], ["Jones", "Chris", ""], ["Potechin", "Aaron", ""], ["Rajendran", "Goutham", ""]]}, {"id": "2009.02452", "submitter": "Mrinal Kumar", "authors": "Mrinal Kumar and Ben Lee Volk", "title": "A Lower Bound on Determinantal Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The determinantal complexity of a polynomial $P \\in \\mathbb{F}[x_1, \\ldots,\nx_n]$ over a field $\\mathbb{F}$ is the dimension of the smallest matrix $M$\nwhose entries are affine functions in $\\mathbb{F}[x_1, \\ldots, x_n]$ such that\n$P = Det(M)$. We prove that the determinantal complexity of the polynomial\n$\\sum_{i = 1}^n x_i^n$ is at least $1.5n - 3$.\n  For every $n$-variate polynomial of degree $d$, the determinantal complexity\nis trivially at least $d$, and it is a long standing open problem to prove a\nlower bound which is super linear in $\\max\\{n,d\\}$. Our result is the first\nlower bound for any explicit polynomial which is bigger by a constant factor\nthan $\\max\\{n,d\\}$, and improves upon the prior best bound of $n + 1$, proved\nby Alper, Bogart and Velasco [ABV17] for the same polynomial.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 03:50:35 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kumar", "Mrinal", ""], ["Volk", "Ben Lee", ""]]}, {"id": "2009.02664", "submitter": "Xueliang Li", "authors": "Xuqing Bai, Xueliang Li", "title": "Strong rainbow disconnection in graphs", "comments": "16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a nontrivial edge-colored connected graph. An edge-cut $R$ of $G$\nis called a {\\it rainbow edge-cut} if no two edges of $R$ are colored with the\nsame color. For two distinct vertices $u$ and $v$ of $G$, if an edge-cut\nseparates them, then the edge-cut is called a {\\it $u$-$v$-edge-cut}. An\nedge-colored graph $G$ is called \\emph{strong rainbow disconnected} if for\nevery two distinct vertices $u$ and $v$ of $G$, there exists a both rainbow and\nminimum $u$-$v$-edge-cut ({\\it rainbow minimum $u$-$v$-edge-cut} for short) in\n$G$, separating them, and this edge-coloring is called a {\\it strong rainbow\ndisconnection coloring} (srd-{\\it coloring} for short) of $G$. For a connected\ngraph $G$, the \\emph{strong rainbow disconnection number} (srd-{\\it number} for\nshort) of $G$, denoted by $\\textnormal{srd}(G)$, is the smallest number of\ncolors that are needed in order to make $G$ strong rainbow disconnected.\n  In this paper, we first characterize the graphs with $m$ edges such that\n$\\textnormal{srd}(G)=k$ for each $k \\in \\{1,2,m\\}$, respectively, and we also\nshow that the srd-number of a nontrivial connected graph $G$ equals the maximum\nsrd-number among the blocks of $G$. Secondly, we study the srd-numbers for the\ncomplete $k$-partite graphs, $k$-edge-connected $k$-regular graphs and grid\ngraphs. Finally, we show that for a connected graph $G$, to compute\n$\\textnormal{srd}(G)$ is NP-hard. In particular, we show that it is already\nNP-complete to decide if $\\textnormal{srd}(G)=3$ for a connected cubic graph.\nMoreover, we show that for a given edge-colored (with an unbounded number of\ncolors) connected graph $G$ it is NP-complete to decide whether $G$ is strong\nrainbow disconnected.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 07:49:01 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bai", "Xuqing", ""], ["Li", "Xueliang", ""]]}, {"id": "2009.02717", "submitter": "Suhail Sherif", "authors": "Arkadev Chattopadhyay, Ankit Garg, Suhail Sherif", "title": "Towards Stronger Counterexamples to the Log-Approximate-Rank Conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give improved separations for the query complexity analogue of the\nlog-approximate-rank conjecture i.e. we show that there are a plethora of total\nBoolean functions on $n$ input bits, each of which has approximate Fourier\nsparsity at most $O(n^3)$ and randomized parity decision tree complexity\n$\\Theta(n)$. This improves upon the recent work of Chattopadhyay, Mande and\nSherif (JACM '20) both qualitatively (in terms of designing a large number of\nexamples) and quantitatively (improving the gap from quartic to cubic). We\nleave open the problem of proving a randomized communication complexity lower\nbound for XOR compositions of our examples. A linear lower bound would lead to\nnew and improved refutations of the log-approximate-rank conjecture. Moreover,\nif any of these compositions had even a sub-linear cost randomized\ncommunication protocol, it would demonstrate that randomized parity decision\ntree complexity does not lift to randomized communication complexity in general\n(with the XOR gadget).\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 11:57:33 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chattopadhyay", "Arkadev", ""], ["Garg", "Ankit", ""], ["Sherif", "Suhail", ""]]}, {"id": "2009.02778", "submitter": "Karthik C. S.", "authors": "Karthik C. S. and Inbal Livni-Navon", "title": "On Hardness of Approximation of Parameterized Set Cover and Label Cover:\n  Threshold Graphs from Error Correcting Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the $(k,h)$-SetCover problem, we are given a collection $\\mathcal{S}$ of\nsets over a universe $U$, and the goal is to distinguish between the case that\n$\\mathcal{S}$ contains $k$ sets which cover $U$, from the case that at least\n$h$ sets in $\\mathcal{S}$ are needed to cover $U$. Lin (ICALP'19) recently\nshowed a gap creating reduction from the $(k,k+1)$-SetCover problem on universe\nof size $O_k(\\log |\\mathcal{S}|)$ to the\n$\\left(k,\\sqrt[k]{\\frac{\\log|\\mathcal{S}|}{\\log\\log |\\mathcal{S}|}}\\cdot\nk\\right)$-SetCover problem on universe of size $|\\mathcal{S}|$. In this paper,\nwe prove a more scalable version of his result: given any error correcting code\n$C$ over alphabet $[q]$, rate $\\rho$, and relative distance $\\delta$, we use\n$C$ to create a reduction from the $(k,k+1)$-SetCover problem on universe $U$\nto the $\\left(k,\\sqrt[2k]{\\frac{2}{1-\\delta}}\\right)$-SetCover problem on\nuniverse of size $\\frac{\\log|\\mathcal{S}|}{\\rho}\\cdot|U|^{q^k}$.\n  Lin established his result by composing the input SetCover instance (that has\nno gap) with a special threshold graph constructed from extremal combinatorial\nobject called universal sets, resulting in a final SetCover instance with gap.\nOur reduction follows along the exact same lines, except that we generate the\nthreshold graphs specified by Lin simply using the basic properties of the\nerror correcting code $C$.\n  We use the same threshold graphs mentioned above to prove inapproximability\nresults, under W[1]$\\neq$FPT and ETH, for the $k$-MaxCover problem introduced\nby Chalermsook et al. (SICOMP'20). Our inapproximaiblity results match the\nbounds obtained by Karthik et al. (JACM'19), although their proof framework is\nvery different, and involves generalization of the distributed PCP framework.\nPrior to this work, it was not clear how to adopt the proof strategy of Lin to\nprove inapproximability results for $k$-MaxCover.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 17:13:48 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["S.", "Karthik C.", ""], ["Livni-Navon", "Inbal", ""]]}, {"id": "2009.02815", "submitter": "Amey Bhangale", "authors": "Amey Bhangale and Subhash Khot", "title": "Optimal Inapproximability of Satisfiable $k$-LIN over Non-Abelian Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A seminal result of H\\r{a}stad [J. ACM, 48(4):798--859, 2001] shows that it\nis NP-hard to find an assignment that satisfies $\\frac{1}{|G|}+\\varepsilon$\nfraction of the constraints of a given $k$-LIN instance over an abelian group,\neven if there is an assignment that satisfies $(1-\\varepsilon)$ fraction of the\nconstraints, for any constant $\\varepsilon>0$. Engebretsen et al. [Theoretical\nComputer Science, 312(1):17--45, 2004] later showed that the same hardness\nresult holds for $k$-LIN instances over any finite non-abelian group.\n  Unlike the abelian case, where we can efficiently find a solution if the\ninstance is satisfiable, in the non-abelian case, it is NP-complete to decide\nif a given system of linear equations is satisfiable or not, as shown by\nGoldmann and Russell [Information and Computation, 178(1):253--262. 2002].\n  Surprisingly, for certain non-abelian groups $G$, given a satisfiable $k$-LIN\ninstance over $G$, one can in fact do better than just outputting a random\nassignment using a simple but clever algorithm. The approximation factor\nachieved by this algorithm varies with the underlying group. In this paper, we\nshow that this algorithm is {\\em optimal} by proving a tight hardness of\napproximation of satisfiable $k$-LIN instance over {\\em any} non-abelian $G$,\nassuming $P \\neq NP$.\n  As a corollary, we also get $3$-query probabilistically checkable proofs with\nperfect completeness over large alphabets with improved soundness.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 20:55:07 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bhangale", "Amey", ""], ["Khot", "Subhash", ""]]}, {"id": "2009.02945", "submitter": "Zohair Raza Hassan", "authors": "Ammar Ahmed, Zohair Raza Hassan, Mudassir Shabbir", "title": "A Simpler NP-Hardness Proof for Familial Graph Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document presents a simpler proof showcasing the NP-hardness of Familial\nGraph Compression.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 08:50:57 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ahmed", "Ammar", ""], ["Hassan", "Zohair Raza", ""], ["Shabbir", "Mudassir", ""]]}, {"id": "2009.03038", "submitter": "Raghuvansh Saxena", "authors": "Sepehr Assadi, Gillat Kol, Raghuvansh R. Saxena, Huacheng Yu", "title": "Multi-Pass Graph Streaming Lower Bounds for Cycle Counting, MAX-CUT,\n  Matching Size, and Other Problems", "comments": "Fixed a mistake in one of the technical lemmas, see Section 1.4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following gap cycle counting problem in the streaming model: The\nedges of a $2$-regular $n$-vertex graph $G$ are arriving one-by-one in a stream\nand we are promised that $G$ is a disjoint union of either $k$-cycles or\n$2k$-cycles for some small $k$; the goal is to distinguish between these two\ncases. Verbin and Yu [SODA 2011] introduced this problem and showed that any\nsingle-pass streaming algorithm solving it requires $n^{1-\\Omega(\\frac{1}{k})}$\nspace. This result and the technique behind it -- the Boolean Hidden\nHypermatching communication problem -- has since been used extensively for\nproving streaming lower bounds for various problems.\n  Despite its significance and broad range of applications, the lower bound\ntechnique of Verbin and Yu comes with a key weakness that is inherited by all\nsubsequent results: the Boolean Hidden Hypermatching problem is hard only if\nthere is exactly one round of communication and can be solved with logarithmic\ncommunication in two rounds. Therefore, all streaming lower bounds derived from\nthis problem only hold for single-pass algorithms.\n  We prove the first multi-pass lower bound for the gap cycle counting problem:\nAny $p$-pass streaming algorithm that can distinguish between disjoint union of\n$k$-cycles vs $2k$-cycles -- or even $k$-cycles vs one Hamiltonian cycle --\nrequires $n^{1-\\frac{1}{k^{\\Omega(1/p)}}}$ space. As a corollary of this\nresult, we can extend many of previous lower bounds to multi-pass algorithms.\nFor instance, we can now prove that any streaming algorithm that\n$(1+\\epsilon)$-approximates the value of MAX-CUT, maximum matching size, or\nrank of an $n$-by-$n$ matrix, requires either $n^{\\Omega(1)}$ space or\n$\\Omega(\\log{(\\frac{1}{\\epsilon})})$ passes. For all these problems, prior work\nleft open the possibility of even an $O(\\log{n})$ space algorithm in only two\npasses.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 12:01:38 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 15:34:00 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Assadi", "Sepehr", ""], ["Kol", "Gillat", ""], ["Saxena", "Raghuvansh R.", ""], ["Yu", "Huacheng", ""]]}, {"id": "2009.03218", "submitter": "Alex Kerzner", "authors": "David Gosset, Daniel Grier, Alex Kerzner, Luke Schaeffer", "title": "Fast simulation of planar Clifford circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general quantum circuit can be simulated in exponential time on a classical\ncomputer. If it has a planar layout, then a tensor-network contraction\nalgorithm due to Markov and Shi has a runtime exponential in the square root of\nits size, or more generally exponential in the treewidth of the underlying\ngraph. Separately, Gottesman and Knill showed that if all gates are restricted\nto be Clifford, then there is a polynomial time simulation. We combine these\ntwo ideas and show that treewidth and planarity can be exploited to improve\nClifford circuit simulation. Our main result is a classical algorithm with\nruntime scaling asymptotically as $ n^{\\omega/2}<n^{1.19}$ which samples from\nthe output distribution obtained by measuring all $n$ qubits of a planar graph\nstate in given Pauli bases. Here $\\omega$ is the matrix multiplication\nexponent. We also provide a classical algorithm with the same asymptotic\nruntime which samples from the output distribution of any constant-depth\nClifford circuit in a planar geometry. Our work improves known classical\nalgorithms with cubic runtime. A key ingredient is a mapping which, given a\ntree decomposition of some graph $G$, produces a Clifford circuit with a\nstructure that mirrors the tree decomposition and which emulates measurement of\nthe quantum graph state corresponding to $G$. We provide a classical simulation\nof this circuit with the runtime stated above for planar graphs and otherwise\n$n t^{\\omega-1}$ where $t$ is the width of the tree decomposition. The\nalgorithm also incorporates a matrix-multiplication-time version of the\nGottesman-Knill simulation of multi-qubit measurement on stabilizer states,\nwhich may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:27:09 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Gosset", "David", ""], ["Grier", "Daniel", ""], ["Kerzner", "Alex", ""], ["Schaeffer", "Luke", ""]]}, {"id": "2009.03352", "submitter": "Jin Cao", "authors": "Jin Cao and Dewei Zhong", "title": "A Fast Randomized Algorithm for Finding the Maximal Common Subsequences", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the common subsequences of $L$ multiple strings has many applications\nin the area of bioinformatics, computational linguistics, and information\nretrieval. A well-known result states that finding a Longest Common Subsequence\n(LCS) for $L$ strings is NP-hard, e.g., the computational complexity is\nexponential in $L$. In this paper, we develop a randomized algorithm, referred\nto as {\\em Random-MCS}, for finding a random instance of Maximal Common\nSubsequence ($MCS$) of multiple strings. A common subsequence is {\\em maximal}\nif inserting any character into the subsequence no longer yields a common\nsubsequence. A special case of MCS is LCS where the length is the longest. We\nshow the complexity of our algorithm is linear in $L$, and therefore is\nsuitable for large $L$. Furthermore, we study the occurrence probability for a\nsingle instance of MCS and demonstrate via both theoretical and experimental\nstudies that the longest subsequence from multiple runs of {\\em Random-MCS}\noften yields a solution to $LCS$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:12:58 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Cao", "Jin", ""], ["Zhong", "Dewei", ""]]}, {"id": "2009.03788", "submitter": "Yihan Zhang", "authors": "Yihan Zhang, Sidharth Jaggi, Amitalok J. Budkuley", "title": "Tight List-Sizes for Oblivious AVCs under Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DM math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study list-decoding over adversarial channels governed by oblivious\nadversaries (a.k.a. oblivious Arbitrarily Varying Channels (AVCs)). This type\nof adversaries aims to maliciously corrupt the communication without knowing\nthe actual transmission from the sender. For any oblivious AVCs potentially\nwith constraints on the sender's transmitted sequence and the adversary's noise\nsequence, we determine the exact value of the minimum list-size that can\nsupport a reliable communication at positive rate. This generalizes a classical\nresult by Hughes (IEEE Transactions on Information Theory, 1997) and answers an\nopen question posed by Sarwate and Gastpar (IEEE Transactions on Information\nTheory, 2012). A lower bound on the list-decoding capacity (whenever positive)\nis presented. Under a certain combinatorial conjecture, we also prove a\nmatching upper bound. En route to a tight characterization of the list-decoding\ncapacity, we propose a method for subcode construction towards the resolution\nof the combinatorial conjecture.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 14:35:48 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zhang", "Yihan", ""], ["Jaggi", "Sidharth", ""], ["Budkuley", "Amitalok J.", ""]]}, {"id": "2009.03924", "submitter": "Arijit Haldar", "authors": "Arijit Haldar, Omid Tavakol, Thomas Scaffidi", "title": "Variational wavefunctions for Sachdev-Ye-Kitaev models", "comments": "6 pages", "journal-ref": "Phys. Rev. Research 3, 023020 (2021)", "doi": "10.1103/PhysRevResearch.3.023020", "report-no": null, "categories": "cond-mat.str-el cs.CC hep-th quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a class of $q$-local Hamiltonians, is it possible to find a simple\nvariational state whose energy is a finite fraction of the ground state energy\nin the thermodynamic limit? Whereas product states often provide an affirmative\nanswer in the case of bosonic (or qubit) models, we show that Gaussian states\nfail dramatically in the fermionic case, like for the Sachdev-Ye-Kitaev (SYK)\nmodels. This prompts us to propose a new class of wavefunctions for SYK models\ninspired by the variational coupled cluster algorithm. We introduce a static\n(\"0+0D\") large-$N$ field theory to study the energy, two-point correlators, and\nentanglement properties of these states. Most importantly, we demonstrate a\nfinite disorder-averaged approximation ratio of $r \\approx 0.62$ between the\nvariational and ground state energy of SYK for $q=4$. Moreover, the variational\nstates provide an exact description of spontaneous symmetry breaking in a\nrelated two-flavor SYK model.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 18:00:08 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 15:21:27 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Haldar", "Arijit", ""], ["Tavakol", "Omid", ""], ["Scaffidi", "Thomas", ""]]}, {"id": "2009.03996", "submitter": "Michael S. Fiske", "authors": "Michael Stephen Fiske", "title": "Combining Determinism and Indeterminism", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.CL math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to construct mathematical operations that combine indeterminism\nmeasured from quantum randomness with computational determinism so that\nnon-mechanistic behavior is preserved in the computation. Formally, some\nresults about operations applied to computably enumerable (c.e.) and bi-immune\nsets are proven here, where the objective is for the operations to preserve\nbi-immunity. While developing rearrangement operations on the natural numbers,\nwe discovered that the bi-immune rearrangements generate an uncountable\nsubgroup of the infinite symmetric group (Sym$(\\mathbb{N})$) on the natural\nnumbers $\\mathbb{N}$.\n  This new uncountable subgroup is called the bi-immune symmetric group. We\nshow that the bi-immune symmetric group contains the finitary symmetric group\non the natural numbers, and consequently is highly transitive. Furthermore, the\nbi-immune symmetric group is dense in Sym$(\\mathbb{N})$ with respect to the\npointwise convergence topology. The complete structure of the bi-immune\nsymmetric group and its subgroups generated by one or more bi-immune\nrearrangements is unknown.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 01:30:00 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 20:49:50 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 20:00:10 GMT"}, {"version": "v4", "created": "Thu, 19 Nov 2020 18:22:48 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Fiske", "Michael Stephen", ""]]}, {"id": "2009.04259", "submitter": "Flavio Ferrarotti", "authors": "Flavio Ferrarotti, Senen Gonzalez, Klaus-Dieter Schewe, Jose Maria\n  Turull-Torres", "title": "Completeness in Polylogarithmic Time and Space", "comments": "Submitted to Annals of Mathematics and Artificial Intelligence. arXiv\n  admin note: text overlap with arXiv:1911.13104", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complexity theory can be viewed as the study of the relationship between\ncomputation and applications, understood the former as complexity classes and\nthe latter as problems. Completeness results are clearly central to that view.\nMany natural algorithms resulting from current applications have\npolylogarithmic time (PolylogTime) or space complexity (PolylogSpace). The\nclassical Karp notion of complete problem however does not plays well with\nthese complexity classes. It is well known that PolylogSpace does not have\ncomplete problems under logarithmic space many-one reductions. In this paper we\nshow similar results for deterministic and non-deterministic PolylogTime as\nwell as for every other level of the polylogarithmic time hierarchy. We achieve\nthat by following a different strategy based on proving the existence of proper\nhierarchies of problems inside each class. We then develop an alternative\nnotion of completeness inspired by the concept of uniformity from circuit\ncomplexity and prove the existence of a (uniformly) complete problem for\nPolylogSpace under this new notion. As a consequence of this result we get that\ncomplete problems can still play an important role in the study of the\ninterrelationship between polylogarithmic and other classical complexity\nclasses.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 14:40:01 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Ferrarotti", "Flavio", ""], ["Gonzalez", "Senen", ""], ["Schewe", "Klaus-Dieter", ""], ["Turull-Torres", "Jose Maria", ""]]}, {"id": "2009.04821", "submitter": "Liam Jordon", "authors": "Liam Jordon, Philippe Moser", "title": "Pushdown and Lempel-Ziv Depth", "comments": "32 pages - Fixed typos from V1. Minor errors in proofs fixed. Results\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper expands upon existing and introduces new formulations of Bennett's\nlogical depth. In previously published work by Jordon and Moser, notions of\nfinite-state-depth and pushdown-depth were examined and compared. These were\nbased on finite-state transducers and information lossless pushdown compressors\nrespectively. Unfortunately a full separation between the two notions was not\nestablished. This paper introduces a new formulation of pushdown-depth based on\nrestricting how fast a pushdown compressor's stack can grow. This improved\nformulation allows us to do a full comparison by demonstrating the existence of\nsequences with high finite-state-depth and low pushdown-depth, and vice-versa.\nA new notion based on the Lempel-Ziv `78 algorithm is also introduced. Its\ndifference from finite-state-depth is shown by demonstrating the existence of a\nLempel-Ziv deep sequence that is not finite-state deep and vice versa.\nLempel-Ziv-depth's difference from pushdown-depth is shown by building\nsequences that have a pushdown-depth of roughly 1/2 but low Lempel-Ziv depth,\nand a sequence with high Lempel-Ziv depth but low pushdown-depth. Properties of\nall three notions are also discussed and proved.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:46:07 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 10:48:05 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Jordon", "Liam", ""], ["Moser", "Philippe", ""]]}, {"id": "2009.04892", "submitter": "Sajin Koroth", "authors": "Mohammad Mahdi Jahanara, Sajin Koroth, Igor Shinkar", "title": "Toward Probabilistic Checking against Non-Signaling Strategies with\n  Constant Locality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-signaling strategies are a generalization of quantum strategies that have\nbeen studied in physics over the past three decades. Recently, they have found\napplications in theoretical computer science, including to proving\ninapproximability results for linear programming and to constructing protocols\nfor delegating computation. A central tool for these applications is\nprobabilistically checkable proof (PCPs) systems that are sound against\nnon-signaling strategies.\n  In this paper we show, assuming a certain geometrical hypothesis about noise\nrobustness of non-signaling proofs (or, equivalently, about robustness to noise\nof solutions to the Sherali-Adams linear program), that a slight variant of the\nparallel repetition of the exponential-length constant-query PCP construction\ndue to Arora et al. (JACM 1998) is sound against non-signaling strategies with\nconstant locality.\n  Our proof relies on the analysis of the linearity test and agreement test\n(also known as the direct product test) in the non-signaling setting.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:37:05 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Jahanara", "Mohammad Mahdi", ""], ["Koroth", "Sajin", ""], ["Shinkar", "Igor", ""]]}, {"id": "2009.05208", "submitter": "S. Rasoul Etesami", "authors": "S. Rasoul Etesami", "title": "Consensus under Network Interruption and Effective Resistance\n  Interdiction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CC cs.MA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of network robustness under consensus dynamics. We first\nshow that the consensus interdiction problem (CIP), in which the goal is to\nmaximize the convergence time of consensus dynamics subject to removing limited\nnetwork edges, can be cast as an effective resistance interdiction problem\n(ERIP). We then show that ERIP is strongly NP-hard, even for bipartite graphs\nof diameter three with fixed source/sink edges. We establish the same hardness\nresult for the CIP, hence correcting some claims in the existing literature. We\nthen show that both ERIP and CIP do not admit a polynomial-time approximation\nscheme, and moreover, they cannot be approximated up to a (nearly) polynomial\nfactor assuming exponential time hypothesis. Finally, using a quadratic program\nformulation, we devise a polynomial-time $n^4$-approximation algorithm for ERIP\nthat only depends on the number of nodes $n$ and is independent of the size of\nedge resistances. We also develop an iterative heuristic approximation\nalgorithm to find a local optimum for the CIP.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 02:40:57 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 03:52:56 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Etesami", "S. Rasoul", ""]]}, {"id": "2009.05218", "submitter": "Prahladh Harsha", "authors": "Irit Dinur and Yuval Filmus and Prahladh Harsha and Madhur Tulsiani", "title": "Explicit SoS lower bounds from high-dimensional expanders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct an explicit family of 3XOR instances which is hard for\n$O(\\sqrt{\\log n})$ levels of the Sum-of-Squares hierarchy. In contrast to\nearlier constructions, which involve a random component, our systems can be\nconstructed explicitly in deterministic polynomial time.\n  Our construction is based on the high-dimensional expanders devised by\nLubotzky, Samuels and Vishne, known as LSV complexes or Ramanujan complexes,\nand our analysis is based on two notions of expansion for these complexes:\ncosystolic expansion, and a local isoperimetric inequality due to Gromov.\n  Our construction offers an interesting contrast to the recent work of Alev,\nJeronimo and the last author~(FOCS 2019). They showed that 3XOR instances in\nwhich the variables correspond to vertices in a high-dimensional expander are\neasy to solve. In contrast, in our instances the variables correspond to the\nedges of the complex.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 03:59:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Dinur", "Irit", ""], ["Filmus", "Yuval", ""], ["Harsha", "Prahladh", ""], ["Tulsiani", "Madhur", ""]]}, {"id": "2009.05314", "submitter": "Thom Fruehwirth", "authors": "Thom Fruehwirth", "title": "Repeated Recursion Unfolding for Super-Linear Speedup within Bounds", "comments": "This is the full version of a paper presented at the 30th\n  International Symposium on Logic-Based Program Synthesis and Transformation\n  (LOPSTR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repeated recursion unfolding is a new approach that repeatedly unfolds a\nrecursion with itself and simplifies it while keeping all unfolded rules. Each\nunfolding doubles the number of recursive steps covered. This reduces the\nnumber of recursive rule applications to its logarithm at the expense of\nintroducing a logarithmic number of unfolded rules to the program. Efficiency\ncrucially depends on the amount of simplification inside the unfolded rules. We\nprove a super-linear speedup theorem in the best case, i.e. speedup by more\nthan a constant factor. Our optimization can lower the time complexity class of\na program. In this paper, the super-linear speedup is within bounds: it holds\nup to an arbitrary but chosen upper bound on the number of recursive steps. We\nalso report on the first results with a prototype implementation of repeated\nrecursion unfolding. A simple program transformation completely removes\nrecursion up to the chosen bound. The actual runtime improvement quickly\nreaches several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 09:59:00 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Fruehwirth", "Thom", ""]]}, {"id": "2009.05685", "submitter": "Andrii Riazanov", "authors": "Venkatesan Guruswami, Andrii Riazanov", "title": "Linear Shannon Capacity of Cayley Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shannon capacity of a graph is a fundamental quantity in zero-error\ninformation theory measuring the rate of growth of independent sets in graph\npowers. Despite being well-studied, this quantity continues to hold several\nmysteries. Lov\\'asz famously proved that the Shannon capacity of $C_5$ (the\n5-cycle) is at most $\\sqrt{5}$ via his theta function. This bound is achieved\nby a simple linear code over $\\mathbb{F}_5$ mapping $x \\mapsto 2x$. This\nmotivates the notion of linear Shannon capacity of graphs, which is the largest\nrate achievable when restricting oneself to linear codes. We give a simple\nproof based on the polynomial method that the linear Shannon capacity of $C_5$\nis $\\sqrt{5}$. Our method applies more generally to Cayley graphs over the\nadditive group of finite fields $\\mathbb{F}_q$, giving an upper bound on the\nlinear Shannon capacity. We compare this bound to the Lov\\'asz theta function,\nshowing that they match for self-complementary Cayley graphs (such as $C_5$),\nand that the bound is smaller in some cases. We also exhibit a quadratic gap\nbetween linear and general Shannon capacity for some graphs.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 23:22:45 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 01:54:32 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Riazanov", "Andrii", ""]]}, {"id": "2009.05870", "submitter": "Anru R. Zhang", "authors": "Yuetian Luo and Anru R. Zhang", "title": "Open Problem: Average-Case Hardness of Hypergraphic Planted Clique\n  Detection", "comments": "Published at Proceedings of Conference on Learning Theory, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.CO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We note the significance of hypergraphic planted clique (HPC) detection in\nthe investigation of computational hardness for a range of tensor problems. We\nask if more evidence for the computational hardness of HPC detection can be\ndeveloped. In particular, we conjecture if it is possible to establish the\nequivalence of the computational hardness between HPC and PC detection.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 21:55:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Luo", "Yuetian", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2009.06107", "submitter": "Samuel Hopkins", "authors": "Matthew Brennan and Guy Bresler and Samuel B. Hopkins and Jerry Li and\n  Tselil Schramm", "title": "Statistical Query Algorithms and Low-Degree Tests Are Almost Equivalent", "comments": "Version 3 fixes typos and adds note on presentation at COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers currently use a number of approaches to predict and substantiate\ninformation-computation gaps in high-dimensional statistical estimation\nproblems. A prominent approach is to characterize the limits of restricted\nmodels of computation, which on the one hand yields strong computational lower\nbounds for powerful classes of algorithms and on the other hand helps guide the\ndevelopment of efficient algorithms. In this paper, we study two of the most\npopular restricted computational models, the statistical query framework and\nlow-degree polynomials, in the context of high-dimensional hypothesis testing.\nOur main result is that under mild conditions on the testing problem, the two\nclasses of algorithms are essentially equivalent in power. As corollaries, we\nobtain new statistical query lower bounds for sparse PCA, tensor PCA and\nseveral variants of the planted clique problem.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 22:55:18 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 05:28:15 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 17:06:23 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""], ["Hopkins", "Samuel B.", ""], ["Li", "Jerry", ""], ["Schramm", "Tselil", ""]]}, {"id": "2009.06117", "submitter": "Kiran Vodrahalli", "authors": "Christos Papadimitriou, Kiran Vodrahalli, Mihalis Yannakakis", "title": "The Platform Design Problem", "comments": "updated with more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.LG cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-line firms deploy suites of software platforms, where each platform is\ndesigned to interact with users during a certain activity, such as browsing,\nchatting, socializing, emailing, driving, etc. The economic and incentive\nstructure of this exchange, as well as its algorithmic nature, have not been\nexplored to our knowledge. We model this interaction as a Stackelberg game\nbetween a Designer and one or more Agents. We model an Agent as a Markov chain\nwhose states are activities; we assume that the Agent's utility is a linear\nfunction of the steady-state distribution of this chain. The Designer may\ndesign a platform for each of these activities/states; if a platform is adopted\nby the Agent, the transition probabilities of the Markov chain are affected,\nand so is the objective of the Agent. The Designer's utility is a linear\nfunction of the steady state probabilities of the accessible states minus the\ndevelopment cost of the platforms. The underlying optimization problem of the\nAgent -- how to choose the states for which to adopt the platform -- is an MDP.\nIf this MDP has a simple yet plausible structure (the transition probabilities\nfrom one state to another only depend on the target state and the recurrent\nprobability of the current state) the Agent's problem can be solved by a greedy\nalgorithm. The Designer's optimization problem (designing a custom suite for\nthe Agent so as to optimize, through the Agent's optimum reaction, the\nDesigner's revenue), is NP-hard to approximate within any finite ratio;\nhowever, the special case, while still NP-hard, has an FPTAS. These results\ngeneralize from a single Agent to a distribution of Agents with finite support,\nas well as to the setting where the Designer must find the best response to the\nexisting strategies of other Designers. We discuss other implications of our\nresults and directions of future research.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:53:19 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 02:14:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Papadimitriou", "Christos", ""], ["Vodrahalli", "Kiran", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "2009.07269", "submitter": "Dmitriy Kunisky", "authors": "Dmitriy Kunisky", "title": "Positivity-preserving extensions of sum-of-squares pseudomoments over\n  the hypercube", "comments": "101 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for building higher-degree sum-of-squares lower\nbounds over the hypercube $\\mathbf{x} \\in \\{\\pm 1\\}^N$ from a given degree 2\nlower bound. Our method constructs pseudoexpectations that are positive\nsemidefinite by design, lightening some of the technical challenges common to\nother approaches to SOS lower bounds, such as pseudocalibration.\n  We give general \"incoherence\" conditions under which degree 2 pseudomoments\ncan be extended to higher degrees. As an application, we extend previous lower\nbounds for the Sherrington-Kirkpatrick Hamiltonian from degree 4 to degree 6.\n(This is subsumed, however, in the stronger results of the parallel work of\nGhosh et al.) This amounts to extending degree 2 pseudomoments given by a\nrandom low-rank projection matrix. As evidence in favor of our construction for\nhigher degrees, we also show that random high-rank projection matrices (an\neasier case) can be extended to degree $\\omega(1)$. We identify the main\nobstacle to achieving the same in the low-rank case, and conjecture that while\nour construction remains correct to leading order, it also requires a\nnext-order adjustment.\n  Our technical argument involves the interplay of two ideas of independent\ninterest. First, our pseudomoment matrix factorizes in terms of certain\nmultiharmonic polynomials. This observation guides our proof of positivity.\nSecond, our pseudomoment values are described graphically by sums over forests,\nwith coefficients given by the M\\\"{o}bius function of a partial ordering of\nthose forests. This connection guides our proof that the pseudomoments satisfy\nthe hypercube constraints. We trace the reason that our pseudomoments can\nsatisfy both the hypercube and positivity constraints simultaneously to a\ncombinatorial relationship between multiharmonic polynomials and this\nM\\\"{o}bius function.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:59:08 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Kunisky", "Dmitriy", ""]]}, {"id": "2009.07311", "submitter": "Vahid Reza Asadi", "authors": "Vahid R. Asadi, Igor Shinkar", "title": "Relaxed Locally Correctable Codes with Improved Parameters", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally decodable codes (LDCs) are error-correcting codes $C : \\Sigma^k \\to\n\\Sigma^n$ that admit a local decoding algorithm that recovers each individual\nbit of the message by querying only a few bits from a noisy codeword. An\nimportant question in this line of research is to understand the optimal\ntrade-off between the query complexity of LDCs and their block length. Despite\nimportance of these objects, the best known constructions of constant query\nLDCs have super-polynomial length, and there is a significant gap between the\nbest constructions and the known lower bounds in terms of the block length.\n  For many applications it suffices to consider the weaker notion of relaxed\nLDCs (RLDCs), which allows the local decoding algorithm to abort if by querying\na few bits it detects that the input is not a codeword. This relaxation turned\nout to allow decoding algorithms with constant query complexity for codes with\nalmost linear length. Specifically, [BGH+06] constructed an $O(q)$-query RLDC\nthat encodes a message of length $k$ using a codeword of block length $n =\nO(k^{1+1/\\sqrt{q}})$.\n  In this work we improve the parameters of [BGH+06] by constructing an\n$O(q)$-query RLDC that encodes a message of length $k$ using a codeword of\nblock length $O(k^{1+1/{q}})$. This construction matches (up to a\nmultiplicative constant factor) the lower bounds of [KT00, Woo07] for constant\nquery LDCs, thus making progress toward understanding the gap between LDCs and\nRLDCs in the constant query regime.\n  In fact, our construction extends to the stronger notion of relaxed locally\ncorrectable codes (RLCCs), introduced in [GRR18], where given a noisy codeword\nthe correcting algorithm either recovers each individual bit of the codeword by\nonly reading a small part of the input, or aborts if the input is detected to\nbe corrupt.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 18:23:38 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Asadi", "Vahid R.", ""], ["Shinkar", "Igor", ""]]}, {"id": "2009.07630", "submitter": "Stasys Jukna", "authors": "Stasys Jukna and Hannes Seiwert", "title": "Tropical Kirchhoff's Formula and Postoptimality in Matroid Optimization", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an assignment of real weights to the ground elements of a matroid, the\nmin-max weight of a ground element $e$ is the minimum, over all circuits\ncontaining $e$, of the maximum weight of an element in that circuit with the\nelement $e$ removed. We use this concept to answer the following structural\nquestions for the minimum weight basis problem. Which elements are persistent\nunder a given weighting (belong to all or to none of the optimal bases)? What\nchanges of the weights are allowed while preserving optimality of optimal\nbases? How does the minimum weight of a basis change when the weight of a\nsingle ground element is changed, or when a ground element is contracted or\ndeleted? Our answer to this latter question gives the tropical (min,+,-)\nanalogue of Kirchhoff's arithmetic (+,x,/) effective conductance formula for\nelectrical networks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:26:09 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Jukna", "Stasys", ""], ["Seiwert", "Hannes", ""]]}, {"id": "2009.08032", "submitter": "Pravesh K Kothari", "authors": "Jackson Abascal, Venkatesan Guruswami, Pravesh K. Kothari", "title": "Strongly refuting all semi-random Boolean CSPs", "comments": "31 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an efficient algorithm to strongly refute \\emph{semi-random}\ninstances of all Boolean constraint satisfaction problems. The number of\nconstraints required by our algorithm matches (up to polylogarithmic factors)\nthe best-known bounds for efficient refutation of fully random instances. Our\nmain technical contribution is an algorithm to strongly refute semi-random\ninstances of the Boolean $k$-XOR problem on $n$ variables that have\n$\\widetilde{O}(n^{k/2})$ constraints. (In a semi-random $k$-XOR instance, the\nequations can be arbitrary and only the right-hand sides are random.)\n  One of our key insights is to identify a simple combinatorial property of\nrandom XOR instances that makes spectral refutation work. Our approach involves\ntaking an instance that does not satisfy this property (i.e., is \\emph{not}\npseudorandom) and reducing it to a partitioned collection of $2$-XOR instances.\nWe analyze these subinstances using a carefully chosen quadratic form as a\nproxy, which in turn is bounded via a combination of spectral methods and\nsemidefinite programming. The analysis of our spectral bounds relies only on an\noff-the-shelf matrix Bernstein inequality. Even for the purely random case,\nthis leads to a shorter proof compared to the ones in the literature that rely\non problem-specific trace-moment computations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 03:01:39 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Abascal", "Jackson", ""], ["Guruswami", "Venkatesan", ""], ["Kothari", "Pravesh K.", ""]]}, {"id": "2009.08353", "submitter": "Astrid Pieterse", "authors": "Hubie Chen, Bart M. P. Jansen, Karolina Okrasa, Astrid Pieterse,\n  Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Sparsification Lower Bounds for List $H$-Coloring", "comments": "Accepted to ISAAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the List $H$-Coloring problem, the generalization of graph\ncoloring that asks whether an input graph $G$ admits a homomorphism to the\nundirected graph $H$ (possibly with loops), such that each vertex $v \\in V(G)$\nis mapped to a vertex on its list $L(v) \\subseteq V(H)$. An important result by\nFeder, Hell, and Huang [JGT 2003] states that List $H$-Coloring is\npolynomial-time solvable if $H$ is a so-called bi-arc graph, and NP-complete\notherwise. We investigate the NP-complete cases of the problem from the\nperspective of polynomial-time sparsification: can an $n$-vertex instance be\nefficiently reduced to an equivalent instance of bitsize $O(n^{2-\\varepsilon})$\nfor some $\\varepsilon > 0$? We prove that if $H$ is not a bi-arc graph, then\nList $H$-Coloring does not admit such a sparsification algorithm unless $NP\n\\subseteq coNP/poly$. Our proofs combine techniques from kernelization lower\nbounds with a study of the structure of graphs $H$ which are not bi-arc graphs.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:03:24 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Chen", "Hubie", ""], ["Jansen", "Bart M. P.", ""], ["Okrasa", "Karolina", ""], ["Pieterse", "Astrid", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "2009.08360", "submitter": "Ronald de Wolf", "authors": "Adam Izdebski and Ronald de Wolf", "title": "Improved Quantum Boosting", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a general method to convert a weak learner (which generates\nhypotheses that are just slightly better than random) into a strong learner\n(which generates hypotheses that are much better than random). Recently,\nArunachalam and Maity gave the first quantum improvement for boosting, by\ncombining Freund and Schapire's AdaBoost algorithm with a quantum algorithm for\napproximate counting. Their booster is faster than classical boosting as a\nfunction of the VC-dimension of the weak learner's hypothesis class, but worse\nas a function of the quality of the weak learner. In this paper we give a\nsubstantially faster and simpler quantum boosting algorithm, based on\nServedio's SmoothBoost algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:16:42 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Izdebski", "Adam", ""], ["de Wolf", "Ronald", ""]]}, {"id": "2009.08634", "submitter": "Guy Van den Broeck", "authors": "Guy Van den Broeck, Anton Lykov, Maximilian Schleich, Dan Suciu", "title": "On the Tractability of SHAP Explanations", "comments": "Proceedings of the 35th AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SHAP explanations are a popular feature-attribution mechanism for explainable\nAI. They use game-theoretic notions to measure the influence of individual\nfeatures on the prediction of a machine learning model. Despite a lot of recent\ninterest from both academia and industry, it is not known whether SHAP\nexplanations of common machine learning models can be computed efficiently. In\nthis paper, we establish the complexity of computing the SHAP explanation in\nthree important settings. First, we consider fully-factorized data\ndistributions, and show that the complexity of computing the SHAP explanation\nis the same as the complexity of computing the expected value of the model.\nThis fully-factorized setting is often used to simplify the SHAP computation,\nyet our results show that the computation can be intractable for commonly used\nmodels such as logistic regression. Going beyond fully-factorized\ndistributions, we show that computing SHAP explanations is already intractable\nfor a very simple setting: computing SHAP explanations of trivial classifiers\nover naive Bayes distributions. Finally, we show that even computing SHAP over\nthe empirical distribution is #P-hard.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 05:48:15 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 00:41:39 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Broeck", "Guy Van den", ""], ["Lykov", "Anton", ""], ["Schleich", "Maximilian", ""], ["Suciu", "Dan", ""]]}, {"id": "2009.08751", "submitter": "Marcel A. Haddad", "authors": "Marc Demange, Marcel A. Haddad, C\\'ecile Murat", "title": "Hardness and approximation of the Probabilistic p-Center problem under\n  Pressure", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Probabilistic p-Center problem under Pressure (Min PpCP) is a variant of\nthe usual p-Center problem we recently introduced in the context of wildfire\nmanagement. The problem is to locate p shelters minimizing the maximum distance\npeople will have to cover to reach the closest accessible shelter in case of\nfire. The landscape is divided into zones and is modeled as an edge-weighted\ngraph with vertices corresponding to zones and edges corresponding to direct\nconnections between two adjacent zones. The risk associated with fire outbreaks\nis modeled using a finite set of fire scenarios. Each scenario corresponds to a\nfire outbreak on a single zone (i.e., on a vertex) with the main consequence of\nmodifying evacuation paths in two ways. First, an evacuation path cannot pass\nthrough the vertex on fire. Second, the fact that someone close to the fire may\nnot take rational decisions when selecting a direction to escape is modeled\nusing new kinds of evacuation paths. In this paper, for a given instance of Min\nPpCP defined by an edge-weighted graph G=(V,E,L) and an integer p, we\ncharacterize the set of feasible solutions of Min PpCP. We prove that Min PpCP\ncannot be approximated with a ratio less than 56/55 on subgrids (subgraphs of\ngrids) of degree at most 3. Then, we propose some approximation results for Min\nPpCP. These results require approximation results for two variants of the\n(deterministic) Min p-Center problem called Min MAC p-Center and Min Partial\np-Center.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 11:19:10 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 10:50:40 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Demange", "Marc", ""], ["Haddad", "Marcel A.", ""], ["Murat", "C\u00e9cile", ""]]}, {"id": "2009.08866", "submitter": "Aritra Sarkar", "authors": "Aritra Sarkar, Koen Bertels", "title": "ACSS-q: Algorithmic complexity for short strings via quantum accelerated\n  approach", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.ET cs.FL q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this research we present a quantum circuit for estimating algorithmic\ncomplexity using the coding theorem method. This accelerates inferring\nalgorithmic structure in data for discovering causal generative models. The\ncomputation model is restricted in time and space resources to make it\ncomputable in approximating the target metrics. The quantum circuit design\nbased on our earlier work that allows executing a superposition of automata is\npresented. As a use-case, an application framework for protein-protein\ninteraction ontology based on algorithmic complexity is proposed. Using\nsmall-scale quantum computers, this has the potential to enhance the results of\nclassical block decomposition method towards bridging the causal gap in entropy\nbased methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:41:41 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Sarkar", "Aritra", ""], ["Bertels", "Koen", ""]]}, {"id": "2009.08871", "submitter": "EPTCS", "authors": "Ronny Tredup (Universit\\\"at Rostock), Evgeny Erofeev (Universit\\\"at\n  Oldenburg)", "title": "On the Parameterized Complexity of Synthesizing Boolean Petri Nets With\n  Restricted Dependency", "comments": "In Proceedings ICE 2020, arXiv:2009.07628. arXiv admin note:\n  substantial text overlap with arXiv:2007.12372", "journal-ref": "EPTCS 324, 2020, pp. 78-95", "doi": "10.4204/EPTCS.324.7", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling of real-world systems with Petri nets allows to benefit from their\ngeneric concepts of parallelism, synchronisation and conflict, and obtain a\nconcise yet expressive system representation. Algorithms for synthesis of a net\nfrom a sequential specification enable the well-developed theory of Petri nets\nto be applied for the system analysis through a net model. The problem of\n$\\tau$-synthesis consists in deciding whether a given directed labeled graph\n$A$ is isomorphic to the reachability graph of a Boolean Petri net $N$ of type\n$\\tau$. In case of a positive decision, $N$ should be constructed. For many\nBoolean types of nets, the problem is NP-complete. This paper deals with a\nspecial variant of $\\tau$-synthesis that imposes restrictions for the target\nnet $N$: we investigate dependency $d$-restricted tau-synthesis (DR$\\tau$S)\nwhere each place of $N$ can influence and be influenced by at most d\ntransitions. For a type $\\tau$, if tau-synthesis is NP-complete then DR$\\tau$S\nis also NP-complete. In this paper, we show that DR$\\tau$S parameterized by $d$\nis in XP. Furthermore, we prove that it is W[2]-hard, for many Boolean types\nthat allow unconditional interactions set and reset.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:48:50 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Tredup", "Ronny", "", "Universit\u00e4t Rostock"], ["Erofeev", "Evgeny", "", "Universit\u00e4t\n  Oldenburg"]]}, {"id": "2009.08903", "submitter": "Benjamin Merlin Bumpus", "authors": "Benjamin Merlin Bumpus, Kitty Meeks, William Pettersson", "title": "Directed branch-width: A directed analogue of tree-width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new digraph width measure called directed branch-width. To do\nthis, we generalize a characterization of graph classes of bounded tree-width\nin terms of their line graphs to digraphs.\n  Under parameterizations by directed branch-width we obtain linear time\nalgorithms for many problems, such as directed Hamilton path and Max-Cut, which\nare hard when parameterized by other known directed width measures. More\ngenerally, we obtain an algorithmic meta-theorem for the model-checking problem\nfor a restricted variant of MSO_2-logic on classes of bounded directed\nbranch-width.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:49:05 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Bumpus", "Benjamin Merlin", ""], ["Meeks", "Kitty", ""], ["Pettersson", "William", ""]]}, {"id": "2009.09460", "submitter": "C Ramya", "authors": "C.Ramya", "title": "Recent Progress on Matrix Rigidity -- A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of matrix rigidity was introduced by Valiant(independently by\nGrigoriev) in the context of computing linear transformations. A matrix is\nrigid if it is far(in terms of Hamming distance) from any matrix of low rank.\nAlthough we know rigid matrices exist, obtaining explicit constructions of\nrigid matrices have remained a long-standing open question. This decade has\nseen tremendous progress towards understanding matrix rigidity. In the past,\nseveral matrices such as Hadamard matrices and Fourier matrices were\nconjectured to be rigid. Very recently, many of these matrices were shown to\nhave low rigidity. Further, several explicit constructions of rigid matrices in\nclasses such as $E$ and $P^{NP}$ were obtained recently. Among other things,\nmatrix rigidity has found striking connections to areas as disparate as\ncommunication complexity, data structure lower bounds and error-correcting\ncodes. In this survey, we present a selected set of results that highlight\nrecent progress on matrix rigidity and its remarkable connections to other\nareas in theoretical computer science.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 15:53:10 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ramya", "C.", ""]]}, {"id": "2009.09623", "submitter": "Emmanouil Zampetakis", "authors": "Constantinos Daskalakis and Stratis Skoulakis and Manolis Zampetakis", "title": "The Complexity of Constrained Min-Max Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its important applications in Machine Learning, min-max optimization\nof nonconvex-nonconcave objectives remains elusive. Not only are there no known\nfirst-order methods converging even to approximate local min-max points, but\nthe computational complexity of identifying them is also poorly understood. In\nthis paper, we provide a characterization of the computational complexity of\nthe problem, as well as of the limitations of first-order methods in\nconstrained min-max optimization problems with nonconvex-nonconcave objectives\nand linear constraints.\n  As a warm-up, we show that, even when the objective is a Lipschitz and smooth\ndifferentiable function, deciding whether a min-max point exists, in fact even\ndeciding whether an approximate min-max point exists, is NP-hard. More\nimportantly, we show that an approximate local min-max point of large enough\napproximation is guaranteed to exist, but finding one such point is\nPPAD-complete. The same is true of computing an approximate fixed point of\nGradient Descent/Ascent.\n  An important byproduct of our proof is to establish an unconditional hardness\nresult in the Nemirovsky-Yudin model. We show that, given oracle access to some\nfunction $f : P \\to [-1, 1]$ and its gradient $\\nabla f$, where $P \\subseteq\n[0, 1]^d$ is a known convex polytope, every algorithm that finds a\n$\\varepsilon$-approximate local min-max point needs to make a number of queries\nthat is exponential in at least one of $1/\\varepsilon$, $L$, $G$, or $d$, where\n$L$ and $G$ are respectively the smoothness and Lipschitzness of $f$ and $d$ is\nthe dimension. This comes in sharp contrast to minimization problems, where\nfinding approximate local minima in the same setting can be done with Projected\nGradient Descent using $O(L/\\varepsilon)$ many queries. Our result is the first\nto show an exponential separation between these two fundamental optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 05:54:12 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Skoulakis", "Stratis", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "2009.09801", "submitter": "Michael Thomazo", "authors": "Meghyn Bienvenu (UB, CNRS, Bordeaux INP, LaBRI), Quentin Mani\\`ere\n  (UB, CNRS, Bordeaux INP, LaBRI), Micha\\\"el Thomazo (VALDA )", "title": "Answering Counting Queries over DL-Lite Ontologies", "comments": null, "journal-ref": "Twenty-Ninth International Joint Conference on Artificial\n  Intelligence (IJCAI 2020), 2020, Yokohama, Japan", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-mediated query answering (OMQA) is a promising approach to data\naccess and integration that has been actively studied in the knowledge\nrepresentation and database communities for more than a decade. The vast\nmajority of work on OMQA focuses on conjunctive queries, whereas more\nexpressive queries that feature counting or other forms of aggregation remain\nlargely unex-plored. In this paper, we introduce a general form of counting\nquery, relate it to previous proposals, and study the complexity of answering\nsuch queries in the presence of DL-Lite ontologies. As it follows from existing\nwork that query answering is intractable and often of high complexity, we\nconsider some practically relevant restrictions, for which we establish\nimproved complexity bounds.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 11:10:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bienvenu", "Meghyn", "", "UB, CNRS, Bordeaux INP, LaBRI"], ["Mani\u00e8re", "Quentin", "", "UB, CNRS, Bordeaux INP, LaBRI"], ["Thomazo", "Micha\u00ebl", "", "VALDA"]]}, {"id": "2009.09971", "submitter": "Mehdi Khosravian Ghadikolaei", "authors": "Louis Dublois, Tesshu Hanaka, Mehdi Khosravian Ghadikolaei, Michael\n  Lampis, Nikolaos Melissinos", "title": "(In)approximability of Maximum Minimal FVS", "comments": "31 pages, 2 figures, ISAAC 2020, Preprint submitted to Journal of\n  Computer and System Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximability of the NP-complete \\textsc{Maximum Minimal\nFeedback Vertex Set} problem. Informally, this natural problem seems to lie in\nan intermediate space between two more well-studied problems of this type:\n\\textsc{Maximum Minimal Vertex Cover}, for which the best achievable\napproximation ratio is $\\sqrt{n}$, and \\textsc{Upper Dominating Set}, which\ndoes not admit any $n^{1-\\epsilon}$ approximation. We confirm and quantify this\nintuition by showing the first non-trivial polynomial time approximation for\n\\textsc{Max Min FVS} with a ratio of $O(n^{2/3})$, as well as a matching\nhardness of approximation bound of $n^{2/3-\\epsilon}$, improving the previous\nknown hardness of $n^{1/2-\\epsilon}$. The approximation algorithm also gives a\ncubic kernel when parameterized by the solution size. Along the way, we also\nobtain an $O(\\Delta)$-approximation and show that this is asymptotically best\npossible, and we improve the bound for which the problem is NP-hard from\n$\\Delta\\ge 9$ to $\\Delta\\ge 6$.\n  Having settled the problem's approximability in polynomial time, we move to\nthe context of super-polynomial time. We devise a generalization of our\napproximation algorithm which, for any desired approximation ratio $r$,\nproduces an $r$-approximate solution in time $n^{O(n/r^{3/2})}$. This\ntime-approximation trade-off is essentially tight: we show that under the ETH,\nfor any ratio $r$ and $\\epsilon>0$, no algorithm can $r$-approximate this\nproblem in time $n^{O((n/r^{3/2})^{1-\\epsilon})}$, hence we precisely\ncharacterize the approximability of the problem for the whole spectrum between\npolynomial and sub-exponential time, up to an arbitrarily small constant in the\nsecond exponent.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:54:48 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 19:55:14 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Dublois", "Louis", ""], ["Hanaka", "Tesshu", ""], ["Ghadikolaei", "Mehdi Khosravian", ""], ["Lampis", "Michael", ""], ["Melissinos", "Nikolaos", ""]]}, {"id": "2009.10088", "submitter": "Jacob Biamonte", "authors": "Jacob Biamonte", "title": "On the Theory of Modern Quantum Algorithms", "comments": "192 pages, Dissertation draft submitted for the degree of Doctor of\n  Physical and Mathematical Sciences (a post-doctoral degree given to reflect\n  second advanced research qualifications or higher doctorates---see ISCED\n  2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation unites variational computation with results and techniques\nappearing in the theory of ground state computation. It should be readable by\ngraduate students.\n  The topics covered include: Ising model reductions, stochastic versus quantum\nprocesses on graphs, quantum gates and circuits as tensor networks, variational\nquantum algorithms and Hamiltonian gadgets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 18:00:02 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Biamonte", "Jacob", ""]]}, {"id": "2009.10677", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek, Neng Huang, Aaron Potechin, Uri Zwick", "title": "On the Mysteries of MAX NAE-SAT", "comments": "40 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAX NAE-SAT is a natural optimization problem, closely related to its\nbetter-known relative MAX SAT. The approximability status of MAX NAE-SAT is\nalmost completely understood if all clauses have the same size $k$, for some\n$k\\ge 2$. We refer to this problem as MAX NAE-$\\{k\\}$-SAT. For $k=2$, it is\nessentially the celebrated MAX CUT problem. For $k=3$, it is related to the MAX\nCUT problem in graphs that can be fractionally covered by triangles. For $k\\ge\n4$, it is known that an approximation ratio of $1-\\frac{1}{2^{k-1}}$, obtained\nby choosing a random assignment, is optimal, assuming $P\\ne NP$. For every\n$k\\ge 2$, an approximation ratio of at least $\\frac{7}{8}$ can be obtained for\nMAX NAE-$\\{k\\}$-SAT. There was some hope, therefore, that there is also a\n$\\frac{7}{8}$-approximation algorithm for MAX NAE-SAT, where clauses of all\nsizes are allowed simultaneously.\n  Our main result is that there is no $\\frac{7}{8}$-approximation algorithm for\nMAX NAE-SAT, assuming the unique games conjecture (UGC). In fact, even for\nalmost satisfiable instances of MAX NAE-$\\{3,5\\}$-SAT (i.e., MAX NAE-SAT where\nall clauses have size $3$ or $5$), the best approximation ratio that can be\nachieved, assuming UGC, is at most $\\frac{3(\\sqrt{21}-4)}{2}\\approx 0.8739$.\nUsing calculus of variations, we extend the analysis of O'Donnell and Wu for\nMAX CUT to MAX NAE-$\\{3\\}$-SAT. We obtain an optimal algorithm, assuming UGC,\nfor MAX NAE-$\\{3\\}$-SAT, slightly improving on previous algorithms. The\napproximation ratio of the new algorithm is $\\approx 0.9089$.\n  We complement our theoretical results with some experimental results. We\ndescribe an approximation algorithm for almost satisfiable instances of MAX\nNAE-$\\{3,5\\}$-SAT with a conjectured approximation ratio of 0.8728, and an\napproximation algorithm for almost satisfiable instances of MAX NAE-SAT with a\nconjectured approximation ratio of 0.8698.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:55:28 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Huang", "Neng", ""], ["Potechin", "Aaron", ""], ["Zwick", "Uri", ""]]}, {"id": "2009.10880", "submitter": "EPTCS", "authors": "Lauri Hella, Antti Kuusisto, Raine R\\\"onnholm", "title": "Bounded Game-Theoretic Semantics for Modal Mu-Calculus and Some Variants", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360. The official\n  conference version of the extended preprint arXiv:1706.00753", "journal-ref": "EPTCS 326, 2020, pp. 82-96", "doi": "10.4204/EPTCS.326.6", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new game-theoretic semantics (GTS) for the modal mu-calculus.\nOur so-called bounded GTS replaces parity games with alternative evaluation\ngames where only finite paths arise; infinite paths are not needed even when\nthe considered transition system is infinite. The novel games offer alternative\napproaches to various constructions in the framework of the mu-calculus. For\nexample, they have already been successfully used as a basis for an approach\nleading to a natural formula size game for the logic. While our main focus is\nintroducing the new GTS, we also consider some applications to demonstrate its\nuses. For example, we consider a natural model transformation procedure that\nreduces model checking games to checking a single, fixed formula in the\nconstructed models, and we also use the GTS to identify new alternative\nvariants of the mu-calculus with PTime model checking.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:25:12 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hella", "Lauri", ""], ["Kuusisto", "Antti", ""], ["R\u00f6nnholm", "Raine", ""]]}, {"id": "2009.10981", "submitter": "Giovanni Viglietta", "authors": "Kwon Kham Sai, Ryuhei Uehara, and Giovanni Viglietta", "title": "Cyclic Shift Problems on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new reconfiguration problem inspired by classic mechanical\npuzzles: a colored token is placed on each vertex of a given graph; we are also\ngiven a set of distinguished cycles on the graph. We are tasked with\nrearranging the tokens from a given initial configuration to a final one by\nusing cyclic shift operations along the distinguished cycles. We first\ninvestigate a large class of graphs, which generalizes several classic puzzles,\nand we give a characterization of which final configurations can be reached\nfrom a given initial configuration. Our proofs are constructive, and yield\nefficient methods for shifting tokens to reach the desired configurations. On\nthe other hand, when the goal is to find a shortest sequence of shifting\noperations, we show that the problem is NP-hard, even for puzzles with tokens\nof only two different colors.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 07:45:45 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Sai", "Kwon Kham", ""], ["Uehara", "Ryuhei", ""], ["Viglietta", "Giovanni", ""]]}, {"id": "2009.11391", "submitter": "J. M. Landsberg", "authors": "Austin Conner, Hang Huang, and J. M. Landsberg", "title": "Bad and good news for Strassen's laser method: Border rank of the 3x3\n  permanent and strict submultiplicativity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the border ranks of tensors that could potentially advance the\nknown upper bound for the exponent $\\omega$ of matrix multiplication. The\nKronecker square of the small $q=2$ Coppersmith-Winograd tensor equals the\n$3\\times 3$ permanent, and could potentially be used to show $\\omega=2$. We\nprove the negative result for complexity theory that its border rank is $16$,\nresolving a longstanding problem. Regarding its $q=4$ skew cousin in $\nC^5\\otimes C^5\\otimes C^5$, which could potentially be used to prove\n$\\omega\\leq 2.11$, we show the border rank of its Kronecker square is at most\n$42$, a remarkable sub-multiplicativity result, as the square of its border\nrank is $64$. We also determine moduli spaces $\\underline{VSP}$ for the small\nCoppersmith-Winograd tensors.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 21:40:15 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Conner", "Austin", ""], ["Huang", "Hang", ""], ["Landsberg", "J. M.", ""]]}, {"id": "2009.11514", "submitter": "Yanyi Liu", "authors": "Yanyi Liu, Rafael Pass", "title": "On One-way Functions and Kolmogorov Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the equivalence of two fundamental problems in the theory of\ncomputing. For every polynomial $t(n)\\geq (1+\\varepsilon)n, \\varepsilon>0$, the\nfollowing are equivalent:\n  - One-way functions exists (which in turn is equivalent to the existence of\nsecure private-key encryption schemes, digital signatures, pseudorandom\ngenerators, pseudorandom functions, commitment schemes, and more);\n  - $t$-time bounded Kolmogorov Complexity, $K^t$, is mildly hard-on-average\n(i.e., there exists a polynomial $p(n)>0$ such that no PPT algorithm can\ncompute $K^t$, for more than a $1-\\frac{1}{p(n)}$ fraction of $n$-bit strings).\n  In doing so, we present the first natural, and well-studied, computational\nproblem characterizing the feasibility of the central private-key primitives\nand protocols in Cryptography.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 06:50:27 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Liu", "Yanyi", ""], ["Pass", "Rafael", ""]]}, {"id": "2009.11622", "submitter": "Sebastian Bala", "authors": "Sebastian Bala and Andrzej Kozik", "title": "On Tractability of Ulams Metric in Highier Dimensions and Dually Related\n  Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ulam's metric is the minimal number of moves consisting in removal of one\nelement from a permutation and its subsequent reinsertion in different place,\nto go between two given permutations. Thet elements that are not moved create\nlongest common subsequence of permutations. Aldous and Diaconis, in their\npaper, pointed that Ulam's metric had been introduced in the context of\nquestions concerning sorting and tossing cards. In this paper we define and\nstudy Ulam's metric in highier dimensions: for dimension one the considered\nobject is a pair of permutations, for dimension k it is a pair of k-tuples of\npermutations. Over encodings by k-tuples of permutations we define two dually\nrelated hierarchies. Our very first motivation come from Murata at al. paper,\nin which pairs of permutations were used as representation of topological\nrelation between rectangles packed into minimal area with application to VLSI\nphysical design. Our results concern hardness, approximability, and\nparametrized complexity inside the hierarchies.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 12:02:34 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 15:27:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bala", "Sebastian", ""], ["Kozik", "Andrzej", ""]]}, {"id": "2009.11642", "submitter": "Pawe{\\l} Rz\\k{a}\\.zewski", "authors": "Marta Piecyk and Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Fine-grained complexity of the list homomorphism problem: feedback\n  vertex set and cutwidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For graphs $G,H$, a homomorphism from $G$ to $H$ is an edge-preserving\nmapping from $V(G)$ to $V(H)$. In the list homomorphism problem, denoted by\n\\textsc{LHom}($H$), we are given a graph $G$ and lists $L: V(G) \\to 2^{V(H)}$,\nand we ask for a homomorphism from $G$ to $H$ which additionally respects the\nlists $L$.\n  Very recently Okrasa, Piecyk, and Rz\\k{a}\\.zewski [ESA 2020] defined an\ninvariant $i^*(H)$ and proved that under the SETH $\\mathcal{O}^*\\left\n(i^*(H)^{\\textrm{tw}(G)}\\right)$ is the tight complexity bound for\n\\textsc{LHom}($H$), parameterized by the treewidth $\\textrm{tw}(G)$ of the\ninstance graph $G$. We study the complexity of the problem under dirretent\nparameterizations. As the first result, we show that $i^*(H)$ is also the right\ncomplexity base if the parameter is the size of a minimum feedback vertex set\nof $G$.\n  Then we turn our attention to a parameterization by the cutwidth\n$\\textrm{ctw}(G)$ of $G$. Jansen and Nederlof~[ESA 2018] showed that\n\\textsc{List $k$-Coloring} (i.e., \\textsc{LHom}($K_k$)) can be solved in time\n$\\mathcal{O}^*\\left (c^{\\textrm{ctw}(G)}\\right)$ where $c$ does not depend on\n$k$. Jansen asked if this behavior extends to graph homomorphisms. As the main\nresult of the paper, we answer the question in the negative. We define a new\ngraph invariant $mim^*(H)$ and prove that \\textsc{LHom}($H$) problem cannot be\nsolved in time $\\mathcal{O}^*\\left\n((mim^*(H)-\\varepsilon)^{\\textrm{ctw}(G)}\\right)$ for any $\\varepsilon >0$,\nunless the SETH fails. This implies that there is no $c$, such that for every\nodd cycle the non-list version of the problem can be solved in time\n$\\mathcal{O}^*\\left (c^{\\textrm{ctw}(G)} \\right)$.\n  Finally, we generalize the algorithm of Jansen and Nederlof, so that it can\nbe used to solve \\textsc{LHom}($H$) for every graph $H$; its complexity depends\non $\\textrm{ctw}(G)$ and another invariant of $H$, which is constant for\ncliques.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 12:53:18 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Piecyk", "Marta", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "2009.11840", "submitter": "Martin Kouteck\\'y", "authors": "Martin Kouteck\\'y and Johannes Zink", "title": "Complexity of Scheduling Few Types of Jobs on Related and Unrelated\n  Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of scheduling jobs to machines while minimizing the total makespan,\nthe sum of weighted completion times, or a norm of the load vector, are among\nthe oldest and most fundamental tasks in combinatorial optimization. Since all\nof these problems are in general NP-hard, much attention has been given to the\nregime where there is only a small number $k$ of job types, but possibly the\nnumber of jobs $n$ is large; this is the few job types, high-multiplicity\nregime. Despite many positive results, the hardness boundary of this regime was\nnot understood until now.\n  We show that makespan minimization on uniformly related machines\n($Q|HM|C_{\\max}$) is NP-hard already with $6$ job types, and that the related\nCutting Stock problem is NP-hard already with $8$ item types. For the more\ngeneral unrelated machines model ($R|HM|C_{\\max}$), we show that if either the\nlargest job size $p_{\\max}$, or the number of jobs $n$ are polynomially bounded\nin the instance size $|I|$, there are algorithms with complexity\n$|I|^{\\textrm{poly}(k)}$. Our main result is that this is unlikely to be\nimproved, because $Q||C_{\\max}$ is W[1]-hard parameterized by $k$ already when\n$n$, $p_{\\max}$, and the numbers describing the speeds are polynomial in $|I|$;\nthe same holds for $R|HM|C_{\\max}$ (without speeds) when the job sizes matrix\nhas rank $2$. Our positive and negative results also extend to the objectives\n$\\ell_2$-norm minimization of the load vector and, partially, sum of weighted\ncompletion times $\\sum w_j C_j$.\n  Along the way, we answer affirmatively the question whether makespan\nminimization on identical machines ($P||C_{\\max}$) is fixed-parameter tractable\nparameterized by $k$, extending our understanding of this fundamental problem.\nTogether with our hardness results for $Q||C_{\\max}$ this implies that the\ncomplexity of $P|HM|C_{\\max}$ is the only remaining open case.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:38:31 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kouteck\u00fd", "Martin", ""], ["Zink", "Johannes", ""]]}, {"id": "2009.12184", "submitter": "Tesshu Hanaka", "authors": "Tesshu Hanaka, Yasuaki Kobayashi, Yusuke Kobayashi, Tsuyoshi Yagita", "title": "Finding a Maximum Minimal Separator: Graph Classes and Fixed-Parameter\n  Tractability", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding a maximum cardinality minimal separator of a\ngraph. This problem is known to be NP-hard even for bipartite graphs. In this\npaper, we strengthen this hardness by showing that for planar bipartite graphs,\nthe problem remains NP-hard. Moreover, for co-bipartite graphs and for line\ngraphs, the problem also remains NP-hard. On the positive side, we give an\nalgorithm deciding whether an input graph has a minimal separator of size at\nleast $k$ that runs in time $2^{O(k)}n^{O(1)}$. We further show that a\nsubexponential parameterized algorithm does not exist unless the Exponential\nTime Hypothesis (ETH) fails. Finally, we discuss a lower bound for polynomial\nkernelizations of this problem.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:40:03 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Hanaka", "Tesshu", ""], ["Kobayashi", "Yasuaki", ""], ["Kobayashi", "Yusuke", ""], ["Yagita", "Tsuyoshi", ""]]}, {"id": "2009.12225", "submitter": "Liam Jordon", "authors": "Liam Jordon and Philippe Moser", "title": "Pebble-Depth", "comments": "Typos corrected and tidied up proofs further from previous versions -\n  results unchanged. arXiv admin note: text overlap with arXiv:2009.04821", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new formulation of Bennett's logical depth based\non pebble transducers. This notion is defined based on the difference between\nthe minimal length descriptional complexity of strings from the perspective of\nfinite-state transducers and pebble transducers. Our notion of pebble-depth\nsatisfies the three fundamental properties of depth: i.e. easy sequences and\nrandom sequences are not deep, and the existence of a slow growth law. We also\ncompare pebble-depth to other depth notions based on finite-state transducers,\npushdown compressors and the Lempel-Ziv $78$ compression algorithm. We first\ndemonstrate how there exists a normal pebble-deep sequence even though there is\nno normal finite-state-deep sequence. We next build a sequence which has a\npebble-depth level of roughly $1$, a pushdown-depth level of roughly $1/2$ and\na finite-state-depth level of roughly $0$. We then build a sequence which has\npebble-depth level of roughly $1/2$ and Lempel-Ziv-depth level of roughly $0$.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:10:20 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 11:19:47 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 14:06:38 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Jordon", "Liam", ""], ["Moser", "Philippe", ""]]}, {"id": "2009.12291", "submitter": "Jeremie Leguay M.", "authors": "Yacine Al-Najjar, and Walid Ben-Ameur and Jeremie Leguay", "title": "On the Approximability of Robust Network Design", "comments": "Preprint accepted to Elsevier Theoretical Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the dynamic nature of traffic, we investigate the variant of robust\nnetwork design where we have to determine the capacity to reserve on each link\nso that each demand vector belonging to a polyhedral set can be routed. The\nobjective is either to minimize congestion or a linear cost. Routing is assumed\nto be fractional and dynamic (i.e., dependent on the current traffic vector).\nWe first prove that the robust network design problem with minimum congestion\ncannot be approximated within any constant factor. Then, using the ETH\nconjecture, we get a $\\Omega(\\frac{\\log n}{\\log \\log n})$ lower bound for the\napproximability of this problem. This implies that the well-known $O(\\log n)$\napproximation ratio established by R\\\"{a}cke in 2008 is tight. Using Lagrange\nrelaxation, we obtain a new proof of the $O(\\log n)$ approximation. An\nimportant consequence of the Lagrange-based reduction and our inapproximability\nresults is that the robust network design problem with linear reservation cost\ncannot be approximated within any constant ratio. This answers a long-standing\nopen question of Chekuri (2007). We also give another proof of the result of\nGoyal\\&al (2009) stating that the optimal linear cost under static routing can\nbe $\\Omega(\\log n)$ more expensive than the cost obtained under dynamic\nrouting. Finally, we show that even if only two given paths are allowed for\neach commodity, the robust network design problem with minimum congestion or\nlinear cost is hard to approximate within some constant.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:29:59 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 08:40:48 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 20:44:16 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Al-Najjar", "Yacine", ""], ["Ben-Ameur", "Walid", ""], ["Leguay", "Jeremie", ""]]}, {"id": "2009.12982", "submitter": "John Wright", "authors": "Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, Henry Yuen", "title": "Quantum soundness of the classical low individual degree test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low degree tests play an important role in classical complexity theory,\nserving as basic ingredients in foundational results such as $\\mathsf{MIP} =\n\\mathsf{NEXP}$ [BFL91] and the PCP theorem [AS98,ALM+98]. Over the last ten\nyears, versions of these tests which are sound against quantum provers have\nfound increasing applications to the study of nonlocal games and the complexity\nclass~$\\mathsf{MIP}^*$. The culmination of this line of work is the result\n$\\mathsf{MIP}^* = \\mathsf{RE}$ [arXiv:2001.04383]. One of the key ingredients\nin the first reported proof of $\\mathsf{MIP}^* = \\mathsf{RE}$ is a two-prover\nvariant of the low degree test, initially shown to be sound against multiple\nquantum provers in [arXiv:1302.1242]. Unfortunately a mistake was recently\ndiscovered in the latter result, invalidating the main result of\n[arXiv:1302.1242] as well as its use in subsequent works, including\n[arXiv:2001.04383]. We analyze a variant of the low degree test called the low\nindividual degree test. Our main result is that the two-player version of this\ntest is sound against quantum provers. This soundness result is sufficient to\nre-derive several bounds on~$\\mathsf{MIP}^*$ that relied on [arXiv:1302.1242],\nincluding $\\mathsf{MIP}^* = \\mathsf{RE}$.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 23:45:58 GMT"}], "update_date": "2020-11-21", "authors_parsed": [["Ji", "Zhengfeng", ""], ["Natarajan", "Anand", ""], ["Vidick", "Thomas", ""], ["Wright", "John", ""], ["Yuen", "Henry", ""]]}, {"id": "2009.13090", "submitter": "Arash Rafiey", "authors": "Tomas Feder, Jeff Kinne, Ashwin Murali, Arash Rafiey", "title": "Digraph homomorphism problem and weak near unanimity polymorphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding a homomorphism from an input digraph $G$\nto a fixed digraph $H$. We show that if $H$ admits a weak near unanimity\npolymorphism $\\phi$ then deciding whether $G$ admits a homomorphism to $H$\n(HOM($H$)) is polynomial-time solvable. This gives proof of the dichotomy\nconjecture (now dichotomy theorem) by Feder and Vardi. Our approach is\ncombinatorial, and it is simpler than the two algorithms found by Bulatov and\nZhuk. We have implemented our algorithm and show some experimental results. We\nuse our algorithm together with the recent result [38] for recognition of\nMaltsev polymorphisms and decide in polynomial time if a given relational\nstructure $\\mathcal{R}$ admits a weak near unanimity polymorphism.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 06:17:36 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 01:43:02 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Feder", "Tomas", ""], ["Kinne", "Jeff", ""], ["Murali", "Ashwin", ""], ["Rafiey", "Arash", ""]]}, {"id": "2009.13184", "submitter": "Stephan Kreutzer", "authors": "Archontia C. Giannopoulou, Ken-ichi Kawarabayashi, Stephan Kreutzer,\n  O-joung Kwon", "title": "The canonical directed tree decomposition and its applications to the\n  directed disjoint paths problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The canonical tree-decomposition theorem, given by Robertson and Seymour in\ntheir seminal graph minors series, turns out to be one of the most important\ntool in structural and algorithmic graph theory. In this paper, we provide the\ncanonical tree decomposition theorem for digraphs. More precisely, we construct\ndirected tree-decompositions of digraphs that distinguish all their tangles of\norder $k$, for any fixed integer $k$, in polynomial time. As an application of\nthis canonical tree-decomposition theorem, we provide the following result for\nthe directed disjoint paths problem:\n  For every fixed $k$ there is a polynomial-time algorithm which, on input $G$,\nand source and terminal vertices $(s_1, t_1), \\dots, (s_k, t_k)$, either\n  1. determines that there is no set of pairwise vertex-disjoint paths\nconnecting each source $s_i$ to its terminal $t_i$, or\n  2.finds a half-integral solution, i.e., outputs paths $P_1, \\dots, P_k$ such\nthat $P_i$ links $s_i$ to $t_i$, so that every vertex of the graph is contained\nin at most two paths. Given known hardness results for the directed disjoint\npaths problem, our result cannot be improved for general digraphs, neither to\nfixed-parameter tractability nor to fully vertex-disjoint directed paths. As\nfar as we are aware, this is the first time to obtain a tractable result for\nthe $k$-disjoint paths problem for general digraphs. We expect more\napplications of our canonical tree-decomposition for directed results.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:55:12 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Giannopoulou", "Archontia C.", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Kreutzer", "Stephan", ""], ["Kwon", "O-joung", ""]]}, {"id": "2009.13353", "submitter": "David Purser", "authors": "Christel Baier, Florian Funke, Simon Jantsch, Toghrul Karimov, Engel\n  Lefaucheux, Jo\\\"el Ouaknine, Amaury Pouly, David Purser and Markus A.\n  Whiteland", "title": "Reachability in Dynamical Systems with Rounding", "comments": "To appear at FSTTCS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider reachability in dynamical systems with discrete linear updates,\nbut with fixed digital precision, i.e., such that values of the system are\nrounded at each step. Given a matrix $M \\in \\mathbb{Q}^{d \\times d}$, an\ninitial vector $x\\in\\mathbb{Q}^{d}$, a granularity $g\\in \\mathbb{Q}_+$ and a\nrounding operation $[\\cdot]$ projecting a vector of $\\mathbb{Q}^{d}$ onto\nanother vector whose every entry is a multiple of $g$, we are interested in the\nbehaviour of the orbit $\\mathcal{O}={<}[x], [M[x]],[M[M[x]]],\\dots{>}$, i.e.,\nthe trajectory of a linear dynamical system in which the state is rounded after\neach step. For arbitrary rounding functions with bounded effect, we show that\nthe complexity of deciding point-to-point reachability---whether a given target\n$y \\in\\mathbb{Q}^{d}$ belongs to $\\mathcal{O}$---is PSPACE-complete for\nhyperbolic systems (when no eigenvalue of $M$ has modulus one). We also\nestablish decidability without any restrictions on eigenvalues for several\nnatural classes of rounding functions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:18:44 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Baier", "Christel", ""], ["Funke", "Florian", ""], ["Jantsch", "Simon", ""], ["Karimov", "Toghrul", ""], ["Lefaucheux", "Engel", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Pouly", "Amaury", ""], ["Purser", "David", ""], ["Whiteland", "Markus A.", ""]]}, {"id": "2009.13949", "submitter": "Kishen N Gowda", "authors": "Kishen N. Gowda, Aditya Lonkar, Fahad Panolan, Vraj Patel, Saket\n  Saurabh", "title": "Improved FPT Algorithms for Deletion to Forest-like Structures", "comments": "ISAAC 2020, 36 pages. arXiv admin note: text overlap with\n  arXiv:1906.12298, arXiv:1103.0534 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Feedback Vertex Set problem is undoubtedly one of the most well-studied\nproblems in Parameterized Complexity. In this problem, given an undirected\ngraph $G$ and a non-negative integer $k$, the objective is to test whether\nthere exists a subset $S\\subseteq V(G)$ of size at most $k$ such that $G-S$ is\na forest. After a long line of improvement, recently, Li and Nederlof [SODA,\n2020] designed a randomized algorithm for the problem running in time\n$\\mathcal{O}^{\\star}(2.7^k)$. In the Parameterized Complexity literature,\nseveral problems around Feedback Vertex Set have been studied. Some of these\ninclude Independent Feedback Vertex Set (where the set $S$ should be an\nindependent set in $G$), Almost Forest Deletion and Pseudoforest Deletion. In\nPseudoforest Deletion, each connected component in $G-S$ has at most one cycle\nin it. However, in Almost Forest Deletion, the input is a graph $G$ and\nnon-negative integers $k,\\ell \\in \\mathbb{N}$, and the objective is to test\nwhether there exists a vertex subset $S$ of size at most $k$, such that $G-S$\nis $\\ell$ edges away from a forest. In this paper, using the methodology of Li\nand Nederlof [SODA, 2020], we obtain the current fastest algorithms for all\nthese problems. In particular we obtain following randomized algorithms.\n  1) Independent Feedback Vertex Set can be solved in time\n$\\mathcal{O}^{\\star}(2.7^k)$.\n  2) Pseudo Forest Deletion can be solved in time\n$\\mathcal{O}^{\\star}(2.85^k)$.\n  3) Almost Forest Deletion can be solved in $\\mathcal{O}^{\\star}(\\min\\{2.85^k\n\\cdot 8.54^\\ell,2.7^k \\cdot 36.61^\\ell,3^k \\cdot 1.78^\\ell\\})$.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 19:04:38 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Gowda", "Kishen N.", ""], ["Lonkar", "Aditya", ""], ["Panolan", "Fahad", ""], ["Patel", "Vraj", ""], ["Saurabh", "Saket", ""]]}, {"id": "2009.13989", "submitter": "Christian Aristide Nikolai Beck", "authors": "Christian Beck and Arnulf Jentzen and Thomas Kruse", "title": "Nonlinear Monte Carlo methods with polynomial runtime for\n  high-dimensional iterated nested expectations", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximative calculation of iterated nested expectations is a recurring\nchallenging problem in applications. Nested expectations appear, for example,\nin the numerical approximation of solutions of backward stochastic differential\nequations (BSDEs), in the numerical approximation of solutions of semilinear\nparabolic partial differential equations (PDEs), in statistical physics, in\noptimal stopping problems such as the approximative pricing of American or\nBermudan options, in risk measure estimation in mathematical finance, or in\ndecision-making under uncertainty. Nested expectations which arise in the above\nnamed applications often consist of a large number of nestings. However, the\ncomputational effort of standard nested Monte Carlo approximations for iterated\nnested expectations grows exponentially in the number of nestings and it\nremained an open question whether it is possible to approximately calculate\nmultiply iterated high-dimensional nested expectations in polynomial time. In\nthis article we tackle this problem by proposing and studying a new class of\nfull-history recursive multilevel Picard (MLP) approximation schemes for\niterated nested expectations. In particular, we prove under suitable\nassumptions that these MLP approximation schemes can approximately calculate\nmultiply iterated nested expectations with a computational effort growing at\nmost polynomially in the number of nestings $ K \\in \\mathbb{N} = \\{1, 2, 3,\n\\ldots \\} $, in the problem dimension $ d \\in \\mathbb{N} $, and in the\nreciprocal $\\frac{1}{\\varepsilon}$ of the desired approximation accuracy $\n\\varepsilon \\in (0, \\infty) $.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:20:36 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Beck", "Christian", ""], ["Jentzen", "Arnulf", ""], ["Kruse", "Thomas", ""]]}, {"id": "2009.14191", "submitter": "Klaus Heeger", "authors": "Robert Bredereck, Klaus Heeger, Du\\v{s}an Knop, Rolf Niedermeier", "title": "Multidimensional Stable Roommates with Master List", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the early days of research in algorithms and complexity, the\ncomputation of stable matchings is a core topic. While in the classic setting\nthe goal is to match up two agents (either from different \"gender\" (this is\nStable Marriage) or \"unrestricted\" (this is Stable Roommates)), Knuth [1976]\ntriggered the study of three- or multidimensional cases. Here, we focus on the\nstudy of Multidimensional Stable Roommates, known to be NP-hard since the early\n1990's. Many NP-hardness results, however, rely on very general input instances\nthat do not occur in at least some of the specific application scenarios. With\nthe quest for identifying islands of tractability for Multidimensional Stable\nRoommates, we study the case of master lists. Here, as natural in applications\nwhere agents express their preferences based on \"objective\" scores, one roughly\nspeaking assumes that all agent preferences are \"derived from\" a central master\nlist, implying that the individual agent preferences shall be similar. Master\nlists have been frequently studied in the two-dimensional (classic) stable\nmatching case, but seemingly almost never for the multidimensional case. This\nwork, also relying on methods from parameterized algorithm design and\ncomplexity analysis, performs a first systematic study of Multidimensional\nStable Roommates under the assumption of master lists.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:57:35 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 17:46:20 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 10:57:13 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Bredereck", "Robert", ""], ["Heeger", "Klaus", ""], ["Knop", "Du\u0161an", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "2009.14336", "submitter": "Erik Demaine", "authors": "Sualeh Asif, Michael Coulombe, Erik D. Demaine, Martin L. Demaine,\n  Adam Hesterberg, Jayson Lynch, Mihir Singhal", "title": "Tetris is NP-hard even with $O(1)$ rows or columns", "comments": "25 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the classic falling-block video game Tetris (both survival and\nboard clearing) remains NP-complete even when restricted to 8 columns, or to 4\nrows, settling open problems posed over 15 years ago [BDH+04]. Our reduction is\nfrom 3-Partition, similar to the previous reduction for unrestricted board\nsizes, but with a better packing of buckets. On the positive side, we prove\nthat 2-column Tetris (and 1-row Tetris) is polynomial. We also prove that the\ngeneralization of Tetris to larger $k$-omino pieces is NP-complete even when\nthe board starts empty, even when restricted to 3 columns or 2 rows or\nconstant-size pieces. Finally, we present an animated Tetris font.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:57:52 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Asif", "Sualeh", ""], ["Coulombe", "Michael", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Hesterberg", "Adam", ""], ["Lynch", "Jayson", ""], ["Singhal", "Mihir", ""]]}, {"id": "2009.14479", "submitter": "Adam Polak", "authors": "Andrea Lincoln, Adam Polak, Virginia Vassilevska Williams", "title": "Monochromatic Triangles, Intermediate Matrix Products, and Convolutions", "comments": "Presented at ITCS 2020. Abstract abridged to meet arXiv requirements", "journal-ref": null, "doi": "10.4230/LIPIcs.ITCS.2020.53", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most studied linear algebraic operation, matrix multiplication, has\nsurprisingly fast $O(n^\\omega)$ time algorithms for $\\omega<2.373$. On the\nother hand, the $(\\min,+)$ matrix product which is at the heart of many\nfundamental graph problems such as APSP, has received only minor improvements\nover its brute-force cubic running time and is widely conjectured to require\n$n^{3-o(1)}$ time. There is a plethora of matrix products and graph problems\nwhose complexity seems to lie in the middle of these two problems. For\ninstance, the Min-Max matrix product, the Minimum Witness matrix product, APSP\nin directed unweighted graphs and determining whether an edge-colored graph\ncontains a monochromatic triangle, can all be solved in $\\tilde\nO(n^{(3+\\omega)/2})$ time. A similar phenomenon occurs for convolution\nproblems, where analogous intermediate problems can be solved in $\\tilde\nO(n^{1.5})$ time.\n  Can one improve upon the running times for these intermediate problems, in\neither the matrix product or the convolution world? Or, alternatively, can one\nrelate these problems to each other and to other key problems in a meaningful\nway?\n  This paper makes progress on these questions by providing a network of\nfine-grained reductions. We show for instance that APSP in directed unweighted\ngraphs and Minimum Witness product can be reduced to both the Min-Max product\nand a variant of the monochromatic triangle problem. We also show that a\nnatural convolution variant of monochromatic triangle is fine-grained\nequivalent to the famous 3SUM problem. As this variant is solvable in\n$O(n^{1.5})$ time and 3SUM is in $O(n^2)$ time (and is conjectured to require\n$n^{2-o(1)}$ time), our result gives the first fine-grained equivalence between\nnatural problems of different running times.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 07:33:23 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Lincoln", "Andrea", ""], ["Polak", "Adam", ""], ["Williams", "Virginia Vassilevska", ""]]}]