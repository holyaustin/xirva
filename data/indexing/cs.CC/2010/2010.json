[{"id": "2010.00087", "submitter": "Karthik C. S.", "authors": "Vincent Cohen-Addad, Karthik C. S., and Euiwoong Lee", "title": "On Approximability of Clustering Problems Without Candidate Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-means objective is arguably the most widely-used cost function for\nmodeling clustering tasks in a metric space. In practice and historically,\nk-means is thought of in a continuous setting, namely where the centers can be\nlocated anywhere in the metric space. For example, the popular Lloyd's\nheuristic locates a center at the mean of each cluster.\n  Despite persistent efforts on understanding the approximability of k-means,\nand other classic clustering problems such as k-median and k-minsum, our\nknowledge of the hardness of approximation factors of these problems remains\nquite poor. In this paper, we significantly improve upon the hardness of\napproximation factors known in the literature for these objectives. We show\nthat if the input lies in a general metric space, it is NP-hard to approximate:\n  $\\bullet$ Continuous k-median to a factor of $2-o(1)$; this improves upon the\nprevious inapproximability factor of 1.36 shown by Guha and Khuller (J.\nAlgorithms '99).\n  $\\bullet$ Continuous k-means to a factor of $4- o(1)$; this improves upon the\nprevious inapproximability factor of 2.10 shown by Guha and Khuller (J.\nAlgorithms '99).\n  $\\bullet$ k-minsum to a factor of $1.415$; this improves upon the\nAPX-hardness shown by Guruswami and Indyk (SODA '03).\n  Our results shed new and perhaps counter-intuitive light on the differences\nbetween clustering problems in the continuous setting versus the discrete\nsetting (where the candidate centers are given as part of the input).\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 20:05:46 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 17:35:55 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["S.", "Karthik C.", ""], ["Lee", "Euiwoong", ""]]}, {"id": "2010.00138", "submitter": "Sophie Toulouse", "authors": "Laurent Alfandari, Sophie Toulouse", "title": "Approximation of the Double Travelling Salesman Problem with Multiple\n  Stacks", "comments": null, "journal-ref": "\"On the Complexity of the Multiple Stack TSP, kSTSP\" (TAMC 2009),\n  \"Approximability of the Multiple Stack TSP\" (ISCO 2010), \"Differential\n  Approximation of the Multiple Stacks TSP\" in (ISCO 2012)", "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Double Travelling Salesman Problem with Multiple Stacks, DTSPMS, deals\nwith the collect and delivery of n commodities in two distinct cities, where\nthe pickup and the delivery tours are related by LIFO constraints. During the\npickup tour, commodities are loaded into a container of k rows, or stacks, with\ncapacity c. This paper focuses on computational aspects of the DTSPMS, which is\nNP-hard.\n  We first review the complexity of two critical subproblems: deciding whether\na given pair of pickup and delivery tours is feasible and, given a loading\nplan, finding an optimal pair of pickup and delivery tours, are both polynomial\nunder some conditions on k and c.\n  We then prove a (3k)/2 standard approximation for the MinMetrickDTSPMS, where\nk is a universal constant, and other approximation results for various versions\nof the problem.\n  We finally present a matching-based heuristic for the 2DTSPMS, which is a\nspecial case with k=2 rows, when the distances are symmetric. This yields a\n1/2-o(1), 3/4-o(1) and 3/2+o(1) standard approximation for respectively\nMax2DTSPMS, its restriction Max2DTSPMS-(1,2) with distances 1 and 2, and\nMin2DTSPMS-(1,2), and a 1/2-o(1) differential approximation for Min2DTSPMS and\nMax2DTSPMS.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 22:50:01 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Alfandari", "Laurent", ""], ["Toulouse", "Sophie", ""]]}, {"id": "2010.00825", "submitter": "Ronny Tredup", "authors": "Ronny Tredup, Evgeny Erofeev", "title": "The Complexity of Boolean State Separation (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a Boolean type of nets $\\tau$, a transition system $A$ is synthesizeable\ninto a $\\tau$-net $N$ if and only if distinct states of $A$ correspond to\ndistinct markings of $N$, and $N$ prevents a transition firing if there is no\nrelated transition in $A$. The former property is called $\\tau$-state\nseparation property ($\\tau$-SSP) while the latter -- $\\tau$-event/state\nseparation property ($\\tau$-ESSP). $A$ is embeddable into the reachability\ngraph of a $\\tau$-net $N$ if and only if $A$ has the $\\tau$-SSP. This paper\npresents a complete characterization of the computational complexity of\n\\textsc{$\\tau$-SSP} for all Boolean Petri net types.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 07:42:41 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Tredup", "Ronny", ""], ["Erofeev", "Evgeny", ""]]}, {"id": "2010.00970", "submitter": "Paul Ferm\\'e", "authors": "Siddharth Barman, Omar Fawzi, Paul Ferm\\'e", "title": "Tight Approximation Guarantees for Concave Coverage Problems", "comments": "33 pages. v3 minor corrections and added FPT hardness", "journal-ref": null, "doi": "10.4230/LIPIcs.STACS.2021.9", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the maximum coverage problem, we are given subsets $T_1, \\ldots, T_m$ of a\nuniverse $[n]$ along with an integer $k$ and the objective is to find a subset\n$S \\subseteq [m]$ of size $k$ that maximizes $C(S) := \\Big|\\bigcup_{i \\in S}\nT_i\\Big|$. It is a classic result that the greedy algorithm for this problem\nachieves an optimal approximation ratio of $1-e^{-1}$.\n  In this work we consider a generalization of this problem wherein an element\n$a$ can contribute by an amount that depends on the number of times it is\ncovered. Given a concave, nondecreasing function $\\varphi$, we define\n$C^{\\varphi}(S) := \\sum_{a \\in [n]}w_a\\varphi(|S|_a)$, where $|S|_a = |\\{i \\in\nS : a \\in T_i\\}|$. The standard maximum coverage problem corresponds to taking\n$\\varphi(j) = \\min\\{j,1\\}$. For any such $\\varphi$, we provide an efficient\nalgorithm that achieves an approximation ratio equal to the Poisson concavity\nratio of $\\varphi$, defined by $\\alpha_{\\varphi} := \\min_{x \\in \\mathbb{N}^*}\n\\frac{\\mathbb{E}[\\varphi(\\text{Poi}(x))]}{\\varphi(\\mathbb{E}[\\text{Poi}(x)])}$.\nComplementing this approximation guarantee, we establish a matching NP-hardness\nresult when $\\varphi$ grows in a sublinear way.\n  As special cases, we improve the result of [Barman et al., IPCO, 2020] about\nmaximum multi-coverage, that was based on the unique games conjecture, and we\nrecover the result of [Dudycz et al., IJCAI, 2020] on multi-winner\napproval-based voting for geometrically dominant rules. Our result goes beyond\nthese special cases and we illustrate it with applications to distributed\nresource allocation problems, welfare maximization problems and approval-based\nvoting for general rules.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:03:04 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 13:19:35 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 10:36:21 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Barman", "Siddharth", ""], ["Fawzi", "Omar", ""], ["Ferm\u00e9", "Paul", ""]]}, {"id": "2010.01365", "submitter": "Mitre Dourado", "authors": "Mitre C. Dourado, Vitor S. Ponciano, R\\^omulo L. O. da Silva", "title": "On the monophonic rank of a graph", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of vertices $S$ of a graph $G$ is {\\em monophonically convex} if every\ninduced path joining two vertices of $S$ is contained in $S$. The {\\em\nmonophonic convex hull of $S$}, $\\langle S \\rangle$, is the smallest\nmonophonically convex set containing $S$. A set $S$ is {\\em monophonic convexly\nindependent} if $v \\not\\in \\langle S - \\{v\\} \\rangle$ for every $v \\in S$. The\n{\\em monophonic rank} of $G$ is the size of the largest monophonic convexly\nindependent set of $G$. We present a characterization of the monophonic\nconvexly independent sets. Using this result, we show how to determine the\nmonophonic rank of graph classes like bipartite, cactus, triangle-free, and\nline graphs in polynomial time. Furthermore, we show that this parameter can\ncomputed in polynomial time for $1$-starlike graphs, i.e., for split graphs,\nand that its determination is $\\NP$-complete for $k$-starlike graphs for any\nfixed $k \\ge 2$, a subclass of chordal graphs. We also consider this problem on\nthe graphs whose intersection graph of the maximal prime subgraphs is a tree.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 14:04:28 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 13:28:36 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 00:37:59 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Dourado", "Mitre C.", ""], ["Ponciano", "Vitor S.", ""], ["da Silva", "R\u00f4mulo L. O.", ""]]}, {"id": "2010.01385", "submitter": "Purnata Ghosal", "authors": "Purnata Ghosal and B. V. Raghavendra Rao", "title": "Limitations of Sums of Bounded-Read Formulas", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proving super polynomial size lower bounds for various classes of arithmetic\ncircuits computing explicit polynomials is a very important and challenging\ntask in algebraic complexity theory. We study representation of polynomials as\nsums of weaker models such as read once formulas (ROFs) and read once oblivious\nalgebraic branching programs (ROABPs). We prove:\n  (1) An exponential separation between sum of ROFs and read-$k$ formulas for\nsome constant $k$. (2) A sub-exponential separation between sum of ROABPs and\nsyntactic multilinear ABPs.\n  Our results are based on analysis of the partial derivative matrix under\ndifferent distributions. These results highlight richness of bounded read\nrestrictions in arithmetic formulas and ABPs.\n  Finally, we consider a generalization of multilinear ROABPs known as\nstrict-interval ABPs defined in [Ramya-Rao, MFCS2019]. We show that\nstrict-interval ABPs are equivalent to ROABPs upto a polynomial size blow up.\nIn contrast, we show that interval formulas are different from ROFs and also\nadmit depth reduction which is not known in the case of strict-interval ABPs.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 16:41:22 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ghosal", "Purnata", ""], ["Rao", "B. V. Raghavendra", ""]]}, {"id": "2010.01439", "submitter": "Arya Tanmay Gupta", "authors": "Arya Tanmay Gupta", "title": "Burning Geometric Graphs", "comments": "Masters' dissertation", "journal-ref": null, "doi": null, "report-no": "201861003", "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A procedure called \\textit{graph burning} was introduced to facilitate the\nmodelling of spread of an alarm, a social contagion, or a social influence or\nemotion on graphs and networks.\n  Graph burning runs on discrete time-steps (or rounds). At each step $t$,\nfirst (a) an unburned vertex is burned (as a \\textit{fire source}) from\n\"outside\", and then (b) the fire spreads to vertices adjacent to the vertices\nwhich are burned till step $t-1$. This process stops after all the vertices of\n$G$ have been burned. The aim is to burn all the vertices in a given graph in\nminimum time-steps. The least number of time-steps required to burn a graph is\ncalled its \\textit{burning number}. The less the burning number is, the faster\na graph can be burned.\n  Burning a general graph optimally is an NP-Complete problem. It has been\nproved that optimal burning of path forests, spider graphs, and trees with\nmaximum degree three is NP-Complete. We study the \\textit{graph burning\nproblem} on several sub-classes of \\textit{geometric graphs}.\n  We show that burning interval graphs (Section 7.1, Theorem 7.1), permutation\ngraphs (Section 7.2, Theorem 7.2) and disk graphs (Section 7.3, Theorem 7.3)\noptimally is NP-Complete. In addition, we opine that optimal burning of general\ngraphs (Section 9.2, Conjecture 9.1) cannot be approximated better than\n3-approximation factor.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 23:03:11 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gupta", "Arya Tanmay", ""]]}, {"id": "2010.01459", "submitter": "Vaggos Chatziafratis", "authors": "Vaggos Chatziafratis, Neha Gupta, Euiwoong Lee", "title": "Inapproximability for Local Correlation Clustering and Dissimilarity\n  Hierarchical Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present hardness of approximation results for Correlation Clustering with\nlocal objectives and for Hierarchical Clustering with dissimilarity\ninformation. For the former, we study the local objective of Puleo and\nMilenkovic (ICML '16) that prioritizes reducing the disagreements at data\npoints that are worst off and for the latter we study the maximization version\nof Dasgupta's cost function (STOC '16). Our APX hardness results imply that the\ntwo problems are hard to approximate within a constant of 4/3 ~ 1.33 (assuming\nP vs NP) and 9159/9189 ~ 0.9967 (assuming the Unique Games Conjecture)\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 01:16:07 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chatziafratis", "Vaggos", ""], ["Gupta", "Neha", ""], ["Lee", "Euiwoong", ""]]}, {"id": "2010.02772", "submitter": "Yangsibo Huang", "authors": "Yangsibo Huang, Zhao Song, Kai Li, Sanjeev Arora", "title": "InstaHide: Instance-hiding Schemes for Private Distributed Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  How can multiple distributed entities collaboratively train a shared deep net\non their private data while preserving privacy? This paper introduces\nInstaHide, a simple encryption of training images, which can be plugged into\nexisting distributed deep learning pipelines. The encryption is efficient and\napplying it during training has minor effect on test accuracy.\n  InstaHide encrypts each training image with a \"one-time secret key\" which\nconsists of mixing a number of randomly chosen images and applying a random\npixel-wise mask. Other contributions of this paper include: (a) Using a large\npublic dataset (e.g. ImageNet) for mixing during its encryption, which improves\nsecurity. (b) Experimental results to show effectiveness in preserving privacy\nagainst known attacks with only minor effects on accuracy. (c) Theoretical\nanalysis showing that successfully attacking privacy requires attackers to\nsolve a difficult computational problem. (d) Demonstrating that use of the\npixel-wise mask is important for security, since Mixup alone is shown to be\ninsecure to some some efficient attacks. (e) Release of a challenge dataset\nhttps://github.com/Hazelsuko07/InstaHide_Challenge\n  Our code is available at https://github.com/Hazelsuko07/InstaHide\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 14:43:23 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 18:54:19 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Huang", "Yangsibo", ""], ["Song", "Zhao", ""], ["Li", "Kai", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2010.02835", "submitter": "Alex B. Grilo", "authors": "Dorit Aharonov, Alex B. Grilo, Yupan Liu", "title": "StoqMA vs. MA: the power of error reduction", "comments": "Version 2 has punctual minor improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  StoqMA characterizes the computational hardness of stoquastic local\nHamiltonians, which is a family of Hamiltonians that does not suffer from the\nsign problem. Although error reduction is commonplace for many complexity\nclasses, such as BPP, BQP, MA, QMA, etc.,this property remains open for StoqMA\nsince Bravyi, Bessen and Terhal defined this class in 2006. In this note, we\nshow that error reduction forStoqMA will imply that StoqMA = MA.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 15:57:11 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 09:01:02 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 19:56:50 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Aharonov", "Dorit", ""], ["Grilo", "Alex B.", ""], ["Liu", "Yupan", ""]]}, {"id": "2010.02922", "submitter": "Bernd Schuh", "authors": "Bernd. R. Schuh", "title": "Balanced incomplete block designs and exact satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper explores the correspondence between balanced incomplete block\ndesigns (BIBD) and certain linear CNF formulas by identifying the points of a\nblock design with the clauses of the Boolean formula and blocks with Boolean\nvariables. Parallel classes in BIBDs correspond to XSAT solutions in the\ncorresponding formula. This correspondence allows for transfers of results from\none field to the other. As a new result we deduce from known satisfiability\ntheorems that the problem of finding a parallel class in a partially balanced\nincomplete block design is NP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 19:54:49 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Schuh", "Bernd. R.", ""]]}, {"id": "2010.03311", "submitter": "Jonni Virtema", "authors": "Jonni Virtema, Jana Hofmann, Bernd Finkbeiner, Juha Kontinen, and Fan\n  Yang", "title": "Linear-time Temporal Logic with Team Semantics: Expressivity and\n  Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the expressivity and the model checking problem of linear temporal\nlogic with team semantics (TeamLTL). In contrast to LTL, TeamLTL is capable of\ndefining hyperproperties, i.e., properties which relate multiple execution\ntraces. Logics for hyperproperties have so far been mostly obtained by\nextending temporal logics like LTL and QPTL with trace quantification,\nresulting in HyperLTL and HyperQPTL. We study the expressivity of TeamLTL and\nits extensions in comparison to HyperLTL and HyperQPTL. By doing so we obtain a\nnumber of model checking results for TeamLTL and identify its undecidability\nfrontier. The two types of logics follow a fundamentally different approach to\nhyperproperties and are of incomparable expressivity. We establish that the\nuniversally quantified fragment of HyperLTL subsumes the so-called k-coherent\nfragment of TeamLTL with contradictory negation. This also implies that the\nmodel checking problem is decidable for the fragment. We show decidability of\nmodel checking of the so-called left-flat fragment of TeamLTL with\ndownward-closed generalised atoms and Boolean disjunction via a translation to\na decidable fragment of HyperQPTL. Finally, we show that the model checking\nproblem of TeamLTL with Boolean disjunction and inclusion atoms is undecidable.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 10:10:02 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 11:36:06 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Virtema", "Jonni", ""], ["Hofmann", "Jana", ""], ["Finkbeiner", "Bernd", ""], ["Kontinen", "Juha", ""], ["Yang", "Fan", ""]]}, {"id": "2010.03393", "submitter": "Karolina Okrasa", "authors": "Karolina Okrasa and Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Complexity of the list homomorphism problem in hereditary graph classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A homomorphism from a graph $G$ to a graph $H$ is an edge-preserving mapping\nfrom $V(G)$ to $V(H)$. For a fixed graph $H$, in the list homomorphism problem,\ndenoted by LHom($H$), we are given a graph $G$, whose every vertex $v$ is\nequipped with a list $L(v) \\subseteq V(H)$. We ask if there exists a\nhomomorphism $f$ from $G$ to $H$, in which $f(v) \\in L(v)$ for every $v \\in\nV(G)$. Feder, Hell, and Huang [JGT~2003] proved that LHom($H$) is polynomial\ntime-solvable if $H$ is a bi-arc-graph, and NP-complete otherwise.\n  We are interested in the complexity of the LHom($H$) problem in graphs\nexcluding a copy of some fixed graph $F$ as an induced subgraph. It is known\nthat if $F$ is connected and is not a path nor a subdivided claw, then for\nevery non-bi-arc graph the LHom($H$) problem is NP-complete and cannot be\nsolved in subexponential time, unless the ETH fails. We consider the remaining\ncases for connected graphs $F$.\n  If $F$ is a path, we exhibit a full dichotomy. We define a class called\npredacious graphs and show that if $H$ is not predacious, then for every fixed\n$t$ the LHom($H$) problem can be solved in quasi-polynomial time in $P_t$-free\ngraphs. On the other hand, if $H$ is predacious, then there exists $t$, such\nthat LHom($H$) cannot be solved in subexponential time in $P_t$-free graphs.\n  If $F$ is a subdivided claw, we show a full dichotomy in two important cases:\nfor $H$ being irreflexive (i.e., with no loops), and for $H$ being reflexive\n(i.e., where every vertex has a loop). Unless the ETH fails, for irreflexive\n$H$ the LHom($H$) problem can be solved in subexponential time in graphs\nexcluding a fixed subdivided claw if and only if $H$ is non-predacious and\ntriangle-free. If $H$ is reflexive, then LHom($H$) cannot be solved in\nsubexponential time whenever $H$ is not a bi-arc graph.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 13:05:17 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Okrasa", "Karolina", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "2010.04333", "submitter": "Sankardeep Chakraborty", "authors": "H\\\"useyin Acan, Sankardeep Chakraborty, Seungbum Jo, Kei Nakashima,\n  Kunihiko Sadakane, Srinivasa Rao Satti", "title": "Succinct Navigational Oracles for Families of Intersection Graphs on a\n  Circle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing succinct navigational oracles, i.e.,\nsuccinct data structures supporting basic navigational queries such as degree,\nadjacency, and neighborhood efficiently for intersection graphs on a circle,\nwhich include graph classes such as {\\it circle graphs}, {\\it\n$k$-polygon-circle graphs}, {\\it circle-trapezoid graphs}, {\\it trapezoid\ngraphs}. The degree query reports the number of incident edges to a given\nvertex, the adjacency query asks if there is an edge between two given\nvertices, and the neighborhood query enumerates all the neighbors of a given\nvertex. We first prove a general lower bound for these intersection graph\nclasses and then present a uniform approach that lets us obtain matching lower\nand upper bounds for representing each of these graph classes. More\nspecifically, our lower bound proofs use a unified technique to produce tight\nbounds for all these classes, and this is followed by our data structures which\nare also obtained from a unified representation method to achieve succinctness\nfor each class. In addition, we prove a lower bound of space for representing\n{\\it trapezoid} graphs and give a succinct navigational oracle for this class\nof graphs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 02:35:58 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Acan", "H\u00fcseyin", ""], ["Chakraborty", "Sankardeep", ""], ["Jo", "Seungbum", ""], ["Nakashima", "Kei", ""], ["Sadakane", "Kunihiko", ""], ["Satti", "Srinivasa Rao", ""]]}, {"id": "2010.04527", "submitter": "Philipp Krause", "authors": "Philipp Klaus Krause", "title": "Constant-time connectivity tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present implementations of constant-time algorithms for connectivity tests\nand related problems. Some are implementations of slightly improved variants of\npreviously known algorithms; for other problems we present new algorithms that\nhave substantially better runtime than previously known algorithms (estimates\nof the distance to and tolerant testers for connectivity, 2-edge-connectivity,\n3-edge-connectivity, eulerianity).\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 12:32:20 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Krause", "Philipp Klaus", ""]]}, {"id": "2010.04618", "submitter": "Libor Barto", "authors": "Kristina Asimi, Libor Barto", "title": "Finitely Tractable Promise Constraint Satisfaction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Promise Constraint Satisfaction Problem (PCSP) is a generalization of the\nConstraint Satisfaction Problem (CSP) that includes approximation variants of\nsatisfiability and graph coloring problems. Barto [LICS '19] has shown that a\nspecific PCSP, the problem to find a valid Not-All-Equal solution to a\n1-in-3-SAT instance, is not finitely tractable in that it can be solved by a\ntrivial reduction to a tractable CSP, but such a CSP is necessarily over an\ninfinite domain (unless P=NP). We initiate a systematic study of this\nphenomenon by giving a general necessary condition for finite tractability and\ncharacterizing finite tractability within a class of templates - the \"basic\"\ntractable cases in the dichotomy theorem for symmetric Boolean PCSPs allowing\nnegations by Brakensiek and Guruswami [SODA'18].\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:01:22 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Asimi", "Kristina", ""], ["Barto", "Libor", ""]]}, {"id": "2010.04623", "submitter": "Libor Barto", "authors": "Libor Barto, Diego Battistelli, Kevin M. Berg", "title": "Symmetric Promise Constraint Satisfaction Problems: Beyond the Boolean\n  Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Promise Constraint Satisfaction Problem (PCSP) is a recently introduced\nvast generalization of the Constraint Satisfaction Problem (CSP). We\ninvestigate the computational complexity of a class of PCSPs beyond the most\nstudied cases - approximation variants of satisfiability and graph coloring\nproblems. We give an almost complete classification for the class of PCSPs of\nthe form: given a 3-uniform hypergraph that has an admissible 2-coloring, find\nan admissible 3-coloring, where admissibility is given by a ternary symmetric\nrelation. The only PCSP of this sort whose complexity is left open in this work\nis a natural hypergraph coloring problem, where admissibility is given by the\nrelation \"if two colors are equal, then the remaining one is higher.\"\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:08:11 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Barto", "Libor", ""], ["Battistelli", "Diego", ""], ["Berg", "Kevin M.", ""]]}, {"id": "2010.04662", "submitter": "Vincent Neiger", "authors": "Vincent Neiger and Cl\\'ement Pernet", "title": "Deterministic computation of the characteristic polynomial in the time\n  of matrix multiplication", "comments": "38 pages, 5 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an algorithm which computes the characteristic\npolynomial of a matrix over a field within the same asymptotic complexity, up\nto constant factors, as the multiplication of two square matrices. Previously,\nthis was only achieved by resorting to genericity assumptions or randomization\ntechniques, while the best known complexity bound with a general deterministic\nalgorithm was obtained by Keller-Gehrig in 1985 and involves logarithmic\nfactors. Our algorithm computes more generally the determinant of a univariate\npolynomial matrix in reduced form, and relies on new subroutines for\ntransforming shifted reduced matrices into shifted weak Popov matrices, and\nshifted weak Popov matrices into shifted Popov matrices.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 16:08:12 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 16:17:29 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Neiger", "Vincent", ""], ["Pernet", "Cl\u00e9ment", ""]]}, {"id": "2010.04799", "submitter": "Sergio Cabello", "authors": "\\'Edouard Bonnet and Sergio Cabello", "title": "The Complexity of Mixed-Connectivity", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the parameterized complexity in $a$ and $b$ of determining\nwhether a graph~$G$ has a subset of $a$ vertices and $b$ edges whose removal\ndisconnects $G$, or disconnects two prescribed vertices $s, t \\in V(G)$.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 20:46:58 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Cabello", "Sergio", ""]]}, {"id": "2010.04910", "submitter": "Artem Govorov", "authors": "Jin-Yi Cai, Artem Govorov", "title": "The Complexity of Counting Edge Colorings for Simple Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove #P-completeness results for counting edge colorings on simple\ngraphs. These strengthen the corresponding results on multigraphs from [4]. We\nprove that for any $\\kappa \\ge r \\ge 3$ counting $\\kappa$-edge colorings on\n$r$-regular simple graphs is #P-complete. Furthermore, we show that for planar\n$r$-regular simple graphs where $r \\in \\{3, 4, 5\\}$ counting edge colorings\nwith \\k{appa} colors for any $\\kappa \\ge r$ is also #P-complete. As there are\nno planar $r$-regular simple graphs for any $r > 5$, these statements cover all\ninteresting cases in terms of the parameters $(\\kappa, r)$.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 05:43:47 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Govorov", "Artem", ""]]}, {"id": "2010.04958", "submitter": "Antoine Mottet", "authors": "Libor Barto and William DeMeo and Antoine Mottet", "title": "Constraint Satisfaction Problems over Finite Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.RA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We initiate a systematic study of the computational complexity of the\nConstraint Satisfaction Problem (CSP) over finite structures that may contain\nboth relations and operations. We show the close connection between this\nproblem and a natural algebraic question: which finite algebras admit only\npolynomially many homomorphisms into them? We give some sufficient and some\nnecessary conditions for a finite algebra to have this property. In particular,\nwe show that every finite equationally nontrivial algebra has this property\nwhich gives us, as a simple consequence, a complete complexity classification\nof CSPs over two-element structures, thus extending the classification for\ntwo-element relational structures by Schaefer (STOC'78). We also present\nexamples of two-element structures that have bounded width but do not have\nrelational width (2,3), thus demonstrating that, from a descriptive complexity\nperspective, allowing operations leads to a richer theory.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 09:43:55 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 08:14:40 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Barto", "Libor", ""], ["DeMeo", "William", ""], ["Mottet", "Antoine", ""]]}, {"id": "2010.04985", "submitter": "Marcel Dall'Agnol", "authors": "Marcel Dall'Agnol, Tom Gur and Oded Lachish", "title": "A Structural Theorem for Local Algorithms with Applications to Coding,\n  Testing, and Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a general structural theorem for a wide family of local algorithms,\nwhich includes property testers, local decoders, and PCPs of proximity. Namely,\nwe show that the structure of every algorithm that makes $q$ adaptive queries\nand satisfies a natural robustness condition admits a sample-based algorithm\nwith $n^{1- 1/O(q^2 \\log^2 q)}$ sample complexity, following the definition of\nGoldreich and Ron (TOCT 2016). We prove that this transformation is nearly\noptimal. Our theorem also admits a scheme for constructing privacy-preserving\nlocal algorithms. Using the unified view that our structural theorem provides,\nwe obtain results regarding various types of local algorithms, including the\nfollowing.\n  - We strengthen the state-of-the-art lower bound for relaxed locally\ndecodable codes, obtaining an exponential improvement on the dependency in\nquery complexity; this resolves an open problem raised by Gur and Lachish (SODA\n2020).\n  - We show that any (constant-query) testable property admits a sample-based\ntester with sublinear sample complexity; this resolves a problem left open in a\nwork of Fischer, Lachish, and Vasudev (FOCS 2015) by extending their main\nresult to adaptive testers.\n  - We prove that the known separation between proofs of proximity and testers\nis essentially maximal; this resolves a problem left open by Gur and Rothblum\n(ECCC 2013, Computational Complexity 2018) regarding sublinear-time delegation\nof computation.\n  Our techniques strongly rely on relaxed sunflower lemmas and the\nHajnal-Szemer\\'edi theorem.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 12:46:42 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Dall'Agnol", "Marcel", ""], ["Gur", "Tom", ""], ["Lachish", "Oded", ""]]}, {"id": "2010.05425", "submitter": "Tianyu Liu", "authors": "Jin-Yi Cai, Tianyu Liu", "title": "FPRAS via MCMC where it mixes torpidly (and very little effort)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is Fully Polynomial-time Randomized Approximation Scheme (FPRAS) for a\nproblem via an MCMC algorithm possible when it is known that rapid mixing\nprovably fails? We introduce several weight-preserving maps for the\neight-vertex model on planar and on bipartite graphs, respectively. Some are\none-to-one, while others are holographic which map superpositions of\nexponentially many states from one setting to another, in a quantum-like\nmany-to-many fashion. In fact we introduce a set of such mappings that forms a\ngroup in each case. Using some holographic maps and their compositions we\nobtain FPRAS for the eight-vertex model at parameter settings where it is known\nthat rapid mixing provably fails due to an intrinsic barrier. This FPRAS is\nindeed the same MCMC algorithm, except its state space corresponds to\nsuperpositions of the given states, where rapid mixing holds. FPRAS is also\ngiven for torus graphs for parameter settings where natural Markov chains are\nknown to mix torpidly. Our results show that the eight-vertex model is the\nfirst problem with the provable property that while NP-hard to approximate on\ngeneral graphs (even #P-hard for planar graphs in exact complexity), it\npossesses FPRAS on both bipartite graphs and planar graphs in substantial\nregions of its parameter space.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 03:09:42 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Cai", "Jin-Yi", ""], ["Liu", "Tianyu", ""]]}, {"id": "2010.05660", "submitter": "Yaroslav Alekseev", "authors": "Yaroslav Alekseev", "title": "A Lower Bound for Polynomial Calculus with Extension Rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study an extension of the Polynomial Calculus proof system\nwhere we can introduce new variables and take a square root. We prove that an\ninstance of the subset-sum principle, the binary value principle, requires\nrefutations of exponential bit size over rationals in this system.\n  Part and Tzameret proved an exponential lower bound on the size of Res-Lin\n(Resolution over linear equations) refutations of the binary value principle.\nWe show that our system p-simulates Res-Lin and thus we get an alternative\nexponential lower bound for the size of Res-Lin refutations of the binary value\nprinciple.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 12:57:28 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Alekseev", "Yaroslav", ""]]}, {"id": "2010.05677", "submitter": "Simon Kn\\\"auer", "authors": "Manuel Bodirsky, Simon Kn\\\"auer and Sebastian Rudolph", "title": "Datalog-Expressibility for Monadic and Guarded Second-Order Logic", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterise the sentences in Monadic Second-order Logic (MSO) that are\nover finite structures equivalent to a Datalog program, in terms of an\nexistential pebble game. We also show that for every class C of finite\nstructures that can be expressed in MSO and is closed under homomorphisms, and\nfor all integers l,k, there exists a *canonical* Datalog program Pi of width\n(l,k), that is, a Datalog program of width (l,k) which is sound for C (i.e., Pi\nonly derives the goal predicate on a finite structure A if A is in C) and with\nthe property that Pi derives the goal predicate whenever *some* Datalog program\nof width (l,k) which is sound for C derives the goal predicate. The same\ncharacterisations also hold for Guarded Second-order Logic (GSO), which\nproperly extends MSO. To prove our results, we show that every class C in GSO\nwhose complement is closed under homomorphisms is a finite union of constraint\nsatisfaction problems (CSPs) of countably categorical structures.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 13:18:14 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Kn\u00e4uer", "Simon", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "2010.05768", "submitter": "Dmitry Gribanov", "authors": "D.V. Gribanov, N.Yu. Zolotykh", "title": "On lattice point counting in $\\Delta$-modular polyhedra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.SC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let a polyhedron $P$ be defined by one of the following ways:\n  (i) $P = \\{x \\in R^n \\colon A x \\leq b\\}$, where $A \\in Z^{(n+k) \\times n}$,\n$b \\in Z^{(n+k)}$ and $rank\\, A = n$;\n  (ii) $P = \\{x \\in R_+^n \\colon A x = b\\}$, where $A \\in Z^{k \\times n}$, $b\n\\in Z^{k}$ and $rank\\, A = k$.\n  And let all rank order minors of $A$ be bounded by $\\Delta$ in absolute\nvalues. We show that the short rational generating function for the power\nseries $$ \\sum\\limits_{m \\in P \\cap Z^n} x^m $$ can be computed with the\narithmetic complexity $ O\\left(T_{SNF}(d) \\cdot d^{k} \\cdot d^{\\log_2\n\\Delta}\\right), $ where $k$ and $\\Delta$ are fixed, $d = \\dim P$, and\n$T_{SNF}(m)$ is the complexity to compute the Smith Normal Form for $m \\times\nm$ integer matrix. In particular, $d = n$ for the case (i) and $d = n-k$ for\nthe case (ii).\n  The simplest examples of polyhedra that meet conditions (i) or (ii) are the\nsimplicies, the subset sum polytope and the knapsack or multidimensional\nknapsack polytopes.\n  We apply these results to parametric polytopes, and show that the step\npolynomial representation of the function $c_P(y) = |P_{y} \\cap Z^n|$, where\n$P_{y}$ is parametric polytope, can be computed by a polynomial time even in\nvarying dimension if $P_{y}$ has a close structure to the cases (i) or (ii). As\nanother consequence, we show that the coefficients $e_i(P,m)$ of the Ehrhart\nquasi-polynomial $$ \\left| mP \\cap Z^n\\right| = \\sum\\limits_{j = 0}^n\ne_i(P,m)m^j $$ can be computed by a polynomial time algorithm for fixed $k$ and\n$\\Delta$.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 15:05:06 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 18:10:56 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 20:18:20 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 18:03:48 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Gribanov", "D. V.", ""], ["Zolotykh", "N. Yu.", ""]]}, {"id": "2010.05822", "submitter": "Nobutaka Shimizu", "authors": "Shuichi Hirahara and Nobutaka Shimizu", "title": "Nearly Optimal Average-Case Complexity of Counting Bicliques Under SETH", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we seek a natural problem and a natural distribution of\ninstances such that any $O(n^{c-\\epsilon})$-time algorithm fails to solve most\ninstances drawn from the distribution, while the problem admits an\n$n^{c+o(1)}$-time algorithm that correctly solves all instances. Specifically,\nwe consider the $K_{a,b}$ counting problem in a random bipartite graph, where\n$K_{a,b}$ is a complete bipartite graph for constants $a$ and $b$. We proved\nthat the $K_{a,b}$ counting problem admits an $n^{a+o(1)}$-time algorithm if\n$a\\geq 8$, while any $n^{a-\\epsilon}$-time algorithm fails to solve it even on\nrandom bipartite graph for any constant $\\epsilon>0$ under the Strong\nExponential Time Hypotheis. Then, we amplify the hardness of this problem using\nthe direct product theorem and Yao's XOR lemma by presenting a general\nframework of hardness amplification in the setting of fine-grained complexity.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 16:16:28 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Hirahara", "Shuichi", ""], ["Shimizu", "Nobutaka", ""]]}, {"id": "2010.05846", "submitter": "Josh Alman", "authors": "Josh Alman and Virginia Vassilevska Williams", "title": "A Refined Laser Method and Faster Matrix Multiplication", "comments": "29 pages, to appear in the 32nd Annual ACM-SIAM Symposium on Discrete\n  Algorithms (SODA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of matrix multiplication is measured in terms of $\\omega$, the\nsmallest real number such that two $n\\times n$ matrices can be multiplied using\n$O(n^{\\omega+\\epsilon})$ field operations for all $\\epsilon>0$; the best bound\nuntil now is $\\omega<2.37287$ [Le Gall'14]. All bounds on $\\omega$ since 1986\nhave been obtained using the so-called laser method, a way to lower-bound the\n`value' of a tensor in designing matrix multiplication algorithms. The main\nresult of this paper is a refinement of the laser method that improves the\nresulting value bound for most sufficiently large tensors. Thus, even before\ncomputing any specific values, it is clear that we achieve an improved bound on\n$\\omega$, and we indeed obtain the best bound on $\\omega$ to date: $$\\omega <\n2.37286.$$ The improvement is of the same magnitude as the improvement that [Le\nGall'14] obtained over the previous bound [Vassilevska W.'12]. Our improvement\nto the laser method is quite general, and we believe it will have further\napplications in arithmetic complexity.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 16:51:36 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Alman", "Josh", ""], ["Williams", "Virginia Vassilevska", ""]]}, {"id": "2010.05998", "submitter": "Lior Gishboliner", "authors": "Lior Gishboliner, Yevgeny Levanzov, Asaf Shapira", "title": "Counting Subgraphs in Degenerate Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of counting the number of copies of a fixed graph $H$\nwithin an input graph $G$. This is one of the most well-studied algorithmic\ngraph problems, with many theoretical and practical applications. We focus on\nsolving this problem when the input $G$ has bounded degeneracy. This is a rich\nfamily of graphs, containing all graphs without a fixed minor (e.g. planar\ngraphs), as well as graphs generated by various random processes (e.g.\npreferential attachment graphs). We say that $H$ is easy if there is a\nlinear-time algorithm for counting the number of copies of $H$ in an input $G$\nof bounded degeneracy. A seminal result of Chiba and Nishizeki from '85 states\nthat every $H$ on at most 4 vertices is easy. Bera, Pashanasangi, and Seshadhri\nrecently extended this to all $H$ on 5 vertices, and further proved that for\nevery $k > 5$ there is a $k$-vertex $H$ which is not easy. They left open the\nnatural problem of characterizing all easy graphs $H$.\n  Bressan has recently introduced a framework for counting subgraphs in\ndegenerate graphs, from which one can extract a sufficient condition for a\ngraph $H$ to be easy. Here we show that this sufficient condition is also\nnecessary, thus fully answering the Bera--Pashanasangi--Seshadhri problem. We\nfurther resolve two closely related problems; namely characterizing the graphs\nthat are easy with respect to counting induced copies, and with respect to\ncounting homomorphisms. Our proofs rely on several novel approaches for proving\nhardness results in the context of subgraph-counting.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 19:53:26 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Gishboliner", "Lior", ""], ["Levanzov", "Yevgeny", ""], ["Shapira", "Asaf", ""]]}, {"id": "2010.06083", "submitter": "Cyrus Rashtchian", "authors": "Vinnu Bhardwaj, Pavel A. Pevzner, Cyrus Rashtchian, Yana Safonova", "title": "Trace Reconstruction Problems in Computational Biology", "comments": "20 pages, 8 figures. Accepted to the Special Issue of IEEE\n  Transactions on Information Theory Dedicated to the Memory of Vladimir I.\n  Levenshtein (copyright of journal version transferred to IEEE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT cs.LG math.IT q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of reconstructing a string from its error-prone copies, the trace\nreconstruction problem, was introduced by Vladimir Levenshtein two decades ago.\nWhile there has been considerable theoretical work on trace reconstruction,\npractical solutions have only recently started to emerge in the context of two\nrapidly developing research areas: immunogenomics and DNA data storage. In\nimmunogenomics, traces correspond to mutated copies of genes, with mutations\ngenerated naturally by the adaptive immune system. In DNA data storage, traces\ncorrespond to noisy copies of DNA molecules that encode digital data, with\nerrors being artifacts of the data retrieval process. In this paper, we\nintroduce several new trace generation models and open questions relevant to\ntrace reconstruction for immunogenomics and DNA data storage, survey\ntheoretical results on trace reconstruction, and highlight their connections to\ncomputational biology. Throughout, we discuss the applicability and\nshortcomings of known solutions and suggest future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 23:52:46 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Bhardwaj", "Vinnu", ""], ["Pevzner", "Pavel A.", ""], ["Rashtchian", "Cyrus", ""], ["Safonova", "Yana", ""]]}, {"id": "2010.06317", "submitter": "Nikolaos Melissinos", "authors": "Ararat Harutyunyan, Michael Lampis, Nikolaos Melissinos", "title": "Digraph Coloring and Distance to Acyclicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In $k$-Digraph Coloring we are given a digraph and are asked to partition its\nvertices into at most $k$ sets, so that each set induces a DAG. This well-known\nproblem is NP-hard, as it generalizes (undirected) $k$-Coloring, but becomes\ntrivial if the input digraph is acyclic. This poses the natural parameterized\ncomplexity question what happens when the input is \"almost\" acyclic. In this\npaper we study this question using parameters that measure the input's distance\nto acyclicity in either the directed or the undirected sense.\n  It is already known that, for all $k\\ge 2$, $k$-Digraph Coloring is NP-hard\non digraphs of DFVS at most $k+4$. We strengthen this result to show that, for\nall $k\\ge 2$, $k$-Digraph Coloring is NP-hard for DFVS $k$. Refining our\nreduction we obtain two further consequences: (i) for all $k\\ge 2$, $k$-Digraph\nColoring is NP-hard for graphs of feedback arc set (FAS) at most $k^2$;\ninterestingly, this leads to a dichotomy, as we show that the problem is FPT by\n$k$ if FAS is at most $k^2-1$; (ii) $k$-Digraph Coloring is NP-hard for graphs\nof DFVS $k$, even if the maximum degree $\\Delta$ is at most $4k-1$; we show\nthat this is also almost tight, as the problem becomes FPT for DFVS $k$ and\n$\\Delta\\le 4k-3$.\n  We then consider parameters that measure the distance from acyclicity of the\nunderlying graph. We show that $k$-Digraph Coloring admits an FPT algorithm\nparameterized by treewidth, whose parameter dependence is $(tw!)k^{tw}$. Then,\nwe pose the question of whether the $tw!$ factor can be eliminated. Our main\ncontribution in this part is to settle this question in the negative and show\nthat our algorithm is essentially optimal, even for the much more restricted\nparameter treedepth and for $k=2$. Specifically, we show that an FPT algorithm\nsolving $2$-Digraph Coloring with dependence $td^{o(td)}$ would contradict the\nETH.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 11:55:50 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Harutyunyan", "Ararat", ""], ["Lampis", "Michael", ""], ["Melissinos", "Nikolaos", ""]]}, {"id": "2010.06401", "submitter": "Pawan Aurora", "authors": "Pawan Aurora, Hans Raj Tiwary", "title": "On the Complexity of Some Facet-Defining Inequalities of the\n  QAP-polytope", "comments": "20 pages. To be published in COCOA 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quadratic Assignment Problem (QAP) is a well-known NP-hard problem that\nis equivalent to optimizing a linear objective function over the QAP polytope.\nThe QAP polytope with parameter $n$ - \\qappolytope{n} - is defined as the\nconvex hull of rank-$1$ matrices $xx^T$ with $x$ as the vectorized $n\\times n$\npermutation matrices.\n  In this paper we consider all the known exponential-sized families of\nfacet-defining inequalities of the QAP-polytope. We describe a new family of\nvalid inequalities that we show to be facet-defining. We also show that\nmembership testing (and hence optimizing) over some of the known classes of\ninequalities is coNP-complete. We complement our hardness results by showing a\nlower bound of $2^{\\Omega(n)}$ on the extension complexity of all relaxations\nof \\qappolytope{n} for which any of the known classes of inequalities are\nvalid.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 13:56:24 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Aurora", "Pawan", ""], ["Tiwary", "Hans Raj", ""]]}, {"id": "2010.06563", "submitter": "Alexander Wein", "authors": "Alexander S. Wein", "title": "Optimal Low-Degree Hardness of Maximum Independent Set", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the algorithmic task of finding a large independent set in a sparse\nErd\\H{o}s-R\\'{e}nyi random graph with $n$ vertices and average degree $d$. The\nmaximum independent set is known to have size $(2 \\log d / d)n$ in the double\nlimit $n \\to \\infty$ followed by $d \\to \\infty$, but the best known\npolynomial-time algorithms can only find an independent set of half-optimal\nsize $(\\log d / d)n$. We show that the class of low-degree polynomial\nalgorithms can find independent sets of half-optimal size but no larger,\nimproving upon a result of Gamarnik, Jagannath, and the author. This\ngeneralizes earlier work by Rahman and Vir\\'ag, which proved the analogous\nresult for the weaker class of local algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 17:26:09 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 16:44:49 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wein", "Alexander S.", ""]]}, {"id": "2010.07405", "submitter": "Nathan Lindzey", "authors": "Neta Dafni, Yuval Filmus, Noam Lifshitz, Nathan Lindzey, Marc Vinyals", "title": "Complexity Measures on the Symmetric Group and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the definitions of complexity measures of functions to domains such\nas the symmetric group. The complexity measures we consider include degree,\napproximate degree, decision tree complexity, sensitivity, block sensitivity,\nand a few others. We show that these complexity measures are polynomially\nrelated for the symmetric group and for many other domains.\n  To show that all measures but sensitivity are polynomially related, we\ngeneralize classical arguments of Nisan and others. To add sensitivity to the\nmix, we reduce to Huang's sensitivity theorem using \"pseudo-characters\", which\nwitness the degree of a function.\n  Using similar ideas, we extend the characterization of Boolean degree 1\nfunctions on the symmetric group due to Ellis, Friedgut and Pilpel to the\nperfect matching scheme. As another application of our ideas, we simplify the\ncharacterization of maximum-size $t$-intersecting families in the symmetric\ngroup and the perfect matching scheme.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 21:07:41 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Dafni", "Neta", ""], ["Filmus", "Yuval", ""], ["Lifshitz", "Noam", ""], ["Lindzey", "Nathan", ""], ["Vinyals", "Marc", ""]]}, {"id": "2010.07794", "submitter": "Michel de Rougemont", "authors": "Claire Mathieu and Michel de Rougemont", "title": "Large Very Dense Subgraphs in a Stream of Edges", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the detection and the reconstruction of a large very dense subgraph\nin a social graph with $n$ nodes and $m$ edges given as a stream of edges, when\nthe graph follows a power law degree distribution, in the regime when $m=O(n.\n\\log n)$. A subgraph $S$ is very dense if it has $\\Omega(|S|^2)$ edges. We\nuniformly sample the edges with a Reservoir of size $k=O(\\sqrt{n}.\\log n)$. Our\ndetection algorithm checks whether the Reservoir has a giant component. We show\nthat if the graph contains a very dense subgraph of size $\\Omega(\\sqrt{n})$,\nthen the detection algorithm is almost surely correct. On the other hand, a\nrandom graph that follows a power law degree distribution almost surely has no\nlarge very dense subgraph, and the detection algorithm is almost surely\ncorrect. We define a new model of random graphs which follow a power law degree\ndistribution and have large very dense subgraphs. We then show that on this\nclass of random graphs we can reconstruct a good approximation of the very\ndense subgraph with high probability. We generalize these results to dynamic\ngraphs defined by sliding windows in a stream of edges.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:36:30 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Mathieu", "Claire", ""], ["de Rougemont", "Michel", ""]]}, {"id": "2010.08083", "submitter": "Noujan Pashanasangi", "authors": "Suman K. Bera, Noujan Pashanasangi, C. Seshadhri", "title": "Near-Linear Time Homomorphism Counting in Bounded Degeneracy Graphs: The\n  Barrier of Long Induced Cycles", "comments": "To be published in Symposium on Discrete Algorithms (SODA) 2021 Added\n  conclusion section in the new version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting homomorphisms of a constant sized pattern graph $H$ in an input\ngraph $G$ is a fundamental computational problem. There is a rich history of\nstudying the complexity of this problem, under various constraints on the input\n$G$ and the pattern $H$. Given the significance of this problem and the large\nsizes of modern inputs, we investigate when near-linear time algorithms are\npossible. We focus on the case when the input graph has bounded degeneracy, a\ncommonly studied and practically relevant class for homomorphism counting. It\nis known from previous work that for certain classes of $H$, $H$-homomorphisms\ncan be counted exactly in near-linear time in bounded degeneracy graphs. Can we\nprecisely characterize the patterns $H$ for which near-linear time algorithms\nare possible?\n  We completely resolve this problem, discovering a clean dichotomy using\nfine-grained complexity. Let $m$ denote the number of edges in $G$. We prove\nthe following: if the largest induced cycle in $H$ has length at most $5$, then\nthere is an $O(m\\log m)$ algorithm for counting $H$-homomorphisms in bounded\ndegeneracy graphs. If the largest induced cycle in $H$ has length at least $6$,\nthen (assuming standard fine-grained complexity conjectures) there is a\nconstant $\\gamma > 0$, such that there is no $o(m^{1+\\gamma})$ time algorithm\nfor counting $H$-homomorphisms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 00:59:01 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 02:57:37 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Bera", "Suman K.", ""], ["Pashanasangi", "Noujan", ""], ["Seshadhri", "C.", ""]]}, {"id": "2010.08445", "submitter": "Pavel Dvo\\v{r}\\'ak", "authors": "Pavel Dvo\\v{r}\\'ak, Michal Kouck\\'y", "title": "Barrington Plays Cards: The Complexity of Card-based Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the computational complexity of functions that have\nefficient card-based protocols. Card-based protocols were proposed by den Boer\n[EUROCRYPT '89] as a means for secure two-party computation. Our contribution\nis two-fold: We classify a large class of protocols with respect to the\ncomputational complexity of functions they compute, and we propose other\nencodings of inputs which require fewer cards than the usual 2-card\nrepresentation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 15:16:32 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Dvo\u0159\u00e1k", "Pavel", ""], ["Kouck\u00fd", "Michal", ""]]}, {"id": "2010.08576", "submitter": "Karol W\\k{e}grzycki", "authors": "Jesper Nederlof, Karol W\\k{e}grzycki", "title": "Improving Schroeppel and Shamir's Algorithm for Subset Sum via\n  Orthogonal Vectors", "comments": "STOC 2021, 38 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an $\\mathcal{O}^\\star(2^{0.5n})$ time and\n$\\mathcal{O}^\\star(2^{0.249999n})$ space randomized algorithm for solving\nworst-case Subset Sum instances with $n$ integers. This is the first\nimprovement over the long-standing $\\mathcal{O}^\\star(2^{n/2})$ time and\n$\\mathcal{O}^\\star(2^{n/4})$ space algorithm due to Schroeppel and Shamir (FOCS\n1979).\n  We breach this gap in two steps: (1) We present a space efficient reduction\nto the Orthogonal Vectors Problem (OV), one of the most central problem in\nFine-Grained Complexity. The reduction is established via an intricate\ncombination of the method of Schroeppel and Shamir, and the representation\ntechnique introduced by Howgrave-Graham and Joux (EUROCRYPT 2010) for designing\nSubset Sum algorithms for the average case regime. (2) We provide an algorithm\nfor OV that detects an orthogonal pair among $N$ given vectors in $\\{0,1\\}^d$\nwith support size $d/4$ in time $\\tilde{O}(N\\cdot2^d/\\binom{d}{d/4})$. Our\nalgorithm for OV is based on and refines the representative families framework\ndeveloped by Fomin, Lokshtanov, Panolan and Saurabh (J. ACM 2016).\n  Our reduction uncovers a curious tight relation between Subset Sum and OV,\nbecause any improvement of our algorithm for OV would imply an improvement over\nthe runtime of Schroeppel and Shamir, which is also a long standing open\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 18:18:22 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 11:23:25 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Nederlof", "Jesper", ""], ["W\u0119grzycki", "Karol", ""]]}, {"id": "2010.08821", "submitter": "Noah Stephens-Davidowitz", "authors": "Zvika Brakerski, Noah Stephens-Davidowitz, Vinod Vaikuntanathan", "title": "On the Hardness of Average-case k-SUM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we show the first worst-case to average-case reduction for the\nclassical $k$-SUM problem. A $k$-SUM instance is a collection of $m$ integers,\nand the goal of the $k$-SUM problem is to find a subset of $k$ elements that\nsums to $0$. In the average-case version, the $m$ elements are chosen uniformly\nat random from some interval $[-u,u]$.\n  We consider the total setting where $m$ is sufficiently large (with respect\nto $u$ and $k$), so that we are guaranteed (with high probability) that\nsolutions must exist. Much of the appeal of $k$-SUM, in particular connections\nto problems in computational geometry, extends to the total setting.\n  The best known algorithm in the average-case total setting is due to Wagner\n(following the approach of Blum-Kalai-Wasserman), and achieves a run-time of\n$u^{O(1/\\log k)}$. This beats the known (conditional) lower bounds for\nworst-case $k$-SUM, raising the natural question of whether it can be improved\neven further. However, in this work, we show a matching average-case\nlower-bound, by showing a reduction from worst-case lattice problems, thus\nintroducing a new family of techniques into the field of fine-grained\ncomplexity. In particular, we show that any algorithm solving average-case\n$k$-SUM on $m$ elements in time $u^{o(1/\\log k)}$ will give a super-polynomial\nimprovement in the complexity of algorithms for lattice problems.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 16:39:41 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 00:56:30 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Brakerski", "Zvika", ""], ["Stephens-Davidowitz", "Noah", ""], ["Vaikuntanathan", "Vinod", ""]]}, {"id": "2010.08862", "submitter": "Jayson Lynch", "authors": "Michael Hoffmann, Jayson Lynch, Andrew Winslow", "title": "Mad Science is Provably Hard: Puzzles in Hearthstone's Boomsday Lab are\n  NP-hard", "comments": "17 pages, 4 appendix, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the computational complexity of winning this turn (mate-in-1 or\n\"finding lethal\") in Hearthstone as well as several other single turn puzzle\ntypes introduced in the Boomsday Lab expansion. We consider three natural\ngeneralizations of Hearthstone (in which hand size, board size, and deck size\nscale) and prove the various puzzle types in each generalization NP-hard.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 20:51:25 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Hoffmann", "Michael", ""], ["Lynch", "Jayson", ""], ["Winslow", "Andrew", ""]]}, {"id": "2010.08994", "submitter": "Sam McGuire", "authors": "Alexander Knop, Shachar Lovett, Sam McGuire, Weiqiang Yuan", "title": "Log-rank and lifting for AND-functions", "comments": "20 pages; comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $f: \\{0,1\\}^n \\to \\{0, 1\\}$ be a boolean function, and let $f_\\land (x,\ny) = f(x \\land y)$ denote the AND-function of $f$, where $x \\land y$ denotes\nbit-wise AND. We study the deterministic communication complexity of $f_\\land$\nand show that, up to a $\\log n$ factor, it is bounded by a polynomial in the\nlogarithm of the real rank of the communication matrix of $f_\\land$. This comes\nwithin a $\\log n$ factor of establishing the log-rank conjecturefor\nAND-functions with no assumptions on $f$. Our result stands in contrast with\nprevious results on special cases of the log-rank conjecture, which needed\nsignificant restrictions on $f$ such as monotonicity or low\n$\\mathbb{F}_2$-degree. Our techniques can also be used to prove (within a $\\log\nn$ factor) a lifting theorem for AND-functions, stating that the deterministic\ncommunication complexity of $f_\\land$ is polynomially-related to the\nAND-decision tree complexity of $f$.\n  The results rely on a new structural result regarding boolean functions\n$f:\\{0, 1\\}^n \\to \\{0, 1\\}$ with a sparse polynomial representation, which may\nbe of independent interest. We show that if the polynomial computing $f$ has\nfew monomials then the set system of the monomials has a small hitting set, of\nsize poly-logarithmic in its sparsity. We also establish extensions of this\nresult to multi-linear polynomials $f:\\{0,1\\}^n \\to \\mathbb{R}$ with a larger\nrange.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 14:22:05 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 16:29:48 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Knop", "Alexander", ""], ["Lovett", "Shachar", ""], ["McGuire", "Sam", ""], ["Yuan", "Weiqiang", ""]]}, {"id": "2010.09014", "submitter": "Michiel de Bondt", "authors": "Michiel de Bondt", "title": "Solving Shisen-Sho boards", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simple proof of that determining solvability of Shisen-Sho boards\nis NP-complete. Furthermore, we show that under realistic assumptions, one can\ncompute in logarithmic time if two tiles form a playable pair.\n  We combine an implementation of the algoritm to test playability of pairs\nwith my earlier algorithm to solve Mahjong Solitaire boards with peeking, to\nobtain an algorithm to solve Shisen-Sho boards. We sample several Shisen-Sho\nand Mahjong Solitaire layouts for solvability for Shisen-Sho and Mahjong\nSolitaire.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 16:16:18 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["de Bondt", "Michiel", ""]]}, {"id": "2010.09255", "submitter": "Alexandra Lassota", "authors": "Sebastian Berndt, Klaus Jansen, Alexandra Lassota", "title": "Tightness of Sensitivity and Proximity Bounds for Integer Linear\n  Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider ILPs, where each variable corresponds to an integral point within\na polytope $\\mathcal{P}$, i. e., ILPs of the form $\\min\\{c^{\\top}x\\mid\n\\sum_{p\\in\\mathcal P\\cap \\mathbb Z^d} x_p p = b, x\\in\\mathbb Z^{|\\mathcal P\\cap\n\\mathbb Z^d|}_{\\ge 0}\\}$.\n  The distance between an optimal fractional solution and an optimal integral\nsolution (called proximity) is an important measure. A classical result by Cook\net al.~(Math. Program., 1986) shows that it is at most $\\Delta^{\\Theta(d)}$\nwhere $\\Delta$ is the largest coefficient in the constraint matrix.\n  Another important measure studies the change in an optimal solution if the\nright-hand side $b$ is replaced by another right-hand side $b'$. The distance\nbetween an optimal solution $x$ w.r.t.~$b$ and an optimal solution $x'$\nw.r.t.~$b'$ (called sensitivity) is similarly bounded, i. e., $\\lVert b-b'\n\\rVert_{1}\\cdot \\Delta^{\\Theta(d)}$, also shown by Cook et al.\n  Even after more than thirty years, these bounds are essentially the best\nknown bounds for these measures.\n  While some lower bounds are known for these measures, they either only work\nfor very small values of $\\Delta$, require negative entries in the constraint\nmatrix, or have fractional right-hand sides.\n  Hence, these lower bounds often do not correspond to instances from\nalgorithmic problems.\n  This work presents for each $\\Delta > 0$ and each $d > 0$ ILPs of the above\ntype with non-negative constraint matrices such that their proximity and\nsensitivity is at least $\\Delta^{\\Theta(d)}$.\n  Furthermore, these instances are closely related to instances of the Bin\nPacking problem as they form a subset of columns of the configuration ILP.\n  We thereby show that the results of Cook et al. are indeed tight, even for\ninstances arising naturally from problems in combinatorial optimization.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 06:48:56 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Berndt", "Sebastian", ""], ["Jansen", "Klaus", ""], ["Lassota", "Alexandra", ""]]}, {"id": "2010.09271", "submitter": "Julian Wellman", "authors": "Josh Brunner, Erik D. Demaine, Dylan Hendrickson, Julian Wellman", "title": "Complexity of Retrograde and Helpmate Chess Problems: Even Cooperative\n  Chess is Hard", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove PSPACE-completeness of two classic types of Chess problems when\ngeneralized to n-by-n boards. A \"retrograde\" problem asks whether it is\npossible for a position to be reached from a natural starting position, i.e.,\nwhether the position is \"valid\" or \"legal\" or \"reachable\". Most real-world\nretrograde Chess problems ask for the last few moves of such a sequence; we\nanalyze the decision question which gets at the existence of an exponentially\nlong move sequence. A \"helpmate\" problem asks whether it is possible for a\nplayer to become checkmated by any sequence of moves from a given position. A\nhelpmate problem is essentially a cooperative form of Chess, where both players\nwork together to cause a particular player to win; it also arises in regular\nChess games, where a player who runs out of time (flags) loses only if they\ncould ever possibly be checkmated from the current position (i.e., the helpmate\nproblem has a solution). Our PSPACE-hardness reductions are from a variant of a\npuzzle game called Subway Shuffle.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 07:32:47 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Brunner", "Josh", ""], ["Demaine", "Erik D.", ""], ["Hendrickson", "Dylan", ""], ["Wellman", "Julian", ""]]}, {"id": "2010.09884", "submitter": "Elaine Shi", "authors": "Gilad Asharov, Wei-Kai Lin, Elaine Shi", "title": "Sorting Short Keys in Circuits of Size o(n log n)", "comments": "SODA'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical problem of sorting an input array containing $n$\nelements, where each element is described with a $k$-bit comparison-key and a\n$w$-bit payload. A long-standing open problem is whether there exist $(k + w)\n\\cdot o(n \\log n)$-sized boolean circuits for sorting. We show that one can\novercome the $n\\log n$ barrier when the keys to be sorted are short.\nSpecifically, we prove that there is a circuit with $(k + w) \\cdot O(n k) \\cdot\n\\poly(\\log^*n - \\log^* (w + k))$ boolean gates capable of sorting any input\narray containing $n$ elements, each described with a $k$-bit key and a $w$-bit\npayload. Therefore, if the keys to be sorted are short, say, $k < o(\\log n)$,\nour result is asymptotically better than the classical AKS sorting network\n(ignoring $\\poly\\log^*$ terms); and we also overcome the $n \\log n$ barrier in\nsuch cases. Such a result might be surprising initially because it is long\nknown that comparator-based techniques must incur $\\Omega(n \\log n)$ comparator\ngates even when the keys to be sorted are only $1$-bit long (e.g., see Knuth's\n\"Art of Programming\" textbook). To the best of our knowledge, we are the first\nto achieve non-trivial results for sorting circuits using non-comparison-based\ntechniques. We also show that if the Li-Li network coding conjecture is true,\nour upper bound is optimal, barring $\\poly\\log^*$ terms, for every $k$ as long\nas $k = O(\\log n)$.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 13:17:44 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 20:31:54 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Asharov", "Gilad", ""], ["Lin", "Wei-Kai", ""], ["Shi", "Elaine", ""]]}, {"id": "2010.10028", "submitter": "David Pastor-Escuredo", "authors": "David Pastor-Escuredo and Ricardo Vinuesa", "title": "Towards and Ethical Framework in the Complex Digital Era", "comments": "arXiv admin note: text overlap with arXiv:2003.06530", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since modernity, ethic has been progressively fragmented into specific\ncommunities of practice. The digital revolution enabled by AI and Data is\nbringing ethical wicked problems in the crossroads of technology and behavior.\nHowever, the need of a comprehensive and constructive ethical framework is\nemerging as digital platforms connect us globally. The unequal structure of the\nglobal system makes that dynamic changes and systemic problems impact more on\nthose that are most vulnerable. Ethical frameworks based only on the\nindividual-level are not longer sufficient. A new ethical vision must comprise\nthe understanding of the scales and complex interconnections of social systems.\nMany of these systems are internally fragile and very sensitive to external\nfactors and threats, which turns into unethical situations that require\nsystemic solutions. The high scale nature of digital technology that expands\nglobally has also an impact at the individual level having the risk to make\nhumans beings more homogeneous, predictable and ultimately controllable. To\npreserve the core of humanity ethic must take a stand to preserve and keep\npromoting individual rights and uniqueness and cultural heterogeneity tackling\nthe negative trends and impact of digitalization. Only combining human-centered\nand collectiveness-oriented digital development it will be possible to\nconstruct new social models and human-machine interactions that are ethical.\nThis vision requires science to enhance ethical frameworks and principles with\nthe actionable insights of relationships and properties of the social systems\nthat may not be evident and need to be quantified and understood to be solved.\nArtificial Intelligence is both a risk and and opportunity for an ethical\ndevelopment, thus we need a conceptual construct that drives towards a better\ndigitalizated world.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 15:28:04 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Pastor-Escuredo", "David", ""], ["Vinuesa", "Ricardo", ""]]}, {"id": "2010.10189", "submitter": "Victor Selivanov", "authors": "Victor Selivanov and Svetlana Selivanova", "title": "Primitive Recursive Ordered Fields and Some Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish primitive recursive versions of some known facts about\ncomputable ordered fields of reals and computable reals, and then apply them to\nproving primitive recursiveness of some natural problems in linear algebra and\nanalysis. In particular, we find a partial primitive recursive analogue of\nErshov-Madison's theorem about real closures of computable ordered fields,\nrelate the corresponding fields to the primitive recursive reals, give\nsufficient conditions for primitive recursive root-finding, computing normal\nforms of matrices, and computing solution operators of some linear systems of\nPDE.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 10:53:13 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Selivanov", "Victor", ""], ["Selivanova", "Svetlana", ""]]}, {"id": "2010.10314", "submitter": "Kitty Meeks", "authors": "Jessica Enright, Duncan Lee, Kitty Meeks, William Pettersson and John\n  Sylvester", "title": "The complexity of finding optimal subgraphs to represent spatial\n  correlation", "comments": "New results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lee, Meeks and Pettersson recently demonstrated that improved inference for\nareal unit count data can be achieved by carrying out modifications to a graph\nrepresenting spatial correlations; specifically, they delete edges of the\nplanar graph derived from border-sharing between geographic regions in order to\nmaximise a specific objective function. In this paper we address the\ncomputational complexity of the associated graph optimisation problem,\ndemonstrating that it cannot be solved in polynomial time unless P = NP; we\nfurther show intractability for a related but simpler problem.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 14:24:47 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 08:07:39 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 16:39:22 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Enright", "Jessica", ""], ["Lee", "Duncan", ""], ["Meeks", "Kitty", ""], ["Pettersson", "William", ""], ["Sylvester", "John", ""]]}, {"id": "2010.10997", "submitter": "Pierre Lairez", "authors": "Peter B\\\"urgisser, Felipe Cucker and Pierre Lairez", "title": "Rigid continuation paths II. Structured polynomial systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the average complexity of solving structured polynomial\nsystems that are characterized by a low evaluation cost, as opposed to the\ndense random model previously used. Firstly, we design a continuation algorithm\nthat computes, with high probability, an approximate zero of a polynomial\nsystem given only as black-box evaluation program. Secondly, we introduce a\nuniversal model of random polynomial systems with prescribed evaluation\ncomplexity L. Combining both, we show that we can compute an approximate zero\nof a random structured polynomial system with n equations of degree at most\n{\\delta} in n variables with only poly(n, {\\delta}) L operations with high\nprobability. This exceeds the expectations implicit in Smale's 17th problem.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:37:35 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 19:18:10 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["B\u00fcrgisser", "Peter", ""], ["Cucker", "Felipe", ""], ["Lairez", "Pierre", ""]]}, {"id": "2010.11381", "submitter": "Li-Yang Tan", "authors": "Guy Blanc, Jane Lange, Li-Yang Tan", "title": "Query strategies for priced information, revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing query strategies for priced information,\nintroduced by Charikar et al. In this problem the algorithm designer is given a\nfunction $f : \\{0,1\\}^n \\to \\{-1,1\\}$ and a price associated with each of the\n$n$ coordinates. The goal is to design a query strategy for determining $f$'s\nvalue on unknown inputs for minimum cost.\n  Prior works on this problem have focused on specific classes of functions. We\nanalyze a simple and natural strategy that applies to all functions $f$, and\nshow that its performance relative to the optimal strategy can be expressed in\nterms of a basic complexity measure of $f$, its influence. For $\\varepsilon \\in\n(0,\\frac1{2})$, writing $\\mathsf{opt}$ to denote the expected cost of the\noptimal strategy that errs on at most an $\\varepsilon$-fraction of inputs, our\nstrategy has expected cost $\\mathsf{opt} \\cdot \\mathrm{Inf}(f)/\\varepsilon^2$\nand also errs on at most an $O(\\varepsilon)$-fraction of inputs. This\nconnection yields new guarantees that complement existing ones for a number of\nfunction classes that have been studied in this context, as well as new\nguarantees for new classes.\n  Finally, we show that improving on the parameters that we achieve will\nrequire making progress on the longstanding open problem of properly learning\ndecision trees.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 02:10:58 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Blanc", "Guy", ""], ["Lange", "Jane", ""], ["Tan", "Li-Yang", ""]]}, {"id": "2010.11658", "submitter": "Yu-Hsuan Huang", "authors": "Kai-Min Chung, Serge Fehr, Yu-Hsuan Huang, Tai-Ning Liao", "title": "On the Compressed-Oracle Technique, and Post-Quantum Security of Proofs\n  of Sequential Work", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the so-called compressed oracle technique, introduced by Zhandry\nfor analyzing quantum algorithms in the quantum random oracle model (QROM). To\nstart off with, we offer a concise exposition of the technique, which easily\nextends to the parallel-query QROM, where in each query-round the considered\nalgorithm may make several queries to the QROM in parallel. This variant of the\nQROM allows for a more fine-grained query-complexity analysis.\n  Our main technical contribution is a framework that simplifies the use of\n(the parallel-query generalization of) the compressed oracle technique for\nproving query complexity results. With our framework in place, whenever\napplicable, it is possible to prove quantum query complexity lower bounds by\nmeans of purely classical reasoning. More than that, for typical examples the\ncrucial classical observations that give rise to the classical bounds are\nsufficient to conclude the corresponding quantum bounds.\n  We demonstrate this on a few examples, recovering known results (like the\noptimality of parallel Grover), but also obtaining new results (like the\noptimality of parallel BHT collision search). Our main target is the hardness\nof finding a $q$-chain with fewer than $q$ parallel queries, i.e., a sequence\n$x_0, x_1,\\ldots, x_q$ with $x_i = H(x_{i-1})$ for all $1 \\leq i \\leq q$.\n  The above problem of finding a hash chain is of fundamental importance in the\ncontext of proofs of sequential work. Indeed, as a concrete cryptographic\napplication of our techniques, we prove that the \"Simple Proofs of Sequential\nWork\" proposed by Cohen and Pietrzak remains secure against quantum attacks.\nSuch an analysis is not simply a matter of plugging in our new bound; the\nentire protocol needs to be analyzed in the light of a quantum attack. Thanks\nto our framework, this can now be done with purely classical reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:44:08 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 12:00:18 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 17:34:03 GMT"}, {"version": "v4", "created": "Fri, 9 Jul 2021 09:06:07 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Chung", "Kai-Min", ""], ["Fehr", "Serge", ""], ["Huang", "Yu-Hsuan", ""], ["Liao", "Tai-Ning", ""]]}, {"id": "2010.11754", "submitter": "Aniruddha Biswas", "authors": "Aniruddha Biswas and Palash Sarkar", "title": "Separation Results for Boolean Function Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show (almost) separation between certain important classes of Boolean\nfunctions. The technique that we use is to show that the total influence of\nfunctions in one class is less than the total influence of functions in the\nother class. In particular, we show (almost) separation of several classes of\nBoolean functions which have been studied in the coding theory and cryptography\nfrom classes which have been studied in combinatorics and complexity theory.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:16:54 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Biswas", "Aniruddha", ""], ["Sarkar", "Palash", ""]]}, {"id": "2010.11788", "submitter": "Armin Wei{\\ss}", "authors": "Pawe{\\l} Idziak, Piotr Kawa{\\l}ek, Jacek Krzaczkowski, Armin Wei{\\ss}", "title": "Equation satisfiability in solvable groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of the complexity of the equation satisfiability problem in finite\ngroups had been initiated by Goldmann and Russell (2002) where they showed that\nthis problem is in polynomial time for nilpotent groups while it is NP-complete\nfor non-solvable groups. Since then, several results have appeared showing that\nthe problem can be solved in polynomial time in certain solvable groups $G$\nhaving a nilpotent normal subgroup $H$ with nilpotent factor $G/H$. This paper\nshows that such normal subgroup must exist in each finite group with equation\nsatisfiability solvable in polynomial time, unless the Exponential Time\nHypothesis fails.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 15:05:55 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Idziak", "Pawe\u0142", ""], ["Kawa\u0142ek", "Piotr", ""], ["Krzaczkowski", "Jacek", ""], ["Wei\u00df", "Armin", ""]]}, {"id": "2010.11983", "submitter": "Murphy Yuezhen Niu", "authors": "Murphy Yuezhen Niu, Andrew M. Dai, Li Li, Augustus Odena, Zhengli\n  Zhao, Vadim Smelyanskyi, Hartmut Neven, and Sergio Boixo", "title": "Learnability and Complexity of Quantum Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a quantum circuit, a quantum computer can sample the output\ndistribution exponentially faster in the number of bits than classical\ncomputers. A similar exponential separation has yet to be established in\ngenerative models through quantum sample learning: given samples from an\nn-qubit computation, can we learn the underlying quantum distribution using\nmodels with training parameters that scale polynomial in n under a fixed\ntraining time? We study four kinds of generative models: Deep Boltzmann machine\n(DBM), Generative Adversarial Networks (GANs), Long Short-Term Memory (LSTM)\nand Autoregressive GAN, on learning quantum data set generated by deep random\ncircuits. We demonstrate the leading performance of LSTM in learning quantum\nsamples, and thus the autoregressive structure present in the underlying\nquantum distribution from random quantum circuits. Both numerical experiments\nand a theoretical proof in the case of the DBM show exponentially growing\ncomplexity of learning-agent parameters required for achieving a fixed accuracy\nas n increases. Finally, we establish a connection between learnability and the\ncomplexity of generative models by benchmarking learnability against different\nsets of samples drawn from probability distributions of variable degrees of\ncomplexities in their quantum and classical representations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 18:45:25 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Niu", "Murphy Yuezhen", ""], ["Dai", "Andrew M.", ""], ["Li", "Li", ""], ["Odena", "Augustus", ""], ["Zhao", "Zhengli", ""], ["Smelyanskyi", "Vadim", ""], ["Neven", "Hartmut", ""], ["Boixo", "Sergio", ""]]}, {"id": "2010.12081", "submitter": "Sankeerth Rao Karingula", "authors": "Sankeerth Rao Karingula and Shachar Lovett", "title": "Codes over integers, and the singularity of random matrices with large\n  entries", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prototypical construction of error correcting codes is based on linear\ncodes over finite fields. In this work, we make first steps in the study of\ncodes defined over integers. We focus on Maximum Distance Separable (MDS)\ncodes, and show that MDS codes with linear rate and distance can be realized\nover the integers with a constant alphabet size. This is in contrast to the\nsituation over finite fields, where a linear size finite field is needed.\n  The core of this paper is a new result on the singularity probability of\nrandom matrices. We show that for a random $n \\times n$ matrix with entries\nchosen independently from the range $\\{-m,\\ldots,m\\}$, the probability that it\nis singular is at most $m^{-cn}$ for some absolute constant $c>0$.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 21:41:23 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Karingula", "Sankeerth Rao", ""], ["Lovett", "Shachar", ""]]}, {"id": "2010.12122", "submitter": "Francois Le Gall", "authors": "Fran\\c{c}ois Le Gall and Saeed Seddighin", "title": "Quantum Meets Fine-grained Complexity: Sublinear Time Quantum Algorithms\n  for String Problems", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Longest common substring (LCS), longest palindrome substring (LPS), and Ulam\ndistance (UL) are three fundamental string problems that can be classically\nsolved in near linear time. In this work, we present sublinear time quantum\nalgorithms for these problems along with quantum lower bounds. Our results shed\nlight on a very surprising fact: Although the classic solutions for LCS and LPS\nare almost identical (via suffix trees), their quantum computational\ncomplexities are different. While we give an exact $\\tilde O(\\sqrt{n})$ time\nalgorithm for LPS, we prove that LCS needs at least time $\\tilde\n\\Omega(n^{2/3})$ even for 0/1 strings.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 01:00:50 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Gall", "Fran\u00e7ois Le", ""], ["Seddighin", "Saeed", ""]]}, {"id": "2010.12265", "submitter": "Bernardo Anibal Subercaseaux Roa", "authors": "Pablo Barcel\\'o, Mika\\\"el Monet, Jorge P\\'erez, Bernardo Subercaseaux", "title": "Model Interpretability through the Lens of Computational Complexity", "comments": "36 pages, including 9 pages of main text. This is the arXiv version\n  of the NeurIPS'2020 paper. Except from minor differences that could be\n  introduced by the publisher, the only difference should be the addition of\n  the appendix, which contains all the proofs that do not appear in the main\n  text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of several claims stating that some models are more interpretable\nthan others -- e.g., \"linear models are more interpretable than deep neural\nnetworks\" -- we still lack a principled notion of interpretability to formally\ncompare among different classes of models. We make a step towards such a notion\nby studying whether folklore interpretability claims have a correlate in terms\nof computational complexity theory. We focus on local post-hoc explainability\nqueries that, intuitively, attempt to answer why individual inputs are\nclassified in a certain way by a given model. In a nutshell, we say that a\nclass $\\mathcal{C}_1$ of models is more interpretable than another class\n$\\mathcal{C}_2$, if the computational complexity of answering post-hoc queries\nfor models in $\\mathcal{C}_2$ is higher than for those in $\\mathcal{C}_1$. We\nprove that this notion provides a good theoretical counterpart to current\nbeliefs on the interpretability of models; in particular, we show that under\nour definition and assuming standard complexity-theoretical assumptions (such\nas P$\\neq$NP), both linear and tree-based models are strictly more\ninterpretable than neural networks. Our complexity analysis, however, does not\nprovide a clear-cut difference between linear and tree-based models, as we\nobtain different results depending on the particular post-hoc explanations\nconsidered. Finally, by applying a finer complexity analysis based on\nparameterized complexity, we are able to prove a theoretical result suggesting\nthat shallow neural networks are more interpretable than deeper ones.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:50:40 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 21:57:06 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Barcel\u00f3", "Pablo", ""], ["Monet", "Mika\u00ebl", ""], ["P\u00e9rez", "Jorge", ""], ["Subercaseaux", "Bernardo", ""]]}, {"id": "2010.12629", "submitter": "Robin Kothari", "authors": "Scott Aaronson and Shalev Ben-David and Robin Kothari and Shravas Rao\n  and Avishay Tal", "title": "Degree vs. Approximate Degree and Quantum Implications of Huang's\n  Sensitivity Theorem", "comments": "This subsumes an earlier preprint by a subset of the authors\n  (arXiv:2004.13231)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the recent breakthrough of Huang (2019), we show that for any total\nBoolean function $f$,\n  $\\bullet \\quad \\mathrm{deg}(f) = O(\\widetilde{\\mathrm{deg}}(f)^2)$: The\ndegree of $f$ is at most quadratic in the approximate degree of $f$. This is\noptimal as witnessed by the OR function.\n  $\\bullet \\quad \\mathrm{D}(f) = O(\\mathrm{Q}(f)^4)$: The deterministic query\ncomplexity of $f$ is at most quartic in the quantum query complexity of $f$.\nThis matches the known separation (up to log factors) due to Ambainis, Balodis,\nBelovs, Lee, Santha, and Smotrovs (2017).\n  We apply these results to resolve the quantum analogue of the\nAanderaa--Karp--Rosenberg conjecture. We show that if $f$ is a nontrivial\nmonotone graph property of an $n$-vertex graph specified by its adjacency\nmatrix, then $\\mathrm{Q}(f)=\\Omega(n)$, which is also optimal. We also show\nthat the approximate degree of any read-once formula on $n$ variables is\n$\\Theta(\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 19:21:28 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Aaronson", "Scott", ""], ["Ben-David", "Shalev", ""], ["Kothari", "Robin", ""], ["Rao", "Shravas", ""], ["Tal", "Avishay", ""]]}, {"id": "2010.13020", "submitter": "Lirong Xia", "authors": "Lirong Xia, Weiqiang Zheng", "title": "The Smoothed Complexity of Computing Kemeny and Slater Rankings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of winner determination under common voting\nrules is a classical and fundamental topic in the field of computational social\nchoice. Previous work has established the NP-hardness of winner determination\nunder some commonly-studied voting rules, especially the Kemeny rule and the\nSlater rule. In a recent blue-sky paper, Baumeister, Hogrebe, and Rothe (2020)\nquestioned the relevance of the worst-case nature of NP-hardness in social\nchoice and proposed to conduct smoothed complexity analysis (Spielman and Teng\n2009) under Blaser and Manthey (2015)'s framework.\n  In this paper, we develop the first smoothed complexity results for winner\ndetermination in voting. We illustrate the inappropriateness of Blaser and\nManthey (2015)'s smoothed complexity framework in social choice contexts by\nproving a paradoxical result, which states that the exponential-time brute\nforce search algorithm is smoothed poly-time according to their definition. We\nthen prove the smoothed hardness of Kemeny and Slater using the classical\nsmoothed complexity analysis, and prove a parameterized typical-case smoothed\neasiness result for Kemeny. Overall, our results show that smoothed complexity\nanalysis in computational social choice is a challenging and fruitful topic.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 02:37:11 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Xia", "Lirong", ""], ["Zheng", "Weiqiang", ""]]}, {"id": "2010.13180", "submitter": "Jason Yang", "authors": "Jason Yang, Jun Wan", "title": "On Updating and Querying Submatrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the $d$-dimensional update-query problem. We provide\nlower bounds on update and query running times, assuming a long-standing\nconjecture on min-plus matrix multiplication, as well as algorithms that are\nclose to the lower bounds. Given a $d$-dimensional matrix, an \\textit{update}\nchanges each element in a given submatrix from $x$ to $x\\bigtriangledown v$,\nwhere $v$ is a given constant. A \\textit{query} returns the $\\bigtriangleup$ of\nall elements in a given submatrix. We study the cases where $\\bigtriangledown$\nand $\\bigtriangleup$ are both commutative and associative binary operators.\nWhen $d = 1$, updates and queries can be performed in $O(\\log N)$ worst-case\ntime for many $(\\bigtriangledown,\\bigtriangleup)$ by using a segment tree with\nlazy propagation. However, when $d\\ge 2$, similar techniques usually cannot be\ngeneralized. We show that if min-plus matrix multiplication cannot be computed\nin $O(N^{3-\\varepsilon})$ time for any $\\varepsilon>0$ (which is widely\nbelieved to be the case), then for\n$(\\bigtriangledown,\\bigtriangleup)=(+,\\min)$, either updates or queries cannot\nboth run in $O(N^{1-\\varepsilon})$ time for any constant $\\varepsilon>0$, or\npreprocessing cannot run in polynomial time. Finally, we show a special case\nwhere lazy propagation can be generalized for $d\\ge 2$ and where updates and\nqueries can run in $O(\\log^d N)$ worst-case time. We present an algorithm that\nmeets this running time and is simpler than similar algorithms of previous\nworks.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 18:17:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yang", "Jason", ""], ["Wan", "Jun", ""]]}, {"id": "2010.13717", "submitter": "Thomas Mu\\~noz", "authors": "Floris Geerts, Thomas Mu\\~noz, Cristian Riveros and Domagoj Vrgo\\v{c}", "title": "Expressive power of linear algebra query languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear algebra algorithms often require some sort of iteration or recursion\nas is illustrated by standard algorithms for Gaussian elimination, matrix\ninversion, and transitive closure. A key characteristic shared by these\nalgorithms is that they allow looping for a number of steps that is bounded by\nthe matrix dimension. In this paper we extend the matrix query language MATLANG\nwith this type of recursion, and show that this suffices to express classical\nlinear algebra algorithms. We study the expressive power of this language and\nshow that it naturally corresponds to arithmetic circuit families, which are\noften said to capture linear algebra. Furthermore, we analyze several\nsub-fragments of our language, and show that their expressive power is closely\ntied to logical formalisms on semiring-annotated relations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:59:09 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Geerts", "Floris", ""], ["Mu\u00f1oz", "Thomas", ""], ["Riveros", "Cristian", ""], ["Vrgo\u010d", "Domagoj", ""]]}, {"id": "2010.14181", "submitter": "Karl Bringmann", "authors": "Amir Abboud, Arturs Backurs, Karl Bringmann, Marvin K\\\"unnemann", "title": "Impossibility Results for Grammar-Compressed Linear Algebra", "comments": "NeurIPS'20, 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To handle vast amounts of data, it is natural and popular to compress vectors\nand matrices. When we compress a vector from size $N$ down to size $n \\ll N$,\nit certainly makes it easier to store and transmit efficiently, but does it\nalso make it easier to process?\n  In this paper we consider lossless compression schemes, and ask if we can run\nour computations on the compressed data as efficiently as if the original data\nwas that small. That is, if an operation has time complexity\n$T(\\rm{inputsize})$, can we perform it on the compressed representation in time\n$T(n)$ rather than $T(N)$? We consider the most basic linear algebra\noperations: inner product, matrix-vector multiplication, and matrix\nmultiplication. In particular, given two compressed vectors, can we compute\ntheir inner product in time $O(n)$? Or perhaps we must decompress first and\nthen multiply, spending $\\Omega(N)$ time?\n  The answer depends on the compression scheme. While for simple ones such as\nRun-Length-Encoding (RLE) the inner product can be done in $O(n)$ time, we\nprove that this is impossible for compressions from a richer class: essentially\n$n^2$ or even larger runtimes are needed in the worst case (under complexity\nassumptions). This is the class of grammar-compressions containing most popular\nmethods such as the Lempel-Ziv family. These schemes are more compressing than\nthe simple RLE, but alas, we prove that performing computations on them is much\nharder.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 10:33:01 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Abboud", "Amir", ""], ["Backurs", "Arturs", ""], ["Bringmann", "Karl", ""], ["K\u00fcnnemann", "Marvin", ""]]}, {"id": "2010.14338", "submitter": "Lukas N\\\"olke", "authors": "Antonios Antoniadis, Margarita Capretto, Parinya Chalermsook,\n  Christoph Damerius, Peter Kling, Lukas N\\\"olke, Nidia Obscura, Joachim\n  Spoerhase", "title": "On Minimum Generalized Manhattan Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider minimum-cardinality Manhattan connected sets with arbitrary\ndemands: Given a collection of points $P$ in the plane, together with a subset\nof pairs of points in $P$ (which we call demands), find a minimum-cardinality\nsuperset of $P$ such that every demand pair is connected by a path whose length\nis the $\\ell_1$-distance of the pair. This problem is a variant of three\nwell-studied problems that have arisen in computational geometry, data\nstructures, and network design: (i) It is a node-cost variant of the classical\nManhattan network problem, (ii) it is an extension of the binary search tree\nproblem to arbitrary demands, and (iii) it is a special case of the directed\nSteiner forest problem. Since the problem inherits basic structural properties\nfrom the context of binary search trees, an $O(\\log n)$-approximation is\ntrivial. We show that the problem is NP-hard and present an $O(\\sqrt{\\log\nn})$-approximation algorithm. Moreover, we provide an $O(\\log\\log\nn)$-approximation algorithm for complete bipartite demands as well as improved\nresults for unit-disk demands and several generalizations. Our results\ncrucially rely on a new lower bound on the optimal cost that could potentially\nbe useful in the context of BSTs.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 14:54:13 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Antoniadis", "Antonios", ""], ["Capretto", "Margarita", ""], ["Chalermsook", "Parinya", ""], ["Damerius", "Christoph", ""], ["Kling", "Peter", ""], ["N\u00f6lke", "Lukas", ""], ["Obscura", "Nidia", ""], ["Spoerhase", "Joachim", ""]]}, {"id": "2010.14752", "submitter": "Baisakh Baisakh", "authors": "Baisakh, Rakesh Mohanty", "title": "Competitive Analysis of Move-to-Front-or-Middle (MFM) Online List Update\n  Algorithm", "comments": "11 pages, 1 figure, 3 tables. arXiv admin note: text overlap with\n  arXiv:2010.13042", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design and analysis of efficient algorithms with the knowledge of current\nand past inputs is a non-trivial and challenging research area in computer\nscience. In many practical applications the future inputs are not available to\nthe algorithm at any instance of time. So the algorithm has to make decisions\nbased on a sequence of inputs that are in order and on the fly. Such algorithms\nare known as online algorithms. For measuring the performance of online\nalgorithms, a standard measure, known as competitive analysis, has been\nextensively used in the literature. List update problem is a well studied\nresearch problem in the area of online algorithms since last few decades. One\nof the widely used deterministic online list update algorithm is the\nMove-To-Front (MTF) algorithm, which has been shown to be 2-competitive with\nbest performance in practical real life inputs. In this paper we analyse the\nMove-to-Front-or-Middle (MFM) algorithm using competitive analysis by\naddressing one of an open question raised by Albers that whether dynamic\noffline algorithm can be used in finding the competitiveness of an online\nalgorithm? Move-To-Front-or-Middle (MFM) was experimentally studied and\nobserved to be performing better than MTF algorithm by using the Calgary Corpus\nand Canterbury Corpus data set. However, it is interesting and challenging to\nfind the lower bound and upper bound on the competitive ratio of MFM algorithm.\nWe make a first attempt to find the competitiveness of MFM algorithm. Our new\nresults show that MFM is not 2-competitive with respect to static optimum\noffline algorithm, whereas it is 2-competitive with respect to dynamic optimum\noffline algorithm. Our new theoretical results may open up a new direction of\nresearch in the online list update problem by characterising the structure of\ncompetitive and non competitive deterministic online algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 11:09:51 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Baisakh", "", ""], ["Mohanty", "Rakesh", ""]]}, {"id": "2010.14801", "submitter": "Yuri Malykhin", "authors": "Yuri Malykhin", "title": "Matrix and tensor rigidity and $L_p$-approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we make two observations. First: the low-rank approximation of\nWalsh-Hadamard matrices (that disproves ridigity) via Alman and Williams\nprovides good $\\ell_p$-approximation for $p<2$. It follows that the first $N$\nfunctions of Walsh-Paley system can be approximated with an error $N^{-\\delta}$\nby a linear space of dimension $N^{1-\\delta}$: $$\nd_{N^{1-\\delta}}(\\{w_1,\\ldots,w_N\\}, L_p[0,1]) \\le N^{-\\delta},\\quad\np\\in[1,2),\\;\\delta=\\delta(p)>0. $$ We do not know if this is possible for the\ntrigonometric system.\n  Second, we notice that the algebraic method of Alon-Frankl-R\\\"odl for\nbounding the number of low-signum-rank matrices, works for tensors: almost all\nsignum-tensors have large signum-rank and can't be $\\ell_1$-approximated by\nlow-rank tensors. That implies lower bounds for $\\Theta_m$ -- the error of\n$m$-term approximation of multivariate functions by sums of tensor products\n$u^1(x_1)\\cdots u^d(x_d)$. In particular, for the set of trigonometric\npolynomials with spectrum in $\\prod_{j=1}^d[-n_j,n_j]$ and of norm\n$\\|t\\|_\\infty\\le 1$ we have $$ \\Theta_m(\\mathcal\nT(n_1,\\ldots,n_d)_\\infty,L_1[-\\pi,\\pi]^d) \\ge c_1(d)>0,\\quad m\\le\nc_2(d)\\frac{\\prod n_j}{\\max\\{n_j\\}}. $$\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 07:52:15 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Malykhin", "Yuri", ""]]}, {"id": "2010.14815", "submitter": "Fei Ma", "authors": "Fei Ma, Ping Wang", "title": "Analytic formulae for random walks on stochastic uniform growth trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walk, as a representation depicting discrete-time unbiased Markov\nprocess, has attracted increasing attention in the past. The most important in\nstudying random walk on networks is to measure a structural parameter called\nmean first-passage time, denote by $\\overline{\\mathcal{F}}$. As known, the\ncommonly-utilized methods for determining $\\overline{\\mathcal{F}}$ are mainly\nbased on Laplacian spectra on networks under consideration. On the other hand,\nmethods of this type can become prohibitively complicated and even fail to work\nin the worst case where the corresponding Laplacian matrix is difficult to\ndescribe in the first place.\n  In this paper, we will propose an effective approach to addressing this kind\nof issues on some tree networks, such as, Vicsek fractal, with intriguing\nstructural properties, for instance, fractal feature. As opposed to most of\nprevious work focusing on estimating $\\overline{\\mathcal{F}}$ on growth trees\nthat share deterministic structure, our goal is to consider stochastic cases\nwhere probability is introduced into the process of growing trees. To this end,\nwe first build up a general formula between Wiener index, denoted by\n$\\mathcal{W}$, and $\\overline{\\mathcal{F}}$ on a tree. This enables us to\nconvert issues to answer into calculation of $\\mathcal{W}$ on networks in\nquestion, which helps us gain what we are seeking for. Additionally, it is\nstraightforward to obtain Kirchhoff index on our tree networks using the\napproach proposed instead of spectral technique. As an immediate consequence,\nthe previously published results in deterministic cases are easily covered by\nformulae established in this paper. Most importantly, our approach is more\nmanageable than many other methods including spectral technique in situations\nconsidered herein.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 08:44:02 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Ma", "Fei", ""], ["Wang", "Ping", ""]]}, {"id": "2010.14916", "submitter": "Yoann Dieudonn\\'e", "authors": "S\\'ebastien Bouchard, Yoann Dieudonn\\'e, Arnaud Labourel, Andrzej Pelc", "title": "Almost-Optimal Deterministic Treasure Hunt in Arbitrary Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mobile agent navigating along edges of a simple connected graph, either\nfinite or countably infinite, has to find an inert target (treasure) hidden in\none of the nodes. This task is known as treasure hunt. The agent has no a\npriori knowledge of the graph, of the location of the treasure or of the\ninitial distance to it. The cost of a treasure hunt algorithm is the worst-case\nnumber of edge traversals performed by the agent until finding the treasure.\nAwerbuch, Betke, Rivest and Singh [3] considered graph exploration and treasure\nhunt for finite graphs in a restricted model where the agent has a fuel tank\nthat can be replenished only at the starting node $s$. The size of the tank is\n$B=2(1+\\alpha)r$, for some positive real constant $\\alpha$, where $r$, called\nthe radius of the graph, is the maximum distance from $s$ to any other node.\nThe tank of size $B$ allows the agent to make at most $\\lfloor B\\rfloor$ edge\ntraversals between two consecutive visits at node $s$.\n  Let $e(d)$ be the number of edges whose at least one extremity is at distance\nless than $d$ from $s$. Awerbuch, Betke, Rivest and Singh [3] conjectured that\nit is impossible to find a treasure hidden in a node at distance at most $d$ at\ncost nearly linear in $e(d)$. We first design a deterministic treasure hunt\nalgorithm working in the model without any restrictions on the moves of the\nagent at cost $\\mathcal{O}(e(d) \\log d)$, and then show how to modify this\nalgorithm to work in the model from [3] with the same complexity. Thus we\nrefute the above twenty-year-old conjecture. We observe that no treasure hunt\nalgorithm can beat cost $\\Theta(e(d))$ for all graphs and thus our algorithms\nare also almost optimal.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 12:25:23 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 12:17:11 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 14:32:43 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 12:43:49 GMT"}, {"version": "v5", "created": "Sat, 13 Feb 2021 10:27:18 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Bouchard", "S\u00e9bastien", ""], ["Dieudonn\u00e9", "Yoann", ""], ["Labourel", "Arnaud", ""], ["Pelc", "Andrzej", ""]]}, {"id": "2010.15600", "submitter": "Ciro Garcia Mr", "authors": "Ciro Ivan Garcia Lopez", "title": "Three computational models and its equivalence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.CL cs.GL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The study of computability has its origin in Hilbert's conference of 1900,\nwhere an adjacent question, to the ones he asked, is to give a precise\ndescription of the notion of algorithm. In the search for a good definition\narose three independent theories: Turing and the Turing machines, G\\\"odel and\nthe recursive functions, Church and the Lambda Calculus.\n  Later there were established by Kleene that the classic models of computation\nare equivalent. This fact is widely accepted by many textbooks and the proof is\nomitted since the proof is tedious and unreadable. We intend to fill this gap\npresenting the proof in a modern way, without forgetting the mathematical\ndetails.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 05:55:19 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Lopez", "Ciro Ivan Garcia", ""]]}, {"id": "2010.16290", "submitter": "Adam Bene Watts", "authors": "Adam Bene Watts and J. William Helton", "title": "3XOR Games with Perfect Commuting Operator Strategies Have Perfect\n  Tensor Product Strategies and are Decidable in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider 3XOR games with perfect commuting operator strategies. Given any\n3XOR game, we show existence of a perfect commuting operator strategy for the\ngame can be decided in polynomial time. Previously this problem was not known\nto be decidable. Our proof leads to a construction, showing a 3XOR game has a\nperfect commuting operator strategy iff it has a perfect tensor product\nstrategy using a 3 qubit (8 dimensional) GHZ state. This shows that for perfect\n3XOR games the advantage of a quantum strategy over a classical strategy\n(defined by the quantum-classical bias ratio) is bounded. This is in contrast\nto the general 3XOR case where the optimal quantum strategies can require high\ndimensional states and there is no bound on the quantum advantage.\n  To prove these results, we first show equivalence between deciding the value\nof an XOR game and solving an instance of the subgroup membership problem on a\nclass of right angled Coxeter groups. We then show, in a proof that consumes\nmost of this paper, that the instances of this problem corresponding to 3XOR\ngames can be solved in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 14:35:19 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Watts", "Adam Bene", ""], ["Helton", "J. William", ""]]}]