[{"id": "1909.00638", "submitter": "Yotam Dikstein", "authors": "Yotam Dikstein and Irit Dinur", "title": "Agreement testing theorems on layered set systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework of layered subsets, and give a sufficient condition\nfor when a set system supports an agreement test. Agreement testing is a\ncertain type of property testing that generalizes PCP tests such as the plane\nvs. plane test. Previous work has shown that high dimensional expansion is\nuseful for agreement tests. We extend these results to more general families of\nsubsets, beyond simplicial complexes. These include\n  - Agreement tests for set systems whose sets are faces of high dimensional\nexpanders. Our new tests apply to all dimensions of complexes both in case of\ntwo-sided expansion and in the case of one-sided partite expansion. This\nimproves and extends an earlier work of Dinur and Kaufman (FOCS 2017) and\napplies to matroids, and potentially many additional complexes.\n  - Agreement tests for set systems whose sets are neighborhoods of vertices in\na high dimensional expander. This family resembles the expander neighborhood\nfamily used in the gap-amplification proof of the PCP theorem. This set system\nis quite natural yet does not sit in a simplicial complex, and demonstrates\nsome versatility in our proof technique.\n  - Agreement tests on families of subspaces (also known as the Grassmann\nposet). This extends the classical low degree agreement tests beyond the\nsetting of low degree polynomials.\n  Our analysis relies on a new random walk on simplicial complexes which we\ncall the ``complement random walk'' and which may be of independent interest.\nThis random walk generalizes the non-lazy random walk on a graph to higher\ndimensions, and has significantly better expansion than previously-studied\nrandom walks on simplicial complexes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 09:50:01 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Dikstein", "Yotam", ""], ["Dinur", "Irit", ""]]}, {"id": "1909.00857", "submitter": "Viswambhara Makam", "authors": "Visu Makam and Avi Wigderson", "title": "Singular tuples of matrices is not a null cone (and, the symmetries of\n  algebraic varieties)", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.CC math.AC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following multi-determinantal algebraic variety plays a central role in\nalgebra, algebraic geometry and computational complexity theory: ${\\rm\nSING}_{n,m}$, consisting of all $m$-tuples of $n\\times n$ complex matrices\nwhich span only singular matrices. In particular, an efficient deterministic\nalgorithm testing membership in ${\\rm SING}_{n,m}$ will imply super-polynomial\ncircuit lower bounds, a holy grail of the theory of computation.\n  A sequence of recent works suggests such efficient algorithms for memberships\nin a general class of algebraic varieties, namely the null cones of linear\ngroup actions. Can this be used for the problem above? Our main result is\nnegative: ${\\rm SING}_{n,m}$ is not the null cone of any (reductive) group\naction! This stands in stark contrast to a non-commutative analog of this\nvariety, and points to an inherent structural difficulty of ${\\rm SING}_{n,m}$.\n  To prove this result we identify precisely the group of symmetries of ${\\rm\nSING}_{n,m}$. We find this characterization, and the tools we introduce to\nprove it, of independent interest. Our work significantly generalizes a result\nof Frobenius for the special case $m=1$, and suggests a general method for\ndetermining the symmetries of algebraic varieties.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 20:37:40 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Makam", "Visu", ""], ["Wigderson", "Avi", ""]]}, {"id": "1909.00885", "submitter": "Khen Elimelech", "authors": "Khen Elimelech, Vadim Indelman", "title": "Simplified Decision Making in the Belief Space using Belief\n  Sparsification", "comments": "Submitted to the International Journal of Robotics Research (IJRR),\n  December 2018; conditionally accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.IT cs.RO cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a new approach for the efficient solution of\nautonomous decision and planning problems, with a special focus on decision\nmaking under uncertainty and belief space planning (BSP) in high-dimensional\nstate spaces. Usually, to solve the decision problem, we identify the optimal\naction, according to some objective function. We claim that we can sometimes\ngenerate and solve an analogous yet simplified decision problem, which can be\nsolved more efficiently; a wise simplification method can lead to the same\naction selection, or one for which the maximal loss can be guaranteed.\nFurthermore, such simplification is separated from the state inference, and\ndoes not compromise its accuracy, as the selected action would finally be\napplied on the original state. First, we present the concept for general\ndecision problems, and provide a theoretical framework for a coherent\nformulation of the approach. We then practically apply these ideas to BSP\nproblems, which can be simplified by considering a sparse approximation of the\ninitial (Gaussian) belief. The scalable belief sparsification algorithm we\nprovide is able to yield solutions which are guaranteed to be consistent with\nthe original problem. We demonstrate the benefits of the approach in the\nsolution of a highly realistic active-SLAM problem, and manage to significantly\nreduce computation time, with practically no loss in the quality of solution.\nThis work is conceptual and fundamental, and holds numerous possible\nextensions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 23:00:59 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 07:30:30 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 19:01:30 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Elimelech", "Khen", ""], ["Indelman", "Vadim", ""]]}, {"id": "1909.01060", "submitter": "Florian Adriaens", "authors": "Florian Adriaens, Cigdem Aslay, Tijl De Bie, Aristides Gionis, Jefrey\n  Lijffijt", "title": "Discovering Interesting Cycles in Directed Graphs", "comments": "Accepted for CIKM'19", "journal-ref": null, "doi": "10.1145/3357384.3357970", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cycles in graphs often signify interesting processes. For example, cyclic\ntrading patterns can indicate inefficiencies or economic dependencies in trade\nnetworks, cycles in food webs can identify fragile dependencies in ecosystems,\nand cycles in financial transaction networks can be an indication of money\nlaundering. Identifying such interesting cycles, which can also be constrained\nto contain a given set of query nodes, although not extensively studied, is\nthus a problem of considerable importance. In this paper, we introduce the\nproblem of discovering interesting cycles in graphs. We first address the\nproblem of quantifying the extent to which a given cycle is interesting for a\nparticular analyst. We then show that finding cycles according to this\ninterestingness measure is related to the longest cycle and maximum mean-weight\ncycle problems (in the unconstrained setting) and to the maximum Steiner cycle\nand maximum mean Steiner cycle problems (in the constrained setting). A\ncomplexity analysis shows that finding interesting cycles is NP-hard, and is\nNP-hard to approximate within a constant factor in the unconstrained setting,\nand within a factor polynomial in the input size for the constrained setting.\nThe latter inapproximability result implies a similar result for the maximum\nSteiner cycle and maximum mean Steiner cycle problems. Motivated by these\nhardness results, we propose a number of efficient heuristic algorithms. We\nverify the effectiveness of the proposed methods and demonstrate their\npractical utility on two real-world use cases: a food web and an international\ntrade-network dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:58:03 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Adriaens", "Florian", ""], ["Aslay", "Cigdem", ""], ["De Bie", "Tijl", ""], ["Gionis", "Aristides", ""], ["Lijffijt", "Jefrey", ""]]}, {"id": "1909.01123", "submitter": "Xiaopeng Luo Dr.", "authors": "Xiaopeng Luo and Xin Xu", "title": "Contraction methods for continuous optimization", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a class of algorithms that establishes a contracting sequence of\nclosed sets for solving continuous optimization. From the perspective of\nensuring effective contractions to achieve a certain accuracy, all the possible\ncontinuous optimization problems could be divided into three categories:\nlogarithmic time contractile, polynomial time contractile, or noncontractile.\nFor any problem from the first two categories, the constructed contracting\nsequence converges to the set of all global minimizers with a theoretical\nguarantee of linear convergence; for any problem from the last category, we\nalso discuss possible troubles caused by using the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 12:49:50 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 08:00:38 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 06:47:37 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 14:23:45 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Luo", "Xiaopeng", ""], ["Xu", "Xin", ""]]}, {"id": "1909.01571", "submitter": "JaeSung Choi", "authors": "Jaesung Choi and Pilwon Kim", "title": "Reservoir Computing based on Quenched Chaos", "comments": null, "journal-ref": null, "doi": "10.1016/j.chaos.2020.110131", "report-no": null, "categories": "nlin.CD cs.CC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing(RC) is a brain-inspired computing framework that employs\na transient dynamical system whose reaction to an input signal is transformed\nto a target output. One of the central problems in RC is to find a reliable\nreservoir with a large criticality, since computing performance of a reservoir\nis maximized near the phase transition. In this work, we propose a continuous\nreservoir that utilizes transient dynamics of coupled chaotic oscillators in a\ncritical regime where sudden amplitude death occurs. This \"explosive death\" not\nonly brings the system a large criticality which provides a variety of orbits\nfor computing, but also stabilizes them which otherwise diverge soon in chaotic\nunits. The proposed framework shows better results in tasks for signal\nreconstructions than RC based on explosive synchronization of regular phase\noscillators. We also show that the information capacity of the reservoirs can\nbe used as a predictive measure for computational capability of a reservoir at\na critical point.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:46:20 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Choi", "Jaesung", ""], ["Kim", "Pilwon", ""]]}, {"id": "1909.01667", "submitter": "Balasubramanian A.R", "authors": "A. R. Balasubramanian", "title": "Complexity of controlled bad sequences over finite sets of\n  $\\mathbb{N}^d$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide upper and lower bounds for the length of controlled bad sequences\nover the majoring and the minoring orderings of finite sets of $\\mathbb{N}^d$.\nThe results are obtained by bounding the length of such sequences by functions\nfrom the Cichon hierarchy. This allows us to translate these results to bounds\nover the fast-growing complexity classes.\n  The obtained bounds are proven to be tight for the majoring ordering, which\nsolves a problem left open by Abriola, Figueira and Senno (Theor. Comp. Sci,\nVol. 603). Finally, we use the results on controlled bad sequences to prove\nupper bounds for the emptiness problem of some classes of automata.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:58:31 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 16:15:01 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 19:59:17 GMT"}, {"version": "v4", "created": "Tue, 14 Jan 2020 10:30:08 GMT"}, {"version": "v5", "created": "Mon, 8 Jun 2020 10:21:46 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Balasubramanian", "A. R.", ""]]}, {"id": "1909.01986", "submitter": "Karthik C. S.", "authors": "Arnab Bhattacharyya, \\'Edouard Bonnet, L\\'aszl\\'o Egri, Suprovat\n  Ghoshal, Karthik C. S., Bingkai Lin, Pasin Manurangsi, and D\\'aniel Marx", "title": "Parameterized Intractability of Even Set and Shortest Vector Problem", "comments": "Preliminary version of this article appeared in ESA'16\n  (arXiv:1601.04935) and ICALP'18 (arXiv:1803.09717)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-Even Set problem is a parameterized variant of the Minimum Distance\nProblem of linear codes over $\\mathbb F_2$, which can be stated as follows:\ngiven a generator matrix $\\mathbf A$ and an integer $k$, determine whether the\ncode generated by $\\mathbf A$ has distance at most $k$, or in other words,\nwhether there is a nonzero vector $\\mathbf{x}$ such that $\\mathbf A \\mathbf{x}$\nhas at most $k$ nonzero coordinates. The question of whether $k$-Even Set is\nfixed parameter tractable (FPT) parameterized by the distance $k$ has been\nrepeatedly raised in literature; in fact, it is one of the few remaining open\nquestions from the seminal book of Downey and Fellows (1999). In this work, we\nshow that $k$-Even Set is W[1]-hard under randomized reductions. We also\nconsider the parameterized $k$-Shortest Vector Problem (SVP), in which we are\ngiven a lattice whose basis vectors are integral and an integer $k$, and the\ngoal is to determine whether the norm of the shortest vector (in the $\\ell_p$\nnorm for some fixed $p$) is at most $k$. Similar to $k$-Even Set, understanding\nthe complexity of this problem is also a long-standing open question in the\nfield of Parameterized Complexity. We show that, for any $p > 1$, $k$-SVP is\nW[1]-hard to approximate (under randomized reductions) to some constant factor.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:18:08 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Bonnet", "\u00c9douard", ""], ["Egri", "L\u00e1szl\u00f3", ""], ["Ghoshal", "Suprovat", ""], ["S.", "Karthik C.", ""], ["Lin", "Bingkai", ""], ["Manurangsi", "Pasin", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1909.02579", "submitter": "Michael Blondin", "authors": "Michael Blondin and Mikhail Raskin", "title": "The Complexity of Reachability in Affine Vector Addition Systems with\n  States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vector addition systems with states (VASS) are widely used for the formal\nverification of concurrent systems. Given their tremendous computational\ncomplexity, practical approaches have relied on techniques such as reachability\nrelaxations, e.g., allowing for negative intermediate counter values. It is\nnatural to question their feasibility for VASS enriched with primitives that\ntypically translate into undecidability. Spurred by this concern, we pinpoint\nthe complexity of integer relaxations with respect to arbitrary classes of\naffine operations.\n  More specifically, we provide a trichotomy on the complexity of integer\nreachability in VASS extended with affine operations (affine VASS). Namely, we\nshow that it is NP-complete for VASS with resets, PSPACE-complete for VASS with\n(pseudo-)transfers and VASS with (pseudo-)copies, and undecidable for any other\nclass. We further present a dichotomy for standard reachability in affine VASS:\nit is decidable for VASS with permutations, and undecidable for any other\nclass. This yields a complete and unified complexity landscape of reachability\nin affine VASS. We also consider the reachability problem parameterized by a\nfixed affine VASS, rather than a class, and we show that the complexity\nlandscape is arbitrary in this setting.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 18:01:22 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 14:54:24 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 19:48:44 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 15:01:48 GMT"}, {"version": "v5", "created": "Mon, 19 Jul 2021 13:00:07 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Blondin", "Michael", ""], ["Raskin", "Mikhail", ""]]}, {"id": "1909.02627", "submitter": "Tyler Schrock", "authors": "Tyler Schrock and Rafael Frongillo", "title": "Computational Complexity of $k$-Block Conjugacy", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several computational problems related to conjugacy between\nsubshifts of finite type, restricted to $k$-block codes: verifying a proposed\n$k$-block conjugacy, deciding if two shifts admit a $k$-block conjugacy, and\nreducing the representation size of a shift via a $k$-block conjugacy. We give\na polynomial-time algorithm for verification, and show GI and NP-hardness for\ndeciding conjugacy and reducing representation size, respectively. Our approach\nfocuses on 1-block conjugacies between vertex shifts, from which we generalize\nto $k$-block conjugacies and to edge shifts. We conclude with several open\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 20:50:43 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Schrock", "Tyler", ""], ["Frongillo", "Rafael", ""]]}, {"id": "1909.02839", "submitter": "Titus Dose", "authors": "Titus Dose", "title": "$\\mathrm{P}\\ne\\mathrm{NP}$ and All Non-Empty Sets in\n  $\\mathrm{NP}\\cup\\mathrm{coNP}$ Have P-Optimal Proof Systems Relative to an\n  Oracle", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.06175,\n  arXiv:1903.11860, arXiv:1910.08571", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one step in a working program initiated by Pudl\\'ak [Pud17] we construct\nan oracle relative to which $\\mathrm{P}\\ne\\mathrm{NP}$ and all non-empty sets\nin $\\mathrm{NP}\\cup\\mathrm{coNP}$ have $\\mathrm{P}$-optimal proof systems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 14:03:01 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 15:57:55 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 15:23:09 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Dose", "Titus", ""]]}, {"id": "1909.02849", "submitter": "Perrot K\\'evin", "authors": "Viet-Ha Nguyen and Kevin Perrot and Mathieu Vallet", "title": "NP-completeness of the game Kingdomino", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kingdomino is a board game designed by Bruno Cathala and edited by Blue\nOrange since 2016. The goal is to place $2 \\times 1$ dominoes on a grid layout,\nand get a better score than other players. Each $1 \\times 1$ domino cell has a\ncolor that must match at least one adjacent cell, and an integer number of\ncrowns (possibly none) used to compute the score. We prove that even with full\nknowledge of the future of the game, in order to maximize their score at\nKingdomino, players are faced with an NP-complete optimization problem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 12:23:25 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 08:29:51 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 13:17:51 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Nguyen", "Viet-Ha", ""], ["Perrot", "Kevin", ""], ["Vallet", "Mathieu", ""]]}, {"id": "1909.03210", "submitter": "Kousha Etessami", "authors": "Kousha Etessami, Christos Papadimitriou, Aviad Rubinstein, Mihalis\n  Yannakakis", "title": "Tarski's Theorem, Supermodular Games, and the Complexity of Equilibria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of monotonicity and Tarski's theorem in existence proofs of\nequilibria is very widespread in economics, while Tarski's theorem is also\noften used for similar purposes in the context of verification. However, there\nhas been relatively little in the way of analysis of the complexity of finding\nthe fixed points and equilibria guaranteed by this result. We study a\ncomputational formalism based on monotone functions on the $d$-dimensional grid\nwith sides of length $N$, and their fixed points, as well as the closely\nconnected subject of supermodular games and their equilibria. It is known that\nfinding some (any) fixed point of a monotone function can be done in time\n$\\log^d N$, and we show it requires at least $\\log^2 N$ function evaluations\nalready on the 2-dimensional grid, even for randomized algorithms. We show that\nthe general Tarski problem of finding some fixed point, when the monotone\nfunction is given succinctly (by a boolean circuit), is in the class PLS of\nproblems solvable by local search and, rather surprisingly, also in the class\nPPAD. Finding the greatest or least fixed point guaranteed by Tarski's theorem,\nhowever, requires $d\\cdot N$ steps, and is NP-hard in the white box model. For\nsupermodular games, we show that finding an equilibrium in such games is\nessentially computationally equivalent to the Tarski problem, and finding the\nmaximum or minimum equilibrium is similarly harder. Interestingly, two-player\nsupermodular games where the strategy space of one player is one-dimensional\ncan be solved in $O(\\log N)$ steps. We also observe that computing\n(approximating) the value of Condon's (Shapley's) stochastic games reduces to\nthe Tarski problem. An important open problem highlighted by this work is\nproving a $\\Omega(\\log^d N)$ lower bound for small fixed dimension $d \\geq 3$.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 08:13:21 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Etessami", "Kousha", ""], ["Papadimitriou", "Christos", ""], ["Rubinstein", "Aviad", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "1909.03255", "submitter": "Omri Ben-Eliezer", "authors": "Omri Ben-Eliezer, Eldar Fischer, Amit Levi, Ron D. Rothblum", "title": "Hard properties with (very) short PCPPs and their applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there exist properties that are maximally hard for testing,\nwhile still admitting PCPPs with a proof size very close to linear.\nSpecifically, for every fixed $\\ell$, we construct a property\n$\\mathcal{P}^{(\\ell)}\\subseteq\\{0,1\\}^n$ satisfying the following: Any testing\nalgorithm for $\\mathcal{P}^{(\\ell)}$ requires $\\Omega(n)$ many queries, and yet\n$\\mathcal{P}^{(\\ell)}$ has a constant query PCPP whose proof size is $O(n\\cdot\n\\log^{(\\ell)}n)$, where $\\log^{(\\ell)}$ denotes the $\\ell$ times iterated log\nfunction (e.g., $\\log^{(2)}n = \\log \\log n$). The best previously known upper\nbound on the PCPP proof size for a maximally hard to test property was $O(n\n\\cdot \\mathrm{poly}\\log{n})$.\n  As an immediate application, we obtain stronger separations between the\nstandard testing model and both the tolerant testing model and the\nerasure-resilient testing model: for every fixed $\\ell$, we construct a\nproperty that has a constant-query tester, but requires\n$\\Omega(n/\\log^{(\\ell)}(n))$ queries for every tolerant or erasure-resilient\ntester.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 12:05:32 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 17:42:07 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ben-Eliezer", "Omri", ""], ["Fischer", "Eldar", ""], ["Levi", "Amit", ""], ["Rothblum", "Ron D.", ""]]}, {"id": "1909.03339", "submitter": "Perrot K\\'evin", "authors": "Kevin Perrot", "title": "On the complexity of counting feedback arc sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note we study the computational complexity of feedback arc set\ncounting problems in directed graphs, highlighting some subtle yet common\nproperties of counting classes. Counting the number of feedback arc sets of\ncardinality $k$ and the total number of feedback arc sets are #P-complete\nproblems, while counting the number of minimum feedback arc sets is only proven\nto be #P-hard. Indeed, this latter problem is #.OptP[log n]-complete, hence if\nit belongs to #P then P=NP.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 21:26:25 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Perrot", "Kevin", ""]]}, {"id": "1909.03547", "submitter": "Shay Moran", "authors": "Mark Braverman and Gillat Kol and Shay Moran and Raghuvansh R. Saxena", "title": "Convex Set Disjointness, Distributed Learning of Halfspaces, and LP\n  Feasibility", "comments": "37 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Convex Set Disjointness (CSD) problem, where two players have\ninput sets taken from an arbitrary fixed domain~$U\\subseteq \\mathbb{R}^d$ of\nsize $\\lvert U\\rvert = n$. Their mutual goal is to decide using minimum\ncommunication whether the convex hulls of their sets intersect (equivalently,\nwhether their sets can be separated by a hyperplane).\n  Different forms of this problem naturally arise in distributed learning and\noptimization: it is equivalent to {\\em Distributed Linear Program (LP)\nFeasibility} -- a basic task in distributed optimization, and it is tightly\nlinked to {\\it Distributed Learning of Halfdpaces in $\\mathbb{R}^d$}. In\n{communication complexity theory}, CSD can be viewed as a geometric\ninterpolation between the classical problems of {Set Disjointness} (when~$d\\geq\nn-1$) and {Greater-Than} (when $d=1$).\n  We establish a nearly tight bound of $\\tilde \\Theta(d\\log n)$ on the\ncommunication complexity of learning halfspaces in $\\mathbb{R}^d$. For Convex\nSet Disjointness (and the equivalent task of distributed LP feasibility) we\nderive upper and lower bounds of $\\tilde O(d^2\\log n)$ and~$\\Omega(d\\log n)$.\nThese results improve upon several previous works in distributed learning and\noptimization.\n  Unlike typical works in communication complexity, the main technical\ncontribution of this work lies in the upper bounds. In particular, our\nprotocols are based on a {\\it Container Lemma for Halfspaces} and on two\nvariants of {\\it Carath\\'eodory's Theorem}, which may be of independent\ninterest. These geometric statements are used by our protocols to provide a\ncompressed summary of the players' input.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 21:19:34 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Braverman", "Mark", ""], ["Kol", "Gillat", ""], ["Moran", "Shay", ""], ["Saxena", "Raghuvansh R.", ""]]}, {"id": "1909.03691", "submitter": "Jan Krajicek", "authors": "Jan Krajicek", "title": "The Cook-Reckhow definition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cook-Reckhow 1979 paper defined the area of research we now call Proof\nComplexity. There were earlier papers which contributed to the subject as we\nunderstand it today, the most significant being Tseitin's 1968 paper, but none\nof them introduced general notions that would allow to make an explicit and\nuniversal link between lengths-of-proofs problems and computational complexity\ntheory. In this note we shall highlight three particular definitions from the\npaper: of proof systems, p-simulations and the pigeonhole principle formula,\nand discuss their role in defining the field. We will also mention some related\ndevelopments and open problems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 08:01:27 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Krajicek", "Jan", ""]]}, {"id": "1909.03787", "submitter": "Ying Hao Chen", "authors": "Ying-hao Chen", "title": "2-Local Hamiltonian with Low Complexity is QCMA", "comments": "A Class project Paper for CS395T Quantum Complexity Theory at UT\n  Austin in Spring 2019 under Professor Scott Aaronson", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that 2-Local Hamiltonian (2-LH) with Low Complexity problem is\nQCMA-complete by combining the results from the QMA-completeness[4] of 2-LH and\nQCMA-completeness of 3-LH with Low Complexity[6]. The idea is straightforward.\nIt has been known that 2-LH is QMA-complete. By putting a low complexity\nconstraint on the input state, we make the problem QCMA. Finally, we use\nsimilar arguments as in [4] to show that all QCMA problems can be reduced to\nour proposed problem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 05:58:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Chen", "Ying-hao", ""]]}, {"id": "1909.04135", "submitter": "Nathan Mull", "authors": "Nathan Mull, Shuo Pang, Alexander Razborov", "title": "On CDCL-based proof systems with the ordered decision strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that conflict-driven clause learning SAT-solvers with the ordered\ndecision strategy and the DECISION learning scheme are equivalent to ordered\nresolution. We also prove that, by replacing this learning scheme with its\nopposite that stops after the first new clause when backtracking, they become\nequivalent to general resolution. To the best of our knowledge, this is the\nfirst theoretical study of the interplay between specific decision strategies\nand clause learning.\n  For both results, we allow nondeterminism in the solver's ability to perform\nunit propagation, conflict analysis, and restarts, in a way that is similar to\nprevious works in the literature. To aid the presentation of our results, and\npossibly future research, we define a model and language for discussing\nCDCL-based proof systems that allows for succinct and precise theorem\nstatements.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:13:31 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Mull", "Nathan", ""], ["Pang", "Shuo", ""], ["Razborov", "Alexander", ""]]}, {"id": "1909.04396", "submitter": "Tapani Toivonen Mr.", "authors": "Tapani Toivonen and Janne Karttunen", "title": "Constant factor approximation of MAX CLIQUE", "comments": "the reduction does not preserve the approximation ratio", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAX CLIQUE problem (MCP) is an NPO problem, which asks to find the largest\ncomplete sub-graph in a graph $G, G = (V, E)$ (directed or undirected). MCP is\nwell known to be $NP-Hard$ to approximate in polynomial time with an\napproximation ratio of $1 + \\epsilon$, for every $\\epsilon > 0$ [9] (and even a\npolynomial time approximation algorithm with a ratio $n^{1 - \\epsilon}$ has\nbeen conjectured to be non-existent [2] for MCP). Up to this date, the best\nknown approximation ratio for MCP of a polynomial time algorithm is\n$O(n(log_2(log_2(n)))^2 / (log_2(n))^3)$ given by Feige [1]. In this paper, we\nshow that MCP can be approximated with a constant factor in polynomial time\nthrough approximation ratio preserving reductions from MCP to MAX DNF and from\nMAX DNF to MIN SAT. A 2-approximation algorithm for MIN SAT was presented in\n[6]. An approximation ratio preserving reduction from MIN SAT to min vertex\ncover improves the approximation ratio to $2 - \\Theta(1/ \\sqrt{n})$ [10]. Hence\nwe prove false the infamous conjecture, which argues that there cannot be a\npolynomial time algorithm for MCP with an approximation ratio of any constant\nfactor.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:42:37 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 06:04:07 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 14:43:08 GMT"}, {"version": "v4", "created": "Wed, 18 Sep 2019 18:54:00 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Toivonen", "Tapani", ""], ["Karttunen", "Janne", ""]]}, {"id": "1909.04774", "submitter": "Anup Rao", "authors": "Anup Rao", "title": "Coding for Sunflowers", "comments": "Revised version includes an improved bound. This version is published\n  by Discrete Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sunflower is a family of sets that have the same pairwise intersections. We\nsimplify a recent result of Alweiss, Lovett, Wu and Zhang that gives an upper\nbound on the size of every family of sets of size $k$ that does not contain a\nsunflower. We show how to use the converse of Shannon's noiseless coding\ntheorem to give a cleaner proof of their result.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 21:57:51 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 19:07:16 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Rao", "Anup", ""]]}, {"id": "1909.04785", "submitter": "J. M. Landsberg", "authors": "Austin Conner, Fulvio Gesmundo, Joseph M. Landsberg, and Emanuele\n  Ventura", "title": "Kronecker powers of tensors and Strassen's laser method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer a question, posed implicitly by Coppersmith-Winogrand and\nBuergisser et. al. and explicitly by Blaeser, showing the border rank of the\nKronecker square of the little Coppersmith-Winograd tensor is the square of the\nborder rank of the tensor for all q>2, a negative result for complexity theory.\nWe further show that when q>4, the analogous result holds for the Kronecker\ncube. In the positive direction, we enlarge the list of explicit tensors\npotentially useful for the laser method. We observe that a well-known tensor,\nthe 3x3 determinant polynomial regarded as a tensor, could potentially be used\nin the laser method to prove the exponent of matrix multiplication is two.\nBecause of this, we prove new upper bounds on its Waring rank and rank (both\n18), border rank and Waring border rank (both 17), which, in addition to being\npromising for the laser method, are of interest in their own right. We discuss\n\"skew\" cousins of the little Coppersmith-Winograd tensor and indicate whey they\nmay be useful for the laser method. We establish general results regarding\nborder ranks of Kronecker powers of tensors, and make a detailed study of\nKronecker squares of tensors of dimensions (3,3,3). In particular we show\nnumerically that for generic tensors in this space, the rank and border rank\nare strictly sub-multiplicative.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 22:44:36 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Conner", "Austin", ""], ["Gesmundo", "Fulvio", ""], ["Landsberg", "Joseph M.", ""], ["Ventura", "Emanuele", ""]]}, {"id": "1909.04871", "submitter": "Libor Barto", "authors": "Libor Barto", "title": "Algebraic Theory of Promise Constraint Satisfaction Problems, First\n  Steps", "comments": null, "journal-ref": "In: G\\k{a}sieniec L., Jansson J., Levcopoulos C. (eds)\n  Fundamentals of Computation Theory. FCT 2019. Lecture Notes in Computer\n  Science, vol 11651. Springer, Cham", "doi": "10.1007/978-3-030-25027-0_1", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes a computational problem easy (e.g., in P, that is, solvable in\npolynomial time) or hard (e.g., NP-hard)? This fundamental question now has a\nsatisfactory answer for a quite broad class of computational problems, so\ncalled fixed-template constraint satisfaction problems (CSPs) -- it has turned\nout that their complexity is captured by a certain specific form of symmetry.\nThis paper explains an extension of this theory to a much broader class of\ncomputational problems, the promise CSPs, which includes relaxed versions of\nCSPs such as the problem of finding a 137-coloring of a 3-colorable graph.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 06:53:35 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Barto", "Libor", ""]]}, {"id": "1909.04878", "submitter": "Libor Barto", "authors": "Libor Barto", "title": "Promises Make Finite (Constraint Satisfaction) Problems Infinitary", "comments": null, "journal-ref": "2019 34th Annual ACM/IEEE Symposium on Logic in Computer Science\n  (LICS), Vancouver, BC, Canada, 2019, pp. 1-8", "doi": "10.1109/LICS.2019.8785671", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fixed template Promise Constraint Satisfaction Problem (PCSP) is a\nrecently proposed significant generalization of the fixed template CSP, which\nincludes approximation variants of satisfiability and graph coloring problems.\nAll the currently known tractable (i.e., solvable in polynomial time) PCSPs\nover finite templates can be reduced, in a certain natural way, to tractable\nCSPs. However, such CSPs are often over infinite domains. We show that the\ninfinity is in fact necessary by proving that a specific finite-domain PCSP,\nnamely (1-in-3-SAT, Not-All-Equal-3-SAT), cannot be naturally reduced to a\ntractable finite-domain CSP, unless P=NP.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:05:07 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Barto", "Libor", ""]]}, {"id": "1909.05822", "submitter": "Pascale Gourdeau", "authors": "Pascale Gourdeau, Varun Kanade, Marta Kwiatkowska, James Worrell", "title": "On the Hardness of Robust Classification", "comments": "To appear in the proceedings of Neural Information Processing Systems\n  Conference (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is becoming increasingly important to understand the vulnerability of\nmachine learning models to adversarial attacks. In this paper we study the\nfeasibility of robust learning from the perspective of computational learning\ntheory, considering both sample and computational complexity. In particular,\nour definition of robust learnability requires polynomial sample complexity. We\nstart with two negative results. We show that no non-trivial concept class can\nbe robustly learned in the distribution-free setting against an adversary who\ncan perturb just a single input bit. We show moreover that the class of\nmonotone conjunctions cannot be robustly learned under the uniform distribution\nagainst an adversary who can perturb $\\omega(\\log n)$ input bits. However if\nthe adversary is restricted to perturbing $O(\\log n)$ bits, then the class of\nmonotone conjunctions can be robustly learned with respect to a general class\nof distributions (that includes the uniform distribution). Finally, we provide\na simple proof of the computational hardness of robust learning on the boolean\nhypercube. Unlike previous results of this nature, our result does not rely on\nanother computational model (e.g. the statistical query model) nor on any\nhardness assumption other than the existence of a hard learning problem in the\nPAC framework.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:29:08 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Gourdeau", "Pascale", ""], ["Kanade", "Varun", ""], ["Kwiatkowska", "Marta", ""], ["Worrell", "James", ""]]}, {"id": "1909.05828", "submitter": "Augusto Modanese", "authors": "Augusto Modanese", "title": "Sublinear-Time Language Recognition and Decision by One-Dimensional\n  Cellular Automata", "comments": "16 pages, 2 figures, to appear at DLT 2020", "journal-ref": null, "doi": "10.1007/978-3-030-48516-0_19", "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After an apparent hiatus of roughly 30 years, we revisit a seemingly\nneglected subject in the theory of (one-dimensional) cellular automata:\nsublinear-time computation. The model considered is that of ACAs, which are\nlanguage acceptors whose acceptance condition depends on the states of all\ncells in the automaton. We prove a time hierarchy theorem for sublinear-time\nACA classes, analyze their intersection with the regular languages, and,\nfinally, establish strict inclusions in the parallel computation classes\n$\\mathsf{SC}$ and (uniform) $\\mathsf{AC}$. As an addendum, we introduce and\ninvestigate the concept of a decider ACA (DACA) as a candidate for a decider\ncounterpart to (acceptor) ACAs. We show the class of languages decidable in\nconstant time by DACAs equals the locally testable languages, and we also\ndetermine $\\Omega(\\sqrt{n})$ as the (tight) time complexity threshold for DACAs\nup to which no advantage compared to constant time is possible.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:36:42 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 13:11:35 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 16:14:55 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Modanese", "Augusto", ""]]}, {"id": "1909.05901", "submitter": "Zarathustra Brady", "authors": "Zarathustra Brady", "title": "Examples, counterexamples, and structure in bounded width algebras", "comments": "Simplified and generalized the main results about partial\n  semilattices", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study bounded width algebras which are minimal in the sense that every\nproper reduct does not have bounded width. We show that minimal bounded width\nalgebras can be arranged into a pseudovariety with one basic ternary operation.\nWe classify minimal bounded width algebras which have size at most three, and\nprove a structure theorem for minimal bounded width algebras which have no\nmajority subalgebra, which form a pseudovariety with a commutative binary\noperation. As a byproduct of our results, we also classify minimal clones which\nhave a Taylor term.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:36:49 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 16:35:20 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Brady", "Zarathustra", ""]]}, {"id": "1909.05968", "submitter": "EPTCS", "authors": "Ronny Tredup (Universit\\\"at Rostock)", "title": "Tracking Down the Bad Guys: Reset and Set Make Feasibility for Flip-Flop\n  Net Derivatives NP-complete", "comments": "In Proceedings ICE 2019, arXiv:1909.05242", "journal-ref": "EPTCS 304, 2019, pp. 20-37", "doi": "10.4204/EPTCS.304.2", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean Petri nets are differentiated by types of nets $\\tau$ based on which\nof the interactions nop, inp, out, set, res, swap, used, and free they apply or\nspare. The synthesis problem relative to a specific type of nets $\\tau$ is to\nfind a boolean $\\tau$-net $N$ whose reachability graph is isomorphic to a given\ntransition system $A$. The corresponding decision version of this search\nproblem is called feasibility. Feasibility is known to be polynomial for all\ntypes of flip flop derivates that contain at least the interactions nop, swap\nand an arbitrary selection of inp, out, used, free. In this paper, we replace\ninp and out by res and set, respectively, and show that feasibility becomes\nNP-complete for the types that contain nop, swap and a non empty selection of\nres, set and a non empty selection of used, free. The reduction guarantees a\nlow degree for A's states and, thus, preserves hardness of feasibility even for\nconsiderable input restrictions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:23:13 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Tredup", "Ronny", "", "Universit\u00e4t Rostock"]]}, {"id": "1909.05981", "submitter": "Justin Yirka", "authors": "Sevag Gharibian, Stephen Piddock, and Justin Yirka", "title": "Oracle complexity classes and local measurements on physical\n  Hamiltonians", "comments": "38 pages, 3 figures", "journal-ref": "Proceedings of 37th International Symposium on Theoretical Aspects\n  of Computer Science (STACS 2020)", "doi": "10.4230/LIPIcs.STACS.2020.20", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The canonical problem for the class Quantum Merlin-Arthur (QMA) is that of\nestimating ground state energies of local Hamiltonians. Perhaps surprisingly,\n[Ambainis, CCC 2014] showed that the related, but arguably more natural,\nproblem of simulating local measurements on ground states of local Hamiltonians\n(APX-SIM) is likely harder than QMA. Indeed, [Ambainis, CCC 2014] showed that\nAPX-SIM is P^QMA[log]-complete, for P^QMA[log] the class of languages decidable\nby a P machine making a logarithmic number of adaptive queries to a QMA oracle.\nIn this work, we show that APX-SIM is P^QMA[log]-complete even when restricted\nto more physical Hamiltonians, obtaining as intermediate steps a variety of\nrelated complexity-theoretic results.\n  We first give a sequence of results which together yield P^QMA[log]-hardness\nfor APX-SIM on well-motivated Hamiltonians: (1) We show that for NP, StoqMA,\nand QMA oracles, a logarithmic number of adaptive queries is equivalent to\npolynomially many parallel queries. These equalities simplify the proofs of our\nsubsequent results. (2) Next, we show that the hardness of APX-SIM is preserved\nunder Hamiltonian simulations (a la [Cubitt, Montanaro, Piddock, 2017]). As a\nbyproduct, we obtain a full complexity classification of APX-SIM, showing it is\ncomplete for P, P^||NP, P^||StoqMA, or P^||QMA depending on the Hamiltonians\nemployed. (3) Leveraging the above, we show that APX-SIM is P^QMA[log]-complete\nfor any family of Hamiltonians which can efficiently simulate spatially sparse\nHamiltonians, including physically motivated models such as the 2D Heisenberg\nmodel.\n  Our second focus considers 1D systems: We show that APX-SIM remains\nP^QMA[log]-complete even for local Hamiltonians on a 1D line of 8-dimensional\nqudits. This uses a number of ideas from above, along with replacing the \"query\nHamiltonian\" of [Ambainis, CCC 2014] with a new \"sifter\" construction.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:51:22 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Gharibian", "Sevag", ""], ["Piddock", "Stephen", ""], ["Yirka", "Justin", ""]]}, {"id": "1909.06210", "submitter": "Ramis Movassagh", "authors": "Ramis Movassagh", "title": "Quantum supremacy and random circuits", "comments": "27 pages. 8 Figures Former title, \"Cayley path and quantum\n  computational supremacy: A proof of average-case $\\#P-$hardness of Random\n  Circuit Sampling with quantified robustness\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.str-el cs.CC hep-th math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Moore's law reaches its limits, quantum computers are emerging with the\npromise of dramatically outperforming classical computers. We have witnessed\nthe advent of quantum processors with over $50$ quantum bits (qubits), which\nare expected to be beyond the reach of classical simulation. Quantum supremacy\nis the event at which the old Extended Church-Turing Thesis is overturned: A\nquantum computer performs a task that is practically impossible for any\nclassical (super)computer. The demonstration requires both a solid theoretical\nguarantee and an experimental realization. The lead candidate is Random Circuit\nSampling (RCS), which is the task of sampling from the output distribution of\nrandom quantum circuits. Google recently announced a $53-$qubit experimental\ndemonstration of RCS. Soon after, classical algorithms appeared that challenge\nthe supremacy of random circuits by estimating their outputs. How hard is it to\nclassically simulate the output of random quantum circuits?\n  We prove that estimating the output probabilities of random quantum circuits\nis formidably hard ($\\#P$-Hard) for any classical computer. This makes RCS the\nstrongest candidate for demonstrating quantum supremacy relative to all other\nproposals. The robustness to the estimation error that we prove may serve as a\nnew hardness criterion for the performance of classical algorithms. To achieve\nthis, we introduce the Cayley path interpolation between any two gates of a\nquantum computation and convolve recent advances in quantum complexity and\ninformation with probability and random matrices. Furthermore, we apply\nalgebraic geometry to generalize the well-known Berlekamp-Welch algorithm that\nis widely used in coding theory and cryptography. Our results imply that there\nis an exponential hardness barrier for the classical simulation of most quantum\ncircuits.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:00:12 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 14:55:36 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 02:39:04 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 19:01:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Movassagh", "Ramis", ""]]}, {"id": "1909.06430", "submitter": "Nicolas Resch", "authors": "Jonathan Mosheiff, Nicolas Resch, Noga Ron-Zewi, Shashwat Silas, and\n  Mary Wootters", "title": "LDPC Codes Achieve List Decoding Capacity", "comments": "36 pages, 3 figures. In this updated version, minor typos are\n  corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Gallager's ensemble of Low-Density Parity Check (LDPC) codes\nachieves list-decoding capacity with high probability. These are the first\ngraph-based codes shown to have this property. This result opens up a potential\navenue towards truly linear-time list-decodable codes that achieve\nlist-decoding capacity.\n  Our result on list decoding follows from a much more general result: any\n$\\textit{local}$ property satisfied with high probability by a random linear\ncode is also satisfied with high probability by a random LDPC code from\nGallager's distribution. Local properties are properties characterized by the\nexclusion of small sets of codewords, and include list-decoding, list-recovery\nand average-radius list-decoding.\n  In order to prove our results on LDPC codes, we establish sharp thresholds\nfor when local properties are satisfied by a random linear code. More\nprecisely, we show that for any local property $\\mathcal{P}$, there is some\n$R^*$ so that random linear codes of rate slightly less than $R^*$ satisfy\n$\\mathcal{P}$ with high probability, while random linear codes of rate slightly\nmore than $R^*$ with high probability do not. We also give a characterization\nof the threshold rate $R^*$.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:17:37 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 18:40:41 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 08:36:00 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Mosheiff", "Jonathan", ""], ["Resch", "Nicolas", ""], ["Ron-Zewi", "Noga", ""], ["Silas", "Shashwat", ""], ["Wootters", "Mary", ""]]}, {"id": "1909.06437", "submitter": "Philipp Zschoche", "authors": "Arnaud Casteigts, Anne-Sophie Himmel, Hendrik Molter, and Philipp\n  Zschoche", "title": "The Computational Complexity of Finding Temporal Paths under Waiting\n  Time Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computing a (short) path between two vertices is one of the most fundamental\nprimitives in graph algorithmics. In recent years, the study of paths in\ntemporal graphs, that is, graphs where the vertex set is fixed but the edge set\nchanges over time, gained more and more attention. A path is time-respecting,\nor temporal, if it uses edges with non-decreasing time stamps. We investigate a\nbasic constraint for temporal paths, where the time spent at each vertex must\nnot exceed a given duration $\\Delta$, referred to as $\\Delta$-restless temporal\npaths. This constraint arises naturally in the modeling of real-world processes\nlike packet routing in communication networks and infection transmission routes\nof diseases where recovery confers lasting resistance. While finding temporal\npaths without waiting time restrictions is known to be doable in polynomial\ntime, we show that the \"restless variant\" of this problem becomes\ncomputationally hard even in very restrictive settings. For example, it is\nW[1]-hard when parameterized by the distance to disjoint path of the underlying\ngraph, which implies W[1]-hardness for many other parameters like feedback\nvertex number and pathwidth. A natural question is thus whether the problem\nbecomes tractable in some natural settings. We explore several natural\nparameterizations, presenting FPT algorithms for three kinds of parameters: (1)\noutput-related parameters (here, the maximum length of the path), (2) classical\nparameters applied to the underlying graph (e.g., feedback edge number), and\n(3) a new parameter called timed feedback vertex number, which captures\nfiner-grained temporal features of the input temporal graph, and which may be\nof interest beyond this work.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:39:44 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 09:43:41 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 15:47:23 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 07:33:05 GMT"}, {"version": "v5", "created": "Wed, 26 May 2021 08:32:50 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Himmel", "Anne-Sophie", ""], ["Molter", "Hendrik", ""], ["Zschoche", "Philipp", ""]]}, {"id": "1909.07326", "submitter": "Martin Kouteck\\'y", "authors": "Du\\v{s}an Knop, Martin Kouteck\\'y, Asaf Levin, Matthias Mnich, Shmuel\n  Onn", "title": "Multitype Integer Monoid Optimization and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Configuration integer programs (IP) have been key in the design of algorithms\nfor NP-hard high-multiplicity problems since the pioneering work of Gilmore and\nGomory [Oper. Res., 1961]. Configuration IPs have a variable for each possible\nconfiguration, which describes a placement of items into a location, and whose\nvalue corresponds to the number of locations with that placement. In high\nmultiplicity problems items come in types, and are represented succinctly by a\nvector of multiplicities; solving the configuration IP then amounts to deciding\nwhether the input vector of multiplicities of items of each type can be\ndecomposed into a given number of configurations.\n  We make this implicit notion explicit by observing that the set of all input\nvectors decomposable into configurations forms a monoid, and solving the\nconfiguration IP is the Monoid Decomposition problem. Motivated by\napplications, we enrich this problem in two ways. First, sometimes each\nconfiguration additionally has an objective value, yielding an optimization\nproblem of finding a \"best\" decomposition under the given objective. Second,\nthere are often different types of configurations for different types of\nlocations. The resulting problem is to optimize over decompositions of the\ninput multiplicity vector into configurations of several types, and we call it\nMultitype Integer Monoid Optimization, or MIMO.\n  We develop fast exact algorithms for various MIMO with few or many location\ntypes and with various objectives. Our algorithms build on a novel proximity\ntheorem connecting the solutions of a certain configuration IP to those of its\ncontinuous relaxation. We then cast several fundamental scheduling and bin\npacking problems as MIMOs, and thereby obtain new or substantially faster\nalgorithms for them.\n  We complement our positive algorithmic results by hardness results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 16:40:11 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Knop", "Du\u0161an", ""], ["Kouteck\u00fd", "Martin", ""], ["Levin", "Asaf", ""], ["Mnich", "Matthias", ""], ["Onn", "Shmuel", ""]]}, {"id": "1909.07413", "submitter": "Matthew Weidner", "authors": "Anand Kumar Narayanan and Matthew Weidner", "title": "On Decoding Cohen-Haeupler-Schulman Tree Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree codes, introduced by Schulman, are combinatorial structures essential to\ncoding for interactive communication. An infinite family of tree codes with\nboth rate and distance bounded by positive constants is called asymptotically\ngood. Rate being constant is equivalent to the alphabet size being constant.\nSchulman proved that there are asymptotically good tree code families using the\nLovasz local lemma, yet their explicit construction remains an outstanding open\nproblem. In a major breakthrough, Cohen, Haeupler and Schulman constructed\nexplicit tree code families with constant distance, but over an alphabet\npolylogarithmic in the length. Our main result is a randomized polynomial time\ndecoding algorithm for these codes making novel use of the polynomial method.\nThe number of errors corrected scales roughly as the block length to the\nthree-fourths power, falling short of the constant fraction error correction\nguaranteed by the constant distance. We further present number theoretic\nvariants of Cohen-Haeupler-Schulman codes, all correcting a constant fraction\nof errors with polylogarithmic alphabet size. Towards efficiently correcting\nclose to a constant fraction of errors, we propose a speculative convex\noptimization approach inspired by compressed sensing.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 18:05:56 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Narayanan", "Anand Kumar", ""], ["Weidner", "Matthew", ""]]}, {"id": "1909.07498", "submitter": "Justin Thaler", "authors": "Alexander A. Sherstov and Justin Thaler", "title": "Vanishing-Error Approximate Degree and QMA Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\epsilon$-approximate degree of a function $f\\colon X \\to \\{0, 1\\}$ is\nthe least degree of a multivariate real polynomial $p$ such that $|p(x)-f(x)|\n\\leq \\epsilon$ for all $x \\in X$. We determine the $\\epsilon$-approximate\ndegree of the element distinctness function, the surjectivity function, and the\npermutation testing problem, showing they are $\\Theta(n^{2/3}\n\\log^{1/3}(1/\\epsilon))$, $\\tilde\\Theta(n^{3/4} \\log^{1/4}(1/\\epsilon))$, and\n$\\Theta(n^{1/3} \\log^{2/3}(1/\\epsilon))$, respectively. Previously, these\nbounds were known only for constant $\\epsilon.$\n  We also derive a connection between vanishing-error approximate degree and\nquantum Merlin--Arthur (QMA) query complexity. We use this connection to show\nthat the QMA complexity of permutation testing is $\\Omega(n^{1/4})$. This\nimproves on the previous best lower bound of $\\Omega(n^{1/6})$ due to Aaronson\n(Quantum Information & Computation, 2012), and comes somewhat close to matching\na known upper bound of $O(n^{1/3})$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:59:01 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Sherstov", "Alexander A.", ""], ["Thaler", "Justin", ""]]}, {"id": "1909.07816", "submitter": "Jiawei Gao", "authors": "Jiawei Gao", "title": "The Computational Complexity of Fire Emblem Series and similar Tactical\n  Role-Playing Games", "comments": "Updated the abstract and the first paragraph of \"main results\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fire Emblem (FE) is a popular turn-based tactical role-playing game (TRPG)\nseries on the Nintendo gaming consoles. This paper studies the computational\ncomplexity of a simplified version of FE (only floor tiles and wall tiles, the\nHP and other attributes of characters are constants at most 8, the movement\ndistance per character each turn is fixed to 6 tiles), and proves that: 1.\nSimplified FE is PSPACE-complete (Thus actual FE is at least as hard). 2.\nPoly-round FE is NP-complete, even when the map is cycle-free, without healing\nunits, and the weapon durability is a small constant. Poly-round FE is to\ndecide whether the player can win the game in a certain number of rounds that\nis polynomial to the map size. A map is called cycle-free if its corresponding\nplanar graph is cycle-free. These hardness results also hold for other similar\nTRPG series, such as Final Fantasy Tactics, Tactics Ogre and Disgaea.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 05:30:30 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 05:09:31 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Gao", "Jiawei", ""]]}, {"id": "1909.08233", "submitter": "EPTCS", "authors": "Michael Morak", "title": "Epistemic Logic Programs: A Different World View", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 52-64", "doi": "10.4204/EPTCS.306.11", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic Logic Programs (ELPs), an extension of Answer Set Programming (ASP)\nwith epistemic operators, have received renewed attention from the research\ncommunity in recent years. Classically, evaluating an ELP yields a set of world\nviews, with each being a set of answer sets. In this paper, we propose an\nalternative definition of world views that represents them as three-valued\nassignments, where each atom can be either always true, always false, or\nneither. Based on several examples, we show that this definition is natural and\nintuitive. We also investigate relevant computational properties of these new\nsemantics, and explore how other notions, like strong equivalence, are\naffected.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:00:47 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Morak", "Michael", ""]]}, {"id": "1909.08426", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet, Nicolas Bousquet, St\\'ephan Thomass\\'e, R\\'emi\n  Watrigant", "title": "When Maximum Stable Set can be solved in FPT time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum Independent Set (MIS for short) is in general graphs the paradigmatic\n$W[1]$-hard problem. In stark contrast, polynomial-time algorithms are known\nwhen the inputs are restricted to structured graph classes such as, for\ninstance, perfect graphs (which includes bipartite graphs, chordal graphs,\nco-graphs, etc.) or claw-free graphs. In this paper, we introduce some variants\nof co-graphs with parameterized noise, that is, graphs that can be made into\ndisjoint unions or complete sums by the removal of a certain number of vertices\nand the addition/deletion of a certain number of edges per incident vertex,\nboth controlled by the parameter. We give a series of FPT Turing-reductions on\nthese classes and use them to make some progress on the parameterized\ncomplexity of MIS in $H$-free graphs. We show that for every fixed $t \\geqslant\n1$, MIS is FPT in $P(1,t,t,t)$-free graphs, where $P(1,t,t,t)$ is the graph\nobtained by substituting all the vertices of a four-vertex path but one end of\nthe path by cliques of size $t$. We also provide randomized FPT algorithms in\ndart-free graphs and in cricket-free graphs. This settles the FPT/W[1]-hard\ndichotomy for five-vertex graphs $H$.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 13:04:39 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Bousquet", "Nicolas", ""], ["Thomass\u00e9", "St\u00e9phan", ""], ["Watrigant", "R\u00e9mi", ""]]}, {"id": "1909.08435", "submitter": "Vangelis Paschos", "authors": "Vangelis Th. Paschos", "title": "A polynomial time approximation schema for maximum k-vertex cover in\n  bipartite graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a polynomial time approximation schema for the\nedge-weighted version of maximum k-vertex cover problem in bipartite graphs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 13:22:39 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Paschos", "Vangelis Th.", ""]]}, {"id": "1909.08608", "submitter": "Renos Karamanis", "authors": "Renos Karamanis, Eleftherios Anastasiadis, Panagiotis Angeloudis and\n  Marc Stettler", "title": "Assignment and Pricing of Shared Rides in Ride-Sourcing using\n  Combinatorial Double Auctions", "comments": "12 pages, Ride-Sharing, Combinatorial Double Auctions, Assignment,\n  Dynamic Pricing", "journal-ref": null, "doi": "10.1109/TITS.2020.2988356", "report-no": null, "categories": "cs.CC cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation Network Companies employ dynamic pricing methods at periods of\npeak travel to incentivise driver participation and balance supply and demand\nfor rides. Surge pricing multipliers are commonly used and are applied\nfollowing demand and estimates of customer and driver trip valuations.\nCombinatorial double auctions have been identified as a suitable alternative,\nas they can achieve maximum social welfare in the allocation by relying on\ncustomers and drivers stating their valuations. A shortcoming of current\nmodels, however, is that they fail to account for the effects of trip detours\nthat take place in shared trips and their impact on the accuracy of pricing\nestimates. To resolve this, we formulate a new shared-ride assignment and\npricing algorithm using combinatorial double auctions. We demonstrate that this\nmodel is reduced to a maximum weighted independent set model, which is known to\nbe APX-hard. A fast local search heuristic is also presented, which is capable\nof producing results that lie within 10% of the exact approach for practical\nimplementations. Our proposed algorithm could be used as a fast and reliable\nassignment and pricing mechanism of ride-sharing requests to vehicles during\npeak travel times.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:56:29 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 20:39:32 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 09:46:49 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Karamanis", "Renos", ""], ["Anastasiadis", "Eleftherios", ""], ["Angeloudis", "Panagiotis", ""], ["Stettler", "Marc", ""]]}, {"id": "1909.08846", "submitter": "Sevag Gharibian", "authors": "Sevag Gharibian, Ojas Parekh", "title": "Almost optimal classical approximation algorithms for a quantum\n  generalization of Max-Cut", "comments": "17 pages, published version", "journal-ref": "Proceedings of the 22nd International Workshop on Approximation\n  Algorithms for Combinatorial Optimization Problems (APPROX), volume 145 of\n  Leibniz International Proceedings in Informatics (LIPIcs), pages 31:1-31:17,\n  2019", "doi": "10.4230/LIPIcs.APPROX-RANDOM.2019.31", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximation algorithms for constraint satisfaction problems (CSPs) are a\ncentral direction of study in theoretical computer science. In this work, we\nstudy classical product state approximation algorithms for a physically\nmotivated quantum generalization of Max-Cut, known as the quantum Heisenberg\nmodel. This model is notoriously difficult to solve exactly, even on bipartite\ngraphs, in stark contrast to the classical setting of Max-Cut. Here we show,\nfor any interaction graph, how to classically and efficiently obtain\napproximation ratios 0.649 (anti-ferromagnetic XY model) and 0.498\n(anti-ferromagnetic Heisenberg XYZ model). These are almost optimal; we show\nthat the best possible ratios achievable by a product state for these models is\n2/3 and 1/2, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:15:48 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Gharibian", "Sevag", ""], ["Parekh", "Ojas", ""]]}, {"id": "1909.09231", "submitter": "Christof Schmidhuber", "authors": "Christof Schmidhuber", "title": "Chaitin's Omega and an Algorithmic Phase Transition", "comments": "29 pages, 5 figures. Added references, a literature review, and a\n  section on analogies with quantum mechanics and field theory (previous title:\n  \"Logical Quantum Field Theory\")", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT hep-th math-ph math.IT math.LO math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the statistical mechanical ensemble of bit string histories that\nare computed by a universal Turing machine. The role of the energy is played by\nthe program size. We show that this ensemble has a first-order phase transition\nat a critical temperature, at which the partition function equals Chaitin's\nhalting probability $\\Omega$. This phase transition has curious properties: the\nfree energy is continuous near the critical temperature, but almost jumps: it\nconverges more slowly to its finite critical value than any computable\nfunction. At the critical temperature, the average size of the bit strings\ndiverges. We define a non-universal Turing machine that approximates this\nbehavior of the partition function in a computable way by a super-logarithmic\nsingularity, and discuss its thermodynamic properties. We also discuss\nanalogies and differences between Chaitin's Omega and the partition functions\nof a quantum mechanical particle, a spin model, random surfaces, and quantum\nTuring machines. For universal Turing machines, we conjecture that the ensemble\nof bit string histories at the critical temperature has a continuum formulation\nin terms of a string theory.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:32:58 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 14:22:21 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 16:05:24 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Schmidhuber", "Christof", ""]]}, {"id": "1909.09518", "submitter": "J. M. Landsberg", "authors": "Austin Conner, Fulvio Gesmundo, Joseph M. Landsberg, and Emanuele\n  Ventura", "title": "Tensors with maximal symmetries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify tensors with maximal and next to maximal dimensional symmetry\ngroups under a natural genericity assumption (1-genericity), in dimensions\ngreater than 13. In other words, we classify minimal dimensional orbits in the\nspace of (m,m,m) tensors assuming 1-genericity. Our study uncovers new tensors\nwith striking geometry. This paper was motivated by Strassen's laser method for\nbounding the exponent of matrix multiplication. The best known tensor for the\nlaser method is the large Coppersmith-Winograd tensor, and our study began with\nthe observation that it has a large symmetry group, of dimension m^2/2 +m/2. We\nshow that in odd dimensions, this is the largest possible for a 1-generic\ntensor, but in even dimensions we exhibit a tensor with a larger dimensional\nsymmetry group. In the course of the proof, we classify nondegenerate bilinear\nforms with large dimensional stabilizers, which may be of interest in its own\nright.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:09:21 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Conner", "Austin", ""], ["Gesmundo", "Fulvio", ""], ["Landsberg", "Joseph M.", ""], ["Ventura", "Emanuele", ""]]}, {"id": "1909.09984", "submitter": "Ilan Newman", "authors": "Hiro Ito, Areej Khoury and Ilan Newman", "title": "On the Characterization of $1$-sided error Strongly-Testable Graph\n  Properties for bounded-degree graphs, including an appendix", "comments": "this version corrects minor details in the previous: (a) removed the\n  non-defined term 'non-redundant' from theorem 3.3. (b) corrected a typo in\n  example 7.2 page 22", "journal-ref": "Comput. Complex. 29(1): 1 (2020)", "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study property testing of (di)graph properties in bounded-degree graph\nmodels. The study of graph properties in bounded-degree models is one of the\nfocal directions of research in property testing in the last 15 years. However,\ndespite of the many results and the extensive research effort, there is no\ncharacterization of the properties that are strongly-testable (i.e., testable\nwith constant query complexity) even for $1$-sided error tests. The\nbounded-degree model can naturally be generalized to directed graphs resulting\nin two models that were considered in the literature. The first contains the\ndirected graphs in which the outdegree is bounded but the indegree is not\nrestricted. In the other, both the outdegree and indegree are bounded. We give\na characterization of the $1$-sided error strongly-testable {\\em monotone}\ngraph properties, and the $1$-sided error strongly-testable {\\em hereditary}\ngraph properties in all the bounded-degree directed and undirected graphs\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 11:28:28 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 11:30:09 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ito", "Hiro", ""], ["Khoury", "Areej", ""], ["Newman", "Ilan", ""]]}, {"id": "1909.10260", "submitter": "Tim Seppelt", "authors": "Tim Seppelt", "title": "The Graph Isomorphism Problem: Local Certificates for Giant Action", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC math.CO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This thesis provides an explanation of L\\'aszl\\'o Babai's quasi-polynomial\nalgorithm for the Graph Isomorphism Problem published in 2015 with a particular\nfocus on the case of local certificates, i.e. the case that cannot be dealt\nwith by Luks' method. The thesis extends the explanations provided by Harald\nAndr\\'es Helfgott in 2017. It is concluded that the complexity of Babai's\nalgorithm is $\\exp\\left(C \\left(\\log n\\right)^3\\right)$ for $n$ the number of\nvertices, $C$ a constant. Group theoretical and combinatorial arguments are\nused to give more details on Babai's method of local certificates. They treat\nLuks' barrier case in which the imprimitve permutation group $G$ can be mapped\nonto an alternating group with large domain.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 10:12:00 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Seppelt", "Tim", ""]]}, {"id": "1909.10279", "submitter": "Alec Koppel", "authors": "Alec Koppel, Amrit Singh Bedi, Brian M. Sadler, and Victor Elvira", "title": "Nearly Consistent Finite Particle Estimates in Streaming Importance\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian inference, we seek to compute information about random variables\nsuch as moments or quantiles on the basis of {available data} and prior\ninformation. When the distribution of random variables is {intractable}, Monte\nCarlo (MC) sampling is usually required. {Importance sampling is a standard MC\ntool that approximates this unavailable distribution with a set of weighted\nsamples.} This procedure is asymptotically consistent as the number of MC\nsamples (particles) go to infinity. However, retaining infinitely many\nparticles is intractable. Thus, we propose a way to only keep a \\emph{finite\nrepresentative subset} of particles and their augmented importance weights that\nis \\emph{nearly consistent}. To do so in {an online manner}, we (1) embed the\nposterior density estimate in a reproducing kernel Hilbert space (RKHS) through\nits kernel mean embedding; and (2) sequentially project this RKHS element onto\na lower-dimensional subspace in RKHS using the maximum mean discrepancy, an\nintegral probability metric. Theoretically, we establish that this scheme\nresults in a bias determined by a compression parameter, which yields a tunable\ntradeoff between consistency and memory. In experiments, we observe the\ncompressed estimates achieve comparable performance to the dense ones with\nsubstantial reductions in representational complexity.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 11:06:15 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 16:51:19 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Koppel", "Alec", ""], ["Bedi", "Amrit Singh", ""], ["Sadler", "Brian M.", ""], ["Elvira", "Victor", ""]]}, {"id": "1909.10303", "submitter": "Nai-Hui Chia", "authors": "Nai-Hui Chia, Kai-Min Chung, and Ching-Yi Lai", "title": "On the Need for Large Quantum Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-term quantum computers are likely to have small depths due to short\ncoherence time and noisy gates, and thus a potential way to use these quantum\ndevices is using a hybrid scheme that interleaves them with classical\ncomputers. For example, the quantum Fourier transform can be implemented by a\nhybrid of logarithmic-depth quantum circuits and a classical polynomial-time\nalgorithm. Along the line, it seems possible that a general quantum computer\nmay only be polynomially faster than a hybrid quantum-classical computer. Jozsa\nraised the question of whether $BQP = BPP^{BQNC}$ and conjectured that they are\nequal, where $BQNC$ means $polylog$-depth quantum circuits. Nevertheless,\nAaronson conjectured an oracle separation for these two classes and gave a\ncandidate. In this work, we prove Aaronson's conjecture for a different but\nrelated oracle problem. Our result also proves that Jozsa's conjecture fails\nrelative to an oracle.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 11:50:13 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 20:51:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chia", "Nai-Hui", ""], ["Chung", "Kai-Min", ""], ["Lai", "Ching-Yi", ""]]}, {"id": "1909.10419", "submitter": "Jan P\\\"oppel", "authors": "Jan P\\\"oppel and Stefan Kopp", "title": "Satisficing Mentalizing: Bayesian Models of Theory of Mind Reasoning in\n  Scenarios with Different Uncertainties", "comments": "This paper is an extended version of the paper \"Satisficing Models of\n  Bayesian Theory of Mind for Explaining Behavior of Differently Uncertain\n  Agents\" by the same authors, submitted to AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to interpret the mental state of another agent based on its\nbehavior, also called Theory of Mind (ToM), is crucial for humans in any kind\nof social interaction. Artificial systems, such as intelligent assistants,\nwould also greatly benefit from such mentalizing capabilities. However, humans\nand systems alike are bound by limitations in their available computational\nresources. This raises the need for satisficing mentalizing, reconciling\naccuracy and efficiency in mental state inference that is good enough for a\ngiven situation. In this paper, we present different Bayesian models of ToM\nreasoning and evaluate them based on actual human behavior data that were\ngenerated under different kinds of uncertainties. We propose a Switching\napproach that combines specialized models, embodying simplifying presumptions,\nin order to achieve a more statisficing mentalizing compared to a Full Bayesian\nToM model.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 15:20:51 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["P\u00f6ppel", "Jan", ""], ["Kopp", "Stefan", ""]]}, {"id": "1909.10428", "submitter": "Nikhil Mande", "authors": "Sourav Chakraborty, Arkadev Chattopadhyay, Nikhil S. Mande, Manaswi\n  Paraashar", "title": "Quantum Query-to-Communication Simulation Needs a Logarithmic Overhead", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buhrman, Cleve and Wigderson (STOC'98) observed that for every Boolean\nfunction $f : \\{-1, 1\\}^n \\to \\{-1, 1\\}$ and $\\bullet : \\{-1, 1\\}^2 \\to \\{-1,\n1\\}$ the two-party bounded-error quantum communication complexity of $(f \\circ\n\\bullet)$ is $O(Q(f) \\log n)$, where $Q(f)$ is the bounded-error quantum query\ncomplexity of $f$. Note that the bounded-error randomized communication\ncomplexity of $(f \\circ \\bullet)$ is bounded by $O(R(f))$, where $R(f)$ denotes\nthe bounded-error randomized query complexity of $f$. Thus, the BCW simulation\nhas an extra $O(\\log n)$ factor appearing that is absent in classical\nsimulation. A natural question is if this factor can be avoided. H{\\o}yer and\nde Wolf (STACS'02) showed that for the Set-Disjointness function, this can be\nreduced to $c^{\\log^* n}$ for some constant $c$, and subsequently Aaronson and\nAmbainis (FOCS'03) showed that this factor can be made a constant. That is, the\nquantum communication complexity of the Set-Disjointness function (which is\n$\\mathsf{NOR}_n \\circ \\wedge$) is $O(Q(\\mathsf{NOR}_n))$.\n  Perhaps somewhat surprisingly, we show that when $ \\bullet = \\oplus$, then\nthe extra $\\log n$ factor in the BCW simulation is unavoidable. In other words,\nwe exhibit a total function $F : \\{-1, 1\\}^n \\to \\{-1, 1\\}$ such that $Q^{cc}(F\n\\circ \\oplus) = \\Theta(Q(F) \\log n)$.\n  To the best of our knowledge, it was not even known prior to this work\nwhether there existed a total function $F$ and 2-bit function $\\bullet$, such\nthat $Q^{cc}(F \\circ \\bullet) = \\omega(Q(F))$.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 15:35:41 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Chakraborty", "Sourav", ""], ["Chattopadhyay", "Arkadev", ""], ["Mande", "Nikhil S.", ""], ["Paraashar", "Manaswi", ""]]}, {"id": "1909.10503", "submitter": "Sanketh Menda", "authors": "Matthew Coudron and Sanketh Menda", "title": "Computations with Greater Quantum Depth Are Strictly More Powerful\n  (Relative to an Oracle)", "comments": "39 pages, revised", "journal-ref": null, "doi": "10.1145/3357713.3384269", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conjecture of Jozsa (arXiv:quant-ph/0508124) states that any\npolynomial-time quantum computation can be simulated by polylogarithmic-depth\nquantum computation interleaved with polynomial-depth classical computation.\nSeparately, Aaronson conjectured that there exists an oracle $\\mathcal{O}$ such\nthat $\\textrm{BQP}^{\\mathcal{O}} \\neq\n(\\textrm{BPP}^\\textrm{BQNC})^{\\mathcal{O}}$. These conjectures are intriguing\nallusions to the unresolved potential of combining classical and low-depth\nquantum computation. In this work we show that the Welded Tree Problem, which\nis an oracle problem that can be solved in quantum polynomial time as shown by\nChilds et al. (arXiv:quant-ph/0209131), cannot be solved in\n$\\textrm{BPP}^{\\textrm{BQNC}}$, nor can it be solved in the class that Jozsa\ndescribes. This proves Aaronson's oracle separation conjecture and provides a\ncounterpoint to Jozsa's conjecture relative to the Welded Tree oracle problem.\nMore precisely, we define two complexity classes, $\\textrm{HQC}$ and\n$\\textrm{JC}$ whose languages are decided by two different families of\ninterleaved quantum-classical circuits. $\\textrm{HQC}$ contains\n$\\textrm{BPP}^\\textrm{BQNC}$ and is therefore relevant to Aaronson's\nconjecture, while $\\textrm{JC}$ captures the model of computation that Jozsa\nconsiders. We show that the Welded Tree Problem gives an oracle separation\nbetween either of $\\{\\textrm{JC}, \\textrm{HQC}\\}$ and $\\textrm{BQP}$.\nTherefore, even when interleaved with arbitrary polynomial-time classical\ncomputation, greater \"quantum depth\" leads to strictly greater computational\nability in this relativized setting.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 17:45:17 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 16:51:21 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 04:43:42 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Coudron", "Matthew", ""], ["Menda", "Sanketh", ""]]}, {"id": "1909.10658", "submitter": "Kewen Wu", "authors": "Shachar Lovett, Kewen Wu, Jiapeng Zhang", "title": "Decision list compression by mild random restrictions", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decision list is an ordered list of rules. Each rule is specified by a\nterm, which is a conjunction of literals, and a value. Given an input, the\noutput of a decision list is the value corresponding to the first rule whose\nterm is satisfied by the input. Decision lists generalize both CNFs and DNFs,\nand have been studied both in complexity theory and in learning theory.\n  The size of a decision list is the number of rules, and its width is the\nmaximal number of variables in a term. We prove that decision lists of small\nwidth can always be approximated by decision lists of small size, where we\nobtain sharp bounds. This in particular resolves a conjecture of Gopalan, Meka\nand Reingold (Computational Complexity, 2013) on DNF sparsification.\n  An ingredient in our proof is a new random restriction lemma, which allows to\nanalyze how DNFs (and more generally, decision lists) simplify if a small\nfraction of the variables are fixed. This is in contrast to the more commonly\nused switching lemma, which requires most of the variables to be fixed.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 00:04:17 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 06:32:33 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lovett", "Shachar", ""], ["Wu", "Kewen", ""], ["Zhang", "Jiapeng", ""]]}, {"id": "1909.10958", "submitter": "Karthik C. S.", "authors": "Anat Ganor, Karthik C. S., and D\\\"om\\\"ot\\\"or P\\'alv\\\"olgyi", "title": "On Communication Complexity of Fixed Point Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brouwer's fixed point theorem states that any continuous function from a\ncompact convex space to itself has a fixed point. Roughgarden and Weinstein\n(FOCS 2016) initiated the study of fixed point computation in the two-player\ncommunication model, where each player gets a function from $[0,1]^n$ to\n$[0,1]^n$, and their goal is to find an approximate fixed point of the\ncomposition of the two functions. They left it as an open question to show a\nlower bound of $2^{\\Omega(n)}$ for the (randomized) communication complexity of\nthis problem, in the range of parameters which make it a total search problem.\nWe answer this question affirmatively.\n  Additionally, we introduce two natural fixed point problems in the two-player\ncommunication model.\n  $\\bullet$ Each player is given a function from $[0,1]^n$ to $[0,1]^{n/2}$,\nand their goal is to find an approximate fixed point of the concatenation of\nthe functions.\n  $\\bullet$ Each player is given a function from $[0,1]^n$ to $[0,1]^{n}$, and\ntheir goal is to find an approximate fixed point of the interpolation of the\nfunctions.\n  We show a randomized communication complexity lower bound of $2^{\\Omega(n)}$\nfor these problems (for some constant approximation factor).\n  Finally, we initiate the study of finding a panchromatic simplex in a\nSperner-coloring of a triangulation (guaranteed by Sperner's lemma) in the\ntwo-player communication model: A triangulation $T$ of the $d$-simplex is\npublicly known and one player is given a set $S_A\\subset T$ and a coloring\nfunction from $S_A$ to $\\{0,\\ldots ,d/2\\}$, and the other player is given a set\n$S_B\\subset T$ and a coloring function from $S_B$ to $\\{d/2+1,\\ldots ,d\\}$,\nsuch that $S_A\\dot\\cup S_B=T$, and their goal is to find a panchromatic\nsimplex. We show a randomized communication complexity lower bound of\n$|T|^{\\Omega(1)}$ for the aforementioned problem as well (when $d$ is large).\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 14:34:41 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 22:56:35 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ganor", "Anat", ""], ["S.", "Karthik C.", ""], ["P\u00e1lv\u00f6lgyi", "D\u00f6m\u00f6t\u00f6r", ""]]}, {"id": "1909.11068", "submitter": "Dhruv Rohatgi", "authors": "Dhruv Rohatgi", "title": "Conditional Hardness of Earth Mover Distance", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": "10.4230/LIPIcs.APPROX-RANDOM.2019.12", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Earth Mover Distance (EMD) between two sets of points $A, B \\subseteq\n\\mathbb{R}^d$ with $|A| = |B|$ is the minimum total Euclidean distance of any\nperfect matching between $A$ and $B$. One of its generalizations is asymmetric\nEMD, which is the minimum total Euclidean distance of any matching of size\n$|A|$ between sets of points $A,B \\subseteq \\mathbb{R}^d$ with $|A| \\leq |B|$.\nThe problems of computing EMD and asymmetric EMD are well-studied and have many\napplications in computer science, some of which also ask for the EMD-optimal\nmatching itself. Unfortunately, all known algorithms require at least quadratic\ntime to compute EMD exactly. Approximation algorithms with nearly linear time\ncomplexity in $n$ are known (even for finding approximately optimal matchings),\nbut suffer from exponential dependence on the dimension.\n  In this paper we show that significant improvements in exact and approximate\nalgorithms for EMD would contradict conjectures in fine-grained complexity. In\nparticular, we prove the following results:\n  (1) Under the Orthogonal Vectors Conjecture, there is some $c>0$ such that\nEMD in $\\Omega(c^{\\log^* n})$ dimensions cannot be computed in truly\nsubquadratic time.\n  (2) Under the Hitting Set Conjecture, for every $\\delta>0$, no truly\nsubquadratic time algorithm can find a $(1 + 1/n^\\delta)$-approximate EMD\nmatching in $\\omega(\\log n)$ dimensions.\n  (3) Under the Hitting Set Conjecture, for every $\\eta = 1/\\omega(\\log n)$, no\ntruly subquadratic time algorithm can find a $(1 + \\eta)$-approximate\nasymmetric EMD matching in $\\omega(\\log n)$ dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:42:35 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Rohatgi", "Dhruv", ""]]}, {"id": "1909.11485", "submitter": "David Gosset", "authors": "Sergey Bravyi, David Gosset, Ramis Movassagh", "title": "Classical algorithms for quantum mean values", "comments": null, "journal-ref": "Nature Physics (2021)", "doi": "10.1038/s41567-020-01109-8", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of estimating the expectation value of an $n$-qubit\ntensor product observable $O_1\\otimes O_2\\otimes \\cdots \\otimes O_n$ in the\noutput state of a shallow quantum circuit. This task is a cornerstone of\nvariational quantum algorithms for optimization, machine learning, and the\nsimulation of quantum many-body systems. Here we study its computational\ncomplexity for constant-depth quantum circuits and three types of single-qubit\nobservables $O_j$ which are (a) close to the identity, (b) positive\nsemidefinite, (c) arbitrary. It is shown that the mean value problem admits a\nclassical approximation algorithm with runtime scaling as $\\mathrm{poly}(n)$\nand $2^{\\tilde{O}(\\sqrt{n})}$ in cases (a,b) respectively. In case (c) we give\na linear-time algorithm for geometrically local circuits on a two-dimensional\ngrid. The mean value is approximated with a small relative error in case (a),\nwhile in cases (b,c) we satisfy a less demanding additive error bound. The\nalgorithms are based on (respectively) Barvinok's polynomial interpolation\nmethod, a polynomial approximation for the OR function arising from quantum\nquery complexity, and a Monte Carlo method combined with Matrix Product State\ntechniques. We also prove a technical lemma characterizing a zero-free region\nfor certain polynomials associated with a quantum circuit, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:32:41 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Bravyi", "Sergey", ""], ["Gosset", "David", ""], ["Movassagh", "Ramis", ""]]}, {"id": "1909.11554", "submitter": "Chuan-Chi Lai", "authors": "Chuan-Chi Lai, Li-Chun Wang, Zhu Han", "title": "Data-Driven 3D Placement of UAV Base Stations for Arbitrarily\n  Distributed Crowds", "comments": "6 pages, 3 figures, accepted by 2019 IEEE Global Communications\n  Conference: Wireless Communications (Globecom2019 WC)", "journal-ref": null, "doi": "10.1109/GLOBECOM38437.2019.9014210", "report-no": null, "categories": "cs.NI cs.CC cs.DS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider an Unmanned Aerial Vehicle (UAV)-assisted cellular\nsystem which consists of multiple UAV base stations (BSs) cooperating the\nterrestrial BSs. In such a heterogeneous network, for cellular operators, the\nproblem is how to determine the appropriate number, locations, and altitudes of\nUAV-BSs to improve the system sumrate as well as satisfy the demands of\narbitrarily flash crowds on data rates. We propose a data-driven 3D placement\nof UAV-BSs for providing an effective placement result with a feasible\ncomputational cost. The proposed algorithm searches for the appropriate number,\nlocation, coverage, and altitude of each UAV-BS in the serving area with the\nmaximized system sumrate in polynomial time so as to guarantee the minimum data\nrate requirement of UE. The simulation results show that the proposed approach\ncan improve system sumrate in comparison with the case without UAV-BSs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:33:19 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Lai", "Chuan-Chi", ""], ["Wang", "Li-Chun", ""], ["Han", "Zhu", ""]]}, {"id": "1909.11929", "submitter": "Alex Samorodnitsky", "authors": "Naomi Kirshner, Alex Samorodnitsky", "title": "A moment ratio bound for polynomials and some extremal properties of\n  Krawchouk polynomials and Hamming spheres", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $p \\ge 2$. We improve the bound $\\frac{\\|f\\|_p}{\\|f\\|_2} \\le (p-1)^{s/2}$\nfor a polynomial $f$ of degree $s$ on the boolean cube $\\{0,1\\}^n$, which comes\nfrom hypercontractivity, replacing the right hand side of this inequality by an\nexplicit bivariate function of $p$ and $s$, which is smaller than $(p-1)^{s/2}$\nfor any $p > 2$ and $s > 0$. We show the new bound to be tight, within a\nsmaller order factor, for the Krawchouk polynomial of degree $s$.\n  This implies several nearly-extremal properties of Krawchouk polynomials and\nHamming spheres (equivalently, Hamming balls). In particular, Krawchouk\npolynomials have (almost) the heaviest tails among all polynomials of the same\ndegree and $\\ell_2$ norm (this has to be interpreted with some care). The\nHamming spheres have the following approximate edge-isoperimetric property: For\nall $1 \\le s \\le \\frac{n}{2}$, and for all even distances $0 \\le i \\le\n\\frac{2s(n-s)}{n}$, the Hamming sphere of radius $s$ contains, up to a\nmultiplicative factor of $O(i)$, as many pairs of points at distance $i$ as\npossible, among sets of the same size (there is a similar, but slightly weaker\nand somewhat more complicated claim for general distances). This also implies\nthat Hamming spheres are (almost) stablest with respect to noise among sets of\nthe same size. In coding theory terms this means that a Hamming sphere\n(equivalently a Hamming ball) has the maximal probability of undetected error,\namong all binary codes of the same rate.\n  We also describe a family of hypercontractive inequalities for functions on\n$\\{0,1\\}^n$, which improve on the `usual' \"$q \\rightarrow 2$\" inequality by\ntaking into account the concentration of a function (expressed as the ratio\nbetween its $\\ell_r$ norms), and which are nearly tight for characteristic\nfunctions of Hamming spheres.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 06:31:58 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Kirshner", "Naomi", ""], ["Samorodnitsky", "Alex", ""]]}, {"id": "1909.12004", "submitter": "Peter Chini", "authors": "Peter Chini, Roland Meyer, Prakash Saivasan", "title": "Complexity of Liveness in Parameterized Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the fine-grained complexity of liveness verification for\nleader contributor systems. These consist of a designated leader thread and an\narbitrary number of identical contributor threads communicating via a shared\nmemory. The liveness verification problem asks whether there is an infinite\ncomputation of the system in which the leader reaches a final state infinitely\noften. Like its reachability counterpart, the problem is known to be\nNP-complete. Our results show that, even from a fine-grained point of view, the\ncomplexities differ only by a polynomial factor.\n  Liveness verification decomposes into reachability and cycle detection. We\npresent a fixed point iteration solving the latter in polynomial time. For\nreachability, we reconsider the two standard parameterizations. When\nparameterized by the number of states of the leader L and the size of the data\ndomain D, we show an (L + D)^O(L + D)-time algorithm. It improves on a previous\nalgorithm, thereby settling an open problem. When parameterized by the number\nof states of the contributor C, we reuse an O*(2^C)-time algorithm. We show how\nto connect both algorithms with the cycle detection to obtain algorithms for\nliveness verification. The running times of the composed algorithms match those\nof reachability, proving that the fine-grained lower bounds for liveness\nverification are met.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 09:47:25 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 08:27:52 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Chini", "Peter", ""], ["Meyer", "Roland", ""], ["Saivasan", "Prakash", ""]]}, {"id": "1909.12211", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "On the complexity of the clone membership problem", "comments": "30 pages", "journal-ref": "Theory of Computing Systems 65 (2021), no. 5, pp. 839--868", "doi": "10.1007/s00224-020-10016-7", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of the Boolean clone membership problem (CMP):\ngiven a set of Boolean functions $F$ and a Boolean function $f$, determine if\n$f$ is in the clone generated by $F$, i.e., if it can be expressed by a circuit\nwith $F$-gates. Here, $f$ and elements of $F$ are given as circuits or formulas\nover the usual De Morgan basis. B\\\"ohler and Schnoor (2007) proved that for any\nfixed $F$, the problem is coNP-complete, with a few exceptions where it is in\nP. Vollmer (2009) incorrectly claimed that the full problem CMP is also\ncoNP-complete. We prove that CMP is in fact $\\Theta^P_2$-complete, and we\ncomplement B\\\"ohler and Schnoor's results by showing that for fixed $f$, the\nproblem is NP-complete unless $f$ is a projection.\n  More generally, we study the problem $B$-CMP where $F$ and $f$ are given by\ncircuits using gates from $B$. For most choices of $B$, we classify the\ncomplexity of $B$-CMP as being $\\Theta^P_2$-complete (possibly under randomized\nreductions), coDP-complete, or in P.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:03:17 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 07:32:11 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 17:06:23 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 16:53:36 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "1909.12256", "submitter": "Jacek Krzaczkowski", "authors": "Piotr Kawa{\\l}ek, Michael Kompatscher and Jacek Krzaczkowski", "title": "Circuit equivalence in 2-nilpotent algebras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The circuit equivalence problem of a finite algebra $\\mathbf A$ is the\ncomputational problem of deciding whether two circuits over $\\mathbf A$ define\nthe same function or not. This problem not just generalises the equivalence\nproblem for Boolean circuits, but is also of high interest in universal\nalgebra, as it models the problems of checking identities in $\\mathbf A$. In\nthis paper we discuss the complexity for algebras from congruence modular\nvarieties. A partial classification was already given by Idziak and\nKrzaczkowski, leaving essentially only a gap for nilpotent but not\nsupernilpotent algebras. We start a systematic study of this open case, proving\nthat the circuit equivalence problem is in P for $2$-nilpotent such algebras.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:02:29 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Kawa\u0142ek", "Piotr", ""], ["Kompatscher", "Michael", ""], ["Krzaczkowski", "Jacek", ""]]}, {"id": "1909.12386", "submitter": "Michael Blondin", "authors": "Michael Blondin and Christoph Haase and Filip Mazowiecki and Mikhail\n  Raskin", "title": "Affine Extensions of Integer Vector Addition Systems with States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the reachability problem for affine $\\mathbb{Z}$-VASS, which are\ninteger vector addition systems with states in which transitions perform affine\ntransformations on the counters. This problem is easily seen to be undecidable\nin general, and we therefore restrict ourselves to affine $\\mathbb{Z}$-VASS\nwith the finite-monoid property (afmp-$\\mathbb{Z}$-VASS). The latter have the\nproperty that the monoid generated by the matrices appearing in their affine\ntransformations is finite. The class of afmp-$\\mathbb{Z}$-VASS encompasses\nclassical operations of counter machines such as resets, permutations,\ntransfers and copies. We show that reachability in an afmp-$\\mathbb{Z}$-VASS\nreduces to reachability in a $\\mathbb{Z}$-VASS whose control-states grow\nlinearly in the size of the matrix monoid. Our construction shows that\nreachability relations of afmp-$\\mathbb{Z}$-VASS are semilinear, and in\nparticular enables us to show that reachability in $\\mathbb{Z}$-VASS with\ntransfers and $\\mathbb{Z}$-VASS with copies is PSPACE-complete. We then focus\non the reachability problem for affine $\\mathbb{Z}$-VASS with monogenic\nmonoids: (possibly infinite) matrix monoids generated by a single matrix. We\nshow that, in a particular case, the reachability problem is decidable for this\nclass, disproving a conjecture about affine $\\mathbb{Z}$-VASS with infinite\nmatrix monoids we raised in a preliminary version of this paper. We complement\nthis result by presenting an affine $\\mathbb{Z}$-VASS with monogenic matrix\nmonoid and undecidable reachability relation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:00:13 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 14:48:50 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 11:52:44 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Blondin", "Michael", ""], ["Haase", "Christoph", ""], ["Mazowiecki", "Filip", ""], ["Raskin", "Mikhail", ""]]}, {"id": "1909.12658", "submitter": "Seiichiro Tani", "authors": "Seiichiro Tani", "title": "Quantum Algorithm for Finding the Optimal Variable Ordering for Binary\n  Decision Diagrams", "comments": "8 figures added; typos corrected", "journal-ref": "Proc. 17th Scandinavian Symposium and Workshops on Algorithm\n  Theory (SWAT 2020), LIPIcs 162, pp. 36:1--36:19", "doi": "10.4230/LIPIcs.SWAT.2020.36", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ordered binary decision diagram (OBDD) is a directed acyclic graph that\nrepresents a Boolean function. OBDDs are also known as special cases of\noblivious read-once branching programs in the field of complexity theory. Since\nOBDDs have many nice properties as data structures, they have been extensively\nstudied for decades in both theoretical and practical fields, such as VLSI\ndesign, formal verification, machine learning, and combinatorial problems.\nArguably, the most crucial problem in using OBDDs is that they may vary\nexponentially in size depending on their variable ordering (i.e., the order in\nwhich the variable are to read) when they represent the same function. Indeed,\nit is NP hard to find an optimal variable ordering that minimizes an OBDD for a\ngiven function. Hence, numerous studies have sought heuristics to find an\noptimal variable ordering. From practical as well as theoretical points of\nview, it is also important to seek algorithms that output optimal solutions\nwith lower (exponential) time complexity than trivial brute-force algorithms\ndo. Friedman and Supowit provided a clever deterministic algorithm with\ntime/space complexity $O^\\ast(3^n)$, where $n$ is the number of variables of\nthe function, which is much better than the trivial brute-force bound\n$O^\\ast(n!2^n)$. This paper shows that a further speedup is possible with\nquantum computers by demonstrating the existence of a quantum algorithm that\nproduces a minimum OBDD together with the corresponding variable ordering in\n$O^\\ast(2.77286^n)$ time and space with an exponentially small error. Moreover,\nthis algorithm can be adapted to constructing other minimum decision diagrams\nsuch as zero-suppressed BDDs, which provide compact representations of sparse\nsets and are often used in the field of discrete optimization and enumeration.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:52:07 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 04:15:02 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Tani", "Seiichiro", ""]]}, {"id": "1909.13017", "submitter": "Kabir Olorede Opeyemi", "authors": "Kabir Opeyemi Olorede and Waheed Babatunde Yahya", "title": "A New Covariance Estimator for Sufficient Dimension Reduction in\n  High-Dimensional and Undersized Sample Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "JCGS-19-251", "categories": "stat.ME cs.CC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of standard sufficient dimension reduction methods for\nreducing the dimension space of predictors without losing regression\ninformation requires inverting the covariance matrix of the predictors. This\nhas posed a number of challenges especially when analyzing high-dimensional\ndata sets in which the number of predictors $\\mathit{p}$ is much larger than\nnumber of samples $n,~(n\\ll p)$. A new covariance estimator, called the\n\\textit{Maximum Entropy Covariance} (MEC) that addresses loss of covariance\ninformation when similar covariance matrices are linearly combined using\n\\textit{Maximum Entropy} (ME) principle is proposed in this work. By\nbenefitting naturally from slicing or discretizing range of the response\nvariable, y into \\textit{H} non-overlapping categories, $\\mathit{h_{1},\\ldots\n,h_{H}}$, MEC first combines covariance matrices arising from samples in each y\nslice $\\mathit{h\\in H}$ and then select the one that maximizes entropy under\nthe principle of maximum uncertainty. The MEC estimator is then formed from\nconvex mixture of such entropy-maximizing sample covariance $S_{\\mbox{mec}}$\nestimate and pooled sample covariance $\\mathbf{S}_{\\mathit{p}}$ estimate across\nthe $\\mathit{H}$ slices without requiring time-consuming covariance\noptimization procedures. MEC deals directly with singularity and instability of\nsample group covariance estimate in both regression and classification\nproblems. The efficiency of the MEC estimator is studied with the existing\nsufficient dimension reduction methods such as \\textit{Sliced Inverse\nRegression} (SIR) and \\textit{Sliced Average Variance Estimator} (SAVE) as\ndemonstrated on both classification and regression problems using real life\nLeukemia cancer data and customers' electricity load profiles from smart meter\ndata sets respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 03:34:42 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Olorede", "Kabir Opeyemi", ""], ["Yahya", "Waheed Babatunde", ""]]}, {"id": "1909.13755", "submitter": "Jayson Lynch", "authors": "Divya Gopinath, Rohan Kodialam, Kevin Lu, Jayson Lynch, Santiago\n  Ospina", "title": "Hamiltonicity in Semi-Regular Tessellation Dual Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows NP-completeness for finding Hamiltonian cycles in induced\nsubgraphs of the dual graphs of semi-regular tessilations. It also shows\nNP-hardness for a new, wide class of graphs called augmented square grids. This\nwork follows up on prior studies of the complexity of finding Hamiltonian\ncycles in regular and semi-regular grid graphs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:43:42 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gopinath", "Divya", ""], ["Kodialam", "Rohan", ""], ["Lu", "Kevin", ""], ["Lynch", "Jayson", ""], ["Ospina", "Santiago", ""]]}, {"id": "1909.13781", "submitter": "Markus Lohrey", "authors": "Laurent Bartholdi, Michael Figelius, Markus Lohrey and Armin Wei{\\ss}", "title": "Groups with ALOGTIME-hard word problems and PSPACE-complete compressed\n  word problems", "comments": "A short version of the paper will appear in the Proceedings of the\n  Computational Complexity Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give lower bounds on the complexity of the word problem of certain\nnon-solvable groups: for a large class of non-solvable infinite groups,\nincluding in particular free groups, Grigorchuk's group and Thompson's groups,\nwe prove that their word problem is $\\mathsf{NC}^1$-hard. For some of these\ngroups (including Grigorchuk's group and Thompson's groups) we prove that the\ncompressed word problem (which is equivalent to the circuit evaluation problem)\nis $\\mathsf{PSPACE}$-complete.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 15:25:09 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 13:41:47 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 21:06:36 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 11:58:47 GMT"}, {"version": "v5", "created": "Sat, 20 Jun 2020 06:08:47 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bartholdi", "Laurent", ""], ["Figelius", "Michael", ""], ["Lohrey", "Markus", ""], ["Wei\u00df", "Armin", ""]]}, {"id": "1909.13848", "submitter": "Ignasi Sau", "authors": "Raul Lopes, Ignasi Sau", "title": "A relaxation of the Directed Disjoint Paths problem: a global congestion\n  metric helps", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Directed Disjoint Paths problem, we are given a digraph $D$ and a set\nof requests $\\{(s_1, t_1), \\ldots, (s_k, t_k)\\}$, and the task is to find a\ncollection of pairwise vertex-disjoint paths $\\{P_1, \\ldots, P_k\\}$ such that\neach $P_i$ is a path from $s_i$ to $t_i$ in $D$. This problem is NP-complete\nfor fixed $k=2$ and W[1]-hard with parameter $k$ in DAGs. A few positive\nresults are known under restrictions on the input digraph, such as being planar\nor having bounded directed tree-width, or under relaxations of the problem,\nsuch as allowing for vertex congestion. Good news are scarce, however, for\ngeneral digraphs. In this article we propose a novel global congestion metric\nfor the problem: we only require the paths to be \"disjoint enough\", in the\nsense that they must behave properly not in the whole graph, but in an\nunspecified large part of it. Namely, in the Disjoint Enough Directed Paths\nproblem, given an $n$-vertex digraph $D$, a set of $k$ requests, and\nnon-negative integers $d$ and $s$, the task is to find a collection of paths\nconnecting the requests such that at least $d$ vertices of $D$ occur in at most\n$s$ paths of the collection. We study the parameterized complexity of this\nproblem for a number of choices of the parameter, including the directed\ntree-width of $D$. Among other results, we show that the problem is W[1]-hard\nin DAGs with parameter $d$ and, on the positive side, we give an algorithm in\ntime $O(n^d \\cdot k^{d\\cdot s})$ and a kernel of size $d \\cdot 2^{k-s}\\cdot\n\\binom{k}{s} + 2k$ in general digraphs. The latter result, which is our main\ncontribution, has consequences for the Steiner Network problem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:12:37 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lopes", "Raul", ""], ["Sau", "Ignasi", ""]]}]