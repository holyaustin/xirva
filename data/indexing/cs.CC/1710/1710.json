[{"id": "1710.00234", "submitter": "Hubie Chen", "authors": "Hubie Chen", "title": "Homomorphisms are indeed a good basis for counting: Three fixed-template\n  dichotomy theorems, for the price of one", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many natural combinatorial quantities can be expressed by counting the number\nof homomorphisms to a fixed relational structure. For example, the number of\n3-colorings of an undirected graph $G$ is equal to the number of homomorphisms\nfrom $G$ to the $3$-clique. In this setup, the structure receiving the\nhomomorphisms is often referred to as a template; we use the term template\nfunction to refer to a function, from structures to natural numbers, that is\ndefinable as the number of homomorphisms to a fixed template. There is a\nliterature that studies the complexity of template functions.\n  The present work is concerned with relating template functions to the\nproblems of counting, with respect to various fixed templates, the number of\ntwo particular types of homomorphisms: surjective homomorphisms and what we\nterm condensations.\n  In this article, we explain how any problem of counting surjective\nhomomorphisms to a fixed template is polynomial-time equivalent to computing a\nlinear combination of template functions; we also show this for any problem of\ncounting condensations to a fixed template. Via a theorem that characterizes\nthe complexity of computing such a linear combination, we show how a known\ndichotomy for template functions can be used to infer a dichotomy for counting\nsurjective homomorphisms on fixed templates, and likewise a dichotomy for\ncounting condensations on fixed templates. Our study is strongly inspired by,\nbased on, and can be viewed as a dual of the graph motif framework of\nCurticapean, Dell, and Marx (STOC 2017); that framework is in turn based on\nwork of Lov\\'asz (2012).\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 17:42:56 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Chen", "Hubie", ""]]}, {"id": "1710.00264", "submitter": "Samuel Hopkins", "authors": "Samuel B. Hopkins and David Steurer", "title": "Bayesian estimation from few samples: community detection and related\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient meta-algorithm for Bayesian estimation problems that\nis based on low-degree polynomials, semidefinite programming, and tensor\ndecomposition. The algorithm is inspired by recent lower bound constructions\nfor sum-of-squares and related to the method of moments. Our focus is on sample\ncomplexity bounds that are as tight as possible (up to additive lower-order\nterms) and often achieve statistical thresholds or conjectured computational\nthresholds.\n  Our algorithm recovers the best known bounds for community detection in the\nsparse stochastic block model, a widely-studied class of estimation problems\nfor community detection in graphs. We obtain the first recovery guarantees for\nthe mixed-membership stochastic block model (Airoldi et el.) in constant\naverage degree graphs---up to what we conjecture to be the computational\nthreshold for this model. We show that our algorithm exhibits a sharp\ncomputational threshold for the stochastic block model with multiple\ncommunities beyond the Kesten--Stigum bound---giving evidence that this task\nmay require exponential time.\n  The basic strategy of our algorithm is strikingly simple: we compute the\nbest-possible low-degree approximation for the moments of the posterior\ndistribution of the parameters and use a robust tensor decomposition algorithm\nto recover the parameters from these approximate posterior moments.\n", "versions": [{"version": "v1", "created": "Sat, 30 Sep 2017 21:58:34 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Hopkins", "Samuel B.", ""], ["Steurer", "David", ""]]}, {"id": "1710.00321", "submitter": "Dmitry Gribanov", "authors": "D. V. Gribanov", "title": "FPT-algorithms for The Shortest Lattice Vector and Integer Linear\n  Programming Problems", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present FPT-algorithms for special cases of the shortest\nvector problem (SVP) and the integer linear programming problem (ILP), when\nmatrices included to the problems' formulations are near square. The main\nparameter is the maximal absolute value of rank minors of matrices included to\nthe problem formulation. Additionally, we present FPT-algorithms with respect\nto the same main parameter for the problems, when the matrices have no singular\nrank sub-matrices.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 09:23:02 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Gribanov", "D. V.", ""]]}, {"id": "1710.00328", "submitter": "Dmitry Gribanov", "authors": "D. V. Gribanov and A. Y. Chirkov", "title": "The Width and Integer Optimization on Simplices With Bounded Minors of\n  the Constraint Matrices", "comments": "12 pages", "journal-ref": "Optim Lett (2016) 10: 1179", "doi": "10.1007/s11590-016-1048-y", "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will show that the width of simplices defined by systems of\nlinear inequalities can be computed in polynomial time if some minors of their\nconstraint matrices are bounded. Additionally, we present some\nquasi-polynomial-time and polynomial-time algorithms to solve the integer\nlinear optimization problem defined on simplices minus all their integer\nvertices assuming that some minors of the constraint matrices of the simplices\nare bounded.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 10:25:51 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Gribanov", "D. V.", ""], ["Chirkov", "A. Y.", ""]]}, {"id": "1710.00528", "submitter": "Tim Seynnaeve", "authors": "Tim Seynnaeve", "title": "Plethysm and fast matrix multiplication", "comments": "5 pages", "journal-ref": "Comptes Rendus Mathematique 356 (2018) 52-55", "doi": "10.1016/j.crma.2017.11.012", "report-no": null, "categories": "math.RT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the symmetric version of matrix multiplication we study the\nplethysm $S^k(\\mathfrak{sl}_n)$ of the adjoint representation $\\mathfrak{sl}_n$\nof the Lie group $SL_n$. In particular, we describe the decomposition of this\nrepresentation into irreducible components for $k=3$, and find highest weight\nvectors for all irreducible components. Relations to fast matrix\nmultiplication, in particular the Coppersmith-Winograd tensor are presented.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 08:27:06 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 16:48:11 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 14:37:37 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Seynnaeve", "Tim", ""]]}, {"id": "1710.00668", "submitter": "Tom\\'a\\v{s} Masa\\v{r}\\'ik", "authors": "Pavel Dvo\\v{r}\\'ak, Andreas Emil Feldmann, Du\\v{s}an Knop, Tom\\'a\\v{s}\n  Masa\\v{r}\\'ik, Tom\\'a\\v{s} Toufar, Pavel Vesel\\'y", "title": "Parameterized Approximation Schemes for Steiner Trees with Small Number\n  of Steiner Vertices", "comments": "23 pages, 6 figures An extended abstract appeared in proceedings of\n  STACS 2018", "journal-ref": "SIAM Journal on Discrete Mathematics 35(1), 546-574 (2021)", "doi": "10.1137/18M1209489", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Steiner Tree problem, in which a set of terminal vertices needs\nto be connected in the cheapest possible way in an edge-weighted graph. This\nproblem has been extensively studied from the viewpoint of approximation and\nalso parametrization. In particular, on one hand Steiner Tree is known to be\nAPX-hard, and W[2]-hard on the other, if parameterized by the number of\nnon-terminals (Steiner vertices) in the optimum solution. In contrast to this\nwe give an efficient parameterized approximation scheme (EPAS), which\ncircumvents both hardness results. Moreover, our methods imply the existence of\na polynomial size approximate kernelization scheme (PSAKS) for the considered\nparameter.\n  We further study the parameterized approximability of other variants of\nSteiner Tree, such as Directed Steiner Tree and Steiner Forest. For neither of\nthese an EPAS is likely to exist for the studied parameter: for Steiner Forest\nan easy observation shows that the problem is APX-hard, even if the input graph\ncontains no Steiner vertices. For Directed Steiner Tree we prove that\napproximating within any function of the studied parameter is W[1]-hard.\nNevertheless, we show that an EPAS exists for Unweighted Directed Steiner Tree,\nbut a PSAKS does not. We also prove that there is an EPAS and a PSAKS for\nSteiner Forest if in addition to the number of Steiner vertices, the number of\nconnected components of an optimal solution is considered to be a parameter.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 14:10:38 GMT"}, {"version": "v2", "created": "Sun, 29 Oct 2017 20:17:30 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 07:10:32 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 06:53:15 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Dvo\u0159\u00e1k", "Pavel", ""], ["Feldmann", "Andreas Emil", ""], ["Knop", "Du\u0161an", ""], ["Masa\u0159\u00edk", "Tom\u00e1\u0161", ""], ["Toufar", "Tom\u00e1\u0161", ""], ["Vesel\u00fd", "Pavel", ""]]}, {"id": "1710.01458", "submitter": "Zhixian Lei", "authors": "Zhixian Lei, Yueqi Sheng", "title": "Sum of Square Proof for Brascamp-Lieb Type Inequality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brascamp-Lieb inequality is an important mathematical tool in analysis,\ngeometry and information theory. There are various ways to prove Brascamp-Lieb\ninequality such as heat flow method, Brownian motion and subadditivity of the\nentropy. While Brascamp-Lieb inequality is originally stated in Euclidean\nSpace, discussed Brascamp-Lieb inequality for discrete Abelian group and\ndiscussed Brascamp-Lieb inequality for Markov semigroups.\n  Many mathematical inequalities can be formulated as algebraic inequalities\nwhich asserts some given polynomial is nonnegative. In 1927, Artin proved that\nany non- negative polynomial can be represented as a sum of squares of rational\nfunctions, which can be further formulated as a polynomial certificate of the\nnonnegativity of the polynomial. This is a Sum of Square proof of the\ninequality. Take the degree of the polynomial certificate as the degree of Sum\nof Square proof. The degree of an Sum of Square proof determines the complexity\nof generating such proof by Sum of Square algorithm which is a powerful tool\nfor optimization and computer aided proof.\n  In this paper, we give a Sum of Square proof for some special settings of\nBrascamp- Lieb inequality following and and discuss some applications of\nBrascamp-Lieb inequality on Abelian group and Euclidean Sphere. If the original\ndescription of the inequality has constant degree and d is constant, the degree\nof the proof is also constant. Therefore, low degree sum of square algorithm\ncan fully capture the power of low degree finite Brascamp-Lieb inequality.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 04:46:05 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 22:28:34 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Lei", "Zhixian", ""], ["Sheng", "Yueqi", ""]]}, {"id": "1710.01576", "submitter": "Hendrik Molter", "authors": "Clemens Hoffmann, Hendrik Molter, Manuel Sorge", "title": "The Parameterized Complexity of Centrality Improvement in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The centrality of a vertex v in a network intuitively captures how important\nv is for communication in the network. The task of improving the centrality of\na vertex has many applications, as a higher centrality often implies a larger\nimpact on the network or less transportation or administration cost. In this\nwork we study the parameterized complexity of the NP-complete problems\nCloseness Improvement and Betweenness Improvement in which we ask to improve a\ngiven vertex' closeness or betweenness centrality by a given amount through\nadding a given number of edges to the network. Herein, the closeness of a\nvertex v sums the multiplicative inverses of distances of other vertices to v\nand the betweenness sums for each pair of vertices the fraction of shortest\npaths going through v. Unfortunately, for the natural parameter \"number of\nedges to add\" we obtain hardness results, even in rather restricted cases. On\nthe positive side, we also give an island of tractability for the parameter\nmeasuring the vertex deletion distance to cluster graphs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 12:46:27 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Hoffmann", "Clemens", ""], ["Molter", "Hendrik", ""], ["Sorge", "Manuel", ""]]}, {"id": "1710.01578", "submitter": "Steffen Schuldenzucker", "authors": "Steffen Schuldenzucker, Sven Seuken, Stefano Battiston", "title": "The Computational Complexity of Financial Networks with Credit Default\n  Swaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.CC cs.GT q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2008 financial crisis has been attributed to \"excessive complexity\" of\nthe financial system due to financial innovation. We employ computational\ncomplexity theory to make this notion precise. Specifically, we consider the\nproblem of clearing a financial network after a shock. Prior work has shown\nthat when banks can only enter into simple debt contracts with each other, then\nthis problem can be solved in polynomial time. In contrast, if they can also\nenter into credit default swaps (CDSs), i.e., financial derivative contracts\nthat depend on the default of another bank, a solution may not even exist.\n  In this work, we show that deciding if a solution exists is NP-complete if\nCDSs are allowed. This remains true if we relax the problem to\n$\\varepsilon$-approximate solutions, for a constant $\\varepsilon$. We further\nshow that, under sufficient conditions where a solution is guaranteed to exist,\nthe approximate search problem is PPAD-complete for constant $\\varepsilon$. We\nthen try to isolate the \"origin\" of the complexity. It turns out that already\ndetermining which banks default is hard. Further, we show that the complexity\nis not driven by the dependence of counterparties on each other, but rather\nhinges on the presence of so-called naked CDSs. If naked CDSs are not present,\nwe receive a simple polynomial-time algorithm. Our results are of practical\nimportance for regulators' stress tests and regulatory policy.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 12:47:49 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 12:54:48 GMT"}, {"version": "v3", "created": "Mon, 20 May 2019 12:45:20 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Schuldenzucker", "Steffen", ""], ["Seuken", "Sven", ""], ["Battiston", "Stefano", ""]]}, {"id": "1710.01712", "submitter": "Holger Dell", "authors": "Holger Dell", "title": "Note on \"The Complexity of Counting Surjective Homomorphisms and\n  Compactions\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Focke, Goldberg, and \\v{Z}ivn\\'y (arXiv 2017) prove a complexity dichotomy\nfor the problem of counting surjective homomorphisms from a large input graph G\nwithout loops to a fixed graph H that may have loops. In this note, we give a\nshort proof of a weaker result: Namely, we only prove the #P-hardness of the\nmore general problem in which G may have loops. Our proof is an application of\na powerful framework of Lov\\'asz (2012), and it is analogous to proofs of\nCurticapean, Dell, and Marx (STOC 2017) who studied the \"dual\" problem in which\nthe pattern graph G is small and the host graph H is the input. Independently,\nChen (arXiv 2017) used Lov\\'asz's framework to prove a complexity dichotomy for\ncounting surjective homomorphisms to fixed finite structures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 17:30:07 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Dell", "Holger", ""]]}, {"id": "1710.01783", "submitter": "Greg Cohen Ph.D. in Mathematics", "authors": "Anna Knezevic, Greg Cohen, Marina Domanskaya", "title": "Some facts on Permanents in Finite Characteristics", "comments": "89 pages; this research was partly supported by the School of\n  Electrical Engineering, Computing and Mathematical Sciences of the Curtin\n  University (Australia) whose member is one of the authors (Anna Knezevic)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polynomial-time computability of the permanent over fields of\ncharacteristic 3 for k-semi-unitary matrices (i.e. square matrices such that\nthe differences of their Gram matrices and the corresponding identity matrices\nare of rank k) in the case k = 0 or k = 1 and its #3P-completeness for any k >\n1 (Ref. 9) is a result that essentially widens our understanding of the\ncomputational complexity boundaries for the permanent modulo 3. Now we extend\nthis result to study more closely the case k > 1 regarding the\n(n-k)x(n-k)-sub-permanents (or permanent-minors) of a unitary nxn-matrix and\ntheir possible relations, because an (n-k)x(n-k)-submatrix of a unitary\nnxn-matrix is generically a k-semi-unitary (n-k)x(n-k)-matrix. The following\npaper offers a way to receive a variety of such equations of different sorts,\nin the meantime extending this direction of research to reviewing all the set\nof polynomial-time permanent-preserving reductions and equations for the\nsub-permanents of a generic matrix they might yield, including a number of\ngeneralizations and formulae (valid in an arbitrary prime characteristic)\nanalogical to the classical identities relating the minors of a matrix and its\ninverse. Moreover, the second chapter also deals with the Hamiltonian cycle\npolynomial in characteristic 2 that surprisingly possesses quite a number of\nproperties very similar to the corresponding ones of the permanent in\ncharacteristic 3, while over the field GF(2) it obtains even more amazing\nfeatures. Besides, the third chapter is devoted to the computational complexity\nissues of the permanent and some related functions on a variety of Cauchy\nmatrices and their certain generalizations, including constructing a\npolynomial-time algorithm (based on them) for the permanent of an arbitrary\nmatrix in characteristic 5 (implying RP = NP) and conjecturing the existence of\na similar scheme in characteristic 3.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 19:57:47 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 03:31:02 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 00:37:48 GMT"}, {"version": "v4", "created": "Mon, 19 Aug 2019 14:05:07 GMT"}, {"version": "v5", "created": "Thu, 22 Aug 2019 15:44:05 GMT"}, {"version": "v6", "created": "Thu, 29 Aug 2019 20:50:03 GMT"}, {"version": "v7", "created": "Tue, 19 Nov 2019 10:46:27 GMT"}, {"version": "v8", "created": "Tue, 3 Dec 2019 15:14:03 GMT"}, {"version": "v9", "created": "Tue, 3 Nov 2020 14:57:22 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Knezevic", "Anna", ""], ["Cohen", "Greg", ""], ["Domanskaya", "Marina", ""]]}, {"id": "1710.01934", "submitter": "Anselm Haak", "authors": "Arnaud Durand, Anselm Haak, Heribert Vollmer", "title": "Model-Theoretic Characterizations of Boolean and Arithmetic Circuit\n  Classes of Small Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give a characterization of both Boolean and arithmetic\ncircuit classes of logarithmic depth in the vein of descriptive complexity\ntheory, i.e., the Boolean classes $\\textrm{NC}^1$, $\\textrm{SAC}^1$ and\n$\\textrm{AC}^1$ as well as their arithmetic counterparts $\\#\\textrm{NC}^1$,\n$\\#\\textrm{SAC}^1$ and $\\#\\textrm{AC}^1$. We build on Immerman's\ncharacterization of constant-depth polynomial-size circuits by formulas of\nfirst-order logic, i.e., $\\textrm{AC}^0 = \\textrm{FO}$, and augment the logical\nlanguage with an operator for defining relations in an inductive way.\nConsidering slight variations of the new operator, we obtain uniform\ncharacterizations of the three just mentioned Boolean classes. The arithmetic\nclasses can then be characterized by functions counting winning strategies in\nsemantic games for formulas characterizing languages in the corresponding\nBoolean class.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 09:23:29 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 06:01:41 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Durand", "Arnaud", ""], ["Haak", "Anselm", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1710.01969", "submitter": "Yassine Hamoudi", "authors": "Yassine Hamoudi", "title": "Simultaneous Multiparty Communication Complexity of Composed Functions", "comments": "17 pages, 1 figure; v2: improved introduction, better cost analysis\n  for the 2nd protocol", "journal-ref": "43rd International Symposium on Mathematical Foundations of\n  Computer Science (MFCS 2018), LIPIcs vol.117, pp. 14:1--14:15, 2018", "doi": "10.4230/LIPIcs.MFCS.2018.14", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Number On the Forehead (NOF) multiparty communication model, $k$\nplayers want to evaluate a function $F : X_1 \\times\\cdots\\times X_k\\rightarrow\nY$ on some input $(x_1,\\dots,x_k)$ by broadcasting bits according to a\npredetermined protocol. The input is distributed in such a way that each player\n$i$ sees all of it except $x_i$. In the simultaneous setting, the players\ncannot speak to each other but instead send information to a referee. The\nreferee does not know the players' input, and cannot give any information back.\nAt the end, the referee must be able to recover $F(x_1,\\dots,x_k)$ from what\nshe obtained.\n  A central open question, called the $\\log n$ barrier, is to find a function\nwhich is hard to compute for $polylog(n)$ or more players (where the $x_i$'s\nhave size $poly(n)$) in the simultaneous NOF model. This has important\napplications in circuit complexity, as it could help to separate $ACC^0$ from\nother complexity classes. One of the candidates belongs to the family of\ncomposed functions. The input to these functions is represented by a $k\\times\n(t\\cdot n)$ boolean matrix $M$, whose row $i$ is the input $x_i$ and $t$ is a\nblock-width parameter. A symmetric composed function acting on $M$ is specified\nby two symmetric $n$- and $kt$-variate functions $f$ and $g$, that output\n$f\\circ g(M)=f(g(B_1),\\dots,g(B_n))$ where $B_j$ is the $j$-th block of width\n$t$ of $M$. As the majority function $MAJ$ is conjectured to be outside of\n$ACC^0$, Babai et. al. suggested to study $MAJ\\circ MAJ_t$, with $t$ large\nenough.\n  So far, it was only known that $t=1$ is not enough for $MAJ\\circ MAJ_t$ to\nbreak the $\\log n$ barrier in the simultaneous deterministic NOF model. In this\npaper, we extend this result to any constant block-width $t>1$, by giving a\nprotocol of cost $2^{O(2^t)}\\log^{2^{t+1}}(n)$ for any symmetric composed\nfunction when there are $2^{\\Omega(2^t)}\\log n$ players.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 11:23:44 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 21:56:20 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Hamoudi", "Yassine", ""]]}, {"id": "1710.02898", "submitter": "Sumegha Garg", "authors": "Sumegha Garg and Jon Schneider", "title": "The space complexity of mirror games", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a simple streaming game between two players Alice and Bob, which\nwe call the mirror game. In this game, Alice and Bob take turns saying numbers\nbelonging to the set $\\{1, 2, \\dots,2N\\}$. A player loses if they repeat a\nnumber that has already been said. Bob, who goes second, has a very simple (and\nmemoryless) strategy to avoid losing: whenever Alice says $x$, respond with\n$2N+1-x$. The question is: does Alice have a similarly simple strategy to win\nthat avoids remembering all the numbers said by Bob?\n  The answer is no. We prove a linear lower bound on the space complexity of\nany deterministic winning strategy of Alice. Interestingly, this follows as a\nconsequence of the Eventown-Oddtown theorem from extremal combinatorics. We\nadditionally demonstrate a randomized strategy for Alice that wins with high\nprobability that requires only $\\tilde{O}(\\sqrt N)$ space (provided that Alice\nhas access to a random matching on $K_{2N}$).\n  We also investigate lower bounds for a generalized mirror game where Alice\nand Bob alternate saying $1$ number and $b$ numbers each turn (respectively).\nWhen $1+b$ is a prime, our linear lower bounds continue to hold, but when $1+b$\nis composite, we show that the existence of a $o(N)$ space strategy for Bob\nimplies the existence of exponential-sized matching vector families over\n$\\mathbb{Z}^N_{1+b}$.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 23:18:43 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Garg", "Sumegha", ""], ["Schneider", "Jon", ""]]}, {"id": "1710.03062", "submitter": "Anand Natarajan", "authors": "Anand Natarajan and Thomas Vidick", "title": "Two-player entangled games are NP-hard", "comments": "The paper has been withdrawn due to an error in the proof of the main\n  theorem, inherited from arXiv:1302.1242. For more details see\n  http://users.cms.caltech.edu/~vidick/errata.pdf and arXiv:2009.12982", "journal-ref": "Proc. CCC 2018, pp. 20:1-20:18", "doi": "10.4230/LIPIcs.CCC.2018.20", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the maximum success probability of players sharing quantum\nentanglement in a two-player game with classical questions of logarithmic\nlength and classical answers of constant length is NP-hard to approximate to\nwithin constant factors. As a corollary, the inclusion\n$\\mathrm{NEXP}\\subseteq\\mathrm{MIP}^*$, first shown in [IV12] with three\nprovers, holds with two provers only. The proof is based on a simpler, improved\nanalysis of the low-degree test Raz and Safra (STOC'97) against two entangled\nprovers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 12:51:46 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 05:13:05 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Natarajan", "Anand", ""], ["Vidick", "Thomas", ""]]}, {"id": "1710.03090", "submitter": "Noson S. Yanofsky", "authors": "Noson S. Yanofsky", "title": "Theoretical Computer Science for the Working Category Theorist", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical computer science discusses foundational issues about\ncomputations. It asks and answers questions such as \"What is a computation?\",\n\"What is computable?\", \"What is efficiently computable?\",\"What is\ninformation?\", \"What is random?\", \"What is an algorithm?\", etc. We will present\nmany of the major themes and theorems with the basic language of category\ntheory. Surprisingly, many interesting theorems and concepts of theoretical\ncomputer science are easy consequences of functoriality and composition when\nyou look at the right categories and functors connecting them.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 19:19:00 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Yanofsky", "Noson S.", ""]]}, {"id": "1710.03148", "submitter": "Stanislav Zivny", "authors": "Clement Carbonnel, Miguel Romero, Stanislav Zivny", "title": "The complexity of general-valued CSPs seen from the other side", "comments": "v2: Full version of a FOCS'18 paper; improved presentation and small\n  corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constraint satisfaction problem (CSP) is concerned with homomorphisms\nbetween two structures. For CSPs with restricted left-hand side structures, the\nresults of Dalmau, Kolaitis, and Vardi [CP'02], Grohe [FOCS'03/JACM'07], and\nAtserias, Bulatov, and Dalmau [ICALP'07] establish the precise borderline of\npolynomial-time solvability (subject to complexity-theoretic assumptions) and\nof solvability by bounded-consistency algorithms (unconditionally) as bounded\ntreewidth modulo homomorphic equivalence.\n  The general-valued constraint satisfaction problem (VCSP) is a generalisation\nof the CSP concerned with homomorphisms between two valued structures. For\nVCSPs with restricted left-hand side valued structures, we establish the\nprecise borderline of polynomial-time solvability (subject to\ncomplexity-theoretic assumptions) and of solvability by the $k$-th level of the\nSherali-Adams LP hierarchy (unconditionally). We also obtain results on related\nproblems concerned with finding a solution and recognising the tractable cases;\nthe latter has an application in database theory.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 15:32:14 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 16:31:28 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Carbonnel", "Clement", ""], ["Romero", "Miguel", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1710.03214", "submitter": "Pranjal Dutta", "authors": "Pranjal Dutta, Nitin Saxena, Amit Sinhababu", "title": "Discovering the roots: Uniform closure results for algebraic classes\n  under factoring", "comments": "33 Pages, No figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newton iteration (NI) is an almost 350 years old recursive formula that\napproximates a simple root of a polynomial quite rapidly. We generalize it to a\nmatrix recurrence (allRootsNI) that approximates all the roots simultaneously.\nIn this form, the process yields a better circuit complexity in the case when\nthe number of roots $r$ is small but the multiplicities are exponentially\nlarge. Our method sets up a linear system in $r$ unknowns and iteratively\nbuilds the roots as formal power series. For an algebraic circuit\n$f(x_1,\\ldots,x_n)$ of size $s$ we prove that each factor has size at most a\npolynomial in: $s$ and the degree of the squarefree part of $f$. Consequently,\nif $f_1$ is a $2^{\\Omega(n)}$-hard polynomial then any nonzero multiple\n$\\prod_{i} f_i^{e_i}$ is equally hard for arbitrary positive $e_i$'s, assuming\nthat $\\sum_i \\text{deg}(f_i)$ is at most $2^{O(n)}$.\n  It is an old open question whether the class of poly($n$)-sized formulas\n(resp. algebraic branching programs) is closed under factoring. We show that\ngiven a polynomial $f$ of degree $n^{O(1)}$ and formula (resp. ABP) size\n$n^{O(\\log n)}$ we can find a similar size formula (resp. ABP) factor in\nrandomized poly($n^{\\log n}$)-time. Consequently, if determinant requires\n$n^{\\Omega(\\log n)}$ size formula, then the same can be said about any of its\nnonzero multiples.\n  As part of our proofs, we identify a new property of multivariate polynomial\nfactorization. We show that under a random linear transformation $\\tau$,\n$f(\\tau\\overline{x})$ completely factors via power series roots. Moreover, the\nfactorization adapts well to circuit complexity analysis. This with allRootsNI\nare the techniques that help us make progress towards the old open problems,\nsupplementing the large body of classical results and concepts in algebraic\ncircuit factorization (eg. Zassenhaus, J.NT 1969, Kaltofen, STOC 1985-7 \\&\nBurgisser, FOCS 2001).\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 17:48:20 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Dutta", "Pranjal", ""], ["Saxena", "Nitin", ""], ["Sinhababu", "Amit", ""]]}, {"id": "1710.03219", "submitter": "Noah Fleming", "authors": "Paul Beame, Noah Fleming, Russell Impagliazzo, Antonina Kolokolova,\n  Denis Pankratov, Toniann Pitassi, Robert Robere", "title": "Stabbing Planes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and develop a new semi-algebraic proof system, called Stabbing\nPlanes that is in the style of DPLL-based modern SAT solvers. As with DPLL,\nthere is only one rule: the current polytope can be subdivided by branching on\nan inequality and its \"integer negation.\" That is, we can (nondeterministically\nchoose) a hyperplane a x \\geq b with integer coefficients, which partitions the\npolytope into three pieces: the points in the polytope satisfying a x \\geq b,\nthe points satisfying a x \\leq b-1, and the middle slab b-1 < a x < b. Since\nthe middle slab contains no integer points it can be safely discarded, and the\nalgorithm proceeds recursively on the other two branches. Each path terminates\nwhen the current polytope is empty, which is polynomial-time checkable. Among\nour results, we show somewhat surprisingly that Stabbing Planes can efficiently\nsimulate Cutting Planes, and moreover, is strictly stronger than Cutting Planes\nunder a reasonable conjecture. We prove linear lower bounds on the rank of\nStabbing Planes refutations, by adapting a lifting argument in communication\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 17:56:24 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Beame", "Paul", ""], ["Fleming", "Noah", ""], ["Impagliazzo", "Russell", ""], ["Kolokolova", "Antonina", ""], ["Pankratov", "Denis", ""], ["Pitassi", "Toniann", ""], ["Robere", "Robert", ""]]}, {"id": "1710.03312", "submitter": "Alexander Woo", "authors": "Alexander Woo and Alexander Yong", "title": "Tropicalization, symmetric polynomials, and complexity", "comments": "8 pages", "journal-ref": "J. Symbolic Comput. 99 (2020), 242--249", "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  D. Grigoriev-G. Koshevoy recently proved that tropical Schur polynomials have\n(at worst) polynomial tropical semiring complexity. They also conjectured\ntropical skew Schur polynomials have at least exponential complexity; we\nestablish a polynomial complexity upper bound. Our proof uses results about\n(stable) Schubert polynomials, due to R. P. Stanley and S. Billey-W.\nJockusch-R. P. Stanley, together with a sufficient condition for polynomial\ncomplexity that is connected to the saturated Newton polytope property.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 20:57:28 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Woo", "Alexander", ""], ["Yong", "Alexander", ""]]}, {"id": "1710.03435", "submitter": "Martin Skrodzki", "authors": "Martin Skrodzki, Ulrich Reitebuch, Alex McDonough", "title": "Combinatorial and Asymptotical Results on the Neighborhood Grid", "comments": "33 pages, 18 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2009, Joselli et al introduced the Neighborhood Grid data structure for\nfast computation of neighborhood estimates in point clouds. Even though the\ndata structure has been used in several applications and shown to be\npractically relevant, it is theoretically not yet well understood. The purpose\nof this paper is to present a polynomial-time algorithm to build the data\nstructure. Furthermore, it is investigated whether the presented algorithm is\noptimal. This investigations leads to several combinatorial questions for which\npartial results are given. Finally, we present several limits and experiments\nregarding the quality of the obtained neighborhood relation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 07:58:14 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 19:35:09 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 18:22:04 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 03:10:30 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Skrodzki", "Martin", ""], ["Reitebuch", "Ulrich", ""], ["McDonough", "Alex", ""]]}, {"id": "1710.03702", "submitter": "Eike Neumann", "authors": "Michal Kone\\v{c}n\\'y and Eike Neumann", "title": "Representations and evaluation strategies for feasibly approximable\n  functions", "comments": "33 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A famous result due to Ko and Friedman (1982) asserts that the problems of\nintegration and maximisation of a univariate real function are computationally\nhard in a well-defined sense. Yet, both functionals are routinely computed at\ngreat speed in practice. We aim to resolve this apparent paradox by studying\nclasses of functions which can be feasibly integrated and maximised, together\nwith representations for these classes of functions which encode the\ninformation which is necessary to uniformly compute integral and maximum in\npolynomial time. The theoretical framework for this is the second-order\ncomplexity theory for operators in analysis which was introduced by Kawamura\nand Cook (2012). The representations we study are based on rigorous\napproximation by polynomials, piecewise polynomials, and rational functions. We\ncompare these representations with respect to polytime reducibility as well as\nwith respect to their ability to quickly evaluate symbolic expressions in a\ngiven language. We show that the representation based on rigorous approximation\nby piecewise polynomials is polytime equivalent to the representation based on\nrigorous approximation by rational functions. With this representation, all\nterms in a certain language, which is expressive enough to contain the maximum\nand integral of most functions of practical interest, can be evaluated in\npolynomial time. By contrast, both the representation based on polynomial\napproximation and the standard representation based on function evaluation,\nwhich implicitly underlies the Ko-Friedman result, require exponential time to\nevaluate certain terms in this language. We confirm our theoretical results by\nan implementation in Haskell, which provides some evidence that second-order\npolynomial time computability is similarly closely tied with practical\nfeasibility as its first-order counterpart.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 16:17:52 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 16:17:12 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 21:01:19 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Kone\u010dn\u00fd", "Michal", ""], ["Neumann", "Eike", ""]]}, {"id": "1710.04376", "submitter": "Tomoaki Ogasawara", "authors": "Yoichi Iwata, Tomoaki Ogasawara, Naoto Ohsaka", "title": "On the Power of Tree-Depth for Fully Polynomial FPT Algorithms", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many classical problems in P whose time complexities have not been\nimproved over the past decades. Recent studies of \"Hardness in P\" have revealed\nthat, for several of such problems, the current fastest algorithm is the best\npossible under some complexity assumptions. To bypass this difficulty, Fomin et\nal. (SODA 2017) introduced the concept of fully polynomial FPT algorithms. For\na problem with the current best time complexity $O(n^c)$, the goal is to design\nan algorithm running in $k^{O(1)}n^{c'}$ time for a parameter $k$ and a\nconstant $c'<c$. In this paper, we investigate the complexity of graph problems\nin P parameterized by tree-depth, a graph parameter related to tree-width. We\nshow that a simple divide-and-conquer method can solve many graph problems,\nincluding Weighted Matching, Negative Cycle Detection, Minimum Weight Cycle,\nReplacement Paths, and 2-hop Cover, in $O(\\mathrm{td}\\cdot m)$ time or\n$O(\\mathrm{td}\\cdot (m+n\\log n))$ time, where $\\mathrm{td}$ is the tree-depth\nof the input graph. Because any graph of tree-width $\\mathrm{tw}$ has\ntree-depth at most $(\\mathrm{tw}+1)\\log_2 n$, our algorithms also run in\n$O(\\mathrm{tw}\\cdot m\\log n)$ time or $O(\\mathrm{tw}\\cdot (m+n\\log n)\\log n)$\ntime. These results match or improve the previous best algorithms parameterized\nby tree-width. Especially, we solve an open problem of fully polynomial FPT\nalgorithm for Weighted Matching parameterized by tree-width posed by Fomin et\nal.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 05:46:58 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 16:42:58 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Iwata", "Yoichi", ""], ["Ogasawara", "Tomoaki", ""], ["Ohsaka", "Naoto", ""]]}, {"id": "1710.04533", "submitter": "Hans Simon", "authors": "Hans U. Simon", "title": "On the Containment Problem for Linear Sets", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the containment problem (as well as the equivalence\nproblem) for semilinear sets is $\\log$-complete in $\\Pi_2^p$. It had been shown\nquite recently that already the containment problem for multi-dimensional\nlinear sets is $\\log$-complete in $\\Pi_2^p$ (where hardness even holds for a\nunary encoding of the numerical input parameters). In this paper, we show that\nalready the containment problem for $1$-dimensional linear sets (with binary\nencoding of the numerical input parameters) is $\\log$-hard (and therefore also\n$\\log$-complete) in $\\Pi_2^p$. However, combining both restrictions (dimension\n$1$ and unary encoding), the problem becomes solvable in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 14:15:45 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 15:18:19 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Simon", "Hans U.", ""]]}, {"id": "1710.04640", "submitter": "Marcos Villagra", "authors": "Javier T. Akagi and Carlos F. Gaona and Fabricio Mendoza and Manjil P.\n  Saikia and Marcos Villagra", "title": "Hard and Easy Instances of L-Tromino Tilings", "comments": "Full extended version of LNCS 11355:82-95 (WALCOM 2019)", "journal-ref": "Theoretical Computer Science 2020", "doi": "10.1016/j.tcs.2020.02.025", "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study tilings of regions in the square lattice with L-shaped trominoes.\nDeciding the existence of a tiling with L-trominoes for an arbitrary region in\ngeneral is NP-complete, nonetheless, we identify restrictions to the problem\nwhere it either remains NP-complete or has a polynomial time algorithm. First,\nwe characterize the possibility of when an Aztec rectangle and an Aztec diamond\nhas an L-tromino tiling. Then, we study tilings of arbitrary regions where only\n$180^\\circ$ rotations of L-trominoes are available. For this particular case we\nshow that deciding the existence of a tiling remains NP-complete; yet, if a\nregion does not contains certain so-called \"forbidden polyominoes\" as\nsub-regions, then there exists a polynomial time algorithm for deciding a\ntiling.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 17:52:22 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 14:42:21 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 18:09:24 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 17:17:50 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Akagi", "Javier T.", ""], ["Gaona", "Carlos F.", ""], ["Mendoza", "Fabricio", ""], ["Saikia", "Manjil P.", ""], ["Villagra", "Marcos", ""]]}, {"id": "1710.04856", "submitter": "Ioannis Emiris", "authors": "Ioannis Emiris (Athens, AROMATH)", "title": "Compact Formulae in Sparse Elimination", "comments": null, "journal-ref": "ISSAC 2016 - International Symposium on Symbolic and Algebraic\n  Computation, Jul 2016, Waterloo, Canada. pp.1 - 8, 2016, ISSAC '16 -\n  Proceedings of the ACM on International Symposium on Symbolic and Algebraic\n  Computation", "doi": "10.1145/2930889.2930943", "report-no": null, "categories": "cs.CC cs.CG cs.DM cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has by now become a standard approach to use the theory of sparse (or\ntoric) elimination, based on the Newton polytope of a polynomial, in order to\nreveal and exploit the structure of algebraic systems. This talk surveys\ncompact formulae, including older and recent results, in sparse elimination. We\nstart with root bounds and juxtapose two recent formulae: a generating function\nof the m-B{\\'e}zout bound and a closed-form expression for the mixed volume by\nmeans of a matrix permanent. For the sparse resultant, a bevy of results have\nestablished determinantal or rational formulae for a large class of systems,\nstarting with Macaulay. The discriminant is closely related to the resultant\nbut admits no compact formula except for very simple cases. We offer a new\ndeterminantal formula for the discriminant of a sparse multilinear system\narising in computing Nash equilibria. We introduce an alternative notion of\ncompact formula, namely the Newton polytope of the unknown polynomial. It is\npossible to compute it efficiently for sparse resultants, discriminants, as\nwell as the implicit equation of a parameterized variety. This leads us to\nconsider implicit matrix representations of geometric objects.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 09:43:30 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Emiris", "Ioannis", "", "Athens, AROMATH"]]}, {"id": "1710.05017", "submitter": "Samuel Hopkins", "authors": "Samuel B. Hopkins and Pravesh K. Kothari and Aaron Potechin and Prasad\n  Raghavendra and Tselil Schramm and David Steurer", "title": "The power of sum-of-squares for detecting hidden structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study planted problems---finding hidden structures in random noisy\ninputs---through the lens of the sum-of-squares semidefinite programming\nhierarchy (SoS). This family of powerful semidefinite programs has recently\nyielded many new algorithms for planted problems, often achieving the best\nknown polynomial-time guarantees in terms of accuracy of recovered solutions\nand robustness to noise. One theme in recent work is the design of spectral\nalgorithms which match the guarantees of SoS algorithms for planted problems.\nClassical spectral algorithms are often unable to accomplish this: the twist in\nthese new spectral algorithms is the use of spectral structure of matrices\nwhose entries are low-degree polynomials of the input variables. We prove that\nfor a wide class of planted problems, including refuting random constraint\nsatisfaction problems, tensor and sparse PCA, densest-k-subgraph, community\ndetection in stochastic block models, planted clique, and others, eigenvalues\nof degree-d matrix polynomials are as powerful as SoS semidefinite programs of\nroughly degree d. For such problems it is therefore always possible to match\nthe guarantees of SoS without solving a large semidefinite program. Using\nrelated ideas on SoS algorithms and low-degree matrix polynomials (and inspired\nby recent work on SoS and the planted clique problem by Barak et al.), we prove\nnew nearly-tight SoS lower bounds for the tensor and sparse principal component\nanalysis problems. Our lower bounds for sparse principal component analysis are\nthe first to suggest that going beyond existing algorithms for this problem may\nrequire sub-exponential time.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 17:37:03 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Hopkins", "Samuel B.", ""], ["Kothari", "Pravesh K.", ""], ["Potechin", "Aaron", ""], ["Raghavendra", "Prasad", ""], ["Schramm", "Tselil", ""], ["Steurer", "David", ""]]}, {"id": "1710.05121", "submitter": "Jeffrey Bosboom", "authors": "Jeffrey Bosboom (MIT CSAIL) and Michael Hoffmann (ETH Zurich)", "title": "Netrunner Mate-in-1 or -2 is Weakly NP-Hard", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that deciding whether the Runner can win this turn (mate-in-1) in\nthe Netrunner card game generalized to allow decks to contain an arbitrary\nnumber of copies of a card is weakly NP-hard. We also prove that deciding\nwhether the Corp can win within two turns (mate-in-2) in this generalized\nNetrunner is weakly NP-hard.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 01:48:07 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Bosboom", "Jeffrey", "", "MIT CSAIL"], ["Hoffmann", "Michael", "", "ETH Zurich"]]}, {"id": "1710.05140", "submitter": "Mikhail Tikhomirov", "authors": "Mikhail Tikhomirov", "title": "On complexity of mutlidistance graph recognition in $\\mathbb{R}^1$", "comments": "38 pages, 9 figures. Extended abstract published in EUROCOMB'17\n  proceedings in Electronic Notes in Discrete Mathematics\n  (http://www.sciencedirect.com/science/article/pii/S1571065317302354)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathcal{A}$ be a set of positive numbers. A graph $G$ is called an\n$\\mathcal{A}$-embeddable graph in $\\mathbb{R}^d$ if the vertices of $G$ can be\npositioned in $\\mathbb{R}^d$ so that the distance between endpoints of any edge\nis an element of $\\mathcal{A}$. We consider the computational problem of\nrecognizing $\\mathcal{A}$-embeddable graphs in $\\mathbb{R}^1$ and classify all\nfinite sets $\\mathcal{A}$ by complexity of this problem in several natural\nvariations.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 06:17:49 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Tikhomirov", "Mikhail", ""]]}, {"id": "1710.05481", "submitter": "Suryajith Chillara", "authors": "Suryajith Chillara, Nutan Limaye, Srikanth Srinivasan", "title": "Small-depth Multilinear Formula Lower Bounds for Iterated Matrix\n  Multiplication, with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the algebraic formula complexity of multiplying $d$\nmany $2\\times 2$ matrices, denoted $\\mathrm{IMM}_{d}$, and show that the\nwell-known divide-and-conquer algorithm cannot be significantly improved at any\ndepth, as long as the formulas are multilinear.\n  Formally, for each depth $\\Delta \\leq \\log d$, we show that any product-depth\n$\\Delta$ multilinear formula for $\\mathrm{IMM}_d$ must have size\n$\\exp(\\Omega(\\Delta d^{1/\\Delta})).$ It also follows from this that any\nmultilinear circuit of product-depth $\\Delta$ for the same polynomial of the\nabove form must have a size of $\\exp(\\Omega(d^{1/\\Delta})).$ In particular, any\npolynomial-sized multilinear formula for $\\mathrm{IMM}_d$ must have depth\n$\\Omega(\\log d)$, and any polynomial-sized multilinear circuit for\n$\\mathrm{IMM}_d$ must have depth $\\Omega(\\log d/\\log \\log d).$ Both these\nbounds are tight up to constant factors.\n  1. Depth-reduction: A well-known result of Brent (JACM 1974) implies that any\nformula of size $s$ can be converted to one of size $s^{O(1)}$ and depth\n$O(\\log s)$; further, this reduction continues to hold for multilinear\nformulas. Our lower bound implies that any depth-reduction in the multilinear\nsetting cannot reduce the depth to $o(\\log s)$ without a superpolynomial\nblow-up in size.\n  2. Separations from general formulas: Our result, along with a non-trivial\nupper bound for $\\mathrm{IMM}_{d}$ implied by a result of Gupta, Kamath, Kayal\nand Saptharishi (SICOMP 2016), shows that for any size $s$ and product-depth\n$\\Delta = o(\\log s),$ general formulas of size $s$ and product-depth $\\Delta$\ncannot be converted to multilinear formulas of size $s^{\\omega(1)}$ and\nproduct-depth $\\Delta,$ when the underlying field has characteristic zero.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 03:01:52 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Chillara", "Suryajith", ""], ["Limaye", "Nutan", ""], ["Srinivasan", "Srikanth", ""]]}, {"id": "1710.05984", "submitter": "Andrei Romashchenko", "authors": "Andrei Romashchenko and Marius Zimand", "title": "An operational characterization of mutual information in algorithmic\n  information theory", "comments": "39 pages, 2 figures. A brief version of this work has been presented\n  at 45th International Colloquium on Automata, Languages, and Programming\n  (ICALP), Prague, July 10-13, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the mutual information, in the sense of Kolmogorov complexity,\nof any pair of strings $x$ and $y$ is equal, up to logarithmic precision, to\nthe length of the longest shared secret key that two parties, one having $x$\nand the complexity profile of the pair and the other one having $y$ and the\ncomplexity profile of the pair, can establish via a probabilistic protocol with\ninteraction on a public channel. For $\\ell > 2$, the longest shared secret that\ncan be established from a tuple of strings $(x_1, \\ldots , x_\\ell)$ by $\\ell$\nparties, each one having one component of the tuple and the complexity profile\nof the tuple, is equal, up to logarithmic precision, to the complexity of the\ntuple minus the minimum communication necessary for distributing the tuple to\nall parties. We establish the communication complexity of secret key agreement\nprotocols that produce a secret key of maximal length, for protocols with\npublic randomness. We also show that if the communication complexity drops\nbelow the established threshold, then only very short secret keys can be\nobtained.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 20:14:24 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 05:45:08 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 15:27:49 GMT"}, {"version": "v4", "created": "Fri, 31 Aug 2018 14:25:31 GMT"}, {"version": "v5", "created": "Mon, 29 Apr 2019 17:44:55 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Romashchenko", "Andrei", ""], ["Zimand", "Marius", ""]]}, {"id": "1710.06100", "submitter": "Mengdi Wang", "authors": "Mengdi Wang", "title": "Primal-Dual $\\pi$ Learning: Sample Complexity and Sublinear Run Time for\n  Ergodic Markov Decision Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of approximating the optimal policy of a Markov decision\nprocess (MDP) by sampling state transitions. In contrast to existing\nreinforcement learning methods that are based on successive approximations to\nthe nonlinear Bellman equation, we propose a Primal-Dual $\\pi$ Learning method\nin light of the linear duality between the value and policy. The $\\pi$ learning\nmethod is model-free and makes primal-dual updates to the policy and value\nvectors as new data are revealed. For infinite-horizon undiscounted Markov\ndecision process with finite state space $S$ and finite action space $A$, the\n$\\pi$ learning method finds an $\\epsilon$-optimal policy using the following\nnumber of sample transitions $$ \\tilde{O}( \\frac{(\\tau\\cdot t^*_{mix})^2 |S|\n|A| }{\\epsilon^2} ),$$ where $t^*_{mix}$ is an upper bound of mixing times\nacross all policies and $\\tau$ is a parameter characterizing the range of\nstationary distributions across policies. The $\\pi$ learning method also\napplies to the computational problem of MDP where the transition probabilities\nand rewards are explicitly given as the input. In the case where each state\ntransition can be sampled in $\\tilde{O}(1)$ time, the $\\pi$ learning method\ngives a sublinear-time algorithm for solving the averaged-reward MDP.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 05:03:19 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Wang", "Mengdi", ""]]}, {"id": "1710.06378", "submitter": "Jeffrey M. Dudek", "authors": "Jeffrey M. Dudek, Kuldeep S. Meel, Moshe Y. Vardi", "title": "The Hard Problems Are Almost Everywhere For Random CNF-XOR Formulas", "comments": "Presented at The 26th International Joint Conference on Artificial\n  Intelligence (IJCAI-17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent universal-hashing based approaches to sampling and counting crucially\ndepend on the runtime performance of SAT solvers on formulas expressed as the\nconjunction of both CNF constraints and variable-width XOR constraints (known\nas CNF-XOR formulas). In this paper, we present the first study of the runtime\nbehavior of SAT solvers equipped with XOR-reasoning techniques on random\nCNF-XOR formulas. We empirically demonstrate that a state-of-the-art SAT solver\nscales exponentially on random CNF-XOR formulas across a wide range of\nXOR-clause densities, peaking around the empirical phase-transition location.\nOn the theoretical front, we prove that the solution space of a random CNF-XOR\nformula 'shatters' at all nonzero XOR-clause densities into well-separated\ncomponents, similar to the behavior seen in random CNF formulas known to be\ndifficult for many SAT algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 16:43:46 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Dudek", "Jeffrey M.", ""], ["Meel", "Kuldeep S.", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1710.06846", "submitter": "Fouad Chedid", "authors": "Fouad B. Chedid", "title": "Kolmogorov Complexity and Information Content", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit a central concept in Kolmogorov complexity in which\none would equate program-size complexity with information content. Despite the\nfact that Kolmogorov complexity has been widely accepted as an objective\nmeasure of the information content of a string, it has been the subject of many\ncriticisms including the fundamental one directed by logicians and philosophers\ntowards the statistical and semantical theories of information, which is about\nconfusing an object and its name. In this paper, we clarify a number of subtle\nissues that are at the center of this debate.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 04:09:18 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Chedid", "Fouad B.", ""]]}, {"id": "1710.07132", "submitter": "Micha{\\l}  Karpi\\'nski", "authors": "Micha{\\l} Karpi\\'nski and Krzysztof Piecuch", "title": "On vertex coloring without monochromatic triangles", "comments": "Extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a certain relaxation of the classic vertex coloring problem, namely,\na coloring of vertices of undirected, simple graphs, such that there are no\nmonochromatic triangles. We give the first classification of the problem in\nterms of classic and parametrized algorithms. Several computational complexity\nresults are also presented, which improve on the previous results found in the\nliterature. We propose the new structural parameter for undirected, simple\ngraphs -- the triangle-free chromatic number $\\chi_3$. We bound $\\chi_3$ by\nother known structural parameters. We also present two classes of graphs with\ninteresting coloring properties, that play pivotal role in proving useful\nobservation about our problem. We give/ask several conjectures/questions\nthroughout this paper to encourage new research in the area of graph coloring.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 13:24:58 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Karpi\u0144ski", "Micha\u0142", ""], ["Piecuch", "Krzysztof", ""]]}, {"id": "1710.07429", "submitter": "Nathan Keller", "authors": "Nathan Keller and Ohad Klein", "title": "Biased halfspaces, noise sensitivity, and local Chernoff inequalities", "comments": "Revised version, published in Discrete Analysis. 50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A halfspace is a function $f\\colon\\{-1,1\\}^n \\rightarrow \\{0,1\\}$ of the form\n$f(x)=\\mathbb{1}(a\\cdot x>t)$, where $\\sum_i a_i^2=1$.\n  We show that if $f$ is a halfspace with $\\mathbb{E}[f]=\\epsilon$ and\n$a'=\\max_i |a_i|$, then the degree-1 Fourier weight of $f$ is\n  $W^1(f)=\\Theta(\\epsilon^2 \\log(1/\\epsilon))$, and the maximal influence of\n$f$ is $I_{\\max}(f)=\\Theta(\\epsilon \\min(1,a' \\sqrt{\\log(1/\\epsilon)}))$.\n  These results, which determine the exact asymptotic order of $W^1(f)$ and\n$I_{\\max}(f)$, provide sharp generalizations of theorems proved by Matulef,\nO'Donnell, Rubinfeld, and Servedio, and settle a conjecture posed by Kalai,\nKeller and Mossel.\n  In addition, we present a refinement of the definition of noise sensitivity\nwhich takes into consideration the bias of the function, and show that (like in\nthe unbiased case) halfspaces are noise resistant, and, in the other direction,\nany noise resistant function is well correlated with a halfspace.\n  Our main tools are 'local' forms of the classical Chernoff inequality, like\nthe following one proved by Devroye and Lugosi (2008):\n  Let $\\{ x_i \\}$ be independent random variables uniformly distributed in\n$\\{-1,1\\}$, and let $a_i\\in\\mathbb{R}_+$ be such that $\\sum_i a_{i}^{2}=1$.\n  If for some $t\\geq 0$ we have $\\Pr[\\sum_{i} a_i x_i > t]=\\epsilon$, then\n$\\Pr[\\sum_{i} a_i x_i>t+\\delta]\\leq \\frac{\\epsilon}{2}$ holds for $\\delta\\leq\nc/\\sqrt{\\log(1/\\epsilon)}$, where $c$ is a universal constant.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 06:46:18 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 23:00:07 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 12:59:00 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Keller", "Nathan", ""], ["Klein", "Ohad", ""]]}, {"id": "1710.07476", "submitter": "Alexander Pilz", "authors": "Alexander Pilz", "title": "Planar 3-SAT with a Clause/Variable Cycle", "comments": "Implementing style of DMTCS journal", "journal-ref": "Discrete Mathematics & Theoretical Computer Science, Vol. 21 no. 3\n  , Discrete Algorithms (June 5, 2019) dmtcs:5521", "doi": "10.23638/DMTCS-21-3-18", "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Planar 3-SAT problem, we are given a 3-SAT formula together with its\nincidence graph, which is planar, and are asked whether this formula is\nsatisfiable. Since Lichtenstein's proof that this problem is NP-complete, it\nhas been used as a starting point for a large number of reductions. In the\ncourse of this research, different restrictions on the incidence graph of the\nformula have been devised, for which the problem also remains hard.\n  In this paper, we investigate the restriction in which we require that the\nincidence graph can be augmented by the edges of a Hamiltonian cycle that first\npasses through all variables and then through all clauses, in a way that the\nresulting graph is still planar. We show that the problem of deciding\nsatisfiability of a 3-SAT formula remains NP-complete even if the incidence\ngraph is restricted in that way and the Hamiltonian cycle is given. This\ncomplements previous results demanding cycles only through either the variables\nor clauses.\n  The problem remains hard for monotone formulas, as well as for instances with\nexactly three distinct variables per clause. In the course of this\ninvestigation, we show that monotone instances of Planar 3-SAT with exactly\nthree distinct variables per clause are always satisfiable, thus settling the\nquestion by Darmann, D\\\"ocker, and Dorn on the complexity of this problem\nvariant in a surprising way.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 10:39:42 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 12:16:52 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 11:07:44 GMT"}, {"version": "v4", "created": "Tue, 22 Jan 2019 19:02:40 GMT"}, {"version": "v5", "created": "Sun, 28 Apr 2019 16:15:25 GMT"}, {"version": "v6", "created": "Mon, 27 May 2019 19:15:18 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Pilz", "Alexander", ""]]}, {"id": "1710.07584", "submitter": "Julien Fradin", "authors": "Guillaume Fertin, Julien Fradin, Christian Komusiewicz", "title": "The Maximum Colorful Arborescence problem parameterized by the structure\n  of its color hierarchy graph", "comments": "Submitted a 12 pages version (+ rest in Appendix for referees) to CPM\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G=(V,A) be a vertex-colored arc-weighted directed acyclic graph (DAG)\nrooted in some vertex r, and let H be its color hierarchy graph, defined as\nfollows: V(H) is the color set C of G, and an arc from color c to color c'\nexists in H if there is an arc in G from a vertex of color c to a vertex of\ncolor c'. In this paper, we study the MAXIMUM COLORFUL ARBORESCENCE problem (or\nMCA), which takes as input a DAG G with the additional constraint that H is\nalso a DAG, and aims at finding in G an arborescence rooted in r, of maximum\nweight, and in which no color appears more than once. The MCA problem is\nmotivated by the inference of unknown metabolites from mass spectrometry\nexperiments. However, whereas the problem has been studied for roughly ten\nyears, the crucial property that H is necessarily a DAG has only been pointed\nout and exploited very recently. In this paper, we further investigate MCA\nunder this new light, by providing algorithmic results for the problem, with a\nspecific focus on fixed-parameterized tractability (FPT) issues, and relatively\nto different structural parameters of H. In particular, we provide an\nO*(3^{nhs}) time algorithm for solving MCA, where nhs is the number of vertices\nof indegree at least two in H, thereby improving the O*(3^{|C|}) algorithm from\n[B\\\"ocker et al. 2008]. We also prove that MCA is W[2]-hard relatively to the\ntreewidth Ht of H, and further show that it is FPT relatively to Ht+lc, where\nlc = |V| - |C|.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 15:55:58 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 16:59:08 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Fertin", "Guillaume", ""], ["Fradin", "Julien", ""], ["Komusiewicz", "Christian", ""]]}, {"id": "1710.07601", "submitter": "Till Fluschnik", "authors": "Till Fluschnik, George B. Mertzios, and Andr\\'e Nichterlein", "title": "Kernelization Lower Bounds for Finding Constant-Size Subgraphs", "comments": "An extended abstract appeared in Proceedings of the 14th Conference\n  on Computability in Europe (CiE 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernelization is an important tool in parameterized algorithmics. Given an\ninput instance accompanied by a parameter, the goal is to compute in polynomial\ntime an equivalent instance of the same problem such that the size of the\nreduced instance only depends on the parameter and not on the size of the\noriginal instance. In this paper, we provide a first conceptual study on limits\nof kernelization for several polynomial-time solvable problems. For instance,\nwe consider the problem of finding a triangle with negative sum of edge weights\nparameterized by the maximum degree of the input graph. We prove that a\nlinear-time computable strict kernel of truly subcubic size for this problem\nviolates the popular APSP-conjecture.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 16:48:35 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 09:23:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Fluschnik", "Till", ""], ["Mertzios", "George B.", ""], ["Nichterlein", "Andr\u00e9", ""]]}, {"id": "1710.08111", "submitter": "Joonatan Jalonen", "authors": "Joonatan Jalonen and Jarkko Kari", "title": "Conjugacy of one-dimensional one-sided cellular automata is undecidable", "comments": "12 pages, 2 figures, accepted for SOFSEM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two cellular automata are strongly conjugate if there exists a\nshift-commuting conjugacy between them. We prove that the following two sets of\npairs $(F,G)$ of one-dimensional one-sided cellular automata over a full shift\nare recursively inseparable: (i) pairs where $F$ has strictly larger\ntopological entropy than $G$, and (ii) pairs that are strongly conjugate and\nhave zero topological entropy.\n  Because there is no factor map from a lower entropy system to a higher\nentropy one, and there is no embedding of a higher entropy system into a lower\nentropy system, we also get as corollaries that the following decision problems\nare undecidable: Given two one-dimensional one-sided cellular automata $F$ and\n$G$ over a full shift: Are $F$ and $G$ conjugate? Is $F$ a factor of $G$? Is\n$F$ a subsystem of $G$? All of these are undecidable in both strong and weak\nvariants (whether the homomorphism is required to commute with the shift or\nnot, respectively). It also immediately follows that these results hold for\none-dimensional two-sided cellular automata.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 06:58:54 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Jalonen", "Joonatan", ""], ["Kari", "Jarkko", ""]]}, {"id": "1710.08163", "submitter": "Jacek Krzaczkowski", "authors": "Pawe{\\l} M. Idziak and Jacek Krzaczkowski", "title": "Satisfiability in multi-valued circuits", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satisfiability of Boolean circuits is among the most known and important\nproblems in theoretical computer science. This problem is NP-complete in\ngeneral but becomes polynomial time when restricted either to monotone gates or\nlinear gates. We go outside Boolean realm and consider circuits built of any\nfixed set of gates on an arbitrary large finite domain. From the complexity\npoint of view this is strictly connected with the problems of solving equations\n(or systems of equations) over finite algebras.\n  The research reported in this work was motivated by a desire to know for\nwhich finite algebras $\\mathbf A$ there is a polynomial time algorithm that\ndecides if an equation over $\\mathbf A$ has a solution. We are also looking for\npolynomial time algorithms that decide if two circuits over a finite algebra\ncompute the same function. Although we have not managed to solve these problems\nin the most general setting we have obtained such a characterization for a very\nbroad class of algebras from congruence modular varieties. This class includes\nmost known and well-studied algebras such as groups, rings, modules (and their\ngeneralizations like quasigroups, loops, near-rings, nonassociative rings, Lie\nalgebras), lattices (and their extensions like Boolean algebras, Heyting\nalgebras or other algebras connected with multi-valued logics including\nMV-algebras).\n  This paper seems to be the first systematic study of the computational\ncomplexity of satisfiability of non-Boolean circuits and solving equations over\nfinite algebras. The characterization results provided by the paper is given in\nterms of nice structural properties of algebras for which the problems are\nsolvable in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 09:27:38 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Idziak", "Pawe\u0142 M.", ""], ["Krzaczkowski", "Jacek", ""]]}, {"id": "1710.08223", "submitter": "Elena Kirshanova", "authors": "Zvika Brakerski and Elena Kirshanova and Damien Stehl\\'e and Weiqiang\n  Wen", "title": "Learning With Errors and Extrapolated Dihedral Cosets", "comments": "Updated acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hardness of the learning with errors (LWE) problem is one of the most\nfruitful resources of modern cryptography. In particular, it is one of the most\nprominent candidates for secure post-quantum cryptography. Understanding its\nquantum complexity is therefore an important goal. We show that under quantum\npolynomial time reductions, LWE is equivalent to a relaxed version of the\ndihedral coset problem (DCP), which we call extrapolated DCP (eDCP). The extent\nof extrapolation varies with the LWE noise rate. By considering different\nextents of extrapolation, our result generalizes Regev's famous proof that if\nDCP is in BQP (quantum poly-time) then so is LWE (FOCS'02). We also discuss a\nconnection between eDCP and Childs and Van Dam's algorithm for generalized\nhidden shift problems (SODA'07). Our result implies that a BQP solution for LWE\nmight not require the full power of solving DCP, but rather only a solution for\nits relaxed version, eDCP, which could be easier.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 12:07:18 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 14:51:24 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Brakerski", "Zvika", ""], ["Kirshanova", "Elena", ""], ["Stehl\u00e9", "Damien", ""], ["Wen", "Weiqiang", ""]]}, {"id": "1710.08225", "submitter": "Guillaume Cheze", "authors": "Guillaume Ch\\`eze (IMT), Thierry Combot (IMB)", "title": "Symbolic Computations of First Integrals for Polynomial Vector Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC math.CA math.DS nlin.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we show how to generalize to the Darbouxian, Liouvillian and\nRiccati case the extactic curve introduced by J. Pereira. With this approach,\nwe get new algorithms for computing, if it exists, a rational, Darbouxian,\nLiouvillian or Riccati first integral with bounded degree of a polynomial\nplanar vector field. We give probabilistic and deterministic algorithms. The\narithmetic complexity of our probabilistic algorithm is in\n$\\tilde{\\mathcal{O}}(N^{\\omega+1})$, where $N$ is the bound on the degree of a\nrepresentation of the first integral and $\\omega \\in [2;3]$ is the exponent of\nlinear algebra. This result improves previous algorithms. Our algorithms have\nbeen implemented in Maple and are available on authors' websites. In the last\nsection, we give some examples showing the efficiency of these algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 12:13:37 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 15:34:04 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Ch\u00e8ze", "Guillaume", "", "IMT"], ["Combot", "Thierry", "", "IMB"]]}, {"id": "1710.08602", "submitter": "Siyi Yang", "authors": "Aleksandrs Belovs, G\\'abor Ivanyos, Youming Qiao, Miklos Santha, Siyi\n  Yang", "title": "On the Polynomial Parity Argument Complexity of the Combinatorial\n  Nullstellensatz", "comments": "26 pages", "journal-ref": "32nd Conference on Computational Complexity (CCC 2017), Leibniz\n  International Proceedings in Informatics (LIPIcs) 79, pp. 30:1-30:24 (2017)", "doi": "10.4230/LIPIcs.CCC.2017.30", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity class PPA consists of NP-search problems which are reducible\nto the parity principle in undirected graphs. It contains a wide variety of\ninteresting problems from graph theory, combinatorics, algebra and number\ntheory, but only a few of these are known to be complete in the class. Before\nthis work, the known complete problems were all discretizations or\ncombinatorial analogues of topological fixed point theorems. Here we prove the\nPPA-completeness of two problems of radically different style. They are\nPPA-Circuit CNSS and PPA-Circuit Chevalley, related respectively to the\nCombinatorial Nullstellensatz and to the Chevalley-Warning Theorem over the two\nelements field GF(2). The input of these problems contain PPA-circuits which\nare arithmetic circuits with special symmetric properties that assure that the\npolynomials computed by them have always an even number of zeros. In the proof\nof the result we relate the multilinear degree of the polynomials to the parity\nof the maximal parse subcircuits that compute monomials with maximal\nmultilinear degree, and we show that the maximal parse subcircuits of a\nPPA-circuit can be paired in polynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 05:08:44 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 13:09:56 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Belovs", "Aleksandrs", ""], ["Ivanyos", "G\u00e1bor", ""], ["Qiao", "Youming", ""], ["Santha", "Miklos", ""], ["Yang", "Siyi", ""]]}, {"id": "1710.09079", "submitter": "Robin Kothari", "authors": "Mark Bun, Robin Kothari, Justin Thaler", "title": "The Polynomial Method Strikes Back: Tight Quantum Query Bounds via Dual\n  Polynomials", "comments": "v1: 67 pages, 2 figures. Abstract shortened to fit within the arXiv\n  limit; v2: Minor changes; v3: Minor fixes incorporating suggestions from\n  referees", "journal-ref": "Proceedings of the 50th ACM Symposium on Theory of Computing (STOC\n  2018), pp. 297-310 (2018)", "doi": "10.1145/3188745.3188784", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximate degree of a Boolean function f is the least degree of a real\npolynomial that approximates f pointwise to error at most 1/3. Approximate\ndegree is known to be a lower bound on quantum query complexity. We resolve or\nnearly resolve the approximate degree and quantum query complexities of the\nfollowing basic functions:\n  $\\bullet$ $k$-distinctness: For any constant $k$, the approximate degree and\nquantum query complexity of $k$-distinctness is $\\Omega(n^{3/4-1/(2k)})$. This\nis nearly tight for large $k$ (Belovs, FOCS 2012).\n  $\\bullet$ Image size testing: The approximate degree and quantum query\ncomplexity of testing the size of the image of a function $[n] \\to [n]$ is\n$\\tilde{\\Omega}(n^{1/2})$. This proves a conjecture of Ambainis et al. (SODA\n2016), and it implies the following lower bounds:\n  $-$ $k$-junta testing: A tight $\\tilde{\\Omega}(k^{1/2})$ lower bound,\nanswering the main open question of Ambainis et al. (SODA 2016).\n  $-$ Statistical Distance from Uniform: A tight $\\tilde{\\Omega}(n^{1/2})$\nlower bound, answering the main question left open by Bravyi et al. (STACS 2010\nand IEEE Trans. Inf. Theory 2011).\n  $-$ Shannon entropy: A tight $\\tilde{\\Omega}(n^{1/2})$ lower bound, answering\na question of Li and Wu (2017).\n  $\\bullet$ Surjectivity: The approximate degree of the Surjectivity function\nis $\\tilde{\\Omega}(n^{3/4})$. The best prior lower bound was $\\Omega(n^{2/3})$.\nOur result matches an upper bound of $\\tilde{O}(n^{3/4})$ due to Sherstov,\nwhich we reprove using different techniques. The quantum query complexity of\nthis function is known to be $\\Theta(n)$ (Beame and Machmouchi, QIC 2012 and\nSherstov, FOCS 2015).\n  Our upper bound for Surjectivity introduces new techniques for approximating\nBoolean functions by low-degree polynomials. Our lower bounds are proved by\nsignificantly refining techniques recently introduced by Bun and Thaler (FOCS\n2017).\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 05:44:14 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 00:32:18 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 18:26:05 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Bun", "Mark", ""], ["Kothari", "Robin", ""], ["Thaler", "Justin", ""]]}, {"id": "1710.09143", "submitter": "Adi Shraibman", "authors": "Adi Shraibman", "title": "Nondeterministic Communication Complexity with Help and Graph Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define nondeterministic communication complexity in the model of\ncommunication complexity with help of Babai, Hayes and Kimmel. We use it to\nprove logarithmic lower bounds on the NOF communication complexity of explicit\ngraph functions, which are complementary to the bounds proved by Beame, David,\nPitassi and Woelfel.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 09:55:57 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Shraibman", "Adi", ""]]}, {"id": "1710.09278", "submitter": "Fabio Lorenzo Traversa Ph.D.", "authors": "Fabio L. Traversa, Pietro Cicotti, Forrest Sheldon, Massimiliano Di\n  Ventra", "title": "Evidence of an exponential speed-up in the solution of hard optimization\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization problems pervade essentially every scientific discipline and\nindustry. Many such problems require finding a solution that maximizes the\nnumber of constraints satisfied. Often, these problems are particularly\ndifficult to solve because they belong to the NP-hard class, namely algorithms\nthat always find a solution in polynomial time are not known. Over the past\ndecades, research has focused on developing heuristic approaches that attempt\nto find an approximation to the solution. However, despite numerous research\nefforts, in many cases even approximations to the optimal solution are hard to\nfind, as the computational time for further refining a candidate solution grows\nexponentially with input size. Here, we show a non-combinatorial approach to\nhard optimization problems that achieves an exponential speed-up and finds\nbetter approximations than the current state-of-the-art. First, we map the\noptimization problem into a boolean circuit made of specially designed,\nself-organizing logic gates, which can be built with (non-quantum) electronic\ncomponents; the equilibrium points of the circuit represent the approximation\nto the problem at hand. Then, we solve its associated non-linear ordinary\ndifferential equations numerically, towards the equilibrium points. We\ndemonstrate this exponential gain by comparing a sequential MatLab\nimplementation of our solver with the winners of the 2016 Max-SAT competition\non a variety of hard optimization instances. We show empirical evidence that\nour solver scales linearly with the size of the problem, both in time and\nmemory, and argue that this property derives from the collective behavior of\nthe simulated physical circuit. Our approach can be applied to other types of\noptimization problems and the results presented here have far-reaching\nconsequences in many fields.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 06:23:09 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Traversa", "Fabio L.", ""], ["Cicotti", "Pietro", ""], ["Sheldon", "Forrest", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "1710.09417", "submitter": "Daniel Severin Dr.", "authors": "Daniel Severin", "title": "Cross-identification of stellar catalogs with multiple stars: Complexity\n  and Resolution", "comments": null, "journal-ref": "Electronic Notes in Discrete Mathematics 69 (2018), 29-36", "doi": "10.1016/j.endm.2018.07.005", "report-no": null, "categories": "cs.DM astro-ph.IM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, I present an optimization problem which consists of assigning\nentries of a stellar catalog to multiple entries of another stellar catalog\nsuch that the probability of such assignment is maximum. I show a way of\nmodeling it as a Maximum Weighted Stable Set Problem which is further used to\nsolve a real astronomical instance and I partially characterize the forbidden\nsubgraphs of the resulting family of graphs given by that reduction. Finally, I\nprove that the problem is NP-Hard.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 18:42:35 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 13:59:21 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Severin", "Daniel", ""]]}, {"id": "1710.09502", "submitter": "Rafael Oliveira", "authors": "Klim Efremenko and Ankit Garg and Rafael Oliveira and Avi Wigderson", "title": "Barriers for Rank Methods in Arithmetic Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arithmetic complexity is considered simpler to understand than Boolean\ncomplexity, namely computing Boolean functions via logical gates. And indeed,\nwe seem to have significantly more lower bound techniques and results in\narithmetic complexity than in Boolean complexity. Despite many successes and\nrapid progress, however, challenges like proving super-polynomial lower bounds\non circuit or formula size for explicit polynomials, or super-linear lower\nbounds on explicit 3-dimensional tensors, remain elusive.\n  At the same time, we have plenty more \"barrier results\" for failing to prove\nbasic lower bounds in Boolean complexity than in arithmetic complexity. Finding\nbarriers to arithmetic lower bound techniques seem harder, and despite some\nattempts we have no excuses of similar quality for these failures in arithmetic\ncomplexity. This paper aims to add to this study.\n  We address rank methods, which were long recognized as encompassing and\nabstracting almost all known arithmetic lower bounds to-date, including the\nmost recent impressive successes. Rank methods (or flattenings) are also in\nwide use in algebraic geometry for proving tensor rank and symmetric tensor\nrank lower bounds. Our main results are barriers to these methods. In\nparticular,\n  1. Rank methods cannot prove better than $\\Omega_d (n^{\\lfloor d/2 \\rfloor})$\nlower bound on the tensor rank of any $d$-dimensional tensor of side $n$. (In\nparticular, they cannot prove super-linear, indeed even $>8n$ tensor rank lower\nbounds for any 3-dimensional tensors.)\n  2. Rank methods cannot prove $\\Omega_d (n^{\\lfloor d/2 \\rfloor})$ on the\nWaring rank of any $n$-variate polynomial of degree $d$. (In particular, they\ncannot prove such lower bounds on stronger models, including depth-3 circuits.)\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 01:03:25 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Efremenko", "Klim", ""], ["Garg", "Ankit", ""], ["Oliveira", "Rafael", ""], ["Wigderson", "Avi", ""]]}, {"id": "1710.09595", "submitter": "Kamil Khadiev", "authors": "Kamil Khadiev, Aliya Khadieva, Dmitry Kravchenko, Alexander Rivosh,\n  Ramis Yamilov and Ilnaz Mannapov", "title": "Quantum versus Classical Online Streaming Algorithms with Logarithmic\n  Size of Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.FL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online algorithms with respect to the competitive ratio. Here, we\ninvestigate quantum and classical one-way automata with non-constant size of\nmemory (streaming algorithms) as a model for online algorithms. We construct\nproblems that can be solved by quantum online streaming algorithms better than\nby classical ones in a case of logarithmic or sublogarithmic size of memory.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 08:53:20 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 12:46:06 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 10:44:11 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Khadiev", "Kamil", ""], ["Khadieva", "Aliya", ""], ["Kravchenko", "Dmitry", ""], ["Rivosh", "Alexander", ""], ["Yamilov", "Ramis", ""], ["Mannapov", "Ilnaz", ""]]}, {"id": "1710.09780", "submitter": "Avi Wigderson", "authors": "Avi Wigderson", "title": "Interactions of Computational Complexity Theory and Mathematics", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $ $[This paper is a (self contained) chapter in a new book, Mathematics and\nComputation, whose draft is available on my homepage at\nhttps://www.math.ias.edu/avi/book ].\n  We survey some concrete interaction areas between computational complexity\ntheory and different fields of mathematics. We hope to demonstrate here that\nhardly any area of modern mathematics is untouched by the computational\nconnection (which in some cases is completely natural and in others may seem\nquite surprising). In my view, the breadth, depth, beauty and novelty of these\nconnections is inspiring, and speaks to a great potential of future\ninteractions (which indeed, are quickly expanding). We aim for variety. We give\nshort, simple descriptions (without proofs or much technical detail) of ideas,\nmotivations, results and connections; this will hopefully entice the reader to\ndig deeper. Each vignette focuses only on a single topic within a large\nmathematical filed. We cover the following:\n  $\\bullet$ Number Theory: Primality testing\n  $\\bullet$ Combinatorial Geometry: Point-line incidences\n  $\\bullet$ Operator Theory: The Kadison-Singer problem\n  $\\bullet$ Metric Geometry: Distortion of embeddings\n  $\\bullet$ Group Theory: Generation and random generation\n  $\\bullet$ Statistical Physics: Monte-Carlo Markov chains\n  $\\bullet$ Analysis and Probability: Noise stability\n  $\\bullet$ Lattice Theory: Short vectors\n  $\\bullet$ Invariant Theory: Actions on matrix tuples\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 16:02:37 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Wigderson", "Avi", ""]]}, {"id": "1710.09806", "submitter": "Andrew Morgan", "authors": "Eric Allender, Joshua A. Grochow, Dieter van Melkebeek, Cristopher\n  Moore, Andrew Morgan", "title": "Minimum Circuit Size, Graph Isomorphism, and Related Problems", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational power of deciding whether a given truth-table can\nbe described by a circuit of a given size (the Minimum Circuit Size Problem, or\nMCSP for short), and of the variant denoted as MKTP where circuit size is\nreplaced by a polynomially-related Kolmogorov measure. All prior reductions\nfrom supposedly-intractable problems to MCSP / MKTP hinged on the power of MCSP\n/ MKTP to distinguish random distributions from distributions produced by\nhardness-based pseudorandom generator constructions. We develop a fundamentally\ndifferent approach inspired by the well-known interactive proof system for the\ncomplement of Graph Isomorphism (GI). It yields a randomized reduction with\nzero-sided error from GI to MKTP. We generalize the result and show that GI can\nbe replaced by any isomorphism problem for which the underlying group satisfies\nsome elementary properties. Instantiations include Linear Code Equivalence,\nPermutation Group Conjugacy, and Matrix Subspace Conjugacy. Along the way we\ndevelop encodings of isomorphism classes that are efficiently decodable and\nachieve compression that is at or near the information-theoretic optimum; those\nencodings may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 16:55:23 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Allender", "Eric", ""], ["Grochow", "Joshua A.", ""], ["van Melkebeek", "Dieter", ""], ["Moore", "Cristopher", ""], ["Morgan", "Andrew", ""]]}, {"id": "1710.10322", "submitter": "Sivakanth Gopi", "authors": "Sivakanth Gopi, Venkatesan Guruswami, Sergey Yekhanin", "title": "Maximally Recoverable LRCs: A field size lower bound and constructions\n  for few heavy parities", "comments": "Conference version to appear in Symposium on Discrete Algorithms\n  (SODA) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion in the volumes of data being stored online has resulted in\ndistributed storage systems transitioning to erasure coding based schemes.\nLocal Reconstruction Codes (LRCs) have emerged as the codes of choice for these\napplications. These codes can correct a small number of erasures by accessing\nonly a small number of remaining coordinates. An $(n,r,h,a,q)$-LRC is a linear\ncode over $\\mathbb{F}_q$ of length $n$, whose codeword symbols are partitioned\ninto $g=n/r$ local groups each of size $r$. It has $h$ global parity checks and\neach local group has $a$ local parity checks. Such an LRC is Maximally\nRecoverable (MR), if it corrects all erasure patterns which are\ninformation-theoretically correctable under the stipulated structure of local\nand global parity checks.\n  We show the first non-trivial lower bounds on the field size required for MR\nLRCs. When $a,h$ are constant and the number of local groups $g \\ge h$, while\n$r$ may grow with $n$, our lower bound simplifies to $q\\ge\n\\Omega_{a,h}\\left(n\\cdot r^{\\min\\{a,h-2\\}}\\right).$ No superlinear (in $n$)\nlower bounds were known prior to this work for any setting of parameters.\n  MR LRCs deployed in practice have a small number of global parities,\ntypically $h=2,3$. We complement our lower bounds by giving constructions with\nsmall field size for $h\\le 3$. For $h=2$, we give a linear field size\nconstruction. We also show a surprising application of elliptic curves and\narithmetic progression free sets in the construction of MR LRCs.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 20:21:56 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 13:55:11 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 20:48:32 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Gopi", "Sivakanth", ""], ["Guruswami", "Venkatesan", ""], ["Yekhanin", "Sergey", ""]]}, {"id": "1710.10545", "submitter": "Hadley Black", "authors": "Hadley Black, Deeparnab Chakrabarty, C. Seshadhri", "title": "A $o(d) \\cdot \\text{polylog}~n$ Monotonicity Tester for Boolean\n  Functions over the Hypergrid $[n]^d$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study monotonicity testing of Boolean functions over the hypergrid $[n]^d$\nand design a non-adaptive tester with $1$-sided error whose query complexity is\n$\\tilde{O}(d^{5/6})\\cdot \\text{poly}(\\log n,1/\\epsilon)$. Previous to our work,\nthe best known testers had query complexity linear in $d$ but independent of\n$n$. We improve upon these testers as long as $n = 2^{d^{o(1)}}$.\n  To obtain our results, we work with what we call the augmented hypergrid,\nwhich adds extra edges to the hypergrid. Our main technical contribution is a\nMargulis-style isoperimetric result for the augmented hypergrid, and our\ntester, like previous testers for the hypercube domain, performs directed\nrandom walks on this structure.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 01:00:12 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Black", "Hadley", ""], ["Chakrabarty", "Deeparnab", ""], ["Seshadhri", "C.", ""]]}, {"id": "1710.10660", "submitter": "Cl\\'ement Canonne", "authors": "Omri Ben-Eliezer, Cl\\'ement L. Canonne", "title": "Improved Bounds for Testing Forbidden Order Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sequence $f\\colon\\{1,\\dots,n\\}\\to\\mathbb{R}$ contains a permutation $\\pi$\nof length $k$ if there exist $i_1<\\dots<i_k$ such that, for all $x,y$,\n$f(i_x)<f(i_y)$ if and only if $\\pi(x)<\\pi(y)$; otherwise, $f$ is said to be\n$\\pi$-free. In this work, we consider the problem of testing for $\\pi$-freeness\nwith one-sided error, continuing the investigation of [Newman et al., SODA'17].\n  We demonstrate a surprising behavior for non-adaptive tests with one-sided\nerror: While a trivial sampling-based approach yields an $\\varepsilon$-test for\n$\\pi$-freeness making $\\Theta(\\varepsilon^{-1/k} n^{1-1/k})$ queries, our lower\nbounds imply that this is almost optimal for most permutations! Specifically,\nfor most permutations $\\pi$ of length $k$, any non-adaptive one-sided\n$\\varepsilon$-test requires\n$\\varepsilon^{-1/(k-\\Theta(1))}n^{1-1/(k-\\Theta(1))}$ queries; furthermore, the\npermutations that are hardest to test require\n$\\Theta(\\varepsilon^{-1/(k-1)}n^{1-1/(k-1)})$ queries, which is tight in $n$\nand $\\varepsilon$.\n  Additionally, we show two hierarchical behaviors here. First, for any $k$ and\n$l\\leq k-1$, there exists some $\\pi$ of length $k$ that requires\n$\\tilde{\\Theta}_{\\varepsilon}(n^{1-1/l})$ non-adaptive queries. Second, we show\nan adaptivity hierarchy for $\\pi=(1,3,2)$ by proving upper and lower bounds for\n(one- and two-sided) testing of $\\pi$-freeness with $r$ rounds of adaptivity.\nThe results answer open questions of Newman et al. and [Canonne and Gur,\nCCC'17].\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 18:06:27 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Ben-Eliezer", "Omri", ""], ["Canonne", "Cl\u00e9ment L.", ""]]}, {"id": "1710.10753", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra", "title": "Computational Social Choice and Computational Complexity: BFFs?", "comments": "A version of this paper will appear in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the connection between computational social choice (comsoc) and\ncomputational complexity. We stress the work so far on, and urge continued\nfocus on, two less-recognized aspects of this connection. Firstly, this is very\nmuch a two-way street: Everyone knows complexity classification is used in\ncomsoc, but we also highlight benefits to complexity that have arisen from its\nuse in comsoc. Secondly, more subtle, less-known complexity tools often can be\nvery productively used in comsoc.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 03:28:32 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 19:36:27 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Hemaspaandra", "Lane A.", ""]]}, {"id": "1710.11278", "submitter": "Boris Hanin", "authors": "Boris Hanin, Mark Sellke", "title": "Approximating Continuous Functions by ReLU Nets of Minimal Width", "comments": "v2. 13p. Extended main result to higher dimensional output. Comments\n  welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article concerns the expressive power of depth in deep feed-forward\nneural nets with ReLU activations. Specifically, we answer the following\nquestion: for a fixed $d_{in}\\geq 1,$ what is the minimal width $w$ so that\nneural nets with ReLU activations, input dimension $d_{in}$, hidden layer\nwidths at most $w,$ and arbitrary depth can approximate any continuous,\nreal-valued function of $d_{in}$ variables arbitrarily well? It turns out that\nthis minimal width is exactly equal to $d_{in}+1.$ That is, if all the hidden\nlayer widths are bounded by $d_{in}$, then even in the infinite depth limit,\nReLU nets can only express a very limited class of functions, and, on the other\nhand, any continuous function on the $d_{in}$-dimensional unit cube can be\napproximated to arbitrary precision by ReLU nets in which all hidden layers\nhave width exactly $d_{in}+1.$ Our construction in fact shows that any\ncontinuous function $f:[0,1]^{d_{in}}\\to\\mathbb R^{d_{out}}$ can be\napproximated by a net of width $d_{in}+d_{out}$. We obtain quantitative depth\nestimates for such an approximation in terms of the modulus of continuity of\n$f$.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 00:26:56 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 21:47:40 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Hanin", "Boris", ""], ["Sellke", "Mark", ""]]}, {"id": "1710.11516", "submitter": "Nicolas Resch", "authors": "Venkatesan Guruswami and Nicolas Resch", "title": "On the List-Decodability of Random Linear Rank-Metric Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The list-decodability of random linear rank-metric codes is shown to match\nthat of random rank-metric codes. Specifically, an $\\mathbb{F}_q$-linear\nrank-metric code over $\\mathbb{F}_q^{m \\times n}$ of rate $R =\n(1-\\rho)(1-\\frac{n}{m}\\rho)-\\varepsilon$ is shown to be (with high probability)\nlist-decodable up to fractional radius $\\rho \\in (0,1)$ with lists of size at\nmost $\\frac{C_{\\rho,q}}{\\varepsilon}$, where $C_{\\rho,q}$ is a constant\ndepending only on $\\rho$ and $q$. This matches the bound for random rank-metric\ncodes (up to constant factors). The proof adapts the approach of Guruswami,\nH\\aa stad, Kopparty (STOC 2010), who established a similar result for the\nHamming metric case, to the rank-metric setting.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 14:42:39 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Resch", "Nicolas", ""]]}]