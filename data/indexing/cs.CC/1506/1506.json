[{"id": "1506.00095", "submitter": "Ioannis Avramopoulos", "authors": "Ioannis Avramopoulos", "title": "On the computational complexity of evolution", "comments": "I am withdrawing the claim that NP = coNP. The community working on\n  the hardness of nonlinear optimization problems uses the term \"NP-hard\" to\n  mean hardness under Turing (rather than Karp) reductions and does not\n  distinguish between \"NP-hard\" and \"coNP-hard\" problems. Therefore, my proof\n  that NP = coNP has a flaw in its argument. The rest of the results are\n  correct though", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the problem of recognizing an ESS in a symmetric\nbimatrix game is coNP-complete. In this paper, we show that recognizing an ESS\neven in doubly symmetric bimatrix games is also coNP-complete. Our result\nfurther implies that recognizing asymptotically stable equilibria of the\nreplicator dynamic in this class of games is also a coNP-complete problem.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 09:06:07 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 17:31:44 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Avramopoulos", "Ioannis", ""]]}, {"id": "1506.00273", "submitter": "Pritish Kamath", "authors": "Badih Ghazi, Pritish Kamath, Madhu Sudan", "title": "Communication Complexity of Permutation-Invariant Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the quest for a broader understanding of communication\ncomplexity of simple functions, we introduce the class of\n\"permutation-invariant\" functions. A partial function $f:\\{0,1\\}^n \\times\n\\{0,1\\}^n\\to \\{0,1,?\\}$ is permutation-invariant if for every bijection\n$\\pi:\\{1,\\ldots,n\\} \\to \\{1,\\ldots,n\\}$ and every $\\mathbf{x}, \\mathbf{y} \\in\n\\{0,1\\}^n$, it is the case that $f(\\mathbf{x}, \\mathbf{y}) =\nf(\\mathbf{x}^{\\pi}, \\mathbf{y}^{\\pi})$. Most of the commonly studied functions\nin communication complexity are permutation-invariant. For such functions, we\npresent a simple complexity measure (computable in time polynomial in $n$ given\nan implicit description of $f$) that describes their communication complexity\nup to polynomial factors and up to an additive error that is logarithmic in the\ninput size. This gives a coarse taxonomy of the communication complexity of\nsimple functions. Our work highlights the role of the well-known lower bounds\nof functions such as 'Set-Disjointness' and 'Indexing', while complementing\nthem with the relatively lesser-known upper bounds for 'Gap-Inner-Product'\n(from the sketching literature) and 'Sparse-Gap-Inner-Product' (from the recent\nwork of Canonne et al. [ITCS 2015]). We also present consequences to the study\nof communication complexity with imperfectly shared randomness where we show\nthat for total permutation-invariant functions, imperfectly shared randomness\nresults in only a polynomial blow-up in communication complexity after an\nadditive $O(\\log \\log n)$ overhead.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 19:13:58 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Ghazi", "Badih", ""], ["Kamath", "Pritish", ""], ["Sudan", "Madhu", ""]]}, {"id": "1506.00479", "submitter": "Johan Thapper", "authors": "Peter Jonsson and Johan Thapper", "title": "Constraint Satisfaction and Semilinear Expansions of Addition over the\n  Rationals and the Reals", "comments": "22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semilinear relation is a finite union of finite intersections of open and\nclosed half-spaces over, for instance, the reals, the rationals, or the\nintegers. Semilinear relations have been studied in connection with algebraic\ngeometry, automata theory, and spatiotemporal reasoning. We consider semilinear\nrelations over the rationals and the reals. Under this assumption, the\ncomputational complexity of the constraint satisfaction problem (CSP) is known\nfor all finite sets containing R+={(x,y,z) | x+y=z}, <=, and {1}. These\nproblems correspond to expansions of the linear programming feasibility\nproblem. We generalise this result and fully determine the complexity for all\nfinite sets of semilinear relations containing R+. This is accomplished in part\nby introducing an algorithm, based on computing affine hulls, which solves a\nnew class of semilinear CSPs in polynomial time. We further analyse the\ncomplexity of linear optimisation over the solution set and the existence of\ninteger solutions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 12:53:56 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Jonsson", "Peter", ""], ["Thapper", "Johan", ""]]}, {"id": "1506.00617", "submitter": "Alexander Kozachinskiy", "authors": "Alexander Kozachinskiy", "title": "On Slepian--Wolf Theorem with Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study interactive \"one-shot\" analogues of the classical\nSlepian-Wolf theorem. Alice receives a value of a random variable $X$, Bob\nreceives a value of another random variable $Y$ that is jointly distributed\nwith $X$. Alice's goal is to transmit $X$ to Bob (with some error probability\n$\\varepsilon$). Instead of one-way transmission, which is studied in the\nclassical coding theory, we allow them to interact. They may also use shared\nrandomness.\n  We show, that Alice can transmit $X$ to Bob in expected $H(X|Y) +\n2\\sqrt{H(X|Y)} + O(\\log_2\\left(\\frac{1}{\\varepsilon}\\right))$ number of bits.\nMoreover, we show that every one-round protocol $\\pi$ with information\ncomplexity $I$ can be compressed to the (many-round) protocol with expected\ncommunication about $I + 2\\sqrt{I}$ bits. This improves a result by Braverman\nand Rao \\cite{braverman2011information}, where they had $5\\sqrt{I}$. Further,\nwe show how to solve this problem (transmitting $X$) using $3H(X|Y) +\nO(\\log_2\\left(\\frac{1}{\\varepsilon}\\right))$ bits and $4$ rounds on average.\nThis improves a result of~\\cite{brody2013towards}, where they had $4H(X|Y) +\nO(\\log1/\\varepsilon)$ bits and 10 rounds on average.\n  In the end of the paper we discuss how many bits Alice and Bob may need to\ncommunicate on average besides $H(X|Y)$. The main question is whether the upper\nbounds mentioned above are tight. We provide an example of $(X, Y)$, such that\ntransmission of $X$ from Alice to Bob with error probability $\\varepsilon$\nrequires $H(X|Y) + \\Omega\\left(\\log_2\\left(\\frac{1}{\\varepsilon}\\right)\\right)$\nbits on average.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 19:25:43 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2015 13:19:53 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Kozachinskiy", "Alexander", ""]]}, {"id": "1506.01083", "submitter": "Joshua Brody", "authors": "Joshua Brody and Mario Sanchez", "title": "Dependent Random Graphs and Multiparty Pointer Jumping", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a study of a relaxed version of the standard Erdos-Renyi random\ngraph model, where each edge may depend on a few other edges. We call such\ngraphs \"dependent random graphs\". Our main result in this direction is a\nthorough understanding of the clique number of dependent random graphs. We also\nobtain bounds for the chromatic number. Surprisingly, many of the standard\nproperties of random graphs also hold in this relaxed setting. We show that\nwith high probability, a dependent random graph will contain a clique of size\n$\\frac{(1-o(1))\\log n}{\\log(1/p)}$, and the chromatic number will be at most\n$\\frac{n \\log(1/1-p)}{\\log n}$.\n  As an application and second main result, we give a new communication\nprotocol for the k-player Multiparty Pointer Jumping (MPJ_k) problem in the\nnumber-on-the-forehead (NOF) model. Multiparty Pointer Jumping is one of the\ncanonical NOF communication problems, yet even for three players, its\ncommunication complexity is not well understood. Our protocol for MPJ_3 costs\n$O(\\frac{n\\log\\log n}{\\log n})$ communication, improving on a bound of Brody\nand Chakrabarti [BC08]. We extend our protocol to the non-Boolean pointer\njumping problem $\\widehat{MPJ}_k$, achieving an upper bound which is o(n) for\nany $k >= 4$ players. This is the first o(n) bound for $\\widehat{MPJ}_k$ and\nimproves on a bound of Damm, Jukna, and Sgall [DJS98] which has stood for\nalmost twenty years.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 23:08:16 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Brody", "Joshua", ""], ["Sanchez", "Mario", ""]]}, {"id": "1506.01296", "submitter": "Vladimir Podolskii", "authors": "Vladimir V. Podolskii", "title": "Circuit Complexity Meets Ontology-Based Data Access", "comments": "To appear in proceedings of CSR 2015, LNCS 9139, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-based data access is an approach to organizing access to a database\naugmented with a logical theory. In this approach query answering proceeds\nthrough a reformulation of a given query into a new one which can be answered\nwithout any use of theory. Thus the problem reduces to the standard database\nsetting.\n  However, the size of the query may increase substantially during the\nreformulation. In this survey we review a recently developed framework on\nproving lower and upper bounds on the size of this reformulation by employing\nmethods and results from Boolean circuit complexity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 16:02:07 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Podolskii", "Vladimir V.", ""]]}, {"id": "1506.01315", "submitter": "Mario Szegedy", "authors": "Mario Szegedy and Yixin Xu", "title": "Impossibility Theorems and the Universal Algebraic Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elucidate a close connection between the Theory of Judgment Aggregation\n(more generally, Evaluation Aggregation), and a relatively young but rapidly\ngrowing field of universal algebra, that was primarily developed to investigate\nconstraint satisfaction problems. Our connection yields a full classification\nof non-binary evaluations into possibility and impossibility domains both under\nthe idempotent and the supportive conditions. Prior to the current result E.\nDokow and R. Holzman nearly classified non-binary evaluations in the supportive\ncase, by combinatorial means. The algebraic approach gives us new insights to\nthe easier binary case as well, which had been fully classified by the above\nauthors. Our algebraic view lets us put forth a suggestion about a\nstrengthening of the Non-dictatorship criterion, that helps us avoid \"outliers\"\nlike the affine subspace. Finally, we give upper bounds on the complexity of\ncomputing if a domain is impossible or not (to our best knowledge no finite\ntime bounds were given earlier).\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 04:42:36 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Szegedy", "Mario", ""], ["Xu", "Yixin", ""]]}, {"id": "1506.01652", "submitter": "George Mertzios", "authors": "Archontia C. Giannopoulou, George B. Mertzios, and Rolf Niedermeier", "title": "Polynomial Fixed-Parameter Algorithms: A Case Study for Longest Path on\n  Interval Graphs", "comments": "34 pages, 1 figure, 1 algorithm, 4 reduction rules", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of fixed-parameter algorithms for problems already known\nto be solvable in polynomial time. The main motivation is to get more efficient\nalgorithms for problems with unattractive polynomial running times. Here, we\nfocus on a fundamental graph problem: Longest Path, that is, given an\nundirected graph, find a maximum-length path in $G$. Longest Path is NP-hard in\ngeneral but known to be solvable in $O(n^{4})$ time on $n$-vertex interval\ngraphs. We show how to solve Longest Path on Interval Graphs, parameterized by\nvertex deletion number $k$ to proper interval graphs, in $O(k^{9}n)$ time.\nNotably, Longest Path is trivially solvable in linear time on proper interval\ngraphs, and the parameter value $k$ can be approximated up to a factor of 4 in\nlinear time. From a more general perspective, we believe that using\nparameterized complexity analysis may enable a refined understanding of\nefficiency aspects for polynomial-time solvable problems similarly to what\nclassical parameterized complexity analysis does for NP-hard problems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 16:49:35 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 20:22:22 GMT"}, {"version": "v3", "created": "Fri, 2 Jun 2017 15:07:45 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 21:43:10 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Giannopoulou", "Archontia C.", ""], ["Mertzios", "George B.", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "1506.01695", "submitter": "Murali Krishna Enduri", "authors": "Bireswar Das, Murali Krishna Enduri and I. Vinod Reddy", "title": "Polynomial-time Algorithm for Isomorphism of Graphs with Clique-width at\n  most Three", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clique-width is a measure of complexity of decomposing graphs into\ncertain tree-like structures. The class of graphs with bounded clique-width\ncontains bounded tree-width graphs. We give a polynomial time graph isomorphism\nalgorithm for graphs with clique-width at most three. Our work is independent\nof the work by Grohe et al. \\cite{grohe2015isomorphism} showing that the\nisomorphism problem for graphs of bounded clique-width is polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 19:33:13 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2016 13:57:50 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Das", "Bireswar", ""], ["Enduri", "Murali Krishna", ""], ["Reddy", "I. Vinod", ""]]}, {"id": "1506.01930", "submitter": "Benjamin Lucien Kaminski", "authors": "Benjamin Lucien Kaminski, Joost-Pieter Katoen", "title": "On the Hardness of Almost-Sure Termination", "comments": "MFCS 2015. arXiv admin note: text overlap with arXiv:1410.7225", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the computational hardness of computing expected\noutcomes and deciding (universal) (positive) almost-sure termination of\nprobabilistic programs. It is shown that computing lower and upper bounds of\nexpected outcomes is $\\Sigma_1^0$- and $\\Sigma_2^0$-complete, respectively.\nDeciding (universal) almost-sure termination as well as deciding whether the\nexpected outcome of a program equals a given rational value is shown to be\n$\\Pi^0_2$-complete. Finally, it is shown that deciding (universal) positive\nalmost-sure termination is $\\Sigma_2^0$-complete ($\\Pi_3^0$-complete).\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 14:52:51 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1506.02243", "submitter": "Ioannis Papoutsakis", "authors": "Ioannis Papoutsakis", "title": "On approximating tree spanners that are breadth first search trees", "comments": null, "journal-ref": "Journal of Computer and System Sciences 82 (2016) 817-825", "doi": "10.1016/j.jcss.2016.02.008", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tree $t$-spanner $T$ of a graph $G$ is a spanning tree of $G$ such that the\ndistance in $T$ between every pair of verices is at most $t$ times the distance\nin $G$ between them. There are efficient algorithms that find a tree $t\\cdot\nO(\\log n)$-spanner of a graph $G$, when $G$ admits a tree $t$-spanner. In this\npaper, the search space is narrowed to $v$-concentrated spanning trees, a\nsimple family that includes all the breadth first search trees starting from\nvertex $v$. In this case, it is not easy to find approximate tree spanners\nwithin factor almost $o(\\log n)$. Specifically, let $m$ and $t$ be integers,\nsuch that $m>0$ and $t\\geq 7$. If there is an efficient algorithm that receives\nas input a graph $G$ and a vertex $v$ and returns a $v$-concentrated tree\n$t\\cdot o((\\log n)^{m/(m+1)})$-spanner of $G$, when $G$ admits a\n$v$-concentrated tree $t$-spanner, then there is an algorithm that decides\n3-SAT in quasi-polynomial time.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 09:24:09 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2015 04:57:23 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Papoutsakis", "Ioannis", ""]]}, {"id": "1506.02442", "submitter": "Irena Rusu Ph.D.", "authors": "Irena Rusu", "title": "NP-hardness of sortedness constraints", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Constraint Programming, global constraints allow to model and solve many\ncombinatorial problems. Among these constraints, several sortedness constraints\nhave been defined, for which propagation algorithms are available, but for\nwhich the tractability is not settled. We show that the sort(U,V) constraint\n(Older et. al, 1995) is intractable for integer variables whose domains are not\nlimited to intervals. As a consequence, the similar result holds for the\nsort(U,V, P) constraint (Zhou, 1996). Moreover, the intractability holds even\nunder the stability condition present in the recently introduced\nkeysorting(U,V,Keys,P) constraint (Carlsson et al., 2014), and requiring that\nthe order of the variables with the same value in the list U be preserved in\nthe list V. Therefore, keysorting(U,V,Keys,P) is intractable as well.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 11:24:06 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Rusu", "Irena", ""]]}, {"id": "1506.02936", "submitter": "Penghui Yao", "authors": "Penghui Yao", "title": "Parity Decision Tree Complexity and 4-Party Communication Complexity of\n  XOR-functions Are Polynomially Equivalent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we study the relation between the parity decision tree\ncomplexity of a boolean function $f$, denoted by $\\mathrm{D}_{\\oplus}(f)$, and\nthe $k$-party number-in-hand multiparty communication complexity of the XOR\nfunctions $F(x_1,\\ldots, x_k)= f(x_1\\oplus\\cdots\\oplus x_k)$, denoted by\n$\\mathrm{CC}^{(k)}(F)$. It is known that $\\mathrm{CC}^{(k)}(F)\\leq\nk\\cdot\\mathrm{D}_{\\oplus}(f)$ because the players can simulate the parity\ndecision tree that computes $f$. In this note, we show that\n\\[\\mathrm{D}_{\\oplus}(f)\\leq O\\big(\\mathrm{CC}^{(4)}(F)^5\\big).\\] Our main tool\nis a recent result from additive combinatorics due to Sanders. As\n$\\mathrm{CC}^{(k)}(F)$ is non-decreasing as $k$ grows, the parity decision tree\ncomplexity of $f$ and the communication complexity of the corresponding\n$k$-argument XOR functions are polynomially equivalent whenever $k\\geq 4$.\n  Remark: After the first version of this paper was finished, we discovered\nthat Hatami and Lovett had already discovered the same result a few years ago,\nwithout writing it up.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 14:42:20 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 16:14:59 GMT"}, {"version": "v3", "created": "Sun, 28 Jun 2015 08:14:51 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Yao", "Penghui", ""]]}, {"id": "1506.03167", "submitter": "David Witmer", "authors": "Guy Kindler, Ryan O'Donnell, David Witmer", "title": "Remarks on the Most Informative Function Conjecture at fixed mean", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2013, Courtade and Kumar posed the following problem: Let $\\boldsymbol{x}\n\\sim \\{\\pm 1\\}^n$ be uniformly random, and form $\\boldsymbol{y} \\sim \\{\\pm\n1\\}^n$ by negating each bit of $\\boldsymbol{x}$ independently with probability\n$\\alpha$. Is it true that the mutual information $I(f(\\boldsymbol{x})\n\\mathbin{;} \\boldsymbol{y})$ is maximized among $f:\\{\\pm 1\\}^n \\to \\{\\pm 1\\}$\nby $f(x) = x_1$? We do not resolve this problem. Instead, we make a couple of\nobservations about the fixed-mean version of the conjecture. We show that\nCourtade and Kumar's stronger Lex Conjecture fails for small noise rates. We\nalso prove a continuous version of the conjecture on the sphere and show that\nit implies the previously-known analogue for Gaussian space.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 05:09:58 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2015 22:19:38 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2016 16:30:11 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Kindler", "Guy", ""], ["O'Donnell", "Ryan", ""], ["Witmer", "David", ""]]}, {"id": "1506.03760", "submitter": "Rajesh Chitnis", "authors": "Rajesh Chitnis, Hossein Esfandiari, MohammadTaghi Hajiaghayi, Rohit\n  Khandekar, Guy Kortsarz, Saeed Seddighin", "title": "A Tight Algorithm for Strongly Connected Steiner Subgraph On Two\n  Terminals With Demands", "comments": "To appear in Algorithmica. An extended abstract appeared in IPEC '14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an edge-weighted directed graph $G=(V,E)$ on $n$ vertices and a set\n$T=\\{t_1, t_2, \\ldots, t_p\\}$ of $p$ terminals, the objective of the \\scss\n($p$-SCSS) problem is to find an edge set $H\\subseteq E$ of minimum weight such\nthat $G[H]$ contains an $t_{i}\\rightarrow t_j$ path for each $1\\leq i\\neq j\\leq\np$. In this paper, we investigate the computational complexity of a variant of\n$2$-SCSS where we have demands for the number of paths between each terminal\npair. Formally, the \\sharinggeneral problem is defined as follows: given an\nedge-weighted directed graph $G=(V,E)$ with weight function $\\omega:\nE\\rightarrow \\mathbb{R}^{\\geq 0}$, two terminal vertices $s, t$, and integers\n$k_1, k_2$ ; the objective is to find a set of $k_1$ paths $F_1, F_2, \\ldots,\nF_{k_1}$ from $s\\leadsto t$ and $k_2$ paths $B_1, B_2, \\ldots, B_{k_2}$ from\n$t\\leadsto s$ such that $\\sum_{e\\in E} \\omega(e)\\cdot \\phi(e)$ is minimized,\nwhere $\\phi(e)= \\max \\Big\\{|\\{i\\in [k_1] : e\\in F_i\\}|\\ ,\\ |\\{j\\in [k_2] : e\\in\nB_j\\}|\\Big\\}$. For each $k\\geq 1$, we show the following: The \\sharing problem\ncan be solved in $n^{O(k)}$ time. A matching lower bound for our algorithm: the\n\\sharing problem does not have an $f(k)\\cdot n^{o(k)}$ algorithm for any\ncomputable function $f$, unless the Exponential Time Hypothesis (ETH) fails.\n  Our algorithm for \\sharing relies on a structural result regarding an optimal\nsolution followed by using the idea of a \"token game\" similar to that of\nFeldman and Ruhl. We show with an example that the structural result does not\nhold for the \\sharinggeneral problem if $\\min\\{k_1, k_2\\}\\geq 2$. Therefore\n\\sharing is the most general problem one can attempt to solve with our\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 18:06:42 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 16:10:08 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Chitnis", "Rajesh", ""], ["Esfandiari", "Hossein", ""], ["Hajiaghayi", "MohammadTaghi", ""], ["Khandekar", "Rohit", ""], ["Kortsarz", "Guy", ""], ["Seddighin", "Saeed", ""]]}, {"id": "1506.04014", "submitter": "Stephen Piddock", "authors": "Stephen Piddock and Ashley Montanaro", "title": "The complexity of antiferromagnetic interactions and 2D lattices", "comments": "35 pages, 11 figures; v2 added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of the minimum eigenvalue of a quantum Hamiltonian can be\nformalised as the Local Hamiltonian problem. We study the natural special case\nof the Local Hamiltonian problem where the same 2-local interaction, with\ndiffering weights, is applied across each pair of qubits. First we consider\nantiferromagnetic/ferromagnetic interactions, where the weights of the terms in\nthe Hamiltonian are restricted to all be of the same sign. We show that for\nsymmetric 2-local interactions with no 1-local part, the problem is either\nQMA-complete or in StoqMA. In particular the antiferromagnetic Heisenberg and\nantiferromagnetic XY interactions are shown to be QMA-complete. We also prove\nStoqMA-completeness of the antiferromagnetic transverse field Ising model.\nSecond, we study the Local Hamiltonian problem under the restriction that the\ninteraction terms can only be chosen to lie on a particular graph. We prove\nthat nearly all of the QMA-complete 2-local interactions remain QMA-complete\nwhen restricted to a 2D square lattice. Finally we consider both restrictions\nat the same time and discover that, with the exception of the antiferromagnetic\nHeisenberg interaction, all of the interactions which are QMA-complete with\npositive coefficients remain QMA-complete when restricted to a 2D triangular\nlattice.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 13:26:26 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2015 15:35:49 GMT"}], "update_date": "2015-12-16", "authors_parsed": [["Piddock", "Stephen", ""], ["Montanaro", "Ashley", ""]]}, {"id": "1506.04184", "submitter": "Marcello Mamino", "authors": "Manuel Bodirsky and Marcello Mamino", "title": "Tropically convex constraint satisfaction", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semilinear relation S is max-closed if it is preserved by taking the\ncomponentwise maximum. The constraint satisfaction problem for max-closed\nsemilinear constraints is at least as hard as determining the winner in Mean\nPayoff Games, a notorious problem of open computational complexity. Mean Payoff\nGames are known to be in the intersection of NP and co-NP, which is not known\nfor max-closed semilinear constraints. Semilinear relations that are max-closed\nand additionally closed under translations have been called tropically convex\nin the literature. One of our main results is a new duality for open tropically\nconvex relations, which puts the CSP for tropically convex semilinaer\nconstraints in general into NP intersected co-NP. This extends the\ncorresponding complexity result for scheduling under and-or precedence\nconstraints, or equivalently the max-atoms problem. To this end, we present a\ncharacterization of max-closed semilinear relations in terms of syntactically\nrestricted first-order logic, and another characterization in terms of a finite\nset of relations L that allow primitive positive definitions of all other\nrelations in the class. We also present a subclass of max-closed constraints\nwhere the CSP is in P; this class generalizes the class of max-closed\nconstraints over finite domains, and the feasibility problem for max-closed\nlinear inequalities. Finally, we show that the class of max-closed semilinear\nconstraints is maximal in the sense that as soon as a single relation that is\nnot max-closed is added to L, the CSP becomes NP-hard.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 21:13:03 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 17:27:44 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mamino", "Marcello", ""]]}, {"id": "1506.04350", "submitter": "Raghu Meka", "authors": "Parikshit Gopalan, Daniel Kane, Raghu Meka", "title": "Pseudorandomness via the discrete Fourier transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to constructing unconditional pseudorandom\ngenerators against classes of functions that involve computing a linear\nfunction of the inputs. We give an explicit construction of a pseudorandom\ngenerator that fools the discrete Fourier transforms of linear functions with\nseed-length that is nearly logarithmic (up to polyloglog factors) in the input\nsize and the desired error parameter. Our result gives a single pseudorandom\ngenerator that fools several important classes of tests computable in logspace\nthat have been considered in the literature, including halfspaces (over general\ndomains), modular tests and combinatorial shapes. For all these classes, our\ngenerator is the first that achieves near logarithmic seed-length in both the\ninput length and the error parameter. Getting such a seed-length is a natural\nchallenge in its own right, which needs to be overcome in order to derandomize\nRL - a central question in complexity theory.\n  Our construction combines ideas from a large body of prior work, ranging from\na classical construction of [NN93] to the recent gradually increasing\nindependence paradigm of [KMN11, CRSW13, GMRTV12], while also introducing some\nnovel analytic machinery which might find other applications.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2015 04:49:43 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 18:30:37 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Gopalan", "Parikshit", ""], ["Kane", "Daniel", ""], ["Meka", "Raghu", ""]]}, {"id": "1506.04428", "submitter": "Gil Cohen", "authors": "Gil Cohen", "title": "Two-Source Dispersers for Polylogarithmic Entropy and Improved Ramsey\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his 1947 paper that inaugurated the probabilistic method, Erd\\H{o}s proved\nthe existence of $2\\log{n}$-Ramsey graphs on $n$ vertices. Matching Erd\\H{o}s'\nresult with a constructive proof is a central problem in combinatorics, that\nhas gained a significant attention in the literature. The state of the art\nresult was obtained in the celebrated paper by Barak, Rao, Shaltiel and\nWigderson [Ann. Math'12], who constructed a\n$2^{2^{(\\log\\log{n})^{1-\\alpha}}}$-Ramsey graph, for some small universal\nconstant $\\alpha > 0$.\n  In this work, we significantly improve the result of Barak~\\etal and\nconstruct $2^{(\\log\\log{n})^c}$-Ramsey graphs, for some universal constant $c$.\nIn the language of theoretical computer science, our work resolves the problem\nof explicitly constructing two-source dispersers for polylogarithmic entropy.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2015 18:56:28 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Cohen", "Gil", ""]]}, {"id": "1506.04719", "submitter": "Troy Lee", "authors": "Andris Ambainis, Kaspars Balodis, Aleksandrs Belovs, Troy Lee, Miklos\n  Santha, Juris Smotrovs", "title": "Separations in Query Complexity Based on Pointer Functions", "comments": "25 pages, 6 figures. Version 3 improves separation between Q_E and\n  R_0 and updates references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1986, Saks and Wigderson conjectured that the largest separation between\ndeterministic and zero-error randomized query complexity for a total boolean\nfunction is given by the function $f$ on $n=2^k$ bits defined by a complete\nbinary tree of NAND gates of depth $k$, which achieves $R_0(f) =\nO(D(f)^{0.7537\\ldots})$. We show this is false by giving an example of a total\nboolean function $f$ on $n$ bits whose deterministic query complexity is\n$\\Omega(n/\\log(n))$ while its zero-error randomized query complexity is $\\tilde\nO(\\sqrt{n})$. We further show that the quantum query complexity of the same\nfunction is $\\tilde O(n^{1/4})$, giving the first example of a total function\nwith a super-quadratic gap between its quantum and deterministic query\ncomplexities.\n  We also construct a total boolean function $g$ on $n$ variables that has\nzero-error randomized query complexity $\\Omega(n/\\log(n))$ and bounded-error\nrandomized query complexity $R(g) = \\tilde O(\\sqrt{n})$. This is the first\nsuper-linear separation between these two complexity measures. The exact\nquantum query complexity of the same function is $Q_E(g) = \\tilde O(\\sqrt{n})$.\n  These two functions show that the relations $D(f) = O(R_1(f)^2)$ and $R_0(f)\n= \\tilde O(R(f)^2)$ are optimal, up to poly-logarithmic factors. Further\nvariations of these functions give additional separations between other query\ncomplexity measures: a cubic separation between $Q$ and $R_0$, a $3/2$-power\nseparation between $Q_E$ and $R$, and a 4th power separation between\napproximate degree and bounded-error randomized query complexity.\n  All of these examples are variants of a function recently introduced by\n\\goos, Pitassi, and Watson which they used to separate the unambiguous\n1-certificate complexity from deterministic query complexity and to resolve the\nfamous Clique versus Independent Set problem in communication complexity.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 19:34:20 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2015 13:22:57 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2015 17:13:50 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Ambainis", "Andris", ""], ["Balodis", "Kaspars", ""], ["Belovs", "Aleksandrs", ""], ["Lee", "Troy", ""], ["Santha", "Miklos", ""], ["Smotrovs", "Juris", ""]]}, {"id": "1506.04722", "submitter": "Zack Fitzsimmons", "authors": "Zack Fitzsimmons and Edith Hemaspaandra", "title": "Complexity of Manipulative Actions When Voting with Ties", "comments": "A version of this paper will appear in ADT-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the computational study of election problems has assumed that each\nvoter's preferences are, or should be extended to, a total order. However in\npractice voters may have preferences with ties. We study the complexity of\nmanipulative actions on elections where voters can have ties, extending the\ndefinitions of the election systems (when necessary) to handle voters with\nties. We show that for natural election systems allowing ties can both increase\nand decrease the complexity of manipulation and bribery, and we state a general\nresult on the effect of voters with ties on the complexity of control.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 19:37:46 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Fitzsimmons", "Zack", ""], ["Hemaspaandra", "Edith", ""]]}, {"id": "1506.04882", "submitter": "Paul Goldberg", "authors": "Paul W. Goldberg", "title": "The Complexity of the Path-following Solutions of Two-dimensional\n  Sperner/Brouwer Functions", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a number of results saying that for certain \"path-following\"\nalgorithms that solve PPAD-complete problems, the solution obtained by the\nalgorithm is PSPACE-complete to compute. We conjecture that these results are\nspecial cases of a much more general principle, that all such algorithms\ncompute PSPACE-complete solutions. Such a general result might shed new light\non the complexity class PPAD.\n  In this paper we present a new PSPACE-completeness result for an interesting\nchallenge instance for this conjecture. Chen and Deng~\\cite{CD} showed that it\nis PPAD-complete to find a trichromatic triangle in a concisely-represented\nSperner triangulation. The proof of Sperner's lemma --- that such a solution\nalways exists --- identifies one solution in particular, that is found via a\nnatural \"path-following\" approach. Here we show that it is PSPACE-complete to\ncompute this specific solution, together with a similar result for the\ncomputation of the path-following solution of two-dimensional discrete Brouwer\nfunctions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 09:08:50 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Goldberg", "Paul W.", ""]]}, {"id": "1506.05043", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Ugo Dal Lago and Georg Moser", "title": "Analysing the Complexity of Functional Programs: Higher-Order Meets\n  First-Order (Long Version)", "comments": "Long version of paper presented at ICFP 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We show how the complexity of higher-order functional programs can be\nanalysed automatically by applying program transformations to a\ndefunctionalized versions of them, and feeding the result to existing tools for\nthe complexity analysis of first-order term rewrite systems. This is done while\ncarefully analysing complexity preservation and reflection of the employed\ntransformations such that the complexity of the obtained term rewrite system\nreflects on the complexity of the initial program. Further, we describe\nsuitable strategies for the application of the studied transformations and\nprovide ample experimental data for assessing the viability of our method.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 17:37:31 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Avanzini", "Martin", ""], ["Lago", "Ugo Dal", ""], ["Moser", "Georg", ""]]}, {"id": "1506.05079", "submitter": "Przemys{\\l}aw Uzna\\'nski", "authors": "Przemys{\\l}aw Uzna\\'nski", "title": "All Permutations Supersequence is coNP-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that deciding whether a given input word contains as subsequence\nevery possible permutation of integers $\\{1,2,\\ldots,n\\}$ is coNP-complete. The\ncoNP-completeness holds even when given the guarantee that the input word\ncontains as subsequences all of length $n-1$ sequences over the same set of\nintegers. We also show NP-completeness of a related problem of Partially\nNon-crossing Perfect Matching in Bipartite Graphs, i.e. to find a perfect\nmatching in an ordered bipartite graph where edges of the matching incident to\nselected vertices (even only from one side) are non-crossing.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 19:12:08 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2015 02:49:35 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Uzna\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "1506.06107", "submitter": "Heather Smith", "authors": "Istv\\'an Mikl\\'os and Heather Smith", "title": "The computational complexity of calculating partition functions of\n  optimal medians with Hamming distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that calculating the partition function of optimal\nmedians of binary strings with Hamming distance is \\#P-complete for several\nweight functions. The case when the weight function is the factorial function\nhas application in bioinformatics. In that case, the partition function counts\nthe most parsimonious evolutionary scenarios on a star tree under several\nmodels in bioinformatics. The results are extended to binary trees and we show\nthat it is also \\#P-complete to calculate the most parsimonious evolutionary\nscenarios on an arbitrary binary tree under the substitution model of\nbiological sequences and under the Single Cut-or-Join model for genome\nrearrangements.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 18:47:43 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2017 20:21:07 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Mikl\u00f3s", "Istv\u00e1n", ""], ["Smith", "Heather", ""]]}, {"id": "1506.06284", "submitter": "Roman Kolpakov", "authors": "Roman Kolpakov, Mikhail Posypkin", "title": "Upper bound on the number of steps for solving the subset sum problem by\n  the Branch-and-Bound method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of one of the particular cases of the\nknapsack problem: the subset sum problem. For solving this problem we consider\none of the basic variants of the Branch-and-Bound method in which any\nsub-problem is decomposed along the free variable with the maximal weight. By\nthe complexity of solving a problem by the Branch-and-Bound method we mean the\nnumber of steps required for solving the problem by this method. In the paper\nwe obtain upper bounds on the complexity of solving the subset sum problem by\nthe Branch-and-Bound method. These bounds can be easily computed from the input\ndata of the problem. So these bounds can be used for the the preliminary\nestimation of the computational resources required for solving the subset sum\nproblem by the Branch-and-Bound method.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2015 19:20:23 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Kolpakov", "Roman", ""], ["Posypkin", "Mikhail", ""]]}, {"id": "1506.06302", "submitter": "Euiwoong Lee", "authors": "Venkatesan Guruswami and Euiwoong Lee", "title": "Inapproximability of $H$-Transversal/Packing", "comments": "31 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an undirected graph $G = (V_G, E_G)$ and a fixed \"pattern\" graph $H =\n(V_H, E_H)$ with $k$ vertices, we consider the $H$-Transversal and $H$-Packing\nproblems. The former asks to find the smallest $S \\subseteq V_G$ such that the\nsubgraph induced by $V_G \\setminus S$ does not have $H$ as a subgraph, and the\nlatter asks to find the maximum number of pairwise disjoint $k$-subsets $S_1,\n..., S_m \\subseteq V_G$ such that the subgraph induced by each $S_i$ has $H$ as\na subgraph.\n  We prove that if $H$ is 2-connected, $H$-Transversal and $H$-Packing are\nalmost as hard to approximate as general $k$-Hypergraph Vertex Cover and\n$k$-Set Packing, so it is NP-hard to approximate them within a factor of\n$\\Omega (k)$ and $\\widetilde \\Omega (k)$ respectively. We also show that there\nis a 1-connected $H$ where $H$-Transversal admits an $O(\\log k)$-approximation\nalgorithm, so that the connectivity requirement cannot be relaxed from 2 to 1.\nFor a special case of $H$-Transversal where $H$ is a (family of) cycles, we\nmention the implication of our result to the related Feedback Vertex Set\nproblem, and give a different hardness proof for directed graphs.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2015 22:55:06 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Guruswami", "Venkatesan", ""], ["Lee", "Euiwoong", ""]]}, {"id": "1506.06399", "submitter": "Swagato Sanyal", "authors": "Sagnik Mukhopadhyay, Swagato Sanyal", "title": "Towards Better Separation between Deterministic and Randomized Query\n  Complexity", "comments": "Reference added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there exists a Boolean function $F$ which observes the following\nseparations among deterministic query complexity $(D(F))$, randomized zero\nerror query complexity $(R_0(F))$ and randomized one-sided error query\ncomplexity $(R_1(F))$: $R_1(F) = \\widetilde{O}(\\sqrt{D(F)})$ and\n$R_0(F)=\\widetilde{O}(D(F))^{3/4}$. This refutes the conjecture made by Saks\nand Wigderson that for any Boolean function $f$,\n$R_0(f)=\\Omega({D(f)})^{0.753..}$. This also shows widest separation between\n$R_1(f)$ and $D(f)$ for any Boolean function. The function $F$ was defined by\nG{\\\"{o}}{\\\"{o}}s, Pitassi and Watson who studied it for showing a separation\nbetween deterministic decision tree complexity and unambiguous\nnon-deterministic decision tree complexity. Independently of us, Ambainis et al\nproved that different variants of the function $F$ certify optimal (quadratic)\nseparation between $D(f)$ and $R_0(f)$, and polynomial separation between\n$R_0(f)$ and $R_1(f)$. Viewed as separation results, our results are subsumed\nby those of Ambainis et al. However, while the functions considerd in the work\nof Ambainis et al are different variants of $F$, we work with the original\nfunction $F$ itself.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2015 18:36:24 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2015 17:36:47 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Mukhopadhyay", "Sagnik", ""], ["Sanyal", "Swagato", ""]]}, {"id": "1506.06444", "submitter": "Vijay Bhattiprolu", "authors": "Vijay V. S. P. Bhattiprolu, Venkatesan Guruswami, Euiwoong Lee", "title": "Approximate Hypergraph Coloring under Low-discrepancy and Related\n  Promises", "comments": "Approx 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hypergraph is said to be $\\chi$-colorable if its vertices can be colored\nwith $\\chi$ colors so that no hyperedge is monochromatic. $2$-colorability is a\nfundamental property (called Property B) of hypergraphs and is extensively\nstudied in combinatorics. Algorithmically, however, given a $2$-colorable\n$k$-uniform hypergraph, it is NP-hard to find a $2$-coloring miscoloring fewer\nthan a fraction $2^{-k+1}$ of hyperedges (which is achieved by a random\n$2$-coloring), and the best algorithms to color the hypergraph properly require\n$\\approx n^{1-1/k}$ colors, approaching the trivial bound of $n$ as $k$\nincreases.\n  In this work, we study the complexity of approximate hypergraph coloring, for\nboth the maximization (finding a $2$-coloring with fewest miscolored edges) and\nminimization (finding a proper coloring using fewest number of colors)\nversions, when the input hypergraph is promised to have the following stronger\nproperties than $2$-colorability:\n  (A) Low-discrepancy: If the hypergraph has discrepancy $\\ell \\ll \\sqrt{k}$,\nwe give an algorithm to color the it with $\\approx n^{O(\\ell^2/k)}$ colors.\nHowever, for the maximization version, we prove NP-hardness of finding a\n$2$-coloring miscoloring a smaller than $2^{-O(k)}$ (resp. $k^{-O(k)}$)\nfraction of the hyperedges when $\\ell = O(\\log k)$ (resp. $\\ell=2$). Assuming\nthe UGC, we improve the latter hardness factor to $2^{-O(k)}$ for almost\ndiscrepancy-$1$ hypergraphs.\n  (B) Rainbow colorability: If the hypergraph has a $(k-\\ell)$-coloring such\nthat each hyperedge is polychromatic with all these colors, we give a\n$2$-coloring algorithm that miscolors at most $k^{-\\Omega(k)}$ of the\nhyperedges when $\\ell \\ll \\sqrt{k}$, and complement this with a matching UG\nhardness result showing that when $\\ell =\\sqrt{k}$, it is hard to even beat the\n$2^{-k+1}$ bound achieved by a random coloring.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 02:20:22 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Bhattiprolu", "Vijay V. S. P.", ""], ["Guruswami", "Venkatesan", ""], ["Lee", "Euiwoong", ""]]}, {"id": "1506.06456", "submitter": "Mario Szegedy", "authors": "Mario Szegedy", "title": "An $O(n^{0.4732})$ upper bound on the complexity of the GKS\n  communication game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an $5\\cdot n^{\\log_{30}5}$ upper bund on the complexity of the\ncommunication game introduced by G. Gilmer, M. Kouck\\'y and M. Saks \\cite{saks}\nto study the Sensitivity Conjecture \\cite{linial}, improving on their\n$\\sqrt{999\\over 1000}\\sqrt{n}$ bound. We also determine the exact complexity of\nthe game up to $n\\le 9$.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 03:57:07 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Szegedy", "Mario", ""]]}, {"id": "1506.06540", "submitter": "Rustem Takhanov", "authors": "Rustem Takhanov", "title": "Hybrid VCSPs with crisp and conservative valued templates", "comments": "21 pages. arXiv admin note: text overlap with arXiv:1504.07067", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A constraint satisfaction problem (CSP) is a problem of computing a\nhomomorphism ${\\bf R} \\rightarrow {\\bf \\Gamma}$ between two relational\nstructures. Analyzing its complexity has been a very fruitful research\ndirection, especially for fixed template CSPs, denoted $CSP({\\bf \\Gamma})$, in\nwhich the right side structure ${\\bf \\Gamma}$ is fixed and the left side\nstructure ${\\bf R}$ is unconstrained.\n  Recently, the hybrid setting, written $CSP_{\\mathcal{H}}({\\bf \\Gamma})$,\nwhere both sides are restricted simultaneously, attracted some attention. It\nassumes that ${\\bf R}$ is taken from a class of relational structures\n$\\mathcal{H}$ that additionally is closed under inverse homomorphisms. The last\nproperty allows to exploit algebraic tools that have been developed for fixed\ntemplate CSPs. The key concept that connects hybrid CSPs with fixed-template\nCSPs is the so called \"lifted language\". Namely, this is a constraint language\n${\\bf \\Gamma}_{{\\bf R}}$ that can be constructed from an input ${\\bf R}$. The\ntractability of that language for any input ${\\bf R}\\in\\mathcal{H}$ is a\nnecessary condition for the tractability of the hybrid problem.\n  In the first part we investigate templates ${\\bf \\Gamma}$ for which the\nlatter condition is not only necessary, but also is sufficient. We call such\ntemplates ${\\bf \\Gamma}$ widely tractable. For this purpose, we construct from\n${\\bf \\Gamma}$ a new finite relational structure ${\\bf \\Gamma}'$ and define\n$\\mathcal{H}_0$ as a class of structures homomorphic to ${\\bf \\Gamma}'$. We\nprove that wide tractability is equivalent to the tractability of\n$CSP_{\\mathcal{H}_0}({\\bf \\Gamma})$. Our proof is based on the key observation\nthat ${\\bf R}$ is homomorphic to ${\\bf \\Gamma}'$ if and only if the core of\n${\\bf \\Gamma}_{{\\bf R}}$ is preserved by a Siggers polymorphism. Analogous\nresult is shown for valued conservative CSPs.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 10:29:46 GMT"}, {"version": "v2", "created": "Thu, 21 Apr 2016 13:56:47 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 11:22:07 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Takhanov", "Rustem", ""]]}, {"id": "1506.06564", "submitter": "Matthew Johnson", "authors": "Konrad K. Dabrowski, Francois Dross, Matthew Johnson, Daniel Paulusma", "title": "Filling the Complexity Gaps for Colouring Planar and Bounded Degree\n  Graphs", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A colouring of a graph $G=(V,E)$ is a function $c: V\\rightarrow\\{1,2,\\ldots\n\\}$ such that $c(u)\\neq c(v)$ for every $uv\\in E$. A $k$-regular list\nassignment of $G$ is a function $L$ with domain $V$ such that for every $u\\in\nV$, $L(u)$ is a subset of $\\{1, 2, \\dots\\}$ of size $k$. A colouring $c$ of $G$\nrespects a $k$-regular list assignment $L$ of $G$ if $c(u)\\in L(u)$ for every\n$u\\in V$. A graph $G$ is $k$-choosable if for every $k$-regular list assignment\n$L$ of $G$, there exists a colouring of $G$ that respects $L$. We may also ask\nif for a given $k$-regular list assignment $L$ of a given graph $G$, there\nexists a colouring of $G$ that respects $L$. This yields the $k$-Regular List\nColouring problem. For $k\\in \\{3,4\\}$ we determine a family of classes ${\\cal\nG}$ of planar graphs, such that either $k$-Regular List Colouring is\nNP-complete for instances $(G,L)$ with $G\\in {\\cal G}$, or every $G\\in {\\cal\nG}$ is $k$-choosable. By using known examples of non-$3$-choosable and\nnon-$4$-choosable graphs, this enables us to classify the complexity of\n$k$-Regular List Colouring restricted to planar graphs, planar bipartite\ngraphs, planar triangle-free graphs and to planar graphs with no $4$-cycles and\nno $5$-cycles. We also classify the complexity of $k$-Regular List Colouring\nand a number of related colouring problems for graphs with bounded maximum\ndegree.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 12:09:25 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2015 19:57:31 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2015 04:24:48 GMT"}, {"version": "v4", "created": "Thu, 14 Sep 2017 17:09:10 GMT"}, {"version": "v5", "created": "Thu, 7 Feb 2019 09:06:06 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Dabrowski", "Konrad K.", ""], ["Dross", "Francois", ""], ["Johnson", "Matthew", ""], ["Paulusma", "Daniel", ""]]}, {"id": "1506.06633", "submitter": "Maciej  Skorski", "authors": "Maciej Skorski", "title": "A New Approximate Min-Max Theorem with Applications in Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel proof technique that can be applied to attack a broad\nclass of problems in computational complexity, when switching the order of\nuniversal and existential quantifiers is helpful. Our approach combines the\nstandard min-max theorem and convex approximation techniques, offering\nquantitative improvements over the standard way of using min-max theorems as\nwell as more concise and elegant proofs.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 14:39:05 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "1506.07002", "submitter": "C\\'ecilia Lancien", "authors": "C\\'ecilia Lancien, Andreas Winter", "title": "Parallel repetition and concentration for (sub-)no-signalling games via\n  a flexible constrained de Finetti reduction", "comments": "19 pages, 1 figure", "journal-ref": "Chicago Journal of Theoretical Computer Science, Vol. 2016, No. 11\n  (2016)", "doi": "10.4086/cjtcs.2016.011", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a recently discovered constrained de Finetti reduction (aka\n\"Post-Selection Lemma\") to study the parallel repetition of multi-player\nnon-local games under no-signalling strategies. Since the technique allows us\nto reduce general strategies to independent plays, we obtain parallel\nrepetition (corresponding to winning all rounds) in the same way as exponential\nconcentration of the probability to win a fraction larger than the value of the\ngame.\n  Our proof technique leads us naturally to a relaxation of no-signalling (NS)\nstrategies, which we dub sub-no-signalling (SNOS). While for two players the\ntwo concepts coincide, they differ for three or more players. Our results are\nmost complete and satisfying for arbitrary number of sub-no-signalling players,\nwhere we get universal parallel repetition and concentration for any game,\nwhile the no-signalling case is obtained as a corollary, but only for games\nwith \"full support\".\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 13:56:31 GMT"}, {"version": "v2", "created": "Sat, 1 Oct 2016 10:27:13 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Lancien", "C\u00e9cilia", ""], ["Winter", "Andreas", ""]]}, {"id": "1506.07080", "submitter": "Laura Man\\v{c}inska", "authors": "Laura Man\\v{c}inska", "title": "Maximally entangled states in pseudo-telepathy games", "comments": "In addition to the published material this version contains results\n  on self testing", "journal-ref": "Computing with New Resources, vol. 8808 of LNCS, pages 200--207,\n  2014", "doi": null, "report-no": null, "categories": "quant-ph cs.CC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pseudo-telepathy game is a nonlocal game which can be won with probability\none using some finite-dimensional quantum strategy but not using a classical\none. Our central question is whether there exist two-party pseudo-telepathy\ngames which cannot be won with probability one using a maximally entangled\nstate. Towards answering this question, we develop conditions under which\nmaximally entangled states suffice. In particular, we show that maximally\nentangled states suffice for weak projection games which we introduce as a\nrelaxation of projection games. Our results also imply that any\npseudo-telepathy weak projection game yields a device-independent certification\nof a maximally entangled state. In particular, by establishing connections to\nthe setting of communication complexity, we exhibit a class of games $G_n$ for\ntesting maximally entangled states of local dimension $\\Omega(n)$. We leave the\nrobustness of these self-tests as an open question.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 16:30:45 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Man\u010dinska", "Laura", ""]]}, {"id": "1506.07204", "submitter": "Oscar Temprano", "authors": "Oscar Temprano", "title": "Complexity of a Tetris variant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In this paper we are going to solve an open problem about the game tetris. We\nare going to give the first results in the complexity of a variant of offline\ntetris introduced by Erik Demaine, Susan Hohenberger and David Liben Nowell in\ntheir paper \"Tetris is hard, even to approximate\". In this variant, that\nfollows a model of movements introduced by John Brzustowsky, we can move and\nrotate a piece the number of times we want in the first row. But then, when we\nleft the piece fall, we cannot move it or rotate it anymore. We are going to\ndemonstrate that the problem of maximizing the number of cleared lines of this\nvariant on a particular game board, is NP-hard by reducing the 3-partition\nproblem to the problem of clearing the board in this variant of tetris\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 21:46:11 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Temprano", "Oscar", ""]]}, {"id": "1506.07216", "submitter": "Tengyu Ma", "authors": "Mark Braverman, Ankit Garg, Tengyu Ma, Huy L. Nguyen, and David P.\n  Woodruff", "title": "Communication Lower Bounds for Statistical Estimation Problems via a\n  Distributed Data Processing Inequality", "comments": "To appear at STOC 2016. Fixed typos in theorem 4.5 and incorporated\n  reviewers' suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the tradeoff between the statistical error and communication cost of\ndistributed statistical estimation problems in high dimensions. In the\ndistributed sparse Gaussian mean estimation problem, each of the $m$ machines\nreceives $n$ data points from a $d$-dimensional Gaussian distribution with\nunknown mean $\\theta$ which is promised to be $k$-sparse. The machines\ncommunicate by message passing and aim to estimate the mean $\\theta$. We\nprovide a tight (up to logarithmic factors) tradeoff between the estimation\nerror and the number of bits communicated between the machines. This directly\nleads to a lower bound for the distributed \\textit{sparse linear regression}\nproblem: to achieve the statistical minimax error, the total communication is\nat least $\\Omega(\\min\\{n,d\\}m)$, where $n$ is the number of observations that\neach machine receives and $d$ is the ambient dimension. These lower results\nimprove upon [Sha14,SD'14] by allowing multi-round iterative communication\nmodel. We also give the first optimal simultaneous protocol in the dense case\nfor mean estimation.\n  As our main technique, we prove a \\textit{distributed data processing\ninequality}, as a generalization of usual data processing inequalities, which\nmight be of independent interest and useful for other problems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 01:01:41 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2015 23:37:03 GMT"}, {"version": "v3", "created": "Tue, 10 May 2016 00:58:29 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Braverman", "Mark", ""], ["Garg", "Ankit", ""], ["Ma", "Tengyu", ""], ["Nguyen", "Huy L.", ""], ["Woodruff", "David P.", ""]]}, {"id": "1506.07234", "submitter": "Yaoqing Yang", "authors": "Yaoqing Yang, Pulkit Grover and Soummya Kar", "title": "Computing Linear Transformations with Unreliable Components", "comments": "Accepted by Transactions on Information Theory for future publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing a binary linear transformation using\nunreliable components when all circuit components are unreliable. Two noise\nmodels of unreliable components are considered: probabilistic errors and\npermanent errors. We introduce the \"ENCODED\" technique that ensures that the\nerror probability of the computation of the linear transformation is kept\nbounded below a small constant independent of the size of the linear\ntransformation even when all logic gates in the computation are noisy. Further,\nwe show that the scheme requires fewer operations (in order sense) than its\n\"uncoded\" counterpart. By deriving a lower bound, we show that in some cases,\nthe scheme is order-optimal. Using these results, we examine the gain in\nenergy-efficiency from use of \"voltage-scaling\" scheme where gate-energy is\nreduced by lowering the supply voltage. We use a gate energy-reliability model\nto show that tuning gate-energy appropriately at different stages of the\ncomputation (\"dynamic\" voltage scaling), in conjunction with ENCODED, can lead\nto order-sense energy-savings over the classical \"uncoded\" approach. Finally,\nwe also examine the problem of computing a linear transformation when noiseless\ndecoders can be used, providing upper and lower bounds to the problem.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 04:03:13 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 17:34:29 GMT"}, {"version": "v3", "created": "Sat, 13 May 2017 19:53:53 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Yang", "Yaoqing", ""], ["Grover", "Pulkit", ""], ["Kar", "Soummya", ""]]}, {"id": "1506.07260", "submitter": "Henning Fernau", "authors": "Cristina Bazgan and Ljiljana Brankovic and Katrin Casel and Henning\n  Fernau and Klaus Jansen and Michael Lampis and Mathieu Liedloff and\n  J\\'er\\^ome Monnot and Vangelis Th. Paschos", "title": "Algorithmic Aspects of Upper Domination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study combinatorial and algorithmic resp. complexity\nquestions of upper domination, i.e., the maximum cardinality of a minimal\ndominating set in a graph. We give a full classification of the related\nmaximisation and minimisation problems, as well as the related parameterised\nproblems, on general graphs and on graphs of bounded degree, and we also study\nplanar graphs.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 07:19:16 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Bazgan", "Cristina", ""], ["Brankovic", "Ljiljana", ""], ["Casel", "Katrin", ""], ["Fernau", "Henning", ""], ["Jansen", "Klaus", ""], ["Lampis", "Michael", ""], ["Liedloff", "Mathieu", ""], ["Monnot", "J\u00e9r\u00f4me", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "1506.07429", "submitter": "Laura Man\\v{c}inska", "authors": "Laura Man\\v{c}inska, David E. Roberson, Antonios Varvitsiotis", "title": "Deciding the existence of perfect entangled strategies for nonlocal\n  games", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First, we consider the problem of deciding whether a nonlocal game admits a\nperfect entangled strategy that uses projective measurements on a maximally\nentangled shared state. Via a polynomial-time Karp reduction, we show that\nindependent set games are the hardest instances of this problem. Secondly, we\nshow that if every independent set game whose entangled value is equal to one\nadmits a perfect entangled strategy, then the same holds for all symmetric\nsynchronous games. Finally, we identify combinatorial lower bounds on the\nclassical and entangled values of synchronous games in terms of variants of the\nindependence number of appropriate graphs. Our results suggest that independent\nset games might be representative of all nonlocal games when dealing with\nquestions concerning perfect entangled strategies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 15:41:54 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Man\u010dinska", "Laura", ""], ["Roberson", "David E.", ""], ["Varvitsiotis", "Antonios", ""]]}, {"id": "1506.07490", "submitter": "Noah Stephens-Davidowitz", "authors": "Noah Stephens-Davidowitz", "title": "Discrete Gaussian Sampling Reduces to CVP and SVP", "comments": "SODA 2016", "journal-ref": "SODA 2016", "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrete Gaussian $D_{L- t, s}$ is the distribution that assigns to each\nvector $x$ in a shifted lattice $L - t$ probability proportional to $e^{-\\pi\n\\|x\\|^2/s^2}$. It has long been an important tool in the study of lattices.\nMore recently, algorithms for discrete Gaussian sampling (DGS) have found many\napplications in computer science. In particular, polynomial-time algorithms for\nDGS with very high parameters $s$ have found many uses in cryptography and in\nreductions between lattice problems. And, in the past year, Aggarwal, Dadush,\nRegev, and Stephens-Davidowitz showed $2^{n+o(n)}$-time algorithms for DGS with\na much wider range of parameters and used them to obtain the current fastest\nknown algorithms for the two most important lattice problems, the Shortest\nVector Problem (SVP) and the Closest Vector Problem (CVP).\n  Motivated by its increasing importance, we investigate the complexity of DGS\nitself and its relationship to CVP and SVP. Our first result is a\npolynomial-time dimension-preserving reduction from DGS to CVP. There is a\nsimple reduction from CVP to DGS, so this shows that DGS is equivalent to CVP.\nOur second result, which we find to be more surprising, is a polynomial-time\ndimension-preserving reduction from centered DGS (the important special case\nwhen $ t = 0$) to SVP. In the other direction, there is a simple reduction from\n$\\gamma$-approximate SVP for any $\\gamma = \\Omega(\\sqrt{n/\\log n})$, and we\npresent some (relatively weak) evidence to suggest that this might be the best\nachievable approximation factor.\n  We also show that our CVP result extends to a much wider class of\ndistributions and even to other norms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 18:18:54 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 19:16:02 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2015 16:08:54 GMT"}, {"version": "v4", "created": "Tue, 19 Apr 2016 19:11:11 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Stephens-Davidowitz", "Noah", ""]]}, {"id": "1506.07675", "submitter": "Alexandru I. Tomescu", "authors": "Ademir Hujdurovi\\'c, Ur\\v{s}a Ka\\v{c}ar, Martin Milani\\v{c}, Bernard\n  Ries, Alexandru I. Tomescu", "title": "Complexity and algorithms for finding a perfect phylogeny from mixed\n  tumor samples", "comments": "This is the extended version of Hujdurovi\\'c et al, Finding a perfect\n  phylogeny from mixed tumor samples, WABI 2015, DOI:\n  10.1007/978-3-662-48221-6_6", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Hajirasouliha and Raphael (WABI 2014) proposed a model for\ndeconvoluting mixed tumor samples measured from a collection of high-throughput\nsequencing reads. This is related to understanding tumor evolution and critical\ncancer mutations. In short, their formulation asks to split each row of a\nbinary matrix so that the resulting matrix corresponds to a perfect phylogeny\nand has the minimum number of rows among all matrices with this property. In\nthis paper we disprove several claims about this problem, including an\nNP-hardness proof of it. However, we show that the problem is indeed NP-hard,\nby providing a different proof. We also prove NP-completeness of a variant of\nthis problem proposed in the same paper. On the positive side, we propose an\nefficient (though not necessarily optimal) heuristic algorithm based on\ncoloring co-comparability graphs, and a polynomial time algorithm for solving\nthe problem optimally on matrix instances in which no column is contained in\nboth columns of a pair of conflicting columns. Implementations of these\nalgorithms are freely available at\nhttps://github.com/alexandrutomescu/MixedPerfectPhylogeny\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 09:33:04 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2015 19:59:08 GMT"}, {"version": "v3", "created": "Sun, 3 Jul 2016 19:56:45 GMT"}, {"version": "v4", "created": "Thu, 7 Jul 2016 22:42:11 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Hujdurovi\u0107", "Ademir", ""], ["Ka\u010dar", "Ur\u0161a", ""], ["Milani\u010d", "Martin", ""], ["Ries", "Bernard", ""], ["Tomescu", "Alexandru I.", ""]]}, {"id": "1506.07729", "submitter": "Bart M. P. Jansen", "authors": "Bart M. P. Jansen and Stefan Kratsch", "title": "A structural approach to kernels for ILPs: Treewidth and Total\n  Unimodularity", "comments": "Extended abstract in the Proceedings of the 23rd European Symposium\n  on Algorithms (ESA 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernelization is a theoretical formalization of efficient preprocessing for\nNP-hard problems. Empirically, preprocessing is highly successful in practice,\nfor example in state-of-the-art ILP-solvers like CPLEX. Motivated by this,\nprevious work studied the existence of kernelizations for ILP related problems,\ne.g., for testing feasibility of Ax <= b. In contrast to the observed success\nof CPLEX, however, the results were largely negative. Intuitively, practical\ninstances have far more useful structure than the worst-case instances used to\nprove these lower bounds.\n  In the present paper, we study the effect that subsystems with (Gaifman graph\nof) bounded treewidth or totally unimodularity have on the kernelizability of\nthe ILP feasibility problem. We show that, on the positive side, if these\nsubsystems have a small number of variables on which they interact with the\nremaining instance, then we can efficiently replace them by smaller subsystems\nof size polynomial in the domain without changing feasibility. Thus, if large\nparts of an instance consist of such subsystems, then this yields a substantial\nsize reduction. We complement this by proving that relaxations to the\nconsidered structures, e.g., larger boundaries of the subsystems, allow\nworst-case lower bounds against kernelization. Thus, these relaxed structures\ncan be used to build instance families that cannot be efficiently reduced, by\nany approach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 12:47:56 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Jansen", "Bart M. P.", ""], ["Kratsch", "Stefan", ""]]}, {"id": "1506.07773", "submitter": "Rogers Mathew", "authors": "Tushar Kalra, Rogers Mathew, Sudebkumar Prasant Pal, Vijay Pandey", "title": "Maximum weighted independent sets with a budget", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph $G$, a non-negative integer $k$, and a weight function that\nmaps each vertex in $G$ to a positive real number, the \\emph{Maximum Weighted\nBudgeted Independent Set (MWBIS) problem} is about finding a maximum weighted\nindependent set in $G$ of cardinality at most $k$. A special case of MWBIS,\nwhen the weight assigned to each vertex is equal to its degree in $G$, is\ncalled the \\emph{Maximum Independent Vertex Coverage (MIVC)} problem. In other\nwords, the MIVC problem is about finding an independent set of cardinality at\nmost $k$ with maximum coverage.\n  Since it is a generalization of the well-known Maximum Weighted Independent\nSet (MWIS) problem, MWBIS too does not have any constant factor polynomial time\napproximation algorithm assuming $P \\neq NP$. In this paper, we study MWBIS in\nthe context of bipartite graphs. We show that, unlike MWIS, the MIVC (and\nthereby the MWBIS) problem in bipartite graphs is NP-hard. Then, we show that\nthe MWBIS problem admits a $\\frac{1}{2}$-factor approximation algorithm in the\nclass of bipartite graphs, which matches the integrality gap of a natural LP\nrelaxation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 14:45:30 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2015 15:39:28 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Kalra", "Tushar", ""], ["Mathew", "Rogers", ""], ["Pal", "Sudebkumar Prasant", ""], ["Pandey", "Vijay", ""]]}, {"id": "1506.07810", "submitter": "Michael Elberfeld", "authors": "Michael Elberfeld and Pascal Schweitzer", "title": "Canonizing Graphs of Bounded Tree Width in Logspace", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph canonization is the problem of computing a unique representative, a\ncanon, from the isomorphism class of a given graph. This implies that two\ngraphs are isomorphic exactly if their canons are equal. We show that graphs of\nbounded tree width can be canonized by logarithmic-space (logspace) algorithms.\nThis implies that the isomorphism problem for graphs of bounded tree width can\nbe decided in logspace. In the light of isomorphism for trees being hard for\nthe complexity class logspace, this makes the ubiquitous class of graphs of\nbounded tree width one of the few classes of graphs for which the complexity of\nthe isomorphism problem has been exactly determined.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 16:45:48 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Elberfeld", "Michael", ""], ["Schweitzer", "Pascal", ""]]}, {"id": "1506.07905", "submitter": "Luk\\'a\\v{s} Folwarczn\\'y", "authors": "Luk\\'a\\v{s} Folwarczn\\'y and Ji\\v{r}\\'i Sgall", "title": "General Caching Is Hard: Even with Small Pages", "comments": "19 pages, 8 figures, an extended abstract appeared in the proceedings\n  of MAPSP 2015 (www.mapsp2015.com), a conference version has been submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caching (also known as paging) is a classical problem concerning page\nreplacement policies in two-level memory systems. General caching is the\nvariant with pages of different sizes and fault costs. We give the first\nNP-hardness result for general caching with small pages: General caching is\n(strongly) NP-hard even when page sizes are limited to {1, 2, 3}. It holds\nalready in the fault model (each page has unit fault cost) as well as in the\nbit model (each page has the same fault cost as size). We also give a very\nshort proof of the strong NP-hardness of general caching with page sizes\nrestricted to {1, 2, 3} and arbitrary costs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 21:45:48 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Folwarczn\u00fd", "Luk\u00e1\u0161", ""], ["Sgall", "Ji\u0159\u00ed", ""]]}, {"id": "1506.08106", "submitter": "Shalev Ben-David", "authors": "Shalev Ben-David", "title": "A Super-Grover Separation Between Randomized and Quantum Query\n  Complexities", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a total Boolean function $f$ satisfying\n$R(f)=\\tilde{\\Omega}(Q(f)^{5/2})$, refuting the long-standing conjecture that\n$R(f)=O(Q(f)^2)$ for all total Boolean functions. Assuming a conjecture of\nAaronson and Ambainis about optimal quantum speedups for partial functions, we\nimprove this to $R(f)=\\tilde{\\Omega}(Q(f)^3)$. Our construction is motivated by\nthe G\\\"o\\\"os-Pitassi-Watson function but does not use it.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 15:03:56 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Ben-David", "Shalev", ""]]}, {"id": "1506.08311", "submitter": "Hans Raj Tiwary", "authors": "David Avis and Hans Raj Tiwary", "title": "On the H-Free Extension Complexity of the TSP", "comments": "Minor revisions; 9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the extension complexity of the TSP polytope for the\ncomplete graph $K_n$ is exponential in $n$ even if the subtour inequalities are\nexcluded. In this article we study the polytopes formed by removing other\nsubsets $\\mathcal{H}$ of facet-defining inequalities of the TSP polytope. In\nparticular, we consider the case when $\\mathcal{H}$ is either the set of\nblossom inequalities or the simple comb inequalities. These inequalities are\nroutinely used in cutting plane algorithms for the TSP. We show that the\nextension complexity remains exponential even if we exclude these inequalities.\nIn addition we show that the extension complexity of polytope formed by all\ncomb inequalities is exponential. For our proofs, we introduce a subclass of\ncomb inequalities, called $(h,t)$-uniform inequalities, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2015 16:56:56 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2015 10:30:41 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Avis", "David", ""], ["Tiwary", "Hans Raj", ""]]}, {"id": "1506.08388", "submitter": "Luk\\'a\\v{s} Folwarczn\\'y", "authors": "Luk\\'a\\v{s} Folwarczn\\'y and Du\\v{s}an Knop", "title": "IV-matching is strongly NP-hard", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IV-matching is a generalization of perfect bipartite matching. The complexity\nof finding IV-matching in a graph was posted as an open problem at the ICALP\n2014 conference.\n  In this note, we resolve the question and prove that, contrary to the\nexpectations of the authors, the given problem is strongly NP-hard (already in\nthe simplest non-trivial case of four layers). Hence it is unlikely that there\nwould be an efficient (polynomial or pseudo-polynomial) algorithm solving the\nproblem.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 12:25:15 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Folwarczn\u00fd", "Luk\u00e1\u0161", ""], ["Knop", "Du\u0161an", ""]]}, {"id": "1506.08409", "submitter": "Erik Demaine", "authors": "Erik D. Demaine and Stefan Langerman", "title": "Bust-a-Move/Puzzle Bobble is NP-Complete", "comments": "9 pages, 9 figures. Corrected mistakes in gadgets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the classic 1994 Taito video game, known as Puzzle Bobble or\nBust-a-Move, is NP-complete. Our proof applies to the perfect-information\nversion where the bubble sequence is known in advance, and it uses just three\nbubble colors.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 14:51:37 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2015 19:23:16 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Demaine", "Erik D.", ""], ["Langerman", "Stefan", ""]]}]