[{"id": "1112.0217", "submitter": "Bernd G\\\"artner", "authors": "Bernd G\\\"artner, Markus Sprecher", "title": "A Polynomial-Time Algorithm for the Tridiagonal and Hessenberg P-Matrix\n  Linear Complementarity Problem", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a polynomial-time dynamic programming algorithm for solving the\nlinear complementarity problem with tridiagonal or, more generally, Hessenberg\nP-matrices. We briefly review three known tractable matrix classes and show\nthat none of them contains all tridiagonal P-matrices.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2011 15:53:50 GMT"}], "update_date": "2011-12-02", "authors_parsed": [["G\u00e4rtner", "Bernd", ""], ["Sprecher", "Markus", ""]]}, {"id": "1112.0520", "submitter": "Bin Fu", "authors": "Bin Fu", "title": "On the Complexity of Approximate Sum of Sorted List", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the complexity for computing the approximate sum\n$a_1+a_2+...+a_n$ of a sorted list of numbers $a_1\\le a_2\\le ...\\le a_n$. We\nshow an algorithm that computes an $(1+\\epsilon)$-approximation for the sum of\na sorted list of nonnegative numbers in an $O({1\\over \\epsilon}\\min(\\log n,\n{\\log ({x_{max}\\over x_{min}})})\\cdot (\\log {1\\over \\epsilon}+\\log\\log n))$\ntime, where $x_{max}$ and $x_{min}$ are the largest and the least positive\nelements of the input list, respectively. We prove a lower bound\n$\\Omega(\\min(\\log n,\\log ({x_{max}\\over x_{min}}))$ time for every\nO(1)-approximation algorithm for the sum of a sorted list of nonnegative\nelements. We also show that there is no sublinear time approximation algorithm\nfor the sum of a sorted list that contains at least one negative number.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2011 17:50:10 GMT"}, {"version": "v2", "created": "Sun, 18 Dec 2011 20:22:51 GMT"}, {"version": "v3", "created": "Mon, 16 Jan 2012 21:08:54 GMT"}, {"version": "v4", "created": "Sat, 21 Jan 2012 21:58:00 GMT"}], "update_date": "2012-01-24", "authors_parsed": [["Fu", "Bin", ""]]}, {"id": "1112.0548", "submitter": "Robin Kothari", "authors": "Andrew M. Childs, Shelby Kimmel and Robin Kothari", "title": "The quantum query complexity of read-many formulas", "comments": "15 pages", "journal-ref": "Lecture Notes in Computer Science 7501, pp. 337-348 (2012)", "doi": "10.1007/978-3-642-33090-2_30", "report-no": "MIT-CTP 4330", "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantum query complexity of evaluating any read-once formula with n\nblack-box input bits is Theta(sqrt(n)). However, the corresponding problem for\nread-many formulas (i.e., formulas in which the inputs have fanout) is not well\nunderstood. Although the optimal read-once formula evaluation algorithm can be\napplied to any formula, it can be suboptimal if the inputs have large fanout.\nWe give an algorithm for evaluating any formula with n inputs, size S, and G\ngates using O(min{n, sqrt{S}, n^{1/2} G^{1/4}}) quantum queries. Furthermore,\nwe show that this algorithm is optimal, since for any n,S,G there exists a\nformula with n inputs, size at most S, and at most G gates that requires\nOmega(min{n, sqrt{S}, n^{1/2} G^{1/4}}) queries. We also show that the\nalgorithm remains nearly optimal for circuits of any particular depth k >= 3,\nand we give a linear-size circuit of depth 2 that requires Omega (n^{5/9})\nqueries. Applications of these results include a Omega (n^{19/18}) lower bound\nfor Boolean matrix product verification, a nearly tight characterization of the\nquantum query complexity of evaluating constant-depth circuits with bounded\nfanout, new formula gate count lower bounds for several functions including\nPARITY, and a construction of an AC^0 circuit of linear size that can only be\nevaluated by a formula with Omega(n^{2-epsilon}) gates.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2011 19:56:16 GMT"}], "update_date": "2012-09-06", "authors_parsed": [["Childs", "Andrew M.", ""], ["Kimmel", "Shelby", ""], ["Kothari", "Robin", ""]]}, {"id": "1112.0699", "submitter": "Lee-Ad Gottlieb", "authors": "Yair Bartal, Lee-Ad Gottlieb, Robert Krauthgamer", "title": "The Traveling Salesman Problem: Low-Dimensionality Implies a Polynomial\n  Time Approximation Scheme", "comments": null, "journal-ref": null, "doi": "10.1137/130913328", "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Traveling Salesman Problem (TSP) is among the most famous NP-hard\noptimization problems. We design for this problem a randomized polynomial-time\nalgorithm that computes a (1+eps)-approximation to the optimal tour, for any\nfixed eps>0, in TSP instances that form an arbitrary metric space with bounded\nintrinsic dimension.\n  The celebrated results of Arora (A-98) and Mitchell (M-99) prove that the\nabove result holds in the special case of TSP in a fixed-dimensional Euclidean\nspace. Thus, our algorithm demonstrates that the algorithmic tractability of\nmetric TSP depends on the dimensionality of the space and not on its specific\ngeometry. This result resolves a problem that has been open since the\nquasi-polynomial time algorithm of Talwar (T-04).\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2011 22:58:13 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2015 12:56:30 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Bartal", "Yair", ""], ["Gottlieb", "Lee-Ad", ""], ["Krauthgamer", "Robert", ""]]}, {"id": "1112.0741", "submitter": "Amir Ali Ahmadi", "authors": "Amir Ali Ahmadi", "title": "On the Difficulty of Deciding Asymptotic Stability of Cubic Homogeneous\n  Vector Fields", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that asymptotic stability (AS) of homogeneous polynomial\nvector fields of degree one (i.e., linear systems) can be decided in polynomial\ntime e.g. by searching for a quadratic Lyapunov function. Since homogeneous\nvector fields of even degree can never be AS, the next interesting degree to\nconsider is equal to three. In this paper, we prove that deciding AS of\nhomogeneous cubic vector fields is strongly NP-hard and pose the question of\ndetermining whether it is even decidable. As a byproduct of the reduction that\nestablishes our NP-hardness result, we obtain a Lyapunov-inspired technique for\nproving positivity of forms. We also show that for asymptotically stable\nhomogeneous cubic vector fields in as few as two variables, the minimum degree\nof a polynomial Lyapunov function can be arbitrarily large. Finally, we show\nthat there is no monotonicity in the degree of polynomial Lyapunov functions\nthat prove AS; i.e., a homogeneous cubic vector field with no homogeneous\npolynomial Lyapunov function of some degree $d$ can very well have a\nhomogeneous polynomial Lyapunov function of degree less than $d$.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2011 10:38:01 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Ahmadi", "Amir Ali", ""]]}, {"id": "1112.0845", "submitter": "Greg Kuperberg", "authors": "Greg Kuperberg (UC Davis)", "title": "Knottedness is in NP, modulo GRH", "comments": "7 pages; minor update", "journal-ref": "Adv. Math. 256 (2014), 493-506", "doi": null, "report-no": null, "categories": "math.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a tame knot K presented in the form of a knot diagram, we show that the\nproblem of determining whether K is knotted is in the complexity class NP,\nassuming the generalized Riemann hypothesis (GRH). In other words, there exists\na polynomial-length certificate that can be verified in polynomial time to\nprove that K is non-trivial. GRH is not needed to believe the certificate, but\nonly to find a short certificate. This result complements the result of Hass,\nLagarias, and Pippenger that unknottedness is in NP. Our proof is a corollary\nof major results of others in algebraic geometry and geometric topology.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 06:44:28 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2014 02:52:52 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Kuperberg", "Greg", "", "UC Davis"]]}, {"id": "1112.0987", "submitter": "Koji Kobayashi", "authors": "Koji Kobayashi", "title": "Small Jump with Negation-UTM Trampoline", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper divide some complexity class by using fixpoint and fixpointless\narea of Decidable Universal Turing Machine (UTM). Decidable Deterministic\nTuring Machine (DTM) have fixpointless combinator that add no extra resources\n(like Negation), but UTM makes some fixpoint in the combinator. This means that\nwe can jump out of the fixpointless combinator system by making more complex\nproblem from diagonalisation argument of UTM.\n  As a concrete example, we proof L is not P . We can make Polynomial time UTM\nthat emulate all Logarithm space DTM (LDTM). LDTM set close under Negation,\ntherefore UTM does not close under LDTM set. (We can proof this theorem like\nhalting problem and time/space hierarchy theorem, and also we can extend this\nproof to divide time/space limited DTM set.) In the same way, we proof P is not\nNP. These are new hierarchy that use UTM and Negation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 16:45:26 GMT"}, {"version": "v10", "created": "Sun, 11 May 2014 12:47:51 GMT"}, {"version": "v11", "created": "Wed, 25 Jun 2014 16:46:38 GMT"}, {"version": "v12", "created": "Sun, 3 Aug 2014 16:43:55 GMT"}, {"version": "v13", "created": "Thu, 4 Sep 2014 16:32:59 GMT"}, {"version": "v14", "created": "Sun, 7 Sep 2014 11:31:28 GMT"}, {"version": "v15", "created": "Wed, 10 Sep 2014 14:52:23 GMT"}, {"version": "v16", "created": "Wed, 8 Oct 2014 16:36:24 GMT"}, {"version": "v17", "created": "Sat, 11 Oct 2014 12:13:19 GMT"}, {"version": "v2", "created": "Sun, 11 Dec 2011 14:47:27 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2013 16:05:16 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2013 15:57:04 GMT"}, {"version": "v5", "created": "Tue, 28 Jan 2014 17:40:49 GMT"}, {"version": "v6", "created": "Tue, 1 Apr 2014 14:54:06 GMT"}, {"version": "v7", "created": "Tue, 8 Apr 2014 12:22:35 GMT"}, {"version": "v8", "created": "Thu, 1 May 2014 17:59:13 GMT"}, {"version": "v9", "created": "Thu, 8 May 2014 17:43:18 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Kobayashi", "Koji", ""]]}, {"id": "1112.1040", "submitter": "Iyad Kanj", "authors": "Iyad Kanj and Ge Xia", "title": "What makes normalized weighted satisfiability tractable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the weighted antimonotone and the weighted monotone\nsatisfiability problems on normalized circuits of depth at most $t \\geq 2$,\nabbreviated {\\sc wsat$^-[t]$} and {\\sc wsat$^+[t]$}, respectively. These\nproblems model the weighted satisfiability of antimonotone and monotone\npropositional formulas (including weighted anitmonoone/monotone {\\sc cnf-sat})\nin a natural way, and serve as the canonical problems in the definition of the\nparameterized complexity hierarchy. We characterize the parameterized\ncomplexity of {\\sc wsat$^-[t]$} and {\\sc wsat$^+[t]$} with respect to the genus\nof the circuit. For {\\sc wsat$^-[t]$}, which is $W[t]$-complete for odd $t$ and\n$W[t-1]$-complete for even $t$, the characterization is precise: We show that\n{\\sc wsat$^-[t]$} is fixed-parameter tractable (FPT) if the genus of the\ncircuit is $n^{o(1)}$ ($n$ is the number of the variables in the circuit), and\nthat it has the same $W$-hardness as the general {\\sc wsat$^-[t]$} problem\n(i.e., with no restriction on the genus) if the genus is $n^{O(1)}$. For {\\sc\nwsat$^+[2]$} (i.e., weighted monotone {\\sc cnf-sat}), which is $W[2]$-complete,\nthe characterization is also precise: We show that {\\sc wsat$^+[2]$} is FPT if\nthe genus is $n^{o(1)}$ and $W[2]$-complete if the genus is $n^{O(1)}$. For\n{\\sc wsat$^+[t]$} where $t > 2$, which is $W[t]$-complete for even $t$ and\n$W[t-1]$-complete for odd $t$, we show that it is FPT if the genus is\n$O(\\sqrt{\\log{n}})$, and that it has the same $W$-hardness as the general {\\sc\nwsat$^+[t]$} problem if the genus is $n^{O(1)}$.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 19:56:11 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Kanj", "Iyad", ""], ["Xia", "Ge", ""]]}, {"id": "1112.1045", "submitter": "Xin Li", "authors": "Xin Li", "title": "Non-Malleable Extractors, Two-Source Extractors and Privacy\n  Amplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dodis and Wichs introduced the notion of a non-malleable extractor to study\nthe problem of privacy amplification with an active adversary. A non-malleable\nextractor is a much stronger version of a strong extractor. Previously, there\nare only two known constructions of non-malleable extractors. Both\nconstructions only work for (n, k)-sources with k>n/2. Interestingly, both\nconstructions are also two-source extractors.\n  In this paper, we present a strong connection between non-malleable\nextractors and two-source extractors. The first part of the connection shows\nthat non-malleable extractors can be used to construct two-source extractors.\nWith appropriate parameters the resulted two-source extractor beats the best\nknown construction of two-source extractors. This partially explains why\nprevious constructions of non-malleable extractors only work for sources with\nentropy rate >1/2, and why explicit non-malleable extractors for small\nmin-entropy may be hard to get. The second part of the connection shows that\ncertain two-source extractors can be used to construct non-malleable\nextractors. Using this connection, we obtain the first construction of\nnon-malleable extractors for k < n/2. Specifically, we give an unconditional\nconstruction for min-entropy k=(1/2-\\delta)n for some constant \\delta>0, and a\nconditional (semi-explicit) construction that can potentially achieve k=\\alpha\nn for any constant \\alpha>0.\n  Finally, despite the lack of explicit non-malleable extractors for\narbitrarily linear entropy, we give the first 2-round privacy amplification\nprotocol with asymptotically optimal entropy loss and communication complexity\nfor (n, k) sources with k=\\alpha n for any constant \\alpha>0. This dramatically\nimproves previous results and answers an open problem in \\cite{DLWZ11}.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2011 20:07:10 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2012 06:21:32 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Li", "Xin", ""]]}, {"id": "1112.1308", "submitter": "Alexey Pospelov", "authors": "Markus Bl\\\"aser, Jean-S\\'ebastien Coron, Alexey Pospelov", "title": "Small Private Circuits", "comments": "Withdrawing while fixing a flaw in the proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ishai, Sahai, and Wagner initiated in 2003 the theoretical study of securing\na circuit against an adversary who can probe its wires. They presented a\nuniversal way of transforming an arbitrary boolean circuit of size s into a\ncircuit of size linear in s and quadratic in t, with perfect security against\nan adversary who can read up to t wires of the circuit. We present a new method\nfor securing circuits against such an adversary with circuit size linear in s\nand polylogarithmic in t, while meeting the original privacy requirements from\nIshai et al.\n  Our solution works for arithmetic circuits over arbitrary fields of positive\ncharacteristic. The improvement from quadratic to quasilinear complexity (in t)\ncomes from using the DFT instead of naive multiplication.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2011 15:15:37 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2012 21:19:37 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Bl\u00e4ser", "Markus", ""], ["Coron", "Jean-S\u00e9bastien", ""], ["Pospelov", "Alexey", ""]]}, {"id": "1112.1564", "submitter": "Chandan K. Dubey", "authors": "Divesh Aggarwal, Chandan Dubey", "title": "Improved hardness results for unique shortest vector problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give several improvements on the known hardness of the unique shortest\nvector problem. - We give a deterministic reduction from the shortest vector\nproblem to the unique shortest vector problem. As a byproduct, we get\ndeterministic NP-hardness for unique shortest vector problem in the\n$\\ell_\\infty$ norm. - We give a randomized reduction from SAT to\nuSVP_{1+1/poly(n)}. This shows that uSVP_{1+1/poly(n)} is NP-hard under\nrandomized reductions. - We show that if GapSVP_\\gamma \\in coNP (or coAM) then\nuSVP_{\\sqrt{\\gamma}} \\in coNP (coAM respectively). This simplifies previously\nknown uSVP_{n^{1/4}} \\in coAM proof by Cai \\cite{Cai98} to uSVP_{(n/\\log\nn)^{1/4}} \\in coAM, and additionally generalizes it to uSVP_{n^{1/4}} \\in coNP.\n- We give a deterministic reduction from search-uSVP_\\gamma to the\ndecision-uSVP_{\\gamma/2}. We also show that the decision-uSVP is {\\bf NP}-hard\nfor randomized reductions, which does not follow from Kumar-Sivakumar\n\\cite{KS01}.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2011 13:58:29 GMT"}], "update_date": "2011-12-08", "authors_parsed": [["Aggarwal", "Divesh", ""], ["Dubey", "Chandan", ""]]}, {"id": "1112.1994", "submitter": "Elena Grigorescu", "authors": "Elena Grigorescu, Chris Peikert", "title": "List Decoding Barnes-Wall Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of list decoding error-correcting codes over finite fields\n(under the Hamming metric) has been widely studied in recent years. Motivated\nby the similar discrete structure of linear codes and point lattices in R^N,\nand their many shared applications across complexity theory, cryptography, and\ncoding theory, we initiate the study of list decoding for lattices. Namely: for\na lattice L in R^N, given a target vector r in R^N and a distance parameter d,\noutput the set of all lattice points w in L that are within distance d of r.\n  In this work we focus on combinatorial and algorithmic questions related to\nlist decoding for the well-studied family of Barnes-Wall lattices. Our main\ncontributions are twofold:\n  1) We give tight (up to polynomials) combinatorial bounds on the worst-case\nlist size, showing it to be polynomial in the lattice dimension for any error\nradius bounded away from the lattice's minimum distance (in the Euclidean\nnorm).\n  2) Building on the unique decoding algorithm of Micciancio and Nicolosi (ISIT\n'08), we give a list-decoding algorithm that runs in time polynomial in the\nlattice dimension and worst-case list size, for any error radius. Moreover, our\nalgorithm is highly parallelizable, and with sufficiently many processors can\nrun in parallel time only poly-logarithmic in the lattice dimension.\n  In particular, our results imply a polynomial-time list-decoding algorithm\nfor any error radius bounded away from the minimum distance, thus beating a\ntypical barrier for error-correcting codes posed by the Johnson radius.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 01:12:47 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2012 03:01:11 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Grigorescu", "Elena", ""], ["Peikert", "Chris", ""]]}, {"id": "1112.2000", "submitter": "Omri Weinstein", "authors": "Mark Braverman and Omri Weinstein", "title": "A discrepancy lower bound for information complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides the first general technique for proving information lower\nbounds on two-party unbounded-rounds communication problems. We show that the\ndiscrepancy lower bound, which applies to randomized communication complexity,\nalso applies to information complexity. More precisely, if the discrepancy of a\ntwo-party function $f$ with respect to a distribution $\\mu$ is $Disc_\\mu f$,\nthen any two party randomized protocol computing $f$ must reveal at least\n$\\Omega(\\log (1/Disc_\\mu f))$ bits of information to the participants. As a\ncorollary, we obtain that any two-party protocol for computing a random\nfunction on $\\{0,1\\}^n\\times\\{0,1\\}^n$ must reveal $\\Omega(n)$ bits of\ninformation to the participants.\n  In addition, we prove that the discrepancy of the Greater-Than function is\n$\\Omega(1/\\sqrt{n})$, which provides an alternative proof to the recent proof\nof Viola \\cite{Viola11} of the $\\Omega(\\log n)$ lower bound on the\ncommunication complexity of this well-studied function and, combined with our\nmain result, proves the tight $\\Omega(\\log n)$ lower bound on its information\ncomplexity.\n  The proof of our main result develops a new simulation procedure that may be\nof an independent interest. In a very recent breakthrough work of Kerenidis et\nal. \\cite{kerenidis2012lower}, this simulation procedure was the main building\nblock for proving that almost all known lower bound techniques for\ncommunication complexity (and not just discrepancy) apply to information\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 02:02:56 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2012 22:58:29 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2012 15:03:24 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Braverman", "Mark", ""], ["Weinstein", "Omri", ""]]}, {"id": "1112.2012", "submitter": "Joshua Grochow", "authors": "Joshua A. Grochow", "title": "Lie algebra conjugacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.SC math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of matrix Lie algebra conjugacy. Lie algebras arise\ncentrally in areas as diverse as differential equations, particle physics,\ngroup theory, and the Mulmuley--Sohoni Geometric Complexity Theory program. A\nmatrix Lie algebra is a set L of matrices such that $A, B\\in L$ implies $AB -\nBA \\in L$. Two matrix Lie algebras are conjugate if there is an invertible\nmatrix $M$ such that $L_1 = M L_2 M^{-1}$.\n  We show that certain cases of Lie algebra conjugacy are equivalent to graph\nisomorphism. On the other hand, we give polynomial-time algorithms for other\ncases of Lie algebra conjugacy, which allow us to essentially derandomize a\nrecent result of Kayal on affine equivalence of polynomials. Affine equivalence\nis related to many complexity problems such as factoring integers, graph\nisomorphism, matrix multiplication, and permanent versus determinant.\n  Specifically, we show:\n  Abelian Lie algebra conjugacy is equivalent to the code equivalence problem,\nand hence is as hard as graph isomorphism.\n  Abelian Lie algebra conjugacy of $n \\times n$ matrices can be solved in\npoly(n) time when the Lie algebras have dimension O(1).\n  Semisimple Lie algebra conjugacy is equivalent to graph isomorphism. A Lie\nalgebra is semisimple if it is a direct sum of simple Lie algebras.\n  Semisimple Lie algebra conjugacy of $n \\times n$ matrices can be solved in\npolynomial time when the Lie algebras consist of only $O(\\log n)$ simple direct\nsummands.\n  Conjugacy of completely reducible Lie algebras---that is, a direct sum of an\nabelian and a semisimple Lie algebra---can be solved in polynomial time when\nthe abelian part has dimension O(1) and the semisimple part has $O(\\log n)$\nsimple direct summands.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 03:24:19 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Grochow", "Joshua A.", ""]]}, {"id": "1112.2127", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "Efficiency Theory: a Unifying Theory for Information, Computation and\n  Intelligence", "comments": null, "journal-ref": "Journal of Discrete Mathematical Sciences & Cryptography. Volume\n  16, Issue 4-5, pp. 259-277. 2013", "doi": "10.1080/09720529.2013.821361", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper serves as the first contribution towards the development of the\ntheory of efficiency: a unifying framework for the currently disjoint theories\nof information, complexity, communication and computation. Realizing the\ndefining nature of the brute force approach in the fundamental concepts in all\nof the above mentioned fields, the paper suggests using efficiency or\nimprovement over the brute force algorithm as a common unifying factor\nnecessary for the creation of a unified theory of information manipulation. By\ndefining such diverse terms as randomness, knowledge, intelligence and\ncomputability in terms of a common denominator we are able to bring together\ncontributions from Shannon, Levin, Kolmogorov, Solomonoff, Chaitin, Yao and\nmany others under a common umbrella of the efficiency theory.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2011 16:41:59 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "1112.2275", "submitter": "Saket Saurabh", "authors": "Marek Cygan and Holger Dell and Daniel Lokshtanov and Daniel Marx and\n  Jesper Nederlof and Yoshio Okamoto and Ramamohan Paturi and Saket Saurabh and\n  Magnus Wahlstrom", "title": "On Problems as Hard as CNFSAT", "comments": "25 pages, 1 figure", "journal-ref": "ACM Trans. Algorithms 12(3): 41:1-41:24 (2016)", "doi": "10.1145/2925416 10.1109/CCC.2012.36", "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of exact exponential time algorithms for NP-hard problems has\nthrived over the last decade. While exhaustive search remains asymptotically\nthe fastest known algorithm for some basic problems, difficult and non-trivial\nexponential time algorithms have been found for a myriad of problems, including\nGraph Coloring, Hamiltonian Path, Dominating Set and 3-CNF-Sat. In some\ninstances, improving these algorithms further seems to be out of reach. The\nCNF-Sat problem is the canonical example of a problem for which the trivial\nexhaustive search algorithm runs in time O(2^n), where n is the number of\nvariables in the input formula. While there exist non-trivial algorithms for\nCNF-Sat that run in time o(2^n), no algorithm was able to improve the growth\nrate 2 to a smaller constant, and hence it is natural to conjecture that 2 is\nthe optimal growth rate. The strong exponential time hypothesis (SETH) by\nImpagliazzo and Paturi [JCSS 2001] goes a little bit further and asserts that,\nfor every epsilon<1, there is a (large) integer k such that that k-CNF-Sat\ncannot be computed in time 2^{epsilon n}.\n  In this paper, we show that, for every epsilon < 1, the problems Hitting Set,\nSet Splitting, and NAE-Sat cannot be computed in time O(2^{epsilon n}) unless\nSETH fails. Here n is the number of elements or variables in the input. For\nthese problems, we actually get an equivalence to SETH in a certain sense. We\nconjecture that SETH implies a similar statement for Set Cover, and prove that,\nunder this assumption, the fastest known algorithms for Steinter Tree,\nConnected Vertex Cover, Set Partitioning, and the pseudo-polynomial time\nalgorithm for Subset Sum cannot be significantly improved. Finally, we justify\nour assumption about the hardness of Set Cover by showing that the parity of\nthe number of set covers cannot be computed in time O(2^{epsilon n}) for any\nepsilon<1 unless SETH fails.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2011 13:19:33 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2012 08:57:25 GMT"}, {"version": "v3", "created": "Thu, 27 Mar 2014 01:34:30 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Cygan", "Marek", ""], ["Dell", "Holger", ""], ["Lokshtanov", "Daniel", ""], ["Marx", "Daniel", ""], ["Nederlof", "Jesper", ""], ["Okamoto", "Yoshio", ""], ["Paturi", "Ramamohan", ""], ["Saurabh", "Saket", ""], ["Wahlstrom", "Magnus", ""]]}, {"id": "1112.2489", "submitter": "Peter Scheiblechner", "authors": "Peter Scheiblechner", "title": "Effective de Rham Cohomology - The Hypersurface Case", "comments": "6 pages, proof of Lemma 1 was unclear, main result now proved without\n  it; bound slightly changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an effective bound for the degrees of generators of the algebraic de\nRham cohomology of smooth affine hypersurfaces. In particular, we show that the\nde Rham cohomology H_dR^p(X) of a smooth hypersurface X of degree d in C^n can\nbe generated by differential forms of degree d^O(pn). This result is relevant\nfor the algorithmic computation of the cohomology, but is also motivated by\nquestions in the theory of ordinary differential equations related to the\ninfinitesimal Hilbert 16th problem.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 09:53:11 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2012 08:47:55 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2012 09:29:21 GMT"}], "update_date": "2012-03-14", "authors_parsed": [["Scheiblechner", "Peter", ""]]}, {"id": "1112.2495", "submitter": "Simon Perdrix", "authors": "Sylvain Gravier, J\\'er\\^ome Javelle, Mehdi Mhalla, Simon Perdrix", "title": "On Weak Odd Domination and Graph-based Quantum Secret Sharing", "comments": "Subsumes arXiv:1109.6181: Optimal accessing and non-accessing\n  structures for graph protocols", "journal-ref": "TCS Theoretical Computer Science 598, 129-137. 2015", "doi": "10.1016/j.tcs.2015.05.038", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A weak odd dominated (WOD) set in a graph is a subset B of vertices for which\nthere exists a distinct set of vertices C such that every vertex in B has an\nodd number of neighbors in C. We point out the connections of weak odd\ndomination with odd domination, [sigma,rho]-domination, and perfect codes. We\nintroduce bounds on \\kappa(G), the maximum size of WOD sets of a graph G, and\non \\kappa'(G), the minimum size of non WOD sets of G. Moreover, we prove that\nthe corresponding decision problems are NP-complete. The study of weak odd\ndomination is mainly motivated by the design of graph-based quantum secret\nsharing protocols: a graph G of order n corresponds to a secret sharing\nprotocol which threshold is \\kappa_Q(G) = max(\\kappa(G), n-\\kappa'(G)). These\ngraph-based protocols are very promising in terms of physical implementation,\nhowever all such graph-based protocols studied in the literature have\nquasi-unanimity thresholds (i.e. \\kappa_Q(G)=n-o(n) where n is the order of the\ngraph G underlying the protocol). In this paper, we show using probabilistic\nmethods, the existence of graphs with smaller \\kappa_Q (i.e. \\kappa_Q(G)<\n0.811n where n is the order of G). We also prove that deciding for a given\ngraph G whether \\kappa_Q(G)< k is NP-complete, which means that one cannot\nefficiently double check that a graph randomly generated has actually a\n\\kappa_Q smaller than 0.811n.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 10:16:19 GMT"}, {"version": "v2", "created": "Mon, 21 May 2012 14:54:10 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Gravier", "Sylvain", ""], ["Javelle", "J\u00e9r\u00f4me", ""], ["Mhalla", "Mehdi", ""], ["Perdrix", "Simon", ""]]}, {"id": "1112.2519", "submitter": "Ritesh Vispute", "authors": "Ritesh Vispute", "title": "Errors in Improved Polynomial Algorithm For 3 Sat Proposed By Narendra\n  Chaudhari", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are errors in the algorithm proposed by Narendra Chaudhari [2]\npurporting to solve the 3-sat problem in polynomial time. The present paper\npresent instances for which the algorithm outputs erroneous results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 12:10:47 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Vispute", "Ritesh", ""]]}, {"id": "1112.2795", "submitter": "Luke Mathieson", "authors": "Bernard Mans and Luke Mathieson", "title": "On the Treewidth of Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic graph theory is a novel, growing area that deals with graphs that\nchange over time and is of great utility in modelling modern wireless, mobile\nand dynamic environments. As a graph evolves, possibly arbitrarily, it is\nchallenging to identify the graph properties that can be preserved over time\nand understand their respective computability.\n  In this paper we are concerned with the treewidth of dynamic graphs. We focus\non metatheorems, which allow the generation of a series of results based on\ngeneral properties of classes of structures. In graph theory two major\nmetatheorems on treewidth provide complexity classifications by employing\nstructural graph measures and finite model theory. Courcelle's Theorem gives a\ngeneral tractability result for problems expressible in monadic second order\nlogic on graphs of bounded treewidth, and Frick & Grohe demonstrate a similar\nresult for first order logic and graphs of bounded local treewidth.\n  We extend these theorems by showing that dynamic graphs of bounded (local)\ntreewidth where the length of time over which the graph evolves and is observed\nis finite and bounded can be modelled in such a way that the (local) treewidth\nof the underlying graph is maintained. We show the application of these results\nto problems in dynamic graph theory and dynamic extensions to static problems.\nIn addition we demonstrate that certain widely used dynamic graph classes\nnaturally have bounded local treewidth.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 05:13:24 GMT"}, {"version": "v2", "created": "Fri, 25 May 2012 04:55:40 GMT"}], "update_date": "2012-05-28", "authors_parsed": [["Mans", "Bernard", ""], ["Mathieson", "Luke", ""]]}, {"id": "1112.2974", "submitter": "Barnaby Martin", "authors": "Florent Madelaine, Barnaby Martin and Juraj Stacho", "title": "Constraint Satisfaction with Counting Quantifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of constraint satisfaction problems (CSPs) in the\npresence of counting quantifiers, which may be seen as variants of CSPs in the\nmould of quantified CSPs (QCSPs). We show that a single counting quantifier\nstrictly between exists^1:=exists and exists^n:=forall (the domain being of\nsize n) already affords the maximal possible complexity of QCSPs (which have\nboth exists and forall), being Pspace-complete for a suitably chosen template.\nNext, we focus on the complexity of subsets of counting quantifiers on clique\nand cycle templates. For cycles we give a full trichotomy -- all such problems\nare in L, NP-complete or Pspace-complete. For cliques we come close to a\nsimilar trichotomy, but one case remains outstanding. Afterwards, we consider\nthe generalisation of CSPs in which we augment the extant quantifier\nexists^1:=exists with the quantifier exists^j (j not 1). Such a CSP is already\nNP-hard on non-bipartite graph templates. We explore the situation of this\ngeneralised CSP on bipartite templates, giving various conditions for both\ntractability and hardness -- culminating in a classification theorem for\ngeneral graphs. Finally, we use counting quantifiers to solve the complexity of\na concrete QCSP whose complexity was previously open.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 17:41:52 GMT"}], "update_date": "2011-12-14", "authors_parsed": [["Madelaine", "Florent", ""], ["Martin", "Barnaby", ""], ["Stacho", "Juraj", ""]]}, {"id": "1112.2993", "submitter": "Steven Heilman", "authors": "Steven Heilman, Aukosh Jagannath, Assaf Naor", "title": "Solution of the propeller conjecture in $\\mathbb{R}^3$", "comments": null, "journal-ref": "Discrete & Computational Geometry. 50 (2013), no. 2, 263-305", "doi": null, "report-no": null, "categories": "cs.CC math.FA math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that every measurable partition ${A_1,..., A_k}$ of\n$\\mathbb{R}^3$ satisfies $$\\sum_{i=1}^k||\\int_{A_i}\nxe^{-\\frac12||x||_2^2}dx||_2^2\\le 9\\pi^2.\\qquad(*)$$ Let ${P_1,P_2,P_3}$ be the\npartition of $\\mathbb{R}^2$ into $120^\\circ$ sectors centered at the origin.\nThe bound is sharp, with equality holding if $A_i=P_i\\times \\mathbb{R}$ for\n$i\\in {1,2,3}$ and $A_i=\\emptyset$ for $i\\in \\{4,...,k\\}$ (up to measure zero\ncorrections, orthogonal transformations and renumbering of the sets\n$\\{A_1,...,A_k\\}$). This settles positively the 3-dimensional Propeller\nConjecture of Khot and Naor (FOCS 2008). The proof of reduces the problem to a\nfinite set of numerical inequalities which are then verified with full rigor in\na computer-assisted fashion. The main consequence (and motivation) of $(*)$ is\ncomplexity-theoretic: the Unique Games hardness threshold of the Kernel\nClustering problem with $4 \\times 4$ centered and spherical hypothesis matrix\nequals $\\frac{2\\pi}{3}$.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 18:27:03 GMT"}, {"version": "v2", "created": "Sun, 6 Apr 2014 02:38:44 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Heilman", "Steven", ""], ["Jagannath", "Aukosh", ""], ["Naor", "Assaf", ""]]}, {"id": "1112.3244", "submitter": "Serge Gaspers", "authors": "Fedor V. Fomin, Serge Gaspers, Petr Golovach, Karol Suchan, Stefan\n  Szeider, Erik Jan van Leeuwen, Martin Vatshelle, Yngve Villanger", "title": "k-Gap Interval Graphs", "comments": "LATIN 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of a new parameterization of graph problems. In a\nmultiple interval representation of a graph, each vertex is associated to at\nleast one interval of the real line, with an edge between two vertices if and\nonly if an interval associated to one vertex has a nonempty intersection with\nan interval associated to the other vertex. A graph on n vertices is a k-gap\ninterval graph if it has a multiple interval representation with at most n+k\nintervals in total. In order to scale up the nice algorithmic properties of\ninterval graphs (where k=0), we parameterize graph problems by k, and find FPT\nalgorithms for several problems, including Feedback Vertex Set, Dominating Set,\nIndependent Set, Clique, Clique Cover, and Multiple Interval Transversal. The\nColoring problem turns out to be W[1]-hard and we design an XP algorithm for\nthe recognition problem.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2011 15:06:52 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2011 14:08:29 GMT"}], "update_date": "2011-12-19", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Gaspers", "Serge", ""], ["Golovach", "Petr", ""], ["Suchan", "Karol", ""], ["Szeider", "Stefan", ""], ["van Leeuwen", "Erik Jan", ""], ["Vatshelle", "Martin", ""], ["Villanger", "Yngve", ""]]}, {"id": "1112.3337", "submitter": "Andris Ambainis", "authors": "Andris Ambainis, Arturs Backurs, Nikolajs Nahimovs, Raitis Ozols,\n  Alexander Rivosh", "title": "Search by quantum walks on two-dimensional grid without amplitude\n  amplification", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study search by quantum walk on a finite two dimensional grid. The\nalgorithm of Ambainis, Kempe, Rivosh (quant-ph/0402107) takes O(\\sqrt{N log N})\nsteps and finds a marked location with probability O(1/log N) for grid of size\n\\sqrt{N} * \\sqrt{N}. This probability is small, thus amplitude amplification is\nneeded to achieve \\Theta(1) success probability. The amplitude amplification\nadds an additional O(\\sqrt{log N}) factor to the number of steps, making it\nO(\\sqrt{N} log N).\n  In this paper, we show that despite a small probability to find a marked\nlocation, the probability to be within an O(\\sqrt{N}) neighbourhood (at an\nO(\\sqrt[4]{N}) distance) of the marked location is \\Theta(1). This allows to\nskip amplitude amplification step and leads to an O(\\sqrt{log N}) speed-up.\n  We describe the results of numerical experiments supporting this idea, and we\nprove this fact analytically.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2011 20:55:56 GMT"}], "update_date": "2011-12-15", "authors_parsed": [["Ambainis", "Andris", ""], ["Backurs", "Arturs", ""], ["Nahimovs", "Nikolajs", ""], ["Ozols", "Raitis", ""], ["Rivosh", "Alexander", ""]]}, {"id": "1112.3506", "submitter": "Mark Jones Mr", "authors": "Robert Crowston, Mark Jones, Matthias Mnich", "title": "Max-Cut Parameterized Above the Edwards-Erd\\H{o}s Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the boundary of tractability for the Max-Cut problem in graphs. Our\nmain result shows that Max-Cut above the Edwards-Erd\\H{o}s bound is\nfixed-parameter tractable: we give an algorithm that for any connected graph\nwith n vertices and m edges finds a cut of size m/2 + (n-1)/4 + k in time\n2^O(k)n^4, or decides that no such cut exists. This answers a long-standing\nopen question from parameterized complexity that has been posed several times\nover the past 15 years. Our algorithm is asymptotically optimal, under the\nExponential Time Hypothesis, and is strengthened by a polynomial-time\ncomputable kernel of polynomial size.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2011 13:38:50 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2012 09:17:40 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2013 16:02:31 GMT"}], "update_date": "2013-11-07", "authors_parsed": [["Crowston", "Robert", ""], ["Jones", "Mark", ""], ["Mnich", "Matthias", ""]]}, {"id": "1112.3611", "submitter": "Aravindan Vijayaraghavan", "authors": "Julia Chuzhoy, Yury Makarychev, Aravindan Vijayaraghavan and Yuan Zhou", "title": "Approximation Algorithms and Hardness of the k-Route Cut Problem", "comments": "To appear in the Symposium on Discrete Algorithms (SODA) 2012. 44\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the k-route cut problem: given an undirected edge-weighted graph\nG=(V,E), a collection {(s_1,t_1),(s_2,t_2),...,(s_r,t_r)} of source-sink pairs,\nand an integer connectivity requirement k, the goal is to find a minimum-weight\nsubset E' of edges to remove, such that the connectivity of every pair (s_i,\nt_i) falls below k. Specifically, in the edge-connectivity version, EC-kRC, the\nrequirement is that there are at most (k-1) edge-disjoint paths connecting s_i\nto t_i in G \\ E', while in the vertex-connectivity version, NC-kRC, the same\nrequirement is for vertex-disjoint paths. Prior to our work, poly-logarithmic\napproximation algorithms have been known for the special case where k >= 3, but\nno non-trivial approximation algorithms were known for any value k>3, except in\nthe single-source setting. We show an O(k log^{3/2}r)-approximation algorithm\nfor EC-kRC with uniform edge weights, and several polylogarithmic bi-criteria\napproximation algorithms for EC-kRC and NC-kRC, where the connectivity\nrequirement k is violated by a constant factor. We complement these upper\nbounds by proving that NC-kRC is hard to approximate to within a factor of\nk^{eps} for some fixed eps>0.\n  We then turn to study a simpler version of NC-kRC, where only one source-sink\npair is present. We give a simple bi-criteria approximation algorithm for this\ncase, and show evidence that even this restricted version of the problem may be\nhard to approximate. For example, we prove that the single source-sink pair\nversion of NC-kRC has no constant-factor approximation, assuming Feige's Random\nk-AND assumption.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2011 19:11:56 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2011 02:24:05 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Chuzhoy", "Julia", ""], ["Makarychev", "Yury", ""], ["Vijayaraghavan", "Aravindan", ""], ["Zhou", "Yuan", ""]]}, {"id": "1112.3765", "submitter": "Gero Greiner", "authors": "Gero Greiner and Riko Jacob", "title": "The Efficiency of MapReduce in Parallel External Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its introduction in 2004, the MapReduce framework has become one of the\nstandard approaches in massive distributed and parallel computation. In\ncontrast to its intensive use in practise, theoretical footing is still limited\nand only little work has been done yet to put MapReduce on a par with the major\ncomputational models. Following pioneer work that relates the MapReduce\nframework with PRAM and BSP in their macroscopic structure, we focus on the\nfunctionality provided by the framework itself, considered in the parallel\nexternal memory model (PEM). In this, we present upper and lower bounds on the\nparallel I/O-complexity that are matching up to constant factors for the\nshuffle step. The shuffle step is the single communication phase where all\ninformation of one MapReduce invocation gets transferred from map workers to\nreduce workers. Hence, we move the focus towards the internal communication\nstep in contrast to previous work. The results we obtain further carry over to\nthe BSP* model. On the one hand, this shows how much complexity can be \"hidden\"\nfor an algorithm expressed in MapReduce compared to PEM. On the other hand, our\nresults bound the worst-case performance loss of the MapReduce approach in\nterms of I/O-efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 11:27:07 GMT"}], "update_date": "2011-12-19", "authors_parsed": [["Greiner", "Gero", ""], ["Jacob", "Riko", ""]]}, {"id": "1112.4295", "submitter": "Samir Datta", "authors": "Samir Datta and Rameshwar Pratap", "title": "Computing Bits of Algebraic Numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the complexity theoretic study of the problem of computing the\nbits of (real) algebraic numbers. This extends the work of Yap on computing the\nbits of transcendental numbers like \\pi, in Logspace.\n  Our main result is that computing a bit of a fixed real algebraic number is\nin C=NC1\\subseteq Logspace when the bit position has a verbose (unary)\nrepresentation and in the counting hierarchy when it has a succinct (binary)\nrepresentation.\n  Our tools are drawn from elementary analysis and numerical analysis, and\ninclude the Newton-Raphson method. The proof of our main result is entirely\nelementary, preferring to use the elementary Liouville's theorem over the much\ndeeper Roth's theorem for algebraic numbers.\n  We leave the possibility of proving non-trivial lower bounds for the problem\nof computing the bits of an algebraic number given the bit position in binary,\nas our main open question. In this direction we show very limited progress by\nproving a lower bound for rationals.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 10:51:14 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Datta", "Samir", ""], ["Pratap", "Rameshwar", ""]]}, {"id": "1112.4419", "submitter": "Micha{\\l} Pilipczuk", "authors": "Fedor V. Fomin and Stefan Kratsch and Marcin Pilipczuk and Micha{\\l}\n  Pilipczuk and Yngve Villanger", "title": "Subexponential fixed-parameter tractability of cluster editing", "comments": "The new version contains results accepted for publication on the 30th\n  Symposium on Theoretical Aspects of Computer Science (STACS 2013) under title\n  'Tight bounds for Parameterized Complexity of Cluster Editing'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Correlation Clustering, also known as Cluster Editing, we are given an\nundirected n-vertex graph G and a positive integer k. The task is to decide if\nG can be transformed into a cluster graph, i.e., a disjoint union of cliques,\nby changing at most k adjacencies, i.e. by adding/deleting at most k edges. We\ngive a subexponential algorithm that, in time 2^O(sqrt(pk)) + n^O(1) decides\nwhether G can be transformed into a cluster graph with p cliques by changing at\nmost k adjacencies. We complement our algorithmic findings by the following\ntight lower bounds on the asymptotic behaviour of our algorithm. We show that,\nunless ETH fails, for any constant 0 < s <= 1, there is p = Theta(k^s) such\nthat there is no algorithm deciding in time 2^o(sqrt(pk)) n^O(1) whether G can\nbe transformed into a cluster graph with p cliques by changing at most k\nadjacencies.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 17:43:36 GMT"}, {"version": "v2", "created": "Tue, 27 Dec 2011 10:31:34 GMT"}, {"version": "v3", "created": "Mon, 12 Mar 2012 12:55:42 GMT"}, {"version": "v4", "created": "Wed, 30 Jan 2013 17:54:14 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Kratsch", "Stefan", ""], ["Pilipczuk", "Marcin", ""], ["Pilipczuk", "Micha\u0142", ""], ["Villanger", "Yngve", ""]]}, {"id": "1112.4523", "submitter": "Bjarke Hammersholt Roune", "authors": "Bjarke Hammersholt Roune, Eduardo S\\'aenz de Cabez\\'on", "title": "Complexity and Algorithms for Euler Characteristic of Simplicial\n  Complexes", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS cs.MS cs.SC math.AC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the Euler characteristic of an abstract\nsimplicial complex given by its vertices and facets. We show that this problem\nis #P-complete and present two new practical algorithms for computing Euler\ncharacteristic. The two new algorithms are derived using combinatorial\ncommutative algebra and we also give a second description of them that requires\nno algebra. We present experiments showing that the two new algorithms can be\nimplemented to be faster than previous Euler characteristic implementations by\na large margin.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 22:51:21 GMT"}], "update_date": "2011-12-21", "authors_parsed": [["Roune", "Bjarke Hammersholt", ""], ["de Cabez\u00f3n", "Eduardo S\u00e1enz", ""]]}, {"id": "1112.4536", "submitter": "Fran\\c{c}ois Nicolas", "authors": "Sebastian B\\\"ocker and Quang Bao Anh Bui and Francois Nicolas and Anke\n  Truss", "title": "Intractability of the Minimum-Flip Supertree problem and its variants", "comments": "To be submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing supertrees is a central problem in phylogenetics. The supertree\nmethod that is by far the most widely used today was introduced in 1992 and is\ncalled Matrix Representation with Parsimony analysis (MRP). Matrix\nRepresentation using Flipping (MRF)}, which was introduced in 2002, is an\ninteresting variant of MRP: MRF is arguably more relevant that MRP and various\nefficient implementations of MRF have been presented. From a theoretical point\nof view, implementing MRF or MRP is solving NP-hard optimization problems. The\naim of this paper is to study the approximability and the fixed-parameter\ntractability of the optimization problem corresponding to MRF, namely\nMinimum-Flip Supertree. We prove strongly negative results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2011 00:32:15 GMT"}], "update_date": "2011-12-21", "authors_parsed": [["B\u00f6cker", "Sebastian", ""], ["Bui", "Quang Bao Anh", ""], ["Nicolas", "Francois", ""], ["Truss", "Anke", ""]]}, {"id": "1112.5245", "submitter": "Christophe Guyeux", "authors": "Jacques M. Bahi and Christophe Guyeux and Pierre-Cyrille Heam", "title": "A Complexity Approach for Steganalysis", "comments": "Submitted to the Journ\\`ees Codes et St\\'eganographie 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this proposal for the Journ\\`ees Codes et St\\'eganographie 2012, we define\na new rigorous approach for steganalysis based on the complexity theory. It is\nsimilar to the definitions of security that can be found for hash functions,\nPRNG, and so on. We propose here a notion of \\emph{secure hiding} and we give a\nfirst secure hiding scheme.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2011 07:58:24 GMT"}], "update_date": "2011-12-23", "authors_parsed": [["Bahi", "Jacques M.", ""], ["Guyeux", "Christophe", ""], ["Heam", "Pierre-Cyrille", ""]]}, {"id": "1112.5741", "submitter": "Amit Weinstein", "authors": "Eric Blais, Amit Weinstein and Yuichi Yoshida", "title": "Partially Symmetric Functions are Efficiently Isomorphism-Testable", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a function f: {0,1}^n \\to {0,1}, the f-isomorphism testing problem\nrequires a randomized algorithm to distinguish functions that are identical to\nf up to relabeling of the input variables from functions that are far from\nbeing so. An important open question in property testing is to determine for\nwhich functions f we can test f-isomorphism with a constant number of queries.\nDespite much recent attention to this question, essentially only two classes of\nfunctions were known to be efficiently isomorphism testable: symmetric\nfunctions and juntas.\n  We unify and extend these results by showing that all partially symmetric\nfunctions---functions invariant to the reordering of all but a constant number\nof their variables---are efficiently isomorphism-testable. This class of\nfunctions, first introduced by Shannon, includes symmetric functions, juntas,\nand many other functions as well. We conjecture that these functions are\nessentially the only functions efficiently isomorphism-testable.\n  To prove our main result, we also show that partial symmetry is efficiently\ntestable. In turn, to prove this result we had to revisit the junta testing\nproblem. We provide a new proof of correctness of the nearly-optimal junta\ntester. Our new proof replaces the Fourier machinery of the original proof with\na purely combinatorial argument that exploits the connection between sets of\nvariables with low influence and intersecting families.\n  Another important ingredient in our proofs is a new notion of symmetric\ninfluence. We use this measure of influence to prove that partial symmetry is\nefficiently testable and also to construct an efficient sample extractor for\npartially symmetric functions. We then combine the sample extractor with the\ntesting-by-implicit-learning approach to complete the proof that partially\nsymmetric functions are efficiently isomorphism-testable.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2011 17:23:14 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Blais", "Eric", ""], ["Weinstein", "Amit", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1112.5947", "submitter": "Sergey Verlan", "authors": "Sergiu Ivanov, Sergey Verlan", "title": "Random Context and Semi-Conditional Insertion-Deletion Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.CL cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we introduce the operations of insertion and deletion working\nin a random-context and semi-conditional manner. We show that the conditional\nuse of rules strictly increase the computational power. In the case of\nsemi-conditional insertion-deletion systems context-free insertion and deletion\nrules of one symbol are sufficient to get the computational completeness. In\nthe random context case our results expose an asymmetry between the\ncomputational power of insertion and deletion rules: systems of size $(2,0,0;\n1,1,0)$ are computationally complete, while systems of size $(1,1,0;2,0,0)$\n(and more generally of size $(1,1,0;p,1,1)$) are not. This is particularly\ninteresting because other control mechanisms like graph-control or matrix\ncontrol used together with insertion-deletion systems do not present such\nasymmetry.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2011 10:16:35 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Ivanov", "Sergiu", ""], ["Verlan", "Sergey", ""]]}, {"id": "1112.6007", "submitter": "Giorgio Ottaviani", "authors": "J. M. Landsberg and Giorgio Ottaviani", "title": "New lower bounds for the border rank of matrix multiplication", "comments": "9 pages. Version 1 contained an error in the proof of its main\n  theorem and in the course of fixing it we proved a stronger statement. v3:\n  proof of main theorem moved up", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The border rank of the matrix multiplication operator for n by n matrices is\na standard measure of its complexity. Using techniques from algebraic geometry\nand representation theory, we show the border rank is at least 2n^2-n. Our\nbounds are better than the previous lower bound (due to Lickteig in 1985) of\n3/2 n^2+ n/2 -1 for all n>2. The bounds are obtained by finding new equations\nthat bilinear maps of small border rank must satisfy, i.e., new equations for\nsecant varieties of triple Segre products, that matrix multiplication fails to\nsatisfy.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2011 19:24:57 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2012 15:25:01 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2013 20:52:52 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Landsberg", "J. M.", ""], ["Ottaviani", "Giorgio", ""]]}, {"id": "1112.6063", "submitter": "Yasuhiro Takahashi", "authors": "Yasuhiro Takahashi, Seiichiro Tani", "title": "Collapse of the Hierarchy of Constant-Depth Exact Quantum Circuits", "comments": "19 pages, 4 figures; v2: one theorem added, title changed, text\n  substantially rewritten", "journal-ref": "Computational Complexity, Vol. 25 Issue 4, pp.849-881, 2016;\n  Proceedings of the 28th IEEE Conference on Computational Complexity (CCC\n  2013), pp.168-178, 2013", "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantum complexity class QNC^0_f of quantum operations\nimplementable exactly by constant-depth polynomial-size quantum circuits with\nunbounded fan-out gates (called QNC^0_f circuits). Our main result is that the\nquantum OR operation is in QNC^0_f, which is an affirmative answer to the\nquestion of Hoyer and Spalek. In sharp contrast to the strict hierarchy of the\nclassical complexity classes: NC^0 \\subsetneq AC^0 \\subsetneq TC^0, our result\nwith Hoyer and Spalek's one implies the collapse of the hierarchy of the\ncorresponding quantum ones: QNC^0_f = QAC^0_f = QTC^0_f. Then, we show that\nthere exists a constant-depth subquadratic-size quantum circuit for the quantum\nthreshold operation. This implies the size difference between the QNC^0_f and\nQTC^0_f circuits for implementing the same quantum operation. Lastly, we show\nthat, if the quantum Fourier transform modulo a prime is in QNC^0_f, there\nexists a polynomial-time exact classical algorithm for a discrete logarithm\nproblem using a QNC^0_f oracle. This implies that, under a plausible\nassumption, there exists a classically hard problem that is solvable exactly by\na QNC^0_f circuit with gates for the quantum Fourier transform.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2011 05:03:39 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2012 04:41:00 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Takahashi", "Yasuhiro", ""], ["Tani", "Seiichiro", ""]]}, {"id": "1112.6140", "submitter": "Tom\\'a\\v{s} Valla", "authors": "R. Samal and T. Valla", "title": "The guarding game is E-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The guarding game is a game in which several cops try to guard a region in a\n(directed or undirected) graph against Robber. Robber and the cops are placed\non the vertices of the graph; they take turns in moving to adjacent vertices\n(or staying), cops inside the guarded region, Robber on the remaining vertices\n(the robber-region). The goal of Robber is to enter the guarded region at a\nvertex with no cop on it. The problem is to determine whether for a given graph\nand given number of cops the cops are able to prevent Robber from entering the\nguarded region. Fomin et al. [Fomin, Golovach, Hall, Mihalak, Vicari, Widmayer:\nHow to Guard a Graph? Algorithmica 61(4), 839--856 (2011)] proved that the\nproblem is NP-complete when the robber-region is restricted to a tree. Further\nthey prove that is it PSPACE-complete when the robber-region is restricted to a\ndirected acyclic graph, and they ask about the problem complexity for arbitrary\ngraphs. In this paper we prove that the problem is E-complete for arbitrary\ndirected graphs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2011 16:03:30 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2013 12:23:49 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["Samal", "R.", ""], ["Valla", "T.", ""]]}, {"id": "1112.6265", "submitter": "Iddo Tzameret", "authors": "Pavel Hrubes and Iddo Tzameret", "title": "Short Proofs for the Determinant Identities", "comments": "46 pages; Revision and corrections to Section 7. Addition of short\n  proofs for the Cayley-Hamilton theorem. Other minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study arithmetic proof systems P_c(F) and P_f(F) operating with arithmetic\ncircuits and arithmetic formulas, respectively, that prove polynomial\nidentities over a field F. We establish a series of structural theorems about\nthese proof systems, the main one stating that P_c(F) proofs can be balanced:\nif a polynomial identity of syntactic degree d and depth k has a P_c(F) proof\nof size s, then it also has a P_c(F) proof of size poly(s,d) and depth\nO(k+\\log^2 d + \\log d\\cd \\log s). As a corollary, we obtain a quasipolynomial\nsimulation of P_c(F) by P_f(F), for identities of a polynomial syntactic\ndegree.\n  Using these results we obtain the following: consider the identities det(XY)\n= det(X)det(Y) and det(Z)= z_{11}... z_{nn}, where X,Y and Z are nxn square\nmatrices and Z is a triangular matrix with z_{11},..., z_{nn} on the diagonal\n(and det is the determinant polynomial). Then we can construct a\npolynomial-size arithmetic circuit det such that the above identities have\nP_c(F) proofs of polynomial-size and O(\\log^2 n) depth. Moreover, there exists\nan arithmetic formula det of size n^{O(\\log n)} such that the above identities\nhave P_f(F) proofs of size n^{O(\\log n)}.\n  This yields a solution to a basic open problem in propositional proof\ncomplexity, namely, whether there are polynomial-size NC^2-Frege proofs for the\ndeterminant identities and the hard matrix identities, as considered, e.g., in\nSoltys and Cook (2004) (cf., Beame and Pitassi (1998)). We show that matrix\nidentities like AB=I {\\to} BA=I (for matrices over the two element field) as\nwell as basic properties of the determinant have polynomial-size NC^2-Frege\nproofs, and quasipolynomial-size Frege proofs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2011 10:18:16 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2013 11:30:21 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Hrubes", "Pavel", ""], ["Tzameret", "Iddo", ""]]}, {"id": "1112.6320", "submitter": "Seyed Hamed  Hassani", "authors": "S. Hamed Hassani, Nicolas Macris, Rudiger Urbanke", "title": "Threshold Saturation in Spatially Coupled Constraint Satisfaction\n  Problems", "comments": null, "journal-ref": null, "doi": "10.1007/s10955-012-0664-x", "report-no": null, "categories": "cs.CC cond-mat.stat-mech cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider chains of random constraint satisfaction models that are\nspatially coupled across a finite window along the chain direction. We\ninvestigate their phase diagram at zero temperature using the survey\npropagation formalism and the interpolation method. We prove that the SAT-UNSAT\nphase transition threshold of an infinite chain is identical to the one of the\nindividual standard model, and is therefore not affected by spatial coupling.\nWe compute the survey propagation complexity using population dynamics as well\nas large degree approximations, and determine the survey propagation threshold.\nWe find that a clustering phase survives coupling. However, as one increases\nthe range of the coupling window, the survey propagation threshold increases\nand saturates towards the phase transition threshold. We also briefly discuss\nother aspects of the problem. Namely, the condensation threshold is not\naffected by coupling, but the dynamic threshold displays saturation towards the\ncondensation one. All these features may provide a new avenue for obtaining\nbetter provable algorithmic lower bounds on phase transition thresholds of the\nindividual standard model.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 10:42:51 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2012 07:32:02 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Hassani", "S. Hamed", ""], ["Macris", "Nicolas", ""], ["Urbanke", "Rudiger", ""]]}]