[{"id": "2101.00003", "submitter": "Edward Haeusler", "authors": "Edward Hermann Haeusler", "title": "Yet another argument in favour of NP=CoNP", "comments": "This article puts together the results shown in arXiv:2009.09802v1\n  and in arXiv:2012.07833v1 to show a proof of NP=CoNP. It is need to read\n  these article to get the details on the proof presented here", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article shows yet another proof of NP=CoNP$. In a previous article, we\nproved that NP=PSPACE and from it we can conclude that NP=CoNP immediately. The\nformer proof shows how to obtain polynomial and, polynomial in time checkable\nDag-like proofs for all purely implicational Minimal logic tautologies. From\nthe fact that Minimal implicational logic is PSPACE-complete we get the proof\nthat NP=PSPACE.\n  This first proof of NP=CoNP uses Hudelmaier linear upper-bound on the height\nof Sequent Calculus minimal implicational logic proofs. In an addendum to the\nproof of NP=PSPACE, we observe that we do not need to use Hudelmaier\nupper-bound since any proof of non-hamiltonicity for any graph is linear\nupper-bounded. By the CoNP-completeness of non-hamiltonicity, we obtain NP=CoNP\nas a corollary of the first proof. In this article we show the third proof of\nCoNP=NP, also providing polynomial size and polynomial verifiable certificates\nthat are Dags. They are generated from normal Natural Deduction proofs, linear\nheight upper-bounded too, by removing redundancy, i.e., repeated parts. The\nexistence of repeated parts is a consequence of the redundancy theorem for a\nfamily of super-polynomial proofs in the purely implicational Minimal logic. It\nis mandatory to read at least two previous articles to get the details of the\nproof presented here. The article that proves the redundancy theorem and the\narticle that shows how to remove the repeated parts of a normal Natural\nDeduction proof to have a polynomial Dag certificate for minimal implicational\nlogic tautologies.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 22:08:20 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Haeusler", "Edward Hermann", ""]]}, {"id": "2101.00061", "submitter": "Simina Br\\^anzei", "authors": "Simina Br\\^anzei and Jiawei Li", "title": "The Query Complexity of Local Search and Brouwer in Rounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of local search and Brouwer fixed-point\ncomputation when there are $k$ rounds of interaction with the oracle that\nanswers queries. Thus in each round, any number of simultaneous queries can be\nissued, the oracle answers are received, and then the queries for the next\nround are submitted. The algorithm must stop by the end of the $k$-th round.\nThis model captures distributed settings, where each query is time consuming\nand can be executed by a separate processor to speed up computation time.\n  We present several new algorithms and lower bounds, which characterize the\ntrade-off between the number of rounds of adaptivity and the total number of\nqueries on local search and Brouwer fixed-point. We mainly focus on studying\nthese problems on the $d$-dimensional grid $[n]^d$, where $d$ is a constant.\n  For local search, if the number of rounds $k$ is a constant, then we obtain a\nquery complexity of $\\Theta\\bigl(n^{\\frac{d^{k+1} - d^k}{d^k - 1}}\\bigl)$ for\nboth deterministic and randomized algorithms. On the other hand, when the\nnumber of rounds is polynomial, i.e. of the form $n = k^{\\alpha}$, where\n$\\alpha$ is a constant with $0 < \\alpha < d/2$, we obtain an upper bound of\n$O\\left(n^{(d-1) - \\frac{d-2}{d}\\alpha}\\right)$ and a lower bound of\n$\\widetilde{\\Omega}\\bigl(\\max(n^{(d-1)-\\alpha}, n^{\\frac{d}{2}})\\bigr)$ for\nrandomized algorithms. For Brouwer fixed-point, we have query complexity of\n$\\Theta\\bigl(n^{\\frac{d^{k+1} - d^k}{d^k - 1}}\\bigl)$ for both deterministic\nand randomized algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 20:27:09 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Br\u00e2nzei", "Simina", ""], ["Li", "Jiawei", ""]]}, {"id": "2101.00211", "submitter": "Ryan Mann", "authors": "Ryan L. Mann", "title": "Simulating Quantum Computations with Tutte Polynomials", "comments": "13 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a classical heuristic algorithm for exactly computing quantum\nprobability amplitudes. Our algorithm is based on mapping output probability\namplitudes of quantum circuits to evaluations of the Tutte polynomial of\ngraphic matroids. The algorithm evaluates the Tutte polynomial recursively\nusing the deletion-contraction property while attempting to exploit structural\nproperties of the matroid. We consider several variations of our algorithm and\npresent experimental results comparing their performance on two classes of\nrandom quantum circuits. Further, we obtain an explicit form for Clifford\ncircuit amplitudes in terms of matroid invariants and an alternative efficient\nclassical algorithm for computing the output probability amplitudes of Clifford\ncircuits.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 11:11:44 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Mann", "Ryan L.", ""]]}, {"id": "2101.00694", "submitter": "Hauke Brinkop", "authors": "Hauke Brinkop, Klaus Jansen, Tim Wei{\\ss}enfels", "title": "An optimal FPT algorithm parametrized by treewidth for\n  Weighted-Max-Bisection given a tree decomposition as advice assuming SETH and\n  the hardness of MinConv", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weighted maximal bisection problem is, given an edge weighted graph, to\nfind a bipartition of the vertex set into two sets such that their cardinality\ndiffers by at most one and the sum of the weight of the edges between vertices\nthat are not in the same set is maximized. This problem is known to be NP-hard,\neven when a tree decomposition of width $t$ and $\\mathcal O(n)$ nodes is given\nas an advice as part of the input, where $n$ is the number of vertices of the\ninput graph. But, given such an advice, the problem is decidable in FPT time in\n$n$ parametrized by $t$. In particular Jansen et al. presented an algorithm\nwith running time $\\mathcal O(2^tn^3)$. Hanaka, Kobayashi, and Sone enhanced\nthe analysis of the complexity to $\\mathcal O(2^t(nt)^2)$. By slightly\nmodifying the approach, we improve the running time to $\\mathcal O(2^tn^2)$ in\nthe RAM model, which is asymptotically optimal in $n$ under the hardness of\nMinConv.\n  We proof that this is also asymptotically optimal in its dependence on $t$\nassuming SETH by showing for a slightly easier problem (maximal cut) that there\nis no $\\mathcal O(2^{\\epsilon t} \\operatorname{poly} n)$ algorithm for any\n$\\varepsilon < 1$ under SETH. This was already claimed by Hanaka, Kobayashi,\nand Sone but without a correct proof.\n  We also present a hardness result (no $\\mathcal O(2^t n^{2-\\varepsilon})$\nalgorithm for any $\\varepsilon > 0$) for a broad family of subclasses of the\nweighted maximal bisection problem that are characterized only by the\ndependence of $t$ from $n$, more precisely, all instances with $t = f(n)$ for\nan arbitrary but fixed $f(n) \\in \\operatorname o(\\log n)$. This holds even when\nonly considering planar graphs.\n  Moreover we present a detailed description of the implementation details and\nassumptions that are necessary to achieve the optimal running time.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 20:00:51 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Brinkop", "Hauke", ""], ["Jansen", "Klaus", ""], ["Wei\u00dfenfels", "Tim", ""]]}, {"id": "2101.00717", "submitter": "Ozgur Ceyhan", "authors": "Ozgur Ceyhan", "title": "Algorithmic Complexities in Backpropagation and Tropical Neural Networks", "comments": "This note is a summary of the lecture given at S\\'eminaire \"Fables\n  G\\'eom\\'etriques\" in University of Geneva on December 9, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.AG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note, we propose a novel technique to reduce the algorithmic\ncomplexity of neural network training by using matrices of tropical real\nnumbers instead of matrices of real numbers. Since the tropical arithmetics\nreplaces multiplication with addition, and addition with max, we theoretically\nachieve several order of magnitude better constant factors in time complexities\nin the training phase. The fact that we replace the field of real numbers with\nthe tropical semiring of real numbers and yet achieve the same classification\nresults via neural networks come from deep results in topology and analysis,\nwhich we verify in our note. We then explore artificial neural networks in\nterms of tropical arithmetics and tropical algebraic geometry, and introduce\nthe multi-layered tropical neural networks as universal approximators. After\ngiving a tropical reformulation of the backpropagation algorithm, we verify the\nalgorithmic complexity is substantially lower than the usual backpropagation as\nthe tropical arithmetic is free of the complexity of usual multiplication.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 22:19:17 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ceyhan", "Ozgur", ""]]}, {"id": "2101.01100", "submitter": "Jason Altschuler", "authors": "Jason M. Altschuler and Enric Boix-Adsera", "title": "Wasserstein barycenters are NP-hard to compute", "comments": "18 pages (9 pages main text)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of computing Wasserstein barycenters (a.k.a. Optimal Transport\nbarycenters) has attracted considerable recent attention due to many\napplications in data science. While there exist polynomial-time algorithms in\nany fixed dimension, all known runtimes suffer exponentially in the dimension.\nIt is an open question whether this exponential dependence is improvable to a\npolynomial dependence. This paper proves that unless P=NP, the answer is no.\nThis uncovers a \"curse of dimensionality\" for Wasserstein barycenter\ncomputation which does not occur for Optimal Transport computation. Moreover,\nour hardness results for computing Wasserstein barycenters extend to\napproximate computation, to seemingly simple cases of the problem, and to\naveraging probability distributions in other Optimal Transport metrics.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 17:16:45 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Altschuler", "Jason M.", ""], ["Boix-Adsera", "Enric", ""]]}, {"id": "2101.01151", "submitter": "Ji\\v{r}\\'i \\v{S}\\'ima", "authors": "Ji\\v{r}\\'i \\v{S}\\'ima and Stanislav \\v{Z}\\'ak", "title": "A polynomial time construction of a hitting set for read-once branching\n  programs of width 3", "comments": "46 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, an interest in constructing pseudorandom or hitting set generators\nfor restricted branching programs has increased, which is motivated by the\nfundamental issue of derandomizing space-bounded computations. Such\nconstructions have been known only in the case of width 2 and in very\nrestricted cases of bounded width. In this paper, we characterize the hitting\nsets for read-once branching programs of width 3 by a so-called richness\ncondition. Namely, we show that such sets hit the class of read-once\nconjunctions of DNF and CNF (i.e. the weak richness). Moreover, we prove that\nany rich set extended with all strings within Hamming distance of 3 is a\nhitting set for read-once branching programs of width 3. Then, we show that any\nalmost $O(\\log n)$-wise independent set satisfies the richness condition. By\nusing such a set due to Alon et al. (1992) our result provides an explicit\npolynomial time construction of a hitting set for read-once branching programs\nof width 3 with acceptance probability $\\varepsilon>5/6$. We announced this\nresult at conferences almost 10 years ago, including only proof sketches, which\nmotivated a plenty of subsequent results on pseudorandom generators for\nrestricted read-once branching programs. This paper contains our original\ndetailed proof that has not been published yet.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 18:31:07 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["\u0160\u00edma", "Ji\u0159\u00ed", ""], ["\u017d\u00e1k", "Stanislav", ""]]}, {"id": "2101.01533", "submitter": "John Tsotsos", "authors": "John K. Tsotsos, Omar Abid, Iuliia Kotseruba, Markus D. Solbach", "title": "On the Control of Attentional Processes in Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.CV cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The study of attentional processing in vision has a long and deep history.\nRecently, several papers have presented insightful perspectives into how the\ncoordination of multiple attentional functions in the brain might occur. These\nbegin with experimental observations and the authors propose structures,\nprocesses, and computations that might explain those observations. Here, we\nconsider a perspective that past works have not, as a complementary approach to\nthe experimentally-grounded ones. We approach the same problem as past authors\nbut from the other end of the computational spectrum, from the problem nature,\nas Marr's Computational Level would prescribe. What problem must the brain\nsolve when orchestrating attentional processes in order to successfully\ncomplete one of the myriad possible visuospatial tasks at which we as humans\nexcel? The hope, of course, is for the approaches to eventually meet and thus\nform a complete theory, but this is likely not soon. We make the first steps\ntowards this by addressing the necessity of attentional control, examining the\nbreadth and computational difficulty of the visuospatial and attentional tasks\nseen in human behavior, and suggesting a sketch of how attentional control\nmight arise in the brain. The key conclusions of this paper are that an\nexecutive controller is necessary for human attentional function in vision, and\nthat there is a 'first principles' computational approach to its understanding\nthat is complementary to the previous approaches that focus on modelling or\nlearning from experimental observations directly.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 14:24:20 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Tsotsos", "John K.", ""], ["Abid", "Omar", ""], ["Kotseruba", "Iuliia", ""], ["Solbach", "Markus D.", ""]]}, {"id": "2101.01945", "submitter": "Markus Schmid", "authors": "Katrin Casel and Markus L. Schmid", "title": "Fine-Grained Complexity of Regular Path Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regular path query (RPQ) is a regular expression q that returns all node\npairs (u, v) from a graph database that are connected by an arbitrary path\nlabelled with a word from L(q). The obvious algorithmic approach to\nRPQ-evaluation (called PG-approach), i.e., constructing the product graph\nbetween an NFA for q and the graph database, is appealing due to its simplicity\nand also leads to efficient algorithms. However, it is unclear whether the\nPG-approach is optimal. We address this question by thoroughly investigating\nwhich upper complexity bounds can be achieved by the PG-approach, and we\ncomplement these with conditional lower bounds (in the sense of the\nfine-grained complexity framework). A special focus is put on enumeration and\ndelay bounds, as well as the data complexity perspective. A main insight is\nthat we can achieve optimal (or near optimal) algorithms with the PG-approach,\nbut the delay for enumeration is rather high (linear in the database). We\nexplore three successful approaches towards enumeration with sub-linear delay:\nsuper-linear preprocessing, approximations of the solution sets, and restricted\nclasses of RPQs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 10:07:16 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Casel", "Katrin", ""], ["Schmid", "Markus L.", ""]]}, {"id": "2101.02003", "submitter": "Joshua Lau", "authors": "Joshua Lau and Angus Ritossa", "title": "Algorithms and Hardness for Multidimensional Range Updates and Queries", "comments": "38 pages, 3 figures, 1 table. Full version of paper to appear in ITCS\n  2021. Abstract abridged for arXiv limits", "journal-ref": null, "doi": "10.4230/LIPIcs.ITCS.2021.37", "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional orthogonal range problems allow queries over a static set of\npoints, each with some value. Dynamic variants allow points to be added or\nremoved, one at a time. To support more powerful updates, we introduce the Grid\nRange class of data structure problems over integer arrays in one or more\ndimensions. These problems allow range updates (such as filling all cells in a\nrange with a constant) and queries (such as finding the sum or maximum of\nvalues in a range). In this work, we consider these operations along with\nupdates that replace each cell in a range with the minimum, maximum, or sum of\nits existing value, and a constant. In one dimension, it is known that segment\ntrees can be leveraged to facilitate any $n$ of these operations in\n$\\tilde{O}(n)$ time overall. Other than a few specific cases, until now, higher\ndimensional variants have been largely unexplored.\n  We show that no truly subquadratic time algorithm can support certain pairs\nof these updates simultaneously without falsifying several popular conjectures.\nOn the positive side, we show that truly subquadratic algorithms can be\nobtained for variants induced by other subsets. We provide two approaches to\ndesigning such algorithms that can be generalised to online and higher\ndimensional settings. First, we give almost-tight $\\tilde{O}(n^{3/2})$ time\nalgorithms for single-update variants where the update operation distributes\nover the query operation. Second, for other variants, we provide a general\nframework for reducing to instances with a special geometry. Using this, we\nshow that $O(m^{3/2-\\epsilon})$ time algorithms for counting paths and walks of\nlength 2 and 3 between vertex pairs in sparse graphs imply truly subquadratic\ndata structures for certain variants; to this end, we give an\n$\\tilde{O}(m^{(4\\omega-1)/(2\\omega+1)}) = O(m^{1.478})$ time algorithm for\ncounting simple 3-paths between vertex pairs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 13:18:02 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Lau", "Joshua", ""], ["Ritossa", "Angus", ""]]}, {"id": "2101.02142", "submitter": "Bruno Grenet", "authors": "Pascal Giorgi, Bruno Grenet, Armelle Perret du Cray", "title": "Polynomial modular product verification and its implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polynomial multiplication is known to have quasi-linear complexity in both\nthe dense and the sparse cases. Yet no truly linear algorithm has been given in\nany case for the problem, and it is not clear whether it is even possible. This\nleaves room for a better algorithm for the simpler problem of verifying a\npolynomial product. While finding deterministic methods seems out of reach,\nthere exist probabilistic algorithms for the problem that are optimal in number\nof algebraic operations.\n  We study the generalization of the problem to the verification of a\npolynomial product modulo a sparse divisor. We investigate its bit complexity\nfor both dense and sparse multiplicands. In particular, we are able to show the\nprimacy of the verification over modular multiplication when the divisor has a\nconstant sparsity and a second highest-degree monomial that is not too large.\nWe use these results to obtain new bounds on the bit complexity of the standard\npolynomial multiplication verification. In particular, we provide optimal\nalgorithms in the bit complexity model in the dense case by improving a result\nof Kaminski and develop the first quasi-optimal algorithm for verifying sparse\npolynomial product.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 17:19:14 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Giorgi", "Pascal", ""], ["Grenet", "Bruno", ""], ["Cray", "Armelle Perret du", ""]]}, {"id": "2101.02209", "submitter": "Yue Li", "authors": "Vijay Balasubramanian, Matthew DeCross, Arjun Kar, Cathy Li, Onkar\n  Parrikar", "title": "Complexity Growth in Integrable and Chaotic Models", "comments": "70+13 pages, 29 figures", "journal-ref": null, "doi": "10.1007/JHEP07(2021)011", "report-no": null, "categories": "hep-th cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the SYK family of models with $N$ Majorana fermions to study the\ncomplexity of time evolution, formulated as the shortest geodesic length on the\nunitary group manifold between the identity and the time evolution operator, in\nfree, integrable, and chaotic systems. Initially, the shortest geodesic follows\nthe time evolution trajectory, and hence complexity grows linearly in time. We\nstudy how this linear growth is eventually truncated by the appearance and\naccumulation of conjugate points, which signal the presence of shorter\ngeodesics intersecting the time evolution trajectory. By explicitly locating\nsuch \"shortcuts\" through analytical and numerical methods, we demonstrate that:\n(a) in the free theory, time evolution encounters conjugate points at a\npolynomial time; consequently complexity growth truncates at $O(\\sqrt{N})$, and\nwe find an explicit operator which \"fast-forwards\" the free $N$-fermion time\nevolution with this complexity, (b) in a class of interacting integrable\ntheories, the complexity is upper bounded by $O({\\rm poly}(N))$, and (c) in\nchaotic theories, we argue that conjugate points do not occur until exponential\ntimes $O(e^N)$, after which it becomes possible to find infinitesimally nearby\ngeodesics which approximate the time evolution operator. Finally, we explore\nthe notion of eigenstate complexity in free, integrable, and chaotic models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 19:00:00 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 02:30:47 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Balasubramanian", "Vijay", ""], ["DeCross", "Matthew", ""], ["Kar", "Arjun", ""], ["Li", "Cathy", ""], ["Parrikar", "Onkar", ""]]}, {"id": "2101.02312", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet", "title": "4 vs 7 sparse undirected unweighted Diameter is SETH-hard at time\n  $n^{4/3}$", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show, assuming the Strong Exponential Time Hypothesis, that for every\n$\\varepsilon > 0$, approximating undirected unweighted Diameter on $n$-vertex\n$n^{1+o(1)}$-edge graphs within ratio $7/4 - \\varepsilon$ requires $m^{4/3 -\no(1)}$ time. This is the first result that conditionally rules out a\nnear-linear time $5/3$-approximation for undirected Diameter.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 00:25:10 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Bonnet", "\u00c9douard", ""]]}, {"id": "2101.02429", "submitter": "Burak Bartan", "authors": "Burak Bartan, Mert Pilanci", "title": "Neural Spectrahedra and Semidefinite Lifts: Global Convex Optimization\n  of Polynomial Activation Neural Networks in Fully Polynomial-Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of two-layer neural networks with nonlinear activation functions\nis an important non-convex optimization problem with numerous applications and\npromising performance in layerwise deep learning. In this paper, we develop\nexact convex optimization formulations for two-layer neural networks with\nsecond degree polynomial activations based on semidefinite programming.\nRemarkably, we show that semidefinite lifting is always exact and therefore\ncomputational complexity for global optimization is polynomial in the input\ndimension and sample size for all input data. The developed convex formulations\nare proven to achieve the same global optimal solution set as their non-convex\ncounterparts. More specifically, the globally optimal two-layer neural network\nwith polynomial activations can be found by solving a semidefinite program\n(SDP) and decomposing the solution using a procedure we call Neural\nDecomposition. Moreover, the choice of regularizers plays a crucial role in the\ncomputational tractability of neural network training. We show that the\nstandard weight decay regularization formulation is NP-hard, whereas other\nsimple convex penalties render the problem tractable in polynomial time via\nconvex programming. We extend the results beyond the fully connected\narchitecture to different neural network architectures including networks with\nvector outputs and convolutional architectures with pooling. We provide\nextensive numerical simulations showing that the standard backpropagation\napproach often fails to achieve the global optimum of the training loss. The\nproposed approach is significantly faster to obtain better test accuracy\ncompared to the standard backpropagation procedure.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 08:43:01 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Bartan", "Burak", ""], ["Pilanci", "Mert", ""]]}, {"id": "2101.02570", "submitter": "Anis Ur Rahman", "authors": "Sadia Tariq, Anis Ur Rahman, Tahir Azim, Rehman Gull Khan", "title": "Instanced model simplification using combined geometric and\n  appearance-related metric", "comments": "9 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Evolution of 3D graphics and graphical worlds has brought issues like content\noptimization, real-time processing, rendering, and shared storage limitation\nunder consideration. Generally, different simplification approaches are used to\nmake 3D meshes viable for rendering. However, many of these approaches ignore\nvertex attributes for instanced 3D meshes. In this paper, we implement and\nevaluate a simple and improved version to simplify instanced 3D textured\nmodels. The approach uses different vertex attributes in addition to geometry\nto simplify mesh instances. The resulting simplified models demonstrate\nefficient time-space requirements and better visual quality.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 14:48:42 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Tariq", "Sadia", ""], ["Rahman", "Anis Ur", ""], ["Azim", "Tahir", ""], ["Khan", "Rehman Gull", ""]]}, {"id": "2101.02854", "submitter": "Sai Sandeep", "authors": "Sai Sandeep", "title": "Almost Optimal Inapproximability of Multidimensional Packing Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multidimensional packing problems generalize the classical packing problems\nsuch as Bin Packing, Multiprocessor Scheduling by allowing the jobs to be\n$d$-dimensional vectors. While the approximability of the scalar problems is\nwell understood, there has been a significant gap between the approximation\nalgorithms and the hardness results for the multidimensional variants. In this\npaper, we close this gap by giving almost tight hardness results for these\nproblems.\n  1. We show that Vector Bin Packing has no polynomial time $\\Omega( \\log d)$\nfactor asymptotic approximation algorithm when $d$ is a large constant,\nassuming $\\textsf{P}\\neq \\textsf{NP}$. This matches the $\\ln d + O(1)$ factor\napproximation algorithms (Chekuri, Khanna SICOMP 2004, Bansal, Caprara,\nSviridenko SICOMP 2009, Bansal, Eli\\'{a}s, Khan SODA 2016) upto constants.\n  2. We show that Vector Scheduling has no polynomial time algorithm with an\napproximation ratio of $\\Omega\\left( (\\log d)^{1-\\epsilon}\\right)$ when $d$ is\npart of the input, assuming $\\textsf{NP}\\nsubseteq \\textsf{ZPTIME}\\left(\nn^{(\\log n)^{O(1)}}\\right)$. This almost matches the $O\\left( \\frac{\\log\nd}{\\log \\log d}\\right)$ factor algorithms(Harris, Srinivasan JACM 2019, Im,\nKell, Kulkarni, Panigrahi SICOMP 2019). We also show that the problem is\nNP-hard to approximate within $(\\log \\log d)^{\\omega(1)}$.\n  3. We show that Vector Bin Covering is NP-hard to approximate within\n$\\Omega\\left( \\frac{\\log d}{\\log \\log d}\\right)$ when $d$ is part of the input,\nalmost matching the $O(\\log d)$ factor algorithm (Alon et al., Algorithmica\n1998).\n  Previously, no hardness results that grow with $d$ were known for Vector\nScheduling and Vector Bin Covering when $d$ is part of the input and for Vector\nBin Packing when $d$ is a fixed constant.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 05:31:16 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 17:05:13 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Sandeep", "Sai", ""]]}, {"id": "2101.05142", "submitter": "Constantin Seebach", "authors": "Pascal Schweitzer, Constantin Seebach (TU Kaiserslautern)", "title": "Resolution with Symmetry Rule applied to Linear Equations", "comments": "18 pages, to be published in STACS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the length of resolution proofs when using\nKrishnamurthy's classic symmetry rules. We show that inconsistent linear\nequation systems of bounded width over a fixed finite field $\\mathbb{F}_p$ with\n$p$ a prime have, in their standard encoding as CNFs, polynomial length\nresolutions when using the local symmetry rule (SRC-II).\n  As a consequence it follows that the multipede instances for the graph\nisomorphism problem encoded as CNF formula have polynomial length resolution\nproofs. This contrasts exponential lower bounds for\nindividualization-refinement algorithms on these graphs.\n  For the Cai-F\\\"urer-Immerman graphs, for which Tor\\'an showed exponential\nlower bounds for resolution proofs (SAT 2013), we also show that already the\nglobal symmetry rule (SRC-I) suffices to allow for polynomial length proofs.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 15:37:11 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Schweitzer", "Pascal", "", "TU Kaiserslautern"], ["Seebach", "Constantin", "", "TU Kaiserslautern"]]}, {"id": "2101.05235", "submitter": "Rahul Jain", "authors": "Sujoy Bhore and Rahul Jain", "title": "Space-Efficient Algorithms for Reachability in Geometric Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The problem of graph Reachability is to decide whether there is a path from\none vertex to another in a given graph. In this paper, we study the\nReachability problem on three distinct graph families - intersection graphs of\nJordan regions, unit contact disk graphs (penny graphs), and chordal graphs.\nFor each of these graph families, we present space-efficient algorithms for the\nReachability problem.\n  For intersection graphs of Jordan regions, we show how to obtain a \"good\"\nvertex separator in a space-efficient manner and use it to solve the\nReachability in polynomial time and $O(m^{1/2}\\log n)$ space, where $n$ is the\nnumber of Jordan regions, and $m$ is the total number of crossings among the\nregions. We use a similar approach for chordal graphs and obtain a\npolynomial-time and $O(m^{1/2}\\log n)$ space algorithm, where $n$ and $m$ are\nthe number of vertices and edges, respectively. However, we use a more involved\ntechnique for unit contact disk graphs (penny graphs) and obtain a better\nalgorithm. We show that for every $\\epsilon> 0$, there exists a polynomial-time\nalgorithm that can solve Reachability in an $n$ vertex directed penny graph,\nusing $O(n^{1/4+\\epsilon})$ space. We note that the method used to solve penny\ngraphs does not extend naturally to the class of geometric intersection graphs\nthat include arbitrary size cliques.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 17:57:55 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 23:11:25 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bhore", "Sujoy", ""], ["Jain", "Rahul", ""]]}, {"id": "2101.05597", "submitter": "Manoj Kumar", "authors": "Manoj Kumar", "title": "Necessary and Sufficient Condition for Satisfiability of a Boolean\n  Formula in CNF and its Implications on P versus NP problem", "comments": "Second Revision: 17 Pages, Affiliation and email address of author\n  added, elaborated Optimisations section, refined theorem 10.8, references\n  updated, typing errors corrected Third Revision: 22 pages, complexity\n  calculated on instance size, results changed, algorithm and related sections\n  added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean satisfiability problem has applications in various fields. An\nefficient algorithm to solve satisfiability problem can be used to solve many\nother problems efficiently. The input of satisfiability problem is a finite set\nof clauses. In this paper, properties of clauses have been studied. A type of\nclauses have been defined, called fully populated clauses, which contains each\nvariable exactly once. A relationship between two unequal fully populated\nclauses has been defined, called sibling clauses. It has been found that, if\none fully populated clause is false, for a truth assignment, then all it's\nsibling clauses will be true for the same truth assignment. Which leads to the\nnecessary and sufficient condition for satisfiability of a boolean formula, in\nCNF. The necessary and sufficient condition has been used to develop a novel\nalgorithm to solve boolean satisfiability problem in polynomial time, which\nimplies, P equals NP. Further, some optimisations have been provided that can\nbe integrated with the algorithm for better performance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 06:55:56 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 15:36:59 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 01:03:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kumar", "Manoj", ""]]}, {"id": "2101.06361", "submitter": "Erik Demaine", "authors": "Erik D. Demaine, Yevhenii Diomidov", "title": "Strings-and-Coins and Nimstring are PSPACE-complete", "comments": "10 pages, 7 figures. Improved wording and figures; cite\n  arXiv:2105.02837", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that Strings-and-Coins -- the combinatorial two-player game\ngeneralizing the dual of Dots-and-Boxes -- is strongly PSPACE-complete on\nmultigraphs. This result improves the best previous result, NP-hardness, argued\nin Winning Ways. Our result also applies to the Nimstring variant, where the\nwinner is determined by normal play; indeed, one step in our reduction is the\nstandard reduction (also from Winning Ways) from Nimstring to\nStrings-and-Coins.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 03:38:08 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 18:23:54 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Demaine", "Erik D.", ""], ["Diomidov", "Yevhenii", ""]]}, {"id": "2101.07000", "submitter": "David Schaller", "authors": "David Schaller, Manuela Gei{\\ss}, Marc Hellmuth, Peter F. Stadler", "title": "Least resolved trees for two-colored best match graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  2-colored best match graphs (2-BMGs) form a subclass of sink-free\nbi-transitive graphs that appears in phylogenetic combinatorics. There, 2-BMGs\ndescribe evolutionarily most closely related genes between a pair of species.\nThey are explained by a unique least resolved tree (LRT). Introducing the\nconcept of support vertices we derive an $O(|V|+|E|\\log^2|V|)$-time algorithm\nto recognize 2-BMGs and to construct its LRT. The approach can be extended to\nalso recognize binary-explainable 2-BMGs with the same complexity. An empirical\ncomparison emphasizes the efficiency of the new algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 11:03:54 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Schaller", "David", ""], ["Gei\u00df", "Manuela", ""], ["Hellmuth", "Marc", ""], ["Stadler", "Peter F.", ""]]}, {"id": "2101.07237", "submitter": "Matthew Ferland", "authors": "Kyle Burke, Matthew Ferland, and Shanghua Teng", "title": "Transverse Wave: an impartial color-propagation game inspired by Social\n  Influence and Quantum Nim", "comments": "29 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a colorful, impartial combinatorial game played on a\ntwo-dimensional grid, Transverse Wave. We are drawn to this game because of its\napparent simplicity, contrasting intractability, and intrinsic connection to\ntwo other combinatorial games, one inspired by social influence and another\ninspired by quantum superpositions.\n  More precisely, we show that Transverse Wave is at the intersection of\nsocial-influence-inspired Friend Circle and superposition-based Demi-Quantum\nNim. Transverse Wave is also connected with Schaefer's logic game Avoid True.\nIn addition to analyzing the mathematical structures and computational\ncomplexity of Transverse Wave, we provide a web-based version of the game,\nplayable at\nhttps://turing.plymouth.edu/~kgb1013/DB/combGames/transverseWave.html.\nFurthermore, we formulate a basic network-influence inspired game, called\nDemographic Influence, which simultaneously generalizes Node-Kyles and\nDemi-Quantum Nim (which in turn contains as special cases Nim, Avoid True, and\nTransverse Wave). These connections illuminate the lattice order, induced by\nspecial-case/generalization relationships over mathematical games, fundamental\nto both the design and comparative analyses of combinatorial games.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 18:45:03 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 20:29:33 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Burke", "Kyle", ""], ["Ferland", "Matthew", ""], ["Teng", "Shanghua", ""]]}, {"id": "2101.07495", "submitter": "Nathan Grosshans", "authors": "Nathan Grosshans, Pierre Mckenzie (DIRO), Luc Segoufin (VALDA, DI-ENS)", "title": "Tameness and the power of programs over monoids in DA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The program-over-monoid model of computation originates with Barrington's\nproof that it captures the complexity class NC$^1$. Here we make progress in\nunderstanding the subtleties of the model. First, we identify a new tameness\ncondition on a class of monoids that entails a natural characterization of the\nregular languages recognizable by programs over monoids from the class. Second,\nwe prove that the class known as DA satisfies tameness and hence that the\nregular languages recognized by programs over monoids in DA are precisely those\nrecognizable in the classical sense by morphisms from QDA. Third, we show by\ncontrast that the well studied class of monoids called J is not tame. Finally,\nwe exhibit a program-length-based hierarchy within the class of languages\nrecognized by programs over monoids from DA.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 07:41:31 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Grosshans", "Nathan", "", "DIRO"], ["Mckenzie", "Pierre", "", "DIRO"], ["Segoufin", "Luc", "", "VALDA, DI-ENS"]]}, {"id": "2101.07546", "submitter": "Charlie Dickens", "authors": "Graham Cormode, Charlie Dickens, David P. Woodruff", "title": "Subspace exploration: Bounds on Projected Frequency Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given an $n \\times d$ dimensional dataset $A$, a projection query specifies a\nsubset $C \\subseteq [d]$ of columns which yields a new $n \\times |C|$ array. We\nstudy the space complexity of computing data analysis functions over such\nsubspaces, including heavy hitters and norms, when the subspaces are revealed\nonly after observing the data. We show that this important class of problems is\ntypically hard: for many problems, we show $2^{\\Omega(d)}$ lower bounds.\nHowever, we present upper bounds which demonstrate space dependency better than\n$2^d$. That is, for $c,c' \\in (0,1)$ and a parameter $N=2^d$ an\n$N^c$-approximation can be obtained in space $\\min(N^{c'},n)$, showing that it\nis possible to improve on the na\\\"{i}ve approach of keeping information for all\n$2^d$ subsets of $d$ columns. Our results are based on careful constructions of\ninstances using coding theory and novel combinatorial reductions that exhibit\nsuch space-approximation tradeoffs.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 10:18:22 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Cormode", "Graham", ""], ["Dickens", "Charlie", ""], ["Woodruff", "David P.", ""]]}, {"id": "2101.07550", "submitter": "Louis Dublois", "authors": "Louis Dublois, Michael Lampis, Vangelis Th. Paschos", "title": "Upper Dominating Set: Tight Algorithms for Pathwidth and Sub-Exponential\n  Approximation", "comments": "This paper has been accepted to CIAC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An upper dominating set is a minimal dominating set in a graph. In the\n\\textsc{Upper Dominating Set} problem, the goal is to find an upper dominating\nset of maximum size. We study the complexity of parameterized algorithms for\n\\textsc{Upper Dominating Set}, as well as its sub-exponential approximation.\nFirst, we prove that, under ETH, \\textsc{$k$-Upper Dominating Set} cannot be\nsolved in time $O(n^{o(k)})$ (improving on $O(n^{o(\\sqrt{k})})$), and in the\nsame time we show under the same complexity assumption that for any constant\nratio $r$ and any $\\varepsilon > 0$, there is no $r$-approximation algorithm\nrunning in time $O(n^{k^{1-\\varepsilon}})$. Then, we settle the problem's\ncomplexity parameterized by pathwidth by giving an algorithm running in time\n$O^*(6^{pw})$ (improving the current best $O^*(7^{pw})$), and a lower bound\nshowing that our algorithm is the best we can get under the SETH. Furthermore,\nwe obtain a simple sub-exponential approximation algorithm for this problem: an\nalgorithm that produces an $r$-approximation in time $n^{O(n/r)}$, for any\ndesired approximation ratio $r < n$. We finally show that this\ntime-approximation trade-off is tight, up to an arbitrarily small constant in\nthe second exponent: under the randomized ETH, and for any ratio $r > 1$ and\n$\\varepsilon > 0$, no algorithm can output an $r$-approximation in time\n$n^{(n/r)^{1-\\varepsilon}}$. Hence, we completely characterize the\napproximability of the problem in sub-exponential time.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 10:31:08 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Dublois", "Louis", ""], ["Lampis", "Michael", ""], ["Paschos", "Vangelis Th.", ""]]}, {"id": "2101.07696", "submitter": "Andr\\'e Nusser", "authors": "Karl Bringmann and Andr\\'e Nusser", "title": "Translating Hausdorff is Hard: Fine-Grained Lower Bounds for Hausdorff\n  Distance Under Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computing the similarity of two point sets is a ubiquitous task in medical\nimaging, geometric shape comparison, trajectory analysis, and many more\nsettings. Arguably the most basic distance measure for this task is the\nHausdorff distance, which assigns to each point from one set the closest point\nin the other set and then evaluates the maximum distance of any assigned pair.\nA drawback is that this distance measure is not translational invariant, that\nis, comparing two objects just according to their shape while disregarding\ntheir position in space is impossible.\n  Fortunately, there is a canonical translational invariant version, the\nHausdorff distance under translation, which minimizes the Hausdorff distance\nover all translations of one of the point sets. For point sets of size $n$ and\n$m$, the Hausdorff distance under translation can be computed in time $\\tilde\nO(nm)$ for the $L_1$ and $L_\\infty$ norm [Chew, Kedem SWAT'92] and $\\tilde O(nm\n(n+m))$ for the $L_2$ norm [Huttenlocher, Kedem, Sharir DCG'93].\n  As these bounds have not been improved for over 25 years, in this paper we\napproach the Hausdorff distance under translation from the perspective of\nfine-grained complexity theory. We show (i) a matching lower bound of\n$(nm)^{1-o(1)}$ for $L_1$ and $L_\\infty$ (and all other $L_p$ norms) assuming\nthe Orthogonal Vectors Hypothesis and (ii) a matching lower bound of\n$n^{2-o(1)}$ for $L_2$ in the imbalanced case of $m = O(1)$ assuming the 3SUM\nHypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 15:52:55 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 16:48:14 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 13:43:02 GMT"}, {"version": "v4", "created": "Mon, 19 Jul 2021 13:15:29 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bringmann", "Karl", ""], ["Nusser", "Andr\u00e9", ""]]}, {"id": "2101.07856", "submitter": "Daniel Paulusma", "authors": "Barnaby Martin and Daniel Paulusma and Siani Smith", "title": "Colouring Graphs of Bounded Diameter in the Absence of Small Cycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For $k\\geq 1$, a $k$-colouring $c$ of $G$ is a mapping from $V(G)$ to\n$\\{1,2,\\ldots,k\\}$ such that $c(u)\\neq c(v)$ for any two non-adjacent vertices\n$u$ and $v$. The $k$-Colouring problem is to decide if a graph $G$ has a\n$k$-colouring. For a family of graphs ${\\cal H}$, a graph $G$ is ${\\cal\nH}$-free if $G$ does not contain any graph from ${\\cal H}$ as an induced\nsubgraph. Let $C_s$ be the $s$-vertex cycle. In previous work (MFCS 2019) we\nexamined the effect of bounding the diameter on the complexity of $3$-Colouring\nfor $(C_3,\\ldots,C_s)$-free graphs and $H$-free graphs where $H$ is some\npolyad. Here, we prove for certain small values of $s$ that $3$-Colouring is\npolynomial-time solvable for $C_s$-free graphs of diameter $2$ and\n$(C_4,C_s)$-free graphs of diameter $2$. In fact, our results hold for the more\ngeneral problem List $3$-Colouring. We complement these results with some\nhardness result for diameter $4$.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 20:42:11 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Martin", "Barnaby", ""], ["Paulusma", "Daniel", ""], ["Smith", "Siani", ""]]}, {"id": "2101.08141", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam and Penghui Yao", "title": "Positive spectrahedra: Invariance principles and Pseudorandom generators", "comments": "63 pages. v2: Minor revisions and Improvements in presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a recent work, O'Donnell, Servedio and Tan (STOC 2019) gave explicit\npseudorandom generators (PRGs) for arbitrary $m$-facet polytopes in $n$\nvariables with seed length poly-logarithmic in $m,n$, concluding a sequence of\nworks in the last decade, that was started by Diakonikolas, Gopalan, Jaiswal,\nServedio, Viola (SICOMP 2010) and Meka, Zuckerman (SICOMP 2013) for fooling\nlinear and polynomial threshold functions, respectively. In this work, we\nconsider a natural extension of PRGs for intersections of positive\nspectrahedrons. A positive spectrahedron is a Boolean function\n$f(x)=[x_1A^1+\\cdots +x_nA^n \\preceq B]$ where the $A^i$s are $k\\times k$\npositive semidefinite matrices. We construct explicit PRGs that $\\delta$-fool\n\"regular\" width-$M$ positive spectrahedrons (i.e., when none of the $A^i$s are\ndominant) over the Boolean space with seed length $\\textsf{poly}(\\log k,\\log n,\nM, 1/\\delta)$.\n  Our main technical contributions are the following: We first prove an\ninvariance principle for positive spectrahedra via the well-known Lindeberg\nmethod. As far as we are aware such a generalization of the Lindeberg method\nwas unknown. Second, we prove an upper bound on noise sensitivity and a\nLittlewood-Offord theorem for positive spectrahedra. Using these results, we\ngive applications for constructing PRGs for positive spectrahedra, learning\ntheory, discrepancy sets for positive spectrahedra (over the Boolean cube) and\nPRGs for intersections of structured polynomial threshold functions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 14:05:49 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:56:24 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Yao", "Penghui", ""]]}, {"id": "2101.08377", "submitter": "Sebastian Rudolph", "authors": "Emanuel Kiero\\'nski and Sebastian Rudolph", "title": "Finite Model Theory of the Triguarded Fragment and Related Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC math.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Triguarded Fragment (TGF) is among the most expressive decidable\nfragments of first-order logic, subsuming both its two-variable and guarded\nfragments without equality. We show that the TGF has the finite model property\n(providing a tight doubly exponential bound on the model size) and hence finite\nsatisfiability coincides with satisfiability known to be N2ExpTime-complete.\nUsing similar constructions, we also establish 2ExpTime-completeness for finite\nsatisfiability of the constant-free (tri)guarded fragment with transitive\nguards.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 00:47:50 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 08:56:14 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Kiero\u0144ski", "Emanuel", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "2101.08381", "submitter": "Alexander Meiburg", "authors": "Alex Meiburg", "title": "Quantum Constraint Problems can be complete for $\\mathsf{BQP}$,\n  $\\mathsf{QCMA}$, and more", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quantum constraint problem is a frustration-free Hamiltonian problem: given\na collection of local operators, is there a state that is in the ground state\nof each operator simultaneously? It has previously been shown that these\nproblems can be in P, NP-complete, MA-complete, or QMA_1-complete, but this\nlist has not been shown to be exhaustive. We present three quantum constraint\nproblems, that are (1) BQP_1-complete (also known as coRQP), (2)\nQCMA_1-complete and (3) coRP-complete. This provides the first natural complete\nproblem for BQP_1. We also show that all quantum constraint problems can be\nrealized on qubits, a trait not shared with classical constraint problems.\nThese results suggest a significant diversity of complexity classes present in\nquantum constraint problems.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 01:08:04 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 19:50:53 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 00:08:03 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Meiburg", "Alex", ""]]}, {"id": "2101.08600", "submitter": "Nikolay Proskurin", "authors": "Nikolay V. Proskurin", "title": "On Separation between the Degree of a Boolean Function and the Block\n  Sensitivity", "comments": "16 pages in total (12 for article + 4 for references and appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we study the separation between two complexity measures: the\ndegree of a Boolean function as a polynomial over the reals and its block\nsensitivity. We show that separation between these two measures can be improved\nfrom $ d^2(f) \\geq bs(f) $, established by Tal, to $ d^2(f) \\geq (\\sqrt{10} -\n2)bs(f) $. As a corollary, we show that separations between some other\ncomplexity measures are not tight as well, for instance, we can improve recent\nsensitivity conjecture result by Huang to $s^4(f) \\geq (\\sqrt{10} - 2)bs(f)$.\nOur techniques are based on paper by Nisan and Szegedy and include more\ndetailed analysis of a symmetrization polynomial.\n  In our next result we show the same type of improvement in the separation\nbetween the approximate degree of a Boolean function and its block sensitivity:\nwe show that $deg_{1/3}^2(f) \\geq \\sqrt{6/101} bs(f)$ and improve the previous\nresult by Nisan and Szegedy $ deg_{1/3}(f) \\geq \\sqrt{bs(f)/6} $. In addition,\nwe construct an example which shows that gap between constants in the lower\nbound and in the known upper bound is less than $0.2$.\n  In our last result we study the properties of conjectured fully sensitive\nfunction on 10 variables of degree 4, existence of which would lead to\nimprovement of the biggest known gap between these two measures. We prove that\nthere is the only univariate polynomial that can be achieved by symmetrization\nof this function by using the combination of interpolation and linear\nprogramming techniques.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 13:41:40 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 06:43:17 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Proskurin", "Nikolay V.", ""]]}, {"id": "2101.08735", "submitter": "Jonas Schmidt", "authors": "Jonas Schmidt, Thomas Schwentick, Till Tantau, Nils Vortmeier, Thomas\n  Zeume", "title": "Work-sensitive Dynamic Complexity of Formal Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Which amount of parallel resources is needed for updating a query result\nafter changing an input? In this work we study the amount of work required for\ndynamically answering membership and range queries for formal languages in\nparallel constant time with polynomially many processors. As a prerequisite, we\npropose a framework for specifying dynamic, parallel, constant-time programs\nthat require small amounts of work. This framework is based on the dynamic\ndescriptive complexity framework by Patnaik and Immerman.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 17:25:47 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Schmidt", "Jonas", ""], ["Schwentick", "Thomas", ""], ["Tantau", "Till", ""], ["Vortmeier", "Nils", ""], ["Zeume", "Thomas", ""]]}, {"id": "2101.09005", "submitter": "Nicholas Coxon", "authors": "Nicholas Coxon (GRACE)", "title": "An in-place truncated Fourier transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that simple modifications to van der Hoeven's forward and inverse\ntruncated Fourier transforms allow the algorithms to be performed in-place, and\nwith only a linear overhead in complexity.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 08:51:06 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Coxon", "Nicholas", "", "GRACE"]]}, {"id": "2101.09147", "submitter": "Jesus Fuentes", "authors": "Jes\\'us Fuentes and Octavio Obreg\\'on", "title": "A superstatistical formulation of complexity measures", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math-ph math.MP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is discussed how the superstatistical formulation of effective Boltzmann\nfactors can be related to the concept of Kolmogorov complexity, generating an\ninfinite set of complexity measures (CMs) for quantifying information. At this\nlevel, the information is treated according to its background, which means that\nthe CM depends on the inherent attributes of the information scenario. While\nthe basic Boltzmann factor directly produces the standard complexity measure\n(SCM), it succeeds in the description of large-scale scenarios where the data\ncomponents are not interrelated with themselves, thus adopting the behaviour of\na gas. What happens in scenarios in which the presence of sources and sinks of\ninformation cannot be neglected, needs of a CM other than the one produced by\nthe ordinary Boltzmann factor. We introduce a set of flexible CMs, without free\nparameters, that converge asymptotically to the Kolmogorov complexity, but also\nquantify the information in scenarios with a reasonable small density of\nstates. We prove that these CMs are obtained from a generalised relative\nentropy and we suggest why such measures are the only compatible\ngeneralisations of the SCM.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 23:19:14 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Fuentes", "Jes\u00fas", ""], ["Obreg\u00f3n", "Octavio", ""]]}, {"id": "2101.09332", "submitter": "Perrot K\\'evin", "authors": "Viet-Ha Nguyen and K\\'evin Perrot", "title": "Rikudo is NP-complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rikudo is a number-placement puzzle, where the player is asked to complete a\nHamiltonian path on a hexagonal grid, given some clues (numbers already placed\nand edges of the path). We prove that the game is complete for NP, even if the\npuzzle has no hole. When all odd numbers are placed it is in P, whereas it is\nstill NP-hard when all numbers of the form $3k+1$ are placed.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 21:07:22 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Nguyen", "Viet-Ha", ""], ["Perrot", "K\u00e9vin", ""]]}, {"id": "2101.09336", "submitter": "Hadjer Benmeziane", "authors": "Hadjer Benmeziane, Kaoutar El Maghraoui, Hamza Ouarnoughi, Smail Niar,\n  Martin Wistuba, Naigang Wang", "title": "A Comprehensive Survey on Hardware-Aware Neural Architecture Search", "comments": "Submitted to Proceedings of IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) methods have been growing in popularity.\nThese techniques have been fundamental to automate and speed up the time\nconsuming and error-prone process of synthesizing novel Deep Learning (DL)\narchitectures. NAS has been extensively studied in the past few years. Arguably\ntheir most significant impact has been in image classification and object\ndetection tasks where the state of the art results have been obtained. Despite\nthe significant success achieved to date, applying NAS to real-world problems\nstill poses significant challenges and is not widely practical. In general, the\nsynthesized Convolution Neural Network (CNN) architectures are too complex to\nbe deployed in resource-limited platforms, such as IoT, mobile, and embedded\nsystems. One solution growing in popularity is to use multi-objective\noptimization algorithms in the NAS search strategy by taking into account\nexecution latency, energy consumption, memory footprint, etc. This kind of NAS,\ncalled hardware-aware NAS (HW-NAS), makes searching the most efficient\narchitecture more complicated and opens several questions.\n  In this survey, we provide a detailed review of existing HW-NAS research and\ncategorize them according to four key dimensions: the search space, the search\nstrategy, the acceleration technique, and the hardware cost estimation\nstrategies. We further discuss the challenges and limitations of existing\napproaches and potential future directions. This is the first survey paper\nfocusing on hardware-aware NAS. We hope it serves as a valuable reference for\nthe various techniques and algorithms discussed and paves the road for future\nresearch towards hardware-aware NAS.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 21:13:46 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Benmeziane", "Hadjer", ""], ["Maghraoui", "Kaoutar El", ""], ["Ouarnoughi", "Hamza", ""], ["Niar", "Smail", ""], ["Wistuba", "Martin", ""], ["Wang", "Naigang", ""]]}, {"id": "2101.09528", "submitter": "Nikita Gaevoy", "authors": "Nikita Gaevoy", "title": "Hard satisfiable formulas for DPLL algorithms using heuristics with\n  small memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DPLL algorithm for solving the Boolean satisfiability problem (SAT) can be\nrepresented in the form of a procedure that, using heuristics $A$ and $B$,\nselect the variable $x$ from the input formula $\\varphi$ and the value $b$ and\nruns recursively on the formulas $\\varphi[x := b]$ and $\\varphi[x := 1 - b]$.\nExponential lower bounds on the running time of DPLL algorithms on\nunsatisfiable formulas follow from the lower bounds for tree-like resolution\nproofs. Lower bounds on satisfiable formulas are also known for some classes of\nDPLL algorithms such as \"myopic\" and \"drunken\" algorithms.\n  All lower bounds are made for the classes of DPLL algorithms that limit\nheuristics access to the formula. In this paper we consider DPLL algorithms\nwith heuristics that have unlimited access to the formula but use small memory.\nWe show that for any pair of heuristics with small memory there exists a family\nof satisfiable formulas $\\Phi_n$ such that a DPLL algorithm that uses these\nheuristics runs in exponential time on the formulas $\\Phi_n$.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 16:01:14 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Gaevoy", "Nikita", ""]]}, {"id": "2101.09592", "submitter": "Noah Singer", "authors": "Noah Singer and Madhu Sudan", "title": "Point-hyperplane incidence geometry and the log-rank conjecture", "comments": "14 pages, no figures. This includes revised introduction and\n  discussion and is (hopefully) final for conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the log-rank conjecture from the perspective of incidence geometry\nand present a reformulation as well as a strengthening. The reformulation\ninvolves point sets in $\\mathbb{R}^d$ that are covered in many ways by constant\nsized sets of parallel hyperplanes. We show that the log-rank conjecture is\nequivalent to the implication that all such configurations contain a subspace\nthat accounts for a large fraction of the incidences, in the sense of\ncontaining a large fraction of the points and being contained in a large\nfraction of the hyperplanes. In other words the log-rank conjecture is\nequivalent to asserting that the point-hyperplane incidence graph for such\nconfigurations has a large complete bipartite subgraph. The strengthening of\nthe log-rank conjecture comes from relaxing the requirements that the set of\nhyperplanes be parallel.\n  Motivated by the connections above we revisit some well-studied questions in\npoint-hyperplane incidence geometry and present some improvements. We give a\nsimple probabilistic argument for the existence of complete bipartite subgraphs\nof density $\\Omega(\\epsilon^{2d}/d)$ in any $d$-dimensional configuration with\nincidence density $\\epsilon$, matching previously known results qualitatively.\nWe also improve an upper-bound construction of Apfelbaum and Sharir, yielding a\nconfiguration whose complete bipartite subgraphs are exponentially small and\nwhose incidence density is $\\Omega(1/\\sqrt d)$.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 21:59:56 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 18:54:32 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 03:47:22 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Singer", "Noah", ""], ["Sudan", "Madhu", ""]]}, {"id": "2101.09693", "submitter": "Mohsen Ahmadzadeh", "authors": "Mohsen Ahmadzadeh, Mehdi Kamal, Ali Afzali-Kusha, Massoud Pedram", "title": "A2P-MANN: Adaptive Attention Inference Hops Pruned Memory-Augmented\n  Neural Networks", "comments": "10 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, to limit the number of required attention inference hops in\nmemory-augmented neural networks, we propose an online adaptive approach called\nA2P-MANN. By exploiting a small neural network classifier, an adequate number\nof attention inference hops for the input query is determined. The technique\nresults in elimination of a large number of unnecessary computations in\nextracting the correct answer. In addition, to further lower computations in\nA2P-MANN, we suggest pruning weights of the final FC (fully-connected) layers.\nTo this end, two pruning approaches, one with negligible accuracy loss and the\nother with controllable loss on the final accuracy, are developed. The efficacy\nof the technique is assessed by using the twenty question-answering (QA) tasks\nof bAbI dataset. The analytical assessment reveals, on average, more than 42%\nfewer computations compared to the baseline MANN at the cost of less than 1%\naccuracy loss. In addition, when used along with the previously published\nzero-skipping technique, a computation count reduction of up to 68% is\nachieved. Finally, when the proposed approach (without zero-skipping) is\nimplemented on the CPU and GPU platforms, up to 43% runtime reduction is\nachieved.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 12:02:12 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Ahmadzadeh", "Mohsen", ""], ["Kamal", "Mehdi", ""], ["Afzali-Kusha", "Ali", ""], ["Pedram", "Massoud", ""]]}, {"id": "2101.09736", "submitter": "Hossein Boomari", "authors": "Hossein Boomari Mojtaba Ostovari Alireza Zarei", "title": "Recognizing Visibility Graphs of Triangulated Irregular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Triangulated Irregular Network (TIN) is a data structure that is usually\nused for representing and storing monotone geographic surfaces, approximately.\nIn this representation, the surface is approximated by a set of triangular\nfaces whose projection on the XY-plane is a triangulation. The visibility graph\nof a TIN is a graph whose vertices correspond to the vertices of the TIN and\nthere is an edge between two vertices if their corresponding vertices on TIN\nsee each other, i.e. the segment that connects these vertices completely lies\nabove the TIN. Computing the visibility graph of a TIN and its properties have\nbeen considered thoroughly in the literature. In this paper, we consider this\nproblem in reverse: Given a graph G, is there a TIN with the same visibility\ngraph as G? We show that this problem is Complete for Existential Theory of The\nReals.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 15:50:08 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Zarei", "Hossein Boomari Mojtaba Ostovari Alireza", ""]]}, {"id": "2101.09918", "submitter": "Elham Havvaei", "authors": "David Eppstein, Siddharth Gupta, Elham Havvaei", "title": "Parameterized Complexity of Finding Subgraphs with Hereditary Properties\n  on Hereditary Graph Classes", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the parameterized complexity of finding subgraphs with\nhereditary properties on graphs belonging to a hereditary graph class. Given a\ngraph $G$, a non-trivial hereditary property $\\Pi$ and an integer parameter\n$k$, the general problem $P(G,\\Pi,k)$ asks whether there exists $k$ vertices of\n$G$ that induce a subgraph satisfying property $\\Pi$. This problem,\n$P(G,\\Pi,k)$ has been proved to be NP-complete by Lewis and Yannakakis. The\nparameterized complexity of this problem is shown to be W[1]-complete by Khot\nand Raman, if $\\Pi$ includes all trivial graphs but not all complete graphs and\nvice versa; and is fixed-parameter tractable (FPT), otherwise. As the problem\nis W[1]-complete on general graphs when $\\Pi$ includes all trivial graphs but\nnot all complete graphs and vice versa, it is natural to further investigate\nthe problem on restricted graph classes.\n  Motivated by this line of research, we study the problem on graphs which also\nbelong to a hereditary graph class and establish a framework which settles the\nparameterized complexity of the problem for various hereditary graph classes.\nIn particular, we show that:\n  $P(G,\\Pi,k)$ is solvable in polynomial time when the graph $G$ is\nco-bipartite and $\\Pi$ is the property of being planar, bipartite or\ntriangle-free (or vice-versa).\n  $P(G,\\Pi,k)$ is FPT when the graph $G$ is planar, bipartite or triangle-free\nand $\\Pi$ is the property of being planar, bipartite or triangle-free, or graph\n$G$ is co-bipartite and $\\Pi$ is the property of being co-bipartite.\n  $P(G,\\Pi,k)$ is W[1]-complete when the graph $G$ is $C_4$-free,\n$K_{1,4}$-free or a unit disk graph and $\\Pi$ is the property of being either\nplanar or bipartite.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 07:04:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Eppstein", "David", ""], ["Gupta", "Siddharth", ""], ["Havvaei", "Elham", ""]]}, {"id": "2101.10907", "submitter": "Stephen Wolfram", "authors": "Stephen Wolfram", "title": "Exploring Rulial Space: The Case of Turing Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As an example of the concept of rulial space, we explore the case of simple\nTuring machines. We construct the rulial multiway graph which represents the\nbehavior of all possible Turing machines with a certain class of rules. This\ngraph (which is a Cayley graph of a \"Turing machine group\") gives a map of the\nspace of non-deterministic Turing machines. We investigate the subgraph formed\nby deterministic machines, and explore the relationship to the P vs. NP\nproblem. We also consider the implications of features of rulial space for\nphysics, including estimating the maximum speed \\r{ho} in rulial space,\nrelations between rulial black holes and computational reducibility, and\ninterpretations of hypercomputation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 21:10:49 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Wolfram", "Stephen", ""]]}, {"id": "2101.11087", "submitter": "Honghao Fu", "authors": "Honghao Fu, Carl A. Miller and William Slofstra", "title": "The membership problem for constant-sized quantum correlations is\n  undecidable", "comments": "68 pages and 1 figure. All comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When two spatially separated parties make measurements on an unknown\nentangled quantum state, what correlations can they achieve? How difficult is\nit to determine whether a given correlation is a quantum correlation? These\nquestions are central to problems in quantum communication and computation.\nPrevious work has shown that the general membership problem for quantum\ncorrelations is computationally undecidable. In the current work we show\nsomething stronger: there is a family of constant-sized correlations -- that\nis, correlations for which the number of measurements and number of measurement\noutcomes are fixed -- such that solving the quantum membership problem for this\nfamily is computationally impossible. Thus, the undecidability that arises in\nunderstanding Bell experiments is not dependent on varying the number of\nmeasurements in the experiment. This places strong constraints on the types of\ndescriptions that can be given for quantum correlation sets. Our proof is based\non a combination of techniques from quantum self-testing and from\nundecidability results of the third author for linear system nonlocal games.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 21:15:25 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Fu", "Honghao", ""], ["Miller", "Carl A.", ""], ["Slofstra", "William", ""]]}, {"id": "2101.11152", "submitter": "Donald Stull", "authors": "D.M. Stull", "title": "Optimal Oracles for Point-to-Set Principles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The point-to-set principle \\cite{LutLut17} characterizes the Hausdorff\ndimension of a subset $E\\subseteq\\R^n$ by the \\textit{effective} (or\nalgorithmic) dimension of its individual points. This characterization has been\nused to prove several results in classical, i.e., without any computability\nrequirements, analysis. Recent work has shown that algorithmic techniques can\nbe fruitfully applied to Marstrand's projection theorem, a fundamental result\nin fractal geometry.\n  In this paper, we introduce an extension of point-to-set principle - the\nnotion of \\textit{optimal oracles} for subsets $E\\subseteq\\R^n$. One of the\nprimary motivations of this definition is that, if $E$ has optimal oracles,\nthen the conclusion of Marstrand's projection theorem holds for $E$. We show\nthat every analytic set has optimal oracles. We also prove that if the\nHausdorff and packing dimensions of $E$ agree, then $E$ has optimal oracles.\nMoreover, we show that the existence of sufficiently nice outer measures on $E$\nimplies the existence of optimal Hausdorff oracles. In particular, the\nexistence of exact gauge functions for a set $E$ is sufficient for the\nexistence of optimal Hausdorff oracles, and is therefore sufficient for\nMarstrand's theorem. Thus, the existence of optimal oracles extends the\ncurrently known sufficient conditions for Marstrand's theorem to hold.\n  Under certain assumptions, every set has optimal oracles. However, assuming\nthe axiom of choice and the continuum hypothesis, we construct sets which do\nnot have optimal oracles. This construction naturally leads to a generalization\nof Davies theorem on projections.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 01:11:36 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 05:10:00 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Stull", "D. M.", ""]]}, {"id": "2101.11500", "submitter": "Simran Tinani", "authors": "Simran Tinani and Joachim Rosenthal", "title": "A Deterministic Algorithm for the Discrete Logarithm Problem in a\n  Semigroup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrete logarithm problem in a finite group is the basis for many\nprotocols in cryptography. The best general algorithms which solve this problem\nhave time complexity of $\\mathcal{O}(\\sqrt{N})$, where $N$ is the order of the\ngroup. These algorithms require the inversion of some some group elements or\nrely on finding collisions, and thus do not adapt to work in the general\nsemigroup setting. For semigroups, probabilistic algorithms with similar time\ncomplexity have been proposed. The main result of this paper is a deterministic\nalgorithm for solving the discrete logarithm problem in a semigroup.\nSpecifically, let $x$ be an element in a semigroup having finite order $N_x$.\nIf $y\\in \\langle x \\rangle $ is given the paper provides an algorithm having\ntime complexity $O(\\sqrt{N_x}\\log N_x)$ to find all natural numbers m with\n$x^m=y$. The paper also give an analysis of the success rates of the existing\nprobabilistic algorithms, which were so far only conjectured or stated loosely.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 15:52:54 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 15:39:57 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 10:30:04 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Tinani", "Simran", ""], ["Rosenthal", "Joachim", ""]]}, {"id": "2101.11727", "submitter": "Cristina Feier", "authors": "Cristina Feier", "title": "Characterising Fixed Parameter Tractability of Query Evaluation over\n  Guarded TGDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of evaluating Ontology Mediated Queries\n(OMQs) based on Guarded TGDs (GTGDs) and Unions of Conjunctive Queries (UCQs),\nin the case where relational symbols have unrestricted arity and where the\nparameter is the size of the OMQ. We establish exact criteria for\nfixed-parameter tractability (fpt) evaluation of recursively enumerable classes\nof such OMQs (under the widely held Exponential Time Hypothesis). One of the\nmain technical tools introduced in the paper is an fpt-reduction from deciding\nparameterized uniform CSPs to parameterized OMQ evaluation. The reduction\npreserves measures which are known to be essential for classifying recursively\nenumerable classes of parameterized uniform CSPs: submodular width (according\nto the well known result of Marx for unrestricted-arity schemas) and treewidth\n(according to the well known result of Grohe for bounded-arity schemas). As\nsuch, it can be employed to obtain hardness results for evaluation of\nrecursively enumerable classes of parameterized OMQs both in the unrestricted\nand in the bounded arity case. Previously, in the case of bounded arity\nschemas, this has been tackled using a technique requiring full introspection\ninto the construction employed by Grohe.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:32:16 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:08:08 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Feier", "Cristina", ""]]}, {"id": "2101.11750", "submitter": "Chuteng Zhou", "authors": "Chuteng Zhou, Quntao Zhuang, Matthew Mattina, Paul N. Whatmough", "title": "Information contraction in noisy binary neural networks and its\n  implications", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.CC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have gained importance as the machine learning models that\nachieve state-of-the-art performance on large-scale image classification,\nobject detection and natural language processing tasks. In this paper, we\nconsider noisy binary neural networks, where each neuron has a non-zero\nprobability of producing an incorrect output. These noisy models may arise from\nbiological, physical and electronic contexts and constitute an important class\nof models that are relevant to the physical world. Intuitively, the number of\nneurons in such systems has to grow to compensate for the noise while\nmaintaining the same level of expressive power and computation reliability. Our\nkey finding is a lower bound for the required number of neurons in noisy neural\nnetworks, which is first of its kind. To prove this lower bound, we take an\ninformation theoretic approach and obtain a novel strong data processing\ninequality (SDPI), which not only generalizes the Evans-Schulman results for\nbinary symmetric channels to general channels, but also improves the tightness\ndrastically when applied to estimate end-to-end information contraction in\nnetworks. Our SDPI can be applied to various information processing systems,\nincluding neural networks and cellular automata. Applying the SDPI in noisy\nbinary neural networks, we obtain our key lower bound and investigate its\nimplications on network depth-width trade-offs, our results suggest a\ndepth-width trade-off for noisy neural networks that is very different from the\nestablished understanding regarding noiseless neural networks. Furthermore, we\napply the SDPI to study fault-tolerant cellular automata and obtain bounds on\nthe error correction overheads and the relaxation time. This paper offers new\nunderstanding of noisy information processing systems through the lens of\ninformation theory.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 00:01:45 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 17:19:25 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhou", "Chuteng", ""], ["Zhuang", "Quntao", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul N.", ""]]}, {"id": "2101.11934", "submitter": "Andrea Galassi", "authors": "Andrea Galassi", "title": "An Upper Bound on the Complexity of Tablut", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Tablut is a complete-knowledge, deterministic, and asymmetric board game,\nwhich has not been solved nor properly studied yet. In this work, its rules and\ncharacteristics are presented, then a study on its complexity is reported. An\nupper bound to its complexity is found eventually by dividing the state-space\nof the game into subspaces according to specific conditions. This upper bound\nis comparable to the one found for Draughts, therefore, it would seem that the\nopen challenge of solving this game requires a considerable computational\neffort.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 11:14:04 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Galassi", "Andrea", ""]]}, {"id": "2101.12018", "submitter": "Yannick Schmitz", "authors": "Yannick Schmitz, Duygu Vietz, Egon Wanke", "title": "A note on the complexity of k-Metric Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two vertices $u, v \\in V$ of an undirected connected graph $G=(V,E)$ are\nresolved by a vertex $w$ if the distance between $u$ and $w$ and the distance\nbetween $v$ and $w$ are different. A set $R \\subseteq V$ of vertices is a\n$k$-resolving set for $G$ if for each pair of vertices $u, v \\in V$ there are\nat least $k$ distinct vertices $w_1,\\ldots,w_k \\in R$ such that each of them\nresolves $u$ and $v$. The $k$-Metric Dimension of $G$ is the size of a smallest\n$k$-resolving set for $G$. The decision problem $k$-Metric Dimension is the\nquestion whether G has a $k$-resolving set of size at most $r$, for a given\ngraph $G$ and a given number $r$. In this paper, we proof the NP-completeness\nof $k$-Metric Dimension for bipartite graphs and each $k \\geq 2$.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 14:35:28 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Schmitz", "Yannick", ""], ["Vietz", "Duygu", ""], ["Wanke", "Egon", ""]]}, {"id": "2101.12033", "submitter": "Markus P. Mueller", "authors": "Marius Krumm, Markus P. Mueller", "title": "Computational irreducibility and compatibilism: towards a formalization", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.hist-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If our actions are determined by the laws of nature, can we meaningfully\nclaim to possess free will? Compatibilists argue that the answer is yes, and\nthat free will is compatible with complete determinism. Previously, it has been\nsuggested that the notion of computational irreducibility can shed light on\nthis relation: it implies that there cannot in general be \"shortcuts\" to the\ndecisions of agents, explaining why deterministic agents often appear to have\nfree will. In this paper, we introduce a variant of computational\nirreducibility that intends to capture more accurately aspects of actual (as\nopposed to apparent) free will: computational sourcehood, i.e. the phenomenon\nthat the successful prediction of a process' outputs must typically involve an\nalmost-exact representation of the relevant features of that process,\nregardless of the time it takes to arrive at the prediction. We conjecture that\nmany processes have this property, and we study different possibilities for how\nto formalize this conjecture in terms of universal Turing machines. While we\nare not able to settle the conjecture, we give several results and\nconstructions that shed light on the quest for its correct formulation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 16:19:54 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Krumm", "Marius", ""], ["Mueller", "Markus P.", ""]]}, {"id": "2101.12524", "submitter": "Aviram Imber", "authors": "Aviram Imber, Benny Kimelfeld", "title": "Probabilistic Inference of Winners in Elections by Independent Random\n  Voters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of computing the probability of winning in an\nelection where voter attendance is uncertain. More precisely, we study the\nsetting where, in addition to a total ordering of the candidates, each voter is\nassociated with a probability of attending the poll, and the attendances of\ndifferent voters are probabilistically independent. We show that the\nprobability of winning can be computed in polynomial time for the plurality and\nveto rules. However, it is computationally hard (#P-hard) for various other\nrules, including $k$-approval and $k$-veto for $k>1$, Borda, Condorcet, and\nMaximin. For some of these rules, it is even hard to find a multiplicative\napproximation since it is already hard to determine whether this probability is\nnonzero. In contrast, we devise a fully polynomial-time randomized\napproximation scheme (FPRAS) for the complement probability, namely the\nprobability of losing, for every positional scoring rule (with polynomial\nscores), as well as for the Condorcet rule.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 11:21:00 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Imber", "Aviram", ""], ["Kimelfeld", "Benny", ""]]}, {"id": "2101.12568", "submitter": "Alexandre Sedoglavic", "authors": "Alexandre Sedoglavic, Alexey V. Smirnov", "title": "The tensor rank of 5x5 matrices multiplication is bounded by 98 and its\n  border rank by 89", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a non-commutative algorithm for the product of 3x5 by 5x5 matrices\nusing 58 multiplications. This algorithm allows to construct a non-commutative\nalgorithm for multiplying 5x5 (resp. 10x10, 15x15) matrices using 98 (resp.\n686, 2088) multiplications. Furthermore, we describe an approximate algorithm\nthat requires 89 multiplications and computes this product with an arbitrary\nsmall error.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 13:35:56 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 11:29:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Sedoglavic", "Alexandre", ""], ["Smirnov", "Alexey V.", ""]]}, {"id": "2101.12582", "submitter": "Sayantan Choudhury", "authors": "Sayantan Choudhury, Sachin Panneer Selvam, K. Shirish", "title": "Circuit Complexity From Supersymmetric Quantum Field Theory With Morse\n  Function", "comments": "39 pages, 10 figures, 4 tables, This project is the part of the\n  non-profit virtual international research consortium \"Quantum Aspects of\n  Space-Time and Matter (QASTM)\", Revised version, References and some of the\n  explanations elaborated and updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th cond-mat.dis-nn cs.CC nlin.CD quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation of circuit complexity has gained much attention in the\nTheoretical Physics community in recent times to gain insights about the\nchaotic features and random fluctuations of fields in the quantum regime.\nRecent studies of circuit complexity take inspiration from the geometric\napproach of Nielsen, which itself is based on the idea of optimal quantum\ncontrol in which a cost function is introduced for the various possible path to\ndetermine the optimum circuit. In this paper, we study the relationship between\nthe circuit complexity and Morse theory within the framework of algebraic\ntopology using which we study circuit complexity in supersymmetric quantum\nfield theory describing both simple and inverted harmonic oscillators up to\nhigher orders of quantum corrections. The expression of circuit complexity in\nquantum regime would then be given by the Hessian of the Morse function in\nsupersymmetric quantum field theory, and try to draw conclusion from their\ngraphical behaviour. We also provide a technical proof of the well known\nuniversal connecting relation between quantum chaos and circuit complexity of\nthe supersymmetric quantum field theories, using the general description of\nMorse theory.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 19:26:45 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 14:17:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Choudhury", "Sayantan", ""], ["Selvam", "Sachin Panneer", ""], ["Shirish", "K.", ""]]}, {"id": "2101.12621", "submitter": "Ran J. Tessler", "authors": "Tali Kaufman and Ran J. Tessler", "title": "Local to global high dimensional expansion and Garland's method for\n  general posets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In simplicial complexes it is well known that many of the global properties\nof the complex, can be deduced from expansion properties of its links. This\nphenomenon was first discovered by Garland [G]. In this work we develop a local\nto global machinery for general posets. We first show that the basic\nlocalization principle of Garland generalizes to more general posets. We then\nshow that notable local to global theorems for simplicial complexes arise from\ngeneral principles for general posets with expanding links. Specifically, we\nprove the following theorems for general posets satisfying some assumptions:\nExpanding links (one sided expansion) imply fast convergence of high\ndimensional random walks (generalization [KO,AL]); Expanding links imply\nTrickling down theorem (generalizing [O]); and a poset has expanding links\n(with two sided expansion) iff it satisfies a global random walk convergence\nproperty (generalization [DDFH]). We axiomatize general conditions on posets\nthat imply local to global theorems. By developing this local to global\nmachinery for general posets we discover that some posets behave better than\nsimplicial complexes with respect to local to global implications.\nSpecifically, we get a trickling down theorem for some posets (e.g. the\nGrassmanian poset) which is better behaved than the trickling down theorem\nknown for simplicial complexes. In addition to this machinery, we also present\na method to construct a new poset out of a pair of an initial poset and an\nauxiliary simplicial complex. By applying this procedure to the case where the\npair is the Grassmanian poset and a bounded degree high dimensional expander,\nwe obtain a bounded degree Grassmanian poset. We prove, using the tools\ndescribed above, that this poset is a bounded degree expanding Grassmanian\nposet, partially proving a conjecture of [DDFH].\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 15:02:37 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Kaufman", "Tali", ""], ["Tessler", "Ran J.", ""]]}]