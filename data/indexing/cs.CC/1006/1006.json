[{"id": "1006.0051", "submitter": "Hector Zenil", "authors": "Hector Zenil, Jean-Paul Delahaye and Cedric Gaucherel", "title": "Image Characterization and Classification by Physical Complexity", "comments": "30 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for estimating the complexity of an image based on\nBennett's concept of logical depth. Bennett identified logical depth as the\nappropriate measure of organized complexity, and hence as being better suited\nto the evaluation of the complexity of objects in the physical world. Its use\nresults in a different, and in some sense a finer characterization than is\nobtained through the application of the concept of Kolmogorov complexity alone.\nWe use this measure to classify images by their information content. The method\nprovides a means for classifying and evaluating the complexity of objects by\nway of their visual representations. To the authors' knowledge, the method and\napplication inspired by the concept of logical depth presented herein are being\nproposed and implemented for the first time.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2010 03:23:25 GMT"}, {"version": "v2", "created": "Fri, 17 Dec 2010 01:19:44 GMT"}, {"version": "v3", "created": "Wed, 2 Feb 2011 22:20:54 GMT"}, {"version": "v4", "created": "Mon, 2 May 2011 20:06:06 GMT"}, {"version": "v5", "created": "Sun, 3 Jul 2011 08:38:50 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Zenil", "Hector", ""], ["Delahaye", "Jean-Paul", ""], ["Gaucherel", "Cedric", ""]]}, {"id": "1006.0220", "submitter": "Michael Thomas", "authors": "Nadia Creignou, Arne Meier, Michael Thomas, and Heribert Vollmer", "title": "The Complexity of Reasoning for Fragments of Autoepistemic Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoepistemic logic extends propositional logic by the modal operator L. A\nformula that is preceded by an L is said to be \"believed\". The logic was\nintroduced by Moore 1985 for modeling an ideally rational agent's behavior and\nreasoning about his own beliefs. In this paper we analyze all Boolean fragments\nof autoepistemic logic with respect to the computational complexity of the\nthree most common decision problems expansion existence, brave reasoning and\ncautious reasoning. As a second contribution we classify the computational\ncomplexity of counting the number of stable expansions of a given knowledge\nbase. To the best of our knowledge this is the first paper analyzing the\ncounting problem for autoepistemic logic.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2010 19:40:43 GMT"}], "update_date": "2010-06-02", "authors_parsed": [["Creignou", "Nadia", ""], ["Meier", "Arne", ""], ["Thomas", "Michael", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1006.0394", "submitter": "EPTCS", "authors": "Matthew S. Bauer (Arcadia University), Xizhong Zheng (Arcadia\n  University)", "title": "On the Weak Computability of Continuous Real Functions", "comments": null, "journal-ref": "EPTCS 24, 2010, pp. 29-40", "doi": "10.4204/EPTCS.24.8", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computable analysis, sequences of rational numbers which effectively\nconverge to a real number x are used as the (rho-) names of x. A real number x\nis computable if it has a computable name, and a real function f is computable\nif there is a Turing machine M which computes f in the sense that, M accepts\nany rho-name of x as input and outputs a rho-name of f(x) for any x in the\ndomain of f. By weakening the effectiveness requirement of the convergence and\nclassifying the converging speeds of rational sequences, several interesting\nclasses of real numbers of weak computability have been introduced in\nliterature, e.g., in addition to the class of computable real numbers (EC), we\nhave the classes of semi-computable (SC), weakly computable (WC), divergence\nbounded computable (DBC) and computably approximable real numbers (CA). In this\npaper, we are interested in the weak computability of continuous real functions\nand try to introduce an analogous classification of weakly computable real\nfunctions. We present definitions of these functions by Turing machines as well\nas by sequences of rational polygons and prove these two definitions are not\nequivalent. Furthermore, we explore the properties of these functions, and\namong others, show their closure properties under arithmetic operations and\ncomposition.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 14:30:07 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Bauer", "Matthew S.", "", "Arcadia University"], ["Zheng", "Xizhong", "", "Arcadia\n  University"]]}, {"id": "1006.0399", "submitter": "EPTCS", "authors": "Vassilios Gregoriades (Technische Universitaet Darmstadt)", "title": "The descriptive set-theoretic complexity of the set of points of\n  continuity of a multi-valued function (Extended Abstract)", "comments": null, "journal-ref": "EPTCS 24, 2010, pp. 92-100", "doi": "10.4204/EPTCS.24.13", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we treat a notion of continuity for a multi-valued function F\nand we compute the descriptive set-theoretic complexity of the set of all x for\nwhich F is continuous at x. We give conditions under which the latter set is\neither a G_\\delta set or the countable union of G_\\delta sets. Also we provide\na counterexample which shows that the latter result is optimum under the same\nconditions. Moreover we prove that those conditions are necessary in order to\nobtain that the set of points of continuity of F is Borel i.e., we show that if\nwe drop some of the previous conditions then there is a multi-valued function F\nwhose graph is a Borel set and the set of points of continuity of F is not a\nBorel set. Finally we give some analogue results regarding a stronger notion of\ncontinuity for a multi-valued function. This article is motivated by a question\nof M. Ziegler in \"Real Computation with Least Discrete Advice: A Complexity\nTheory of Nonuniform Computability with Applications to Linear Algebra\",\n(submitted).\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 14:30:31 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Gregoriades", "Vassilios", "", "Technische Universitaet Darmstadt"]]}, {"id": "1006.0400", "submitter": "EPTCS", "authors": "Dianchen Lu (Jiangsu University), Qingyan Wang (Jiangsu University),\n  Rui Zheng (Jiangsu University)", "title": "Computing the Solutions of the Combined Korteweg-de Vries Equation by\n  Turing Machines", "comments": null, "journal-ref": "EPTCS 24, 2010, pp. 101-105", "doi": "10.4204/EPTCS.24.14", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the computability of the initial value problem of the\nCombined KdV equation. It is shown that, for any integer s>2, the nonlinear\nsolution operator which maps an initial condition data to the solution of the\nCombined KdV equation can be computed by a Turing machine.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 14:30:36 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Lu", "Dianchen", "", "Jiangsu University"], ["Wang", "Qingyan", "", "Jiangsu University"], ["Zheng", "Rui", "", "Jiangsu University"]]}, {"id": "1006.0402", "submitter": "EPTCS", "authors": "Robert Rettinger", "title": "A Local to Global Principle for the Complexity of Riemann Mappings\n  (Extended Abstract)", "comments": null, "journal-ref": "EPTCS 24, 2010, pp. 120-129", "doi": "10.4204/EPTCS.24.16", "report-no": null, "categories": "cs.CC cs.LO cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the computational complexity of Riemann mappings can be bounded\nby the complexity needed to compute conformal mappings locally at boundary\npoints. As a consequence we get first formally proven upper bounds for\nSchwarz-Christoffel mappings and, more generally, Riemann mappings of domains\nwith piecewise analytic boundaries.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 14:30:45 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Rettinger", "Robert", ""]]}, {"id": "1006.0403", "submitter": "EPTCS", "authors": "Yuping Shen (Institute of Logic and Cognition, Sun Yat-sen\n  University), Xishun Zhao (Institute of Logic and Cognition, Sun Yat-sen\n  University)", "title": "NP-Logic Systems and Model-Equivalence Reductions", "comments": null, "journal-ref": "EPTCS 24, 2010, pp. 130-138", "doi": "10.4204/EPTCS.24.17", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the existence of model-equivalence reduction\nbetween NP-logic systems which are logic systems with model existence problem\nin NP. It is shown that among all NP-systems with model checking problem in NP,\nthe existentially quantified propositional logic (\\exists PF) is maximal with\nrespect to poly-time model-equivalent reduction. However, \\exists PF seems not\na maximal NP-system in general because there exits a NP-system with model\nchecking problem D^P-complete.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 14:30:50 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Shen", "Yuping", "", "Institute of Logic and Cognition, Sun Yat-sen\n  University"], ["Zhao", "Xishun", "", "Institute of Logic and Cognition, Sun Yat-sen\n  University"]]}, {"id": "1006.0406", "submitter": "EPTCS", "authors": "Yongcheng Wu (Nanjing University of Information Science and\n  Technology)", "title": "Complete Multi-Representations of Sets in a Computable Measure Space", "comments": null, "journal-ref": "EPTCS 24, 2010, pp. 160-166", "doi": "10.4204/EPTCS.24.20", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, two multi-representations for the measurable sets in a\ncomputable measure space have been introduced, which prove to be topologically\ncomplete w.r.t. certain topological properties. In this contribution, we show\nthem recursively complete w.r.t. computability of measure and set-theoretical\noperations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 14:31:06 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Wu", "Yongcheng", "", "Nanjing University of Information Science and\n  Technology"]]}, {"id": "1006.0469", "submitter": "David Zuckerman", "authors": "David Zuckerman", "title": "Certifiably Pseudorandom Financial Derivatives", "comments": "17 pages. An extended abstract of this paper appeared in EC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arora, Barak, Brunnermeier, and Ge showed that taking computational\ncomplexity into account, a dishonest seller could strategically place lemons in\nfinancial derivatives to make them substantially less valuable to buyers. We\nshow that if the seller is required to construct derivatives of a certain form,\nthen this phenomenon disappears. In particular, we define and construct\npseudorandom derivative families, for which lemon placement only slightly\naffects the values of the derivatives. Our constructions use expander graphs.\nWe study our derivatives in a more general setting than Arora et al. In\nparticular, we analyze arbitrary tranches of the common collateralized debt\nobligations (CDOs) when the underlying assets can have significant\ndependencies.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 19:03:31 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2010 21:23:12 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2010 16:29:21 GMT"}, {"version": "v4", "created": "Thu, 21 Oct 2010 21:53:13 GMT"}, {"version": "v5", "created": "Tue, 28 Dec 2010 14:21:32 GMT"}, {"version": "v6", "created": "Mon, 3 Jan 2011 20:34:38 GMT"}, {"version": "v7", "created": "Tue, 25 Jan 2011 17:45:47 GMT"}, {"version": "v8", "created": "Sun, 27 Jan 2019 20:54:20 GMT"}, {"version": "v9", "created": "Sat, 31 Aug 2019 19:15:43 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zuckerman", "David", ""]]}, {"id": "1006.0551", "submitter": "EPTCS", "authors": "Xizhong Zheng (Arcadia University), Ning Zhong (University of\n  Cincinnati)", "title": "Proceedings Seventh International Conference on Computability and\n  Complexity in Analysis", "comments": null, "journal-ref": "EPTCS 24, 2010", "doi": "10.4204/EPTCS.24", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume of the Electronic Proceedings in Theoretical Computer Science\n(EPTCS) contains extended abstracts of talks to be presented at the Seventh\nInternational Conference on Computability and Complexity in Analysis (CCA 2010)\nthat will take place in Zhenjiang, China, June 21-25, 2010. This conference is\nthe seventeenth event in the series of CCA annual meetings. The CCA conferences\nare aimed at promoting the study and advancement of the theory of computability\nand complexity over real-valued data and its application.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2010 04:22:39 GMT"}], "update_date": "2010-06-04", "authors_parsed": [["Zheng", "Xizhong", "", "Arcadia University"], ["Zhong", "Ning", "", "University of\n  Cincinnati"]]}, {"id": "1006.0701", "submitter": "Marius Zimand", "authors": "Marius Zimand", "title": "Impossibility of independence amplification in Kolmogorov complexity\n  theory", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-15155-2_61", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies randomness extraction from sources with bounded\nindependence and the issue of independence amplification of sources, using the\nframework of Kolmogorov complexity. The dependency of strings $x$ and $y$ is\n${\\rm dep}(x,y) = \\max\\{C(x) - C(x \\mid y), C(y) - C(y\\mid x)\\}$, where\n$C(\\cdot)$ denotes the Kolmogorov complexity. It is shown that there exists a\ncomputable Kolmogorov extractor $f$ such that, for any two $n$-bit strings with\ncomplexity $s(n)$ and dependency $\\alpha(n)$, it outputs a string of length\n$s(n)$ with complexity $s(n)- \\alpha(n)$ conditioned by any one of the input\nstrings. It is proven that the above are the optimal parameters a Kolmogorov\nextractor can achieve. It is shown that independence amplification cannot be\neffectively realized. Specifically, if (after excluding a trivial case) there\nexist computable functions $f_1$ and $f_2$ such that ${\\rm dep}(f_1(x,y),\nf_2(x,y)) \\leq \\beta(n)$ for all $n$-bit strings $x$ and $y$ with ${\\rm\ndep}(x,y) \\leq \\alpha(n)$, then $\\beta(n) \\geq \\alpha(n) - O(\\log n)$.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2010 17:31:14 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Zimand", "Marius", ""]]}, {"id": "1006.0744", "submitter": "Heidi Gebauer", "authors": "Heidi Gebauer, Tibor Szabo and Gabor Tardos", "title": "The Local Lemma is asymptotically tight for SAT", "comments": "40 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Local Lemma is a fundamental tool of probabilistic combinatorics and\ntheoretical computer science, yet there are hardly any natural problems known\nwhere it provides an asymptotically tight answer. The main theme of our paper\nis to identify several of these problems, among them a couple of widely studied\nextremal functions related to certain restricted versions of the k-SAT problem,\nwhere the Local Lemma does give essentially optimal answers.\n  As our main contribution, we construct unsatisfiable k-CNF formulas where\nevery clause has k distinct literals and every variable appears in at most (2/e\n+ o(1))*2^k/k clauses. The Lopsided Local Lemma shows that this is\nasymptotically best possible. The determination of this extremal function is\nparticularly important as it represents the value where the corresponding k-SAT\nproblem exhibits a complexity hardness jump: from having every instance being a\nYES-instance it becomes NP-hard just by allowing each variable to occur in one\nmore clause.\n  The construction of our unsatisfiable CNF-formulas is based on the binary\ntree approach of [16] and thus the constructed formulas are in the class MU(1)\nof minimal unsatisfiable formulas having one more clauses than variables. The\nmain novelty of our approach here comes in setting up an appropriate continuous\napproximation of the problem. This leads us to a differential equation, the\nsolution of which we are able to estimate. The asymptotically optimal binary\ntrees are then obtained through a discretization of this solution.\n  The importance of the binary trees constructed is also underlined by their\nappearance in many other scenarios. In particular, they give asymptotically\nprecise answers for seemingly unrelated problems like the European Tenure Game\nintroduced by Doerr [9] and a search problem allowing a limited number of\nconsecutive lies.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2010 21:14:00 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2013 19:21:47 GMT"}, {"version": "v3", "created": "Tue, 19 Apr 2016 20:01:11 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Gebauer", "Heidi", ""], ["Szabo", "Tibor", ""], ["Tardos", "Gabor", ""]]}, {"id": "1006.1315", "submitter": "Marius Zimand", "authors": "Marius Zimand", "title": "Counting dependent and independent strings", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-15155-2_60", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper gives estimations for the sizes of the the following sets: (1) the\nset of strings that have a given dependency with a fixed string, (2) the set of\nstrings that are pairwise \\alpha independent, (3) the set of strings that are\nmutually \\alpha independent. The relevant definitions are as follows: C(x) is\nthe Kolmogorov complexity of the string x. A string y has \\alpha -dependency\nwith a string x if C(y) - C(y|x) \\geq \\alpha. A set of strings {x_1, \\ldots,\nx_t} is pairwise \\alpha-independent if for all i different from j, C(x_i) -\nC(x_i | x_j) \\leq \\alpha. A tuple of strings (x_1, \\ldots, x_t) is mutually\n\\alpha-independent if C(x_{\\pi(1)} \\ldots x_{\\pi(t)}) \\geq C(x_1) + \\ldots +\nC(x_t) - \\alpha, for every permutation \\pi of [t].\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2010 18:21:10 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Zimand", "Marius", ""]]}, {"id": "1006.1409", "submitter": "EPTCS", "authors": "Oliver Friedmann (University of Munich), Martin Lange (University of\n  Kassel)", "title": "Local Strategy Improvement for Parity Game Solving", "comments": null, "journal-ref": "EPTCS 25, 2010, pp. 118-131", "doi": "10.4204/EPTCS.25.13", "report-no": null, "categories": "cs.GT cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of solving a parity game is at the core of many problems in model\nchecking, satisfiability checking and program synthesis. Some of the best\nalgorithms for solving parity game are strategy improvement algorithms. These\nare global in nature since they require the entire parity game to be present at\nthe beginning. This is a distinct disadvantage because in many applications one\nonly needs to know which winning region a particular node belongs to, and a\nwitnessing winning strategy may cover only a fractional part of the entire game\ngraph.\n  We present a local strategy improvement algorithm which explores the game\ngraph on-the-fly whilst performing the improvement steps. We also compare it\nempirically with existing global strategy improvement algorithms and the\ncurrently only other local algorithm for solving parity games. It turns out\nthat local strategy improvement can outperform these others by several orders\nof magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 00:42:58 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Friedmann", "Oliver", "", "University of Munich"], ["Lange", "Martin", "", "University of\n  Kassel"]]}, {"id": "1006.1411", "submitter": "EPTCS", "authors": "Ivan Fial\\'ik", "title": "Unitary Noise and the Mermin-GHZ Game", "comments": null, "journal-ref": "EPTCS 25, 2010, pp. 188-198", "doi": "10.4204/EPTCS.25.18", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication complexity is an area of classical computer science which\nstudies how much communication is necessary to solve various distributed\ncomputational problems. Quantum information processing can be used to reduce\nthe amount of communication required to carry out some distributed problems. We\nspeak of pseudo-telepathy when it is able to completely eliminate the need for\ncommunication. Since it is generally very hard to perfectly implement a quantum\nwinning strategy for a pseudo-telepathy game, quantum players are almost\ncertain to make errors even though they use a winning strategy. After\nintroducing a model for pseudo-telepathy games, we investigate the impact of\nerroneously performed unitary transformations on the quantum winning strategy\nfor the Mermin-GHZ game. The question of how strong the unitary noise can be so\nthat quantum players would still be better than classical ones is also dealt\nwith.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 00:43:13 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Fial\u00edk", "Ivan", ""]]}, {"id": "1006.1419", "submitter": "EPTCS", "authors": "Alastair A. Abbott (UoA), Cristian S. Calude (UoA)", "title": "Understanding the Quantum Computational Speed-up via De-quantisation", "comments": null, "journal-ref": "EPTCS 26, 2010, pp. 1-12", "doi": "10.4204/EPTCS.26.1", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it seems possible that quantum computers may allow for algorithms\noffering a computational speed-up over classical algorithms for some problems,\nthe issue is poorly understood. We explore this computational speed-up by\ninvestigating the ability to de-quantise quantum algorithms into classical\nsimulations of the algorithms which are as efficient in both time and space as\nthe original quantum algorithms.\n  The process of de-quantisation helps formulate conditions to determine if a\nquantum algorithm provides a real speed-up over classical algorithms. These\nconditions can be used to develop new quantum algorithms more effectively (by\navoiding features that could allow the algorithm to be efficiently classically\nsimulated), as well as providing the potential to create new classical\nalgorithms (by using features which have proved valuable for quantum\nalgorithms).\n  Results on many different methods of de-quantisations are presented, as well\nas a general formal definition of de-quantisation. De-quantisations employing\nhigher-dimensional classical bits, as well as those using matrix-simulations,\nput emphasis on entanglement in quantum algorithms; a key result is that any\nalgorithm in which the entanglement is bounded is de-quantisable. These methods\nare contrasted with the stabiliser formalism de-quantisations due to the\nGottesman-Knill Theorem, as well as those which take advantage of the topology\nof the circuit for a quantum algorithm.\n  The benefits of the different methods are contrasted, and the importance of a\nrange of techniques is emphasised. We further discuss some features of quantum\nalgorithms which current de-quantisation methods do not cover.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 00:56:38 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Abbott", "Alastair A.", "", "UoA"], ["Calude", "Cristian S.", "", "UoA"]]}, {"id": "1006.1423", "submitter": "EPTCS", "authors": "Dominik F. Floess, Erika Andersson, Mark Hillery", "title": "Quantum algorithms for testing Boolean functions", "comments": null, "journal-ref": "EPTCS 26, 2010, pp. 101-108", "doi": "10.4204/EPTCS.26.9", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss quantum algorithms, based on the Bernstein-Vazirani algorithm, for\nfinding which variables a Boolean function depends on. There are 2^n possible\nlinear Boolean functions of n variables; given a linear Boolean function, the\nBernstein-Vazirani quantum algorithm can deterministically identify which one\nof these Boolean functions we are given using just one single function query.\nThe same quantum algorithm can also be used to learn which input variables\nother types of Boolean functions depend on, with a success probability that\ndepends on the form of the Boolean function that is tested, but does not depend\non the total number of input variables. We also outline a procedure to futher\namplify the success probability, based on another quantum algorithm, the Grover\nsearch.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 01:11:24 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Floess", "Dominik F.", ""], ["Andersson", "Erika", ""], ["Hillery", "Mark", ""]]}, {"id": "1006.1537", "submitter": "Minghao Yin", "authors": "Junping Zhou and Minghao Yin and Chunguang Zhou", "title": "New worst upper bound for #SAT", "comments": "6 pages; proceedings of AAAI 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The rigorous theoretical analyses of algorithms for #SAT have been proposed\nin the literature. As we know, previous algorithms for solving #SAT have been\nanalyzed only regarding the number of variables as the parameter. However, the\ntime complexity for solving #SAT instances depends not only on the number of\nvariables, but also on the number of clauses. Therefore, it is significant to\nexploit the time complexity from the other point of view, i.e. the number of\nclauses. In this paper, we present algorithms for solving #2-SAT and #3-SAT\nwith rigorous complexity analyses using the number of clauses as the parameter.\nBy analyzing the algorithms, we obtain the new worst-case upper bounds\nO(1.1892m) for #2-SAT and O(1.4142m) for #3-SAT, where m is the number of\nclauses.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 11:48:12 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Zhou", "Junping", ""], ["Yin", "Minghao", ""], ["Zhou", "Chunguang", ""]]}, {"id": "1006.2063", "submitter": "Chien-Chung Huang", "authors": "Danny Hermelin and Chien-Chung Huang and Stefan Kratsch and Magnus\n  Wahlstrom", "title": "Parameterized Two-Player Nash Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computation of Nash equilibria in a two-player normal form game\nfrom the perspective of parameterized complexity. Recent results proved\nhardness for a number of variants, when parameterized by the support size. We\ncomplement those results, by identifying three cases in which the problem\nbecomes fixed-parameter tractable. These cases occur in the previously studied\nsettings of sparse games and unbalanced games as well as in the newly\nconsidered case of locally bounded treewidth games that generalizes both these\ntwo cases.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2010 15:27:40 GMT"}], "update_date": "2010-06-11", "authors_parsed": [["Hermelin", "Danny", ""], ["Huang", "Chien-Chung", ""], ["Kratsch", "Stefan", ""], ["Wahlstrom", "Magnus", ""]]}, {"id": "1006.2218", "submitter": "Carlos Barr\\'on-Romero", "authors": "Carlos Barron-Romero", "title": "The Complexity Of The NP-Class", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS physics.atm-clus", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel and straight formulation, and gives a complete\ninsight towards the understanding of the complexity of the problems of the so\ncalled NP-Class. In particular, this paper focuses in the Searching of the\nOptimal Geometrical Structures and the Travelling Salesman Problems. The main\nresults are the polynomial reduction procedure and the solution to the Noted\nConjecture of the NP-Class.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2010 07:56:52 GMT"}], "update_date": "2010-06-14", "authors_parsed": [["Barron-Romero", "Carlos", ""]]}, {"id": "1006.2461", "submitter": "Praveen Manjunatha", "authors": "M. Praveen", "title": "Does Treewidth Help in Modal Satisfiability?", "comments": "Full version of the paper appearing in MFCS 2010. Change from v1:\n  improved section 5 to avoid exponential blow-up in formula size", "journal-ref": null, "doi": "10.1007/978-3-642-15155-2_51", "report-no": null, "categories": "cs.LO cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tractable algorithms for solving the Constraint Satisfaction Problem\n(CSP) have been developed using the notion of the treewidth of some graph\nderived from the input CSP instance. In particular, the incidence graph of the\nCSP instance is one such graph. We introduce the notion of an incidence graph\nfor modal logic formulae in a certain normal form. We investigate the\nparameterized complexity of modal satisfiability with the modal depth of the\nformula and the treewidth of the incidence graph as parameters. For various\ncombinations of Euclidean, reflexive, symmetric and transitive models, we show\neither that modal satisfiability is FPT, or that it is W[1]-hard. In\nparticular, modal satisfiability in general models is FPT, while it is\nW[1]-hard in transitive models. As might be expected, modal satisfiability in\ntransitive and Euclidean models is FPT.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2010 12:25:17 GMT"}, {"version": "v2", "created": "Tue, 11 Jan 2011 11:10:15 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Praveen", "M.", ""]]}, {"id": "1006.2570", "submitter": "Alexander Ushakov", "authors": "Alexei G. Myasnikov, Alexander Ushakov, and Dong Wook Won", "title": "Power Circuits, Exponential Algebra, and Time Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by algorithmic problems from combinatorial group theory we study\ncomputational properties of integers equipped with binary operations +, -, z =\nx 2^y, z = x 2^{-y} (the former two are partial) and predicates < and =. Notice\nthat in this case very large numbers, which are obtained as n towers of\nexponentiation in the base 2 can be realized as n applications of the operation\nx2^y, so working with such numbers given in the usual binary expansions\nrequires super exponential space. We define a new compressed representation for\nintegers by power circuits (a particular type of straight-line programs) which\nis unique and easily computable, and show that the operations above can be\nperformed in polynomial time if the numbers are presented by power circuits. We\nmention several applications of this technique to algorithmic problems, in\nparticular, we prove that the quantifier-free theories of various exponential\nalgebras are decidable in polynomial time, as well as the word problems in some\n\"hard to crack\" one-relator groups.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2010 21:58:31 GMT"}], "update_date": "2010-06-15", "authors_parsed": [["Myasnikov", "Alexei G.", ""], ["Ushakov", "Alexander", ""], ["Won", "Dong Wook", ""]]}, {"id": "1006.2897", "submitter": "David Doty", "authors": "Nathaniel Bryans, Ehsan Chiniforooshan, David Doty, Lila Kari, and\n  Shinnosuke Seki", "title": "The Power of Nondeterminism in Self-Assembly", "comments": "Accepted to SODA 2011. The previous version of this paper (which\n  appears in the SODA proceedings) had open questions about computing the\n  minimum number of tile types to weakly self-assemble a set. The answer to\n  these questions is \"no\", by a very simple imitation of the proof that\n  Kolmogorov complexity is uncomputable based on the Berry paradox. These open\n  questions have been removed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the role of nondeterminism in Winfree's abstract Tile Assembly\nModel (aTAM), which was conceived to model artificial molecular self-assembling\nsystems constructed from DNA. Of particular practical importance is to find\ntile systems that minimize resources such as the number of distinct tile types,\neach of which corresponds to a set of DNA strands that must be\ncustom-synthesized in actual molecular implementations of the aTAM. We seek to\nidentify to what extent the use of nondeterminism in tile systems affects the\nresources required by such molecular shape-building algorithms.\n  We first show a \"molecular computability theoretic\" result: there is an\ninfinite shape S that is uniquely assembled by a tile system but not by any\ndeterministic tile system. We then show an analogous phenomenon in the finitary\n\"molecular complexity theoretic\" case: there is a finite shape S that is\nuniquely assembled by a tile system with c tile types, but every deterministic\ntile system that uniquely assembles S has more than c tile types. In fact we\nextend the technique to derive a stronger (classical complexity theoretic)\nresult, showing that the problem of finding the minimum number of tile types\nthat uniquely assemble a given finite shape is Sigma-P-2-complete. In contrast,\nthe problem of finding the minimum number of deterministic tile types that\nuniquely assemble a shape was shown to be NP-complete by Adleman, Cheng, Goel,\nHuang, Kempe, Moisset de Espan\\'es, and Rothemund (Combinatorial Optimization\nProblems in Self-Assembly, STOC 2002).\n  The conclusion is that nondeterminism confers extra power to assemble a shape\nfrom a small tile system, but unless the polynomial hierarchy collapses, it is\ncomputationally more difficult to exploit this power by finding the size of the\nsmallest tile system, compared to finding the size of the smallest\ndeterministic tile system.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 06:24:06 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2010 21:19:07 GMT"}, {"version": "v3", "created": "Thu, 25 Nov 2010 17:26:11 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Bryans", "Nathaniel", ""], ["Chiniforooshan", "Ehsan", ""], ["Doty", "David", ""], ["Kari", "Lila", ""], ["Seki", "Shinnosuke", ""]]}, {"id": "1006.2951", "submitter": "Svozil Karl", "authors": "Cristian S. Calude, Elena Calude and Karl Svozil", "title": "The Complexity of Proving Chaoticity and the Church-Turing Thesis", "comments": "13 pages, new proof of the main theorem", "journal-ref": "Chaos: An Interdisciplinary Journal of Nonlinear Science 20(3),\n  037103 (2010)", "doi": "10.1063/1.3489096", "report-no": "CDMTCS preprint nr. 384/2010", "categories": "nlin.CD cs.CC physics.gen-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proving the chaoticity of some dynamical systems is equivalent to solving the\nhardest problems in mathematics. Conversely, one argues that it is not\nunconceivable that classical physical systems may \"compute the hard or even the\nincomputable\" by measuring observables which correspond to computationally hard\nor even incomputable problems.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 10:39:57 GMT"}, {"version": "v2", "created": "Sat, 21 Aug 2010 16:47:12 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Calude", "Cristian S.", ""], ["Calude", "Elena", ""], ["Svozil", "Karl", ""]]}, {"id": "1006.3046", "submitter": "Matthew Patitz", "authors": "Matthew J. Patitz and Scott M. Summers", "title": "Identifying Shapes Using Self-Assembly (extended abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the following problem in the theory of\nalgorithmic self-assembly: given an input shape as the seed of a tile-based\nself-assembly system, design a finite tile set that can, in some sense,\nuniquely identify whether or not the given input shape--drawn from a very\ngeneral class of shapes--matches a particular target shape. We first study the\ncomplexity of correctly identifying squares. Then we investigate the complexity\nassociated with the identification of a considerably more general class of\nnon-square, hole-free shapes.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 18:31:40 GMT"}], "update_date": "2010-06-16", "authors_parsed": [["Patitz", "Matthew J.", ""], ["Summers", "Scott M.", ""]]}, {"id": "1006.3275", "submitter": "Paul Vitanyi", "authors": "Sebastiaan A. Terwijn (Radboud Univ. Nijmegen), Leen Torenvliet (Univ.\n  Amsterdam), and Paul M.B. Vitanyi (CWI, Amsterdam)", "title": "Normalized Information Distance is Not Semicomputable", "comments": "9 pages, LaTeX, No figures, To appear in J. Comput. Syst. Sci", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CV physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalized information distance (NID) uses the theoretical notion of\nKolmogorov complexity, which for practical purposes is approximated by the\nlength of the compressed version of the file involved, using a real-world\ncompression program. This practical application is called 'normalized\ncompression distance' and it is trivially computable. It is a parameter-free\nsimilarity measure based on compression, and is used in pattern recognition,\ndata mining, phylogeny, clustering, and classification. The complexity\nproperties of its theoretical precursor, the NID, have been open. We show that\nthe NID is neither upper semicomputable nor lower semicomputable.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2010 17:17:09 GMT"}], "update_date": "2010-06-17", "authors_parsed": [["Terwijn", "Sebastiaan A.", "", "Radboud Univ. Nijmegen"], ["Torenvliet", "Leen", "", "Univ.\n  Amsterdam"], ["Vitanyi", "Paul M. B.", "", "CWI, Amsterdam"]]}, {"id": "1006.3585", "submitter": "Jelani Nelson", "authors": "Daniel M. Kane, Jelani Nelson", "title": "A Derandomized Sparse Johnson-Lindenstrauss Transform", "comments": "v3: Improved seed length, alternative proof of JL row optimality,\n  other minor changes; v2: Improved presentation. Added a warmup section,\n  Section 4, which gives a short proof of the JL lemma", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work of [Dasgupta-Kumar-Sarlos, STOC 2010] gave a sparse\nJohnson-Lindenstrauss transform and left as a main open question whether their\nconstruction could be efficiently derandomized. We answer their question\naffirmatively by giving an alternative proof of their result requiring only\nbounded independence hash functions. Furthermore, the sparsity bound obtained\nin our proof is improved. The main ingredient in our proof is a spectral moment\nbound for quadratic forms that was recently used in [Diakonikolas-Kane-Nelson,\nFOCS 2010].\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 01:39:18 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2010 18:05:08 GMT"}, {"version": "v3", "created": "Tue, 7 Dec 2010 18:40:07 GMT"}], "update_date": "2010-12-08", "authors_parsed": [["Kane", "Daniel M.", ""], ["Nelson", "Jelani", ""]]}, {"id": "1006.3651", "submitter": "Andris Ambainis", "authors": "Andris Ambainis", "title": "Quantum algorithms for formula evaluation", "comments": "11 pages, survey for NATO ARW \"Quantum Cryptography and Computing\",\n  Gdansk, September 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey the recent sequence of algorithms for evaluating Boolean formulas\nconsisting of NAND gates.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 09:43:01 GMT"}], "update_date": "2010-06-21", "authors_parsed": [["Ambainis", "Andris", ""]]}, {"id": "1006.3786", "submitter": "Emmanuel Abbe A", "authors": "Emmanuel Abbe, Andrea Montanari", "title": "On the concentration of the number of solutions of random satisfiability\n  formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cond-mat.stat-mech cs.CC cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $Z(F)$ be the number of solutions of a random $k$-satisfiability formula\n$F$ with $n$ variables and clause density $\\alpha$. Assume that the probability\nthat $F$ is unsatisfiable is $O(1/\\log(n)^{1+\\e})$ for $\\e>0$. We show that\n(possibly excluding a countable set of `exceptional' $\\alpha$'s) the number of\nsolutions concentrate in the logarithmic scale, i.e., there exists a non-random\nfunction $\\phi(\\alpha)$ such that, for any $\\delta>0$, $(1/n)\\log Z(F)\\in\n[\\phi-\\delta,\\phi+\\delta]$ with high probability. In particular, the assumption\nholds for all $\\alpha<1$, which proves the above concentration claim in the\nwhole satisfiability regime of random $2$-SAT. We also extend these results to\na broad class of constraint satisfaction problems. The proof is based on an\ninterpolation technique from spin-glass theory, and on an application of\nFriedgut's theorem on sharp thresholds for graph properties.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 19:53:56 GMT"}], "update_date": "2010-06-23", "authors_parsed": [["Abbe", "Emmanuel", ""], ["Montanari", "Andrea", ""]]}, {"id": "1006.4014", "submitter": "Andris Ambainis", "authors": "Andris Ambainis", "title": "New Developments in Quantum Algorithms", "comments": "11 pages, 1 figure, to appear as an invited survey talk at MFCS'2010", "journal-ref": null, "doi": "10.1007/978-3-642-15155-2_1", "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey, we describe two recent developments in quantum algorithms.\n  The first new development is a quantum algorithm for evaluating a Boolean\nformula consisting of AND and OR gates of size N in time O(\\sqrt{N}). This\nprovides quantum speedups for any problem that can be expressed via Boolean\nformulas. This result can be also extended to span problems, a generalization\nof Boolean formulas. This provides an optimal quantum algorithm for any Boolean\nfunction in the black-box query model.\n  The second new development is a quantum algorithm for solving systems of\nlinear equations. In contrast with traditional algorithms that run in time\nO(N^{2.37...}) where N is the size of the system, the quantum algorithm runs in\ntime O(\\log^c N). It outputs a quantum state describing the solution of the\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2010 08:57:04 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Ambainis", "Andris", ""]]}, {"id": "1006.4349", "submitter": "Ali Civril", "authors": "Ali Civril and Malik Magdon-Ismail", "title": "Exponential Inapproximability of Selecting a Maximum Volume Sub-matrix", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a matrix $A \\in \\mathbb{R}^{m \\times n}$ ($n$ vectors in $m$\ndimensions), and a positive integer $k < n$, we consider the problem of\nselecting $k$ column vectors from $A$ such that the volume of the\nparallelepiped they define is maximum over all possible choices. We prove that\nthere exists $\\delta<1$ and $c>0$ such that this problem is not approximable\nwithin $2^{-ck}$ for $k = \\delta n$, unless $P=NP$.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2010 19:09:02 GMT"}, {"version": "v2", "created": "Wed, 23 Feb 2011 13:03:54 GMT"}, {"version": "v3", "created": "Tue, 23 Aug 2011 18:26:11 GMT"}, {"version": "v4", "created": "Wed, 12 Oct 2011 11:26:22 GMT"}], "update_date": "2011-10-13", "authors_parsed": [["Civril", "Ali", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1006.4388", "submitter": "Dave Bacon", "authors": "Elizabeth Crosson, Dave Bacon, and Kenneth R. Brown", "title": "Making Classical Ground State Spin Computing Fault-Tolerant", "comments": "24 pages, 1 figure", "journal-ref": "Physical Review E, 82(3), 031106 (2010)", "doi": "10.1103/PhysRevE.82.031106", "report-no": null, "categories": "cond-mat.stat-mech cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a model of classical deterministic computing in which the ground\nstate of the classical system is a spatial history of the computation. This\nmodel is relevant to quantum dot cellular automata as well as to recent\nuniversal adiabatic quantum computing constructions. In its most primitive\nform, systems constructed in this model cannot compute in an error free manner\nwhen working at non-zero temperature. However, by exploiting a mapping between\nthe partition function for this model and probabilistic classical circuits we\nare able to show that it is possible to make this model effectively error free.\nWe achieve this by using techniques in fault-tolerant classical computing and\nthe result is that the system can compute effectively error free if the\ntemperature is below a critical temperature. We further link this model to\ncomputational complexity and show that a certain problem concerning finite\ntemperature classical spin systems is complete for the complexity class\nMerlin-Arthur. This provides an interesting connection between the physical\nbehavior of certain many-body spin systems and computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2010 22:05:25 GMT"}, {"version": "v2", "created": "Tue, 18 Nov 2014 12:27:51 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Crosson", "Elizabeth", ""], ["Bacon", "Dave", ""], ["Brown", "Kenneth R.", ""]]}, {"id": "1006.4524", "submitter": "Petros Elia", "authors": "Petros Elia and Joakim Jalden", "title": "Fundamental Rate-Reliability-Complexity Limits in Outage Limited MIMO\n  Communications", "comments": "6 pages, no figures. Slide presentation of partial work at ITA 2010.\n  Published at ISIT2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work establishes fundamental limits with respect to rate, reliability and\ncomputational complexity, for a general setting of outage-limited MIMO\ncommunications. In the high-SNR regime, the limits are optimized over all\nencoders, all decoders, and all complexity regulating policies. The work then\nproceeds to explicitly identify encoder-decoder designs and policies, that meet\nthis optimal tradeoff. In practice, the limits aim to meaningfully quantify\ndifferent pertinent measures, such as the optimal rate-reliability capabilities\nper unit complexity and power, the optimal diversity gains per complexity\ncosts, or the optimal number of numerical operations (i.e., flops) per bit.\nFinally the tradeoff's simple nature, renders it useful for insightful\ncomparison of the rate-reliability-complexity capabilities for different\nencoders-decoders.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 14:05:36 GMT"}], "update_date": "2010-06-24", "authors_parsed": [["Elia", "Petros", ""], ["Jalden", "Joakim", ""]]}, {"id": "1006.4625", "submitter": "Franklin Marquezino", "authors": "F.L. Marquezino, R. Portugal, G. Abal", "title": "Mixing Times in Quantum Walks on Two-Dimensional Grids", "comments": "11 pages", "journal-ref": "Physical Review A, v. 82, p. 042341, 2010", "doi": "10.1103/PhysRevA.82.042341", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixing properties of discrete-time quantum walks on two-dimensional grids\nwith torus-like boundary conditions are analyzed, focusing on their connection\nto the complexity of the corresponding abstract search algorithm. In\nparticular, an exact expression for the stationary distribution of the coherent\nwalk over odd-sided lattices is obtained after solving the eigenproblem for the\nevolution operator for this particular graph. The limiting distribution and\nmixing time of a quantum walk with a coin operator modified as in the abstract\nsearch algorithm are obtained numerically. On the basis of these results, the\nrelation between the mixing time of the modified walk and the running time of\nthe corresponding abstract search algorithm is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 19:44:41 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Marquezino", "F. L.", ""], ["Portugal", "R.", ""], ["Abal", "G.", ""]]}, {"id": "1006.4700", "submitter": "Pascal Koiran", "authors": "Pascal Koiran (LIP)", "title": "Arithmetic circuits: the chasm at depth four gets wider", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their paper on the \"chasm at depth four\", Agrawal and Vinay have shown\nthat polynomials in m variables of degree O(m) which admit arithmetic circuits\nof size 2^o(m) also admit arithmetic circuits of depth four and size 2^o(m).\nThis theorem shows that for problems such as arithmetic circuit lower bounds or\nblack-box derandomization of identity testing, the case of depth four circuits\nis in a certain sense the general case. In this paper we show that smaller\ndepth four circuits can be obtained if we start from polynomial size arithmetic\ncircuits. For instance, we show that if the permanent of n*n matrices has\ncircuits of size polynomial in n, then it also has depth 4 circuits of size\nn^O(sqrt(n)*log(n)). Our depth four circuits use integer constants of\npolynomial size. These results have potential applications to lower bounds and\ndeterministic identity testing, in particular for sums of products of sparse\nunivariate polynomials. We also give an application to boolean circuit\ncomplexity, and a simple (but suboptimal) reduction to polylogarithmic depth\nfor arithmetic circuits of polynomial size and polynomially bounded degree.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2010 07:22:19 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2010 18:50:37 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2010 19:17:39 GMT"}, {"version": "v4", "created": "Fri, 23 Mar 2012 07:11:30 GMT"}], "update_date": "2012-03-26", "authors_parsed": [["Koiran", "Pascal", "", "LIP"]]}, {"id": "1006.4923", "submitter": "Nadia Creignou", "authors": "Nadia Creignou, Johannes Schmidt, Michael Thomas", "title": "Complexity Classifications for Propositional Abduction in Post's\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the complexity of abduction, a fundamental and\nimportant form of non-monotonic reasoning. Given a knowledge base explaining\nthe world's behavior it aims at finding an explanation for some observed\nmanifestation. In this paper we consider propositional abduction, where the\nknowledge base and the manifestation are represented by propositional formulae.\nThe problem of deciding whether there exists an explanation has been shown to\nbe \\SigPtwo-complete in general. We focus on formulae in which the allowed\nconnectives are taken from certain sets of Boolean functions. We consider\ndifferent variants of the abduction problem in restricting both the\nmanifestations and the hypotheses. For all these variants we obtain a\ncomplexity classification for all possible sets of Boolean functions. In this\nway, we identify easier cases, namely \\NP-complete, \\coNP-complete and\npolynomial cases. Thus, we get a detailed picture of the complexity of the\npropositional abduction problem, hence highlighting sources of intractability.\nFurther, we address the problem of counting the explanations and draw a\ncomplete picture for the counting complexity.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2010 07:52:18 GMT"}], "update_date": "2010-06-28", "authors_parsed": [["Creignou", "Nadia", ""], ["Schmidt", "Johannes", ""], ["Thomas", "Michael", ""]]}, {"id": "1006.5234", "submitter": "Leslie Ann Goldberg", "authors": "Leslie Ann Goldberg and Mark Jerrum", "title": "Approximating the Tutte polynomial of a binary matroid and other related\n  combinatorial polynomials", "comments": null, "journal-ref": "JCSS 79(1) (February, 2013) 68-78", "doi": "10.1016/j.jcss.2012.04.005", "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximating certain combinatorial polynomials.\nFirst, we consider the problem of approximating the Tutte polynomial of a\nbinary matroid with parameters q>= 2 and gamma. (Relative to the classical\n(x,y) parameterisation, q=(x-1)(y-1) and gamma=y-1.) A graph is a special case\nof a binary matroid, so earlier work by the authors shows inapproximability\n(subject to certain complexity assumptions) for q>2, apart from the trivial\ncase gamma=0. The situation for q=2 is different. Previous results for graphs\nimply inapproximability in the region -2<=gamma<0, apart from at two \"special\npoints\" where the polynomial can be computed exactly in polynomial time. For\nbinary matroids, we extend this result by showing (i) there is no FPRAS in the\nregion gamma<-2 unless NP=RP, and (ii) in the region gamma>0, the approximation\nproblem is hard for the complexity class #RHPi_1 under approximation-preserving\n(AP) reducibility. The latter result indicates a gap in approximation\ncomplexity at q=2: whereas an FPRAS is known in the graphical case, there can\nbe none in the binary matroid case, unless there is an FPRAS for all of\n#RHPi_1. The result also implies that it is computationally difficult to\napproximate the weight enumerator of a binary linear code, apart from at the\nspecial weights at which the problem is exactly solvable in polynomial time. As\na consequence, we show that approximating the cycle index polynomial of a\npermutation group is hard for #RHPi_1 under AP-reducibility, partially\nresolving a question that we first posed in 1992.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2010 20:29:56 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2012 10:11:16 GMT"}], "update_date": "2013-08-01", "authors_parsed": [["Goldberg", "Leslie Ann", ""], ["Jerrum", "Mark", ""]]}, {"id": "1006.5318", "submitter": "Ignacio Villanueva", "authors": "Carlos Palazuelos, David Perez-Garcia, Ignacio Villanueva", "title": "Tripartite probability distributions and communication complexity", "comments": "This paper has been withdrawn by the authors. We believe the main\n  result to be true, but the proof is not correct. We are at the moment trying\n  to fix it", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every tripartite quantum correlation generated with a Schmidt\nstate (in particular every correlation generated with the GHZ state) can be\nsimulated with the sending of two bits of classical communication from Alice to\nBob and Charlie plus the sending of two bits of classical communication from\nBob to Charlie. This extends recent results which showed that the maximal\nviolation of Bell inequalities attainable by these correlations is uniformly\nbounded. For simplicity, we state and prove the result for three parties, but\nthe generalization to the case of $n$ parties follows easily.\n  We also show that every $n$-partite probability distribution generated with\nlocal resources plus $c$-bits of local communication can violate a Bell\ninequality by at most a factor of $2^c$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2010 11:17:18 GMT"}, {"version": "v2", "created": "Mon, 17 Jan 2011 09:32:34 GMT"}], "update_date": "2011-01-18", "authors_parsed": [["Palazuelos", "Carlos", ""], ["Perez-Garcia", "David", ""], ["Villanueva", "Ignacio", ""]]}, {"id": "1006.5352", "submitter": "Paul Goldberg", "authors": "Paul W. Goldberg, Christos H. Papadimitriou, and Rahul Savani", "title": "The Complexity of the Homotopy Method, Equilibrium Selection, and\n  Lemke-Howson Solutions", "comments": "23 pages, 1 figure; to appear in FOCS 2011 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the widely used homotopy method for solving fixpoint problems,\nas well as the Harsanyi-Selten equilibrium selection process for games, are\nPSPACE-complete to implement. Extending our result for the Harsanyi-Selten\nprocess, we show that several other homotopy-based algorithms for finding\nequilibria of games are also PSPACE-complete to implement. A further\napplication of our techniques yields the result that it is PSPACE-complete to\ncompute any of the equilibria that could be found via the classical\nLemke-Howson algorithm, a complexity-theoretic strengthening of the result in\n[Savani and von Stengel]. These results show that our techniques can be widely\napplied and suggest that the PSPACE-completeness of implementing homotopy\nmethods is a general principle.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2010 13:59:00 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2011 13:54:12 GMT"}], "update_date": "2011-08-05", "authors_parsed": [["Goldberg", "Paul W.", ""], ["Papadimitriou", "Christos H.", ""], ["Savani", "Rahul", ""]]}, {"id": "1006.5892", "submitter": "Michael Huber", "authors": "Michael Huber", "title": "Computational complexity of reconstruction and isomorphism testing for\n  designs and line graphs", "comments": "12 pages; to appear in: \"Journal of Combinatorial Theory, Series A\"", "journal-ref": null, "doi": "10.1016/j.jcta.2010.06.006", "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs with high symmetry or regularity are the main source for\nexperimentally hard instances of the notoriously difficult graph isomorphism\nproblem. In this paper, we study the computational complexity of isomorphism\ntesting for line graphs of $t$-$(v,k,\\lambda)$ designs. For this class of\nhighly regular graphs, we obtain a worst-case running time of $O(v^{\\log v +\nO(1)})$ for bounded parameters $t,k,\\lambda$. In a first step, our approach\nmakes use of the Babai--Luks algorithm to compute canonical forms of\n$t$-designs. In a second step, we show that $t$-designs can be reconstructed\nfrom their line graphs in polynomial-time. The first is algebraic in nature,\nthe second purely combinatorial. For both, profound structural knowledge in\ndesign theory is required. Our results extend earlier complexity results about\nisomorphism testing of graphs generated from Steiner triple systems and block\ndesigns.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2010 15:50:25 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Huber", "Michael", ""]]}]