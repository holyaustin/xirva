[{"id": "1809.00954", "submitter": "Laurent Lyaudet", "authors": "Laurent Lyaudet", "title": "A class of orders with linear? time sorting algorithm", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we give a precise mathematical meaning to `linear? time'\nthat matches experimental behaviour of the algorithm. The sorting algorithm is\nnot our own, it is a variant of radix sort with counting sort as a subroutine.\nThe true result of this article is an efficient universality result for\nlexicographic order, or more generally for some linear extensions of the\npartial order `Next': `if current items are equal, compare next items'. We\ndefine new classes of orders: (Finite width) Tree Structured Orders. We show\nthat an instance of a finite width tree structured order can be converted in\nlinear time and space to an instance of lexicographic order. The constants\nimplied by the `nextification' algorithm are small (around 3 for real world\norders). The class of finite width tree structured orders contains finite\norders ({0, 1}, int32, int64, ..., float, double, ...), and orders constructed\nfrom them on a tree structure. In particular, unbounded integers, strings with\narbitrary collation, and all orders used for sorting SQL queries are finite\nwidth tree structured orders.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 13:44:11 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 19:34:00 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2018 20:54:09 GMT"}, {"version": "v4", "created": "Thu, 1 Nov 2018 17:53:52 GMT"}, {"version": "v5", "created": "Sun, 30 Dec 2018 17:55:29 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Lyaudet", "Laurent", ""]]}, {"id": "1809.01021", "submitter": "Fatemeh Hadaeghi", "authors": "Fatemeh Hadaeghi and Herbert Jaeger", "title": "Computing optimal discrete readout weights in reservoir computing is\n  NP-hard", "comments": "8 pages submitted to Neurocomputing", "journal-ref": "Neurocomputing Volume 338, 21 April 2019, Pages 233-236", "doi": "10.1016/j.neucom.2019.02.009", "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We show NP-hardness of a generalized quadratic programming problem, which we\ncalled Unconstrained N-ary Quadratic Programming (UNQP). This problem has\nrecently become practically relevant in the context of novel memristor-based\nneuromorphic microchip designs, where solving the UNQP is a key operation for\non-chip training of the neural network implemented on the chip. UNQP is the\nproblem of finding a vector $\\mathbf{v} \\in S^N$ which minimizes\n$\\mathbf{v}^T\\,Q\\,\\mathbf{v} +\\mathbf{v}^T \\mathbf{c} $, where $S = \\{s_1,\n\\ldots, s_n\\} \\subset \\mathbb{Z}$ is a given set of eligible parameters for\n$\\mathbf{v}$, $Q \\in \\mathbb{Z}^{N \\times N}$ is positive semi-definite, and\n$\\mathbf{c} \\in \\mathbb{Z}^{N}$. In memristor-based neuromorphic hardware, $S$\nis physically given by a finite (and small) number of possible memristor\nstates. The proof of NP-hardness is by reduction from the Unconstrained Binary\nQuadratic Programming problem, which is a special case of UNQP where $S = \\{0,\n1\\}$ and which is known to be NP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 14:30:02 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hadaeghi", "Fatemeh", ""], ["Jaeger", "Herbert", ""]]}, {"id": "1809.01077", "submitter": "Jan H\\k{a}z{\\l}a", "authors": "Jan H\\k{a}z{\\l}a, Ali Jadbabaie, Elchanan Mossel, M. Amin Rahimian", "title": "Reasoning in Bayesian Opinion Exchange Networks Is PSPACE-Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.GT cs.SI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Bayesian model of opinion exchange of fully rational agents\narranged on a network. In this model, the agents receive private signals that\nare indicative of an unkown state of the world. Then, they repeatedly announce\nthe state of the world they consider most likely to their neighbors, at the\nsame time updating their beliefs based on their neighbors' announcements.\n  This model is extensively studied in economics since the work of Aumann\n(1976) and Geanakoplos and Polemarchakis (1982). It is known that the agents\neventually agree with high probability on any network. It is often argued that\nthe computations needed by agents in this model are difficult, but prior to our\nresults there was no rigorous work showing this hardness.\n  We show that it is PSPACE-hard for the agents to compute their actions in\nthis model. Furthermore, we show that it is equally difficult even to\napproximate an agent's posterior: It is PSPACE-hard to distinguish between the\nposterior being almost entirely concentrated on one state of the world or\nanother.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:36:22 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["H\u0105z\u0142a", "Jan", ""], ["Jadbabaie", "Ali", ""], ["Mossel", "Elchanan", ""], ["Rahimian", "M. Amin", ""]]}, {"id": "1809.01118", "submitter": "Yaqiao Li", "authors": "Yaqiao Li", "title": "A note on the tight example in On the randomised query complexity of\n  composition", "comments": "This will be merged with another paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make two observations regarding a recent tight example for a composition\ntheorem for randomized query complexity: (1) it implies general randomized\nquery-to-communication lifting is not always true if one allows relations, (2)\nit is in a certain sense essential that a relation is used in constructing the\nexample.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 17:51:04 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 22:04:28 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Yaqiao", ""]]}, {"id": "1809.01207", "submitter": "Tselil Schramm", "authors": "Pravesh Kothari and Ryan O'Donnell and Tselil Schramm", "title": "SOS lower bounds with hard constraints: think global, act local", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many previous Sum-of-Squares (SOS) lower bounds for CSPs had two deficiencies\nrelated to global constraints. First, they were not able to support a\n\"cardinality constraint\", as in, say, the Min-Bisection problem. Second, while\nthe pseudoexpectation of the objective function was shown to have some value\n$\\beta$, it did not necessarily actually \"satisfy\" the constraint \"objective =\n$\\beta$\". In this paper we show how to remedy both deficiencies in the case of\nrandom CSPs, by translating \\emph{global} constraints into \\emph{local}\nconstraints. Using these ideas, we also show that degree-$\\Omega(\\sqrt{n})$ SOS\ndoes not provide a $(\\frac{4}{3} - \\epsilon)$-approximation for Min-Bisection,\nand degree-$\\Omega(n)$ SOS does not provide a $(\\frac{11}{12} +\n\\epsilon)$-approximation for Max-Bisection or a $(\\frac{5}{4} -\n\\epsilon)$-approximation for Min-Bisection. No prior SOS lower bounds for these\nproblems were known.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 19:11:03 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Kothari", "Pravesh", ""], ["O'Donnell", "Ryan", ""], ["Schramm", "Tselil", ""]]}, {"id": "1809.01225", "submitter": "Tsung-Yu Hsieh", "authors": "Tsung-Yu Hsieh, Yasser EL-Manzalawy, Yiwei Sun, Vasant Honavar", "title": "Compositional Stochastic Average Gradient for Machine Learning and\n  Related Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning, statistical inference, and portfolio optimization\nproblems require minimization of a composition of expected value functions\n(CEVF). Of particular interest is the finite-sum versions of such compositional\noptimization problems (FS-CEVF). Compositional stochastic variance reduced\ngradient (C-SVRG) methods that combine stochastic compositional gradient\ndescent (SCGD) and stochastic variance reduced gradient descent (SVRG) methods\nare the state-of-the-art methods for FS-CEVF problems. We introduce\ncompositional stochastic average gradient descent (C-SAG) a novel extension of\nthe stochastic average gradient method (SAG) to minimize composition of\nfinite-sum functions. C-SAG, like SAG, estimates gradient by incorporating\nmemory of previous gradient information. We present theoretical analyses of\nC-SAG which show that C-SAG, like SAG, and C-SVRG, achieves a linear\nconvergence rate when the objective function is strongly convex; However, C-CAG\nachieves lower oracle query complexity per iteration than C-SVRG. Finally, we\npresent results of experiments showing that C-SAG converges substantially\nfaster than full gradient (FG), as well as C-SVRG.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 19:58:06 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 14:57:46 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Hsieh", "Tsung-Yu", ""], ["EL-Manzalawy", "Yasser", ""], ["Sun", "Yiwei", ""], ["Honavar", "Vasant", ""]]}, {"id": "1809.01525", "submitter": "Ivailo Hartarsky", "authors": "Ivailo Hartarsky and Tam\\'as R\\'obert Mezei", "title": "Complexity of 2D bootstrap percolation difficulty: Algorithm and\n  NP-hardness", "comments": "21 pages, 2 figures, changes: improved presentation, detailed proofs,\n  new appendix", "journal-ref": "SIAM J. Discrete Math., 2(34, 2020), 1444-1459", "doi": "10.1137/19M1239933", "report-no": null, "categories": "math.CO cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrap percolation is a class of cellular automata with random initial\nstate. Two-dimensional bootstrap percolation models have three rough\nuniversality classes, the most studied being the `critical' one. For this class\nthe scaling of the quantity of greatest interest -- the critical probability --\nwas determined by Bollob\\'as, Duminil-Copin, Morris and Smith in terms of a\nsimply defined combinatorial quantity called `difficulty', so the subject\nseemed closed up to finding sharper results. However, the computation of the\ndifficulty, was never considered. In this paper we provide the first algorithm\nto determine this quantity, which is, surprisingly, not as easy as the\ndefinition leads to thinking. The proof also provides some explicit upper\nbounds, which are of use for bootstrap percolation. On the other hand, we also\nprove the negative result that computing the difficulty of a critical model is\nNP-hard. This two-dimensional picture contrasts with an upcoming result of\nBalister, Bollob\\'as, Morris and Smith on uncomputability in higher dimensions.\nThe proof of NP-hardness is achieved by a technical reduction to the Set Cover\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 14:03:48 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2019 15:24:46 GMT"}, {"version": "v3", "created": "Sat, 30 Nov 2019 14:56:30 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Hartarsky", "Ivailo", ""], ["Mezei", "Tam\u00e1s R\u00f3bert", ""]]}, {"id": "1809.01998", "submitter": "Irena Rusu Ph.D.", "authors": "Irena Rusu", "title": "Min (A)cyclic Feedback Vertex Sets and Min Ones Monotone 3-SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In directed graphs, we investigate the problems of finding: 1) a minimum\nfeedback vertex set (also called the Feedback Vertex Set problem, or MFVS), 2)\na feedback vertex set inducing an acyclic graph (also called the Vertex\n2-Coloring without Monochromatic Cycles problem, or Acyclic FVS) and 3) a\nminimum feedback vertex set inducing an acyclic graph (Acyclic MFVS).\n  We show that these problems are strongly related to (variants of) Monotone\n3-SAT and Monotone NAE 3-SAT, where monotone means that all literals are in\npositive form. As a consequence, we deduce several NP-completeness results on\nrestricted versions of these problems. In particular, we define the 2-Choice\nversion of an optimization problem to be its restriction where the optimum\nvalue is known to be either D or D+1 for some integer D, and the problem is\nreduced to decide which of D or D+1 is the optimum value. We show that the\n2-Choice versions of MFVS, Acyclic MFVS, Min Ones Monotone 3-SAT and Min Ones\nMonotone NAE 3-SAT are NP-complete. The two latter problems are the variants of\nMonotone 3-SAT and respectively Monotone NAE 3-SAT requiring that the truth\nassignment minimize the number of variables set to true.\n  Finally, we propose two classes of directed graphs for which Acyclic FVS is\npolynomially solvable, namely flow reducible graphs (for which MFVS is already\nknown to be polynomially solvable) and C1P-digraphs (defined by an adjacency\nmatrix with the Consecutive Ones Property).\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 13:58:03 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Rusu", "Irena", ""]]}, {"id": "1809.02254", "submitter": "Justin Thaler", "authors": "Mark Bun, Robin Kothari, Justin Thaler", "title": "Quantum algorithms and approximating polynomials for composed functions\n  with shared inputs", "comments": "31 pages; 1 figure. This update includes an additional result on\n  lower bounds for AC$^0 \\circ \\oplus$ computing the Inner Product function on\n  average", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give new quantum algorithms for evaluating composed functions whose inputs\nmay be shared between bottom-level gates. Let $f$ be a Boolean function and\nconsider a function $F$ obtained by applying $f$ to conjunctions of possibly\noverlapping subsets of $n$ variables. If $f$ has quantum query complexity\n$Q(f)$, we give an algorithm for evaluating $F$ using $\\tilde{O}(\\sqrt{Q(f)\n\\cdot n})$ quantum queries. This improves on the bound of $O(Q(f) \\cdot\n\\sqrt{n})$ that follows by treating each conjunction independently, and is\ntight for worst-case choices of $f$. Using completely different techniques, we\nprove a similar tight composition theorem for the approximate degree of $f$.\n  By recursively applying our composition theorems, we obtain a nearly optimal\n$\\tilde{O}(n^{1-2^{-d}})$ upper bound on the quantum query complexity and\napproximate degree of linear-size depth-$d$ AC$^0$ circuits. As a consequence,\nsuch circuits can be PAC learned in subexponential time, even in the\nchallenging agnostic setting. Prior to our work, a subexponential-time\nalgorithm was not known even for linear-size depth-3 AC$^0$ circuits.\n  As an additional consequence, we show that AC$^0 \\circ \\oplus$ circuits of\ndepth $d+1$ require size $\\tilde{\\Omega}(n^{1/(1- 2^{-d})}) \\geq \\omega(n^{1+\n2^{-d}} )$ to compute the Inner Product function even on average. The previous\nbest size lower bound was $\\Omega(n^{1+4^{-(d+1)}})$ and only held in the worst\ncase (Cheraghchi et al., JCSS 2018).\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 23:58:47 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 22:11:31 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bun", "Mark", ""], ["Kothari", "Robin", ""], ["Thaler", "Justin", ""]]}, {"id": "1809.02280", "submitter": "Rucha Kulkarni", "authors": "Shant Boodaghians, Rucha Kulkarni, Ruta Mehta", "title": "Smoothed Efficient Algorithms and Reductions for Network Coordination\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Worst-case hardness results for most equilibrium computation problems have\nraised the need for beyond-worst-case analysis. To this end, we study the\nsmoothed complexity of finding pure Nash equilibria in Network Coordination\nGames, a PLS-complete problem in the worst case. This is a potential game where\nthe sequential-better-response algorithm is known to converge to a pure NE,\nalbeit in exponential time. First, we prove polynomial (resp. quasi-polynomial)\nsmoothed complexity when the underlying game graph is a complete (resp.\narbitrary) graph, and every player has constantly many strategies. We note that\nthe complete graph case is reminiscent of perturbing all parameters, a common\nassumption in most known smoothed analysis results.\n  Second, we define a notion of smoothness-preserving reduction among search\nproblems, and obtain reductions from $2$-strategy network coordination games to\nlocal-max-cut, and from $k$-strategy games (with arbitrary $k$) to\nlocal-max-cut up to two flips. The former together with the recent result of\n[BCC18] gives an alternate $O(n^8)$-time smoothed algorithm for the\n$2$-strategy case. This notion of reduction allows for the extension of\nsmoothed efficient algorithms from one problem to another.\n  For the first set of results, we develop techniques to bound the probability\nthat an (adversarial) better-response sequence makes slow improvements on the\npotential. Our approach combines and generalizes the local-max-cut approaches\nof [ER14,ABPW17] to handle the multi-strategy case: it requires a careful\ndefinition of the matrix which captures the increase in potential, a tighter\nunion bound on adversarial sequences, and balancing it with good enough rank\nbounds. We believe that the approach and notions developed herein could be of\ninterest in addressing the smoothed complexity of other potential and/or\ncongestion games.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 02:29:20 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 01:26:32 GMT"}, {"version": "v3", "created": "Sat, 17 Nov 2018 17:24:23 GMT"}, {"version": "v4", "created": "Tue, 26 Feb 2019 18:31:39 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Boodaghians", "Shant", ""], ["Kulkarni", "Rucha", ""], ["Mehta", "Ruta", ""]]}, {"id": "1809.02434", "submitter": "Riccardo Dondi", "authors": "Riccardo Dondi, Mohammad Mehdi Hosseinzadeh, Giancarlo Mauri, Italo\n  Zoppis", "title": "Top-k Overlapping Densest Subgraphs: Approximation and Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in graph mining is finding dense subgraphs, with several\napplications in different fields, a notable example being identifying\ncommunities. While a lot of effort has been put on the problem of finding a\nsingle dense subgraph, only recently the focus has been shifted to the problem\nof finding a set of densest subgraphs. Some approaches aim at finding disjoint\nsubgraphs, while in many real-world networks communities are often overlapping.\nAn approach introduced to find possible overlapping subgraphs is the Top-k\nOverlapping Densest Subgraphs problem. For a given integer k >= 1, the goal of\nthis problem is to find a set of k densest subgraphs that may share some\nvertices. The objective function to be maximized takes into account both the\ndensity of the subgraphs and the distance between subgraphs in the solution.\n  The Top-k Overlapping Densest Subgraphs problem has been shown to admit a\n1/10-factor approximation algorithm. Furthermore, the computational complexity\nof the problem has been left open. In this paper, we present contributions\nconcerning the approximability and the computational complexity of the problem.\nFor the approximability, we present approximation algorithms that improves the\napproximation factor to 1/2 , when k is bounded by the vertex set, and to 2/3\nwhen k is a constant. For the computational complexity, we show that the\nproblem is NP-hard even when k = 3.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 12:21:03 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 12:33:42 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Dondi", "Riccardo", ""], ["Hosseinzadeh", "Mohammad Mehdi", ""], ["Mauri", "Giancarlo", ""], ["Zoppis", "Italo", ""]]}, {"id": "1809.02656", "submitter": "Satu Elisa Schaeffer", "authors": "Nancy A. Arellano-Arriaga and Juli\\'an Molina and Satu Elisa Schaeffer\n  and Ada M. \\'Alvarez-Socarr\\'as and Iris A. Mart\\'inez-Salazar", "title": "Complexity of MLDP", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We carry out an explicit examination of the NP-hardness of a bi- objective\noptimization problem to minimize distance and latency of a single-vehicle route\ndesigned to serve a set of client requests. In addition to being a Hamiltonian\ncycle the route is to minimize the traveled distance of the vehicle as well as\nthe total waiting time of the clients along the route.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 20:02:47 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Arellano-Arriaga", "Nancy A.", ""], ["Molina", "Juli\u00e1n", ""], ["Schaeffer", "Satu Elisa", ""], ["\u00c1lvarez-Socarr\u00e1s", "Ada M.", ""], ["Mart\u00ednez-Salazar", "Iris A.", ""]]}, {"id": "1809.02835", "submitter": "Igor Shinkar", "authors": "Noga Alon, Jonathan D. Cohen, Thomas L. Griffiths, Pasin Manurangsi,\n  Daniel Reichman, Igor Shinkar, Tal Wagner, Alexander Yu", "title": "Multitasking Capacity: Hardness Results and Improved Constructions", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of determining the maximal $\\alpha \\in (0,1]$ such\nthat every matching $M$ of size $k$ (or at most $k$) in a bipartite graph $G$\ncontains an induced matching of size at least $\\alpha |M|$. This measure was\nrecently introduced in Alon et al. (NIPS 2018) and is motivated by\nconnectionist models of cognition as well as modeling interference in wireless\nand communication networks.\n  We prove various hardness results for computing $\\alpha$ either exactly or\napproximately. En route to our results, we also consider the maximum connected\nmatching problem: determining the largest matching $N$ in a graph $G$ such that\nevery two edges in $N$ are connected by an edge. We prove a nearly optimal\n$n^{1-\\epsilon}$ hardness of approximation result (under randomized reductions)\nfor connected matching in bipartite graphs (with both sides of cardinality\n$n$). Towards this end we define bipartite half-covers: A new combinatorial\nobject that may be of independent interest. To the best of our knowledge, the\nbest previous hardness result for the connected matching problem was some\nconstant $\\beta>1$.\n  Finally, we demonstrate the existence of bipartite graphs with $n$ vertices\non each side of average degree $d$, that achieve $\\alpha=1/2-\\epsilon$ for\nmatchings of size sufficiently smaller than $n/poly(d)$. This nearly matches\nthe trivial upper bound of $1/2$ on $\\alpha$ which holds for any graph\ncontaining a path of length 3.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 17:04:36 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Alon", "Noga", ""], ["Cohen", "Jonathan D.", ""], ["Griffiths", "Thomas L.", ""], ["Manurangsi", "Pasin", ""], ["Reichman", "Daniel", ""], ["Shinkar", "Igor", ""], ["Wagner", "Tal", ""], ["Yu", "Alexander", ""]]}, {"id": "1809.02843", "submitter": "Nicola Galesi", "authors": "Stefan Dantchev, Nicola Galesi, Barnaby Martin", "title": "Resolution and the binary encoding of combinatorial principles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the size complexity of proofs in $Res(s)$ -- an extension of\nResolution working on $s$-DNFs instead of clauses -- for families of\ncontradictions given in the {\\em unusual binary} encoding. A motivation of our\nwork is size lower bounds of refutations in Resolution for families of\ncontradictions in the usual unary encoding. Our main interest is the $k$-Clique\nPrinciple, whose Resolution complexity is still unknown.\n  Our main result is a $n^{\\Omega(k)}$ lower bound for the size of refutations\nof the binary $k$-Clique Principle in $Res(\\lfloor \\frac{1}{2}\\log \\log\nn\\rfloor)$. This improves the result of Lauria, Pudl\\'ak et al. [24] who proved\nthe lower bound for Resolution, that is $Res(1)$.\n  Our second lower bound proves that in $RES(s)$ for $s\\leq\n\\log^{\\frac{1}{2-\\epsilon}}(n)$, the shortest proofs of the $BinPHP^m_n$,\nrequires size $2^{n^{1-\\delta}}$, for any $\\delta>0$. Furthermore we prove that\n$BinPHP^m_n$ can be refuted in size $2^{\\Theta(n)}$ in treelike $Res(1)$,\ncontrasting with the unary case, where $PHP^m_n$ requires treelike $RES(1)$ \\\nrefutations of size $2^{\\Omega(n \\log n)}$ [9,16].\n  Furthermore we study under what conditions the complexity of refutations in\nResolution will not increase significantly (more than a polynomial factor) when\nshifting between the unary encoding and the binary encoding. We show that this\nis true, from unary to binary, for propositional encodings of principles\nexpressible as a $\\Pi_2$-formula and involving {\\em total variable\ncomparisons}. We then show that this is true, from binary to unary, when one\nconsiders the \\emph{functional unary encoding}. Finally we prove that the\nbinary encoding of the general Ordering principle $OP$ -- with no total\nordering constraints -- is polynomially provable in Resolution.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 17:41:16 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 12:22:21 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Dantchev", "Stefan", ""], ["Galesi", "Nicola", ""], ["Martin", "Barnaby", ""]]}, {"id": "1809.03063", "submitter": "Mohammad Mahmoody", "authors": "Saeed Mahloujifar, Dimitrios I. Diochnos, Mohammad Mahmoody", "title": "The Curse of Concentration in Robust Learning: Evasion and Poisoning\n  Attacks from Concentration of Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern machine learning classifiers are shown to be vulnerable to\nadversarial perturbations of the instances. Despite a massive amount of work\nfocusing on making classifiers robust, the task seems quite challenging. In\nthis work, through a theoretical study, we investigate the adversarial risk and\nrobustness of classifiers and draw a connection to the well-known phenomenon of\nconcentration of measure in metric measure spaces. We show that if the metric\nprobability space of the test instance is concentrated, any classifier with\nsome initial constant error is inherently vulnerable to adversarial\nperturbations.\n  One class of concentrated metric probability spaces are the so-called Levy\nfamilies that include many natural distributions. In this special case, our\nattacks only need to perturb the test instance by at most $O(\\sqrt n)$ to make\nit misclassified, where $n$ is the data dimension. Using our general result\nabout Levy instance spaces, we first recover as special case some of the\npreviously proved results about the existence of adversarial examples. However,\nmany more Levy families are known (e.g., product distribution under the Hamming\ndistance) for which we immediately obtain new attacks that find adversarial\nexamples of distance $O(\\sqrt n)$.\n  Finally, we show that concentration of measure for product spaces implies the\nexistence of forms of \"poisoning\" attacks in which the adversary tampers with\nthe training data with the goal of degrading the classifier. In particular, we\nshow that for any learning algorithm that uses $m$ training examples, there is\nan adversary who can increase the probability of any \"bad property\" (e.g.,\nfailing on a particular test instance) that initially happens with\nnon-negligible probability to $\\approx 1$ by substituting only $\\tilde{O}(\\sqrt\nm)$ of the examples with other (still correctly labeled) examples.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 23:57:29 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 04:31:04 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Diochnos", "Dimitrios I.", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1809.03103", "submitter": "EPTCS", "authors": "Laura Bozzelli (University of Napoli Federico II, Italy), Alberto\n  Molinari (University of Udine, Italy), Angelo Montanari (University of Udine,\n  Italy), Adriano Peron (University of Napoli Federico II, Italy)", "title": "Complexity of Timeline-Based Planning over Dense Temporal Domains:\n  Exploring the Middle Ground", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 191-205", "doi": "10.4204/EPTCS.277.14", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address complexity issues for timeline-based planning over\ndense temporal domains. The planning problem is modeled by means of a set of\nindependent, but interacting, components, each one represented by a number of\nstate variables, whose behavior over time (timelines) is governed by a set of\ntemporal constraints (synchronization rules). While the temporal domain is\nusually assumed to be discrete, here we consider the dense case. Dense\ntimeline-based planning has been recently shown to be undecidable in the\ngeneral case; decidability (NP-completeness) can be recovered by restricting to\npurely existential synchronization rules (trigger-less rules). In this paper,\nwe investigate the unexplored area of intermediate cases in between these two\nextremes. We first show that decidability and non-primitive recursive-hardness\ncan be proved by admitting synchronization rules with a trigger, but forcing\nthem to suitably check constraints only in the future with respect to the\ntrigger (future simple rules). More \"tractable\" results can be obtained by\nadditionally constraining the form of intervals in future simple rules:\nEXPSPACE-completeness is guaranteed by avoiding singular intervals,\nPSPACE-completeness by admitting only intervals of the forms [0,a] and\n[b,$\\infty$[.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:33:42 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Bozzelli", "Laura", "", "University of Napoli Federico II, Italy"], ["Molinari", "Alberto", "", "University of Udine, Italy"], ["Montanari", "Angelo", "", "University of Udine,\n  Italy"], ["Peron", "Adriano", "", "University of Napoli Federico II, Italy"]]}, {"id": "1809.03104", "submitter": "EPTCS", "authors": "Marcin Przyby{\\l}ko", "title": "On Computing the Measures of First-Order Definable Sets of Trees", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 206-219", "doi": "10.4204/EPTCS.277.15", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the measure of a regular language of\ninfinite binary trees. While the general case remains unsolved, we show that\nthe measure of a language defined by a first-order formula with no descendant\nrelation or by a Boolean combination of conjunctive queries (with descendant\nrelation) is rational and computable. Additionally, we provide an example of a\nfirst-order formula that uses descendant relation and defines a language of\ninfinite trees having an irrational measure.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:34:04 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Przyby\u0142ko", "Marcin", ""]]}, {"id": "1809.03141", "submitter": "Marcin Waniek", "authors": "Marcin Waniek, Khaled Elbassioni, Flavio L. Pinheiro, Cesar A. Hidalgo\n  and Aamena Alshamsi", "title": "Computational Aspects of Optimal Strategic Network Diffusion", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.tcs.2020.01.027", "report-no": null, "categories": "cs.CC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion on complex networks is often modeled as a stochastic process. Yet,\nrecent work on strategic diffusion emphasizes the decision power of agents and\ntreats diffusion as a strategic problem. Here we study the computational\naspects of strategic diffusion, i.e., finding the optimal sequence of nodes to\nactivate a network in the minimum time. We prove that finding an optimal\nsolution to this problem is NP-complete in a general case. To overcome this\ncomputational difficulty, we present an algorithm to compute an optimal\nsolution based on a dynamic programming technique. We also show that the\nproblem is fixed parameter-tractable when parametrized by the product of the\ntreewidth and maximum degree. We analyze the possibility of developing an\nefficient approximation algorithm and show that two heuristic algorithms\nproposed so far cannot have better than a logarithmic approximation guarantee.\nFinally, we prove that the problem does not admit better than a logarithmic\napproximation, unless P=NP.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 05:29:10 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 09:04:31 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Waniek", "Marcin", ""], ["Elbassioni", "Khaled", ""], ["Pinheiro", "Flavio L.", ""], ["Hidalgo", "Cesar A.", ""], ["Alshamsi", "Aamena", ""]]}, {"id": "1809.03474", "submitter": "Mohammad Mahmoody", "authors": "Saeed Mahloujifar, Mohammad Mahmoody, Ameer Mohammed", "title": "Multi-party Poisoning through Generalized $p$-Tampering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a poisoning attack against a learning algorithm, an adversary tampers with\na fraction of the training data $T$ with the goal of increasing the\nclassification error of the constructed hypothesis/model over the final test\ndistribution. In the distributed setting, $T$ might be gathered gradually from\n$m$ data providers $P_1,\\dots,P_m$ who generate and submit their shares of $T$\nin an online way.\n  In this work, we initiate a formal study of $(k,p)$-poisoning attacks in\nwhich an adversary controls $k\\in[n]$ of the parties, and even for each\ncorrupted party $P_i$, the adversary submits some poisoned data $T'_i$ on\nbehalf of $P_i$ that is still \"$(1-p)$-close\" to the correct data $T_i$ (e.g.,\n$1-p$ fraction of $T'_i$ is still honestly generated). For $k=m$, this model\nbecomes the traditional notion of poisoning, and for $p=1$ it coincides with\nthe standard notion of corruption in multi-party computation.\n  We prove that if there is an initial constant error for the generated\nhypothesis $h$, there is always a $(k,p)$-poisoning attacker who can decrease\nthe confidence of $h$ (to have a small error), or alternatively increase the\nerror of $h$, by $\\Omega(p \\cdot k/m)$. Our attacks can be implemented in\npolynomial time given samples from the correct data, and they use no wrong\nlabels if the original distributions are not noisy.\n  At a technical level, we prove a general lemma about biasing bounded\nfunctions $f(x_1,\\dots,x_n)\\in[0,1]$ through an attack model in which each\nblock $x_i$ might be controlled by an adversary with marginal probability $p$\nin an online way. When the probabilities are independent, this coincides with\nthe model of $p$-tampering attacks, thus we call our model generalized\n$p$-tampering. We prove the power of such attacks by incorporating ideas from\nthe context of coin-flipping attacks into the $p$-tampering model and\ngeneralize the results in both of these areas.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:47:24 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 22:49:33 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""], ["Mohammed", "Ameer", ""]]}, {"id": "1809.03671", "submitter": "Troy Lee", "authors": "Troy Lee and Maharshi Ray and Miklos Santha", "title": "Strategies for quantum races", "comments": "50 pages. v2 fixes an error in Lemma 48, which leads to an increase\n  in the collision probability by a factor of the number of players", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We initiate the study of quantum races, games where two or more quantum\ncomputers compete to solve a computational problem. While the problem of\ndueling algorithms has been studied for classical deterministic algorithms, the\nquantum case presents additional sources of uncertainty for the players. The\nforemost among these is that players do not know if they have solved the\nproblem until they measure their quantum state. This question of `when to\nmeasure?' presents a very interesting strategic problem. We develop a\ngame-theoretic model of a multiplayer quantum race, and find an approximate\nNash equilibrium where all players play the same strategy. In the two-party\ncase, we further show that this strategy is nearly optimal in terms of payoff\namong all symmetric Nash equilibria. A key role in our analysis of quantum\nraces is played by a more tractable version of the game where there is no\npayout on a tie; for such races we completely characterize the Nash equilibria\nin the two-party case.\n  One application of our results is to the stability of the Bitcoin protocol\nwhen mining is done by quantum computers. Bitcoin mining is a race to solve a\ncomputational search problem, with the winner gaining the right to create a new\nblock. Our results inform the strategies that eventual quantum miners should\nuse, and also indicate that the collision probability---the probability that\ntwo miners find a new block at the same time---would not be too high in the\ncase of quantum miners. Such collisions are undesirable as they lead to forking\nof the Bitcoin blockchain.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 03:43:00 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 09:34:16 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Lee", "Troy", ""], ["Ray", "Maharshi", ""], ["Santha", "Miklos", ""]]}, {"id": "1809.04091", "submitter": "Pooya Ronagh", "authors": "Behrooz Sepehry, Ehsan Iranmanesh, Michael P. Friedlander and Pooya\n  Ronagh", "title": "Quantum Algorithms for Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.OC quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two quantum algorithms for solving structured prediction\nproblems. We first show that a stochastic gradient descent that uses the\nquantum minimum finding algorithm and takes its probabilistic failure into\naccount solves the structured prediction problem with a runtime that scales\nwith the square root of the size of the label space, and in $\\widetilde\nO\\left(1/\\epsilon\\right)$ with respect to the precision, $\\epsilon$, of the\nsolution. Motivated by robust inference techniques in machine learning, we then\nintroduce another quantum algorithm that solves a smooth approximation of the\nstructured prediction problem with a similar quantum speedup in the size of the\nlabel space and a similar scaling in the precision parameter. In doing so, we\nanalyze a variant of stochastic gradient descent for convex optimization in the\npresence of an additive error in the calculation of the gradients, and show\nthat its convergence rate does not deteriorate if the additive errors are of\nthe order $O(\\sqrt\\epsilon)$. This algorithm uses quantum Gibbs sampling at\ntemperature $\\Omega (\\epsilon)$ as a subroutine. Based on these theoretical\nobservations, we propose a method for using quantum Gibbs samplers to combine\nfeedforward neural networks with probabilistic graphical models for quantum\nmachine learning. Our numerical results using Monte Carlo simulations on an\nimage tagging task demonstrate the benefit of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 18:04:11 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 18:00:21 GMT"}, {"version": "v3", "created": "Tue, 8 Jan 2019 19:13:05 GMT"}, {"version": "v4", "created": "Thu, 28 Feb 2019 00:45:51 GMT"}, {"version": "v5", "created": "Thu, 1 Jul 2021 20:43:29 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Sepehry", "Behrooz", ""], ["Iranmanesh", "Ehsan", ""], ["Friedlander", "Michael P.", ""], ["Ronagh", "Pooya", ""]]}, {"id": "1809.04092", "submitter": "S Venkitesh", "authors": "Nutan Limaye, Karteek Sreenivasaiah, Srikanth Srinivasan, Utkarsh\n  Tripathi, S. Venkitesh", "title": "A Fixed-Depth Size-Hierarchy Theorem for AC$^0[\\oplus]$ via the Coin\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the first Fixed-depth Size-hierarchy Theorem for uniform\nAC$^0[\\oplus]$ circuits; in particular, for fixed $d$, the class\n$\\mathcal{C}_{d,k}$ of uniform AC$^0[\\oplus]$ formulas of depth $d$ and size\n$n^k$ form an infinite hierarchy. For this, we find the first class of explicit\nfunctions giving (up to polynomial factor) matching upper and lower bounds for\nAC$^0[\\oplus]$ formulas, derived from the $\\delta$-Coin Problem, the\ncomputational problem of distinguishing between coins that are heads with\nprobability $(1+\\delta)/2$ or $(1-\\delta)/2,$ where $\\delta$ is a parameter\ngoing to $0$. We study this problem's complexity and make progress on both\nupper bounds and lower bounds.\n  Upper bounds. We find explicit monotone AC$^0$ formulas solving the\n$\\delta$-coin problem, having depth $d$, size $\\exp(O(d(1/\\delta)^{1/(d-1)}))$,\nand sample complexity poly$(1/\\delta)$, for constant $d\\ge2$. This matches\nprevious upper bounds of O'Donnell and Wimmer (ICALP 2007) and Amano (ICALP\n2009) in terms of size and improves the sample complexity.\n  Lower bounds. The upper bounds are nearly tight even for the stronger model\nof AC$^0[\\oplus]$ formulas (which allow NOT and Parity gates): any\nAC$^0[\\oplus]$ formula solving the $\\delta$-coin problem must have size\n$\\exp(\\Omega(d(1/\\delta)^{1/(d-1)})).$ This strengthens a result of Cohen,\nGanor and Raz (APPROX-RANDOM 2014), who prove a similar result for AC$^0$, and\na result of Shaltiel and Viola (SICOMP 2010), who give a superpolynomially\nweaker (still exponential) lower bound.\n  The upper bound is a derandomization involving a use of Janson's inequality\n(as far as we know, the first such use of the inequality) and classical\ncombinatorial designs. For the lower bound, we prove an optimal (up to constant\nfactor) degree lower bound for multivariate polynomials over $\\mathbb{F}_2$\nsolving the $\\delta$-coin problem, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 18:04:36 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 07:41:22 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Limaye", "Nutan", ""], ["Sreenivasaiah", "Karteek", ""], ["Srinivasan", "Srikanth", ""], ["Tripathi", "Utkarsh", ""], ["Venkitesh", "S.", ""]]}, {"id": "1809.04312", "submitter": "Sixue Liu", "authors": "S. Cliff Liu", "title": "The Curse and Blessing of Not-All-Equal in k-Satisfiability", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a natural variant of the $k$-SAT problem, NAE-$k$-SAT additionally\nrequires the literals in each clause to take not-all-equal (NAE) truth values.\nIn this paper, we study the worst-case time complexities of solving NAE-$k$-SAT\nand MAX-NAE-$k$-SAT approximation, as functions of $k$, the number of variables\n$n$, and the performance ratio $\\delta$. The latter problem asks for a solution\nof at least $\\delta$ times the optimal. Our main results include:\n  (1) A deterministic algorithm for NAE-$k$-SAT that is faster than the best\ndeterministic algorithm for $k$-SAT on all $k \\ge 3$. Previously, no\nNAE-$k$-SAT algorithm is known to be faster than $k$-SAT algorithms. For $k =\n3$, we achieve an upper bound of $1.326^n$. The corresponding bound for $3$-SAT\nis $1.328^n$.\n  (2) A randomized algorithm for MAX-NAE-$k$-SAT approximation, with upper\nbound $(2 - \\epsilon_k(\\delta))^n$ where $\\epsilon_k(\\delta) > 0$ only depends\non $k$ and $\\delta$. Previously, no upper bound better than the trivial $2^n$\nis known for MAX-NAE-$k$-SAT approximation on $k \\ge 4$. For $\\delta = 0.9$ and\n$k = 4$, we achieve an upper bound of $1.947^n$.\n  (3) A deterministic algorithm for MAX-NAE-$k$-SAT approximation. For $\\delta\n= 0.9$ and $k = 3$, we achieve an upper bound of $1.698^n$, which is better\nthan the upper bound $1.731^n$ of the exact algorithm for MAX-NAE-$3$-SAT.\n  Our finding sheds new light on the following question: Is NAE-$k$-SAT easier\nthan $k$-SAT? The answer might be affirmative at least on solving the problems\nexactly and deterministically, while approximately solving MAX-NAE-$k$-SAT\nmight be harder than MAX-$k$-SAT on $k \\ge 4$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 08:50:23 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 06:15:15 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 06:41:08 GMT"}, {"version": "v4", "created": "Sun, 10 Feb 2019 00:10:54 GMT"}, {"version": "v5", "created": "Tue, 25 Jun 2019 21:27:01 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Liu", "S. Cliff", ""]]}, {"id": "1809.04519", "submitter": "Aizhong Li", "authors": "Aizhong Li", "title": "A Simple Elementary Proof of P=NP based on the Relational Model of E. F.\n  Codd", "comments": "14 pages, 6 figures. (added polynomial space bound to a periodic\n  machine, formally)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The P versus NP problem is studied under the relational model of E. F. Codd.\nI found that the term \"complete configuration\" is unnecessary and harmful in\ncomputational complexity theory because of excessive symbol redundancy. For an\ninput, its valid sequences of complete configurations are normalized into a\nrelational model of shared trichoices with no redundancy. To simplify the\nproblem, a polynomial time nondeterministic Turing machine is polynomially\nreduced to a periodic machine, which only reverses its tape head displacement\nat the tape ends. By enumerating all the O(p(n)) shared trichoices, a\npolynomial time p(n) periodic machine is simulated in time O((p(n))^4) under\nlogarithmic cost. A simple elementary proof of P=NP is obtained.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 15:40:15 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 16:31:21 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2018 15:30:07 GMT"}, {"version": "v4", "created": "Mon, 22 Oct 2018 15:51:01 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Li", "Aizhong", ""]]}, {"id": "1809.04954", "submitter": "Hannes Pichler", "authors": "Hannes Pichler, Sheng-Tao Wang, Leo Zhou, Soonwon Choi, Mikhail D.\n  Lukin", "title": "Computational complexity of the Rydberg blockade in two dimensions", "comments": "12 pages, see also companion paper arXiv:1808.10816", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.quant-gas cs.CC physics.atom-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the computational complexity of finding the ground state of the\ntwo-dimensional array of quantum bits that interact via strong van der Waals\ninteractions. Specifically, we focus on systems where the interaction strength\nbetween two spins depends only on their relative distance $x$ and decays as\n$1/x^6$ that have been realized with individually trapped homogeneously excited\nneutral atoms interacting via the so-called Rydberg blockade mechanism. We show\nthat the solution to NP-complete problems can be encoded in ground state of\nsuch a many-body system by a proper geometrical arrangement of the atoms. We\npresent a reduction from the NP-complete maximum independent set problem on\nplanar graphs with maximum degree three. Our results demonstrate that\ncomputationally hard optimization problems can be naturally addressed with\ncoherent quantum optimizers accessible in near term experiments.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 13:43:14 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Pichler", "Hannes", ""], ["Wang", "Sheng-Tao", ""], ["Zhou", "Leo", ""], ["Choi", "Soonwon", ""], ["Lukin", "Mikhail D.", ""]]}, {"id": "1809.05009", "submitter": "Teun Janssen", "authors": "T. Janssen, C. Swennenhuis, A. Bitar, T. Bosman, D. Gijswijt, L. van\n  Iersel, S. Dauz\\'ere-P\\'er\\`es, C. Yugma", "title": "Parallel Machine Scheduling with a Single Resource per Job", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of scheduling jobs on parallel machines minimizing the\ntotal completion time, with each job using exactly one resource. First, we\nderive fundamental properties of the problem and show that the problem is\npolynomially solvable if $p_j = 1$. Then we look at a variant of the shortest\nprocessing time rule as an approximation algorithm for the problem and show\nthat it gives at least a $(2-\\frac{1}{m})$-approximation. Subsequently, we show\nthat, although the complexity of the problem remains open, three related\nproblems are $\\mathcal{NP}$-hard. In the first problem, every resource also has\na subset of machines on which it can be used. In the second problem, once a\nresource has been used on a machine it cannot be used on any other machine,\nhence all jobs using the same resource need to be scheduled on the same\nmachine. In the third problem, every job needs exactly two resources instead of\njust one.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 15:09:27 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 11:15:23 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 11:36:28 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Janssen", "T.", ""], ["Swennenhuis", "C.", ""], ["Bitar", "A.", ""], ["Bosman", "T.", ""], ["Gijswijt", "D.", ""], ["van Iersel", "L.", ""], ["Dauz\u00e9re-P\u00e9r\u00e8s", "S.", ""], ["Yugma", "C.", ""]]}, {"id": "1809.05443", "submitter": "Arnaud Mary", "authors": "Nicolas Bousquet, Arnaud Mary", "title": "Reconfiguration of graphs with connectivity constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph $G$ realizes the degree sequence $S$ if the degrees of its vertices\nis $S$. Hakimi gave a necessary and sufficient condition to guarantee that\nthere exists a connected multigraph realizing $S$. Taylor later proved that any\nconnected multigraph can be transformed into any other via a sequence of flips\n(maintaining connectivity at any step). A flip consists in replacing two edges\n$ab$ and $cd$ by the diagonals $ac$ and $bd$. In this paper, we study a\ngeneralization of this problem. A set of subsets of vertices $\\mathcal{CC}$ is\n\\emph{nested} if for every $C,C' \\in \\mathcal{CC}$ either $C \\cap C' =\n\\emptyset$ or one is included in the other. We are interested in multigraphs\nrealizing a degree sequence $S$ and such that all the sets of a nested\ncollection $\\mathcal{CC}$ induce connected subgraphs. Such constraints\nnaturally appear in tandem mass spectrometry.\n  We show that it is possible to decide in polynomial if there exists a graph\nrealizing $S$ where all the sets in $\\mathcal{CC}$ induce connected subgraphs.\nMoreover, we prove that all such graphs can be obtained via a sequence of flips\nsuch that all the intermediate graphs also realize $S$ and where all the sets\nof $\\mathcal{CC}$ induce connected subgraphs. Our proof is algorithmic and\nprovides a polynomial time approximation algorithm on the shortest sequence of\nflips between two graphs whose ratio depends on the depth of the nested\npartition.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 14:38:22 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Bousquet", "Nicolas", ""], ["Mary", "Arnaud", ""]]}, {"id": "1809.05925", "submitter": "Daniel Kane", "authors": "Daniel M. Kane", "title": "Quantum Money from Modular Forms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new idea for a class of public key quantum money protocols where\nthe bills are joint eigenstates of systems of commuting unitary operators. We\nshow that this system is secure against black box attacks, and propose an\nimplementation where our operators are obtained as Hecke operators on spaces of\nmodular forms.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 18:22:21 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 21:41:05 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Kane", "Daniel M.", ""]]}, {"id": "1809.05932", "submitter": "Deepanshu Kush", "authors": "Swapnam Bajpai, Vaibhav Krishan, Deepanshu Kush, Nutan Limaye and\n  Srikanth Srinivasan", "title": "A #SAT Algorithm for Small Constant-Depth Circuits with PTF gates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there is a randomized algorithm that, when given a small\nconstant-depth Boolean circuit $C$ made up of gates that compute\nconstant-degree Polynomial Threshold functions or PTFs (i.e., Boolean functions\nthat compute signs of constant-degree polynomials), counts the number of\nsatisfying assignments to $C$ in significantly better than brute-force time.\n  Formally, for any constants $d,k$, there is an $\\epsilon > 0$ such that the\nalgorithm counts the number of satisfying assignments to a given depth-$d$\ncircuit $C$ made up of $k$-PTF gates such that $C$ has size at most\n$n^{1+\\epsilon}$. The algorithm runs in time $2^{n-n^{\\Omega(\\epsilon)}}$.\n  Before our result, no algorithm for beating brute-force search was known even\nfor a single degree-$2$ PTF (which is a depth-$1$ circuit of linear size).\n  The main new tool is the use of a learning algorithm for learning degree-$1$\nPTFs (or Linear Threshold Functions) using comparison queries due to Kane,\nLovett, Moran and Zhang (FOCS 2017). We show that their ideas fit nicely into a\nmemoization approach that yields the #SAT algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 18:36:20 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Bajpai", "Swapnam", ""], ["Krishan", "Vaibhav", ""], ["Kush", "Deepanshu", ""], ["Limaye", "Nutan", ""], ["Srinivasan", "Srikanth", ""]]}, {"id": "1809.06041", "submitter": "Guillaume Ducoffe", "authors": "Guillaume Ducoffe and Arne Leitert", "title": "Equivalence between pathbreadth and strong pathbreadth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We say that a given graph $G = (V, E)$ has \\emph{pathbreadth} at most $\\rho$,\ndenoted $\\pb(G) \\leq \\rho$, if there exists a Roberston and Seymour's path\ndecomposition where every bag is contained in the $\\rho$-neighbourhood of some\nvertex. Similarly, we say that $G$ has \\emph{strong pathbreadth} at most\n$\\rho$, denoted $\\spb(G) \\leq \\rho$, if there exists a Roberston and Seymour's\npath decomposition where every bag is the complete $\\rho$-neighbourhood of some\nvertex. It is straightforward that $\\pb(G) \\leq \\spb(G)$ for any graph $G$.\nInspired from a close conjecture in [Leitert and Dragan, COCOA'16], we prove in\nthis note that $\\spb(G) \\leq 4 \\cdot \\pb(G)$.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 06:40:31 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Ducoffe", "Guillaume", ""], ["Leitert", "Arne", ""]]}, {"id": "1809.06171", "submitter": "Astrid Pieterse", "authors": "Hubie Chen, Bart M. P. Jansen, Astrid Pieterse", "title": "Best-case and Worst-case Sparsifiability of Boolean CSPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue the investigation of polynomial-time sparsification for\nNP-complete Boolean Constraint Satisfaction Problems (CSPs). The goal in\nsparsification is to reduce the number of constraints in a problem instance\nwithout changing the answer, such that a bound on the number of resulting\nconstraints can be given in terms of the number of variables n. We investigate\nhow the worst-case sparsification size depends on the types of constraints\nallowed in the problem formulation (the constraint language). Two algorithmic\nresults are presented. The first result essentially shows that for any arity k,\nthe only constraint type for which no nontrivial sparsification is possible has\nexactly one falsifying assignment, and corresponds to logical OR (up to\nnegations). Our second result concerns linear sparsification, that is, a\nreduction to an equivalent instance with O(n) constraints. Using linear algebra\nover rings of integers modulo prime powers, we give an elegant necessary and\nsufficient condition for a constraint type to be captured by a degree-1\npolynomial over such a ring, which yields linear sparsifications. The\ncombination of these algorithmic results allows us to prove two\ncharacterizations that capture the optimal sparsification sizes for a range of\nBoolean CSPs. For NP-complete Boolean CSPs whose constraints are symmetric (the\nsatisfaction depends only on the number of 1 values in the assignment, not on\ntheir positions), we give a complete characterization of which constraint\nlanguages allow for a linear sparsification. For Boolean CSPs in which every\nconstraint has arity at most three, we characterize the optimal size of\nsparsifications in terms of the largest OR that can be expressed by the\nconstraint language.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:00:18 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Chen", "Hubie", ""], ["Jansen", "Bart M. P.", ""], ["Pieterse", "Astrid", ""]]}, {"id": "1809.06956", "submitter": "Masoud Bashiri", "authors": "Masoud Bashiri, Hassan Jafarzadeh and Cody Fleming", "title": "PAIM: Platoon-based Autonomous Intersection Management", "comments": "Accepted to the ITSC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of autonomous ground vehicles and the recent advancements\nin Intelligent Transportation Systems, Autonomous Traffic Management has\ngarnered more and more attention. Autonomous Intersection Management (AIM),\nalso known as Cooperative Intersection Management (CIM) is among the more\nchallenging traffic problems that poses important questions related to safety\nand optimization in terms of delays, fuel consumption, emissions and\nreliability. Previously we introduced two stop-sign based policies for\nautonomous intersection management that were compatible with platoons of\nautonomous vehicles. These policies outperformed regular stop-sign policy both\nin terms of average delay per vehicle and variance in delay. This paper\nintroduces a reservation-based policy that utilizes the cost functions from our\nprevious work to derive optimal schedules for platoons of vehicles. The\nproposed policy guarantees safety by not allowing vehicles with conflicting\nturning movement to be in the conflict zone at the same time. Moreover, a\ngreedy algorithm is designed to search through all possible schedules to pick\nthe best that minimizes a cost function based on a trade-off between total\ndelay and variance in delay. A simulator software is designed to compare the\nresults of the proposed policy in terms of average delay per vehicle and\nvariance in delay with that of a 4-phase traffic light.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 22:26:11 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Bashiri", "Masoud", ""], ["Jafarzadeh", "Hassan", ""], ["Fleming", "Cody", ""]]}, {"id": "1809.08154", "submitter": "Anuj Dawar", "authors": "Anuj Dawar and Kashif Khan", "title": "Constructing Hard Examples for Graph Isomorphism", "comments": "20 pages. A revised version incorporating new experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for generating graphs that provide difficult examples\nfor practical Graph Isomorphism testers. We first give the theoretical\nconstruction, showing that we can have a family of graphs without any\nnon-trivial automorphisms which also have high Weisfeiler-Leman dimension. The\nconstruction is based on properties of random 3XOR-formulas. We describe how to\nconvert such a formula into a graph which has the desired properties with high\nprobability. We validate the method by an experimental implementation. We\nconstruct random formulas and validate them with a SAT solver to filter through\nsuitable ones, and then convert them into graphs. Experimental results\ndemonstrate that the resulting graphs do provide hard examples that match the\nhardest known benchmarks for graph isomorphism.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 14:47:54 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 10:38:30 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Dawar", "Anuj", ""], ["Khan", "Kashif", ""]]}, {"id": "1809.08453", "submitter": "Olivier Spanjaard", "authors": "Hugo Gilbert and Olivier Spanjaard", "title": "Optimizing a Generalized Gini Index in Stable Marriage Problems:\n  NP-Hardness, Approximation and a Polynomial Time Special Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with fairness in stable marriage problems. The idea studied\nhere is to achieve fairness thanks to a Generalized Gini Index (GGI), a\nwell-known criterion in inequality measurement, that includes both the\negalitarian and utilitarian criteria as special cases. We show that determining\na stable marriage optimizing a GGI criterion of agents' disutilities is an\nNP-hard problem. We then provide a polynomial time 2-approximation algorithm in\nthe general case, as well as an exact algorithm which is polynomial time in the\ncase of a constant number of non-zero weights parametrizing the GGI criterion.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 16:39:08 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Gilbert", "Hugo", ""], ["Spanjaard", "Olivier", ""]]}, {"id": "1809.08858", "submitter": "Balagopal Komarath", "authors": "Markus Bl\\\"aser and Balagopal Komarath and Karteek Sreenivasaiah", "title": "Graph Pattern Polynomials", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the time complexity of induced subgraph isomorphism problems where\nthe pattern graph is fixed. The earliest known example of an improvement over\ntrivial algorithms is by Itai and Rodeh (1978) who sped up triangle detection\nin graphs using fast matrix multiplication. This algorithm was generalized by\nNe\\v{s}et\\v{r}il and Poljak (1985) to speed up detection of k-cliques.\n  Improved algorithms are known for certain small-sized patterns. For example,\na linear-time algorithm is known for detecting length-4 paths. In this paper,\nwe give the first pattern detection algorithm that improves upon\nNe\\v{s}et\\v{r}il and Poljak's algorithm for arbitrarily large pattern graphs\n(not cliques). The algorithm is obtained by reducing the induced subgraph\nisomorphism problem to the problem of detecting multilinear terms in\nconstant-degree polynomials.\n  We show that the same technique can be used to reduce the induced subgraph\nisomorphism problem of many pattern graphs to constructing arithmetic circuits\ncomputing homomorphism polynomials of these pattern graphs. Using this, we\nobtain faster combinatorial algorithms (algorithms that do not use fast matrix\nmultiplication) for k-paths and k-cycles. We also obtain faster algorithms for\n5-paths and 5-cycles that match the runtime for triangle detection.\n  We show that these algorithms are expressible using polynomial families that\nwe call graph pattern polynomial families. We then define a notion of reduction\namong these polynomials that allows us to compare the complexity of various\npattern detection problems within this framework. For example, we show that the\ninduced subgraph isomorphism polynomial for any pattern that contains a\nk-clique is harder than the induced subgraph isomorphism polynomial for\nk-clique. An analogue of this theorem is not known with respect to general\nalgorithmic hardness.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 11:53:09 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Bl\u00e4ser", "Markus", ""], ["Komarath", "Balagopal", ""], ["Sreenivasaiah", "Karteek", ""]]}, {"id": "1809.09063", "submitter": "Kaave Hosseini", "authors": "Kaave Hosseini, Shachar Lovett, Grigory Yaroslavtsev", "title": "Optimality of Linear Sketching under Modular Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relation between streaming algorithms and linear sketching\nalgorithms, in the context of binary updates. We show that for inputs in $n$\ndimensions, the existence of efficient streaming algorithms which can process\n$\\Omega(n^2)$ updates implies efficient linear sketching algorithms with\ncomparable cost. This improves upon the previous work of Li, Nguyen and\nWoodruff [LNW14] and Ai, Hu, Li and Woodruff [AHLW16] which required a\ntriple-exponential number of updates to achieve a similar result for updates\nover integers. We extend our results to updates modulo $p$ for integers $p \\ge\n2$, and to approximation instead of exact computation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 17:12:11 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Hosseini", "Kaave", ""], ["Lovett", "Shachar", ""], ["Yaroslavtsev", "Grigory", ""]]}, {"id": "1809.09345", "submitter": "Pawe{\\l} Rz\\k{a}\\.zewski", "authors": "Karolina Okrasa and Pawe{\\l} Rz\\k{a}\\.zewski", "title": "Subexponential algorithms for variants of homomorphism problem in string\n  graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the complexity of finding weighted homomorphisms from\nintersection graphs of curves (string graphs) with $n$ vertices to a fixed\ngraph $H$. We provide a complete dichotomy for the problem: if $H$ has no two\nvertices sharing two common neighbors, then the problem can be solved in time\n$2^{O(n^{2/3} \\log n)}$, otherwise there is no algorithm working in time\n$2^{o(n)}$, even in intersection graphs of segments, unless the ETH fails. This\ngeneralizes several known results concerning the complexity of computatational\nproblems in geometric intersection graphs. Then we consider two variants of\ngraph homomorphism problem, called locally injective homomorphism and locally\nbijective homomorphism, where we require the homomorphism to be injective or\nbijective on the neighborhood of each vertex. We show that for each target\ngraph $H$, both problems can always be solved in time $2^{O(\\sqrt{n} \\log n)}$\nin string graphs. For the locally surjecive homomorphism, defined in an\nanalogous way, the situation seems more complicated. We show the dichotomy\ntheorem for simple connected graphs $H$ with maximum degree 2. If $H$ is\nisomorphic to $P_3$ or $C_4$, then the existence of a locally surjective\nhomomorphism from a string graph with $n$ vertices to $H$ can be decided in\ntime $2^{O(n^{2/3} \\log^{3/2} n)}$, otherwise the problem cannot be solved in\ntime $2^{o(n)}$, unless the ETH fails. As a byproduct, we obtain several\nresults concerning the complexity of variants of homomorphism problem in\n$P_t$-free graphs. In particular, we obtain the dichotomy theorem for weighted\nhomomorphism, analogous to the one for string graphs.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 07:00:55 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 17:02:45 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 12:34:21 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Okrasa", "Karolina", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""]]}, {"id": "1809.09493", "submitter": "Nate Veldt", "authors": "David F. Gleich and Nate Veldt and Anthony Wirth", "title": "Correlation Clustering Generalized", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new results for LambdaCC and MotifCC, two recently introduced\nvariants of the well-studied correlation clustering problem. Both variants are\nmotivated by applications to network analysis and community detection, and have\nnon-trivial approximation algorithms. We first show that the standard linear\nprogramming relaxation of LambdaCC has a $\\Theta(\\log n)$ integrality gap for a\ncertain choice of the parameter $\\lambda$. This sheds light on previous\nchallenges encountered in obtaining parameter-independent approximation results\nfor LambdaCC. We generalize a previous constant-factor algorithm to provide the\nbest results, from the LP-rounding approach, for an extended range of\n$\\lambda$. MotifCC generalizes correlation clustering to the hypergraph\nsetting. In the case of hyperedges of degree $3$ with weights satisfying\nprobability constraints, we improve the best approximation factor from $9$ to\n$8$. We show that in general our algorithm gives a $4(k-1)$ approximation when\nhyperedges have maximum degree $k$ and probability weights. We additionally\npresent approximation results for LambdaCC and MotifCC where we restrict to\nforming only two clusters.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 13:56:30 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Gleich", "David F.", ""], ["Veldt", "Nate", ""], ["Wirth", "Anthony", ""]]}, {"id": "1809.09776", "submitter": "Hengzhao Ma", "authors": "Hengzhao Ma, Jianzhong Li", "title": "An Algorithm for Reducing Approximate Nearest Neighbor to Approximate\n  Near Neighbor with O(logn) Query Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new algorithm for reducing Approximate Nearest Neighbor\nproblem to Approximate Near Neighbor problem. The advantage of this algorithm\nis that it achieves O(log n) query time. As a reduction problem, the uery time\ncomplexity is the times of invoking the algorithm for Approximate Near Neighbor\nproblem. All former algorithms for the same reduction need polylog(n) query\ntime. A box split method proposed by Vaidya is used in our paper to achieve the\nO(log n) query time complexity.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 01:42:05 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Ma", "Hengzhao", ""], ["Li", "Jianzhong", ""]]}, {"id": "1809.09819", "submitter": "Nitin Saurabh", "authors": "Srinivasan Arunachalam and Sourav Chakraborty and Michal Kouck\\'y and\n  Nitin Saurabh and Ronald de Wolf", "title": "Improved bounds on Fourier entropy and Min-entropy", "comments": "38 pages, arxiv abstract shortened to fit within the size limit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a Boolean function $f:\\{-1,1\\}^n\\to \\{-1,1\\}$, the Fourier distribution\nassigns probability $\\widehat{f}(S)^2$ to $S\\subseteq [n]$. The Fourier\nEntropy-Influence (FEI) conjecture of Friedgut and Kalai asks if there exist a\nuniversal constant C>0 such that $H(\\hat{f}^2)\\leq C Inf(f)$, where\n$H(\\hat{f}^2)$ is the Shannon entropy of the Fourier distribution of $f$ and\n$Inf(f)$ is the total influence of $f$.\n  1) We consider the weaker Fourier Min-entropy-Influence (FMEI) conjecture.\nThis asks if $H_{\\infty}(\\hat{f}^2)\\leq C Inf(f)$, where\n$H_{\\infty}(\\hat{f}^2)$ is the min-entropy of the Fourier distribution. We show\n$H_{\\infty}(\\hat{f}^2)\\leq 2C_{\\min}^\\oplus(f)$, where $C_{\\min}^\\oplus(f)$ is\nthe minimum parity certificate complexity of $f$. We also show that for every\n$\\epsilon\\geq 0$, we have $H_{\\infty}(\\hat{f}^2)\\leq 2\\log\n(\\|\\hat{f}\\|_{1,\\epsilon}/(1-\\epsilon))$, where $\\|\\hat{f}\\|_{1,\\epsilon}$ is\nthe approximate spectral norm of $f$. As a corollary, we verify the FMEI\nconjecture for the class of read-$k$ $DNF$s (for constant $k$).\n  2) We show that $H(\\hat{f}^2)\\leq 2 aUC^\\oplus(f)$, where $aUC^\\oplus(f)$ is\nthe average unambiguous parity certificate complexity of $f$. This improves\nupon Chakraborty et al. An important consequence of the FEI conjecture is the\nlong-standing Mansour's conjecture. We show that a weaker version of FEI\nalready implies Mansour's conjecture: is $H(\\hat{f}^2)\\leq C\n\\min\\{C^0(f),C^1(f)\\}$?, where $C^0(f), C^1(f)$ are the 0- and 1-certificate\ncomplexities of $f$, respectively.\n  3) We study what FEI implies about the structure of polynomials that\n1/3-approximate a Boolean function. We pose a conjecture (which is implied by\nFEI): no \"flat\" degree-$d$ polynomial of sparsity $2^{\\omega(d)}$ can\n1/3-approximate a Boolean function. We prove this conjecture unconditionally\nfor a particular class of polynomials.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 05:56:41 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Chakraborty", "Sourav", ""], ["Kouck\u00fd", "Michal", ""], ["Saurabh", "Nitin", ""], ["de Wolf", "Ronald", ""]]}, {"id": "1809.10219", "submitter": "Yaqiao Li", "authors": "Yaqiao Li", "title": "Trading information complexity for error II: the case of a large error\n  and external information complexity", "comments": "paper rewritten, new results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two problems are studied in this paper. (1) How much external or internal\ninformation cost is required to compute a Boolean-valued function with an error\nat most $1/2-\\epsilon$ for a small $\\epsilon$? It is shown that information\ncost of order $\\epsilon^2$ is necessary and of order $\\epsilon$ is sufficient.\n(2) How much external information cost can be saved to compute a function with\na small error $\\epsilon>0$ comparing to the case when no error is allowed? It\nis shown that information cost of order at least $\\epsilon$ and at most\n$h(\\sqrt{\\epsilon})$ can be saved. Except the $O(h(\\sqrt{\\epsilon}))$ upper\nbound, the other three bounds are tight. For distribution $\\mu$ that is equally\ndistributed on $(0,0)$ and $(1,1)$, it is shown that $IC^{ext}_\\mu(XOR,\n\\epsilon)=1-2\\epsilon$ where XOR is the two-bit xor function. This equality\nseems to be the first example of exact information complexity when an error is\nallowed.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 20:29:23 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 22:24:35 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Li", "Yaqiao", ""]]}, {"id": "1809.10325", "submitter": "Yan Jin", "authors": "Yan Jin, Elchanan Mossel, Govind Ramnarayan", "title": "Being Corrupt Requires Being Clever, But Detecting Corruption Doesn't", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variation of the problem of corruption detection on networks\nposed by Alon, Mossel, and Pemantle '15. In this model, each vertex of a graph\ncan be either truthful or corrupt. Each vertex reports about the types\n(truthful or corrupt) of all its neighbors to a central agency, where truthful\nnodes report the true types they see and corrupt nodes report adversarially.\nThe central agency aggregates these reports and attempts to find a single\ntruthful node. Inspired by real auditing networks, we pose our problem for\narbitrary graphs and consider corruption through a computational lens. We\nidentify a key combinatorial parameter of the graph $m(G)$, which is the\nminimal number of corrupted agents needed to prevent the central agency from\nidentifying a single truthful node. We give an efficient (in fact, linear time)\nalgorithm for the central agency to identify a truthful node that is successful\nwhenever the number of corrupt nodes is less than $m(G)/2$. On the other hand,\nwe prove that for any constant $\\alpha > 1$, it is NP-hard to find a subset of\nnodes $S$ in $G$ such that corrupting $S$ prevents the central agency from\nfinding one truthful node and $|S| \\leq \\alpha m(G)$, assuming the Small Set\nExpansion Hypothesis (Raghavendra and Steurer, STOC '10). We conclude that\nbeing corrupt requires being clever, while detecting corruption does not.\n  Our main technical insight is a relation between the minimum number of\ncorrupt nodes required to hide all truthful nodes and a certain notion of\nvertex separability for the underlying graph. Additionally, this insight lets\nus design an efficient algorithm for a corrupt party to decide which graphs\nrequire the fewest corrupted nodes, up to a multiplicative factor of $O(\\log\nn)$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 03:14:47 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 02:34:23 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Jin", "Yan", ""], ["Mossel", "Elchanan", ""], ["Ramnarayan", "Govind", ""]]}, {"id": "1809.10372", "submitter": "Sivakanth Gopi", "authors": "Zeev Dvir, Sivakanth Gopi, Yuzhou Gu, Avi Wigderson", "title": "Spanoids - an abstraction of spanning structures, and a barrier for LCCs", "comments": "Conference version to appear in ITCS 2019. arXiv:1810.02494 is merged\n  into the new version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.IT math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple logical inference structure we call a\n$\\textsf{spanoid}$ (generalizing the notion of a matroid), which captures\nwell-studied problems in several areas. These include combinatorial geometry,\nalgebra (arrangements of hypersurfaces and ideals), statistical physics\n(bootstrap percolation) and coding theory. We initiate a thorough investigation\nof spanoids, from computational and structural viewpoints, focusing on\nparameters relevant to the applications areas above and, in particular, to\nquestions regarding Locally Correctable Codes (LCCs).\n  One central parameter we study is the $\\textsf{rank}$ of a spanoid, extending\nthe rank of a matroid and related to the dimension of codes. This leads to one\nmain application of our work, establishing the first known barrier to improving\nthe nearly 20-year old bound of Katz-Trevisan (KT) on the dimension of LCCs. On\nthe one hand, we prove that the KT bound (and its more recent refinements)\nholds for the much more general setting of spanoid rank. On the other hand we\nshow that there exist (random) spanoids whose rank matches these bounds. Thus,\nto significantly improve the known bounds one must step out of the spanoid\nframework.\n  Another parameter we explore is the $\\textsf{functional rank}$ of a spanoid,\nwhich captures the possibility of turning a given spanoid into an actual code.\nThe question of the relationship between rank and functional rank is one of the\nmain questions we raise as it may reveal new avenues for constructing new LCCs\n(perhaps even matching the KT bound). As a first step, we develop an entropy\nrelaxation of functional rank to create a small constant gap and amplify it by\ntensoring to construct a spanoid whose functional rank is smaller than rank by\na polynomial factor. This is evidence that the entropy method we develop can\nprove polynomially better bounds than KT-type methods on the dimension of LCCs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 06:44:15 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 23:13:54 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Dvir", "Zeev", ""], ["Gopi", "Sivakanth", ""], ["Gu", "Yuzhou", ""], ["Wigderson", "Avi", ""]]}, {"id": "1809.10469", "submitter": "Xianghui Zhong", "authors": "Xianghui Zhong", "title": "Smoothed Analysis of Edge Elimination for Euclidean TSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to speed up the calculation of optimal TSP tours in practice is\neliminating edges that are certainly not in the optimal tour as a preprocessing\nstep. In order to do so several edge elimination approaches have been proposed\nin the past. In this work we investigate two of them in the scenario where the\ninput consists of $n$ independently distributed random points with bounded\ndensity function from above and below by arbitrary positive constants. We show\nthat after the edge elimination procedure of Hougardy and Schroeder the\nexpected number of remaining edges is $\\Theta(n)$, while after that of Jonker\nand Volgenant the expected number of remaining edges is $\\Theta(n^2)$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 11:56:36 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 13:19:20 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 10:20:43 GMT"}, {"version": "v4", "created": "Fri, 26 Apr 2019 16:10:28 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Zhong", "Xianghui", ""]]}, {"id": "1809.10578", "submitter": "Elisabet Burjons", "authors": "Hans-Joachim B\\\"ockenhauer, Elisabet Burjons, Martin Raszyk, and Peter\n  Rossmanith", "title": "Reoptimization of Parameterized Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized complexity allows us to analyze the time complexity of problems\nwith respect to a natural parameter depending on the problem. Reoptimization\nlooks for solutions or approximations for problem instances when given\nsolutions to neighboring instances. We try to combine both techniques, in order\nto better classify the complexity of problems in the parameterized setting.\nSpecifically, we see that some problems in the class of compositional problems,\nwhich do not have polynomial kernels under standard complexity-theoretic\nassumptions, do have polynomial kernels under reoptimization for some local\nmodifications. Moreover, we find that the reoptimization version of Vertex\nCover has a polynomial kernel of size 2k using crown decomposition. Finally, in\na negative result, we prove that the reoptimization version of Connected Vertex\nCover does not have a Turing kernelization unless Set Cover has a polynomial\nkernel\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 15:31:32 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 08:57:05 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["B\u00f6ckenhauer", "Hans-Joachim", ""], ["Burjons", "Elisabet", ""], ["Raszyk", "Martin", ""], ["Rossmanith", "Peter", ""]]}, {"id": "1809.10787", "submitter": "Digvijay Boob", "authors": "Digvijay Boob, Santanu S. Dey, Guanghui Lan", "title": "Complexity of Training ReLU Neural Network", "comments": "Hardness proof has been simplified. Accepted for publication at\n  Discrete Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore some basic questions on the complexity of training\nneural networks with ReLU activation function. We show that it is NP-hard to\ntrain a two-hidden layer feedforward ReLU neural network. If dimension of the\ninput data and the network topology is fixed, then we show that there exists a\npolynomial time algorithm for the same training problem. We also show that if\nsufficient over-parameterization is provided in the first hidden layer of ReLU\nneural network, then there is a polynomial time algorithm which finds weights\nsuch that output of the over-parameterized ReLU neural network matches with the\noutput of the given data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:32:50 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 21:12:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Boob", "Digvijay", ""], ["Dey", "Santanu S.", ""], ["Lan", "Guanghui", ""]]}, {"id": "1809.11086", "submitter": "Arash Ardakani", "authors": "Arash Ardakani, Zhengyun Ji, Sean C. Smithson, Brett H. Meyer, Warren\n  J. Gross", "title": "Learning Recurrent Binary/Ternary Weights", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have shown excellent performance in\nprocessing sequence data. However, they are both complex and memory intensive\ndue to their recursive nature. These limitations make RNNs difficult to embed\non mobile devices requiring real-time processes with limited hardware\nresources. To address the above issues, we introduce a method that can learn\nbinary and ternary weights during the training phase to facilitate hardware\nimplementations of RNNs. As a result, using this approach replaces all\nmultiply-accumulate operations by simple accumulations, bringing significant\nbenefits to custom hardware in terms of silicon area and power consumption. On\nthe software side, we evaluate the performance (in terms of accuracy) of our\nmethod using long short-term memories (LSTMs) on various sequential models\nincluding sequence classification and language modeling. We demonstrate that\nour method achieves competitive results on the aforementioned tasks while using\nbinary/ternary weights during the runtime. On the hardware side, we present\ncustom hardware for accelerating the recurrent computations of LSTMs with\nbinary/ternary weights. Ultimately, we show that LSTMs with binary/ternary\nweights can achieve up to 12x memory saving and 10x inference speedup compared\nto the full-precision implementation on an ASIC platform.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:27:29 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 19:14:18 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Ardakani", "Arash", ""], ["Ji", "Zhengyun", ""], ["Smithson", "Sean C.", ""], ["Meyer", "Brett H.", ""], ["Gross", "Warren J.", ""]]}]