[{"id": "1812.00901", "submitter": "Karthik C. S.", "authors": "Karthik C. S. and Pasin Manurangsi", "title": "On Closest Pair in Euclidean Metric: Monochromatic is as Hard as\n  Bichromatic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of $n$ points in $\\mathbb R^d$, the (monochromatic) Closest Pair\nproblem asks to find a pair of distinct points in the set that are closest in\nthe $\\ell_p$-metric. Closest Pair is a fundamental problem in Computational\nGeometry and understanding its fine-grained complexity in the Euclidean metric\nwhen $d=\\omega(\\log n)$ was raised as an open question in recent works\n(Abboud-Rubinstein-Williams [FOCS'17], Williams [SODA'18],\nDavid-Karthik-Laekhanukit [SoCG'18]).\n  In this paper, we show that for every $p\\in\\mathbb R_{\\ge 1}\\cup\\{0\\}$, under\nthe Strong Exponential Time Hypothesis (SETH), for every $\\varepsilon>0$, the\nfollowing holds:\n  $\\bullet$ No algorithm running in time $O(n^{2-\\varepsilon})$ can solve the\nClosest Pair problem in $d=(\\log n)^{\\Omega_{\\varepsilon}(1)}$ dimensions in\nthe $\\ell_p$-metric.\n  $\\bullet$ There exists $\\delta = \\delta(\\varepsilon)>0$ and $c =\nc(\\varepsilon)\\ge 1$ such that no algorithm running in time\n$O(n^{1.5-\\varepsilon})$ can approximate Closest Pair problem to a factor of\n$(1+\\delta)$ in $d\\ge c\\log n$ dimensions in the $\\ell_p$-metric.\n  At the heart of all our proofs is the construction of a dense bipartite graph\nwith low contact dimension, i.e., we construct a balanced bipartite graph on\n$n$ vertices with $n^{2-\\varepsilon}$ edges whose vertices can be realized as\npoints in a $(\\log n)^{\\Omega_\\varepsilon(1)}$-dimensional Euclidean space such\nthat every pair of vertices which have an edge in the graph are at distance\nexactly 1 and every other pair of vertices are at distance greater than 1. This\ngraph construction is inspired by the construction of locally dense codes\nintroduced by Dumer-Miccancio-Sudan [IEEE Trans. Inf. Theory'03].\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:01:06 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["S.", "Karthik C.", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "1812.01163", "submitter": "Aaron Potechin", "authors": "Aaron Potechin", "title": "Sum of squares bounds for the ordering principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the sum of squares hierarchy (SOS) on the ordering\nprinciple on $n$ elements. We prove that degree $O(\\sqrt{n}log(n))$ SOS can\nprove the ordering principle. We then show that this upper bound is essentially\ntight by proving that for any $\\epsilon > 0$, SOS requires degree\n$\\Omega(n^{\\frac{1}{2} - \\epsilon})$ to prove the ordering principle on $n$\nelements.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 02:03:32 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 18:04:37 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 02:10:29 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Potechin", "Aaron", ""]]}, {"id": "1812.01241", "submitter": "Xiaofu Ma", "authors": "Xiaofu Ma, Qinghai Gao, Vuk Marojevic, Jeffrey H. Reed", "title": "Hypergraph matching for MU-MIMO user grouping in wireless LANs", "comments": "Ad Hoc Networks, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the user grouping problem of downlink wireless local\narea networks (WLANs) with multi-user MIMO (MU-MIMO). Particularly, we focus on\nthe problem of whether single user transmit beamforming (SU-TxBF) or MU-MIMO\nshould be utilized, and how many users and which users should be in a\nmulti-user (MU) group. We formulate the problem for maximizing the system\nthroughput subject to the multi-user air time fairness (MU-ATF) criterion. We\nshow that hypergraphs provide a suitable mathematical model and effective tool\nfor finding the optimal or close to optimal solution. We show that the optimal\ngrouping problem can be solved efficiently for the case where only SU-TxBF and\n2-user MU groups are allowed in the system. For the general case, where any\nnumber of users can be assigned to groups of different sizes, we develop an\nefficient graph matching algorithm (GMA) based on graph theory principles. We\nevaluate the proposed algorithm in terms of system throughput using an 802.11ac\nemulator, which is created using collected channel measurements from an indoor\nenvironment and simulated channel samples for outdoor scenarios. We show that\nour GMA achieves at least 93% of the optimal system throughput in all\nconsidered test cases.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 06:27:22 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Ma", "Xiaofu", ""], ["Gao", "Qinghai", ""], ["Marojevic", "Vuk", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "1812.01482", "submitter": "Rogers Mathew", "authors": "Suman Banerjee, Rogers Mathew, and Fahad Panolan", "title": "Target Set Selection parameterized by vertex cover and more", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a simple, undirected graph $G$ with a threshold function $\\tau:V(G)\n\\rightarrow \\mathbb{N}$, the \\textsc{Target Set Selection} (TSS) problem is\nabout choosing a minimum cardinality set, say $S \\subseteq V(G)$, such that\nstarting a diffusion process with $S$ as its seed set will eventually result in\nactivating all the nodes in $G$. For any non-negative integer $i$, we say a set\n$T\\subseteq V(G)$ is a \"degree-$i$ modulator\" of $G$ if the degree of any\nvertex in the graph $G-T$ is at most $i$. Degree-$0$ modulators of a graph are\nprecisely its vertex covers. Consider a graph $G$ on $n$ vertices and $m$\nedges. We have the following results on the TSS problem:\n  -> It was shown by Nichterlein et al. [Social Network Analysis and Mining,\n2013] that it is possible to compute an optimal-sized target set in\n$O(2^{(2^{t}+1)t}\\cdot m)$ time, where $t$ denotes the cardinality of a minimum\ndegree-$0$ modulator of $G$. We improve this result by designing an algorithm\nrunning in time $2^{O(t\\log t)}n^{O(1)}$.\n  -> We design a $2^{2^{O(t)}}n^{O(1)}$ time algorithm to compute an optimal\ntarget set for $G$, where $t$ is the size of a minimum degree-$1$ modulator of\n$G$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 15:23:48 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 08:55:23 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 05:04:11 GMT"}, {"version": "v4", "created": "Wed, 10 Jun 2020 07:51:30 GMT"}, {"version": "v5", "created": "Sun, 16 May 2021 12:55:37 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Banerjee", "Suman", ""], ["Mathew", "Rogers", ""], ["Panolan", "Fahad", ""]]}, {"id": "1812.01789", "submitter": "Andrew Lucas", "authors": "Andrew Lucas", "title": "Hard combinatorial problems and minor embeddings on lattice graphs", "comments": "26+7 pages; 9+1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, hardware constraints are an important limitation on quantum adiabatic\noptimization algorithms. Firstly, computational problems must be formulated as\nquadratic unconstrained binary optimization (QUBO) in the presence of noisy\ncoupling constants. Secondly, the interaction graph of the QUBO must have an\neffective minor embedding into a two-dimensional nonplanar lattice graph. We\ndescribe new strategies for constructing QUBOs for NP-complete/hard\ncombinatorial problems that address both of these challenges. Our results\ninclude asymptotically improved embeddings for number partitioning, filling\nknapsacks, graph coloring, and finding Hamiltonian cycles. These embeddings can\nbe also be found with reduced computational effort. Our new embedding for\nnumber partitioning may be more effective on next-generation hardware.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 02:34:28 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Lucas", "Andrew", ""]]}, {"id": "1812.01982", "submitter": "Prahladh Harsha", "authors": "Siddharth Bhandari, Prahladh Harsha, Tulasimohan Molli, Srikanth\n  Srinivasan", "title": "On the Probabilistic Degree of OR over the Reals", "comments": null, "journal-ref": "In Proc. 38th IARCS Conf. on Foundations of Software Technology &\n  Theoretical Computer Science (FSTTCS) (Ahmedabad, India, 10-14 December),\n  volume 122 of LiPiCS, pages 5:1-5:12, 2018", "doi": "10.4230/LIPIcs.FSTTCS.2018.5", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the probabilistic degree over reals of the OR function on $n$\nvariables. For an error parameter $\\epsilon$ in (0,1/3), the $\\epsilon$-error\nprobabilistic degree of any Boolean function $f$ over reals is the smallest\nnon-negative integer $d$ such that the following holds: there exists a\ndistribution $D$ of polynomials entirely supported on polynomials of degree at\nmost $d$ such that for all $z \\in \\{0,1\\}^n$, we have $Pr_{P \\sim D} [P(z) =\nf(z) ] \\geq 1- \\epsilon$. It is known from the works of Tarui ({Theoret.\nComput. Sci.} 1993) and Beigel, Reingold, and Spielman ({ Proc. 6th CCC} 1991),\nthat the $\\epsilon$-error probabilistic degree of the OR function is at most\n$O(\\log n.\\log 1/\\epsilon)$. Our first observation is that this can be improved\nto $O{\\log {{n}\\choose{\\leq \\log 1/\\epsilon}}}$, which is better for small\nvalues of $\\epsilon$.\n  In all known constructions of probabilistic polynomials for the OR function\n(including the above improvement), the polynomials $P$ in the support of the\ndistribution $D$ have the following special structure:$P = 1 -\n(1-L_1).(1-L_2)...(1-L_t)$, where each $L_i(x_1,..., x_n)$ is a linear form in\nthe variables $x_1,...,x_n$, i.e., the polynomial $1-P(x_1,...,x_n)$ is a\nproduct of affine forms. We show that the $\\epsilon$-error probabilistic degree\nof OR when restricted to polynomials of the above form is $\\Omega ( \\log\na/\\log^2 a )$ where $a = \\log {{n}\\choose{\\leq \\log 1/\\epsilon}}$. Thus\nmatching the above upper bound (up to poly-logarithmic factors).\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 13:19:11 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 11:00:47 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Bhandari", "Siddharth", ""], ["Harsha", "Prahladh", ""], ["Molli", "Tulasimohan", ""], ["Srinivasan", "Srikanth", ""]]}, {"id": "1812.02037", "submitter": "C.S. Rahul", "authors": "R. Ganian, N. S. Narayanaswamy, S. Ordyniak, C. S. Rahul, M. S.\n  Ramanujan", "title": "On the Complexity Landscape of Connected f -Factor Problems", "comments": "Under review in Algorithmica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Let G be an undirected simple graph having n vertices and let f be a function\ndefined to be f:V(G) -> {0,..., n-1}. An f-factor of G is a spanning subgraph H\nsuch that degree of a vertex v in H is f(v) for every vertex v in V(G). The\nsubgraph H is called a connected f-factor if, in addition, H is connected. A\nclassical result of Tutte(1954) is the polynomial time algorithm to check\nwhether a given graph has a specified f-factor. However, checking for the\npresence of a connected f-factor is easily seen to generalize HAMILTONIAN CYCLE\nand hence is NP-complete. In fact, the CONNECTED f-FACTOR problem remains\nNP-complete even when we restrict f(v) to be at least n^e for each vertex v and\n0<e<1; on the other side of the spectrum of nontrivial lower bounds on f, the\nproblem is known to be polynomial time solvable when f(v) is at least n/3 for\nevery vertex v. In this paper, we extend this line of work and obtain new\ncomplexity results based on restrictions on the function f. In particular, we\nshow that when f(v) is restricted to be at least n/(log n)^c , the problem can\nbe solved in quasi-polynomial time in general and in randomized polynomial time\nif c<=1. Furthermore, we show that when c>1, the problem is NP-intermediate.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 15:20:37 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Ganian", "R.", ""], ["Narayanaswamy", "N. S.", ""], ["Ordyniak", "S.", ""], ["Rahul", "C. S.", ""], ["Ramanujan", "M. S.", ""]]}, {"id": "1812.02215", "submitter": "John Hooker", "authors": "Danial Davarnia, J. N. Hooker", "title": "Consistency for 0-1 Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concepts of consistency have long played a key role in constraint programming\nbut never developed in integer programming (IP). Consistency nonetheless plays\na role in IP as well. For example, cutting planes can reduce backtracking by\nachieving various forms of consistency as well as by tightening the linear\nprogramming (LP) relaxation. We introduce a type of consistency that is\nparticularly suited for 0-1 programming and develop the associated theory. We\ndefine a 0-1 constraint set as LP-consistent when any partial assignment that\nis consistent with its linear programming relaxation is consistent with the\noriginal 0-1 constraint set. We prove basic properties of LP-consistency,\nincluding its relationship with Chvatal-Gomory cuts and the integer hull. We\nshow that a weak form of LP-consistency can reduce or eliminate backtracking in\na way analogous to k-consistency but is easier to achieve. In so doing, we\nidentify a class of valid inequalities that can be more effective than\ntraditional cutting planes at cutting off infeasible 0-1 partial assignments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 20:41:02 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Davarnia", "Danial", ""], ["Hooker", "J. N.", ""]]}, {"id": "1812.02507", "submitter": "Lutz Oettershagen", "authors": "Petra Mutzel and Lutz Oettershagen", "title": "On the Enumeration and Counting of Bicriteria Temporal Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the complexity of path enumeration and counting in weighted\ntemporal graphs. In a weighted temporal graph, each edge has an availability\ntime, a traversal time and some real cost. We introduce two bicriteria temporal\nmin-cost path problems in which we are interested in the set of all efficient\npaths with low cost and short duration or early arrival time, respectively.\nHowever, the number of efficient paths can be exponential in the size of the\ninput. For the case of strictly positive edge costs we are able to provide\nalgorithms that enumerate the set of efficient paths with polynomial time delay\nand polynomial space. If we are only interested in the set of Pareto-optimal\nsolutions and not in the paths themselves, then these can be determined in\npolynomial time if all edge costs are nonnegative. In addition, for each\nPareto-optimal solution, we are able to find an efficient path in polynomial\ntime. On the negative side, we prove that counting the number of efficient\npaths is #P-complete, even in the non-weighted single criterion case.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 13:06:55 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 08:27:53 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Mutzel", "Petra", ""], ["Oettershagen", "Lutz", ""]]}, {"id": "1812.02715", "submitter": "Dingkang Wang", "authors": "Dingkang Wang, Yusu Wang", "title": "An Improved Cost Function for Hierarchical Cluster Trees", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering has been a popular method in various data analysis\napplications. It partitions a data set into a hierarchical collection of\nclusters, and can provide a global view of (cluster) structure behind data\nacross different granularity levels. A hierarchical clustering (HC) of a data\nset can be naturally represented by a tree, called a HC-tree, where leaves\ncorrespond to input data and subtrees rooted at internal nodes correspond to\nclusters. Many hierarchical clustering algorithms used in practice are\ndeveloped in a procedure manner. Dasgupta proposed to study the hierarchical\nclustering problem from an optimization point of view, and introduced an\nintuitive cost function for similarity-based hierarchical clustering with nice\nproperties as well as natural approximation algorithms.\n  We observe that while Dasgupta's cost function is effective at\ndifferentiating a good HC-tree from a bad one for a fixed graph, the value of\nthis cost function does not reflect how well an input similarity graph is\nconsistent to a hierarchical structure. In this paper, we present a new cost\nfunction, which is developed based on Dasgupta's cost function, to address this\nissue. The optimal tree under the new cost function remains the same as the one\nunder Dasgupta's cost function. However, the value of our cost function is more\nmeaningful. The new way of formulating the cost function also leads to a\npolynomial time algorithm to compute the optimal cluster tree when the input\ngraph has a perfect HC-structure, or an approximation algorithm when the input\ngraph 'almost' has a perfect HC-structure. Finally, we provide further\nunderstanding of the new cost function by studying its behavior for random\ngraphs sampled from an edge probability matrix.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:50:35 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 20:08:47 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Wang", "Dingkang", ""], ["Wang", "Yusu", ""]]}, {"id": "1812.03155", "submitter": "Holger Dell", "authors": "Holger Dell and D\\'aniel Marx", "title": "Kernelization of Packing Problems", "comments": "An extended abstract was presented at SODA 2012, but this full\n  version contains some new material: Sec. 5 and 6.2 are new, and the gadget in\n  Fig. 1 is simpler & better", "journal-ref": null, "doi": "10.1137/1.9781611973099.6", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kernelization algorithms are polynomial-time reductions from a problem to\nitself that guarantee their output to have a size not exceeding some bound. For\nexample, d-Set Matching for integers d>2 is the problem of finding a matching\nof size at least k in a given d-uniform hypergraph and has kernels with O(k^d)\nedges. Bodlaender et al. [JCSS 2009], Fortnow and Santhanam [JCSS 2011], Dell\nand Van Melkebeek [JACM 2014] developed a framework for proving lower bounds on\nthe kernel size for certain problems, under the complexity-theoretic hypothesis\nthat coNP is not contained in NP/poly. Under the same hypothesis, we show tight\nlower bounds for the kernelization of d-Set Matching and other packing\nproblems.\n  Our bounds are tight for d-Set Matching: It does not have kernels with\nO(k^{d-{\\epsilon}}) edges for any {\\epsilon}>0 unless the hypothesis fails. By\nreduction, this transfers to a bound of O(k^{d-1-{\\epsilon}}) for the problem\nof finding k vertex-disjoint cliques of size d in standard graphs. Obtaining\ntight bounds for graph packing problems is challenging: We make first progress\nin this direction by showing non-trivial kernels with O(k^2.5) edges for the\nproblem of finding k vertex-disjoint paths of three edges each. If the paths\nhave d edges each, we improve the straightforward O(k^{d+1}) kernel to a\nuniform polynomial kernel where the exponent of the kernel size is independent\nof k.\n  Most of our lower bound proofs follow a general scheme that we discover: To\nexclude kernels of size O(k^{d-{\\epsilon}}) for a problem in d-uniform\nhypergraphs, one should reduce from a carefully chosen d-partite problem that\nis still NP-hard. As an illustration, we apply this scheme to the vertex cover\nproblem, which allows us to replace the number-theoretical construction by Dell\nand Van Melkebeek [JACM 2014] with shorter elementary arguments.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 18:41:10 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Dell", "Holger", ""], ["Marx", "D\u00e1niel", ""]]}, {"id": "1812.03410", "submitter": "Robert D\\\"urichen Dr.", "authors": "Robert D\\\"urichen, Thomas Rocznik, Oliver Renz, Christian Peters", "title": "Binary Input Layer: Training of CNN models with binary input data", "comments": "NeurIPS, 2nd Workshop on Machine Learning on the Phone and other\n  Consumer Devices (MLPCD 2), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For the efficient execution of deep convolutional neural networks (CNN) on\nedge devices, various approaches have been presented which reduce the bit width\nof the network parameters down to 1 bit. Binarization of the first layer was\nalways excluded, as it leads to a significant error increase. Here, we present\nthe novel concept of binary input layer (BIL), which allows the usage of binary\ninput data by learning bit specific binary weights. The concept is evaluated on\nthree datasets (PAMAP2, SVHN, CIFAR-10). Our results show that this approach is\nin particular beneficial for multimodal datasets (PAMAP2) where it outperforms\nnetworks using full precision weights in the first layer by 1:92 percentage\npoints (pp) while consuming only 2 % of the chip area.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 00:17:32 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["D\u00fcrichen", "Robert", ""], ["Rocznik", "Thomas", ""], ["Renz", "Oliver", ""], ["Peters", "Christian", ""]]}, {"id": "1812.03592", "submitter": "Dylan Hendrickson", "authors": "Erik D. Demaine, Dylan H. Hendrickson, Jayson Lynch", "title": "Toward a General Theory of Motion Planning Complexity: Characterizing\n  Which Gadgets Make Games Hard", "comments": "Added applications, fixed typos, changed style and colors", "journal-ref": "11th Innovations in Theoretical Computer Science Conference (ITCS\n  2020)", "doi": "10.4230/LIPIcs.ITCS.2020.62", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a general theory for characterizing the computational complexity of\nmotion planning of robot(s) through a graph of \"gadgets\", where each gadget has\nits own state defining a set of allowed traversals which in turn modify the\ngadget's state. We study two families of such gadgets, one which naturally\nleads to motion planning problems with polynomially bounded solutions, and\nanother which leads to polynomially unbounded (potentially exponential)\nsolutions. We also study a range of competitive game-theoretic scenarios, from\none player controlling one robot to teams of players each controlling their own\nrobot and racing to achieve their team's goal. Under small restrictions on\nthese gadgets, we fully characterize the complexity of bounded 1-player motion\nplanning (NL vs. NP-complete), unbounded 1-player motion planning (NL vs.\nPSPACE-complete), and bounded 2-player motion planning (P vs. PSPACE-complete),\nand we partially characterize the complexity of unbounded 2-player motion\nplanning (P vs. EXPTIME-complete), bounded 2-team motion planning (P vs.\nNEXPTIME-complete), and unbounded 2-team motion planning (P vs. undecidable).\nThese results can be seen as an alternative to Constraint Logic (which has\nalready proved useful as a basis for hardness reductions), providing a wide\nvariety of agent-based gadgets, any one of which suffices to prove a problem\nhard.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 01:40:11 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 06:42:23 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Demaine", "Erik D.", ""], ["Hendrickson", "Dylan H.", ""], ["Lynch", "Jayson", ""]]}, {"id": "1812.03703", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae, Harumichi Nishimura, Yuki Takeuchi, Seiichiro Tani", "title": "Impossibility of blind quantum sampling for classical client", "comments": "19 pages, 2 figures", "journal-ref": "Quantum Information and Computation 19, 0793-0806 (2019)", "doi": null, "report-no": "YITP-18-119", "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind quantum computing enables a client, who can only generate or measure\nsingle-qubit states, to delegate quantum computing to a remote quantum server\nin such a way that the input, output, and program are hidden from the server.\nIt is an open problem whether a completely classical client can delegate\nquantum computing blindly. In this paper, we show that if a completely\nclassical client can blindly delegate sampling of subuniversal models, such as\nthe DQC1 model and the IQP model, then the polynomial-time hierarchy collapses\nto the third level. Our delegation protocol is the one where the client first\nsends a polynomial-length bit string to the server and then the server returns\na single bit to the client. Generalizing the no-go result to more general\nsetups is an open problem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 09:57:59 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Morimae", "Tomoyuki", ""], ["Nishimura", "Harumichi", ""], ["Takeuchi", "Yuki", ""], ["Tani", "Seiichiro", ""]]}, {"id": "1812.04219", "submitter": "Daniel Grier", "authors": "Scott Aaronson, Daniel Grier, Luke Schaeffer", "title": "A Quantum Query Complexity Trichotomy for Regular Languages", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a trichotomy theorem for the quantum query complexity of regular\nlanguages. Every regular language has quantum query complexity Theta(1),\n~Theta(sqrt n), or Theta(n). The extreme uniformity of regular languages\nprevents them from taking any other asymptotic complexity. This is in contrast\nto even the context-free languages, which we show can have query complexity\nTheta(n^c) for all computable c in [1/2,1]. Our result implies an equivalent\ntrichotomy for the approximate degree of regular languages, and a\ndichotomy---either Theta(1) or Theta(n)---for sensitivity, block sensitivity,\ncertificate complexity, deterministic query complexity, and randomized query\ncomplexity.\n  The heart of the classification theorem is an explicit quantum algorithm\nwhich decides membership in any star-free language in ~O(sqrt n) time. This\nwell-studied family of the regular languages admits many interesting\ncharacterizations, for instance, as those languages expressible as sentences in\nfirst-order logic over the natural numbers with the less-than relation.\nTherefore, not only do the star-free languages capture functions such as OR,\nthey can also express functions such as \"there exist a pair of 2's such that\neverything between them is a 0.\"\n  Thus, we view the algorithm for star-free languages as a nontrivial\ngeneralization of Grover's algorithm which extends the quantum quadratic\nspeedup to a much wider range of string-processing algorithms than was\npreviously known. We show a variety of applications---new quantum algorithms\nfor dynamic constant-depth Boolean formulas, balanced parentheses nested\nconstantly many levels deep, binary addition, a restricted word break problem,\nand path-discovery in narrow grids---all obtained as immediate consequences of\nour classification theorem.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 05:00:52 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 23:52:19 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 21:09:43 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Aaronson", "Scott", ""], ["Grier", "Daniel", ""], ["Schaeffer", "Luke", ""]]}, {"id": "1812.04401", "submitter": "Ben Chugg", "authors": "Ben Chugg, Anne Condon, Hooman Hashemi", "title": "Output-Oblivious Stochastic Chemical Reaction Networks", "comments": "Extended abstract published in OPODIS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify the functions $f:\\mathbb{N}^2 \\rightarrow \\mathbb{N}$ which are\nstably computable by output-oblivious Stochastic Chemical Reaction Networks\n(CRNs), i.e., systems of reactions in which output species are never reactants.\nWhile it is known that precisely the semilinear functions are stably computable\nby CRNs, such CRNs sometimes rely on initially producing too many output\nspecies and then consuming the excess in order to reach a correct stable state.\nThese CRNs may be difficult to integrate into larger systems: if the output of\na CRN $\\mathcal{C}$ becomes the input to a downstream CRN $\\mathcal{C}'$, then\n$\\mathcal{C}'$ could inadvertently consume too many outputs before\n$\\mathcal{C}$ stabilizes. If, on the other hand, $\\mathcal{C}$ is\noutput-oblivious then $\\mathcal{C}'$ may consume $\\mathcal{C}$'s output as soon\nas it is available. In this work we prove that a semilinear function\n$f:\\mathbb{N}^2 \\rightarrow \\mathbb{N}$ is stably computable by an\noutput-oblivious CRN with a leader if and only if it is both increasing and\neither grid-affine (intuitively, its domains are congruence classes), or the\nminimum of a finite set of fissure functions (intuitively, functions behaving\nlike the min function).\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 16:43:32 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Chugg", "Ben", ""], ["Condon", "Anne", ""], ["Hashemi", "Hooman", ""]]}, {"id": "1812.05306", "submitter": "Wenjian Yu Prof.", "authors": "Dingcheng Yang, Wenjian Yu, Junhui Deng, Shenghua Liu", "title": "Optimal Algorithm for Profiling Dynamic Arrays with Finite Values", "comments": "6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  How can one quickly answer the most and top popular objects at any time,\ngiven a large log stream in a system of billions of users? It is equivalent to\nfind the mode and top-frequent elements in a dynamic array corresponding to the\nlog stream. However, most existing work either restrain the dynamic array\nwithin a sliding window, or do not take advantages of only one element can be\nadded or removed in a log stream. Therefore, we propose a profiling algorithm,\nnamed S-Profile, which is of $O(1)$ time complexity for every updating of the\ndynamic array, and optimal in terms of computational complexity. With the\nprofiling results, answering the queries on the statistics of dynamic array\nbecomes trivial and fast. With the experiments of various settings of dynamic\narrays, our accurate S-Profile algorithm outperforms the well-known methods,\nshowing at least 2X speedup to the heap based approach and 13X or larger\nspeedup to the balanced tree based approach.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 08:04:09 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Yang", "Dingcheng", ""], ["Yu", "Wenjian", ""], ["Deng", "Junhui", ""], ["Liu", "Shenghua", ""]]}, {"id": "1812.05316", "submitter": "Martin Milani\\v{c}", "authors": "T{\\i}naz Ekim and Didem G\\\"oz\\\"upek and Ademir Hujdurovi\\'c and Martin\n  Milani\\v{c}", "title": "Mind the Independence Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The independence gap of a graph was introduced by Ekim et al. (2018) as a\nmeasure of how far a graph is from being well-covered. It is defined as the\ndifference between the maximum and minimum size of a maximal independent set.\n  We investigate the independence gap of a graph from structural and\nalgorithmic points of view, with a focus on classes of perfect graphs.\nGeneralizing results on well-covered graphs due to Dean and Zito (1994) and\nHujdurovi\\'c et al. (2018), we express the independence gap of a perfect graph\nin terms of clique partitions and use this characterization to develop a\npolynomial-time algorithm for recognizing graphs of constant independence gap\nin any class of perfect graphs of bounded clique number. Next, we introduce a\nhereditary variant of the parameter, which we call hereditary independence gap\nand which measures the maximum independence gap over all induced subgraphs of\nthe graph. We show that determining whether a given graph has hereditary\nindependence gap at most $k$ is polynomial-time solvable if $k$ is fixed and\nco-NP-complete if $k$ is part of input. We also investigate the complexity of\nthe independent set problem in graph classes related to independence gap,\nshowing that the problem is NP-complete in the class of graphs of independence\ngap at most one and polynomial-time solvable in any class of graphs with\nbounded hereditary independence gap. Combined with some known results on\nclaw-free graphs, our results imply that the independent domination problem is\nsolvable in polynomial time in the class of $\\{$claw, 2$P_3\\}$-free graphs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 08:55:01 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Ekim", "T\u0131naz", ""], ["G\u00f6z\u00fcpek", "Didem", ""], ["Hujdurovi\u0107", "Ademir", ""], ["Milani\u010d", "Martin", ""]]}, {"id": "1812.06369", "submitter": "Emmanuel Abbe A", "authors": "Emmanuel Abbe and Colin Sandon", "title": "Provable limitations of deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the success of deep learning reaches more grounds, one would like to also\nenvision the potential limits of deep learning. This paper gives a first set of\nresults proving that certain deep learning algorithms fail at learning certain\nefficiently learnable functions. The results put forward a notion of\ncross-predictability that characterizes when such failures take place. Parity\nfunctions provide an extreme example with a cross-predictability that decays\nexponentially, while a mere super-polynomial decay of the cross-predictability\nis shown to be sufficient to obtain failures. Examples in community detection\nand arithmetic learning are also discussed.\n  Recall that it is known that the class of neural networks (NNs) with\npolynomial network size can express any function that can be implemented in\npolynomial time, and that their sample complexity scales polynomially with the\nnetwork size. The challenge is with the optimization error (the ERM is\nNP-hard), and the success behind deep learning is to train deep NNs with\ndescent algorithms. The failures shown in this paper apply to training\npoly-size NNs on function distributions of low cross-predictability with a\ndescent algorithm that is either run with limited memory per sample or that is\ninitialized and run with enough randomness. We further claim that such types of\nconstraints are necessary to obtain failures, in that exact SGD with careful\nnon-random initialization can be shown to learn parities. The\ncross-predictability in our results plays a similar role the statistical\ndimension in statistical query (SQ) algorithms, with distinctions explained in\nthe paper. The proof techniques are based on exhibiting algorithmic constraints\nthat imply a statistical indistinguishability between the algorithm's output on\nthe test model v.s.\\ a null model, using information measures to bound the\ntotal variation distance.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 00:10:08 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 08:29:32 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Abbe", "Emmanuel", ""], ["Sandon", "Colin", ""]]}, {"id": "1812.06828", "submitter": "Peter B\\\"urgisser", "authors": "Peter B\\\"urgisser", "title": "The Complexity of Factors of Multivariate Polynomials", "comments": "This is an updated version of a paper published in J. FoCM in 2004.\n  Here we have corrected an error in the statement and proof of Theorem 5.7", "journal-ref": "Foundations of Computational Mathematics 4(4): 369-396, 2004", "doi": "10.1007/s10208-002-0059-5", "report-no": null, "categories": "cs.CC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of string functions, which are not polynomial time computable,\nbut whose graph is checkable in polynomial time, is a basic assumption in\ncryptography. We prove that in the framework of algebraic complexity, there are\nno such families of polynomial functions of polynomially bounded degree over\nfields of characteristic zero. The proof relies on a polynomial upper bound on\nthe approximative complexity of a factor g of a polynomial f in terms of the\n(approximative) complexity of f and the degree of the factor g. This extends a\nresult by Kaltofen (STOC 1986). The concept of approximative complexity allows\nto cope with the case that a factor has an exponential multiplicity, by using a\nperturbation argument. Our result extends to randomized (two-sided error)\ndecision complexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 15:16:33 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["B\u00fcrgisser", "Peter", ""]]}, {"id": "1812.06952", "submitter": "Jeroen Zuiddam", "authors": "Matthias Christandl, P\\'eter Vrana, Jeroen Zuiddam", "title": "Barriers for fast matrix multiplication from irreversibility", "comments": "Updated journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC math.AC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the asymptotic algebraic complexity of matrix multiplication,\nsuccinctly represented by the matrix multiplication exponent $\\omega$, is a\ncentral problem in algebraic complexity theory. The best upper bounds on\n$\\omega$, leading to the state-of-the-art $\\omega \\leq 2.37..$, have been\nobtained via the laser method of Strassen and its generalization by Coppersmith\nand Winograd. Recent barrier results show limitations for these and related\napproaches to improve the upper bound on $\\omega$.\n  We introduce a new and more general barrier, providing stronger limitations\nthan in previous work. Concretely, we introduce the notion of \"irreversibility\"\nof a tensor and we prove (in some precise sense) that any approach that uses an\nirreversible tensor in an intermediate step (e.g., as a starting tensor in the\nlaser method) cannot give $\\omega = 2$. In quantitative terms, we prove that\nthe best upper bound achievable is lower bounded by two times the\nirreversibility of the intermediate tensor. The quantum functionals and\nStrassen support functionals give (so far, the best) lower bounds on\nirreversibility. We provide lower bounds on the irreversibility of key\nintermediate tensors, including the small and big Coppersmith--Winograd\ntensors, that improve limitations shown in previous work. Finally, we discuss\nbarriers on the group-theoretic approach in terms of \"monomial\"\nirreversibility.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 18:49:18 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 16:14:26 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 15:36:07 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Christandl", "Matthias", ""], ["Vrana", "P\u00e9ter", ""], ["Zuiddam", "Jeroen", ""]]}, {"id": "1812.07793", "submitter": "Matthew Stephenson", "authors": "Matthew Stephenson, Jochen Renz, Xiaoyu Ge", "title": "The Computational Complexity of Angry Birds", "comments": "55 Pages, 39 Figures", "journal-ref": "Artificial Intelligence (AIJ), Volume 280, March 2020, 103232", "doi": "10.1016/j.artint.2019.103232", "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The physics-based simulation game Angry Birds has been heavily researched by\nthe AI community over the past five years, and has been the subject of a\npopular AI competition that is currently held annually as part of a leading AI\nconference. Developing intelligent agents that can play this game effectively\nhas been an incredibly complex and challenging problem for traditional AI\ntechniques to solve, even though the game is simple enough that any human\nplayer could learn and master it within a short time. In this paper we analyse\nhow hard the problem really is, presenting several proofs for the computational\ncomplexity of Angry Birds. By using a combination of several gadgets within\nthis game's environment, we are able to demonstrate that the decision problem\nof solving general levels for different versions of Angry Birds is either\nNP-hard, PSPACE-hard, PSPACE-complete or EXPTIME-hard. Proof of NP-hardness is\nby reduction from 3-SAT, whilst proof of PSPACE-hardness is by reduction from\nTrue Quantified Boolean Formula (TQBF). Proof of EXPTIME-hardness is by\nreduction from G2, a known EXPTIME-complete problem similar to that used for\nmany previous games such as Chess, Go and Checkers. To the best of our\nknowledge, this is the first time that a single-player game has been proven\nEXPTIME-hard. This is achieved by using stochastic game engine dynamics to\neffectively model the real world, or in our case the physics simulator, as the\nopponent against which we are playing. These proofs can also be extended to\nother physics-based games with similar mechanics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 07:39:26 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 21:08:47 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 20:21:31 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Stephenson", "Matthew", ""], ["Renz", "Jochen", ""], ["Ge", "Xiaoyu", ""]]}, {"id": "1812.07844", "submitter": "Eraldo Marinho", "authors": "Eraldo Pereira Marinho", "title": "Beyond z=0. The Deutsch-Jozsa decided monochromatic languages", "comments": "25 pages, 13 figures, minor changes on the previous version before\n  submitting to International Journal of Quantum Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work points out that the Deutsch-Jozsa algorithm was the first\nformal description of a quantum decider. In particular, it is studied here the\nclass of languages whose indicator functions allow the Deutsch-Jozsa algorithm\nto output a monochromatic result, beyond the trivial case z = 0 for constant\nindicator functions. To illustrate examples of randomly balanced languages and\nsome monochromatic cases, it was performed classical computational simulations\nof the Deutsch-Jozsa quantum algorithm for the specific cases of 4 and 6\nqubits, respectively. The general case of the Deutsch-Jozsa decided languages\nare named balanced languages, and their outcomes from the simulation suggest\nthat such languages are equivalent to the quantum superposition of the\nmonochromatic cases.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 09:48:22 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 11:35:48 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 17:46:22 GMT"}, {"version": "v4", "created": "Thu, 19 Sep 2019 17:03:22 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Marinho", "Eraldo Pereira", ""]]}, {"id": "1812.08731", "submitter": "Josh Alman", "authors": "Josh Alman", "title": "Limits on the Universal Method for Matrix Multiplication", "comments": "25 pages, to appear in 34th Computational Complexity Conference (CCC\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we prove limitations on the known methods for designing matrix\nmultiplication algorithms. Alman and Vassilevska Williams recently defined the\nUniversal Method, which substantially generalizes all the known approaches\nincluding Strassen's Laser Method and Cohn and Umans' Group Theoretic Method.\nWe prove concrete lower bounds on the algorithms one can design by applying the\nUniversal Method to many different tensors. Our proofs use new tools for upper\nbounding the asymptotic slice rank of a wide range of tensors. Our main result\nis that the Universal method applied to any Coppersmith-Winograd tensor $CW_q$\ncannot yield a bound on $\\omega$, the exponent of matrix multiplication, better\nthan $2.16805$. By comparison, it was previously only known that the weaker\n`Galactic Method' applied to $CW_q$ could not achieve an exponent of $2$.\n  We also study the Laser Method (which is, in principle, a highly special case\nof the Universal Method) and prove that it is \"complete\" for matrix\nmultiplication algorithms: when it applies to a tensor $T$, it achieves $\\omega\n= 2$ if and only if it is possible for the Universal method applied to $T$ to\nachieve $\\omega = 2$. Hence, the Laser Method, which was originally used as an\nalgorithmic tool, can also be seen as a lower bounding tool. For example, in\ntheir landmark paper, Coppersmith and Winograd achieved a bound of $\\omega \\leq\n2.376$, by applying the Laser Method to $CW_q$. By our result, the fact that\nthey did not achieve $\\omega=2$ implies a lower bound on the Universal Method\napplied to $CW_q$. Indeed, if it were possible for the Universal Method applied\nto $CW_q$ to achieve $\\omega=2$, then Coppersmith and Winograd's application of\nthe Laser Method would have achieved $\\omega=2$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 18:04:08 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 13:56:29 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Alman", "Josh", ""]]}, {"id": "1812.09110", "submitter": "Bernd Schuh", "authors": "Bernd R. Schuh", "title": "Sub-exponential complexity of regular linear CNF formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of regular linear conjunctive normal form (LCNF) formulas is of\ninterest because exact satisfiability (XSAT) is known to be NP-complete for\nthis class of formulas. In a recent paper it was shown that the subclass of\nregular exact LCNF formulas (XLCNF) is of sub-exponential complexity, i.e. XSAT\ncan be determined in sub-exponential time. Here I show that this class is just\na subset of a larger class of LCNF formulas which display this very kind of\ncomplexity. To this end I introduce the property of disjointedness of LCNF\nformulas, measured, for a single clause C, by the number of clauses which have\nno variable in common with C. If for a given LCNF formula F all clauses have\nthe same disjointedness d we call F d-disjointed and denote the class of such\nformulas by dLCNF. XLCNF formulas correspond to the special cased=0. One main\nresult of the paper is that the class of all monotone l-regular LCNF formulas\nwhich are d-disjointed, with d smaller than some upper bound D, is of\nsub-exponential complexity. This result can be generalized to show that all\nmonotone, l-regular LCNF formulas F which have a bounded mean disjointedness,\nare of sub-exponential XSAT-complexity, as well.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 13:34:37 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Schuh", "Bernd R.", ""]]}, {"id": "1812.09206", "submitter": "Seonghyuk Im", "authors": "Seonghyuk Im", "title": "Complexity of Partitioning Hypergraphs", "comments": "9pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given $\\pi=(\\pi_0, \\pi_1,..., \\pi_k) \\in \\{0, 1, *\\}^{k+1}$, we want to\ndetermine whether an input $k$-uniform hypergraph $G=(V, E)$ has a partition\n$(V_1, V_2)$ of the vertex set so that for all $X \\subseteq V$ of size $k$, $X\n\\in E$ if $\\pi_{|X\\cap V_1|}=1$ and $X \\notin E$ if $\\pi_{|X\\cap V_1|}=0$. We\nprove that this problem is either polynomial-time solvable or NP-complete\ndepending on $\\pi$ when $k=3$ or $4$. We also extend this result into\n$k$-uniform hypergraphs for $k \\geq 5$.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 15:50:10 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Im", "Seonghyuk", ""]]}, {"id": "1812.09290", "submitter": "Florian Speelman", "authors": "Jop Bri\\\"et, Harry Buhrman, Debbie Leung, Teresa Piovesan, Florian\n  Speelman", "title": "Round elimination in exact communication complexity", "comments": "The arXiv submission is similar to the published version, with the\n  addition of Sections 2, 3.3, 4.4, and Appendices A, D, and E", "journal-ref": "LIPIcs-Leibniz International Proceedings in Informatics, Volume\n  44, Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2015", "doi": "10.4230/LIPIcs.TQC.2015.206", "report-no": null, "categories": "quant-ph cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study two basic graph parameters, the chromatic number and the orthogonal\nrank, in the context of classical and quantum exact communication complexity.\nIn particular, we consider two types of communication problems that we call\npromise equality and list problems. For both of these, it was already known\nthat the one-round classical and one-round quantum complexities are\ncharacterized by the chromatic number and orthogonal rank of a certain graph,\nrespectively.\n  In a promise equality problem, Alice and Bob must decide if their inputs are\nequal or not. We prove that classical protocols for such problems can always be\nreduced to one-round protocols with no extra communication. In contrast, we\ngive an explicit instance of a promise equality problem that exhibits an\nexponential gap between the one- and two-round exact quantum communication\ncomplexities. Whereas the chromatic number thus fully captures the complexity\nof promise equality problems, the hierarchy of \"quantum chromatic numbers\"\n(starting with the orthogonal rank) giving the quantum communication complexity\nfor every fixed number of communication rounds turns out to enjoy a much richer\nstructure.\n  In a list problem, Bob gets a subset of some finite universe, Alice gets an\nelement from Bob's subset, and their goal is for Bob to learn which element\nAlice was given. The best general lower bound (due to Orlitsky) and upper bound\n(due to Naor, Orlitsky, and Shor) on the classical communication complexity of\nsuch problems differ only by a constant factor. We exhibit an example showing\nthat, somewhat surprisingly, the four-round protocol used in the bound of Naor\net al. can in fact be optimal. Finally, we pose a conjecture on the\northogonality rank of a certain graph whose truth would imply an intriguing\nimpossibility of round elimination in quantum protocols for list problems,\nsomething that works trivially in the classical case.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 18:02:13 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Bri\u00ebt", "Jop", ""], ["Buhrman", "Harry", ""], ["Leung", "Debbie", ""], ["Piovesan", "Teresa", ""], ["Speelman", "Florian", ""]]}, {"id": "1812.09428", "submitter": "Daniel Copeland", "authors": "Daniel Copeland and Jamie Pommersheim", "title": "Quantum query complexity of symmetric oracle problems", "comments": "v2 25 pages, fixed proof of Prop. 5.6, added Section 7 v3 32 pages,\n  added detail to proofs in Sec. 5, also minor revisions and corrections", "journal-ref": "Quantum 5, 403 (2021)", "doi": "10.22331/q-2021-03-07-403", "report-no": null, "categories": "cs.CC quant-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We study the query complexity of quantum learning problems in which the\noracles form a group $G$ of unitary matrices. In the simplest case, one wishes\nto identify the oracle, and we find a description of the optimal success\nprobability of a $t$-query quantum algorithm in terms of group characters. As\nan application, we show that $\\Omega(n)$ queries are required to identify a\nrandom permutation in $S_n$. More generally, suppose $H$ is a fixed subgroup of\nthe group $G$ of oracles, and given access to an oracle sampled uniformly from\n$G$, we want to learn which coset of $H$ the oracle belongs to. We call this\nproblem coset identification and it generalizes a number of well-known quantum\nalgorithms including the Bernstein-Vazirani problem, the van Dam problem and\nfinite field polynomial interpolation. We provide character-theoretic formulas\nfor the optimal success probability achieved by a $t$-query algorithm for this\nproblem. One application involves the Heisenberg group and provides a family of\nproblems depending on $n$ which require $n+1$ queries classically and only $1$\nquery quantumly.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 01:20:18 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 21:05:14 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 21:30:54 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Copeland", "Daniel", ""], ["Pommersheim", "Jamie", ""]]}, {"id": "1812.09967", "submitter": "Tselil Schramm", "authors": "Ryan O'Donnell and Tselil Schramm", "title": "Sherali--Adams Strikes Back", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be any $n$-vertex graph whose random walk matrix has its nontrivial\neigenvalues bounded in magnitude by $1/\\sqrt{\\Delta}$ (for example, a random\ngraph $G$ of average degree~$\\Theta(\\Delta)$ typically has this property). We\nshow that the $\\exp\\Big(c \\frac{\\log n}{\\log \\Delta}\\Big)$-round Sherali--Adams\nlinear programming hierarchy certifies that the maximum cut in such a~$G$ is at\nmost $50.1\\%$ (in fact, at most $\\tfrac12 + 2^{-\\Omega(c)}$). For example, in\nrandom graphs with $n^{1.01}$ edges, $O(1)$ rounds suffice; in random graphs\nwith $n \\cdot \\text{polylog}(n)$ edges, $n^{O(1/\\log \\log n)} = n^{o(1)}$\nrounds suffice.\n  Our results stand in contrast to the conventional beliefs that linear\nprogramming hierarchies perform poorly for \\maxcut and other CSPs, and that\neigenvalue/SDP methods are needed for effective refutation. Indeed, our results\nimply that constant-round Sherali--Adams can strongly refute random Boolean\n$k$-CSP instances with $n^{\\lceil k/2 \\rceil + \\delta}$ constraints; previously\nthis had only been done with spectral algorithms or the SOS SDP hierarchy.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 19:23:52 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["O'Donnell", "Ryan", ""], ["Schramm", "Tselil", ""]]}, {"id": "1812.10249", "submitter": "Prerona Chatterjee", "authors": "Prerona Chatterjee and Ramprasad Saptharishi", "title": "Constructing Faithful Homomorphisms over Fields of Finite Characteristic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the question of algebraic rank or transcendence degree preserving\nhomomorphisms over finite fields. This concept was first introduced by Beecken,\nMittmann and Saxena (2013), and exploited by them, and Agrawal, Saha,\nSaptharishi and Saxena (2016) to design algebraic independence based identity\ntests using the Jacobian criterion over characteristic zero fields. An analogue\nof such constructions over finite characteristic fields was unknown due to the\nfailure of the Jacobian criterion over finite characteristic fields.\n  Building on a recent criterion of Pandey, Sinhababu and Saxena (2018), we\nconstruct explicit faithful maps for some natural classes of polynomials in the\npositive characteristic field setting, when a certain parameter called the\ninseparable degree of the underlying polynomials is bounded (this parameter is\nalways 1 in fields of characteristic zero). This presents the first\ngeneralisation of some of the results of Beecken et al. and Agrawal et al. in\nthe positive characteristic setting.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 07:07:24 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 12:06:40 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chatterjee", "Prerona", ""], ["Saptharishi", "Ramprasad", ""]]}, {"id": "1812.10771", "submitter": "Leszek Ko{\\l}odziejczyk", "authors": "Leszek Aleksander Ko{\\l}odziejczyk and Neil Thapen", "title": "Approximate counting and NP search problems", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new class of NP search problems, those which can be proved total\nin the theory $\\mathrm{APC}_2$ of [Je\\v{r}\\'abek 2009]. This is an axiomatic\ntheory in bounded arithmetic which can formalize standard combinatorial\narguments based on approximate counting. In particular, the Ramsey and weak\npigeonhole search problems lie in the class. We give a purely computational\ncharacterization of this class and show that, relative to an oracle, it does\nnot contain the problem CPLS, a strengthening of PLS.\n  As CPLS is provably total in the theory $T^2_2$, this shows that\n$\\mathrm{APC}_2$ does not prove every $\\forall \\Sigma^b_1$ sentence which is\nprovable in bounded arithmetic. This answers the question posed in [Buss,\nKo{\\l}odziejczyk, Thapen 2014] and represents some progress in the programme of\nseparating the levels of the bounded arithmetic hierarchy by low-complexity\nsentences.\n  Our main technical tool is an extension of the \"fixing lemma\" from [Pudl\\'ak,\nThapen 2017], a form of switching lemma, which we use to show that a random\npartial oracle from a certain distribution will, with high probability,\ndetermine an entire computation of a $\\textrm{P}^{\\textrm{NP}}$ oracle machine.\nThe paper is intended to be accessible to someone unfamiliar with NP search\nproblems or with bounded arithmetic.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 17:03:43 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Ko\u0142odziejczyk", "Leszek Aleksander", ""], ["Thapen", "Neil", ""]]}, {"id": "1812.10837", "submitter": "Jesse Goodman", "authors": "Alexandre Bayen, Jesse Goodman, Eugene Vinitsky", "title": "On the Approximability of Time Disjoint Walks", "comments": "20 pages; extended (full) version; preliminary version appeared in\n  COCOA 2018; new results in the extended version include those listed in the\n  second paragraph of the abstract", "journal-ref": "Journal of Combinatorial Optimization (2020)", "doi": "10.1007/s10878-020-00525-z", "report-no": null, "categories": "cs.DS cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the combinatorial optimization problem Time Disjoint Walks\n(TDW), which has applications in collision-free routing of discrete objects\n(e.g., autonomous vehicles) over a network. This problem takes as input a\ndigraph $G$ with positive integer arc lengths, and $k$ pairs of vertices that\neach represent a trip demand from a source to a destination. The goal is to\nfind a walk and delay for each demand so that no two trips occupy the same\nvertex at the same time, and so that a min-max or min-sum objective over the\ntrip durations is realized.\n  We focus here on the min-sum variant of Time Disjoint Walks, although most of\nour results carry over to the min-max case. We restrict our study to various\nsubclasses of DAGs, and observe that there is a sharp complexity boundary\nbetween Time Disjoint Walks on oriented stars and on oriented stars with the\ncentral vertex replaced by a path. In particular, we present a poly-time\nalgorithm for min-sum and min-max TDW on the former, but show that min-sum TDW\non the latter is NP-hard.\n  Our main hardness result is that for DAGs with max degree $\\Delta\\leq3$,\nmin-sum Time Disjoint Walks is APX-hard. We present a natural approximation\nalgorithm for the same class, and provide a tight analysis. In particular, we\nprove that it achieves an approximation ratio of $\\Theta(k/\\log k)$ on\nbounded-degree DAGs, and $\\Theta(k)$ on DAGs and bounded-degree digraphs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 21:56:02 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 07:46:45 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bayen", "Alexandre", ""], ["Goodman", "Jesse", ""], ["Vinitsky", "Eugene", ""]]}, {"id": "1812.11685", "submitter": "Simone Ingrid Monteiro Gama", "authors": "Simone Gama, Rosiane de Freitas, M\\'ario Salvatierra", "title": "Choosability in bounded sequential list coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The list coloring problem is a variation of the classical vertex coloring\nproblem, extensively studied in recent years, where each vertex has a\nrestricted list of allowed colors, and having some variations as the\n$(\\gamma,\\mu)$-coloring, where the color lists have sequential values with\nknown lower and upper bounds. This work discusses the choosability property,\nthat consists in determining the least number $k$ for which it has a proper\nlist coloring no matter how one assigns a list of $k$ colors to each vertex.\nThis is a $\\Pi_2^P$-complete problem, however, we show that\n$k$-$(\\gamma,\\mu)$-choosability is an $NP$-problem due to its relation with the\n$k$-coloring of a graph and application of methods of proof in choosability for\nsome classes of graphs, such as complete bipartite graph, which is $ 3\n$-choosable, but $ 2 $-$(\\gamma,\\mu)$-choosable.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 03:36:55 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Gama", "Simone", ""], ["de Freitas", "Rosiane", ""], ["Salvatierra", "M\u00e1rio", ""]]}, {"id": "1812.11712", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Chrystalla Pavlou", "title": "On the Complexity of the Inverse Semivalue Problem for Weighted Voting\n  Games", "comments": "To appear in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted voting games are a family of cooperative games, typically used to\nmodel voting situations where a number of agents (players) vote against or for\na proposal. In such games, a proposal is accepted if an appropriately weighted\nsum of the votes exceeds a prespecified threshold. As the influence of a player\nover the voting outcome is not in general proportional to her assigned weight,\nvarious power indices have been proposed to measure each player's influence.\nThe inverse power index problem is the problem of designing a weighted voting\ngame that achieves a set of target influences according to a predefined power\nindex. In this work, we study the computational complexity of the inverse\nproblem when the power index belongs to the class of semivalues. We prove that\nthe inverse problem is computationally intractable for a broad family of\nsemivalues, including all regular semivalues. As a special case of our general\nresult, we establish computational hardness of the inverse problem for the\nBanzhaf indices and the Shapley values, arguably the most popular power\nindices.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 07:28:23 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Pavlou", "Chrystalla", ""]]}, {"id": "1812.11772", "submitter": "Andrey Mokhov", "authors": "Alexander S. Kulikov, Ivan Mikhailin, Andrey Mokhov, Vladimir\n  Podolskii", "title": "Complexity of Linear Operators", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A \\in \\{0,1\\}^{n \\times n}$ be a matrix with $z$ zeroes and $u$ ones and\n$x$ be an $n$-dimensional vector of formal variables over a semigroup $(S,\n\\circ)$. How many semigroup operations are required to compute the linear\noperator $Ax$?\n  As we observe in this paper, this problem contains as a special case the\nwell-known range queries problem and has a rich variety of applications in such\nareas as graph algorithms, functional programming, circuit complexity, and\nothers. It is easy to compute $Ax$ using $O(u)$ semigroup operations. The main\nquestion studied in this paper is: can $Ax$ be computed using $O(z)$ semigroup\noperations? We prove that in general this is not possible: there exists a\nmatrix $A \\in \\{0,1\\}^{n \\times n}$ with exactly two zeroes in every row (hence\n$z=2n$) whose complexity is $\\Theta(n\\alpha(n))$ where $\\alpha(n)$ is the\ninverse Ackermann function. However, for the case when the semigroup is\ncommutative, we give a constructive proof of an $O(z)$ upper bound. This\nimplies that in commutative settings, complements of sparse matrices can be\nprocessed as efficiently as sparse matrices (though the corresponding\nalgorithms are more involved). Note that this covers the cases of Boolean and\ntropical semirings that have numerous applications, e.g., in graph theory.\n  As a simple application of the presented linear-size construction, we show\nhow to multiply two $n\\times n$ matrices over an arbitrary semiring in $O(n^2)$\ntime if one of these matrices is a 0/1-matrix with $O(n)$ zeroes (i.e., a\ncomplement of a sparse matrix).\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 12:10:25 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 14:32:06 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Kulikov", "Alexander S.", ""], ["Mikhailin", "Ivan", ""], ["Mokhov", "Andrey", ""], ["Podolskii", "Vladimir", ""]]}]