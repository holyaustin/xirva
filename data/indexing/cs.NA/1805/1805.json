[{"id": "1805.00193", "submitter": "Mason A. Porter", "authors": "Walid Ahmad, Mason A. Porter, Mariano Beguerisse-D\\'iaz", "title": "Tie-decay networks in continuous time and eigenvector-based centralities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.NA cs.SI math.NA math.PR nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network theory is a useful framework for studying interconnected systems of\ninteracting entities. Many networked systems evolve continuously in time, but\nmost existing methods for the analysis of time-dependent networks rely on\ndiscrete or discretized time. In this paper, we propose an approach for\nstudying networks that evolve in continuous time by distinguishing between\n\\emph{interactions}, which we model as discrete contacts, and \\emph{ties},\nwhich encode the strengths of relationships as functions of time. To illustrate\nour tie-decay network formalism, we adapt the well-known PageRank centrality\nscore to our tie-decay framework in a mathematically tractable and\ncomputationally efficient way. We apply this framework to a synthetic example\nand then use it to study a network of retweets during the 2012 National Health\nService controversy in the United Kingdom. Our work also provides guidance for\nsimilar generalizations of other tools from network theory to continuous-time\nnetworks with tie decay, including for applications to streaming data.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 05:34:26 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 22:17:20 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 04:19:58 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ahmad", "Walid", ""], ["Porter", "Mason A.", ""], ["Beguerisse-D\u00edaz", "Mariano", ""]]}, {"id": "1805.00335", "submitter": "Miao-jung Ou", "authors": "Miao-Jung Yvonne Ou and Hugo J. Woerdeman", "title": "On the augmented Biot-JKD equations with Pole-Residue representation of\n  the dynamic tortuosity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive the augmented Biot-JKD equations, where the memory\nterms in the original Biot-JKD equations are dealt with by introducing\nauxiliary dependent variables. The evolution in time of these new variables are\ngoverned by ordinary differential equations whose coefficients can be\nrigorously computed from the JKD dynamic tortuosity function $T^D(\\omega)$ by\nutilizing its Stieltjes function representation derived in\n\\cite{ou2014on-reconstructi}, where an algorithm for computing the pole-residue\nrepresentation of the JKD tortuosity is also proposed. The two numerical\nschemes presented in the current work for computing the poles and residues\nrepresentation of $T^D(\\omega)$ improve the previous scheme in the sense that\nthey interpolate the function at infinite frequency and have much higher\naccuracy than the one proposed in \\cite{ou2014on-reconstructi}.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 01:03:13 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 20:46:17 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 18:39:49 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ou", "Miao-Jung Yvonne", ""], ["Woerdeman", "Hugo J.", ""]]}, {"id": "1805.00415", "submitter": "Kody Law", "authors": "Yaxian Xu, Ajay Jasra, and Kody J. H. Law", "title": "Multi-Index Sequential Monte Carlo Methods for partially observed\n  Stochastic Partial Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider sequential joint state and static parameter\nestimation given discrete time observations associated to a partially observed\nstochastic partial differential equation (SPDE). It is assumed that one can\nonly estimate the hidden state using a discretization of the model. In this\ncontext, it is known that the multi-index Monte Carlo (MIMC) method of [11] can\nbe used to improve over direct Monte Carlo from the most precise discretizaton.\nHowever, in the context of interest, it cannot be directly applied, but rather\nmust be used within another advanced method such as sequential Monte Carlo\n(SMC). We show how one can use the MIMC method by renormalizing the MI identity\nand approximating the resulting identity using the SMC$^2$ method of [5]. We\nprove that our approach can reduce the cost to obtain a given mean square error\n(MSE), relative to just using SMC$^2$ on the most precise discretization. We\ndemonstrate this with some numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 16:16:53 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 16:37:18 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 13:34:55 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Xu", "Yaxian", ""], ["Jasra", "Ajay", ""], ["Law", "Kody J. H.", ""]]}, {"id": "1805.00754", "submitter": "Jun-Gi Jang", "authors": "Jun-Gi Jang, Dongjin Choi, Jinhong Jung, U Kang", "title": "Zoom-SVD: Fast and Memory Efficient Method for Extracting Key Patterns\n  in an Arbitrary Time Range", "comments": "10 pages, 2018 ACM Conference on Information and Knowledge Management\n  (CIKM 2018)", "journal-ref": null, "doi": "10.1145/3269206.3271682", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given multiple time series data, how can we efficiently find latent patterns\nin an arbitrary time range? Singular value decomposition (SVD) is a crucial\ntool to discover hidden factors in multiple time series data, and has been used\nin many data mining applications including dimensionality reduction, principal\ncomponent analysis, recommender systems, etc. Along with its static version,\nincremental SVD has been used to deal with multiple semi infinite time series\ndata and to identify patterns of the data. However, existing SVD methods for\nthe multiple time series data analysis do not provide functionality for\ndetecting patterns of data in an arbitrary time range: standard SVD requires\ndata for all intervals corresponding to a time range query, and incremental SVD\ndoes not consider an arbitrary time range. In this paper, we propose Zoom-SVD,\na fast and memory efficient method for finding latent factors of time series\ndata in an arbitrary time range. Zoom-SVD incrementally compresses multiple\ntime series data block by block to reduce the space cost in storage phase, and\nefficiently computes singular value decomposition (SVD) for a given time range\nquery in query phase by carefully stitching stored SVD results. Through\nextensive experiments, we demonstrate that Zoom-SVD is up to 15x faster, and\nrequires 15x less space than existing methods. Our case study shows that\nZoom-SVD is useful for capturing past time ranges whose patterns are similar to\na query time range.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 12:04:37 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 06:29:10 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Jang", "Jun-Gi", ""], ["Choi", "Dongjin", ""], ["Jung", "Jinhong", ""], ["Kang", "U", ""]]}, {"id": "1805.00903", "submitter": "Austin Benson", "authors": "Austin R. Benson, David F. Gleich", "title": "Computing tensor Z-eigenvectors with dynamical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new framework for computing Z-eigenvectors of general tensors\nbased on numerically integrating a dynamical system that can only converge to a\nZ-eigenvector. Our motivation comes from our recent research on spacey random\nwalks, where the long-term dynamics of a stochastic process are governed by a\ndynamical system that must converge to a Z-eigenvector of a transition\nprobability tensor. Here, we apply the ideas more broadly to general tensors\nand find that our method can compute Z-eigenvectors that algebraic methods like\nthe higher-order power method cannot compute.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 16:47:25 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 16:56:03 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 22:35:58 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Benson", "Austin R.", ""], ["Gleich", "David F.", ""]]}, {"id": "1805.01140", "submitter": "Hao-Ning Wu", "authors": "Congpei An and Hao-Ning Wu", "title": "Regularized Weighted Discrete Least Squares Approximation Using Gauss\n  Quadrature Points", "comments": "Grammer mistakes, e.g. the usage of definite/indefinite articles,\n  have been revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider polynomial approximation over the interval $[-1,1]$ by\nregularized weighted discrete least squares methods with $\\ell_2-$ or\n$\\ell_1-$regularization, respectively. As the set of nodes we use Gauss\nquadrature points (which are zeros of orthogonal polynomials). The number of\nGauss quadrature points is $N+1$. For $2L\\leq2N+1$, with the aid of Gauss\nquadrature, we obtain approximation polynomials of degree $L$ in closed form\nwithout solving linear algebra or optimization problems. In fact, these\napproximation polynomials can be expressed in the form of the barycentric\ninterpolation formula when an interpolation condition is satisfied. We then\nstudy the approximation quality of the $\\ell_2-$regularized approximation\npolynomial in terms of Lebesgue constants, and the sparsity of the\n$\\ell_1-$regularized approximation polynomial. Finally, we give numerical\nexamples to illustrate these theoretical results and show that a well-chosen\nregularization parameter can lead to good performance, with or without\ncontaminated data.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 07:08:04 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 10:39:59 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 08:08:12 GMT"}, {"version": "v4", "created": "Sat, 20 Jul 2019 06:26:09 GMT"}, {"version": "v5", "created": "Mon, 26 Aug 2019 08:33:49 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["An", "Congpei", ""], ["Wu", "Hao-Ning", ""]]}, {"id": "1805.01389", "submitter": "Kalyana Babu Nakshatrala", "authors": "M. S. Joshaghani, S. H. S. Joodat and K. B. Nakshatrala", "title": "A stabilized mixed discontinuous Galerkin formulation for double\n  porosity/permeability model", "comments": "There was a mistake in the boundedness proof in the earlier version\n  (specifically version #1). We now rectified this mistake and improved\n  sections 1 and 3", "journal-ref": null, "doi": "10.1016/j.cma.2019.04.010", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling flow through porous media with multiple pore-networks has now become\nan active area of research due to recent technological endeavors like\ngeological carbon sequestration and recovery of hydrocarbons from tight rock\nformations. Herein, we consider the double porosity/permeability (DPP) model,\nwhich describes the flow of a single-phase incompressible fluid through a\nporous medium exhibiting two dominant pore-networks with a possibility of mass\ntransfer across them. We present a stable mixed discontinuous Galerkin (DG)\nformulation for the DPP model. The formulation enjoys several attractive\nfeatures. These include: (i) Equal-order interpolation for all the field\nvariables (which is computationally the most convenient) is stable under the\nproposed formulation. (ii) The stabilization terms are residual-based, and the\nstabilization parameters do not contain any mesh-dependent parameters. (iii)\nThe formulation is theoretically shown to be consistent, stable, and hence\nconvergent. (iv) The formulation supports non-conforming discretizations and\ndistorted meshes. (v) The DG formulation has improved element-wise (local) mass\nbalance compared to the corresponding continuous formulation. (vi) The proposed\nformulation can capture physical instabilities in coupled flow and transport\nproblems under the DPP model.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 16:02:33 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 05:24:38 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Joshaghani", "M. S.", ""], ["Joodat", "S. H. S.", ""], ["Nakshatrala", "K. B.", ""]]}, {"id": "1805.01844", "submitter": "Pierre Aubert", "authors": "Pierre Aubert, Thomas Vuillaume, Gilles Maurin, Jean Jacquemier,\n  Giovanni Lamanna, Nahid Emad", "title": "Polynomial data compression for large-scale physics experiments", "comments": "12 pages", "journal-ref": "Computing and Software for Big Science (2018)", "doi": null, "report-no": null, "categories": "cs.NA astro-ph.IM physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new generation research experiments will introduce huge data surge to a\ncontinuously increasing data production by current experiments. This data surge\nnecessitates efficient compression techniques. These compression techniques\nmust guarantee an optimum tradeoff between compression rate and the\ncorresponding compression /decompression speed ratio without affecting the data\nintegrity.\n  This work presents a lossless compression algorithm to compress physics data\ngenerated by Astronomy, Astrophysics and Particle Physics experiments.\n  The developed algorithms have been tuned and tested on a real use case~: the\nnext generation ground-based high-energy gamma ray observatory, Cherenkov\nTelescope Array (CTA), requiring important compression performance.\nStand-alone, the proposed compression method is very fast and reasonably\nefficient. Alternatively, applied as pre-compression algorithm, it can\naccelerate common methods like LZMA, keeping close performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 16:52:05 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Aubert", "Pierre", ""], ["Vuillaume", "Thomas", ""], ["Maurin", "Gilles", ""], ["Jacquemier", "Jean", ""], ["Lamanna", "Giovanni", ""], ["Emad", "Nahid", ""]]}, {"id": "1805.01922", "submitter": "Gaurav Mittal Mr", "authors": "Gaurav Mittal and Ankik Kumar Giri", "title": "Iteratively regularized landweber iteration method: Convergence analysis\n  via H\\\"older Stability", "comments": "This paper consists of 25 pages", "journal-ref": "Volume 392, 1 March 2021, 125744, Applied Mathematics and\n  Computation", "doi": "10.1016/j.amc.2020.125744", "report-no": null, "categories": "math.NA cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the local convergence of Iteratively regularized Landweber\niteration method is investigated for solving non-linear inverse problems in\nBanach spaces. Our analysis mainly relies on the assumption that the inverse\nmapping satisfies the H\\\"older stability estimate locally. We consider both\nnoisy as well as non-noisy data in our analysis. Under the a-priori choice of\nstopping index for noisy data, we show that the iterates remain in a certain\nball around exact solution and obtain the convergence rates. The convergence of\nthe Iteratively regularized Landweber iterates to the exact solution is shown\nunder certain assumptions in the case of non-noisy data and as a by-product,\nunder different conditions, two different convergence rates are obtained.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 19:45:58 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 14:57:06 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 16:59:33 GMT"}, {"version": "v4", "created": "Sun, 15 Nov 2020 15:43:14 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mittal", "Gaurav", ""], ["Giri", "Ankik Kumar", ""]]}, {"id": "1805.02061", "submitter": "Christian Lessig", "authors": "Christian Lessig", "title": "Polar Wavelets in Space", "comments": "Supplementary material available at\n  http://graphics.cs.uni-magdeburg.de/projects/polarlets/polarlets_supp.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work introduced a unified framework for steerable and directional\nwavelets in two and three dimensions that ensures many desirable properties,\nsuch as a multi-scale structure, fast transforms, and a flexible angular\nlocalization. We show that, for an appropriate choice for the radial window\nfunction, these wavelets also have closed form expressions for, among other\nthings, the spatial representation, the filter taps for the fast transform, and\nthe frame representation of the Laplace operator. The numerical practicality\nand benefits of our work are demonstrated using signal estimation from\nnon-uniform, point-wise samples, as required for example in ray tracing, and\nfor reconstructing a signal over a lower-dimensional sub-manifold, with\napplications for instance in medical imaging.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 14:23:45 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Lessig", "Christian", ""]]}, {"id": "1805.02062", "submitter": "Christian Lessig", "authors": "Christian Lessig", "title": "Divergence Free Polar Wavelets for the Analysis and Representation of\n  Fluid Flows", "comments": "To appear in Journal of Mathematical Fluid Dynamics. Extensive\n  supplementary material available at\n  http://graphics.cs.uni-magdeburg.de/projects/psidiv/psidiv_supp.pdf", "journal-ref": null, "doi": "10.1007/s00021-019-0408-7", "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Parseval tight wavelet frame for the representation and analysis\nof velocity vector fields of incompressible fluids. Our wavelets have closed\nform expressions in the frequency and spatial domains, are divergence free in\nthe ideal, analytic sense, have a multi-resolution structure and fast\ntransforms, and an intuitive correspondence to common flow phenomena. Our\nconstruction also allows for well defined directional selectivity, e.g. to\nmodel the behavior of divergence free vector fields in the vicinity of\nboundaries or to represent highly directional features like in a von K\\'arm\\'an\nvortex street. We demonstrate the practicality and efficiency of our\nconstruction by analyzing the representation of different divergence free\nvector fields in our wavelets.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 14:24:48 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 15:50:35 GMT"}, {"version": "v3", "created": "Sun, 30 Sep 2018 09:57:03 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Lessig", "Christian", ""]]}, {"id": "1805.02150", "submitter": "Chandrasekhar Venkataraman", "authors": "Mariya Ptashnyk and Chandrasekhar Venkataraman", "title": "Multiscale analysis and simulation of a signalling process with surface\n  diffusion", "comments": "Accepted for publication in SIAM MMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and analyse a model for cell signalling processes in biological\ntissues. The model includes diffusion and nonlinear reactions on the cell\nsurfaces, and both inter- and intracellular signalling. Using techniques from\nthe theory of two-scale convergence as well the unfolding method, we show\nconvergence of the solutions to the model to solutions of a two-scale\nmacroscopic problem. We also present a two-scale bulk-surface finite element\nmethod for the approximation of the macroscopic model. We report on some\nbenchmarking results as well as numerical simulations in a biologically\nrelevant regime that illustrate the influence of cell-scale heterogeneities on\nmacroscopic concentrations.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 05:05:37 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 13:42:38 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Ptashnyk", "Mariya", ""], ["Venkataraman", "Chandrasekhar", ""]]}, {"id": "1805.03117", "submitter": "M.C. David Marsh", "authors": "Theodor Bjorkmo and M.C. David Marsh", "title": "Local, algebraic simplifications of Gaussian random fields", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": "10.1088/1475-7516/2018/12/022", "report-no": null, "categories": "astro-ph.CO cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of Gaussian random fields and Gaussian random processes are\nlimited by the computational complexity of evaluating the probability density\nfunction, which involves inverting the relevant covariance matrix. In this\nwork, we show how that problem can be completely circumvented for the local\nTaylor coefficients of a Gaussian random field with a Gaussian (or `square\nexponential') covariance function. Our results hold for any dimension of the\nfield and to any order in the Taylor expansion. We present two applications.\nFirst, we show that this method can be used to explicitly generate non-trivial\npotential energy landscapes with many fields. This application is particularly\nuseful when one is concerned with the field locally around special points\n(e.g.~maxima or minima), as we exemplify by the problem of cosmic `manyfield'\ninflation in the early universe. Second, we show that this method has\napplications in machine learning, and greatly simplifies the regression problem\nof determining the hyperparameters of the covariance function given a training\ndata set consisting of local Taylor coefficients at single point. An\naccompanying Mathematica notebook is available at\nhttps://doi.org/10.17863/CAM.22859 .\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 15:43:54 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Bjorkmo", "Theodor", ""], ["Marsh", "M. C. David", ""]]}, {"id": "1805.03950", "submitter": "Weihua Deng Professor", "authors": "Xing Liu and Weihua Deng", "title": "Numerical methods for the two-dimensional Fokker-Planck equation\n  governing the probability density function of the tempered fractional\n  Brownian motion", "comments": "10 pages, 3 figures", "journal-ref": "Numerical Algorithms volume 85, pages 23-38 (2020)", "doi": "10.1007/s11075-019-00800-z", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the numerical schemes for the two-dimensional\nFokker-Planck equation governing the probability density function of the\ntempered fractional Brownian motion. The main challenges of the numerical\nschemes come from the singularity in the time direction. When $0<H<0.5$, a\nchange of variables $\\partial \\left(t^{2H}\\right)=2Ht^{2H-1}\\partial t$ avoids\nthe singularity of numerical computation at $t=0$, which naturally results in\nnonuniform time discretization and greatly improves the computational\nefficiency. For $0.5<H<1$, the time span dependent numerical scheme and\nnonuniform time discretization are introduced to ensure the effectiveness of\nthe calculation and the computational efficiency. By numerically solving the\ncorresponding Fokker-Planck equation, we obtain the mean squared displacement\nof stochastic processes, which conforms to the characteristics of the tempered\nfractional Brownian motion.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 08:56:22 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 15:20:21 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Liu", "Xing", ""], ["Deng", "Weihua", ""]]}, {"id": "1805.03967", "submitter": "Zhen Long", "authors": "Zhen Long, Yipeng Liu, Longxi Chen, Ce Zhu", "title": "Low Rank Tensor Completion for Multiway Visual Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor completion recovers missing entries of multiway data. Teh missing of\nentries could often be caused during teh data acquisition and transformation.\nIn dis paper, we provide an overview of recent development in low rank tensor\ncompletion for estimating teh missing components of visual data, e. g. , color\nimages and videos. First, we categorize these methods into two groups based on\nteh different optimization models. One optimizes factors of tensor\ndecompositions wif predefined tensor rank. Teh other iteratively updates teh\nestimated tensor via minimizing teh tensor rank. Besides, we summarize teh\ncorresponding algorithms to solve those optimization problems in details.\nNumerical experiments are given to demonstrate teh performance comparison when\ndifferent methods are applied to color image and video processing.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 08:51:26 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Long", "Zhen", ""], ["Liu", "Yipeng", ""], ["Chen", "Longxi", ""], ["Zhu", "Ce", ""]]}, {"id": "1805.03981", "submitter": "Svenja Schoeder", "authors": "Svenja Schoeder, Katharina Kormann, Wolfgang Wall, Martin Kronbichler", "title": "Efficient Explicit Time Stepping of High Order Discontinuous Galerkin\n  Schemes for Waves", "comments": null, "journal-ref": null, "doi": "10.1137/18M1185399", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents algorithms for the efficient implementation of\ndiscontinuous Galerkin methods with explicit time stepping for acoustic wave\npropagation on unstructured meshes of quadrilaterals or hexahedra. A crucial\nstep towards efficiency is to evaluate operators in a matrix-free way with\nsum-factorization kernels. The method allows for general curved geometries and\nvariable coefficients. Temporal discretization is carried out by low-storage\nexplicit Runge-Kutta schemes and the arbitrary derivative (ADER) method. For\nADER, we propose a flexible basis change approach that combines cheap face\nintegrals with cell evaluation using collocated nodes and quadrature points.\nAdditionally, a degree reduction for the optimized cell evaluation is presented\nto decrease the computational cost when evaluating higher order spatial\nderivatives as required in ADER time stepping. We analyze and compare the\nperformance of state-of-the-art Runge-Kutta schemes and ADER time stepping with\nthe proposed optimizations. ADER involves fewer operations and additionally\nreaches higher throughput by higher arithmetic intensities and hence decreases\nthe required computational time significantly. Comparison of Runge-Kutta and\nADER at their respective CFL stability limit renders ADER especially beneficial\nfor higher orders when the Butcher barrier implies an overproportional amount\nof stages. Moreover, vector updates in explicit Runge--Kutta schemes are shown\nto take a substantial amount of the computational time due to their memory\nintensity.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 14:23:05 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Schoeder", "Svenja", ""], ["Kormann", "Katharina", ""], ["Wall", "Wolfgang", ""], ["Kronbichler", "Martin", ""]]}, {"id": "1805.04006", "submitter": "Andrea Bonito", "authors": "Andrea Bonito, Vivette Girault and Endre S\\\"uli", "title": "Finite Element Approximation of a Strain-Limiting Elastic Model", "comments": "[v3] modifications / simplifications in the proof of Theorem 7.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a finite element approximation of a strain-limiting elastic\nmodel on a bounded open domain in $\\mathbb{R}^d$, $d \\in \\{2,3\\}$. The sequence\nof finite element approximations is shown to exhibit strong convergence to the\nunique weak solution of the model. Assuming that the material parameters\nfeaturing in the model are Lipschitz-continuous, and assuming that the weak\nsolution has additional regularity, the sequence of finite element\napproximations is shown to converge with a rate. An iterative algorithm is\nconstructed for the solution of the system of nonlinear algebraic equations\nthat arises from the finite element approximation. An appealing feature of the\niterative algorithm is that it decouples the monotone and linear elastic parts\nof the nonlinearity in the model. In particular, our choice of piecewise\nconstant approximation for the stress tensor (and continuous piecewise linear\napproximation for the displacement) allows us to compute the monotone part of\nthe nonlinearity by solving an algebraic system with $d(d+1)/2$ unknowns\nindependently on each element in the subdivision of the computational domain.\nThe theoretical results are illustrated by numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 14:38:48 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 18:27:47 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 13:43:01 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Bonito", "Andrea", ""], ["Girault", "Vivette", ""], ["S\u00fcli", "Endre", ""]]}, {"id": "1805.04158", "submitter": "Linan Zhang", "authors": "Hayden Schaeffer, Giang Tran, Rachel Ward, Linan Zhang", "title": "Extracting structured dynamical systems using sparse optimization with\n  very few samples", "comments": "37 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning governing equations allows for deeper understanding of the structure\nand dynamics of data. We present a random sampling method for learning\nstructured dynamical systems from under-sampled and possibly noisy state-space\nmeasurements. The learning problem takes the form of a sparse least-squares\nfitting over a large set of candidate functions. Based on a Bernstein-like\ninequality for partly dependent random variables, we provide theoretical\nguarantees on the recovery rate of the sparse coefficients and the\nidentification of the candidate functions for the corresponding problem.\nComputational results are demonstrated on datasets generated by the Lorenz 96\nequation, the viscous Burgers' equation, and the two-component\nreaction-diffusion equations (which is challenging due to parameter sensitives\nin the model). This formulation has several advantages including ease of use,\ntheoretical guarantees of success, and computational efficiency with respect to\nambient dimension and number of candidate functions.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 20:11:52 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Schaeffer", "Hayden", ""], ["Tran", "Giang", ""], ["Ward", "Rachel", ""], ["Zhang", "Linan", ""]]}, {"id": "1805.04196", "submitter": "Silvia Bertoluzza", "authors": "Silvia Bertoluzza and Daniele Prada", "title": "A Polygonal Discontinuous Galerkin Method with Minus One Stabilization", "comments": "23 pages", "journal-ref": "ESAIM: Mathematical Modelling and Numerical Analysis 55 (2021)\n  S785-S810", "doi": "10.1051/m2an/2020059", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Discontinuous Galerkin method for the Poisson equation on\npolygonal tessellations in two dimensions, stabilized by penalizing, locally in\neach element $K$, a residual term involving the fluxes, measured in the norm of\nthe dual of $H^1(K)$. The scalar product corresponding to such a norm is\nnumerically realized via the introduction of a (minimal) auxiliary space\ninspired by the Virtual Element Method. Stability and optimal error estimates\nin the broken $H^1$ norm are proven under a weak shape regularity assumption\nallowing the presence of very small edges.\n  The results of numerical tests confirm the theoretical estimates.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 22:25:17 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 15:50:33 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 13:02:55 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Bertoluzza", "Silvia", ""], ["Prada", "Daniele", ""]]}, {"id": "1805.04488", "submitter": "Eunice Y. S. Chan", "authors": "Eunice Y. S. Chan, Robert M. Corless, Leili Rafiee Sevyeri", "title": "Generalized Standard Triples for Algebraic Linearizations of Matrix\n  Polynomials", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define \\emph{generalized standard triples} $\\mathbf{X}$, $\\mathbf{Y}$, and\n$L(z) = z\\mathbf{C}_{1} - \\mathbf{C}_{0}$, where $L(z)$ is a linearization of a\nregular matrix polynomial $\\mathbf{P}(z) \\in \\mathbb{C}^{n \\times n}[z]$, in\norder to use the representation $\\mathbf{X}(z\n\\mathbf{C}_{1}~-~\\mathbf{C}_{0})^{-1}\\mathbf{Y}~=~\\mathbf{P}^{-1}(z)$ which\nholds except when $z$ is an eigenvalue of $\\mathbf{P}$. This representation can\nbe used in constructing so-called \\emph{algebraic linearizations} for matrix\npolynomials of the form $\\mathbf{H}(z) = z \\mathbf{A}(z)\\mathbf{B}(z) +\n\\mathbf{C} \\in \\mathbb{C}^{n \\times n}[z]$ from generalized standard triples of\n$\\mathbf{A}(z)$ and $\\mathbf{B}(z)$. This can be done even if $\\mathbf{A}(z)$\nand $\\mathbf{B}(z)$ are expressed in differing polynomial bases. Our main\ntheorem is that $\\mathbf{X}$ can be expressed using the coefficients of the\nexpression $1 = \\sum_{k=0}^\\ell e_k \\phi_k(z)$ in terms of the relevant\npolynomial basis. For convenience, we tabulate generalized standard triples for\northogonal polynomial bases, the monomial basis, and Newton interpolational\nbases; for the Bernstein basis; for Lagrange interpolational bases; and for\nHermite interpolational bases. We account for the possibility of common\nsimilarity transformations.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 16:50:04 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 19:08:55 GMT"}, {"version": "v3", "created": "Tue, 23 Jul 2019 16:52:52 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 14:11:08 GMT"}, {"version": "v5", "created": "Thu, 25 Mar 2021 18:06:27 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Chan", "Eunice Y. S.", ""], ["Corless", "Robert M.", ""], ["Sevyeri", "Leili Rafiee", ""]]}, {"id": "1805.05325", "submitter": "Kui Ren", "authors": "Christina Frederick and Kui Ren and Sarah Vall\\'elian", "title": "Image reconstruction in quantitative photoacoustic tomography with the\n  simplified $P_2$ approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photoacoustic tomography (PAT) is a hybrid imaging modality that intends to\nconstruct high-resolution images of optical properties of heterogeneous media\nfrom measured acoustic data generated by the photoacoustic effect. To date,\nmost of the model-based quantitative image reconstructions in PAT are performed\nwith either the radiative transport equation or its classical diffusion\napproximation as the model of light propagation. In this work, we study\nquantitative image reconstructions in PAT using the simplified $P_2$ equations\nas the light propagation model. We provide numerical evidences on the\nfeasibility of this approach and derive some stability results as theoretical\njustifications.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 05:43:10 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 03:38:58 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Frederick", "Christina", ""], ["Ren", "Kui", ""], ["Vall\u00e9lian", "Sarah", ""]]}, {"id": "1805.05715", "submitter": "Bailin Deng", "authors": "Yue Peng, Bailin Deng, Juyong Zhang, Fanyu Geng, Wenjie Qin, Ligang\n  Liu", "title": "Anderson Acceleration for Geometry Optimization and Physics Simulation", "comments": "SIGGRAPH 2018 Technical Paper", "journal-ref": null, "doi": "10.1145/3197517.3201290", "report-no": null, "categories": "cs.GR cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer graphics problems require computing geometric shapes subject to\ncertain constraints. This often results in non-linear and non-convex\noptimization problems with globally coupled variables, which pose great\nchallenge for interactive applications. Local-global solvers developed in\nrecent years can quickly compute an approximate solution to such problems,\nmaking them an attractive choice for applications that prioritize efficiency\nover accuracy. However, these solvers suffer from lower convergence rate, and\nmay take a long time to compute an accurate result. In this paper, we propose a\nsimple and effective technique to accelerate the convergence of such solvers.\nBy treating each local-global step as a fixed-point iteration, we apply\nAnderson acceleration, a well-established technique for fixed-point solvers, to\nspeed up the convergence of a local-global solver. To address the stability\nissue of classical Anderson acceleration, we propose a simple strategy to\nguarantee the decrease of target energy and ensure its global convergence. In\naddition, we analyze the connection between Anderson acceleration and\nquasi-Newton methods, and show that the canonical choice of its mixing\nparameter is suitable for accelerating local-global solvers. Moreover, our\ntechnique is effective beyond classical local-global solvers, and can be\napplied to iterative methods with a common structure. We evaluate the\nperformance of our technique on a variety of geometry optimization and physics\nsimulation problems. Our approach significantly reduces the number of\niterations required to compute an accurate result, with only a slight increase\nof computational cost per iteration. Its simplicity and effectiveness makes it\na promising tool for accelerating existing algorithms as well as designing\nefficient new algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 11:43:29 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Peng", "Yue", ""], ["Deng", "Bailin", ""], ["Zhang", "Juyong", ""], ["Geng", "Fanyu", ""], ["Qin", "Wenjie", ""], ["Liu", "Ligang", ""]]}, {"id": "1805.06137", "submitter": "Li Shen", "authors": "Li Shen, Peng Sun, Yitong Wang, Wei Liu, Tong Zhang", "title": "An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal\n  Extra-Gradient Method", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithmic framework of Variable Metric Over-Relaxed\nHybrid Proximal Extra-gradient (VMOR-HPE) method with a global convergence\nguarantee for the maximal monotone operator inclusion problem. Its iteration\ncomplexities and local linear convergence rate are provided, which\ntheoretically demonstrate that a large over-relaxed step-size contributes to\naccelerating the proposed VMOR-HPE as a byproduct. Specifically, we find that a\nlarge class of primal and primal-dual operator splitting algorithms are all\nspecial cases of VMOR-HPE. Hence, the proposed framework offers a new insight\ninto these operator splitting algorithms. In addition, we apply VMOR-HPE to the\nKarush-Kuhn-Tucker (KKT) generalized equation of linear equality constrained\nmulti-block composite convex optimization, yielding a new algorithm, namely\nnonsymmetric Proximal Alternating Direction Method of Multipliers with a\npreconditioned Extra-gradient step in which the preconditioned metric is\ngenerated by a blockwise Barzilai-Borwein line search technique (PADMM-EBB). We\nalso establish iteration complexities of PADMM-EBB in terms of the KKT\nresidual. Finally, we apply PADMM-EBB to handle the nonnegative dual graph\nregularized low-rank representation problem. Promising results on synthetic and\nreal datasets corroborate the efficacy of PADMM-EBB.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 05:38:37 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 03:51:22 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Shen", "Li", ""], ["Sun", "Peng", ""], ["Wang", "Yitong", ""], ["Liu", "Wei", ""], ["Zhang", "Tong", ""]]}, {"id": "1805.06322", "submitter": "Abdullah Al-Dujaili", "authors": "Abdullah Al-Dujaili, Shashank Srikant, Erik Hemberg, Una-May O'Reilly", "title": "On the Application of Danskin's Theorem to Derivative-Free Minimax\n  Optimization", "comments": "Submitted to LEGO 2018 (14th Int. Workshop on Global Optimization)", "journal-ref": null, "doi": "10.1063/1.5089993", "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by Danskin's theorem, gradient-based methods have been applied with\nempirical success to solve minimax problems that involve non-convex outer\nminimization and non-concave inner maximization. On the other hand, recent work\nhas demonstrated that Evolution Strategies (ES) algorithms are stochastic\ngradient approximators that seek robust solutions. In this paper, we address\nblack-box (gradient-free) minimax problems that have long been tackled in a\ncoevolutionary setup. To this end and guaranteed by Danskin's theorem, we\nemploy ES as a stochastic estimator for the descent direction. The proposed\napproach is validated on a collection of black-box minimax problems. Based on\nour experiments, our method's performance is comparable with its coevolutionary\ncounterparts and favorable for high-dimensional problems. Its efficacy is\ndemonstrated on a real-world application.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 13:55:24 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Al-Dujaili", "Abdullah", ""], ["Srikant", "Shashank", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1805.06454", "submitter": "Maruti Mudunuru", "authors": "V. V. Vesselinov, M. K. Mudunuru, S. Karra, D. O. Malley, and B. S.\n  Alexandrov", "title": "Unsupervised Machine Learning Based on Non-Negative Tensor Factorization\n  for Analyzing Reactive-Mixing", "comments": "34 pages", "journal-ref": null, "doi": "10.1016/j.jcp.2019.05.039", "report-no": null, "categories": "cs.CE cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of reactive-diffusion simulations requires a large number of\nindependent model runs. For each high-fidelity simulation, inputs are varied\nand the predicted mixing behavior is represented by changes in species\nconcentration. It is then required to discern how the model inputs impact the\nmixing process. This task is challenging and typically involves interpretation\nof large model outputs. However, the task can be automated and substantially\nsimplified by applying Machine Learning (ML) methods. In this paper, we present\nan application of an unsupervised ML method (called NTFk) using Non-negative\nTensor Factorization (NTF) coupled with a custom clustering procedure based on\nk-means to reveal hidden features in product concentration. An attractive\naspect of the proposed ML method is that it ensures the extracted features are\nnon-negative, which are important to obtain a meaningful deconstruction of the\nmixing processes. The ML method is applied to a large set of high-resolution\nFEM simulations representing reaction-diffusion processes in perturbed\nvortex-based velocity fields. The applied FEM ensures that species\nconcentration are always non-negative. The simulated reaction is a fast\nirreversible bimolecular reaction. The reactive-diffusion model input\nparameters that control mixing include properties of velocity field,\nanisotropic dispersion, and molecular diffusion. We demonstrate the\napplicability of the ML method to produce a meaningful deconstruction of model\noutputs to discriminate between different physical processes impacting the\nreactants, their mixing, and the spatial distribution of the product. The\npresented ML analysis allowed us to identify additive features that\ncharacterize mixing behavior.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 03:05:40 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 20:21:12 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Vesselinov", "V. V.", ""], ["Mudunuru", "M. K.", ""], ["Karra", "S.", ""], ["Malley", "D. O.", ""], ["Alexandrov", "B. S.", ""]]}, {"id": "1805.06557", "submitter": "Martin Schreiber", "authors": "Martin Schreiber, Nathana\\\"el Schaeffer, Richard Loft", "title": "Exponential Integrators with Parallel-in-Time Rational Approximations\n  for the Shallow-Water Equations on the Rotating Sphere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance computing trends towards many-core systems are expected to\ncontinue over the next decade. As a result, parallel-in-time methods,\nmathematical formulations which exploit additional degrees of parallelism in\nthe time dimension, have gained increasing interest in recent years. In this\nwork we study a massively parallel rational approximation of exponential\nintegrators (REXI). This method replaces a time integration of stiff linear\noscillatory and diffusive systems by the sum of the solutions of many decoupled\nsystems, which can be solved in parallel. Previous numerical studies showed\nthat this reformulation allows taking arbitrarily long time steps for the\nlinear oscillatory parts.\n  The present work studies the non-linear shallow-water equations on the\nrotating sphere, a simplified system of equations used to study properties of\nspace and time discretization methods in the context of atmospheric\nsimulations. After introducing time integrators, we first compare the time step\nsizes to the errors in the simulation, discussing pros and cons of different\nformulations of REXI. Here, REXI already shows superior properties compared to\nexplicit and implicit time stepping methods. Additionally, we present\nwallclock-time-to-error results revealing the sweet spots of REXI obtaining\neither an over 6x higher accuracy within the same time frame or an about 3x\nreduced time-to-solution for a similar error threshold. Our results motivate\nfurther explorations of REXI for operational weather/climate systems.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 23:52:28 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 19:54:56 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 11:25:45 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Schreiber", "Martin", ""], ["Schaeffer", "Nathana\u00ebl", ""], ["Loft", "Richard", ""]]}, {"id": "1805.06604", "submitter": "Nicolas Gillis", "authors": "Andersen Man Shun Ang and Nicolas Gillis", "title": "Accelerating Nonnegative Matrix Factorization Algorithms using\n  Extrapolation", "comments": "19 pages, 6 figures, 6 tables. v2: few typos corrected, additional\n  comparison with the extrapolated projected gradient method of Xu and Yin\n  (SIAM J. on Imaging Sciences, 2013)", "journal-ref": "Neural Computation 31 (2), pp. 417-439, 2019", "doi": "10.1162/neco_a_01157", "report-no": null, "categories": "cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a general framework to accelerate significantly the\nalgorithms for nonnegative matrix factorization (NMF). This framework is\ninspired from the extrapolation scheme used to accelerate gradient methods in\nconvex optimization and from the method of parallel tangents. However, the use\nof extrapolation in the context of the two-block exact coordinate descent\nalgorithms tackling the non-convex NMF problems is novel. We illustrate the\nperformance of this approach on two state-of-the-art NMF algorithms, namely,\naccelerated hierarchical alternating least squares (A-HALS) and alternating\nnonnegative least squares (ANLS), using synthetic, image and document data\nsets.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 05:26:14 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 12:49:56 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ang", "Andersen Man Shun", ""], ["Gillis", "Nicolas", ""]]}, {"id": "1805.06607", "submitter": "Andreas Kl\\\"ockner", "authors": "Cory Mikida, Andreas Kl\\\"ockner, Daniel Bodony", "title": "Multi-Rate Time Integration on Overset Meshes", "comments": null, "journal-ref": "Journal of Computational Physics 2019", "doi": "10.1016/j.jcp.2019.06.021", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overset meshes are an effective tool for the computational fluid dynamic\nsimulation of problems with complex geometries or multiscale spatio-temporal\nfeatures. When the maximum allowable timestep on one or more meshes is\nsignificantly smaller than on the remaining meshes, standard explicit time\nintegrators impose inefficiencies for time-accurate calculations by requiring\nthat all meshes advance with the smallest timestep. With the targeted use of\nmulti-rate time integrators, separate meshes can be time-marched at independent\nrates to avoid wasteful computation while maintaining accuracy and stability.\nThis work applies time-explicit multi-rate integrators to the simulation of the\ncompressible Navier-Stokes equations discretized on overset meshes using\nsummation-by-parts (SBP) operators and simultaneous approximation term (SAT)\nboundary conditions. We introduce a class of multi-rate Adams-Bashforth (MRAB)\nschemes that offer significant stability improvements and computational\nefficiencies for SBP-SAT methods. We present numerical results that confirm the\nefficacy of MRAB integrators, outline a number of implementation challenges,\nand demonstrate a reduction in computational cost enabled by MRAB. We also\ninvestigate the use of our method in the setting of a large-scale\ndistributed-memory parallel implementation where we discuss concerns involving\nload balancing and communication efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 05:51:55 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 21:21:57 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mikida", "Cory", ""], ["Kl\u00f6ckner", "Andreas", ""], ["Bodony", "Daniel", ""]]}, {"id": "1805.06667", "submitter": "Bal\\'azs Kov\\'acs", "authors": "Bal\\'azs Kov\\'acs, Buyang Li and Christian Lubich", "title": "A convergent evolving finite element algorithm for mean curvature flow\n  of closed surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A proof of convergence is given for semi- and full discretizations of mean\ncurvature flow of closed two-dimensional surfaces. The numerical method\nproposed and studied here combines evolving finite elements, whose nodes\ndetermine the discrete surface like in Dziuk's method, and linearly implicit\nbackward difference formulae for time integration. The proposed method differs\nfrom Dziuk's approach in that it discretizes Huisken's evolution equations for\nthe normal vector and mean curvature and uses these evolving geometric\nquantities in the velocity law projected to the finite element space. This\nnumerical method admits a convergence analysis in the case of finite elements\nof polynomial degree at least two and backward difference formulae of orders\ntwo to five. The error analysis combines stability estimates and consistency\nestimates to yield optimal-order $H^1$-norm error bounds for the computed\nsurface position, velocity, normal vector and mean curvature. The stability\nanalysis is based on the matrix--vector formulation of the finite element\nmethod and does not use geometric arguments. The geometry enters only into the\nconsistency estimates. Numerical experiments illustrate and complement the\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 09:25:27 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 07:41:09 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 12:53:30 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2019 11:36:18 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Kov\u00e1cs", "Bal\u00e1zs", ""], ["Li", "Buyang", ""], ["Lubich", "Christian", ""]]}, {"id": "1805.07174", "submitter": "Bj\\\"orn Sprungk", "authors": "Daniel Rudolf and Bj\\\"orn Sprungk", "title": "On a Metropolis-Hastings importance sampling estimator", "comments": "33 pages, 4 figures, accepted for publication in Electron. J. Stat", "journal-ref": "Electron. J. Statist. 14(1) (2020) 857-889", "doi": "10.1214/20-EJS1680", "report-no": null, "categories": "stat.CO cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical approach for approximating expectations of functions w.r.t.\npartially known distributions is to compute the average of function values\nalong a trajectory of a Metropolis-Hastings (MH) Markov chain. A key part in\nthe MH algorithm is a suitable acceptance/rejection of a proposed state, which\nensures the correct stationary distribution of the resulting Markov chain.\nHowever, the rejection of proposals causes highly correlated samples. In\nparticular, when a state is rejected it is not taken any further into account.\nIn contrast to that we consider a MH importance sampling estimator which\nexplicitly incorporates all proposed states generated by the MH algorithm. The\nestimator satisfies a strong law of large numbers as well as a central limit\ntheorem, and, in addition to that, we provide an explicit mean squared error\nbound. Remarkably, the asymptotic variance of the MH importance sampling\nestimator does not involve any correlation term in contrast to its classical\ncounterpart. Moreover, although the analyzed estimator uses the same amount of\ninformation as the classical MH estimator, it can outperform the latter in\nscenarios of moderate dimensions as indicated by numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 12:39:33 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 13:14:25 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 14:54:13 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Rudolf", "Daniel", ""], ["Sprungk", "Bj\u00f6rn", ""]]}, {"id": "1805.07451", "submitter": "Yingzhou Li", "authors": "Yingzhou Li, Xiuyuan Cheng, Jianfeng Lu", "title": "Butterfly-Net: Optimal Function Representation Based on Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks, especially convolutional neural networks (CNNs), have been\nsuccessfully applied in various areas of machine learning as well as to\nchallenging problems in other scientific and engineering fields. This paper\nintroduces Butterfly-Net, a low-complexity CNN with structured and sparse\ncross-channel connections, together with a Butterfly initialization strategy\nfor a family of networks. Theoretical analysis of the approximation power of\nButterfly-Net to the Fourier representation of input data shows that the error\ndecays exponentially as the depth increases. Combining Butterfly-Net with a\nfully connected neural network, a large class of problems are proved to be well\napproximated with network complexity depending on the effective frequency\nbandwidth instead of the input dimension. Regular CNN is covered as a special\ncase in our analysis. Numerical experiments validate the analytical results on\nthe approximation of Fourier kernels and energy functionals of Poisson's\nequations. Moreover, all experiments support that training from Butterfly\ninitialization outperforms training from random initialization. Also, adding\nthe remaining cross-channel connections, although significantly increase the\nparameter number, does not much improve the post-training accuracy and is more\nsensitive to data distribution.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 21:36:25 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 02:49:05 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 14:41:21 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 21:28:04 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Li", "Yingzhou", ""], ["Cheng", "Xiuyuan", ""], ["Lu", "Jianfeng", ""]]}, {"id": "1805.07659", "submitter": "Robert Corless", "authors": "Robert M. Corless", "title": "Compact Finite Differences and Cubic Splines", "comments": "Revised and corrected version. 25 pages, 4 figures; keywords: compact\n  finite differences; cubic splines; barycentric form; compact cubic splines;\n  contour integral methods; totally nonnegative matrices", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper I uncover and explain---using contour integrals and\nresidues---a connection between cubic splines and a popular compact finite\ndifference formula. The connection is that on a uniform mesh the simplest\nPad\\'e scheme for generating fourth-order accurate compact finite differences\ngives \\textsl{exactly} the derivatives at the interior nodes needed to\nguarantee twice-continuous differentiability for cubic splines. %I found this\nconnection surprising, because the two problems being solved are different. I\nalso introduce an apparently new spline-like interpolant that I call a compact\ncubic interpolant; this is similar to one introduced in 1972 by Swartz and\nVarga, but has higher order accuracy at the edges. I argue that for mildly\nnonuniform meshes the compact cubic approach offers some potential advantages,\nand even for uniform meshes offers a simple way to treat the edge conditions,\nrelieving the user of the burden of deciding to use one of the three standard\noptions: free (natural), complete (clamped), or \"not-a-knot\" conditions.\nFinally, I establish that the matrices defining the compact cubic splines\n(equivalently, the fourth-order compact finite difference formul\\ae) are\npositive definite, and in fact totally nonnegative, if all mesh widths are the\nsame sign.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 21:40:14 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 20:12:54 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 10:30:44 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Corless", "Robert M.", ""]]}, {"id": "1805.07821", "submitter": "Eran Treister", "authors": "Eran Treister, Lars Ruthotto, Michal Sharoni, Sapir Zafrani, Eldad\n  Haber", "title": "Low-Cost Parameterizations of Deep Convolutional Neural Networks", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) filter the input data using a series of\nspatial convolution operators with compactly supported stencils and point-wise\nnonlinearities. Commonly, the convolution operators couple features from all\nchannels. For wide networks, this leads to immense computational cost in the\ntraining of and prediction with CNNs. In this paper, we present novel ways to\nparameterize the convolution more efficiently, aiming to decrease the number of\nparameters in CNNs and their computational complexity. We propose new\narchitectures that use a sparser coupling between the channels and thereby\nreduce both the number of trainable weights and the computational cost of the\nCNN. Our architectures arise as new types of residual neural network (ResNet)\nthat can be seen as discretizations of a Partial Differential Equations (PDEs)\nand thus have predictable theoretical properties. Our first architecture\ninvolves a convolution operator with a special sparsity structure, and is\napplicable to a large class of CNNs. Next, we present an architecture that can\nbe seen as a discretization of a diffusion reaction PDE, and use it with three\ndifferent convolution operators. We outline in our experiments that the\nproposed architectures, although considerably reducing the number of trainable\nweights, yield comparable accuracy to existing CNNs that are fully coupled in\nthe channel dimension.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 20:17:47 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 07:32:58 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 06:10:32 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Treister", "Eran", ""], ["Ruthotto", "Lars", ""], ["Sharoni", "Michal", ""], ["Zafrani", "Sapir", ""], ["Haber", "Eldad", ""]]}, {"id": "1805.07887", "submitter": "Yukun Li", "authors": "Yukun Li, Yi Zhang", "title": "Analysis of adaptive two-grid finite element algorithms for linear and\n  nonlinear problems", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes some efficient and accurate adaptive two-grid (ATG)\nfinite element algorithms for linear and nonlinear partial differential\nequations (PDEs). The main idea of these algorithms is to utilize the solutions\non the $k$-th level adaptive meshes to find the solutions on the $(k+1)$-th\nlevel adaptive meshes which are constructed by performing adaptive element\nbisections on the $k$-th level adaptive meshes. These algorithms transform\nnon-symmetric positive definite (non-SPD) PDEs (resp., nonlinear PDEs) into\nsymmetric positive definite (SPD) PDEs (resp., linear PDEs). The proposed\nalgorithms are both accurate and efficient due to the following advantages:\nthey do not need to solve the non-symmetric or nonlinear systems; the degrees\nof freedom (d.o.f.) are very small; they are easily implemented; the\ninterpolation errors are very small. Next, this paper constructs residue-type\n{\\em a posteriori} error estimators, which are shown to be reliable and\nefficient. The key ingredient in proving the efficiency is to establish an\nupper bound of the oscillation terms, which may not be higher-order terms\n(h.o.t.) due to the low regularity of the numerical solution. Furthermore, the\nconvergence of the algorithms is proved when bisection is used for the mesh\nrefinements. Finally, numerical experiments are provided to verify the accuracy\nand efficiency of the ATG finite element algorithms, compared to regular\nadaptive finite element algorithms and two-grid finite element algorithms [27].\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 04:16:59 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 20:53:00 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 21:41:34 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Yukun", ""], ["Zhang", "Yi", ""]]}, {"id": "1805.07962", "submitter": "Aritra Dutta", "authors": "Aritra Dutta and Filip Hanzely and Peter Richt\\'arik", "title": "A Nonconvex Projection Method for Robust PCA", "comments": "In the proceedings of Thirty-Third AAAI Conference on Artificial\n  Intelligence (AAAI-19)", "journal-ref": "In the proceedings of Thirty-Third AAAI Conference on Artificial\n  Intelligence (AAAI-19), 33(01), pp. 1468-1476, 2019", "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust principal component analysis (RPCA) is a well-studied problem with the\ngoal of decomposing a matrix into the sum of low-rank and sparse components. In\nthis paper, we propose a nonconvex feasibility reformulation of RPCA problem\nand apply an alternating projection method to solve it. To the best of our\nknowledge, we are the first to propose a method that solves RPCA problem\nwithout considering any objective function, convex relaxation, or surrogate\nconvex constraints. We demonstrate through extensive numerical experiments on a\nvariety of applications, including shadow removal, background estimation, face\ndetection, and galaxy evolution, that our approach matches and often\nsignificantly outperforms current state-of-the-art in various ways.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 09:49:06 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 16:20:55 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Dutta", "Aritra", ""], ["Hanzely", "Filip", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1805.08034", "submitter": "Lars Ruthotto", "authors": "Eldad Haber, Felix Lucka, Lars Ruthotto", "title": "Never look back - A modified EnKF method and its application to the\n  training of neural networks without back propagation", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a new derivative-free optimization method and\ninvestigate its use for training neural networks. Our method is motivated by\nthe Ensemble Kalman Filter (EnKF), which has been used successfully for solving\noptimization problems that involve large-scale, highly nonlinear dynamical\nsystems. A key benefit of the EnKF method is that it requires only the\nevaluation of the forward propagation but not its derivatives. Hence, in the\ncontext of neural networks, it alleviates the need for back propagation and\nreduces the memory consumption dramatically. However, the method is not a pure\n\"black-box\" global optimization heuristic as it efficiently utilizes the\nstructure of typical learning problems. Promising first results of the EnKF for\ntraining deep neural networks have been presented recently by Kovachki and\nStuart. We propose an important modification of the EnKF that enables us to\nprove convergence of our method to the minimizer of a strongly convex function.\nOur method also bears similarity with implicit filtering and we demonstrate its\npotential for minimizing highly oscillatory functions using a simple example.\nFurther, we provide numerical examples that demonstrate the potential of our\nmethod for training deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 13:08:31 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 13:07:07 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Haber", "Eldad", ""], ["Lucka", "Felix", ""], ["Ruthotto", "Lars", ""]]}, {"id": "1805.08084", "submitter": "Anouar Ben Mabrouk", "authors": "Malika Jallouli, Wafa Bel Hadj Khalifa, Anouar Ben Mabrouk and Mohamed\n  Ali Mahjoub", "title": "Spherical harmonics entropy for optimal 3D modeling", "comments": "17 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D image processing constitutes nowadays a challenging topic in many\nscientific fields such as medicine, computational physics and informatics.\nTherefore, development of suitable tools that guaranty a best treatment is a\nnecessity. Spherical shapes are a big class of 3D images whom processing\nnecessitates adoptable tools. This encourages researchers to develop spherical\nwavelets and spherical harmonics as special mathematical bases able for 3D\nspherical shapes. The present work lies in the whole topic of 3D image\nprocessing with the special spherical harmonics bases. A spherical harmonics\nbased approach is proposed for the reconstruction of images provided with\nspherical harmonics Shannon-type entropy to evaluate the order/disorder of the\nreconstructed image. Efficiency and accuracy of the approach is demonstrated by\na simulation study on several spherical models.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:02:39 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Jallouli", "Malika", ""], ["Khalifa", "Wafa Bel Hadj", ""], ["Mabrouk", "Anouar Ben", ""], ["Mahjoub", "Mohamed Ali", ""]]}, {"id": "1805.08095", "submitter": "Jo\\~ao F. Henriques", "authors": "Jo\\~ao F. Henriques, Sebastien Ehrhardt, Samuel Albanie, Andrea\n  Vedaldi", "title": "Small steps and giant leaps: Minimal Newton solvers for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast second-order method that can be used as a drop-in\nreplacement for current deep learning solvers. Compared to stochastic gradient\ndescent (SGD), it only requires two additional forward-mode automatic\ndifferentiation operations per iteration, which has a computational cost\ncomparable to two standard forward passes and is easy to implement. Our method\naddresses long-standing issues with current second-order solvers, which invert\nan approximate Hessian matrix every iteration exactly or by conjugate-gradient\nmethods, a procedure that is both costly and sensitive to noise. Instead, we\npropose to keep a single estimate of the gradient projected by the inverse\nHessian matrix, and update it once per iteration. This estimate has the same\nsize and is similar to the momentum variable that is commonly used in SGD. No\nestimate of the Hessian is maintained. We first validate our method, called\nCurveBall, on small problems with known closed-form solutions (noisy Rosenbrock\nfunction and degenerate 2-layer linear networks), where current deep learning\nsolvers seem to struggle. We then train several large models on CIFAR and\nImageNet, including ResNet and VGG-f networks, where we demonstrate faster\nconvergence with no hyperparameter tuning. Code is available.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:54:28 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Henriques", "Jo\u00e3o F.", ""], ["Ehrhardt", "Sebastien", ""], ["Albanie", "Samuel", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1805.08261", "submitter": "Qiang Du", "authors": "Qiang Du and Xiaochuan Tian", "title": "Mathematics of Smoothed Particle Hydrodynamics: a Study via Nonlocal\n  Stokes Equations", "comments": "modified title, revised form accepted by journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothed Particle Hydrodynamics (SPH) is a popular numerical technique\ndeveloped for simulating complex fluid flows. Among its key ingredients is the\nuse of nonlocal integral relaxations to local differentiations. Mathematical\nanalysis of the corresponding nonlocal models on the continuum level can\nprovide further theoretical understanding of SPH. We present, in this part of a\nseries of works on the mathematics of SPH, a nonlocal relaxation to the\nconventional linear steady state Stokes system for incompressible viscous\nflows. The nonlocal continuum model is characterized by a smoothing length\n$\\delta$ which measures the range of nonlocal interactions. It serves as a\nbridge between the discrete approximation schemes that involve a nonlocal\nintegral relaxation and the local continuum models. We show that for a class of\ncarefully chosen nonlocal operators, the resulting nonlocal Stokes equation is\nwell-posed and recovers the original Stokes equation in the local limit when\n$\\delta$ approaches zero. We also discuss the implications of our finding on\nthe design of numerical methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 19:12:57 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 11:18:45 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Du", "Qiang", ""], ["Tian", "Xiaochuan", ""]]}, {"id": "1805.08278", "submitter": "Jeff Calder", "authors": "Jeff Calder, Charles K Smart", "title": "The limit shape of convex hull peeling", "comments": null, "journal-ref": "Duke Math. J. 169, no. 11 (2020), 2079-2124", "doi": "10.1215/00127094-2020-0013", "report-no": null, "categories": "math.AP cs.DS cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the convex peeling of a random point set in dimension d\napproximates motion by the 1/(d + 1) power of Gaussian curvature. We use\nviscosity solution theory to interpret the limiting partial differential\nequation. We use the Martingale method to solve the cell problem associated to\nconvex peeling. Our proof follows the program of Armstrong-Cardaliaguet for\nhomogenization of geometric motions, but with completely different ingredients.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 20:10:31 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 03:02:56 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Calder", "Jeff", ""], ["Smart", "Charles K", ""]]}, {"id": "1805.08468", "submitter": "Longhao Yuan", "authors": "Longhao Yuan, Chao Li, Danilo Mandic, Jianting Cao and Qibin Zhao", "title": "Rank Minimization on Tensor Ring: A New Paradigm in Scalable Tensor\n  Decomposition and Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In low-rank tensor completion tasks, due to the underlying multiple\nlarge-scale singular value decomposition (SVD) operations and rank selection\nproblem of the traditional methods, they suffer from high computational cost\nand high sensitivity of model complexity. In this paper, taking advantages of\nhigh compressibility of the recently proposed tensor ring (TR) decomposition,\nwe propose a new model for tensor completion problem. This is achieved through\nintroducing convex surrogates of tensor low-rank assumption on latent tensor\nring factors, which makes it possible for the Schatten norm regularization\nbased models to be solved at much smaller scale. We propose two algorithms\nwhich apply different structured Schatten norms on tensor ring factors\nrespectively. By the alternating direction method of multipliers (ADMM) scheme,\nthe tensor ring factors and the predicted tensor can be optimized\nsimultaneously. The experiments on synthetic data and real-world data show the\nhigh performance and efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 09:16:34 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Yuan", "Longhao", ""], ["Li", "Chao", ""], ["Mandic", "Danilo", ""], ["Cao", "Jianting", ""], ["Zhao", "Qibin", ""]]}, {"id": "1805.08479", "submitter": "Philippe Dreesen", "authors": "Philippe Dreesen and Jeroen De Geeter and Mariya Ishteva", "title": "Decoupling multivariate functions using second-order information and\n  tensors", "comments": "Accepted for presentation at the 14th International Conference on\n  Latent Variable Analysis and Signal Separation (LVA/ICA 2018), July 2-6,\n  2018, University of Surrey, Guildford, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of multivariate functions is their ability to model a wide variety\nof phenomena, but have the disadvantages that they lack an intuitive or\ninterpretable representation, and often require a (very) large number of\nparameters. We study decoupled representations of multivariate vector\nfunctions, which are linear combinations of univariate functions in linear\ncombinations of the input variables. This model structure provides a\ndescription with fewer parameters, and reveals the internal workings in a\nsimpler way, as the nonlinearities are one-to-one functions. In earlier work, a\ntensor-based method was developed for performing this decomposition by using\nfirst-order derivative information. In this article, we generalize this method\nand study how the use of second-order derivative information can be\nincorporated. By doing this, we are able to push the method towards more\ninvolved configurations, while preserving uniqueness of the underlying tensor\ndecompositions. Furthermore, even for some non-identifiable structures, the\nmethod seems to return a valid decoupled representation. These results are a\nstep towards more general data-driven and noise-robust tensor-based framework\nfor computing decoupled function representations.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 10:05:25 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Dreesen", "Philippe", ""], ["De Geeter", "Jeroen", ""], ["Ishteva", "Mariya", ""]]}, {"id": "1805.08846", "submitter": "David Ketcheson", "authors": "H. Gorune Ohannessian and George Turkiyyah and Aron Ahmadia and David\n  Ketcheson", "title": "CUDACLAW: A high-performance programmable GPU framework for the solution\n  of hyperbolic PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present cudaclaw, a CUDA-based high performance data-parallel framework\nfor the solution of multidimensional hyperbolic partial differential equation\n(PDE) systems, equations describing wave motion. cudaclaw allows computational\nscientists to solve such systems on GPUs without being burdened by the need to\nwrite CUDA code, worry about thread and block details, data layout, and data\nmovement between the different levels of the memory hierarchy. The user defines\nthe set of PDEs to be solved via a CUDA- independent serial Riemann solver and\nthe framework takes care of orchestrating the computations and data transfers\nto maximize arithmetic throughput. cudaclaw treats the different spatial\ndimensions separately to allow suitable block sizes and dimensions to be used\nin the different directions, and includes a number of optimizations to minimize\naccess to global memory.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:21:51 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Ohannessian", "H. Gorune", ""], ["Turkiyyah", "George", ""], ["Ahmadia", "Aron", ""], ["Ketcheson", "David", ""]]}, {"id": "1805.08863", "submitter": "Charles Matthews", "authors": "Charles Matthews and Jonathan Weare", "title": "Langevin Markov Chain Monte Carlo with stochastic gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.NA math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo sampling techniques have broad applications in machine learning,\nBayesian posterior inference, and parameter estimation. Often the target\ndistribution takes the form of a product distribution over a dataset with a\nlarge number of entries. For sampling schemes utilizing gradient information it\nis cheaper for the derivative to be approximated using a random small subset of\nthe data, introducing extra noise into the system. We present a new\ndiscretization scheme for underdamped Langevin dynamics when utilizing a\nstochastic (noisy) gradient. This scheme is shown to bias computed averages to\nsecond order in the stepsize while giving exact results in the special case of\nsampling a Gaussian distribution with a normally distributed stochastic\ngradient.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 20:54:44 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 22:22:57 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Matthews", "Charles", ""], ["Weare", "Jonathan", ""]]}, {"id": "1805.09106", "submitter": "Robert Nasdala", "authors": "Robert Nasdala and Daniel Potts", "title": "Transformed rank-1 lattices for high-dimensional approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an extension of Fourier approximation methods for\nmultivariate functions defined on the torus $\\mathbb{T}^d$ to functions in a\nweighted Hilbert space $L_{2}(\\mathbb{R}^d, \\omega)$ via a multivariate change\nof variables $\\psi:\\left(-\\frac{1}{2},\\frac{1}{2}\\right)^d\\to\\mathbb{R}^d$. We\nestablish sufficient conditions on $\\psi$ and $\\omega$ such that the\ncomposition of a function in such a weighted Hilbert space with $\\psi$ yields a\nfunction in the Sobolev space $H_{\\mathrm{mix}}^{m}(\\mathbb{T}^d)$ of functions\non the torus with mixed smoothness of natural order $m \\in \\mathbb{N}_{0}$. In\nthis approach we adapt algorithms for the evaluation and reconstruction of\nmultivariate trigonometric polynomials on the torus $\\mathbb{T}^d$ based on\nsingle and multiple reconstructing rank-$1$ lattices. Since in applications it\nmay be difficult to choose a related function space, we make use of dimension\nincremental construction methods for sparse frequency sets. Various numerical\ntests confirm obtained theoretical results for the transformed methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:01:28 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 10:42:41 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 13:32:30 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Nasdala", "Robert", ""], ["Potts", "Daniel", ""]]}, {"id": "1805.09464", "submitter": "Anastasios Kyrillidis", "authors": "Anastasios Kyrillidis", "title": "Simple and practical algorithms for $\\ell_p$-norm low-rank approximation", "comments": "16 pages, 11 figures, to appear in UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NA math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose practical algorithms for entrywise $\\ell_p$-norm low-rank\napproximation, for $p = 1$ or $p = \\infty$. The proposed framework, which is\nnon-convex and gradient-based, is easy to implement and typically attains\nbetter approximations, faster, than state of the art.\n  From a theoretical standpoint, we show that the proposed scheme can attain\n$(1 + \\varepsilon)$-OPT approximations. Our algorithms are not\nhyperparameter-free: they achieve the desiderata only assuming algorithm's\nhyperparameters are known a priori---or are at least approximable. I.e., our\ntheory indicates what problem quantities need to be known, in order to get a\ngood solution within polynomial time, and does not contradict to recent\ninapproximabilty results, as in [46].\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 00:41:25 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Kyrillidis", "Anastasios", ""]]}, {"id": "1805.09737", "submitter": "Nargiz Kalantarova", "authors": "Nargiz Kalantarova, Levent Tun\\c{c}el", "title": "On the spectral structure of Jordan-Kronecker products of symmetric and\n  skew-symmetric matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the conjectures formulated in 2003 by Tun\\c{c}el et al., we\nstudy interlacing properties of the eigenvalues of $A\\otimes B + B\\otimes A$\nfor pairs of $n$-by-$n$ matrices $A, B$. We prove that for every pair of\nsymmetric matrices (and skew-symmetric matrices) with one of them at most rank\ntwo, the \\emph{odd spectrum} (those eigenvalues determined by skew-symmetric\neigenvectors) of $A\\otimes B + B\\otimes A$ interlaces its \\emph{even spectrum}\n(those eigenvalues determined by symmetric eigenvectors). Using this result, we\nalso show that when $n \\leq 3$, the odd spectrum of $A\\otimes B + B\\otimes A$\ninterlaces its even spectrum for every pair $A, B$. The interlacing results\nalso specify the structure of the eigenvectors corresponding to the extreme\neigenvalues. In addition, we identify where the conjecture(s) and some\ninterlacing properties hold for a number of structured matrices. We settle the\nconjectures of Tun\\c{c}el et al. and show they fail for some pairs of symmetric\nmatrices $A, B$, when $n\\geq 4$ and the ranks of $A$ and $B$ are at least $3$.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 15:42:54 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 15:05:12 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 01:04:25 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kalantarova", "Nargiz", ""], ["Tun\u00e7el", "Levent", ""]]}, {"id": "1805.09920", "submitter": "Eldar Khattatov", "authors": "Ilona Ambartsumyan, Eldar Khattatov, Jan M. Nordbotten, Ivan Yotov", "title": "A multipoint stress mixed finite element method for elasticity on\n  simplicial grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new multipoint stress mixed finite element method for linear\nelasticity with weakly enforced stress symmetry on simplicial grids. Motivated\nby the multipoint flux mixed finite element method for Darcy flow, the method\nutilizes the lowest order Brezzi-Douglas-Marini finite element spaces for the\nstress and the vertex quadrature rule in order to localize the interaction of\ndegrees of freedom. This allows for local stress elimination around each\nvertex. We develop two variants of the method. The first uses a piecewise\nconstant rotation and results in a cell-centered system for displacement and\nrotation. The second uses a piecewise linear rotation and a quadrature rule for\nthe asymmetry bilinear form. This allows for further elimination of the\nrotation, resulting in a cell-centered system for the displacement only.\nStability and error analysis is performed for both variants. First-order\nconvergence is established for all variables in their natural norms. A duality\nargument is further employed to prove second order superconvergence of the\ndisplacement at the cell centers. Numerical results are presented in\nconfirmation of the theory.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 22:05:50 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 23:01:28 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 22:21:07 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ambartsumyan", "Ilona", ""], ["Khattatov", "Eldar", ""], ["Nordbotten", "Jan M.", ""], ["Yotov", "Ivan", ""]]}, {"id": "1805.10177", "submitter": "Louisa Schlachter", "authors": "Jakob D\\\"urrw\\\"achter, Thomas Kuhn, Fabian Meyer, Louisa Schlachter,\n  Florian Schneider", "title": "A hyperbolicity-preserving discontinuous stochastic Galerkin scheme for\n  uncertain hyperbolic systems of equations", "comments": null, "journal-ref": null, "doi": "10.1016/j.cam.2019.112602", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusive Uncertainty Quantification methods such as stochastic Galerkin are\ngaining popularity, whereas the classical stochastic Galerkin approach is not\nensured to preserve hyperbolicity of the underlying hyperbolic system. We apply\na modification of this method that uses a slope limiter to retain admissible\nsolutions of the system, while providing high-order approximations in the\nphysical and stochastic space. This is done using a spatial discontinuous\nGalerkin scheme and a Multi-Element stochastic Galerkin ansatz in the random\nspace. We analyze the convergence of the resulting scheme and apply it to the\ncompressible Euler equations with various uncertain initial states in one and\ntwo spatial domains with up to three uncertainties. The performance in multiple\nstochastic dimensions is compared to the non-intrusive Stochastic Collocation\nmethod. The numerical results underline the strength of our method, especially\nif discontinuities are present in the uncertainty of the solution.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 14:36:52 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 14:19:01 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 13:15:48 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["D\u00fcrrw\u00e4chter", "Jakob", ""], ["Kuhn", "Thomas", ""], ["Meyer", "Fabian", ""], ["Schlachter", "Louisa", ""], ["Schneider", "Florian", ""]]}, {"id": "1805.10192", "submitter": "Khalide Jbilou", "authors": "M. Hached and K. Jbilou", "title": "Numerical methods for differential linear matrix equations via Krylov\n  subspace methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we present some numerical methods for computing\napproximate solutions to some large differential linear matrix equations. In\nthe first part of this work, we deal with differential generalized Sylvester\nmatrix equations with full rank right-hand sides using a global Galerkin and a\nnorm-minimization approaches. In the second part, we consider large\ndifferential Lyapunov matrix equations with low rank right-hand sides and use\nthe extended global Arnoldi process to produce low rank approximate solutions.\nWe give some theoretical results and present some numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:11:42 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Hached", "M.", ""], ["Jbilou", "K.", ""]]}, {"id": "1805.10219", "submitter": "Przemyslaw Zielinski", "authors": "Kristian Debrabant, Giovanni Samaey, Przemys{\\l}aw Zieli\\'nski", "title": "Study of micro-macro acceleration schemes for linear slow-fast\n  stochastic differential equations with additive noise", "comments": "29 pages, 8 figures", "journal-ref": "BIT Numerical Mathematics 60, no. 4 (2020), pp. 959-998", "doi": "10.1007/s10543-020-00804-5", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational multi-scale methods capitalize on a large time-scale separation\nto efficiently simulate slow dynamics over long time intervals. For stochastic\nsystems, one often aims at resolving the statistics of the slowest dynamics.\nThis paper looks at the efficiency of a micro-macro acceleration method that\ncouples short bursts of stochastic path simulation with extrapolation of\nspatial averages forward in time. To have explicit derivations, we elicit an\namenable linear test equation containing multiple time scales. We make\nderivations and perform numerical experiments in the Gaussian setting, where\nonly the evolution of mean and variance matters. The analysis shows that, for\nthis test model, the stability threshold on the extrapolation step is largely\nindependent of the time-scale separation. In consequence, the micro-macro\nacceleration method increases the admissible time steps far beyond those for\nwhich a direct time discretization becomes unstable.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 16:00:27 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 09:48:21 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 16:36:26 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Debrabant", "Kristian", ""], ["Samaey", "Giovanni", ""], ["Zieli\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "1805.10502", "submitter": "Anton Arnold", "authors": "Anton Arnold, Kirian D\\\"opfner", "title": "Stationary Schr\\\"odinger equation in the semi-classical limit: WKB-based\n  scheme coupled to a turning point", "comments": null, "journal-ref": null, "doi": "10.1007/s10092-019-0349-9", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the efficient numerical treatment of 1D\nstationary Schr\\\"odinger equations in the semi-classical limit when including a\nturning point of first order. For the considered scattering problems we show\nthat the wave function asymptotically blows up at the turning point as the\nscaled Planck constant $\\varepsilon\\to0$, which is a key challenge for the\nanalysis. Assuming that the given potential is linear or quadratic in a small\nneighborhood of the turning point, the problem is analytically solvable on that\nsubinterval in terms of Airy or parabolic cylinder functions, respectively.\nAway from the turning point, the analytical solution is coupled to a numerical\nsolution that is based on a WKB-marching method -- using a coarse grid even for\nhighly oscillatory solutions. We provide an error analysis for the hybrid\nanalytic-numerical problem up to the turning point (where the solution is\nasymptotically unbounded) and illustrate it in numerical experiments: If the\nphase of the problem is explicitly computable, the hybrid scheme is\nasymptotically correct w.r.t.\\ $\\varepsilon$. If the phase is obtained with a\nquadrature rule of, e.g., order 4, then the spatial grid size has the\nlimitation $h={\\cal O}(\\varepsilon^{7/12})$ which is slightly worse than the\n$h={\\cal O}(\\varepsilon^{1/2})$ restriction in the case without a turning\npoint.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 15:57:55 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 13:25:42 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 15:11:03 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Arnold", "Anton", ""], ["D\u00f6pfner", "Kirian", ""]]}, {"id": "1805.10638", "submitter": "Bailin Deng", "authors": "Juyong Zhang, Yuxin Yao, Yue Peng, Hao Yu, Bailin Deng", "title": "Fast K-Means Clustering with Anderson Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to accelerate Lloyd's algorithm for K-Means\nclustering. Unlike previous acceleration approaches that reduce computational\ncost per iterations or improve initialization, our approach is focused on\nreducing the number of iterations required for convergence. This is achieved by\ntreating the assignment step and the update step of Lloyd's algorithm as a\nfixed-point iteration, and applying Anderson acceleration, a well-established\ntechnique for accelerating fixed-point solvers. Classical Anderson acceleration\nutilizes m previous iterates to find an accelerated iterate, and its\nperformance on K-Means clustering can be sensitive to choice of m and the\ndistribution of samples. We propose a new strategy to dynamically adjust the\nvalue of m, which achieves robust and consistent speedups across different\nproblem instances. Our method complements existing acceleration techniques, and\ncan be combined with them to achieve state-of-the-art performance. We perform\nextensive experiments to evaluate the performance of the proposed method, where\nit outperforms other algorithms in 106 out of 120 test cases, and the mean\ndecrease ratio of computational time is more than 33%.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 15:17:33 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhang", "Juyong", ""], ["Yao", "Yuxin", ""], ["Peng", "Yue", ""], ["Yu", "Hao", ""], ["Deng", "Bailin", ""]]}, {"id": "1805.11137", "submitter": "C\\'onall Kelly", "authors": "C\\'onall Kelly and Gabriel Lord", "title": "Adaptive Euler methods for stochastic systems with non-globally\n  Lipschitz coefficients", "comments": "This is a preprint of an article published in Numerical Algorithms.\n  The final authenticated version is available online at:\n  https://doi.org/10.1007/s11075-021-01131-8", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present strongly convergent explicit and semi-implicit adaptive numerical\nschemes for systems of stiff stochastic differential equations (SDEs) where\nboth the drift and diffusion are non-globally Lipschitz continuous. This\nstiffness may originate either from a linear operator in the drift, or from a\nperturbation of the nonlinear structures under discretisation, or both. Typical\napplications arise from the space discretisation of an SPDE, stochastic\nvolatility models in finance, or certain ecological models. We prove that a\ntimetepping strategy that adapts the stepsize based on the drift alone is\nsufficient to control growth and to obtain strong convergence with polynomial\norder. The order of strong convergence of our scheme is $(1-\\varepsilon)/2$,\nfor $\\varepsilon\\in(0,1)$, where $\\varepsilon$ becomes arbitrarily small as the\nnumber of available finite moments for solutions of the SDE increases.\nNumerically, we compare the adaptive semi-implicit method to a fully drift\nimplicit method, three tamed type methods and a truncated method. Our numerical\nresults show that the adaptive semi-implicit method is well suited as a general\npurpose solver, is more robust than the explicit time stepping methods and more\nefficient than the drift implicit method.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 19:14:42 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 10:05:35 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 10:56:26 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 11:16:41 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Kelly", "C\u00f3nall", ""], ["Lord", "Gabriel", ""]]}, {"id": "1805.11830", "submitter": "Tom Lefebvre", "authors": "Tom Lefebvre, Frederik De Belie, Guillaume Crevecoeur", "title": "A Radial Basis Function based Optimization Algorithm with Regular\n  Simplex set geometry in Ellipsoidal Trust-Regions", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel derivative-free interpolation based optimization\nalgorithm. A trust-region method is used where a surrogate model is realized\nvia an interpolation framework. The framework for interpolation is provided by\nUniversal Kriging. A first contribution focuses on the development of an\noriginal sampling strategy. A valid model is guaranteed by maintaining a\nwell-poised subset that exhibits the regular simplex geometry approximately. It\nfollows that this strategy improves the scattering of points with respect to\nthe state-of-the-art and, even importantly, assures that the surrogate model\nexhibits curvature. A second contribution focuses on the generalization of the\nspherical trust-region geometry to an ellipsoidal geometry, that to account for\nlocal anisotropy of the objective function and to improve the interpolation\nconditions as seen from the output space. The ensemble method is validated\nagainst its direct competitors on a set of multidimensional problems.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 07:12:55 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Lefebvre", "Tom", ""], ["De Belie", "Frederik", ""], ["Crevecoeur", "Guillaume", ""]]}, {"id": "1805.11854", "submitter": "Gaurav Mittal Mr", "authors": "Gaurav Mittal, Ankik Kumar Giri", "title": "Convergence rates of nonlinear inverse problems in Banach spaces via\n  novel smoothness concepts", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate the convergence rates of well known Tikhonov\nregularization scheme for solving the nonlinear ill-posed problems by\nintroducing a novel smoothness concept termed as approximate H\\\"older stability\nestimates. In addition to this, we introduce another smoothness concept which\nis a variant of the conditional stability estimates and incorporate this\nsmoothness concept to obtain the convergence rates in terms of weaker norms. In\norder to complement the abstract theory, we also discuss some examples of\ninverse problems that satisfy a variant of conditional stability estimates.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 08:39:05 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 17:21:53 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 15:58:59 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 16:21:34 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Mittal", "Gaurav", ""], ["Giri", "Ankik Kumar", ""]]}, {"id": "1805.11930", "submitter": "Eike Hermann M\\\"uller", "authors": "Peter Bastian, Eike Hermann M\\\"uller, Steffen M\\\"uthing, Marian\n  Piatkowski", "title": "Matrix-free multigrid block-preconditioners for higher order\n  Discontinuous Galerkin discretisations", "comments": "28 pages, 10 figures, 10 tables; accepted for publication in Journal\n  of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2019.06.001", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and suitably preconditioned iterative solvers for elliptic partial\ndifferential equations (PDEs) of the convection-diffusion type are used in all\nfields of science and engineering. To achieve optimal performance, solvers have\nto exhibit high arithmetic intensity and need to exploit every form of\nparallelism available in modern manycore CPUs. The computationally most\nexpensive components of the solver are the repeated applications of the linear\noperator and the preconditioner. For discretisations based on higher-order\nDiscontinuous Galerkin methods, sum-factorisation results in a dramatic\nreduction of the computational complexity of the operator application while, at\nthe same time, the matrix-free implementation can run at a significant fraction\nof the theoretical peak floating point performance. Multigrid methods for high\norder methods often rely on block-smoothers to reduce high-frequency error\ncomponents within one grid cell. Traditionally, this requires the assembly and\nexpensive dense matrix solve in each grid cell, which counteracts any\nimprovements achieved in the fast matrix-free operator application. To overcome\nthis issue, we present a new matrix-free implementation of block-smoothers.\nInverting the block matrices iteratively avoids storage and factorisation of\nthe matrix and makes it is possible to harness the full power of the CPU. We\nimplemented a hybrid multigrid algorithm with matrix-free block-smoothers in\nthe high order DG space combined with a low order coarse grid correction using\nalgebraic multigrid where only low order components are explicitly assembled.\nThe effectiveness of this approach is demonstrated by solving a set of\nrepresentative elliptic PDEs of increasing complexity, including a convection\ndominated problem and the stationary SPE10 benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 13:07:20 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 17:23:33 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Bastian", "Peter", ""], ["M\u00fcller", "Eike Hermann", ""], ["M\u00fcthing", "Steffen", ""], ["Piatkowski", "Marian", ""]]}, {"id": "1805.12042", "submitter": "Victor Pan", "authors": "Victor Y. Pan", "title": "New Progress in Polynomial Root-finding", "comments": "112 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Univariate polynomial root-finding has been studied for four millennia and\nvery intensively in the last decades, but mostly for polynomials given in\nmonomial basis -- with their coefficients. We propose and extensively analyze\nvarious novel techniques, which enable significant acceleration of the known\nalgorithms, particularly for root-finding in a disc on the complex plane that\ncontains a small number of roots where a polynomial is given by a subroutine\nfor its evaluation\n  rather than by its coefficients. Our auxiliary algorithms and estimates,\ne.g., for the approximation of root radii, that is, the distances from a\ncomplex point to the roots, can be of independent interest..\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 15:46:07 GMT"}, {"version": "v10", "created": "Mon, 11 Nov 2019 20:36:37 GMT"}, {"version": "v11", "created": "Sat, 25 Jan 2020 12:07:51 GMT"}, {"version": "v12", "created": "Tue, 4 Feb 2020 23:57:23 GMT"}, {"version": "v13", "created": "Fri, 20 Mar 2020 12:20:34 GMT"}, {"version": "v14", "created": "Sat, 4 Apr 2020 02:26:36 GMT"}, {"version": "v15", "created": "Mon, 18 May 2020 02:09:25 GMT"}, {"version": "v16", "created": "Sun, 13 Sep 2020 22:09:35 GMT"}, {"version": "v17", "created": "Wed, 16 Dec 2020 19:56:04 GMT"}, {"version": "v18", "created": "Sun, 31 Jan 2021 21:53:07 GMT"}, {"version": "v19", "created": "Sun, 28 Feb 2021 16:33:30 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 22:33:58 GMT"}, {"version": "v20", "created": "Thu, 1 Jul 2021 03:10:00 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 20:30:30 GMT"}, {"version": "v4", "created": "Sun, 10 Feb 2019 22:36:16 GMT"}, {"version": "v5", "created": "Mon, 8 Apr 2019 14:53:11 GMT"}, {"version": "v6", "created": "Thu, 23 May 2019 15:33:44 GMT"}, {"version": "v7", "created": "Wed, 29 May 2019 02:45:34 GMT"}, {"version": "v8", "created": "Sat, 6 Jul 2019 11:58:08 GMT"}, {"version": "v9", "created": "Mon, 23 Sep 2019 18:36:36 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Pan", "Victor Y.", ""]]}, {"id": "1805.12417", "submitter": "Murat Manguoglu", "authors": "Murat Manguoglu and Volker Mehrmann", "title": "A Robust Iterative Scheme for Symmetric Indefinite Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-level nested preconditioned iterative scheme for solving\nsparse linear systems of equations in which the coefficient matrix is symmetric\nand indefinite with relatively small number of negative eigenvalues. The\nproposed scheme consists of an outer Minimum Residual (MINRES) iteration,\npreconditioned by an inner Conjugate Gradient (CG) iteration in which CG can be\nfurther preconditioned. The robustness of the proposed scheme is illustrated by\nsolving indefinite linear systems that arise in the solution of quadratic\neigenvalue problems in the context of model reduction methods for finite\nelement models of disk brakes as well as on other problems that arise in a\nvariety of applications.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 11:00:12 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 12:04:41 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 08:28:11 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Manguoglu", "Murat", ""], ["Mehrmann", "Volker", ""]]}]