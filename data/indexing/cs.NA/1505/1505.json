[{"id": "1505.00370", "submitter": "Serkan Gugercin", "authors": "Zlatko Drmac and Serkan Gugercin", "title": "A New Selection Operator for the Discrete Empirical Interpolation Method\n  -- improved a priori error bound and extensions", "comments": "19 pages", "journal-ref": "SIAM Journal on Scientific Computing, Vol. 38, No. 2, pp.\n  A631-A648, 2016", "doi": "10.1137/15M1019271", "report-no": null, "categories": "cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new framework for constructing the Discrete Empirical\nInterpolation Method DEIM projection operator. The interpolation node selection\nprocedure is formulated using the QR factorization with column pivoting, and it\nenjoys a sharper error bound for the DEIM projection error. Furthermore, for a\nsubspace $\\mathcal{U}$ given as the range of an orthonormal $U$, the DEIM\nprojection does not change if $U$ is replaced by $U \\Omega$ with arbitrary\nunitary matrix $\\Omega$. In a large-scale setting, the new approach allows\nmodifications that use only randomly sampled rows of $U$, but with the\npotential of producing good approximations with corresponding probabilistic\nerror bounds. Another salient feature of the new framework is that robust and\nefficient software implementation is easily developed, based on readily\navailable high performance linear algebra packages.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2015 20:27:11 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2015 19:56:56 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Drmac", "Zlatko", ""], ["Gugercin", "Serkan", ""]]}, {"id": "1505.00383", "submitter": "Jan Verschelde", "authors": "Jan Verschelde and Xiangcheng Yu", "title": "Tracking Many Solution Paths of a Polynomial Homotopy on a Graphics\n  Processing Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.AG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polynomial systems occur in many areas of science and engineering. Unlike\ngeneral nonlinear systems, the algebraic structure enables to compute all\nsolutions of a polynomial system. We describe our massive parallel\npredictor-corrector algorithms to track many solution paths of a polynomial\nhomotopy. The data parallelism that provides the speedups stems from the\nevaluation and differentiation of the monomials in the same polynomial system\nat different data points, which are the points on the solution paths.\nPolynomial homotopies that have tens of thousands of solution paths can keep a\nsufficiently large amount of threads occupied. Our accelerated code combines\nthe reverse mode of algorithmic differentiation with double double and quad\ndouble precision to compute more accurate results faster.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2015 00:50:23 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Verschelde", "Jan", ""], ["Yu", "Xiangcheng", ""]]}, {"id": "1505.00398", "submitter": "Ruoxi Wang", "authors": "Ruoxi Wang, Yingzhou Li, Michael W. Mahoney, Eric Darve", "title": "Block Basis Factorization for Scalable Kernel Matrix Evaluation", "comments": "16 pages, 5 figures", "journal-ref": "SIAM Journal on Matrix Analysis and Applications, 2019, Vol. 40,\n  No. 4 : pp. 1497-1526", "doi": "10.1137/18M1212586", "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods are widespread in machine learning; however, they are limited\nby the quadratic complexity of the construction, application, and storage of\nkernel matrices. Low-rank matrix approximation algorithms are widely used to\naddress this problem and reduce the arithmetic and storage cost. However, we\nobserved that for some datasets with wide intra-class variability, the optimal\nkernel parameter for smaller classes yields a matrix that is less well\napproximated by low-rank methods. In this paper, we propose an efficient\nstructured low-rank approximation method -- the Block Basis Factorization (BBF)\n-- and its fast construction algorithm to approximate radial basis function\n(RBF) kernel matrices. Our approach has linear memory cost and floating-point\noperations for many machine learning kernels. BBF works for a wide range of\nkernel bandwidth parameters and extends the domain of applicability of low-rank\napproximation methods significantly. Our empirical results demonstrate the\nstability and superiority over the state-of-art kernel approximation\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2015 07:05:45 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 21:48:23 GMT"}, {"version": "v3", "created": "Tue, 16 Apr 2019 07:06:20 GMT"}, {"version": "v4", "created": "Tue, 4 May 2021 06:02:31 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Wang", "Ruoxi", ""], ["Li", "Yingzhou", ""], ["Mahoney", "Michael W.", ""], ["Darve", "Eric", ""]]}, {"id": "1505.00940", "submitter": "Luca Bonaventura", "authors": "Luca Bonaventura and Roberto Ferretti", "title": "Flux form Semi-Lagrangian methods for parabolic problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semi-Lagrangian method for parabolic problems is proposed, that extends\nprevious work by the authors to achieve a fully conservative, flux-form\ndiscretization of linear and nonlinear diffusion equations. A basic consistency\nand convergence analysis are proposed. Numerical examples validate the proposed\nmethod and display its potential for consistent semi-Lagrangian discretization\nof advection--diffusion and nonlinear parabolic problems.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 09:54:36 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Bonaventura", "Luca", ""], ["Ferretti", "Roberto", ""]]}, {"id": "1505.01519", "submitter": "Petr Vabishchevich N.", "authors": "Alexander G. Churbanov and Petr N. Vabishchevich", "title": "Numerical investigation of a space-fractional model of turbulent fluid\n  flow in rectangular ducts", "comments": "19 pages, 17 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2016.06.009", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The models that are based of fractional derivatives should be highlighted\namong promising new models to describe turbulent fluid flows. In the present\nwork, a steady-state flow in a duct is considered under the condition that the\nturbulent diffusion is governed by a fractional power of the Laplace operator.\nTo study numerically flows in rectangular channels, finite-difference\napproximations are employed. For approximate solving the corresponding boundary\nvalue problem, the iterative method of conjugate gradients is used. At each\niteration, the problem with a fractional power of the grid Laplace operator is\nsolved. Predictions of turbulent flows in ducts at different Reynolds numbers\nare presented via mean velocity fields.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 21:07:28 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Churbanov", "Alexander G.", ""], ["Vabishchevich", "Petr N.", ""]]}, {"id": "1505.01599", "submitter": "Kenji Kume", "authors": "Kenji Kume and Naoko Nose-Togawa", "title": "Filter characteristics in image decomposition with singular spectrum\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular spectrum analysis is developed as a nonparametric spectral\ndecomposition of a time series. It can be easily extended to the decomposition\nof multidimensional lattice-like data through the filtering interpretation. In\nthis viewpoint, the singular spectrum analysis can be understood as the\nadaptive and optimal generation of the filters and their two-step\npoint-symmetric operation to the original data. In this paper, we point out\nthat, when applied to the multidimensional data, the adaptively generated\nfilters exhibit symmetry properties resulting from the bisymmetric nature of\nthe lag-covariance matrices. The eigenvectors of the lag-covariance matrix are\neither symmetric or antisymmetric, and for the 2D image data, these lead to the\ndifferential-type filters with even- or odd-order derivatives. The dominant\nfilter is a smoothing filter, reflecting the dominance of low-frequency\ncomponents of the photo images. The others are the edge-enhancement or the\nnoise filters corresponding to the band-pass or the high-pass filters. The\nimplication of the decomposition to the image denoising is briefly discussed.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2015 06:21:15 GMT"}], "update_date": "2015-05-08", "authors_parsed": [["Kume", "Kenji", ""], ["Nose-Togawa", "Naoko", ""]]}, {"id": "1505.01973", "submitter": "Geir Bogfjellmo", "authors": "Geir Bogfjellmo", "title": "Algebraic structure of aromatic B-series", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aromatic B-series are a generalization of B-series. Some of the operations\ndefined for B-series can be defined analogically for aromatic B-series. This\npaper derives combinatorial formulas for the composition and substitution laws\nfor aromatic B-series.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 09:58:43 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 11:12:46 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 13:42:26 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Bogfjellmo", "Geir", ""]]}, {"id": "1505.02248", "submitter": "Luca Bonaventura", "authors": "Luca Bonaventura", "title": "Local Exponential Methods: a domain decomposition approach to\n  exponential time integration of PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A local approach to the time integration of PDEs by exponential methods is\nproposed, motivated by theoretical estimates by A.Iserles on the decay of\noff-diagonal terms in the exponentials of sparse matrices. An overlapping\ndomain decomposition technique is outlined, that allows to replace the\ncomputation of a global exponential matrix by a number of independent and\neasily parallelizable local problems. Advantages and potential problems of the\nproposed technique are discussed. Numerical experiments on simple, yet relevant\nmodel problems show that the resulting method allows to increase computational\nefficiency with respect to standard implementations of exponential methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2015 09:21:30 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Bonaventura", "Luca", ""]]}, {"id": "1505.02343", "submitter": "Qibin Zhao Dr", "authors": "Qibin Zhao, Liqing Zhang, Andrzej Cichocki", "title": "Bayesian Sparse Tucker Models for Dimension Reduction and Tensor\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tucker decomposition is the cornerstone of modern machine learning on\ntensorial data analysis, which have attracted considerable attention for\nmultiway feature extraction, compressive sensing, and tensor completion. The\nmost challenging problem is related to determination of model complexity (i.e.,\nmultilinear rank), especially when noise and missing data are present. In\naddition, existing methods cannot take into account uncertainty information of\nlatent factors, resulting in low generalization performance. To address these\nissues, we present a class of probabilistic generative Tucker models for tensor\ndecomposition and completion with structural sparsity over multilinear latent\nspace. To exploit structural sparse modeling, we introduce two group sparsity\ninducing priors by hierarchial representation of Laplace and Student-t\ndistributions, which facilitates fully posterior inference. For model learning,\nwe derived variational Bayesian inferences over all model (hyper)parameters,\nand developed efficient and scalable algorithms based on multilinear\noperations. Our methods can automatically adapt model complexity and infer an\noptimal multilinear rank by the principle of maximum lower bound of model\nevidence. Experimental results and comparisons on synthetic, chemometrics and\nneuroimaging data demonstrate remarkable performance of our models for\nrecovering ground-truth of multilinear rank and missing entries.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2015 05:17:34 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Zhao", "Qibin", ""], ["Zhang", "Liqing", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1505.02740", "submitter": "Rasmus Dalgas Kongskov", "authors": "Rasmus Dalgas Kongskov, Jakob Sauer J{\\o}rgensen, Henning Friis\n  Poulsen, Per Christian Hansen", "title": "Noise Robustness of a Combined Phase Retrieval and Reconstruction Method\n  for Phase-Contrast Tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical reconstruction methods for phase-contrast tomography consist of two\nstages: phase retrieval and tomographic reconstruction. A novel algebraic\nmethod combining the two was suggested by Kostenko et al. (Opt. Express, 21,\n12185, 2013) and preliminary results demonstrating improved reconstruction\ncompared to a two-stage method given. Using simulated free-space propagation\nexperiments with a single sample-detector distance, we thoroughly compare the\nnovel method with the two-stage method to address limitations of the\npreliminary results. We demonstrate that the novel method is substantially more\nrobust towards noise; our simulations point to a possible reduction in counting\ntimes by an order of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 19:17:33 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2015 13:30:49 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2015 14:42:20 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Kongskov", "Rasmus Dalgas", ""], ["J\u00f8rgensen", "Jakob Sauer", ""], ["Poulsen", "Henning Friis", ""], ["Hansen", "Per Christian", ""]]}, {"id": "1505.03445", "submitter": "Guangning Tan", "authors": "Guangning Tan, Ned S. Nedialkov, John D. Pryce", "title": "Symbolic-numeric methods for improving structural analysis of\n  differential-algebraic equation systems", "comments": "technical report, 84 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems of differential-algebraic equations (DAEs) are generated routinely by\nsimulation and modeling environments such as Modelica and MapleSim. Before a\nsimulation starts and a numerical solution method is applied, some kind of\nstructural analysis is performed to determine the structure and the index of a\nDAE. Structural analysis methods serve as a necessary preprocessing stage, and\namong them, Pantelides's algorithm is widely used.\n  Recently Pryce's $\\Sigma$-method is becoming increasingly popular, owing to\nits straightforward approach and capability of analyzing high-order systems.\nBoth methods are equivalent in the sense that when one succeeds, producing a\nnonsingular system Jacobian, the other also succeeds, and the two give the same\nstructural index.\n  Although provably successful on fairly many problems of interest, the\nstructural analysis methods can fail on some simple, solvable DAEs and give\nincorrect structural information including the index. In this report, we focus\non the $\\Sigma$-method. We investigate its failures, and develop two\nsymbolic-numeric conversion methods for converting a DAE, on which the\n$\\Sigma$-method fails, to an equivalent problem on which this method succeeds.\nAimed at making structural analysis methods more reliable, our conversion\nmethods exploit structural information of a DAE, and require a symbolic tool\nfor their implementation.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 16:11:42 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Tan", "Guangning", ""], ["Nedialkov", "Ned S.", ""], ["Pryce", "John D.", ""]]}, {"id": "1505.04103", "submitter": "Petr Vabishchevich N.", "authors": "Petr N. Vabishchevich", "title": "A splitting scheme to solve an equation for fractional powers of\n  elliptic operators", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An equation containing a fractional power of an elliptic operator of second\norder is studied for Dirichlet boundary conditions. Finite difference\napproximations in space are employed. The proposed numerical algorithm is based\non solving an auxiliary Cauchy problem for a pseudo-parabolic equation.\nUnconditionally stable vector additive schemes (splitting schemes) are\nconstructed. Numerical results for a model problem in a rectangle calculated\nusing the splitting with respect to spatial variables are presented.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 15:59:16 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Vabishchevich", "Petr N.", ""]]}, {"id": "1505.04123", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Javier Pe\\~na", "title": "Margins, Kernels and Non-linear Smoothed Perceptrons", "comments": "17 pages, published in the proceedings of the International\n  Conference on Machine Learning, 2014", "journal-ref": "Ramdas, Aaditya, and Javier Pena. \"Margins, kernels and non-linear\n  smoothed perceptrons.\" Proceedings of the 31st International Conference on\n  Machine Learning (ICML-14). 2014", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of finding a non-linear classification function that\nlies in a Reproducing Kernel Hilbert Space (RKHS) both from the primal point of\nview (finding a perfect separator when one exists) and the dual point of view\n(giving a certificate of non-existence), with special focus on generalizations\nof two classical schemes - the Perceptron (primal) and Von-Neumann (dual)\nalgorithms.\n  We cast our problem as one of maximizing the regularized normalized\nhard-margin ($\\rho$) in an RKHS and %use the Representer Theorem to rephrase it\nin terms of a Mahalanobis dot-product/semi-norm associated with the kernel's\n(normalized and signed) Gram matrix. We derive an accelerated smoothed\nalgorithm with a convergence rate of $\\tfrac{\\sqrt {\\log n}}{\\rho}$ given $n$\nseparable points, which is strikingly similar to the classical kernelized\nPerceptron algorithm whose rate is $\\tfrac1{\\rho^2}$. When no such classifier\nexists, we prove a version of Gordan's separation theorem for RKHSs, and give a\nreinterpretation of negative margins. This allows us to give guarantees for a\nprimal-dual algorithm that halts in $\\min\\{\\tfrac{\\sqrt n}{|\\rho|},\n\\tfrac{\\sqrt n}{\\epsilon}\\}$ iterations with a perfect separator in the RKHS if\nthe primal is feasible or a dual $\\epsilon$-certificate of near-infeasibility.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 16:54:58 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Pe\u00f1a", "Javier", ""]]}, {"id": "1505.04340", "submitter": "Ruipeng Li", "authors": "Ruipeng Li, Yuanzhe Xi, Yousef Saad", "title": "Schur Complement based domain decomposition preconditioners with\n  Low-rank corrections", "comments": null, "journal-ref": null, "doi": null, "report-no": "ys-2014-3", "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a robust preconditioner for general sparse symmetric\nmatrices, that is based on low-rank approximations of the Schur complement in a\nDomain Decomposition (DD) framework. In this \"Schur Low Rank\" (SLR)\npreconditioning approach, the coefficient matrix is first decoupled by DD, and\nthen a low-rank correction is exploited to compute an approximate inverse of\nthe Schur complement associated with the interface points. The method avoids\nexplicit formation of the Schur complement matrix. We show the feasibility of\nthis strategy for a model problem, and conduct a detailed spectral analysis for\nthe relationship between the low-rank correction and the quality of the\npreconditioning. Numerical experiments on general matrices illustrate the\nrobustness and efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2015 23:55:25 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Li", "Ruipeng", ""], ["Xi", "Yuanzhe", ""], ["Saad", "Yousef", ""]]}, {"id": "1505.04341", "submitter": "Ruipeng Li", "authors": "Ruipeng Li, Yousef Saad", "title": "Low-rank correction methods for algebraic domain decomposition\n  preconditioners", "comments": null, "journal-ref": null, "doi": null, "report-no": "ys-2014-4", "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a parallel preconditioning method for distributed sparse\nlinear systems, based on an approximate inverse of the original matrix, that\nadopts a general framework of distributed sparse matrices and exploits the\ndomain decomposition method and low-rank corrections. The domain decomposition\napproach decouples the matrix and once inverted, a low-rank approximation is\napplied by exploiting the Sherman-Morrison-Woodbury formula, which yields two\nvariants of the preconditioning methods. The low-rank expansion is computed by\nthe Lanczos procedure with reorthogonalizations. Numerical experiments indicate\nthat, when combined with Krylov subspace accelerators, this preconditioner can\nbe efficient and robust for solving symmetric sparse linear systems.\nComparisons with other distributed-memory preconditioning methods are\npresented.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2015 23:56:32 GMT"}, {"version": "v2", "created": "Fri, 29 May 2015 20:46:40 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Li", "Ruipeng", ""], ["Saad", "Yousef", ""]]}, {"id": "1505.04515", "submitter": "Vishwas Rao", "authors": "Vishwas Rao and Adrian Sandu", "title": "A Time-parallel Approach to Strong-constraint Four-dimensional\n  Variational Data Assimilation", "comments": "22 Pages", "journal-ref": null, "doi": "10.1016/j.jcp.2016.02.040", "report-no": "CSL TR-18-2015", "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parallel-in-time algorithm based on an augmented Lagrangian approach is\nproposed to solve four-dimensional variational (4D-Var) data assimilation\nproblems. The assimilation window is divided into multiple sub-intervals that\nallows to parallelize cost function and gradient computations. Solution\ncontinuity equations across interval boundaries are added as constraints. The\naugmented Lagrangian approach leads to a different formulation of the\nvariational data assimilation problem than weakly constrained 4D-Var. A\ncombination of serial and parallel 4D-Vars to increase performance is also\nexplored. The methodology is illustrated on data assimilation problems with\nLorenz-96 and the shallow water models.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 05:33:50 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Rao", "Vishwas", ""], ["Sandu", "Adrian", ""]]}, {"id": "1505.04724", "submitter": "Vishwas Rao", "authors": "Ahmed Attia and Vishwas Rao and Adrian Sandu", "title": "A Hybrid Monte-Carlo Sampling Smoother for Four Dimensional Data\n  Assimilation", "comments": "33 Pages", "journal-ref": null, "doi": null, "report-no": "CSL-TR-19-2015", "categories": "cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper constructs an ensemble-based sampling smoother for\nfour-dimensional data assimilation using a Hybrid/Hamiltonian Monte-Carlo\napproach. The smoother samples efficiently from the posterior probability\ndensity of the solution at the initial time. Unlike the well-known ensemble\nKalman smoother, which is optimal only in the linear Gaussian case, the\nproposed methodology naturally accommodates non-Gaussian errors and non-linear\nmodel dynamics and observation operators. Unlike the four-dimensional\nvariational met\\-hod, which only finds a mode of the posterior distribution,\nthe smoother provides an estimate of the posterior uncertainty. One can use the\nensemble mean as the minimum variance estimate of the state, or can use the\nensemble in conjunction with the variational approach to estimate the\nbackground errors for subsequent assimilation windows. Numerical results\ndemonstrate the advantages of the proposed method compared to the traditional\nvariational and ensemble-based smoothing methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 17:15:49 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Attia", "Ahmed", ""], ["Rao", "Vishwas", ""], ["Sandu", "Adrian", ""]]}, {"id": "1505.05571", "submitter": "Radford M. Neal", "authors": "Radford M. Neal", "title": "Fast exact summation using small and large superaccumulators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I present two new methods for exactly summing a set of floating-point\nnumbers, and then correctly rounding to the nearest floating-point number.\nHigher accuracy than simple summation (rounding after each addition) is\nimportant in many applications, such as finding the sample mean of data. Exact\nsummation also guarantees identical results with parallel and serial\nimplementations, since the exact sum is independent of order. The new methods\nuse variations on the concept of a \"superaccumulator\" - a large fixed-point\nnumber that can exactly represent the sum of any reasonable number of\nfloating-point values. One method uses a \"small\" superaccumulator with\nsixty-seven 64-bit chunks, each with 32-bit overlap with the next chunk,\nallowing carry propagation to be done infrequently. The small superaccumulator\nis used alone when summing a small number of terms. For big summations, a\n\"large\" superaccumulator is used as well. It consists of 4096 64-bit chunks,\none for every possible combination of exponent bits and sign bit, plus counts\nof when each chunk needs to be transferred to the small superaccumulator. To\nadd a term to the large superaccumulator, only a single chunk and its\nassociated count need to be updated, which takes very few instructions if\ncarefully implemented. On modern 64-bit processors, exactly summing a large\narray using this combination of large and small superaccumulators takes less\nthan twice the time of simple, inexact, ordered summation, with a serial\nimplementation. A parallel implementation using a small number of processor\ncores can be expected to perform exact summation of large arrays at a speed\nthat reaches the limit imposed by memory bandwidth. Some common methods that\nattempt to improve accuracy without being exact may therefore be pointless, at\nleast for large summations, since they are slower than computing the sum\nexactly.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 01:17:04 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Neal", "Radford M.", ""]]}, {"id": "1505.05840", "submitter": "Bibek Kabi", "authors": "Tapan Pradhan, Aurobinda Routray, Bibek Kabi", "title": "Comparative Evaluation of Symmetric SVD Algorithms for Real-time Face\n  and Eye Tracking", "comments": "20 pages, 4 figures, book chapter", "journal-ref": "Springer Berlin Heidelberg. (2013) 323-340", "doi": "10.1007/978-3-642-30232-9_13", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation of singular value decomposition (SVD) has been a topic of concern\nby many numerical linear algebra researchers. Fast SVD has been a very\neffective tool in computer vision in a number of aspects, such as: face\nrecognition, eye tracking etc. At the present state of the art fast and\nfixed-point power efficient SVD algorithm needs to be developed for real-time\nembedded computing. The work in this paper is the genesis of an attempt to\nbuild an on-board real-time face and eye tracking system for human drivers to\ndetect loss of attention due to drowsiness or fatigue. A major function of this\non-board system is quick customization. This is carried out when a new driver\ncomes in. The face and eye images are recorded while instructing the driver for\nmaking specific poses. The eigen faces and eigen eyes are generated at several\nresolution levels and stored in the on-board computer. The discriminating eigen\nspace of face and eyes are determined and stored in the on-board flash memory\nfor detection and tracking of face and eyes and classification of eyes (open or\nclosed) as well. Therefore, fast SVD of image covariance matrix at various\nlevels of resolution needs to be carried out to generate the eigen database. As\na preliminary step, we review the existing symmetric SVD algorithms and\nevaluate their feasibility for such an application. In this article, we compare\nthe performance of (1) Jacobi's, (2) Hestenes', (3) Golub-Kahan, (4)\nTridiagonalization and Symmetric QR iteration and (5) Tridiagonalization and\nDivide and Conquer algorithms. A case study has been demonstrated as an\nexample.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 18:57:10 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Pradhan", "Tapan", ""], ["Routray", "Aurobinda", ""], ["Kabi", "Bibek", ""]]}, {"id": "1505.06052", "submitter": "Yu Du Doc.", "authors": "Yu Du and Haijun Wu", "title": "A pure source transfer domain decomposition method for Helmholtz\n  equations in unbounded domain", "comments": "31 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a pure source transfer domain decomposition method (PSTDDM) for\nsolving the truncated perfectly matched layer (PML) approximation in bounded\ndomain of Helmholtz scattering problem. The method is a modification of the\nSTDDM proposed by [Z. Chen and X. Xiang, SIAM J. Numer. Anal., 51 (2013), pp.\n2331--2356]. After decomposing the domain into $N$ non-overlapping layers, the\nSTDDM is composed of two series steps of sources transfers and wave expansions,\nwhere $N-1$ truncated PML problems on two adjacent layers and $N-2$ truncated\nhalf-space PML problems are solved successively. While the PSTDDM consists\nmerely of two parallel source transfer steps in two opposite directions, and in\neach step $N-1$ truncated PML problems on two adjacent layers are solved\nsuccessively. One benefit of such a modification is that the truncated PML\nproblems on two adjacent layers can be further solved by the PSTDDM along\ndirections parallel to the layers. And therefore, we obtain a block-wise PSTDDM\non the decomposition composed of $N^2$ squares, which reduces the size of\nsubdomain problems and is more suitable for large-scale problems. Convergences\nof both the layer-wise PSTDDM and the block-wise PSTDDM are proved for the case\nof constant wave number. Numerical examples are included to show that the\nPSTDDM gives good approximations to the discrete Helmholtz equations with\nconstant wave numbers and can be used as an efficient preconditioner in the\npreconditioned GMRES method for solving the discrete Helmholtz equations with\nconstant and heterogeneous wave numbers.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2015 12:50:18 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 04:22:44 GMT"}, {"version": "v3", "created": "Sun, 11 Dec 2016 08:09:50 GMT"}, {"version": "v4", "created": "Fri, 5 Jul 2019 02:36:42 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Du", "Yu", ""], ["Wu", "Haijun", ""]]}, {"id": "1505.06151", "submitter": "Cezar Doca", "authors": "Cezar Doca, and Constantin Paunoiu", "title": "Automatic Detection of the Common and Non-common Frequencies in\n  Congruent Discrete Spectra. A Theoretical Approach", "comments": "7 Pages; 10 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both sampling a time-varying signal, and its spectral analysis are activities\nsubjected to theoretically compelling, such as Shannon's theorem and the\nobjectively limiting of the frequency's resolution. Usually, the signals'\nspectra are processed and interpreted by a scientist who, presumably, has\nsufficient prior information about the monitored signals to conclude on the\nsignificant frequencies, for example. On the other hand, processing and\ninterpretation of signals' spectra can be routine tasks that must be automated\nusing suitable software, i.e. PC application. In the above context, the paper\npresents the theoretic bases of an intuitive and practical approach of the\n(automatic) detection of the common and non-common frequencies in two or more\ncongruent spectra.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2015 17:10:52 GMT"}], "update_date": "2015-05-25", "authors_parsed": [["Doca", "Cezar", ""], ["Paunoiu", "Constantin", ""]]}, {"id": "1505.06195", "submitter": "Dishi Liu", "authors": "Dishi Liu and Hermann G. Matthies", "title": "Pivoted Cholesky decomposition by Cross Approximation for efficient\n  solution of kernel systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large kernel systems are prone to be ill-conditioned. Pivoted Cholesky\ndecomposition (PCD) render a stable and efficient solution to the systems\nwithout a perturbation of regularization. This paper proposes a new PCD\nalgorithm by tuning Cross Approximation (CA) algorithm to kernel matrices which\nmerges the merits of PCD and CA, and proves as well as numerically exemplifies\nthat it solves large kernel systems two-order more efficiently than those\nresorts to regularization. As a by-product, a diagonal-pivoted CA technique is\nalso shown efficient in eigen-decomposition of large covariance matrices in an\nuncertainty quantification problem.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 13:11:13 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2015 13:58:52 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2015 14:35:44 GMT"}, {"version": "v4", "created": "Fri, 26 Apr 2019 11:29:45 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Liu", "Dishi", ""], ["Matthies", "Hermann G.", ""]]}, {"id": "1505.06582", "submitter": "Shin Harase", "authors": "Shin Harase and Takamitsu Kimoto", "title": "Implementing 64-bit Maximally Equidistributed $\\mathbb{F}_2$-Linear\n  Generators with Mersenne Prime Period", "comments": "11 Pages", "journal-ref": "ACM Transactions on Mathematical Software, Volume 44, Issue 3,\n  April 2018, Article No. 30, 11 Pages", "doi": "10.1145/3159444", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CPUs and operating systems are moving from 32 to 64 bits, and hence it is\nimportant to have good pseudorandom number generators designed to fully exploit\nthese word lengths. However, existing 64-bit very long period generators based\non linear recurrences modulo 2 are not completely optimized in terms of the\nequidistribution properties. Here we develop 64-bit maximally equidistributed\npseudorandom number generators that are optimal in this respect and have speeds\nequivalent to 64-bit Mersenne Twisters. We provide a table of specific\nparameters with period lengths from $2^{607}-1$ to $2^{44497}-1$. (An online\nappendix is available at http://www.ritsumei.ac.jp/~harase/melg-64-app.pdf)\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 09:54:00 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 15:55:44 GMT"}, {"version": "v3", "created": "Mon, 3 Oct 2016 08:59:02 GMT"}, {"version": "v4", "created": "Tue, 4 Oct 2016 12:14:08 GMT"}, {"version": "v5", "created": "Mon, 27 Mar 2017 16:43:37 GMT"}, {"version": "v6", "created": "Mon, 20 Nov 2017 09:34:25 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Harase", "Shin", ""], ["Kimoto", "Takamitsu", ""]]}, {"id": "1505.06699", "submitter": "Hao Zhuang", "authors": "Hao Zhuang, Wenjian Yu, Shih-Hung Weng, Ilgweon Kang, Jeng-Hau Lin,\n  Xiang Zhang, Ryan Coutts, Chung-Kuan Cheng", "title": "Simulation Algorithms with Exponential Integration for Time-Domain\n  Analysis of Large-Scale Power Delivery Networks", "comments": "Accepted by IEEE Transactions on Computer Aided Design of Integrated\n  Circuits and Systems (TCAD)", "journal-ref": null, "doi": "10.1109/TCAD.2016.2523908", "report-no": null, "categories": "cs.CE cs.DC cs.NA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design an algorithmic framework using matrix exponentials for time-domain\nsimulation of power delivery network (PDN). Our framework can reuse factorized\nmatrices to simulate the large-scale linear PDN system with variable stepsizes.\nIn contrast, current conventional PDN simulation solvers have to use fixed\nstep-size approach in order to reuse factorized matrices generated by the\nexpensive matrix decomposition. Based on the proposed exponential integration\nframework, we design a PDN solver R-MATEX with the flexible time-stepping\ncapability. The key operation of matrix exponential and vector product (MEVP)\nis computed by the rational Krylov subspace method.\n  To further improve the runtime, we also propose a distributed computing\nframework DR-MATEX. DR-MATEX reduces Krylov subspace generations caused by\nfrequent breakpoints from a large number of current sources during simulation.\nBy virtue of the superposition property of linear system and scaling invariance\nproperty of Krylov subspace, DR-MATEX can divide the whole simulation task into\nsubtasks based on the alignments of breakpoints among those sources. The\nsubtasks are processed in parallel at different computing nodes without any\ncommunication during the computation of transient simulation. The final result\nis obtained by summing up the partial results among all the computing nodes\nafter they finish the assigned subtasks. Therefore, our computation model\nbelongs to the category known as Embarrassingly Parallel model.\n  Experimental results show R-MATEX and DR-MATEX can achieve up to around 14.4X\nand 98.0X runtime speedups over traditional trapezoidal integration based\nsolver with fixed timestep approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 17:39:17 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 06:28:51 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2016 04:54:09 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zhuang", "Hao", ""], ["Yu", "Wenjian", ""], ["Weng", "Shih-Hung", ""], ["Kang", "Ilgweon", ""], ["Lin", "Jeng-Hau", ""], ["Zhang", "Xiang", ""], ["Coutts", "Ryan", ""], ["Cheng", "Chung-Kuan", ""]]}, {"id": "1505.06957", "submitter": "Nicolas Gillis", "authors": "Gabriella Casalino, Nicolas Gillis", "title": "Sequential Dimensionality Reduction for Extracting Localized Features", "comments": "24 pages, 12 figures. New numerical experiments on synthetic data\n  sets, discussion about the convergence", "journal-ref": "Pattern Recoginition 63, pp. 15-29, 2017", "doi": "10.1016/j.patcog.2016.09.006", "report-no": null, "categories": "cs.CV cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear dimensionality reduction techniques are powerful tools for image\nanalysis as they allow the identification of important features in a data set.\nIn particular, nonnegative matrix factorization (NMF) has become very popular\nas it is able to extract sparse, localized and easily interpretable features by\nimposing an additive combination of nonnegative basis elements. Nonnegative\nmatrix underapproximation (NMU) is a closely related technique that has the\nadvantage to identify features sequentially. In this paper, we propose a\nvariant of NMU that is particularly well suited for image analysis as it\nincorporates the spatial information, that is, it takes into account the fact\nthat neighboring pixels are more likely to be contained in the same features,\nand favors the extraction of localized features by looking for sparse basis\nelements. We show that our new approach competes favorably with comparable\nstate-of-the-art techniques on synthetic, facial and hyperspectral image data\nsets.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 14:06:16 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2016 06:44:58 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Casalino", "Gabriella", ""], ["Gillis", "Nicolas", ""]]}, {"id": "1505.07519", "submitter": "Oliver Serang", "authors": "Julianus Pfeuffer and Oliver Serang", "title": "A Bounded $p$-norm Approximation of Max-Convolution for Sub-Quadratic\n  Bayesian Inference on Additive Factors", "comments": null, "journal-ref": "Journal of Machine Learning Research 17 (2016) 1-39", "doi": null, "report-no": null, "categories": "stat.CO cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-convolution is an important problem closely resembling standard\nconvolution; as such, max-convolution occurs frequently across many fields.\nHere we extend the method with fastest known worst-case runtime, which can be\napplied to nonnegative vectors by numerically approximating the Chebyshev norm\n$\\| \\cdot \\|_\\infty$, and use this approach to derive two numerically stable\nmethods based on the idea of computing $p$-norms via fast convolution: The\nfirst method proposed, with runtime in $O( k \\log(k) \\log(\\log(k)) )$ (which is\nless than $18 k \\log(k)$ for any vectors that can be practically realized),\nuses the $p$-norm as a direct approximation of the Chebyshev norm. The second\napproach proposed, with runtime in $O( k \\log(k) )$ (although in practice both\nperform similarly), uses a novel null space projection method, which extracts\ninformation from a sequence of $p$-norms to estimate the maximum value in the\nvector (this is equivalent to querying a small number of moments from a\ndistribution of bounded support in order to estimate the maximum). The $p$-norm\napproaches are compared to one another and are shown to compute an\napproximation of the Viterbi path in a hidden Markov model where the transition\nmatrix is a Toeplitz matrix; the runtime of approximating the Viterbi path is\nthus reduced from $O( n k^2 )$ steps to $O( n $k \\log(k))$ steps in practice,\nand is demonstrated by inferring the U.S. unemployment rate from the S&P 500\nstock index.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 01:03:29 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 00:18:21 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Pfeuffer", "Julianus", ""], ["Serang", "Oliver", ""]]}, {"id": "1505.07529", "submitter": "Yuanxun Bao", "authors": "Yuanxun Bao, Alexander D. Kaiser, Jason Kaye, Charles S. Peskin", "title": "Gaussian-Like Immersed Boundary Kernels with Three Continuous\n  Derivatives and Improved Translational Invariance", "comments": "10 pages, 4 figures. This is an updated manuscript to the published\n  version with a new 5-point kernel", "journal-ref": null, "doi": "10.1016/j.jcp.2016.04.024", "report-no": null, "categories": "math.NA cs.NA physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The immersed boundary (IB) method is a general mathematical framework for\nstudying problems involving fluid-structure interactions in which an elastic\nstructure is immersed in a viscous incompressible fluid. In the IB formulation,\nthe fluid described by Eulerian variables is coupled with the immersed\nstructure described by Lagrangian variables via the use of the Dirac delta\nfunction. From a numerical standpoint, the Lagrangian force spreading and the\nEulerian velocity interpolation are carried out by a regularized, compactly\nsupported discrete delta function, which is assumed to be a tensor product of a\nsingle-variable immersed-boundary kernel. IB kernels are derived from a set of\npostulates designed to achieve approximate grid translational invariance,\ninterpolation accuracy and computational efficiency. In this note, we present\nnew 5-point and 6-point immersed-boundary kernels that are $\\mathscr{C}^3$ and\nyield a substantially improved translational invariance compared to other\ncommon IB kernels.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 02:18:36 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 21:06:53 GMT"}, {"version": "v3", "created": "Thu, 6 Apr 2017 21:37:02 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 18:16:26 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Bao", "Yuanxun", ""], ["Kaiser", "Alexander D.", ""], ["Kaye", "Jason", ""], ["Peskin", "Charles S.", ""]]}, {"id": "1505.07589", "submitter": "Paul Liu", "authors": "Chen Greif, Shiwen He, Paul Liu", "title": "SYM-ILDL: Incomplete $LDL^{T}$ Factorization of Symmetric Indefinite and\n  Skew-Symmetric Matrices", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SYM-ILDL is a numerical software package that computes incomplete $LDL^{T}$\n(or `ILDL') factorizations of symmetric indefinite and real skew-symmetric\nmatrices. The core of the algorithm is a Crout variant of incomplete LU (ILU),\noriginally introduced and implemented for symmetric matrices by [Li and Saad,\nCrout versions of ILU factorization with pivoting for sparse symmetric\nmatrices, Transactions on Numerical Analysis 20, pp. 75--85, 2005]. Our code is\neconomical in terms of storage and it deals with real skew-symmetric matrices\nas well, in addition to symmetric ones. The package is written in C++ and it is\ntemplated, open source, and includes a MATLAB interface. The code includes\nbuilt-in RCM and AMD reordering, two equilibration strategies, threshold\nBunch-Kaufman pivoting and rook pivoting, as well as a wrapper to MC64, a\npopular matching based equilibration and reordering algorithm. We also include\ntwo built-in iterative solvers: SQMR preconditioned with ILDL, or MINRES\npreconditioned with a symmetric positive definite preconditioner based on the\nILDL factorization.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 08:25:45 GMT"}, {"version": "v2", "created": "Fri, 25 Mar 2016 00:19:02 GMT"}, {"version": "v3", "created": "Tue, 1 Nov 2016 23:54:16 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Greif", "Chen", ""], ["He", "Shiwen", ""], ["Liu", "Paul", ""]]}, {"id": "1505.07676", "submitter": "Artiom Kovnatsky Artiom Kovnatsky", "authors": "Artiom Kovnatsky, Klaus Glashoff, and Michael M. Bronstein", "title": "MADMM: a generic algorithm for non-smooth optimization on manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous problems in machine learning are formulated as optimization with\nmanifold constraints. In this paper, we propose the Manifold alternating\ndirections method of multipliers (MADMM), an extension of the classical ADMM\nscheme for manifold-constrained non-smooth optimization problems and show its\napplication to several challenging problems in dimensionality reduction, data\nanalysis, and manifold learning.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 12:44:25 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Kovnatsky", "Artiom", ""], ["Glashoff", "Klaus", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "1505.08115", "submitter": "Per-Gunnar Martinsson", "authors": "P.G. Martinsson", "title": "Blocked rank-revealing QR factorizations: How randomized sampling can be\n  used to avoid single-vector pivoting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a matrix $A$ of size $m\\times n$, the manuscript describes a algorithm\nfor computing a QR factorization $AP=QR$ where $P$ is a permutation matrix, $Q$\nis orthonormal, and $R$ is upper triangular. The algorithm is blocked, to allow\nit to be implemented efficiently. The need for single vector pivoting in\nclassical algorithms for computing QR factorizations is avoided by the use of\nrandomized sampling to find blocks of pivot vectors at once. The advantage of\nblocking becomes particularly pronounced when $A$ is very large, and possibly\nstored out-of-core, or on a distributed memory machine. The manuscript also\ndescribes a generalization of the QR factorization that allows $P$ to be a\ngeneral orthonormal matrix. In this setting, one can at moderate cost compute a\n\\textit{rank-revealing} factorization where the mass of $R$ is concentrated to\nthe diagonal entries. Moreover, the diagonal entries of $R$ closely approximate\nthe singular values of $A$. The algorithms described have asymptotic flop count\n$O(m\\,n\\,\\min(m,n))$, just like classical deterministic methods. The scaling\nconstant is slightly higher than those of classical techniques, but this is\nmore than made up for by reduced communication and the ability to block the\ncomputation.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 17:31:35 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Martinsson", "P. G.", ""]]}]