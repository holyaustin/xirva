[{"id": "1612.00530", "submitter": "Jun Makino", "authors": "Naoki Yoshifuji, Ryo Sakamoto, Keigo Nitadori and Jun Makino", "title": "Implementation and evaluation of data-compression algorithms for\n  irregular-grid iterative methods on the PEZY-SC processor", "comments": "Talk given at IA3 2016 Sixth Workshop on Irregular Applications:\n  Architectures and Algorithms http://hpc.pnl.gov/IA3/IA3/Program.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative methods on irregular grids have been used widely in all areas of\ncomptational science and engineering for solving partial differential equations\nwith complex geometry. They provide the flexibility to express complex shapes\nwith relatively low computational cost. However, the direction of the evolution\nof high-performance processors in the last two decades have caused serious\ndegradation of the computational efficiency of iterative methods on irregular\ngrids, because of relatively low memory bandwidth. Data compression can in\nprinciple reduce the necessary memory memory bandwidth of iterative methods and\nthus improve the efficiency. We have implemented several data compression\nalgorithms on the PEZY-SC processor, using the matrix generated for the HPCG\nbenchmark as an example. For the SpMV (Sparse Matrix-Vector multiplication)\npart of the HPCG benchmark, the best implementation without data compression\nachieved 11.6Gflops/chip, close to the theoretical limit due to the memory\nbandwidth. Our implementation with data compression has achieved 32.4Gflops.\nThis is of course rather extreme case, since the grid used in HPCG is\ngeometrically regular and thus its compression efficiency is very high.\nHowever, in real applications, it is in many cases possible to make a large\npart of the grid to have regular geometry, in particular when the resolution is\nhigh. Note that we do not need to change the structure of the program, except\nfor the addition of the data compression/decompression subroutines. Thus, we\nbelieve the data compression will be very useful way to improve the performance\nof many applications which rely on the use of irregular grids.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 01:09:23 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Yoshifuji", "Naoki", ""], ["Sakamoto", "Ryo", ""], ["Nitadori", "Keigo", ""], ["Makino", "Jun", ""]]}, {"id": "1612.01410", "submitter": "Francesco Fambri Dr", "authors": "Francesco Fambri, Michael Dumbser and Olindo Zanotti", "title": "Space-time adaptive ADER-DG schemes for dissipative flows: compressible\n  Navier-Stokes and resistive MHD equations", "comments": "33 pages, 17 figures", "journal-ref": null, "doi": "10.1016/j.cpc.2017.08.001", "report-no": null, "categories": "math.NA astro-ph.IM cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an arbitrary h.o. accurate ADER DG method on space-time\nadaptive meshes (AMR) for the solution of two important families of non-linear\ntime dependent PDE for compr. dissipative flows: the compr. Navier-Stokes\nequations and the equations of visc. and res. MHD in 2 and 3 space-dimensions.\nThe work continues a recent series of papers concerning the development and\napplication of a proper a posteriori subcell FV limiting procedure suitable for\nDG methods. It is a well known fact that a major weakness of h.o. DG methods\nlies in the difficulty of limiting discontinuous solutions, which generate\nspurious oscillations, namely the so-called 'Gibbs phenomenon'. In the present\nwork the main benefits of the MOOD paradigm, i.e. the computational robustness\neven in the presence of strong shocks, are preserved and the numerical\ndiffusion is considerably reduced also for the limited cells by resorting to a\nproper sub-grid. An important feature of our new scheme is its ability to cure\neven floating point errors that may occur during a simulation, for example when\ntaking real roots of negative numbers or after divisions by zero. We apply the\nwhole approach for the first time to the equations of compr. gas dynamics and\nMHD in the presence of viscosity, thermal conductivity and magnetic\nresistivity, therefore extending our family of adaptive ADER-DG schemes to\ncases for which the numerical fluxes also depend on the gradient of the state\nvector. The distinguished high-resolution properties of the presented numerical\nscheme stands out against a wide number of non-trivial test cases both for the\ncompr. Navier-Stokes and the viscous and resistive MHD equations. The present\nresults show clearly that the shock-capturing capability of the news schemes\nare significantly enhanced within a cell-by-cell Adaptive Mesh Refinement\nimplementation together with time accurate local time stepping (LTS).\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 15:57:20 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 20:10:45 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Fambri", "Francesco", ""], ["Dumbser", "Michael", ""], ["Zanotti", "Olindo", ""]]}, {"id": "1612.01597", "submitter": "Morteza Ashraphijuo", "authors": "Morteza Ashraphijuo and Vaneet Aggarwal and Xiaodong Wang", "title": "Deterministic and Probabilistic Conditions for Finite Completability of\n  Low-Tucker-Rank Tensor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the fundamental conditions on the sampling pattern, i.e.,\nlocations of the sampled entries, for finite completability of a low-rank\ntensor given some components of its Tucker rank. In order to find the\ndeterministic necessary and sufficient conditions, we propose an algebraic\ngeometric analysis on the Tucker manifold, which allows us to incorporate\nmultiple rank components in the proposed analysis in contrast with the\nconventional geometric approaches on the Grassmannian manifold. This analysis\ncharacterizes the algebraic independence of a set of polynomials defined based\non the sampling pattern, which is closely related to finite completion.\nProbabilistic conditions are then studied and a lower bound on the sampling\nprobability is given, which guarantees that the proposed deterministic\nconditions on the sampling patterns for finite completability hold with high\nprobability. Furthermore, using the proposed geometric approach for finite\ncompletability, we propose a sufficient condition on the sampling pattern that\nensures there exists exactly one completion for the sampled tensor.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 00:08:09 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 14:31:39 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 20:26:52 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Ashraphijuo", "Morteza", ""], ["Aggarwal", "Vaneet", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1612.02153", "submitter": "Erivelton Geraldo Nepomuceno", "authors": "B. C. Silva, F. L. Milani, E. G. Nepomuceno, S. A. M. Martins, G. F.\n  V. Amaral", "title": "Revisiting Hammel et al. (1987): Does the shadowing property hold for\n  modern computers?", "comments": "6th NSC - International Conference on Nonlinear Science and\n  Complexity, NSC, S\\~ao Jos\\'e dos Campos, Brazil, p.1-4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational techniques are extensively applied in nonlinear science.\nHowever, while the use of computers for research has been expressive, the\nevaluation of numerical results does not grow in the same pace. Hammel et al.\n(Journal of Complexity, 1987, 3(2), 136--145) were pioneers in the numerical\nreliability field and have proved a theorem that a pseudo-orbit of a logistic\nmap is shadowed by a true orbit within a distance of $10^{-8}$ for $10^{7}$\niterates. But the simulation of the logistic map with less than 100 iterates\npresents an error greater than $10^{-8}$ in a modern computer, performing a\ntest based on the concept of multiple pseudo-orbits and symbolic computing.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 08:53:49 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Silva", "B. C.", ""], ["Milani", "F. L.", ""], ["Nepomuceno", "E. G.", ""], ["Martins", "S. A. M.", ""], ["Amaral", "G. F. V.", ""]]}, {"id": "1612.02397", "submitter": "Gabriel Monz\\'on", "authors": "Gabriel Monz\\'on", "title": "Anisotropic interpolation error estimate for arbitrary quadrilateral\n  isoparametric elements", "comments": "The final publication is available at link.springer.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to show that, for any $p \\in [1,\\infty)$, the\n$W^{1,p}$-anisotropic interpolation error estimate holds on quadrilateral\nisoparametric elements verifying the maximum angle condition ($MAC$) and the\nproperty of comparable lengths for opposite sides ($clos$), i.e., on all those\nquadrilaterals with interior angles uniformly bounded away from $\\pi$ and with\nboth pairs of opposite sides having comparable lengths.\n  For rectangular elements our interpolation error estimate agrees with the\nusual one whereas for perturbations of rectangles (the most general\nquadrilateral elements previously considered as far as we know) our result has\nsome advantages with respect to the pre-existing ones: the interpolation error\nestimate that we proved is written by using two neighboring sides of the\nelement instead of the sides of the unknown perturbed rectangle and, on the\nother hand, conditions $MAC$ and $clos$ are much simpler requirements to verify\nand with a clearer geometrical sense than those involved in the definition of\nperturbations of a rectangle.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 20:12:20 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2017 13:21:22 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 15:44:07 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Monz\u00f3n", "Gabriel", ""]]}, {"id": "1612.02561", "submitter": "Christoph Lehrenfeld", "authors": "Christoph Lehrenfeld", "title": "A Higher Order Isoparametric Fictitious Domain Method for Level Set\n  Domains", "comments": "27 pages, 8 figures. (v2 of this paper is an accidental copy of\n  arXiv:1602.02970v2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a new fictitious domain approach of higher order accuracy. To\nimplement Dirichlet conditions we apply the classical Nitsche method combined\nwith a facet-based stabilization (ghost penalty). Both techniques are combined\nwith a higher order isoparametric finite element space which is based on a\nspecial mesh transformation. The mesh transformation is build upon a higher\norder accurate level set representation and allows to reduce the problem of\nnumerical integration to problems on domains which are described by piecewise\nlinear level set functions. The combination of this strategy for the numerical\nintegration and the stabilized Nitsche formulation results in an accurate and\nrobust method. We introduce and analyze it and give numerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 08:36:43 GMT"}, {"version": "v2", "created": "Fri, 3 Feb 2017 14:49:47 GMT"}, {"version": "v3", "created": "Tue, 21 Feb 2017 18:03:18 GMT"}, {"version": "v4", "created": "Thu, 23 Feb 2017 14:25:25 GMT"}, {"version": "v5", "created": "Mon, 3 Jul 2017 06:42:23 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Lehrenfeld", "Christoph", ""]]}, {"id": "1612.03247", "submitter": "Salah Hamim", "authors": "Salah U. Hamim", "title": "Parameter Estimation of a Nonlinear Burgers Model using Nanoindentation\n  and Finite Element-based Inverse Analysis", "comments": "PhD Dissertation, Oklahoma State University, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nanoindentation involves probing a hard diamond tip into a material, where\nthe load and the displacement experienced by the tip is recorded continuously.\nThis load-displacement data is a direct function of material's innate\nstress-strain behavior. Thus, theoretically it is possible to extract\nmechanical properties of a material through nanoindentation. However, due to\nvarious nonlinearities associated with nanoindentation the process of\ninterpreting load-displacement data into material properties is difficult.\nAlthough, simple elastic behavior can be characterized easily, a method to\ncharacterize complicated material behavior such as nonlinear viscoelasticity is\nstill lacking. In this study, a nanoindentation-based material characterization\ntechnique is developed to characterize soft materials exhibiting nonlinear\nviscoelasticity. Nanoindentation experiment was modeled in finite element\nanalysis software (ABAQUS), where a nonlinear viscoelastic behavior was\nincorporated using user-defined subroutine (UMAT). The model parameters were\ncalibrated using a process called inverse analysis. In this study, a surrogate\nmodel-based approach was used for the inverse analysis. The different factors\naffecting the surrogate model performance are analyzed in order to optimize the\nperformance with respect to the computational cost.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 03:39:20 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Hamim", "Salah U.", ""]]}, {"id": "1612.04464", "submitter": "Ben Adcock", "authors": "Ben Adcock and Daan Huybrechs", "title": "Frames and numerical approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functions of one or more variables are usually approximated with a basis: a\ncomplete, linearly-independent system of functions that spans a suitable\nfunction space. The topic of this paper is the numerical approximation of\nfunctions using the more general notion of frames: that is, complete systems\nthat are generally redundant but provide infinite representations with bounded\ncoefficients. While frames are well-known in image and signal processing,\ncoding theory and other areas of applied mathematics, their use in numerical\nanalysis is far less widespread. Yet, as we show via a series of examples,\nframes are more flexible than bases, and can be constructed easily in a range\nof problems where finding orthonormal bases with desirable properties (rapid\nconvergence, high resolution power, etc.) is difficult or impossible.\n  A key concern when using frames is that computing a best approximation\nrequires solving an ill-conditioned linear system. Nonetheless, we construct a\nframe approximation via regularization with bounded condition number (with\nrespect to perturbations in the data), and which approximates any function up\nto an error of order $\\sqrt{\\epsilon}$, or even of order $\\epsilon$ with\nsuitable modifications. Here $\\epsilon$ is a threshold value that can be chosen\nby the user. Crucially, rate of decay of the error down to this level is\ndetermined by the existence of approximate representations of $f$ in the frame\npossessing small-norm coefficients. We demonstrate the existence of such\nrepresentations in all of our examples. Overall, our analysis suggests that\nframes are a natural generalization of bases in which to develop numerical\napproximation. In particular, even in the presence of severely ill-conditioned\nlinear systems, the frame condition imposes sufficient mathematical structure\nin order to give rise to accurate, well-conditioned approximations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 02:49:06 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 21:36:37 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 21:16:34 GMT"}, {"version": "v4", "created": "Mon, 5 Nov 2018 23:21:35 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Adcock", "Ben", ""], ["Huybrechs", "Daan", ""]]}, {"id": "1612.04542", "submitter": "Luc Le", "authors": "Luc Le Magoarou (PANAMA), R\\'emi Gribonval (PANAMA), Nicolas Tremblay\n  (Phys-ENS, GIPSA-CICS)", "title": "Approximate fast graph Fourier transforms via multi-layer sparse\n  approximations", "comments": null, "journal-ref": "IEEE transactions on Signal and Information Processing over\n  Networks, IEEE, pp.15 (2017)", "doi": "10.1109/TSIPN.2017.2710619", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fast Fourier Transform (FFT) is an algorithm of paramount importance in\nsignal processing as it allows to apply the Fourier transform in O(n log n)\ninstead of O(n 2) arithmetic operations. Graph Signal Processing (GSP) is a\nrecent research domain that generalizes classical signal processing tools, such\nas the Fourier transform, to situations where the signal domain is given by any\narbitrary graph instead of a regular grid. Today, there is no method to rapidly\napply graph Fourier transforms. We propose in this paper a method to obtain\napproximate graph Fourier transforms that can be applied rapidly and stored\nefficiently. It is based on a greedy approximate diagonalization of the graph\nLaplacian matrix, carried out using a modified version of the famous Jacobi\neigenvalues algorithm. The method is described and analyzed in detail, and then\napplied to both synthetic and real graphs, showing its potential.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 09:09:16 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 13:09:14 GMT"}, {"version": "v3", "created": "Fri, 16 Jun 2017 09:51:55 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Magoarou", "Luc Le", "", "PANAMA"], ["Gribonval", "R\u00e9mi", "", "PANAMA"], ["Tremblay", "Nicolas", "", "Phys-ENS, GIPSA-CICS"]]}, {"id": "1612.04694", "submitter": "Mojmir Mutny", "authors": "Mojmir Mutny", "title": "Stochastic Second-Order Optimization via von Neumann Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stochastic iterative algorithm approximating second-order information using\nvon Neumann series is discussed. We present convergence guarantees for\nstrongly-convex and smooth functions. Our analysis is much simpler in contrast\nto a similar algorithm and its analysis, LISSA. The algorithm is primarily\nsuitable for training large scale linear models, where the number of data\npoints is very large. Two novel analyses, one showing space independent linear\nconvergence, and one showing conditional quadratic convergence are discussed.\nIn numerical experiments, the behavior of the error is similar to the\nsecond-order algorithm L-BFGS, and improves the performance of LISSA for\nquadratic objective function.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 15:38:37 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2016 16:46:49 GMT"}, {"version": "v3", "created": "Mon, 13 Mar 2017 09:56:15 GMT"}, {"version": "v4", "created": "Thu, 13 Apr 2017 09:47:48 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Mutny", "Mojmir", ""]]}, {"id": "1612.04796", "submitter": "J\\\"org Stiller", "authors": "Joerg Stiller", "title": "Robust Multigrid for Cartesian Interior Penalty DG Formulations of the\n  Poisson Equation in 3D", "comments": "Submitted to ICOSAHOM 2016 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polynomial multigrid method for the nodal interior penalty\nformulation of the Poisson equation on three-dimensional Cartesian grids. Its\nkey ingredient is a weighted overlapping Schwarz smoother operating on\nelement-centered subdomains. The MG method reaches superior convergence rates\ncorresponding to residual reductions of about two orders of magnitude within a\nsingle V(1,1) cycle. It is robust with respect to the mesh size and the ansatz\norder, at least up to ${P=32}$. Rigorous exploitation of tensor-product\nfactorization yields a computational complexity of $O(PN)$ for $N$ unknowns,\nwhereas numerical experiments indicate even linear runtime scaling. Moreover,\nby allowing adjustable subdomain overlaps and adding Krylov acceleration, the\nmethod proved feasible for anisotropic grids with element aspect ratios up to\n48.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 20:26:33 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Stiller", "Joerg", ""]]}, {"id": "1612.05057", "submitter": "Radu Ioan Bot", "authors": "Sebastian Banert, Radu Ioan Bot, Ern\\\"o Robert Csetnek", "title": "Fixing and extending some recent results on the ADMM algorithm", "comments": "Updates in Section 2 concerning the derivation of the convergence\n  rates + a unifying convergence theorem for the sequence of iterates", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the techniques and ideas used in the convergence analysis of\ntwo proximal ADMM algorithms for solving convex optimization problems involving\ncompositions with linear operators. Besides this, we formulate a variant of the\nADMM algorithm that is able to handle convex optimization problems involving an\nadditional smooth function in its objective, and which is evaluated through its\ngradient. Moreover, in each iteration we allow the use of variable metrics,\nwhile the investigations are carried out in the setting of infinite dimensional\nHilbert spaces. This algorithmic scheme is investigated from the point of view\nof its convergence properties.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 13:33:32 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 14:50:33 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 09:35:51 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Banert", "Sebastian", ""], ["Bot", "Radu Ioan", ""], ["Csetnek", "Ern\u00f6 Robert", ""]]}, {"id": "1612.07526", "submitter": "Shengguo Li", "authors": "Shengguo Li, Francois-Henry Rouet, Jie Liu, Chun Huang, Xingyu Gao and\n  Xuebin Chi", "title": "An efficient hybrid tridiagonal divide-and-conquer algorithm on\n  distributed memory architectures", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an efficient divide-and-conquer (DC) algorithm is proposed for\nthe symmetric tridiagonal matrices based on ScaLAPACK and the hierarchically\nsemiseparable (HSS) matrices. HSS is an important type of rank-structured\nmatrices.Most time of the DC algorithm is cost by computing the eigenvectors\nvia the matrix-matrix multiplications (MMM). In our parallel hybrid DC (PHDC)\nalgorithm, MMM is accelerated by using the HSS matrix techniques when the\nintermediate matrix is large. All the HSS algorithms are done via the package\nSTRUMPACK. PHDC has been tested by using many different matrices. Compared with\nthe DC implementation in MKL, PHDC can be faster for some matrices with few\ndeflations when using hundreds of processes. However, the gains decrease as the\nnumber of processes increases. The comparisons of PHDC with ELPA (the\nEigenvalue soLvers for Petascale Applications library) are similar. PHDC is\nusually slower than MKL and ELPA when using 300 or more processes on Tianhe-2\nsupercomputer.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 10:19:09 GMT"}], "update_date": "2016-12-27", "authors_parsed": [["Li", "Shengguo", ""], ["Rouet", "Francois-Henry", ""], ["Liu", "Jie", ""], ["Huang", "Chun", ""], ["Gao", "Xingyu", ""], ["Chi", "Xuebin", ""]]}, {"id": "1612.07578", "submitter": "Peter Opsomer", "authors": "Daan Huybrechs and Peter Opsomer", "title": "Construction and implementation of asymptotic expansions for\n  Laguerre-type orthogonal polynomials", "comments": "28 pages, 5 figures, 29 references. The article mentioned is\n  arXiv:math/0504604 and the implementation is available on\n  http://nines.cs.kuleuven.be/software/LAGUERRE/", "journal-ref": "Published online in IMA Journal of Numerical Analysis Published by\n  Oxford University Press in July 2017", "doi": "10.1093/imanum/drx030", "report-no": "TW676", "categories": "cs.NA math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laguerre and Laguerre-type polynomials are orthogonal polynomials on the\ninterval $[0,\\infty)$ with respect to a weight function of the form $w(x) =\nx^{\\alpha} e^{-Q(x)}, Q(x) = \\sum_{k=0}^m q_k x^k, \\alpha > -1, q_m > 0$. The\nclassical Laguerre polynomials correspond to $Q(x)=x$. The computation of\nhigher-order terms of the asymptotic expansions of these polynomials for large\ndegree becomes quite complicated, and a full description seems to be lacking in\nliterature. However, this information is implicitly available in the work of\nVanlessen, based on a non-linear steepest descent analysis of an associated\nso-called Riemann--Hilbert problem. We will extend this work and show how to\nefficiently compute an arbitrary number of higher-order terms in the asymptotic\nexpansions of Laguerre and Laguerre-type polynomials. This effort is similar to\nthe case of Jacobi and Jacobi-type polynomials in a previous paper. We supply\nan implementation with explicit expansions in four different regions of the\ncomplex plane. These expansions can also be extended to Hermite-type weights of\nthe form $\\exp(-\\sum_{k=0}^m q_k x^{2k})$ on $(-\\infty,\\infty)$, and to general\nnon-polynomial functions $Q(x)$ using contour integrals. The expansions may be\nused, e.g., to compute Gauss-Laguerre quadrature rules in a lower computational\ncomplexity than based on the recurrence relation, and with improved accuracy\nfor large degree. They are also of interest in random matrix theory.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 12:36:19 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Huybrechs", "Daan", ""], ["Opsomer", "Peter", ""]]}, {"id": "1612.07838", "submitter": "Julie Nutini", "authors": "Julie Nutini, Behrooz Sepehry, Issam Laradji, Mark Schmidt, Hoyt\n  Koepke, and Alim Virani", "title": "Convergence Rates for Greedy Kaczmarz Algorithms, and Faster Randomized\n  Kaczmarz Rules Using the Orthogonality Graph", "comments": null, "journal-ref": "Conference on Uncertainty in Artificial Intelligence 2016", "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kaczmarz method is an iterative algorithm for solving systems of linear\nequalities and inequalities, that iteratively projects onto these constraints.\nRecently, Strohmer and Vershynin [J. Fourier Anal. Appl., 15(2):262-278, 2009]\ngave a non-asymptotic convergence rate analysis for this algorithm, spurring\nnumerous extensions and generalizations of the Kaczmarz method. Rather than the\nrandomized selection rule analyzed in that work, in this paper we instead\ndiscuss greedy and approximate greedy selection rules. We show that in some\napplications the computational costs of greedy and random selection are\ncomparable, and that in many cases greedy selection rules give faster\nconvergence rates than random selection rules. Further, we give the first\nmulti-step analysis of Kaczmarz methods for a particular greedy rule, and\npropose a provably-faster randomized selection rule for matrices with many\npairwise-orthogonal rows.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 23:31:35 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Nutini", "Julie", ""], ["Sepehry", "Behrooz", ""], ["Laradji", "Issam", ""], ["Schmidt", "Mark", ""], ["Koepke", "Hoyt", ""], ["Virani", "Alim", ""]]}, {"id": "1612.07875", "submitter": "Seth Pendergrass", "authors": "Seth D. Pendergrass, J. Nathan Kutz, Steven L. Brunton", "title": "Streaming GPU Singular Value and Dynamic Mode Decompositions", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops a parallelized algorithm to compute the dynamic mode\ndecomposition (DMD) on a graphics processing unit using the streaming method of\nsnapshots singular value decomposition. This allows the algorithm to operate\nefficiently on streaming data by avoiding redundant inner-products as new data\nbecomes available. In addition, it is possible to leverage the native\ncompressed format of many data streams, such as HD video and computational\nphysics codes that are represented sparsely in the Fourier domain, to massively\nreduce data transfer from CPU to GPU and to enable sparse matrix\nmultiplications. Taken together, these algorithms facilitate real-time\nstreaming DMD on high-dimensional data streams. We demonstrate the proposed\nmethod on numerous high-dimensional data sets ranging from video background\nmodeling to scientific computing applications, where DMD is becoming a mainstay\nalgorithm. The computational framework is developed as an open-source library\nwritten in C++ with CUDA, and the algorithms may be generalized to include\nother DMD advances, such as compressed sensing DMD, multi resolution DMD, or\nDMD with control. Keywords: Singular value decomposition, dynamic mode\ndecomposition, streaming computations, graphics processing unit, video\nbackground modeling, scientific computing.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 05:06:25 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Pendergrass", "Seth D.", ""], ["Kutz", "J. Nathan", ""], ["Brunton", "Steven L.", ""]]}, {"id": "1612.08461", "submitter": "Liang Zhang", "authors": "Liang Zhang, Gang Wang, Daniel Romero, Georgios B. Giannakis", "title": "Randomized Block Frank-Wolfe for Convergent Large-Scale Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2017.2755597", "report-no": null, "categories": "math.OC cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to their low-complexity iterations, Frank-Wolfe (FW) solvers are well\nsuited for various large-scale learning tasks. When block-separable constraints\nare present, randomized block FW (RB-FW) has been shown to further reduce\ncomplexity by updating only a fraction of coordinate blocks per iteration. To\ncircumvent the limitations of existing methods, the present work develops step\nsizes for RB-FW that enable a flexible selection of the number of blocks to\nupdate per iteration while ensuring convergence and feasibility of the\niterates. To this end, convergence rates of RB-FW are established through\ncomputational bounds on a primal sub-optimality measure and on the duality gap.\nThe novel bounds extend the existing convergence analysis, which only applies\nto a step-size sequence that does not generally lead to feasible iterates.\nFurthermore, two classes of step-size sequences that guarantee feasibility of\nthe iterates are also proposed to enhance flexibility in choosing decay rates.\nThe novel convergence results are markedly broadened to encompass also\nnonconvex objectives, and further assert that RB-FW with exact line-search\nreaches a stationary point at rate $\\mathcal{O}(1/\\sqrt{t})$. Performance of\nRB-FW with different step sizes and number of blocks is demonstrated in two\napplications, namely charging of electrical vehicles and structural support\nvector machines. Extensive simulated tests demonstrate the performance\nimprovement of RB-FW relative to existing randomized single-block FW methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 00:01:13 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 21:59:46 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Zhang", "Liang", ""], ["Wang", "Gang", ""], ["Romero", "Daniel", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1612.08469", "submitter": "Masoud Abbaszadeh", "authors": "Masoud Abbaszadeh", "title": "Is Lipschitz Continuity Preserved under Sampled-Data Discretization?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually, given a continuous-time nonlinear model, a closed form solution for\nan exact discretization cannot be found explicitly, originating the need of\napproximating discrete-time models. This note studies the preservation of the\nLipschitz continuity under approximate discretizations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 01:20:14 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 22:10:09 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Abbaszadeh", "Masoud", ""]]}, {"id": "1612.08686", "submitter": "Jesus Bonilla", "authors": "Santiago Badia, Jes\\'us Bonilla, Alba Hierro", "title": "Differentiable monotonicity-preserving schemes for discontinuous\n  Galerkin methods on arbitrary meshes", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2017.03.032", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is devoted to the design of interior penalty discontinuous Galerkin\n(dG) schemes that preserve maximum principles at the discrete level for the\nsteady transport and convection-diffusion problems and the respective transient\nproblems with implicit time integration. Monotonic schemes that combine\nexplicit time stepping with dG space discretization are very common, but the\ndesign of such schemes for implicit time stepping is rare, and it had only been\nattained so far for 1D problems. The proposed scheme is based on an artificial\ndiffusion that linearly depends on a shock detector that identifies the\ntroublesome areas. In order to define the new shock detector, we have\nintroduced the concept of discrete local extrema. The diffusion operator is a\ngraph-Laplacian, instead of the more common finite element discretization of\nthe Laplacian operator, which is essential to keep monotonicity on general\nmeshes and in multi-dimension. The resulting nonlinear stabilization is\nnon-smooth and nonlinear solvers can fail to converge. As a result, we propose\na smoothed (twice differentiable) version of the nonlinear stabilization, which\nallows us to use Newton with line search nonlinear solvers and dramatically\nimprove nonlinear convergence. A theoretical numerical analysis of the proposed\nschemes show that they satisfy the desired monotonicity properties. Further,\nthe resulting operator is Lipschitz continuous and there exists at least one\nsolution of the discrete problem, even in the non-smooth version. We provide a\nset of numerical results to support our findings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 17:17:53 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 14:14:47 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Badia", "Santiago", ""], ["Bonilla", "Jes\u00fas", ""], ["Hierro", "Alba", ""]]}, {"id": "1612.08709", "submitter": "Mark Tygert", "authors": "Huamin Li, Yuval Kluger, and Mark Tygert", "title": "Randomized algorithms for distributed computation of principal component\n  analysis and singular value decomposition", "comments": "21 pages, 29 tables, 1 figure, 8 algorithms in pseudocode", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized algorithms provide solutions to two ubiquitous problems: (1) the\ndistributed calculation of a principal component analysis or singular value\ndecomposition of a highly rectangular matrix, and (2) the distributed\ncalculation of a low-rank approximation (in the form of a singular value\ndecomposition) to an arbitrary matrix. Carefully honed algorithms yield results\nthat are uniformly superior to those of the stock, deterministic\nimplementations in Spark (the popular platform for distributed computation); in\nparticular, whereas the stock software will without warning return left\nsingular vectors that are far from numerically orthonormal, a significantly\nburnished randomized implementation generates left singular vectors that are\nnumerically orthonormal to nearly the machine precision.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 19:06:13 GMT"}, {"version": "v2", "created": "Sat, 31 Dec 2016 22:06:19 GMT"}, {"version": "v3", "created": "Wed, 31 May 2017 23:04:43 GMT"}, {"version": "v4", "created": "Mon, 1 Jan 2018 20:24:15 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Li", "Huamin", ""], ["Kluger", "Yuval", ""], ["Tygert", "Mark", ""]]}, {"id": "1612.08807", "submitter": "Carlos Am\\'endola", "authors": "Carlos Am\\'endola, Julia Lindberg, Jose Israel Rodriguez", "title": "Solving Parameterized Polynomial Systems with Decomposable Projections", "comments": "18 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Galois group of a parameterized polynomial system of equations encodes\nthe structure of the solutions. This monodromy group acts on the set of\nsolutions for a general set of parameters, that is, on the fiber of a\nprojection from the incidence variety of parameters and solutions onto the\nspace of parameters. When this projection is decomposable, the Galois group is\nimprimitive, and we show that the structure can be exploited for computational\nimprovements. Furthermore, we develop a new algorithm for solving these systems\nbased on a suitable trace test. We illustrate our method on examples in\nstatistics, kinematics, and benchmark problems in computational algebra. In\nparticular, we resolve a conjecture on the number of solutions of the moment\nsystem associated to a mixture of Gaussian distributions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 06:17:28 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 17:41:46 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Am\u00e9ndola", "Carlos", ""], ["Lindberg", "Julia", ""], ["Rodriguez", "Jose Israel", ""]]}, {"id": "1612.09097", "submitter": "Vladimir Puzyrev", "authors": "Vladimir Puzyrev, Quanling Deng, Victor Calo", "title": "Dispersion-optimized quadrature rules for isogeometric analysis:\n  modified inner products, their dispersion properties, and optimally blended\n  schemes", "comments": null, "journal-ref": "Computer Methods in Applied Mechanics and Engineering 320, 2017", "doi": "10.1016/j.cma.2017.03.029", "report-no": null, "categories": "math.NA cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces optimally-blended quadrature rules for isogeometric\nanalysis and analyzes the numerical dispersion of the resulting\ndiscretizations. To quantify the approximation errors when we modify the inner\nproducts, we generalize the Pythagorean eigenvalue theorem of Strang and Fix.\nThe proposed blended quadrature rules have advantages over alternative\nintegration rules for isogeometric analysis on uniform and non-uniform meshes\nas well as for different polynomial orders and continuity of the basis. The\noptimally-blended schemes improve the convergence rate of the method by two\norders with respect to the fully-integrated Galerkin method. The proposed\ntechnique increases the accuracy and robustness of isogeometric analysis for\nwave propagation problems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 11:06:20 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Puzyrev", "Vladimir", ""], ["Deng", "Quanling", ""], ["Calo", "Victor", ""]]}, {"id": "1612.09471", "submitter": "Danial Sadeghi", "authors": "Danial Sadeghi and Azim Rivaz", "title": "Some results about the Equiangular Algorithm", "comments": "15 pages, 1 figures. arXiv admin note: substantial text overlap with\n  arXiv:1412.7552", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equiangular Algorithm generates a set of equiangular normalized vectors with\ngiven angle {\\theta} using a set of linearly independence vectors in a real\ninner product space, which span the same subspaces. The outcome of EA on column\nvectors of a matrix A provides a matrix decomposition A = SR, where S is called\nEquiangular Matrix which has equiangular column vectors. In this paper we\ndiscuss some properties of equiangular matrices. The inverse and eigenvalue\nproblems of these matrices are studied. Also we derive some canonical forms of\nsome matrices based on equiangular ones.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 12:13:04 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Sadeghi", "Danial", ""], ["Rivaz", "Azim", ""]]}]