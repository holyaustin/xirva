[{"id": "1110.0010", "submitter": "John Jakeman", "authors": "John D. Jakeman, Stephen G. Roberts", "title": "Local and Dimension Adaptive Sparse Grid Interpolation and Quadrature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a locally and dimension-adaptive sparse grid method\nfor interpolation and integration of high-dimensional functions with\ndiscontinuities. The proposed algorithm combines the strengths of the\ngeneralised sparse grid algorithm and hierarchical surplus-guided local\nadaptivity. A high-degree basis is used to obtain a high-order method which,\ngiven sufficient smoothness, performs significantly better than the\npiecewise-linear basis. The underlying generalised sparse grid algorithm\ngreedily selects the dimensions and variable interactions that contribute most\nto the variability of a function. The hierarchical surplus of points within the\nsparse grid is used as an error criterion for local refinement with the aim of\nconcentrating computational effort within rapidly varying or discontinuous\nregions. This approach limits the number of points that are invested in\n`unimportant' dimensions and regions within the high-dimensional domain. We\nshow the utility of the proposed method for non-smooth functions with hundreds\nof variables.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2011 20:14:32 GMT"}], "update_date": "2011-10-04", "authors_parsed": [["Jakeman", "John D.", ""], ["Roberts", "Stephen G.", ""]]}, {"id": "1110.0169", "submitter": "Gleb Beliakov", "authors": "Gleb Beliakov, Andrei Kelarev, John Yearwood", "title": "Robust artificial neural networks and outlier detection. Technical\n  report", "comments": null, "journal-ref": null, "doi": "10.1080/02331934.2012.674946", "report-no": null, "categories": "math.OC cs.CV cs.NA cs.NE math.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large outliers break down linear and nonlinear regression models. Robust\nregression methods allow one to filter out the outliers when building a model.\nBy replacing the traditional least squares criterion with the least trimmed\nsquares criterion, in which half of data is treated as potential outliers, one\ncan fit accurate regression models to strongly contaminated data.\nHigh-breakdown methods have become very well established in linear regression,\nbut have started being applied for non-linear regression only recently. In this\nwork, we examine the problem of fitting artificial neural networks to\ncontaminated data using least trimmed squares criterion. We introduce a\npenalized least trimmed squares criterion which prevents unnecessary removal of\nvalid data. Training of ANNs leads to a challenging non-smooth global\noptimization problem. We compare the efficiency of several derivative-free\noptimization methods in solving it, and show that our approach identifies the\noutliers correctly when ANNs are used for nonlinear regression.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2011 10:56:07 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Beliakov", "Gleb", ""], ["Kelarev", "Andrei", ""], ["Yearwood", "John", ""]]}, {"id": "1110.0569", "submitter": "Ronald Caplan", "authors": "R.M. Caplan and R. Carretero-Gonz\\'alez", "title": "A Modulus-Squared Dirichlet Boundary Condition for Time-Dependent\n  Complex Partial Differential Equations and its Application to the Nonlinear\n  Schr\u007f\\\"odinger Equation", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An easy to implement modulus-squared Dirichlet (MSD) boundary condition is\nformulated for numerical simulations of time-dependent complex partial\ndifferential equations in multidimensional settings. The MSD boundary condition\napproximates a constant modulus-square value of the solution at the boundaries.\nApplication of the MSD boundary condition to the nonlinear Schr\\\"odinger\nequation is shown, and numerical simulations are performed to demonstrate its\nusefulness and advantages over other simple boundary conditions.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 03:17:21 GMT"}], "update_date": "2011-10-05", "authors_parsed": [["Caplan", "R. M.", ""], ["Carretero-Gonz\u00e1lez", "R.", ""]]}, {"id": "1110.0811", "submitter": "Nilotpal Kanti Sinha", "authors": "Nilotpal Kanti Sinha", "title": "A general model of regression using iterative series", "comments": "Need major changes and corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new and general method of weighted least square univariate\nregression where the dependent variable is expanded as a series of suitably\nchosen functions of the independent variables. Each term of the series is\nobtained by an iterative process which reduces the sum of the square of the\nresiduals. Thus by evaluating the regression series to a sufficiently large\nnumber of terms we can, in principle, reduce the sum of the square of residuals\nand improve the accuracy of the fit.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 19:25:13 GMT"}, {"version": "v2", "created": "Tue, 22 May 2012 19:17:14 GMT"}, {"version": "v3", "created": "Mon, 17 Sep 2012 17:44:09 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 10:04:33 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Sinha", "Nilotpal Kanti", ""]]}, {"id": "1110.0895", "submitter": "Michael Friedlander", "authors": "Aleksandr Aravkin, Michael P. Friedlander, Tristan van Leeuwen", "title": "Robust inversion via semistochastic dimensionality reduction", "comments": "Mathematical Programming, 2012", "journal-ref": "Mathematical Programming 134 (1), 101-125, 2012", "doi": "10.1007/s10107-012-0571-6", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of inverse problems where it is possible to aggregate the\nresults of multiple experiments. This class includes problems where the forward\nmodel is the solution operator to linear ODEs or PDEs. The tremendous size of\nsuch problems motivates dimensionality reduction techniques based on randomly\nmixing experiments. These techniques break down, however, when robust\ndata-fitting formulations are used, which are essential in cases of missing\ndata, unusually large errors, and systematic features in the data unexplained\nby the forward model. We survey robust methods within a statistical framework,\nand propose a semistochastic optimization approach that allows dimensionality\nreduction. The efficacy of the methods are demonstrated for a large-scale\nseismic inverse problem using the robust Student's t-distribution, where a\nuseful synthetic velocity model is recovered in the extreme scenario of 60%\ndata missing at random. The semistochastic approach achieves this recovery\nusing 20% of the effort required by a direct robust approach.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 04:55:59 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2011 18:30:05 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2012 23:54:40 GMT"}, {"version": "v4", "created": "Mon, 2 Jul 2012 14:07:13 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Aravkin", "Aleksandr", ""], ["Friedlander", "Michael P.", ""], ["van Leeuwen", "Tristan", ""]]}, {"id": "1110.1676", "submitter": "Yuanchang Sun", "authors": "Yuanchang Sun, Kai Huang, Jack Xin", "title": "Structure Assisted NMF Methods for Separation of Degenerate Mixture Data\n  with Application to NMR Spectroscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we develop structure assisted nonnegative matrix factorization\n(NMF) methods for blind source separation of degenerate data. The motivation\noriginates from nuclear magnetic resonance (NMR) spectroscopy, where a multiple\nmixture NMR spectra are recorded to identify chemical compounds with similar\nstructures. Consider the linear mixing model (LMM), we aim to identify the\nchemical compounds involved when the mixing process is known to be nearly\nsingular. We first consider a class of data with dominant interval(s) (DI)\nwhere each of source signals has dominant peaks over others. Besides, a nearly\nsingular mixing process produces degenerate mixtures. The DI condition implies\nclustering structures in the data points. Hence, the estimation of the mixing\nmatrix could be achieved by data clustering. Due to the presence of the noise\nand the degeneracy of the data, a small deviation in the estimation may\nintroduce errors in the output. To resolve this problem and improve robustness\nof the separation, methods are developed in two aspects. One is to find better\nestimation of the mixing matrix by allowing a constrained perturbation to the\nclustering output, and it can be achieved by a quadratic programming. The other\nis to seek sparse source signals by exploiting the DI condition, and it solves\nan $\\ell_1$ optimization. If no source information is available, we propose to\nadopt the nonnegative matrix factorization approach by incorporating the matrix\nstructure (parallel columns of the mixing matrix) into the cost function and\ndevelop multiplicative iteration rules for the numerical solutions. We present\nexperimental results of NMR data to show the performance and reliability of the\nmethod in the applications arising in NMR spectroscopy.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2011 23:19:09 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 02:14:34 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Sun", "Yuanchang", ""], ["Huang", "Kai", ""], ["Xin", "Jack", ""]]}, {"id": "1110.2921", "submitter": "Rio Yokota Dr.", "authors": "Rio Yokota and L. A. Barba", "title": "FMM-based vortex method for simulation of isotropic turbulence on GPUs,\n  compared with a spectral method", "comments": null, "journal-ref": null, "doi": "10.1016/j.compfluid.2012.08.002", "report-no": null, "categories": "cs.NA physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lagrangian vortex method offers an alternative numerical approach for\ndirect numerical simulation of turbulence. The fact that it uses the fast\nmultipole method (FMM)--a hierarchical algorithm for N-body problems with\nhighly scalable parallel implementations--as numerical engine makes it a\npotentially good candidate for exascale systems. However, there have been few\nvalidation studies of Lagrangian vortex simulations and the insufficient\ncomparisons against standard DNS codes has left ample room for skepticism. This\npaper presents a comparison between a Lagrangian vortex method and a\npseudo-spectral method for the simulation of decaying homogeneous isotropic\nturbulence. This flow field is chosen despite the fact that it is not the most\nfavorable flow problem for particle methods (which shine in wake flows or where\nvorticity is compact), due to the fact that it is ideal for the quantitative\nvalidation of DNS codes. We use a 256^3 grid with Re_lambda=50 and 100 and look\nat the turbulence statistics, including high-order moments. The focus is on the\neffect of the various parameters in the vortex method, e.g., order of FMM\nseries expansion, frequency of reinitialization, overlap ratio and time step.\nThe vortex method uses an FMM code (exaFMM) that runs on GPU hardware using\nCUDA, while the spectral code (hit3d) runs on CPU only. Results indicate that,\nfor this application (and with the current code implementations), the spectral\nmethod is an order of magnitude faster than the vortex method when using a\nsingle GPU for the FMM and six CPU cores for the FFT.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 12:52:38 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2012 07:37:28 GMT"}, {"version": "v3", "created": "Thu, 2 Aug 2012 14:05:46 GMT"}, {"version": "v4", "created": "Mon, 20 Aug 2012 12:58:13 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Yokota", "Rio", ""], ["Barba", "L. A.", ""]]}, {"id": "1110.3349", "submitter": "Richard J. Mathar", "authors": "Richard J. Mathar", "title": "RiemCirc: A Generator of Nodes and Weights for Riemann Integration on\n  the Circle", "comments": "Version 2 includes examples of many configurations, omp\n  parallelization of the code, and another run-time option", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RiemCirc is a C++ program which allocates points inside the unit circle for\nnumerical quadrature on the circle, aiming at homogeneous equidistant\ndistribution. The weights of the quadrature rule are computed by the area of\nthe tiles that surround these nodes. The shapes of the areas are polygonal,\ndefined by Voronoi tessellation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2011 22:02:51 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 20:46:29 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mathar", "Richard J.", ""]]}, {"id": "1110.4193", "submitter": "Jiawei Chiu", "authors": "Jiawei Chiu and Laurent Demanet", "title": "Sublinear randomized algorithms for skeleton decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A$ be a $n$ by $n$ matrix. A skeleton decomposition is any factorization\nof the form $CUR$ where $C$ comprises columns of $A$, and $R$ comprises rows of\n$A$. In this paper, we consider uniformly sampling $\\l\\simeq k \\log n$ rows and\ncolumns to produce a skeleton decomposition. The algorithm runs in $O(\\l^3)$\ntime, and has the following error guarantee. Let $\\norm{\\cdot}$ denote the\n2-norm. Suppose $A\\simeq X B Y^T$ where $X,Y$ each have $k$ orthonormal\ncolumns. Assuming that $X,Y$ are incoherent, we show that with high\nprobability, the approximation error $\\norm{A-CUR}$ will scale with\n$(n/\\l)\\norm{A-X B Y^T}$ or better. A key step in this algorithm involves\nregularization. This step is crucial for a nonsymmetric $A$ as empirical\nresults suggest. Finally, we use our proof framework to analyze two existing\nalgorithms in an intuitive way.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2011 06:36:02 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2012 05:34:09 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Chiu", "Jiawei", ""], ["Demanet", "Laurent", ""]]}, {"id": "1110.4437", "submitter": "Haim Avron", "authors": "Haim Avron and Sivan Toledo", "title": "Effective Stiffness: Generalizing Effective Resistance Sampling to\n  Finite Element Matrices", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define the notion of effective stiffness and show that it can used to\nbuild sparsifiers, algorithms that sparsify linear systems arising from\nfinite-element discretizations of PDEs. In particular, we show that sampling\n$O(n\\log n)$ elements according to probabilities derived from effective\nstiffnesses yields a high quality preconditioner that can be used to solve the\nlinear system in a small number of iterations. Effective stiffness generalizes\nthe notion of effective resistance, a key ingredient of recent progress in\ndeveloping nearly linear symmetric diagonally dominant (SDD) linear solvers.\nSolving finite elements problems is of considerably more interest than the\nsolution of SDD linear systems, since the finite element method is frequently\nused to numerically solve PDEs arising in scientific and engineering\napplications. Unlike SDD systems, which are relatively easy to solve, there has\nbeen limited success in designing fast solvers for finite element systems, and\nprevious algorithms usually target discretization of limited class of PDEs like\nscalar elliptic or 2D trusses. Our sparsifier is general; it applies to a wide\nrange of finite-element discretizations. A sparsifier does not constitute a\ncomplete linear solver. To construct a solver, one needs additional components\n(e.g., an efficient elimination or multilevel scheme for the sparsified\nsystem). Still, sparsifiers have been a critical tools in efficient SDD\nsolvers, and we believe that our sparsifier will become a key ingredient in\nfuture fast finite-element solvers.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2011 03:54:53 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2014 17:07:18 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Avron", "Haim", ""], ["Toledo", "Sivan", ""]]}, {"id": "1110.5305", "submitter": "Alex Gittens", "authors": "Alex Gittens", "title": "The spectral norm error of the naive Nystrom extension", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The naive Nystrom extension forms a low-rank approximation to a\npositive-semidefinite matrix by uniformly randomly sampling from its columns.\nThis paper provides the first relative-error bound on the spectral norm error\nincurred in this process. This bound follows from a natural connection between\nthe Nystrom extension and the column subset selection problem. The main tool is\na matrix Chernoff bound for sampling without replacement.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2011 18:57:57 GMT"}], "update_date": "2011-10-25", "authors_parsed": [["Gittens", "Alex", ""]]}, {"id": "1110.5989", "submitter": "Zhengjun Cao", "authors": "Zhengjun Cao and Xiao Fan", "title": "A Heuristic Description of Fast Fourier Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast Fourier Transform (FFT) is an efficient algorithm to compute the\nDiscrete Fourier Transform (DFT) and its inverse. In this paper, we pay special\nattention to the description of complex-data FFT. We analyze two common\ndescriptions of FFT and propose a new presentation. Our heuristic description\nis helpful for students and programmers to grasp the algorithm entirely and\ndeeply.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2011 05:51:23 GMT"}], "update_date": "2011-10-28", "authors_parsed": [["Cao", "Zhengjun", ""], ["Fan", "Xiao", ""]]}, {"id": "1110.5992", "submitter": "Timo Aittokoski Dr.", "authors": "Timo Aittokoski and Suvi Tarkkanen", "title": "User preference extraction using dynamic query sliders in conjunction\n  with UPS-EMO algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One drawback of evolutionary multiobjective optimization algorithms (EMOA)\nhas traditionally been high computational cost to create an approximation of\nthe Pareto front: number of required objective function evaluations usually\ngrows high. On the other hand, for the decision maker (DM) it may be difficult\nto select one of the many produced solutions as the final one, especially in\nthe case of more than two objectives.\n  To overcome the above mentioned drawbacks number of EMOA's incorporating the\ndecision makers preference information have been proposed. In this case, it is\npossible to save objective function evaluations by generating only the part of\nthe front the DM is interested in, thus also narrowing down the pool of\npossible selections for the final solution.\n  Unfortunately, most of the current EMO approaches utilizing preferences are\nnot very intuitive to use, i.e. they may require tweaking of unintuitive\nparameters, and it is not always clear what kind of results one can get with\ngiven set of parameters. In this study we propose a new approach to visually\ninspect produced solutions, and to extract preference information from the DM\nto further guide the search. Our approach is based on intuitive use of dynamic\nquery sliders, which serve as a means to extract preference information and are\npart of the graphical user interface implemented for the efficient UPS-EMO\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2011 06:40:45 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Aittokoski", "Timo", ""], ["Tarkkanen", "Suvi", ""]]}, {"id": "1110.6834", "submitter": "Dante  Kalise", "authors": "Dante Kalise, Ivar Lie and Eleuterio F. Toro", "title": "High-order finite volume schemes for layered atmospheric models", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a numerical scheme for the solution of a class of atmospheric\nmodels where high horizontal resolution is required while a coarser vertical\nstructure is allowed. The proposed scheme considers a layering procedure for\nthe original set of equations, and the use of high-order ADER finite volume\nschemes for the solution of the system of balance laws arising from the\ndimensional reduction procedure. We present several types of layering based\nupon Galerkin discretizations of the vertical structure, and we study the\neffect of incrementing the order of horizontal approximation. Numerical\nexperiments for the computational validation of the convergence of the scheme\ntogether with the study of physical phenomena are performed over 2D linear\nadvective models, including a set of equations for an isothermal atmosphere.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2011 15:32:50 GMT"}], "update_date": "2011-11-01", "authors_parsed": [["Kalise", "Dante", ""], ["Lie", "Ivar", ""], ["Toro", "Eleuterio F.", ""]]}]