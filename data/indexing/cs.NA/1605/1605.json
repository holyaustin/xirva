[{"id": "1605.00190", "submitter": "David Spivak", "authors": "David I. Spivak", "title": "Pixel matrices: An elementary technique for solving nonlinear systems", "comments": "There is a later, more up-to-date and complete version on the arXiv,\n  namely \"Pixel Arrays: A fast and elementary method for solving nonlinear\n  systems\", arXiv:1609.00061", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A new technique for approximating the entire solution set for a nonlinear\nsystem of relations (nonlinear equations, inequalities, etc. involving\nalgebraic, smooth, or even continuous functions) is presented. The technique is\nto first plot each function as a pixel matrix, and to then perform a sequence\nof basic matrix operations, as dictated by how variables are shared by the\nrelations in the system. The result is a pixel matrix graphing the approximated\nsimultaneous solution set for the system.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 00:39:38 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 00:48:55 GMT"}, {"version": "v3", "created": "Wed, 6 Dec 2017 01:27:18 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Spivak", "David I.", ""]]}, {"id": "1605.00232", "submitter": "Sergio P. Perez", "authors": "Jos\\'e A. Carrillo, Young-Pil Choi, Sergio P. Perez", "title": "A review on attractive-repulsive hydrodynamics for consensus in\n  collective behavior", "comments": "36 pages, 67 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey summarizes and illustrates the main qualitative properties of\nhydrodynamics models for collective behavior. These models include a velocity\nconsensus term together with attractive-repulsive potentials leading to\nnon-trivial flock profiles. The connection between the underlying particle\nsystems to the swarming hydrodynamic equations is performed through kinetic\ntheory modelling arguments. We focus on Lagrangian schemes for the hydrodynamic\nsystems showing the different qualitative behavior of the systems and its\ncapability of keeping properties of the original particle models. We illustrate\nknown results concerning large time profiles and blow-up in finite time of the\nhydrodynamic systems to validate the numerical scheme. We finally explore\nunknown situations making use of the numerical scheme showcasing a number of\nconjectures based on the numerical results.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 10:33:51 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 10:59:55 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Carrillo", "Jos\u00e9 A.", ""], ["Choi", "Young-Pil", ""], ["Perez", "Sergio P.", ""]]}, {"id": "1605.00410", "submitter": "Alexander Kobel", "authors": "Alexander Kobel and Fabrice Rouillier and Michael Sagraloff", "title": "Computing Real Roots of Real Polynomials ... and now For Real!", "comments": "Accepted for presentation at the 41st International Symposium on\n  Symbolic and Algebraic Computation (ISSAC), July 19--22, 2016, Waterloo,\n  Ontario, Canada", "journal-ref": null, "doi": "10.1145/2930889.2930937", "report-no": null, "categories": "cs.MS cs.NA cs.SC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very recent work introduces an asymptotically fast subdivision algorithm,\ndenoted ANewDsc, for isolating the real roots of a univariate real polynomial.\nThe method combines Descartes' Rule of Signs to test intervals for the\nexistence of roots, Newton iteration to speed up convergence against clusters\nof roots, and approximate computation to decrease the required precision. It\nachieves record bounds on the worst-case complexity for the considered problem,\nmatching the complexity of Pan's method for computing all complex roots and\nimproving upon the complexity of other subdivision methods by several\nmagnitudes.\n  In the article at hand, we report on an implementation of ANewDsc on top of\nthe RS root isolator. RS is a highly efficient realization of the classical\nDescartes method and currently serves as the default real root solver in Maple.\nWe describe crucial design changes within ANewDsc and RS that led to a\nhigh-performance implementation without harming the theoretical complexity of\nthe underlying algorithm.\n  With an excerpt of our extensive collection of benchmarks, available online\nat http://anewdsc.mpi-inf.mpg.de/, we illustrate that the theoretical gain in\nperformance of ANewDsc over other subdivision methods also transfers into\npractice. These experiments also show that our new implementation outperforms\nboth RS and mature competitors by magnitudes for notoriously hard instances\nwith clustered roots. For all other instances, we avoid almost any overhead by\nintegrating additional optimizations and heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 09:47:10 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Kobel", "Alexander", ""], ["Rouillier", "Fabrice", ""], ["Sagraloff", "Michael", ""]]}, {"id": "1605.00423", "submitter": "Musabbir Majeed", "authors": "Musabbir Majeed, Fehmi Cirak", "title": "Isogeometric analysis using manifold-based smooth basis functions", "comments": "27 pages, 25 figures", "journal-ref": null, "doi": "10.1016/j.cma.2016.08.013", "report-no": null, "categories": "cs.NA cs.GR math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an isogeometric analysis technique that builds on manifold-based\nsmooth basis functions for geometric modelling and analysis. Manifold-based\nsurface construction techniques are well known in geometric modelling and a\nnumber of variants exist. Common to all is the concept of constructing a smooth\nsurface by blending together overlapping patches (or, charts), as in\ndifferential geometry description of manifolds. Each patch on the surface has a\ncorresponding planar patch with a smooth one-to-one mapping onto the surface.\nIn our implementation, manifold techniques are combined with conformal\nparametrisations and the partition-of-unity method for deriving smooth basis\nfunctions on unstructured quadrilateral meshes. Each vertex and its adjacent\nelements on the surface control mesh have a corresponding planar patch of\nelements. The star-shaped planar patch with congruent wedge-shaped elements is\nsmoothly parameterised with copies of a conformally mapped unit square. The\nconformal maps can be easily inverted in order to compute the transition\nfunctions between the different planar patches that have an overlap on the\nsurface. On the collection of star-shaped planar patches the partition of unity\nmethod is used for approximation. The smooth partition of unity, or blending\nfunctions, are assembled from tensor-product b-spline segments defined on a\nunit square. On each patch a polynomial with a prescribed degree is used as a\nlocal approximant. To obtain a mesh-based approximation scheme, the\ncoefficients of the local approximants are expressed in dependence of vertex\ncoefficients. This yields a basis function for each vertex of the mesh which is\nsmooth and non-zero over a vertex and its adjacent elements. Our numerical\nsimulations indicate the optimal convergence of the resulting approximation\nscheme for Poisson problems and near optimal convergence for thin-plate and\nthin-shell problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 10:35:23 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Majeed", "Musabbir", ""], ["Cirak", "Fehmi", ""]]}, {"id": "1605.00621", "submitter": "Bahman Kalantari", "authors": "Bahman Kalantari", "title": "A Necessary and Sufficient Condition for Local Maxima of Polynomial\n  Modulus Over Unit Disc", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important quantity associated with a complex polynomial $p(z)$ is $\\Vert p\n\\Vert_\\infty$, the maximum of its modulus over the unit disc $D$. We prove,\n$z_* \\in D$ is a local maximum of $|p(z)|$ if and only if $a_*$ satisfies,\n$z_*=p(z_*)|p'(z_*)|/p'(z_*)|p(z_*)|$, i.e. it is proportional to its\ncorresponding Newton direction. This explicit formula gives rise to novel\niterative algorithms for computing $\\Vert p \\Vert_\\infty$. We describe two such\nalgorithms, including a Newton-like method and present some visualization of\ntheir performance.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 19:06:46 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Kalantari", "Bahman", ""]]}, {"id": "1605.01384", "submitter": "Konstantinos Zygalakis", "authors": "Michael B. Giles and Mateusz B. Majka and Lukasz Szpruch and Sebastian\n  Vollmer and Konstantinos Zygalakis", "title": "Multilevel Monte Carlo methods for the approximation of invariant\n  measures of stochastic differential equations", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework that allows the use of the multi-level Monte Carlo\n(MLMC) methodology (Giles2015) to calculate expectations with respect to the\ninvariant measure of an ergodic SDE. In that context, we study the\n(over-damped) Langevin equations with a strongly concave potential. We show\nthat, when appropriate contracting couplings for the numerical integrators are\navailable, one can obtain a uniform in time estimate of the MLMC variance in\ncontrast to the majority of the results in the MLMC literature. As a\nconsequence, a root mean square error of $\\mathcal{O}(\\varepsilon)$ is achieved\nwith $\\mathcal{O}(\\varepsilon^{-2})$ complexity on par with Markov Chain Monte\nCarlo (MCMC) methods, which however can be computationally intensive when\napplied to large data sets. Finally, we present a multi-level version of the\nrecently introduced Stochastic Gradient Langevin Dynamics (SGLD) method\n(Welling and Teh, 2011) built for large datasets applications. We show that\nthis is the first stochastic gradient MCMC method with complexity\n$\\mathcal{O}(\\varepsilon^{-2}|\\log {\\varepsilon}|^{3})$, in contrast to the\ncomplexity $\\mathcal{O}(\\varepsilon^{-3})$ of currently available methods.\nNumerical experiments confirm our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 19:12:13 GMT"}, {"version": "v2", "created": "Sun, 31 Jul 2016 08:57:39 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2019 11:07:26 GMT"}, {"version": "v4", "created": "Mon, 12 Aug 2019 14:07:59 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Giles", "Michael B.", ""], ["Majka", "Mateusz B.", ""], ["Szpruch", "Lukasz", ""], ["Vollmer", "Sebastian", ""], ["Zygalakis", "Konstantinos", ""]]}, {"id": "1605.01656", "submitter": "Jie Shen", "authors": "Jie Shen and Ping Li", "title": "A Tight Bound of Hard Thresholding", "comments": "V1 was submitted to COLT 2016. V2 fixes minor flaws, adds extra\n  experiments and discusses time complexity, V3 has been accepted to JMLR", "journal-ref": "Journal of Machine Learning Research 18(208): 1-42, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.NA math.IT math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the hard thresholding operator which sets all\nbut the $k$ largest absolute elements of a vector to zero. We establish a {\\em\ntight} bound to quantitatively characterize the deviation of the thresholded\nsolution from a given signal. Our theoretical result is universal in the sense\nthat it holds for all choices of parameters, and the underlying analysis\ndepends only on fundamental arguments in mathematical optimization. We discuss\nthe implications for two domains:\n  Compressed Sensing. On account of the crucial estimate, we bridge the\nconnection between the restricted isometry property (RIP) and the sparsity\nparameter for a vast volume of hard thresholding based algorithms, which\nrenders an improvement on the RIP condition especially when the true sparsity\nis unknown. This suggests that in essence, many more kinds of sensing matrices\nor fewer measurements are admissible for the data acquisition procedure.\n  Machine Learning. In terms of large-scale machine learning, a significant yet\nchallenging problem is learning accurate sparse models in an efficient manner.\nIn stark contrast to prior work that attempted the $\\ell_1$-relaxation for\npromoting sparsity, we present a novel stochastic algorithm which performs hard\nthresholding in each iteration, hence ensuring such parsimonious solutions.\nEquipped with the developed bound, we prove the {\\em global linear convergence}\nfor a number of prevalent statistical models under mild assumptions, even\nthough the problem turns out to be non-convex.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 17:10:34 GMT"}, {"version": "v2", "created": "Sun, 15 Oct 2017 03:04:09 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 17:58:11 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Shen", "Jie", ""], ["Li", "Ping", ""]]}, {"id": "1605.02626", "submitter": "Maxence Reberol", "authors": "Maxence Reberol (ALICE), Bruno L\\'evy (ALICE)", "title": "Low-order continuous finite element spaces on hybrid non-conforming\n  hexahedral-tetrahedral meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with solving partial differential equations with the\nfinite element method on hybrid non-conforming hexahedral-tetrahedral meshes.\nBy non-conforming, we mean that a quadrangular face of a hexahedron can be\nconnected to two triangular faces of tetrahedra. We introduce a set of\nlow-order continuous (C0) finite element spaces defined on these meshes. They\nare built from standard tri-linear and quadratic Lagrange finite elements with\nan extra set of constraints at non-conforming hexahedra-tetrahedra junctions to\nrecover continuity. We consider both the continuity of the geometry and the\ncontinuity of the function basis as follows: the continuity of the geometry is\nachieved by using quadratic mappings for tetrahedra connected to tri-affine\nhexahedra and the continuity of interpolating functions is enforced in a\nsimilar manner by using quadratic Lagrange basis on tetrahedra with constraints\nat non-conforming junctions to match tri-linear hexahedra. The so-defined\nfunction spaces are validated numerically on simple Poisson and linear\nelasticity problems for which an analytical solution is known. We observe that\nusing a hybrid mesh with the proposed function spaces results in an accuracy\nsignificantly better than when using linear tetrahedra and slightly worse than\nwhen solely using tri-linear hexahedra. As a consequence, the proposed function\nspaces may be a promising alternative for complex geometries that are out of\nreach of existing full hexahedral meshing methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 15:42:30 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Reberol", "Maxence", "", "ALICE"], ["L\u00e9vy", "Bruno", "", "ALICE"]]}, {"id": "1605.02630", "submitter": "Avram Sidi", "authors": "Avram Sidi", "title": "On a Vectorized Version of a Generalized Richardson Extrapolation\n  Process", "comments": null, "journal-ref": "Numerical Algorithms, 74:937--949, 2017", "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\{\\xx_m\\}$ be a vector sequence that satisfies $$ \\xx_m\\sim\n\\sss+\\sum^\\infty_{i=1}\\alpha_i \\gg_i(m)\\quad\\text{as $m\\to\\infty$},$$ $\\sss$\nbeing the limit or antilimit of $\\{\\xx_m\\}$ and $\\{\\gg_i(m)\\}^\\infty_{i=1}$\nbeing an asymptotic scale as $m\\to\\infty$, in the sense that\n$$\\lim_{m\\to\\infty}\\frac{\\|\\gg_{i+1}(m)\\|}{\\|\\gg_{i}(m)\\|}=0,\\quad\ni=1,2,\\ldots.$$ The vector sequences $\\{\\gg_i(m)\\}^\\infty_{m=0}$,\n$i=1,2,\\ldots,$ are known, as well as $\\{\\xx_m\\}$. In this work, we analyze the\nconvergence and convergence acceleration properties of a vectorized version of\nthe generalized Richardson extrapolation process that is defined via the\nequations $$\n\\sum^k_{i=1}\\braket{\\yy,\\Delta\\gg_{i}(m)}\\widetilde{\\alpha}_i=\\braket{\\yy,\\Delta\\xx_m},\\quad\nn\\leq m\\leq n+k-1;\\quad\n\\sss_{n,k}=\\xx_n+\\sum^k_{i=1}\\widetilde{\\alpha}_i\\gg_{i}(n),$$ $\\sss_{n,k}$\nbeing the approximation to $\\sss$. Here $\\yy$ is some nonzero vector,\n$\\braket{\\cdot\\,,\\cdot}$ is an inner product, such that\n$\\braket{\\alpha\\aaa,\\beta\\bb}=\\bar{\\alpha}\\beta\\braket{\\aaa,\\bb}$, and\n$\\Delta\\xx_m=\\xx_{m+1}-~\\xx_m$ and $\\Delta\\gg_i(m)=\\gg_i(m+1)-\\gg_i(m)$. By\nimposing a minimal number of reasonable additional conditions on the\n$\\gg_i(m)$, we show that the error $\\sss_{n,k}-\\sss$ has a full asymptotic\nexpansion as $n\\to\\infty$. We also show that actual convergence acceleration\ntakes place and we provide a complete classification of it.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 15:45:52 GMT"}, {"version": "v2", "created": "Fri, 5 Aug 2016 06:49:45 GMT"}, {"version": "v3", "created": "Sun, 6 Dec 2020 09:34:44 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Sidi", "Avram", ""]]}, {"id": "1605.03364", "submitter": "Hans Kersting", "authors": "Hans Kersting, Philipp Hennig", "title": "Active Uncertainty Calibration in Bayesian ODE Solvers", "comments": "10 pages, 3 figures, published at UAI 2016. Changes for Version 3:\n  fixed minor index mistake in equation (14) (q-1-i instead of q+1-i on top of\n  the product)", "journal-ref": "Proceedings of the Thirty-Second Conference on Uncertainty in\n  Artificial Intelligence (UAI2016) 309--3018", "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is resurging interest, in statistics and machine learning, in solvers\nfor ordinary differential equations (ODEs) that return probability measures\ninstead of point estimates. Recently, Conrad et al. introduced a sampling-based\nclass of methods that are 'well-calibrated' in a specific sense. But the\ncomputational cost of these methods is significantly above that of classic\nmethods. On the other hand, Schober et al. pointed out a precise connection\nbetween classic Runge-Kutta ODE solvers and Gaussian filters, which gives only\na rough probabilistic calibration, but at negligible cost overhead. By\nformulating the solution of ODEs as approximate inference in linear Gaussian\nSDEs, we investigate a range of probabilistic ODE solvers, that bridge the\ntrade-off between computational cost and probabilistic calibration, and\nidentify the inaccurate gradient measurement as the crucial source of\nuncertainty. We propose the novel filtering-based method Bayesian Quadrature\nfiltering (BQF) which uses Bayesian quadrature to actively learn the\nimprecision in the gradient measurement by collecting multiple gradient\nevaluations.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 10:24:04 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 13:56:57 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 09:39:02 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Kersting", "Hans", ""], ["Hennig", "Philipp", ""]]}, {"id": "1605.03503", "submitter": "Javier Segura", "authors": "A. Gil, J. Segura, N. M. Temme", "title": "Efficient algorithms for the inversion of the cumulative central beta\n  distribution", "comments": "To appear in Numerical Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and efficient algorithms for the inversion of the cumulative central\nbeta distribution are described. The algorithms are based on the combination of\na fourth-order fixed point method with good non-local convergence properties\n(the Schwarzian-Newton method), asymptotic inversion methods and sharp bounds\nin the tails of the distribution function.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 16:32:37 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Gil", "A.", ""], ["Segura", "J.", ""], ["Temme", "N. M.", ""]]}, {"id": "1605.04086", "submitter": "Bal\\'azs Kov\\'acs", "authors": "Bal\\'azs Kov\\'acs and Christian Lubich", "title": "Stable and convergent fully discrete interior-exterior coupling of\n  Maxwell's equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maxwell's equations are considered with transparent boundary conditions, for\ninitial conditions and inhomogeneity having support in a bounded, not\nnecessarily convex three-dimensional domain or in a collection of such domains.\nThe numerical method only involves the interior domain and its boundary. The\ntransparent boundary conditions are imposed via a time-dependent boundary\nintegral operator that is shown to satisfy a coercivity property. The stability\nof the numerical method relies on this coercivity and on an anti-symmetric\nstructure of the discretized equations that is inherited from a weak\nfirst-order formulation of the continuous equations. The method proposed here\nuses a discontinuous Galerkin method and the leapfrog scheme in the interior\nand is coupled to boundary elements and convolution quadrature on the boundary.\nThe method is explicit in the interior and implicit on the boundary. Stability\nand convergence of the spatial semidiscretization are proven, and with a\ncomputationally simple stabilization term, this is also shown for the full\ndiscretization.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 08:55:00 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 10:13:08 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 07:01:55 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Kov\u00e1cs", "Bal\u00e1zs", ""], ["Lubich", "Christian", ""]]}, {"id": "1605.04380", "submitter": "Mostafa Rahmani", "authors": "M. Hadi Amini, Mostafa Rahmani, Kianoosh G. Boroojeni, George Atia,\n  S.S. Iyengar, and Orkun Karabasoglu", "title": "Sparsity-Based Error Detection in DC Power Flow State Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for identifying the measurement error in\nthe DC power flow state estimation problem. The proposed algorithm exploits the\nsingularity of the impedance matrix and the sparsity of the error vector by\nposing the DC power flow problem as a sparse vector recovery problem that\nleverages the structure of the power system and uses $l_1$-norm minimization\nfor state estimation. This approach can provably compute the measurement errors\nexactly, and its performance is robust to the arbitrary magnitudes of the\nmeasurement errors. Hence, the proposed approach can detect the noisy elements\nif the measurements are contaminated with additive white Gaussian noise plus\nsparse noise with large magnitude. The effectiveness of the proposed\nsparsity-based decomposition-DC power flow approach is demonstrated on the IEEE\n118-bus and 300-bus test systems.\n", "versions": [{"version": "v1", "created": "Sat, 14 May 2016 05:07:37 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 21:23:40 GMT"}, {"version": "v3", "created": "Fri, 26 Aug 2016 16:52:29 GMT"}], "update_date": "2016-08-29", "authors_parsed": [["Amini", "M. Hadi", ""], ["Rahmani", "Mostafa", ""], ["Boroojeni", "Kianoosh G.", ""], ["Atia", "George", ""], ["Iyengar", "S. S.", ""], ["Karabasoglu", "Orkun", ""]]}, {"id": "1605.04644", "submitter": "Xingyan Bin", "authors": "Xingyan Bin, Ying Zhao and Bilong Shen", "title": "Abnormal Subspace Sparse PCA for Anomaly Detection and Interpretation", "comments": "ODDx3, ACM SIGKDD 2015 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main shortage of principle component analysis (PCA) based anomaly\ndetection models is their interpretability. In this paper, our goal is to\npropose an interpretable PCA-based model for anomaly detection and\ninterpretation. The propose ASPCA model constructs principal components with\nsparse and orthogonal loading vectors to represent the abnormal subspace, and\nuses them to interpret detected anomalies. Our experiments on a synthetic\ndataset and two real world datasets showed that the proposed ASPCA models\nachieved comparable detection accuracies as the PCA model, and can provide\ninterpretations for individual anomalies.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 03:55:31 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Bin", "Xingyan", ""], ["Zhao", "Ying", ""], ["Shen", "Bilong", ""]]}, {"id": "1605.05023", "submitter": "Mohammad Mansour", "authors": "Mohammad M. Mansour", "title": "Comments on \"A Square-Root-Free Matrix Decomposition Method for\n  Energy-Efficient Least Square Computation on Embedded Systems\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A square-root-free matrix QR decomposition (QRD) scheme was rederived in [1]\nbased on [2] to simplify computations when solving least-squares (LS) problems\non embedded systems. The scheme of [1] aims at eliminating both the square-root\nand division operations in the QRD normalization and backward substitution\nsteps in the LS computations. It is claimed in [1] that the LS solution only\nrequires finding the directions of the orthogonal basis of the matrix in\nquestion, regardless of the normalization of their Euclidean norms. MIMO\ndetection problems have been named as potential applications that benefit from\nthis. While this is true for unconstrained LS problems, we conversely show here\nthat constrained LS problems such as MIMO detection still require computing the\nnorms of the orthogonal basis to produce the correct result.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 05:51:42 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Mansour", "Mohammad M.", ""]]}, {"id": "1605.05042", "submitter": "Monica Pragliola", "authors": "Daniela Calvetti, Salvatore Cuomo, Monica Pragliola, Erkki Somersalo,\n  Gerardo Toraldo", "title": "Computational issues and numerical experiments for Linear Multistep\n  Method Particle Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Linear Multistep Method Particle Filter (LMM PF) is a method for\npredicting the evolution in time of a evolutionary system governed by a system\nof differential equations. If some of the parameters of the governing equations\nare unknowns, it is possible to organize the calculations so as to estimate\nthem while following the evolution of the system in time. The underlying\nassumption in the approach that we present is that all unknowns are modelled as\nrandom variables, where the randomness is an indication of the uncertainty of\ntheir values rather than an intrinsic property of the quantities. Consequently,\nthe states of the system and the parameters are described in probabilistic\nterms by their density, often in the form of representative samples. This\napproach is particularly attractive in the context of parameter estimation\ninverse problems, because the statistical formulation naturally provides a\nmeans of assessing the uncertainty in the solution via the spread of the\ndistribution. The computational efficiency of the underlying sampling technique\nis crucial for the success of the method, because the accuracy of the solution\ndepends on the ability to produce representative samples from the distribution\nof the unknown parameters. In this paper LMM PF is tested on a skeletal muscle\nmetabolism problem, which was previously treated within the Ensemble Kalman\nfiltering framework. Here numerical evidences are used to highlight the\ncorrelation between the main sources of errors and the influence of the linera\nmultistep method adopted. Finally, we analyzed the effect of replacing LMM with\nRunge-Kutta class integration methods for supporting the PF technique.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 07:45:34 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Calvetti", "Daniela", ""], ["Cuomo", "Salvatore", ""], ["Pragliola", "Monica", ""], ["Somersalo", "Erkki", ""], ["Toraldo", "Gerardo", ""]]}, {"id": "1605.05610", "submitter": "Edo Liberty", "authors": "Edo Liberty", "title": "A Short Proof for Gap Independence of Simultaneous Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note provides a very short proof of a spectral gap independent property\nof the simultaneous iterations algorithm for finding the top singular space of\na matrix. See Rokhlin-Szlam-Tygert-2009, Halko-Martinsson-Tropp-2011 and\nMusco-Musco-2015. The proof is terse but completely self contained and should\nbe accessible to the linear algebra savvy reader.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 15:09:46 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 19:15:28 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Liberty", "Edo", ""]]}, {"id": "1605.06532", "submitter": "Andy Wan T. S.", "authors": "Andy T.S. Wan and Marc Laforest", "title": "A Posteriori Error Estimation for the p-curl Problem", "comments": "32 pages", "journal-ref": "SIAM J. Numer. Anal. 58(1) 460-491 (2020)", "doi": "10.1137/16M1075624", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a posteriori error estimates for a semi-discrete finite element\napproximation of a nonlinear eddy current problem arising from applied\nsuperconductivity, known as the $p$-curl problem. In particular, we show the\nreliability for non-conforming N\\'{e}d\\'{e}lec elements based on a residual\ntype argument and a Helmholtz-Weyl decomposition of\n$W^p_0(\\text{curl};\\Omega)$. As a consequence, we are also able to derive an a\nposteriori error estimate for a quantity of interest called the AC loss. The\nnonlinearity for this form of Maxwell's equation is an analogue of the one\nfound in the $p$-Laplacian. It is handled without linearizing around the\napproximate solution. The non-conformity is dealt by adapting error\ndecomposition techniques of Carstensen, Hu and Orlando. Geometric\nnon-conformities also appear because the continuous problem is defined over a\nbounded $C^{1,1}$ domain while the discrete problem is formulated over a weaker\npolyhedral domain. The semi-discrete formulation studied in this paper is often\nencountered in commercial codes and is shown to be well-posed. The paper\nconcludes with numerical results confirming the reliability of the a posteriori\nerror estimate.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 20:38:43 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 05:53:12 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Wan", "Andy T. S.", ""], ["Laforest", "Marc", ""]]}, {"id": "1605.06760", "submitter": "Yiping Cheng", "authors": "Yiping Cheng", "title": "Space-Efficient Karatsuba Multiplication for Multi-Precision Integers", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional Karatsuba algorithm for the multiplication of polynomials and\nmulti-precision integers has a time complexity of $O(n^{1.59})$ and a space\ncomplexity of $O(n)$. Roche proposed an improved algorithm with the same\n$O(n^{1.59})$ time complexity but with a much reduced $O(\\log n)$ space\ncomplexity. In Roche's paper details were provided for multiplication of\npolynomials, but not for multi-precision integers. Multi-precision integers\ndiffer from polynomials by the presence of carries, which poses difficulties in\nimplementing Roche's scheme in multi-precision integers. This paper provides a\ndetailed solution to these difficulties. Finally, numerical comparisons between\nthe schoolbook, traditional Karatsuba, and space-efficient Karatsuba algorithms\nare provided.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 09:08:09 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Cheng", "Yiping", ""]]}, {"id": "1605.06968", "submitter": "Bamdev Mishra", "authors": "Bamdev Mishra, Hiroyuki Kasai, and Atul Saroop", "title": "A Riemannian gossip approach to decentralized matrix completion", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose novel gossip algorithms for the low-rank\ndecentralized matrix completion problem. The proposed approach is on the\nRiemannian Grassmann manifold that allows local matrix completion by different\nagents while achieving asymptotic consensus on the global low-rank factors. The\nresulting approach is scalable and parallelizable. Our numerical experiments\nshow the good performance of the proposed algorithms on various benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 10:46:08 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Mishra", "Bamdev", ""], ["Kasai", "Hiroyuki", ""], ["Saroop", "Atul", ""]]}, {"id": "1605.07246", "submitter": "Zheng Xu", "authors": "Zheng Xu, Mario A. T. Figueiredo, Tom Goldstein", "title": "Adaptive ADMM with Spectral Penalty Parameter Selection", "comments": "AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alternating direction method of multipliers (ADMM) is a versatile tool\nfor solving a wide range of constrained optimization problems, with\ndifferentiable or non-differentiable objective functions. Unfortunately, its\nperformance is highly sensitive to a penalty parameter, which makes ADMM often\nunreliable and hard to automate for a non-expert user. We tackle this weakness\nof ADMM by proposing a method to adaptively tune the penalty parameters to\nachieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm,\ninspired by the successful Barzilai-Borwein spectral method for gradient\ndescent, yields fast convergence and relative insensitivity to the initial\nstepsize and problem scaling.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 00:48:28 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 19:21:26 GMT"}, {"version": "v3", "created": "Fri, 9 Sep 2016 19:51:17 GMT"}, {"version": "v4", "created": "Wed, 25 Jan 2017 18:49:04 GMT"}, {"version": "v5", "created": "Wed, 19 Jul 2017 16:23:11 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Xu", "Zheng", ""], ["Figueiredo", "Mario A. T.", ""], ["Goldstein", "Tom", ""]]}, {"id": "1605.07367", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai, Hiroyuki Sato, and Bamdev Mishra", "title": "Riemannian stochastic variance reduced gradient on Grassmann manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variance reduction algorithms have recently become popular for\nminimizing the average of a large, but finite, number of loss functions. In\nthis paper, we propose a novel Riemannian extension of the Euclidean stochastic\nvariance reduced gradient algorithm (R-SVRG) to a compact manifold search\nspace. To this end, we show the developments on the Grassmann manifold. The key\nchallenges of averaging, addition, and subtraction of multiple gradients are\naddressed with notions like logarithm mapping and parallel translation of\nvectors on the Grassmann manifold. We present a global convergence analysis of\nthe proposed algorithm with decay step-sizes and a local convergence rate\nanalysis under fixed step-size with some natural assumptions. The proposed\nalgorithm is applied on a number of problems on the Grassmann manifold like\nprincipal components analysis, low-rank matrix completion, and the Karcher mean\ncomputation. In all these cases, the proposed algorithm outperforms the\nstandard Riemannian stochastic gradient descent algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 10:36:32 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 12:55:11 GMT"}, {"version": "v3", "created": "Sun, 9 Apr 2017 06:17:52 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Kasai", "Hiroyuki", ""], ["Sato", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1605.07646", "submitter": "Shengxin Zhu", "authors": "Shengxin Zhu, Tongxiang Gu, Xingping Liu", "title": "AIMS:Average Information Matrix Splitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For linear mixed models with co-variance matrices which are not linearly\ndependent on variance component parameters, we prove that the average of the\nobserved information and the Fisher information can be split into two parts.\nThe essential part enjoys a simple and computational friendly formula, while\nthe other part which involves a lot of computations is a random zero matrix and\nthus is negligible.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 20:16:42 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2016 03:54:26 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 03:09:40 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 06:16:39 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Zhu", "Shengxin", ""], ["Gu", "Tongxiang", ""], ["Liu", "Xingping", ""]]}, {"id": "1605.07658", "submitter": "Kalyana Babu Nakshatrala", "authors": "K. B. Nakshatrala, S. H. S. Joodat, and R. Ballarini", "title": "Modeling flow in porous media with double porosity/permeability:\n  Mathematical model, properties, and analytical solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geo-materials such as vuggy carbonates are known to exhibit multiple spatial\nscales. A common manifestation of spatial scales is the presence of (at least)\ntwo different scales of pores, which is commonly referred to as double\nporosity. To complicate things, the pore-network at each scale exhibits\ndifferent permeability, and these networks are connected through fissure and\nconduits. Although some models are available in the literature, they lack a\nstrong theoretical basis. This paper aims to fill this lacuna by providing the\nmuch needed theoretical foundations of the flow in porous media which exhibit\ndouble porosity/permeability. We first obtain a mathematical model for double\nporosity/permeability using the maximization of rate of dissipation hypothesis,\nand thereby providing a firm thermodynamic underpinning. We then present, along\nwith mathematical proofs, several important mathematical properties that the\nsolutions to the double porosity/permeability model satisfy. These properties\nare important in their own right as well as serve as good (mechanics-based) a\nposteriori measures to assess the accuracy of numerical solutions. We also\npresent several canonical problems and obtain the corresponding analytical\nsolutions, which are used to gain insights into the velocity and pressure\nprofiles, and the mass transfer across the two pore-networks. In particular, we\nhighlight how the solutions under the double porosity/permeability differ from\nthe corresponding solutions under Darcy equations.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 21:26:40 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 20:58:03 GMT"}, {"version": "v3", "created": "Tue, 6 Mar 2018 16:51:33 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Nakshatrala", "K. B.", ""], ["Joodat", "S. H. S.", ""], ["Ballarini", "R.", ""]]}, {"id": "1605.07811", "submitter": "Jon Cockayne", "authors": "Jon Cockayne, Chris Oates, Tim Sullivan, Mark Girolami", "title": "Probabilistic Numerical Methods for Partial Differential Equations and\n  Bayesian Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.NA math.NA math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a probabilistic numerical method for solution of partial\ndifferential equations (PDEs) and studies application of that method to\nPDE-constrained inverse problems. This approach enables the solution of\nchallenging inverse problems whilst accounting, in a statistically principled\nway, for the impact of discretisation error due to numerical solution of the\nPDE. In particular, the approach confers robustness to failure of the numerical\nPDE solver, with statistical inferences driven to be more conservative in the\npresence of substantial discretisation error. Going further, the problem of\nchoosing a PDE solver is cast as a problem in the Bayesian design of\nexperiments, where the aim is to minimise the impact of solver error on\nstatistical inferences; here the challenge of non-linear PDEs is also\nconsidered. The method is applied to parameter inference problems in which\ndiscretisation error in non-negligible and must be accounted for in order to\nreach conclusions that are statistically valid.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 10:22:19 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 08:55:10 GMT"}, {"version": "v3", "created": "Tue, 11 Jul 2017 15:22:34 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Cockayne", "Jon", ""], ["Oates", "Chris", ""], ["Sullivan", "Tim", ""], ["Girolami", "Mark", ""]]}, {"id": "1605.07859", "submitter": "Bahman Kalantari", "authors": "Terence Coelho and Bahman Kalantari", "title": "How Many Real Attractive Fixed Points Can A Polynomial Have?", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a complex polynomial of degree $n$ has at most $\\lceil n/2 \\rceil$\nattractive fixed points lying on a line. We also consider the general case.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 12:42:04 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Coelho", "Terence", ""], ["Kalantari", "Bahman", ""]]}, {"id": "1605.08134", "submitter": "Hao Ji", "authors": "Hao Ji, Wenjian Yu, Yaohang Li", "title": "A Rank Revealing Randomized Singular Value Decomposition (R3SVD)\n  Algorithm for Low-rank Matrix Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Rank Revealing Randomized Singular Value\nDecomposition (R3SVD) algorithm to incrementally construct a low-rank\napproximation of a potentially large matrix while adaptively estimating the\nappropriate rank that can capture most of the actions of the matrix. Starting\nfrom a low-rank approximation with an initial guessed rank, R3SVD adopts an\northogonal Gaussian sampling approach to obtain the dominant subspace within\nthe leftover space, which is used to add up to the existing low-rank\napproximation. Orthogonal Gaussian sampling is repeated until an appropriate\nlow-rank approximation with satisfactory accuracy, measured by the overall\nenergy percentage of the original matrix, is obtained. While being a fast\nalgorithm, R3SVD is also a memory-aware algorithm where the computational\nprocess can be decomposed into a series of sampling tasks that use constant\namount of memory. Numerical examples in image compression and matrix completion\nare used to demonstrate the effectiveness of R3SVD in low-rank approximation.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 03:17:33 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Ji", "Hao", ""], ["Yu", "Wenjian", ""], ["Li", "Yaohang", ""]]}, {"id": "1605.08257", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai and Bamdev Mishra", "title": "Low-rank tensor completion: a Riemannian manifold preconditioning\n  approach", "comments": "The 33rd International Conference on Machine Learning (ICML 2016).\n  arXiv admin note: substantial text overlap with arXiv:1506.02159", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Riemannian manifold preconditioning approach for the\ntensor completion problem with rank constraint. A novel Riemannian metric or\ninner product is proposed that exploits the least-squares structure of the cost\nfunction and takes into account the structured symmetry that exists in Tucker\ndecomposition. The specific metric allows to use the versatile framework of\nRiemannian optimization on quotient manifolds to develop preconditioned\nnonlinear conjugate gradient and stochastic gradient descent algorithms for\nbatch and online setups, respectively. Concrete matrix representations of\nvarious optimization-related ingredients are listed. Numerical comparisons\nsuggest that our proposed algorithms robustly outperform state-of-the-art\nalgorithms across different synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 12:55:02 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Kasai", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1605.08771", "submitter": "Eric Polizzi", "authors": "Brendan Gavin, Eric Polizzi", "title": "Enhancing the Performance and Robustness of the FEAST Eigensolver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FEAST algorithm is a subspace iteration method that uses a spectral\nprojector as a rational filter in order to efficiently solve interior\neigenvalue problems in parallel. Although the solutions from the FEAST\nalgorithm converge rapidly in many cases, convergence can be slow in situations\nwhere the eigenvalues of a matrix are densely populated near the edges of the\nsearch interval of interest, which can be detrimental to parallel load\nbalancing. This work introduces two methods that allow one to improve the\nconvergence robustness of the FEAST algorithm in these situations without\nhaving to increase the amount of computation. Selected numerical examples are\npresented and discussed\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 19:54:39 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Gavin", "Brendan", ""], ["Polizzi", "Eric", ""]]}, {"id": "1605.09049", "submitter": "Krzysztof Choromanski", "authors": "Krzysztof Choromanski, Vikas Sindhwani", "title": "Recycling Randomness with Structure for Sublinear time Kernel Expansions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scheme for recycling Gaussian random vectors into structured\nmatrices to approximate various kernel functions in sublinear time via random\nembeddings. Our framework includes the Fastfood construction as a special case,\nbut also extends to Circulant, Toeplitz and Hankel matrices, and the broader\nfamily of structured matrices that are characterized by the concept of\nlow-displacement rank. We introduce notions of coherence and graph-theoretic\nstructural constants that control the approximation quality, and prove\nunbiasedness and low-variance properties of random feature maps that arise\nwithin our framework. For the case of low-displacement matrices, we show how\nthe degree of structure and randomness can be controlled to reduce statistical\nvariance at the cost of increased computation and storage requirements.\nEmpirical results strongly support our theory and justify the use of a broader\nfamily of structured matrices for scaling up kernel methods using random\nfeatures.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 19:21:22 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1605.09148", "submitter": "Michael Schaub", "authors": "Michael T. Schaub, Maguy Trefois, Paul Van Dooren, Jean-Charles\n  Delvenne", "title": "Sparse matrix factorizations for fast linear solvers with application to\n  Laplacian systems", "comments": "20 pages, 2 figures", "journal-ref": "SIAM J. Matrix Anal. Appl., 38(2), 505-529, 2017", "doi": "10.1137/16M1077398", "report-no": null, "categories": "cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In solving a linear system with iterative methods, one is usually confronted\nwith the dilemma of having to choose between cheap, inefficient iterates over\nsparse search directions (e.g., coordinate descent), or expensive iterates in\nwell-chosen search directions (e.g., conjugate gradients). In this paper, we\npropose to interpolate between these two extremes, and show how to perform\ncheap iterations along non-sparse search directions, provided that these\ndirections can be extracted from a new kind of sparse factorization. For\nexample, if the search directions are the columns of a hierarchical matrix,\nthen the cost of each iteration is typically logarithmic in the number of\nvariables. Using some graph-theoretical results on low-stretch spanning trees,\nwe deduce as a special case a nearly-linear time algorithm to approximate the\nminimal norm solution of a linear system $Bx= b$ where $B$ is the incidence\nmatrix of a graph. We thereby can connect our results to recently proposed\nnearly-linear time solvers for Laplacian systems, which emerge here as a\nparticular application of our sparse matrix factorization.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 09:15:16 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 01:04:01 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Schaub", "Michael T.", ""], ["Trefois", "Maguy", ""], ["Van Dooren", "Paul", ""], ["Delvenne", "Jean-Charles", ""]]}, {"id": "1605.09181", "submitter": "Krzysztof Domino", "authors": "Krzysztof Domino", "title": "The use of the multi-cumulant tensor analysis for the algorithmic\n  optimisation of investment portfolios", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": "10.1016/j.physa.2016.10.042", "report-no": null, "categories": "q-fin.PM cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cumulant analysis plays an important role in non Gaussian distributed\ndata analysis. The shares' prices returns are good example of such data. The\npurpose of this research is to develop the cumulant based algorithm and use it\nto determine eigenvectors that represent investment portfolios with low\nvariability. Such algorithm is based on the Alternating Least Square method and\ninvolves the simultaneous minimisation 2'nd -- 6'th cumulants of the\nmultidimensional random variable (percentage shares' returns of many\ncompanies). Then the algorithm was tested during the recent crash on the Warsaw\nStock Exchange. To determine incoming crash and provide enter and exit signal\nfor the investment strategy the Hurst exponent was calculated using the local\nDFA. It was shown that introduced algorithm is on average better that benchmark\nand other portfolio determination methods, but only within examination window\ndetermined by low values of the Hurst exponent. Remark that the algorithm of is\nbased on cumulant tensors up to the 6'th order calculated for a\nmultidimensional random variable, what is the novel idea. It can be expected\nthat the algorithm would be useful in the financial data analysis on the world\nwide scale as well as in the analysis of other types of non Gaussian\ndistributed data.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 11:34:31 GMT"}, {"version": "v2", "created": "Thu, 25 Aug 2016 07:13:24 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Domino", "Krzysztof", ""]]}, {"id": "1605.09232", "submitter": "Raja Giryes", "authors": "Raja Giryes and Yonina C. Eldar and Alex M. Bronstein and Guillermo\n  Sapiro", "title": "Tradeoffs between Convergence Speed and Reconstruction Accuracy in\n  Inverse Problems", "comments": "To appear in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving inverse problems with iterative algorithms is popular, especially for\nlarge data. Due to time constraints, the number of possible iterations is\nusually limited, potentially affecting the achievable accuracy. Given an error\none is willing to tolerate, an important question is whether it is possible to\nmodify the original iterations to obtain faster convergence to a minimizer\nachieving the allowed error without increasing the computational cost of each\niteration considerably. Relying on recent recovery techniques developed for\nsettings in which the desired signal belongs to some low-dimensional set, we\nshow that using a coarse estimate of this set may lead to faster convergence at\nthe cost of an additional reconstruction error related to the accuracy of the\nset approximation. Our theory ties to recent advances in sparse recovery,\ncompressed sensing, and deep learning. Particularly, it may provide a possible\nexplanation to the successful approximation of the l1-minimization solution by\nneural networks with layers representing iterations, as practiced in the\nlearned iterative shrinkage-thresholding algorithm (LISTA).\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 13:43:59 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 17:43:20 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 10:53:57 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Giryes", "Raja", ""], ["Eldar", "Yonina C.", ""], ["Bronstein", "Alex M.", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1605.09527", "submitter": "Thomas Goldstein", "authors": "Sohil Shah, Abhay Kumar, Carlos Castillo, David Jacobs, Christoph\n  Studer, Tom Goldstein", "title": "Biconvex Relaxation for Semidefinite Programming in Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semidefinite programming is an indispensable tool in computer vision, but\ngeneral-purpose solvers for semidefinite programs are often too slow and memory\nintensive for large-scale problems. We propose a general framework to\napproximately solve large-scale semidefinite problems (SDPs) at low complexity.\nOur approach, referred to as biconvex relaxation (BCR), transforms a general\nSDP into a specific biconvex optimization problem, which can then be solved in\nthe original, low-dimensional variable space at low complexity. The resulting\nbiconvex problem is solved using an efficient alternating minimization (AM)\nprocedure. Since AM has the potential to get stuck in local minima, we propose\na general initialization scheme that enables BCR to start close to a global\noptimum - this is key for our algorithm to quickly converge to optimal or\nnear-optimal solutions. We showcase the efficacy of our approach on three\napplications in computer vision, namely segmentation, co-segmentation, and\nmanifold metric learning. BCR achieves solution quality comparable to\nstate-of-the-art SDP methods with speedups between 4X and 35X. At the same\ntime, BCR handles a more general set of SDPs than previous approaches, which\nare more specialized.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 08:43:44 GMT"}, {"version": "v2", "created": "Mon, 8 Aug 2016 23:23:28 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Shah", "Sohil", ""], ["Kumar", "Abhay", ""], ["Castillo", "Carlos", ""], ["Jacobs", "David", ""], ["Studer", "Christoph", ""], ["Goldstein", "Tom", ""]]}]