[{"id": "1701.00016", "submitter": "Jeremy Kepner", "authors": "Connor Sell, Jeremy Kepner", "title": "Non-Negative Matrix Factorization Test Cases", "comments": "4 pages, 3 figures, to appear in the proceedings of the 2015 IEEE MIT\n  Undergraduate Research Conference", "journal-ref": null, "doi": "10.1109/URTC.2016.8284085", "report-no": null, "categories": "math.NA cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is a prob- lem with many\napplications, ranging from facial recognition to document clustering. However,\ndue to the variety of algorithms that solve NMF, the randomness involved in\nthese algorithms, and the somewhat subjective nature of the problem, there is\nno clear \"correct answer\" to any particular NMF problem, and as a result, it\ncan be hard to test new algorithms. This paper suggests some test cases for NMF\nalgorithms derived from matrices with enumerable exact non-negative\nfactorizations and perturbations of these matrices. Three algorithms using\nwidely divergent approaches to NMF all give similar solutions over these test\ncases, suggesting that these test cases could be used as test cases for\nimplementations of these existing NMF algorithms as well as potentially new NMF\nalgorithms. This paper also describes how the proposed test cases could be used\nin practice.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 21:18:01 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Sell", "Connor", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1701.00392", "submitter": "Christoph Boeddeker", "authors": "Christoph Boeddeker and Patrick Hanebrink and Lukas Drude and Jahn\n  Heymann and Reinhold Haeb-Umbach", "title": "On the Computation of Complex-valued Gradients with Application to\n  Statistically Optimum Beamforming", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report describes the computation of gradients by algorithmic\ndifferentiation for statistically optimum beamforming operations. Especially\nthe derivation of complex-valued functions is a key component of this approach.\nTherefore the real-valued algorithmic differentiation is extended via the\ncomplex-valued chain rule. In addition to the basic mathematic operations the\nderivative of the eigenvalue problem with complex-valued eigenvectors is one of\nthe key results of this report. The potential of this approach is shown with\nexperimental results on the CHiME-3 challenge database. There, the beamforming\ntask is used as a front-end for an ASR system. With the developed derivatives a\njoint optimization of a speech enhancement and speech recognition system w.r.t.\nthe recognition optimization criterion is possible.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 14:03:38 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 10:08:28 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Boeddeker", "Christoph", ""], ["Hanebrink", "Patrick", ""], ["Drude", "Lukas", ""], ["Heymann", "Jahn", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1701.00573", "submitter": "Gonzalo Otazu", "authors": "Gonzalo H Otazu", "title": "Robust method for finding sparse solutions to linear inverse problems\n  using an L2 regularization", "comments": "13 pages, 6 figures. Code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyzed the performance of a biologically inspired algorithm called the\nCorrected Projections Algorithm (CPA) when a sparseness constraint is required\nto unambiguously reconstruct an observed signal using atoms from an\novercomplete dictionary. By changing the geometry of the estimation problem,\nCPA gives an analytical expression for a binary variable that indicates the\npresence or absence of a dictionary atom using an L2 regularizer. The\nregularized solution can be implemented using an efficient real-time\nKalman-filter type of algorithm. The smoother L2 regularization of CPA makes it\nvery robust to noise, and CPA outperforms other methods in identifying known\natoms in the presence of strong novel atoms in the signal.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 03:31:03 GMT"}, {"version": "v2", "created": "Sun, 8 Jan 2017 05:38:58 GMT"}, {"version": "v3", "created": "Wed, 22 Mar 2017 22:19:57 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Otazu", "Gonzalo H", ""]]}, {"id": "1701.00694", "submitter": "Ming Yan", "authors": "Xiaolin Huang and Yan Xia and Lei Shi and Yixing Huang and Ming Yan\n  and Joachim Hornegger and Andreas Maier", "title": "Mixed one-bit compressive sensing with applications to overexposure\n  correction for CT reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a measurement falls outside the quantization or measurable range, it\nbecomes saturated and cannot be used in classical reconstruction methods. For\nexample, in C-arm angiography systems, which provide projection radiography,\nfluoroscopy, digital subtraction angiography, and are widely used for medical\ndiagnoses and interventions, the limited dynamic range of C-arm flat detectors\nleads to overexposure in some projections during an acquisition, such as\nimaging relatively thin body parts (e.g., the knee). Aiming at overexposure\ncorrection for computed tomography (CT) reconstruction, we in this paper\npropose a mixed one-bit compressive sensing (M1bit-CS) to acquire information\nfrom both regular and saturated measurements. This method is inspired by the\nrecent progress on one-bit compressive sensing, which deals with only sign\nobservations. Its successful applications imply that information carried by\nsaturated measurements is useful to improve recovery quality. For the proposed\nM1bit-CS model, alternating direction methods of multipliers is developed and\nan iterative saturation detection scheme is established. Then we evaluate\nM1bit-CS on one-dimensional signal recovery tasks. In some experiments, the\nperformance of the proposed algorithms on mixed measurements is almost the same\nas recovery on unsaturated ones with the same amount of measurements. Finally,\nwe apply the proposed method to overexposure correction for CT reconstruction\non a phantom and a simulated clinical image. The results are promising, as the\ntypical streaking artifacts and capping artifacts introduced by saturated\nprojection data are effectively reduced, yielding significant error reduction\ncompared with existing algorithms based on extrapolation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 14:35:33 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Huang", "Xiaolin", ""], ["Xia", "Yan", ""], ["Shi", "Lei", ""], ["Huang", "Yixing", ""], ["Yan", "Ming", ""], ["Hornegger", "Joachim", ""], ["Maier", "Andreas", ""]]}, {"id": "1701.00722", "submitter": "Laslo Hunhold", "authors": "Laslo Hunhold", "title": "The Unum Number Format: Mathematical Foundations, Implementation and\n  Comparison to IEEE 754 Floating-Point Numbers", "comments": "95 pages, 7 figures, 14 code listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This thesis examines a modern concept for machine numbers based on interval\narithmetic called 'Unums' and compares it to IEEE 754 floating-point\narithmetic, evaluating possible uses of this format where floating-point\nnumbers are inadequate. In the course of this examination, this thesis builds\ntheoretical foundations for IEEE 754 floating-point numbers, interval\narithmetic based on the projectively extended real numbers and Unums.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 23:21:43 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Hunhold", "Laslo", ""]]}, {"id": "1701.01359", "submitter": "Daniel Ruprecht", "authors": "Daniel Ruprecht", "title": "Wave propagation characteristics of Parareal", "comments": null, "journal-ref": "Computing and Visualization in Science 19(1), pp. 1- 17, 2018", "doi": "10.1007/s00791-018-0296-z", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper derives and analyses the (semi-)discrete dispersion relation of the\nParareal parallel-in-time integration method. It investigates Parareal's wave\npropagation characteristics with the aim to better understand what causes the\nwell documented stability problems for hyperbolic equations. The analysis shows\nthat the instability is caused by convergence of the amplification factor to\nthe exact value from above for medium to high wave numbers. Phase errors in the\ncoarse propagator are identified as the culprit, which suggests that\nspecifically tailored coarse level methods could provide a remedy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 15:49:54 GMT"}, {"version": "v2", "created": "Sat, 14 Oct 2017 12:33:08 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Ruprecht", "Daniel", ""]]}, {"id": "1701.01477", "submitter": "Evgeniy Abramov G.", "authors": "E. G. Abramov", "title": "Unconstrained inverse quadratic programming problem", "comments": "7 pages with 1 Octave script", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper covers a formulation of the inverse quadratic programming problem\nin terms of unconstrained optimization where it is required to find the unknown\nparameters (the matrix of the quadratic form and the vector of the quasi-linear\npart of the quadratic form) provided that approximate estimates of the optimal\nsolution of the direct problem and those of the target function to be minimized\nin the form of pairs of values lying in the corresponding neighborhoods are\nonly known. The formulation of the inverse problem and its solution are based\non the least squares method. In the explicit form the inverse problem solution\nhas been derived in the form a system of linear equations. The parameters\nobtained can be used for reconstruction of the direct quadratic programming\nproblem and determination of the optimal solution and the extreme value of the\ntarget function, which were not known formerly. It is possible this approach\nopens new ways in over applications, for example, in neurocomputing and quadric\nsurfaces fitting. Simple numerical examples have been demonstrated. A scenario\nin the Octave/MATLAB programming language has been proposed for practical\nimplementation of the method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 15:48:59 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Abramov", "E. G.", ""]]}, {"id": "1701.01780", "submitter": "Stephen Kruzick", "authors": "Stephen Kruzick and Jos\\'e M. F. Moura", "title": "Spectral Statistics of Lattice Graph Structured, Non-uniform\n  Percolations", "comments": "ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of filters for graph signal processing benefits from knowledge of the\nspectral decomposition of matrices that encode graphs, such as the adjacency\nmatrix and the Laplacian matrix, used to define the shift operator. For shift\nmatrices with real eigenvalues, which arise for symmetric graphs, the empirical\nspectral distribution captures the eigenvalue locations. Under realistic\ncircumstances, stochastic influences often affect the network structure and,\nconsequently, the shift matrix empirical spectral distribution. Nevertheless,\ndeterministic functions may often be found to approximate the asymptotic\nbehavior of empirical spectral distributions of random matrices. This paper\nuses stochastic canonical equation methods developed by Girko to derive such\ndeterministic equivalent distributions for the empirical spectral distributions\nof random graphs formed by structured, non-uniform percolation of a\nD-dimensional lattice supergraph. Included simulations demonstrate the results\nfor sample parameters.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2017 23:57:07 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Kruzick", "Stephen", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "1701.01994", "submitter": "Mark Giesbrecht", "authors": "Mark Giesbrecht and Joseph Haraldson and Erich Kaltofen", "title": "Computing Approximate Greatest Common Right Divisors of Differential\n  Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential (Ore) type polynomials with \"approximate\" polynomial\ncoefficients are introduced. These provide an effective notion of approximate\ndifferential operators, with a strong algebraic structure. We introduce the\napproximate Greatest Common Right Divisor Problem (GCRD) of differential\npolynomials, as a non-commutative generalization of the well-studied\napproximate GCD problem.\n  Given two differential polynomials, we present an algorithm to find nearby\ndifferential polynomials with a non-trivial GCRD, where nearby is defined with\nrespect to a suitable coefficient norm. Intuitively, given two linear\ndifferential polynomials as input, the (approximate) GCRD problem corresponds\nto finding the (approximate) differential polynomial whose solution space is\nthe intersection of the solution spaces of the two inputs.\n  The approximate GCRD problem is proven to be locally well-posed. A method\nbased on the singular value decomposition of a differential Sylvester matrix is\ndeveloped to produce an initial approximation of the GCRD. With a sufficiently\ngood initial approximation, Newton iteration is shown to converge quadratically\nto an optimal solution. Finally, sufficient conditions for existence of a\nsolution to the global problem are presented along with examples demonstrating\nthat no solution exists when these conditions are not satisfied.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 18:06:21 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 18:40:29 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Giesbrecht", "Mark", ""], ["Haraldson", "Joseph", ""], ["Kaltofen", "Erich", ""]]}, {"id": "1701.02161", "submitter": "Martin Vohralik", "authors": "Alexandre Ern and Martin Vohral\\'ik", "title": "Stable broken $H^1$ and $\\bf H(\\mathrm{div})$ polynomial extensions for\n  polynomial-degree-robust potential and flux reconstruction in three space\n  dimensions", "comments": null, "journal-ref": "Mathematics of Computation, 2019", "doi": "10.1090/mcom/3482", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study extensions of piecewise polynomial data prescribed on faces and\npossibly in elements of a patch of simplices sharing a vertex. In the $H^1$\nsetting, we look for functions whose jumps across the faces are prescribed,\nwhereas in the ${\\bf H}(\\mathrm{div})$ setting, the normal component jumps and\nthe piecewise divergence are prescribed. We show stability in the sense that\nthe minimizers over piecewise polynomial spaces of the same degree as the data\nare subordinate in the broken energy norm to the minimizers over the whole\nbroken $H^1$ and ${\\bf H}(\\mathrm{div})$ spaces. Our proofs are constructive\nand yield constants independent of the polynomial degree. One particular\napplication of these results is in a posteriori error analysis, where the\npresent results justify polynomial-degree-robust efficiency of potential and\nflux reconstructions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 13:00:28 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 20:06:52 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 15:06:03 GMT"}, {"version": "v4", "created": "Fri, 4 Oct 2019 11:39:15 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Ern", "Alexandre", ""], ["Vohral\u00edk", "Martin", ""]]}, {"id": "1701.02324", "submitter": "Chenhan Yu", "authors": "Chenhan D. Yu, William B. March, George Biros", "title": "An $N \\log N$ Parallel Fast Direct Solver for Kernel Matrices", "comments": "proceeding 31st IEEE International Parallel & Distributed Processing\n  Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel matrices appear in machine learning and non-parametric statistics.\nGiven $N$ points in $d$ dimensions and a kernel function that requires\n$\\mathcal{O}(d)$ work to evaluate, we present an $\\mathcal{O}(dN\\log N)$-work\nalgorithm for the approximate factorization of a regularized kernel matrix, a\ncommon computational bottleneck in the training phase of a learning task. With\nthis factorization, solving a linear system with a kernel matrix can be done\nwith $\\mathcal{O}(N\\log N)$ work. Our algorithm only requires kernel\nevaluations and does not require that the kernel matrix admits an efficient\nglobal low rank approximation. Instead our factorization only assumes low-rank\nproperties for the off-diagonal blocks under an appropriate row and column\nordering. We also present a hybrid method that, when the factorization is\nprohibitively expensive, combines a partial factorization with iterative\nmethods. As a highlight, we are able to approximately factorize a dense\n$11M\\times11M$ kernel matrix in 2 minutes on 3,072 x86 \"Haswell\" cores and a\n$4.5M\\times4.5M$ matrix in 1 minute using 4,352 \"Knights Landing\" cores.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 19:11:10 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Yu", "Chenhan D.", ""], ["March", "William B.", ""], ["Biros", "George", ""]]}, {"id": "1701.03240", "submitter": "Kevin Carlberg", "authors": "Sumeet Trehan, Kevin Carlberg, Louis J. Durlofsky", "title": "Error modeling for surrogates of dynamical systems using machine\n  learning", "comments": "International Journal for Numerical Methods in Engineering, in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine-learning-based framework for modeling the error introduced by\nsurrogate models of parameterized dynamical systems is proposed. The framework\nentails the use of high-dimensional regression techniques (e.g., random\nforests, LASSO) to map a large set of inexpensively computed `error indicators'\n(i.e., features) produced by the surrogate model at a given time instance to a\nprediction of the surrogate-model error in a quantity of interest (QoI). This\neliminates the need for the user to hand-select a small number of informative\nfeatures. The methodology requires a training set of parameter instances at\nwhich the time-dependent surrogate-model error is computed by simulating both\nthe high-fidelity and surrogate models. Using these training data, the method\nfirst determines regression-model locality (via classification or clustering),\nand subsequently constructs a `local' regression model to predict the\ntime-instantaneous error within each identified region of feature space. We\nconsider two uses for the resulting error model: (1) as a correction to the\nsurrogate-model QoI prediction at each time instance, and (2) as a way to\nstatistically model arbitrary functions of the time-dependent surrogate-model\nerror (e.g., time-integrated errors). We apply the proposed framework to model\nerrors in reduced-order models of nonlinear oil--water subsurface flow\nsimulations. The reduced-order models used in this work entail application of\ntrajectory piecewise linearization with proper orthogonal decomposition. When\nthe first use of the method is considered, numerical experiments demonstrate\nconsistent improvement in accuracy in the time-instantaneous QoI prediction\nrelative to the original surrogate model, across a large number of test cases.\nWhen the second use is considered, results show that the proposed method\nprovides accurate statistical predictions of the time- and well-averaged\nerrors.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 05:42:22 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 19:01:20 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Trehan", "Sumeet", ""], ["Carlberg", "Kevin", ""], ["Durlofsky", "Louis J.", ""]]}, {"id": "1701.03477", "submitter": "Marc Olm", "authors": "Santiago Badia and Marc Olm", "title": "Space-time balancing domain decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose two-level space-time domain decomposition\npreconditioners for parabolic problems discretized using finite elements. They\nare motivated as an extension to space-time of balancing domain decomposition\nby constraints preconditioners. The key ingredients to be defined are the\nsub-assembled space and operator, the coarse degrees of freedom (DOFs) in which\nwe want to enforce continuity among subdomains at the preconditioner level, and\nthe transfer operator from the sub-assembled to the original finite element\nspace. With regard to the sub-assembled operator, a perturbation of the time\nderivative is needed to end up with a well-posed preconditioner. The set of\ncoarse DOFs includes the time average (at the space-time subdomain) of\nclassical space constraints plus new constraints between consecutive subdomains\nin time. Numerical experiments show that the proposed schemes are weakly\nscalable in time, i.e., we can efficiently exploit increasing computational\nresources to solve more time steps in the same {total elapsed} time. Further,\nthe scheme is also weakly space-time scalable, since it leads to asymptotically\nconstant iterations when solving larger problems both in space and time.\nExcellent {wall clock} time weak scalability is achieved for space-time\nparallel solvers on some thousands of cores.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 19:32:09 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Badia", "Santiago", ""], ["Olm", "Marc", ""]]}, {"id": "1701.03720", "submitter": "Azam Moosavi", "authors": "Azam Moosavi, Razvan Stefanescu, Adrian Sandu", "title": "Multivariate predictions of local reduced-order-model errors and\n  dimensions", "comments": "19 pages, 15 figures, 7 tables. arXiv admin note: substantial text\n  overlap with arXiv:1511.02909", "journal-ref": null, "doi": null, "report-no": "CSL-2017-1", "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces multivariate input-output models to predict the errors\nand bases dimensions of local parametric Proper Orthogonal Decomposition\nreduced-order models. We refer to these multivariate mappings as the MP-LROM\nmodels. We employ Gaussian Processes and Artificial Neural Networks to\nconstruct approximations of these multivariate mappings. Numerical results with\na viscous Burgers model illustrate the performance and potential of the machine\nlearning based regression MP-LROM models to approximate the characteristics of\nparametric local reduced-order models. The predicted reduced-order models\nerrors are compared against the multi-fidelity correction and reduced order\nmodel error surrogates methods predictions, whereas the predicted reduced-order\ndimensions are tested against the standard method based on the spectrum of\nsnapshots matrix. Since the MP-LROM models incorporate more features and\nelements to construct the probabilistic mappings they achieve more accurate\nresults. However, for high-dimensional parametric spaces, the MP-LROM models\nmight suffer from the curse of dimensionality. Scalability challenges of\nMP-LROM models and the feasible ways of addressing them are also discussed in\nthis study.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 16:49:25 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Moosavi", "Azam", ""], ["Stefanescu", "Razvan", ""], ["Sandu", "Adrian", ""]]}, {"id": "1701.03787", "submitter": "Mikael Mortensen", "authors": "Mikael Mortensen", "title": "A spectral-Galerkin turbulent channel flow solver for large-scale\n  simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fully (pseudo-)spectral solver for direct numerical simulations of\nlarge-scale turbulent channel flows is described. The solver utilizes the\nChebyshev base functions suggested by J. Shen [SIAM J. Sci. Comput., 16, 1,\n1995], that lead to stable and robust numerical schemes, even at very large\nscale. New and fast algorithms for the direct solution of the linear systems\nare devised, and algorithms and matrices for all required scalar products and\ntransforms are provided. We validate the solver for very high Reynolds numbers.\nSpecifically, the solver is shown to reproduce the first order statistics of\nHoyas and Jim\\'{e}nez [Phys. Fluids, 18(1), 2006], for a channel flow at\n$Re_{\\tau}=2000$. The solver is available through the open source project\nspectralDNS [https://github.com/spectralDNS].\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 13:50:16 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Mortensen", "Mikael", ""]]}, {"id": "1701.03989", "submitter": "Erin Carson", "authors": "Erin Carson", "title": "The Adaptive $s$-step Conjugate Gradient Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On modern large-scale parallel computers, the performance of Krylov subspace\niterative methods is limited by global synchronization. This has inspired the\ndevelopment of $s$-step Krylov subspace method variants, in which iterations\nare computed in blocks of $s$, which can reduce the number of global\nsynchronizations per iteration by a factor of $O(s)$.\n  Although the $s$-step variants are mathematically equivalent to their\nclassical counterparts, they can behave quite differently in finite precision\ndepending on the parameter $s$. If $s$ is chosen too large, the $s$-step method\ncan suffer a convergence delay and a decrease in attainable accuracy relative\nto the classical method. This makes it difficult for a potential user of such\nmethods - the $s$ value that minimizes the time per iteration may not be the\nbest $s$ for minimizing the overall time-to-solution, and further may cause an\nunacceptable decrease in accuracy.\n  Towards improving the reliability and usability of $s$-step Krylov subspace\nmethods, in this work we derive the \\emph{adaptive $s$-step CG method}, a\nvariable $s$-step CG method where in block $k$, the parameter $s_k$ is\ndetermined automatically such that a user-specified accuracy is attainable. The\nmethod for determining $s_k$ is based on a bound on growth of the residual gap\nwithin block $k$, from which we derive a constraint on the condition numbers of\nthe computed $O(s_k)$-dimensional Krylov subspace bases. The computations\nrequired for determining the block size $s_k$ can be performed without\nincreasing the number of global synchronizations per block. Our numerical\nexperiments demonstrate that the adaptive $s$-step CG method is able to attain\nup to the same accuracy as classical CG while still significantly reducing the\ntotal number of global synchronizations.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 03:17:00 GMT"}], "update_date": "2017-02-12", "authors_parsed": [["Carson", "Erin", ""]]}, {"id": "1701.04006", "submitter": "Jon Cockayne", "authors": "Jon Cockayne, Chris Oates, Tim Sullivan, Mark Girolami", "title": "Probabilistic Numerical Methods for PDE-constrained Bayesian Inverse\n  Problems", "comments": null, "journal-ref": null, "doi": "10.1063/1.4985359", "report-no": null, "categories": "stat.ME cs.NA math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops meshless methods for probabilistically describing\ndiscretisation error in the numerical solution of partial differential\nequations. This construction enables the solution of Bayesian inverse problems\nwhile accounting for the impact of the discretisation of the forward problem.\nIn particular, this drives statistical inferences to be more conservative in\nthe presence of significant solver error. Theoretical results are presented\ndescribing rates of convergence for the posteriors in both the forward and\ninverse problems. This method is tested on a challenging inverse problem with a\nnonlinear forward model.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 08:50:06 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Cockayne", "Jon", ""], ["Oates", "Chris", ""], ["Sullivan", "Tim", ""], ["Girolami", "Mark", ""]]}, {"id": "1701.05054", "submitter": "Carmen Gr\\\"a{\\ss}le", "authors": "Carmen Gr\\\"a{\\ss}le, Michael Hinze", "title": "POD reduced order modeling for evolution equations utilizing arbitrary\n  finite element discretizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main focus of the present work is the inclusion of spatial adaptivity for\nthe snapshot computation in the offline phase of model order reduction\nutilizing Proper Orthogonal Decomposition (POD-MOR) for nonlinear parabolic\nevolution problems. We consider snapshots which live in different finite\nelement spaces, which means in a fully discrete setting that the snapshots are\nvectors of different length. From a numerical point of view, this leads to the\nproblem that the usual POD procedure which utilizes a singular value\ndecomposition of the snapshot matrix, cannot be carried out. In order to\novercome this problem, we here construct the POD model / basis using the\neigensystem of the correlation matrix (snapshot gramian), which is motivated\nfrom a continuous perspective and is set up explicitly e.g. without the\nnecessity of interpolating snapshots into a common finite element space. It is\nan advantage of this approach that the assembling of the matrix only requires\nthe evaluation of inner products of snapshots in a common Hilbert space. This\nallows a great flexibility concerning the spatial discretization of the\nsnapshots. The analysis for the error between the resulting POD solution and\nthe true solution reveals that the accuracy of the reduced order solution can\nbe estimated by the spatial and temporal discretization error as well as the\nPOD error. Finally, to illustrate the feasibility our approach, we present a\ntest case of the Cahn-Hilliard system utilizing h-adapted hierarchical meshes\nand two settings of a linear heat equation using nested and non-nested grids.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 13:25:11 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 12:41:59 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 11:01:16 GMT"}, {"version": "v4", "created": "Tue, 27 Aug 2019 15:02:24 GMT"}, {"version": "v5", "created": "Sat, 1 Aug 2020 21:45:38 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gr\u00e4\u00dfle", "Carmen", ""], ["Hinze", "Michael", ""]]}, {"id": "1701.05378", "submitter": "Burak Civek", "authors": "Burak C. Civek and Suleyman S. Kozat", "title": "Efficient Implementation Of Newton-Raphson Methods For Sequential Data\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of sequential linear data prediction for real life\nbig data applications. The second order algorithms, i.e., Newton-Raphson\nMethods, asymptotically achieve the performance of the \"best\" possible linear\ndata predictor much faster compared to the first order algorithms, e.g., Online\nGradient Descent. However, implementation of these methods is not usually\nfeasible in big data applications because of the extremely high computational\nneeds. Regular implementation of the Newton-Raphson Methods requires a\ncomputational complexity in the order of $O(M^2)$ for an $M$ dimensional\nfeature vector, while the first order algorithms need only $O(M)$. To this end,\nin order to eliminate this gap, we introduce a highly efficient implementation\nreducing the computational complexity of the Newton-Raphson Methods from\nquadratic to linear scale. The presented algorithm provides the well-known\nmerits of the second order methods while offering the computational complexity\nof $O(M)$. We utilize the shifted nature of the consecutive feature vectors and\ndo not rely on any statistical assumptions. Therefore, both regular and fast\nimplementations achieve the same performance in the sense of mean square error.\nWe demonstrate the computational efficiency of our algorithm on real life\nsequential big datasets. We also illustrate that the presented algorithm is\nnumerically stable.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 11:34:17 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Civek", "Burak C.", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1701.05420", "submitter": "Krzysztof Domino", "authors": "Krzysztof Domino, Piotr Gawron, {\\L}ukasz Pawela", "title": "Efficient computation of higher order cumulant tensors", "comments": "22 pages, 6 figures", "journal-ref": "SIAM J. Sci. Comput., 40(3), A1590-A1610, 2018", "doi": "10.1137/17M1149365", "report-no": null, "categories": "cs.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel algorithm for calculating arbitrary order\ncumulants of multidimensional data. Since the $d^\\text{th}$ order cumulant can\nbe presented in the form of an $d$-dimensional tensor, the algorithm is\npresented using tensor operations. The algorithm provided in the paper takes\nadvantage of super-symmetry of cumulant and moment tensors. We show that the\nproposed algorithm considerably reduces the computational complexity and the\ncomputational memory requirement of cumulant calculation as compared with\nexisting algorithms. For the sizes of interest, the reduction is of the order\nof $d!$ compared to the naive algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 14:08:50 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 10:50:18 GMT"}, {"version": "v3", "created": "Wed, 28 Feb 2018 10:30:56 GMT"}, {"version": "v4", "created": "Tue, 10 Apr 2018 10:20:18 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Domino", "Krzysztof", ""], ["Gawron", "Piotr", ""], ["Pawela", "\u0141ukasz", ""]]}, {"id": "1701.06446", "submitter": "Krzysztof Domino", "authors": "Krzysztof Domino, Piotr Gawron", "title": "Algorithm for an arbitrary-order cumulant tensor calculation in a\n  sliding window of data streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High order cumulant tensors carry information about statistics of\nnon-normally distributed multivariate data. In this work we present a new\nefficient algorithm for calculation of cumulants of arbitrary order in a\nsliding window for data streams. We showed that this algorithms enables\nspeedups of cumulants updates compared to current algorithms. This algorithm\ncan be used for processing on-line high-frequency multivariate data and can\nfind applications in, e.g., on-line signal filtering and classification of data\nstreams.\n  To present an application of this algorithm, we propose an estimator of\nnon-Gaussianity of a data stream based on the norms of high-order cumulant\ntensors.\n  We show how to detect the transition from Gaussian distributed data to\nnon-Gaussian ones in a~data stream. In order to achieve high implementation\nefficiency of operations on super-symmetric tensors, such as cumulant tensors,\nwe employ the block structure to store and calculate only one hyper-pyramid\npart of such tensors.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2017 11:51:35 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 07:24:48 GMT"}, {"version": "v3", "created": "Thu, 4 Oct 2018 07:39:07 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Domino", "Krzysztof", ""], ["Gawron", "Piotr", ""]]}, {"id": "1701.06528", "submitter": "Mahesh Narayanamurthi", "authors": "Mahesh Narayanamurthi (1), Paul Tranquilli (1), Adrian Sandu (1) and\n  Mayya Tokman (2) ((1) Virginia Tech, (2) University of California, Merced)", "title": "EPIRK-W and EPIRK-K time discretization methods", "comments": "Fixed spelling error, rewrote a sentence and moved a paragraph after\n  rephrasing it. Fixed a small bug in the legend of figure 8b (results\n  unchanged). Fixed a typo in figure caption. Fixed a typo in a sentence.\n  Results unchanged", "journal-ref": null, "doi": null, "report-no": "CSL-TR-17-2", "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential integrators are special time discretization methods where the\ntraditional linear system solves used by implicit schemes are replaced with\ncomputing the action of matrix exponential-like functions on a vector. A very\ngeneral formulation of exponential integrators is offered by the Exponential\nPropagation Iterative methods of Runge-Kutta type (EPIRK) family of schemes.\nThe use of Jacobian approximations is an important strategy to drastically\nreduce the overall computational costs of implicit schemes while maintaining\nthe quality of their solutions. This paper extends the EPIRK class to allow the\nuse of inexact Jacobians as arguments of the matrix exponential-like functions.\nSpecifically, we develop two new families of methods: EPIRK-W integrators that\ncan accommodate any approximation of the Jacobian, and EPIRK-K integrators that\nrely on a specific Krylov-subspace projection of the exact Jacobian. Classical\norder conditions theories are constructed for these families. A practical\nEPIRK-W method of order three and an EPIRK-K method of order four are\ndeveloped. Numerical experiments indicate that the methods proposed herein are\ncomputationally favorable when compared to existing exponential integrators.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 17:55:50 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 17:56:48 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Narayanamurthi", "Mahesh", "", "Virginia Tech"], ["Tranquilli", "Paul", "", "Virginia Tech"], ["Sandu", "Adrian", "", "Virginia Tech"], ["Tokman", "Mayya", "", "University of California, Merced"]]}, {"id": "1701.06600", "submitter": "Grey Ballard", "authors": "Casey Battaglino and Grey Ballard and Tamara G. Kolda", "title": "A Practical Randomized CP Tensor Decomposition", "comments": null, "journal-ref": "SIAM Journal on Matrix Analysis and Applications, Vol. 39, No. 2,\n  pp. 876-901, 2018", "doi": "10.1137/17M1112303", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CANDECOMP/PARAFAC (CP) decomposition is a leading method for the analysis\nof multiway data. The standard alternating least squares algorithm for the CP\ndecomposition (CP-ALS) involves a series of highly overdetermined linear least\nsquares problems. We extend randomized least squares methods to tensors and\nshow the workload of CP-ALS can be drastically reduced without a sacrifice in\nquality. We introduce techniques for efficiently preprocessing, sampling, and\ncomputing randomized least squares on a dense tensor of arbitrary order, as\nwell as an efficient sampling-based technique for checking the stopping\ncondition. We also show more generally that the Khatri-Rao product (used within\nthe CP-ALS iteration) produces conditions favorable for direct sampling. In\nnumerical results, we see improvements in speed, reductions in memory\nrequirements, and robustness with respect to initialization.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 19:37:35 GMT"}, {"version": "v2", "created": "Sun, 22 Oct 2017 16:54:01 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Battaglino", "Casey", ""], ["Ballard", "Grey", ""], ["Kolda", "Tamara G.", ""]]}, {"id": "1701.06794", "submitter": "Xavier Caruso", "authors": "Xavier Caruso (IRMAR)", "title": "Computations with p-adic numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.NA cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document contains the notes of a lecture I gave at the \"Journ\\'ees\nNationales du Calcul Formel\" (JNCF) on January 2017. The aim of the lecture was\nto discuss low-level algorithmics for p-adic numbers. It is divided into two\nmain parts: first, we present various implementations of p-adic numbers and\ncompare them and second, we introduce a general framework for studying\nprecision issues and apply it in several concrete situations.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 10:22:45 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Caruso", "Xavier", "", "IRMAR"]]}, {"id": "1701.06920", "submitter": "Hui Liu Mr", "authors": "Hui Liu, Tao Cui, Wei Leng, Linbo Zhang", "title": "An hp-adaptive strategy for elliptic problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new hp-adaptive strategy for elliptic problems based on\nrefinement history is proposed, which chooses h-, p- or hp-refinement on\nindividual elements according to a posteriori error estimate, as well as\nsmoothness estimate of the solution obtained by comparing the actual and\nexpected error reduction rate. Numerical experiments show that exponential\nconvergence can be achieved with this strategy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 17:08:14 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Liu", "Hui", ""], ["Cui", "Tao", ""], ["Leng", "Wei", ""], ["Zhang", "Linbo", ""]]}, {"id": "1701.07059", "submitter": "Denys Dutykh", "authors": "Suelen Gasparin (PUCPR, LAMA), Julien Berger (LOCIE, PUCPR), Denys\n  Dutykh (LAMA), Nathan Mendes (PUCPR)", "title": "Stable explicit schemes for simulation of nonlinear moisture transfer in\n  porous materials", "comments": "35 pages, 16 figures, 1 table, 32 references. Other author's papers\n  can be downloaded at http://www.denys-dutykh.com/. arXiv admin note: text\n  overlap with arXiv:1612.07649", "journal-ref": "Journal of Building Performance Simulation (2018), Vol. 11, Issue\n  2, pp. 129-144", "doi": "10.1080/19401493.2017.1298669", "report-no": null, "categories": "cs.CE cs.NA physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit schemes have been extensively used in building physics to compute\nthe solution of moisture diffusion problems in porous materials for improving\nstability conditions. Nevertheless, these schemes require important\nsub-iterations when treating non-linear problems. To overcome this\ndisadvantage, this paper explores the use of improved explicit schemes, such as\nDufort-Frankel, Crank-Nicolson and hyperbolisation approaches. A first case\nstudy has been considered with the hypothesis of linear transfer. The\nDufort-Frankel, Crank-Nicolson and hyperbolisation schemes were compared to the\nclassical Euler explicit scheme and to a reference solution. Results have shown\nthat the hyperbolisation scheme has a stability condition higher than the\nstandard Courant-Friedrichs-Lewy (CFL) condition. The error of this schemes\ndepends on the parameter \\tau representing the hyperbolicity magnitude added\ninto the equation. The Dufort-Frankel scheme has the advantages of being\nunconditionally stable and is preferable for non-linear transfer, which is the\nsecond case study. Results have shown the error is proportional to O(\\Delta t).\nA modified Crank-Nicolson scheme has been proposed in order to avoid\nsub-iterations to treat the non-linearities at each time step. The main\nadvantages of the Dufort-Frankel scheme are (i) to be twice faster than the\nCrank-Nicolson approach; (ii) to compute explicitly the solution at each time\nstep; (iii) to be unconditionally stable and (iv) easier to parallelise on\nhigh-performance computer systems. Although the approach is unconditionally\nstable, the choice of the time discretisation $\\Delta t$ remains an important\nissue to accurately represent the physical phenomena.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2017 15:06:51 GMT"}, {"version": "v2", "created": "Fri, 3 Feb 2017 14:17:38 GMT"}, {"version": "v3", "created": "Tue, 28 Mar 2017 08:25:16 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Gasparin", "Suelen", "", "PUCPR, LAMA"], ["Berger", "Julien", "", "LOCIE, PUCPR"], ["Dutykh", "Denys", "", "LAMA"], ["Mendes", "Nathan", "", "PUCPR"]]}, {"id": "1701.08935", "submitter": "Yingzhou Li", "authors": "Yingzhou Li and Haizhao Yang", "title": "Interior Eigensolver for Sparse Hermitian Definite Matrices Based on\n  Zolotarev's Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an efficient method for computing selected generalized\neigenpairs of a sparse Hermitian definite matrix pencil $(A,B)$. Based on\nZolotarev's best rational function approximations of the signum function and\nconformal mapping techniques, we construct the best rational function\napproximation of a rectangular function supported on an arbitrary interval via\nfunction compositions with partial fraction representations. This new best\nrational function approximation can be applied to construct spectrum filters of\n$(A,B)$ with a smaller number of poles than a direct construction without\nfunction compositions. Combining fast direct solvers and the shift-invariant\ngeneralized minimal residual method, a hybrid fast algorithm is proposed to\napply spectral filters efficiently. Compared to the state-of-the-art algorithm\nFEAST, the proposed rational function approximation is more efficient when\nsparse matrix factorizations are required to solve multi-shift linear systems\nin the eigensolver, since the smaller number of matrix factorizations is needed\nin our method. The efficiency and stability of the proposed method are\ndemonstrated by numerical examples from computational chemistry.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 07:46:47 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 04:54:49 GMT"}, {"version": "v3", "created": "Wed, 1 Nov 2017 13:56:58 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 03:05:28 GMT"}, {"version": "v5", "created": "Wed, 30 Dec 2020 15:13:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Li", "Yingzhou", ""], ["Yang", "Haizhao", ""]]}]