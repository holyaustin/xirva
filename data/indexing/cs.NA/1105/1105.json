[{"id": "1105.0010", "submitter": "Gaurav Thakur", "authors": "Gaurav Thakur, Eugene Brevdo, Neven S. Fu\\v{c}kar, Hau-Tieng Wu", "title": "The Synchrosqueezing algorithm for time-varying spectral analysis:\n  robustness properties and new paleoclimate applications", "comments": "to appear in Signal Processing", "journal-ref": "Signal Processing 93:1079-1094, 2013", "doi": "10.1016/j.sigpro.2012.11.029", "report-no": null, "categories": "math.CA cs.CE cs.NA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the stability properties of the Synchrosqueezing transform, a\ntime-frequency signal analysis method that can identify and extract oscillatory\ncomponents with time-varying frequency and amplitude. We show that\nSynchrosqueezing is robust to bounded perturbations of the signal and to\nGaussian white noise. These results justify its applicability to noisy or\nnonuniformly sampled data that is ubiquitous in engineering and the natural\nsciences. We also describe a practical implementation of Synchrosqueezing and\nprovide guidance on tuning its main parameters. As a case study in the\ngeosciences, we examine characteristics of a key paleoclimate change in the\nlast 2.5 million years, where Synchrosqueezing provides significantly improved\ninsights.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 20:04:48 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2012 23:42:46 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2012 00:24:06 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Thakur", "Gaurav", ""], ["Brevdo", "Eugene", ""], ["Fu\u010dkar", "Neven S.", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "1105.0706", "submitter": "Kalyana Babu Nakshatrala", "authors": "K. B. Nakshatrala and D. Z. Turner", "title": "A mixed formulation for a modification to Darcy equation based on Picard\n  linearization and numerical solutions to large-scale realistic problems", "comments": "The earlier versions of this paper on arXiv were under the title: \"A\n  mixed formulation for a modification to Darcy equation with applications to\n  enhanced oil recovery and carbon-dioxide sequestration.\" The title has\n  changed at the suggestion of a journal reviewer, as the new title better\n  reflects the main contributions of this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a modification to Darcy equation by taking into\naccount the dependence of viscosity on the pressure. We present a stabilized\nmixed formulation for the resulting governing equations. Equal-order\ninterpolation for the velocity and pressure is considered, and shown to be\nstable (which is not the case under the classical mixed formulation). The\nproposed mixed formulation is tested using a wide variety of numerical\nexamples. The proposed formulation is also implemented in a parallel setting,\nand the performance of the formulation for large-scale problems is illustrated\nusing a representative problem. Two practical and technologically important\nproblems, one each on enhanced oil recovery and geological carbon-dioxide\nsequestration, are solved using the proposed formulation. The numerical\nexamples show that the predictions based on Darcy model are qualitatively and\nquantitatively different from that of the predictions based on the modified\nDarcy model, which takes into account the dependence of the viscosity on the\npressure. In particular, the numerical example on the geological carbon-dioxide\nsequestration shows that Darcy model over-predicts the leakage into an\nabandoned well when compared to that of the modified Darcy model. On the other\nhand, the modified Darcy model predicts higher pressures and higher pressure\ngradients near the injection well. These predictions have dire consequences in\npredicting damage and fracture zones, and designing the seal, whose integrity\nis crucial to the safety of a geological carbon-dioxide sequestration\ngeosystem.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 23:00:45 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2012 01:29:16 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2013 08:36:37 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Nakshatrala", "K. B.", ""], ["Turner", "D. Z.", ""]]}, {"id": "1105.3422", "submitter": "Daniel Dunlavy", "authors": "Evrim Acar, Tamara G. Kolda and Daniel M. Dunlavy", "title": "All-at-once Optimization for Coupled Matrix and Tensor Factorizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint analysis of data from multiple sources has the potential to improve our\nunderstanding of the underlying structures in complex data sets. For instance,\nin restaurant recommendation systems, recommendations can be based on rating\nhistories of customers. In addition to rating histories, customers' social\nnetworks (e.g., Facebook friendships) and restaurant categories information\n(e.g., Thai or Italian) can also be used to make better recommendations. The\ntask of fusing data, however, is challenging since data sets can be incomplete\nand heterogeneous, i.e., data consist of both matrices, e.g., the person by\nperson social network matrix or the restaurant by category matrix, and\nhigher-order tensors, e.g., the \"ratings\" tensor of the form restaurant by meal\nby person.\n  In this paper, we are particularly interested in fusing data sets with the\ngoal of capturing their underlying latent structures. We formulate this problem\nas a coupled matrix and tensor factorization (CMTF) problem where heterogeneous\ndata sets are modeled by fitting outer-product models to higher-order tensors\nand matrices in a coupled manner. Unlike traditional approaches solving this\nproblem using alternating algorithms, we propose an all-at-once optimization\napproach called CMTF-OPT (CMTF-OPTimization), which is a gradient-based\noptimization approach for joint analysis of matrices and higher-order tensors.\nWe also extend the algorithm to handle coupled incomplete data sets. Using\nnumerical experiments, we demonstrate that the proposed all-at-once approach is\nmore accurate than the alternating least squares approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2011 16:12:19 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Acar", "Evrim", ""], ["Kolda", "Tamara G.", ""], ["Dunlavy", "Daniel M.", ""]]}, {"id": "1105.3448", "submitter": "Petr Vabishchevich N.", "authors": "Petr N. Vabishchevich", "title": "Substructuring domain decomposition scheme for unsteady problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain decomposition methods are used for approximate solving boundary\nproblems for partial differential equations on parallel computing systems.\nSpecific features of unsteady problems are taken into account in the most\ncomplete way in iteration-free schemes of domain decomposition.\nRegionally-additive schemes are based on different classes of splitting\nschemes. In this paper we highlight a class of domain decomposition schemes\nwhich is based on the partition of the initial domain into subdomains with\ncommon boundary nodes. Using the partition of unit we have constructed and\nstudied unconditionally stable schemes of domain decomposition based on\ntwo-component splitting: the problem within subdomain and the problem at their\nboundaries. As an example there is considered the Cauchy problem for\nevolutionary equations of first and second order with non-negative self-adjoint\noperator in a finite Hilbert space. The theoretical consideration is\nsupplemented with numerical solving a model problem for the two-dimensional\nparabolic equation.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2011 18:40:18 GMT"}], "update_date": "2011-05-18", "authors_parsed": [["Vabishchevich", "Petr N.", ""]]}, {"id": "1105.3723", "submitter": "Jakob Heide J{\\o}rgensen", "authors": "Tobias Lindstr{\\o}m Jensen, Jakob Heide J{\\o}rgensen, Per Christian\n  Hansen, S{\\o}ren Holdt Jensen", "title": "Implementation of an Optimal First-Order Method for Strongly Convex\n  Total Variation Regularization", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a practical implementation of an optimal first-order method, due\nto Nesterov, for large-scale total variation regularization in tomographic\nreconstruction, image deblurring, etc. The algorithm applies to $\\mu$-strongly\nconvex objective functions with $L$-Lipschitz continuous gradient. In the\nframework of Nesterov both $\\mu$ and $L$ are assumed known -- an assumption\nthat is seldom satisfied in practice. We propose to incorporate mechanisms to\nestimate locally sufficient $\\mu$ and $L$ during the iterations. The mechanisms\nalso allow for the application to non-strongly convex functions. We discuss the\niteration complexity of several first-order methods, including the proposed\nalgorithm, and we use a 3D tomography problem to compare the performance of\nthese methods. The results show that for ill-conditioned problems solved to\nhigh accuracy, the proposed method significantly outperforms state-of-the-art\nfirst-order methods, as also suggested by theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2011 19:57:12 GMT"}], "update_date": "2011-05-19", "authors_parsed": [["Jensen", "Tobias Lindstr\u00f8m", ""], ["J\u00f8rgensen", "Jakob Heide", ""], ["Hansen", "Per Christian", ""], ["Jensen", "S\u00f8ren Holdt", ""]]}, {"id": "1105.4002", "submitter": "Jakob Heide J{\\o}rgensen", "authors": "Jakob Heide J{\\o}rgensen, Tobias Lindstr{\\o}m Jensen, Per Christian\n  Hansen, S{\\o}ren Holdt Jensen, Emil Y. Sidky, Xiaochuan Pan", "title": "Accelerated gradient methods for total-variation-based CT image\n  reconstruction", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Total-variation (TV)-based Computed Tomography (CT) image reconstruction has\nshown experimentally to be capable of producing accurate reconstructions from\nsparse-view data. In particular TV-based reconstruction is very well suited for\nimages with piecewise nearly constant regions. Computationally, however,\nTV-based reconstruction is much more demanding, especially for 3D imaging, and\nthe reconstruction from clinical data sets is far from being close to\nreal-time. This is undesirable from a clinical perspective, and thus there is\nan incentive to accelerate the solution of the underlying optimization problem.\nThe TV reconstruction can in principle be found by any optimization method, but\nin practice the large-scale systems arising in CT image reconstruction preclude\nthe use of memory-demanding methods such as Newton's method. The simple\ngradient method has much lower memory requirements, but exhibits slow\nconvergence. In the present work we consider the use of two accelerated\ngradient-based methods, GPBB and UPN, for reducing the number of gradient\nmethod iterations needed to achieve a high-accuracy TV solution in CT image\nreconstruction. The former incorporates several heuristics from the\noptimization literature such as Barzilai-Borwein (BB) step size selection and\nnonmonotone line search. The latter uses a cleverly chosen sequence of\nauxiliary points to achieve a better convergence rate. The methods are memory\nefficient and equipped with a stopping criterion to ensure that the TV\nreconstruction has indeed been found. An implementation of the methods (in C\nwith interface to Matlab) is available for download from\nhttp://www2.imm.dtu.dk/~pch/TVReg/. We compare the proposed methods with the\nstandard gradient method, applied to a 3D test problem with synthetic few-view\ndata. We find experimentally that for realistic parameters the proposed methods\nsignificantly outperform the gradient method.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2011 01:04:10 GMT"}], "update_date": "2011-05-23", "authors_parsed": [["J\u00f8rgensen", "Jakob Heide", ""], ["Jensen", "Tobias Lindstr\u00f8m", ""], ["Hansen", "Per Christian", ""], ["Jensen", "S\u00f8ren Holdt", ""], ["Sidky", "Emil Y.", ""], ["Pan", "Xiaochuan", ""]]}, {"id": "1105.4136", "submitter": "Riccardo Murri", "authors": "Riccardo Murri", "title": "A novel parallel algorithm for Gaussian Elimination of sparse\n  unsymmetric matrices", "comments": "14 pages; 2 PDF figures; LaTeX2e; final version submitted for the\n  PPAM2011 conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new algorithm for Gaussian Elimination suitable for general\n(unsymmetric and possibly singular) sparse matrices, of any entry type, which\nhas a natural parallel and distributed-memory formulation but degrades\ngracefully to sequential execution.\n  We present a sample MPI implementation of a program computing the rank of a\nsparse integer matrix using the proposed algorithm. Some preliminary\nperformance measurements are presented and discussed, and the performance of\nthe algorithm is compared to corresponding state-of-the-art algorithms for\nfloating-point and integer matrices.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2011 17:29:57 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2011 18:36:54 GMT"}, {"version": "v3", "created": "Sun, 15 Jan 2012 21:34:56 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Murri", "Riccardo", ""]]}, {"id": "1105.4337", "submitter": "Louis Yu Lu", "authors": "Louis Yu Lu", "title": "Equivalent Effect Function and Fast Intrinsic Mode Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Equivalent Effect Function (EEF) is defined as having the identical\nintegral values on the control points of the original time series data; the EEF\ncan be obtained from the derivative of the spline function passing through the\nintegral values on the control points. By choosing control points with\ndifferent criteria, the EEF can be used to find the intrinsic mode\nfunction(IMF, fluctuation) and the residue (trend); to fit the curve of the\noriginal data function; and to take samples on original data with equivalent\neffect. As examples of application, results of trend and fluctuation on real\nstock historical data are calculated on different time scales. A new approach\nto extend the EEF to 2D intrinsic mode decomposition is introduced to resolve\nthe inter slice non continuity problem, some photo image decomposition examples\nare presented.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2011 13:14:06 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Lu", "Louis Yu", ""]]}, {"id": "1105.5331", "submitter": "Hans De Sterck", "authors": "Hans De Sterck", "title": "A Nonlinear GMRES Optimization Algorithm for Canonical Tensor\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithm is presented for computing a canonical rank-R tensor\napproximation that has minimal distance to a given tensor in the Frobenius\nnorm, where the canonical rank-R tensor consists of the sum of R rank-one\ncomponents. Each iteration of the method consists of three steps. In the first\nstep, a tentative new iterate is generated by a stand-alone one-step process,\nfor which we use alternating least squares (ALS). In the second step, an\naccelerated iterate is generated by a nonlinear generalized minimal residual\n(GMRES) approach, recombining previous iterates in an optimal way, and\nessentially using the stand-alone one-step process as a preconditioner. In\nparticular, the nonlinear extension of GMRES is used that was proposed by\nWashio and Oosterlee in [ETNA Vol. 15 (2003), pp. 165-185] for nonlinear\npartial differential equation problems. In the third step, a line search is\nperformed for globalization. The resulting nonlinear GMRES (N-GMRES)\noptimization algorithm is applied to dense and sparse tensor decomposition test\nproblems. The numerical tests show that ALS accelerated by N-GMRES may\nsignificantly outperform both stand-alone ALS and a standard nonlinear\nconjugate gradient optimization method, especially when highly accurate\nstationary points are desired for difficult problems. The proposed N-GMRES\noptimization algorithm is based on general concepts and may be applied to other\nnonlinear optimization problems.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 16:00:23 GMT"}], "update_date": "2011-05-27", "authors_parsed": [["De Sterck", "Hans", ""]]}, {"id": "1105.5924", "submitter": "Andriyan Suksmono Bayu", "authors": "Andriyan Bayu Suksmono", "title": "Reconstruction of Fractional Brownian Motion Signals From Its Sparse\n  Samples Based on Compressive Sampling", "comments": "6 double-column pages, 5 figures, submitted to ICEEI-2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.PR physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new fBm (fractional Brownian motion)\ninterpolation/reconstruction method from partially known samples based on CS\n(Compressive Sampling). Since 1/f property implies power law decay of the fBm\nspectrum, the fBm signals should be sparse in frequency domain. This property\nmotivates the adoption of CS in the development of the reconstruction method.\nHurst parameter H that occurs in the power law determines the sparsity level,\ntherefore the CS reconstruction quality of an fBm signal for a given number of\nknown subsamples will depend on H. However, the proposed method does not\nrequire the information of H to reconstruct the fBm signal from its partial\nsamples. The method employs DFT (Discrete Fourier Transform) as the sparsity\nbasis and a random matrix derived from known samples positions as the\nprojection basis. Simulated fBm signals with various values of H are used to\nshow the relationship between the Hurst parameter and the reconstruction\nquality. Additionally, US-DJIA (Dow Jones Industrial Average) stock index\nmonthly values time-series are also used to show the applicability of the\nproposed method to reconstruct a real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 10:11:06 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Suksmono", "Andriyan Bayu", ""]]}, {"id": "1105.6138", "submitter": "Mark Iwen", "authors": "J. Bailey and M. A. Iwen and C. V. Spencer", "title": "On the Design of Deterministic Matrices for Fast Recovery of Fourier\n  Compressible Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general class of compressed sensing matrices which are then\ndemonstrated to have associated sublinear-time sparse approximation algorithms.\nWe then develop methods for constructing specialized matrices from this class\nwhich are sparse when multiplied with a discrete Fourier transform matrix.\nUltimately, these considerations improve previous sampling requirements for\ndeterministic sparse Fourier transform methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 23:44:14 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Bailey", "J.", ""], ["Iwen", "M. A.", ""], ["Spencer", "C. V.", ""]]}]