[{"id": "1501.00125", "submitter": "Hao Wu", "authors": "Hao Wu", "title": "Maximum Margin Clustering for State Decomposition of Metastable Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.SY math.NA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When studying a metastable dynamical system, a prime concern is how to\ndecompose the phase space into a set of metastable states. Unfortunately, the\nmetastable state decomposition based on simulation or experimental data is\nstill a challenge. The most popular and simplest approach is geometric\nclustering which is developed based on the classical clustering technique.\nHowever, the prerequisites of this approach are: (1) data are obtained from\nsimulations or experiments which are in global equilibrium and (2) the\ncoordinate system is appropriately selected. Recently, the kinetic clustering\napproach based on phase space discretization and transition probability\nestimation has drawn much attention due to its applicability to more general\ncases, but the choice of discretization policy is a difficult task. In this\npaper, a new decomposition method designated as maximum margin metastable\nclustering is proposed, which converts the problem of metastable state\ndecomposition to a semi-supervised learning problem so that the large margin\ntechnique can be utilized to search for the optimal decomposition without phase\nspace discretization. Moreover, several simulation examples are given to\nillustrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2014 12:50:08 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Wu", "Hao", ""]]}, {"id": "1501.00160", "submitter": "Dmitry Batenkov", "authors": "Dmitry Batenkov", "title": "Accurate solution of near-colliding Prony systems via decimation and\n  homotopy continuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.SC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider polynomial systems of Prony type, appearing in many areas of\nmathematics. Their robust numerical solution is considered to be difficult,\nespecially in \"near-colliding\" situations. We consider a case when the\nstructure of the system is a-priori fixed. We transform the nonlinear part of\nthe Prony system into a Hankel-type polynomial system. Combining this\nrepresentation with a recently discovered \"decimation\" technique, we present an\nalgorithm which applies homotopy continuation to an appropriately chosen\nHankel-type system as above. In this way, we are able to solve for the\nnonlinear variables of the original system with high accuracy when the data is\nperturbed.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2014 15:56:37 GMT"}, {"version": "v2", "created": "Mon, 5 Jan 2015 07:14:21 GMT"}, {"version": "v3", "created": "Fri, 21 Oct 2016 17:08:03 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Batenkov", "Dmitry", ""]]}, {"id": "1501.00680", "submitter": "Ricardo Monge", "authors": "Osvaldo Skliar and Ricardo E. Monge and Sherry Gapper", "title": "A New Method for Signal and Image Analysis: The Square Wave Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A brief review is provided of the use of the Square Wave Method (SWM) in the\nfield of signal and image analysis and it is specified how results thus\nobtained are expressed using the Square Wave Transform (SWT), in the frequency\ndomain. To illustrate the new approach introduced in this field, the results of\ntwo cases are analyzed: a) a sequence of samples (that is, measured values) of\nan electromyographic recording; and b) the classic image of Lenna.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2015 14:35:58 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Skliar", "Osvaldo", ""], ["Monge", "Ricardo E.", ""], ["Gapper", "Sherry", ""]]}, {"id": "1501.00696", "submitter": "Pauli Miettinen", "authors": "Saskia Metzler and Pauli Miettinen", "title": "Clustering Boolean Tensors", "comments": null, "journal-ref": null, "doi": "10.1007/s10618-015-0420-3", "report-no": null, "categories": "cs.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor factorizations are computationally hard problems, and in particular,\nare often significantly harder than their matrix counterparts. In case of\nBoolean tensor factorizations -- where the input tensor and all the factors are\nrequired to be binary and we use Boolean algebra -- much of that hardness comes\nfrom the possibility of overlapping components. Yet, in many applications we\nare perfectly happy to partition at least one of the modes. In this paper we\ninvestigate what consequences does this partitioning have on the computational\ncomplexity of the Boolean tensor factorizations and present a new algorithm for\nthe resulting clustering problem. This algorithm can alternatively be seen as a\nparticularly regularized clustering algorithm that can handle extremely\nhigh-dimensional observations. We analyse our algorithms with the goal of\nmaximizing the similarity and argue that this is more meaningful than\nminimizing the dissimilarity. As a by-product we obtain a PTAS and an efficient\n0.828-approximation algorithm for rank-1 binary factorizations. Our algorithm\nfor Boolean tensor clustering achieves high scalability, high similarity, and\ngood generalization to unseen data with both synthetic and real-world data\nsets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2015 17:01:03 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Metzler", "Saskia", ""], ["Miettinen", "Pauli", ""]]}, {"id": "1501.00828", "submitter": "Aleksandr Cariow", "authors": "Aleksandr Cariow and Galina Cariowa", "title": "A new algorithm for multiplying two Dirac numbers", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work a rationalized algorithm for Dirac numbers multiplication is\npresented. This algorithm has a low computational complexity feature and is\nwell suited to FPGA implementation. The computation of two Dirac numbers\nproduct using the na\\\"ive method takes 256 real multiplications and 240 real\nadditions, while the proposed algorithm can compute the same result in only 88\nreal multiplications and 256 real additions. During synthesis of the discussed\nalgorithm we use the fact that Dirac numbers product may be represented as\nvector-matrix product. The matrix participating in the product has unique\nstructural properties that allow performing its advantageous decomposition.\nNamely this decomposition leads to significant reducing of the computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 12:00:11 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Cariow", "Aleksandr", ""], ["Cariowa", "Galina", ""]]}, {"id": "1501.01571", "submitter": "Joel Tropp", "authors": "Joel A. Tropp", "title": "An Introduction to Matrix Concentration Inequalities", "comments": "163 pages. To appear in Foundations and Trends in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS cs.IT cs.NA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, random matrices have come to play a major role in\ncomputational mathematics, but most of the classical areas of random matrix\ntheory remain the province of experts. Over the last decade, with the advent of\nmatrix concentration inequalities, research has advanced to the point where we\ncan conquer many (formerly) challenging problems with a page or two of\narithmetic. The aim of this monograph is to describe the most successful\nmethods from this area along with some interesting examples that these\ntechniques can illuminate.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 17:46:02 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Tropp", "Joel A.", ""]]}, {"id": "1501.01809", "submitter": "Lawrence Mitchell", "authors": "Florian Rathgeber, David A. Ham, Lawrence Mitchell, Michael Lange,\n  Fabio Luporini, Andrew T. T. McRae, Gheorghe-Teodor Bercea, Graham R.\n  Markall, Paul H. J. Kelly", "title": "Firedrake: automating the finite element method by composing\n  abstractions", "comments": "Minor revisions to v2", "journal-ref": "ACM Transactions on Mathematical Software 43(3):24:1--24:27 (2016)", "doi": "10.1145/2998441", "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firedrake is a new tool for automating the numerical solution of partial\ndifferential equations. Firedrake adopts the domain-specific language for the\nfinite element method of the FEniCS project, but with a pure Python\nruntime-only implementation centred on the composition of several existing and\nnew abstractions for particular aspects of scientific computing. The result is\na more complete separation of concerns which eases the incorporation of\nseparate contributions from computer scientists, numerical analysts and\napplication specialists. These contributions may add functionality, or improve\nperformance.\n  Firedrake benefits from automatically applying new optimisations. This\nincludes factorising mixed function spaces, transforming and vectorising inner\nloops, and intrinsically supporting block matrix operations. Importantly,\nFiredrake presents a simple public API for escaping the UFL abstraction. This\nallows users to implement common operations that fall outside pure variational\nformulations, such as flux-limiters.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 11:57:05 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2015 17:33:48 GMT"}, {"version": "v3", "created": "Fri, 1 Jul 2016 13:24:51 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Rathgeber", "Florian", ""], ["Ham", "David A.", ""], ["Mitchell", "Lawrence", ""], ["Lange", "Michael", ""], ["Luporini", "Fabio", ""], ["McRae", "Andrew T. T.", ""], ["Bercea", "Gheorghe-Teodor", ""], ["Markall", "Graham R.", ""], ["Kelly", "Paul H. J.", ""]]}, {"id": "1501.01946", "submitter": "Renato J Cintra", "authors": "D. Suarez, R. J. Cintra, F. M. Bayer, A. Sengupta, S. Kulasekera, A.\n  Madanayake", "title": "Multi-Beam RF Aperture Using Multiplierless FFT Approximation", "comments": "8 pages, 3 figures, 2 tables, sfg corrected", "journal-ref": "Electronics Letters, volume 50, issue 24, pages 1788-1790, 2014", "doi": "10.1049/el.2014.3561", "report-no": null, "categories": "stat.ME cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple independent radio frequency (RF) beams find applications in\ncommunications, radio astronomy, radar, and microwave imaging. An $N$-point FFT\napplied spatially across an array of receiver antennas provides $N$-independent\nRF beams at $\\frac{N}{2}\\log_2N$ multiplier complexity. Here, a low-complexity\nmultiplierless approximation for the 8-point FFT is presented for RF\nbeamforming, using only 26 additions. The algorithm provides eight beams that\nclosely resemble the antenna array patterns of the traditional FFT-based\nbeamformer albeit without using multipliers. The proposed FFT-like algorithm is\nuseful for low-power RF multi-beam receivers; being synthesized in 45 nm CMOS\ntechnology at 1.1 V supply, and verified on-chip using a Xilinx Virtex-6 Lx240T\nFPGA device. The CMOS simulation and FPGA implementation indicate bandwidths of\n588 MHz and 369 MHz, respectively, for each of the independent receive-mode RF\nbeams.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 20:21:05 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Suarez", "D.", ""], ["Cintra", "R. J.", ""], ["Bayer", "F. M.", ""], ["Sengupta", "A.", ""], ["Kulasekera", "S.", ""], ["Madanayake", "A.", ""]]}, {"id": "1501.02581", "submitter": "Kalyana Babu Nakshatrala", "authors": "M. Shabouei and K. B. Nakshatrala", "title": "Mechanics-based solution verification for porous media models", "comments": null, "journal-ref": null, "doi": "10.4208/cicp.OA-2016-0007", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to verify accuracy of computational\nsimulations. We develop mathematical theorems which can serve as robust a\nposteriori error estimation techniques to identify numerical pollution, check\nthe performance of adaptive meshes, and verify numerical solutions. We\ndemonstrate performance of this methodology on problems from flow thorough\nporous media. However, one can extend it to other models. We construct\nmathematical properties such that the solutions to Darcy and Darcy-Brinkman\nequations satisfy them. The mathematical properties include the total minimum\nmechanical power, minimum dissipation theorem, reciprocal relation, and maximum\nprinciple for the vorticity. All the developed theorems have firm mechanical\nbases and are independent of numerical methods. So, these can be utilized for\nsolution verification of finite element, finite volume, finite difference,\nlattice Boltzmann methods and so forth. In particular, we show that, for a\ngiven set of boundary conditions, Darcy velocity has the minimum total\nmechanical power of all the kinematically admissible vector fields. We also\nshow that a similar result holds for Darcy-Brinkman velocity. We then show for\na conservative body force, the Darcy and Darcy-Brinkman velocities have the\nminimum total dissipation among their respective kinematically admissible\nvector fields. Using numerical examples, we show that the minimum dissipation\nand total mechanical power theorems can be utilized to identify pollution\nerrors in numerical solutions. The solutions to Darcy and Darcy-Brinkman\nequations are shown to satisfy a reciprocal relation, which has the potential\nto identify errors in the numerical implementation of boundary conditions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 09:41:43 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2016 05:47:49 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Shabouei", "M.", ""], ["Nakshatrala", "K. B.", ""]]}, {"id": "1501.02627", "submitter": "Oliver Serang", "authors": "Oliver Serang", "title": "A fast numerical method for max-convolution and the application to\n  efficient max-product inference in Bayesian networks", "comments": null, "journal-ref": "Journal of Computational Biology. August 2015, 22(8): 770-783", "doi": "10.1089/cmb.2015.0013", "report-no": null, "categories": "cs.NA math.NA stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observations depending on sums of random variables are common throughout many\nfields; however, no efficient solution is currently known for performing\nmax-product inference on these sums of general discrete distributions\n(max-product inference can be used to obtain maximum a posteriori estimates).\nThe limiting step to max-product inference is the max-convolution problem\n(sometimes presented in log-transformed form and denoted as \"infimal\nconvolution\", \"min-convolution\", or \"convolution on the tropical semiring\"),\nfor which no O(k log(k)) method is currently known. Here I present a O(k\nlog(k)) numerical method for estimating the max-convolution of two nonnegative\nvectors (e.g., two probability mass functions), where k is the length of the\nlarger vector. This numerical max-convolution method is then demonstrated by\nperforming fast max-product inference on a convolution tree, a data structure\nfor performing fast inference given information on the sum of n discrete random\nvariables in O(n k log(n k) log(n) ) steps (where each random variable has an\narbitrary prior distribution on k contiguous possible states). The numerical\nmax-convolution method can be applied to specialized classes of hidden Markov\nmodels to reduce the runtime of computing the Viterbi path from n k^2 to n k\nlog(k), and has potential application to the all-pairs shortest paths problem.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 12:57:01 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2015 01:49:25 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Serang", "Oliver", ""]]}, {"id": "1501.02995", "submitter": "Renato J Cintra", "authors": "U. S. Potluri, A. Madanayake, R. J. Cintra, F. M. Bayer, S.\n  Kulasekera, A. Edirisuriya", "title": "Improved 8-point Approximate DCT for Image and Video Compression\n  Requiring Only 14 Additions", "comments": "30 pages, 7 figures, 5 tables", "journal-ref": "Circuits and Systems I: Regular Papers, IEEE Transactions on,\n  Volume 61, Issue 6, June 2014, 1727--1740", "doi": "10.1109/TCSI.2013.2295022", "report-no": null, "categories": "cs.MM cs.CV cs.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video processing systems such as HEVC requiring low energy consumption needed\nfor the multimedia market has lead to extensive development in fast algorithms\nfor the efficient approximation of 2-D DCT transforms. The DCT is employed in a\nmultitude of compression standards due to its remarkable energy compaction\nproperties. Multiplier-free approximate DCT transforms have been proposed that\noffer superior compression performance at very low circuit complexity. Such\napproximations can be realized in digital VLSI hardware using additions and\nsubtractions only, leading to significant reductions in chip area and power\nconsumption compared to conventional DCTs and integer transforms. In this\npaper, we introduce a novel 8-point DCT approximation that requires only 14\naddition operations and no multiplications. The proposed transform possesses\nlow computational complexity and is compared to state-of-the-art DCT\napproximations in terms of both algorithm complexity and peak signal-to-noise\nratio. The proposed DCT approximation is a candidate for reconfigurable video\nstandards such as HEVC. The proposed transform and several other DCT\napproximations are mapped to systolic-array digital architectures and\nphysically realized as digital prototype circuits using FPGA technology and\nmapped to 45 nm CMOS technology.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 13:26:40 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Potluri", "U. S.", ""], ["Madanayake", "A.", ""], ["Cintra", "R. J.", ""], ["Bayer", "F. M.", ""], ["Kulasekera", "S.", ""], ["Edirisuriya", "A.", ""]]}, {"id": "1501.03105", "submitter": "David Gleich", "authors": "Yao Zhu and David F. Gleich", "title": "A Parallel Min-Cut Algorithm using Iteratively Reweighted Least Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel algorithm for the undirected $s,t$-mincut problem with\nfloating-point valued weights. Our overarching algorithm uses an iteratively\nreweighted least squares framework. This generates a sequence of Laplacian\nlinear systems, which we solve using parallel matrix algorithms. Our overall\nimplementation is up to 30-times faster than a serial solver when using 128\ncores.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 18:48:27 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Zhu", "Yao", ""], ["Gleich", "David F.", ""]]}, {"id": "1501.03358", "submitter": "Amit Amritkar", "authors": "Amit Amritkar, Eric de Sturler, Katarzyna \\'Swirydowicz, Danesh Tafti\n  and Kapil Ahuja", "title": "Recycling Krylov subspaces for CFD applications and a new hybrid\n  recycling solver", "comments": "26 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2015.09.040", "report-no": null, "categories": "cs.NA math.NA physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on robust and efficient iterative solvers for the pressure Poisson\nequation in incompressible Navier-Stokes problems. Preconditioned Krylov\nsubspace methods are popular for these problems, with BiCGStab and GMRES(m)\nmost frequently used for nonsymmetric systems. BiCGStab is popular because it\nhas cheap iterations, but it may fail for stiff problems, especially early on\nas the initial guess is far from the solution. Restarted GMRES is better, more\nrobust, in this phase, but restarting may lead to very slow convergence.\nTherefore, we evaluate the rGCROT method for these systems. This method\nrecycles a selected subspace of the search space (called recycle space) after a\nrestart. This generally improves the convergence drastically compared with\nGMRES(m). Recycling subspaces is also advantageous for subsequent linear\nsystems, if the matrix changes slowly or is constant. However, rGCROT\niterations are still expensive in memory and computation time compared with\nthose of BiCGStab. Hence, we propose a new, hybrid approach that combines the\ncheap iterations of BiCGStab with the robustness of rGCROT. For the first few\ntime steps the algorithm uses rGCROT and builds an effective recycle space, and\nthen it recycles that space in the rBiCGStab solver. We evaluate rGCROT on a\nturbulent channel flow problem, and we evaluate both rGCROT and the new, hybrid\ncombination of rGCROT and rBiCGStab on a porous medium flow problem. We see\nsubstantial performance gains on both problems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 01:45:31 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2015 22:17:50 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Amritkar", "Amit", ""], ["de Sturler", "Eric", ""], ["\u015awirydowicz", "Katarzyna", ""], ["Tafti", "Danesh", ""], ["Ahuja", "Kapil", ""]]}, {"id": "1501.04002", "submitter": "Darren Engwirda", "authors": "Darren Engwirda, David Ivers", "title": "Size-optimal Steiner points for Delaunay-refinement on curved surfaces", "comments": "Submitted to Computer-Aided Design (23rd International Meshing\n  Roundtable special issue). A short version appears in the proceedings of the\n  23rd International Meshing Roundtable. (v2 - revisions to description of\n  point-placement scheme, figures.) (v3 - updated to final pre-print version.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extension of the restricted Delaunay-refinement algorithm for surface mesh\ngeneration is described, where a new point-placement scheme is introduced to\nimprove element quality in the presence of mesh size constraints. Specifically,\nit is shown that the use of off-centre Steiner points, positioned on the faces\nof the associated Voronoi diagram, typically leads to significant improvements\nin the shape- and size-quality of the resulting surface tessellations. The new\nalgorithm can be viewed as a Frontal-Delaunay approach -- a hybridisation of\nconventional Delaunay-refinement and advancing-front techniques in which new\nvertices are positioned to satisfy both element size and shape constraints. The\nperformance of the new scheme is investigated experimentally via a series of\ncomparative studies that contrast its performance with that of a typical\nDelaunay-refinement technique. It is shown that the new method inherits many of\nthe best features of classical Delaunay-refinement and advancing-front type\nmethods, leading to the construction of smooth, high quality surface\ntriangulations with bounded radius-edge ratios and convergence guarantees.\nExperiments are conducted using a range of complex benchmarks, verifying the\nrobustness and practical performance of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 14:55:49 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2015 18:21:36 GMT"}, {"version": "v3", "created": "Mon, 27 Jun 2016 14:28:02 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Engwirda", "Darren", ""], ["Ivers", "David", ""]]}, {"id": "1501.04784", "submitter": "Francisco Javier Ramirez Gil", "authors": "Francisco Javier Ram\\'irez-Gil, Marcos de Sales Guerra Tsuzuki and\n  Wilfredo Montealegre-Rubio", "title": "Global finite element matrix construction based on a CPU-GPU\n  implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE cs.DC cs.PF math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The finite element method (FEM) has several computational steps to\nnumerically solve a particular problem, to which many efforts have been\ndirected to accelerate the solution stage of the linear system of equations.\nHowever, the finite element matrix construction, which is also time-consuming\nfor unstructured meshes, has been less investigated. The generation of the\nglobal finite element matrix is performed in two steps, computing the local\nmatrices by numerical integration and assembling them into a global system,\nwhich has traditionally been done in serial computing. This work presents a\nfast technique to construct the global finite element matrix that arises by\nsolving the Poisson's equation in a three-dimensional domain. The proposed\nmethodology consists in computing the numerical integration, due to its\nintrinsic parallel opportunities, in the graphics processing unit (GPU) and\ncomputing the matrix assembly, due to its intrinsic serial operations, in the\ncentral processing unit (CPU). In the numerical integration, only the lower\ntriangular part of each local stiffness matrix is computed thanks to its\nsymmetry, which saves GPU memory and computing time. As a result of symmetry,\nthe global sparse matrix also contains non-zero elements only in its lower\ntriangular part, which reduces the assembly operations and memory usage. This\nmethodology allows generating the global sparse matrix from any unstructured\nfinite element mesh size on GPUs with little memory capacity, only limited by\nthe CPU memory.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 12:41:28 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Ram\u00edrez-Gil", "Francisco Javier", ""], ["Tsuzuki", "Marcos de Sales Guerra", ""], ["Montealegre-Rubio", "Wilfredo", ""]]}, {"id": "1501.04979", "submitter": "Thomas Goldstein", "authors": "Tom Goldstein, Christoph Studer, Richard Baraniuk", "title": "FASTA: A Generalized Implementation of Forward-Backward Splitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a user manual for the software package FASTA.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 01:22:55 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2015 16:54:50 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2016 23:51:33 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Goldstein", "Tom", ""], ["Studer", "Christoph", ""], ["Baraniuk", "Richard", ""]]}, {"id": "1501.05097", "submitter": "Dmitry Gromov", "authors": "Fernando Casta\\~nos and Hannah Michalska and Dmitry Gromov and Vincent\n  Hayward", "title": "Discrete-Time Models for Implicit Port-Hamiltonian Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NA math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit representations of finite-dimensional port-Hamiltonian systems are\nstudied from the perspective of their use in numerical simulation and control\ndesign. Implicit representations arise when a system is modeled in Cartesian\ncoordinates and when the system constraints are applied in the form of\nadditional algebraic equations (the system model is in a DAE form). Such\nrepresentations lend themselves better to sample-data approximations. An\nimplicit representation of a port-Hamiltonian system is given and it is shown\nhow to construct a sampled-data model that preserves the port-Hamiltonian\nstructure under sample and hold.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 09:12:42 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Casta\u00f1os", "Fernando", ""], ["Michalska", "Hannah", ""], ["Gromov", "Dmitry", ""], ["Hayward", "Vincent", ""]]}, {"id": "1501.05508", "submitter": "Lukas Einkemmer", "authors": "Lukas Einkemmer", "title": "High performance computing aspects of a dimension independent\n  semi-Lagrangian discontinuous Galerkin code", "comments": null, "journal-ref": "Computer Physics Communications, Volume 202, May 2016, Pages\n  326-336", "doi": "10.1016/j.cpc.2016.01.012", "report-no": null, "categories": "physics.comp-ph cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently developed semi-Lagrangian discontinuous Galerkin approach is\nused to discretize hyperbolic partial differential equations (usually first\norder equations). Since these methods are conservative, local in space, and\nable to limit numerical diffusion, they are considered a promising alternative\nto more traditional semi-Lagrangian schemes (which are usually based on\npolynomial or spline interpolation).\n  In this paper, we consider a parallel implementation of a semi-Lagrangian\ndiscontinuous Galerkin method for distributed memory systems (so-called\nclusters). Both strong and weak scaling studies are performed on the Vienna\nScientific Cluster 2 (VSC-2). In the case of weak scaling, up to 8192 cores, we\nobserve a parallel efficiency above 0.89 for both two and four dimensional\nproblems. Strong scaling results show good scalability to at least 1024 cores\n(we consider problems that can be run on a single processor in reasonable\ntime). In addition, we study the scaling of a two dimensional Vlasov--Poisson\nsolver that is implemented using the framework provided. All of the simulation\nare conducted in the context of worst case communication overhead; i.e., in a\nsetting where the CFL number increases linearly with the problem size.\n  The framework introduced in this paper facilitates a dimension independent\nimplementation (based on C++ templates) of scientific codes using both an MPI\nand a hybrid approach to parallelization. We describe the essential ingredients\nof our implementation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 14:26:47 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Einkemmer", "Lukas", ""]]}, {"id": "1501.05740", "submitter": "Martin Sundin", "authors": "Martin Sundin, Cristian R. Rojas, Magnus Jansson and Saikat Chatterjee", "title": "Bayesian Learning for Low-Rank matrix reconstruction", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop latent variable models for Bayesian learning based low-rank matrix\ncompletion and reconstruction from linear measurements. For under-determined\nsystems, the developed methods are shown to reconstruct low-rank matrices when\nneither the rank nor the noise power is known a-priori. We derive relations\nbetween the latent variable models and several low-rank promoting penalty\nfunctions. The relations justify the use of Kronecker structured covariance\nmatrices in a Gaussian based prior. In the methods, we use evidence\napproximation and expectation-maximization to learn the model parameters. The\nperformance of the methods is evaluated through extensive numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 08:52:35 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Sundin", "Martin", ""], ["Rojas", "Cristian R.", ""], ["Jansson", "Magnus", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "1501.06209", "submitter": "Martin Uecker", "authors": "Martin Uecker", "title": "Parallel Magnetic Resonance Imaging", "comments": "22 pages, 9 Figures, 76 References. Copyright: Martin Uecker. Draft\n  for a book chapter. To appear in: A Majumdar and RK Ward (eds.), MRI:\n  Physics, Image Reconstruction, and Analysis, CRC Press 2015", "journal-ref": "In: MRI: Physics, Image Reconstruction, and Analysis, CRC Press\n  2015, pp. 73-92, ISBN 9781482298871", "doi": null, "report-no": null, "categories": "cs.NA cs.CV math.NA math.OC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main disadvantage of Magnetic Resonance Imaging (MRI) are its long scan\ntimes and, in consequence, its sensitivity to motion. Exploiting the\ncomplementary information from multiple receive coils, parallel imaging is able\nto recover images from under-sampled k-space data and to accelerate the\nmeasurement. Because parallel magnetic resonance imaging can be used to\naccelerate basically any imaging sequence it has many important applications.\nParallel imaging brought a fundamental shift in image reconstruction: Image\nreconstruction changed from a simple direct Fourier transform to the solution\nof an ill-conditioned inverse problem. This work gives an overview of image\nreconstruction from the perspective of inverse problems. After introducing\nbasic concepts such as regularization, discretization, and iterative\nreconstruction, advanced topics are discussed including algorithms for\nauto-calibration, the connection to approximation theory, and the combination\nwith compressed sensing.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jan 2015 21:01:41 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2015 06:20:43 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Uecker", "Martin", ""]]}, {"id": "1501.06318", "submitter": "Volodymyr Kuleshov", "authors": "Volodymyr Kuleshov, Arun Tesjavi Chaganty, Percy Liang", "title": "Simultaneous diagonalization: the asymmetric, low-rank, and noisy\n  settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous matrix diagonalization is used as a subroutine in many machine\nlearning problems, including blind source separation and paramater estimation\nin latent variable models. Here, we extend algorithms for performing joint\ndiagonalization to low-rank and asymmetric matrices, and we also provide\nextensions to the perturbation analysis of these methods. Our results allow\njoint diagonalization to be applied in several new settings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 10:36:03 GMT"}, {"version": "v2", "created": "Sat, 9 May 2015 18:32:54 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Kuleshov", "Volodymyr", ""], ["Chaganty", "Arun Tesjavi", ""], ["Liang", "Percy", ""]]}, {"id": "1501.06625", "submitter": "Jan Verschelde", "authors": "Jan Verschelde and Xiangcheng Yu", "title": "Accelerating Polynomial Homotopy Continuation on a Graphics Processing\n  Unit with Double Double and Quad Double Arithmetic", "comments": "Accepted for publication in the Proceedings of the 7th International\n  Workshop on Parallel Symbolic Computation (PASCO 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA math.AG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical continuation methods track a solution path defined by a homotopy.\nThe systems we consider are defined by polynomials in several variables with\ncomplex coefficients. For larger dimensions and degrees, the numerical\nconditioning worsens and hardware double precision becomes often insufficient\nto reach the end of the solution path. With double double and quad double\narithmetic, we can solve larger problems that we could not solve with hardware\ndouble arithmetic, but at a higher computational cost. This cost overhead can\nbe compensated by acceleration on a Graphics Processing Unit (GPU). We describe\nour implementation and report on computational results on benchmark polynomial\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 23:54:20 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2015 15:55:11 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2015 15:08:55 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Verschelde", "Jan", ""], ["Yu", "Xiangcheng", ""]]}, {"id": "1501.06741", "submitter": "Juergen Zechner", "authors": "Gernot Beer and Benjamin Marussig and J\\\"urgen Zechner", "title": "A simple approach to the numerical simulation with trimmed CAD surfaces", "comments": "20 pages and 16 figures", "journal-ref": "Computer Methods in Applied Mechanics and Engineering, Volume 285,\n  1 March 2015, Pages 776-790", "doi": "10.1016/j.cma.2014.12.010", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work a novel method for the analysis with trimmed CAD surfaces is\npresented. The method involves an additional mapping step and the attraction\nstems from its sim- plicity and ease of implementation into existing Finite\nElement (FEM) or Boundary Element (BEM) software. The method is first verified\nwith classical test examples in structural mechanics. Then two practical\napplications are presented one using the FEM, the other the BEM, that show the\napplicability of the method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 11:01:00 GMT"}], "update_date": "2015-01-28", "authors_parsed": [["Beer", "Gernot", ""], ["Marussig", "Benjamin", ""], ["Zechner", "J\u00fcrgen", ""]]}, {"id": "1501.07242", "submitter": "Tengyuan Liang", "authors": "Alexandre Belloni, Tengyuan Liang, Hariharan Narayanan, Alexander\n  Rakhlin", "title": "Escaping the Local Minima via Simulated Annealing: Optimization of\n  Approximately Convex Functions", "comments": "27 pages", "journal-ref": "Proceedings of the 28th Conference on Learning Theory 40 (2015)\n  240-265", "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimizing an approximately convex function over a\nbounded convex set in $\\mathbb{R}^n$ using only function evaluations. The\nproblem is reduced to sampling from an \\emph{approximately} log-concave\ndistribution using the Hit-and-Run method, which is shown to have the same\n$\\mathcal{O}^*$ complexity as sampling from log-concave distributions. In\naddition to extend the analysis for log-concave distributions to approximate\nlog-concave distributions, the implementation of the 1-dimensional sampler of\nthe Hit-and-Run walk requires new methods and analysis. The algorithm then is\nbased on simulated annealing which does not relies on first order conditions\nwhich makes it essentially immune to local minima.\n  We then apply the method to different motivating problems. In the context of\nzeroth order stochastic convex optimization, the proposed method produces an\n$\\epsilon$-minimizer after $\\mathcal{O}^*(n^{7.5}\\epsilon^{-2})$ noisy function\nevaluations by inducing a $\\mathcal{O}(\\epsilon/n)$-approximately log concave\ndistribution. We also consider in detail the case when the \"amount of\nnon-convexity\" decays towards the optimum of the function. Other applications\nof the method discussed in this work include private computation of empirical\nrisk minimizers, two-stage stochastic programming, and approximate dynamic\nprogramming for online learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 19:12:40 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 15:11:54 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Belloni", "Alexandre", ""], ["Liang", "Tengyuan", ""], ["Narayanan", "Hariharan", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "1501.07255", "submitter": "Renato J Cintra", "authors": "M. M. S. Lira, H. M. de Oliveira, R. J. Cintra", "title": "Elliptic-cylindrical Wavelets: The Mathieu Wavelets", "comments": "10 pages, 2 figures", "journal-ref": "IEEE Signal Processing Letters, vol. 11, issue 1, pp. 52-55, 2004", "doi": "10.1109/LSP.2003.819341", "report-no": null, "categories": "stat.ME cs.NA math.NA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note introduces a new family of wavelets and a multiresolution analysis,\nwhich exploits the relationship between analysing filters and Floquet's\nsolution of Mathieu differential equations. The transfer function of both the\ndetail and the smoothing filter is related to the solution of a Mathieu\nequation of odd characteristic exponent. The number of notches of these filters\ncan be easily designed. Wavelets derived by this method have potential\napplication in the fields of Optics and Electromagnetism.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 20:00:17 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Lira", "M. M. S.", ""], ["de Oliveira", "H. M.", ""], ["Cintra", "R. J.", ""]]}, {"id": "1501.07774", "submitter": "Vikram Sharma", "authors": "Vikram Sharma and Prashant Batra", "title": "Near Optimal Subdivision Algorithms for Real Root Isolation", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.SC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a subroutine that improves the running time of any subdivision\nalgorithm for real root isolation. The subroutine first detects clusters of\nroots using a result of Ostrowski, and then uses Newton iteration to converge\nto them. Near a cluster, we switch to subdivision, and proceed recursively. The\nsubroutine has the advantage that it is independent of the predicates used to\nterminate the subdivision. This gives us an alternative and simpler approach to\nrecent developments of Sagraloff (2012) and Sagraloff-Mehlhorn (2013), assuming\nexact arithmetic.\n  The subdivision tree size of our algorithm using predicates based on\nDescartes's rule of signs is bounded by $O(n\\log n)$, which is better by\n$O(n\\log L)$ compared to known results. Our analysis differs in two key\naspects. First, we use the general technique of continuous amortization from\nBurr-Krahmer-Yap (2009), and second, we use the geometry of clusters of roots\ninstead of the Davenport-Mahler bound. The analysis naturally extends to other\npredicates.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2015 13:53:37 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Sharma", "Vikram", ""], ["Batra", "Prashant", ""]]}]