[{"id": "1402.0642", "submitter": "Thomas Wentworth", "authors": "Thomas Wentworth and Ilse Ipsen", "title": "kappa_SQ: A Matlab package for randomized sampling of matrices with\n  orthonormal columns", "comments": "Kappa_SQ can be downloaded from :\n  http://www4.ncsu.edu/~tawentwo/kappaSQ_02042014.zip", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kappa_SQ software package is designed to assist researchers working on\nrandomized row sampling. The package contains a collection of Matlab functions\nalong with a GUI that ties them all together and provides a platform for the\nuser to perform experiments. In particular, kappa_SQ is designed to do\nexperiments related to the two-norm condition number of a sampled matrix,\n$\\kappa(SQ)$, where $S$ is a row sampling matrix and $Q$ is a tall and skinny\nmatrix with orthonormal columns. Via a simple GUI, kappa_SQ can generate test\nmatrices, perform various types of row sampling, measure $\\kappa(SQ)$,\ncalculate bounds and produce high quality plots of the results. All of the\nimportant codes are written in separate Matlab function files in a standard\nformat which makes it easy for a user to either use the codes by themselves or\nincorporate their own codes into the kappa_SQ package.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 07:17:01 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Wentworth", "Thomas", ""], ["Ipsen", "Ilse", ""]]}, {"id": "1402.0998", "submitter": "Julius Reiss", "authors": "Julius Reiss", "title": "A family of energy stable, skew-symmetric finite difference schemes on\n  collocated grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple scheme for incompressible, constant density flows is presented,\nwhich avoids odd-even decoupling for the Laplacian on a collocated grids.\nEnergy stability is implied by maintaining strict energy conservation. Momentum\nis conserved. Arbitrary order in space and time can easily be obtained. The\nconservation properties hold on transformed grids.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 10:19:38 GMT"}], "update_date": "2014-02-06", "authors_parsed": [["Reiss", "Julius", ""]]}, {"id": "1402.1298", "submitter": "Lenka Zdeborova", "authors": "Yoshiyuki Kabashima, Florent Krzakala, Marc M\\'ezard, Ayaka Sakata,\n  and Lenka Zdeborov\\'a", "title": "Phase transitions and sample complexity in Bayes-optimal matrix\n  factorization", "comments": "50 pages, 10 figures", "journal-ref": "IEEE Transactions on Information Theory (Volume:62 , Issue: 7,\n  Pages: 4228 - 4265) 2016", "doi": "10.1109/TIT.2016.2556702", "report-no": null, "categories": "cs.NA cond-mat.stat-mech cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the matrix factorization problem. Given a noisy measurement of a\nproduct of two matrices, the problem is to estimate back the original matrices.\nIt arises in many applications such as dictionary learning, blind matrix\ncalibration, sparse principal component analysis, blind source separation, low\nrank matrix completion, robust principal component analysis or factor analysis.\nIt is also important in machine learning: unsupervised representation learning\ncan often be studied through matrix factorization. We use the tools of\nstatistical mechanics - the cavity and replica methods - to analyze the\nachievability and computational tractability of the inference problems in the\nsetting of Bayes-optimal inference, which amounts to assuming that the two\nmatrices have random independent elements generated from some known\ndistribution, and this information is available to the inference algorithm. In\nthis setting, we compute the minimal mean-squared-error achievable in principle\nin any computational time, and the error that can be achieved by an efficient\napproximate message passing algorithm. The computation is based on the\nasymptotic state-evolution analysis of the algorithm. The performance that our\nanalysis predicts, both in terms of the achieved mean-squared-error, and in\nterms of sample complexity, is extremely promising and motivating for a further\ndevelopment of the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 09:56:50 GMT"}, {"version": "v2", "created": "Sat, 31 Jan 2015 20:56:04 GMT"}, {"version": "v3", "created": "Mon, 21 Mar 2016 18:07:08 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Kabashima", "Yoshiyuki", ""], ["Krzakala", "Florent", ""], ["M\u00e9zard", "Marc", ""], ["Sakata", "Ayaka", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1402.1636", "submitter": "Petr Vabishchevich N.", "authors": "Petr N. Vabishchevich", "title": "Numerical solving the boundary value problem for fractional powers of\n  elliptic operators", "comments": "18 pages, 17 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2014.11.022", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A boundary value problem for a fractional power of the second-order elliptic\noperator is considered. It is solved numerically using a time-dependent problem\nfor a pseudo-parabolic equation. For the auxiliary Cauchy problem, the standard\ntwo-level schemes with weights are applied. Stability conditions are obtained\nfor the fully discrete schemes under the consideration. The numerical results\nare presented for a model two-dimensional boundary value problem wit a\nfractional power of an elliptic operator. The dependence of accuracy on grids\nin time and in space is studied.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 13:42:18 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Vabishchevich", "Petr N.", ""]]}, {"id": "1402.1673", "submitter": "Petr  Tichavsky", "authors": "Petr Tichavsky, Anh Huy Phan, and Andrzej Cichocki", "title": "Non-Orthogonal Tensor Diagonalization", "comments": "The manuscript was revised deeply, but the main idea is the same. The\n  algorithm has changed significantly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor diagonalization means transforming a given tensor to an exactly or\nnearly diagonal form through multiplying the tensor by non-orthogonal\ninvertible matrices along selected dimensions of the tensor. It is\ngeneralization of approximate joint diagonalization (AJD) of a set of matrices.\nIn particular, we derive (1) a new algorithm for symmetric AJD, which is called\ntwo-sided symmetric diagonalization of order-three tensor, (2) a similar\nalgorithm for non-symmetric AJD, also called general two-sided diagonalization\nof an order-3 tensor, and (3) an algorithm for three-sided diagonalization of\norder-3 or order-4 tensors. The latter two algorithms may serve for canonical\npolyadic (CP) tensor decomposition, and they can outperform other CP tensor\ndecomposition methods in terms of computational speed under the restriction\nthat the tensor rank does not exceed the tensor multilinear rank. Finally, we\npropose (4) similar algorithms for tensor block diagonalization, which is\nrelated to the tensor block-term decomposition.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 15:50:21 GMT"}, {"version": "v2", "created": "Mon, 16 Feb 2015 14:01:09 GMT"}, {"version": "v3", "created": "Fri, 1 Jul 2016 17:18:59 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Tichavsky", "Petr", ""], ["Phan", "Anh Huy", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1402.1786", "submitter": "Neelesh Patankar", "authors": "Yong Chen and Neelesh A. Patankar", "title": "Fluctuating Immersed Material (FIMAT) Dynamics for Fully Resolved\n  Simulation of the Brownian Motion of Particles", "comments": "37 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluctuating hydrodynamics based techniques have been developed in recent\nyears for the simulation of Brownian motion of particles. These mesoscale\nsimulation tools are viable approaches for problems where molecular dynamics\nsimulations may be deemed expensive. We have developed a rigid constraint-based\nformulation where the key idea is to assume that the entire domain is a\nfluctuating fluid. Rigid motion constraints are then imposed in regions that\nare occupied by rigid particles. The resulting solution gives the Brownian\nmotion of the particles. This approach is shown to be viable for the simulation\nof long time scale diffusive behavior as well as for short time scale dynamics\nby using two separate solution techniques. Test cases are reported to validate\nthe approach and to establish its efficacy.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 22:19:13 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Chen", "Yong", ""], ["Patankar", "Neelesh A.", ""]]}, {"id": "1402.2018", "submitter": "Razvan Stefanescu", "authors": "R\\u{a}zvan \\c{S}tef\\u{a}nescu, Adrian Sandu, and Ionel M. Navon", "title": "Comparison of POD reduced order strategies for the nonlinear 2D Shallow\n  Water Equations", "comments": "23 pages, 8 figures, 5 tables", "journal-ref": null, "doi": "10.1002/fld.3946", "report-no": "TR 2/2014", "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces tensorial calculus techniques in the framework of\nProper Orthogonal Decomposition (POD) to reduce the computational complexity of\nthe reduced nonlinear terms. The resulting method, named tensorial POD, can be\napplied to polynomial nonlinearities of any degree $p$. Such nonlinear terms\nhave an on-line complexity of $\\mathcal{O}(k^{p+1})$, where $k$ is the\ndimension of POD basis, and therefore is independent of full space dimension.\nHowever it is efficient only for quadratic nonlinear terms since for higher\nnonlinearities standard POD proves to be less time consuming once the POD basis\ndimension $k$ is increased. Numerical experiments are carried out with a two\ndimensional shallow water equation (SWE) test problem to compare the\nperformance of tensorial POD, standard POD, and POD/Discrete Empirical\nInterpolation Method (DEIM). Numerical results show that tensorial POD\ndecreases by $76\\times$ times the computational cost of the on-line stage of\nstandard POD for configurations using more than $300,000$ model variables. The\ntensorial POD SWE model was only $2-8\\times$ slower than the POD/DEIM SWE model\nbut the implementation effort is considerably increased. Tensorial calculus was\nagain employed to construct a new algorithm allowing POD/DEIM shallow water\nequation model to compute its off-line stage faster than the standard and\ntensorial POD approaches.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 02:20:09 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["\u015etef\u0103nescu", "R\u0103zvan", ""], ["Sandu", "Adrian", ""], ["Navon", "Ionel M.", ""]]}, {"id": "1402.2058", "submitter": "Philipp Hennig PhD", "authors": "Philipp Hennig", "title": "Probabilistic Interpretation of Linear Solvers", "comments": "final version, in press at SIAM J Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript proposes a probabilistic framework for algorithms that\niteratively solve unconstrained linear problems $Bx = b$ with positive definite\n$B$ for $x$. The goal is to replace the point estimates returned by existing\nmethods with a Gaussian posterior belief over the elements of the inverse of\n$B$, which can be used to estimate errors. Recent probabilistic interpretations\nof the secant family of quasi-Newton optimization algorithms are extended.\nCombined with properties of the conjugate gradient algorithm, this leads to\nuncertainty-calibrated methods with very limited cost overhead over conjugate\ngradients, a self-contained novel interpretation of the quasi-Newton and\nconjugate gradient algorithms, and a foundation for new nonlinear optimization\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 07:56:13 GMT"}, {"version": "v2", "created": "Wed, 15 Oct 2014 08:23:52 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Hennig", "Philipp", ""]]}, {"id": "1402.2626", "submitter": "Jan Verschelde", "authors": "Jan Verschelde and Xiangcheng Yu", "title": "GPU acceleration of Newton's method for large systems of polynomial\n  equations in double double and quad double arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to compensate for the higher cost of double double and quad double\narithmetic when solving large polynomial systems, we investigate the\napplication of NVIDIA Tesla K20C general purpose graphics processing unit. The\nfocus on this paper is on Newton's method, which requires the evaluation of the\npolynomials, their derivatives, and the solution of a linear system to compute\nthe update to the current approximation for the solution. The reverse mode of\nalgorithmic differentiation for a product of variables is rewritten in a binary\ntree fashion so all threads in a block can collaborate in the computation. For\ndouble arithmetic, the evaluation and differentiation problem is memory bound,\nwhereas for complex quad double arithmetic the problem is compute bound. With\nacceleration we can double the dimension and get results that are twice as\naccurate in about the same time.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 20:18:31 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 13:38:42 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Verschelde", "Jan", ""], ["Yu", "Xiangcheng", ""]]}, {"id": "1402.2703", "submitter": "Jeffrey Tsang", "authors": "Jeffrey Tsang, Rajesh Pereira", "title": "Taking all positive eigenvectors is suboptimal in classical\n  multidimensional scaling", "comments": "13 pages, 1 figure, 1 table, 1 supplementary file", "journal-ref": "SIAM Journal on Optimization 26(4):2080-2090, 2016", "doi": "10.1137/15M102602X", "report-no": null, "categories": "math.ST cs.NA math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is hard to overstate the importance of multidimensional scaling as an\nanalysis technique in the broad sciences. Classical, or Torgerson\nmultidimensional scaling is one of the main variants, with the advantage that\nit has a closed-form analytic solution. However, this solution is exact if and\nonly if the distances are Euclidean. Conversely, there has been comparatively\nlittle discussion on what to do in the presence of negative eigenvalues: the\nintuitive solution, prima facie justifiable in least-squares terms, is to take\nevery positive eigenvector as a dimension. We show that this, minimizing\nleast-squares to the centred distances instead of the true distances, is\nsuboptimal - throwing away positive eigenvectors can decrease the error even as\nwe project to fewer dimensions. We provide provably better methods for handling\nthis common case.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 00:29:37 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Tsang", "Jeffrey", ""], ["Pereira", "Rajesh", ""]]}, {"id": "1402.2991", "submitter": "Jean-Michel Muller", "authors": "Stef Graillat (LIP6), Vincent Lef\\`evre (Inria Grenoble Rh\\^one-Alpes\n  / LIP Laboratoire de l'Informatique du Parall\\'elisme), Jean-Michel Muller\n  (Inria Grenoble Rh\\^one-Alpes / LIP Laboratoire de l'Informatique du\n  Parall\\'elisme)", "title": "On the maximum relative error when computing x^n in floating-point\n  arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we improve the usual relative error bound for the computation\nof x^n through iterated multiplications by x in binary floating-point\narithmetic. The obtained error bound is only slightly better than the usual\none, but it is simpler. We also discuss the more general problem of computing\nthe product of n terms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 20:13:14 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["Graillat", "Stef", "", "LIP6"], ["Lef\u00e8vre", "Vincent", "", "Inria Grenoble Rh\u00f4ne-Alpes\n  / LIP Laboratoire de l'Informatique du Parall\u00e9lisme"], ["Muller", "Jean-Michel", "", "Inria Grenoble Rh\u00f4ne-Alpes / LIP Laboratoire de l'Informatique du\n  Parall\u00e9lisme"]]}, {"id": "1402.3545", "submitter": "Eike Hermann M\\\"uller", "authors": "Eike Hermann M\\\"uller, Robert Scheichl, Eero Vainikko", "title": "Petascale elliptic solvers for anisotropic PDEs on GPU clusters", "comments": "20 pages, 6 figures. Additional explanations and clarifications of\n  the characteristics of the PDE; discussion and estimate of the condition\n  number. Added section and figure on the robustness of both the single-level\n  and the multigrid method under variations of the Courant number. Clarified\n  the terminology in the performance analysis. Added section on preliminary\n  strong scaling results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory bound applications such as solvers for large sparse systems of\nequations remain a challenge for GPUs. Fast solvers should be based on\nnumerically efficient algorithms and implemented such that global memory access\nis minimised. To solve systems with up to one trillion ($10^{12}$) unknowns the\ncode has to make efficient use of several million individual processor cores on\nlarge GPU clusters. We describe the multi-GPU implementation of two\nalgorithmically optimal iterative solvers for anisotropic elliptic PDEs which\nare encountered in atmospheric modelling. In this application the condition\nnumber is large but independent of the grid resolution and both methods are\nasymptotically optimal, albeit with different absolute performance. We\nparallelise the solvers and adapt them to the specific features of GPU\narchitectures, paying particular attention to efficient global memory access.\nWe achieve a performance of up to 0.78 PFLOPs when solving an equation with\n$0.55\\cdot 10^{12}$ unknowns on 16384 GPUs; this corresponds to about $3\\%$ of\nthe theoretical peak performance of the machine and we use more than $40\\%$ of\nthe peak memory bandwidth with a Conjugate Gradient (CG) solver. Although the\nother solver, a geometric multigrid algorithm, has a slightly worse performance\nin terms of FLOPs per second, overall it is faster as it needs less iterations\nto converge; the multigrid algorithm can solve a linear PDE with half a\ntrillion unknowns in about one second.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 18:30:04 GMT"}, {"version": "v2", "created": "Fri, 29 May 2015 10:56:36 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["M\u00fcller", "Eike Hermann", ""], ["Scheichl", "Robert", ""], ["Vainikko", "Eero", ""]]}, {"id": "1402.5086", "submitter": "Aravindh Krishnamoorthy", "authors": "Aravindh Krishnamoorthy", "title": "Symmetric QR Algorithm with Permutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the QR Algorithm with Permutations that shows an\nimproved convergence rate compared to the classical QR algorithm. We determine\na bound for performance based on best instantaneous convergence, and develop\nlow complexity methods for computing the permutation matrices at every\niteration. We use simulations to verify the improvement, and to compare the\nperformance of proposed algorithms to the classical QR algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 17:34:49 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Krishnamoorthy", "Aravindh", ""]]}, {"id": "1402.5287", "submitter": "Gleb Beliakov", "authors": "Gleb Beliakov", "title": "On fast matrix-vector multiplication with a Hankel matrix in\n  multiprecision arithmetics", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two fast algorithms for matrix-vector multiplication $y=Ax$, where\n$A$ is a Hankel matrix. The current asymptotically fastest method is based on\nthe Fast Fourier Transform (FFT), however in multiprecision arithmetics with\nvery high accuracy FFT method is actually slower than schoolbook multiplication\nfor matrix sizes up to $n=8000$. One method presented is based on a\ndecomposition of multiprecision numbers into sums, and applying standard or\ndouble precision FFT. The second method, inspired by Karatsuba multiplication,\nis based on recursively performing multiplications with matrices of half-size\nof the original. Its complexity in terms of the matrix size $n$ is\n$\\Theta(n^{\\log 3})$. Both methods are applicable to Toeplitz matrices and to\ncirculant matrices.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 13:03:18 GMT"}, {"version": "v2", "created": "Mon, 24 Mar 2014 10:40:07 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Beliakov", "Gleb", ""]]}, {"id": "1402.5521", "submitter": "Gesualdo Scutari", "authors": "Francisco Facchinei and Gesualdo Scutari and Simone Sagratella", "title": "Parallel Selective Algorithms for Big Data Optimization", "comments": "This work is an extended version of the conference paper that has\n  been presented at IEEE ICASSP'14. The first and the second author contributed\n  equally to the paper. This revised version contains new numerical results on\n  non convex quadratic problems", "journal-ref": null, "doi": "10.1109/TSP.2015.2399858", "report-no": null, "categories": "cs.DC cs.IT cs.NA math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decomposition framework for the parallel optimization of the sum\nof a differentiable (possibly nonconvex) function and a (block) separable\nnonsmooth, convex one. The latter term is usually employed to enforce structure\nin the solution, typically sparsity. Our framework is very flexible and\nincludes both fully parallel Jacobi schemes and Gauss- Seidel (i.e.,\nsequential) ones, as well as virtually all possibilities \"in between\" with only\na subset of variables updated at each iteration. Our theoretical convergence\nresults improve on existing ones, and numerical results on LASSO, logistic\nregression, and some nonconvex quadratic problems show that the new method\nconsistently outperforms existing algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2014 16:01:50 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2014 14:04:41 GMT"}, {"version": "v3", "created": "Thu, 6 Mar 2014 13:41:01 GMT"}, {"version": "v4", "created": "Fri, 8 Aug 2014 23:26:02 GMT"}, {"version": "v5", "created": "Tue, 9 Dec 2014 00:44:39 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Facchinei", "Francisco", ""], ["Scutari", "Gesualdo", ""], ["Sagratella", "Simone", ""]]}, {"id": "1402.5897", "submitter": "Elmar Peise", "authors": "Elmar Peise (1), Paolo Bientinesi (1) ((1) AICES, RWTH Aachen)", "title": "A Study on the Influence of Caching: Sequences of Dense Linear Algebra\n  Kernels", "comments": "Submitted to the Ninth International Workshop on Automatic\n  Performance Tuning (iWAPT2014)", "journal-ref": null, "doi": null, "report-no": "AICES-2014/02-1", "categories": "cs.MS cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is universally known that caching is critical to attain high- performance\nimplementations: In many situations, data locality (in space and time) plays a\nbigger role than optimizing the (number of) arithmetic floating point\noperations. In this paper, we show evidence that at least for linear algebra\nalgorithms, caching is also a crucial factor for accurate performance modeling\nand performance prediction.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 12:23:19 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Peise", "Elmar", "", "AICES, RWTH Aachen"], ["Bientinesi", "Paolo", "", "AICES, RWTH Aachen"]]}, {"id": "1402.6081", "submitter": "Sebastian Liska", "authors": "Sebastian Liska and Tim Colonius", "title": "A parallel fast multipole method for elliptic difference equations", "comments": "Corrected typos; changed output format", "journal-ref": "Journal of Computational Physics 278 (2014), 76-91", "doi": "10.1016/j.jcp.2014.07.048", "report-no": null, "categories": "physics.comp-ph cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new fast multipole formulation for solving elliptic difference equations on\nunbounded domains and its parallel implementation are presented. These\ndifference equations can arise directly in the description of physical systems,\ne.g. crystal structures, or indirectly through the discretization of PDEs. In\nthe analog to solving continuous inhomogeneous differential equations using\nGreen's functions, the proposed method uses the fundamental solution of the\ndiscrete operator on an infinite grid, or lattice Green's function. Fast\nsolutions $\\mathcal{O}(N)$ are achieved by using a kernel-independent\ninterpolation-based fast multipole method. Unlike other fast multipole\nalgorithms, our approach exploits the regularity of the underlying Cartesian\ngrid and the efficiency of FFTs to reduce the computation time. Our parallel\nimplementation allows communications and computations to be overlapped and\nrequires minimal global synchronization. The accuracy, efficiency, and parallel\nperformance of the method are demonstrated through numerical experiments on the\ndiscrete 3D Poisson equation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 08:18:58 GMT"}, {"version": "v2", "created": "Fri, 7 Nov 2014 23:00:32 GMT"}, {"version": "v3", "created": "Wed, 6 Apr 2016 21:10:42 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Liska", "Sebastian", ""], ["Colonius", "Tim", ""]]}, {"id": "1402.6763", "submitter": "Alan Malek", "authors": "Yasin Abbasi-Yadkori, Peter L. Bartlett, Alan Malek", "title": "Linear Programming for Large-Scale Markov Decision Problems", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of controlling a Markov decision process (MDP) with a\nlarge state space, so as to minimize average cost. Since it is intractable to\ncompete with the optimal policy for large scale problems, we pursue the more\nmodest goal of competing with a low-dimensional family of policies. We use the\ndual linear programming formulation of the MDP average cost problem, in which\nthe variable is a stationary distribution over state-action pairs, and we\nconsider a neighborhood of a low-dimensional subset of the set of stationary\ndistributions (defined in terms of state-action features) as the comparison\nclass. We propose two techniques, one based on stochastic convex optimization,\nand one based on constraint sampling. In both cases, we give bounds that show\nthat the performance of our algorithms approaches the best achievable by any\npolicy in the comparison class. Most importantly, these results depend on the\nsize of the comparison class, but not on the size of the state space.\nPreliminary experiments show the effectiveness of the proposed algorithms in a\nqueuing application.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 01:43:38 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Abbasi-Yadkori", "Yasin", ""], ["Bartlett", "Peter L.", ""], ["Malek", "Alan", ""]]}, {"id": "1402.6964", "submitter": "Austin Benson", "authors": "Austin R. Benson, Jason D. Lee, Bartek Rajwa, David F. Gleich", "title": "Scalable methods for nonnegative matrix factorizations of near-separable\n  tall-and-skinny matrices", "comments": null, "journal-ref": "Proceedings of Neural Information Processing Systems, 2014", "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous algorithms are used for nonnegative matrix factorization under the\nassumption that the matrix is nearly separable. In this paper, we show how to\nmake these algorithms efficient for data matrices that have many more rows than\ncolumns, so-called \"tall-and-skinny matrices\". One key component to these\nimproved methods is an orthogonal matrix transformation that preserves the\nseparability of the NMF problem. Our final methods need a single pass over the\ndata matrix and are suitable for streaming, multi-core, and MapReduce\narchitectures. We demonstrate the efficacy of these algorithms on\nterabyte-sized synthetic matrices and real-world matrices from scientific\ncomputing and bioinformatics.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 16:41:26 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Benson", "Austin R.", ""], ["Lee", "Jason D.", ""], ["Rajwa", "Bartek", ""], ["Gleich", "David F.", ""]]}]