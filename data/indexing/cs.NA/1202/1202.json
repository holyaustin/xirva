[{"id": "1202.0988", "submitter": "Massimo Di Pierro", "authors": "Massimo Di Pierro", "title": "Improving non-linear fits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA hep-lat", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this notes we describe an algorithm for non-linear fitting which\nincorporates some of the features of linear least squares into a general\nminimum $\\chi^2$ fit and provide a pure Python implementation of the algorithm.\nIt consists of the variable projection method (varpro), combined with a Newton\noptimizer and stabilized using the steepest descent with an adaptative step.\nThe algorithm includes a term to account for Bayesian priors. We performed\ntests of the algorithm using simulated data. This method is suitable, for\nexample, for fitting with sums of exponentials as often needed in Lattice\nQuantum Chromodynamics.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2012 18:22:37 GMT"}, {"version": "v2", "created": "Tue, 7 Feb 2012 04:01:38 GMT"}], "update_date": "2012-02-08", "authors_parsed": [["Di Pierro", "Massimo", ""]]}, {"id": "1202.1490", "submitter": "Aravindh Krishnamoorthy", "authors": "Aravindh Krishnamoorthy, Kenan Kocagoez", "title": "Singular Values using Cholesky Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper two ways to compute singular values are presented which use\nCholesky decomposition as their basic operation.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 18:37:07 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Krishnamoorthy", "Aravindh", ""], ["Kocagoez", "Kenan", ""]]}, {"id": "1202.1928", "submitter": "Tim Sullivan", "authors": "T. J. Sullivan, M. McKerns, D. Meyer, F. Theil, H. Owhadi, and M.\n  Ortiz", "title": "Optimal uncertainty quantification for legacy data observations of\n  Lipschitz functions", "comments": "38 pages", "journal-ref": "ESAIM Math. Model. Numer. Anal. 47(6):1657--1689, 2013", "doi": "10.1051/m2an/2013083", "report-no": null, "categories": "math.PR cs.NA math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of providing optimal uncertainty quantification (UQ)\n--- and hence rigorous certification --- for partially-observed functions. We\npresent a UQ framework within which the observations may be small or large in\nnumber, and need not carry information about the probability distribution of\nthe system in operation. The UQ objectives are posed as optimization problems,\nthe solutions of which are optimal bounds on the quantities of interest; we\nconsider two typical settings, namely parameter sensitivities (McDiarmid\ndiameters) and output deviation (or failure) probabilities. The solutions of\nthese optimization problems depend non-trivially (even non-monotonically and\ndiscontinuously) upon the specified legacy data. Furthermore, the extreme\nvalues are often determined by only a few members of the data set; in our\nprincipal physically-motivated example, the bounds are determined by just 2 out\nof 32 data points, and the remainder carry no information and could be\nneglected without changing the final answer. We propose an analogue of the\nsimplex algorithm from linear programming that uses these observations to offer\nefficient and rigorous UQ for high-dimensional systems with high-cardinality\nlegacy data. These findings suggest natural methods for selecting optimal\n(maximally informative) next experiments.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 09:43:49 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2013 23:39:46 GMT"}, {"version": "v3", "created": "Sat, 13 Apr 2013 04:25:43 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Sullivan", "T. J.", ""], ["McKerns", "M.", ""], ["Meyer", "D.", ""], ["Theil", "F.", ""], ["Owhadi", "H.", ""], ["Ortiz", "M.", ""]]}, {"id": "1202.3108", "submitter": "Dohy Hong", "authors": "Dohy Hong", "title": "D-iteration based asynchronous distributed computation", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to explain how the D-iteration can be used for an\nefficient asynchronous distributed computation. We present the main ideas of\nthe method and illustrate them through very simple examples.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 18:07:32 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Hong", "Dohy", ""]]}, {"id": "1202.3173", "submitter": "Olga Holtz", "authors": "Grey Ballard, James Demmel, Olga Holtz, Benjamin Lipshitz, Oded\n  Schwartz", "title": "Communication-Optimal Parallel Algorithm for Strassen's Matrix\n  Multiplication", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC cs.NA math.CO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel matrix multiplication is one of the most studied fundamental\nproblems in distributed and high performance computing. We obtain a new\nparallel algorithm that is based on Strassen's fast matrix multiplication and\nminimizes communication. The algorithm outperforms all known parallel matrix\nmultiplication algorithms, classical and Strassen-based, both asymptotically\nand in practice.\n  A critical bottleneck in parallelizing Strassen's algorithm is the\ncommunication between the processors. Ballard, Demmel, Holtz, and Schwartz\n(SPAA'11) prove lower bounds on these communication costs, using expansion\nproperties of the underlying computation graph. Our algorithm matches these\nlower bounds, and so is communication-optimal. It exhibits perfect strong\nscaling within the maximum possible range.\n  Benchmarking our implementation on a Cray XT4, we obtain speedups over\nclassical and Strassen-based algorithms ranging from 24% to 184% for a fixed\nmatrix dimension n=94080, where the number of nodes ranges from 49 to 7203.\n  Our parallelization approach generalizes to other fast matrix multiplication\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 23:12:23 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Ballard", "Grey", ""], ["Demmel", "James", ""], ["Holtz", "Olga", ""], ["Lipshitz", "Benjamin", ""], ["Schwartz", "Oded", ""]]}, {"id": "1202.3177", "submitter": "Olga Holtz", "authors": "Grey Ballard, James Demmel, Olga Holtz, Benjamin Lipshitz, Oded\n  Schwartz", "title": "Strong Scaling of Matrix Multiplication Algorithms and\n  Memory-Independent Communication Lower Bounds", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC cs.NA math.CO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parallel algorithm has perfect strong scaling if its running time on P\nprocessors is linear in 1/P, including all communication costs.\nDistributed-memory parallel algorithms for matrix multiplication with perfect\nstrong scaling have only recently been found. One is based on classical matrix\nmultiplication (Solomonik and Demmel, 2011), and one is based on Strassen's\nfast matrix multiplication (Ballard, Demmel, Holtz, Lipshitz, and Schwartz,\n2012). Both algorithms scale perfectly, but only up to some number of\nprocessors where the inter-processor communication no longer scales.\n  We obtain a memory-independent communication cost lower bound on classical\nand Strassen-based distributed-memory matrix multiplication algorithms. These\nbounds imply that no classical or Strassen-based parallel matrix multiplication\nalgorithm can strongly scale perfectly beyond the ranges already attained by\nthe two parallel algorithms mentioned above. The memory-independent bounds and\nthe strong scaling bounds generalize to other algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 23:42:19 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Ballard", "Grey", ""], ["Demmel", "James", ""], ["Holtz", "Olga", ""], ["Lipshitz", "Benjamin", ""], ["Schwartz", "Oded", ""]]}, {"id": "1202.3772", "submitter": "Yao-Liang Yu", "authors": "Yao-Liang Yu, Dale Schuurmans", "title": "Rank/Norm Regularization with Closed-Form Solutions: Application to\n  Subspace Clustering", "comments": "11 pages, 1 figure, appeared in UAI 2011. One footnote corrected and\n  appendix added", "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-778-785", "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When data is sampled from an unknown subspace, principal component analysis\n(PCA) provides an effective way to estimate the subspace and hence reduce the\ndimension of the data. At the heart of PCA is the Eckart-Young-Mirsky theorem,\nwhich characterizes the best rank k approximation of a matrix. In this paper,\nwe prove a generalization of the Eckart-Young-Mirsky theorem under all\nunitarily invariant norms. Using this result, we obtain closed-form solutions\nfor a set of rank/norm regularized problems, and derive closed-form solutions\nfor a general class of subspace clustering problems (where data is modelled by\nunions of unknown subspaces). From these results we obtain new theoretical\ninsights and promising experimental results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2012 21:00:59 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Yu", "Yao-Liang", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1202.3856", "submitter": "Kadir Akbudak Mr", "authors": "Kadir Akbudak, Enver Kayaaslan and Cevdet Aykanat", "title": "Technical Report on Hypergraph-Partitioning-Based Models and Methods for\n  Exploiting Cache Locality in Sparse-Matrix Vector Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": "BU-CE-1201", "categories": "cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparse matrix-vector multiplication (SpMxV) is a kernel operation widely\nused in iterative linear solvers. The same sparse matrix is multiplied by a\ndense vector repeatedly in these solvers. Matrices with irregular sparsity\npatterns make it difficult to utilize cache locality effectively in SpMxV\ncomputations. In this work, we investigate single- and multiple-SpMxV\nframeworks for exploiting cache locality in SpMxV computations. For the\nsingle-SpMxV framework, we propose two cache-size-aware top-down\nrow/column-reordering methods based on 1D and 2D sparse matrix partitioning by\nutilizing the column-net and enhancing the row-column-net hypergraph models of\nsparse matrices. The multiple-SpMxV framework depends on splitting a given\nmatrix into a sum of multiple nonzero-disjoint matrices so that the SpMxV\noperation is performed as a sequence of multiple input- and output- dependent\nSpMxV operations. For an effective matrix splitting required in this framework,\nwe propose a cache- size-aware top-down approach based on 2D sparse matrix\npartitioning by utilizing the row-column-net hypergraph model. For this\nframework, we also propose two methods for effective ordering of individual\nSpMxV operations. The primary objective in all of the three methods is to\nmaximize the exploitation of temporal locality. We evaluate the validity of our\nmodels and methods on a wide range of sparse matrices using both cache-miss\nsimulations and actual runs by using OSKI. Experimental results show that\nproposed methods and models outperform state-of-the-art schemes.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 09:28:24 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2012 13:02:08 GMT"}, {"version": "v3", "created": "Mon, 27 Feb 2012 09:31:09 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Akbudak", "Kadir", ""], ["Kayaaslan", "Enver", ""], ["Aykanat", "Cevdet", ""]]}, {"id": "1202.4407", "submitter": "Amaury Pouly", "authors": "Olivier Bournez, Daniel S. Gra\\c{c}a, Amaury Pouly", "title": "On the complexity of solving initial value problems", "comments": "8 pages (two columns per page), submitted to ISSAC'12 conference", "journal-ref": null, "doi": "10.1145/2442829.2442849", "report-no": null, "categories": "cs.NA cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove that computing the solution of an initial-value\nproblem $\\dot{y}=p(y)$ with initial condition $y(t_0)=y_0\\in\\R^d$ at time\n$t_0+T$ with precision $e^{-\\mu}$ where $p$ is a vector of polynomials can be\ndone in time polynomial in the value of $T$, $\\mu$ and $Y=\\sup_{t_0\\leqslant\nu\\leqslant T}\\infnorm{y(u)}$. Contrary to existing results, our algorithm works\nfor any vector of polynomials $p$ over any bounded or unbounded domain and has\na guaranteed complexity and precision. In particular we do not assume $p$ to be\nfixed, nor the solution to lie in a compact domain, nor we assume that $p$ has\na Lipschitz constant.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 18:09:18 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Bournez", "Olivier", ""], ["Gra\u00e7a", "Daniel S.", ""], ["Pouly", "Amaury", ""]]}, {"id": "1202.5414", "submitter": "Marco Reisert", "authors": "Marco Reisert and Henrik Skibbe", "title": "Left-Invariant Diffusion on the Motion Group in terms of the Irreducible\n  Representations of SO(3)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.CV cs.NA math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the formulation of convection/diffusion equations on\nthe 3D motion group SE(3) in terms of the irreducible representations of SO(3).\nTherefore, the left-invariant vector-fields on SE(3) are expressed as linear\noperators, that are differential forms in the translation coordinate and\nalgebraic in the rotation. In the context of 3D image processing this approach\navoids the explicit discretization of SO(3) or $S_2$, respectively. This is\nparticular important for SO(3), where a direct discretization is infeasible due\nto the enormous memory consumption. We show two applications of the framework:\none in the context of diffusion-weighted magnetic resonance imaging and one in\nthe context of object detection.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2012 10:33:06 GMT"}], "update_date": "2012-02-27", "authors_parsed": [["Reisert", "Marco", ""], ["Skibbe", "Henrik", ""]]}, {"id": "1202.5471", "submitter": "Jiasong Wu", "authors": "Jiasong Wu, Xu Zhang, Xiaoqing Wang, Lotfi Senhadji, Huazhong Shu", "title": "L1-norm minimization for quaternion signals", "comments": "4 pages,2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The l1-norm minimization problem plays an important role in the compressed\nsensing (CS) theory. We present in this letter an algorithm for solving the\nproblem of l1-norm minimization for quaternion signals by converting it to\nsecond-order cone programming. An application example of the proposed algorithm\nis also given for practical guidelines of perfect recovery of quaternion\nsignals. The proposed algorithm may find its potential application when CS\ntheory meets the quaternion signal processing.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2012 15:01:37 GMT"}], "update_date": "2012-02-27", "authors_parsed": [["Wu", "Jiasong", ""], ["Zhang", "Xu", ""], ["Wang", "Xiaoqing", ""], ["Senhadji", "Lotfi", ""], ["Shu", "Huazhong", ""]]}, {"id": "1202.5710", "submitter": "Paul Leopardi", "authors": "Markus Hegland and Paul Leopardi (Australian National University)", "title": "Sparse grid quadrature on products of spheres", "comments": "34 pages, 6 figures. Accepted 7 January 2015 for publication in\n  Numerical Algorithms. Revised at page proof stage to (1) update email\n  address; (2) correct the accent on \"Wozniakowski\" on p. 7; (3) update\n  reference 2; (4) correct references 3, 18 and 26", "journal-ref": "Numerical Algorithms, Volume 70, Issue 3, 2015, pp. 485-517", "doi": "10.1007/s11075-015-9958-9", "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine sparse grid quadrature on weighted tensor products (WTP) of\nreproducing kernel Hilbert spaces on products of the unit sphere, in the case\nof worst case quadrature error for rules with arbitrary quadrature weights. We\ndescribe a dimension adaptive quadrature algorithm based on an algorithm of\nHegland (2003), and also formulate a version of Wasilkowski and Wozniakowski's\nWTP algorithm (1999), here called the WW algorithm. We prove that the dimension\nadaptive algorithm is optimal in the sense of Dantzig (1957) and therefore no\ngreater in cost than the WW algorithm. Both algorithms therefore have the\noptimal asymptotic rate of convergence given by Theorem 3 of Wasilkowski and\nWozniakowski (1999). A numerical example shows that, even though the asymptotic\nconvergence rate is optimal, if the dimension weights decay slowly enough, and\nthe dimensionality of the problem is large enough, the initial convergence of\nthe dimension adaptive algorithm can be slow.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2012 01:29:54 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2012 01:23:07 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2013 06:31:46 GMT"}, {"version": "v4", "created": "Tue, 25 Mar 2014 13:01:58 GMT"}, {"version": "v5", "created": "Wed, 23 Apr 2014 02:44:58 GMT"}, {"version": "v6", "created": "Fri, 10 Oct 2014 01:10:54 GMT"}, {"version": "v7", "created": "Thu, 15 Jan 2015 11:57:11 GMT"}, {"version": "v8", "created": "Thu, 22 Jan 2015 12:41:39 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Hegland", "Markus", "", "Australian National University"], ["Leopardi", "Paul", "", "Australian National University"]]}, {"id": "1202.5844", "submitter": "Deyu Meng", "authors": "Deyu Meng and Zongben Xu", "title": "Divide-and-Conquer Method for L1 Norm Matrix Factorization in the\n  Presence of Outliers and Missing Data", "comments": "19 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The low-rank matrix factorization as a L1 norm minimization problem has\nrecently attracted much attention due to its intrinsic robustness to the\npresence of outliers and missing data. In this paper, we propose a new method,\ncalled the divide-and-conquer method, for solving this problem. The main idea\nis to break the original problem into a series of smallest possible\nsub-problems, each involving only unique scalar parameter. Each of these\nsubproblems is proved to be convex and has closed-form solution. By recursively\noptimizing these small problems in an analytical way, efficient algorithm,\nentirely avoiding the time-consuming numerical optimization as an inner loop,\nfor solving the original problem can naturally be constructed. The\ncomputational complexity of the proposed algorithm is approximately linear in\nboth data size and dimensionality, making it possible to handle large-scale L1\nnorm matrix factorization problems. The algorithm is also theoretically proved\nto be convergent. Based on a series of experiment results, it is substantiated\nthat our method always achieves better results than the current\nstate-of-the-art methods on $L1$ matrix factorization calculation in both\ncomputational time and accuracy, especially on large-scale applications such as\nface recognition and structure from motion.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 07:57:04 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 14:37:56 GMT"}, {"version": "v3", "created": "Wed, 25 Apr 2012 11:27:51 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Meng", "Deyu", ""], ["Xu", "Zongben", ""]]}, {"id": "1202.6522", "submitter": "Nathana\\\"el Schaeffer", "authors": "Nathana\\\"el Schaeffer", "title": "Efficient Spherical Harmonic Transforms aimed at pseudo-spectral\n  numerical simulations", "comments": "8 pages", "journal-ref": "Geochemistry, Geophysics, Geosystems, American Geophysical Union\n  (AGU), 2013, 14 (3), pp.751-758", "doi": "10.1002/ggge.20071", "report-no": null, "categories": "physics.comp-ph cs.MS cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report on very efficient algorithms for the spherical\nharmonic transform (SHT). Explicitly vectorized variations of the algorithm\nbased on the Gauss-Legendre quadrature are discussed and implemented in the\nSHTns library which includes scalar and vector transforms. The main\nbreakthrough is to achieve very efficient on-the-fly computations of the\nLegendre associated functions, even for very high resolutions, by taking\nadvantage of the specific properties of the SHT and the advanced capabilities\nof current and future computers. This allows us to simultaneously and\nsignificantly reduce memory usage and computation time of the SHT. We measure\nthe performance and accuracy of our algorithms. Even though the complexity of\nthe algorithms implemented in SHTns are in $O(N^3)$ (where N is the maximum\nharmonic degree of the transform), they perform much better than any third\nparty implementation, including lower complexity algorithms, even for\ntruncations as high as N=1023. SHTns is available at\nhttps://bitbucket.org/nschaeff/shtns as open source software.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 12:05:12 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2012 13:37:52 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2013 13:20:31 GMT"}, {"version": "v4", "created": "Thu, 20 Nov 2014 15:14:32 GMT"}, {"version": "v5", "created": "Wed, 7 Jan 2015 14:40:46 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Schaeffer", "Nathana\u00ebl", ""]]}]