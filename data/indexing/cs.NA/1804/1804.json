[{"id": "1804.00462", "submitter": "Maboud Kaloorazi", "authors": "Maboud F. Kaloorazi, Rodrigo C. de Lamare", "title": "Subspace-Orbit Randomized Decomposition for Low-rank Matrix\n  Approximation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2853137", "report-no": null, "categories": "cs.NA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient, accurate and reliable approximation of a matrix by one of lower\nrank is a fundamental task in numerical linear algebra and signal processing\napplications. In this paper, we introduce a new matrix decomposition approach\ntermed Subspace-Orbit Randomized singular value decomposition (SOR-SVD), which\nmakes use of random sampling techniques to give an approximation to a low-rank\nmatrix. Given a large and dense data matrix of size $m\\times n$ with numerical\nrank $k$, where $k \\ll \\text{min} \\{m,n\\}$, the algorithm requires a few passes\nthrough data, and can be computed in $O(mnk)$ floating-point operations.\nMoreover, the SOR-SVD algorithm can utilize advanced computer architectures,\nand, as a result, it can be optimized for maximum efficiency. The SOR-SVD\nalgorithm is simple, accurate, and provably correct, and outperforms previously\nreported techniques in terms of accuracy and efficiency. Our numerical\nexperiments support these claims.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 11:55:06 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Kaloorazi", "Maboud F.", ""], ["de Lamare", "Rodrigo C.", ""]]}, {"id": "1804.01410", "submitter": "Jens Saak", "authors": "Peter Benner, Matthias Heinkenschloss, Jens Saak, Heiko K. Weichelt", "title": "Efficient Solution of Large-Scale Algebraic Riccati Equations Associated\n  with Index-2 DAEs via the Inexact Low-Rank Newton-ADI Method", "comments": "21 pages, 2 figures, 4 tables", "journal-ref": "Applied Numerical Mathematics Volume 152, June 2020", "doi": "10.1016/j.apnum.2019.11.016", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the algorithm of Benner, Heinkenschloss, Saak, and\nWeichelt: An inexact low-rank Newton-ADI method for large-scale algebraic\nRiccati equations, Applied Numerical Mathematics Vol.~108 (2016), pp.~125--142,\ndoi:10.1016/j.apnum.2016.05.006 to Riccati equations associated with Hessenberg\nindex-2 Differential Algebratic Equation (DAE) systems. Such DAE systems arise,\ne.g., from semi-discretized, linearized (around steady state) Navier-Stokes\nequations. The solution of the associated Riccati equation is important, e.g.,\nto compute feedback laws that stabilize the Navier-Stokes equations. Challenges\nin the numerical solution of the Riccati equation arise from the large-scale of\nthe underlying systems and the algebraic constraint in the DAE system. These\nchallenges are met by a careful extension of the inexact low-rank Newton-ADI\nmethod to the case of DAE systems. A main ingredient in the extension to the\nDAE case is the projection onto the manifold described by the algebraic\nconstraints. In the algorithm, the equations are never explicitly projected,\nbut the projection is only applied as needed. Numerical experience indicates\nthat the algorithmic choices for the control of inexactness and line-search can\nhelp avoid subproblems with matrices that are only marginally stable. The\nperformance of the algorithm is illustrated on a large-scale Riccati equation\nassociated with the stabilization of Navier-Stokes flow around a cylinder.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 13:47:35 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 10:11:08 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Benner", "Peter", ""], ["Heinkenschloss", "Matthias", ""], ["Saak", "Jens", ""], ["Weichelt", "Heiko K.", ""]]}, {"id": "1804.01526", "submitter": "Mario Drumond", "authors": "Mario Drumond, Tao Lin, Martin Jaggi, Babak Falsafi", "title": "Training DNNs with Hybrid Block Floating Point", "comments": "9 pages, 3 figures. Accepted in Neural Information Processing Systems\n  2018 (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of DNNs has given birth to unrelenting computing\nrequirements, forcing datacenter operators to adopt domain-specific\naccelerators to train them. These accelerators typically employ densely packed\nfull precision floating-point arithmetic to maximize performance per area.\nOngoing research efforts seek to further increase that performance density by\nreplacing floating-point with fixed-point arithmetic. However, a significant\nroadblock for these attempts has been fixed point's narrow dynamic range, which\nis insufficient for DNN training convergence. We identify block floating point\n(BFP) as a promising alternative representation since it exhibits wide dynamic\nrange and enables the majority of DNN operations to be performed with\nfixed-point logic. Unfortunately, BFP alone introduces several limitations that\npreclude its direct applicability. In this work, we introduce HBFP, a hybrid\nBFP-FP approach, which performs all dot products in BFP and other operations in\nfloating point. HBFP delivers the best of both worlds: the high accuracy of\nfloating point at the superior hardware density of fixed point. For a wide\nvariety of models, we show that HBFP matches floating point's accuracy while\nenabling hardware implementations that deliver up to 8.5x higher throughput.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 09:40:59 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 21:48:51 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 17:48:03 GMT"}, {"version": "v4", "created": "Sun, 2 Dec 2018 15:11:18 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Drumond", "Mario", ""], ["Lin", "Tao", ""], ["Jaggi", "Martin", ""], ["Falsafi", "Babak", ""]]}, {"id": "1804.01583", "submitter": "Stanley Bak", "authors": "Stanley Bak, Hoang-Dung Tran, and Taylor T. Johnson", "title": "Numerical Verification of Affine Systems with up to a Billion Dimensions", "comments": null, "journal-ref": null, "doi": "10.1145/3302504.3311792", "report-no": null, "categories": "cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affine systems reachability is the basis of many verification methods. With\nfurther computation, methods exist to reason about richer models with inputs,\nnonlinear differential equations, and hybrid dynamics. As such, the scalability\nof affine systems verification is a prerequisite to scalable analysis for more\ncomplex systems. In this paper, we improve the scalability of affine systems\nverification, in terms of the number of dimensions (variables) in the system.\n  The reachable states of affine systems can be written in terms of the matrix\nexponential, and safety checking can be performed at specific time steps with\nlinear programming. Unfortunately, for large systems with many state variables,\nthis direct approach requires an intractable amount of memory while using an\nintractable amount of computation time. We overcome these challenges by\ncombining several methods that leverage common problem structure. Memory is\nreduced by exploiting initial states that are not full-dimensional and safety\nproperties (outputs) over a few linear projections of the state variables.\nComputation time is saved by using numerical simulations to compute only\nprojections of the matrix exponential relevant for the verification problem.\nSince large systems often have sparse dynamics, we use Krylov-subspace\nsimulation approaches based on the Arnoldi or Lanczos iterations. Our method\nproduces accurate counter-examples when properties are violated and, in the\nextreme case with sufficient problem structure, can analyze a system with one\nbillion real-valued state variables.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 19:41:52 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 13:14:00 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 22:16:42 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Bak", "Stanley", ""], ["Tran", "Hoang-Dung", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "1804.01609", "submitter": "Varun Shankar", "authors": "Varun Shankar and Grady Wright", "title": "Mesh-free Semi-Lagrangian Methods for Transport on a Sphere Using Radial\n  Basis Functions", "comments": "26 pages, 14 figures, 2 tables", "journal-ref": null, "doi": "10.1016/j.jcp.2018.04.007", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present three new semi-Lagrangian methods based on radial basis function\n(RBF) interpolation for numerically simulating transport on a sphere. The\nmethods are mesh-free and are formulated entirely in Cartesian coordinates,\nthus avoiding any irregular clustering of nodes at artificial boundaries on the\nsphere and naturally bypassing any apparent artificial singularities associated\nwith surface-based coordinate systems. For problems involving tracer transport\nin a given velocity field, the semi-Lagrangian framework allows these new\nmethods to avoid the use of any stabilization terms (such as hyperviscosity)\nduring time-integration, thus reducing the number of parameters that have to be\ntuned. The three new methods are based on interpolation using 1) global RBFs,\n2) local RBF stencils, and 3) RBF partition of unity. For the latter two of\nthese methods, we find that it is crucial to include some low degree spherical\nharmonics in the interpolants. Standard test cases consisting of solid body\nrotation and deformational flow are used to compare and contrast the methods in\nterms of their accuracy, efficiency, conservation properties, and\ndissipation/dispersion errors. For global RBFs, spectral spatial convergence is\nobserved for smooth solutions on quasi-uniform nodes, while high-order accuracy\nis observed for the local RBF stencil and partition of unity approaches.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 21:19:06 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Shankar", "Varun", ""], ["Wright", "Grady", ""]]}, {"id": "1804.01679", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson (LFANT), Iaroslav Blagouchine (UTLN SeaTech)", "title": "Computing Stieltjes constants using complex integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized Stieltjes constants $\\gamma\\_n(v)$ are, up to a simple\nscaling factor, the Laurent series coefficients of the Hurwitz zeta function\n$\\zeta(s,v)$ about its unique pole $s = 1$. In this work, we devise an\nefficient algorithm to compute these constants to arbitrary precision with\nrigorous error bounds, for the first time achieving this with low complexity\nwith respect to the order~$n$. Our computations are based on an integral\nrepresentation with a hyperbolic kernel that decays exponentially fast. The\nalgorithm consists of locating an approximate steepest descent contour and then\nevaluating the integral numerically in ball arithmetic using the Petras\nalgorithm with a Taylor expansion for bounds near the saddle point. An\nimplementation is provided in the Arb library. We can, for example, compute\n$\\gamma\\_n(1)$ to 1000 digits in a minute for any $n$ up to $n=10^{100}$. We\nalso provide other interesting integral representations for $\\gamma\\_n(v)$,\n$\\zeta(s)$, $\\zeta(s,v)$, some polygamma functions and the Lerch transcendent.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 06:21:14 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 06:30:20 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2018 09:51:21 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Johansson", "Fredrik", "", "LFANT"], ["Blagouchine", "Iaroslav", "", "UTLN SeaTech"]]}, {"id": "1804.01765", "submitter": "Adrian Ebert", "authors": "Adrian Ebert, Peter Kritzer", "title": "Constructing lattice points for numerical integration by a reduced fast\n  successive coordinate search algorithm", "comments": "33 pages, 2 figures", "journal-ref": null, "doi": "10.1016/j.cam.2018.10.046", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study an efficient algorithm for constructing node sets of\nhigh-quality quasi-Monte Carlo integration rules for weighted Korobov, Walsh,\nand Sobolev spaces. The algorithm presented is a reduced fast successive\ncoordinate search (SCS) algorithm, which is adapted to situations where the\nweights in the function space show a sufficiently fast decay. The new SCS\nalgorithm is designed to work for the construction of lattice points, and, in a\nmodified version, for polynomial lattice points, and the corresponding\nintegration rules can be used to treat functions in different kinds of function\nspaces. We show that the integration rules constructed by our algorithms\nsatisfy error bounds of optimal convergence order. Furthermore, we give details\non efficient implementation such that we obtain a considerable speed-up of\npreviously known SCS algorithms. This improvement is illustrated by numerical\nresults. The speed-up obtained by our results may be of particular interest in\nthe context of QMC for PDEs with random coefficients, where both the dimension\nand the required numberof points are usually very large. Furthermore, our main\ntheorems yield previously unknown generalizations of earlier results.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 10:28:02 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 13:37:07 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 14:56:57 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Ebert", "Adrian", ""], ["Kritzer", "Peter", ""]]}, {"id": "1804.01932", "submitter": "Justin Kinney", "authors": "Wei-Chia Chen, Ammar Tareen, Justin B. Kinney", "title": "Density estimation on small datasets", "comments": "Includes main text (5 pages, 3 figures) and Supplemental Information\n  (10 pages, 4 figures). Same as version 3 but with Feynman diagrams properly\n  rendered", "journal-ref": "Phys. Rev. Lett. 121, 160605 (2018)", "doi": "10.1103/PhysRevLett.121.160605", "report-no": null, "categories": "physics.data-an cs.NA physics.comp-ph q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How might a smooth probability distribution be estimated, with accurately\nquantified uncertainty, from a limited amount of sampled data? Here we describe\na field-theoretic approach that addresses this problem remarkably well in one\ndimension, providing an exact nonparametric Bayesian posterior without relying\non tunable parameters or large-data approximations. Strong non-Gaussian\nconstraints, which require a non-perturbative treatment, are found to play a\nmajor role in reducing distribution uncertainty. A software implementation of\nthis method is provided.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 16:12:37 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 13:30:49 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2018 00:57:03 GMT"}, {"version": "v4", "created": "Thu, 30 Aug 2018 01:04:09 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Chen", "Wei-Chia", ""], ["Tareen", "Ammar", ""], ["Kinney", "Justin B.", ""]]}, {"id": "1804.01983", "submitter": "Longhao Yuan", "authors": "Longhao Yuan, Qibin Zhao, Lihua Gui and Jianting Cao", "title": "High-dimension Tensor Completion via Gradient-based Optimization Under\n  Tensor-train Format", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor train (TT) decomposition has drawn people's attention due to its\npowerful representation ability and performance stability in high-order\ntensors. In this paper, we propose a novel approach to recover the missing\nentries of incomplete data represented by higher-order tensors. We attempt to\nfind the low-rank TT decomposition of the incomplete data which captures the\nlatent features of the whole data and then reconstruct the missing entries. By\napplying gradient descent algorithms, tensor completion problem is efficiently\nsolved by optimization models. We propose two TT-based algorithms: Tensor Train\nWeighted Optimization (TT-WOPT) and Tensor Train Stochastic Gradient Descent\n(TT-SGD) to optimize TT decomposition factors. In addition, a method named\nVisual Data Tensorization (VDT) is proposed to transform visual data into\nhigher-order tensors, resulting in the performance improvement of our\nalgorithms. The experiments in synthetic data and visual data show high\nefficiency and performance of our algorithms compared to the state-of-the-art\ncompletion algorithms, especially in high-order, high missing rate, and\nlarge-scale tensor completion situations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 02:06:28 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 09:03:23 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 03:21:55 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Yuan", "Longhao", ""], ["Zhao", "Qibin", ""], ["Gui", "Lihua", ""], ["Cao", "Jianting", ""]]}, {"id": "1804.02014", "submitter": "Federico Pichi", "authors": "Federico Pichi and Gianluigi Rozza", "title": "Reduced basis approaches for parametrized bifurcation problems held by\n  non-linear Von K\\'arm\\'an equations", "comments": "30 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on the detection of the buckling phenomena and bifurcation\nanalysis of the parametric Von K\\'arm\\'an plate equations based on reduced\norder methods and spectral analysis. The computational complexity - due to the\nfourth order derivative terms, the non-linearity and the parameter dependence -\nprovides an interesting benchmark to test the importance of the computational\nreduction strategies, during the construction of the bifurcation diagram by\nvarying the parameter(s). To this end, together the state equations, we carry\nout also an analysis of the linearized eigenvalue problem, that allows us to\nbetter understand the physical behaviour near the bifurcation points, where we\nlose the uniqueness of solution.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 18:25:27 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 10:27:20 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Pichi", "Federico", ""], ["Rozza", "Gianluigi", ""]]}, {"id": "1804.02095", "submitter": "Dong An", "authors": "Dong An, Lin Lin", "title": "Quantum Dynamics with the Parallel Transport Gauge", "comments": "SIAM Multiscale Model. Simul. accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of a closed quantum system is often studied with the direct\nevolution of the Schrodinger equation. In this paper, we propose that the gauge\nchoice (i.e. degrees of freedom irrelevant to physical observables) of the\nSchrodinger equation can be generally non-optimal for numerical simulation.\nThis can limit, and in some cases severely limit the time step size. We find\nthat the optimal gauge choice is given by a parallel transport formulation.\nThis parallel transport dynamics can be simply interpreted as the dynamics\ndriven by the residual vectors, analogous to those defined in eigenvalue\nproblems in the time-independent setup. The parallel transport dynamics can be\nderived from a Hamiltonian structure, thus suitable to be solved using a\nsymplectic and implicit time discretization scheme, such as the implicit\nmidpoint rule, which allows the usage of a large time step and ensures the long\ntime numerical stability. We analyze the parallel transport dynamics in the\ncontext of the singularly perturbed linear Schrodinger equation, and\ndemonstrate its superior performance in the near adiabatic regime. We\ndemonstrate the effectiveness of our method using numerical results for linear\nand nonlinear Schrodinger equations, as well as the time-dependent density\nfunctional theory (TDDFT) calculations for electrons in a benzene molecule\ndriven by an ultrashort laser pulse.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 00:53:59 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 06:47:28 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["An", "Dong", ""], ["Lin", "Lin", ""]]}, {"id": "1804.02307", "submitter": "Ganesh Sundaramoorthi", "authors": "Ganesh Sundaramoorthi and Anthony Yezzi", "title": "Accelerated Optimization in the PDE Framework: Formulations for the\n  Manifold of Diffeomorphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimization of cost functionals on the\ninfinite-dimensional manifold of diffeomorphisms. We present a new class of\noptimization methods, valid for any optimization problem setup on the space of\ndiffeomorphisms by generalizing Nesterov accelerated optimization to the\nmanifold of diffeomorphisms. While our framework is general for infinite\ndimensional manifolds, we specifically treat the case of diffeomorphisms,\nmotivated by optical flow problems in computer vision. This is accomplished by\nbuilding on a recent variational approach to a general class of accelerated\noptimization methods by Wibisono, Wilson and Jordan, which applies in finite\ndimensions. We generalize that approach to infinite dimensional manifolds. We\nderive the surprisingly simple continuum evolution equations, which are partial\ndifferential equations, for accelerated gradient descent, and relate it to\nsimple mechanical principles from fluid mechanics. Our approach has natural\nconnections to the optimal mass transport problem. This is because one can\nthink of our approach as an evolution of an infinite number of particles\nendowed with mass (represented with a mass density) that moves in an energy\nlandscape. The mass evolves with the optimization variable, and endows the\nparticles with dynamics. This is different than the finite dimensional case\nwhere only a single particle moves and hence the dynamics does not depend on\nthe mass. We derive the theory, compute the PDEs for accelerated optimization,\nand illustrate the behavior of these new accelerated optimization schemes.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 19:58:03 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 21:38:57 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Sundaramoorthi", "Ganesh", ""], ["Yezzi", "Anthony", ""]]}, {"id": "1804.02338", "submitter": "Nathan Sime", "authors": "Paul Houston and Nathan Sime", "title": "Automatic symbolic computation for discontinuous Galerkin finite element\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of discontinuous Galerkin finite element methods (DGFEMs)\nrepresents a very challenging computational task, particularly for systems of\ncoupled nonlinear PDEs, including multiphysics problems, whose parameters may\nconsist of power series or functionals of the solution variables. Thereby, the\nexploitation of symbolic algebra to express a given DGFEM approximation of a\nPDE problem within a high level language, whose syntax closely resembles the\nmathematical definition, is an invaluable tool. Indeed, this then facilitates\nthe automatic assembly of the resulting system of (nonlinear) equations, as\nwell as the computation of Fr\\'echet derivative(s) of the DGFEM scheme, needed,\nfor example, within a Newton-type solver. However, even exploiting symbolic\nalgebra, the discretisation of coupled systems of PDEs can still be extremely\nverbose and hard to debug. Thereby, in this article we develop a further layer\nof abstraction by designing a class structure for the automatic computation of\nDGFEM formulations. This work has been implemented within the FEniCS package,\nbased on exploiting the Unified Form Language. Numerical examples are presented\nwhich highlight the simplicity of implementation of DGFEMs for the numerical\napproximation of a range of PDE problems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 16:09:06 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Houston", "Paul", ""], ["Sime", "Nathan", ""]]}, {"id": "1804.02718", "submitter": "Yanzhi Zhang", "authors": "Siwei Duo and Yanzhi Zhang", "title": "Accurate numerical methods for two and three dimensional integral\n  fractional Laplacian with applications", "comments": "24 pages, 6 figures, and 6 tables", "journal-ref": "Computer Methods in Applied Mechanics and Engineering, 355 (2019),\n  pp. 639-662", "doi": "10.1016/j.cma.2019.06.016", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose accurate and efficient finite difference methods to\ndiscretize the two- and three-dimensional fractional Laplacian\n$(-\\Delta)^{\\frac{\\alpha}{2}}$ ($0 < \\alpha < 2$) in hypersingular integral\nform. The proposed finite difference methods provide a fractional analogue of\nthe central difference schemes to the fractional Laplacian, and as $\\alpha \\to\n2^-$, they collapse to the central difference schemes of the classical Laplace\noperator $-\\Delta$. We prove that our methods are consistent if $u \\in\nC^{\\lfloor\\alpha\\rfloor, \\alpha-\\lfloor\\alpha\\rfloor+\\epsilon}({\\mathbb R}^d)$,\nand the local truncation error is ${\\mathcal O}(h^\\epsilon)$, with $\\epsilon >\n0$ a small constant and $\\lfloor \\cdot \\rfloor$ denoting the floor function. If\n$u \\in C^{2+\\lfloor\\alpha\\rfloor,\n\\alpha-\\lfloor\\alpha\\rfloor+\\epsilon}({\\mathbb R}^d)$, they can achieve the\nsecond order of accuracy for any $\\alpha \\in (0, 2)$. These results hold for\nany dimension $d \\ge 1$ and thus improve the existing error estimates for the\nfinite difference method of the one-dimensional fractional Laplacian. Extensive\nnumerical experiments are provided and confirm our analytical results. We then\napply our method to solve the fractional Poisson problems and the fractional\nAllen-Cahn equations. Numerical simulations suggest that to achieve the second\norder of accuracy, the solution of the fractional Poisson problem should {\\it\nat most} satisfy $u \\in C^{1,1}({\\mathbb R}^d)$. One merit of our methods is\nthat they yield a multilevel Toeplitz stiffness matrix, an appealing property\nfor the development of fast algorithms via the fast Fourier transform (FFT).\nOur studies of the two- and three-dimensional fractional Allen-Cahn equations\ndemonstrate the efficiency of our methods in solving the high-dimensional\nfractional problems.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 17:08:25 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 02:39:32 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Duo", "Siwei", ""], ["Zhang", "Yanzhi", ""]]}, {"id": "1804.02839", "submitter": "Kateryna Melnykova", "authors": "Kateryna Melnykova and Ozgur Yilmaz", "title": "Memoryless scalar quantization for random frames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memoryless scalar quantization (MSQ) is a common technique to quantize frame\ncoefficients of signals (which are used as a model for generalized linear\nsamples), making them compatible with our digital technology. The process of\nquantization is generally not invertible, and thus one can only recover an\napproximation to the original signal from its quantized coefficients. The\nnon-linear nature of quantization makes the analysis of the corresponding\napproximation error challenging, often resulting in the use of a simplifying\nassumption, called the \"white noise hypothesis\" (WNH) that simplifies this\nanalysis. However, the WNH is known to be not rigorous and, at least in certain\ncases, not valid.\n  Given a fixed, deterministic signal, we assume that we use a random frame,\nwhose analysis matrix has independent isotropic sub-Gaussian rows, to collect\nthe measurements, which are consecutively quantized via MSQ. For this setting,\nthe numerically observed decay rate seems to agree with the prediction by the\nWNH. We rigorously establish sharp non-asymptotic error bounds without using\nthe WNH that explains the observed decay rate. Furthermore, we show that the\nreconstruction error does not necessarily diminish as redundancy increases. We\nalso extend this approach to the compressed sensing setting, obtaining rigorous\nerror bounds that agree with empirical observations, again, without resorting\nto the WNH.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 06:37:12 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 22:11:00 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Melnykova", "Kateryna", ""], ["Yilmaz", "Ozgur", ""]]}, {"id": "1804.02962", "submitter": "Siegfried Cools", "authors": "Siegfried Cools", "title": "Numerical analysis of the maximal attainable accuracy in communication\n  hiding pipelined Conjugate Gradient methods", "comments": "28 pages, 7 figures, 1 table, 4 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Krylov subspace methods are widely known as efficient algebraic methods for\nsolving large scale linear systems. However, on massively parallel hardware the\nperformance of these methods is typically limited by communication latency\nrather than floating point performance. With HPC hardware advancing towards the\nexascale regime the gap between computation and communication keeps steadily\nincreasing, imposing the need for scalable alternatives to traditional Krylov\nsubspace methods. One such approach are the so-called pipelined Krylov subspace\nmethods, which reduce the number of global synchronization points and overlap\nglobal communication latency with local arithmetic operations, thus hiding the\nglobal reduction phases behind useful computations. To obtain this overlap the\ntraditional Krylov subspace algorithm is reformulated by introducing a number\nof auxiliary vector quantities, which are computed using additional recurrence\nrelations. Although pipelined Krylov subspace methods are equivalent to\ntraditional Krylov subspace methods in exact arithmetic, local rounding errors\ninduced by the multi-term recurrence relations in finite precision may in\npractice affect convergence significantly. This numerical stability study aims\nto characterize the effect of local rounding errors on attainable accuracy in\nvarious pipelined versions of the popular Conjugate Gradient method.\nExpressions for the gaps between the true and recursively computed variables\nthat are used to update the search directions in the different CG variants are\nderived. Furthermore, it is shown how these results can be used to analyze and\ncorrect the effect of local rounding error propagation on the maximal\nattainable accuracy of pipelined CG methods. The analysis in this work is\nsupplemented by numerical experiments that demonstrate the numerical behavior\nof the pipelined CG methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 13:15:48 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 13:38:24 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Cools", "Siegfried", ""]]}, {"id": "1804.03171", "submitter": "Petr N. Vabishchevich", "authors": "Petr N. Vabishchevich", "title": "Computational identification of the lowest space-wise dependent\n  coefficient of a parabolic equation", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work, we consider a nonlinear inverse problem of identifying\nthe lowest coefficient of a parabolic equation. The desired coefficient depends\non spatial variables only. Additional information about the solution is given\nat the final time moment, i.e., we consider the final redefinition. An\niterative process is used to evaluate the lowest coefficient, where at each\niteration we solve the standard initial-boundary value problem for the\nparabolic equation. On the basis of the maximum principle for the solution of\nthe differential problem, the monotonicity of the iterative process is\nestablished along with the fact that the coefficient approaches from above. The\npossibilities of the proposed computational algorithm are illustrated by\nnumerical examples for a model two-dimensional problem.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 18:18:45 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Vabishchevich", "Petr N.", ""]]}, {"id": "1804.03245", "submitter": "Teseo Schneider", "authors": "Teseo Schneider, Jeremie Dumas, Xifeng Gao, Mario Botsch, Daniele\n  Panozzo, Denis Zorin", "title": "Poly-Spline Finite Element Method", "comments": "FORTHCOMING in TOG", "journal-ref": null, "doi": "10.1145/3313797", "report-no": null, "categories": "cs.NA cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an integrated meshing and finite element method pipeline\nenabling black-box solution of partial differential equations in the volume\nenclosed by a boundary representation. We construct a hybrid\nhexahedral-dominant mesh, which contains a small number of star-shaped\npolyhedra, and build a set of high-order basis on its elements, combining\ntriquadratic B-splines, triquadratic hexahedra (27 degrees of freedom), and\nharmonic elements. We demonstrate that our approach converges cubically under\nrefinement, while requiring around 50% of the degrees of freedom than a\nsimilarly dense hexahedral mesh composed of triquadratic hexahedra. We validate\nour approach solving Poisson's equation on a large collection of models, which\nare automatically processed by our algorithm, only requiring the user to\nprovide boundary conditions on their surface.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 21:27:01 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 20:14:03 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Schneider", "Teseo", ""], ["Dumas", "Jeremie", ""], ["Gao", "Xifeng", ""], ["Botsch", "Mario", ""], ["Panozzo", "Daniele", ""], ["Zorin", "Denis", ""]]}, {"id": "1804.03613", "submitter": "Moritz August", "authors": "Moritz August and Mari Carmen Banuls", "title": "Efficient approximation for global functions of matrix product operators", "comments": "8 pages, comments very welcome", "journal-ref": "Phys. Rev. B 98, 075128 (2018)", "doi": "10.1103/PhysRevB.98.075128", "report-no": null, "categories": "quant-ph cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on a previously introduced block Lanczos method, we demonstrate how\nto approximate any operator function of the form Trf (A) when the argument A is\ngiven as a Hermitian matrix product operator. This gives access to quantities\nthat, depending on the full spectrum, are difficult to access for standard\ntensor network techniques, such as the von Neumann entropy and the trace norm\nof an MPO. We present a modified, more efficient strategy for computing thermal\nproperties of short- or long-range Hamiltonians, and illustrate the performance\nof the method with numerical results for the thermal equilibrium states of the\nLipkin-Meshkov-Glick and Ising Hamiltonians.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 16:11:20 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 11:12:43 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["August", "Moritz", ""], ["Banuls", "Mari Carmen", ""]]}, {"id": "1804.03881", "submitter": "Luca Fenzi", "authors": "Luca Fenzi and Wim Michiels", "title": "Polynomial (chaos) approximation of maximum eigenvalue functions:\n  efficiency and limitations", "comments": "This is a pre-print of an article published in Numerical Algorithms.\n  The final authenticated version is available online at:\n  https://doi.org/10.1007/s11075-018-00648-9", "journal-ref": "Numerical Algorithms 82, pages1143-1169 (2019)", "doi": "10.1007/s11075-018-00648-9", "report-no": null, "categories": "math.NA cs.NA math.DS math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with polynomial approximations of the spectral\nabscissa function (the supremum of the real parts of the eigenvalues) of a\nparameterized eigenvalue problem, which are closely related to polynomial chaos\napproximations if the parameters correspond to realizations of random\nvariables.\n  Unlike in existing works, we highlight the major role of the smoothness\nproperties of the spectral abscissa function. Even if the matrices of the\neigenvalue problem are analytic functions of the parameters, the spectral\nabscissa function may not be everywhere differentiable, even not everywhere\nLipschitz continuous, which is related to multiple rightmost eigenvalues or\nrightmost eigenvalues with multiplicity higher than one.\n  The presented analysis demonstrates that the smoothness properties heavily\naffect the approximation errors of the Galerkin and collocation-based\npolynomial approximations, and the numerical errors of the evaluation of\ncoefficients with integration methods. A documentation of the experiments,\nconducted on the benchmark problems through the software Chebfun, is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 09:13:35 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 10:27:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Fenzi", "Luca", ""], ["Michiels", "Wim", ""]]}, {"id": "1804.04215", "submitter": "Lingjiong Zhu", "authors": "Zhenyu Cui, Michael C. Fu, Yijie Peng, Lingjiong Zhu", "title": "Optimal Unbiased Estimation for Expected Cumulative Cost", "comments": "35 pages, 5 figures", "journal-ref": "European Journal of Operational Research 2020, Volume 286, Issue\n  2, 604-618", "doi": null, "report-no": null, "categories": "math.NA cs.NA math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimating an expected infinite-horizon cumulative discounted\ncost/reward contingent on an underlying stochastic process by Monte Carlo\nsimulation. An unbiased estimator based on truncating the cumulative cost at a\nrandom horizon is proposed. Explicit forms for the optimal distributions of the\nrandom horizon are given, and explicit expressions for the optimal random\ntruncation level are obtained, leading to a full analysis of the bias-variance\ntradeoff when comparing this new class of randomized estimators with\ntraditional fixed truncation estimators. Moreover, we characterize when the\noptimal randomized estimator is preferred over a fixed truncation estimator by\nconsidering the tradeoff between bias and variance. This comparison provides\nguidance on when to choose randomized estimators over fixed truncation\nestimators in practice. Numerical experiments substantiate the theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:45:24 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:14:33 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cui", "Zhenyu", ""], ["Fu", "Michael C.", ""], ["Peng", "Yijie", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "1804.04385", "submitter": "Jose A. Carrillo", "authors": "Jos\\'e A. Carrillo, Francis Filbet, Markus Schmidtchen", "title": "Convergence of a Finite Volume Scheme for a System of Interacting\n  Species with Cross-Diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present the convergence of a positivity preserving\nsemi-discrete finite volume scheme for a coupled system of two non-local\npartial differential equations with cross-diffusion. The key to proving the\nconvergence result is to establish positivity in order to obtain a discrete\nenergy estimate to obtain compactness. We numerically observe the convergence\nto reference solutions with a first order accuracy in space. Moreover we\nrecover segregated stationary states in spite of the regularising effect of the\nself-diffusion. However, if the self-diffusion or the cross-diffusion is strong\nenough, mixing occurs while both densities remain continuous.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 09:17:28 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 17:54:12 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 08:40:31 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Carrillo", "Jos\u00e9 A.", ""], ["Filbet", "Francis", ""], ["Schmidtchen", "Markus", ""]]}, {"id": "1804.04712", "submitter": "Lucia Carichino", "authors": "Lucia Carichino and Sarah D. Olson", "title": "Emergent three-dimensional sperm motility: Coupling calcium dynamics and\n  preferred curvature in a Kirchhoff rod model", "comments": null, "journal-ref": "Mathematical Medicine and Biology: A Journal of the IMA, dqy015,\n  16 October 2018", "doi": "10.1093/imammb/dqy015", "report-no": null, "categories": "math.NA cs.NA q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Changes in calcium concentration along the sperm flagellum regulate sperm\nmotility and hyperactivation, characterized by an increased flagellar bend\namplitude and beat asymmetry, enabling the sperm to reach and penetrate the\novum (egg). The signaling pathways by which calcium increases within the\nflagellum are well established. However, the exact mechanisms of how calcium\nregulates flagellar bending are still under investigation. We extend our\nprevious model of planar flagellar bending by developing a fluid-structure\ninteraction model that couples the three-dimensional motion of the flagellum in\na viscous, Newtonian fluid with the evolving calcium concentration. The\nflagellum is modeled as a Kirchhoff rod: an elastic rod with preferred\ncurvature and twist. The calcium dynamics are represented as a one-dimensional\nreaction-diffusion model on a moving domain, the centerline of the flagellum.\nThe two models are coupled assuming that the preferred curvature and twist of\nthe sperm flagellum depend on the local calcium concentration. To investigate\nthe effect of calcium on sperm motility, we compare model results of flagellar\nbend amplitude and swimming speed for three cases: planar, helical (spiral with\nequal amplitude in both directions), and quasi-planar (spiral with small\namplitude in one direction). We observe that for the same parameters, the\nplanar swimmer is faster and a turning motion is more clearly observed when\ncalcium coupling is accounted for in the model. In the case of flagellar\nbending coupled to the calcium concentration, we observe emergent trajectories\nthat can be characterized as a hypotrochoid for both quasi-planar and helical\nbending.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 20:11:36 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 16:10:15 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Carichino", "Lucia", ""], ["Olson", "Sarah D.", ""]]}, {"id": "1804.04713", "submitter": "Vishal Vaibhav", "authors": "Vishal Vaibhav", "title": "New method of bandlimited extrapolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with numerical solution of the Fredholm integral equation\nassociated with the classical problem of extrapolating bandlimited functions\nknown on $(-1,1)$ to the entire real line. The approach presented can be\ncharacterized as the degenerate kernel method using the spherical Bessel\nfunctions as basis functions where the Tikhonov regularization is applied at\nthe discrete level in order to deal with the ill-posedness of the problem.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 20:19:11 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 07:29:11 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Vaibhav", "Vishal", ""]]}, {"id": "1804.04718", "submitter": "Ruslan Feshchenko", "authors": "R.M. Feshchenko, I.A. Artyukov, and A.V. Vinogradov", "title": "On inverse problem with phase retrieval for an inclined line in the\n  parabolic approximation", "comments": "5 figures, to be submitted to JOSA A", "journal-ref": "Journal of Modern Optics, 68:9, 471-482 (2021)", "doi": "10.1080/09500340.2021.1915399", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse problem of amplitude reconstruction on an inclined line based on\nthe values of amplitude or its module as recorded on semi-infinite line\northogonal to the beam propagation direction is considered within the framework\nof 2D parabolic equation. It is demonstrated that this inverse problem, in case\nwhen the complex image plane amplitude is known, can be reduced to a singular\nCauchy type integral equation. The existence of its solutions requires that\ncertain conditions be met but if a solution exists it is necessary unique. The\nobtained integral equation is then approximated piece-wisely and the resulting\nlinear algebraic system is solved numerically while applying necessary\nregularization procedures to enhance the stability of its solutions. Finally,\nan iterative method of phase retrieval is developed and a set of numerical\nexperiments is performed.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 07:33:55 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 20:33:23 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Feshchenko", "R. M.", ""], ["Artyukov", "I. A.", ""], ["Vinogradov", "A. V.", ""]]}, {"id": "1804.04847", "submitter": "Julien Alexandre Dit Sandretto", "authors": "Julien Alexandre dit Sandretto", "title": "Runge-Kutta Theory and Constraint Programming", "comments": "This is a revised version of \"Runge-Kutta Theory and Constraint\n  Programming\", Reliable Computing vol. 25, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist many Runge-Kutta methods (explicit or implicit), more or less\nadapted to specific problems. Some of them have interesting properties, such as\nstability for stiff problems or symplectic capability for problems with energy\nconservation. Defining a new method suitable to a given problem has become a\nchallenge. The size, the complexity and the order do not stop growing. This\ninformal challenge to implement the best method is interesting but an important\nunsolved problem persists. Indeed, the coefficients of Runge-Kutta methods are\nharder and harder to compute, and the result is often expressed in\nfloating-point numbers, which may lead to erroneous integration schemes. Here,\nwe propose to use interval analysis tools to compute Runge-Kutta coefficients.\nIn particular, we use a solver based on guaranteed constraint programming.\nMoreover, with a global optimization process and a well chosen cost function,\nwe propose a way to define some novel optimal Runge-Kutta methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 09:12:34 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Sandretto", "Julien Alexandre dit", ""]]}, {"id": "1804.04883", "submitter": "Roberto Garrappa", "authors": "Roberto Garrappa and Marina Popolizio", "title": "Computing the matrix Mittag-Leffler function with applications to\n  fractional calculus", "comments": null, "journal-ref": "Journal of Scientific Computing, Volume 77, Issue 1, pp 129-153\n  (2018)", "doi": "10.1007/s10915-018-0699-5", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of the Mittag-Leffler (ML) function with matrix arguments,\nand some applications in fractional calculus, are discussed. In general the\nevaluation of a scalar function in matrix arguments may require the computation\nof derivatives of possible high order depending on the matrix spectrum.\nRegarding the ML function, the numerical computation of its derivatives of\narbitrary order is a completely unexplored topic; in this paper we address this\nissue and three different methods are tailored and investigated. The methods\nare combined together with an original derivatives balancing technique in order\nto devise an algorithm capable of providing high accuracy. The conditioning of\nthe evaluation of matrix ML functions is also studied. The numerical\nexperiments presented in the paper show that the proposed algorithm provides\nhigh accuracy, very often close to the machine precision.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 10:53:42 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 17:52:41 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Garrappa", "Roberto", ""], ["Popolizio", "Marina", ""]]}, {"id": "1804.05112", "submitter": "Qiaoling Zhang", "authors": "Qiaoling Zhang, Malcolm Sabin, and Fehmi Cirak", "title": "Subdivision surfaces with isogeometric analysis adapted refinement\n  weights", "comments": "12 pages, 14 figures", "journal-ref": null, "doi": "10.1016/j.cad.2018.04.020", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subdivision surfaces provide an elegant isogeometric analysis framework for\ngeometric design and analysis of partial differential equations defined on\nsurfaces. They are already a standard in high-end computer animation and\ngraphics and are becoming available in a number of geometric modelling systems\nfor engineering design. The subdivision refinement rules are usually adapted\nfrom knot insertion rules for splines. The quadrilateral Catmull-Clark scheme\nconsidered in this work is equivalent to cubic B-splines away from\nextraordinary, or irregular, vertices with other than four adjacent elements.\nAround extraordinary vertices the surface consists of a nested sequence of\nsmooth spline patches which join $C^1$ continuously at the point itself. As\nknown from geometric design literature, the subdivision weights can be\noptimised so that the surface quality is improved by minimising\nshort-wavelength surface oscillations around extraordinary vertices. We use the\nrelated techniques to determine weights that minimise finite element\ndiscretisation errors as measured in the thin-shell energy norm. The\noptimisation problem is formulated over a characteristic domain and the errors\nin approximating cup- and saddle-like quadratic shapes obtained from\neigenanalysis of the subdivision matrix are minimised. In finite element\nanalysis the optimised subdivision weights for either cup- or saddle-like\nshapes are chosen depending on the shape of the solution field around an\nextraordinary vertex. As our computations confirm, the optimised subdivision\nweights yield a reduction of $50\\%$ and more in discretisation errors in the\nenergy and $L_2$ norms. Although, as to be expected, the convergence rates are\nthe same as for the classical Catmull-Clark weights, the convergence constants\nare improved.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 20:43:04 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 19:14:49 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Zhang", "Qiaoling", ""], ["Sabin", "Malcolm", ""], ["Cirak", "Fehmi", ""]]}, {"id": "1804.05114", "submitter": "Xiaocheng Shang", "authors": "Xiaocheng Shang and Hans Christian \\\"Ottinger", "title": "Structure-preserving integrators for dissipative systems based on\n  reversible-irreversible splitting", "comments": null, "journal-ref": "Proceedings of the Royal Society A: Mathematical, Physical and\n  Engineering Sciences, 476, 20190446, (2020)", "doi": "10.1098/rspa.2019.0446", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the optimal design of numerical integrators for dissipative systems,\nfor which there exists an underlying thermodynamic structure known as GENERIC\n(general equation for the nonequilibrium reversible-irreversible coupling). We\npresent a frame-work to construct structure-preserving integrators by splitting\nthe system into reversible and irreversible dynamics. The reversible part,\nwhich is often degenerate and reduces to a Hamiltonian form on its symplectic\nleaves, is solved by using a symplectic method (e.g., Verlet) with degenerate\nvariables being left unchanged, for which an associated modified Hamiltonian\n(and subsequently a modified energy) in the form of a series expansion can be\nobtained by using backward error analysis. The modified energy is then used to\nconstruct a modified friction matrix associated with the irreversible part in\nsuch a way that a modified degeneracy condition is satisfied. The modified\nirreversible dynamics can be further solved by an explicit midpoint method if\nnot exactly solvable. Our findings are verified by various numerical\nexperiments, demonstrating the superiority of structure-preserving integrators\nover alternative schemes in terms of not only the accuracy control of both\nenergy conservation and entropy production but also the preservation of the\nconformal symplectic structure in the case of linearly damped systems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 20:54:51 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 21:03:17 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Shang", "Xiaocheng", ""], ["\u00d6ttinger", "Hans Christian", ""]]}, {"id": "1804.05394", "submitter": "Patrick Cheridito", "authors": "Sebastian Becker, Patrick Cheridito and Arnulf Jentzen", "title": "Deep optimal stopping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a deep learning method for optimal stopping problems\nwhich directly learns the optimal stopping rule from Monte Carlo samples. As\nsuch, it is broadly applicable in situations where the underlying randomness\ncan efficiently be simulated. We test the approach on three problems: the\npricing of a Bermudan max-call option, the pricing of a callable multi barrier\nreverse convertible and the problem of optimally stopping a fractional Brownian\nmotion. In all three cases it produces very accurate results in\nhigh-dimensional situations with short computing times.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 17:57:07 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 19:57:31 GMT"}, {"version": "v3", "created": "Mon, 29 Apr 2019 15:11:29 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 14:55:06 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Becker", "Sebastian", ""], ["Cheridito", "Patrick", ""], ["Jentzen", "Arnulf", ""]]}, {"id": "1804.05522", "submitter": "Leonardo Robol", "authors": "Stefano Massei, Mariarosa Mazza and Leonardo Robol", "title": "Fast solvers for two-dimensional fractional diffusion equations using\n  rank structured matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the discretization of time-space diffusion equations with\nfractional derivatives in space and either 1D or 2D spatial domains. The use of\nimplicit Euler scheme in time and finite differences or finite elements in\nspace, leads to a sequence of dense large scale linear systems describing the\nbehavior of the solution over a time interval. We prove that the coefficient\nmatrices arising in the 1D context are rank structured and can be efficiently\nrepresented using hierarchical formats ($\\mathcal H$-matrices, HODLR).\nQuantitative estimates for the rank of the off-diagonal blocks of these\nmatrices are presented. We analyze the use of HODLR arithmetic for solving the\n1D case and we compare this strategy with existing methods that exploit the\nToeplitz-like structure to precondition the GMRES iteration. The numerical\ntests demonstrate the convenience of the HODLR format when at least a\nreasonably low number of time steps is needed. Finally, we explain how these\nproperties can be leveraged to design fast solvers for problems with 2D spatial\ndomains that can be reformulated as matrix equations. The experiments show that\nthe approach based on the use of rank-structured arithmetic is particularly\neffective and outperforms current state of the art techniques.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 07:13:27 GMT"}, {"version": "v2", "created": "Sat, 10 Aug 2019 08:12:40 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Massei", "Stefano", ""], ["Mazza", "Mariarosa", ""], ["Robol", "Leonardo", ""]]}, {"id": "1804.06114", "submitter": "Cong Chen", "authors": "Cong Chen, Kim Batselier, Ching-Yun Ko and Ngai Wong", "title": "A Support Tensor Train Machine", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been growing interest in extending traditional vector-based machine\nlearning techniques to their tensor forms. An example is the support tensor\nmachine (STM) that utilizes a rank-one tensor to capture the data structure,\nthereby alleviating the overfitting and curse of dimensionality problems in the\nconventional support vector machine (SVM). However, the expressive power of a\nrank-one tensor is restrictive for many real-world data. To overcome this\nlimitation, we introduce a support tensor train machine (STTM) by replacing the\nrank-one tensor in an STM with a tensor train. Experiments validate and confirm\nthe superiority of an STTM over the SVM and STM.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 08:59:13 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Chen", "Cong", ""], ["Batselier", "Kim", ""], ["Ko", "Ching-Yun", ""], ["Wong", "Ngai", ""]]}, {"id": "1804.06128", "submitter": "Ching-Yun Ko", "authors": "Ching-Yun Ko, Kim Batselier, Wenjian Yu, Ngai Wong", "title": "Fast and Accurate Tensor Completion with Total Variation Regularized\n  Tensor Trains", "comments": "13 pages. Source code and supplemental materials are available via:\n  https://github.com/IRENEKO/TTC Updates 11/13: included more comparisons and\n  experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new tensor completion method based on tensor trains. The\nto-be-completed tensor is modeled as a low-rank tensor train, where we use the\nknown tensor entries and their coordinates to update the tensor train. A novel\ntensor train initialization procedure is proposed specifically for image and\nvideo completion, which is demonstrated to ensure fast convergence of the\ncompletion algorithm. The tensor train framework is also shown to easily\naccommodate Total Variation and Tikhonov regularization due to their low-rank\ntensor train representations. Image and video inpainting experiments verify the\nsuperiority of the proposed scheme in terms of both speed and scalability,\nwhere a speedup of up to 155X is observed compared to state-of-the-art tensor\ncompletion methods at a similar accuracy. Moreover, we demonstrate the proposed\nscheme is especially advantageous over existing algorithms when only tiny\nportions (say, 1%) of the to-be-completed images/videos are known.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 09:37:11 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 05:26:47 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 07:59:54 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Ko", "Ching-Yun", ""], ["Batselier", "Kim", ""], ["Yu", "Wenjian", ""], ["Wong", "Ngai", ""]]}, {"id": "1804.06200", "submitter": "Caroline Moosm\\\"uller", "authors": "Caroline Moosm\\\"uller, Svenja H\\\"uning, Costanza Conti", "title": "Stirling numbers and Gregory coefficients for the factorization of\n  Hermite subdivision operators", "comments": "31 pages, 1 figure, references and contact information updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a factorization framework for Hermite subdivision\nschemes refining function values and first derivatives, which satisfy a\nspectral condition of high order. In particular we show that spectral order $d$\nallows for $d$ factorizations of the subdivision operator with respect to the\nGregory operators: A new sequence of operators we define using Stirling numbers\nand Gregory coefficients. We further prove that the $d$-th factorization\nprovides a ``convergence from contractivity'' method for showing\n$C^d$-convergence of the associated Hermite subdivision scheme. The power of\nour factorization framework lies in the reduction of computational effort for\nlarge $d$: In order to prove $C^d$-convergence, up to now, $d$ factorization\nsteps were needed, while our method requires only one step, independently of\n$d$. Furthermore, in this paper, we show by an example that the spectral\ncondition is not equivalent to the reproduction of polynomials.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 12:31:25 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 17:31:14 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Moosm\u00fcller", "Caroline", ""], ["H\u00fcning", "Svenja", ""], ["Conti", "Costanza", ""]]}, {"id": "1804.06245", "submitter": "Amelie Trotignon", "authors": "B Bogosel (CMAP), V Perrollaz (IDP), K. Raschel (IDP, CNRS), A\n  Trotignon (IDP)", "title": "3d positive lattice walks and spherical triangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the asymptotic enumeration of three-dimensional\nexcursions confined to the positive octant. As shown in [29], both the\nexponential growth and the critical exponent admit universal formulas,\nrespectively in terms of the inventory of the step set and of the principal\nDirichlet eigenvalue of a certain spherical triangle, itself being\ncharacterized by the steps of the model. We focus on the critical exponent, and\nour main objective is to relate combinatorial properties of the step set\n(structure of the so-called group of the walk, existence of a Hadamard\nfactorization, existence of differential equations satisfied by the generating\nfunctions) to geometric or analytic properties of the associated spherical\ntriangle (remarkable angles, tiling properties, existence of an exceptional\nclosed-form formula for the principal eigenvalue). As in general the\neigenvalues of the Dirichlet problem on a spherical triangle are not known in\nclosed form, we also develop a finite-elements method to compute approximate\nvalues, typically with ten digits of precision.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 13:46:05 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 11:01:06 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Bogosel", "B", "", "CMAP"], ["Perrollaz", "V", "", "IDP"], ["Raschel", "K.", "", "IDP, CNRS"], ["Trotignon", "A", "", "IDP"]]}, {"id": "1804.06252", "submitter": "Aritra Dutta", "authors": "Aritra Dutta, Xin Li, Peter Richtarik", "title": "Weighted Low-Rank Approximation of Matrices and Background Modeling", "comments": "arXiv admin note: text overlap with arXiv:1707.00281", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We primarily study a special a weighted low-rank approximation of matrices\nand then apply it to solve the background modeling problem. We propose two\nalgorithms for this purpose: one operates in the batch mode on the entire data\nand the other one operates in the batch-incremental mode on the data and\nnaturally captures more background variations and computationally more\neffective. Moreover, we propose a robust technique that learns the background\nframe indices from the data and does not require any training frames. We\ndemonstrate through extensive experiments that by inserting a simple weight in\nthe Frobenius norm, it can be made robust to the outliers similar to the\n$\\ell_1$ norm. Our methods match or outperform several state-of-the-art online\nand batch background modeling methods in virtually all quantitative and\nqualitative measures.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 21:43:08 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Dutta", "Aritra", ""], ["Li", "Xin", ""], ["Richtarik", "Peter", ""]]}, {"id": "1804.06455", "submitter": "August Johansson", "authors": "August Johansson, Mats G. Larson, Anders Logg", "title": "MultiMesh Finite Elements with Flexible Mesh Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze a new framework for expressing finite element methods on\narbitrarily many intersecting meshes: multimesh finite element methods. The\nmultimesh finite element method, first presented in [40], enables the use of\nseparate meshes to discretize parts of a computational domain that are\nnaturally separate; such as the components of an engine, the domains of a\nmultiphysics problem, or solid bodies interacting under the influence of forces\nfrom surrounding fluids or other physical fields. Furthermore, each of these\nmeshes may have its own mesh parameter.\n  In the present paper we study the Poisson equation and show that the proposed\nformulation is stable without assumptions on the relative sizes of the mesh\nparameters. In particular, we prove optimal order a priori error estimates as\nwell as optimal order estimates of the condition number. Throughout the\nanalysis, we trace the dependence of the number of intersecting meshes.\nNumerical examples are included to illustrate the stability of the method.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 19:52:23 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 20:30:14 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 12:04:58 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Johansson", "August", ""], ["Larson", "Mats G.", ""], ["Logg", "Anders", ""]]}, {"id": "1804.06501", "submitter": "Vahid Keshavarzzadeh", "authors": "Vahid Keshavarzzadeh, Robert M. Kirby, and Akil Narayan", "title": "Numerical Integration in Multiple Dimensions with Designed Quadrature", "comments": null, "journal-ref": null, "doi": "10.1137/17M1137875", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a systematic computational framework for generating positive\nquadrature rules in multiple dimensions on general geometries. A direct\nmoment-matching formulation that enforces exact integration on polynomial\nsubspaces yields nonlinear conditions and geometric constraints on nodes and\nweights. We use penalty methods to address the geometric constraints, and\nsubsequently solve a quadratic minimization problem via the Gauss-Newton\nmethod. Our analysis provides guidance on requisite sizes of quadrature rules\nfor a given polynomial subspace, and furnishes useful user-end stability bounds\non error in the quadrature rule in the case when the polynomial moment\nconditions are violated by a small amount due to, e.g., finite precision\nlimitations or stagnation of the optimization procedure. We present several\nnumerical examples investigating optimal low-degree quadrature rules, Lebesgue\nconstants, and 100-dimensional quadrature. Our capstone examples compare our\nquadrature approach to popular alternatives, such as sparse grids and\nquasi-Monte Carlo methods, for problems in linear elasticity and topology\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 23:23:44 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Keshavarzzadeh", "Vahid", ""], ["Kirby", "Robert M.", ""], ["Narayan", "Akil", ""]]}, {"id": "1804.06724", "submitter": "Carl Nettelblad", "authors": "Alberto Pietrini, Carl Nettelblad", "title": "Using Convex Optimization of Autocorrelation with Constrained Support\n  and Windowing for Improved Phase Retrieval Accuracy", "comments": "19 pages, 4 figures, 1 table", "journal-ref": null, "doi": "10.1364/OE.26.024422", "report-no": null, "categories": "eess.SP cs.NA physics.bio-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In imaging modalities recording diffraction data, the original image can be\nreconstructed assuming known phases. When phases are unknown, oversampling and\na constraint on the support region in the original object can be used to solve\na non-convex optimization problem.\n  Such schemes are ill-suited to find the optimum solution for sparse data,\nsince the recorded image does not correspond exactly to the original wave\nfunction. We construct a convex optimization problem using a relaxed support\nconstraint and a maximum-likelihood treatment of the recorded data as a sample\nfrom the underlying wave function. We also stress the need to use relevant\nwindowing techniques to account for the sampled pattern being finite.\n  On simulated data, we demonstrate the benefits of our approach in terms of\nvisual quality and an improvement in the crystallographic R-factor from .4 to\n.1 for highly noisy data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 09:23:11 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Pietrini", "Alberto", ""], ["Nettelblad", "Carl", ""]]}, {"id": "1804.07334", "submitter": "Jeffrey Uhlmann", "authors": "Jeffrey Uhlmann", "title": "A Rank-Preserving Generalized Matrix Inverse for Consistency with\n  Respect to Similarity", "comments": "Included simulation results and revised text in preparation for\n  journal submission", "journal-ref": "IEEE Control Systems Letters (2018)", "doi": "10.1109/LCSYS.2018.2854240", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been renewed recognition of the need to understand the\nconsistency properties that must be preserved when a generalized matrix inverse\nis required. The most widely known generalized inverse, the Moore-Penrose\npseudoinverse, provides consistency with respect to orthonormal transformations\n(e.g., rotations of a coordinate frame), and a recently derived inverse\nprovides consistency with respect to diagonal transformations (e.g., a change\nof units on state variables). Another well-known and theoretically important\ngeneralized inverse is the Drazin inverse, which preserves consistency with\nrespect to similarity transformations. In this paper we note a limitation of\nthe Drazin inverse is that it does not generally preserve the rank of the\nlinear system of interest. We then introduce an alternative generalized inverse\nthat both preserves rank and provides consistency with respect to similarity\ntransformations. Lastly we provide an example and discuss experiments which\nsuggest the need for algorithms with improved numerical stability.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 18:46:08 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 16:03:08 GMT"}, {"version": "v3", "created": "Sun, 6 May 2018 15:15:55 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Uhlmann", "Jeffrey", ""]]}, {"id": "1804.07468", "submitter": "Christian Offen", "authors": "Robert I McLachlan and Christian Offen", "title": "Preservation of bifurcations of Hamiltonian boundary value problems\n  under discretisation", "comments": null, "journal-ref": "Foundations of Computational Mathematics (FoCM) 20, 1363--1400,\n  2020", "doi": "10.1007/s10208-020-09454-z", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that symplectic integrators preserve bifurcations of Hamiltonian\nboundary value problems and that nonsymplectic integrators do not. We provide a\nuniversal description of the breaking of umbilic bifurcations by nonysmplectic\nintegrators. We discover extra structure induced from certain types of boundary\nvalue problems, including classical Dirichlet problems, that is useful to\nlocate bifurcations. Geodesics connecting two points are an example of a\nHamiltonian boundary value problem, and we introduce the jet-RATTLE method, a\nsymplectic integrator that easily computes geodesics and their bifurcations.\nFinally, we study the periodic pitchfork bifurcation, a codimension-1\nbifurcation arising in integrable Hamiltonian systems. It is not preserved by\neither symplectic on nonsymplectic integrators, but in some circumstances\nsymplecticity greatly reduces the error.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 06:57:10 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 05:50:07 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 07:05:13 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["McLachlan", "Robert I", ""], ["Offen", "Christian", ""]]}, {"id": "1804.07701", "submitter": "Alessio De Angelis", "authors": "Alessio De Angelis, Johan Schoukens, Keith R. Godfrey, Paolo Carbone", "title": "Practical Issues in the Synthesis of Ternary Sequences", "comments": null, "journal-ref": "A. De Angelis, J. Schoukens, K. R. Godfrey and P. Carbone,\n  \"Practical Issues in the Synthesis of Ternary Sequences,\" in IEEE\n  Transactions on Instrumentation and Measurement, vol. 66, no. 2, pp. 212-222,\n  Feb. 2017", "doi": "10.1109/TIM.2016.2622778", "report-no": null, "categories": "eess.SP cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several issues related to the practical synthesis of ternary sequences with\nspecified spectra are addressed in this paper. Specifically, sequences with\nharmonic multiples of two and three suppressed are studied, given their\nrelevance when testing and characterizing nonlinear systems. In particular, the\neffect of non-uniform Digital to Analog Converter (DAC) levels on the spectral\nproperties of the generated signal is analyzed. It is analytically shown that\nthe DAC non-uniform levels result in degraded harmonic suppression performance.\nMoreover, a new approach is proposed for designing ternary sequences, which is\nflexible and can be adapted to suit different requirements. The resulting\nsequences, denoted as randomized constrained sequences, are characterized\ntheoretically by deriving an analytical expression of the power spectral\ndensity. Furthermore, they are extensively compared with three synthesis\napproaches proposed in the literature. The approach is validated by numerical\nsimulations and experimental results, showing the potential to achieve harmonic\nsuppression performance of approximately 100 dB.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 16:10:01 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["De Angelis", "Alessio", ""], ["Schoukens", "Johan", ""], ["Godfrey", "Keith R.", ""], ["Carbone", "Paolo", ""]]}, {"id": "1804.07716", "submitter": "Arash Sarshar", "authors": "Arash Sarshar, Steven Roberts and Adrian Sandu", "title": "Design of High-Order Decoupled Multirate GARK Schemes", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing, Vol. 41, No. 2, 2019, PP.\n  A816-A847", "doi": "10.1137/18M1182875", "report-no": "CSL-TR-18-4", "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multirate time integration methods apply different step sizes to resolve\ndifferent components of the system based on the local activity levels. This\nlocal selection of step sizes allows increased computational efficiency while\nachieving the desired solution accuracy. While the multirate idea is elegant\nand has been around for decades, multirate methods are not yet widely used in\napplications. This is due, in part, to the difficulties raised by the\nconstruction of high order multirate schemes.\n  Seeking to overcome these challenges, this work focuses on the design of\npractical high-order multirate methods using the theoretical framework of\ngeneralized additive Runge-Kutta (MrGARK) methods, which provides the generic\norder conditions and the linear and nonlinear stability analyses.\n  A set of design criteria for practical multirate methods is defined herein:\nmethod coefficients should be generic in the step size ratio, but should not\ndepend strongly on this ratio; unnecessary coupling between the fast and the\nslow components should be avoided; and the step size controllers should adjust\nboth the micro- and the macro-steps.\n  Using these criteria, we develop MrGARK schemes of up to order four that are\nexplicit-explicit (both the fast and slow component are treated explicitly),\nimplicit-explicit (implicit in the fast component and explicit in the slow\none), and explicit-implicit (explicit in the fast component and implicit in the\nslow one). Numerical experiments illustrate the performance of these new\nschemes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 16:45:36 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 23:00:41 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2019 18:54:19 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Sarshar", "Arash", ""], ["Roberts", "Steven", ""], ["Sandu", "Adrian", ""]]}, {"id": "1804.07796", "submitter": "Susanne Solem", "authors": "Jos\\'e A. Carrillo, Ulrik Skre Fjordholm and Susanne Solem", "title": "A second-order numerical method for the aggregation equations", "comments": "Improved manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by so-called TVD limiter-based second-order schemes for hyperbolic\nconservation laws, we develop a second-order accurate numerical method for\nmulti-dimensional aggregation equations. The method allows for simulations to\nbe continued after the first blow-up time of the solution. In the case of\nsymmetric, lambda-convex potentials with a possible Lipschitz singularity at\nthe origin we prove that the method converges in the Monge--Kantorovich\ndistance towards the unique gradient flow solution. Several numerical\nexperiments are presented to validate the second-order convergence rate and to\nexplore the performance of the scheme.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:55:43 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 11:28:29 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 12:38:16 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Carrillo", "Jos\u00e9 A.", ""], ["Fjordholm", "Ulrik Skre", ""], ["Solem", "Susanne", ""]]}, {"id": "1804.07898", "submitter": "Lorenzo Mascotto", "authors": "L. Beir\\~ao da Veiga, G. Manzini, L. Mascotto", "title": "A posteriori error estimation and adaptivity in $hp$ virtual elements", "comments": "28 pages, 16 figures", "journal-ref": null, "doi": "10.1007/s00211-019-01054-6", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An explicit and computable error estimator for the $hp$ version of the\nvirtual element method (VEM), together with lower and upper bounds with respect\nto the exact energy error, is presented. Such error estimator is employed to\nprovide $hp$ adaptive mesh refinements for very general polygonal meshes. In\naddition, a novel VEM $hp$ Cl\\'ement quasi-interpolant, instrumental for the a\nposteriori error analysis, is introduced. The performances of the adaptive\nmethod are validated by a number of numerical experiments.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 06:08:25 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 10:12:08 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["da Veiga", "L. Beir\u00e3o", ""], ["Manzini", "G.", ""], ["Mascotto", "L.", ""]]}, {"id": "1804.07979", "submitter": "Shuvam Sen", "authors": "Subhajit Giri and Shuvam Sen", "title": "Phase error analysis of implicit Runge-Kutta methods: Introducing new\n  classes of minimal dissipation low dispersion high order schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current research, we analyse dissipation and dispersion characteristics of\nmost accurate two and three stage Gauss-Legendre implicit Runge-Kutta (R-K)\nmethods. These methods, known for their $A$-stability and immense accuracy, are\nobserved to carry minimum dissipation error along with highest possible\ndispersive order in their respective classes. We investigate to reveal that\nthese schemes are inherently optimized to carry low phase error only at small\nwavenumber. As larger temporal step size is imperative in conjunction with\nimplicit R-K methods for physical problems, we interpret to derive a class of\nminimum dissipation and optimally low dispersion implicit R-K schemes. Schemes\nthus obtained by cutting down amplification error and maximum reduction of\nweighted phase error, suggest better accuracy for relatively bigger CFL number.\nSignificantly, we are able to outline an algorithm that can be used to design\nstable implicit R-K methods for suitable time step with better accuracy\nvirtues. The algorithm is potentially generalizable for implicit R-K class of\nmethods. As we focus on two and three stage schemes a comprehensive comparison\nis carried out using numerical test cases.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 15:21:17 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 12:27:35 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Giri", "Subhajit", ""], ["Sen", "Shuvam", ""]]}, {"id": "1804.08265", "submitter": "Samrat Mukhopadhyay", "authors": "Samrat Mukhopadhyay and Mrityunjoy Chakraborty", "title": "Deterministic and Randomized Diffusion based Iterative Generalized Hard\n  Thresholding (DiFIGHT) for Distributed Sparse Signal Recovery", "comments": "11 pages, 4 figures, Updated some analysis, Added a few more\n  explanations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a distributed iterated hard thresholding algorithm\ntermed DiFIGHT over a network that is built on the diffusion mechanism and also\npropose a modification of the proposed algorithm, termed MoDiFIGHT, that has\nlow complexity in terms of communication in the network. We additionally\npropose four different strategies termed RP, RNP, RGP$_r$, and RGNP$_r$ that\nare used to randomly select a subset of nodes that are subsequently activated\nto take part in the distributed algorithm, so as to reduce the mean number of\ncommunications during the run of the distributed algorithm. We present\ntheoretical estimates of the long run communication per unit time for these\ndifferent strategies, when used by the two proposed algorithms. Also, we\npresent analysis of the two proposed algorithms and provide provable bounds on\ntheir recovery performance with or without using the random node selection\nstrategies. Finally we use numerical studies to show that both when the random\nstrategies are used as well as when they are not used, the proposed algorithms\ndisplay performances far superior to distributed IHT algorithm using consensus\nmechanism .\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 07:13:47 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 16:37:20 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Mukhopadhyay", "Samrat", ""], ["Chakraborty", "Mrityunjoy", ""]]}, {"id": "1804.08445", "submitter": "Anthony Torres", "authors": "A. Torres-Hernandez, F. Brambila-Paz, U. Iturrar\\'an-Viveros, R.\n  Caballero-Cruz", "title": "Fractional Newton-Raphson Method Accelerated with Aitken's Method", "comments": "Newton-Raphson Method, Fractional Calculus, Fractional Derivative of\n  Riemann-Liouville, Method of Aitken. arXiv admin note: substantial text\n  overlap with arXiv:1710.07634", "journal-ref": "Axioms, 10(2):1-25, 2021", "doi": "10.3390/axioms10020047", "report-no": null, "categories": "math.NA cs.NA math.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the following document, we present a way to obtain the order of\nconvergence of the Fractional Newton-Raphson (F N-R) method, which seems to\nhave an order of convergence at least linearly for the case in which the order\n$\\alpha$ of the derivative is different from one. A simplified way of\nconstructing the Riemann-Liouville (R-L) fractional operators, fractional\nintegral and fractional derivative, is presented along with examples of its\napplication on different functions. Furthermore, an introduction to the\nAitken's method is made and it is explained why it has the ability to\naccelerate the convergence of the iterative methods, to finally present the\nresults that were obtained when implementing the Aitken's method in the F N-R\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 08:11:58 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 23:03:08 GMT"}, {"version": "v3", "created": "Sat, 4 May 2019 05:22:38 GMT"}, {"version": "v4", "created": "Sat, 26 Oct 2019 06:57:04 GMT"}, {"version": "v5", "created": "Mon, 22 Feb 2021 01:46:14 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Torres-Hernandez", "A.", ""], ["Brambila-Paz", "F.", ""], ["Iturrar\u00e1n-Viveros", "U.", ""], ["Caballero-Cruz", "R.", ""]]}, {"id": "1804.09137", "submitter": "Sameh Abdulah", "authors": "Sameh Abdulah, Hatem Ltaief, Ying Sun, Marc G. Genton, and David E.\n  Keyes", "title": "Parallel Approximation of the Maximum Likelihood Estimation for the\n  Prediction of Large-Scale Geostatistics Simulations", "comments": null, "journal-ref": null, "doi": "10.1109/CLUSTER.2018.00089", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum likelihood estimation is an important statistical technique for\nestimating missing data, for example in climate and environmental applications,\nwhich are usually large and feature data points that are irregularly spaced. In\nparticular, the Gaussian log-likelihood function is the \\emph{de facto} model,\nwhich operates on the resulting sizable dense covariance matrix. The advent of\nhigh performance systems with advanced computing power and memory capacity have\nenabled full simulations only for rather small dimensional climate problems,\nsolved at the machine precision accuracy. The challenge for high dimensional\nproblems lies in the computation requirements of the log-likelihood function,\nwhich necessitates ${\\mathcal O}(n^2)$ storage and ${\\mathcal O}(n^3)$\noperations, where $n$ represents the number of given spatial locations. This\nprohibitive computational cost may be reduced by using approximation techniques\nthat not only enable large-scale simulations otherwise intractable but also\nmaintain the accuracy and the fidelity of the spatial statistics model. In this\npaper, we extend the Exascale GeoStatistics software framework (i.e.,\nExaGeoStat) to support the Tile Low-Rank (TLR) approximation technique, which\nexploits the data sparsity of the dense covariance matrix by compressing the\noff-diagonal tiles up to a user-defined accuracy threshold. The underlying\nlinear algebra operations may then be carried out on this data compression\nformat, which may ultimately reduce the arithmetic complexity of the maximum\nlikelihood estimation and the corresponding memory footprint. Performance\nresults of TLR-based computations on shared and distributed-memory systems\nattain up to 13X and 5X speedups, respectively, compared to full accuracy\nsimulations using synthetic and real datasets (up to 2M), while ensuring\nadequate prediction accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:02:25 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 09:35:08 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Abdulah", "Sameh", ""], ["Ltaief", "Hatem", ""], ["Sun", "Ying", ""], ["Genton", "Marc G.", ""], ["Keyes", "David E.", ""]]}, {"id": "1804.09893", "submitter": "Haim Avron", "authors": "Haim Avron, Michael Kapralov, Cameron Musco, Christopher Musco, Ameya\n  Velingker, Amir Zandieh", "title": "Random Fourier Features for Kernel Ridge Regression: Approximation\n  Bounds and Statistical Guarantees", "comments": "An extended abstract of this work appears in the Proceedings of the\n  34th International Conference on Machine Learning (ICML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Fourier features is one of the most popular techniques for scaling up\nkernel methods, such as kernel ridge regression. However, despite impressive\nempirical results, the statistical properties of random Fourier features are\nstill not well understood. In this paper we take steps toward filling this gap.\nSpecifically, we approach random Fourier features from a spectral matrix\napproximation point of view, give tight bounds on the number of Fourier\nfeatures required to achieve a spectral approximation, and show how spectral\nmatrix approximation bounds imply statistical guarantees for kernel ridge\nregression.\n  Qualitatively, our results are twofold: on the one hand, we show that random\nFourier feature approximation can provably speed up kernel ridge regression\nunder reasonable assumptions. At the same time, we show that the method is\nsuboptimal, and sampling from a modified distribution in Fourier space, given\nby the leverage function of the kernel, yields provably better performance. We\nstudy this optimal sampling distribution for the Gaussian kernel, achieving a\nnearly complete characterization for the case of low-dimensional bounded\ndatasets. Based on this characterization, we propose an efficient sampling\nscheme with guarantees superior to random Fourier features in this regime.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 05:34:25 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 09:17:40 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Avron", "Haim", ""], ["Kapralov", "Michael", ""], ["Musco", "Cameron", ""], ["Musco", "Christopher", ""], ["Velingker", "Ameya", ""], ["Zandieh", "Amir", ""]]}, {"id": "1804.09972", "submitter": "Rachid Ait-Haddou", "authors": "Rachid Ait-Haddou", "title": "Computation of optimal linear strong stability preserving methods via\n  adaptive spectral transformations of Poisson-Charlier measures", "comments": "50 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong stability preserving (SSP) coefficients govern the maximally allowable\nstep-size at which positivity or contractivity preservation of integration\nmethods for initial value problems is guaranteed. In this paper, we show that\nthe task of computing linear SSP coefficients of explicit one-step methods is,\nto a certain extent, equivalent to the problem of characterizing positive\nquadratures with integer nodes with respect to Poisson-Charlier measures. Using\nthis equivalence, we provide sharp upper and lower bounds for the optimal\nlinear SSP coefficients in terms of the zeros of generalized Laguerre\northogonal polynomials. This in particular provides us with a sharp upper bound\nfor the optimal SSP coefficients of explicit Runge-Kutta methods. Also based on\nthis equivalence, we propose a highly efficient and stable algorithm for\ncomputing these coefficients, and their associated optimal linear SSP methods,\nbased on adaptive spectral transformations of Poisson-Charlier measures. The\nalgorithm possesses the remarkable property that its complexity depends only on\nthe order of the method and thus is independent of the number of stages. Our\nresults are achieved by adapting and extending an ingenious technique by\nBernstein in his seminal work on absolutely monotonic functions. Moreover, the\ntechniques introduced in this work can be adapted to solve the integer\nquadrature problem for any positive discrete multi-parametric measure supported\non $\\mathbb{N}$ under some mild conditions on the zeros of the associated\northogonal polynomials.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 10:13:00 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 09:12:52 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ait-Haddou", "Rachid", ""]]}, {"id": "1804.10110", "submitter": "Jeff Anderson", "authors": "Jeff Anderson, Engin Kayraklioglu, Volker Sorger, Tarek El-Ghazawi", "title": "Adaptive Mesh Refinement in Analog Mesh Computers", "comments": "large error in simulation of results. nullifies most of the results,\n  as far as accuracy and energy savings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The call for efficient computer architectures has introduced a variety of\napplication-specific compute engines to the heterogeneous computing landscape.\nOne particular engine, the analog mesh computer, has been well received due to\nits ability to efficiently solve partial differential equations by eliminating\nthe iterative stages common to numerical solvers. This article introduces an\nimplementation of refinement for analog mesh computers.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 18:02:06 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 18:24:13 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Anderson", "Jeff", ""], ["Kayraklioglu", "Engin", ""], ["Sorger", "Volker", ""], ["El-Ghazawi", "Tarek", ""]]}, {"id": "1804.10194", "submitter": "Hailong Guo", "authors": "Hailong Guo and Cong Xie and Ren Zhao", "title": "Superconvergent Gradient Recovery for Virtual Element Methods", "comments": "Mathematical Models and Methods in Applied Sciences, 2019", "journal-ref": null, "doi": "10.1142/S0218202519500386", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual element methods is a new promising finite element methods using\ngeneral polygonal meshes. Its optimal a priori error estimates are well\nestablished in the literature. In this paper, we take a different viewpoint. We\ntry to uncover the superconvergent property of the virtual element methods by\ndoing some local post-processing only on the degrees of freedom. Using linear\nvirtual element method as an example, we propose a universal recovery procedure\nto improve the accuracy of gradient approximation for numerical methods using\ngeneral polygonal meshes. Its capability of serving as a posteriori error\nestimators in adaptive methods is also investigated. Compared to the existing\nresidual-type a posteriori error estimators for the virtual element methods,\nthe recovery-type a posteriori error estimator based on the proposed gradient\nrecovery technique is much simpler in implementation and asymptotically exact.\nA series of benchmark tests are presented to numerically illustrate the\nsuperconvergence of recovered gradient and validate the asymptotical exactness\nof the recovery-based a posteriori error estimator.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:48:32 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 12:19:50 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Guo", "Hailong", ""], ["Xie", "Cong", ""], ["Zhao", "Ren", ""]]}, {"id": "1804.10547", "submitter": "Patrick Henning", "authors": "Patrick Henning and Johan W\\\"arneg{\\aa}rd", "title": "Numerical comparison of mass-conservative schemes for the\n  Gross-Pitaevskii equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a numerical comparison of various mass-conservative\ndiscretizations for the time-dependent Gross-Pitaevskii equation. We have three\nmain objectives. First, we want to clarify how purely mass-conservative methods\nperform compared to methods that are additionally energy-conservative or\nsymplectic. Second, we shall compare the accuracy of energy-conservative and\nsymplectic methods among each other. Third, we will investigate if a linearized\nenergy-conserving method suffers from a loss of accuracy compared to an\napproach which requires to solve a full nonlinear problem in each time-step. In\norder to obtain a representative comparison, our numerical experiments cover\ndifferent physically relevant test cases, such as traveling solitons,\nstationary multi-solitons, Bose-Einstein condensates in an optical lattice and\nvortex pattern in a rapidly rotating superfluid. We shall also consider a\ncomputationally severe test case involving a pseudo Mott insulator. Our space\ndiscretization is based on finite elements throughout the paper. We will also\ngive special attention to long time behavior and possible coupling conditions\nbetween time-step sizes and mesh sizes. The main observation of this paper is\nthat mass conservation alone will not lead to a competitive method in complex\nsettings. Furthermore, energy-conserving and symplectic methods are both\nreliable and accurate, yet, the energy-conservative schemes achieve a visibly\nhigher accuracy in our test cases. Finally, the scheme that performs best\nthroughout our experiments is an energy-conserving relaxation scheme with\nlinear time-stepping proposed by C. Besse (SINUM,42(3):934--952,2004).\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:06:34 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 11:18:01 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 14:28:19 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2019 14:15:48 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Henning", "Patrick", ""], ["W\u00e4rneg\u00e5rd", "Johan", ""]]}, {"id": "1804.10953", "submitter": "Timothy F. Havel", "authors": "Igor Najfeld and Timothy F. Havel", "title": "Embedding with a Rigid Substructure", "comments": "This technical report is being reposted on the CS archive because the\n  problem solved therein is essentially a least-squares formulation of the\n  \"sensor localization\" problem, which is of wide-spread interest to this\n  community", "journal-ref": "Journal of Mathematical Chemistry 21 (1997) 223-260", "doi": "10.1023/A:1019190907089", "report-no": "Harvard Center for Research in Computing Technology TR-04-97", "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new distance geometry algorithm for calculating atomic\ncoordinates from estimates of the interatomic distances, which maintains the\npositions of the atoms in a known rigid substructure. Given an $M \\times 3$\nmatrix of coordinates for the rigid substructure $\\mathbf X$, this problem\nconsists of finding the $N \\times 3$ matrix $\\mathbf Y$ that yields of global\nminimum of the so-called STRAIN, i.e. \\[ \\min_{\\mathbf Y} \\left\\|\n\\begin{bmatrix} \\mathbf{XX}^\\top & \\mathbf{XY}^\\top \\\\ \\mathbf{YX}^\\top &\n\\mathbf{YY}^\\top \\end{bmatrix} \\,-\\, \\begin{bmatrix} \\mathbf A & \\mathbf B \\\\\n\\mathbf B^\\top & \\mathbf C \\end{bmatrix} \\right\\|_{\\mathsf F}^2 ~, \\] where\n$\\mathbf A = \\mathbf{XX}^\\top$ , and $\\mathbf B, \\mathbf C$ are matrices of\ninner products calculated from the estimated distances.\n  The vanishing of the gradient of the STRAIN is shown to be equivalent to a\nsystem of only six nonlinear equations in six unknowns for the inertial tensor\nassociated with the solution Y . The entire solution space is characterized in\nterms of the geometry of the intersection curves between the unit sphere and\ncertain variable ellipsoids. Upon deriving tight bilateral bounds on the\nmoments of inertia of any possible solution, we construct a search procedure\nthat reliably locates the global minimum. The effectiveness of this method is\ndemonstrated on realistic simulated and chemical test problems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 15:26:53 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Najfeld", "Igor", ""], ["Havel", "Timothy F.", ""]]}, {"id": "1804.11157", "submitter": "Jonas Latz", "authors": "Jonas Latz, Marvin Eisenberger, Elisabeth Ullmann", "title": "Fast sampling of parameterised Gaussian random fields", "comments": "35 pages", "journal-ref": "Comput. Methods Appl. Mech. Engrg. (2019)", "doi": "10.1016/j.cma.2019.02.003", "report-no": null, "categories": "math.NA cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian random fields are popular models for spatially varying\nuncertainties, arising for instance in geotechnical engineering, hydrology or\nimage processing. A Gaussian random field is fully characterised by its mean\nfunction and covariance operator. In more complex models these can also be\npartially unknown. In this case we need to handle a family of Gaussian random\nfields indexed with hyperparameters. Sampling for a fixed configuration of\nhyperparameters is already very expensive due to the nonlocal nature of many\nclassical covariance operators. Sampling from multiple configurations increases\nthe total computational cost severely. In this report we employ parameterised\nKarhunen-Lo\\`eve expansions for sampling. To reduce the cost we construct a\nreduced basis surrogate built from snapshots of Karhunen-Lo\\`eve eigenvectors.\nIn particular, we consider Mat\\'ern-type covariance operators with unknown\ncorrelation length and standard deviation. We suggest a linearisation of the\ncovariance function and describe the associated online-offline decomposition.\nIn numerical experiments we investigate the approximation error of the reduced\neigenpairs. As an application we consider forward uncertainty propagation and\nBayesian inversion with an elliptic partial differential equation where the\nlogarithm of the diffusion coefficient is a parameterised Gaussian random\nfield. In the Bayesian inverse problem we employ Markov chain Monte Carlo on\nthe reduced space to generate samples from the posterior measure. All numerical\nexperiments are conducted in 2D physical space, with non-separable covariance\noperators, and finite element grids with $\\sim 10^4$ degrees of freedom.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 12:38:13 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 10:45:21 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Latz", "Jonas", ""], ["Eisenberger", "Marvin", ""], ["Ullmann", "Elisabeth", ""]]}, {"id": "1804.11331", "submitter": "Xiaojie Wang", "authors": "Ruisheng Qi, Xiaojie Wang", "title": "Optimal error estimates of Galerkin finite element methods for\n  stochastic Allen-Cahn equation with additive noise", "comments": "22 pages, 6 figures", "journal-ref": "Journal of Scientific Computing, 2019, 80(2): 1171-1194", "doi": "10.1007/s10915-019-00973-8", "report-no": null, "categories": "math.NA cs.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong approximation errors of both finite element semi-discretization and\nspatio-temporal full discretization are analyzed for the stochastic Allen-Cahn\nequation driven by additive noise in space dimension $d \\leq 3$. The full\ndiscretization is realized by combining the standard finite element method with\nthe backward Euler time-stepping scheme. Distinct from the globally Lipschitz\nsetting, the error analysis becomes rather challenging and demanding, due to\nthe presence of the cubic nonlinearity in the underlying model. By introducing\ntwo auxiliary approximation processes, we propose an appropriate decomposition\nof the considered error terms and introduce a novel approach of error analysis,\nto successfully recover the convergence rates of the numerical schemes. The\napproach is original and does not rely on high-order spatial regularity\nproperties of the approximation processes. It is shown that the fully discrete\nscheme possesses convergence rates of order $ O(h^{\\gamma} ) $ in space and\norder $ O( \\tau^{ \\frac{\\gamma}{2} } )$ in time, subject to the spatial\ncorrelation of the noise process, characterized by $\n\\|A^{\\frac{\\gamma-1}2}Q^{\\frac12}\\|_{\\mathcal{L}_2}<\\infty, \\, \\gamma \\in[\\frac\nd3,2] $, $ d\\in\\{1,2,3\\}$. In particular, a classical convergence rate of order\n$O(h^2 +\\tau)$ is reachable, even in multiple space dimensions, when the\naforementioned condition is fulfilled with $ \\gamma = 2 $. Numerical examples\nconfirm the previous findings.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 17:26:48 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 15:49:15 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 08:42:22 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Qi", "Ruisheng", ""], ["Wang", "Xiaojie", ""]]}]