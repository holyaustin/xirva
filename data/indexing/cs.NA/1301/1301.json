[{"id": "1301.0581", "submitter": "Martijn Leisink", "authors": "Martijn Leisink, Hilbert Kappen", "title": "General Lower Bounds based on Computer Generated Higher Order Expansions", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-293-300", "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we show the rough outline of a computer algorithm to generate\nlower bounds on the exponential function of (in principle) arbitrary precision.\nWe implemented this to generate all necessary analytic terms for the Boltzmann\nmachine partition function thus leading to lower bounds of any order. It turns\nout that the extra variational parameters can be optimized analytically. We\nshow that bounds upto nineth order are still reasonably calculable in practical\nsituations. The generated terms can also be used as extra correction terms\n(beyond TAP) in mean field expansions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:07 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Leisink", "Martijn", ""], ["Kappen", "Hilbert", ""]]}, {"id": "1301.0878", "submitter": "Nir Ailon", "authors": "Nir Ailon and Holger Rauhut", "title": "Fast and RIP-optimal transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study constructions of $k \\times n$ matrices $A$ that both (1) satisfy the\nrestricted isometry property (RIP) at sparsity $s$ with optimal parameters, and\n(2) are efficient in the sense that only $O(n\\log n)$ operations are required\nto compute $Ax$ given a vector $x$. Our construction is based on repeated\napplication of independent transformations of the form $DH$, where $H$ is a\nHadamard or Fourier transform and $D$ is a diagonal matrix with random\n$\\{+1,-1\\}$ elements on the diagonal, followed by any $k \\times n$ matrix of\northonormal rows (e.g.\\ selection of $k$ coordinates). We provide guarantees\n(1) and (2) for a larger regime of parameters for which such constructions were\npreviously unknown. Additionally, our construction does not suffer from the\nextra poly-logarithmic factor multiplying the number of observations $k$ as a\nfunction of the sparsity $s$, as present in the currently best known RIP\nestimates for partial random Fourier matrices and other classes of structured\nrandom matrices.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2013 07:39:15 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2013 11:18:05 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Ailon", "Nir", ""], ["Rauhut", "Holger", ""]]}, {"id": "1301.0967", "submitter": "Xianyi Zeng", "authors": "Xianyi Zeng", "title": "A general approach to enhance slope limiters on non-uniform rectilinear\n  grids", "comments": "25 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most slope limiter functions in high-resolution finite volume methods to\nsolve hyperbolic conservation laws are designed assuming one-dimensional\nuniform grids, and they are also used to compute slope limiters in computations\non non-uniform rectilinear grids. However, this strategy may lead to either\nloss of total variation diminishing (TVD) stability for 1D linear problems or\nthe loss of formal second-order accuracy if the grid is highly non-uniform.\nThis is especially true when the limiter function is not piecewise linear.\nNumerical evidences are provided to support this argument for two popular\nfinite volume strategies: MUSCL in space and method of lines in time\n(MUSCL-MOL), and capacity-form differencing. In order to deal with this issue,\nthis paper presents a general approach to study and enhance the slope limiter\nfunctions for highly non-uniform grids in the MUSCL-MOL framework. This\napproach extends the classical reconstruct-evolve-project procedure to general\ngrids, and it gives sufficient conditions for a slope limiter function leading\nto a TVD stable, formal second-order accuracy in space, and symmetry preserving\nnumerical scheme on arbitrary grids. Several widely used limiter functions,\nincluding the smooth ones by van Leer and van Albada, are enhanced to satisfy\nthese conditions. These properties are confirmed by solving various\none-dimensional and two-dimensional benchmark problems using the enhanced\nlimiters on highly non-uniform rectilinear grids.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2013 03:12:38 GMT"}, {"version": "v2", "created": "Tue, 20 May 2014 03:27:09 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Zeng", "Xianyi", ""]]}, {"id": "1301.1071", "submitter": "Austin Benson", "authors": "Austin R. Benson, David F. Gleich, James Demmel", "title": "Direct QR factorizations for tall-and-skinny matrices in MapReduce\n  architectures", "comments": null, "journal-ref": "Proceedings of the IEEE International Conference on Big Data, 2013", "doi": "10.1109/BigData.2013.6691583", "report-no": null, "categories": "cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The QR factorization and the SVD are two fundamental matrix decompositions\nwith applications throughout scientific computing and data analysis. For\nmatrices with many more rows than columns, so-called \"tall-and-skinny\nmatrices,\" there is a numerically stable, efficient, communication-avoiding\nalgorithm for computing the QR factorization. It has been used in traditional\nhigh performance computing and grid computing environments. For MapReduce\nenvironments, existing methods to compute the QR decomposition use a\nnumerically unstable approach that relies on indirectly computing the Q factor.\nIn the best case, these methods require only two passes over the data. In this\npaper, we describe how to compute a stable tall-and-skinny QR factorization on\na MapReduce architecture in only slightly more than 2 passes over the data. We\ncan compute the SVD with only a small change and no difference in performance.\nWe present a performance comparison between our new direct TSQR method, a\nstandard unstable implementation for MapReduce (Cholesky QR), and the classic\nstable algorithm implemented for MapReduce (Householder QR). We find that our\nnew stable method has a large performance advantage over the Householder QR\nmethod. This holds both in a theoretical performance model as well as in an\nactual implementation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2013 22:56:36 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Benson", "Austin R.", ""], ["Gleich", "David F.", ""], ["Demmel", "James", ""]]}, {"id": "1301.1107", "submitter": "Haim Avron", "authors": "Haim Avron, Alex Druinsky, Sivan Toledo", "title": "Spectral Condition-Number Estimation of Large Sparse Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a randomized Krylov-subspace method for estimating the spectral\ncondition number of a real matrix A or indicating that it is numerically rank\ndeficient. The main difficulty in estimating the condition number is the\nestimation of the smallest singular value \\sigma_{\\min} of A. Our method\nestimates this value by solving a consistent linear least-squares problem with\na known solution using a specific Krylov-subspace method called LSQR. In this\nmethod, the forward error tends to concentrate in the direction of a right\nsingular vector corresponding to \\sigma_{\\min}. Extensive experiments show that\nthe method is able to estimate well the condition number of a wide array of\nmatrices. It can sometimes estimate the condition number when running a dense\nSVD would be impractical due to the computational cost or the memory\nrequirements. The method uses very little memory (it inherits this property\nfrom LSQR) and it works equally well on square and rectangular matrices.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 04:31:19 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2014 15:55:48 GMT"}, {"version": "v3", "created": "Tue, 10 Feb 2015 16:56:34 GMT"}, {"version": "v4", "created": "Wed, 8 Mar 2017 22:10:27 GMT"}, {"version": "v5", "created": "Wed, 28 Jun 2017 06:57:58 GMT"}, {"version": "v6", "created": "Thu, 30 Aug 2018 06:05:34 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Avron", "Haim", ""], ["Druinsky", "Alex", ""], ["Toledo", "Sivan", ""]]}, {"id": "1301.2102", "submitter": "Kirk Soodhalter", "authors": "Kirk M. Soodhalter", "title": "A block MINRES algorithm based on the banded Lanczos method", "comments": "20 Pages, 8 figures, 1 Algorithm, Revision based on reviewer comments", "journal-ref": null, "doi": "10.1007/s11075-014-9907-z", "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a block minimum residual (MINRES) algorithm for symmetric\nindefinite matrices. This version is built upon the band Lanczos method that\ngenerates one basis vector of the block Krylov subspace per iteration rather\nthan a whole block as in the block Lanczos process. However, we modify the\nmethod such that the most expensive operations are still performed in a block\nfashion. The benefit of using the band Lanczos method is that one can detect\nbreakdowns from scalar values arising in the computation, allowing for a\nhandling of breakdown which is straightforward to implement.\n  We derive a progressive formulation of the MINRES method based on the band\nLanczos process and give some implementation details. Specifically, a simple\nreordering of the steps allows us to perform many of the operations at the\nblock level in order to take advantage of communication efficiencies offered by\nthe block Lanczos process. This is an important concern in the context of\nnext-generation super computing applications.\n  We also present a technique allowing us to maintain the block size by\nreplacing dependent Lanczos vectors with pregenerated random vectors whose\northogonality against all Lanczos vectors is maintained. Numerical results\nillustrate the performance on some sample problems. We present experiments that\nshow how the relationship between right-hand sides can effect the performance\nof the method.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 12:22:23 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2013 09:50:43 GMT"}, {"version": "v3", "created": "Tue, 13 May 2014 13:29:05 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Soodhalter", "Kirk M.", ""]]}, {"id": "1301.2481", "submitter": "Hubert Karl Dr", "authors": "Hubert Karl, Sebstian Karl", "title": "Zur iterativen Loesung von linearen Gleichungssystemen", "comments": "15 pages, German, 1 figure, translation in work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that a fixed point iteration for solving a linear equation\nsystem converges if and only if the spectral radius of the iteration matrix is\nless than one. A method is presented which guarantees the Fixed Point, even if\nthis condition is not (\"spectral radius <1\") fulfilled and demonstrated through\ncalculation examples.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 12:53:14 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:08:24 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Karl", "Hubert", ""], ["Karl", "Sebstian", ""]]}, {"id": "1301.2650", "submitter": "Kirk Soodhalter", "authors": "Kirk M. Soodhalter and Daniel B. Szyld and Fei Xue", "title": "Krylov Subspace Recycling for Sequences of Shifted Linear Systems", "comments": "5 figures, 20 pages (main paper 18 pages + refs 2 pages)", "journal-ref": "Applied Numerical Mathematics 81C (2014), pp. 105-118", "doi": "10.1016/j.apnum.2014.02.006", "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of Krylov subspace recycling for the solution of a sequence\nof slowly-changing families of linear systems, where each family consists of\nshifted linear systems that differ in the coefficient matrix only by multiples\nof the identity. Our aim is to explore the simultaneous solution of each family\nof shifted systems within the framework of subspace recycling, using one\naugmented subspace to extract candidate solutions for all the shifted systems.\nThe ideal method would use the same augmented subspace for all systems and have\nfixed storage requirements, independent of the number of shifted systems per\nfamily. We show that a method satisfying both requirements cannot exist in this\nframework.\n  As an alternative, we introduce two schemes. One constructs a separate\ndeflation space for each shifted system but solves each family of shifted\nsystems simultaneously. The other builds only one recycled subspace and\nconstructs approximate corrections to the solutions of the shifted systems at\neach cycle of the iterative linear solver while only minimizing the base system\nresidual. At convergence of the base system solution, we apply the method\nrecursively to the remaining unconverged systems. We present numerical examples\ninvolving systems arising in lattice quantum chromodynamics.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 05:36:09 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 10:19:09 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2013 10:59:06 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Soodhalter", "Kirk M.", ""], ["Szyld", "Daniel B.", ""], ["Xue", "Fei", ""]]}, {"id": "1301.2707", "submitter": "Sou-Cheng Choi", "authors": "Sou-Cheng T. Choi and Michael A. Saunders", "title": "ALGORITHM 937: MINRES-QLP for Singular Symmetric and Hermitian Linear\n  Equations and Least-Squares Problems", "comments": "14 pages and 1 figure", "journal-ref": null, "doi": "10.1145/2527267", "report-no": null, "categories": "cs.MS cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe algorithm MINRES-QLP and its FORTRAN 90 implementation for\nsolving symmetric or Hermitian linear systems or least-squares problems. If the\nsystem is singular, MINRES-QLP computes the unique minimum-length solution\n(also known as the pseudoinverse solution), which generally eludes MINRES. In\nall cases, it overcomes a potential instability in the original MINRES\nalgorithm. A positive-definite preconditioner may be supplied. Our FORTRAN 90\nimplementation illustrates a design pattern that allows users to make problem\ndata known to the solver but hidden and secure from other program units. In\nparticular, we circumvent the need for reverse communication. While we focus\nhere on a FORTRAN 90 implementation, we also provide and maintain MATLAB\nversions of MINRES and MINRES-QLP.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 19:00:15 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2015 00:44:56 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Choi", "Sou-Cheng T.", ""], ["Saunders", "Michael A.", ""]]}, {"id": "1301.2866", "submitter": "Juan Galvis", "authors": "Yalchin Efendiev, Juan Galvis, Thomas Y. Hou", "title": "Generalized Multiscale Finite Element Methods (GMsFEM)", "comments": "Revised version", "journal-ref": null, "doi": "10.1016/j.jcp.2013.04.045", "report-no": null, "categories": "math.NA cs.CE cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a general approach called Generalized Multiscale\nFinite Element Method (GMsFEM) for performing multiscale simulations for\nproblems without scale separation over a complex input space. As in multiscale\nfinite element methods (MsFEMs), the main idea of the proposed approach is to\nconstruct a small dimensional local solution space that can be used to generate\nan efficient and accurate approximation to the multiscale solution with a\npotentially high dimensional input parameter space. In the proposed approach,\nwe present a general procedure to construct the offline space that is used for\na systematic enrichment of the coarse solution space in the online stage. The\nenrichment in the online stage is performed based on a spectral decomposition\nof the offline space. In the online stage, for any input parameter, a\nmultiscale space is constructed to solve the global problem on a coarse grid.\nThe online space is constructed via a spectral decomposition of the offline\nspace and by choosing the eigenvectors corresponding to the largest\neigenvalues. The computational saving is due to the fact that the construction\nof the online multiscale space for any input parameter is fast and this space\ncan be re-used for solving the forward problem with any forcing and boundary\ncondition. Compared with the other approaches where global snapshots are used,\nthe local approach that we present in this paper allows us to eliminate\nunnecessary degrees of freedom on a coarse-grid level. We present various\nexamples in the paper and some numerical results to demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 06:43:11 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2013 12:31:10 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Efendiev", "Yalchin", ""], ["Galvis", "Juan", ""], ["Hou", "Thomas Y.", ""]]}, {"id": "1301.3007", "submitter": "Dohy Hong", "authors": "Dohy Hong, Fabien Mathieu and G\\'erard Burnside", "title": "Convergence of the D-iteration algorithm: convergence rate and\n  asynchronous distributed scheme", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define the general framework to describe the diffusion\noperators associated to a positive matrix. We define the equations associated\nto diffusion operators and present some general properties of their state\nvectors. We show how this can be applied to prove and improve the convergence\nof a fixed point problem associated to the matrix iteration scheme, including\nfor distributed computation framework. The approach can be understood as a\ndecomposition of the matrix-vector product operation in elementary operations\nat the vector entry level.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 15:11:08 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Hong", "Dohy", ""], ["Mathieu", "Fabien", ""], ["Burnside", "G\u00e9rard", ""]]}, {"id": "1301.3389", "submitter": "Hugo Van hamme", "authors": "Hugo Van hamme", "title": "The Diagonalized Newton Algorithm for Nonnegative Matrix Factorization", "comments": "8 pages + references; International Conference on Learning\n  Representations, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) has become a popular machine learning\napproach to many problems in text mining, speech and image processing,\nbio-informatics and seismic data analysis to name a few. In NMF, a matrix of\nnon-negative data is approximated by the low-rank product of two matrices with\nnon-negative entries. In this paper, the approximation quality is measured by\nthe Kullback-Leibler divergence between the data and its low-rank\nreconstruction. The existence of the simple multiplicative update (MU)\nalgorithm for computing the matrix factors has contributed to the success of\nNMF. Despite the availability of algorithms showing faster convergence, MU\nremains popular due to its simplicity. In this paper, a diagonalized Newton\nalgorithm (DNA) is proposed showing faster convergence while the implementation\nremains simple and suitable for high-rank problems. The DNA algorithm is\napplied to various publicly available data sets, showing a substantial speed-up\non modern hardware.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 15:59:46 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2013 09:15:29 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Van hamme", "Hugo", ""]]}, {"id": "1301.3527", "submitter": "Vamsi Potluru", "authors": "Vamsi K. Potluru, Sergey M. Plis, Jonathan Le Roux, Barak A.\n  Pearlmutter, Vince D. Calhoun, Thomas P. Hayes", "title": "Block Coordinate Descent for Sparse NMF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has become a ubiquitous tool for data\nanalysis. An important variant is the sparse NMF problem which arises when we\nexplicitly require the learnt features to be sparse. A natural measure of\nsparsity is the L$_0$ norm, however its optimization is NP-hard. Mixed norms,\nsuch as L$_1$/L$_2$ measure, have been shown to model sparsity robustly, based\non intuitive attributes that such measures need to satisfy. This is in contrast\nto computationally cheaper alternatives such as the plain L$_1$ norm. However,\npresent algorithms designed for optimizing the mixed norm L$_1$/L$_2$ are slow\nand other formulations for sparse NMF have been proposed such as those based on\nL$_1$ and L$_0$ norms. Our proposed algorithm allows us to solve the mixed norm\nsparsity constraints while not sacrificing computation time. We present\nexperimental evidence on real-world datasets that shows our new algorithm\nperforms an order of magnitude faster compared to the current state-of-the-art\nsolvers optimizing the mixed norm and is suitable for large-scale datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 23:11:05 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2013 22:42:11 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Potluru", "Vamsi K.", ""], ["Plis", "Sergey M.", ""], ["Roux", "Jonathan Le", ""], ["Pearlmutter", "Barak A.", ""], ["Calhoun", "Vince D.", ""], ["Hayes", "Thomas P.", ""]]}, {"id": "1301.3584", "submitter": "Razvan Pascanu", "authors": "Razvan Pascanu and Yoshua Bengio", "title": "Revisiting Natural Gradient for Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate natural gradient, an algorithm originally proposed in Amari\n(1997), for learning deep models. The contributions of this paper are as\nfollows. We show the connection between natural gradient and three other\nrecently proposed methods for training deep models: Hessian-Free (Martens,\n2010), Krylov Subspace Descent (Vinyals and Povey, 2012) and TONGA (Le Roux et\nal., 2008). We describe how one can use unlabeled data to improve the\ngeneralization error obtained by natural gradient and empirically evaluate the\nrobustness of the algorithm to the ordering of the training set compared to\nstochastic gradient descent. Finally we extend natural gradient to incorporate\nsecond order information alongside the manifold information and provide a\nbenchmark of the new algorithm using a truncated Newton approach for inverting\nthe metric matrix instead of using a diagonal approximation of it.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 04:47:02 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 03:57:04 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2013 14:59:04 GMT"}, {"version": "v4", "created": "Wed, 13 Mar 2013 19:13:08 GMT"}, {"version": "v5", "created": "Fri, 20 Dec 2013 19:29:42 GMT"}, {"version": "v6", "created": "Tue, 7 Jan 2014 18:11:36 GMT"}, {"version": "v7", "created": "Mon, 17 Feb 2014 16:29:27 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Pascanu", "Razvan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.4438", "submitter": "Jean-Guillaume Dumas", "authors": "Jean-Guillaume Dumas (LJK), Cl\\'ement Pernet (INRIA Grenoble\n  Rh\\^one-Alpes / LIG Laboratoire d'Informatique de Grenoble), Ziad Sultan\n  (LJK, INRIA Grenoble Rh\\^one-Alpes / LIG Laboratoire d'Informatique de\n  Grenoble)", "title": "Simultaneous computation of the row and column rank profiles", "comments": null, "journal-ref": "ISSAC 2013, Boston, MA : \\'Etats-Unis (2013)", "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian elimination with full pivoting generates a PLUQ matrix\ndecomposition. Depending on the strategy used in the search for pivots, the\npermutation matrices can reveal some information about the row or the column\nrank profiles of the matrix. We propose a new pivoting strategy that makes it\npossible to recover at the same time both row and column rank profiles of the\ninput matrix and of any of its leading sub-matrices. We propose a\nrank-sensitive and quad-recursive algorithm that computes the latter PLUQ\ntriangular decomposition of an m \\times n matrix of rank r in O(mnr^{\\omega-2})\nfield operations, with \\omega the exponent of matrix multiplication. Compared\nto the LEU decomposition by Malashonock, sharing a similar recursive structure,\nits time complexity is rank sensitive and has a lower leading constant. Over a\nword size finite field, this algorithm also improveLs the practical efficiency\nof previously known implementations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 17:23:01 GMT"}], "update_date": "2013-05-21", "authors_parsed": [["Dumas", "Jean-Guillaume", "", "LJK"], ["Pernet", "Cl\u00e9ment", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LIG Laboratoire d'Informatique de Grenoble"], ["Sultan", "Ziad", "", "LJK, INRIA Grenoble Rh\u00f4ne-Alpes / LIG Laboratoire d'Informatique de\n  Grenoble"]]}, {"id": "1301.4749", "submitter": "Teruyoshi Washizawa", "authors": "Teruyoshi Washizawa", "title": "On the Behavior of the Residual in Conjugate Gradient Method", "comments": "8 pages", "journal-ref": "Applied Mathematics, vol.1, no.3, pp.211-214, 2010", "doi": "10.4236/am.2010.13025", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conjugate gradient method, it is well known that the recursively computed\nresidual differs from true one as the iteration proceeds in finite arithmetic.\nSome work have been devoted to analyze this be-havior and to evaluate the lower\nand the upper bounds of the difference. This paper focuses on the behavior of\nthese two kinds of residuals, especially their lower bounds caused by the loss\nof trailing digit, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 04:08:52 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Washizawa", "Teruyoshi", ""]]}, {"id": "1301.5412", "submitter": "Teruyoshi Washizawa", "authors": "Yuichiro Miki, Teruyoshi Washizawa", "title": "A2ILU: Auto-accelerated ILU Preconditioner for Sparse Linear Systems", "comments": "21 pages, 14 figures", "journal-ref": "SIAM Journal on Scientific Computing, Vol.35, No.2, pp.1212-1232,\n  2013", "doi": "10.1137/110842685", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ILU-based preconditioning methods in previous work have their own\nparameters to improve their performances. Although the parameters may degrade\nthe performance, their determination is left to users. Thus, these previous\nmethods are not reliable in practical computer-aided engineering use. This\npaper proposes a novel ILU-based preconditioner called the auto-accelerated\nILU, or A2ILU. In order to improve the convergence, A2ILU introduces\nacceleration parameters which modify the ILU factorized preconditioning matrix.\nA$^2$ILU needs no more operations than the original ILU because the\nacceleration parameters are optimized automatically by A2ILU itself. Numerical\ntests reveal the performance of A2ILU is superior to previous ILU-based methods\nwith manually optimized parameters. The numerical tests also demonstrate the\nability to apply auto-acceleration to ILU-based methods to improve their\nperformances and robustness of parameter sensitivities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 06:34:44 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2013 22:43:39 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Miki", "Yuichiro", ""], ["Washizawa", "Teruyoshi", ""]]}, {"id": "1301.5435", "submitter": "Shin Harase", "authors": "Shin Harase", "title": "On the $\\mathbb{F}_2$-linear relations of Mersenne Twister pseudorandom\n  number generators", "comments": "19 pages", "journal-ref": "Mathematics and Computers in Simulation, Volume 100, June 2014,\n  Pages 103-113", "doi": "10.1016/j.matcom.2014.02.002", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence generators obtained by linear recursions over the two-element field\n$\\mathbb{F}_2$, i.e., $\\mathbb{F}_2$-linear generators, are widely used as\npseudorandom number generators. For example, the Mersenne Twister MT19937 is\none of the most successful applications. An advantage of such generators is\nthat we can assess them quickly by using theoretical criteria, such as the\ndimension of equidistribution with $v$-bit accuracy. To compute these\ndimensions, several polynomial-time lattice reduction algorithms have been\nproposed in the case of $\\mathbb{F}_2$-linear generators.\n  In this paper, in order to assess non-random bit patterns in dimensions that\nare higher than the dimension of equidistribution with $v$-bit accuracy,we\nfocus on the relationship between points in the Couture--L'Ecuyer dual lattices\nand $\\mathbb{F}_2$-linear relations on the most significant $v$ bits of output\nsequences, and consider a new figure of merit $N_v$ based on the minimum weight\nof $\\mathbb{F}_2$-linear relations whose degrees are minimal for $v$. Next, we\nnumerically show that MT19937 has low-weight $\\mathbb{F}_2$-linear relations in\ndimensions higher than 623, and show that some output vectors with specific\nlags are rejected or have small $p$-values in the birthday spacings tests. We\nalso report that some variants of Mersenne Twister, such as WELL generators,\nare significantly improved from the perspective of $N_v$.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 08:53:13 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2013 13:43:30 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2013 16:45:33 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Harase", "Shin", ""]]}, {"id": "1301.5885", "submitter": "Weihua Geng", "authors": "Weihua Geng and Ferosh Jacob", "title": "A GPU-accelerated Direct-sum Boundary Integral Poisson-Boltzmann Solver", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2013.01.017", "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a GPU-accelerated direct-sum boundary integral\nmethod to solve the linear Poisson-Boltzmann (PB) equation. In our method, a\nwell-posed boundary integral formulation is used to ensure the fast convergence\nof Krylov subspace based linear algebraic solver such as the GMRES. The\nmolecular surfaces are discretized with flat triangles and centroid\ncollocation. To speed up our method, we take advantage of the parallel nature\nof the boundary integral formulation and parallelize the schemes within CUDA\nshared memory architecture on GPU. The schemes use only $11N+6N_c$\nsize-of-double device memory for a biomolecule with $N$ triangular surface\nelements and $N_c$ partial charges. Numerical tests of these schemes show\nwell-maintained accuracy and fast convergence. The GPU implementation using one\nGPU card (Nvidia Tesla M2070) achieves 120-150X speed-up to the implementation\nusing one CPU (Intel L5640 2.27GHz). With our approach, solving PB equations on\nwell-discretized molecular surfaces with up to 300,000 boundary elements will\ntake less than about 10 minutes, hence our approach is particularly suitable\nfor fast electrostatics computations on small to medium biomolecules.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 20:25:10 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Geng", "Weihua", ""], ["Jacob", "Ferosh", ""]]}, {"id": "1301.6330", "submitter": "Pierre Kerfriden", "authors": "Pierre Kerfriden, Juan Jos\\'e R\\'odenas Garc\\'ia (DIMM), St\\'ephane\n  Pierre-Alain Bordas", "title": "Certification of projection-based reduced order modelling in\n  computational homogenisation by the Constitutive Relation Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose upper and lower error bounding techniques for\nreduced order modelling applied to the computational homogenisation of random\ncomposites. The upper bound relies on the construction of a reduced model for\nthe stress field. Upon ensuring that the reduced stress satisfies the\nequilibrium in the finite element sense, the desired bounding property is\nobtained. The lower bound is obtained by defining a hierarchical enriched\nreduced model for the displacement. We show that the sharpness of both error\nestimates can be seamlessly controlled by adapting the parameters of the\ncorresponding reduced order model.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 07:29:19 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2013 12:44:47 GMT"}, {"version": "v3", "created": "Thu, 22 May 2014 20:21:02 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Kerfriden", "Pierre", "", "DIMM"], ["Garc\u00eda", "Juan Jos\u00e9 R\u00f3denas", "", "DIMM"], ["Bordas", "St\u00e9phane Pierre-Alain", ""]]}, {"id": "1301.6336", "submitter": "Yaron Lipman", "authors": "Yaron Lipman", "title": "Approximation of Polyhedral Surface Uniformization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a constructive approach for approximating the conformal map\n(uniformization) of a polyhedral surface to a canonical domain in the plane.\nThe main tool is a characterization of convex spaces of quasiconformal\nsimplicial maps and their approximation properties. As far as we are aware,\nthis is the first algorithm proved to approximate the uniformization of general\npolyhedral surfaces.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 09:35:33 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Lipman", "Yaron", ""]]}, {"id": "1301.6628", "submitter": "Aaron Sidford", "authors": "Jonathan A. Kelner, Lorenzo Orecchia, Aaron Sidford, Zeyuan Allen Zhu", "title": "A Simple, Combinatorial Algorithm for Solving SDD Systems in\n  Nearly-Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a simple combinatorial algorithm that solves\nsymmetric diagonally dominant (SDD) linear systems in nearly-linear time. It\nuses very little of the machinery that previously appeared to be necessary for\na such an algorithm. It does not require recursive preconditioning, spectral\nsparsification, or even the Chebyshev Method or Conjugate Gradient. After\nconstructing a \"nice\" spanning tree of a graph associated with the linear\nsystem, the entire algorithm consists of the repeated application of a simple\n(non-recursive) update rule, which it implements using a lightweight data\nstructure. The algorithm is numerically stable and can be implemented without\nthe increased bit-precision required by previous solvers. As such, the\nalgorithm has the fastest known running time under the standard unit-cost RAM\nmodel. We hope that the simplicity of the algorithm and the insights yielded by\nits analysis will be useful in both theory and practice.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 18:06:21 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Kelner", "Jonathan A.", ""], ["Orecchia", "Lorenzo", ""], ["Sidford", "Aaron", ""], ["Zhu", "Zeyuan Allen", ""]]}, {"id": "1301.7530", "submitter": "Pierre Gosselet", "authors": "Pierre Gosselet (LMT), Christian Rey (LMT), Julien Pebrel (LMT)", "title": "Total and selective reuse of Krylov subspaces for the resolution of\n  sequences of nonlinear structural problems", "comments": "International Journal for Numerical Methods in Engineering (2013) 24\n  pages", "journal-ref": null, "doi": "10.1002/nme.4441", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the definition and optimization of augmentation spaces\nfor faster convergence of the conjugate gradient method in the resolution of\nsequences of linear systems. Using advanced convergence results from the\nliterature, we present a procedure based on a selection of relevant\napproximations of the eigenspaces for extracting, selecting and reusing\ninformation from the Krylov subspaces generated by previous solutions in order\nto accelerate the current iteration. Assessments of the method are proposed in\nthe cases of both linear and nonlinear structural problems.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 07:50:11 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Gosselet", "Pierre", "", "LMT"], ["Rey", "Christian", "", "LMT"], ["Pebrel", "Julien", "", "LMT"]]}]