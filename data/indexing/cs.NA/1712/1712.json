[{"id": "1712.00233", "submitter": "Rafael Ballester-Ripoll", "authors": "Rafael Ballester-Ripoll, Enrique G. Paredes, Renato Pajarola", "title": "Sobol Tensor Trains for Global Sensitivity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sobol indices are a widespread quantitative measure for variance-based global\nsensitivity analysis, but computing and utilizing them remains challenging for\nhigh-dimensional systems. We propose the tensor train decomposition (TT) as a\nunified framework for surrogate modeling and global sensitivity analysis via\nSobol indices. We first overview several strategies to build a TT surrogate of\nthe unknown true model using either an adaptive sampling strategy or a\npredefined set of samples. We then introduce and derive the Sobol tensor train,\nwhich compactly represents the Sobol indices for all possible joint variable\ninteractions which are infeasible to compute and store explicitly. Our\nformulation allows efficient aggregation and subselection operations: we are\nable to obtain related indices (closed, total, and superset indices) at\nnegligible cost. Furthermore, we exploit an existing global optimization\nprocedure within the TT framework for variable selection and model analysis\ntasks. We demonstrate our algorithms with two analytical engineering models and\na parallel computing simulation data set.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 08:52:12 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Ballester-Ripoll", "Rafael", ""], ["Paredes", "Enrique G.", ""], ["Pajarola", "Renato", ""]]}, {"id": "1712.00369", "submitter": "Matthias Althoff", "authors": "Matthias Althoff", "title": "Reachability Analysis of Large Linear Systems with Uncertain Inputs in\n  the Krylov Subspace", "comments": null, "journal-ref": "in IEEE Transactions on Automatic Control, vol. 65, no. 2, pp.\n  477-492, Feb. 2020", "doi": "10.1109/TAC.2019.2906432.", "report-no": null, "categories": "math.NA cs.NA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One often wishes for the ability to formally analyze large-scale\nsystems---typically, however, one can either formally analyze a rather small\nsystem or informally analyze a large-scale system. This work tries to further\nclose this performance gap for reachability analysis of linear systems.\nReachability analysis can capture the whole set of possible solutions of a\ndynamic system and is thus used to prove that unsafe states are never reached;\nthis requires full consideration of arbitrarily varying uncertain inputs, since\nsensor noise or disturbances usually do not follow any patterns. We use Krylov\nmethods in this work to compute reachable sets for large-scale linear systems.\nWhile Krylov methods have been used before in reachability analysis, we\novercome the previous limitation that inputs must be (piecewise) constant. As a\nresult, we can compute reachable sets of systems with several thousand state\nvariables for bounded, but arbitrarily varying inputs.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 15:34:12 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 08:43:16 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Althoff", "Matthias", ""]]}, {"id": "1712.00379", "submitter": "Sarah Hamilton", "authors": "S.J. Hamilton, J.L. Mueller, and T.R. Santos", "title": "Robust Computation in 2D Absolute EIT (a-EIT) Using D-bar Methods with\n  the `exp' Approximation", "comments": "17 pages, 10 figures, 3 tables", "journal-ref": "Physiological Measurement, Volume 39, Number 6, 2018", "doi": "10.1088/1361-6579/aac8b1", "report-no": null, "categories": "math.AP cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Absolute images have important applications in medical Electrical\nImpedance Tomography (EIT) imaging, but the traditional minimization and\nstatistical based computations are very sensitive to modeling errors and noise.\nIn this paper, it is demonstrated that D-bar reconstruction methods for\nabsolute EIT are robust to such errors. Approach: The effects of errors in\ndomain shape and electrode placement on absolute images computed with 2D D-bar\nreconstruction algorithms are studied on experimental data. Main Results: It is\ndemonstrated with tank data from several EIT systems that these methods are\nquite robust to such modeling errors, and furthermore the artefacts arising\nfrom such modeling errors are similar to those occurring in classic\ntime-difference EIT imaging. Significance: This study is promising for clinical\napplications where absolute EIT images are desirable, but previously thought\nimpossible.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 15:55:59 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 21:59:36 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Hamilton", "S. J.", ""], ["Mueller", "J. L.", ""], ["Santos", "T. R.", ""]]}, {"id": "1712.00693", "submitter": "Steven Kast", "authors": "Steven M. Kast", "title": "An Introduction to Adjoints and Output Error Estimation in Computational\n  Fluid Dynamics", "comments": "87 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the use of adjoint vectors in Computational Fluid Dynamics\n(CFD) has seen a dramatic rise. Their utility in numerous applications,\nincluding design optimization, data assimilation, and mesh adaptation has\nsparked the interest of both researchers and practitioners alike. In many of\nthese fields, the concept of an adjoint is explained differently, with various\nnotations and motivations employed. Further complicating matters is the\nexistence of two seemingly different types of adjoints -- \"continuous\" and\n\"discrete\" -- as well as the more formal definition of adjoint operators\nemployed in linear algebra and functional analysis. These issues can make the\nfundamental concept of an adjoint difficult to pin down. In these notes, we\nhope to clarify some of the ideas surrounding adjoint vectors and to provide a\nuseful reference for both continuous and discrete adjoints alike. In\nparticular, we focus on the use of adjoints within the context of output-based\nmesh adaptation, where the goal is to achieve accuracy in a particular quantity\n(or \"output\") of interest by performing targeted adaptation of the\ncomputational mesh. While this is our application of interest, the ideas\ndiscussed here apply directly to design optimization, data assimilation, and\nmany other fields where adjoints are employed.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 01:53:40 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Kast", "Steven M.", ""]]}, {"id": "1712.00716", "submitter": "Qing Qu", "authors": "Qing Qu, Yuqian Zhang, Yonina C. Eldar, and John Wright", "title": "Convolutional Phase Retrieval via Gradient Descent", "comments": "64 pages , 9 figures, appeared in NeurIPS 2017. Accepted at IEEE\n  Transactions on Information Theory. This is the final (minor) update: fixed\n  typos and grammar issues", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.IT cs.NA math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convolutional phase retrieval problem, of recovering an unknown\nsignal $\\mathbf x \\in \\mathbb C^n $ from $m$ measurements consisting of the\nmagnitude of its cyclic convolution with a given kernel $\\mathbf a \\in \\mathbb\nC^m $. This model is motivated by applications such as channel estimation,\noptics, and underwater acoustic communication, where the signal of interest is\nacted on by a given channel/filter, and phase information is difficult or\nimpossible to acquire. We show that when $\\mathbf a$ is random and the number\nof observations $m$ is sufficiently large, with high probability $\\mathbf x$\ncan be efficiently recovered up to a global phase shift using a combination of\nspectral initialization and generalized gradient descent. The main challenge is\ncoping with dependencies in the measurement operator. We overcome this\nchallenge by using ideas from decoupling theory, suprema of chaos processes and\nthe restricted isometry property of random circulant matrices, and recent\nanalysis of alternating minimization methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 06:04:25 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 03:30:06 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 02:55:12 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Qu", "Qing", ""], ["Zhang", "Yuqian", ""], ["Eldar", "Yonina C.", ""], ["Wright", "John", ""]]}, {"id": "1712.00897", "submitter": "Benjamin Seibold", "authors": "Rodolfo Ruben Rosales, Benjamin Seibold, David Shirokoff, Dong Zhou", "title": "Spatial Manifestations of Order Reduction in Runge-Kutta Methods for\n  Initial Boundary Value Problems", "comments": "41 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the spatial manifestations of order reduction that occur\nwhen time-stepping initial-boundary-value problems (IBVPs) with high-order\nRunge-Kutta methods. For such IBVPs, geometric structures arise that do not\nhave an analog in ODE IVPs: boundary layers appear, induced by a mismatch\nbetween the approximation error in the interior and at the boundaries. To\nunderstand those boundary layers, an analysis of the modes of the numerical\nscheme is conducted, which explains under which circumstances boundary layers\npersist over many time steps. Based on this, two remedies to order reduction\nare studied: first, a new condition on the Butcher tableau, called weak stage\norder, that is compatible with diagonally implicit Runge-Kutta schemes; and\nsecond, the impact of modified boundary conditions on the boundary layer theory\nis analyzed.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 04:04:40 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 05:00:06 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Rosales", "Rodolfo Ruben", ""], ["Seibold", "Benjamin", ""], ["Shirokoff", "David", ""], ["Zhou", "Dong", ""]]}, {"id": "1712.01454", "submitter": "Shuaifang Zhang", "authors": "Shuaifang Zhang, Dongdong He, Dongsheng Li, Zhifeng Zhang, Yu Liu, Wei\n  Shen", "title": "Wave analysis in one dimensional structures with a wavelet finite\n  element model and precise integration method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical simulation of ultrasonic wave propagation provides an efficient\ntool for crack identification in structures, while it requires a high\nresolution and expensive time calculation cost in both time integration and\nspatial discretization. Wavelet finite element model provides a highorder\nfinite element model and gives a higher accuracy on spatial discretization,\nB-Spline wavelet interval (BSWI) has been proved to be one of the most commonly\nused wavelet finite element model with the advantage of getting the same\naccuracy but with fewer element so that the calculation cost is much lower than\ntraditional finite element method and other high-order element methods. Precise\nIntegration Method provides a higher resolution in time integration and has\nbeen proved to be a stable time integration method with a much lower cut-off\nerror for same and even smaller time step. In this paper, a wavelet finite\nelement model combined with precise integration method is presented for the\nnumerical simulation of ultrasonic wave propagation and crack identification in\n1D structures. Firstly, the wavelet finite element based on BSWI is constructed\nfor rod and beam structures. Then Precise Integrated Method is introduced with\napplication for the wave propagation in 1D structures. Finally, numerical\nexamples of ultrasonic wave propagation in rod and beam structures are\nconducted for verification. Moreover, crack identification in both rod and beam\nstructures are studied based on the new model.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 02:50:09 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Zhang", "Shuaifang", ""], ["He", "Dongdong", ""], ["Li", "Dongsheng", ""], ["Zhang", "Zhifeng", ""], ["Liu", "Yu", ""], ["Shen", "Wei", ""]]}, {"id": "1712.01633", "submitter": "Rafael Ballester-Ripoll", "authors": "Rafael Ballester-Ripoll, Enrique G. Paredes, Renato Pajarola", "title": "Tensor Approximation of Advanced Metrics for Sensitivity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following up on the success of the analysis of variance (ANOVA) decomposition\nand the Sobol indices (SI) for global sensitivity analysis, various related\nquantities of interest have been defined in the literature including the\neffective and mean dimensions, the dimension distribution, and the Shapley\nvalues. Such metrics combine up to exponential numbers of SI in different ways\nand can be of great aid in uncertainty quantification and model interpretation\ntasks, but are computationally challenging. We focus on surrogate based\nsensitivity analysis for independently distributed variables, namely via the\ntensor train (TT) decomposition. This format permits flexible and scalable\nsurrogate modeling and can efficiently extract all SI at once in a compressed\nTT representation of their own. Based on this, we contribute a range of novel\nalgorithms that compute more advanced sensitivity metrics by selecting and\naggregating certain subsets of SI in the tensor compressed domain. Drawing on\nan interpretation of the TT model in terms of deterministic finite automata, we\nare able to construct explicit auxiliary TT tensors that encode exactly all\nnecessary index selection masks. Having both the SI and the masks in the TT\nformat allows efficient computation of all aforementioned metrics, as we\ndemonstrate in a number of example models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 14:13:12 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Ballester-Ripoll", "Rafael", ""], ["Paredes", "Enrique G.", ""], ["Pajarola", "Renato", ""]]}, {"id": "1712.01975", "submitter": "Nand Sharma", "authors": "Nand Sharma, Prathamesh Verlekar, Rehab Ashary, Sui Zhiquan", "title": "Regularization and feature selection for large dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection has evolved to be an important step in several machine\nlearning paradigms. In domains like bio-informatics and text classification\nwhich involve data of high dimensions, feature selection can help in\ndrastically reducing the feature space. In cases where it is difficult or\ninfeasible to obtain sufficient number of training examples, feature selection\nhelps overcome the curse of dimensionality which in turn helps improve\nperformance of the classification algorithm. The focus of our research here are\nfive embedded feature selection methods which use either the ridge regression,\nor Lasso regression, or a combination of the two in the regularization part of\nthe optimization function. We evaluate five chosen methods on five large\ndimensional datasets and compare them on the parameters of sparsity and\ncorrelation in the datasets and their execution times.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 00:01:57 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 23:49:36 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 20:20:39 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Sharma", "Nand", ""], ["Verlekar", "Prathamesh", ""], ["Ashary", "Rehab", ""], ["Zhiquan", "Sui", ""]]}, {"id": "1712.02248", "submitter": "Gabriele Torre", "authors": "Gabriele Torre and Michael Graber", "title": "An Efficient Algorithm for Non-Negative Matrix Factorization with Random\n  Projections", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is one of the most popular\ndecomposition techniques for multivariate data. NMF is a core method for many\nmachine-learning related computational problems, such as data compression,\nfeature extraction, word embedding, recommender systems etc. In practice,\nhowever, its application is challenging for large datasets. The efficiency of\nNMF is constrained by long data loading times, by large memory requirements and\nby limited parallelization capabilities. Here we present a novel and efficient\ncompressed NMF algorithm. Our algorithm applies a random compression scheme to\ndrastically reduce the dimensionality of the problem, preserving well the\npairwise distances between data points and inherently limiting the memory and\ncommunication load. Our algorithm supersedes existing methods in speed.\nNonetheless, it matches the best non-compressed algorithms in reconstruction\nprecision.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 15:56:21 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Torre", "Gabriele", ""], ["Graber", "Michael", ""]]}, {"id": "1712.02260", "submitter": "Charles Pierre", "authors": "Yves Coudi\\`ere, Charlie Douanla Lontsi, Charles Pierre (LMAP)", "title": "Rush-Larsen time-stepping methods of high order for stiff problems in\n  cardiac electrophysiology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the issues of stability and accuracy for reaction-diffusion\nequations, the development of high order and stable time-stepping methods is\nnecessary. This is particularly true in the context of cardiac\nelectrophysiology, where reaction-diffusion equations are coupled with stiff\nODE systems. Many research have been led in that way in the past 15 years\nconcerning implicit-explicit methods and exponential integrators. In 2009,\nPerego and Veneziani proposed an innovative time-stepping method of order 2. In\nthis paper we present the extension of this method to the orders 3 and 4 and\nintroduce the Rush-Larsen schemes of order k (shortly denoted RL\\_k). The RL\\_k\nschemes are explicit multistep exponential integrators. They display a simple\ngeneral formulation and an easy implementation. The RL\\_k schemes are shown to\nbe stable under perturbation and convergent of order k. Their Dahlquist\nstability analysis is performed. They have a very large stability domain\nprovided that the stabilizer associated with the method captures well enough\nthe stiff modes of the problem. The RL\\_k method is numerically studied as\napplied to the membrane equation in cardiac electrophysiology. The RL k schemes\nare shown to be stable under perturbation and convergent oforder k. Their\nDahlquist stability analysis is performed. They have a very large stability\ndomain provided that the stabilizer associated with the method captures well\nenough the stiff modes of the problem. The RL k method is numerically studied\nas applied to the membrane equation in cardiac electrophysiology.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 16:19:25 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 14:48:52 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 14:52:50 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Coudi\u00e8re", "Yves", "", "LMAP"], ["Lontsi", "Charlie Douanla", "", "LMAP"], ["Pierre", "Charles", "", "LMAP"]]}, {"id": "1712.02657", "submitter": "Darren Engwirda", "authors": "Darren Engwirda", "title": "Generalised primal-dual grids for unstructured co-volume schemes", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2018.07.025", "report-no": null, "categories": "cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of high-quality staggered unstructured grids is considered,\nleading to the development of a new optimisation-based strategy designed to\nconstruct weighted `Regular-Power' tessellations appropriate for co-volume type\nnumerical discretisation techniques. This new framework aims to extend the\nconventional Delaunay-Voronoi primal-dual structure; seeking to assemble\ngeneralised orthogonal tessellations with enhanced geometric quality. The\nconstruction of these grids is motivated by the desire to improve the\nperformance and accuracy of numerical methods based on unstructured co-volume\ntype schemes, including various staggered grid techniques for the simulation of\nfluid dynamics and hyperbolic transport. In this study, a new hybrid\noptimisation strategy is proposed; seeking to optimise the geometry, topology\nand weights associated with general, two-dimensional Regular-Power\ntessellations using a combination of gradient-ascent and energy-based\ntechniques. The performance of this new method is tested experimentally, with a\nrange of complex, multi-resolution primal-dual grids generated for various\ncoastal and regional ocean modelling applications.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 17:56:05 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 22:19:15 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Engwirda", "Darren", ""]]}, {"id": "1712.03052", "submitter": "Huu Phuoc Bui", "authors": "Huu Phuoc Bui, Satyendra Tomar and St\\'ephane P.A. Bordas", "title": "Corotational Cut Finite Element Method for real-time surgical\n  simulation: application to needle insertion simulation", "comments": "25 pages, 25 figures", "journal-ref": null, "doi": "10.1016/j.cma.2018.10.023", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the use of the corotational cut Finite Element Method\n(FEM) for real-time surgical simulation. Users only need to provide a\nbackground mesh which is not necessarily conforming to the\nboundaries/interfaces of the simulated object. The details of the surface,\nwhich can be directly obtained from binary images, are taken into account by a\nmultilevel embedding algorithm applied to elements of the background mesh that\ncut by the surface. Boundary conditions can be implicitly imposed on the\nsurface using Lagrange multipliers. The implementation is verified by\nconvergence studies with optimal rates. The algorithm is applied to various\nneedle insertion simulations (e.g. for biopsy or brachytherapy) into brain and\nliver to verify the reliability of method, and numerical results show that the\npresent method can make the discretisation independent from geometric\ndescription, and can avoid the complexity of mesh generation of complex\ngeometries while retaining the accuracy of the standard FEM. Using the proposed\napproach is very suitable for real-time and patient specific simulations as it\nimproves the simulation accuracy by taking into account automatically and\nproperly the simulated geometry.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 13:22:30 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Bui", "Huu Phuoc", ""], ["Tomar", "Satyendra", ""], ["Bordas", "St\u00e9phane P. A.", ""]]}, {"id": "1712.03082", "submitter": "Robert Berman", "authors": "Robert J. Berman", "title": "The Sinkhorn algorithm, parabolic optimal transport and geometric\n  Monge-Amp\\`ere equations", "comments": "v3: Major revision; the general exposition has been improved and the\n  main results have been improved for smooth data (Section 5.4). 52 pages v4:\n  This is essentially the version that will appear in Numerische Mathematik", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the discrete Sinkhorn algorithm - as applied in the setting of\nOptimal Transport on a compact manifold - converges to the solution of a fully\nnon-linear parabolic PDE of Monge-Ampere type, in a large-scale limit. The\nlatter evolution equation has previously appeared in different contexts (e.g.\non the torus it can be be identified with the Ricci flow). This leads to\nalgorithmic approximations of the potential of the Optimal Transport map, as\nwell as the Optimal Transport distance, with explicit bounds on the arithmetic\ncomplexity of the construction and the approximation errors. As applications we\nobtain explicit schemes of nearly linear complexity, at each iteration, for\noptimal transport on the torus and the two-sphere, as well as the far-field\nantenna problem. Connections to Quasi-Monte Carlo methods are exploited.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 14:28:28 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 06:49:24 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 09:54:46 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 09:59:45 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Berman", "Robert J.", ""]]}, {"id": "1712.04389", "submitter": "Igor Ostanin A", "authors": "Igor Ostanin, George Ovchinnikov, Davi Colli Tozoni, Denis Zorin", "title": "A parameteric class of composites with a large achievable range of\n  effective elastic properties", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmps.2018.05.018", "report-no": null, "categories": "physics.comp-ph cs.NA math.NA physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate numerically an instance of the problem of\nG-closure for two-dimensional periodic metamaterials. Specifically, we consider\ncomposites with isotropic homogenized elasticity tensor, obtained as a mixture\nof two isotropic materials, focusing on the case of a single material with\nvoids. This problem is important, in particular, in the context of designing\nsmall-scale structures for metamaterials in the context of additive\nfabrication, as this type of metamaterials makes it possible to obtain a range\nof material properties using a single base material. We demonstrate that two\nclosely related simple parametric families based on the structure proposed by\nO. Sigmund attain good coverage of the space of isotropic properties satisfying\nHashin-Shtrikman bounds. In particular, for positive Poisson ratio, we\ndemonstrate that Hashin-Shtrikman bound can be approximated arbitrarily well,\nwithin limits imposed by numerical approximation: a strong evidence that these\nbounds are achievable in this case. For negative Poisson ratios, we numerically\nobtain a bound which we hypothesize to be close to optimal, at least for\nmetamaterials with rotational symmetries of a regular triangle tiling.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 16:55:16 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 09:20:02 GMT"}, {"version": "v3", "created": "Fri, 19 Jan 2018 21:48:11 GMT"}, {"version": "v4", "created": "Tue, 17 Sep 2019 16:59:23 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Ostanin", "Igor", ""], ["Ovchinnikov", "George", ""], ["Tozoni", "Davi Colli", ""], ["Zorin", "Denis", ""]]}, {"id": "1712.04523", "submitter": "Jun Wu", "authors": "Jun Wu", "title": "Continuous Optimization of Adaptive Quadtree Structures", "comments": "Solid and Physical Modeling - SPM 2018", "journal-ref": "Computer-Aided Design 102 (2018) 72-82", "doi": "10.1016/j.cad.2018.04.008", "report-no": null, "categories": "math.NA cs.CE cs.GR cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel continuous optimization method to the discrete problem of\nquadtree optimization. The optimization aims at achieving a quadtree structure\nwith the highest mechanical stiffness, where the edges in the quadtree are\ninterpreted as structural elements carrying mechanical loads. We formulate\nquadtree optimization as a continuous material distribution problem. The\ndiscrete design variables (i.e., to refine or not to refine) are replaced by\ncontinuous variables on multiple levels in the quadtree hierarchy. In discrete\nquadtree optimization, a cell is only eligible for refinement if its parent\ncell has been refined. We propose a continuous analogue to this dependency for\ncontinuous multi-level design variables, and integrate it in the iterative\noptimization process. Our results show that the continuously optimized quadtree\nstructures perform much stiffer than uniform patterns and the heuristically\noptimized counterparts. We demonstrate the use of adaptive structures as\nlightweight infill for 3D printed parts, where uniform geometric patterns have\nbeen typically used in practice.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 21:13:36 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 08:56:03 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Wu", "Jun", ""]]}, {"id": "1712.04667", "submitter": "Nikita Zhivotovskiy", "authors": "D. Belomestny, L. Iosipoi, Q. Paris, N. Zhivotovskiy", "title": "Empirical Variance Minimization with Applications in Variance Reduction\n  and Optimal Control", "comments": "31 pages, Quentin Paris added as an author, the paper is\n  significantly reworked and the title is changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of empirical minimization for variance-type functionals\nover functional classes. Sharp non-asymptotic bounds for the excess variance\nare derived under mild conditions. In particular, it is shown that under some\nrestrictions imposed on the functional class fast convergence rates can be\nachieved including the optimal non-parametric rates for expressive classes in\nthe non-Donsker regime under some additional assumptions. Our main applications\ninclude variance reduction and optimal control.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 09:09:09 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 12:59:51 GMT"}, {"version": "v3", "created": "Sat, 8 Dec 2018 09:55:24 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 17:32:56 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Belomestny", "D.", ""], ["Iosipoi", "L.", ""], ["Paris", "Q.", ""], ["Zhivotovskiy", "N.", ""]]}, {"id": "1712.04732", "submitter": "Davood Saffar Shamshirgar", "authors": "Davood Saffar Shamshirgar, Joar Bagge, Anna-Karin Tornberg", "title": "Fast Ewald summation for electrostatic potentials with arbitrary\n  periodicity", "comments": "45 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A unified treatment for fast and spectrally accurate evaluation of\nelectrostatic potentials subject to periodic boundary conditions in any or none\nof the three spatial dimensions is presented. Ewald decomposition is used to\nsplit the problem into a real-space and a Fourier-space part, and the FFT-based\nSpectral Ewald (SE) method is used to accelerate the computation of the latter.\nA key component in the unified treatment is an FFT-based solution technique for\nthe free-space Poisson problem in three, two or one dimensions, depending on\nthe number of non-periodic directions. The computational cost is furthermore\nreduced by employing an adaptive FFT for the doubly and singly periodic cases,\nallowing for different local upsampling factors. The SE method will always be\nmost efficient for the triply periodic case as the cost of computing FFTs will\nthen be the smallest, whereas the computational cost of the rest of the\nalgorithm is essentially independent of periodicity. We show that the cost of\nremoving periodic boundary conditions from one or two directions out of three\nwill only moderately increase the total runtime. Our comparisons also show that\nthe computational cost of the SE method in the free-space case is around four\ntimes that of the triply periodic case.\n  The Gaussian window function previously used in the SE method, is here\ncompared to a piecewise polynomial approximation of the Kaiser-Bessel window\nfunction. With a carefully tuned shape parameter that is selected based on an\nerror estimate for this new window function, runtimes for the SE method can be\nfurther reduced. Furthermore, we consider different methods for computing the\nforce, and compare the runtime of the SE method with that of the Fast Multipole\nMethod.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 12:21:53 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 16:00:18 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Shamshirgar", "Davood Saffar", ""], ["Bagge", "Joar", ""], ["Tornberg", "Anna-Karin", ""]]}, {"id": "1712.05171", "submitter": "Ren\\'e S{\\o}rensen", "authors": "R. B. S{\\o}rensen, D. M. Kim, J. J. Nielsen and P. Popovski", "title": "Analysis of Latency and MAC-layer Performance for Class A LoRaWAN", "comments": null, "journal-ref": "IEEE Wireless Communications Letters, vol. 6, no. 5, pp. 566-569,\n  Oct. 2017", "doi": "10.1109/LWC.2017.2716932", "report-no": null, "categories": "cs.NI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose analytical models that allow us to investigate the performance of\nlong range wide area network (LoRaWAN) uplink in terms of latency, collision\nrate, and throughput under the constraints of the regulatory duty cycling, when\nassuming exponential inter-arrival times. Our models take into account sub-band\nselection and the case of sub-band combining. Our numerical evaluations\nconsider specifically the European ISM band, but the analysis is applicable to\nany coherent band. Protocol simulations are used to validate the proposed\nmodels. We find that sub-band selection and combining have a large effect on\nthe quality of service (QoS) experienced in an LoRaWAN cell for a given load.\nThe proposed models allow for the optimization of resource allocation within a\ncell given a set of QoS requirements and a traffic model.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 11:06:43 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["S\u00f8rensen", "R. B.", ""], ["Kim", "D. M.", ""], ["Nielsen", "J. J.", ""], ["Popovski", "P.", ""]]}, {"id": "1712.05487", "submitter": "Ruben Becker", "authors": "Ruben Becker and Michael Sagraloff", "title": "Counting Solutions of a Polynomial System Locally and Exactly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a symbolic-numeric algorithm to count the number of solutions of a\npolynomial system within a local region. More specifically, given a\nzero-dimensional system $f_1=\\cdots=f_n=0$, with\n$f_i\\in\\mathbb{C}[x_1,\\ldots,x_n]$, and a polydisc\n$\\mathbf{\\Delta}\\subset\\mathbb{C}^n$, our method aims to certify the existence\nof $k$ solutions (counted with multiplicity) within the polydisc.\n  In case of success, it yields the correct result under guarantee. Otherwise,\nno information is given. However, we show that our algorithm always succeeds if\n$\\mathbf{\\Delta}$ is sufficiently small and well-isolating for a $k$-fold\nsolution $\\mathbf{z}$ of the system.\n  Our analysis of the algorithm further yields a bound on the size of the\npolydisc for which our algorithm succeeds under guarantee. This bound depends\non local parameters such as the size and multiplicity of $\\mathbf{z}$ as well\nas the distances between $\\mathbf{z}$ and all other solutions. Efficiency of\nour method stems from the fact that we reduce the problem of counting the roots\nin $\\mathbf{\\Delta}$ of the original system to the problem of solving a\ntruncated system of degree $k$. In particular, if the multiplicity $k$ of\n$\\mathbf{z}$ is small compared to the total degrees of the polynomials $f_i$,\nour method considerably improves upon known complete and certified methods.\n  For the special case of a bivariate system, we report on an implementation of\nour algorithm, and show experimentally that our algorithm leads to a\nsignificant improvement, when integrated as inclusion predicate into an\nelimination method.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 00:33:30 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Becker", "Ruben", ""], ["Sagraloff", "Michael", ""]]}, {"id": "1712.05559", "submitter": "Maokun Li", "authors": "Tao Shan, Wei Tang, Xunwang Dang, Maokun Li, Fan Yang, Shenheng Xu,\n  and Ji Wu", "title": "Study on a Poisson's Equation Solver Based On Deep Learning Technique", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigated the feasibility of applying deep learning\ntechniques to solve Poisson's equation. A deep convolutional neural network is\nset up to predict the distribution of electric potential in 2D or 3D cases.\nWith proper training data generated from a finite difference solver, the strong\napproximation capability of the deep convolutional neural network allows it to\nmake correct prediction given information of the source and distribution of\npermittivity. With applications of L2 regularization, numerical experiments\nshow that the predication error of 2D cases can reach below 1.5\\% and the\npredication of 3D cases can reach below 3\\%, with a significant reduction in\nCPU time compared with the traditional solver based on finite difference\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 06:51:47 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Shan", "Tao", ""], ["Tang", "Wei", ""], ["Dang", "Xunwang", ""], ["Li", "Maokun", ""], ["Yang", "Fan", ""], ["Xu", "Shenheng", ""], ["Wu", "Ji", ""]]}, {"id": "1712.05594", "submitter": "Uwe K\\\"ocher", "authors": "Uwe K\\\"ocher", "title": "Influence of the SIPG penalisation on the numerical properties of linear\n  systems for elastic wave propagation", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-96415-7_18", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interior penalty discontinuous Galerkin discretisations (IPDG) and especially\nthe symmetric variant (SIPG) for time-domain wave propagation problems are\nbroadly accepted and widely used due to their advantageous properties. Linear\nsystems with block structure arise by applying space-time discretisations and\nreducing the global system to time-slab problems. The design of efficient and\nrobust iterative solvers for linear systems from interior penalty\ndiscretisations for hyperbolic wave equations is still a challenging task and\nrelies on understanding the properties of the systems. In this work the\nnumerical properties such as the condition number and the distribution of\neigenvalues of different representations of the linear systems coming from\nspace-time discretisations for elastic wave propagation are numerically\nstudied. These properties for interior penalty discretisations depend on the\npenalisation and on the time interval length.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 09:44:34 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["K\u00f6cher", "Uwe", ""]]}, {"id": "1712.05717", "submitter": "Tim Sullivan", "authors": "H. C. Lie and T. J. Sullivan and A. L. Teckentrup", "title": "Random forward models and log-likelihoods in Bayesian inverse problems", "comments": "25 pages", "journal-ref": "ASA/SIAM Journal of Uncertainty Quantification (2018)", "doi": "10.1137/18M1166523", "report-no": null, "categories": "math.ST cs.NA math.NA math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the use of randomised forward models and log-likelihoods within\nthe Bayesian approach to inverse problems. Such random approximations to the\nexact forward model or log-likelihood arise naturally when a computationally\nexpensive model is approximated using a cheaper stochastic surrogate, as in\nGaussian process emulation (kriging), or in the field of probabilistic\nnumerical methods. We show that the Hellinger distance between the exact and\napproximate Bayesian posteriors is bounded by moments of the difference between\nthe true and approximate log-likelihoods. Example applications of these\nstability results are given for randomised misfit models in large data\napplications and the probabilistic solution of ordinary differential equations.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 15:39:26 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 10:08:59 GMT"}, {"version": "v3", "created": "Wed, 31 Jan 2018 14:16:50 GMT"}, {"version": "v4", "created": "Wed, 27 Jun 2018 10:53:11 GMT"}, {"version": "v5", "created": "Fri, 28 Sep 2018 09:02:26 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lie", "H. C.", ""], ["Sullivan", "T. J.", ""], ["Teckentrup", "A. L.", ""]]}, {"id": "1712.05742", "submitter": "Jos\\'e Henrique de Morais Goulart", "authors": "Jos\\'e Henrique de Morais Goulart, Pierre Comon", "title": "On the minimal ranks of matrix pencils and the existence of a best\n  approximate block-term tensor decomposition", "comments": "This work was supported by the European Research Council under the\n  European Programme FP7/2007-2013, Grant AdG-2013-320594 \"DECODA.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the action of the general linear group with tensor structure, the ranks\nof matrices $A$ and $B$ forming an $m \\times n$ pencil $A + \\lambda B$ can\nchange, but in a restricted manner. Specifically, with every pencil one can\nassociate a pair of minimal ranks, which is unique up to a permutation. This\nnotion can be defined for matrix pencils and, more generally, also for matrix\npolynomials of arbitrary degree. In this paper, we provide a formal definition\nof the minimal ranks, discuss its properties and the natural hierarchy it\ninduces in a pencil space. Then, we show how the minimal ranks of a pencil can\nbe determined from its Kronecker canonical form. For illustration, we classify\nthe orbits according to their minimal ranks (under the action of the general\nlinear group) in the case of real pencils with $m, n \\le 4$. Subsequently, we\nshow that real regular $2k \\times 2k$ pencils having only complex-valued\neigenvalues, which form an open positive-volume set, do not admit a best\napproximation (in the norm topology) on the set of real pencils whose minimal\nranks are bounded by $2k-1$. Our results can be interpreted from a tensor\nviewpoint, where the minimal ranks of a degree-$(d-1)$ matrix polynomial\ncharacterize the minimal ranks of matrices constituting a block-term\ndecomposition of an $m \\times n \\times d$ tensor into a sum of matrix-vector\ntensor products.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 16:40:23 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 15:31:46 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Goulart", "Jos\u00e9 Henrique de Morais", ""], ["Comon", "Pierre", ""]]}, {"id": "1712.05870", "submitter": "Tai-Xiang Jiang", "authors": "Tai-Xiang Jiang, Ting-Zhu Huang, Xi-Le Zhao, and Liang-Jian Deng", "title": "Multi-dimensional imaging data recovery via minimizing the partial sum\n  of tubal nuclear norm", "comments": null, "journal-ref": null, "doi": "10.1016/j.cam.2019.112680", "report-no": null, "categories": "cs.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate tensor recovery problems within the tensor\nsingular value decomposition (t-SVD) framework. We propose the partial sum of\nthe tubal nuclear norm (PSTNN) of a tensor. The PSTNN is a surrogate of the\ntensor tubal multi-rank. We build two PSTNN-based minimization models for two\ntypical tensor recovery problems, i.e., the tensor completion and the tensor\nprincipal component analysis. We give two algorithms based on the alternating\ndirection method of multipliers (ADMM) to solve proposed PSTNN-based tensor\nrecovery models. Experimental results on the synthetic data and real-world data\nreveal the superior of the proposed PSTNN.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 22:51:13 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 17:40:15 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 08:12:53 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Jiang", "Tai-Xiang", ""], ["Huang", "Ting-Zhu", ""], ["Zhao", "Xi-Le", ""], ["Deng", "Liang-Jian", ""]]}, {"id": "1712.06017", "submitter": "Svetlana Matculevich", "authors": "Ulrich Langer, Svetlana Matculevich, and Sergey Repin", "title": "Guaranteed error control bounds for the stabilised space-time IgA\n  approximations to parabolic problems", "comments": "24 pages, 15 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is concerned with space-time IgA approximations of parabolic\ninitial-boundary value problems. We deduce guaranteed and fully computable\nerror bounds adapted to special features of IgA approximations and investigate\ntheir applicability. The derivation method is based on the analysis of\nrespective integral identities and purely functional arguments. Therefore, the\nestimates do not contain mesh-dependent constants and are valid for any\napproximation from the admissible (energy) class. In particular, they provide\ncomputable error bounds for norms associated with stabilised space-time IgA\napproximations as well as imply efficient error indicators enhancing the\nperformance of fully adaptive solvers. The last section of the paper contains a\nseries of numerical examples where approximate solutions are recovered by IgA\ntechniques. The mesh refinement algorithm is governed by a local error\nindicator generated by the error majorant. Numerical results discussed in the\nlast section illustrate both reliability, as well as the quantitative\nefficiency of the error estimates presented.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 20:45:10 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 13:57:41 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Langer", "Ulrich", ""], ["Matculevich", "Svetlana", ""], ["Repin", "Sergey", ""]]}, {"id": "1712.06173", "submitter": "Antonio Huerta Prof.", "authors": "Ruben Sevilla, Matteo Giacomini and Antonio Huerta", "title": "A face-centred finite volume method for second-order elliptic problems", "comments": "43 pages, 33 figures, 3 tables", "journal-ref": "Int. J. Numer. Methods Eng., Vol. 115, Issue 8, pp. 986-1014\n  (2018)", "doi": "10.1002/nme.5833", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel finite volume paradigm, the face-centred finite\nvolume (FCFV) method. Contrary to the popular vertex (VCFV) and cell (CCFV)\ncentred finite volume methods, the novel FCFV defines the solution on the mesh\nfaces (edges in 2D) to construct locally-conservative numerical schemes.\n  The idea of the FCFV method stems from a hybridisable discontinuous Galerkin\n(HDG) formulation with constant degree of approximation, thus inheriting the\nconvergence properties of the classical HDG. The resulting FCFV features a\nglobal problem in terms of a piecewise constant function defined on the faces\nof the mesh. The solution and its gradient in each element are then recovered\nby solving a set of independent element-by-element problems.\n  The mathematical formulation of FCFV for Poisson and Stokes equation is\nderived and numerical evidence of optimal convergence in 2D and 3D is provided.\nNumerical examples are presented to illustrate the accuracy, efficiency and\nrobustness of the proposed methodology. The results show that, contrary to\nother FV methods, the accuracy of the FCFV method is not sensitive to mesh\ndistortion and stretching. In addition, the FCFV method shows its better\nperformance, accuracy and robustness using simplicial elements, facilitating\nits application to problems involving complex geometries in 3D.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 20:08:52 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Sevilla", "Ruben", ""], ["Giacomini", "Matteo", ""], ["Huerta", "Antonio", ""]]}, {"id": "1712.06221", "submitter": "Bruno Louren\\c{c}o", "authors": "Bruno F. Louren\\c{c}o", "title": "Amenable cones: error bounds without constraint qualifications", "comments": "36 pages, 1 figure. This version was significantly revised. A\n  discussion on the relation between amenability and related concepts was\n  added. In particular, there is a proof that amenable cones are nice and,\n  therefore, facially exposed. Also, gathered the results on symmetric cones in\n  a single section. Several typos and minor issues were fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a framework for obtaining error bounds for linear conic problems\nwithout assuming constraint qualifications or regularity conditions. The key\naspects of our approach are the notions of amenable cones and facial residual\nfunctions. For amenable cones, it is shown that error bounds can be expressed\nas a composition of facial residual functions. The number of compositions is\nrelated to the facial reduction technique and the singularity degree of the\nproblem. In particular, we show that symmetric cones are amenable and compute\nfacial residual functions. From that, we are able to furnish a new H\\\"olderian\nerror bound, thus extending and shedding new light on an earlier result by\nSturm on semidefinite matrices. We also provide error bounds for the\nintersection of amenable cones, this will be used to provided error bounds for\nthe doubly nonnegative cone.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 01:54:44 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 22:28:52 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Louren\u00e7o", "Bruno F.", ""]]}, {"id": "1712.06251", "submitter": "Shuaifang Zhang", "authors": "Shuaifang Zhang, Dongsheng Li, Wei Shen, Xiwen Zhang, Yu Liu", "title": "Crack detection in beam structures with a novel Laplace based Wavelet\n  Finite Element method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam structure is one of the most widely used structures in mechanical\nengineering and civil engineering. Ultrasonic guided wave based crack\nidentification is one of the most important and accepted approaches applied to\ndetect unseen small flaws in structures. Numerical simulations of ultrasonic\nguided wave propagation have caught more and more attention due to the fast\ndevelopment of hardware and software in the last few years. From all the\nnumerical simulation methods, wavelet based finite element method has been\nproved to be one of the most efficient methods due to its better spatial\nresolution, which means it needs fewer elements to get the same accuracy and it\ncan improve the calculation cost significantly. However, it needs a very small\ntime interval. Laplace transform can easily convert the time domain into a\nfrequency domain and then revert it back to a time domain. Laplace transform\nhas thus the advantage of finding better results with a very large time\ninterval. which can save a lot of time cost. This paper will present an\ninnovative method combining Laplace transform and the B-spline wavelet on\ninterval (BSWI) finite element method. This novel method allows to get results\nwith the same accuracy and with a significantly lower time cost, which would\nnot only decrease the total number of elements in the structure but also\nincrease the time integration interval. The numerical Laplace transform and\nBSWI finite element will be introduced. Moreover, this innovative method is\napplied to simulate the ultrasonic wave propagation in a beam structure in\ndifferent materials. Numerical examples for crack identification in beam\nstructures have been studied for verification.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 05:16:37 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Zhang", "Shuaifang", ""], ["Li", "Dongsheng", ""], ["Shen", "Wei", ""], ["Zhang", "Xiwen", ""], ["Liu", "Yu", ""]]}, {"id": "1712.06782", "submitter": "Alexander Gilbert", "authors": "Alexander D. Gilbert, Frances Y. Kuo, Dirk Nuyens and Grzegorz W.\n  Wasilkowski", "title": "Efficient implementations of the Multivariate Decomposition Method for\n  approximating infinite-variate integrals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on efficient implementations of the Multivariate\nDecomposition Method (MDM) for approximating integrals of $\\infty$-variate\nfunctions. Such $\\infty$-variate integrals occur for example as expectations in\nuncertainty quantification. Starting with the anchored decomposition $f =\n\\sum_{\\mathfrak{u}\\subset\\mathbb{N}} f_\\mathfrak{u}$, where the sum is over all\nfinite subsets of $\\mathbb{N}$ and each $f_\\mathfrak{u}$ depends only on the\nvariables $x_j$ with $j\\in\\mathfrak{u}$, our MDM algorithm approximates the\nintegral of $f$ by first truncating the sum to some `active set' and then\napproximating the integral of the remaining functions $f_\\mathfrak{u}$\nterm-by-term using Smolyak or (randomized) quasi-Monte Carlo (QMC) quadratures.\nThe anchored decomposition allows us to compute $f_\\mathfrak{u}$ explicitly by\nfunction evaluations of $f$. Given the specification of the active set and\ntheoretically derived parameters of the quadrature rules, we exploit structures\nin both the formula for computing $f_\\mathfrak{u}$ and the quadrature rules to\ndevelop computationally efficient strategies to implement the MDM in various\nscenarios. In particular, we avoid repeated function evaluations at the same\npoint. We provide numerical results for a test function to demonstrate the\neffectiveness of the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 05:08:50 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 06:27:22 GMT"}, {"version": "v3", "created": "Fri, 3 Aug 2018 02:07:06 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Gilbert", "Alexander D.", ""], ["Kuo", "Frances Y.", ""], ["Nuyens", "Dirk", ""], ["Wasilkowski", "Grzegorz W.", ""]]}, {"id": "1712.06959", "submitter": "Vadim Zaliva", "authors": "Vadim Zaliva", "title": "Constructing an orthonormal set of eigenvectors for DFT matrix using\n  Gramians and determinants", "comments": "includes Mathematica code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constructing an orthogonal set of eigenvectors for a DFT\nmatrix is well studied. An elegant solution is mentioned by Matveev in his\npaper \"Interwining relations between the Fourier transfom and discrete Fourier\ntransform, the related functional identities and beyond\". In this paper, we\npresent a distilled form of his solution including some steps unexplained in\nhis paper, along with correction of typos and errors using more consistent\nnotation. Then we compare the computational complexity of his method with the\nmore traditional method involving direct application of the Gram-Schmidt\nprocess. Finally, we present our implementation of Matveev's method as a\nMathematica module.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 18:03:12 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Zaliva", "Vadim", ""]]}, {"id": "1712.07223", "submitter": "Dimitrios Loukrezis", "authors": "Dimitrios Loukrezis, Ulrich R\\\"omer, and Herbert De Gersem", "title": "Assessing the Performance of Leja and Clenshaw-Curtis Collocation for\n  Computational Electromagnetics with Random Input Data", "comments": "27 pages, 11 figures, 2 tables", "journal-ref": null, "doi": "10.1615/Int.J.UncertaintyQuantification.2018025234", "report-no": null, "categories": "cs.CE cs.NA math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of quantifying uncertainty regarding the output of an\nelectromagnetic field problem in the presence of a large number of uncertain\ninput parameters. In order to reduce the growth in complexity with the number\nof dimensions, we employ a dimension-adaptive stochastic collocation method\nbased on nested univariate nodes. We examine the accuracy and performance of\ncollocation schemes based on Clenshaw-Curtis and Leja rules, for the cases of\nuniform and bounded, non-uniform random inputs, respectively. Based on\nnumerical experiments with an academic electromagnetic field model, we compare\nthe two rules in both the univariate and multivariate case and for both\nquadrature and interpolation purposes. Results for a real-world electromagnetic\nfield application featuring high-dimensional input uncertainty are also\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 21:28:26 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 08:07:20 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Loukrezis", "Dimitrios", ""], ["R\u00f6mer", "Ulrich", ""], ["De Gersem", "Herbert", ""]]}, {"id": "1712.07297", "submitter": "Chao Chen", "authors": "Chao Chen, Hadi Pouransari, Sivasankaran Rajamanickam, Erik G. Boman,\n  Eric Darve", "title": "A distributed-memory hierarchical solver for general sparse linear\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel hierarchical solver for general sparse linear systems\non distributed-memory machines. For large-scale problems, this fully algebraic\nalgorithm is faster and more memory-efficient than sparse direct solvers\nbecause it exploits the low-rank structure of fill-in blocks. Depending on the\naccuracy of low-rank approximations, the hierarchical solver can be used either\nas a direct solver or as a preconditioner. The parallel algorithm is based on\ndata decomposition and requires only local communication for updating boundary\ndata on every processor. Moreover, the computation-to-communication ratio of\nthe parallel algorithm is approximately the volume-to-surface-area ratio of the\nsubdomain owned by every processor. We present various numerical results to\ndemonstrate the versatility and scalability of the parallel algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 02:54:20 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Chen", "Chao", ""], ["Pouransari", "Hadi", ""], ["Rajamanickam", "Sivasankaran", ""], ["Boman", "Erik G.", ""], ["Darve", "Eric", ""]]}, {"id": "1712.07309", "submitter": "James Van Zandt", "authors": "James R. Van Zandt", "title": "Efficient Cubature Rules", "comments": "26 pages, 4 figures, 95 supplemental files. The 10 point rule for\n  E_2^{r^2} was known, but had not been published. It was found by Jankewitz\n  (private communication to R. Cools, 1998). Both the 15 and 16 point formulas\n  of degree 4 for the sphere in 4 dimensions are new, and different from the 16\n  point formula found by Mysovskih", "journal-ref": "Electronic Transactions on Numerical Analysis, vol 51, pp 219-239,\n  2019", "doi": "10.1553/etna_vol51s219", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  73 new cubature rules are found for three standard multidimensional integrals\nwith spherically symmetric regions and weights, using direct search with a\nnumerical zero-finder. All but four of the new rules have fewer integration\npoints than known rules of the same degree, and twenty are within three points\nof M{\\\"o}ller's lower bound. Most have all positive coefficients and most have\nsome symmetry, including some supported by one or two concentric spheres. They\ninclude degree 7 formulas for integration over the sphere and Gaussian-weighted\nintegrals over all space, each in 6 and 7 dimensions, with 127 and 183 points,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 03:26:30 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 01:05:54 GMT"}, {"version": "v3", "created": "Sun, 16 Jun 2019 02:12:08 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Van Zandt", "James R.", ""]]}, {"id": "1712.08286", "submitter": "Matthew Knepley", "authors": "Jonas Actor and Matthew G. Knepley", "title": "An Algorithm for Computing Lipschitz Inner Functions in Kolmogorov's\n  Superposition Theorem", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kolmogorov famously proved that multivariate continuous functions can be\nrepresented as a superposition of a small number of univariate continuous\nfunctions, $$ f(x_1,\\dots,x_n) = \\sum_{q=0}^{2n+1} \\chi^q \\left( \\sum_{p=1}^n\n\\psi^{pq}(x_p) \\right).$$ Fridman \\cite{fridman} posed the best smoothness\nbound for the functions $\\psi^{pq}$, that such functions can be constructed to\nbe Lipschitz continuous with constant 1. Previous algorithms to describe these\ninner functions have only been H\\\"older continuous, such as those proposed by\nK\\\"oppen and Braun and Griebel. This is problematic, as pointed out by Griebel,\nin that non-smooth functions have very high storage/evaluation complexity, and\nthis makes Kolmogorov's representation (KR) impractical using the standard\ndefinition of the inner functions.\n  To date, no one has presented a method to compute a Lipschitz continuous\ninner function. In this paper, we revisit Kolmogorov's theorem along with\nFridman's result. We examine a simple Lipschitz function which appear to\nsatisfy the necessary criteria for Kolmogorov's representation, but fails in\nthe limit. We then present a full solution to the problem, including an\nalgorithm that computes such a Lipschitz function.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 02:39:20 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Actor", "Jonas", ""], ["Knepley", "Matthew G.", ""]]}, {"id": "1712.08447", "submitter": "Christian Himpe", "authors": "Peter Benner, Christian Himpe, Tim Mitchell", "title": "On Reduced Input-Output Dynamic Mode Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of reduced-order models from high-dimensional data is a\nchallenging task, and even more so if the identified system should not only be\nsuitable for a certain data set, but generally approximate the input-output\nbehavior of the data source. In this work, we consider the input-output dynamic\nmode decomposition method for system identification. We compare excitation\napproaches for the data-driven identification process and describe an\noptimization-based stabilization strategy for the identified systems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 14:02:43 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Benner", "Peter", ""], ["Himpe", "Christian", ""], ["Mitchell", "Tim", ""]]}, {"id": "1712.08560", "submitter": "Ihor Sirenko", "authors": "O. Stelia, L. Potapenko, I. Sirenko", "title": "Monotone Difference Schemes for Convection-Dominated Diffusion-Reaction\n  Equations Based on Quadratic Spline", "comments": "8 pp., 1 fig", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A three-point monotone difference scheme is proposed for solving a\none-dimensional non-stationary convection-diffusion-reaction equation with\nvariable coefficients. The scheme is based on a parabolic spline and allows to\nlinearly reproduce the numerical solution of the boundary value problem over\nthe integral segment in the form of the function which continuous with its\nfirst derivative. The constructed difference scheme give a highly effective\ntool for solving problems with a small parameter at the older derivative in a\nwide range of output data of the problem. In the test case, numerical and exact\nsolutions of the problem are compared with the significant dominance of the\nconvective term of the equation over the diffusion. Numerous calculations\nshowed the high efficiency of the new monotonous scheme developed.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 16:39:40 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Stelia", "O.", ""], ["Potapenko", "L.", ""], ["Sirenko", "I.", ""]]}, {"id": "1712.09379", "submitter": "Anastasios Kyrillidis", "authors": "Rajiv Khanna and Anastasios Kyrillidis", "title": "IHT dies hard: Provable accelerated Iterative Hard Thresholding", "comments": "accepted to AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study --both in theory and practice-- the use of momentum motions in\nclassic iterative hard thresholding (IHT) methods. By simply modifying plain\nIHT, we investigate its convergence behavior on convex optimization criteria\nwith non-convex constraints, under standard assumptions. In diverse scenaria,\nwe observe that acceleration in IHT leads to significant improvements, compared\nto state of the art projected gradient descent and Frank-Wolfe variants. As a\nbyproduct of our inspection, we study the impact of selecting the momentum\nparameter: similar to convex settings, two modes of behavior are observed\n--\"rippling\" and linear-- depending on the level of momentum.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 19:40:47 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 18:01:30 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Khanna", "Rajiv", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "1712.09472", "submitter": "Varun Jain", "authors": "Varun Jain, Yi Zhang, Artur Palha, Marc Gerritsma", "title": "Construction and application of algebraic dual polynomial\n  representations for finite element methods on quadrilateral and hexahedral\n  meshes", "comments": "This is version5 of this article", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sequence of finite element spaces which form a de Rham sequence, we\nwill construct a dual representation of these spaces with associated\ndifferential operators which connect these spaces such that they also form a de\nRham sequence. The matrix which converts primal representations to dual\nrepresentations -- the Hodge matrix -- is the mass or Gram matrix. It will be\nshown that a bilinear form of a primal and a dual representation is equal to\nthe vector inner product of the expansion coefficients (degrees of freedom) of\nboth representations. This leads to very sparse system matrices, even for high\norder methods. The derivative of dual representations will be defined. Vector\noperations, grad, curl and div, for primal and dual representations are both\ntopological and do not depend on the metric, i.e. the size and shape of the\nmesh or the order of the numerical method. Derivatives are evaluated by\napplying sparse incidence and inclusion matrices to the expansion coefficients\nof the representations. As illustration of the use of dual representations, the\nmethod will be applied to i) a mixed formulation for the Poisson problem in 3D,\nii) it will be shown that this approach allows one to preserve the equivalence\nbetween Dirichlet and Neumann problems in the finite dimensional setting and,\niii) the method will be applied to the approximation of grad-div eigenvalue\nproblem on affine and non-affine meshes.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 01:12:38 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 13:07:05 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 18:21:51 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 13:01:20 GMT"}, {"version": "v5", "created": "Tue, 29 Sep 2020 07:30:50 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Jain", "Varun", ""], ["Zhang", "Yi", ""], ["Palha", "Artur", ""], ["Gerritsma", "Marc", ""]]}, {"id": "1712.09677", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Peter Richt\\'arik", "title": "Momentum and Stochastic Momentum for Stochastic Gradient, Newton,\n  Proximal Point and Subspace Descent Methods", "comments": "47 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study several classes of stochastic optimization algorithms\nenriched with heavy ball momentum. Among the methods studied are: stochastic\ngradient descent, stochastic Newton, stochastic proximal point and stochastic\ndual subspace ascent. This is the first time momentum variants of several of\nthese methods are studied. We choose to perform our analysis in a setting in\nwhich all of the above methods are equivalent. We prove global nonassymptotic\nlinear convergence rates for all methods and various measures of success,\nincluding primal function values, primal iterates (in L2 sense), and dual\nfunction values. We also show that the primal iterates converge at an\naccelerated linear rate in the L1 sense. This is the first time a linear rate\nis shown for the stochastic heavy ball method (i.e., stochastic gradient\ndescent method with momentum). Under somewhat weaker conditions, we establish a\nsublinear convergence rate for Cesaro averages of primal iterates. Moreover, we\npropose a novel concept, which we call stochastic momentum, aimed at decreasing\nthe cost of performing the momentum step. We prove linear convergence of\nseveral stochastic methods with stochastic momentum, and show that in some\nsparse data regimes and for sufficiently small momentum parameters, these\nmethods enjoy better overall complexity than methods with deterministic\nmomentum. Finally, we perform extensive numerical testing on artificial and\nreal datasets, including data coming from average consensus problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 20:40:24 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 18:14:11 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1712.09952", "submitter": "Joanna Piotrowska", "authors": "Joanna Piotrowska, Jonah M. Miller, Erik Schnetter", "title": "Spectral Methods in the Presence of Discontinuities", "comments": "20 pages, 18 figures", "journal-ref": "Journal of Computational Physics 390 (2019) 527-547", "doi": "10.1016/j.jcp.2019.03.048", "report-no": "LA-UR-17-31492", "categories": "cs.NA gr-qc physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral methods provide an elegant and efficient way of numerically solving\ndifferential equations of all kinds. For smooth problems, truncation error for\nspectral methods vanishes exponentially in the infinity norm and $L_2$-norm.\nHowever, for non-smooth problems, convergence is significantly worse---the\n$L_2$-norm of the error for a discontinuous problem will converge at a\nsub-linear rate and the infinity norm will not converge at all. We explore and\nimprove upon a post-processing technique---optimally convergent mollifiers---to\nrecover exponential convergence from a poorly-converging spectral\nreconstruction of non-smooth data. This is an important first step towards\nusing these techniques for simulations of realistic systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 17:48:30 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 14:17:39 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Piotrowska", "Joanna", ""], ["Miller", "Jonah M.", ""], ["Schnetter", "Erik", ""]]}, {"id": "1712.09999", "submitter": "Jonathan Jiang", "authors": "Jonathan Q. Jiang and Michael K. Ng", "title": "Parallel Active Subspace Decomposition for Scalable and Efficient Tensor\n  Robust Principal Component Analysis", "comments": "19 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor robust principal component analysis (TRPCA) has received a substantial\namount of attention in various fields. Most existing methods, normally relying\non tensor nuclear norm minimization, need to pay an expensive computational\ncost due to multiple singular value decompositions (SVDs) at each iteration. To\novercome the drawback, we propose a scalable and efficient method, named\nParallel Active Subspace Decomposition (PASD), which divides the unfolding\nalong each mode of the tensor into a columnwise orthonormal matrix (active\nsubspace) and another small-size matrix in parallel. Such a transformation\nleads to a nonconvex optimization problem in which the scale of nulcear norm\nminimization is generally much smaller than that in the original problem.\nFurthermore, we introduce an alternating direction method of multipliers (ADMM)\nmethod to solve the reformulated problem and provide rigorous analyses for its\nconvergence and suboptimality. Experimental results on synthetic and real-world\ndata show that our algorithm is more accurate than the state-of-the-art\napproaches, and is orders of magnitude faster.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 18:56:04 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Jiang", "Jonathan Q.", ""], ["Ng", "Michael K.", ""]]}, {"id": "1712.10230", "submitter": "Anton Shterenlikht", "authors": "Anton Shterenlikht", "title": "On quality of implementation of Fortran 2008 complex intrinsic functions\n  on branch cuts", "comments": "28 pages, 10 figures, 13 tables, original work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branch cuts in complex functions in combination with signed zero and signed\ninfinity have important uses in fracture mechanics, jet flow and aerofoil\nanalysis. We present benchmarks for validating Fortran 2008 complex functions -\nLOG, SQRT, ASIN, ACOS, ATAN, ASINH, ACOSH and ATANH - on branch cuts with\narguments of all 3 IEEE floating point binary formats: binary32, binary64 and\nbinary128. Results are reported with 8 Fortran 2008 compilers: GCC, Flang,\nCray, Oracle, PGI, Intel, NAG and IBM. Multiple test failures were revealed,\ne.g. wrong signs of results or unexpected overflow, underflow, or NaN. We\nconclude that the quality of implementation of these Fortran 2008 intrinsics in\nmany compilers is not yet sufficient to remove the need for special code for\nbranch cuts. The test results are complemented by conformal maps of the branch\ncuts and detailed derivations of the values of these functions on branch cuts,\nto be used as a reference. The benchmarks are freely available from\ncmplx.sf.net. This work will be of interest to engineers who use complex\nfunctions, as well as to compiler and maths library developers.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 13:53:03 GMT"}], "update_date": "2018-01-05", "authors_parsed": [["Shterenlikht", "Anton", ""]]}]