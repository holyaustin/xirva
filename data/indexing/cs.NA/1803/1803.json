[{"id": "1803.00043", "submitter": "Jeffrey Hokanson", "authors": "Jeffrey M. Hokanson", "title": "A Data-Driven McMillan Degree Lower Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given measurements of a linear time-invariant system, the McMillan degree is\nthe dimension of the smallest such system that reproduces these observed\ndynamics. Using impulse response measurements where the system has been started\nin some (unknown) state and then allowed to evolve freely, a classical result\nby Ho and Kalman reveals the McMillan degree as the rank of a Hankel matrix\nbuilt from these measurements. However, if measurements are contaminated by\nnoise, this Hankel matrix will almost surely be full rank. Hence practitioners\noften estimate the rank of this matrix---and thus the McMillan degree---by\nmanually setting a threshold between the large singular values that correspond\nto the non-zero singular values of the noise-free Hankel matrix and the small\nsingular values that are pertubations of the zero singular values. Here we\nintroduce a probabilistic upper bound on the perturbation of the singular\nvalues of this Hankel matrix when measurements are corrupted by additive\nGaussian noise, and hence provide guidance on setting the threshold to obtain a\nlower bound on the McMillan degree. This result is powered by a new,\nprobabilistic bound on the 2-norm of a random Hankel matrix with normally\ndistributed entries. Unlike existing results for random Hankel matrices, this\nbound features no unknown constants and, moreover, is within a small factor of\nthe empirically observed bound when entries are independent and identically\ndistributed. This bound on the McMillan degree provides an inexpensive\nalternative to more general model order selection techniques such as the Akaike\nInformation Criteria (AIC).\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 19:25:16 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 20:41:03 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Hokanson", "Jeffrey M.", ""]]}, {"id": "1803.00092", "submitter": "Markus Haltmeier", "authors": "Housen Li, Johannes Schwab, Stephan Antholzer, Markus Haltmeier", "title": "NETT: Solving Inverse Problems with Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering a function or high-dimensional parameter vector from indirect\nmeasurements is a central task in various scientific areas. Several methods for\nsolving such inverse problems are well developed and well understood. Recently,\nnovel algorithms using deep learning and neural networks for inverse problems\nappeared. While still in their infancy, these techniques show astonishing\nperformance for applications like low-dose CT or various sparse data problems.\nHowever, there are few theoretical results for deep learning in inverse\nproblems. In this paper, we establish a complete convergence analysis for the\nproposed NETT (Network Tikhonov) approach to inverse problems. NETT considers\ndata consistent solutions having small value of a regularizer defined by a\ntrained neural network. We derive well-posedness results and quantitative error\nestimates, and propose a possible strategy for training the regularizer. Our\ntheoretical results and framework are different from any previous work using\nneural networks for solving inverse problems. A possible data driven\nregularizer is proposed. Numerical results are presented for a tomographic\nsparse data problem, which demonstrate good performance of NETT even for\nunknowns of different type from the training data. To derive the convergence\nand convergence rates results we introduce a new framework based on the\nabsolute Bregman distance generalizing the standard Bregman distance from the\nconvex to the non-convex case.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 21:23:22 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 10:39:04 GMT"}, {"version": "v3", "created": "Sun, 8 Dec 2019 17:13:50 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Li", "Housen", ""], ["Schwab", "Johannes", ""], ["Antholzer", "Stephan", ""], ["Haltmeier", "Markus", ""]]}, {"id": "1803.00192", "submitter": "Bang Liu", "authors": "Bang Liu, Borislav Mavrin, Linglong Kong, Di Niu", "title": "Recover Fine-Grained Spatial Data from Coarse Aggregation", "comments": "Accepted by ICDM 2017, 6 pages", "journal-ref": null, "doi": "10.1109/ICDM.2017.122", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a new type of spatial sparse recovery problem, that\nis to infer the fine-grained spatial distribution of certain density data in a\nregion only based on the aggregate observations recorded for each of its\nsubregions. One typical example of this spatial sparse recovery problem is to\ninfer spatial distribution of cellphone activities based on aggregate mobile\ntraffic volumes observed at sparsely scattered base stations. We propose a\nnovel Constrained Spatial Smoothing (CSS) approach, which exploits the local\ncontinuity that exists in many types of spatial data to perform sparse recovery\nvia finite-element methods, while enforcing the aggregated observation\nconstraints through an innovative use of the ADMM algorithm. We also improve\nthe approach to further utilize additional geographical attributes. Extensive\nevaluations based on a large dataset of phone call records and a demographical\ndataset from the city of Milan show that our approach significantly outperforms\nvarious state-of-the-art approaches, including Spatial Spline Regression (SSR).\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:30:24 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Liu", "Bang", ""], ["Mavrin", "Borislav", ""], ["Kong", "Linglong", ""], ["Niu", "Di", ""]]}, {"id": "1803.00204", "submitter": "Chen Wang", "authors": "Chen Wang, Xiaomei Yang, Shaomin Fei, Kai Zhou, Xiaofeng Gong, Miao\n  Du, Ruisen Luo", "title": "Scalar Quantization as Sparse Least Square Optimization", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2019", "doi": "10.1109/TPAMI.2019.2952096", "report-no": null, "categories": "cs.LG cs.AI cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quantization can be used to form new vectors/matrices with shared values\nclose to the original. In recent years, the popularity of scalar quantization\nfor value-sharing applications has been soaring as it has been found huge\nutilities in reducing the complexity of neural networks. Existing\nclustering-based quantization techniques, while being well-developed, have\nmultiple drawbacks including the dependency of the random seed, empty or\nout-of-the-range clusters, and high time complexity for a large number of\nclusters. To overcome these problems, in this paper, the problem of scalar\nquantization is examined from a new perspective, namely sparse least square\noptimization. Specifically, inspired by the property of sparse least square\nregression, several quantization algorithms based on $l_1$ least square are\nproposed. In addition, similar schemes with $l_1 + l_2$ and $l_0$\nregularization are proposed. Furthermore, to compute quantization results with\na given amount of values/clusters, this paper designed an iterative method and\na clustering-based method, and both of them are built on sparse least square.\nThe paper shows that the latter method is mathematically equivalent to an\nimproved version of k-means clustering-based quantization algorithm, although\nthe two algorithms originated from different intuitions. The algorithms\nproposed were tested with three types of data and their computational\nperformances, including information loss, time consumption, and the\ndistribution of the values of the sparse vectors, were compared and analyzed.\nThe paper offers a new perspective to probe the area of quantization, and the\nalgorithms proposed can outperform existing methods especially under some\nbit-width reduction scenarios, when the required post-quantization resolution\n(number of values) is not significantly lower than the original number.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:07:40 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 16:24:26 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 17:32:25 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 04:12:41 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Wang", "Chen", ""], ["Yang", "Xiaomei", ""], ["Fei", "Shaomin", ""], ["Zhou", "Kai", ""], ["Gong", "Xiaofeng", ""], ["Du", "Miao", ""], ["Luo", "Ruisen", ""]]}, {"id": "1803.00269", "submitter": "Moein Khalighi", "authors": "Moein Khalighi, Mohammad Amirian Matlob, Alaeddin Malek", "title": "A new approach to solving multi-order fractional equations using BEM and\n  Chebyshev matrix", "comments": null, "journal-ref": null, "doi": "10.1002/mma.6352", "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the boundary element method is combined with Chebyshev\noperational matrix technique to solve two-dimensional multi-order\ntime-fractional partial differential equations; nonlinear and linear in respect\nto spatial and temporal variables, respectively. Fractional derivatives are\nestimated by Caputo sense. Boundary element method is used to convert the main\nproblem into a system of a multi-order fractional ordinary differential\nequation. Then, the produced system is approximated by Chebyshev operational\nmatrix technique, ans its condition number is analyzed. Accuracy and efficiency\nof the proposed hybrid scheme are demonstrated by solving three different types\nof two-dimensional time fractional convection-diffusion equations numerically.\nThe convergent rates are calculated for different meshing within the boundary\nelement technique. Numerical results are given by graphs and tables for\nsolutions and different type of error norms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 09:33:15 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 07:26:32 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 12:15:49 GMT"}, {"version": "v4", "created": "Fri, 16 Aug 2019 15:05:15 GMT"}, {"version": "v5", "created": "Mon, 17 Feb 2020 10:21:25 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Khalighi", "Moein", ""], ["Matlob", "Mohammad Amirian", ""], ["Malek", "Alaeddin", ""]]}, {"id": "1803.00423", "submitter": "Antoine Tambue", "authors": "Jean Daniel Mukam, Antoine Tambue", "title": "Strong Convergence of a Stochastic Rosenbrock-type Scheme for the Finite\n  Element Discretization of Semilinear SPDEs Driven by Multiplicative and\n  Additive Noise", "comments": "arXiv admin note: text overlap with arXiv:1710.01386", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to investigate the numerical approximation of a general\nsecond order parabolic stochastic partial differential equation(SPDE) driven by\nmultiplicative and additive noise. Our main interest is on such SPDEs where the\nnonlinear part is stronger than the linear part, usually called stochastic\ndominated transport equations. Most standard numerical schemes lose their good\nstability properties on such equations, including the current linear implicit\nEuler method. We discretise the SPDE in space by the finite element method and\npropose a new scheme in time appropriate for such equations, called stochastic\nRosenbrock-Type scheme, which is based on the local linearisation of the\nsemi-discrete problem obtained after space discretisation. We provide a strong\nconvergence of the new fully discrete scheme toward the exact solution for\nmultiplicative and additive noise. Our convergence rates are in agreement with\nresults in the literature. Numerical experiments to sustain our theoretical\nresults are provided.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 12:13:17 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 19:13:40 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Mukam", "Jean Daniel", ""], ["Tambue", "Antoine", ""]]}, {"id": "1803.00785", "submitter": "Robert Berman", "authors": "Robert J. Berman", "title": "Convergence rates for discretized Monge-Amp\\`ere equations and\n  quantitative stability of optimal transport", "comments": "v1: 25 pages. v2: Improved exposition (32 pages); this version will\n  appear in Foundations of Computational Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.AP math.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent works - both experimental and theoretical - it has been shown how\nto use computational geometry to efficently construct approximations to the\noptimal transport map between two given probability measures on Euclidean\nspace, by discretizing one of the measures. Here we provide a quantative\nconvergence analysis for the solutions of the corresponding discretized\nMonge-Amp\\`ere equations. This yields L^{2}-converge rates, in terms of the\ncorresponding spatial resolution h, of the discrete approximations of the\noptimal transport map, when the source measure is discretized and the target\nmeasure has bounded convex support. Periodic variants of the results are also\nestablished. The proofs are based on quantitative stability results for optimal\ntransport maps, shown using complex geometry.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 09:56:59 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 09:06:48 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Berman", "Robert J.", ""]]}, {"id": "1803.00862", "submitter": "Thomas Lundgaard Hansen", "authors": "Thomas Lundgaard Hansen and Tobias Lindstr{\\o}m Jensen", "title": "A Fast Interior Point Method for Atomic Norm Soft Thresholding", "comments": "31 pages, accepted for publication in Elsevier Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The atomic norm provides a generalization of the $\\ell_1$-norm to continuous\nparameter spaces. When applied as a sparse regularizer for line spectral\nestimation the solution can be obtained by solving a convex optimization\nproblem. This problem is known as atomic norm soft thresholding (AST). It can\nbe cast as a semidefinite program and solved by standard methods. In the\nsemidefinite formulation there are $O(N^2)$ dual variables which complicates\nthe implementation of a standard primal-dual interior-point method based on\nsymmetric cones. That has lead researcher to consider alternating direction\nmethod of multipliers (ADMM) for the solution of AST, but this method is still\nsomewhat slow for large problem sizes. To obtain a faster algorithm we\nreformulate AST as a non-symmetric conic program. That has two properties of\nkey importance to its numerical solution: the conic formulation has only $O(N)$\ndual variables and the Toeplitz structure inherent to AST is preserved. Based\non it we derive FastAST which is a primal-dual interior point method for\nsolving AST. Two variants are considered with the fastest one requiring only\n$O(N^2)$ flops per iteration. Extensive numerical experiments demonstrate that\nFastAST solves AST significantly faster than a state-of-the-art solver based on\nADMM.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 14:24:51 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 19:37:22 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hansen", "Thomas Lundgaard", ""], ["Jensen", "Tobias Lindstr\u00f8m", ""]]}, {"id": "1803.01419", "submitter": "Nina Golyandina", "authors": "N. Zvonarev and N. Golyandina", "title": "Image space projection for low-rank signal estimation: Modified\n  Gauss-Newton method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is devoted to the solution of a weighted nonlinear least-squares\nproblem for low-rank signal estimation, which is related to Hankel structured\nlow-rank approximation problems. A modified weighted Gauss-Newton method, which\nuses projecting on the image space of the signal, is proposed to solve this\nproblem. The advantage of the proposed method is the possibility of its\nnumerically stable and fast implementation. For a weight matrix, which\ncorresponds to an autoregressive process of order $p$, the computational cost\nof iterations is $O(N r^2 + N p^2 + r N \\log N)$, where $N$ is the time series\nlength, $r$ is the rank of the approximating time series. For developing the\nmethod, some useful properties of the space of time series of rank $r$ are\nstudied. The method is compared with state-of-the-art methods based on the\nvariable projection approach in terms of numerical stability, accuracy and\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 20:55:47 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 16:23:35 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 21:36:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zvonarev", "N.", ""], ["Golyandina", "N.", ""]]}, {"id": "1803.01619", "submitter": "Jens Markus Melenk", "authors": "Jens Markus Melenk and Stefan Sauter", "title": "Wavenumber-explicit $hp$-FEM analysis for Maxwell's equations with\n  transparent boundary conditions", "comments": null, "journal-ref": null, "doi": "10.1007/s10208-020-09452-1", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time-harmonic Maxwell equations at high wavenumber $k$ are discretized by\nedge elements of degree $p$ on a mesh of width $h$. For the case of a ball and\nexact, transparent boundary conditions, we show quasi-optimality of the\nGalerkin method under the $k$-explicit scale resolution condition that a)\n$kh/p$ is sufficient small and b) $p/\\log k$ is bounded from below.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 11:54:32 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 09:52:14 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 14:52:08 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Melenk", "Jens Markus", ""], ["Sauter", "Stefan", ""]]}, {"id": "1803.01982", "submitter": "Yuehua Feng", "authors": "Yuehua Feng, Jianwei Xiao, Ming Gu", "title": "Low-Rank Matrix Approximations with Flip-Flop Spectrum-Revealing QR\n  Factorization", "comments": null, "journal-ref": "Electronic Transactions on Numerical Analysis, 2019, 51: 469-494", "doi": "10.1553/etna_vol51s469", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Flip-Flop Spectrum-Revealing QR (Flip-Flop SRQR) factorization, a\nsignificantly faster and more reliable variant of the QLP factorization of\nStewart, for low-rank matrix approximations. Flip-Flop SRQR uses SRQR\nfactorization to initialize a partial column pivoted QR factorization and then\ncompute a partial LQ factorization. As observed by Stewart in his original QLP\nwork, Flip-Flop SRQR tracks the exact singular values with \"considerable\nfidelity\". We develop singular value lower bounds and residual error upper\nbounds for Flip-Flop SRQR factorization. In situations where singular values of\nthe input matrix decay relatively quickly, the low-rank approximation computed\nby SRQR is guaranteed to be as accurate as truncated SVD. We also perform a\ncomplexity analysis to show that for the same accuracy, Flip-Flop SRQR is\nfaster than randomized subspace iteration for approximating the SVD, the\nstandard method used in Matlab tensor toolbox. We also compare Flip-Flop SRQR\nwith alternatives on two applications, tensor approximation and nuclear norm\nminimization, to demonstrate its efficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 01:52:31 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 23:56:58 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Feng", "Yuehua", ""], ["Xiao", "Jianwei", ""], ["Gu", "Ming", ""]]}, {"id": "1803.02143", "submitter": "Lukas Einkemmer", "authors": "Lukas Einkemmer", "title": "A comparison of semi-Lagrangian discontinuous Galerkin and spline based\n  Vlasov solvers in four dimensions", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2018.10.012", "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the present paper is to compare two semi-Lagrangian methods in\nthe context of the four-dimensional Vlasov--Poisson equation. More\nspecifically, our goal is to compare the performance of the more recently\ndeveloped semi-Lagrangian discontinuous Galerkin scheme with the de facto\nstandard in Eulerian Vlasov simulation (i.e. using cubic spline interpolation).\nTo that end, we perform simulations for nonlinear Landau damping and a\ntwo-stream instability and provide benchmarks for the SeLaLib and sldg codes\n(both on a workstation and using MPI on a cluster).\n  We find that the semi-Lagrangian discontinuous Galerkin scheme shows a\nmoderate improvement in run time for nonlinear Landau damping and a substantial\nimprovement for the two-stream instability. It should be emphasized that these\nresults are markedly different from results obtained in the asymptotic regime\n(which favor spline interpolation). Thus, we conclude that the traditional\napproach of evaluating numerical methods is misleading, even for short time\nsimulations. In addition, the absence of any All-to-All communication in the\nsemi-Lagrangian discontinuous Galerkin method gives it a decisive advantage for\nscaling to more than 256 cores.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 12:41:23 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Einkemmer", "Lukas", ""]]}, {"id": "1803.02235", "submitter": "Stefan Steinerberger", "authors": "Stefan Steinerberger", "title": "Generalized Designs on Graphs: Sampling, Spectra, Symmetries", "comments": "to appear in Journal of Graph Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.NA math.FA math.NA math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical Designs are finite sets of points on the sphere $\\mathbb{S}^{d}$\nwith the property that the average of certain (low-degree) polynomials in these\npoints coincides with the global average of the polynomial on $\\mathbb{S}^{d}$.\nThey are evenly distributed and often exhibit a great degree of regularity and\nsymmetry. We point out that a spectral definition of spherical designs easily\ntransfers to finite graphs -- these 'graphical designs' are subsets of vertices\nthat are evenly spaced and capture the symmetries of the underlying graph\n(should they exist). Our main result states that good graphical designs either\nconsist of many vertices or their neighborhoods have exponential volume growth.\nWe show several examples, describe ways to find them and discuss problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 15:00:59 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 23:37:38 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 11:58:39 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Steinerberger", "Stefan", ""]]}, {"id": "1803.02386", "submitter": "Diego Armando Rueda G\\'omez", "authors": "F. Guill\\'en-Gonz\\'alez, M. A. Rodr\\'iguez-Bellido and D. A.\n  Rueda-G\\'omez", "title": "Study of a chemo-repulsion model with quadratic production. Part I:\n  Analysis of the continuous problem and time-discrete numerical schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a chemo-repulsion model with quadratic production in a bounded\ndomain. Firstly, we obtain global in time weak solutions, and give a regularity\ncriterion (which is satisfied for $1D$ and $2D$ domains) to deduce uniqueness\nand global regularity. After, we study two cell-conservative and\nunconditionally energy-stable first-order time schemes: a (nonlinear and\npositive) Backward Euler scheme and a linearized coupled version, proving\nsolvability, convergence towards weak solutions and error estimates. In\nparticular, the linear scheme does not preserve positivity and the uniqueness\nof the nonlinear scheme is proved assuming small time step with respect to a\nstrong norm of the discrete solution. This hypothesis is reduced to small time\nstep in $nD$ domains ($n\\le 2$) where global in time strong estimates are\nproved. Finally, we show the behavior of the schemes through some numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 19:11:39 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 20:54:13 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Guill\u00e9n-Gonz\u00e1lez", "F.", ""], ["Rodr\u00edguez-Bellido", "M. A.", ""], ["Rueda-G\u00f3mez", "D. A.", ""]]}, {"id": "1803.02391", "submitter": "Diego Armando Rueda G\\'omez", "authors": "F. Guill\\'en-Gonz\\'alez, M. A. Rodr\\'iguez-Bellido and D. A.\n  Rueda-G\\'omez", "title": "Study of a chemo-repulsion model with quadratic production. Part II:\n  Analysis of an unconditional energy-stable fully discrete scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is devoted to the study of a fully discrete scheme for a repulsive\nchemotaxis with quadratic production model. By following the ideas presented in\n[Guilen-Gonzalez et al], we introduce an auxiliary variable (the gradient of\nthe chemical concentration), and prove that the corresponding Finite Element\n(FE) backward Euler scheme is conservative and unconditionally energy-stable.\nAdditionally, we also study some properties like solvability, a priori\nestimates, convergence towards weak solutions and error estimates. On the other\nhand, we propose two linear iterative methods to approach the nonlinear scheme:\nan energy-stable Picard method and Newton's method. We prove solvability and\nconvergence of both methods towards the nonlinear scheme. Finally, we provide\nsome numerical results in agreement with our theoretical analysis with respect\nto the error estimates.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 19:23:18 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 21:10:51 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Guill\u00e9n-Gonz\u00e1lez", "F.", ""], ["Rodr\u00edguez-Bellido", "M. A.", ""], ["Rueda-G\u00f3mez", "D. A.", ""]]}, {"id": "1803.02481", "submitter": "Luke Olson", "authors": "Andrew Reisner, Luke N. Olson, J. David Moulton", "title": "Scaling Structured Multigrid to 500K+ Cores through Coarse-Grid\n  Redistribution", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": "Los Alamos Report LA-UR-17-22886", "categories": "cs.MS cs.NA cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient solution of sparse, linear systems resulting from the\ndiscretization of partial differential equations is crucial to the performance\nof many physics-based simulations. The algorithmic optimality of multilevel\napproaches for common discretizations makes them a good candidate for an\nefficient parallel solver. Yet, modern architectures for high-performance\ncomputing systems continue to challenge the parallel scalability of multilevel\nsolvers. While algebraic multigrid methods are robust for solving a variety of\nproblems, the increasing importance of data locality and cost of data movement\nin modern architectures motivates the need to carefully exploit structure in\nthe problem.\n  Robust logically structured variational multigrid methods, such as Black Box\nMultigrid (BoxMG), maintain structure throughout the multigrid hierarchy. This\navoids indirection and increased coarse-grid communication costs typical in\nparallel algebraic multigrid. Nevertheless, the parallel scalability of\nstructured multigrid is challenged by coarse-grid problems where the overhead\nin communication dominates computation. In this paper, an algorithm is\nintroduced for redistributing coarse-grid problems through incremental\nagglomeration. Guided by a predictive performance model, this algorithm\nprovides robust redistribution decisions for structured multilevel solvers.\n  A two-dimensional diffusion problem is used to demonstrate the significant\ngain in performance of this algorithm over the previous approach that used\nagglomeration to one processor. In addition, the parallel scalability of this\napproach is demonstrated on two large-scale computing systems, with solves on\nup to 500K+ cores.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 23:57:38 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Reisner", "Andrew", ""], ["Olson", "Luke N.", ""], ["Moulton", "J. David", ""]]}, {"id": "1803.02602", "submitter": "Oleg Balabanov", "authors": "Oleg Balabanov and Anthony Nouy", "title": "Randomized linear algebra for model reduction. Part I: Galerkin methods\n  and error estimation", "comments": "Published version. Supplementary material is attached", "journal-ref": "Adv Comput Math 45, 2969-3019 (2019)", "doi": "10.1007/s10444-019-09725-6", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic way for reducing the cost of classical\nprojection-based model order reduction methods for parameter-dependent linear\nequations. A reduced order model is here approximated from its random sketch,\nwhich is a set of low-dimensional random projections of the reduced\napproximation space and the spaces of associated residuals. This approach\nexploits the fact that the residuals associated with approximations in\nlow-dimensional spaces are also contained in low-dimensional spaces. We provide\nconditions on the dimension of the random sketch for the resulting reduced\norder model to be quasi-optimal with high probability. Our approach can be used\nfor reducing both complexity and memory requirements. The provided algorithms\nare well suited for any modern computational environment. Major operations,\nexcept solving linear systems of equations, are embarrassingly parallel. Our\nversion of proper orthogonal decomposition can be computed on multiple\nworkstations with a communication cost independent of the dimension of the full\norder model. The reduced order model can even be constructed in a so-called\nstreaming environment, i.e., under extreme memory constraints. In addition, we\nprovide an efficient way for estimating the error of the reduced order model,\nwhich is not only more efficient than the classical approach but is also less\nsensitive to round-off errors. Finally, the methodology is validated on\nbenchmark problems.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 11:25:12 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 13:27:29 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 17:16:34 GMT"}, {"version": "v4", "created": "Thu, 31 Oct 2019 13:10:25 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Balabanov", "Oleg", ""], ["Nouy", "Anthony", ""]]}, {"id": "1803.02661", "submitter": "Haim Avron", "authors": "Liron Mor-Yosef and Haim Avron", "title": "Sketching for Principal Component Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component regression (PCR) is a useful method for regularizing\nlinear regression. Although conceptually simple, straightforward\nimplementations of PCR have high computational costs and so are inappropriate\nwhen learning with large scale data. In this paper, we propose efficient\nalgorithms for computing approximate PCR solutions that are, on one hand, high\nquality approximations to the true PCR solutions (when viewed as minimizer of a\nconstrained optimization problem), and on the other hand entertain rigorous\nrisk bounds (when viewed as statistical estimators). In particular, we propose\nan input sparsity time algorithms for approximate PCR. We also consider\ncomputing an approximate PCR in the streaming model, and kernel PCR. Empirical\nresults demonstrate the excellent performance of our proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 14:09:10 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 07:45:19 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Mor-Yosef", "Liron", ""], ["Avron", "Haim", ""]]}, {"id": "1803.02848", "submitter": "Dirk Lorenz", "authors": "Dirk A. Lorenz, Sean Rose, Frank Sch\\\"opfer", "title": "The Randomized Kaczmarz Method with Mismatched Adjoint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the randomized version of the Kaczmarz method to\nsolve linear systems in the case where the adjoint of the system matrix is not\nexact---a situation we refer to as \"mismatched adjoint\". We show that the\nmethod may still converge both in the over- and underdetermined consistent case\nunder appropriate conditions, and we calculate the expected asymptotic rate of\nlinear convergence. Moreover, we analyze the inconsistent case and obtain\nresults for the method with mismatched adjoint as for the standard method.\nFinally, we derive a method to compute optimized probabilities for the choice\nof the rows and illustrate our findings with numerical example.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 19:29:06 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Lorenz", "Dirk A.", ""], ["Rose", "Sean", ""], ["Sch\u00f6pfer", "Frank", ""]]}, {"id": "1803.02865", "submitter": "Xiaoixa Wu", "authors": "Xiaoxia Wu and Rachel Ward and L\\'eon Bottou", "title": "WNGrad: Learn the Learning Rate in Gradient Descent", "comments": "10 pages, 3 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adjusting the learning rate schedule in stochastic gradient methods is an\nimportant unresolved problem which requires tuning in practice. If certain\nparameters of the loss function such as smoothness or strong convexity\nconstants are known, theoretical learning rate schedules can be applied.\nHowever, in practice, such parameters are not known, and the loss function of\ninterest is not convex in any case. The recently proposed batch normalization\nreparametrization is widely adopted in most neural network architectures today\nbecause, among other advantages, it is robust to the choice of Lipschitz\nconstant of the gradient in loss function, allowing one to set a large learning\nrate without worry. Inspired by batch normalization, we propose a general\nnonlinear update rule for the learning rate in batch and stochastic gradient\ndescent so that the learning rate can be initialized at a high value, and is\nsubsequently decreased according to gradient observations along the way. The\nproposed method is shown to achieve robustness to the relationship between the\nlearning rate and the Lipschitz constant, and near-optimal convergence rates in\nboth the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch\nsetting, and $O(1/\\sqrt{T})$ for convex loss in the stochastic setting). We\nalso show through numerical evidence that such robustness of the proposed\nmethod extends to highly nonconvex and possibly non-smooth loss function in\ndeep learning problems.Our analysis establishes some first theoretical\nunderstanding into the observed robustness for batch normalization and weight\nnormalization.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 20:30:35 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 20:31:14 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wu", "Xiaoxia", ""], ["Ward", "Rachel", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1803.03290", "submitter": "Chen Yuan", "authors": "Yiting Zhao, Chen Yuan, Guangyi Liu, Ilya Grinberg", "title": "Graph-based Preconditioning Conjugate Gradient Algorithm for N-1\n  Contingency Analysis", "comments": "5 pages, 8 figures, Proc. of 2018 IEEE Power and Energy Society\n  General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contingency analysis (CA) plays a critical role to guarantee operation\nsecurity in the modern power systems. With the high penetration of renewable\nenergy, a real-time and comprehensive N-1 CA is needed as a power system\nanalysis tool to ensure system security. In this paper, a graph-based\npreconditioning conjugate gradient (GPCG) approach is proposed for the nodal\nparallel computing in N-1 CA. To pursue a higher performance in the practical\napplication, the coefficient matrix of the base case is used as the incomplete\nLU (ILU) preconditioner for each N-1 scenario. Additionally, the re-dispatch\nstrategy is employed to handle the islanding issues in CA. Finally, computation\nperformance of the proposed GPCG approach is tested on a real provincial system\nin China.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 20:11:28 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Zhao", "Yiting", ""], ["Yuan", "Chen", ""], ["Liu", "Guangyi", ""], ["Grinberg", "Ilya", ""]]}, {"id": "1803.03300", "submitter": "Chen Yuan", "authors": "Chen Yuan, Yuqi Zhou, Guofang Zhang, Guangyi Liu, Renchang Dai, Xi\n  Chen, Zhiwei Wang", "title": "Exploration of Graph Computing in Power System State Estimation", "comments": "5 pages, 2 figures, Proc. of 2018 IEEE Power and Energy Society\n  General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DM cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased complexity of power systems due to the integration of\nsmart grid technologies and renewable energy resources, more frequent changes\nhave been introduced to system status, and the traditional serial mode of state\nestimation algorithm cannot well meet the restrict time-constrained requirement\nfor the future dynamic power grid, even with advanced computer hardware. To\nguarantee the grid reliability and minimize the impacts caused by system status\nfluctuations, a fast, even SCADA-rate, state estimator is urgently needed. In\nthis paper, a graph based power system modeling is firstly explored and a graph\ncomputing based state estimation is proposed to speed up its performance. The\npower system is represented by a graph, which is a collection of vertices and\nedges, and the measurements are attributes of vertices and edges. Each vertex\ncan independently implement local computation, like formulations of the\nnode-based H matrix, gain matrix and righthand-side (RHS) vector, only with the\ninformation on its connected edges and neighboring vertices. Then, by taking\nadvantages of graph database, these node-based data are conveniently collected\nand stored in the compressed sparse row (CSR) format avoiding the complexity\nand heaviness introduced by the sparse matrices. With communications and\nsynchronization, centralized computation of solving the weighted least square\n(WLS) state estimation is completed with hierarchical parallel computing. The\nproposed strategy is implemented on a graph database platform. The testing\nresults of IEEE 14-bus, IEEE 118-bus systems and a provincial system in China\nverify the accuracy and high-performance of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 20:49:51 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Yuan", "Chen", ""], ["Zhou", "Yuqi", ""], ["Zhang", "Guofang", ""], ["Liu", "Guangyi", ""], ["Dai", "Renchang", ""], ["Chen", "Xi", ""], ["Wang", "Zhiwei", ""]]}, {"id": "1803.03551", "submitter": "Jean-Christophe Mourrat", "authors": "S. Armstrong, A. Hannukainen, T. Kuusi, J.-C. Mourrat", "title": "An iterative method for elliptic problems with rapidly oscillating\n  coefficients", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new iterative method for computing solutions of elliptic\nequations with random rapidly oscillating coefficients. Similarly to a\nmultigrid method, each step of the iteration involves different computations\nmeant to address different length scales. However, we use here the homogenized\nequation on all scales larger than a fixed multiple of the scale of oscillation\nof the coefficients. While the performance of standard multigrid methods\ndegrades rapidly under the regime of large scale separation that we consider\nhere, we show an explicit estimate on the contraction factor of our method\nwhich is independent of the size of the domain. We also present numerical\nexperiments which confirm the effectiveness of the method, with openly\navailable source code.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 15:18:06 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 16:19:34 GMT"}, {"version": "v3", "created": "Thu, 10 Jan 2019 07:39:17 GMT"}, {"version": "v4", "created": "Fri, 27 Mar 2020 21:08:56 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Armstrong", "S.", ""], ["Hannukainen", "A.", ""], ["Kuusi", "T.", ""], ["Mourrat", "J. -C.", ""]]}, {"id": "1803.04046", "submitter": "Kurt Riedel", "authors": "Andrew Mullhaupt, Kurt Riedel", "title": "Exponential Condition Number of Solutions of the Discrete Lyapunov\n  Equation", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, Volume: 52, Issue: 5, May\n  2004, pgs. 1257 - 1265", "doi": "10.1109/TSP.2004.826177", "report-no": null, "categories": "stat.ME cs.NA cs.SY eess.SY math.NA math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The condition number of the $n\\ x\\ n$ matrix $P$ is examined, where $P$\nsolves %the discete Lyapunov equation, $P - A P A^* = BB^*$, and $B$ is a $n\\\nx\\ d$ matrix. Lower bounds on the condition number, $\\kappa$, of $P$ are given\nwhen $A$ is normal, a single Jordan block or in Frobenius form. The bounds show\nthat the ill-conditioning of $P$ grows as $\\exp(n/d) >> 1$. These bounds are\nrelated to the condition number of the transformation that takes $A$ to input\nnormal form. A simulation shows that $P$ is typically ill-conditioned in the\ncase of $n>>1$ and $d=1$. When $A_{ij}$ has an independent Gaussian\ndistribution (subject to restrictions), we observe that $\\kappa(P)^{1/n} ~=\n3.3$. The effect of auto-correlated forcing on the conditioning on state space\nsystems is examined\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 21:29:54 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Mullhaupt", "Andrew", ""], ["Riedel", "Kurt", ""]]}, {"id": "1803.04151", "submitter": "Fardin Saedpanah", "authors": "Mih\\'aly Kov\\'acs, Stig Larsson, and Fardin Saedpanah", "title": "Mittag-Leffler Euler integrator for a stochastic fractional order\n  equation with additive noise", "comments": "20 pages, 5 figures", "journal-ref": "SIAM J. Numer. Anal. 58 (2020), 66-85", "doi": "10.1137/18M1177895", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by fractional derivative models in viscoelasticity, a class of\nsemilinear stochastic Volterra integro-differential equations, and their\ndeterministic counterparts, are considered. A generalized exponential Euler\nmethod, named here as the Mittag-Leffler Euler integrator, is used for the\ntemporal discretization, while the spatial discretization is performed by the\nspectral Galerkin method. The temporal rate of strong convergence is found to\nbe (almost) twice compared to when the backward Euler method is used together\nwith a convolution quadrature for time discretization. Numerical experiments\nthat validate the theory are presented.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 08:32:27 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 11:15:57 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 09:25:16 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Kov\u00e1cs", "Mih\u00e1ly", ""], ["Larsson", "Stig", ""], ["Saedpanah", "Fardin", ""]]}, {"id": "1803.04346", "submitter": "Praveen Chandrashekar", "authors": "Deepak Varma, Praveen Chandrashekar", "title": "A second-order, discretely well-balanced finite volume scheme for Euler\n  equations with gravity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a well-balanced, second order, Godunov-type finite volume scheme\nfor compressible Euler equations with gravity. By construction, the scheme\nadmits a discrete stationary solution which is a second order accurate\napproximation to the exact stationary solution. Such a scheme is useful for\nproblems involving complex equations of state and/or hydrostatic solutions\nwhich are not known in closed form expression. No \\'a priori knowledge of the\nhydrostatic solution is required to achieve the well-balanced property. The\nperformance of the scheme is demonstrated on several test cases in terms of\npreservation of hydrostatic solution and computation of small perturbations\naround a hydrostatic solution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 16:13:19 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 04:02:17 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Varma", "Deepak", ""], ["Chandrashekar", "Praveen", ""]]}, {"id": "1803.05026", "submitter": "Vaneet Aggarwal", "authors": "Wenqi Wang and Vaneet Aggarwal and Shuchin Aeron", "title": "Principal Component Analysis with Tensor Train Subspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT cs.NA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor train is a hierarchical tensor network structure that helps alleviate\nthe curse of dimensionality by parameterizing large-scale multidimensional data\nvia a set of network of low-rank tensors. Associated with such a construction\nis a notion of Tensor Train subspace and in this paper we propose a TT-PCA\nalgorithm for estimating this structured subspace from the given data. By\nmaintaining low rank tensor structure, TT-PCA is more robust to noise comparing\nwith PCA or Tucker-PCA. This is borne out numerically by testing the proposed\napproach on the Extended YaleFace Dataset B.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 19:58:46 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Wang", "Wenqi", ""], ["Aggarwal", "Vaneet", ""], ["Aeron", "Shuchin", ""]]}, {"id": "1803.05182", "submitter": "Jingwei Liu", "authors": "Jingwei Liu", "title": "Approximative Theorem of Incomplete Riemann-Stieltjes Sum of Stochastic\n  Integral", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximative theorems of incomplete Riemann-Stieltjes sums of Ito\nstochastic integral, mean square integral and Stratonovich stochastic integral\nwith respect to Brownian motion are investigated. Some sufficient conditions of\nincomplete Riemann-Stieltjes sums approaching stochastic integral are\ndeveloped, which establish the alternative ways to converge stochastic\nintegral. And, Two simulation examples of incomplete Riemann-Stieltjes sums\nabout Ito stochastic integral and Stratonovich stochastic integral are given\nfor demonstration.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 09:56:47 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 07:12:42 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Liu", "Jingwei", ""]]}, {"id": "1803.05332", "submitter": "Peter Frolkovi\\v{c}", "authors": "Peter Frolkovi\\v{c} and Karol Mikula", "title": "Semi-implicit second order schemes for numerical solution of level set\n  advection equation on Cartesian grids", "comments": "arXiv admin note: substantial text overlap with arXiv:1611.04153\n  Comment from the authors - this is a corrected paper where typesetting error\n  in formula (37) is removed", "journal-ref": "Applied Mathematics and Computation, Volume 329, 15 July 2018,\n  Pages 129-142", "doi": "10.1016/j.amc.2018.01.065", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new parametric class of semi-implicit numerical schemes for a level set\nadvection equation on Cartesian grids is derived and analyzed. An accuracy and\na stability study is provided for a linear advection equation with a variable\nvelocity using partial Lax-Wendroff procedure and numerical von Neumann\nstability analysis. The obtained semi-implicit kappa-scheme is 2nd order\naccurate in space and time in any dimensional case when using a dimension by\ndimension extension of the one-dimensional scheme that is not the case for\nanalogous fully explicit or fully implicit kappa-schemes. A further improvement\nis obtained by using so-called Corner Transport Upwind extension in\ntwo-dimensional case. The extended semi-implicit kappa-scheme with a specific\n(velocity dependent) value of kappa is 3rd order accurate in space and time for\na constant advection velocity, and it is unconditional stable according to the\nnumerical von Neumann stability analysis for the linear advection equation in\ngeneral.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 14:57:55 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 11:30:54 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Frolkovi\u010d", "Peter", ""], ["Mikula", "Karol", ""]]}, {"id": "1803.05503", "submitter": "Iryna Kulchytska-Ruchka", "authors": "Martin J. Gander, Iryna Kulchytska-Ruchka, Innocent Niyonzima, and\n  Sebastian Sch\\\"ops", "title": "A New Parareal Algorithm for Problems with Discontinuous Sources", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing 2019 41:2, B375-B395", "doi": "10.1137/18M1175653", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Parareal algorithm allows to solve evolution problems exploiting\nparallelization in time. Its convergence and stability have been proved under\nthe assumption of regular (smooth) inputs. We present and analyze here a new\nParareal algorithm for ordinary differential equations which involve\ndiscontinuous right-hand sides. Such situations occur in various applications,\ne.g., when an electric device is supplied with a pulse-width-modulated signal.\nOur new Parareal algorithm uses a smooth input for the coarse problem with\nreduced dynamics. We derive error estimates that show how the input reduction\ninfluences the overall convergence rate of the algorithm. We support our\ntheoretical results by numerical experiments, and also test our new Parareal\nalgorithm in an eddy current simulation of an induction machine.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 20:37:54 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Gander", "Martin J.", ""], ["Kulchytska-Ruchka", "Iryna", ""], ["Niyonzima", "Innocent", ""], ["Sch\u00f6ps", "Sebastian", ""]]}, {"id": "1803.05671", "submitter": "Renato L. G. Cavalcante", "authors": "Renato L. G. Cavalcante and Slawomir Stanczak", "title": "Spectral radii of asymptotic mappings and the convergence speed of the\n  standard fixed point algorithm", "comments": "Paper accepted for presentation at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important problems in wireless networks can often be solved by computing\nfixed points of standard or contractive interference mappings, and the\nconventional fixed point algorithm is widely used for this purpose. Knowing\nthat the mapping used in the algorithm is not only standard but also\ncontractive (or only contractive) is valuable information because we obtain a\nguarantee of geometric convergence rate, and the rate is related to a property\nof the mapping called modulus of contraction. To date, contractive mappings and\ntheir moduli of contraction have been identified with case-by-case approaches\nthat can be difficult to generalize. To address this limitation of existing\napproaches, we show in this study that the spectral radii of asymptotic\nmappings can be used to identify an important subclass of contractive mappings\nand also to estimate their moduli of contraction. In addition, if the fixed\npoint algorithm is applied to compute fixed points of positive concave\nmappings, we show that the spectral radii of asymptotic mappings provide us\nwith simple lower bounds for the estimation error of the iterates. An immediate\napplication of this result proves that a known algorithm for load estimation in\nwireless networks becomes slower with increasing traffic.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 10:07:59 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Cavalcante", "Renato L. G.", ""], ["Stanczak", "Slawomir", ""]]}, {"id": "1803.05676", "submitter": "Adrien B. Taylor", "authors": "Yoel Drori, Adrien B. Taylor", "title": "Efficient First-order Methods for Convex Minimization: a Constructive\n  Approach", "comments": "Accepted in Mathematical Programming\n  (https://doi.org/10.1007/s10107-019-01410-2). Code available on GitHub\n  (https://github.com/AdrienTaylor/GreedyMethods)", "journal-ref": null, "doi": "10.1007/s10107-019-01410-2", "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel constructive technique for devising efficient first-order\nmethods for a wide range of large-scale convex minimization settings, including\nsmooth, non-smooth, and strongly convex minimization. The technique builds upon\na certain variant of the conjugate gradient method to construct a family of\nmethods such that a) all methods in the family share the same worst-case\nguarantee as the base conjugate gradient method, and b) the family includes a\nfixed-step first-order method. We demonstrate the effectiveness of the approach\nby deriving optimal methods for the smooth and non-smooth cases, including new\nmethods that forego knowledge of the problem parameters at the cost of a\none-dimensional line search per iteration, and a universal method for the union\nof these classes that requires a three-dimensional search per iteration. In the\nstrongly convex case, we show how numerical tools can be used to perform the\nconstruction, and show that the resulting method offers an improved worst-case\nbound compared to Nesterov's celebrated fast gradient method.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 10:25:22 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 16:59:18 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 16:38:32 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Drori", "Yoel", ""], ["Taylor", "Adrien B.", ""]]}, {"id": "1803.05919", "submitter": "Maria Han Veiga", "authors": "Maria Han Veiga, David A. Romero Velasco, R\\'emi Abgrall and Romain\n  Teyssier", "title": "Capturing near-equilibrium solutions: a comparison between high-order\n  discontinuous Galerkin methods and well-balanced schemes", "comments": "37 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA astro-ph.IM cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium or stationary solutions usually proceed through the exact balance\nbetween hyperbolic transport terms and source terms. Such equilibrium solutions\nare affected by truncation errors that prevent any classical numerical scheme\nfrom capturing the evolution of small amplitude waves of physical significance.\nIn order to overcome this problem, we compare two commonly adopted strategies:\ngoing to very high order and reduce drastically the truncation errors on the\nequilibrium solution, or design a specific scheme that preserves by\nconstruction the equilibrium exactly, the so-called well-balanced approach. We\npresent a modern numerical implementation of these two strategies and compare\nthem in details, using hydrostatic but also dynamical equilibrium solutions of\nseveral simple test cases. Finally, we apply our methodology to the simulation\nof a protoplanetary disc in centrifugal equilibrium around its star and model\nits interaction with an embedded planet, illustrating in a realistic\napplication the strength of both methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 18:00:02 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 11:45:27 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Veiga", "Maria Han", ""], ["Velasco", "David A. Romero", ""], ["Abgrall", "R\u00e9mi", ""], ["Teyssier", "Romain", ""]]}, {"id": "1803.06156", "submitter": "Martin Storath", "authors": "Martin Storath, Lukas Kiefer, Andreas Weinmann", "title": "Smoothing for signals with discontinuities using higher order\n  Mumford-Shah models", "comments": null, "journal-ref": null, "doi": "10.1007/s00211-019-01052-8", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing the Mumford-Shah functional is frequently used for smoothing\nsignals or time series with discontinuities. A significant limitation of the\nstandard Mumford-Shah model is that linear trends -- and in general polynomial\ntrends -- in the data are not well preserved. This can be improved by building\non splines of higher order which leads to higher order Mumford-Shah models. In\nthis work, we study these models in the univariate situation: we discuss\nimportant differences to the first order Mumford-Shah model, and we obtain\nuniqueness results for their solutions. As a main contribution, we derive fast\nminimization algorithms for Mumford-Shah models of arbitrary orders. We show\nthat the worst case complexity of all proposed schemes is quadratic in the\nlength of the signal. Remarkably, they thus achieve the worst case complexity\nof the fastest solver for the piecewise constant Mumford-Shah model (which is\nthe simplest model of the class). Further, we obtain stability results for the\nproposed algorithms. We complement these results with a numerical study. Our\nreference implementation processes signals with more than 10,000 elements in\nless than one second.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 10:34:59 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 18:54:55 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Storath", "Martin", ""], ["Kiefer", "Lukas", ""], ["Weinmann", "Andreas", ""]]}, {"id": "1803.06322", "submitter": "Leonardo Robol", "authors": "Giulio Masetti and Leonardo Robol", "title": "Computing performability measures in Markov chains by means of matrix\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the efficient computation of performance, reliability, and\navailability measures for Markov chains; these metrics, and the ones obtained\nby combining them, are often called performability measures. We show that this\ncomputational problem can be recasted as the evaluation of a bilinear forms\ninduced by appropriate matrix functions, and thus solved by leveraging the fast\nmethods available for this task. We provide a comprehensive analysis of the\ntheory required to translate the problem from the language of Markov chains to\nthe one of matrix functions. The advantages of this new formulation are\ndiscussed, and it is shown that this setting allows to easily study the\nsensitivities of the measures with respect to the model parameters. Numerical\nexperiments confirm the effectiveness of our approach; the tests we have run\nshow that we can outperform the solvers available in state of the art\ncommercial packages on a representative set of large scale examples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 17:21:21 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 08:53:02 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 07:34:50 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Masetti", "Giulio", ""], ["Robol", "Leonardo", ""]]}, {"id": "1803.06418", "submitter": "Andrew Nystrom", "authors": "Andrew Nystrom and John Hughes", "title": "Leveraging Sparsity to Speed Up Polynomial Feature Expansions of CSR\n  Matrices Using $K$-Simplex Numbers", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An algorithm is provided for performing polynomial feature expansions that\nboth operates on and produces compressed sparse row (CSR) matrices. Previously,\nno such algorithm existed, and performing polynomial expansions on CSR matrices\nrequired an intermediate densification step. The algorithm performs a\n$K$-degree expansion by using a bijective function involving $K$-simplex\nnumbers of column indices in the original matrix to column indices in the\nexpanded matrix. Not only is space saved by operating in CSR format, but the\nbijective function allows for only the nonzero elements to be iterated over and\nmultiplied together during the expansion, greatly improving average time\ncomplexity. For a vector of dimensionality $D$ and density $0 \\le d \\le 1$, the\nalgorithm has average time complexity $\\Theta(d^KD^K)$ where $K$ is the\npolynomial-feature order; this is an improvement by a factor $d^K$ over the\nstandard method. This work derives the required function for the cases of $K=2$\nand $K=3$ and shows its use in the $K=2$ algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 22:24:32 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 03:46:50 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 04:04:09 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Nystrom", "Andrew", ""], ["Hughes", "John", ""]]}, {"id": "1803.06496", "submitter": "Sihong Shao", "authors": "Sihong Shao, Dong Zhang, Weixi Zhang", "title": "A simple iterative algorithm for maxcut", "comments": "30 pages, 1 figure. Subgradient selection, cost analysis and local\n  breakout are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.CO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple iterative (SI) algorithm for the maxcut problem through\nfully using an equivalent continuous formulation. It does not need rounding at\nall and has advantages that all subproblems have explicit analytic solutions,\nthe cut values are monotonically updated and the iteration points converge to a\nlocal optima in finite steps via an appropriate subgradient selection.\nNumerical experiments on G-set demonstrate the performance. In particular, the\nratios between the best cut values achieved by SI and the best known ones are\nat least $0.986$ and can be further improved to at least $0.997$ by a\npreliminary attempt to break out of local optima.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 12:29:19 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 23:24:34 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Shao", "Sihong", ""], ["Zhang", "Dong", ""], ["Zhang", "Weixi", ""]]}, {"id": "1803.06635", "submitter": "Andre Massing", "authors": "Ceren G\\\"urkan and Andr\\'e Massing", "title": "A stabilized cut discontinuous Galerkin framework: I. Elliptic boundary\n  value and interface problems", "comments": "35 pages, 12 figures, 2 tables", "journal-ref": null, "doi": "10.1016/j.cma.2018.12.041", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a stabilized cut discontinuous Galerkin framework for the\nnumerical solution of el- liptic boundary value and interface problems on\ncomplicated domains. The domain of interest is embedded in a structured,\nunfitted background mesh in R d , so that the boundary or interface can cut\nthrough it in an arbitrary fashion. The method is based on an unfitted variant\nof the classical symmetric interior penalty method using piecewise\ndiscontinuous polynomials defined on the back- ground mesh. Instead of the cell\nagglomeration technique commonly used in previously introduced unfitted\ndiscontinuous Galerkin methods, we employ and extend ghost penalty techniques\nfrom recently developed continuous cut finite element methods, which allows for\na minimal extension of existing fitted discontinuous Galerkin software to\nhandle unfitted geometries. Identifying four abstract assumptions on the ghost\npenalty, we derive geometrically robust a priori error and con- dition number\nestimates for the Poisson boundary value problem which hold irrespective of the\nparticular cut configuration. Possible realizations of suitable ghost penalties\nare discussed. We also demonstrate how the framework can be elegantly applied\nto discretize high contrast interface problems. The theoretical results are\nillustrated by a number of numerical experiments for various approximation\norders and for two and three-dimensional test problems.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 10:25:30 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 09:03:57 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["G\u00fcrkan", "Ceren", ""], ["Massing", "Andr\u00e9", ""]]}, {"id": "1803.06843", "submitter": "Pawe{\\l} Wo\\'zny", "authors": "Filip Chudy, Pawe{\\l} Wo\\'zny", "title": "Linear-time geometric algorithm for evaluating B\\'ezier curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithm for computing a point on a polynomial or rational curve in\nB\\'{e}zier form is proposed. The method has a geometric interpretation and uses\nonly convex combinations of control points. The new algorithm's computational\ncomplexity is linear with respect to the number of control points and its\nmemory complexity is $O(1)$. Some remarks on similar methods for surfaces in\nrectangular and triangular B\\'{e}zier form are also given.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 09:36:36 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 10:54:29 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 11:48:36 GMT"}, {"version": "v4", "created": "Wed, 19 Jun 2019 11:23:45 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Chudy", "Filip", ""], ["Wo\u017any", "Pawe\u0142", ""]]}, {"id": "1803.07226", "submitter": "Jinshi Yu", "authors": "Jinshi Yu, Guoxu Zhou, Andrzej Cichocki, Shengli Xie", "title": "Learning the Hierarchical Parts of Objects by Deep Non-Smooth\n  Nonnegative Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonsmooth Nonnegative Matrix Factorization (nsNMF) is capable of producing\nmore localized, less overlapped feature representations than other variants of\nNMF while keeping satisfactory fit to data. However, nsNMF as well as other\nexisting NMF methods is incompetent to learn hierarchical features of complex\ndata due to its shallow structure. To fill this gap, we propose a deep nsNMF\nmethod coined by the fact that it possesses a deeper architecture compared with\nstandard nsNMF. The deep nsNMF not only gives parts-based features due to the\nnonnegativity constraints, but also creates higher-level, more abstract\nfeatures by combing lower-level ones. The in-depth description of how deep\narchitecture can help to efficiently discover abstract features in dnsNMF is\npresented. And we also show that the deep nsNMF has close relationship with the\ndeep autoencoder, suggesting that the proposed model inherits the major\nadvantages from both deep learning and NMF. Extensive experiments demonstrate\nthe standout performance of the proposed method in clustering analysis.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 02:39:44 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Yu", "Jinshi", ""], ["Zhou", "Guoxu", ""], ["Cichocki", "Andrzej", ""], ["Xie", "Shengli", ""]]}, {"id": "1803.07374", "submitter": "Filip Hanzely", "authors": "Filip Hanzely and Peter Richt\\'arik", "title": "Fastest Rates for Stochastic Mirror Descent Methods", "comments": "45 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relative smoothness - a notion introduced by Birnbaum et al. (2011) and\nrediscovered by Bauschke et al. (2016) and Lu et al. (2016) - generalizes the\nstandard notion of smoothness typically used in the analysis of gradient type\nmethods. In this work we are taking ideas from well studied field of stochastic\nconvex optimization and using them in order to obtain faster algorithms for\nminimizing relatively smooth functions. We propose and analyze two new\nalgorithms: Relative Randomized Coordinate Descent (relRCD) and Relative\nStochastic Gradient Descent (relSGD), both generalizing famous algorithms in\nthe standard smooth setting. The methods we propose can be in fact seen as a\nparticular instances of stochastic mirror descent algorithms. One of them,\nrelRCD corresponds to the first stochastic variant of mirror descent algorithm\nwith linear convergence rate.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 11:27:01 GMT"}], "update_date": "2018-03-25", "authors_parsed": [["Hanzely", "Filip", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1803.07661", "submitter": "Zhe Li", "authors": "Zhe Li, Shuo Wang, Caiwen Ding, Qinru Qiu, Yanzhi Wang, Yun Liang", "title": "Efficient Recurrent Neural Networks using Structured Matrices in FPGAs", "comments": "To appear in International Conference on Learning Representations\n  2018 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are becoming increasingly important for time\nseries-related applications which require efficient and real-time\nimplementations. The recent pruning based work ESE suffers from degradation of\nperformance/energy efficiency due to the irregular network structure after\npruning. We propose block-circulant matrices for weight matrix representation\nin RNNs, thereby achieving simultaneous model compression and acceleration. We\naim to implement RNNs in FPGA with highest performance and energy efficiency,\nwith certain accuracy requirement (negligible accuracy degradation).\nExperimental results on actual FPGA deployments shows that the proposed\nframework achieves a maximum energy efficiency improvement of 35.7$\\times$\ncompared with ESE.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 21:21:22 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 17:26:10 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Li", "Zhe", ""], ["Wang", "Shuo", ""], ["Ding", "Caiwen", ""], ["Qiu", "Qinru", ""], ["Wang", "Yanzhi", ""], ["Liang", "Yun", ""]]}, {"id": "1803.07726", "submitter": "Cong Ma", "authors": "Yuxin Chen, Yuejie Chi, Jianqing Fan, Cong Ma", "title": "Gradient Descent with Random Initialization: Fast Global Convergence for\n  Nonconvex Phase Retrieval", "comments": "Accepted to Mathematical Programming", "journal-ref": "Mathematical Programming 2019, Volume 176, Issue 1-2, 5-37", "doi": "10.1007/s10107-019-01363-6", "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.NA math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of solving systems of quadratic equations,\nnamely, recovering an object of interest\n$\\mathbf{x}^{\\natural}\\in\\mathbb{R}^{n}$ from $m$ quadratic equations/samples\n$y_{i}=(\\mathbf{a}_{i}^{\\top}\\mathbf{x}^{\\natural})^{2}$, $1\\leq i\\leq m$. This\nproblem, also dubbed as phase retrieval, spans multiple domains including\nphysical sciences and machine learning.\n  We investigate the efficiency of gradient descent (or Wirtinger flow)\ndesigned for the nonconvex least squares problem. We prove that under Gaussian\ndesigns, gradient descent --- when randomly initialized --- yields an\n$\\epsilon$-accurate solution in $O\\big(\\log n+\\log(1/\\epsilon)\\big)$ iterations\ngiven nearly minimal samples, thus achieving near-optimal computational and\nsample complexities at once. This provides the first global convergence\nguarantee concerning vanilla gradient descent for phase retrieval, without the\nneed of (i) carefully-designed initialization, (ii) sample splitting, or (iii)\nsophisticated saddle-point escaping schemes. All of these are achieved by\nexploiting the statistical models in analyzing optimization algorithms, via a\nleave-one-out approach that enables the decoupling of certain statistical\ndependency between the gradient descent iterates and the data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:14:16 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 13:56:11 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Chen", "Yuxin", ""], ["Chi", "Yuejie", ""], ["Fan", "Jianqing", ""], ["Ma", "Cong", ""]]}, {"id": "1803.08114", "submitter": "Jamie Haddock", "authors": "Jamie Haddock, Deanna Needell", "title": "Randomized Projection Methods for Linear Systems with Arbitrarily Large\n  Sparse Corruptions", "comments": null, "journal-ref": null, "doi": "10.1063/1.5044141", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications like medical imaging, error correction, and sensor networks,\none needs to solve large-scale linear systems that may be corrupted by a small\nnumber of arbitrarily large corruptions. We consider solving such large-scale\nsystems of linear equations $A\\mathbf{x}=\\mathbf{b}$ that are inconsistent due\nto corruptions in the measurement vector $\\mathbf{b}$. With this as our\nmotivating example, we develop an approach for this setting that allows\ndetection of the corrupted entries and thus convergence to the \"true\" solution\nof the original system. We provide analytical justification for our approaches\nas well as experimental evidence on real and synthetic systems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 20:21:02 GMT"}, {"version": "v2", "created": "Sun, 23 Dec 2018 03:55:07 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Haddock", "Jamie", ""], ["Needell", "Deanna", ""]]}, {"id": "1803.08137", "submitter": "Sathya N. Ravi", "authors": "Sathya N. Ravi, Ronak Mehta, Vikas Singh", "title": "Robust Blind Deconvolution via Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the Blind Deconvolution problem with a focus on understanding its\nrobustness and convergence properties. Provable robustness to noise and other\nperturbations is receiving recent interest in vision, from obtaining immunity\nto adversarial attacks to assessing and describing failure modes of algorithms\nin mission critical applications. Further, many blind deconvolution methods\nbased on deep architectures internally make use of or optimize the basic\nformulation, so a clearer understanding of how this sub-module behaves, when it\ncan be solved, and what noise injection it can tolerate is a first order\nrequirement. We derive new insights into the theoretical underpinnings of blind\ndeconvolution. The algorithm that emerges has nice convergence guarantees and\nis provably robust in a sense we formalize in the paper. Interestingly, these\ntechnical results play out very well in practice, where on standard datasets\nour algorithm yields results competitive with or superior to the state of the\nart. Keywords: blind deconvolution, robust continuous optimization\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 20:55:26 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Ravi", "Sathya N.", ""], ["Mehta", "Ronak", ""], ["Singh", "Vikas", ""]]}, {"id": "1803.09232", "submitter": "Svetlana Matculevich", "authors": "Svetlana Matculevich and Monika Wolfmayr", "title": "On the a posteriori error analysis for linear Fokker-Planck models in\n  convection-dominated diffusion problems", "comments": "29 pages, 14 figures, 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is aimed at the derivation of reliable and efficient a posteriori\nerror estimates for convection-dominated diffusion problems motivated by a\nlinear Fokker-Planck problem appearing in computational neuroscience. We obtain\ncomputable error bounds of the functional type for the static and\ntime-dependent case and for different boundary conditions (mixed and pure\nNeumann boundary conditions). Finally, we present a set of various numerical\nexamples including discussions on mesh adaptivity and space-time\ndiscretisation. The numerical results confirm the reliability and efficiency of\nthe error estimates derived.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 11:07:40 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 14:46:32 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Matculevich", "Svetlana", ""], ["Wolfmayr", "Monika", ""]]}, {"id": "1803.09283", "submitter": "Kapil Ahuja", "authors": "Navneet Pratap Singh and Kapil Ahuja", "title": "Stability Analysis of Inexact Solves in Moment Matching based Model\n  Reduction", "comments": "24 Pages and 7 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a new algorithm for model reduction of second order linear dynamical\nsystems with proportional damping, the Adaptive Iterative Rational Global\nArnoldi (AIRGA) algorithm (Bonin et. al., 2016), has been proposed. The main\ncomputational cost of the AIRGA algorithm is solving a sequence of linear\nsystems. Usually, direct methods (e.g., LU) are used for solving these systems.\nAs model sizes grow, direct methods become prohibitively expensive. Iterative\nmethods (e.g., Krylov) scale well with size, and hence, are a good choice with\nan appropriate preconditioner.\n  Preconditioned iterative methods introduce errors in linear solves because\nthey are not exact. They solve linear systems up to a certain tolerance. We\nprove that, under mild conditions, the AIRGA algorithm is backward stable with\nrespect to the errors introduced by these inexact linear solves. Our first\nassumption is use of a Ritz-Galerkin based solver that satisfies few extra\northogonality conditions. Since Conjugate Gradient (CG) is the most popular\nmethod based upon the Ritz-Galerkin theory, we use it. We show how to modify CG\nto achieve these extra orthogonalities.\n  Modifying CG with the suggested changes is non-trivial. Hence, we demonstrate\nthat using Recycling CG (RCG) helps us achieve these orthogonalities with no\ncode changes. The extra cost of orthogonalizations is often offset by savings\nbecause of recycling. Our second and third assumptions involve existence,\ninvertibility and boundedness of two matrices, which are easy to satisfy.\n  While satisfying the backward stability assumptions, by numerical experiments\nwe show that as we iteratively solve the linear systems arising in the AIRGA\nalgorithm more accurately, we obtain a more accurate reduced system. We also\nshow that recycling Krylov subspaces helps satisfy the backward stability\nassumptions (extra-orthogonalities) at almost no extra cost.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 15:55:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Singh", "Navneet Pratap", ""], ["Ahuja", "Kapil", ""]]}, {"id": "1803.09303", "submitter": "Kurt Riedel", "authors": "D.Borba, K.S. Riedel, W. Kerner, G.T.A. Huysmans, M. Ottaviani, P.J.\n  Schmid", "title": "Pseudo-Spectrum of the Resistive Magneto-hydrodynamics Operator:\n  Resolving the Resistive Alfven Paradox", "comments": null, "journal-ref": "Physics of Plasmas 1, 3151 (1994)", "doi": "10.1063/1.870468", "report-no": "JET-P(94)04", "categories": "physics.plasm-ph cs.NA math-ph math.MP math.NA math.SP physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The `Alfv\\'en Paradox' is that as resistivity decreases, the discrete\neigenmodes do not converge to the generalized eigenmodes of the ideal Alfv\\'en\ncontinuum. To resolve the paradox, the $\\epsilon$-pseudospectrum of the RMHD\noperator is considered. It is proven that for any $\\epsilon$, the $\\epsilon$-\npseudospectrum contains the Alfv\\'en continuum for sufficiently small\nresistivity. Formal $\\epsilon-pseudoeigenmodes$ are constructed using the\nformal Wentzel-Kramers-Brillouin-Jeffreys solutions, and it is shown that the\nentire stable half-annulus of complex frequencies with\n$\\rho{|\\omega|^2}=|\\bf{v} \\cdot \\bf{B}(x)|^2$ is resonant to order $\\epsilon$,\ni.e.~belongs to the $\\epsilon-pseudospectrum$. The resistive eigenmodes are\nexponentially ill-conditioned as a basis and the condition number is\nproportional to $\\exp(R_M^{1\\over 2})$, where $R_M$ is the magnetic Reynolds\nnumber.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 18:22:43 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Borba", "D.", ""], ["Riedel", "K. S.", ""], ["Kerner", "W.", ""], ["Huysmans", "G. T. A.", ""], ["Ottaviani", "M.", ""], ["Schmid", "P. J.", ""]]}, {"id": "1803.09446", "submitter": "Yumiharu Nakano", "authors": "Yumiharu Nakano", "title": "Convergent kernel-based methods for parabolic equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the functions constructed by the kernel-based regressions with\nWendland kernels under $\\ell_1$-norm constraints converge to unique viscosity\nsolutions of the corresponding fully nonlinear parabolic equations. A key\ningredient in our proof is the max-min representations of the nonlinearities of\nthe equations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 07:31:35 GMT"}, {"version": "v10", "created": "Mon, 4 Nov 2019 13:59:36 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 06:00:34 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 02:37:26 GMT"}, {"version": "v4", "created": "Sat, 6 Jul 2019 05:00:42 GMT"}, {"version": "v5", "created": "Thu, 18 Jul 2019 05:57:36 GMT"}, {"version": "v6", "created": "Wed, 24 Jul 2019 14:20:55 GMT"}, {"version": "v7", "created": "Thu, 25 Jul 2019 02:20:03 GMT"}, {"version": "v8", "created": "Fri, 26 Jul 2019 12:44:35 GMT"}, {"version": "v9", "created": "Wed, 30 Oct 2019 05:50:41 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Nakano", "Yumiharu", ""]]}, {"id": "1803.09941", "submitter": "Zhaosong Lu", "authors": "Zhaosong Lu and Zirui Zhou", "title": "Iteration-complexity of first-order augmented Lagrangian methods for\n  convex conic programming", "comments": "Needs substantial revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a class of convex conic programming. In particular,\nwe propose an inexact augmented Lagrangian (I-AL) method for solving this\nproblem, in which the augmented Lagrangian subproblems are solved approximately\nby a variant of Nesterov's optimal first-order method. We show that the total\nnumber of first-order iterations of the proposed I-AL method for computing an\n$\\epsilon$-KKT solution is at most $\\mathcal{O}(\\epsilon^{-7/4})$. We also\npropose a modified I-AL method and show that it has an improved\niteration-complexity $\\mathcal{O}(\\epsilon^{-1}\\log\\epsilon^{-1})$, which is so\nfar the lowest complexity bound among all first-order I-AL type of methods for\ncomputing an $\\epsilon$-KKT solution. Our complexity analysis of the I-AL\nmethods is mainly based on an analysis on inexact proximal point algorithm\n(PPA) and the link between the I-AL methods and inexact PPA. It is\nsubstantially different from the existing complexity analyses of the\nfirst-order I-AL methods in the literature, which typically regard the I-AL\nmethods as an inexact dual gradient method. Compared to the mostly related I-AL\nmethods \\cite{Lan16}, our modified I-AL method is more practically efficient\nand also applicable to a broader class of problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 07:48:55 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 03:51:08 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Lu", "Zhaosong", ""], ["Zhou", "Zirui", ""]]}, {"id": "1803.09950", "submitter": "Robert Altmann", "authors": "Robert Altmann, Patrick Henning, Daniel Peterseim", "title": "Quantitative Anderson localization of Schr\\\"odinger eigenstates under\n  disorder potentials", "comments": "accepted for publication in M3AS", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math-ph math.MP math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns spectral properties of linear Schr\\\"odinger operators\nunder oscillatory high-amplitude potentials on bounded domains. Depending on\nthe degree of disorder, we prove the existence of spectral gaps amongst the\nlowermost eigenvalues and the emergence of exponentially localized states. We\nquantify the rate of decay in terms of geometric parameters that characterize\nthe potential. The proofs are based on the convergence theory of iterative\nsolvers for eigenvalue problems and their optimal local preconditioning by\ndomain decomposition.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 08:12:52 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 14:31:47 GMT"}, {"version": "v3", "created": "Mon, 25 Jun 2018 21:29:59 GMT"}, {"version": "v4", "created": "Sun, 9 Feb 2020 15:46:17 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Altmann", "Robert", ""], ["Henning", "Patrick", ""], ["Peterseim", "Daniel", ""]]}, {"id": "1803.10286", "submitter": "Juan Vicente Guti\\'errez-Santacreu", "authors": "Roberto Carlos Cabrales, Juan Vicente Guti\\'errez-Santacreu, Jos\\'e\n  Rafael Rodr\\'iguez-Galv\\'an", "title": "Numerical solution for an aggregation equation with degenerate diffusion", "comments": "27 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A numerical method for approximating weak solutions of an aggregation\nequation with degenerate diffusion is introduced. The numerical method consists\nof a stabilized finite element method together with a mass lumping technique\nand an extra stabilizing term plus a semi--implicit Euler time integration.\nThen we carry out a rigorous passage to the limit as the spatial and temporal\ndiscretization parameters tend to zero, and show that the sequence of finite\nelement approximations converges toward the unique weak solution of the model\nat hands. In doing so, nonnegativity is attained due to the stabilizing term\nand the acuteness on partitions of the computational domain, and hence a priori\nenergy estimates of finite element approximations are established. As we deal\nwith a nonlinear problem, some form of strong convergence is required. The key\ncompactness result is obtained via an adaptation of a\nRiesz--Fr\\'echet--Kolmogorov criterion by perturbation. A numerical example is\nalso presented.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 19:45:57 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 17:58:48 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Cabrales", "Roberto Carlos", ""], ["Guti\u00e9rrez-Santacreu", "Juan Vicente", ""], ["Rodr\u00edguez-Galv\u00e1n", "Jos\u00e9 Rafael", ""]]}, {"id": "1803.10405", "submitter": "Kurt Riedel", "authors": "Kurt S. Riedel", "title": "A Sherman-Morrison-Woodbury Identity for Rank Augmenting Matrices with\n  Application to Centering", "comments": "Better in Mathematics, Spectral Theory, General, or Numerical\n  Analysis", "journal-ref": "SIAM Journal on Numerical Analysis Vol. 31, No. 4 (Aug., 1994),\n  pp. 1219-1225", "doi": null, "report-no": null, "categories": "stat.ME cs.NA cs.SY eess.SY math.FA math.NA math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrices of the form $\\bf{A} + (\\bf{V}_1 + \\bf{W}_1)\\bf{G}(\\bf{V}_2 +\n\\bf{W}_2)^*$ are considered where $\\bf{A}$ is a $singular$ $\\ell \\times \\ell$\nmatrix and $\\bf{G}$ is a nonsingular $k \\times k$ matrix, $k \\le \\ell$. Let the\ncolumns of $\\bf{V}_1$ be in the column space of $\\bf{A}$ and the columns of\n$\\bf{W}_1$ be orthogonal to $\\bf{A}$. Similarly, let the columns of $\\bf{V}_2$\nbe in the column space of $\\bf{A}^*$ and the columns of $\\bf{W}_2$ be\northogonal to $\\bf{A}^*$. An explicit expression for the inverse is given,\nprovided that $\\bf{W}_i^* \\bf{W}_i$ has rank $k$. %and $\\bf{W}_1$ and\n$\\bf{W}_2$ have the same column space. An application to centering covariance\nmatrices about the mean is given.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 04:05:31 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Riedel", "Kurt S.", ""]]}, {"id": "1803.10600", "submitter": "Khaled Saleh", "authors": "Khaled Saleh (MMCS, ICJ)", "title": "A relaxation scheme for a hyperbolic multiphase flow model. Part I:\n  barotropic eos", "comments": "arXiv admin note: text overlap with arXiv:1601.07345", "journal-ref": "ESAIM: Mathematical Modelling and Numerical Analysis, EDP\n  Sciences, 2019", "doi": null, "report-no": null, "categories": "math.NA cs.NA math.AP physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is the first of two in which we develop a relaxation finite\nvolume scheme for the convective part of the multiphase flow models introduced\nin the series of papers [10, 9, 4]. In the present article we focus on\nbarotropic flows where in each phase the pressure is a given function of the\ndensity. The case of general equations of state will be the purpose of the\nsecond article. We show how it is possible to extend the relaxation scheme\ndesigned in [8] for the barotropic Baer-Nunziato two-phase flow model to the\nmultiphase flow model with N-where N is arbitrarily large-phases. The obtained\nscheme inherits the main properties of the relaxation scheme designed for the\nBaer-Nunziato two phase flow model. The approximated phase fractions and phase\ndensities are proven to remain positive and a discrete energy inequality is\nalso proven under a classical CFL condition. For the same level of refinement,\nthe relaxation scheme is shown to be much more accurate than Rusanov's scheme,\nand for a given level of approximation error, the relaxation scheme is shown to\nperform much better in terms of computational cost than Rusanov's scheme.\nMoreover, contrary to Rusanov's scheme which develops strong oscillations when\napproximating vanishing phase solutions, the numerical results show that the\nrelaxation scheme remains stable in such regimes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 10:15:40 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 09:18:52 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Saleh", "Khaled", "", "MMCS, ICJ"]]}, {"id": "1803.10754", "submitter": "Madan Singh", "authors": "Madan Singh", "title": "Investigating the hybrid textures of neutrino mass matrix for near\n  maximal atmospheric neutrino mixing", "comments": null, "journal-ref": "Advances in High Energy Physics Volume 2018, Article ID 5806743,\n  16 pages", "doi": "10.1155/2018/5806743", "report-no": null, "categories": "hep-ph cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we have studied that the implication of a large value\nof the effective Majorana neutrino mass in case of neutrino mass matrices\nhaving either two equal elements and one zero element (popularly known as\nhybrid texture) or two equal cofactors and one zero minor (popularly known as\ninverse hybrid texture) in the flavor basis. In each of these cases, four out\nof sixty phenomenologically possible patterns predict near maximal atmospheric\nneutrino mixing angle in the limit of large effective Majorana neutrino mass.\nThis feature remains irrespective of the experimental data on solar and reactor\nmixing angles. In addition, we have also performed the comparative study of all\nthe viable cases of hybrid and inverse hybrid textures at 3$\\sigma$ CL.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 17:45:10 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Singh", "Madan", ""]]}, {"id": "1803.10765", "submitter": "Kurt Riedel", "authors": "Kurt S. Riedel", "title": "Generalized Epsilon-Pseudospectra", "comments": null, "journal-ref": "SIAM Journal on Numerical Analysis Vol. 31, No. 4 (Aug., 1994),\n  pp. 1219-1225", "doi": null, "report-no": null, "categories": "math.NA cs.NA cs.SY eess.SY math.SP physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize $\\epsilon$-pseudospectra and the associated computational\nalgorithms to the generalized eigenvalue problem. Rank one perturbations are\nused to determine the $\\epsilon$-pseudospectra.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 03:48:35 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Riedel", "Kurt S.", ""]]}, {"id": "1803.10887", "submitter": "Thi Kim Thoa Thieu", "authors": "Vo Anh Khoa, Thieu Thi Kim Thoa and Ekeoma Rowland Ijioma", "title": "On a pore-scale stationary diffusion equation: scaling effects and\n  correctors for the homogenization limit", "comments": "29 pages, 14 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a microscopic semilinear elliptic equation posed\nin periodically perforated domains and associated with the Fourier-type\ncondition on internal micro-surfaces. The first contribution of this work is\nthe construction of a reliable linearization scheme that allows us, by a\nsuitable choice of scaling arguments and stabilization constants, to prove the\nweak solvability of the microscopic model. Asymptotic behaviors of the\nmicroscopic solution with respect to the microscale parameter are thoroughly\ninvestigated in the second theme, based upon several cases of scaling. In\nparticular, the variable scaling illuminates the trivial and non-trivial limits\nat the macroscale, confirmed by certain rates of convergence. Relying on\nclassical results for homogenization of multiscale elliptic problems, we design\na modified two-scale asymptotic expansion to derive the corresponding\nmacroscopic equation, when the scaling choices are compatible. Moreover, we\nprove the high-order corrector estimates for the homogenization limit in the\nenergy space $H^1$, using a large amount of energy-like estimates. A numerical\nexample is provided to corroborate the asymptotic analysis.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 00:49:48 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 12:54:39 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Khoa", "Vo Anh", ""], ["Thoa", "Thieu Thi Kim", ""], ["Ijioma", "Ekeoma Rowland", ""]]}, {"id": "1803.10986", "submitter": "Barbara Barabasz", "authors": "Barbara Barabasz, Andrew Anderson, Kirk M. Soodhalter and David Gregg", "title": "Error Analysis and Improving the Accuracy of Winograd Convolution for\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular deep neural networks (DNNs) spend the majority of their execution\ntime computing convolutions. The Winograd family of algorithms can greatly\nreduce the number of arithmetic operations required and is present in many DNN\nsoftware frameworks. However, the performance gain is at the expense of a\nreduction in floating point (FP) numerical accuracy. In this paper, we analyse\nthe worst case FP error and prove the estimation of norm and conditioning of\nthe algorithm. We show that the bound grows exponentially with the size of the\nconvolution, but the error bound of the \\textit{modified} algorithm is smaller\nthan the original one. We propose several methods for reducing FP error. We\npropose a canonical evaluation ordering based on Huffman coding that reduces\nsummation error. We study the selection of sampling \"points\" experimentally and\nfind empirically good points for the most important sizes. We identify the main\nfactors associated with good points. In addition, we explore other methods to\nreduce FP error, including mixed-precision convolution, and pairwise summation\nacross DNN channels. Using our methods we can significantly reduce FP error for\na given block size, which allows larger block sizes and reduced computation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 09:48:02 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 17:32:05 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 19:38:11 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Barabasz", "Barbara", ""], ["Anderson", "Andrew", ""], ["Soodhalter", "Kirk M.", ""], ["Gregg", "David", ""]]}, {"id": "1803.10991", "submitter": "Amir Sagiv", "authors": "Adi Ditkowski, Gadi Fibich, and Amir Sagiv", "title": "Density Estimation in Uncertainty Propagation Problems Using a Surrogate\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effect of uncertainties and noise on a quantity of interest (model\noutput) is often better described by its probability density function (PDF)\nthan by its moments. Although density estimation is a common task, the adequacy\nof approximation methods (surrogate models) for density estimation has not been\nanalyzed before in the uncertainty-quantification (UQ) literature. In this\npaper, we first show that standard surrogate models (such as generalized\npolynomial chaos), which are highly accurate for moment estimation, might\ncompletely fail to approximate the PDF, even for one-dimensional noise. This is\nbecause density estimation requires that the surrogate model accurately\napproximates the gradient of the quantity of interest, and not just the\nquantity of interest itself. Hence, we develop a novel spline-based algorithm\nfor density-estimation whose convergence rate in $L^q$ is polynomial in the\nsampling resolution. This convergence rate is better than that of standard\nstatistical density-estimation methods (such as histograms and kernel density\nestimators) at dimensions $1 \\leq d\\leq \\frac{5}{2}m$, where $m$ is the spline\norder. Furthermore, we obtain the convergence rate for density estimation with\nany surrogate model that approximates the quantity of interest and its gradient\nin $L^{\\infty}$. Finally, we demonstrate our algorithm for problems in\nnonlinear optics and fluid dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 09:54:13 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 16:46:40 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 12:35:35 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Ditkowski", "Adi", ""], ["Fibich", "Gadi", ""], ["Sagiv", "Amir", ""]]}, {"id": "1803.11131", "submitter": "Pushpendra Singh", "authors": "Pushpendra Singh", "title": "Novel Fourier Quadrature Transforms and Analytic Signal Representations\n  for Nonlinear and Non-stationary Time Series Analysis", "comments": "22 pages, 13 figures", "journal-ref": "Royal Society Open Science, November 28, 2018", "doi": "10.1098/rsos.181131", "report-no": null, "categories": "eess.SP cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hilbert transform (HT) and associated Gabor analytic signal (GAS)\nrepresentation are well-known and widely used mathematical formulations for\nmodeling and analysis of signals in various applications. In this study, like\nthe HT, to obtain quadrature component of a signal, we propose the novel\ndiscrete Fourier cosine quadrature transforms (FCQTs) and discrete Fourier sine\nquadrature transforms (FSQTs), designated as Fourier quadrature transforms\n(FQTs). Using these FQTs, we propose sixteen Fourier-Singh analytic signal\n(FSAS) representations with following properties: (1) real part of eight FSAS\nrepresentations is the original signal and imaginary part is the FCQT of the\nreal part, (2) imaginary part of eight FSAS representations is the original\nsignal and real part is the FSQT of the real part, (3) like the GAS, Fourier\nspectrum of the all FSAS representations has only positive frequencies, however\nunlike the GAS, the real and imaginary parts of the proposed FSAS\nrepresentations are not orthogonal to each other. The Fourier decomposition\nmethod (FDM) is an adaptive data analysis approach to decompose a signal into a\nset of small number of Fourier intrinsic band functions which are AM-FM\ncomponents. This study also proposes a new formulation of the FDM using the\ndiscrete cosine transform (DCT) with the GAS and FSAS representations, and\ndemonstrate its efficacy for improved time-frequency-energy representation and\nanalysis of nonlinear and non-stationary time series.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 16:38:55 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Singh", "Pushpendra", ""]]}, {"id": "1803.11191", "submitter": "Zhenning Cai", "authors": "Yanli Wang and Zhenning Cai", "title": "Approximation of the Boltzmann Collision Operator Based on Hermite\n  Spectral Method", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.07.014", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the Hermite expansion of the distribution function, we introduce a\nGalerkin spectral method for the spatially homogeneous Boltzmann equation with\nthe realistic inverse-power-law models. A practical algorithm is proposed to\nevaluate the coefficients in the spectral method with high accuracy, and these\ncoefficients are also used to construct new computationally affordable\ncollision models. Numerical experiments show that our method captures the\nlow-order moments very efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 07:06:34 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 15:45:27 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 18:11:19 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Yanli", ""], ["Cai", "Zhenning", ""]]}]