[{"id": "1802.00197", "submitter": "Jens Markus Melenk", "authors": "Jens Markus Melenk and Claudio Rojik", "title": "On commuting $p$-version projection-based interpolation on tetrahedra", "comments": null, "journal-ref": "Math. Comp.89 (2019), pp. 45-87", "doi": "10.1090/mcom/3454", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the reference tetrahedron $\\widehat K$, we define three projection-based\ninterpolation operators on $H^2(\\widehat K)$, ${\\mathbf H}^1(\\widehat\nK,\\operatorname{\\mathbf{curl}})$, and ${\\mathbf H}^1(\\widehat\nK,\\operatorname{div})$. These operators are projections onto space of\npolynomials, they have the commuting diagram property and feature the optimal\nconvergence rate as the polynomial degree increases in $H^{1-s}(\\widehat K)$,\n${\\mathbf H}^{-s}(\\widehat K,\\operatorname{\\mathbf{curl}})$, ${\\mathbf\nH}^{-s}(\\widehat K,\\operatorname{div})$ for $0 \\leq s \\leq 1$.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 08:54:13 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 13:35:41 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 14:49:34 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 13:09:06 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Melenk", "Jens Markus", ""], ["Rojik", "Claudio", ""]]}, {"id": "1802.00330", "submitter": "Liangyu Chen", "authors": "Dang Lin, Liangyu Chen", "title": "An efficient algorithm for global interval solution of nonlinear\n  algebraic equations and its GPGPU implementation", "comments": "21pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving nonlinear algebraic equations is a classic mathematics problem, and\ncommon in scientific researches and engineering applications. There are many\nnumeric, symbolic and numeric-symbolic methods of solving (real) solutions.\nUnlucky, these methods are constrained by some factors, e.g., high complexity,\nslow serial calculation, and the notorious intermediate expression expansion.\nEspecially when the count of variables is larger than six, the efficiency is\ndecreasing drastically. In this paper, according to the property of physical\nworld, we pay attention to nonlinear algebraic equations whose variables are in\nfixed constraints, and get meaningful real solutions. Combining with\nparallelism of GPGPU, we present an efficient algorithm, by searching the\nsolution space globally and solving the nonlinear algebraic equations with real\ninterval solutions. Furthermore, we realize the Hansen-Sengupta method on\nGPGPU. The experiments show that our method can solve many nonlinear algebraic\nequations, and the results are accurate and more efficient compared to\ntraditional serial methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 13:29:50 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Lin", "Dang", ""], ["Chen", "Liangyu", ""]]}, {"id": "1802.00602", "submitter": "Ben Adcock", "authors": "Ben Adcock and Daan Huybrechs", "title": "Approximating smooth, multivariate functions on irregular domains", "comments": null, "journal-ref": "Forum of Mathematics, Sigma 8 (2020) e26", "doi": "10.1017/fms.2020.23", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a method known as polynomial frame approximation\nfor approximating smooth, multivariate functions defined on irregular domains\nin $d$ dimensions, where $d$ can be arbitrary. This method is simple, and\nrelies only on orthogonal polynomials on a bounding tensor-product domain. In\nparticular, the domain of the function need not be known in advance. When\nrestricted to a subdomain, an orthonormal basis is no longer a basis, but a\nframe. Numerical computations with frames present potential difficulties, due\nto the near-linear dependence of the truncated approximation system.\nNevertheless, well-conditioned approximations can be obtained via\nregularization, for instance, truncated singular value decompositions. We\ncomprehensively analyze such approximations in this paper, providing error\nestimates for functions with both classical and mixed Sobolev regularity, with\nthe latter being particularly suitable for higher-dimensional problems. We also\nanalyze the sample complexity of the approximation for sample points chosen\nrandomly according to a probability measure, providing estimates in terms of\nthe corresponding \\textit{Nikolskii inequality} for the domain. In particular,\nwe show that the sample complexity for points drawn from the uniform measure is\nquadratic (up to a log factor) in the dimension of the polynomial space,\nindependently of $d$, for a large class of nontrivial domains. This extends a\nwell-known result for polynomial approximation in hypercubes.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 08:57:09 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 19:55:26 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 22:26:00 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Adcock", "Ben", ""], ["Huybrechs", "Daan", ""]]}, {"id": "1802.00930", "submitter": "Dheevatsa Mudigere", "authors": "Dipankar Das, Naveen Mellempudi, Dheevatsa Mudigere, Dhiraj Kalamkar,\n  Sasikanth Avancha, Kunal Banerjee, Srinivas Sridharan, Karthik Vaidyanathan,\n  Bharat Kaul, Evangelos Georganas, Alexander Heinecke, Pradeep Dubey, Jesus\n  Corbal, Nikita Shustrov, Roma Dubtsov, Evarist Fomenko, Vadim Pirogov", "title": "Mixed Precision Training of Convolutional Neural Networks using Integer\n  Operations", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art (SOTA) for mixed precision training is dominated by\nvariants of low precision floating point operations, and in particular, FP16\naccumulating into FP32 Micikevicius et al. (2017). On the other hand, while a\nlot of research has also happened in the domain of low and mixed-precision\nInteger training, these works either present results for non-SOTA networks (for\ninstance only AlexNet for ImageNet-1K), or relatively small datasets (like\nCIFAR-10). In this work, we train state-of-the-art visual understanding neural\nnetworks on the ImageNet-1K dataset, with Integer operations on General Purpose\n(GP) hardware. In particular, we focus on Integer Fused-Multiply-and-Accumulate\n(FMA) operations which take two pairs of INT16 operands and accumulate results\ninto an INT32 output.We propose a shared exponent representation of tensors and\ndevelop a Dynamic Fixed Point (DFP) scheme suitable for common neural network\noperations. The nuances of developing an efficient integer convolution kernel\nis examined, including methods to handle overflow of the INT32 accumulator. We\nimplement CNN training for ResNet-50, GoogLeNet-v1, VGG-16 and AlexNet; and\nthese networks achieve or exceed SOTA accuracy within the same number of\niterations as their FP32 counterparts without any change in hyper-parameters\nand with a 1.8X improvement in end-to-end training throughput. To the best of\nour knowledge these results represent the first INT16 training results on GP\nhardware for ImageNet-1K dataset using SOTA CNNs and achieve highest reported\naccuracy using half-precision\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 07:01:48 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 18:02:58 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Das", "Dipankar", ""], ["Mellempudi", "Naveen", ""], ["Mudigere", "Dheevatsa", ""], ["Kalamkar", "Dhiraj", ""], ["Avancha", "Sasikanth", ""], ["Banerjee", "Kunal", ""], ["Sridharan", "Srinivas", ""], ["Vaidyanathan", "Karthik", ""], ["Kaul", "Bharat", ""], ["Georganas", "Evangelos", ""], ["Heinecke", "Alexander", ""], ["Dubey", "Pradeep", ""], ["Corbal", "Jesus", ""], ["Shustrov", "Nikita", ""], ["Dubtsov", "Roma", ""], ["Fomenko", "Evarist", ""], ["Pirogov", "Vadim", ""]]}, {"id": "1802.00984", "submitter": "Frank Sottile", "authors": "Anton Leykin and Abraham Martin del Campo and Frank Sottile and Ravi\n  Vakil and Jan Verschelde", "title": "Numerical Schubert Calculus via the Littlewood-Richardson Homotopy\n  Algorithm", "comments": "27 pages, many figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the Littlewood-Richardson homotopy algorithm, which uses numerical\ncontinuation to compute solutions to Schubert problems on Grassmannians and is\nbased on the geometric Littlewood-Richardson rule. One key ingredient of this\nalgorithm is our new optimal formulation of Schubert problems in local Stiefel\ncoordinates as systems of equations. Our implementation can solve problem\ninstances with tens of thousands of solutions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 14:56:58 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 17:42:35 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 16:07:43 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Leykin", "Anton", ""], ["del Campo", "Abraham Martin", ""], ["Sottile", "Frank", ""], ["Vakil", "Ravi", ""], ["Verschelde", "Jan", ""]]}, {"id": "1802.01353", "submitter": "Andrei Ivanov", "authors": "Andrei Ivanov, Alena Sholokhova, Sergei Andrianov, Roman\n  Konoplev-Esgenburg", "title": "Lie Transform--based Neural Networks for Dynamics Simulation and\n  Learning", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.NA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the article, we discuss the architecture of the polynomial neural network\nthat corresponds to the matrix representation of Lie transform. The matrix form\nof Lie transform is an approximation of the general solution of the nonlinear\nsystem of ordinary differential equations. The proposed architecture can be\ntrained with small data sets, extrapolate predictions outside the training\ndata, and provide a possibility for interpretation. We provide a theoretical\nexplanation of the proposed architecture, as well as demonstrate it in several\napplications. We present the results of modeling and identification for both\nsimple and well-known dynamical systems, and more complicated examples from\nprice dynamics, chemistry, and accelerator physics. From a practical point of\nview, we describe the training of a Lie transform--based neural network with a\nsmall data set containing only 10 data points. We also demonstrate an\ninterpretation of the fitted neural network by converting it to a system of\ndifferential equations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 11:25:54 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 08:41:41 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Ivanov", "Andrei", ""], ["Sholokhova", "Alena", ""], ["Andrianov", "Sergei", ""], ["Konoplev-Esgenburg", "Roman", ""]]}, {"id": "1802.01950", "submitter": "Ben Adcock", "authors": "Ben Adcock and Daan Huybrechs", "title": "Frames and numerical approximation II: generalized sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous paper [Adcock & Huybrechs, 2019] we described the numerical\napproximation of functions using redundant sets and frames. Redundancy in the\nfunction representation offers enormous flexibility compared to using a basis,\nbut ill-conditioning often prevents the numerical computation of best\napproximations. We showed that, in spite of said ill-conditioning,\napproximations with regularization may still provide accuracy up to order\n$\\sqrt{\\epsilon}$, where $\\epsilon$ is a small truncation threshold. When using\nframes, i.e. complete systems that are generally redundant but which provide\ninfinite representations with coefficients of bounded norm, this accuracy can\nactually be achieved for all functions in a space. Here, we generalize that\nsetting in two ways. We assume information or samples from $f$ from a wide\nclass of linear operators acting on $f$, rather than inner products associated\nwith the best approximation projection. This enables the analysis of fully\ndiscrete approximations based, for instance, on function values only. Next, we\nallow oversampling, leading to least-squares approximations. We show that this\nleads to much improved accuracy on the order of $\\epsilon$ rather than\n$\\sqrt{\\epsilon}$. Overall, we demonstrate that numerical function\napproximation using redundant representations may lead to highly accurate\napproximations in spite of having to solve ill-conditioned systems of\nequations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 14:03:19 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 21:56:18 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 21:17:28 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Adcock", "Ben", ""], ["Huybrechs", "Daan", ""]]}, {"id": "1802.02015", "submitter": "Sohrab Valizadeh", "authors": "Sohrab Valizadeh, Alaeddin Malek and Abdollah Borhanifar", "title": "Compact ADI method for solving two-dimensional Riesz space fractional\n  diffusion equation", "comments": "16 pages, 2 tables, This article has not been published in any\n  journals", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a compact alternating direction implicit (ADI) method has been\ndeveloped for solving two-dimensional Riesz space fractional diffusion\nequation. The precision of the discretization method used in spatial directions\nis twice the order of the corresponding fractional derivatives. It is proved\nthat the proposed method is unconditionally stable via the matrix analysis\nmethod and the maximum error in achieving convergence is discussed. Several\nnumerical examples are considered aiming to demonstrate the validity and\napplicability of the proposed technique.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 15:54:26 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 21:44:14 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 08:36:34 GMT"}, {"version": "v4", "created": "Sat, 18 Apr 2020 18:42:27 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Valizadeh", "Sohrab", ""], ["Malek", "Alaeddin", ""], ["Borhanifar", "Abdollah", ""]]}, {"id": "1802.02035", "submitter": "Laurent van den Bos", "authors": "L.M.M. van den Bos, B. Sanderse, W.A.A.M. Bierbooms, and G.J.W. van\n  Bussel", "title": "Bayesian model calibration with interpolating polynomials based on\n  adaptively weighted Leja nodes", "comments": null, "journal-ref": "Communication in Computational Physics 27(1):33-69, 2020", "doi": "10.4208/cicp.OA-2018-0218", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient algorithm is proposed for Bayesian model calibration, which is\ncommonly used to estimate the model parameters of non-linear, computationally\nexpensive models using measurement data. The approach is based on Bayesian\nstatistics: using a prior distribution and a likelihood, the posterior\ndistribution is obtained through application of Bayes' law. Our novel algorithm\nto accurately determine this posterior requires significantly fewer discrete\nmodel evaluations than traditional Monte Carlo methods. The key idea is to\nreplace the expensive model by an interpolating surrogate model and to\nconstruct the interpolating nodal set maximizing the accuracy of the posterior.\nTo determine such a nodal set an extension to weighted Leja nodes is\nintroduced, based on a new weighting function. We prove that the convergence of\nthe posterior has the same rate as the convergence of the model. If the\nconvergence of the posterior is measured in the Kullback-Leibler divergence,\nthe rate doubles. The algorithm and its theoretical properties are verified in\nthree different test cases: analytical cases that confirm the correctness of\nthe theoretical findings, Burgers' equation to show its applicability in\nimplicit problems, and finally the calibration of the closure parameters of a\nturbulence model to show the effectiveness for computationally expensive\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 16:20:49 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 14:09:40 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 10:35:08 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Bos", "L. M. M. van den", ""], ["Sanderse", "B.", ""], ["Bierbooms", "W. A. A. M.", ""], ["van Bussel", "G. J. W.", ""]]}, {"id": "1802.02098", "submitter": "Camille Negrello", "authors": "Camille Negrello (LMT), Pierre Gosselet (LMT), Christian Rey", "title": "A new impedance accounting for short and long range effects in mixed\n  substructured formulations of nonlinear problems", "comments": null, "journal-ref": "International Journal for Numerical Methods in Engineering, Wiley,\n  2018, 10.1002/nme.5195", "doi": "10.1002/nme.5195", "report-no": null, "categories": "math.NA cs.DC cs.NA physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient method for solving large nonlinear problems combines Newton\nsolvers and Domain Decomposition Methods (DDM). In the DDM framework, the\nboundary conditions can be chosen to be primal, dual or mixed. The mixed\napproach presents the advantage to be eligible for the research of an optimal\ninterface parameter (often called impedance) which can increase the convergence\nrate. The optimal value for this parameter is often too expensive to be\ncomputed exactly in practice: an approximate version has to be sought for,\nalong with a compromise between efficiency and computational cost. In the\ncontext of parallel algorithms for solving nonlinear structural mechanical\nproblems, we propose a new heuristic for the impedance which combines short and\nlong range effects at a low computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 10:45:19 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Negrello", "Camille", "", "LMT"], ["Gosselet", "Pierre", "", "LMT"], ["Rey", "Christian", ""]]}, {"id": "1802.02123", "submitter": "Antonio Huerta", "authors": "Ruben Sevilla, Matteo Giacomini, Alexandros Karkoulias, and Antonio\n  Huerta", "title": "A super--convergent hybridisable discontinuous Galerkin method for\n  linear elasticity", "comments": "37 pages, 18 figures", "journal-ref": "Int. J. Numer. Methods Eng. Vol. 116, Issue 2, pp. 91-116 (2018)", "doi": "10.1002/nme.5916", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first super-convergent hybridisable discontinuous Galerkin (HDG) method\nfor linear elastic problems capable of using the same degree of approximation\nfor both the primal and mixed variables is presented. The key feature of the\nmethod is the strong imposition of the symmetry of the stress tensor by means\nof the well-known and extensively used Voigt notation, circumventing the use of\ncomplex mathematical concepts to enforce the symmetry of the stress tensor\neither weakly or strongly. A novel procedure to construct element-by-element a\nsuper-convergent post-processed displacement is proposed. Contrary to other HDG\nformulations, the methodology proposed here is able to produce a\nsuper-convergent displacement field for low order approximations. The resulting\nmethod is robust and locking-free in the nearly-incompressible limit. An\nextensive set of numerical examples is utilised to provide evidence of the\noptimality of the method and its super-convergent properties in two and three\ndimensions and for different element types.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 18:39:21 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Sevilla", "Ruben", ""], ["Giacomini", "Matteo", ""], ["Karkoulias", "Alexandros", ""], ["Huerta", "Antonio", ""]]}, {"id": "1802.02724", "submitter": "Yangyang Xu", "authors": "Yangyang Xu", "title": "Primal-dual stochastic gradient method for convex programs with many\n  functional constraints", "comments": "One technical mistake was corrected, and a feature with adaptive\n  learning was added to the algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient method (SGM) has been popularly applied to solve\noptimization problems with objective that is stochastic or an average of many\nfunctions. Most existing works on SGMs assume that the underlying problem is\nunconstrained or has an easy-to-project constraint set. In this paper, we\nconsider problems that have a stochastic objective and also many functional\nconstraints. For such problems, it could be extremely expensive to project a\npoint to the feasible set, or even compute subgradient and/or function value of\nall constraint functions. To find solutions of these problems, we propose a\nnovel (adaptive) SGM based on the classical augmented Lagrangian function.\nWithin every iteration, it inquires a stochastic subgradient of the objective,\nand a subgradient and the function value of one randomly sampled constraint\nfunction. Hence, the per-iteration complexity is low. We establish its\nconvergence rate for convex problems and also problems with strongly convex\nobjective. It can achieve the optimal $O(1/\\sqrt{k})$ convergence rate for\nconvex case and nearly optimal $O\\big((\\log k)/k\\big)$ rate for strongly convex\ncase. Numerical experiments on a sample approximation problem of the robust\nportfolio selection and quadratically constrained quadratic programming are\nconducted to demonstrate its efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 05:54:22 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 18:01:22 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Xu", "Yangyang", ""]]}, {"id": "1802.02978", "submitter": "Niklas Georg", "authors": "Niklas Georg, Wolfgang Ackermann, Jacopo Corno, Sebastian Sch\\\"ops", "title": "Uncertainty Quantification for Maxwell's Eigenproblem based on\n  Isogeometric Analysis and Mode Tracking", "comments": null, "journal-ref": "Comput. Method Appl. M., 350(15): 228-244, 2019", "doi": "10.1016/j.cma.2019.03.002", "report-no": null, "categories": "cs.CE cs.NA math.NA physics.acc-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electromagnetic field distribution as well as the resonating frequency of\nvarious modes in superconducting cavities used in particle accelerators for\nexample are sensitive to small geometry deformations. The occurring variations\nare motivated by measurements of an available set of resonators from which we\npropose to extract a small number of relevant and independent deformations by\nusing a truncated Karhunen-Lo\\`eve expansion. The random deformations are used\nin an expressive uncertainty quantification workflow to determine the\nsensitivity of the eigenmodes. For the propagation of uncertainty, a stochastic\ncollocation method based on sparse grids is employed. It requires the repeated\nsolution of Maxwell's eigenvalue problem at predefined collocation points,\ni.e., for cavities with perturbed geometry. The main contribution of the paper\nis ensuring the consistency of the solution, i.e., matching the eigenpairs,\namong the various eigenvalue problems at the stochastic collocation points. To\nthis end, a classical eigenvalue tracking technique is proposed that is based\non homotopies between collocation points and a Newton-based eigenvalue solver.\nThe approach can be efficiently parallelized while tracking the eigenpairs. In\nthis paper, we propose the application of isogeometric analysis since it allows\nfor the exact description of the geometrical domains with respect to common\ncomputer-aided design kernels, for a straightforward and convenient way of\nhandling geometrical variations and smooth solutions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 17:40:03 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 20:31:38 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 16:21:35 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Georg", "Niklas", ""], ["Ackermann", "Wolfgang", ""], ["Corno", "Jacopo", ""], ["Sch\u00f6ps", "Sebastian", ""]]}, {"id": "1802.03064", "submitter": "Dirk Pfl\\\"uger", "authors": "Markus K\\\"oppel and Fabian Franzelin and Ilja Kr\\\"oker and Sergey\n  Oladyshkin and Gabriele Santin and Dominik Wittwar and Andrea Barth and\n  Bernard Haasdonk and Wolfgang Nowak and Dirk Pfl\\\"uger and Christian Rohde", "title": "Comparison of data-driven uncertainty quantification methods for a\n  carbon dioxide storage benchmark scenario", "comments": null, "journal-ref": null, "doi": "10.1007/s10596-018-9785-x", "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of methods is available to quantify uncertainties arising with\\-in\nthe modeling of flow and transport in carbon dioxide storage, but there is a\nlack of thorough comparisons. Usually, raw data from such storage sites can\nhardly be described by theoretical statistical distributions since only very\nlimited data is available. Hence, exact information on distribution shapes for\nall uncertain parameters is very rare in realistic applications. We discuss and\ncompare four different methods tested for data-driven uncertainty\nquantification based on a benchmark scenario of carbon dioxide storage. In the\nbenchmark, for which we provide data and code, carbon dioxide is injected into\na saline aquifer modeled by the nonlinear capillarity-free fractional flow\nformulation for two incompressible fluid phases, namely carbon dioxide and\nbrine. To cover different aspects of uncertainty quantification, we incorporate\nvarious sources of uncertainty such as uncertainty of boundary conditions, of\nconceptual model definitions and of material properties. We consider recent\nversions of the following non-intrusive and intrusive uncertainty\nquantification methods: arbitary polynomial chaos, spatially adaptive sparse\ngrids, kernel-based greedy interpolation and hybrid stochastic Galerkin. The\nperformance of each approach is demonstrated assessing expectation value and\nstandard deviation of the carbon dioxide saturation against a reference\nstatistic based on Monte Carlo sampling. We compare the convergence of all\nmethods reporting on accuracy with respect to the number of model runs and\nresolution. Finally we offer suggestions about the methods' advantages and\ndisadvantages that can guide the modeler for uncertainty quantification in\ncarbon dioxide storage and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 22:27:38 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["K\u00f6ppel", "Markus", ""], ["Franzelin", "Fabian", ""], ["Kr\u00f6ker", "Ilja", ""], ["Oladyshkin", "Sergey", ""], ["Santin", "Gabriele", ""], ["Wittwar", "Dominik", ""], ["Barth", "Andrea", ""], ["Haasdonk", "Bernard", ""], ["Nowak", "Wolfgang", ""], ["Pfl\u00fcger", "Dirk", ""], ["Rohde", "Christian", ""]]}, {"id": "1802.03430", "submitter": "Sinong Wang", "authors": "Sinong Wang, Jiashang Liu and Ness Shroff", "title": "Coded Sparse Matrix Multiplication", "comments": "new comparisons with existing sparse codes are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a large-scale and distributed matrix multiplication problem\n$C=A^{\\intercal}B$, where $C\\in\\mathbb{R}^{r\\times t}$, the coded computation\nplays an important role to effectively deal with \"stragglers\" (distributed\ncomputations that may get delayed due to few slow or faulty processors).\nHowever, existing coded schemes could destroy the significant sparsity that\nexists in large-scale machine learning problems, and could result in much\nhigher computation overhead, i.e., $O(rt)$ decoding time. In this paper, we\ndevelop a new coded computation strategy, we call \\emph{sparse code}, which\nachieves near \\emph{optimal recovery threshold}, \\emph{low computation\noverhead}, and \\emph{linear decoding time} $O(nnz(C))$. We implement our scheme\nand demonstrate the advantage of the approach over both uncoded and current\nfastest coded strategies.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 19:49:36 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 21:18:04 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Wang", "Sinong", ""], ["Liu", "Jiashang", ""], ["Shroff", "Ness", ""]]}, {"id": "1802.03527", "submitter": "Khalide Jbilou", "authors": "A. Bentbib, M. El Guide, K. Jbilou", "title": "A generalized matrix Krylov subspace method for TV regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient algorithm to solve total variation (TV)\nregularizations of images contaminated by a both blur and noise. The\nunconstrained structure of the problem suggests that one can solve a\nconstrained optimization problem by transforming the original unconstrained\nminimization problem to an equivalent constrained minimization one. An\naugmented Lagrangian method is developed to handle the constraints when the\nmodel is given with matrix variables, and an alternating direction method (ADM)\nis used to iteratively find solutions. The solutions of some sub-problems are\nbelonging to subspaces generated by application of successive orthogonal\nprojections onto a class of generalized matrix Krylov subspaces of increasing\ndimension.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 06:11:05 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Bentbib", "A.", ""], ["Guide", "M. El", ""], ["Jbilou", "K.", ""]]}, {"id": "1802.03770", "submitter": "Victor Minden", "authors": "Victor Minden and Lexing Ying", "title": "A simple solver for the fractional Laplacian in multiple dimensions", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple discretization scheme for the hypersingular integral\nrepresentation of the fractional Laplace operator and solver for the\ncorresponding fractional Laplacian problem. Through singularity subtraction, we\nobtain a regularized integrand that is amenable to the trapezoidal rule with\nequispaced nodes, assuming a high degree of regularity in the underlying\nfunction (i.e., $u\\in C^6(R^d)$). The resulting quadrature scheme gives a\ndiscrete operator on a regular grid that is translation-invariant and thus can\nbe applied quickly with the fast Fourier transform. For discretizations of\nproblems related to space-fractional diffusion on bounded domains, we observe\nthat the underlying linear system can be efficiently solved via preconditioned\nKrylov methods with a preconditioner based on the finite-difference\n(non-fractional) Laplacian. We show numerical results illustrating the error of\nour simple scheme as well the efficiency of our preconditioning approach, both\nfor the elliptic (steady-state) fractional diffusion problem and the\ntime-dependent problem.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 17:01:41 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 18:51:14 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 14:05:04 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Minden", "Victor", ""], ["Ying", "Lexing", ""]]}, {"id": "1802.03773", "submitter": "Jan Svoboda", "authors": "Jan Svoboda, Thomas Cashman, Andrew Fitzgibbon", "title": "QRkit: Sparse, Composable QR Decompositions for Efficient and Stable\n  Solutions to Problems in Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded computer vision applications increasingly require the speed and\npower benefits of single-precision (32 bit) floating point. However,\napplications which make use of Levenberg-like optimization can lose significant\naccuracy when reducing to single precision, sometimes unrecoverably so. This\naccuracy can be regained using solvers based on QR rather than Cholesky\ndecomposition, but the absence of sparse QR solvers for common sparsity\npatterns found in computer vision means that many applications cannot benefit.\nWe introduce an open-source suite of solvers for Eigen, which efficiently\ncompute the QR decomposition for matrices with some common sparsity patterns\n(block diagonal, horizontal and vertical concatenation, and banded). For\nproblems with very particular sparsity structures, these elements can be\ncomposed together in 'kit' form, hence the name QRkit. We apply our methods to\nseveral computer vision problems, showing competitive performance and\nsuitability especially in single precision arithmetic.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 17:18:18 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Svoboda", "Jan", ""], ["Cashman", "Thomas", ""], ["Fitzgibbon", "Andrew", ""]]}, {"id": "1802.03948", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson (LFANT), Marc Mezzarobba (ARIC)", "title": "Fast and rigorous arbitrary-precision computation of Gauss-Legendre\n  quadrature nodes and weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a strategy for rigorous arbitrary-precision evaluation of\nLegendre polynomials on the unit interval and its application in the generation\nof Gauss-Legendre quadrature rules. Our focus is on making the evaluation\npractical for a wide range of realistic parameters, corresponding to the\nrequirements of numerical integration to an accuracy of about 100 to 100 000\nbits. Our algorithm combines the summation by rectangular splitting of several\ntypes of expansions in terms of hypergeometric series with a fixed-point\nimplementation of Bonnet's three-term recurrence relation. We then compute\nrigorous enclosures of the Gauss-Legendre nodes and weights using the interval\nNewton method. We provide rigorous error bounds for all steps of the algorithm.\nThe approach is validated by an implementation in the Arb library, which\nachieves order-of-magnitude speedups over previous code for computing\nGauss-Legendre rules with simultaneous high degree and precision.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 09:47:05 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 07:33:50 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Johansson", "Fredrik", "", "LFANT"], ["Mezzarobba", "Marc", "", "ARIC"]]}, {"id": "1802.04079", "submitter": "Filip Hanzely", "authors": "Robert M. Gower, Filip Hanzely, Peter Richt\\'arik and Sebastian Stich", "title": "Accelerated Stochastic Matrix Inversion: General Theory and Speeding up\n  BFGS Rules for Faster Second-Order Optimization", "comments": "37 pages, 32 figures, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first accelerated randomized algorithm for solving linear\nsystems in Euclidean spaces. One essential problem of this type is the matrix\ninversion problem. In particular, our algorithm can be specialized to invert\npositive definite matrices in such a way that all iterates (approximate\nsolutions) generated by the algorithm are positive definite matrices\nthemselves. This opens the way for many applications in the field of\noptimization and machine learning. As an application of our general theory, we\ndevelop the {\\em first accelerated (deterministic and stochastic) quasi-Newton\nupdates}. Our updates lead to provably more aggressive approximations of the\ninverse Hessian, and lead to speed-ups over classical non-accelerated rules in\nnumerical experiments. Experiments with empirical risk minimization show that\nour rules can accelerate training of machine learning models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 14:47:55 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 21:03:16 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Gower", "Robert M.", ""], ["Hanzely", "Filip", ""], ["Richt\u00e1rik", "Peter", ""], ["Stich", "Sebastian", ""]]}, {"id": "1802.04385", "submitter": "Victor Magron", "authors": "Victor Magron and Alexandre Rocca and Thao Dang", "title": "Certified Roundoff Error Bounds using Bernstein Expansions and Sparse\n  Krivine-Stengle Representations", "comments": "14 pages, 2 figures, 2 tables. Extension of the work in\n  arXiv:1610.07038", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floating point error is a drawback of embedded systems implementation that is\ndifficult to avoid. Computing rigorous upper bounds of roundoff errors is\nabsolutely necessary for the validation of critical software. This problem of\ncomputing rigorous upper bounds is even more challenging when addressing\nnon-linear programs. In this paper, we propose and compare two new algorithms\nbased on Bernstein expansions and sparse Krivine-Stengle representations,\nadapted from the field of the global optimization, to compute upper bounds of\nroundoff errors for programs implementing polynomial and rational functions. We\nalso provide the convergence rate of these two algorithms. We release two\nrelated software package FPBern and FPKriSten, and compare them with the\nstate-of-the-art tools. We show that these two methods achieve competitive\nperformance, while providing accurate upper bounds by comparison with the other\ntools.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 22:56:20 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Magron", "Victor", ""], ["Rocca", "Alexandre", ""], ["Dang", "Thao", ""]]}, {"id": "1802.04447", "submitter": "Yu Jin", "authors": "Yu Jin, Andreas Loukas, Joseph F. JaJa", "title": "Graph Coarsening with Preserved Spectral Properties", "comments": "Submitted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale graphs are widely used to represent object relationships in many\nreal world applications. The occurrence of large-scale graphs presents\nsignificant computational challenges to process, analyze, and extract\ninformation. Graph coarsening techniques are commonly used to reduce the\ncomputational load while attempting to maintain the basic structural properties\nof the original graph. As there is no consensus on the specific graph\nproperties preserved by coarse graphs, how to measure the differences between\noriginal and coarse graphs remains a key challenge. In this work, we introduce\na new perspective regarding the graph coarsening based on concepts from\nspectral graph theory. We propose and justify new distance functions that\ncharacterize the differences between original and coarse graphs. We show that\nthe proposed spectral distance naturally captures the structural differences in\nthe graph coarsening process. In addition, we provide efficient graph\ncoarsening algorithms to generate graphs which provably preserve the spectral\nproperties from original graphs. Experiments show that our proposed algorithms\nconsistently achieve better results compared to previous graph coarsening\nmethods on graph classification and block recovery tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 02:57:59 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 06:48:10 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Jin", "Yu", ""], ["Loukas", "Andreas", ""], ["JaJa", "Joseph F.", ""]]}, {"id": "1802.04475", "submitter": "Muni Sreenivas Pydi", "authors": "Muni Sreenivas Pydi, Varun Jog, Po-Ling Loh", "title": "Graph-Based Ascent Algorithms for Function Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding the maximum of a function defined on the\nnodes of a connected graph. The goal is to identify a node where the function\nobtains its maximum. We focus on local iterative algorithms, which traverse the\nnodes of the graph along a path, and the next iterate is chosen from the\nneighbors of the current iterate with probability distribution determined by\nthe function values at the current iterate and its neighbors. We study two\nalgorithms corresponding to a Metropolis-Hastings random walk with different\ntransition kernels: (i) The first algorithm is an exponentially weighted random\nwalk governed by a parameter $\\gamma$. (ii) The second algorithm is defined\nwith respect to the graph Laplacian and a smoothness parameter $k$. We derive\nconvergence rates for the two algorithms in terms of total variation distance\nand hitting times. We also provide simulations showing the relative convergence\nrates of our algorithms in comparison to an unbiased random walk, as a function\nof the smoothness of the graph function. Our algorithms may be categorized as a\nnew class of \"descent-based\" methods for function maximization on the nodes of\na graph.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 06:31:15 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Pydi", "Muni Sreenivas", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1802.04628", "submitter": "Gabriele Santin", "authors": "Tobias K\\\"oppl, Gabriele Santin, Bernard Haasdonk, and Rainer Helmig", "title": "Numerical modelling of a peripheral arterial stenosis using\n  dimensionally reduced models and kernel methods", "comments": null, "journal-ref": null, "doi": "10.1002/cnm.3095", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider two kinds of model reduction techniques to simulate\nblood flow through the largest systemic arteries, where a stenosis is located\nin a peripheral artery i.e. in an artery that is located far away from the\nheart. For our simulations we place the stenosis in one of the tibial arteries\nbelonging to the right lower leg (right post tibial artery). The model\nreduction techniques that are used are on the one hand dimensionally reduced\nmodels (1-D and 0-D models, the so-called mixed-dimension model) and on the\nother hand surrogate models produced by kernel methods. Both methods are\ncombined in such a way that the mixed-dimension models yield training data for\nthe surrogate model, where the surrogate model is parametrised by the degree of\nnarrowing of the peripheral stenosis. By means of a well-trained surrogate\nmodel, we show that simulation data can be reproduced with a satisfactory\naccuracy and that parameter optimisation or state estimation problems can be\nsolved in a very efficient way. Furthermore it is demonstrated that a surrogate\nmodel enables us to present after a very short simulation time the impact of a\nvarying degree of stenosis on blood flow, obtaining a speedup of several orders\nover the full model.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 14:06:22 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 10:01:01 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 09:24:27 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["K\u00f6ppl", "Tobias", ""], ["Santin", "Gabriele", ""], ["Haasdonk", "Bernard", ""], ["Helmig", "Rainer", ""]]}, {"id": "1802.04658", "submitter": "Inna K. Shingareva Dr. Prof.", "authors": "Andrei D. Polyanin, Inna K. Shingareva", "title": "Hypersingular nonlinear boundary-value problems with a small parameter", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA math-ph math.MP physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the first time, some hypersingular nonlinear boundary-value problems with\na small parameter~$\\varepsilon$ at the highest derivative are described. These\nproblems essentially (qualitatively and quantitatively) differ from the usual\nlinear and quasilinear singularly perturbed boundary-value problems and have\nthe following unusual properties:\n  (i) in hypersingular boundary-value problems, super thin boundary layers\narise, and the derivative at the boundary layer can have very large values of\nthe order of $e^{1/\\varepsilon}$ and more (in standard problems with boundary\nlayers, the derivative at the boundary has the order of $\\varepsilon^{-1}$ or\nless);\n  (ii) in hypersingular boundary-value problems, the position of the boundary\nlayer is determined by the values of the unknown function at the boundaries (in\nstandard problems with boundary layers, the position of the boundary layer is\ndetermined by coefficients of the given equation, and the values of the unknown\nfunction at the boundaries do not play a role here);\n  (iii) hypersingular boundary-value problems do not admit a direct application\nof the method of matched asymptotic expansions (without a preliminary nonlinear\npoint transformation of the equation under consideration).\n  Examples of hypersingular nonlinear boundary-value problems with ODEs and\nPDEs are given and their exact solutions are obtained. It is important to note\nthat the exact solutions presented in this paper can be used to compare the\neffectiveness of various methods of numerical integration of singularly\nperturbed problems with boundary layers, and also to develop new numerical and\napproximate analytical methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 06:31:32 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Polyanin", "Andrei D.", ""], ["Shingareva", "Inna K.", ""]]}, {"id": "1802.04963", "submitter": "Yuwen Li", "authors": "Randolph E. Bank and Yuwen Li", "title": "Superconvergent recovery of Raviart--Thomas mixed finite elements on\n  triangular grids", "comments": null, "journal-ref": "Journal of Scientific Computing 81:3, 1882-1905 (2019)", "doi": "10.1007/s10915-019-01068-0", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the second lowest-order Raviart--Thomas mixed method, we prove that the\ncanonical interpolant and finite element solution for the vector variable in\nelliptic problems are superclose in the $H(\\text{div})$-norm on mildly\nstructured meshes, where most pairs of adjacent triangles form approximate\nparallelograms. We then develop a family of postprocessing operators for\nRaviart--Thomas mixed elements on triangular grids by using the idea of local\nleast squares fittings. Super-approximation property of the postprocessing\noperators for the lowest and second lowest order Raviart--Thomas elements is\nproved under mild conditions. Combining the supercloseness and\nsuper-approximation results, we prove that the postprocessed solution\nsuperconverges to the exact solution in the $L^2$-norm on mildly structured\nmeshes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 05:36:56 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 01:54:59 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 18:02:17 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Bank", "Randolph E.", ""], ["Li", "Yuwen", ""]]}, {"id": "1802.05469", "submitter": "Petre Birtea", "authors": "Petre Birtea, Ioan Casu, Dan Comanescu", "title": "Second order optimality on orthogonal Stiefel manifolds", "comments": null, "journal-ref": null, "doi": "10.1016/j.bulsci.2020.102868", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main tool to study a second order optimality problem is the Hessian\noperator associated to the cost function that defines the optimization problem.\nBy regarding an orthogonal Stiefel manifold as a constraint manifold embedded\nin an Euclidean space we obtain a concise matrix formula for the Hessian of a\ncost function defined on such a manifold. We introduce an explicit local frame\non an orthogonal Stiefel manifold in order to compute the components of the\nHessian matrix of a cost function. We present some important properties of this\nframe. As applications we rediscover second order conditions of optimality for\nthe Procrustes and the Penrose regression problems (previously found in the\nliterature). For the Brockett problem we find necessary and sufficient\nconditions for a critical point to be a local minimum. Since many optimization\nproblems are approached using numerical algorithms, we give an explicit\ndescription of the Newton algorithm on orthogonal Stiefel manifolds.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 10:30:09 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 11:33:07 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 09:18:51 GMT"}, {"version": "v4", "created": "Fri, 8 Mar 2019 09:43:06 GMT"}, {"version": "v5", "created": "Mon, 4 May 2020 14:26:54 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Birtea", "Petre", ""], ["Casu", "Ioan", ""], ["Comanescu", "Dan", ""]]}, {"id": "1802.05681", "submitter": "Kristian Debrabant", "authors": "Olivier Bokanowski and Kristian Debrabant", "title": "Backward Differentiation Formula finite difference schemes for diffusion\n  equations with an obstacle term", "comments": null, "journal-ref": "IMA Journal of Numerical Analysis, Volume 41, Issue 2, April 2021,\n  Pages 900-934", "doi": "10.1093/imanum/draa014", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite difference schemes, using Backward Differentiation Formula (BDF), are\nstudied for the approximation of one-dimensional diffusion equations with an\nobstacle term, of the form $$\\min(v_t - a(t,x) v_{xx} + b(t,x) v_x + r(t,x) v,\nv- \\varphi(t,x))= f(t,x).$$ For the scheme building on the second order BDF\nformula (BDF2), we discuss unconditional stability, prove an $L^2$-error\nestimate and show numerically second order convergence, in both space and time,\nunconditionally on the ratio of the mesh steps. In the analysis, an equivalence\nof the obstacle equation with a Hamilton-Jacobi-Bellman equation is mentioned,\nand a Crank-Nicolson scheme is tested in this context. Two academic problems\nfor parabolic equations with an obstacle term with explicit solutions and the\nAmerican option problem in mathematical finance are used for numerical tests.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 17:55:06 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 08:11:56 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 15:44:42 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Bokanowski", "Olivier", ""], ["Debrabant", "Kristian", ""]]}, {"id": "1802.05699", "submitter": "Fabian Faulstich", "authors": "Fabian M. Faulstich, Andre Laestadius, \\\"Ors Legeza, Reinhold\n  Schneider, Simen Kvaal", "title": "Analysis of The Tailored Coupled-Cluster Method in Quantum Chemistry", "comments": null, "journal-ref": null, "doi": "10.1137/18M1171436", "report-no": null, "categories": "math.NA cond-mat.str-el cs.NA physics.chem-ph physics.comp-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantum chemistry, one of the most important challenges is the static\ncorrelation problem when solving the electronic Schr\\\"odinger equation for\nmolecules in the Born--Oppenheimer approximation. In this article, we analyze\nthe tailored coupled-cluster method (TCC), one particular and promising method\nfor treating molecular electronic-structure problems with static correlation.\nThe TCC method combines the single-reference coupled-cluster (CC) approach with\nan approximate reference calculation in a subspace [complete active space\n(CAS)] of the considered Hilbert space that covers the static correlation. A\none-particle spectral gap assumption is introduced, separating the CAS from the\nremaining Hilbert space. This replaces the nonexisting or nearly nonexisting\ngap between the highest occupied molecular orbital and the lowest unoccupied\nmolecular orbital usually encountered in standard single-reference quantum\nchemistry. The analysis covers, in particular, CC methods tailored by\ntensor-network states (TNS-TCC methods). The problem is formulated in a\nnonlinear functional analysis framework, and, under certain conditions such as\nthe aforementioned gap, local uniqueness and existence are proved using\nZarantonello's lemma. From the Aubin--Nitsche-duality method, a quadratic error\nbound valid for TNS-TCC methods is derived, e.g., for linear-tensor-network TCC\nschemes using the density matrix renormalization group method.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 18:45:53 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 07:32:17 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Faulstich", "Fabian M.", ""], ["Laestadius", "Andre", ""], ["Legeza", "\u00d6rs", ""], ["Schneider", "Reinhold", ""], ["Kvaal", "Simen", ""]]}, {"id": "1802.05966", "submitter": "Marc Schmidlin", "authors": "Helmut Harbrecht and Marc Schmidlin", "title": "Multilevel quadrature for elliptic problems on random domains by the\n  coupling of FEM and BEM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elliptic boundary value problems which are posed on a random domain can be\nmapped to a fixed, nominal domain. The randomness is thus transferred to the\ndiffusion matrix and the loading. While this domain mapping method is quite\nefficient for theory and practice, since only a single domain discretisation is\nneeded, it also requires the knowledge of the domain mapping.\n  However, in certain applications, the random domain is only described by its\nrandom boundary, while the quantity of interest is defined on a fixed,\ndeterministic subdomain. In this setting, it thus becomes necessary to compute\na random domain mapping on the whole domain, such that the domain mapping is\nthe identity on the fixed subdomain and maps the boundary of the chosen fixed,\nnominal domain on to the random boundary.\n  To overcome the necessity of computing such a mapping, we therefore couple\nthe finite element method on the fixed subdomain with the boundary element\nmethod on the random boundary. We verify the required regularity of the\nsolution with respect to the random domain mapping for the use of multilevel\nquadrature, derive the coupling formulation, and show by numerical results that\nthe approach is feasible.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 15:01:50 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 15:12:36 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Harbrecht", "Helmut", ""], ["Schmidlin", "Marc", ""]]}, {"id": "1802.05982", "submitter": "Chuan Zhang", "authors": "Chuan Zhang (1 and 2 and 3), Yufeng Yang (1 and 2 and 3), Shunqing\n  Zhang (4), Zaichen Zhang (2 and 3), Xiaohu You (2) ((1) Lab of Efficient\n  Architectures for Digital-communication and Signal-processing (LEADS), (2)\n  National Mobile Communications Research Laboratory, (3) Quantum Information\n  Center, Southeast University, China, (4) Shanghai Institute for Advanced\n  Communications and Data Science, Shanghai University, Shanghai, China)", "title": "Residual-Based Detections and Unified Architecture for Massive MIMO\n  Uplink", "comments": "submitted to Journal of Signal Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive multiple-input multiple-output (M-MIMO) technique brings better\nenergy efficiency and coverage but higher computational complexity than\nsmall-scale MIMO. For linear detections such as minimum mean square error\n(MMSE), prohibitive complexity lies in solving large-scale linear equations.\nFor a better trade-off between bit-error-rate (BER) performance and\ncomputational complexity, iterative linear algorithms like conjugate gradient\n(CG) have been applied and have shown their feasibility in recent years. In\nthis paper, residual-based detection (RBD) algorithms are proposed for M-MIMO\ndetection, including minimal residual (MINRES) algorithm, generalized minimal\nresidual (GMRES) algorithm, and conjugate residual (CR) algorithm. RBD\nalgorithms focus on the minimization of residual norm per iteration, whereas\nmost existing algorithms focus on the approximation of exact signal. Numerical\nresults have shown that, for $64$-QAM $128\\times 8$ MIMO, RBD algorithms are\nonly $0.13$ dB away from the exact matrix inversion method when BER$=10^{-4}$.\nStability of RBD algorithms has also been verified in various correlation\nconditions. Complexity comparison has shown that, CR algorithm require $87\\%$\nless complexity than the traditional method for $128\\times 60$ MIMO. The\nunified hardware architecture is proposed with flexibility, which guarantees a\nlow-complexity implementation for a family of RBD M-MIMO detectors.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 10:54:31 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Zhang", "Chuan", "", "1 and 2 and 3"], ["Yang", "Yufeng", "", "1 and 2 and 3"], ["Zhang", "Shunqing", "", "2 and 3"], ["Zhang", "Zaichen", "", "2 and 3"], ["You", "Xiaohu", ""]]}, {"id": "1802.06099", "submitter": "Thomas Brown", "authors": "Harbir Antil, Thomas S. Brown, and Francisco-Javier Sayas", "title": "A problem in control of elastodynamics with piezoelectric effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.AP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an optimal control problem where the state equations are a\ncoupled hyperbolic-elliptic system. This system arises in elastodynamics with\npiezoelectric effects -- the elastic stress tensor is a function of elastic\ndisplacement and electric potential. The electric flux acts as the control\nvariable and, in addition to the state constraints, the bound constraints on\nthe control are considered. We develop a complete analysis for the state\nequations and the control problem. The requisite regularity on the control, to\nshow the well-posedness of state equations, is enforced using the cost\nfunctional. We rigorously derive the first order necessary and sufficient\nconditions using adjoint equations and further study their well-posedness. For\nspatially discrete (time continuous) problem, we show the convergence of our\nnumerical scheme. Three dimensional numerical experiments are provided showing\nconvergence properties of a fully discrete method and the practical\napplicability of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 19:40:18 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 16:36:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Antil", "Harbir", ""], ["Brown", "Thomas S.", ""], ["Sayas", "Francisco-Javier", ""]]}, {"id": "1802.06203", "submitter": "Petr N. Vabishchevich", "authors": "Alexander G. Churbanov and Petr N. Vabishchevich", "title": "Numerical solution of boundary value problems for the eikonal equation\n  in an anisotropic medium", "comments": "20 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Dirichlet problem is considered for the eikonal equation in an anisotropic\nmedium. The nonlinear boundary value problem (BVP) formulated in the present\nwork is the limit of the diffusion-reaction problem with a reaction parameter\ntending to infinity. To solve numerically the singularly perturbed\ndiffusion-reaction problem, monotone approximations are employed. Numerical\nexamples are presented for a two-dimensional BVP for the eikonal equation in an\nanisotropic medium. The standard piecewise-linear finite-element approximation\nin space is used in computations.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 07:37:34 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Churbanov", "Alexander G.", ""], ["Vabishchevich", "Petr N.", ""]]}, {"id": "1802.06266", "submitter": "Hrushikesh Mhaskar", "authors": "Hrushikesh Mhaskar, Tomaso Poggio", "title": "An analysis of training and generalization errors in shallow and deep\n  networks", "comments": "21 pages; Accepted for publication in Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by an open problem around deep networks, namely, the\napparent absence of over-fitting despite large over-parametrization which\nallows perfect fitting of the training data. In this paper, we analyze this\nphenomenon in the case of regression problems when each unit evaluates a\nperiodic activation function. We argue that the minimal expected value of the\nsquare loss is inappropriate to measure the generalization error in\napproximation of compositional functions in order to take full advantage of the\ncompositional structure. Instead, we measure the generalization error in the\nsense of maximum loss, and sometimes, as a pointwise error. We give estimates\non exactly how many parameters ensure both zero training error as well as a\ngood generalization error. We prove that a solution of a regularization problem\nis guaranteed to yield a good training error as well as a good generalization\nerror and estimate how much error to expect at which test data.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 17:50:19 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 03:20:24 GMT"}, {"version": "v3", "created": "Sat, 13 Jul 2019 04:56:49 GMT"}, {"version": "v4", "created": "Tue, 27 Aug 2019 05:18:04 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Mhaskar", "Hrushikesh", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1802.06302", "submitter": "Jan Cieslinski L.", "authors": "Cezary J. Walczyk, Leonid V. Moroz, Jan L. Cie\\'sli\\'nski", "title": "Improving the accuracy of the fast inverse square root algorithm", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present improved algorithms for fast calculation of the inverse square\nroot for single-precision floating-point numbers. The algorithms are much more\naccurate than the famous fast inverse square root algorithm and have the same\nor similar computational cost. The main idea of our work consists in modifying\nthe Newton-Raphson method and demanding that the maximal error is as small as\npossible. Such modification is possible when the distribution of Newton-Raphson\ncorrections is not symmetric (e.g., if they are non-positive functions).\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 22:16:16 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Walczyk", "Cezary J.", ""], ["Moroz", "Leonid V.", ""], ["Cie\u015bli\u0144ski", "Jan L.", ""]]}, {"id": "1802.06380", "submitter": "Kenneth Duru", "authors": "Kenneth Duru, Leonhard Rannabauer, Alice-Agnes Gabriel and Heiner Igel", "title": "A new discontinuous Galerkin spectral element method for elastic waves\n  with physically motivated numerical fluxes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discontinuous Galerkin (DG) method is an established method for computing\napproximate solutions of partial differential equations in many applications.\nUnlike continuous finite elements, in DG methods, numerical fluxes are used to\nenforce inter-element conditions, and internal and external physical boundary\nconditions. However, for certain problems such as elastic wave propagation in\ncomplex media, where several wave types and wave speeds are simultaneously\npresent, a standard numerical flux may not be compatible with the physical\nboundary conditions. If surface or interface waves are present, this\nincompatibility may lead to numerical instabilities. We present a stable and\narbitrary order accurate DG method for elastic waves with a physically\nmotivated numerical flux. Our numerical flux is compatible with all well-posed,\ninternal and external, boundary conditions, including linear and nonlinear\nfrictional constitutive equations for modelling spontaneously propagating shear\nruptures in elastic solids and dynamic earthquake rupture processes. We present\nnumerical experiments in one and two space dimensions verifying high order\naccuracy and asymptotic numerical stability, and demonstrating potentials for\nmodelling complex nonlinear frictional problems in elastic solids.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 13:59:09 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 19:53:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Duru", "Kenneth", ""], ["Rannabauer", "Leonhard", ""], ["Gabriel", "Alice-Agnes", ""], ["Igel", "Heiner", ""]]}, {"id": "1802.06820", "submitter": "Austin Benson", "authors": "Austin R. Benson", "title": "Tools for higher-order network analysis", "comments": "Ph.D. Thesis, Stanford University, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cond-mat.stat-mech cs.NA physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are a fundamental model of complex systems throughout the sciences,\nand network datasets are typically analyzed through lower-order connectivity\npatterns described at the level of individual nodes and edges. However,\nhigher-order connectivity patterns captured by small subgraphs, also called\nnetwork motifs, describe the fundamental structures that control and mediate\nthe behavior of many complex systems. We develop three tools for network\nanalysis that use higher-order connectivity patterns to gain new insights into\nnetwork datasets: (1) a framework to cluster nodes into modules based on joint\nparticipation in network motifs; (2) a generalization of the clustering\ncoefficient measurement to investigate higher-order closure patterns; and (3) a\ndefinition of network motifs for temporal networks and fast algorithms for\ncounting them. Using these tools, we analyze data from biology, ecology,\neconomics, neuroscience, online social networks, scientific collaborations,\ntelecommunications, transportation, and the World Wide Web.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 19:26:48 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Benson", "Austin R.", ""]]}, {"id": "1802.07601", "submitter": "Luca Pegolotti", "authors": "Simone Deparis and Luca Pegolotti", "title": "Coupling non-conforming discretizations of PDEs by spectral\n  approximation of the Lagrange multiplier space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on the development of a non-conforming domain decomposition\nmethod for the approximation of PDEs based on weakly imposed transmission\nconditions: the continuity of the global solution is enforced by a discrete\nnumber of Lagrange multipliers defined over the interfaces of adjacent\nsubdomains. The method falls into the class of primal hybrid methods, which\nalso include the well-known mortar method. Differently from the mortar method,\nwe discretize the space of basis functions on the interface by spectral\napproximation independently of the discretization of the two adjacent domains;\none of the possible choices is to approximate the interface variational space\nby Fourier basis functions. As we show in the numerical simulations, our\napproach is well-suited for the solution of problems with non-conforming meshes\nor with finite element basis functions with different polynomial degrees in\neach subdomain. Another application of the method that still needs to be\ninvestigated is the coupling of solutions obtained from otherwise incompatible\nmethods, such as the finite element method, the spectral element method or\nisogeometric analysis.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 14:58:21 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Deparis", "Simone", ""], ["Pegolotti", "Luca", ""]]}, {"id": "1802.07942", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson", "title": "Numerical integration in arbitrary-precision ball arithmetic", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an implementation of arbitrary-precision numerical integration\nwith rigorous error bounds in the Arb library. Rapid convergence is ensured for\npiecewise complex analytic integrals by use of the Petras algorithm, which\ncombines adaptive bisection with adaptive Gaussian quadrature where error\nbounds are determined via complex magnitudes without evaluating derivatives.\nThe code is general, easy to use, and efficient, often outperforming existing\nnon-rigorous software.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 08:46:14 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Johansson", "Fredrik", ""]]}, {"id": "1802.08055", "submitter": "Azam Moosavi", "authors": "Azam Moosavi, Vishwas Rao, Adrian Sandu", "title": "A Learning Based Approach for Uncertainty Analysis in Numerical Weather\n  Prediction Models", "comments": "23 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": "CSL-2018-2", "categories": "cs.NA physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex numerical weather prediction models incorporate a variety of physical\nprocesses, each described by multiple alternative physical schemes with\nspecific parameters. The selection of the physical schemes and the choice of\nthe corresponding physical parameters during model configuration can\nsignificantly impact the accuracy of model forecasts. There is no combination\nof physical schemes that works best for all times, at all locations, and under\nall conditions. It is therefore of considerable interest to understand the\ninterplay between the choice of physics and the accuracy of the resulting\nforecasts under different conditions. This paper demonstrates the use of\nmachine learning techniques to study the uncertainty in numerical weather\nprediction models due to the interaction of multiple physical processes. The\nfirst problem addressed herein is the estimation of systematic model errors in\noutput quantities of interest at future times, and the use of this information\nto improve the model forecasts. The second problem considered is the\nidentification of those specific physical processes that contribute most to the\nforecast uncertainty in the quantity of interest under specified meteorological\nconditions.\n  The discrepancies between model results and observations at past times are\nused to learn the relationships between the choice of physical processes and\nthe resulting forecast errors. Numerical experiments are carried out with the\nWeather Research and Forecasting (WRF) model. The output quantity of interest\nis the model precipitation, a variable that is both extremely important and\nvery challenging to forecast. The physical processes under consideration\ninclude various micro-physics schemes, cumulus parameterizations, short wave,\nand long wave radiation schemes. The experiments demonstrate the strong\npotential of machine learning approaches to aid the study of model errors.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 09:11:30 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Moosavi", "Azam", ""], ["Rao", "Vishwas", ""], ["Sandu", "Adrian", ""]]}, {"id": "1802.08157", "submitter": "Abele Simona", "authors": "Abele Simona, Luca Bonaventura, Thomas Pugnat, Barbara Dalena", "title": "High order time integrators for the simulation of charged particle\n  motion in magnetic quadrupoles", "comments": "39 pages, 18 figures", "journal-ref": null, "doi": "10.1016/j.cpc.2019.01.018", "report-no": null, "categories": "cs.CE cs.NA physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic quadrupoles are essential components of particle accelerators like\nthe Large Hadron Collider. In order to study numerically the stability of the\nparticle beam crossing a quadrupole, a large number of particle revolutions in\nthe accelerator must be simulated, thus leading to the necessity to preserve\nnumerically invariants of motion over a long time interval and to a substantial\ncomputational cost, mostly related to the repeated evaluation of the magnetic\nvector potential. In this paper, in order to reduce this cost, we first\nconsider a specific gauge transformation that allows to reduce significantly\nthe number of vector potential evaluations. We then analyze the sensitivity of\nthe numerical solution to the interpolation procedure required to compute\nmagnetic vector potential data from gridded precomputed values at the locations\nrequired by high order time integration methods. Finally, we compare several\nhigh order integration techniques, in order to assess their accuracy and\nefficiency for these long term simulations. Explicit high order Lie methods are\nconsidered, along with implicit high order symplectic integrators and\nconventional explicit Runge Kutta methods. Among symplectic methods, high order\nLie integrators yield optimal results in terms of cost/accuracy ratios, but non\nsymplectic Runge Kutta methods perform remarkably well even in very long term\nsimulations. Furthermore, the accuracy of the field reconstruction and\ninterpolation techniques are shown to be limiting factors for the accuracy of\nthe particle tracking procedures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 16:47:22 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Simona", "Abele", ""], ["Bonaventura", "Luca", ""], ["Pugnat", "Thomas", ""], ["Dalena", "Barbara", ""]]}, {"id": "1802.08245", "submitter": "Satrya Fajri Pratama", "authors": "Satrya Fajri Pratama, Azah Kamilah Muda, and Yun-Huoy Choo", "title": "Arbitrarily Substantial Number Representation for Complex Number", "comments": "This is a published version of an article published in Journal of\n  Telecommunication, Electronic and Computer Engineering, available online at:\n  http://journal.utem.edu.my/index.php/jtec/article/view/3590", "journal-ref": "Journal of Telecommunication, Electronic and Computer Engineering\n  (2018), 23-26", "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researchers are often perplexed when their machine learning algorithms are\nrequired to deal with complex number. Various strategies are commonly employed\nto project complex number into real number, although it is frequently\nsacrificing the information contained in the complex number. This paper\nproposes a new method and four techniques to represent complex number as real\nnumber, without having to sacrifice the information contained. The proposed\ntechniques are also capable of retrieving the original complex number from the\nrepresenting real number, with little to none of information loss. The\npromising applicability of the proposed techniques has been demonstrated and\nworth to receive further exploration in representing the complex number.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:58:09 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 02:12:53 GMT"}, {"version": "v3", "created": "Mon, 2 Apr 2018 07:09:04 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Pratama", "Satrya Fajri", ""], ["Muda", "Azah Kamilah", ""], ["Choo", "Yun-Huoy", ""]]}, {"id": "1802.08532", "submitter": "Xavier Caruso", "authors": "Xavier Caruso (LAGA), David Roe (MIT), Tristan Vaccon (XLIM-MATHIS)", "title": "ZpL: a p-adic precision package", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.NA cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new package ZpL for the mathematical software system SM. It\nimplements a sharp tracking of precision on p-adic numbers, following the\ntheory of ultrametric precision introduced in [4]. The underlying algorithms\nare mostly based on automatic dierentiation techniques. We introduce them,\nstudy their complexity and discuss our design choices. We illustrate the\nbene-ts of our package (in comparison with previous implementations) with a\nlarge sample of examples coming from linear algebra, com-mutative algebra and\ndierential equations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 13:55:12 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Caruso", "Xavier", "", "LAGA"], ["Roe", "David", "", "MIT"], ["Vaccon", "Tristan", "", "XLIM-MATHIS"]]}, {"id": "1802.08558", "submitter": "Walter Mascarenhas", "authors": "Walter F. Mascarenhas", "title": "Moore: Interval Arithmetic in C++20", "comments": "arXiv admin note: text overlap with arXiv:1611.09567\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the Moore library for interval arithmetic in C++20. It\ngives examples of how the library can be used, and explains the basic\nprinciples underlying its design.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 19:02:45 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Mascarenhas", "Walter F.", ""]]}, {"id": "1802.08666", "submitter": "Mario Ullrich", "authors": "Christopher Kacwin and Jens Oettershagen and Mario Ullrich and Tino\n  Ullrich", "title": "Numerical performance of optimized Frolov lattices in tensor product\n  reproducing kernel Sobolev spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with several aspects of the universal Frolov cubature\nmethod, that is known to achieve optimal asymptotic convergence rates in a\nbroad range of function spaces. Even though every admissible lattice has this\nfavorable asymptotic behavior, there are significant differences concerning the\nprecise numerical behavior of the worst-case error. To this end, we propose new\ngenerating polynomials that promise a significant reduction of the integration\nerror compared to the classical polynomials. Moreover, we develop a new\nalgorithm to enumerate the Frolov points from non-orthogonal lattices for\nnumerical cubature in the $d$-dimensional unit cube $[0,1]^d$. Finally, we\nstudy Sobolev spaces with anisotropic mixed smoothness and compact support in\n$[0,1]^d$ and derive explicit formulas for their reproducing kernels. This\nallows for the simulation of exact worst-case errors which numerically validate\nour theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 18:17:41 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Kacwin", "Christopher", ""], ["Oettershagen", "Jens", ""], ["Ullrich", "Mario", ""], ["Ullrich", "Tino", ""]]}, {"id": "1802.09062", "submitter": "Markus Bachmayr", "authors": "Markus Bachmayr and Vladimir Kazeev", "title": "Stability of Low-Rank Tensor Representations and Structured Multilevel\n  Preconditioning for Elliptic PDEs", "comments": "44 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Folding grid value vectors of size $2^L$ into $L$th order tensors of mode\nsizes $2\\times \\cdots\\times 2$, combined with low-rank representation in the\ntensor train format, has been shown to lead to highly efficient approximations\nfor various classes of functions. These include solutions of elliptic PDEs on\nnonsmooth domains or with oscillatory data. This tensor-structured approach is\nattractive because it leads to highly compressed, adaptive approximations based\non simple discretizations. Standard choices of the underlying basis, such as\npiecewise multilinear finite elements on uniform tensor product grids, entail\nthe well-known matrix ill-conditioning of discrete operators. We demonstrate\nthat for low-rank representations, the use of tensor structure itself\nadditionally introduces representation ill-conditioning, a new effect specific\nto computations in tensor networks. We analyze the tensor structure of a BPX\npreconditioner for second-order linear elliptic operators and construct an\nexplicit tensor-structured representation of the preconditioner, with ranks\nindependent of the number $L$ of discretization levels. The straightforward\napplication of the preconditioner yields discrete operators whose matrix\nconditioning is uniform with respect to the discretization parameter, but in\ndecompositions that suffer from representation ill-conditioning. By\nadditionally eliminating certain redundancies in the representations of the\npreconditioned discrete operators, we obtain reduced-rank decompositions that\nare free of both matrix and representation ill-conditioning. For an iterative\nsolver based on soft thresholding of low-rank tensors, we obtain convergence\nand complexity estimates and demonstrate its reliability and efficiency for\ndiscretizations with up to $2^{50}$ nodes in each dimension.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 18:55:26 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 19:52:43 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bachmayr", "Markus", ""], ["Kazeev", "Vladimir", ""]]}, {"id": "1802.09303", "submitter": "Ganzhao Yuan", "authors": "Ganzhao Yuan, Li Shen, Wei-Shi Zheng", "title": "A Decomposition Algorithm for the Sparse Generalized Eigenvalue Problem", "comments": "To appear in CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparse generalized eigenvalue problem arises in a number of standard and\nmodern statistical learning models, including sparse principal component\nanalysis, sparse Fisher discriminant analysis, and sparse canonical correlation\nanalysis. However, this problem is difficult to solve since it is NP-hard. In\nthis paper, we consider a new decomposition method to tackle this problem.\nSpecifically, we use random or/and swapping strategies to find a working set\nand perform global combinatorial search over the small subset of variables. We\nconsider a bisection search method and a coordinate descent method for solving\nthe quadratic fractional programming subproblem. In addition, we provide some\ntheoretical analysis for the proposed method. Our experiments have shown that\nthe proposed method significantly and consistently outperforms existing\nsolutions in term of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 14:00:22 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 08:34:02 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Yuan", "Ganzhao", ""], ["Shen", "Li", ""], ["Zheng", "Wei-Shi", ""]]}, {"id": "1802.09394", "submitter": "Matteo Giacomini", "authors": "Matteo Giacomini, Alexandros Karkoulias, Ruben Sevilla, Antonio Huerta", "title": "A superconvergent HDG method for Stokes flow with strongly enforced\n  symmetry of the stress tensor", "comments": "28 pages, 10 figures, 1 table", "journal-ref": "J. Sci. Comput., 77(3):1679--1702 (2018)", "doi": "10.1007/s10915-018-0855-y", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a superconvergent hybridizable discontinuous Galerkin\n(HDG) method for the approximation of the Cauchy formulation of the Stokes\nequation using same degree of polynomials for the primal and mixed variables.\nThe novel formulation relies on the well-known Voigt notation to strongly\nenforce the symmetry of the stress tensor. The proposed strategy introduces\nseveral advantages with respect to the existing HDG formulations. First, it\nremedies the suboptimal behavior experienced by the classical HDG method for\nformulations involving the symmetric part of the gradient of the primal\nvariable. The optimal convergence of the mixed variable is retrieved and an\nelement-by-element post-process procedure leads to a superconvergent velocity\nfield, even for low-order approximations. Second, no additional enrichment of\nthe discrete spaces is required and a gain in computational efficiency follows\nfrom reducing the quantity of stored information and the size of the local\nproblems. Eventually, the novel formulation naturally imposes physical\ntractions on the Neumann boundary. Numerical validation of the optimality of\nthe method and its superconvergent properties is performed in 2D and 3D using\nmeshes of different element types.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 15:24:51 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Giacomini", "Matteo", ""], ["Karkoulias", "Alexandros", ""], ["Sevilla", "Ruben", ""], ["Huerta", "Antonio", ""]]}, {"id": "1802.09413", "submitter": "Xiaojie Wang", "authors": "Xiaojie Wang", "title": "An efficient explicit full-discrete scheme for strong approximation of\n  stochastic Allen-Cahn equation", "comments": "25 pages", "journal-ref": "Stochastic Processes and their Applications 130 (2020) 6271-6299", "doi": "10.1007/s11040-020-09347-1", "report-no": null, "categories": "math.NA cs.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Becker and Jentzen (2019) and Becker et al. (2017), an explicit temporal\nsemi-discretization scheme and a space-time full-discretization scheme were,\nrespectively, introduced and analyzed for the additive noise-driven stochastic\nAllen-Cahn type equations, with strong convergence rates recovered. The present\nwork aims to propose a different explicit full-discrete scheme to numerically\nsolve the stochastic Allen-Cahn equation with cubic nonlinearity, perturbed by\nadditive space-time white noise. The approximation is easily implementable,\nperforming the spatial discretization by a spectral Galerkin method and the\ntemporal discretization by a kind of nonlinearity-tamed accelerated exponential\nintegrator scheme. Error bounds in a strong sense are analyzed for both the\nspatial semi-discretization and the spatio-temporal full discretization, with\nconvergence rates in both space and time explicitly identified. It turns out\nthat the obtained convergence rate of the new scheme is, in the temporal\ndirection, twice as high as existing ones in the literature. Numerical results\nare finally reported to confirm the previous theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 15:54:04 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 14:54:00 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 10:48:54 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Wang", "Xiaojie", ""]]}, {"id": "1802.09513", "submitter": "Rainer Sinn", "authors": "Daniel Irving Bernstein, Grigoriy Blekherman, Rainer Sinn", "title": "Typical and Generic Ranks in Matrix Completion", "comments": "to appear in Linear Algebra and its Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.NA math.AG math.NA math.RA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of exact low-rank matrix completion from a geometric\nviewpoint: given a partially filled matrix M, we keep the positions of\nspecified and unspecified entries fixed, and study how the minimal completion\nrank depends on the values of the known entries. If the entries of the matrix\nare complex numbers, then for a fixed pattern of locations of specified and\nunspecified entries there is a unique completion rank which occurs with\npositive probability. We call this rank the generic completion rank. Over the\nreal numbers there can be multiple ranks that occur with positive probability;\nwe call them typical completion ranks. We introduce these notions formally, and\nprovide a number of inequalities and exact results on typical and generic ranks\nfor different families of patterns of known and unknown entries.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:54:50 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 13:41:52 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Bernstein", "Daniel Irving", ""], ["Blekherman", "Grigoriy", ""], ["Sinn", "Rainer", ""]]}, {"id": "1802.09879", "submitter": "Ganzhao Yuan", "authors": "Ganzhao Yuan, Bernard Ghanem", "title": "L0TV: A Sparse Optimization Method for Impulse Noise Image Restoration", "comments": "to appear in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA eess.IV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Total Variation (TV) is an effective and popular prior model in the field of\nregularization-based image processing. This paper focuses on total variation\nfor removing impulse noise in image restoration. This type of noise frequently\narises in data acquisition and transmission due to many reasons, e.g. a faulty\nsensor or analog-to-digital converter errors. Removing this noise is an\nimportant task in image restoration. State-of-the-art methods such as Adaptive\nOutlier Pursuit(AOP) \\cite{yan2013restoration}, which is based on TV with\n$\\ell_{02}$-norm data fidelity, only give sub-optimal performance. In this\npaper, we propose a new sparse optimization method, called $\\ell_0TV$-PADMM,\nwhich solves the TV-based restoration problem with $\\ell_0$-norm data fidelity.\nTo effectively deal with the resulting non-convex non-smooth optimization\nproblem, we first reformulate it as an equivalent biconvex Mathematical Program\nwith Equilibrium Constraints (MPEC), and then solve it using a proximal\nAlternating Direction Method of Multipliers (PADMM). Our $\\ell_0TV$-PADMM\nmethod finds a desirable solution to the original $\\ell_0$-norm optimization\nproblem and is proven to be convergent under mild conditions. We apply\n$\\ell_0TV$-PADMM to the problems of image denoising and deblurring in the\npresence of impulse noise. Our extensive experiments demonstrate that\n$\\ell_0TV$-PADMM outperforms state-of-the-art image restoration methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 13:45:09 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 15:48:08 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Yuan", "Ganzhao", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1802.10275", "submitter": "Yuehaw Khoo", "authors": "Yuehaw Khoo, Jianfeng Lu, Lexing Ying", "title": "Solving for high dimensional committor functions using artificial neural\n  networks", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we propose a method based on artificial neural network to study\nthe transition between states governed by stochastic processes. In particular,\nwe aim for numerical schemes for the committor function, the central object of\ntransition path theory, which satisfies a high-dimensional Fokker-Planck\nequation. By working with the variational formulation of such partial\ndifferential equation and parameterizing the committor function in terms of a\nneural network, approximations can be obtained via optimizing the neural\nnetwork weights using stochastic algorithms. The numerical examples show that\nmoderate accuracy can be achieved for high-dimensional problems.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 06:16:33 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Khoo", "Yuehaw", ""], ["Lu", "Jianfeng", ""], ["Ying", "Lexing", ""]]}, {"id": "1802.10444", "submitter": "Chuan Zhang", "authors": "Chuan Zhang (1 and 2 and 3), Xiao Liang (1 and 2 and 3), Zhizhen Wu (1\n  and 2 and 3), Feng Wang (1 and 2 and 3), Shunqing Zhang (4), Zaichen Zhang (2\n  and 3), Xiaohu You (2) ((1) Lab of Efficient Architectures for\n  Digital-communication and Signal-processing (LEADS), (2) National Mobile\n  Communications Research Laboratory, (3) Quantum Information Center, Southeast\n  University, China, (4) Shanghai Institute for Advanced Communications and\n  Data Science, Shanghai University, Shanghai, China)", "title": "On the Low-Complexity, Hardware-Friendly Tridiagonal Matrix Inversion\n  for Correlated Massive MIMO Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In massive MIMO (M-MIMO) systems, one of the key challenges in the\nimplementation is the large-scale matrix inversion operation, as widely used in\nchannel estimation, equalization, detection, and decoding procedures.\nTraditionally, to handle this complexity issue, several low-complexity matrix\ninversion approximation methods have been proposed, including the classic\nCholesky decomposition and the Neumann series expansion (NSE). However, the\nconventional approaches failed to exploit neither the special structure of\nchannel matrices nor the critical issues in the hardware implementation, which\nresults in poorer throughput performance and longer processing delay. In this\npaper, by targeting at the correlated M-MIMO systems, we propose a modified NSE\nbased on tridiagonal matrix inversion approximation (TMA) to accommodate the\ncomplexity as well as the performance issue in the conventional hardware\nimplementation, and analyze the corresponding approximation errors. Meanwhile,\nwe investigate the VLSI implementation for the proposed detection algorithm\nbased on a Xilinx Virtex-7 XC7VX690T FPGA platform. It is shown that for\ncorrelated massive MIMO systems, it can achieve near-MMSE performance and $630$\nMb/s throughput. Compared with other benchmark systems, the proposed pipelined\nTMA detector can get high throughput-to-hardware ratio. Finally, we also\npropose a fast iteration structure for further research.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 08:51:48 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Zhang", "Chuan", "", "1 and 2 and 3"], ["Liang", "Xiao", "", "1 and 2 and 3"], ["Wu", "Zhizhen", "", "1\n  and 2 and 3"], ["Wang", "Feng", "", "1 and 2 and 3"], ["Zhang", "Shunqing", "", "2\n  and 3"], ["Zhang", "Zaichen", "", "2\n  and 3"], ["You", "Xiaohu", ""]]}, {"id": "1802.10453", "submitter": "Jean-Guillaume Dumas", "authors": "Jean-Guillaume Dumas (CASYS), Clement Pernet (CASYS)", "title": "Symmetric indefinite triangular factorization revealing the rank profile\n  matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel recursive algorithm for reducing a symmetric matrix to a\ntriangular factorization which reveals the rank profile matrix. That is, the\nalgorithm computes a factorization $\\mathbf{P}^T\\mathbf{A}\\mathbf{P} =\n\\mathbf{L}\\mathbf{D}\\mathbf{L}^T$ where $\\mathbf{P}$ is a permutation matrix,\n$\\mathbf{L}$ is lower triangular with a unit diagonal and $\\mathbf{D}$ is\nsymmetric block diagonal with $1{\\times}1$ and $2{\\times}2$ antidiagonal\nblocks. The novel algorithm requires $O(n^2r^{\\omega-2})$ arithmetic\noperations. Furthermore, experimental results demonstrate that our algorithm\ncan even be slightly more than twice as fast as the state of the art\nunsymmetric Gaussian elimination in most cases, that is it achieves\napproximately the same computational speed. By adapting the pivoting strategy\ndeveloped in the unsymmetric case, we show how to recover the rank profile\nmatrix from the permutation matrix and the support of the block-diagonal\nmatrix. There is an obstruction in characteristic $2$ for revealing the rank\nprofile matrix which requires to relax the shape of the block diagonal by\nallowing the 2-dimensional blocks to have a non-zero bottom-right coefficient.\nThis relaxed decomposition can then be transformed into a standard\n$\\mathbf{P}\\mathbf{L}\\mathbf{D}\\mathbf{L}^T\\mathbf{P}^T$ decomposition at a\nnegligible cost.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 15:37:00 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Dumas", "Jean-Guillaume", "", "CASYS"], ["Pernet", "Clement", "", "CASYS"]]}, {"id": "1802.10492", "submitter": "Jakob Assl\\\"ander", "authors": "Sunli Tang, Carlos Fernandez-Granda, Sylvain Lannuzel, Brett\n  Bernstein, Riccardo Lattanzi, Martijn Cloos, Florian Knoll, and Jakob\n  Assl\\\"ander", "title": "Multicompartment Magnetic Resonance Fingerprinting", "comments": "Sunli Tang and Carlos Fernandez-Granda contributed equally to this\n  paper", "journal-ref": null, "doi": "10.1088/1361-6420/aad1c3", "report-no": null, "categories": "physics.med-ph cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance fingerprinting (MRF) is a technique for quantitative\nestimation of spin-relaxation parameters from magnetic-resonance data. Most\ncurrent MRF approaches assume that only one tissue is present in each voxel,\nwhich neglects the tissue's microstructure, and may lead to artifacts in the\nrecovered parameter maps at boundaries between tissues. In this work, we\npropose a multicompartment MRF model that accounts for the presence of multiple\ntissues per voxel. The model is fit to the data by iteratively solving a sparse\nlinear inverse problem at each voxel, in order to express the magnetization\nsignal as a linear combination of a few fingerprints in the precomputed\ndictionary. Thresholding-based methods commonly used for sparse recovery and\ncompressed sensing do not perform well in this setting due to the high local\ncoherence of the dictionary. Instead, we solve this challenging sparse-recovery\nproblem by applying reweighted-l1-norm regularization, implemented using an\nefficient interior-point method. The proposed approach is validated with\nsimulated data at different noise levels and undersampling factors, as well as\nwith a controlled phantom imaging experiment on a clinical magnetic-resonance\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 15:56:16 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Tang", "Sunli", ""], ["Fernandez-Granda", "Carlos", ""], ["Lannuzel", "Sylvain", ""], ["Bernstein", "Brett", ""], ["Lattanzi", "Riccardo", ""], ["Cloos", "Martijn", ""], ["Knoll", "Florian", ""], ["Assl\u00e4nder", "Jakob", ""]]}, {"id": "1802.10585", "submitter": "Saray Busto", "authors": "A. Berm\\'udez, S. Busto, M. Dumbser, J.L. Ferr\\'in, L. Saavedra, M.E.\n  V\\'azquez-Cend\\'on", "title": "A staggered semi-implicit hybrid FV/FE projection method for weakly\n  compressible flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present a novel staggered semi-implicit hybrid\nfinite-volume/finite-element (FV/FE) method for the resolution of weakly\ncompressible flows in two and three space dimensions. The pressure-based\nmethodology introduced in Berm\\'udez et al. 2014 and Busto et al. 2018 for\nviscous incompressible flows is extended here to solve the compressible\nNavier-Stokes equations. Instead of considering the classical system including\nthe energy conservation equation, we replace it by the pressure evolution\nequation written in non-conservative form. To ease the discretization of\ncomplex spatial domains, face-type unstructured staggered meshes are\nconsidered. A projection method allows the decoupling of the computation of the\ndensity and linear momentum variables from the pressure. Then, an explicit\nfinite volume scheme is used for the resolution of the transport diffusion\nequations on the dual mesh, whereas the pressure system is solved implicitly by\nusing continuous finite elements defined on the primal simplex mesh.\nConsequently, the CFL stability condition depends only on the flow velocity,\navoiding the severe time restrictions that might be imposed by the sound\nvelocity in the weakly compressible regime. High order of accuracy in space and\ntime of the transport diffusion stage is attained using a local ADER (LADER)\nmethodology. Moreover, also the CVC Kolgan-type second order in space and first\norder in time scheme is considered. To prevent spurious oscillations in the\npresence of shocks, an ENO-based reconstruction, the minmod limiter or the\nBarth-Jespersen limiter are employed. To show the validity and robustness of\nour novel staggered semi-implicit hybrid FV/FE scheme, several benchmarks are\nanalysed, showing a good agreement with available exact solutions and numerical\nreference data from low Mach numbers, up to Mach numbers of the order of unity.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:47:48 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 14:38:21 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 17:58:48 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Berm\u00fadez", "A.", ""], ["Busto", "S.", ""], ["Dumbser", "M.", ""], ["Ferr\u00edn", "J. L.", ""], ["Saavedra", "L.", ""], ["V\u00e1zquez-Cend\u00f3n", "M. E.", ""]]}]