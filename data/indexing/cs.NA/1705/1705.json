[{"id": "1705.00058", "submitter": "Min Xiang Mr.", "authors": "Min Xiang, Shirin Enshaeifar, Alexander E. Stott, Clive Cheong Took,\n  Yili Xia, Sithan Kanna, Danilo P. Mandic", "title": "Simultaneous diagonalisation of the covariance and complementary\n  covariance matrices in quaternion widely linear signal processing", "comments": "41 pages, single column, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in quaternion-valued widely linear processing have\nestablished that the exploitation of complete second-order statistics requires\nconsideration of both the standard covariance and the three complementary\ncovariance matrices. Although such matrices have a tremendous amount of\nstructure and their decomposition is a powerful tool in a variety of\napplications, the non-commutative nature of the quaternion product has been\nprohibitive to the development of quaternion uncorrelating transforms. To this\nend, we introduce novel techniques for a simultaneous decomposition of the\ncovariance and complementary covariance matrices in the quaternion domain,\nwhereby the quaternion version of the Takagi factorisation is explored to\ndiagonalise symmetric quaternion-valued matrices. This gives new insights into\nthe quaternion uncorrelating transform (QUT) and forms a basis for the proposed\nquaternion approximate uncorrelating transform (QAUT) which simultaneously\ndiagonalises all four covariance matrices associated with improper quaternion\nsignals. The effectiveness of the proposed uncorrelating transforms is\nvalidated by simulations on both synthetic and real-world quaternion-valued\nsignals.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 19:57:16 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 15:20:44 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Xiang", "Min", ""], ["Enshaeifar", "Shirin", ""], ["Stott", "Alexander E.", ""], ["Took", "Clive Cheong", ""], ["Xia", "Yili", ""], ["Kanna", "Sithan", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "1705.01576", "submitter": "Xiao-Yang Liu", "authors": "Xiao-Yang Liu and Xiaodong Wang", "title": "Fourth-order Tensors with Multidimensional Discrete Transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The big data era is swamping areas including data analysis, machine/deep\nlearning, signal processing, statistics, scientific computing, and cloud\ncomputing. The multidimensional feature and huge volume of big data put urgent\nrequirements to the development of multilinear modeling tools and efficient\nalgorithms. In this paper, we build a novel multilinear tensor space that\nsupports useful algorithms such as SVD and QR, while generalizing the matrix\nspace to fourth-order tensors was believed to be challenging. Specifically,\ngiven any multidimensional discrete transform, we show that fourth-order\ntensors are bilinear operators on a space of matrices. First, we take a\ntransform-based approach to construct a new tensor space by defining a new\nmultiplication operation and tensor products, and accordingly the analogous\nconcepts: identity, inverse, transpose, linear combinations, and orthogonality.\nSecondly, we define the $\\mathcal{L}$-SVD for fourth-order tensors and present\nan efficient algorithm, where the tensor case requires a stronger condition for\nunique decomposition than the matrix case. Thirdly, we define the tensor\n$\\mathcal{L}$-QR decomposition and propose a Householder QR algorithm to avoid\nthe catastrophic cancellation problem associated with the conventional\nGram-Schmidt process. Finally, we validate our schemes on video compression and\none-shot face recognition. For video compression, compared with the existing\ntSVD, the proposed $\\mathcal{L}$-SVD achieves $3\\sim 10$dB gains in RSE, while\nthe running time is reduced by about $50\\%$ and $87.5\\%$, respectively. For\none-shot face recognition, the recognition rate is increased by about $10\\%\n\\sim 20\\%$.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 18:44:31 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Liu", "Xiao-Yang", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1705.01668", "submitter": "Philip Zwanenburg", "authors": "Philip Zwanenburg and Siva Nadarajah", "title": "On the Necessity of Superparametric Geometry Representation for\n  Discontinuous Galerkin Methods on Domains with Curved Boundaries", "comments": "AIAA Aviation 2017 conference paper", "journal-ref": null, "doi": "10.2514/6.2017-3946", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide numerical evidence demonstrating the necessity of employing a\nsuperparametric geometry representation in order to obtain optimal convergence\norders on two-dimensional domains with curved boundaries when solving the Euler\nequations using Discontinuous Galerkin methods. However, concerning the\nobtention of optimal convergence orders for the Navier-Stokes equations, we\ndemonstrate numerically that the use of isoparametric geometry representation\nis sufficient for the case considered here.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 01:30:05 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Zwanenburg", "Philip", ""], ["Nadarajah", "Siva", ""]]}, {"id": "1705.02274", "submitter": "Piero Triverio", "authors": "Fadime Bekmambetova, Xinyue Zhang and Piero Triverio", "title": "A Dissipation Theory for Three-Dimensional FDTD with Application to\n  Stability Analysis and Subgridding", "comments": null, "journal-ref": null, "doi": "10.1109/TAP.2018.2869617", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The finite-difference time-domain (FDTD) algorithm is a popular numerical\nmethod for solving electromagnetic problems. FDTD simulations can suffer from\ninstability due to the explicit nature of the method. Stability enforcement can\nbe particularly challenging in scenarios where a setup is composed of multiple\ncomponents, such as grids of different resolution, advanced boundary\nconditions, reduced-order models, and lumped elements. We propose a dissipation\ntheory for 3-D FDTD inspired by the principle of energy conservation. We view\nthe FDTD update equations for a 3-D region as a dynamical system, and show\nunder which conditions the system is dissipative. By requiring each component\nof an FDTD-like scheme to be dissipative, the stability of the overall coupled\nscheme follows by construction. The proposed framework enables the creation of\nprovably stable schemes in an easy and modular fashion, since conditions are\nimposed on the individual components, rather than on the overall coupled scheme\nas in existing approaches. With the proposed framework, we derive a new\nsubgridding scheme with guaranteed stability, low reflections, support for\nmaterial traverse and arbitrary (odd) grid refinement ratio.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 15:44:14 GMT"}, {"version": "v2", "created": "Sat, 22 Jul 2017 06:56:52 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Bekmambetova", "Fadime", ""], ["Zhang", "Xinyue", ""], ["Triverio", "Piero", ""]]}, {"id": "1705.02878", "submitter": "Alexander Evako V", "authors": "Alexander V. Evako", "title": "Solution of the Hyperbolic Partial Differential Equation on Graphs and\n  Digital Spaces: a Klein Bottle a Projective Plane and a 4D Sphere", "comments": "7 pages, 11figures", "journal-ref": "International Journal of Discrete Mathematics, 2017; 2(3): 88-94\n  http://www.sciencepublishinggroup.com/j/dmath", "doi": "10.11648/j.dmath.20170203.15", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases, analytic solutions of partial differential equations may not\nbe possible. For practical problems, it is more reasonable to carry out\ncomputational solutions. However, the standard grid in the finite difference\napproximation is not a correct model of the continuous domain in terms of\ndigital topology. In order to avoid serious problems in computational solutions\nit is necessary to use topologically correct digital domains. This paper\nstudies the structure of the hyperbolic partial differential equation on graphs\nand digital n-dimensional manifolds, which are digital models of continuous\nn-manifolds. Conditions for the existence of solutions are determined and\ninvestigated. Numerical solutions of the equation on graphs and digital\nn-manifolds are presented.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 22:56:36 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Evako", "Alexander V.", ""]]}, {"id": "1705.02944", "submitter": "Rasmus J Kyng", "authors": "Rasmus Kyng, Peng Zhang", "title": "Hardness Results for Structured Linear Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if the nearly-linear time solvers for Laplacian matrices and\ntheir generalizations can be extended to solve just slightly larger families of\nlinear systems, then they can be used to quickly solve all systems of linear\nequations over the reals. This result can be viewed either positively or\nnegatively: either we will develop nearly-linear time algorithms for solving\nall systems of linear equations over the reals, or progress on the families we\ncan solve in nearly-linear time will soon halt.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 16:11:26 GMT"}, {"version": "v2", "created": "Sun, 24 Sep 2017 18:28:43 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Kyng", "Rasmus", ""], ["Zhang", "Peng", ""]]}, {"id": "1705.03266", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson", "title": "Computing the Lambert W function in arbitrary-precision complex interval\n  arithmetic", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithm to evaluate all the complex branches of the Lambert\nW function with rigorous error bounds in interval arithmetic, which has been\nimplemented in the Arb library. The classic 1996 paper on the Lambert W\nfunction by Corless et al. provides a thorough but partly heuristic numerical\nanalysis which needs to be complemented with some explicit inequalities and\npractical observations about managing precision and branch cuts.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 10:45:42 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Johansson", "Fredrik", ""]]}, {"id": "1705.03341", "submitter": "Lars Ruthotto", "authors": "Eldad Haber and Lars Ruthotto", "title": "Stable Architectures for Deep Neural Networks", "comments": "23 pages, 7 figures", "journal-ref": "Inverse Problems, Volume 34, Number 1 Inverse Problems, Volume 34,\n  Number 1, 2017", "doi": "10.1088/1361-6420/aa9a90", "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have become invaluable tools for supervised machine\nlearning, e.g., classification of text or images. While often offering superior\nresults over traditional techniques and successfully expressing complicated\npatterns in data, deep architectures are known to be challenging to design and\ntrain such that they generalize well to new data. Important issues with deep\narchitectures are numerical instabilities in derivative-based learning\nalgorithms commonly called exploding or vanishing gradients. In this paper we\npropose new forward propagation techniques inspired by systems of Ordinary\nDifferential Equations (ODE) that overcome this challenge and lead to\nwell-posed learning problems for arbitrarily deep networks.\n  The backbone of our approach is our interpretation of deep learning as a\nparameter estimation problem of nonlinear dynamical systems. Given this\nformulation, we analyze stability and well-posedness of deep learning and use\nthis new understanding to develop new network architectures. We relate the\nexploding and vanishing gradient phenomenon to the stability of the discrete\nODE and present several strategies for stabilizing deep learning for very deep\nnetworks. While our new architectures restrict the solution space, several\nnumerical experiments show their competitiveness with state-of-the-art\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 14:13:18 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 08:47:13 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 16:13:21 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Haber", "Eldad", ""], ["Ruthotto", "Lars", ""]]}, {"id": "1705.03434", "submitter": "Petr Vabishchevich N.", "authors": "Petr N. Vabishchevich", "title": "Two-component domain decomposition scheme with overlapping subdomains\n  for parabolic equations", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An iteration-free method of domain decomposition is considered for\napproximate solving a boundary value problem for a second-order parabolic\nequation. A standard approach to constructing domain decomposition schemes is\nbased on a partition of unity for the domain under the consideration. Here a\nnew general approach is proposed for constructing domain decomposition schemes\nwith overlapping subdomains based on indicator functions of subdomains. The\nbasic peculiarity of this method is connected with a representation of the\nproblem operator as the sum of two operators, which are constructed for two\nseparate subdomains with the subtraction of the operator that is associated\nwith the intersection of the subdomains. There is developed a two-component\nfactorized scheme, which can be treated as a generalization of the standard\nAlternating Direction Implicit (ADI) schemes to the case of a special\nthree-component splitting. There are obtained conditions for the unconditional\nstability of regionally additive schemes constructed using indicator functions\nof subdomains. Numerical results are presented for a model two-dimensional\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 17:17:44 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Vabishchevich", "Petr N.", ""]]}, {"id": "1705.03493", "submitter": "Andrew Knyazev", "authors": "Andrew Knyazev, Alexander Malyshev", "title": "Signal reconstruction via operator guiding", "comments": "5 pages, 8 figures. To appear in Proceedings of SampTA 2017: Sampling\n  Theory and Applications, 12th International Conference, July 3-7, 2017,\n  Tallinn, Estonia", "journal-ref": "IEEE Xplore: 2017 International Conference on Sampling Theory and\n  Applications (SampTA), Tallin, Estonia, 2017, pp. 630-634", "doi": "10.1109/SAMPTA.2017.8024424", "report-no": "MERL TR2017-087", "categories": "cs.CV cs.GR cs.IT cs.NA math.IT math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal reconstruction from a sample using an orthogonal projector onto a\nguiding subspace is theoretically well justified, but may be difficult to\npractically implement. We propose more general guiding operators, which\nincrease signal components in the guiding subspace relative to those in a\ncomplementary subspace, e.g., iterative low-pass edge-preserving filters for\nsuper-resolution of images. Two examples of super-resolution illustrate our\ntechnology: a no-flash RGB photo guided using a high resolution flash RGB\nphoto, and a depth image guided using a high resolution RGB photo.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 19:06:16 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Knyazev", "Andrew", ""], ["Malyshev", "Alexander", ""]]}, {"id": "1705.03625", "submitter": "Kalyana Babu Nakshatrala", "authors": "J. Chang, K. B. Nakshatrala, M. G. Knepley and L. Johnsson", "title": "A performance spectrum for parallel computational frameworks that solve\n  PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important computational physics problems are often large-scale in nature, and\nit is highly desirable to have robust and high performing computational\nframeworks that can quickly address these problems. However, it is no trivial\ntask to determine whether a computational framework is performing efficiently\nor is scalable. The aim of this paper is to present various strategies for\nbetter understanding the performance of any parallel computational frameworks\nfor solving PDEs. Important performance issues that negatively impact\ntime-to-solution are discussed, and we propose a performance spectrum analysis\nthat can enhance one's understanding of critical aforementioned performance\nissues. As proof of concept, we examine commonly used finite element simulation\npackages and software and apply the performance spectrum to quickly analyze the\nperformance and scalability across various hardware platforms, software\nimplementations, and numerical discretizations. It is shown that the proposed\nperformance spectrum is a versatile performance model that is not only\nextendable to more complex PDEs such as hydrostatic ice sheet flow equations,\nbut also useful for understanding hardware performance in a massively parallel\ncomputing environment. Potential applications and future extensions of this\nwork are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 06:51:15 GMT"}, {"version": "v2", "created": "Fri, 15 Sep 2017 00:00:52 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Chang", "J.", ""], ["Nakshatrala", "K. B.", ""], ["Knepley", "M. G.", ""], ["Johnsson", "L.", ""]]}, {"id": "1705.03667", "submitter": "Mikl\\'os Homolya", "authors": "Mikl\\'os Homolya, Lawrence Mitchell, Fabio Luporini, David A. Ham", "title": "TSFC: a structure-preserving form compiler", "comments": "Accepted version. 28 pages plus 5 pages supplement", "journal-ref": "SIAM Journal on Scientific Computing, 40 (2018), pp. C401-C428", "doi": "10.1137/17M1130642", "report-no": null, "categories": "cs.MS cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A form compiler takes a high-level description of the weak form of partial\ndifferential equations and produces low-level code that carries out the finite\nelement assembly. In this paper we present the Two-Stage Form Compiler (TSFC),\na new form compiler with the main motivation to maintain the structure of the\ninput expression as long as possible. This facilitates the application of\noptimizations at the highest possible level of abstraction. TSFC features a\nnovel, structure-preserving method for separating the contributions of a form\nto the subblocks of the local tensor in discontinuous Galerkin problems. This\nenables us to preserve the tensor structure of expressions longer through the\ncompilation process than other form compilers. This is also achieved in part by\na two-stage approach that cleanly separates the lowering of finite element\nconstructs to tensor algebra in the first stage, from the scheduling of those\ntensor operations in the second stage. TSFC also efficiently traverses\ncomplicated expressions, and experimental evaluation demonstrates good\ncompile-time performance even for highly complex forms.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 09:21:24 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 13:51:11 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Homolya", "Mikl\u00f3s", ""], ["Mitchell", "Lawrence", ""], ["Luporini", "Fabio", ""], ["Ham", "David A.", ""]]}, {"id": "1705.04431", "submitter": "Caroline Wormell", "authors": "Caroline L. Wormell", "title": "Spectral Galerkin methods for transfer operators in uniformly expanding\n  dynamics", "comments": null, "journal-ref": "Numer. Math. 142, 421-463 (2019)", "doi": "10.1007/s00211-019-01031-z", "report-no": null, "categories": "math.DS cs.NA math.NA nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov expanding maps, a class of simple chaotic systems, are commonly used\nas models for chaotic dynamics, but existing numerical methods to study\nlong-time statistical properties such as invariant measures have a poor\ntrade-off between computational effort and accuracy. We develop a spectral\nGalerkin method for these maps' transfer operators, estimating statistical\nquantities using finite submatrices of the transfer operators' infinite Fourier\nor Chebyshev basis coefficient matrices. Rates of convergence of these\nestimates are obtained via quantitative bounds on the full transfer operator\nmatrix entries; we find the method furnishes up to exponentially accurate\nestimates of statistical properties in only a polynomially large computational\ntime.\n  To implement these results we suggest and demonstrate two algorithms: a\nrigorously-validated algorithm, and a fast, more convenient adaptive algorithm.\nUsing the first algorithm we prove rigorous bounds on some exemplar quantities\nthat are substantially more accurate than previous. We show that the adaptive\nalgorithm can produce double floating-point accuracy estimates in a fraction of\na second on a personal computer.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 03:33:57 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 11:10:28 GMT"}, {"version": "v3", "created": "Tue, 6 Mar 2018 03:14:12 GMT"}, {"version": "v4", "created": "Tue, 2 Jun 2020 12:47:02 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wormell", "Caroline L.", ""]]}, {"id": "1705.04807", "submitter": "Fatima Abu Salem", "authors": "Fatima K. Abu Salem and Mira Al Arab", "title": "Cache-oblivious Matrix Multiplication for Exact Factorisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a cache-oblivious adaptation of matrix multiplication to be\nincorporated in the parallel TU decomposition for rectangular matrices over\nfinite fields, based on the Morton-hybrid space-filling curve representation.\nTo realise this, we introduce the concepts of alignment and containment of\nsub-matrices under the Morton-hybrid layout. We redesign the decompositions\nwithin the recursive matrix multiplication to force the base case to avoid all\njumps in address space, at the expense of extra recursive matrix multiplication\n(MM) calls. We show that the resulting cache oblivious adaptation has low span,\nand our experiments demonstrate that its sequential evaluation order\ndemonstrates orders of magnitude improvement in run-time, despite the recursion\noverhead.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 06:33:43 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Salem", "Fatima K. Abu", ""], ["Arab", "Mira Al", ""]]}, {"id": "1705.04870", "submitter": "Savio Rodrigues", "authors": "Savio B. Rodrigues", "title": "Improving the IMEX method with a residual balanced decomposition", "comments": "This ArXiv version 3 corrects figure 4 of version 2 and it has a new\n  title", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In numerical time-integration with implicit-explicit (IMEX) methods, a\nwithin-step adaptable decomposition called residual balanced decomposition is\nintroduced. With this decomposition, the requirement of a small enough residual\nin the iterative solver can be removed, consequently, this allows to exchange\nstability for efficiency. This decomposition transfers any residual occurring\nin the implicit equation of the implicit-step into the explicit part of the\ndecomposition. By balancing the residual, the accuracy of the local truncation\nerror of the time-stepping method becomes independent from the accuracy by\nwhich the implicit equation is solved. In order to balance the residual, the\noriginal IMEX decomposition is adjusted after the iterative solver has been\nstopped. For this to work, the traditional IMEX time-stepping algorithm needs\nto be changed. We call this new method the shortcut-IMEX (SIMEX). SIMEX can\ngain computational efficiency by exploring the trade-off between the\ncomputational effort placed in solving the implicit equation and the size of\nthe numerically stable time-step. Typically, increasing the number of solver\niterations increases the largest stable step-size. Both multi-step and\nRunge-Kutta (RK) methods are suitable for use with SIMEX. Here, we show the\nefficiency of a SIMEX-RK method in overcoming parabolic stiffness by applying\nit to a nonlinear reaction-advection-diffusion equation. In order to define a\nstability region for SIMEX, a region in the complex plane is depicted by\napplying SIMEX to a suitable PDE model containing diffusion and dispersion. A\nmyriad of stability regions can be reached by changing the RK tableau and the\nsolver.\n", "versions": [{"version": "v1", "created": "Sat, 13 May 2017 18:21:00 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 18:51:15 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 12:24:13 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Rodrigues", "Savio B.", ""]]}, {"id": "1705.05256", "submitter": "Sina Bittens", "authors": "Sina Bittens (University of G\\\"ottingen) and Ruochuan Zhang (Michigan\n  State University) and Mark A. Iwen (Michigan State University)", "title": "A Deterministic Sparse FFT for Functions with Structured Fourier\n  Sparsity", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a deterministic sparse Fourier transform algorithm is presented\nwhich breaks the quadratic-in-sparsity runtime bottleneck for a large class of\nperiodic functions exhibiting structured frequency support. These functions\ninclude, e.g., the oft-considered set of block frequency sparse functions of\nthe form $$f(x) = \\sum^{n}_{j=1} \\sum^{B-1}_{k=0} c_{\\omega_j + k}\ne^{i(\\omega_j + k)x},~~\\{ \\omega_1, \\dots, \\omega_n \\} \\subset\n\\left(-\\left\\lceil \\frac{N}{2}\\right\\rceil, \\left\\lfloor\n\\frac{N}{2}\\right\\rfloor\\right]\\cap\\mathbb{Z}$$ as a simple subclass.\nTheoretical error bounds in combination with numerical experiments demonstrate\nthat the newly proposed algorithms are both fast and robust to noise. In\nparticular, they outperform standard sparse Fourier transforms in the rapid\nrecovery of block frequency sparse functions of the type above.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 14:13:40 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 15:32:43 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Bittens", "Sina", "", "University of G\u00f6ttingen"], ["Zhang", "Ruochuan", "", "Michigan\n  State University"], ["Iwen", "Mark A.", "", "Michigan State University"]]}, {"id": "1705.05470", "submitter": "Omar Lakkis", "authors": "Mehmet Ersoy, Omar Lakkis and Philip Townsend", "title": "A Saint-Venant shallow water model for overland flows with precipitation\n  and recharge", "comments": "6 figures, free simulation software available on request", "journal-ref": "Mathematical and Computational Applications (2021) (published\n  online 29 Dec 2020)", "doi": "10.3390/mca26010001", "report-no": null, "categories": "math.NA cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a one-dimensional Saint-Venant (open channel) model overland flows\nincluding a water input--output source term modelling recharge via rainfall and\ninfiltration (or exfiltration). We derive the model via asymptotic reduction\nfrom the two-dimensional Navier--Stokes equations under the shallow water\nassumption, with boundary conditions including recharge via ground infiltration\nand runoff. This new model recovers existing models as sepcial cases, and adds\nmore scope by adding a water-mixing friction terms that depends on the rate of\nwater recharge. We prospose a novel entropy function and its flux, that are\nuseful in validating the model's conservation or dissipation properties. Based\non this entropy function we propose a finite volume scheme extending a class of\nkinetic schemes and provide numerical comparisons with respect to the newly\nintroduced mixing friction coefficient. We also provide a comparison with\nexperimental data.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 22:18:12 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2017 20:09:48 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 18:03:41 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Ersoy", "Mehmet", ""], ["Lakkis", "Omar", ""], ["Townsend", "Philip", ""]]}, {"id": "1705.05475", "submitter": "Tsung-Han Lin", "authors": "Ping Tak Peter Tang, Tsung-Han Lin, Mike Davies", "title": "Sparse Coding by Spiking Neural Networks: Convergence Theory and\n  Computational Results", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a spiking neural network (SNN), individual neurons operate autonomously\nand only communicate with other neurons sparingly and asynchronously via spike\nsignals. These characteristics render a massively parallel hardware\nimplementation of SNN a potentially powerful computer, albeit a non von Neumann\none. But can one guarantee that a SNN computer solves some important problems\nreliably? In this paper, we formulate a mathematical model of one SNN that can\nbe configured for a sparse coding problem for feature extraction. With a\nmoderate but well-defined assumption, we prove that the SNN indeed solves\nsparse coding. To the best of our knowledge, this is the first rigorous result\nof this kind.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 23:06:34 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Tang", "Ping Tak Peter", ""], ["Lin", "Tsung-Han", ""], ["Davies", "Mike", ""]]}, {"id": "1705.05589", "submitter": "Denys Dutykh", "authors": "Suelen Gasparin (LAMA, PUCPR), Julien Berger (LOCIE), Denys Dutykh\n  (LAMA), Nathan Mendes (PUCPR)", "title": "Advanced reduced-order models for moisture diffusion in porous media", "comments": "42 pages, 14 figures, 1 table, 69 references. Other author's papers\n  can be downloaded at http://www.denys-dutykh.com/. arXiv admin note: text\n  overlap with arXiv:1704.07607", "journal-ref": "Transport in Porous Media (2018), Vol. 124, pp. 965-994", "doi": "10.1007/s11242-018-1106-2", "report-no": null, "categories": "physics.comp-ph cs.NA math.AP math.NA physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of great concern to produce numerically efficient methods for moisture\ndiffusion through porous media, capable of accurately calculate moisture\ndistribution with a reduced computational effort. In this way, model reduction\nmethods are promising approaches to bring a solution to this issue since they\ndo not degrade the physical model and provide a significant reduction of\ncomputational cost. Therefore, this article explores in details the\ncapabilities of two model-reduction techniques - the Spectral Reduced-Order\nModel (Spectral-ROM) and the Proper Generalised Decomposition (PGD) - to\nnumerically solve moisture diffusive transfer through porous materials. Both\napproaches are applied to three different problems to provide clear examples of\nthe construction and use of these reduced-order models. The methodology of both\napproaches is explained extensively so that the article can be used as a\nnumerical benchmark by anyone interested in building a reduced-order model for\ndiffusion problems in porous materials. Linear and non-linear unsteady\nbehaviors of unidimensional moisture diffusion are investigated. The last case\nfocuses on solving a parametric problem in which the solution depends on space,\ntime and the diffusivity properties. Results have highlighted that both methods\nprovide accurate solutions and enable to reduce significantly the order of the\nmodel around ten times lower than the large original model. It also allows an\nefficient computation of the physical phenomena with an error lower than\n10^{-2} when compared to a reference solution.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 08:39:25 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 08:22:14 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Gasparin", "Suelen", "", "LAMA, PUCPR"], ["Berger", "Julien", "", "LOCIE"], ["Dutykh", "Denys", "", "LAMA"], ["Mendes", "Nathan", "", "PUCPR"]]}, {"id": "1705.05804", "submitter": "Vamsi Ithapu", "authors": "Vamsi K. Ithapu, Risi Kondor, Sterling C. Johnson, Vikas Singh", "title": "The Incremental Multiresolution Matrix Factorization Algorithm", "comments": "Computer Vision and Pattern Recognition (CVPR) 2017, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiresolution analysis and matrix factorization are foundational tools in\ncomputer vision. In this work, we study the interface between these two\ndistinct topics and obtain techniques to uncover hierarchical block structure\nin symmetric matrices -- an important aspect in the success of many vision\nproblems. Our new algorithm, the incremental multiresolution matrix\nfactorization, uncovers such structure one feature at a time, and hence scales\nwell to large matrices. We describe how this multiscale analysis goes much\nfarther than what a direct global factorization of the data can identify. We\nevaluate the efficacy of the resulting factorizations for relative leveraging\nwithin regression tasks using medical imaging data. We also use the\nfactorization on representations learned by popular deep networks, providing\nevidence of their ability to infer semantic relationships even when they are\nnot explicitly trained to do so. We show that this algorithm can be used as an\nexploratory tool to improve the network architecture, and within numerous other\nsettings in vision.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 17:10:05 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Ithapu", "Vamsi K.", ""], ["Kondor", "Risi", ""], ["Johnson", "Sterling C.", ""], ["Singh", "Vikas", ""]]}, {"id": "1705.05927", "submitter": "Jacek Cyranka", "authors": "Jacek Cyranka, Md. Ariful Islam, Greg Byrne, Paul Jones, Scott A.\n  Smolka, Radu Grosu", "title": "Lagrangian Reachabililty", "comments": "Accepted to CAV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NA math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce LRT, a new Lagrangian-based ReachTube computation algorithm that\nconservatively approximates the set of reachable states of a nonlinear\ndynamical system. LRT makes use of the Cauchy-Green stretching factor (SF),\nwhich is derived from an over-approximation of the gradient of the solution\nflows. The SF measures the discrepancy between two states propagated by the\nsystem solution from two initial states lying in a well-defined region, thereby\nallowing LRT to compute a reachtube with a ball-overestimate in a metric where\nthe computed enclosure is as tight as possible. To evaluate its performance, we\nimplemented a prototype of LRT in C++/Matlab, and ran it on a set of\nwell-established benchmarks. Our results show that LRT compares very favorably\nwith respect to the CAPD and Flow* tools.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 21:34:31 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 01:13:41 GMT"}, {"version": "v3", "created": "Fri, 2 Jun 2017 19:15:52 GMT"}, {"version": "v4", "created": "Mon, 3 Jul 2017 16:10:17 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Cyranka", "Jacek", ""], ["Islam", "Md. Ariful", ""], ["Byrne", "Greg", ""], ["Jones", "Paul", ""], ["Smolka", "Scott A.", ""], ["Grosu", "Radu", ""]]}, {"id": "1705.06391", "submitter": "Yangyang Xu", "authors": "Yangyang Xu", "title": "Asynchronous parallel primal-dual block coordinate update methods for\n  affinely constrained convex programs", "comments": null, "journal-ref": "Computational Optimization and Applications, 72(1), pp. 87-113,\n  2019", "doi": "10.1007/s10589-018-0037-8", "report-no": null, "categories": "math.OC cs.DC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent several years have witnessed the surge of asynchronous (async-)\nparallel computing methods due to the extremely big data involved in many\nmodern applications and also the advancement of multi-core machines and\ncomputer clusters. In optimization, most works about async-parallel methods are\non unconstrained problems or those with block separable constraints.\n  In this paper, we propose an async-parallel method based on block coordinate\nupdate (BCU) for solving convex problems with nonseparable linear constraint.\nRunning on a single node, the method becomes a novel randomized primal-dual BCU\nwith adaptive stepsize for multi-block affinely constrained problems. For these\nproblems, Gauss-Seidel cyclic primal-dual BCU needs strong convexity to have\nconvergence. On the contrary, merely assuming convexity, we show that the\nobjective value sequence generated by the proposed algorithm converges in\nprobability to the optimal value and also the constraint residual to zero. In\naddition, we establish an ergodic $O(1/k)$ convergence result, where $k$ is the\nnumber of iterations. Numerical experiments are performed to demonstrate the\nefficiency of the proposed method and significantly better speed-up performance\nthan its sync-parallel counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 01:53:51 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 20:19:02 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Xu", "Yangyang", ""]]}, {"id": "1705.07010", "submitter": "Petr Vabishchevich N.", "authors": "Petr N. Vabishchevich", "title": "Fundamental mode exact schemes for unsteady problems", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of increasing the accuracy of an approximate solution is\nconsidered for boundary value problems for parabolic equations. For ordinary\ndifferential equations (ODEs), nonstandard finite difference schemes are in\ncommon use for this problem. They are based on a modification of standard\ndiscretizations of time derivatives and, in some cases, allow to obtain the\nexact solution of problems. For multidimensional problems, we can consider the\nproblem of increasing the accuracy only for the most important components of\nthe approximate solution. In the present work, new unconditionally stable\nschemes for parabolic problems are constructed, which are exact for the\nfundamental mode. Such two-level schemes are designed via a modification of\nstandard schemes with weights using Pad\\'{e} approximations. Numerical results\nobtained for a model problem demonstrate advantages of the proposed fundamental\nmode exact schemes.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 14:20:28 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Vabishchevich", "Petr N.", ""]]}, {"id": "1705.07112", "submitter": "Masaki Onuki", "authors": "Masaki Onuki, Shunsuke Ono, Keiichiro Shirai, Yuichi Tanaka", "title": "Fast Singular Value Shrinkage with Chebyshev Polynomial Approximation\n  Based on Signal Sparsity", "comments": "This is a journal paper", "journal-ref": null, "doi": "10.1109/TSP.2017.2745444", "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approximation method for thresholding of singular values using\nChebyshev polynomial approximation (CPA). Many signal processing problems\nrequire iterative application of singular value decomposition (SVD) for\nminimizing the rank of a given data matrix with other cost functions and/or\nconstraints, which is called matrix rank minimization. In matrix rank\nminimization, singular values of a matrix are shrunk by hard-thresholding,\nsoft-thresholding, or weighted soft-thresholding. However, the computational\ncost of SVD is generally too expensive to handle high dimensional signals such\nas images; hence, in this case, matrix rank minimization requires enormous\ncomputation time. In this paper, we leverage CPA to (approximately) manipulate\nsingular values without computing singular values and vectors. The thresholding\nof singular values is expressed by a multiplication of certain matrices, which\nis derived from a characteristic of CPA. The multiplication is also efficiently\ncomputed using the sparsity of signals. As a result, the computational cost is\nsignificantly reduced. Experimental results suggest the effectiveness of our\nmethod through several image processing applications based on matrix rank\nminimization with nuclear norm relaxation in terms of computation time and\napproximation precision.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 17:55:58 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Onuki", "Masaki", ""], ["Ono", "Shunsuke", ""], ["Shirai", "Keiichiro", ""], ["Tanaka", "Yuichi", ""]]}, {"id": "1705.07113", "submitter": "Kaibo Hu", "authors": "Kaibo Hu, Ragnar Winther", "title": "Well-conditioned frames for high order finite element methods", "comments": "numerical experiments added, accepted by Journal of Computational\n  Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to discuss representations of high order $C^0$\nfinite element spaces on simplicial meshes in any dimension. When computing\nwith high order piecewise polynomials the conditioning of the basis is likely\nto be important. The main result of this paper is a construction of\nrepresentations by frames such that the associated $L^2$ condition number is\nbounded independently of the polynomial degree. To our knowledge, such a\nrepresentation has not been presented earlier. The main tools we will use for\nthe construction is the bubble transform, introduced previously in [Falk and\nWinther, Found Comput Math (2016) 16: 297], and properties of Jacobi\npolynomials on simplexes in higher dimensions. We also include a brief\ndiscussion of preconditioned iterative methods for the finite element systems\nin the setting of representations by frames.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 17:56:33 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 12:49:16 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 20:42:30 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 18:50:41 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Hu", "Kaibo", ""], ["Winther", "Ragnar", ""]]}, {"id": "1705.07252", "submitter": "Yifei Jin", "authors": "Yifei Jin and Lingxiao Huang and Jian Li", "title": "SVM via Saddle Point Optimization: New Bounds and Distributed Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two important SVM variants: hard-margin SVM (for linearly separable\ncases) and $\\nu$-SVM (for linearly non-separable cases). We propose new\nalgorithms from the perspective of saddle point optimization. Our algorithms\nachieve $(1-\\epsilon)$-approximations with running time $\\tilde{O}(nd+n\\sqrt{d\n/ \\epsilon})$ for both variants, where $n$ is the number of points and $d$ is\nthe dimensionality. To the best of our knowledge, the current best algorithm\nfor $\\nu$-SVM is based on quadratic programming approach which requires\n$\\Omega(n^2 d)$ time in worst case~\\cite{joachims1998making,platt199912}. In\nthe paper, we provide the first nearly linear time algorithm for $\\nu$-SVM. The\ncurrent best algorithm for hard margin SVM achieved by Gilbert\nalgorithm~\\cite{gartner2009coresets} requires $O(nd / \\epsilon )$ time. Our\nalgorithm improves the running time by a factor of $\\sqrt{d}/\\sqrt{\\epsilon}$.\nMoreover, our algorithms can be implemented in the distributed settings\nnaturally. We prove that our algorithms require $\\tilde{O}(k(d\n+\\sqrt{d/\\epsilon}))$ communication cost, where $k$ is the number of clients,\nwhich almost matches the theoretical lower bound. Numerical experiments support\nour theory and show that our algorithms converge faster on high dimensional,\nlarge and dense data sets, as compared to previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 03:06:13 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 07:09:30 GMT"}, {"version": "v3", "created": "Wed, 24 May 2017 05:40:16 GMT"}, {"version": "v4", "created": "Sun, 28 Jan 2018 12:51:58 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Jin", "Yifei", ""], ["Huang", "Lingxiao", ""], ["Li", "Jian", ""]]}, {"id": "1705.07285", "submitter": "Philippe Toint", "authors": "C. Cartis, N. I. M. Gould and Ph. L. Toint", "title": "Optimality of orders one to three and beyond: characterization and\n  evaluation complexity in constrained nonconvex optimization", "comments": "32 pages, 3 figures", "journal-ref": "Journal of Complexity, vol. 53, pp. 68-94, 2019", "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Necessary conditions for high-order optimality in smooth nonlinear\nconstrained optimization are explored and their inherent intricacy discussed. A\ntwo-phase minimization algorithm is proposed which can achieve approximate\nfirst-, second- and third-order criticality and its evaluation complexity is\nanalyzed as a function of the choice (among existing methods) of an inner\nalgorithm for solving subproblems in each of the two phases. The relation\nbetween high-order criticality and penalization techniques is finally\nconsidered, showing that standard algorithmic approaches will fail if\napproximate constrained high-order critical points are sought.\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 09:48:20 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 10:39:30 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Cartis", "C.", ""], ["Gould", "N. I. M.", ""], ["Toint", "Ph. L.", ""]]}, {"id": "1705.07364", "submitter": "Sohil Shah", "authors": "Abhay Yadav, Sohil Shah, Zheng Xu, David Jacobs and Tom Goldstein", "title": "Stabilizing Adversarial Nets With Prediction Methods", "comments": "Accepted at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial neural networks solve many important problems in data science,\nbut are notoriously difficult to train. These difficulties come from the fact\nthat optimal weights for adversarial nets correspond to saddle points, and not\nminimizers, of the loss function. The alternating stochastic gradient methods\ntypically used for such problems do not reliably converge to saddle points, and\nwhen convergence does happen it is often highly sensitive to learning rates. We\npropose a simple modification of stochastic gradient descent that stabilizes\nadversarial networks. We show, both in theory and practice, that the proposed\nmethod reliably converges to saddle points, and is stable with a wider range of\ntraining parameters than a non-prediction method. This makes adversarial\nnetworks less likely to \"collapse,\" and enables faster training with larger\nlearning rates.\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 22:27:19 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 04:22:35 GMT"}, {"version": "v3", "created": "Thu, 8 Feb 2018 21:57:54 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Yadav", "Abhay", ""], ["Shah", "Sohil", ""], ["Xu", "Zheng", ""], ["Jacobs", "David", ""], ["Goldstein", "Tom", ""]]}, {"id": "1705.07803", "submitter": "Hongxuan Zhang", "authors": "Jinchao Xu, Hongxuan Zhang and Ludmil Zikatanov", "title": "On the Weyl's law for discretized elliptic operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give an estimate on the asymptotic behavior of eigenvalues\nof discretized elliptic boundary values problems. We first prove a simple\nmin-max principle for selfadjoint operators on a Hilbert space. Then we show\ntwo sided bounds on the $k$-th eigenvalue of the discrete Laplacian by the\n$k$-th eigenvalue of the continuous Laplacian operator under the assumption\nthat the finite element mesh is quasi-uniform. Combining this result with the\nwell-known Weyl's law, we show that the $k$-th eigenvalue of the discretized\nisotropic elliptic operators, spectrally equivalent to the discretized\nLaplacian, is $\\mathcal O\\left(k^{2/d}\\right)$. Finally, we show how these\nresults can be used to obtain an error estimate for finite element\napproximations of elliptic eigenvalue problems.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 15:20:49 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 13:19:49 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Xu", "Jinchao", ""], ["Zhang", "Hongxuan", ""], ["Zikatanov", "Ludmil", ""]]}, {"id": "1705.08286", "submitter": "Qibin Zhao Dr", "authors": "Qibin Zhao, Masashi Sugiyama, Andrzej Cichocki", "title": "Learning Efficient Tensor Representations with Ring Structure Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1606.05535", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor train (TT) decomposition is a powerful representation for high-order\ntensors, which has been successfully applied to various machine learning tasks\nin recent years. However, since the tensor product is not commutative,\npermutation of data dimensions makes solutions and TT-ranks of TT decomposition\ninconsistent. To alleviate this problem, we propose a permutation symmetric\nnetwork structure by employing circular multilinear products over a sequence of\nlow-order core tensors. This network structure can be graphically interpreted\nas a cyclic interconnection of tensors, and thus we call it tensor ring (TR)\nrepresentation. We develop several efficient algorithms to learn TR\nrepresentation with adaptive TR-ranks by employing low-rank approximations.\nFurthermore, mathematical properties are investigated, which enables us to\nperform basic operations in a computationally efficiently way by using TR\nrepresentations. Experimental results on synthetic signals and real-world\ndatasets demonstrate that the proposed TR network is more expressive and\nconsistently informative than existing TT networks.\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 06:40:49 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 05:28:29 GMT"}, {"version": "v3", "created": "Fri, 26 May 2017 03:33:17 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Zhao", "Qibin", ""], ["Sugiyama", "Masashi", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1705.08445", "submitter": "Brian Van Koten", "authors": "Aaron R. Dinner, Erik Thiede, Brian Van Koten, Jonathan Weare", "title": "Stratification as a general variance reduction method for Markov chain\n  Monte Carlo", "comments": "52 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Eigenvector Method for Umbrella Sampling (EMUS) belongs to a popular\nclass of methods in statistical mechanics which adapt the principle of\nstratified survey sampling to the computation of free energies. We develop a\ndetailed theoretical analysis of EMUS. Based on this analysis, we show that\nEMUS is an efficient general method for computing averages over arbitrary\ntarget distributions. In particular, we show that EMUS can be dramatically more\nefficient than direct MCMC when the target distribution is multimodal or when\nthe goal is to compute tail probabilities. To illustrate these theoretical\nresults, we present a tutorial application of the method to a problem from\nBayesian statistics.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 17:59:32 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 14:06:03 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 14:26:46 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Dinner", "Aaron R.", ""], ["Thiede", "Erik", ""], ["Van Koten", "Brian", ""], ["Weare", "Jonathan", ""]]}, {"id": "1705.08614", "submitter": "Svetlana Matculevich", "authors": "B\\\"arbel Holm and Svetlana Matculevich", "title": "Fully reliable error control for evolutionary problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is focused on the application of functional-type a posteriori error\nestimates and corresponding indicators to a class of time-dependent problems.\nWe consider the algorithmic part of their derivation and implementation and\nalso discuss the numerical properties of these bounds that comply with obtained\nnumerical results. This paper examines two different methods of approximate\nsolution reconstruction for evolutionary models, i.e., a time-marching\ntechnique and a space-time approach. The first part of the study presents an\nalgorithm for global minimization of the majorant on each of discretization\ntime-cylinders (time-slabs), the effectiveness of this algorithm is confirmed\nby extensive numerical tests. In the second part of the publication, the\napplication of functional error estimates is discussed with respect to a\nspace-time approach. It is followed by a set of extensive numerical tests that\ndemonstrate the efficiency of proposed error control method.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 05:35:41 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Holm", "B\u00e4rbel", ""], ["Matculevich", "Svetlana", ""]]}, {"id": "1705.08806", "submitter": "Murugesan Venkatapathi", "authors": "Puneet Jain, Krishna Manglani and Murugesan Venkatapathi", "title": "Error estimators and their analysis for CG, Bi-CG and GMRES", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis of the uncertainty in the convergence of iterative\nlinear solvers when using relative residue as a stopping criterion, and the\nresulting over/under computation for a given tolerance in error. This shows\nthat error estimation is indispensable for efficient and accurate solution of\nmoderate to high conditioned linear systems ($\\kappa>100$), where $\\kappa$ is\nthe condition number of the matrix. An $\\mathcal{O}(1)$ error estimator for\niterations of the CG (Conjugate Gradient) algorithm was proposed more than two\ndecades ago. Recently, an $\\mathcal{O}(k^2)$ error estimator was described for\nthe GMRES (Generalized Minimal Residual) algorithm which allows for\nnon-symmetric linear systems as well, where $k$ is the iteration number. We\nsuggest a minor modification in this GMRES error estimation for increased\nstability. In this work, we also propose an $\\mathcal{O}(n)$ error estimator\nfor A-norm and $l_{2}$ norm of the error vector in Bi-CG (Bi-Conjugate\nGradient) algorithm. The robust performance of these estimates as a stopping\ncriterion results in increased savings and accuracy in computation, as\ncondition number and size of problems increase.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 14:56:28 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 15:34:45 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Jain", "Puneet", ""], ["Manglani", "Krishna", ""], ["Venkatapathi", "Murugesan", ""]]}, {"id": "1705.08883", "submitter": "Kalyana Babu Nakshatrala", "authors": "S. H. S. Joodat, K. B. Nakshatrala and R. Ballarini", "title": "Modeling flow in porous media with double porosity/permeability: A\n  stabilized mixed formulation, error analysis, and numerical solutions", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2018.04.004", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The flow of incompressible fluids through porous media plays a crucial role\nin many technological applications such as enhanced oil recovery and geological\ncarbon-dioxide sequestration. The flow within numerous natural and synthetic\nporous materials that contain multiple scales of pores cannot be adequately\ndescribed by the classical Darcy equations. It is for this reason that\nmathematical models for fluid flow in media with multiple scales of pores have\nbeen proposed in the literature. However, these models are analytically\nintractable for realistic problems. In this paper, a stabilized mixed\nfour-field finite element formulation is presented to study the flow of an\nincompressible fluid in porous media exhibiting double porosity/permeability.\nThe stabilization terms and the stabilization parameters are derived in a\nmathematically and thermodynamically consistent manner, and the computationally\nconvenient equal-order interpolation of all the field variables is shown to be\nstable. A systematic error analysis is performed on the resulting stabilized\nweak formulation. Representative problems, patch tests and numerical\nconvergence analyses are performed to illustrate the performance and\nconvergence behavior of the proposed mixed formulation in the discrete setting.\nThe accuracy of numerical solutions is assessed using the mathematical\nproperties satisfied by the solutions of this double porosity/permeability\nmodel. Moreover, it is shown that the proposed framework can perform well under\ntransient conditions and that it can capture well-known instabilities such as\nviscous fingering.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 17:55:12 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 18:31:23 GMT"}, {"version": "v3", "created": "Sun, 5 Nov 2017 18:30:59 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Joodat", "S. H. S.", ""], ["Nakshatrala", "K. B.", ""], ["Ballarini", "R.", ""]]}, {"id": "1705.09382", "submitter": "Vahan Huroyan", "authors": "Vahan Huroyan and Gilad Lerman", "title": "Distributed Robust Subspace Recovery", "comments": null, "journal-ref": "SIAM J. Sci. Comput. 40 (2018) A3067-A3090", "doi": "10.1137/17M1131659", "report-no": null, "categories": "math.NA cs.AI cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose distributed solutions to the problem of Robust Subspace Recovery\n(RSR). Our setting assumes a huge dataset in an ad hoc network without a\ncentral processor, where each node has access only to one chunk of the dataset.\nFurthermore, part of the whole dataset lies around a low-dimensional subspace\nand the other part is composed of outliers that lie away from that subspace.\nThe goal is to recover the underlying subspace for the whole dataset, without\ntransferring the data itself between the nodes. We first apply the\nConsensus-Based Gradient method to the Geometric Median Subspace algorithm for\nRSR. For this purpose, we propose an iterative solution for the local dual\nminimization problem and establish its r-linear convergence. We then explain\nhow to distributedly implement the Reaper and Fast Median Subspace algorithms\nfor RSR. The proposed algorithms display competitive performance on both\nsynthetic and real data.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 22:22:51 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2018 21:31:02 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2018 21:56:51 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Huroyan", "Vahan", ""], ["Lerman", "Gilad", ""]]}, {"id": "1705.09907", "submitter": "Maurice S. Fabien", "authors": "M. S. Fabien, M. G. Knepley, R. T. Mills, and B. M. Riviere", "title": "Manycore parallel computing for a hybridizable discontinuous Galerkin\n  nested multigrid method", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel computing strategy for a hybridizable discontinuous\nGalerkin (HDG) nested geometric multigrid (GMG) solver. Parallel GMG solvers\nrequire a combination of coarse-grain and fine-grain parallelism to improve\ntime to solution performance. In this work we focus on fine-grain parallelism.\nWe use Intel's second generation Xeon Phi (Knights Landing) many-core\nprocessor. The GMG method achieves ideal convergence rates of $0.2$ or less,\nfor high polynomial orders. A matrix free (assembly free) technique is\nexploited to save considerable memory usage and increase arithmetic intensity.\nHDG enables static condensation, and due to the discontinuous nature of the\ndiscretization, we developed a matrix vector multiply routine that does not\nrequire any costly synchronizations or barriers. Our algorithm is able to\nattain 80\\% of peak bandwidth performance for higher order polynomials. This is\npossible due to the data locality inherent in the HDG method. Very high\nperformance is realized for high order schemes, due to good arithmetic\nintensity, which declines as the order is reduced.\n", "versions": [{"version": "v1", "created": "Sun, 28 May 2017 07:51:06 GMT"}, {"version": "v2", "created": "Sun, 4 Jun 2017 08:42:50 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 16:22:17 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Fabien", "M. S.", ""], ["Knepley", "M. G.", ""], ["Mills", "R. T.", ""], ["Riviere", "B. M.", ""]]}, {"id": "1705.09992", "submitter": "James Herring", "authors": "James Herring, James Nagy, Lars Ruthotto", "title": "LAP: a Linearize and Project Method for Solving Inverse Problems with\n  Coupled Variables", "comments": "21 pages, 6 figures, 3 tables", "journal-ref": "STSIP 17.2 (2018) pp.127-151", "doi": null, "report-no": null, "categories": "math.NA cs.CV cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many inverse problems involve two or more sets of variables that represent\ndifferent physical quantities but are tightly coupled with each other. For\nexample, image super-resolution requires joint estimation of the image and\nmotion parameters from noisy measurements. Exploiting this structure is key for\nefficiently solving these large-scale optimization problems, which are often\nill-conditioned.\n  In this paper, we present a new method called Linearize And Project (LAP)\nthat offers a flexible framework for solving inverse problems with coupled\nvariables. LAP is most promising for cases when the subproblem corresponding to\none of the variables is considerably easier to solve than the other. LAP is\nbased on a Gauss-Newton method, and thus after linearizing the residual, it\neliminates one block of variables through projection. Due to the linearization,\nthis block can be chosen freely. Further, LAP supports direct, iterative, and\nhybrid regularization as well as constraints. Therefore LAP is attractive,\ne.g., for ill-posed imaging problems. These traits differentiate LAP from\ncommon alternatives for this type of problem such as variable projection\n(VarPro) and block coordinate descent (BCD). Our numerical experiments compare\nthe performance of LAP to BCD and VarPro using three coupled problems whose\nforward operators are linear with respect to one block and nonlinear for the\nother set of variables.\n", "versions": [{"version": "v1", "created": "Sun, 28 May 2017 21:11:53 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 20:02:54 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 14:35:48 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Herring", "James", ""], ["Nagy", "James", ""], ["Ruthotto", "Lars", ""]]}, {"id": "1705.10404", "submitter": "Cun Mu", "authors": "Cun Mu, Daniel Hsu, Donald Goldfarb", "title": "Successive Rank-One Approximations for Nearly Orthogonally Decomposable\n  Symmetric Tensors", "comments": null, "journal-ref": "SIAM Journal on Matrix Analysis and Applications 36.4 (2015):\n  1638-1659", "doi": "10.1137/15M1010890", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many idealized problems in signal processing, machine learning and statistics\ncan be reduced to the problem of finding the symmetric canonical decomposition\nof an underlying symmetric and orthogonally decomposable (SOD) tensor. Drawing\ninspiration from the matrix case, the successive rank-one approximations (SROA)\nscheme has been proposed and shown to yield this tensor decomposition exactly,\nand a plethora of numerical methods have thus been developed for the tensor\nrank-one approximation problem. In practice, however, the inevitable errors\n(say) from estimation, computation, and modeling necessitate that the input\ntensor can only be assumed to be a nearly SOD tensor---i.e., a symmetric tensor\nslightly perturbed from the underlying SOD tensor. This article shows that even\nin the presence of perturbation, SROA can still robustly recover the symmetric\ncanonical decomposition of the underlying tensor. It is shown that when the\nperturbation error is small enough, the approximation errors do not accumulate\nwith the iteration number. Numerical results are presented to support the\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 21:37:32 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Mu", "Cun", ""], ["Hsu", "Daniel", ""], ["Goldfarb", "Donald", ""]]}, {"id": "1705.10608", "submitter": "Birte Schmidtmann", "authors": "Birte Schmidtmann, Pawel Buchm\\\"uller, Manuel Torrilhon", "title": "Third-order Limiting for Hyperbolic Conservation Laws applied to\n  Adaptive Mesh Refinement and Non-Uniform 2D Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend the recently developed third-order limiter function\n$H_{3\\text{L}}^{(c)}$ [J. Sci. Comput., (2016), 68(2), pp.~624--652] to make it\napplicable for more elaborate test cases in the context of finite volume\nschemes. This work covers the generalization to non-uniform grids in one and\ntwo space dimensions, as well as two-dimensional Cartesian grids with adaptive\nmesh refinement (AMR). The extension to 2D is obtained by the common approach\nof dimensional splitting. In order to apply this technique without loss of\nthird-order accuracy, the order-fix developed by Buchm\\\"uller and Helzel [J.\nSci. Comput., (2014), 61(2), pp.~343--368] is incorporated into the scheme.\nSeveral numerical examples on different grid configurations show that the\nlimiter function $H_{3\\text{L}}^{(c)}$ maintains the optimal third-order\naccuracy on smooth profiles and avoids oscillations in case of discontinuous\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 21:53:47 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Schmidtmann", "Birte", ""], ["Buchm\u00fcller", "Pawel", ""], ["Torrilhon", "Manuel", ""]]}, {"id": "1705.10881", "submitter": "Harm Derksen", "authors": "Harm Derksen", "title": "A general theory of singular values with applications to signal\n  denoising", "comments": "59 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.IT cs.NA math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Pareto frontier for two competing norms $\\|\\cdot\\|_X$ and\n$\\|\\cdot\\|_Y$ on a vector space. For a given vector $c$, the pareto frontier\ndescribes the possible values of $(\\|a\\|_X,\\|b\\|_Y)$ for a decomposition\n$c=a+b$. The singular value decomposition of a matrix is closely related to the\nPareto frontier for the spectral and nuclear norm. We will develop a general\ntheory that extends the notion of singular values of a matrix to arbitrary\nfinite dimensional euclidean vector spaces equipped with dual norms. This also\ngeneralizes the diagonal singular value decompositions for tensors introduced\nby the author in previous work. We can apply the results to denoising, where\n$c$ is a noisy signal, $a$ is a sparse signal and $b$ is noise. Applications\ninclude 1D total variation denoising, 2D total variation Rudin-Osher-Fatemi\nimage denoising, LASSO, basis pursuit denoising and tensor decompositions.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 22:25:03 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Derksen", "Harm", ""]]}, {"id": "1705.10887", "submitter": "Javier Turek", "authors": "Javier S. Turek, Alexander Huth", "title": "Efficient, sparse representation of manifold distance matrices for\n  classical scaling", "comments": "Conference CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geodesic distance matrices can reveal shape properties that are largely\ninvariant to non-rigid deformations, and thus are often used to analyze and\nrepresent 3-D shapes. However, these matrices grow quadratically with the\nnumber of points. Thus for large point sets it is common to use a low-rank\napproximation to the distance matrix, which fits in memory and can be\nefficiently analyzed using methods such as multidimensional scaling (MDS). In\nthis paper we present a novel sparse method for efficiently representing\ngeodesic distance matrices using biharmonic interpolation. This method exploits\nknowledge of the data manifold to learn a sparse interpolation operator that\napproximates distances using a subset of points. We show that our method is 2x\nfaster and uses 20x less memory than current leading methods for solving MDS on\nlarge point sets, with similar quality. This enables analyses of large point\nsets that were previously infeasible.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 23:18:18 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 17:35:03 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Turek", "Javier S.", ""], ["Huth", "Alexander", ""]]}]