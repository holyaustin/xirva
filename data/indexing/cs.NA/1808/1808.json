[{"id": "1808.00186", "submitter": "Octavio Castillo Reyes", "authors": "Octavio Castillo-Reyes, Josep de la Puente, Jos\\'e Mar\\'ia Cela", "title": "PETGEM: A parallel code for 3D CSEM forward modeling using edge finite\n  elements", "comments": "\\c{opyright} 2018. This manuscript version is made available under\n  the CC-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/\n  This project has received funding from the EC-H2020 under the Marie\n  Sklodowska-Curie grant agreement No. 644202, and from the EC-H2020 under the\n  HPC4E Project, grant agreement No. 689772", "journal-ref": "Computers and Geosciences 2018", "doi": "10.1016/j.cageo.2018.07.005", "report-no": null, "categories": "physics.comp-ph cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present the capabilities and results of the Parallel Edge-based Tool for\nGeophysical Electromagnetic modeling (PETGEM), as well as the physical and\nnumerical foundations upon which it has been developed. PETGEM is an\nopen-source and distributed parallel Python code for fast and highly accurate\nmodeling of 3D marine controlled-source electromagnetic (3D CSEM) problems. We\nemploy the N\\'ed\\'elec Edge Finite Element Method (EFEM) which offers a good\ntrade-off between accuracy and number of degrees of freedom, while naturally\nsupporting unstructured tetrahedral meshes. We have particularised this new\nmodeling tool to the 3D CSEM problem for infinitesimal point dipoles asumming\narbitrarily isotropic media for low-frequencies approximations. In order to\navoid source-singularities, PETGEM solves the frequency-domain Maxwell's\nequations of the secondary electric field, and the primary electric field is\ncalculated analytically for homogeneous background media. We assess the PETGEM\naccuracy using classical tests with known analytical solutions as well as\nrecent published data of real life geological scenarios. This assessment proves\nthat this new modeling tool reproduces expected accurate solutions in the\nformer tests, and its flexibility on realistic 3D electromagnetic problems.\nFurthermore, an automatic mesh adaptation strategy for a given frequency and\nspecific source position is presented. We also include a scalability study\nbased on fundamental metrics for high-performance computing (HPC)\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 06:34:05 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Castillo-Reyes", "Octavio", ""], ["de la Puente", "Josep", ""], ["Cela", "Jos\u00e9 Mar\u00eda", ""]]}, {"id": "1808.00355", "submitter": "Vien Minh Nguyen-Thanh", "authors": "Vien Minh Nguyen-Thanh, Xiaoying Zhuang, Hung Nguyen-Xuan, Timon\n  Rabczuk, Peter Wriggers", "title": "A Virtual Element Method for 2D linear elastic fracture analysis", "comments": null, "journal-ref": "Computer Methods in Applied Mechanics and Engineering, Elsevier 1\n  October 2018", "doi": "10.1016/j.cma.2018.05.021", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Virtual Element Method (VEM) for the modeling of\ncrack propagation in 2D within the context of linear elastic fracture mechanics\n(LEFM). By exploiting the advantage of mesh flexibility in the VEM, we\nestablish an adaptive mesh refinement strategy based on the superconvergent\npatch recovery for triangular, quadrilateral as well as for arbitrary polygonal\nmeshes. For the local stiffness matrix in VEM, we adopt a stabilization term\nwhich is stable for both isotropic scaling and ratio. Stress intensity factors\n(SIFs) of a polygonal mesh are discussed and solved by using the interaction\ndomain integral. The present VEM formulations are finally tested and validated\nby studying its convergence rate for both continuous and discontinuous\nproblems, and are compared with the optimal convergence rate in the\nconventional Finite Element Method (FEM). Furthermore, the adaptive mesh\nrefinement strategies used to effectively predict the crack growth with the\nexistence of hanging nodes in nonconforming elements are examined.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 15:07:08 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Nguyen-Thanh", "Vien Minh", ""], ["Zhuang", "Xiaoying", ""], ["Nguyen-Xuan", "Hung", ""], ["Rabczuk", "Timon", ""], ["Wriggers", "Peter", ""]]}, {"id": "1808.00505", "submitter": "Martin Storath", "authors": "Martin Storath, Andreas Weinmann", "title": "Wavelet Sparse Regularization for Manifold-Valued Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV cs.NA math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the sparse regularization of manifold-valued data\nwith respect to an interpolatory wavelet/multiscale transform. We propose and\nstudy variational models for this task and provide results on their\nwell-posedness. We present algorithms for a numerical realization of these\nmodels in the manifold setup. Further, we provide experimental results to show\nthe potential of the proposed schemes for applications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 18:47:36 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Storath", "Martin", ""], ["Weinmann", "Andreas", ""]]}, {"id": "1808.01084", "submitter": "Justin Krometis", "authors": "Jeff Borggaard, Nathan E. Glatt-Holtz, Justin A. Krometis", "title": "A Bayesian Approach to Estimating Background Flows from a Passive Scalar", "comments": "Streamlined, moved IS & MALA to appendix, and added appendix on\n  fluids observables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the statistical inverse problem of estimating a background flow\nfield (e.g., of air or water) from the partial and noisy observation of a\npassive scalar (e.g., the concentration of a solute), a common experimental\napproach to visualizing complex fluid flows. Here the unknown is a vector field\nthat is specified by a large or infinite number of degrees of freedom. Since\nthe inverse problem is ill-posed, i.e., there may be many or no background\nflows that match a given set of observations, we adopt a Bayesian approach to\nregularize it. In doing so, we leverage frameworks developed in recent years\nfor infinite-dimensional Bayesian inference. The contributions in this work are\nthreefold. First, we lay out a functional analytic and Bayesian framework for\napproaching this problem. Second, we define an adjoint method for efficient\ncomputation of the gradient of the log likelihood, a key ingredient in many\nnumerical methods. Finally, we identify interesting example problems that\nexhibit posterior measures with simple and complex structure. We use these\nexamples to conduct a large-scale benchmark of Markov Chain Monte Carlo methods\ndeveloped in recent years for infinite-dimensional settings. Our results\nindicate that these methods are capable of resolving complex multimodal\nposteriors in high dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 04:41:36 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 15:30:14 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 19:08:49 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Borggaard", "Jeff", ""], ["Glatt-Holtz", "Nathan E.", ""], ["Krometis", "Justin A.", ""]]}, {"id": "1808.01105", "submitter": "Franco Dassi", "authors": "Lourenco Beir\\~ao da Veiga and Franco Dassi and Alessandro Russo", "title": "$C^1$ Virtual Element Method on polyhedral meshes", "comments": "Computer & Mathematics with Applications (Jul 2019)", "journal-ref": null, "doi": "10.1016/j.camwa.2019.06.019", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the present paper is to develop $C^1$ Virtual Elements in\nthree dimensions for linear elliptic fourth order problems, motivated by the\ndifficulties that standard conforming Finite Elements encounter in this\nframework. We focus the presentation on the lowest order case, the\ngeneralization to higher orders being briefly provided in the Appendix. The\ndegrees of freedom of the proposed scheme are only 4 per mesh vertex,\nrepresenting function values and gradient values. Interpolation error estimates\nfor the proposed space are provided, together with a set of numerical tests to\nvalidate the method at the practical level.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 07:42:38 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 14:44:59 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 08:15:56 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["da Veiga", "Lourenco Beir\u00e3o", ""], ["Dassi", "Franco", ""], ["Russo", "Alessandro", ""]]}, {"id": "1808.01471", "submitter": "Haijun Yu", "authors": "Tao Tang, Haijun Yu and Tao Zhou", "title": "On energy dissipation theory and numerical stability for time-fractional\n  phase field equations", "comments": "21 pages, 6 figures, to appear on SIAM Sci. Comput", "journal-ref": "SIAM Journal on Scientific Computing, 41(6), A3757-A3778, 2019", "doi": "10.1137/18M1203560", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the time-fractional phase field models, the corresponding energy\ndissipation law has not been settled on both the continuous level and the\ndiscrete level. In this work, we shall address this open issue. More precisely,\nwe prove for the first time that the time-fractional phase field models indeed\nadmit an energy dissipation law of an integral type. In the discrete level, we\npropose a class of finite difference schemes that can inherit the theoretical\nenergy stability. Our discussion covers the time-fractional gradient systems,\nincluding the time-fractional Allen-Cahn equation, the time-fractional\nCahn-Hilliard equation, and the time-fractional molecular beam epitaxy models.\nNumerical examples are presented to confirm the theoretical results. Moreover,\na numerical study of the coarsening rate of random initial states depending on\nthe fractional parameter $\\alpha$ reveals that there are several coarsening\nstages for both time-fractional Cahn-Hilliard equation and time-fractional\nmolecular beam epitaxy model, while there exists a $-\\alpha/3$ power law\ncoarsening stage.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 12:09:16 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 01:40:37 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Tang", "Tao", ""], ["Yu", "Haijun", ""], ["Zhou", "Tao", ""]]}, {"id": "1808.01783", "submitter": "Leon Bungert", "authors": "Leon Bungert, Martin Burger", "title": "Solution Paths of Variational Regularization Methods for Inverse\n  Problems", "comments": "36 pages, 6 figures, published version", "journal-ref": "Inverse Problems 35 (10), 105012, 2019", "doi": "10.1088/1361-6420/ab1d71", "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a family of variational regularization functionals for a generic\ninverse problem, where the data fidelity and regularization term are given by\npowers of a Hilbert norm and an absolutely one-homogeneous functional,\nrespectively, and the regularization parameter is interpreted as artificial\ntime. We investigate the small and large time behavior of the associated\nsolution paths and, in particular, prove finite extinction time for a large\nclass of functionals. Depending on the powers, we also show that the solution\npaths are of bounded variation or even Lipschitz continuous. In addition, it\nwill turn out that the models are \"almost\" mutually equivalent in terms of the\nminimizers they admit. Finally, we apply our results to define and compare two\ndifferent non-linear spectral representations of data and show that only one of\nit is able to decompose a linear combination of non-linear eigenfunctions into\nthe individual eigenfunctions. For that purpose, we will also briefly address\npiecewise affine solution paths.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 08:59:45 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 08:32:21 GMT"}, {"version": "v3", "created": "Sun, 2 Sep 2018 15:44:21 GMT"}, {"version": "v4", "created": "Tue, 29 Jan 2019 15:30:05 GMT"}, {"version": "v5", "created": "Thu, 2 May 2019 11:43:07 GMT"}, {"version": "v6", "created": "Tue, 29 Oct 2019 10:17:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Bungert", "Leon", ""], ["Burger", "Martin", ""]]}, {"id": "1808.01887", "submitter": "Anton Arnold", "authors": "A. Arnold, C. Klein. B. Ujvari", "title": "WKB-method for the 1D Schr\\\"odinger equation in the semi-classical\n  limit: enhanced phase treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the efficient numerical computation of solutions\nto the 1D stationary Schr\\\"odinger equation in the semiclassical limit in the\nhighly oscillatory regime. A previous approach to this problem based on\nexplicitly incorporating the leading terms of the WKB approximation is enhanced\nin two ways: first a refined error analysis for the method is presented for a\nnot explicitly known WKB phase, and secondly the phase and its derivatives will\nbe computed with spectral methods. The efficiency of the approach is\nillustrated for several examples.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 13:33:00 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 19:41:52 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Arnold", "A.", ""], ["Ujvari", "C. Klein. B.", ""]]}, {"id": "1808.02086", "submitter": "Boris Kramer", "authors": "Boris Kramer and Karen Willcox", "title": "Nonlinear Model Order Reduction via Lifting Transformations and Proper\n  Orthogonal Decomposition", "comments": null, "journal-ref": "AIAA Journal, Vol. 57, No. 6, June 2019", "doi": "10.2514/1.J057791", "report-no": null, "categories": "cs.NA cs.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a structure-exploiting nonlinear model reduction method\nfor systems with general nonlinearities. First, the nonlinear model is lifted\nto a model with more structure via variable transformations and the\nintroduction of auxiliary variables. The lifted model is equivalent to the\noriginal model---it uses a change of variables, but introduces no\napproximations. When discretized, the lifted model yields a polynomial system\nof either ordinary differential equations or differential algebraic equations,\ndepending on the problem and lifting transformation. Proper orthogonal\ndecomposition (POD) is applied to the lifted models, yielding a reduced-order\nmodel for which all reduced-order operators can be pre-computed. Thus, a key\nbenefit of the approach is that there is no need for additional approximations\nof nonlinear terms, in contrast with existing nonlinear model reduction methods\nrequiring sparse sampling or hyper-reduction. Application of the lifting and\nPOD model reduction to the FitzHugh-Nagumo benchmark problem and to a tubular\nreactor model with Arrhenius reaction terms shows that the approach is\ncompetitive in terms of reduced model accuracy with state-of-the-art model\nreduction via POD and discrete empirical interpolation, while having the added\nbenefits of opening new pathways for rigorous analysis and input-independent\nmodel reduction via the introduction of the lifted problem structure.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 19:48:32 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2019 18:08:30 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kramer", "Boris", ""], ["Willcox", "Karen", ""]]}, {"id": "1808.02097", "submitter": "Brian Freno", "authors": "Brian A. Freno and Kevin T. Carlberg", "title": "Machine-learning error models for approximate solutions to parameterized\n  systems of nonlinear equations", "comments": null, "journal-ref": "Computer Methods in Applied Mechanics and Engineering 348 (2019)\n  250--296", "doi": "10.1016/j.cma.2019.01.024", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a machine-learning framework for constructing statistical\nmodels of errors incurred by approximate solutions to parameterized systems of\nnonlinear equations. These approximate solutions may arise from early\ntermination of an iterative method, a lower-fidelity model, or a\nprojection-based reduced-order model, for example. The proposed statistical\nmodel comprises the sum of a deterministic regression-function model and a\nstochastic noise model. The method constructs the regression-function model by\napplying regression techniques from machine learning (e.g., support vector\nregression, artificial neural networks) to map features (i.e., error indicators\nsuch as sampled elements of the residual) to a prediction of the\napproximate-solution error. The method constructs the noise model as a\nmean-zero Gaussian random variable whose variance is computed as the sample\nvariance of the approximate-solution error on a test set; this variance can be\ninterpreted as the epistemic uncertainty introduced by the approximate\nsolution. This work considers a wide range of feature-engineering methods,\ndata-set-construction techniques, and regression techniques that aim to ensure\nthat (1) the features are cheaply computable, (2) the noise model exhibits low\nvariance (i.e., low epistemic uncertainty introduced), and (3) the regression\nmodel generalizes to independent test data. Numerical experiments performed on\nseveral computational-mechanics problems and types of approximate solutions\ndemonstrate the ability of the method to generate statistical models of the\nerror that satisfy these criteria and significantly outperform more commonly\nadopted approaches for error modeling.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 20:17:20 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 00:39:43 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2019 19:05:51 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Freno", "Brian A.", ""], ["Carlberg", "Kevin T.", ""]]}, {"id": "1808.02316", "submitter": "Pavel Kharyuk", "authors": "Pavel Kharyuk, Ivan Oseledets", "title": "Modelling hidden structure of signals in group data analysis with\n  modified (Lr, 1) and block-term decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is devoted to elaboration on the idea to use block term\ndecomposition for group data analysis and to raise the possibility of modelling\ngroup activity with (Lr, 1) and Tucker blocks. A new generalization of block\ntensor decomposition was considered in application to group data analysis.\nSuggested approach was evaluated on multilabel classification task for a set of\nimages. This contribution also reports results of investigation on clustering\nwith proposed tensor models in comparison with known matrix models, namely\ncommon orthogonal basis extraction and group independent component analysis.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 12:04:40 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Kharyuk", "Pavel", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1808.02341", "submitter": "Denis Belomestny", "authors": "Denis Belomestny, John Schoenmakers, Vladimir Spokoiny and Bakhyt\n  Zharkynbay", "title": "Optimal stopping via reinforced regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we propose a new approach towards solving numerically optimal\nstopping problems via reinforced regression based Monte Carlo algorithms. The\nmain idea of the method is to reinforce standard linear regression algorithms\nin each backward induction step by adding new basis functions based on\npreviously estimated continuation values. The proposed methodology is\nillustrated by a numerical example from mathematical finance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 13:12:05 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 15:13:06 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 10:01:19 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Belomestny", "Denis", ""], ["Schoenmakers", "John", ""], ["Spokoiny", "Vladimir", ""], ["Zharkynbay", "Bakhyt", ""]]}, {"id": "1808.02446", "submitter": "Doosung Choi", "authors": "Doosung Choi, Junbeom Kim, Mikyoung Lim", "title": "Geometric multipole expansion and its application to semi-neutral\n  inclusions of general shape", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new concept of geometric multipole expansion for the\nconductivity or anti-plane elasticity problem in two dimensions by using the\nFaber polynomials. As an application, we construct semi-neutral inclusions of\ngeneral shape that show relatively negligible field perturbations for low-order\npolynomial loadings. These inclusions are of the multilayer structure whose\nmaterial parameters are determined such that some coefficients of geometric\nmultipole expansion vanish.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 09:33:59 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 11:13:23 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 04:34:27 GMT"}, {"version": "v4", "created": "Thu, 3 Jan 2019 06:07:14 GMT"}, {"version": "v5", "created": "Fri, 12 Apr 2019 08:17:40 GMT"}, {"version": "v6", "created": "Thu, 19 Nov 2020 09:44:03 GMT"}, {"version": "v7", "created": "Tue, 22 Jun 2021 07:07:49 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Choi", "Doosung", ""], ["Kim", "Junbeom", ""], ["Lim", "Mikyoung", ""]]}, {"id": "1808.02615", "submitter": "Yanzhi Zhang", "authors": "Siwei Duo and Yanzhi Zhang", "title": "Numerical approximations for the tempered fractional Laplacian: Error\n  analysis and applications", "comments": "21 pages, 11 figures, 3 tables", "journal-ref": "Journal of Scientific Computing, 81 (2019), pp. 569-593", "doi": "10.1007/s10915-019-01029-7", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an accurate finite difference method to discretize\nthe $d$-dimensional (for $d\\ge 1$) tempered integral fractional Laplacian and\napply it to study the tempered effects on the solution of problems arising in\nvarious applications. Compared to other existing methods, our method has higher\naccuracy and simpler implementation. Our numerical method has an accuracy of\n$O(h^\\epsilon)$, for $u \\in C^{0, \\alpha+\\epsilon} (\\bar{\\Omega})$ if $\\alpha <\n1$ (or $u \\in C^{1, \\alpha-1+\\epsilon} (\\bar{\\Omega})$ if $\\alpha \\ge 1$) with\n$\\epsilon > 0$, suggesting the minimum consistency conditions. The accuracy can\nbe improved to $O(h^2)$, for $u \\in C^{2, \\alpha+\\epsilon} (\\bar{\\Omega})$ if\n$\\alpha < 1$ (or $u \\in C^{3, \\alpha - 1 + \\epsilon} (\\bar{\\Omega})$ if $\\alpha\n\\ge 1$). Numerical experiments confirm our analytical results and provide\ninsights in solving the tempered fractional Poisson problem. It suggests that\nto achieve the second order of accuracy, our method only requires the solution\n$u \\in C^{1,1}(\\bar{\\Omega})$ for any $0<\\alpha<2$. Moreover, if the solution\nof tempered fractional Poisson problems satisfies $u \\in C^{p,\ns}(\\bar{\\Omega})$ for $p = 0, 1$ and $0<s \\le 1$, our method has the accuracy\nof $O(h^{p+s})$. Since our method yields a (multilevel) Toeplitz stiffness\nmatrix, one can design fast algorithms via the fast Fourier transform for\nefficient simulations. Finally, we apply it together with fast algorithms to\nstudy the tempered effects on the solutions of various tempered fractional\nPDEs, including the Allen-Cahn equation and Gray-Scott equations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 03:40:33 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 02:03:59 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Duo", "Siwei", ""], ["Zhang", "Yanzhi", ""]]}, {"id": "1808.02638", "submitter": "Xinsheng Qin", "authors": "Xinsheng Qin, Randall J. LeVeque, Michael R. Motley", "title": "Accelerating wave-propagation algorithms with adaptive mesh refinement\n  using the Graphics Processing Unit (GPU)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clawpack is a library for solving nonlinear hyperbolic partial differential\nequations using high-resolution finite volume methods based on Riemann solvers\nand limiters. It supports Adaptive Mesh Refinement (AMR), which is essential in\nsolving multi-scale problems. Recently, we added capabilities to accelerate the\ncode by using the Graphics Process Unit (GPU). Routines that manage CPU and GPU\nAMR data and facilitate the execution of GPU kernels are added. Customized and\nCPU thread-safe memory managers are designed to manage GPU and CPU memory\npools, which is essential in eliminating the overhead of memory allocation and\nde-allocation. A global reduction is conducted every time step for dynamically\nadjusting the time step based on Courant number restrictions. Some small GPU\nkernels are merged into bigger kernels, which greatly reduces kernel launching\noverhead. A speed-up between $2$ and $3$ for the total running time is observed\nin an acoustics benchmark problem.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 06:21:56 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Qin", "Xinsheng", ""], ["LeVeque", "Randall J.", ""], ["Motley", "Michael R.", ""]]}, {"id": "1808.02655", "submitter": "Fleurianne Bertrand", "authors": "Fleurianne Bertrand, Bernhard Kober, Marcel Moldenhauer and Gerhard\n  Starke", "title": "Weakly symmetric stress equilibration and a posteriori error estimation\n  for linear elasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stress equilibration procedure for linear elasticity is proposed and\nanalyzed in this paper with emphasis on the behavior for (nearly)\nincompressible materials. Based on the displacement-pressure approximation\ncomputed with a stable finite element pair, it constructs an $H\n(\\text{div})$-conforming, weakly symmetric stress reconstruction. Our focus is\non the Taylor-Hood combination of continuous finite element spaces of\npolynomial degrees $k+1$ and $k$ for the displacement and the pressure,\nrespectively. Our construction leads then to reconstructed stresses by\nRaviart-Thomas elements of degree $k$ which are weakly symmetric in the sense\nthat its anti-symmetric part is zero tested against continuous piecewise\npolynomial functions of degree $k$. The computation is performed locally on a\nset of vertex patches covering the computational domain in the spirit of\nequilibration \\cite{BraSch:08}. Due to the weak symmetry constraint, the local\nproblems need to satisfy consistency conditions associated with all rigid body\nmodes, in contrast to the case of Poisson's equation where only the constant\nmodes are involved. The resulting error estimator is shown to constitute a\nguaranteed upper bound for the error with a constant that depends only on the\nshape regularity of the triangulation. Local efficiency, uniformly in the\nincompressible limit, is deduced from the upper bound by the residual error\nestimator.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 08:12:46 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 13:32:20 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Bertrand", "Fleurianne", ""], ["Kober", "Bernhard", ""], ["Moldenhauer", "Marcel", ""], ["Starke", "Gerhard", ""]]}, {"id": "1808.02759", "submitter": "Adrian Sandu", "authors": "Adrian Sandu", "title": "A Class of Multirate Infinitesimal GARK Methods", "comments": null, "journal-ref": null, "doi": "10.1137/18M1205492", "report-no": "CSL-TR-2018-5", "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential equations arising in many practical applications are\ncharacterized by multiple time scales. Multirate time integration seeks to\nsolve them efficiently by discretizing each scale with a different, appropriate\ntime step, while ensuring the overall accuracy and stability of the numerical\nsolution. In a seminal paper Knoth and Wolke (APNUM, 1998) proposed a hybrid\nsolution approach: discretize the slow component with an explicit Runge-Kutta\nmethod, and advance the fast component via a modified fast differential\nequation. The idea led to the development of multirate infinitesimal step (MIS)\nmethods by Wensch et al. (BIT, 2009.)G\\\"{u}nther and Sandu (BIT, 2016)\nexplained MIS schemes as a particular case of multirate General-structure\nAdditive Runge-Kutta (MR-GARK) methods. The hybrid approach offers extreme\nflexibility in the choice of the numerical solution process for the fast\ncomponent.\n  This work constructs a family of multirate infinitesimal GARK schemes\n(MRI-GARK) that extends the hybrid dynamics approachin multiple ways. Order\nconditions theory and stability analyses are developed, and practical explicit\nand implicit methods of up to order four are constructed. Numerical results\nconfirm the theoretical findings. We expect the new MRI-GARK family to be most\nuseful for systems of equations with widely disparate time scales, where the\nfast process is dispersive, and where the influence of the fast component on\nthe slow dynamics is weak.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 14:43:45 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 20:09:14 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Sandu", "Adrian", ""]]}, {"id": "1808.02827", "submitter": "Milo Viviani", "authors": "Klas Modin and Milo Viviani", "title": "Lie-Poisson methods for isospectral flows", "comments": "29 pages, 9 figures", "journal-ref": "Foundations of Computational Mathematics, (2019), 1-33", "doi": "10.1007/s10208-019-09428-w", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of isospectral flows comprises a large class of continuous\ndynamical systems, particularly integrable systems and Lie--Poisson systems.\nTheir discretization is a classical problem in numerical analysis. Preserving\nthe spectra in the discrete flow requires the conservation of high order\npolynomials, which is hard to come by. Existing methods achieving this are\ncomplicated and usually fail to preserve the underlying Lie--Poisson structure.\nHere we present a class of numerical methods of arbitrary order for Hamiltonian\nand non-Hamiltonian isospectral flows, which preserve both the spectra and the\nLie--Poisson structure. The methods are surprisingly simple, and avoid the use\nof constraints or exponential maps. Furthermore, due to preservation of the\nLie--Poisson structure, they exhibit near conservation of the Hamiltonian\nfunction. As an illustration, we apply the methods to several classical\nisospectral flows.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 15:36:00 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 10:43:15 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 11:11:10 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Modin", "Klas", ""], ["Viviani", "Milo", ""]]}, {"id": "1808.02912", "submitter": "Daniel Boley", "authors": "Daniel Boley, Alejandro Buendia, Golshan Golnari", "title": "Random Walk Laplacian and Network Centrality Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walks over directed graphs are used to model activities in many\ndomains, such as social networks, influence propagation, and Bayesian graphical\nmodels. They are often used to compute the importance or centrality of\nindividual nodes according to a variety of different criteria. Here we show how\nthe pseudoinverse of the \"random walk\" Laplacian can be used to quickly compute\nmeasures such as the average number of visits to a given node and various\ncentrality and betweenness measures for individual nodes, both for the network\nin general and in the case a subset of nodes is to be avoided. We show that\nwith a single matrix inversion it is possible to rapidly compute many such\nquantities.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 18:52:02 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Boley", "Daniel", ""], ["Buendia", "Alejandro", ""], ["Golnari", "Golshan", ""]]}, {"id": "1808.03112", "submitter": "Davide Pradovera", "authors": "Francesca Bonizzoni, Fabio Nobile, Ilaria Perugia, Davide Pradovera", "title": "Fast Least-Squares Pad\\'e approximation of problems with normal\n  operators and meromorphic structure", "comments": null, "journal-ref": "Math. Comput. 89 (2020) 1229-1257", "doi": "10.1090/mcom/3511", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the approximation of Hilbert space-valued\nmeromorphic functions that arise as solution maps of parametric PDEs whose\noperator is the shift of an operator with normal and compact resolvent, e.g.\nthe Helmholtz equation. In this restrictive setting, we propose a simplified\nversion of the Least-Squares Pad\\'e approximation technique introduced in [6]\nfollowing [11]. In particular, the estimation of the poles of the target\nfunction reduces to a low-dimensional eigenproblem for a Gramian matrix,\nallowing for a robust and efficient numerical implementation (hence the \"fast\"\nin the name). Moreover, we prove several theoretical results that improve and\nextend those in [6], including the exponential decay of the error in the\napproximation of the poles, and the convergence in measure of the approximant\nto the target function. The latter result extends the classical one for scalar\nPad\\'e approximation to our functional framework. We provide numerical results\nthat confirm the improved accuracy of the proposed method with respect to the\none introduced in [6] for differential operators with normal and compact\nresolvent.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 12:26:35 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 11:55:33 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Bonizzoni", "Francesca", ""], ["Nobile", "Fabio", ""], ["Perugia", "Ilaria", ""], ["Pradovera", "Davide", ""]]}, {"id": "1808.03408", "submitter": "Li Shen", "authors": "Fangyu Zou, Li Shen, Zequn Jie, Ju Sun and Wei Liu", "title": "Weighted AdaGrad with Unified Momentum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating adaptive learning rate and momentum techniques into SGD leads to\na large class of efficiently accelerated adaptive stochastic algorithms, such\nas Nadam, AccAdaGrad, \\textit{etc}. In spite of their effectiveness in\npractice, there is still a large gap in their theories of convergences,\nespecially in the difficult non-convex stochastic setting. To fill this gap, we\npropose \\emph{weighted AdaGrad with unified momentum}, dubbed AdaUSM, which has\nthe main characteristics that (1) it incorporates a unified momentum scheme\nwhich covers both the heavy ball momentum and the Nesterov accelerated gradient\nmomentum; (2) it adopts a novel weighted adaptive learning rate that can unify\nthe learning rates of AdaGrad, AccAdaGrad, Adam, and RMSProp. Moreover, when we\ntake polynomially growing weights in AdaUSM, we obtain its\n$\\mathcal{O}(\\log(T)/\\sqrt{T})$ convergence rate in the non-convex stochastic\nsetting. We also show that the adaptive learning rates of Adam and RMSProp\ncorrespond to taking exponentially growing weights in AdaUSM, which thereby\nprovides a new perspesctive for understanding Adam and RMSProp. Lastly,\ncomparative experiments of AdaUSM against SGD with momentum, AdaGrad, AdaEMA,\nAdam, and AMSGrad on various deep learning models and datasets are also\nprovided.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 04:18:48 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 08:53:20 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 10:50:45 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Zou", "Fangyu", ""], ["Shen", "Li", ""], ["Jie", "Zequn", ""], ["Sun", "Ju", ""], ["Liu", "Wei", ""]]}, {"id": "1808.03535", "submitter": "Sophie Puttkammer", "authors": "Carsten Carstensen and Sophie Puttkammer", "title": "How to prove the discrete reliability for nonconforming finite element\n  methods", "comments": "35 pages, LaTeX; typos corrected, more details (e.g. Section 1.3\n  Model problems, Section 5.8 Towards application in 3D (on Morley in 3D), and\n  in Proof of Lemma 5.1) added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal convergence rates of adaptive finite element methods are well\nunderstood in terms of the axioms of adaptivity. One key ingredient is the\ndiscrete reliability of a residual-based a posteriori error estimator, which\ncontrols the error of two discrete finite element solutions based on two nested\ntriangulations. In the error analysis of nonconforming finite element methods,\nlike the Crouzeix-Raviart or Morley finite element schemes, the difference of\nthe piecewise derivatives of discontinuous approximations to the distributional\ngradients of global Sobolev functions plays a dominant role and is the object\nof this paper. The nonconforming interpolation operator, which comes natural\nwith the definition of the aforementioned nonconforming finite element in the\nsense of Ciarlet, allows for stability and approximation properties that enable\ndirect proofs of the reliability for the residual that monitors the equilibrium\ncondition. The novel approach of this paper is the suggestion of a\nright-inverse of this interpolation operator in conforming piecewise\npolynomials to design a nonconforming approximation of a given coarse-grid\napproximation on a refined triangulation. The results of this paper allow for\nsimple proofs of the discrete reliability in any space dimension and multiply\nconnected domains on general shape-regular triangulations beyond newest-vertex\nbisection of simplices. Particular attention is on optimal constants in some\nstandard discrete estimates listed in the appendices.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 13:41:06 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 10:03:44 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Carstensen", "Carsten", ""], ["Puttkammer", "Sophie", ""]]}, {"id": "1808.03568", "submitter": "Dejan Brkic", "authors": "Pavel Praks and Dejan Brkic", "title": "Choosing the optimal multi-point iterative method for the Colebrook flow\n  friction equation -- Numerical validation", "comments": "16 pages, 69 references", "journal-ref": "Praks, P.; Brki\\'c, D. Choosing the Optimal Multi-Point Iterative\n  Method for the Colebrook Flow Friction Equation. Processes 2018, 6(8), 130", "doi": "10.3390/pr6080130", "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Colebrook equation $\\zeta$ is implicitly given in respect to the unknown\nflow friction factor $\\lambda$; $\\lambda=\\zeta(Re,\\epsilon^*,\\lambda)$ which\ncannot be expressed explicitly in exact way without simplifications and use of\napproximate calculus. Common approach to solve it is through the Newton-Raphson\niterative procedure or through the fixed-point iterative procedure. Both\nrequires in some case even eight iterations. On the other hand numerous more\npowerful iterative methods such as three-or two-point methods, etc. are\navailable. The purpose is to choose optimal iterative method in order to solve\nthe implicit Colebrook equation for flow friction accurately using the least\npossible number of iterations. The methods are thoroughly tested and those\nwhich require the least possible number of iterations to reach the accurate\nsolution are identified. The most powerful three-point methods require in worst\ncase only two iterations to reach final solution. The recommended\nrepresentatives are Sharma-Guha-Gupta, Sharma-Sharma, Sharma-Arora,\nD\\v{z}uni\\'c-Petkovi\\'c-Petkovi\\'c; Bi-Ren-Wu, Chun-Neta based on Kung-Traub,\nNeta, and Jain method based on Steffensen scheme. The recommended iterative\nmethods can reach the final accurate solution with the least possible number of\niterations. The approach is hybrid between iterative procedure and one-step\nexplicit approximations and can be used in engineering design for initial\nrough, but also for final fine calculations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 14:52:48 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Praks", "Pavel", ""], ["Brkic", "Dejan", ""]]}, {"id": "1808.03718", "submitter": "Daniel Reynolds", "authors": "Jean M. Sexton and Daniel R. Reynolds", "title": "Relaxed Multirate Infinitesimal Step Methods for Initial-Value Problems", "comments": "Submitted to J. Comput. Appl. Math", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on the construction of a new class of fourth-order accurate\nmethods for multirate time evolution of systems of ordinary differential\nequations. We base our work on the Recursive Flux Splitting Multirate (RFSMR)\nversion of the Multirate Infinitesimal Step (MIS) methods and use recent\ntheoretical developments for Generalized Additive Runge-Kutta methods to\npropose our higher-order Relaxed Multirate Infinitesimal Step extensions. The\nresulting framework supports a range of attractive properties for multirate\nmethods, including telescopic extensions, subcycling, embeddings for temporal\nerror estimation, and support for changes to the fast/slow time-scale\nseparation between steps, without requiring any sacrifices in linear stability.\nIn addition to providing rigorous theoretical developments for these new\nmethods, we provide numerical tests demonstrating convergence and efficiency on\na suite of multirate test problems.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 22:02:41 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 17:17:46 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 15:20:45 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Sexton", "Jean M.", ""], ["Reynolds", "Daniel R.", ""]]}, {"id": "1808.03809", "submitter": "Maria Filipkovska", "authors": "M. S. Filipkovska", "title": "Two combined methods for the global solution of implicit semilinear\n  differential equations with the use of spectral projectors and Taylor\n  expansions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two combined numerical methods for solving semilinear differential-algebraic\nequations (DAEs) are obtained and their convergence is proved. The comparative\nanalysis of these methods is carried out and conclusions about the\neffectiveness of their application in various situations are made. In\ncomparison with other known methods, the obtained methods require weaker\nrestrictions for the nonlinear part of the DAE. Also, the obtained methods\nenable to compute approximate solutions of the DAEs on any given time interval\nand, therefore, enable to carry out the numerical analysis of global dynamics\nof mathematical models described by the DAEs. The examples demonstrating the\ncapabilities of the developed methods are provided. To construct the methods we\nuse the spectral projectors, Taylor expansions and finite differences. Since\nthe used spectral projectors can be easily computed, to apply the methods it is\nnot necessary to carry out additional analytical transformations.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 14:19:09 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 22:11:06 GMT"}, {"version": "v3", "created": "Sat, 28 Sep 2019 10:56:35 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Filipkovska", "M. S.", ""]]}, {"id": "1808.03906", "submitter": "Raziyeh Dehbozorgi", "authors": "R. Dehbozorgi, K. Maleknejad", "title": "Direct numerical scheme for all classes of nonlinear Volterra integral\n  equations of the first kind", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a direct numerical scheme to approximate the solution of\nall classes of nonlinear Volterra integral equations of the first kind. This\ncomputational method is based on operational matrices and vectors. The\noperational vector for hybrid block pulse functions and Chebyshev polynomials\nis constructed. The scheme transforms the integral equation to a matrix\nequation and solves it with a careful estimate of the error involved. The main\ncharacteristic of the scheme is the low cost of setting up the equations\nwithout using any projection method which is the consequence of using\noperational vectors. Simple structure to implement, low computational cost and\nperfect approximate solutions are the major points of the presented method.\n  Error analysis and comparisons with other existing schemes demonstrate the\nefficiency and the superiority of our scheme.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 08:19:41 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 15:04:57 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Dehbozorgi", "R.", ""], ["Maleknejad", "K.", ""]]}, {"id": "1808.03994", "submitter": "Bachir El Khadir", "authors": "Amir Ali Ahmadi and Bachir El Khadir", "title": "Time-Varying Semidefinite Programs", "comments": "Minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study time-varying semidefinite programs (TV-SDPs), which are semidefinite\nprograms whose data (and solutions) are functions of time. Our focus is on the\nsetting where the data varies polynomially with time. We show that under a\nstrict feasibility assumption, restricting the solutions to also be polynomial\nfunctions of time does not change the optimal value of the TV-SDP. Moreover, by\nusing a Positivstellensatz on univariate polynomial matrices, we show that the\nbest polynomial solution of a given degree to a TV-SDP can be found by solving\na semidefinite program of tractable size. We also provide a sequence of dual\nproblems which can be cast as SDPs and that give upper bounds on the optimal\nvalue of a TV-SDP (in maximization form). We prove that under a boundedness\nassumption, this sequence of upper bounds converges to the optimal value of the\nTV-SDP. Under the same assumption, we also show that the optimal value of the\nTV-SDP is attained. We demonstrate the efficacy of our algorithms on a\nmaximum-flow problem with time-varying edge capacities, a wireless coverage\nproblem with time-varying coverage requirements, and on bi-objective\nsemidefinite optimization where the goal is to approximate the Pareto curve in\none shot.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 19:54:59 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 04:29:58 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Khadir", "Bachir El", ""]]}, {"id": "1808.04156", "submitter": "Kurusch Ebrahimi-Fard", "authors": "Charles Curry, Kurusch Ebrahimi-Fard, Brynjulf Owren", "title": "The Magnus expansion and Post-Lie algebras", "comments": "final version", "journal-ref": "Math. Comp. 89 (2020), 2785-2799", "doi": "10.1090/mcom/3541", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We relate the classical and post-Lie Magnus expansions. Intertwining\nalgebraic and geometric arguments allows to placing the classical Magnus\nexpansion in the context of Lie group integrators.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 11:52:31 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 22:08:46 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Curry", "Charles", ""], ["Ebrahimi-Fard", "Kurusch", ""], ["Owren", "Brynjulf", ""]]}, {"id": "1808.04180", "submitter": "Francesco Tudisco", "authors": "Antoine Gautier and Francesco Tudisco", "title": "The contractivity of cone-preserving multilinear mappings", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6544/ab3352", "report-no": null, "categories": "math.SP cs.NA math-ph math.FA math.MP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the notion of mode-$j$ Birkhoff contraction ratio, we prove a\nmultilinear version of the Birkhoff-Hopf and the Perron-Fronenius theorems,\nwhich provide conditions on the existence and uniqueness of a solution to a\nlarge family of systems of nonlinear equations of the type\n$f_i(x_1,\\dots,x_\\nu)= \\lambda_i x_i$, being $x_i$ and element of a cone $C_i$\nin a Banach space $V_i$. We then consider a family of nonlinear integral\noperators $f_i$ with positive kernel, acting on product of spaces of continuous\nreal valued functions. In this setting we provide an explicit formula for the\nmode-$j$ contraction ratio which is particularly relevant in practice as this\ntype of operators play a central role in numerous models and applications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 12:50:38 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 21:34:25 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Gautier", "Antoine", ""], ["Tudisco", "Francesco", ""]]}, {"id": "1808.04487", "submitter": "Andreas Mang", "authors": "Andreas Mang and Amir Gholami and Christos Davatzikos and George Biros", "title": "CLAIRE: A distributed-memory solver for constrained large deformation\n  diffeomorphic image registration", "comments": "37 pages;", "journal-ref": "SIAM Journal on Scientific Computing, 41(5):C548-C584, 2019", "doi": "10.1137/18M1207818", "report-no": null, "categories": "math.OC cs.CV cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With this work, we release CLAIRE, a distributed-memory implementation of an\neffective solver for constrained large deformation diffeomorphic image\nregistration problems in three dimensions. We consider an optimal control\nformulation. We invert for a stationary velocity field that parameterizes the\ndeformation map. Our solver is based on a globalized, preconditioned, inexact\nreduced space Gauss--Newton--Krylov scheme. We exploit state-of-the-art\ntechniques in scientific computing to develop an effective solver that scales\nto thousands of distributed memory nodes on high-end clusters. We present the\nformulation, discuss algorithmic features, describe the software package, and\nintroduce an improved preconditioner for the reduced space Hessian to speed up\nthe convergence of our solver. We test registration performance on synthetic\nand real data. We demonstrate registration accuracy on several neuroimaging\ndatasets. We compare the performance of our scheme against different flavors of\nthe Demons algorithm for diffeomorphic image registration. We study convergence\nof our preconditioner and our overall algorithm. We report scalability results\non state-of-the-art supercomputing platforms. We demonstrate that we can solve\nregistration problems for clinically relevant data sizes in two to four minutes\non a standard compute node with 20 cores, attaining excellent data fidelity.\nWith the present work we achieve a speedup of (on average) 5$\\times$ with a\npeak performance of up to 17$\\times$ compared to our former work.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 22:59:25 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 21:50:57 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Mang", "Andreas", ""], ["Gholami", "Amir", ""], ["Davatzikos", "Christos", ""], ["Biros", "George", ""]]}, {"id": "1808.04661", "submitter": "Espen Sande", "authors": "Adrian Montgomery Ruf, Espen Sande and Susanne Solem", "title": "The optimal convergence rate of monotone schemes for conservation laws\n  in the Wasserstein distance", "comments": "10 pages, 5 figures, 2 tables. Fixed typos. Article published in\n  Journal of Scientific Computing", "journal-ref": null, "doi": "10.1007/s10915-019-00996-1", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1994, Nessyahu, Tadmor and Tassa studied convergence rates of monotone\nfinite volume approximations of conservation laws. For compactly supported,\n$\\Lip^+$-bounded initial data they showed a first-order convergence rate in the\nWasserstein distance. Our main result is to prove that this rate is optimal. We\nfurther provide numerical evidence indicating that the rate in the case of\n$\\Lip^+$-unbounded initial data is worse than first-order.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 12:38:11 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 13:23:36 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 15:56:37 GMT"}, {"version": "v4", "created": "Sat, 6 Jul 2019 14:46:11 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Ruf", "Adrian Montgomery", ""], ["Sande", "Espen", ""], ["Solem", "Susanne", ""]]}, {"id": "1808.04747", "submitter": "Yufei Zhang", "authors": "Christoph Reisinger, Yufei Zhang", "title": "A penalty scheme for monotone systems with interconnected obstacles:\n  convergence and error estimates", "comments": "Accepted for publication (in this revised form) in SIAM Journal on\n  Numerical Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel penalty approach for a class of quasi-variational\ninequalities (QVIs) involving monotone systems and interconnected obstacles. We\nshow that for any given positive switching cost, the solutions of the penalized\nequations converge monotonically to those of the QVIs. We estimate the\npenalization errors and are able to deduce that the optimal switching regions\nare constructed exactly. We further demonstrate that as the switching cost\ntends to zero, the QVI degenerates into an equation of HJB type, which is\napproximated by the penalized equation at the same order (up to a log factor)\nas that for positive switching cost. Numerical experiments on optimal switching\nproblems are presented to illustrate the theoretical results and to demonstrate\nthe effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 15:25:20 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 11:08:46 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Reisinger", "Christoph", ""], ["Zhang", "Yufei", ""]]}, {"id": "1808.04779", "submitter": "Patricia Diaz de Alba", "authors": "Gian Piero Deidda, Patricia D\\'iaz de Alba, Caterina Fenu, Gabriele\n  Lovicu, and Giuseppe Rodriguez", "title": "FDEMtools: a MATLAB package for FDEM data inversion", "comments": null, "journal-ref": null, "doi": "10.1007/s11075-019-00843-2", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electromagnetic induction surveys are among the most popular techniques for\nnon-destructive investigation of soil properties in order to detect the\npresence of either ground inhomogeneities or of particular substances. This\nwork introduces a MATLAB package for the inversion of electromagnetic data\ncollected by a ground conductivity meter. Based on a nonlinear forward model\nused to describe the interaction between an electromagnetic field and the soil,\nthe software reconstructs either the electrical conductivity or the magnetic\npermeability of the soil with respect to depth, by a regularized damped\nGauss-Newton method. The regularization part of the algorithm is based on a\nlow-rank approximation of the Jacobian of the nonlinear model. Both the\nrelaxation parameter and the regularization parameter are chosen by automatic\nprocedures. The package allows the user to experiment with synthetic data sets\nand different regularization strategies, in order to compare them and draw\nconclusions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 16:14:50 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 21:45:47 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 09:05:11 GMT"}, {"version": "v4", "created": "Wed, 16 Oct 2019 08:40:04 GMT"}, {"version": "v5", "created": "Wed, 20 Nov 2019 15:40:53 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Deidda", "Gian Piero", ""], ["de Alba", "Patricia D\u00edaz", ""], ["Fenu", "Caterina", ""], ["Lovicu", "Gabriele", ""], ["Rodriguez", "Giuseppe", ""]]}, {"id": "1808.04932", "submitter": "Bosu Choi", "authors": "Bosu Choi, Mark Iwen and Felix Krahmer", "title": "Sparse Harmonic Transforms: A New Class of Sublinear-time Algorithms for\n  Learning Functions of Many Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop fast and memory efficient numerical methods for learning functions\nof many variables that admit sparse representations in terms of general bounded\northonormal tensor product bases. Such functions appear in many applications\nincluding, e.g., various Uncertainty Quantification(UQ) problems involving the\nsolution of parametric PDE that are approximately sparse in Chebyshev or\nLegendre product bases. We expect that our results provide a starting point for\na new line of research on sublinear-time solution techniques for UQ\napplications of the type above which will eventually be able to scale to\nsignificantly higher-dimensional problems than what are currently\ncomputationally feasible.\n  More concretely, let $B$ be a finite Bounded Orthonormal Product Basis (BOPB)\nof cardinality $|B|=N$. We will develop methods that approximate any function\n$f$ that is sparse in the BOPB, that is, $f:\\mathcal{D}\\subset R^D\\rightarrow\nC$ of the form $f(\\mathbf{x})=\\sum_{b\\in S}c_b\\cdot b(\\mathbf{x})$ with\n$S\\subset B$ of cardinality $|S| =s\\ll N$. Our method has a runtime of just\n$(s\\log N)^{O(1)}$, uses only $(s\\log N)^{O(1)}$ function evaluations on a\nfixed and nonadaptive grid, and not more than $(s\\log N)^{O(1)}$ bits of\nmemory.\n  For $s\\ll N$, the runtime $(s\\log N)^{O(1)}$ will be less than what is\nrequired to simply enumerate the elements of the basis $B$; thus our method is\nthe first approach applicable in a general BOPB framework that falls into the\nclass referred to as \"sublinear-time\". This and the similarly reduced sample\nand memory requirements set our algorithm apart from previous works based on\nstandard compressive sensing algorithms such as basis pursuit which typically\nstore and utilize full intermediate basis representations of size $\\Omega(N)$.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 00:55:58 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 00:08:12 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Choi", "Bosu", ""], ["Iwen", "Mark", ""], ["Krahmer", "Felix", ""]]}, {"id": "1808.04990", "submitter": "Thomas Wihler", "authors": "Pascal Heid and Thomas P. Wihler", "title": "Adaptive Iterative Linearization Galerkin Methods for Nonlinear Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of (fixed-point) iterative methods for the solution of\nnonlinear equations (in Hilbert spaces) exists. In many cases, such schemes can\nbe interpreted as iterative local linearization methods, which, as will be\nshown, can be obtained by applying a suitable preconditioning operator to the\noriginal (nonlinear) equation. Based on this observation, we will derive a\nunified abstract framework which recovers some prominent iterative schemes. In\nparticular, for Lipschitz continuous and strongly monotone operators, we derive\na general convergence analysis. Furthermore, in the context of numerical\nsolution schemes for nonlinear partial differential equations, we propose a\ncombination of the iterative linearization approach and the classical Galerkin\ndiscretization method, thereby giving rise to the so-called iterative\nlinearization Galerkin (ILG) methodology. Moreover, still on an abstract level,\nbased on two different elliptic reconstruction techniques, we derive a\nposteriori error estimates which separately take into account the\ndiscretization and linearization errors. Furthermore, we propose an adaptive\nalgorithm, which provides an efficient interplay between these two effects. In\naddition, the ILG approach will be applied to the specific context of finite\nelement discretizations of quasilinear elliptic equations, and some numerical\nexperiments will be performed.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 07:35:06 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 14:11:02 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Heid", "Pascal", ""], ["Wihler", "Thomas P.", ""]]}, {"id": "1808.05160", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong and Tuan Hang Nguyen", "title": "Backtracking gradient descent method for general $C^1$ functions, with\n  applications to Deep Learning", "comments": "37 pages, 3 figures, 3 tables. Exposition improved, many new results\n  are added. Accompanying source codes will be available at the link:\n  https://github.com/hank-nguyen/MBT-optimizer", "journal-ref": "Applied Mathematics and Optimization 2020, Minimax Theory and its\n  Applications 2021", "doi": null, "report-no": "The paper, with additional experiments and in combination with\n  arXiv:2001.02005 and arXiv:2007.03618 - and a reference to a variant of\n  Backtracking GD by the first author (applicable to Lojasiewicz gradient\n  inequality), has been divided into 2 parts (titles changed) and accepted for\n  publications in 2 journals (see below)", "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Standard gradient descent is one very popular optimisation method, its\nconvergence cannot be proven beyond the class of functions whose gradient is\nglobally Lipschitz continuous. As such, it is not actually applicable to\nrealistic applications such as Deep Neural Networks. In this paper, we prove\nthat its backtracking variant behaves very nicely, in particular convergence\ncan be shown for all Morse functions. The main theoretical result of this paper\nis as follows.\n  Theorem. Let $f:\\mathbb{R}^k\\rightarrow \\mathbb{R}$ be a $C^1$ function, and\n$\\{z_n\\}$ a sequence constructed from the Backtracking gradient descent\nalgorithm. (1) Either $\\lim _{n\\rightarrow\\infty}||z_n||=\\infty$ or $\\lim\n_{n\\rightarrow\\infty}||z_{n+1}-z_n||=0$. (2) Assume that $f$ has at most\ncountably many critical points. Then either $\\lim\n_{n\\rightarrow\\infty}||z_n||=\\infty$ or $\\{z_n\\}$ converges to a critical point\nof $f$. (3) More generally, assume that all connected components of the set of\ncritical points of $f$ are compact. Then either $\\lim\n_{n\\rightarrow\\infty}||z_n||=\\infty$ or $\\{z_n\\}$ is bounded. Moreover, in the\nlatter case the set of cluster points of $\\{z_n\\}$ is connected.\n  Some generalised versions of this result, including an inexact version, are\nincluded. Another result in this paper concerns the problem of saddle points.\nWe then present a heuristic argument to explain why Standard gradient descent\nmethod works so well, and modifications of the backtracking versions of GD, MMT\nand NAG. Experiments with datasets CIFAR10 and CIFAR100 on various popular\narchitectures verify the heuristic argument also for the mini-batch practice\nand show that our new algorithms, while automatically fine tuning learning\nrates, perform better than current state-of-the-art methods such as MMT, NAG,\nAdagrad, Adadelta, RMSProp, Adam and Adamax.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 15:54:24 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 17:20:50 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Truong", "Tuyen Trung", ""], ["Nguyen", "Tuan Hang", ""]]}, {"id": "1808.05510", "submitter": "Patrick K\\\"urschner", "authors": "Patrick K\\\"urschner, Sergey Dolgov, Kameron Decker Harris, Peter\n  Benner", "title": "Greedy low-rank algorithm for spatial connectome regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering brain connectivity from tract tracing data is an important\ncomputational problem in the neurosciences. Mesoscopic connectome\nreconstruction was previously formulated as a structured matrix regression\nproblem (Harris et al., 2016), but existing techniques do not scale to the\nwhole-brain setting. The corresponding matrix equation is challenging to solve\ndue to large scale, ill-conditioning, and a general form that lacks a\nconvergent splitting. We propose a greedy low-rank algorithm for connectome\nreconstruction problem in very high dimensions. The algorithm approximates the\nsolution by a sequence of rank-one updates which exploit the sparse and\npositive definite problem structure. This algorithm was described previously\n(Kressner and Sirkovi\\'c, 2015) but never implemented for this connectome\nproblem, leading to a number of challenges. We have had to design judicious\nstopping criteria and employ efficient solvers for the three main sub-problems\nof the algorithm, including an efficient GPU implementation that alleviates the\nmain bottleneck for large datasets. The performance of the method is evaluated\non three examples: an artificial \"toy\" dataset and two whole-cortex instances\nusing data from the Allen Mouse Brain Connectivity Atlas. We find that the\nmethod is significantly faster than previous methods and that moderate ranks\noffer good approximation. This speedup allows for the estimation of\nincreasingly large-scale connectomes across taxa as these data become available\nfrom tracing experiments. The data and code are available online.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 14:26:05 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 12:03:54 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["K\u00fcrschner", "Patrick", ""], ["Dolgov", "Sergey", ""], ["Harris", "Kameron Decker", ""], ["Benner", "Peter", ""]]}, {"id": "1808.05513", "submitter": "Lawrence Mitchell", "authors": "Robert C. Kirby and Lawrence Mitchell", "title": "Code generation for generally mapped finite elements", "comments": "23 pages", "journal-ref": "ACM Transactions on Mathematical Software 45(41):1-23 (2019)", "doi": "10.1145/3361745", "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many classical finite elements such as the Argyris and Bell elements have\nlong been absent from high-level PDE software. Building on recent theoretical\nwork, we describe how to implement very general finite element transformations\nin FInAT and hence into the Firedrake finite element system. Numerical results\nevaluate the new elements, comparing them to existing methods for classical\nproblems. For a second order model problem, we find that new elements give\nsmooth solutions at a mild increase in cost over standard Lagrange elements.\nFor fourth-order problems, however, the newly-enabled methods significantly\noutperform interior penalty formulations. We also give some advanced use cases,\nsolving the nonlinear Cahn-Hilliard equation and some biharmonic eigenvalue\nproblems (including Chladni plates) using $C^1$ discretizations.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 14:30:14 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 10:30:57 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Kirby", "Robert C.", ""], ["Mitchell", "Lawrence", ""]]}, {"id": "1808.05530", "submitter": "Gon\\c{c}alo dos Reis Dr.", "authors": "G. dos Reis, S. Engelhardt and G. Smith", "title": "Simulation of McKean Vlasov SDEs with super linear growth", "comments": "43 pages, 4 figures, 1 Table; Final Author version (to appear in IMA\n  Journal of Numerical Analysis)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two fully probabilistic Euler schemes, one explicit and one\nimplicit, for the simulation of McKean-Vlasov Stochastic Differential Equations\n(MV-SDEs) with drifts of super-linear growth and random initial condition.\n  We provide a pathwise propagation of chaos result and show strong convergence\nfor both schemes on the consequent particle system. The explicit scheme attains\nthe standard $1/2$ rate in stepsize. From a technical point of view, we\nsuccessfully use stopping times to prove the convergence of the implicit method\nalthough we avoid them altogether for the explicit one. The combination of\nparticle interactions and random initial condition makes the proofs technically\nmore involved.\n  Numerical tests recover the theoretical convergence rates and illustrate a\ncomputational complexity advantage of the explicit over the implicit scheme. A\ncomparative analysis is carried out on a stylized non-Lipschitz MV-SDE and a\nmean-field model for FitzHugh-Nagumo neurons. We provide numerical tests\nillustrating \"particle corruption\" effect where one single particle diverging\ncan \"corrupt\" the whole particle system. Moreover, the more particles in the\nsystem the more likely this divergence is to occur.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 15:06:44 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 16:45:56 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 09:54:48 GMT"}, {"version": "v4", "created": "Mon, 28 Dec 2020 17:22:49 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Reis", "G. dos", ""], ["Engelhardt", "S.", ""], ["Smith", "G.", ""]]}, {"id": "1808.05780", "submitter": "Daniel Mckenzie", "authors": "Ming-Jun Lai, Daniel Mckenzie", "title": "Compressive Sensing for cut improvement and local clustering", "comments": "25 pages. Generalizes and improves upon the earlier versions arxiv:\n  1808.05780 and arXiv:1708.09477. To appear in SIMODS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NA cs.SI math.IT math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how one can phrase the cut improvement problem for graphs as a sparse\nrecovery problem, whence one can use algorithms originally developed for use in\ncompressive sensing (such as SubspacePursuit or CoSaMP) to solve it. We show\nthat this approach to cut improvement is fast, both in theory and practice and\nmoreover enjoys statistical guarantees of success when applied to graphs drawn\nfrom probabilistic models such as the Stochastic Block Model. Using this new\ncut improvement approach, which we call ClusterPursuit, as an algorithmic\nprimitive we then propose new methods for local clustering and semi-supervised\nclustering, which enjoy similar guarantees of success and speed. Finally, we\nverify the promise of our approach with extensive numerical benchmarking.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 07:38:08 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 18:26:07 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 16:50:06 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Lai", "Ming-Jun", ""], ["Mckenzie", "Daniel", ""]]}, {"id": "1808.05890", "submitter": "Slobodan Milovanovi\\'c", "authors": "Slobodan Milovanovi\\'c and Lina von Sydow", "title": "A High Order Method for Pricing of Financial Derivatives using Radial\n  Basis Function generated Finite Differences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the numerical pricing of financial derivatives\nusing Radial Basis Function generated Finite Differences in space. Such\ndiscretization methods have the advantage of not requiring Cartesian grids.\nInstead, the nodes can be placed with higher density in areas where there is a\nneed for higher accuracy. Still, the discretization matrix is fairly sparse. As\na model problem, we consider the pricing of European options in 2D. Since such\noptions have a discontinuity in the first derivative of the payoff function\nwhich prohibits high order convergence, we smooth this function using an\nestablished technique for Cartesian grids. Numerical experiments show that we\nacquire a fourth order scheme in space, both for the uniform and the nonuniform\nnode layouts that we use. The high order method with the nonuniform node layout\nachieves very high accuracy with relatively few nodes. This renders the\npotential for solving pricing problems in higher spatial dimensions since the\ncomputational memory and time demand become much smaller with this method\ncompared to standard techniques.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 15:00:42 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 06:20:40 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Milovanovi\u0107", "Slobodan", ""], ["von Sydow", "Lina", ""]]}, {"id": "1808.05924", "submitter": "Jocelyn Chi", "authors": "Jocelyn T. Chi and Ilse C. F. Ipsen", "title": "A Projector-Based Approach to Quantifying Total and Excess Uncertainties\n  for Sketched Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Linear regression is a classic method of data analysis. In recent years,\nsketching -- a method of dimension reduction using random sampling, random\nprojections, or both -- has gained popularity as an effective computational\napproximation when the number of observations greatly exceeds the number of\nvariables. In this paper, we address the following question: How does sketching\naffect the statistical properties of the solution and key quantities derived\nfrom it?\n  To answer this question, we present a projector-based approach to sketched\nlinear regression that is exact and that requires minimal assumptions on the\nsketching matrix. Therefore, downstream analyses hold exactly and generally for\nall sketching schemes. Additionally, a projector-based approach enables\nderivation of key quantities from classic linear regression that account for\nthe combined model- and algorithm-induced uncertainties. We demonstrate the\nusefulness of a projector-based approach in quantifying and enabling insight on\nexcess uncertainties and bias-variance decompositions for sketched linear\nregression. Finally, we demonstrate how the insights from our projector-based\nanalyses can be used to produce practical sketching diagnostics to aid the\ndesign of judicious sketching schemes.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 16:42:09 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 04:13:26 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 14:34:07 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Chi", "Jocelyn T.", ""], ["Ipsen", "Ilse C. F.", ""]]}, {"id": "1808.06126", "submitter": "Danny Hermes", "authors": "Danny Hermes", "title": "A 2-Norm Condition Number for B\\'ezier Curve Intersection", "comments": null, "journal-ref": null, "doi": "10.1016/j.cagd.2019.101791", "report-no": null, "categories": "math.NA cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a condition number of the intersection of two B\\'ezier curves.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 20:05:47 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 05:08:13 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 06:10:07 GMT"}, {"version": "v4", "created": "Fri, 18 Oct 2019 04:54:17 GMT"}, {"version": "v5", "created": "Sat, 9 Nov 2019 05:58:11 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Hermes", "Danny", ""]]}, {"id": "1808.06239", "submitter": "Stefania Bellavia", "authors": "Stefania Bellavia, Gianmarco Gurioli, Benedetta Morini", "title": "Adaptive Cubic Regularization Methods with Dynamic Inexact Hessian\n  Information and Applications to Finite-Sum Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Adaptive Regularization with Cubics approach for solving\nnonconvex optimization problems and propose a new variant based on inexact\nHessian information chosen dynamically. The theoretical analysis of the\nproposed procedure is given. The key property of ARC framework, constituted by\noptimal worst-case function/derivative evaluation bounds for first- and\nsecond-order critical point, is guaranteed. Application to large-scale\nfinite-sum minimization based on subsampled Hessian is discussed and analyzed\nin both a deterministic and probabilistic manner and equipped with numerical\nexperiments on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 18:01:35 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 10:23:08 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 10:24:54 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bellavia", "Stefania", ""], ["Gurioli", "Gianmarco", ""], ["Morini", "Benedetta", ""]]}, {"id": "1808.06309", "submitter": "Zhongjian Wang", "authors": "Zhongjian Wang, Jack Xin, Zhiwen Zhang", "title": "Sharp error estimates on a stochastic structure-preserving scheme in\n  computing effective diffusivity of 3D chaotic flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of computing the effective diffusivity\nfor particles moving in chaotic flows. Instead of solving a\nconvection-diffusion type cell problem in the Eulerian formulation (arising\nfrom homogenization theory for parabolic equations), we compute the motion of\nparticles in the Lagrangian formulation, which is modeled by stochastic\ndifferential equations (SDEs). A robust numerical integrator based on a\nsplitting method was proposed to solve the SDEs and a rigorous error analysis\nfor the numerical integrator was provided using the backward error analysis\n(BEA) technique [35]. However, the upper bound in the error estimate is not\nsharp. To improve our result, we propose a new and uniform in time error\nanalysis for the numerical integrator that allows us to get rid of the\nexponential growth factor in our previous error estimate. Our new error\nanalysis is based on a probabilistic approach, which interprets the solution\nprocess generated by our numerical integrator as a Markov process. By exploring\nthe ergodicity of the solution process, we prove the convergence analysis of\nour method in computing effective diffusivity over infinite time. We present\nnumerical results to verify the accuracy and efficiency of the proposed method\nin computing effective diffusivity for several chaotic flows, especially the\nArnold-Beltrami-Childress (ABC) flow and Kolmogorov flow in three-dimensional\nspace.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 05:29:20 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 03:55:27 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Wang", "Zhongjian", ""], ["Xin", "Jack", ""], ["Zhang", "Zhiwen", ""]]}, {"id": "1808.06357", "submitter": "Yuya Suzuki", "authors": "Yuya Suzuki, Gowri Suryanarayana, Dirk Nuyens", "title": "Strang splitting in combination with rank-$1$ and rank-$r$ lattices for\n  the time-dependent Schr\\\"odinger equation", "comments": "Modified. 40pages, 5 figures. The proof of Lemma 1 is updated after\n  the paper is published", "journal-ref": "SIAM Journal on Scientific Computing. 41.6 (2019), B1254-B1283", "doi": "10.1137/18M1207879", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approximate the solution for the time dependent Schr\\\"odinger equation\n(TDSE) in two steps. We first use a pseudo-spectral collocation method that\nuses samples of functions on rank-1 or rank-r lattice points with unitary\nFourier transforms. We then get a system of ordinary differential equations in\ntime, which we solve approximately by stepping in time using the Strang\nsplitting method. We prove that the numerical scheme proposed converges\nquadratically with respect to the time step size, given that the potential is\nin a Korobov space with the smoothness parameter greater than $9/2$.\nParticularly, we prove that the required degree of smoothness is independent of\nthe dimension of the problem. We demonstrate our new method by comparing with\nresults using sparse grids from [12], with several numerical examples showing\nlarge advantage for our new method and pushing the examples to higher\ndimensionality. The proposed method has two distinctive features from a\nnumerical perspective: (i) numerical results show the error convergence of time\ndiscretization is consistent even for higher-dimensional problems; (ii) by\nusing the rank-$1$ lattice points, the solution can be efficiently computed\n(and further time stepped) using only $1$-dimensional Fast Fourier Transforms.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 09:28:44 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 16:06:07 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 09:25:21 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Suzuki", "Yuya", ""], ["Suryanarayana", "Gowri", ""], ["Nuyens", "Dirk", ""]]}, {"id": "1808.06447", "submitter": "Marco ten Eikelder", "authors": "M. ten Eikelder, I. Akkerman", "title": "Variation entropy: a continuous local generalization of the TVD property\n  using entropy principles", "comments": "Update to postprint version", "journal-ref": "Comput. Methods Appl. Mech. Engrg. 355 (2019) 261-283", "doi": "10.1016/j.cma.2019.06.023", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the notion of a variation entropy. This concept is an\nentropy framework for the gradient of the solution of a conservation law\ninstead of on the solution itself. It appears that all semi-norms are\nadmissible variation entropies. This provides insight into the total variation\ndiminishing property and justifies it from entropy principles. The framework\nallows to derive new local variation diminishing properties in the continuous\nform. This can facilitate the design of new numerical methods for problems that\ncontain discontinuities.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 13:38:49 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 12:47:12 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 12:34:18 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Eikelder", "M. ten", ""], ["Akkerman", "I.", ""]]}, {"id": "1808.06604", "submitter": "Megan McCracken", "authors": "Megan McCracken", "title": "Artificial Neural Networks in Fluid Dynamics: A Novel Approach to the\n  Navier-Stokes Equations", "comments": "4 pages, 8 figures, PEARC '18: Practice and Experience in Advanced\n  Research Computing, July 22--26, 2018, Pittsburgh, PA, USA", "journal-ref": null, "doi": "10.1145/3219104.3229262", "report-no": null, "categories": "cs.NA cs.NE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been used to solve different types of large data related\nproblems in many different fields.This project takes a novel approach to\nsolving the Navier-Stokes Equations for turbulence by training a neural network\nusing Bayesian Cluster and SOM neighbor weighting to map ionospheric velocity\nfields based on 3-dimensional inputs. Parameters used in this problem included\nthe velocity, Reynolds number, Prandtl number, and temperature. In this project\ndata was obtained from Johns-Hopkins University to train the neural network\nusing MATLAB. The neural network was able to map the velocity fields within a\nsixty-seven percent accuracy of the validation data used. Further studies will\nfocus on higher accuracy and solving further non-linear differential equations\nusing convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 14:46:57 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["McCracken", "Megan", ""]]}, {"id": "1808.06714", "submitter": "Yasunori Aoki", "authors": "Yasunori Aoki, Ken Hayami, Kota Toshimoto, and Yuichi Sugiyama", "title": "Cluster Gauss-Newton method for finding multiple approximate minimisers\n  of nonlinear least squares problems with applications to parameter estimation\n  of pharmacokinetic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter estimation problems of mathematical models can often be formulated\nas nonlinear least squares problems. Typically these problems are solved\nnumerically using iterative methods. The local minimiserobtained using these\niterative methods usually depends on the choice of the initial iterate. Thus,\nthe estimated parameter and subsequent analyses using it depend on the choice\nof the initial iterate. One way to reduce the analysis bias due to the choice\nof the initial iterate is to repeat the algorithm from multiple initial\niterates (i.e. use a multi-start method). However, the procedure can be\ncomputationally intensive and is not always used in practice. To overcome this\nproblem, we propose the Cluster Gauss-Newton (CGN) method, an efficient\nalgorithm for finding multiple approximate minimisers of nonlinear-least\nsquares problems. CGN simultaneously solves the nonlinear least squares problem\nfrom multiple initial iterates. Then, CGN iteratively improves the solutions\nfrom these initial iterates similarly to the Gauss-Newton method. However, it\nuses a global linear approximation instead of the Jacobian. The global linear\napproximations are computed collectively among all the iterates to minimise the\ncomputational cost. We use physiologically based pharmacokinetic (PBPK) models\nused in pharmaceutical drug development to demonstrate its use and show that\nCGN is computationally more efficient and more robust against local minima\ncompared to the standard Levenberg-Marquardt method, as well as state-of-the\nart multi-start and derivative-free methods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 22:49:13 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 22:50:06 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 13:38:47 GMT"}, {"version": "v4", "created": "Mon, 6 Apr 2020 07:04:21 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Aoki", "Yasunori", ""], ["Hayami", "Ken", ""], ["Toshimoto", "Kota", ""], ["Sugiyama", "Yuichi", ""]]}, {"id": "1808.06736", "submitter": "Alex Barnett", "authors": "Alex H. Barnett, Jeremy F. Magland, Ludvig af Klinteberg", "title": "A parallel non-uniform fast Fourier transform library based on an\n  \"exponential of semicircle\" kernel", "comments": "25 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nonuniform fast Fourier transform (NUFFT) generalizes the FFT to off-grid\ndata. Its many applications include image reconstruction, data analysis, and\nthe numerical solution of differential equations. We present FINUFFT, an\nefficient parallel library for type 1 (nonuiform to uniform), type 2 (uniform\nto nonuniform), or type 3 (nonuniform to nonuniform) transforms, in dimensions\n1, 2, or 3. It uses minimal RAM, requires no precomputation or plan steps, and\nhas a simple interface to several languages. We perform the expensive\nspreading/interpolation between nonuniform points and the fine grid via a\nsimple new kernel---the `exponential of semicircle' $e^{\\beta \\sqrt{1-x^2}}$ in\n$x\\in[-1,1]$---in a cache-aware load-balanced multithreaded implementation. The\ndeconvolution step requires the Fourier transform of the kernel, for which we\npropose efficient numerical quadrature. For types 1 and 2, rigorous error\nbounds asymptotic in the kernel width approach the fastest known exponential\nrate, namely that of the Kaiser--Bessel kernel. We benchmark against several\npopular CPU-based libraries, showing favorable speed and memory footprint,\nespecially in three dimensions when high accuracy and/or clustered point\ndistributions are desired.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 01:55:35 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 20:26:13 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Barnett", "Alex H.", ""], ["Magland", "Jeremy F.", ""], ["Klinteberg", "Ludvig af", ""]]}, {"id": "1808.06854", "submitter": "Chaolong Jiang", "authors": "Chaolong Jiang, Wenjun Cai, Yushun Wang", "title": "A linearly implicit and local energy-preserving scheme for the\n  sine-Gordon equation based on the invariant energy quadratization approach", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a novel, linearly implicit and local\nenergy-preserving scheme for the sine-Gordon equation. The basic idea is from\nthe invariant energy quadratization approach to construct energy stable schemes\nfor gradient systems, which are energy dispassion. We here take the sine-Gordon\nequation as an example to show that the invariant energy quadratization\napproach is also an efficient way to construct linearly implicit and local\nenergy-conserving schemes for energy-conserving systems. Utilizing the\ninvariant energy quadratization approach, the sine-Gordon equation is first\nreformulated into an equivalent system, which inherits a modified local energy\nconservation law. The new system are then discretized by the conventional\nfinite difference method and a semi-discretized system is obtained, which can\nconserve the semi-discretized local energy conservation law. Subsequently, the\nlinearly implicit structure-preserving method is applied for the resulting\nsemi-discrete system to arrive at a fully discretized scheme. We prove that the\nresulting scheme can exactly preserve the discrete local energy conservation\nlaw. Moveover, with the aid of the classical energy method, an unconditional\nand optimal error estimate for the scheme is established in discrete\n$H_h^1$-norm. Finally, various numerical examples are addressed to confirm our\ntheoretical analysis and demonstrate the advantage of the new scheme over some\nexisting local structure-preserving schemes.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 11:38:58 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 01:03:16 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 04:49:23 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Jiang", "Chaolong", ""], ["Cai", "Wenjun", ""], ["Wang", "Yushun", ""]]}, {"id": "1808.06942", "submitter": "Ignacio Ramirez", "authors": "Ignacio Francisco Ram\\'irez Paulino", "title": "PACO: Global Signal Restoration via PAtch COnsensus", "comments": "Submitted to Siam SIIMS for peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.DC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many signal processing algorithms break the target signal into overlapping\nsegments (also called windows, or patches), process them separately, and then\nstitch them back into place to produce a unified output. At the overlaps, the\nfinal value of those samples that are estimated more than once needs to be\ndecided in some way. Averaging, the simplest approach, often leads to\nunsatisfactory results. Significant work has been devoted to this issue in\nrecent years. Several works explore the idea of a weighted average of the\noverlapped patches and/or pixels; others promote agreement (consensus) between\nthe patches at their intersections. Agreement can be either encouraged or\nimposed as a hard constraint. This work develops on the latter case. The result\nis a variational signal processing framework, named PACO, which features a\nnumber of appealing theoretical and practical properties. The PACO framework\nconsists of a variational formulation that fits a wide variety of problems, and\na general ADMMbased algorithm for minimizing the resulting energies. As a\nbyproduct, we show that the consensus step of the algorithm, which is the main\nbottleneck of similar methods, can be solved efficiently and easily for any\narbitrary patch decomposition scheme. We demonstrate the flexibility and power\nof PACO on three different problems: image inpainting (which we have already\ncovered in previous works), image denoising, and contrast enhancement, using\ndifferent cost functions including Laplacian and Gaussian Mixture Models.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 15:20:46 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 20:48:24 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 18:02:53 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Paulino", "Ignacio Francisco Ram\u00edrez", ""]]}, {"id": "1808.07044", "submitter": "Shinhoo Kang", "authors": "Shinhoo Kang, Tan Bui-Thanh, Todd Arbogast", "title": "A Hybridized Discontinuous Galerkin Method for A Linear Degenerate\n  Elliptic Equation Arising from Two-Phase Mixtures", "comments": "20 pages, 6 figures, 8 tables", "journal-ref": null, "doi": "10.1016/j.cma.2019.03.018", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a high-order hybridized discontinuous Galerkin (HDG) method for a\nlinear degenerate elliptic equation arising from a two-phase mixture of mantle\nconvection or glacier dynamics. We show that the proposed HDG method is\nwell-posed by using an energy approach. We derive ${\\it a priori}$ error\nestimates for the proposed HDG method on simplicial meshes in both two- and\nthree-dimensions. The error analysis shows that the convergence rates are\noptimal for both the scaled pressure and the scaled velocity for non-degenerate\nproblems and are sub-optimal by half order for degenerate ones. Several\nnumerical results are presented to confirm the theoretical estimates. We also\nenhance the HDG solutions by post-processing. The superconvergence rates of\n$(k+2)$ and $(k+\\frac{3}{2})$ are observed for both a non-degenerate case and a\ndegenerate case away from the degeneracy. Degenerate problems with low\nregularity solutions are also studied, and numerical results show that\nhigh-order methods are beneficial in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 17:52:59 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 03:08:20 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Kang", "Shinhoo", ""], ["Bui-Thanh", "Tan", ""], ["Arbogast", "Todd", ""]]}, {"id": "1808.07390", "submitter": "Kailiang Wu", "authors": "Kailiang Wu, Dongbin Xiu", "title": "An Explicit Neural Network Construction for Piecewise Constant Function\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an explicit construction for feedforward neural network (FNN),\nwhich provides a piecewise constant approximation for multivariate functions.\nThe proposed FNN has two hidden layers, where the weights and thresholds are\nexplicitly defined and do not require numerical optimization for training.\nUnlike most of the existing work on explicit FNN construction, the proposed FNN\ndoes not rely on tensor structure in multiple dimensions. Instead, it\nautomatically creates Voronoi tessellation of the domain, based on the given\ndata of the target function, and piecewise constant approximation of the\nfunction. This makes the construction more practical for applications. We\npresent both theoretical analysis and numerical examples to demonstrate its\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 14:45:46 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Wu", "Kailiang", ""], ["Xiu", "Dongbin", ""]]}, {"id": "1808.07677", "submitter": "Carola Kruse", "authors": "Mario Arioli, Carola Kruse, Ulrich Ruede, Nicolas Tardieu", "title": "An iterative generalized Golub-Kahan algorithm for problems in\n  structural mechanics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the Craig variant of the Golub-Kahan bidiagonalization\nalgorithm as an iterative solver for linear systems with saddle point\nstructure. Such symmetric indefinite systems in 2x2 block form arise in many\napplications, but standard iterative solvers are often found to perform poorly\non them and robust preconditioners may not be available. Specifically, such\nsystems arise in structural mechanics, when a semidefinite finite element\nstiffness matrix is augmented with linear multi-point constraints via Lagrange\nmultipliers. Engineers often use such multi-point constraints to introduce\nboundary or coupling conditions into complex finite element models. The article\nwill present a systematic convergence study of the Golub-Kahan algorithm for a\nsequence of test problems of increasing complexity, including concrete\nstructures enforced with pretension cables and the coupled finite element model\nof a reactor containment building. When the systems are suitably transformed\nusing augmented Lagrangians on the semidefinite block and when the constraint\nequations are properly scaled, the Golub-Kahan algorithm is found to exhibit\nexcellent convergence that depends only weakly on the size of the model. The\nnew algorithm is found to be robust in practical cases that are otherwise\nconsidered to be difficult for iterative solvers.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 09:43:44 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Arioli", "Mario", ""], ["Kruse", "Carola", ""], ["Ruede", "Ulrich", ""], ["Tardieu", "Nicolas", ""]]}, {"id": "1808.08028", "submitter": "Gabriele Pozzetti", "authors": "Bernhard Peters, Maryam Baniasadi, Mehdi Baniasadi, Xavier Besseron,\n  Alvaro Estupinan Donoso, Mohammad Mohseni, Gabriele Pozzetti", "title": "The XDEM Multi-physics and Multi-scale Simulation Technology: Review on\n  DEM-CFD Coupling, Methodology and Engineering Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The XDEM multi-physics and multi-scale simulation platform roots in the Ex-\ntended Discrete Element Method (XDEM) and is being developed at the In- stitute\nof Computational Engineering at the University of Luxembourg. The platform is\nan advanced multi- physics simulation technology that combines flexibility and\nversatility to establish the next generation of multi-physics and multi-scale\nsimulation tools. For this purpose the simulation framework relies on coupling\nvarious predictive tools based on both an Eulerian and Lagrangian approach.\nEulerian approaches represent the wide field of continuum models while the\nLagrange approach is perfectly suited to characterise discrete phases. Thus,\ncontinuum models include classical simulation tools such as Computa- tional\nFluid Dynamics (CFD) or Finite Element Analysis (FEA) while an ex- tended\nconfiguration of the classical Discrete Element Method (DEM) addresses the\ndiscrete e.g. particulate phase. Apart from predicting the trajectories of\nindividual particles, XDEM extends the application to estimating the thermo-\ndynamic state of each particle by advanced and optimised algorithms. The\nthermodynamic state may include temperature and species distributions due to\nchemical reaction and external heat sources. Hence, coupling these extended\nfeatures with either CFD or FEA opens up a wide range of applications as\ndiverse as pharmaceutical industry e.g. drug production, agriculture food and\nprocessing industry, mining, construction and agricultural machinery, metals\nmanufacturing, energy production and systems biology.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 07:06:33 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Peters", "Bernhard", ""], ["Baniasadi", "Maryam", ""], ["Baniasadi", "Mehdi", ""], ["Besseron", "Xavier", ""], ["Donoso", "Alvaro Estupinan", ""], ["Mohseni", "Mohammad", ""], ["Pozzetti", "Gabriele", ""]]}, {"id": "1808.08036", "submitter": "Svetlana Kyas (Matculevich)", "authors": "Kundan Kumar, Svetlana Kyas, Jan Nordbotten, Sergey Repin", "title": "Guaranteed and computable error bounds for approximations constructed by\n  an iterative decoupling of the Biot problem", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is concerned with guaranteed a posteriori error estimates for a\nclass of evolutionary problems related to poroelastic media governed by the\nquasi-static linear Biot equations. The system is decoupled employing the\nfixed-stress split scheme, which leads to a semi-discrete system solved\niteratively. The error bounds are derived by combining a posteriori estimates\nfor contractive mappings with those of the functional type for elliptic partial\ndifferential equations. The estimates are applicable for any approximation in\nthe admissible functional space and are independent of the discretization\nmethod. They are fully computable, do not contain mesh dependent constants, and\nprovide reliable global estimates of the error measured in the energy norm.\nMoreover, they suggest efficient error indicators for the distribution of local\nerrors, which can be used in adaptive procedures.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 07:48:52 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 09:38:03 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Kumar", "Kundan", ""], ["Kyas", "Svetlana", ""], ["Nordbotten", "Jan", ""], ["Repin", "Sergey", ""]]}, {"id": "1808.08163", "submitter": "Yakov Berchenko-Kogan", "authors": "Yakov Berchenko-Kogan", "title": "The entropy of the Angenent torus is approximately 1.85122", "comments": "14 pages, 5 figures, Jupyter code included as ancillary file. Journal\n  of Experimental Mathematics, 2019", "journal-ref": null, "doi": "10.1080/10586458.2019.1583616", "report-no": null, "categories": "math.DG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To study the singularities that appear in mean curvature flow, one must\nunderstand self-shrinkers, surfaces that shrink by dilations under mean\ncurvature flow. The simplest examples of self-shrinkers are spheres and\ncylinders. In 1989, Angenent constructed the first nontrivial example of a\nself-shrinker, a torus. A key quantity in the study of the formation of\nsingularities is the entropy, defined by Colding and Minicozzi based on work of\nHuisken. The values of the entropy of spheres and cylinders have explicit\nformulas, but there is no known formula for the entropy of the Angenent torus.\nIn this work, we numerically estimate the entropy of the Angenent torus using\nthe discrete Euler-Lagrange equations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 14:55:23 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 21:42:14 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Berchenko-Kogan", "Yakov", ""]]}, {"id": "1808.08172", "submitter": "Christian Glusa", "authors": "Christian Glusa, Paritosh Ramanan, Erik G. Boman, Edmond Chow,\n  Sivasankaran Rajamanickam", "title": "Asynchronous One-Level and Two-Level Domain Decomposition Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel implementations of linear iterative solvers generally alternate\nbetween phases of data exchange and phases of local computation. Increasingly\nlarge problem sizes on more heterogeneous systems make load balancing and\nnetwork layout very challenging tasks. In particular, global communication\npatterns such as inner products become increasingly limiting at scale. We\nexplore the use of asynchronous communication based on one-sided MPI primitives\nin a multitude of domain decomposition solvers. In particular, a scalable\nasynchronous two-level method is presented. We discuss practical issues\nencountered in the development of a scalable solver and show experimental\nresults obtained on state-of-the-art supercomputer systems that illustrate the\nbenefits of asynchronous solvers in load balanced as well as load imbalanced\nscenarios. Using the novel method, we can observe speed-ups of up to 4x over\nits classical synchronous equivalent.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 15:27:22 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 01:51:35 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Glusa", "Christian", ""], ["Ramanan", "Paritosh", ""], ["Boman", "Erik G.", ""], ["Chow", "Edmond", ""], ["Rajamanickam", "Sivasankaran", ""]]}, {"id": "1808.08290", "submitter": "Sergii Torba M.", "authors": "Igor V. Kravchenko, Vladislav V. Kravchenko, Sergii M. Torba, Jos\\'e\n  Carlos Dias", "title": "Generalized exponential basis for efficient solving of homogeneous\n  diffusion free boundary problems: Russian option pricing", "comments": "26 pages, 6 figures, 1 table. Some typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a method for solving free boundary problems for\ntime-homogeneous diffusions. We combine the complete exponential system of\nsolutions for the heat equation, transmutation operators and recently\ndiscovered Neumann series of Bessel functions representation for solutions of\nSturm-Liouville equations to construct a complete system of solutions for the\nconsidered partial differential equations. The conceptual algorithm for the\napplication of the method is presented. The valuation of Russian options with\nfinite horizon is used as a numerical illustration. The solution under\ndifferent horizons is computed and compared to the results that appear in the\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 19:53:05 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 22:54:51 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kravchenko", "Igor V.", ""], ["Kravchenko", "Vladislav V.", ""], ["Torba", "Sergii M.", ""], ["Dias", "Jos\u00e9 Carlos", ""]]}, {"id": "1808.08328", "submitter": "Kalyana Babu Nakshatrala", "authors": "M. S. Joshaghani, J. Chang, K. B. Nakshatrala and M. G. Knepley", "title": "Composable block solvers for the four-field double porosity/permeability\n  model", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.02.020", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is twofold. First, we propose two composable\nblock solver methodologies to solve the discrete systems that arise from finite\nelement discretizations of the double porosity/permeability (DPP) model. The\nDPP model, which is a four-field mathematical model, describes the flow of a\nsingle-phase incompressible fluid in a porous medium with two distinct\npore-networks and with a possibility of mass transfer between them. Using the\ncomposable solvers feature available in PETSc and the finite element libraries\navailable under the Firedrake Project, we illustrate two different ways by\nwhich one can effectively precondition these large systems of equations.\nSecond, we employ the recently developed performance model called the\nTime-Accuracy-Size (TAS) spectrum to demonstrate that the proposed composable\nblock solvers are scalable in both the parallel and algorithmic sense.\nMoreover, we utilize this spectrum analysis to compare the performance of three\ndifferent finite element discretizations (classical mixed formulation with\nH(div) elements, stabilized continuous Galerkin mixed formulation, and\nstabilized discontinuous Galerkin mixed formulation) for the DPP model. Our\nperformance spectrum analysis demonstrates that the composable block solvers\nare fine choices for any of these three finite element discretizations. Sample\ncomputer codes are provided to illustrate how one can easily implement the\nproposed block solver methodologies through PETSc command line options.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 22:38:19 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Joshaghani", "M. S.", ""], ["Chang", "J.", ""], ["Nakshatrala", "K. B.", ""], ["Knepley", "M. G.", ""]]}, {"id": "1808.08381", "submitter": "Chunfeng Cui", "authors": "Chunfeng Cui and Zheng Zhang", "title": "Stochastic Collocation with Non-Gaussian Correlated Parameters via a New\n  Quadrature Rule", "comments": "3 pages, 5 figure, EPEPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper generalizes stochastic collocation methods to handle correlated\nnon-Gaussian random parameters. The key challenge is to perform a multivariate\nnumerical integration in a correlated parameter space when computing the\ncoefficient of each basis function via a projection step. We propose an\noptimization model and a block coordinate descent solver to compute the\nrequired quadrature samples. Our method is verified with a CMOS ring oscillator\nand an optical ring resonator, showing 3000x speedup over Monte Carlo.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 08:48:21 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Cui", "Chunfeng", ""], ["Zhang", "Zheng", ""]]}, {"id": "1808.08810", "submitter": "Ron Levie", "authors": "Ron Levie and Haim Avron", "title": "Randomized Signal Processing with Continuous Frames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on signal processing tasks in which the signal is\ntransformed from the signal space to a higher dimensional phase space using a\ncontinuous frame, processed in this space, and synthesized to an output signal.\nFor example, in a phase vocoder method, an audio signal is transformed to the\ntime-frequency plane via the short time Fourier transform, manipulated there,\nand synthesized to an output audio signal. We show how to approximate such\nmethods, termed phase space signal processing methods, using a Monte Carlo\nmethod. The Monte Carlo method speeds up computations, since the number of\nsamples required for a certain accuracy is proportional to the dimension of the\nsignal space, and not to the dimension of phase space, which is typically\nhigher. We utilize this property for a new phase vocoder method, based on an\nenhanced time-frequency space, with more dimensions than the classical method.\nThe higher dimension of phase space improves the quality of the method, while\nretaining the computational complexity of a standard phase vocoder based on\nregular samples.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 12:14:16 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 14:16:57 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 07:17:51 GMT"}, {"version": "v4", "created": "Sun, 20 Sep 2020 16:33:12 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Levie", "Ron", ""], ["Avron", "Haim", ""]]}, {"id": "1808.09131", "submitter": "Aziz Takhirov", "authors": "Aziz Takhirov and Jiajia Waters", "title": "Ensemble algorithm for parametrized flow problems with energy stable\n  open boundary conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose novel ensemble calculation methods for Navier-Stokes equations\nsubject to various initial conditions, forcing terms and viscosity\ncoefficients. We establish the stability of the schemes under a CFL condition\ninvolving velocity fluctuations. Similar to related works, the schemes require\nsolution of a single system with multiple right-hand sides. Moreover, we extend\nthe ensemble calculation method to problems with open boundary conditions, with\nprovable energy stability.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 05:52:53 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 17:37:22 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 16:02:20 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Takhirov", "Aziz", ""], ["Waters", "Jiajia", ""]]}, {"id": "1808.09506", "submitter": "David Shuman", "authors": "Li Fan, David I Shuman, Shashanka Ubaru, and Yousef Saad", "title": "Spectrum-Adapted Polynomial Approximation for Matrix Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate two new methods to approximate $f({\\bf A}){\\bf b}$\nfor large, sparse, Hermitian matrices ${\\bf A}$. The main idea behind both\nmethods is to first estimate the spectral density of ${\\bf A}$, and then find\npolynomials of a fixed order that better approximate the function $f$ on areas\nof the spectrum with a higher density of eigenvalues. Compared to\nstate-of-the-art methods such as the Lanczos method and truncated Chebyshev\nexpansion, the proposed methods tend to provide more accurate approximations of\n$f({\\bf A}){\\bf b}$ at lower polynomial orders, and for matrices ${\\bf A}$ with\na large number of distinct interior eigenvalues and a small spectral width.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 19:31:26 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Fan", "Li", ""], ["Shuman", "David I", ""], ["Ubaru", "Shashanka", ""], ["Saad", "Yousef", ""]]}, {"id": "1808.09540", "submitter": "Jeff Calder", "authors": "Chris Finlay, Jeff Calder, Bilal Abbasi, and Adam Oberman", "title": "Lipschitz regularized Deep Neural Networks generalize and are\n  adversarially robust", "comments": "18 pages, 4 figures (merged with arXiv:1810.00953)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study input gradient regularization of deep neural networks,\nand demonstrate that such regularization leads to generalization proofs and\nimproved adversarial robustness. The proof of generalization does not overcome\nthe curse of dimensionality, but it is independent of the number of layers in\nthe networks. The adversarial robustness regularization combines adversarial\ntraining, which we show to be equivalent to Total Variation regularization,\nwith Lipschitz regularization. We demonstrate empirically that the regularized\nmodels are more robust, and that gradient norms of images can be used for\nattack detection.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 20:53:01 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 13:49:52 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 14:08:55 GMT"}, {"version": "v4", "created": "Thu, 12 Sep 2019 02:40:39 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Finlay", "Chris", ""], ["Calder", "Jeff", ""], ["Abbasi", "Bilal", ""], ["Oberman", "Adam", ""]]}, {"id": "1808.09810", "submitter": "Limin Ma", "authors": "Jun Hu, Limin Ma, Rui Ma", "title": "Optimal Superconvergence Analysis for the Crouzeix-Raviart and the\n  Morley elements", "comments": "20 pages, 3 figures, 3 tables. arXiv admin note: text overlap with\n  arXiv:1802.01896", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an improved superconvergence analysis is presented for both\nthe Crouzeix-Raviart element and the Morley element. The main idea of the\nanalysis is to employ a discrete Helmholtz decomposition of the difference\nbetween the canonical interpolation and the finite element solution for the\nfirst order mixed Raviart--Thomas element and the mixed\nHellan--Herrmann--Johnson element, respectively. This, in particular, allows\nfor proving a full one order superconvergence result for these two mixed finite\nelements. Finally, a full one order superconvergence result of both the\nCrouzeix-Raviart element and the Morley element follows from their special\nrelations with the first order mixed Raviart--Thomas element and the mixed\nHellan--Herrmann--Johnson element respectively. Those superconvergence results\nare also extended to mildly-structured meshes.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 02:04:17 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 23:56:01 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Hu", "Jun", ""], ["Ma", "Limin", ""], ["Ma", "Rui", ""]]}, {"id": "1808.10154", "submitter": "F\\'elix del Teso", "authors": "F\\'elix del Teso, Juan J. Manfredi, Mikko Parviainen", "title": "Convergence of dynamic programming principles for the $p$-Laplacian", "comments": "28 pages, 1 figure. Accepted for publication in Advances in Calculus\n  of Variations", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a unified strategy to show that solutions of dynamic programming\nprinciples associated to the $p$-Laplacian converge to the solution of the\ncorresponding Dirichlet problem. Our approach includes all previously known\ncases for continuous and discrete dynamic programming principles, provides new\nresults, and gives a convergence proof free of probability arguments.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 07:29:08 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 17:00:06 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 15:38:42 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["del Teso", "F\u00e9lix", ""], ["Manfredi", "Juan J.", ""], ["Parviainen", "Mikko", ""]]}, {"id": "1808.10367", "submitter": "Vahid Keshavarzzadeh", "authors": "Vahid Keshavarzzadeh, Robert M. Kirby and Akil Narayan", "title": "Parametric Topology Optimization with Multi-Resolution Finite Element\n  Models", "comments": null, "journal-ref": null, "doi": "10.1002/nme.6063", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a methodical procedure for topology optimization under uncertainty\nwith multi-resolution finite element models. We use our framework in a\nbi-fidelity setting where a coarse and a fine mesh corresponding to low- and\nhigh-resolution models are available. The inexpensive low-resolution model is\nused to explore the parameter space and approximate the parameterized\nhigh-resolution model and its sensitivity where parameters are considered in\nboth structural load and stiffness. We provide error bounds for bi-fidelity\nfinite element (FE) approximations and their sensitivities and conduct\nnumerical studies to verify these theoretical estimates. We demonstrate our\napproach on benchmark compliance minimization problems where we show\nsignificant reduction in computational cost for expensive problems such as\ntopology optimization under manufacturing variability while generating almost\nidentical designs to those obtained with single resolution mesh. We also\ncompute the parametric Von-Mises stress for the generated designs via our\nbi-fidelity FE approximation and compare them with standard Monte Carlo\nsimulations. The implementation of our algorithm which extends the well-known\n88-line topology optimization code in MATLAB is provided.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 15:52:08 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Keshavarzzadeh", "Vahid", ""], ["Kirby", "Robert M.", ""], ["Narayan", "Akil", ""]]}, {"id": "1808.10473", "submitter": "Benjamin Peherstorfer", "authors": "Benjamin Peherstorfer, Zlatko Drma\\v{c}, Serkan Gugercin", "title": "Stability of discrete empirical interpolation and gappy proper\n  orthogonal decomposition with randomized and deterministic sampling points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the stability of (discrete) empirical interpolation\nfor nonlinear model reduction and state field approximation from measurements.\nEmpirical interpolation derives approximations from a few samples\n(measurements) via interpolation in low-dimensional spaces. It has been\nobserved that empirical interpolation can become unstable if the samples are\nperturbed due to, e.g., noise, turbulence, and numerical inaccuracies. The main\ncontribution of this work is a probabilistic analysis that shows that stable\napproximations are obtained if samples are randomized and if more samples than\ndimensions of the low-dimensional spaces are used. Oversampling, i.e., taking\nmore sampling points than dimensions of the low-dimensional spaces, leads to\napproximations via regression and is known under the name of gappy proper\northogonal decomposition. Building on the insights of the probabilistic\nanalysis, a deterministic sampling strategy is presented that aims to achieve\nlower approximation errors with fewer points than randomized sampling by taking\ninformation about the low-dimensional spaces into account. Numerical results of\nreconstructing velocity fields from noisy measurements of combustion processes\nand model reduction in the presence of noise demonstrate the instability of\nempirical interpolation and the stability of gappy proper orthogonal\ndecomposition with oversampling.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 18:12:06 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 19:59:25 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 23:36:13 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 14:32:47 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Peherstorfer", "Benjamin", ""], ["Drma\u010d", "Zlatko", ""], ["Gugercin", "Serkan", ""]]}, {"id": "1808.10626", "submitter": "Fabian Meyer", "authors": "A. Beck, J. D\\\"urrw\\\"achter, T. Kuhn, F. Meyer, C.-D. Munz, C. Rohde", "title": "$hp$-Multilevel Monte Carlo Methods for Uncertainty Quantification of\n  Compressible Flows", "comments": "26 pages", "journal-ref": "SIAM Journal on Scientific Computing 42.4 (2020): B1067-B1091", "doi": "10.1137/18M1210575", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel $hp$-multilevel Monte Carlo method for the quantification\nof uncertainties in the compressible Navier-Stokes equations, using the\nDiscontinuous Galerkin method as deterministic solver. The multilevel approach\nexploits hierarchies of uniformly refined meshes while simultaneously\nincreasing the polynomial degree of the ansatz space. It allows for a very\nlarge range of resolutions in the physical space and thus an efficient decrease\nof the statistical error. We prove that the overall complexity of the\n$hp$-multilevel Monte Carlo method to compute the mean field with prescribed\naccuracy is, in best-case, of quadratic order with respect to the accuracy. We\nalso propose a novel and simple approach to estimate a lower confidence bound\nfor the optimal number of samples per level, which helps to prevent\noverestimating these quantities. The method is in particular designed for\napplication on queue-based computing systems, where it is desirable to compute\na large number of samples during one iteration, without overestimating the\noptimal number of samples. Our theoretical results are verified by numerical\nexperiments for the two-dimensional compressible Navier-Stokes equations. In\nparticular we consider a cavity flow problem from computational acoustics,\ndemonstrating that the method is suitable to handle complex engineering\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 08:20:11 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 15:48:54 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 19:35:24 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Beck", "A.", ""], ["D\u00fcrrw\u00e4chter", "J.", ""], ["Kuhn", "T.", ""], ["Meyer", "F.", ""], ["Munz", "C. -D.", ""], ["Rohde", "C.", ""]]}, {"id": "1808.10659", "submitter": "Dante Kalise", "authors": "Dante Kalise and Karl Kunisch and Zhiping Rao", "title": "Sparse and Switching Infinite Horizon Optimal Control with Mixed-Norm\n  Penalizations", "comments": null, "journal-ref": "ESAIM: COCV, Volume 26, 2020, Article Number 61", "doi": "10.1051/cocv/2019038", "report-no": null, "categories": "math.OC cs.NA cs.SY math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A class of infinite horizon optimal control problems involving mixed\nquasi-norms of $L^p$-type cost functionals for the controls is discussed. These\nfunctionals enhance sparsity and switching properties of the optimal controls.\nThe existence of optimal controls and their structural properties are analyzed\non the basis of first order optimality conditions. A dynamic programming\napproach is used for numerical realization.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 10:12:57 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 17:57:02 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kalise", "Dante", ""], ["Kunisch", "Karl", ""], ["Rao", "Zhiping", ""]]}, {"id": "1808.10680", "submitter": "Philippe Blondeel", "authors": "Philippe Blondeel, Pieterjan Robbe, C\\'edric van hoorickx, Geert\n  Lombaert, Stefan Vandewalle", "title": "Multilevel Monte Carlo for uncertainty quantification in structural\n  engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practical structural engineering problems often exhibit a significant degree\nof uncertainty in the material properties being used, the dimensions of the\nmodeled structures, etc. In this paper, we consider a cantilever beam and a\nbeam clamped at both ends, both subjected to a static and a dynamic load. The\nmaterial uncertainty resides in the Young's modulus, which is modeled by means\nof one random variable, sampled from a univariate Gamma distribution, or with\nmultiple random variables, sampled from a Gamma random field. Three different\nresponses are considered: the static elastic, the dynamic elastic and the\nstatic elastoplastic response. In the first two cases, we simulate the spatial\ndisplacement of a concrete beam and its frequency response in the elastic\ndomain. The third case simulates the spatial displacement of a steel beam in\nthe elastoplastic domain. In order to compute the statistical quantities of the\nstatic deflection and frequency response function, Multilevel Monte Carlo\n(MLMC) is combined with a Finite Element solver. In this paper, the\ncomputational costs and run times of the MLMC method are compared with those of\nthe classical Monte Carlo method, demonstrating a significant speedup of up to\nseveral orders of magnitude for the studied cases.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 11:14:12 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Blondeel", "Philippe", ""], ["Robbe", "Pieterjan", ""], ["van hoorickx", "C\u00e9dric", ""], ["Lombaert", "Geert", ""], ["Vandewalle", "Stefan", ""]]}, {"id": "1808.10720", "submitter": "Vitoriano Ruas", "authors": "Larisa Beilina and Vitoriano Ruas", "title": "An explicit P1 finite element scheme for Maxwell's equations with\n  constant permittivity in a boundary neighborhood", "comments": "This version consists of 38 pages. It incorporates an additional\n  section containing results of numerical experimentation, which validate the\n  theoretical analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the complete convergence study of the finite-element\napproximation of Maxwell's equations in the case where the magnetic\npermeability is constant. Standard linear finite elements for the space\ndiscretization are combined with a well-known explicit finite-difference scheme\nfor the time discretization. The analysis applies to the particular case where\nthe dielectric permittivity has a constant value outside a sub-domain, whose\nclosure does not intersect the boundary of the problem-definition domain.\nOptimal convergence results are established in natural norms under reasonable\nassumptions, provided a classical CFL condition holds. A numerical validation\nof the theoretical results is provided.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 13:10:26 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 15:13:52 GMT"}, {"version": "v3", "created": "Tue, 24 Dec 2019 12:33:38 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 21:27:42 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Beilina", "Larisa", ""], ["Ruas", "Vitoriano", ""]]}, {"id": "1808.10747", "submitter": "Charles Epstein", "authors": "Alexander Barnett, Charles L. Epstein, Leslie Greengard, and Jeremy\n  Magland", "title": "Geometry of the Phase Retrieval Problem", "comments": "This is a substantial revision of version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA eess.IV math-ph math.DG math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most powerful approaches to imaging at the nanometer or\nsubnanometer length scale is coherent diffraction imaging using X-ray sources.\nFor amorphous (non-crystalline) samples, the raw data can be interpreted as the\nmodulus of the continuous Fourier transform of the unknown object. Making use\nof prior information about the sample (such as its support), a natural goal is\nto recover the phase through computational means, after which the unknown\nobject can be visualized at high resolution. While many algorithms have been\nproposed for this phase retrieval problem, careful analysis of its\nwell-posedness has received relatively little attention. In this paper, we show\nthat the problem is, in general, not well-posed and describe some of the\nunderlying issues that are responsible for the ill-posedness. We then show how\nthis analysis can be used to develop experimental protocols that lead to better\nconditioned inverse problems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 21:48:06 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 13:58:25 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Barnett", "Alexander", ""], ["Epstein", "Charles L.", ""], ["Greengard", "Leslie", ""], ["Magland", "Jeremy", ""]]}]