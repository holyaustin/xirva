[{"id": "1304.0825", "submitter": "Hengjun Zhao", "authors": "Deepak Kapur, Naijun Zhan, Hengjun Zhao", "title": "Synthesizing Switching Controllers for Hybrid Systems by Continuous\n  Invariant Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NA cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend a template-based approach for synthesizing switching controllers\nfor semi-algebraic hybrid systems, in which all expressions are polynomials.\nThis is achieved by combining a QE (quantifier elimination)-based method for\ngenerating continuous invariants with a qualitative approach for predefining\ntemplates. Our synthesis method is relatively complete with regard to a given\nfamily of predefined templates. Using qualitative analysis, we discuss\nheuristics to reduce the numbers of parameters appearing in the templates. To\navoid too much human interaction in choosing templates as well as the high\ncomputational complexity caused by QE, we further investigate applications of\nthe SOS (sum-of-squares) relaxation approach and the template polyhedra\napproach in continuous invariant generation, which are both well supported by\nefficient numerical solvers.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 02:49:17 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Kapur", "Deepak", ""], ["Zhan", "Naijun", ""], ["Zhao", "Hengjun", ""]]}, {"id": "1304.1608", "submitter": "Mario Mulansky", "authors": "Mario Mulansky", "title": "Simulating DNLS models", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present different techniques to numerically solve the equations of motion\nfor the widely studied Discrete Nonlinear Schroedinger equation (DNLS). Being a\nHamiltonian system, the DNLS requires symplectic routines for an efficient\nnumerical treatment. Here, we introduce different such schemes in detail and\ncompare their performance and accuracy by extensive numerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 03:35:40 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Mulansky", "Mario", ""]]}, {"id": "1304.1760", "submitter": "Dohy Hong", "authors": "Dohy Hong", "title": "Note: interpreting iterative methods convergence with diffusion point of\n  view", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explain the convergence speed of different iteration\nschemes with the fluid diffusion view when solving a linear fixed point\nproblem. This interpretation allows one to better understand why power\niteration or Jacobi iteration may converge faster or slower than Gauss-Seidel\niteration.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 16:52:21 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Hong", "Dohy", ""]]}, {"id": "1304.1864", "submitter": "Paolo Bientinesi", "authors": "Matthias Petschow (1), Enrique Quintana-Orti (2), Paolo Bientinesi\n  (1), ((1) AICES, RWTH Aachen, (2) Universidad Jaume I)", "title": "Improved Accuracy and Parallelism for MRRR-based Eigensolvers -- A Mixed\n  Precision Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": "AICES-2013/04-1", "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real symmetric tridiagonal eigenproblem is of outstanding importance in\nnumerical computations; it arises frequently as part of eigensolvers for\nstandard and generalized dense Hermitian eigenproblems that are based on a\nreduction to tridiagonal form. For its solution, the algorithm of Multiple\nRelatively Robust Representations (MRRR) is among the fastest methods. Although\nfast, the solvers based on MRRR do not deliver the same accuracy as competing\nmethods like Divide & Conquer or the QR algorithm. In this paper, we\ndemonstrate that the use of mixed precisions leads to improved accuracy of\nMRRR-based eigensolvers with limited or no performance penalty. As a result, we\nobtain eigensolvers that are not only equally or more accurate than the best\navailable methods, but also -in most circumstances- faster and more scalable\nthan the competition.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2013 08:14:25 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2013 08:40:47 GMT"}, {"version": "v3", "created": "Sat, 22 Jun 2013 10:08:46 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Petschow", "Matthias", "", "AICES, RWTH Aachen"], ["Quintana-Orti", "Enrique", "", "Universidad Jaume I"], ["Bientinesi", "Paolo", "", "AICES, RWTH Aachen"]]}, {"id": "1304.1978", "submitter": "Carola Doerr", "authors": "Carola Doerr, Francois-Michel De Rainville", "title": "Constructing Low Star Discrepancy Point Sets with Genetic Algorithms", "comments": "Extended abstract appeared at GECCO 2013. v2: corrected 3 numbers in\n  table 4", "journal-ref": null, "doi": "10.1145/2463372.2463469", "report-no": null, "categories": "cs.NE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric discrepancies are standard measures to quantify the irregularity of\ndistributions. They are an important notion in numerical integration. One of\nthe most important discrepancy notions is the so-called \\emph{star\ndiscrepancy}. Roughly speaking, a point set of low star discrepancy value\nallows for a small approximation error in quasi-Monte Carlo integration. It is\nthus the most studied discrepancy notion.\n  In this work we present a new algorithm to compute point sets of low star\ndiscrepancy. The two components of the algorithm (for the optimization and the\nevaluation, respectively) are based on evolutionary principles. Our algorithm\nclearly outperforms existing approaches. To the best of our knowledge, it is\nalso the first algorithm which can be adapted easily to optimize inverse star\ndiscrepancies.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2013 10:29:41 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2013 13:57:57 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Doerr", "Carola", ""], ["De Rainville", "Francois-Michel", ""]]}, {"id": "1304.2097", "submitter": "M.M.A. Hashem", "authors": "R. M. Jalal Uddin Jamali, M. M. A. Hashem, M. Mahfuz Hasan and Md.\n  Bazlar Rahman", "title": "Solving Linear Equations by Classical Jacobi-SR Based Hybrid\n  Evolutionary Algorithm with Uniform Adaptation Technique", "comments": "14 Pages, 5 Figures and 7 Tables", "journal-ref": "Journal of Engineering Science, Vol. 1, No. 2, pp. 11-24, [ISSN:\n  2075-4914](2010)", "doi": null, "report-no": null, "categories": "cs.NE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving a set of simultaneous linear equations is probably the most important\ntopic in numerical methods. For solving linear equations, iterative methods are\npreferred over the direct methods especially when the coefficient matrix is\nsparse. The rate of convergence of iteration method is increased by using\nSuccessive Relaxation (SR) technique. But SR technique is very much sensitive\nto relaxation factor, {\\omega}. Recently, hybridization of classical\nGauss-Seidel based successive relaxation technique with evolutionary\ncomputation techniques have successfully been used to solve large set of linear\nequations in which relaxation factors are self-adapted. In this paper, a new\nhybrid algorithm is proposed in which uniform adaptive evolutionary computation\ntechniques and classical Jacobi based SR technique are used instead of\nclassical Gauss-Seidel based SR technique. The proposed Jacobi-SR based uniform\nadaptive hybrid algorithm, inherently, can be implemented in parallel\nprocessing environment efficiently. Whereas Gauss-Seidel-SR based hybrid\nalgorithms cannot be implemented in parallel computing environment efficiently.\nThe convergence theorem and adaptation theorem of the proposed algorithm are\nproved theoretically. And the performance of the proposed Jacobi-SR based\nuniform adaptive hybrid evolutionary algorithm is compared with Gauss-Seidel-SR\nbased uniform adaptive hybrid evolutionary algorithm as well as with both\nclassical Jacobi-SR method and Gauss-Seidel-SR method in the experimental\ndomain. The proposed Jacobi-SR based hybrid algorithm outperforms the\nGauss-Seidel-SR based hybrid algorithm as well as both classical Jacobi-SR\nmethod and Gauss-Seidel-SR method in terms of convergence speed and\neffectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 04:23:55 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Jamali", "R. M. Jalal Uddin", ""], ["Hashem", "M. M. A.", ""], ["Hasan", "M. Mahfuz", ""], ["Rahman", "Md. Bazlar", ""]]}, {"id": "1304.2276", "submitter": "Hong Zhang", "authors": "Angelamaria Cardone, Zdzislaw Jackiewicz, Hong Zhang, Adrian Sandu", "title": "Extrapolation-based implicit-explicit general linear methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many systems of differential equations modeling problems in science and\nengineering, there are natural splittings of the right hand side into two\nparts, one non-stiff or mildly stiff, and the other one stiff. For such systems\nimplicit-explicit (IMEX) integration combines an explicit scheme for the\nnon-stiff part with an implicit scheme for the stiff part.\n  In a recent series of papers two of the authors (Sandu and Zhang) have\ndeveloped IMEX GLMs, a family of implicit-explicit schemes based on general\nlinear methods. It has been shown that, due to their high stage order, IMEX\nGLMs require no additional coupling order conditions, and are not marred by\norder reduction.\n  This work develops a new extrapolation-based approach to construct practical\nIMEX GLM pairs of high order. We look for methods with large absolute stability\nregion, assuming that the implicit part of the method is A- or L-stable. We\nprovide examples of IMEX GLMs with optimal stability properties. Their\napplication to a two dimensional test problem confirms the theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 17:22:23 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Cardone", "Angelamaria", ""], ["Jackiewicz", "Zdzislaw", ""], ["Zhang", "Hong", ""], ["Sandu", "Adrian", ""]]}, {"id": "1304.2545", "submitter": "M.M.A. Hashem", "authors": "A. R. M. Jalal Uddin Jamali, Mohammad Arif Hossain, G.M. Moniruzzaman\n  and M. M. A. Hashem", "title": "For Solving Linear Equations Recombination is a Needless Operation in\n  Time-Variant Adaptive Hybrid Algorithms", "comments": null, "journal-ref": "Procs. of the 8th International Conference on Computer &\n  Information Technology (ICCIT 2005), pp. 23-28, Dhaka, Bangladesh, December\n  28-30, (2005)", "doi": null, "report-no": null, "categories": "cs.NE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently hybrid evolutionary computation (EC) techniques are successfully\nimplemented for solving large sets of linear equations. All the recently\ndeveloped hybrid evolutionary algorithms, for solving linear equations, contain\nboth the recombination and the mutation operations. In this paper, two modified\nhybrid evolutionary algorithms contained time-variant adaptive evolutionary\ntechnique are proposed for solving linear equations in which recombination\noperation is absent. The effectiveness of the recombination operator has been\nstudied for the time-variant adaptive hybrid algorithms for solving large set\nof linear equations. Several experiments have been carried out using both the\nproposed modified hybrid evolutionary algorithms (in which the recombination\noperation is absent) and corresponding existing hybrid algorithms (in which the\nrecombination operation is present) to solve large set of linear equations. It\nis found that the number of generations required by the existing hybrid\nalgorithms (i.e. the Gauss-Seidel-SR based time variant adaptive (GSBTVA)\nhybrid algorithm and the Jacobi-SR based time variant adaptive (JBTVA) hybrid\nalgorithm) and modified hybrid algorithms (i.e. the modified Gauss-Seidel-SR\nbased time variant adaptive (MGSBTVA) hybrid algorithm and the modified\nJacobi-SR based time variant adaptive (MJBTVA) hybrid algorithm) are\ncomparable. Also the proposed modified algorithms require less amount of\ncomputational time in comparison to the corresponding existing hybrid\nalgorithms. As the proposed modified hybrid algorithms do not contain\nrecombination operation, so they require less computational effort, and also\nthey are more efficient, effective and easy to implement.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2013 12:00:43 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Jamali", "A. R. M. Jalal Uddin", ""], ["Hossain", "Mohammad Arif", ""], ["Moniruzzaman", "G. M.", ""], ["Hashem", "M. M. A.", ""]]}, {"id": "1304.2695", "submitter": "Jan Cieslinski L.", "authors": "Jan L. Cie\\'sli\\'nski", "title": "Locally exact modifications of numerical schemes", "comments": "28 pages plus 6 figures, Computers & Mathematics with Applications,\n  2013. arXiv admin note: substantial text overlap with arXiv:1101.0578", "journal-ref": "Computers & Mathematics with Applications 65 (2013) 1920-1938", "doi": "10.1016/j.camwa.2013.04.015", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new class of exponential integrators for ordinary differential\nequations: locally exact modifications of known numerical schemes. Local\nexactness means that they preserve the linearization of the original system at\nevery point. In particular, locally exact integrators preserve all fixed points\nand are A-stable. We apply this approach to popular schemes including Euler\nschemes, implicit midpoint rule and trapezoidal rule. We found locally exact\nmodifications of discrete gradient schemes (for symmetric discrete gradients\nand coordinate increment discrete gradients) preserving their main geometric\nproperty: exact conservation of the energy integral (for arbitrary\nmultidimensional Hamiltonian systems in canonical coordinates). Numerical\nexperiments for a 2-dimensional anharmonic oscillator show that locally exact\nschemes have very good accuracy in the neighbourhood of stable equilibrium,\nmuch higher than suggested by the order of new schemes (locally exact\nmodification sometimes increases the order but in many cases leaves it\nunchanged).\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2013 18:48:18 GMT"}], "update_date": "2013-08-08", "authors_parsed": [["Cie\u015bli\u0144ski", "Jan L.", ""]]}, {"id": "1304.3200", "submitter": "M.M.A. Hashem", "authors": "A.R.M. Jalal Uddin Jamali, M.M.A. Hashem, and Md. Bazlar Rahman", "title": "An Approach to Solve Linear Equations Using a Time-Variant Adaptation\n  Based Hybrid Evolutionary Algorithm", "comments": "arXiv admin note: text overlap with arXiv:1304.2097", "journal-ref": "Jahangirnagar University Journal of Science, Bangladesh, Vol. 27,\n  pp. 277-289, (2004)", "doi": null, "report-no": null, "categories": "cs.NE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For small number of equations, systems of linear (and sometimes nonlinear)\nequations can be solved by simple classical techniques. However, for large\nnumber of systems of linear (or nonlinear) equations, solutions using classical\nmethod become arduous. On the other hand evolutionary algorithms have mostly\nbeen used to solve various optimization and learning problems. Recently,\nhybridization of evolutionary algorithm with classical Gauss-Seidel based\nSuccessive Over Relaxation (SOR) method has successfully been used to solve\nlarge number of linear equations; where a uniform adaptation (UA) technique of\nrelaxation factor is used. In this paper, a new hybrid algorithm is proposed in\nwhich a time-variant adaptation (TVA) technique of relaxation factor is used\ninstead of uniform adaptation technique to solve large number of linear\nequations. The convergence theorems of the proposed algorithms are proved\ntheoretically. And the performance of the proposed TVA-based algorithm is\ncompared with the UA-based hybrid algorithm in the experimental domain. The\nproposed algorithm outperforms the hybrid one in terms of efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2013 05:36:53 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Jamali", "A. R. M. Jalal Uddin", ""], ["Hashem", "M. M. A.", ""], ["Rahman", "Md. Bazlar", ""]]}, {"id": "1304.3919", "submitter": "Tarek El-Mistikawy", "authors": "Tarek M. A. El-Mistikawy", "title": "Modular Analysis of Almost Block Diagonal Systems of Equations", "comments": "The article is in 40 pages; containing 1 figure, 1 table, 13\n  references, and 3 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost block diagonal linear systems of equations can be exemplified by two\nmodules. This makes it possible to construct all sequential forms of band\nand/or block elimination methods, six old and fourteen new. It allows easy\nassessment of the methods on the basis of their operation counts, storage\nneeds, and admissibility of partial pivoting. It unveils a robust partial\npivoting strategy- local pivoting. Extension of modular analysis to bordered\nsystems is also included.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2013 14:59:00 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["El-Mistikawy", "Tarek M. A.", ""]]}, {"id": "1304.4162", "submitter": "Alexander Petukhov", "authors": "Alexander Petukhov, Inna Kozlov", "title": "Greedy Approach for Low-Rank Matrix Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.IT cs.NA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the Simple Greedy Matrix Completion Algorithm providing an\nefficient method for restoration of low-rank matrices from incomplete corrupted\nentries.\n  We provide numerical evidences that, even in the simplest implementation, the\ngreedy approach may increase the recovery capability of existing algorithms\nsignificantly.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2013 16:41:54 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Petukhov", "Alexander", ""], ["Kozlov", "Inna", ""]]}, {"id": "1304.4292", "submitter": "Bradley Lowery", "authors": "Bradley R. Lowery", "title": "Relative error due to a single bit-flip in floating-point arithmetic", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the error due to a single bit-flip in a floating point number. We\nassume IEEE 754 double precision arithmetic, which encodes binary floating\npoint numbers in a 64-bit word. We assume that the bit-flip happens randomly so\nit has equi-probability (1/64) to hit any of the 64 bits. Since we want to\nmitigate the assumption on our initial floating-point number, we assume that it\nis uniformly picked among all normalized number. With this framework, we can\nsummarize our findings as follows. The probability for a single bit flip to\ncause a relative error less than 10^-11 in a normalized floating-point number\nis above 25%; The probability for a single bit flip to cause a relative error\nless than 10^-6 in a normalized floating-point number is above 50%; Etc.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2013 23:24:46 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Lowery", "Bradley R.", ""]]}, {"id": "1304.4373", "submitter": "Martin Storath", "authors": "Martin Storath, Andreas Weinmann, Laurent Demaret", "title": "Jump-sparse and sparse recovery using Potts functionals", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2014.2329263", "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recover jump-sparse and sparse signals from blurred incomplete data\ncorrupted by (possibly non-Gaussian) noise using inverse Potts energy\nfunctionals. We obtain analytical results (existence of minimizers, complexity)\non inverse Potts functionals and provide relations to sparsity problems. We\nthen propose a new optimization method for these functionals which is based on\ndynamic programming and the alternating direction method of multipliers (ADMM).\nA series of experiments shows that the proposed method yields very satisfactory\njump-sparse and sparse reconstructions, respectively. We highlight the\ncapability of the method by comparing it with classical and recent approaches\nsuch as TV minimization (jump-sparse signals), orthogonal matching pursuit,\niterative hard thresholding, and iteratively reweighted $\\ell^1$ minimization\n(sparse signals).\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2013 09:14:32 GMT"}, {"version": "v2", "created": "Mon, 2 Jun 2014 22:14:46 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Storath", "Martin", ""], ["Weinmann", "Andreas", ""], ["Demaret", "Laurent", ""]]}, {"id": "1304.4738", "submitter": "Jaroslav Hor\\'a\\v{c}ek", "authors": "Jaroslav Hor\\'a\\v{c}ek, Milan Hlad\\'ik", "title": "Computing Enclosures of Overdetermined Interval Linear Systems", "comments": "Presented at SCAN 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers special types of interval linear systems - overdetermined\nsystems. Simply said these systems have more equations than variables. The\nsolution set of an interval linear system is a collection of all solutions of\nall instances of an interval system. By the instance we mean a point real\nsystem that emerges when we independently choose a real number from each\ninterval coefficient of the interval system. Enclosing the solution set of\nthese systems is in some ways more difficult than for square systems. The main\ngoal of this work is to present various methods for solving overdetermined\ninterval linear systems. We would like to present them in an understandable way\neven for nonspecialists in a field of linear systems. The second goal is a\nnumerical comparison of all the methods on random interval linear systems\nregarding widths of enclosures, computation times and other special properties\nof methods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 09:04:39 GMT"}], "update_date": "2013-04-18", "authors_parsed": [["Hor\u00e1\u010dek", "Jaroslav", ""], ["Hlad\u00edk", "Milan", ""]]}, {"id": "1304.4964", "submitter": "Todd Plantenga", "authors": "Samantha Hansen, Todd Plantenga, Tamara G. Kolda", "title": "Newton-Based Optimization for Kullback-Leibler Nonnegative Tensor\n  Factorizations", "comments": "Clarified notation in section 3.1.1, and used simpler score()\n  function in section B.2", "journal-ref": "Optimization Methods and Software, Vol. 30, No. 5, pp. 1002-1029,\n  April 2015", "doi": "10.1080/10556788.2015.1009977", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor factorizations with nonnegative constraints have found application in\nanalyzing data from cyber traffic, social networks, and other areas. We\nconsider application data best described as being generated by a Poisson\nprocess (e.g., count data), which leads to sparse tensors that can be modeled\nby sparse factor matrices. In this paper we investigate efficient techniques\nfor computing an appropriate canonical polyadic tensor factorization based on\nthe Kullback-Leibler divergence function. We propose novel subproblem solvers\nwithin the standard alternating block variable approach. Our new methods\nexploit structure and reformulate the optimization problem as small independent\nsubproblems. We employ bound-constrained Newton and quasi-Newton methods. We\ncompare our algorithms against other codes, demonstrating superior speed for\nhigh accuracy results and the ability to quickly find sparse solutions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 20:35:37 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2013 19:37:10 GMT"}, {"version": "v3", "created": "Tue, 29 Jul 2014 21:29:28 GMT"}, {"version": "v4", "created": "Mon, 10 Nov 2014 19:51:46 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Hansen", "Samantha", ""], ["Plantenga", "Todd", ""], ["Kolda", "Tamara G.", ""]]}, {"id": "1304.5546", "submitter": "Andreas Kl\\\"ockner", "authors": "Andreas Kl\\\"ockner and Timothy Warburton and Jan S. Hesthaven", "title": "Solving Wave Equations on Unstructured Geometries", "comments": "GPU Computing Gems, edited by Wen-mei Hwu, Elsevier (2011), ISBN\n  9780123859631, Chapter 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Waves are all around us--be it in the form of sound, electromagnetic\nradiation, water waves, or earthquakes. Their study is an important basic tool\nacross engineering and science disciplines. Every wave solver serving the\ncomputational study of waves meets a trade-off of two figures of merit--its\ncomputational speed and its accuracy. Discontinuous Galerkin (DG) methods fall\non the high-accuracy end of this spectrum. Fortuitously, their computational\nstructure is so ideally suited to GPUs that they also achieve very high\ncomputational speeds. In other words, the use of DG methods on GPUs\nsignificantly lowers the cost of obtaining accurate solutions. This article\naims to give the reader an easy on-ramp to the use of this technology, based on\na sample implementation which demonstrates a highly accurate, GPU-capable,\nreal-time visualizing finite element solver in about 1500 lines of code.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2013 21:07:10 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Kl\u00f6ckner", "Andreas", ""], ["Warburton", "Timothy", ""], ["Hesthaven", "Jan S.", ""]]}, {"id": "1304.5923", "submitter": "Petr Vabishchevich N.", "authors": "P.N. Vabishchevich and V.I. Vasil'ev", "title": "Numerical solving the identification problem for the lower coefficient\n  of parabolic equation", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the theory and practice of inverse problems for partial differential\nequations (PDEs) much attention is paid to the problem of the identification of\ncoefficients from some additional information. This work deals with the problem\nof determining in a multidimensional parabolic equation the lower coefficient\nthat depends on time only. To solve numerically a nonlinear inverse problem,\nlinearized approximations in time are constructed using standard finite element\nprocedures in space. The computational algorithm is based on a special\ndecomposition, where the transition to a new time level is implemented via\nsolving two standard elliptic problems. The numerical results presented here\nfor a model 2D problem demonstrate capabilities of the proposed computational\nalgorithms for approximate solving inverse problems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2013 12:19:15 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Vabishchevich", "P. N.", ""], ["Vasil'ev", "V. I.", ""]]}, {"id": "1304.6475", "submitter": "Haim Avron", "authors": "Haim Avron, Alex Druinsky, Anshul Gupta", "title": "Revisiting Asynchronous Linear Solvers: Provable Convergence Rate\n  Through Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous methods for solving systems of linear equations have been\nresearched since Chazan and Miranker's pioneering 1969 paper on chaotic\nrelaxation. The underlying idea of asynchronous methods is to avoid processor\nidle time by allowing the processors to continue to make progress even if not\nall progress made by other processors has been communicated to them.\n  Historically, the applicability of asynchronous methods for solving linear\nequations was limited to certain restricted classes of matrices, such as\ndiagonally dominant matrices. Furthermore, analysis of these methods focused on\nproving convergence in the limit. Comparison of the asynchronous convergence\nrate with its synchronous counterpart and its scaling with the number of\nprocessors were seldom studied, and are still not well understood.\n  In this paper, we propose a randomized shared-memory asynchronous method for\ngeneral symmetric positive definite matrices. We rigorously analyze the\nconvergence rate and prove that it is linear, and is close to that of the\nmethod's synchronous counterpart if the processor count is not excessive\nrelative to the size and sparsity of the matrix. We also present an algorithm\nfor unsymmetric systems and overdetermined least-squares. Our work presents a\nsignificant improvement in the applicability of asynchronous linear solvers as\nwell as in their convergence analysis, and suggests randomization as a key\nparadigm to serve as a foundation for asynchronous methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 03:18:53 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2013 20:19:45 GMT"}, {"version": "v3", "created": "Wed, 2 Jul 2014 20:43:04 GMT"}, {"version": "v4", "created": "Fri, 18 Jul 2014 20:08:45 GMT"}, {"version": "v5", "created": "Fri, 6 Mar 2015 21:17:17 GMT"}, {"version": "v6", "created": "Tue, 14 Jul 2015 20:35:14 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Avron", "Haim", ""], ["Druinsky", "Alex", ""], ["Gupta", "Anshul", ""]]}, {"id": "1304.6508", "submitter": "Tomoaki Okayama", "authors": "Tomoaki Okayama", "title": "Theoretical analysis of Sinc-collocation methods and Sinc-Nystr\\\"{o}m\n  methods for initial value problems", "comments": "Keywords: Sinc approximation, Sinc indefinite integration,\n  differential equation, Volterra integral equation, tanh transformation,\n  double-exponential transformation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Sinc-collocation method has been proposed by Stenger, and he also gave\ntheoretical analysis of the method in the case of a `scalar' equation. This\npaper extends the theoretical results to the case of a `system' of equations.\nFurthermore, this paper proposes more efficient method by replacing the\nvariable transformation employed in Stenger's method. The efficiency is\nconfirmed by both of theoretical analysis and numerical experiments. In\naddition to the existing and newly-proposed Sinc-collocation methods, this\npaper also gives similar theoretical results for Sinc-Nystr\\\"{o}m methods\nproposed by Nurmuhammad et al. From a viewpoint of the computational cost, it\nturns out that the newly-proposed Sinc-collocation method is the most efficient\namong those methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 08:25:59 GMT"}], "update_date": "2013-04-25", "authors_parsed": [["Okayama", "Tomoaki", ""]]}, {"id": "1304.6533", "submitter": "Jan Cieslinski L.", "authors": "Jan L. Cie\\'sli\\'nski", "title": "Locally exact modifications of discrete gradient schemes", "comments": "16 pages plus 4 figures", "journal-ref": "Physics Letters A 377 (8) (2013) 651-654", "doi": "10.1016/j.physleta.2013.01.005", "report-no": null, "categories": "physics.comp-ph cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally exact integrators preserve linearization of the original system at\nevery point. We construct energy-preserving locally exact discrete gradient\nschemes for arbitrary multidimensional canonical Hamiltonian systems by\nmodifying classical discrete gradient schemes. Modifications of this kind are\nfound for any discrete gradient.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 09:53:44 GMT"}], "update_date": "2013-08-08", "authors_parsed": [["Cie\u015bli\u0144ski", "Jan L.", ""]]}, {"id": "1304.6962", "submitter": "Konstantin Usevich", "authors": "Konstantin Usevich and Ivan Markovsky", "title": "Variable projection methods for approximate (greatest) common divisor\n  computations", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding for a given $N$-tuple of polynomials (real\nor complex) the closest $N$-tuple that has a common divisor of degree at least\n$d$. Extended weighted Euclidean seminorm of the coefficients is used as a\nmeasure of closeness. Two equivalent representations of the problem are\nconsidered: (i) direct parameterization over the common divisors and quotients\n(image representation), and (ii) Sylvester low-rank approximation (kernel\nrepresentation). We use the duality between least-squares and least-norm\nproblems to show that (i) and (ii) are closely related to mosaic Hankel\nlow-rank approximation. This allows us to apply to the approximate common\ndivisor problem recent results on complexity and accuracy of computations for\nmosaic Hankel low-rank approximation. We develop optimization methods based on\nthe variable projection principle both for image and kernel representation.\nThese methods have linear complexity in the degrees of the polynomials for\nsmall and large $d$. We provide a software implementation of the developed\nmethods, which is based on a software package for structured low-rank\napproximation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 17:02:07 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2015 17:34:04 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Usevich", "Konstantin", ""], ["Markovsky", "Ivan", ""]]}, {"id": "1304.6996", "submitter": "Pierre Gosselet", "authors": "Olivier Allix (LMT), Pierre Gosselet (LMT), Pierre Kerfriden, Karin\n  Saavedra (LMT)", "title": "Virtual Delamination Testing through Non-Linear Multi-Scale\n  Computational Methods: Some Recent Progress", "comments": null, "journal-ref": "CMC: Computers, Materials, \\& Continua 32, 2 (2012) 107-132", "doi": "10.3970/cmc.2012.032.107", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the parallel simulation of delamination problems at the\nmeso-scale by means of multi-scale methods, the aim being the Virtual\nDelamination Testing of Composite parts. In the non-linear context, Domain\nDecomposition Methods are mainly used as a solver for the tangent problem to be\nsolved at each iteration of a Newton-Raphson algorithm. In case of strongly\nnonlinear and heterogeneous problems, this procedure may lead to severe\ndifficulties. The paper focuses on methods to circumvent these problems, which\ncan now be expressed using a relatively general framework, even though the\ndifferent ingredients of the strategy have emerged separately. We rely here on\nthe micro-macro framework proposed in (Ladev\\`eze, Loiseau, and Dureisseix,\n2001). The method proposed in this paper introduces three additional features:\n(i) the adaptation of the macro-basis to situations where classical\nhomogenization does not provide a good preconditioner, (ii) the use of\nnon-linear relocalization to decrease the number of global problems to be\nsolved in the case of unevenly distributed non-linearities, (iii) the\nadaptation of the approximation of the local Schur complement which governs the\nconvergence of the proposed iterative technique. Computations of delamination\nand delamination-buckling interaction with contact on potentially large\ndelaminated areas are used to illustrate those aspects.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 19:57:03 GMT"}], "update_date": "2013-04-26", "authors_parsed": [["Allix", "Olivier", "", "LMT"], ["Gosselet", "Pierre", "", "LMT"], ["Kerfriden", "Pierre", "", "LMT"], ["Saavedra", "Karin", "", "LMT"]]}, {"id": "1304.7018", "submitter": "Jasper Kreeft", "authors": "Jasper Kreeft and Marc Gerritsma", "title": "Higher-order compatible discretization on hexahedrals", "comments": "to appear in Lecture Notes in Computational Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph cs.CE cs.CG cs.NA math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a compatible discretization method that relies heavily on the\nunderlying geometric structure, and obeys the topological sequences and\ncommuting properties that are constructed. As a sample problem we consider the\nvorticity-velocity-pressure formulation of the Stokes problem. We motivate the\nchoice for a mixed variational formulation based on both geometric as well as\nphysical arguments. Numerical tests confirm the theoretical results that we\nobtain a pointwise divergence-free solution for the Stokes problem and that the\nmethod obtains optimal convergence rates.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2013 20:12:24 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Kreeft", "Jasper", ""], ["Gerritsma", "Marc", ""]]}, {"id": "1304.7479", "submitter": "Varun Shankar", "authors": "Varun Shankar, Grady B. Wright, Robert M. Kirby and Aaron L. Fogelson", "title": "Augmenting the Immersed Boundary Method with Radial Basis Functions\n  (RBFs) for the Modeling of Platelets in Hemodynamic Flows", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new computational method by extending the Immersed Boundary (IB)\nmethod with a spectrally-accurate geometric model based on Radial Basis\nFunction (RBF) interpolation of the Lagrangian structures. Our specific\nmotivation is the modeling of platelets in hemodynamic flows, though we\nanticipate that our method will be useful in other applications as well. The\nefficacy of our new RBF-IB method is shown through a series of numerical\nexperiments. Specifically, we compare our method with the traditional IB method\nin terms of convergence and accuracy, computational cost, maximum stable\ntime-step size and volume loss. We conclude that the RBF-IB method has\nadvantages over the traditional Immersed Boundary method, and is well-suited\nfor modeling of platelets in hemodynamic flows.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2013 15:31:46 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 08:52:09 GMT"}, {"version": "v3", "created": "Mon, 25 May 2015 22:14:10 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Shankar", "Varun", ""], ["Wright", "Grady B.", ""], ["Kirby", "Robert M.", ""], ["Fogelson", "Aaron L.", ""]]}, {"id": "1304.8069", "submitter": "Alexander Kobel", "authors": "Alexander Kobel, Michael Sagraloff", "title": "Fast Approximate Polynomial Multipoint Evaluation and Applications", "comments": "minor editorial changes over the first version: revised references\n  and mentioned related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.SC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that, using fast algorithms for polynomial multiplication\nand division, evaluation of a polynomial $F \\in \\mathbb{C}[x]$ of degree $n$ at\n$n$ complex-valued points can be done with $\\tilde{O}(n)$ exact field\noperations in $\\mathbb{C},$ where $\\tilde{O}(\\cdot)$ means that we omit\npolylogarithmic factors. We complement this result by an analysis of\napproximate multipoint evaluation of $F$ to a precision of $L$ bits after the\nbinary point and prove a bit complexity of $\\tilde{O}(n(L + \\tau + n\\Gamma)),$\nwhere $2^\\tau$ and $2^\\Gamma,$ with $\\tau, \\Gamma \\in \\mathbb{N}_{\\ge 1},$ are\nbounds on the magnitude of the coefficients of $F$ and the evaluation points,\nrespectively. In particular, in the important case where the precision demand\ndominates the other input parameters, the complexity is soft-linear in $n$ and\n$L$.\n  Our result on approximate multipoint evaluation has some interesting\nconsequences on the bit complexity of further approximation algorithms which\nall use polynomial evaluation as a key subroutine. Of these applications, we\ndiscuss in detail an algorithm for polynomial interpolation and for computing a\nTaylor shift of a polynomial. Furthermore, our result can be used to derive\nimproved complexity bounds for algorithms to refine isolating intervals for the\nreal roots of a polynomial. For all of the latter algorithms, we derive\nnear-optimal running times.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 17:01:11 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 09:11:12 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Kobel", "Alexander", ""], ["Sagraloff", "Michael", ""]]}]