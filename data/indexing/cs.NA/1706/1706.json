[{"id": "1706.00578", "submitter": "Thomas-Peter Fries", "authors": "T.P. Fries, S. Omerovi\\'c, D. Sch\\\"ollhammer, J. Steidl", "title": "Higher-order meshing of implicit geometries - part I: Integration and\n  interpolation in cut elements", "comments": "Published in Comp. Methods Appl. Mech. Engrg", "journal-ref": "Comp. Methods Appl. Mech. Engrg., volume 313, pages 759-784 (2017)", "doi": "10.1016/j.cma.2016.10.019", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate implicit description of geometries is enabled by the level-set\nmethod. Level-set data is given at the nodes of a higher-order background mesh\nand the interpolated zero-level sets imply boundaries of the domain or\ninterfaces within. The higher-order accurate integration of elements cut by the\nzero-level sets is described. The proposed strategy relies on an automatic\nmeshing of the cut elements. Firstly, the zero-level sets are identified and\nmeshed by higher-order interface elements. Secondly, the cut elements are\ndecomposed into conforming sub-elements on the two sides of the zero-level\nsets. Any quadrature rule may then be employed within the sub-elements. The\napproach is described in two and three dimensions without any requirements on\nthe background meshes. Special attention is given to the consideration of\ncorners and edges of the implicit geometries.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 07:50:13 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Fries", "T. P.", ""], ["Omerovi\u0107", "S.", ""], ["Sch\u00f6llhammer", "D.", ""], ["Steidl", "J.", ""]]}, {"id": "1706.00692", "submitter": "Eric Polizzi", "authors": "Brendan Gavin, Eric Polizzi", "title": "An improved Krylov eigenvalue strategy using the FEAST algorithm with\n  inexact system solves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FEAST eigenvalue algorithm is a subspace iteration algorithm that uses\ncontour integration in the complex plane to obtain the eigenvectors of a matrix\nfor the eigenvalues that are located in any user-defined search interval. By\ncomputing small numbers of eigenvalues in specific regions of the complex\nplane, FEAST is able to naturally parallelize the solution of eigenvalue\nproblems by solving for multiple eigenpairs simultaneously. The traditional\nFEAST algorithm is implemented by directly solving collections of shifted\nlinear systems of equations; in this paper, we describe a variation of the\nFEAST algorithm that uses iterative Krylov subspace algorithms for solving the\nshifted linear systems inexactly. We show that this iterative FEAST algorithm\n(which we call IFEAST) is mathematically equivalent to a block Krylov subspace\nmethod for solving eigenvalue problems. By using Krylov subspaces indirectly\nthrough solving shifted linear systems, rather than directly for projecting the\neigenvalue problem, IFEAST is able to solve eigenvalue problems using very\nlarge dimension Krylov subspaces, without ever having to store a basis for\nthose subspaces. IFEAST thus combines the flexibility and power of Krylov\nmethods, requiring only matrix-vector multiplication for solving eigenvalue\nproblems, with the natural parallelism of the traditional FEAST algorithm. We\ndiscuss the relationship between IFEAST and more traditional Krylov methods,\nand provide numerical examples illustrating its behavior.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 14:16:50 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Gavin", "Brendan", ""], ["Polizzi", "Eric", ""]]}, {"id": "1706.00840", "submitter": "Thomas-Peter Fries", "authors": "T.P. Fries, D. Sch\\\"ollhammer", "title": "Higher-order meshing of implicit geometries - part II: Approximations on\n  manifolds", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2017.07.037", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new concept for the higher-order accurate approximation of partial\ndifferential equations on manifolds is proposed where a surface mesh composed\nby higher-order elements is automatically generated based on level-set data.\nThereby, it enables a completely automatic workflow from the geometric\ndescription to the numerical analysis without any user-intervention. A master\nlevel-set function defines the shape of the manifold through its\nzero-isosurface which is then restricted to a finite domain by additional\nlevel-set functions. It is ensured that the surface elements are sufficiently\ncontinuous and shape regular which is achieved by manipulating the background\nmesh. The numerical results show that optimal convergence rates are obtained\nwith a moderate increase in the condition number compared to handcrafted\nsurface meshes.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 20:20:59 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Fries", "T. P.", ""], ["Sch\u00f6llhammer", "D.", ""]]}, {"id": "1706.00919", "submitter": "Thomas-Peter Fries", "authors": "T.P. Fries", "title": "Higher-order meshing of implicit geometries - part III: Conformal\n  Decomposition FEM (CDFEM)", "comments": "Article submitted to Comp. Methods Appl. Mech. Engrg. with a slightly\n  different title \"Higher-order Conformal Decomposition FEM (CDFEM)\" because\n  part II of the series is not yet accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A higher-order accurate finite element method is proposed which uses\nautomatically generated meshes based on implicit level-set data for the\ndescription of boundaries and interfaces in two and three dimensions. The\nmethod is an alternative for fictitious domain and extended finite element\nmethods. The domain of interest is immersed in a background mesh composed by\nhigher-order elements. The zero-level sets are identified and meshed followed\nby a decomposition of the cut background elements into conforming sub-elements.\nAdaptivity is a crucial ingredient of the method to guarantee the success of\nthe mesh generation. It ensures the successful decomposition of cut elements\nand enables improved geometry descriptions and approximations. It is confirmed\nthat higher-order accurate results with optimal convergence rates are achieved\nwith the proposed conformal decomposition finite element method (CDFEM).\n", "versions": [{"version": "v1", "created": "Sat, 3 Jun 2017 09:50:57 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Fries", "T. P.", ""]]}, {"id": "1706.01108", "submitter": "Peter Richt\\'arik", "authors": "Peter Richt\\'arik and Martin Tak\\'a\\v{c}", "title": "Stochastic Reformulations of Linear Systems: Algorithms and Convergence\n  Theory", "comments": "Accepted to SIAM Journal on Matrix Analysis and Applications. This\n  arXiv version has an additional section (Section 6.2), listing several\n  extensions done since the paper was first written. Statistics: 39 pages, 4\n  reformulations, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a family of reformulations of an arbitrary consistent linear\nsystem into a stochastic problem. The reformulations are governed by two\nuser-defined parameters: a positive definite matrix defining a norm, and an\narbitrary discrete or continuous distribution over random matrices. Our\nreformulation has several equivalent interpretations, allowing for researchers\nfrom various communities to leverage their domain specific insights. In\nparticular, our reformulation can be equivalently seen as a stochastic\noptimization problem, stochastic linear system, stochastic fixed point problem\nand a probabilistic intersection problem. We prove sufficient, and necessary\nand sufficient conditions for the reformulation to be exact. Further, we\npropose and analyze three stochastic algorithms for solving the reformulated\nproblem---basic, parallel and accelerated methods---with global linear\nconvergence rates. The rates can be interpreted as condition numbers of a\nmatrix which depends on the system matrix and on the reformulation parameters.\nThis gives rise to a new phenomenon which we call stochastic preconditioning,\nand which refers to the problem of finding parameters (matrix and distribution)\nleading to a sufficiently small condition number. Our basic method can be\nequivalently interpreted as stochastic gradient descent, stochastic Newton\nmethod, stochastic proximal point method, stochastic fixed point method, and\nstochastic projection method, with fixed stepsize (relaxation parameter),\napplied to the reformulations.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 17:04:15 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 04:44:19 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 11:21:42 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 16:50:14 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Richt\u00e1rik", "Peter", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1706.01169", "submitter": "Cun Mu", "authors": "Cun Mu, Daniel Hsu and Donald Goldfarb", "title": "Greedy Approaches to Symmetric Orthogonal Tensor Decomposition", "comments": "To appear in SIAM Journal on Matrix Analysis and Applications (SIMAX)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the symmetric and orthogonal decomposition (SOD) of a tensor is a\nrecurring problem in signal processing, machine learning and statistics. In\nthis paper, we review, establish and compare the perturbation bounds for two\nnatural types of incremental rank-one approximation approaches. Numerical\nexperiments and open questions are also presented and discussed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 00:31:10 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Mu", "Cun", ""], ["Hsu", "Daniel", ""], ["Goldfarb", "Donald", ""]]}, {"id": "1706.01176", "submitter": "Gang Wu", "authors": "Najmeh Azizi Zadeh, Azita Tajaddini, Gang Wu", "title": "A weighted global GMRES algorithm with deflation for solving large\n  Sylvester matrix equations", "comments": "20 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The solution of large scale Sylvester matrix equation plays an important role\nin control and large scientific computations. A popular approach is to use the\nglobal GMRES algorithm. In this work, we first consider the global GMRES\nalgorithm with weighting strategy, and propose some new schemes based on\nresidual to update the weighting matrix. Due to the growth of memory\nrequirements and computational cost, it is necessary to restart the algorithm\nefficiently. The deflation strategy is popular for the solution of large linear\nsystems and large eigenvalue problems, to the best of our knowledge, little\nwork is done on applying deflation to the global GMRES algorithm for large\nSylvester matrix equations. We then consider how to combine the weighting\nstrategy with deflated restarting, and propose a weighted global GMRES\nalgorithm with deflation for solving large Sylvester matrix equations.\nTheoretical analysis is given to show why the new algorithm works effectively.\nFurther, unlike the weighted GMRES-DR presented in [{\\sc M. Embree, R. B.\nMorgan and H. V. Nguyen}, {\\em Weighted inner products for GMRES and GMRES-DR},\n(2017), arXiv:1607.00255v2], we show that in our new algorithm, there is no\nneed to change the inner product with respect to diagonal matrix to that with\nnon-diagonal matrix, and our scheme is much cheaper. Numerical examples\nillustrate the numerical behavior of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 02:16:43 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Zadeh", "Najmeh Azizi", ""], ["Tajaddini", "Azita", ""], ["Wu", "Gang", ""]]}, {"id": "1706.01344", "submitter": "Pierre-Alexandre Beaufort Ir", "authors": "Pierre-Alexandre Beaufort, Christos Georgiadis Jonathan Lambrechts,\n  Fran\\c{c}ois Henrotte, Christophe Geuzaine, Jean-Fran\\c{c}ois Remacle", "title": "Computing cross fields -- A PDE approach based on the Ginzburg-Landau\n  theory", "comments": "Promoted version of: Proceeding for the 26th International Meshing\n  Roundtable, IMR26, 18-21 September 2017, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to compute crossfields based on the\nGinzburg-Landau theory. The Ginzburg-Landau functional has two terms: the\nDirichlet energy of the distribution and a term penalizing the mismatch between\nthe fixed and actual norm of the distribution. Directional fields on surfaces\nare known to have a number of critical points, which are properly identified\nwith the Ginzburg-Landau approach: the asymptotic behavior of Ginzburg-Landau\nproblem provides well-distributed critical points over the 2-manifold, whose\nindices are as low as possible. The central idea in this paper is to exploit\nthis theoretical background for crossfield computation on arbitrary surfaces.\nSuch crossfields are instrumental in the generation of meshes with quadrangular\nelements. The relation between the topological properties of quadrangular\nmeshes and crossfields are hence first recalled. It is then shown that a\ncrossfield on a surface can be represented by a complex function of unit norm\nwith a number of critical points, i.e., a nearly everywhere smooth function\ntaking its values in the unit circle of the complex plane. As maximal\nsmoothness of the crossfield is equivalent with minimal energy, the crossfield\nproblem is equivalent to an optimization problem based on Ginzburg-Landau\nfunctional. A discretization scheme with Crouzeix-Raviart elements is applied\nand the correctness of the resulting finite element formulation is validated on\nthe unit disk by comparison with an analytical solution. The method is also\napplied to the 2-sphere where, surprisingly but rightly, the computed critical\npoints are not located at the vertices of a cube, but at those of an anticube.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 13:49:39 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 08:07:02 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 14:59:02 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Beaufort", "Pierre-Alexandre", ""], ["Lambrechts", "Christos Georgiadis Jonathan", ""], ["Henrotte", "Fran\u00e7ois", ""], ["Geuzaine", "Christophe", ""], ["Remacle", "Jean-Fran\u00e7ois", ""]]}, {"id": "1706.01346", "submitter": "Lawrence Mitchell", "authors": "Robert C. Kirby and Lawrence Mitchell", "title": "Solver composition across the PDE/linear algebra barrier", "comments": "23 pages. Fixed axis labelling in Fig 3", "journal-ref": "SIAM Journal on Scientific Computing 40(1):C76-C98 (2018)", "doi": "10.1137/17M1133208", "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient solution of discretisations of coupled systems of partial\ndifferential equations (PDEs) is at the core of much of numerical simulation.\nSignificant effort has been expended on scalable algorithms to precondition\nKrylov iterations for the linear systems that arise. With few exceptions, the\nreported numerical implementation of such solution strategies is specific to a\nparticular model setup, and intimately ties the solver strategy to the\ndiscretisation and PDE, especially when the preconditioner requires auxiliary\noperators. In this paper, we present recent improvements in the Firedrake\nfinite element library that allow for straightforward development of the\nbuilding blocks of extensible, composable preconditioners that decouple the\nsolver from the model formulation. Our implementation extends the algebraic\ncomposability of linear solvers offered by the PETSc library by augmenting\noperators, and hence preconditioners, with the ability to provide any necessary\nauxiliary operators. Rather than specifying up front the full solver\nconfiguration, tied to the model, solvers can be developed independently of\nmodel formulation and configured at runtime. We illustrate with examples from\nincompressible fluids and temperature-driven convection.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 14:25:39 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 16:16:44 GMT"}, {"version": "v3", "created": "Wed, 8 Nov 2017 11:04:49 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Kirby", "Robert C.", ""], ["Mitchell", "Lawrence", ""]]}, {"id": "1706.01361", "submitter": "Li Chen", "authors": "Li Chen and Ruo Li and Feng Yang", "title": "An Integrated Quadratic Reconstruction for Finite Volume Schemes to\n  Scalar Conservation Laws in Multiple Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a piecewise quadratic reconstruction method in multiple\ndimensions, which is in an integrated style, for finite volume schemes to\nscalar conservation laws. This integrated quadratic reconstruction is\nparameter-free and applicable on flexible grids. We show that the finite volume\nschemes with the new reconstruction satisfy a local maximum principle with\nproperly setup on time steplength. Numerical examples are presented to show\nthat the proposed scheme attains a third-order accuracy for smooth solutions in\nboth 2D and 3D cases. It is indicated by numerical results that the local\nmaximum principle is helpful to prevent overshoots in numerical solutions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 14:58:49 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 13:55:38 GMT"}, {"version": "v3", "created": "Fri, 23 Jun 2017 05:04:29 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2020 09:03:47 GMT"}, {"version": "v5", "created": "Wed, 5 Aug 2020 23:49:05 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Chen", "Li", ""], ["Li", "Ruo", ""], ["Yang", "Feng", ""]]}, {"id": "1706.01613", "submitter": "Amaury Johnen", "authors": "Amaury Johnen, Jean-Christophe Weill, Jean-Fran\\c{c}ois Remacle", "title": "Robust and efficient validation of the linear hexahedral element", "comments": "13 pages, 7 figures. Submitted to the 26th International Meshing\n  Roundtable conference. V2: removed Appendix \"Derivatives of the Jacobian\n  determinant of a linear hexahedron\" and update acknowledgements. V3:\n  modifications in abstract, introduction and conclusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Checking mesh validity is a mandatory step before doing any finite element\nanalysis. If checking the validity of tetrahedra is trivial, checking the\nvalidity of hexahedral elements is far from being obvious. In this paper, a\nmethod that robustly and efficiently compute the validity of standard linear\nhexahedral elements is presented. This method is a significant improvement of a\nprevious work on the validity of curvilinear elements. The new implementation\nis simple and computationally efficient. The key of the algorithm is still to\ncompute B\\'ezier coefficients of the Jacobian determinant. We show that only 20\nJacobian determinants are necessary to compute the 27 B\\'ezier coefficients.\nThose 20 Jacobians can be efficiently computed by calculating the volume of 20\ntetrahedra. The new implementation is able to check the validity of about 6\nmillion hexahedra per second on one core of a personal computer. Through the\npaper, all the necessary information is provided that allow to easily reproduce\nthe results, \\ie write a simple code that takes the coordinates of 8 points as\ninput and outputs the validity of the hexahedron.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 06:14:10 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 09:07:35 GMT"}, {"version": "v3", "created": "Mon, 7 Aug 2017 13:49:16 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Johnen", "Amaury", ""], ["Weill", "Jean-Christophe", ""], ["Remacle", "Jean-Fran\u00e7ois", ""]]}, {"id": "1706.02069", "submitter": "Youhei Akimoto", "authors": "Youhei Akimoto", "title": "Fast Eigen Decomposition for Low-Rank Matrix Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an efficient algorithm to compute the eigen\ndecomposition of a matrix that is a weighted sum of the self outer products of\nvectors such as a covariance matrix of data. A well known algorithm to compute\nthe eigen decomposition of such matrices is though the singular value\ndecomposition, which is available only if all the weights are nonnegative. Our\nproposed algorithm accepts both positive and negative weights.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 07:24:49 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Akimoto", "Youhei", ""]]}, {"id": "1706.02205", "submitter": "Florian Sch\\\"afer", "authors": "Florian Sch\\\"afer and T. J. Sullivan and Houman Owhadi", "title": "Compression, inversion, and approximate PCA of dense kernel matrices at\n  near-linear computational complexity", "comments": "52 pages. A high level summary of this work can be found under\n  https://f-t-s.github.io/projects/cholesky/", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC cs.DS cs.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense kernel matrices $\\Theta \\in \\mathbb{R}^{N \\times N}$ obtained from\npoint evaluations of a covariance function $G$ at locations $\\{ x_{i} \\}_{1\n\\leq i \\leq N} \\subset \\mathbb{R}^{d}$ arise in statistics, machine learning,\nand numerical analysis. For covariance functions that are Green's functions of\nelliptic boundary value problems and homogeneously-distributed sampling points,\nwe show how to identify a subset $S \\subset \\{ 1 , \\dots , N \\}^2$, with $\\# S\n= O ( N \\log (N) \\log^{d} ( N /\\epsilon ) )$, such that the zero fill-in\nincomplete Cholesky factorisation of the sparse matrix $\\Theta_{ij} 1_{( i, j )\n\\in S}$ is an $\\epsilon$-approximation of $\\Theta$. This factorisation can\nprovably be obtained in complexity $O ( N \\log( N ) \\log^{d}( N /\\epsilon) )$\nin space and $O ( N \\log^{2}( N ) \\log^{2d}( N /\\epsilon) )$ in time, improving\nupon the state of the art for general elliptic operators; we further present\nnumerical evidence that $d$ can be taken to be the intrinsic dimension of the\ndata set rather than that of the ambient space. The algorithm only needs to\nknow the spatial configuration of the $x_{i}$ and does not require an analytic\nrepresentation of $G$. Furthermore, this factorization straightforwardly\nprovides an approximate sparse PCA with optimal rate of convergence in the\noperator norm. Hence, by using only subsampling and the incomplete Cholesky\nfactorization, we obtain, at nearly linear complexity, the compression,\ninversion and approximate PCA of a large class of covariance matrices. By\ninverting the order of the Cholesky factorization we also obtain a solver for\nelliptic PDE with complexity $O ( N \\log^{d}( N /\\epsilon) )$ in space and $O (\nN \\log^{2d}( N /\\epsilon) )$ in time, improving upon the state of the art for\ngeneral elliptic operators.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 14:26:14 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 22:22:57 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2019 19:36:49 GMT"}, {"version": "v4", "created": "Wed, 6 May 2020 20:11:23 GMT"}, {"version": "v5", "created": "Fri, 30 Oct 2020 18:34:14 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Sch\u00e4fer", "Florian", ""], ["Sullivan", "T. J.", ""], ["Owhadi", "Houman", ""]]}, {"id": "1706.02374", "submitter": "Liu Yanli", "authors": "Yanli Liu, Ernest K. Ryu, and Wotao Yin", "title": "A New Use of Douglas-Rachford Splitting and ADMM for Identifying\n  Infeasible, Unbounded, and Pathological Conic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method for identifying infeasible, unbounded, and\npathological conic programs based on Douglas-Rachford splitting, or\nequivalently ADMM. When an optimization program is infeasible, unbounded, or\npathological, the iterates of Douglas-Rachford splitting diverge. Somewhat\nsurprisingly, such divergent iterates still provide useful information, which\nour method uses for identification. In addition, for strongly infeasible\nproblems the method produces a separating hyperplane and informs the user on\nhow to minimally modify the given problem to achieve strong feasibility. As a\nfirst-order method, the proposed algorithm relies on simple subroutines, and\ntherefore is simple to implement and has low per-iteration cost.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 20:35:49 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 20:25:42 GMT"}, {"version": "v3", "created": "Sun, 15 Oct 2017 17:54:28 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Liu", "Yanli", ""], ["Ryu", "Ernest K.", ""], ["Yin", "Wotao", ""]]}, {"id": "1706.02808", "submitter": "Art Owen", "authors": "Art B. Owen", "title": "A randomized Halton algorithm in R", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized quasi-Monte Carlo (RQMC) sampling can bring orders of magnitude\nreduction in variance compared to plain Monte Carlo (MC) sampling. The extent\nof the efficiency gain varies from problem to problem and can be hard to\npredict. This article presents an R function rhalton that produces scrambled\nversions of Halton sequences. On some problems it brings efficiency gains of\nseveral thousand fold. On other problems, the efficiency gain is minor. The\ncode is designed to make it easy to determine whether a given integrand will\nbenefit from RQMC sampling. An RQMC sample of n points in $[0,1]^d$ can be\nextended later to a larger n and/or d.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 01:44:03 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 22:04:44 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Owen", "Art B.", ""]]}, {"id": "1706.02869", "submitter": "Zheng Xu", "authors": "Zheng Xu, Gavin Taylor, Hao Li, Mario Figueiredo, Xiaoming Yuan, Tom\n  Goldstein", "title": "Adaptive Consensus ADMM for Distributed Optimization", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alternating direction method of multipliers (ADMM) is commonly used for\ndistributed model fitting problems, but its performance and reliability depend\nstrongly on user-defined penalty parameters. We study distributed ADMM methods\nthat boost performance by using different fine-tuned algorithm parameters on\neach worker node. We present a O(1/k) convergence rate for adaptive ADMM\nmethods with node-specific parameters, and propose adaptive consensus ADMM\n(ACADMM), which automatically tunes parameters without user oversight.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 08:52:37 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 05:22:11 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Xu", "Zheng", ""], ["Taylor", "Gavin", ""], ["Li", "Hao", ""], ["Figueiredo", "Mario", ""], ["Yuan", "Xiaoming", ""], ["Goldstein", "Tom", ""]]}, {"id": "1706.03147", "submitter": "Yu-Hong Yeung", "authors": "Yu-Hong Yeung (1), Alex Pothen (1), Mahantesh Halappanavar (2) and\n  Zhenyu Huang (2) ((1) Purdue University, (2) Pacific Northwest National\n  Laboratory)", "title": "AMPS: An Augmented Matrix Formulation for Principal Submatrix Updates\n  with Application to Power Grids", "comments": "19 pages, 4 figures, 2 tables, SIAM Journal on Scientific Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AMPS, an augmented matrix approach to update the solution to a\nlinear system of equations when the matrix is modified by a few elements within\na principal submatrix. This problem arises in the dynamic security analysis of\na power grid, where operators need to perform N - k contingency analysis, i.e.,\ndetermine the state of the system when exactly k links from N fail. Our\nalgorithms augment the matrix to account for the changes in it, and then\ncompute the solution to the augmented system without refactoring the modified\nmatrix. We provide two algorithms, a direct method, and a hybrid\ndirect-iterative method for solving the augmented system. We also exploit the\nsparsity of the matrices and vectors to accelerate the overall computation. We\nanalyze the time complexity of both algorithms, and show that it is bounded by\nthe number of nonzeros in a subset of the columns of the Cholesky factor that\nare selected by the nonzeros in the sparse right-hand-side vector. Our\nalgorithms are compared on three power grids with PARDISO, a parallel direct\nsolver, and CHOLMOD, a direct solver with the ability to modify the Cholesky\nfactors of the matrix. We show that our augmented algorithms outperform PARDISO\n(by two orders of magnitude), and CHOLMOD (by a factor of up to 5). Further,\nour algorithms scale better than CHOLMOD as the number of elements updated\nincreases. The solutions are computed with high accuracy. Our algorithms are\ncapable of computing N - k contingency analysis on a 778 thousand bus grid,\nupdating a solution with k = 20 elements in 16 milliseconds on an Intel Xeon\nprocessor.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 22:41:27 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Yeung", "Yu-Hong", ""], ["Pothen", "Alex", ""], ["Halappanavar", "Mahantesh", ""], ["Huang", "Zhenyu", ""]]}, {"id": "1706.03203", "submitter": "Luca Bonaventura", "authors": "Luca Bonaventura, Roberto Ferretti, Lorenzo Rocchi", "title": "A fully semi-Lagrangian discretization for the 2D Navier--Stokes\n  equations in the vorticity--streamfunction formulation", "comments": null, "journal-ref": null, "doi": "10.1016/j.amc.2017.11.030", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A numerical method for the two-dimensional, incompressible Navier--Stokes\nequations in vorticity--streamfunction form is proposed, which employs\nsemi-Lagrangian discretizations for both the advection and diffusion terms,\nthus achieving unconditional stability without the need to solve linear systems\nbeyond that required by the Poisson solver for the reconstruction of the\nstreamfunction. A description of the discretization of Dirichlet boundary\nconditions for the semi-Lagrangian approach to diffusion terms is also\npresented. Numerical experiments on classical benchmarks for incompressible\nflow in simple geometries validate the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 08:21:14 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Bonaventura", "Luca", ""], ["Ferretti", "Roberto", ""], ["Rocchi", "Lorenzo", ""]]}, {"id": "1706.03248", "submitter": "Caleb Magruder", "authors": "Caleb C. Magruder and Serkan Gugercin and Christopher A. Beattie", "title": "Linear time-periodic dynamical systems: An H2 analysis and a model\n  reduction framework", "comments": "Submitted to Mathematical and Computer Modeling of Dynamical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear time-periodic (LTP) dynamical systems frequently appear in the\nmodeling of phenomena related to fluid dynamics, electronic circuits, and\nstructural mechanics via linearization centered around known periodic orbits of\nnonlinear models. Such LTP systems can reach orders that make repeated\nsimulation or other necessary analysis prohibitive, motivating the need for\nmodel reduction.\n  We develop here an algorithmic framework for constructing reduced models that\nretains the linear time-periodic structure of the original LTP system. Our\napproach generalizes optimal approaches that have been established previously\nfor linear time-invariant (LTI) model reduction problems. We employ an\nextension of the usual H2 Hardy space defined for the LTI setting to\ntime-periodic systems and within this broader framework develop an a posteriori\nerror bound expressible in terms of related LTI systems. Optimization of this\nbound motivates our algorithm. We illustrate the success of our method on two\nnumerical examples.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 16:07:09 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Magruder", "Caleb C.", ""], ["Gugercin", "Serkan", ""], ["Beattie", "Christopher A.", ""]]}, {"id": "1706.03558", "submitter": "Mikael Laaksonen", "authors": "Harri Hakula and Mikael Laaksonen", "title": "Asymptotic convergence of spectral inverse iterations for stochastic\n  eigenvalue problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider and analyze applying a spectral inverse iteration algorithm and\nits subspace iteration variant for computing eigenpairs of an elliptic operator\nwith random coefficients. With these iterative algorithms the solution is\nsought from a finite dimensional space formed as the tensor product of the\napproximation space for the underlying stochastic function space, and the\napproximation space for the underlying spatial function space. Sparse\npolynomial approximation is employed to obtain the first one, while classical\nfinite elements are employed to obtain the latter. An error analysis is\npresented for the asymptotic convergence of the spectral inverse iteration to\nthe smallest eigenvalue and the associated eigenvector of the problem. A series\nof detailed numerical experiments supports the conclusions of this analysis.\nNumerical experiments are also presented for the spectral subspace iteration,\nand convergence of the algorithm is observed in an example case, where the\neigenvalues cross within the parameter space. The outputs of both algorithms\nare verified by comparing to solutions obtained by a sparse stochastic\ncollocation method.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 10:53:47 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Hakula", "Harri", ""], ["Laaksonen", "Mikael", ""]]}, {"id": "1706.04097", "submitter": "Yingyu Liang", "authors": "Yuanzhi Li, Yingyu Liang", "title": "Provable Alternating Gradient Descent for Non-negative Matrix\n  Factorization with Strong Correlations", "comments": "Accepted to the International Conference on Machine Learning (ICML),\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization is a basic tool for decomposing data into\nthe feature and weight matrices under non-negativity constraints, and in\npractice is often solved in the alternating minimization framework. However, it\nis unclear whether such algorithms can recover the ground-truth feature matrix\nwhen the weights for different features are highly correlated, which is common\nin applications. This paper proposes a simple and natural alternating gradient\ndescent based algorithm, and shows that with a mild initialization it provably\nrecovers the ground-truth in the presence of strong correlations. In most\ninteresting cases, the correlation can be in the same order as the highest\npossible. Our analysis also reveals its several favorable features including\nrobustness to noise. We complement our theoretical results with empirical\nstudies on semi-synthetic datasets, demonstrating its advantage over several\npopular methods in recovering the ground-truth.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 14:39:59 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Li", "Yuanzhi", ""], ["Liang", "Yingyu", ""]]}, {"id": "1706.04237", "submitter": "Xiantao Li", "authors": "Adam Telatovich and Xiantao Li", "title": "The strong convergence of operator-splitting methods for the Langevin\n  dynamics model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the strong convergence of some operator-splitting methods for the\nLangevin dynamics model with additive noise. It will be shown that a direct\nsplitting of deterministic and random terms, including the symmetric splitting\nmethods, only offers strong convergence of order 1. To improve the order of\nstrong convergence, a new class of operator-splitting methods based on Kunita's\nsolution representation are proposed. We present stochastic algorithms with\nstrong orders up to 3. Both mathematical analysis and numerical evidence are\nprovided to verify the desired order of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 19:46:39 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 02:19:53 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Telatovich", "Adam", ""], ["Li", "Xiantao", ""]]}, {"id": "1706.04680", "submitter": "Jelena Diakonikolas", "authors": "Jelena Diakonikolas and Lorenzo Orecchia", "title": "Accelerated Extra-Gradient Descent: A Novel Accelerated First-Order\n  Method", "comments": "Appeared in Proc. ITCS'18, conference version available at:\n  http://drops.dagstuhl.de/opus/volltexte/2018/8356/", "journal-ref": null, "doi": "10.4230/LIPIcs.ITCS.2018.23", "report-no": null, "categories": "math.OC cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel accelerated first-order method that achieves the\nasymptotically optimal convergence rate for smooth functions in the first-order\noracle model. To this day, Nesterov's Accelerated Gradient Descent (AGD) and\nvariations thereof were the only methods achieving acceleration in this\nstandard blackbox model. In contrast, our algorithm is significantly different\nfrom AGD, as it relies on a predictor-corrector approach similar to that used\nby Mirror-Prox [Nemirovski, 2004] and Extra-Gradient Descent [Korpelevich,\n1977] in the solution of convex-concave saddle point problems. For this reason,\nwe dub our algorithm Accelerated Extra-Gradient Descent (AXGD). Its\nconstruction is motivated by the discretization of an accelerated\ncontinuous-time dynamics [Krichene et al., 2015] using the classical method of\nimplicit Euler discretization. Our analysis explicitly shows the effects of\ndiscretization through a conceptually novel primal-dual viewpoint. Moreover, we\nshow that the method is quite general: it attains optimal convergence rates for\nother classes of objectives (e.g., those with generalized smoothness properties\nor that are non-smooth and Lipschitz-continuous) using the appropriate choices\nof step lengths. Finally, we present experiments showing that our algorithm\nmatches the performance of Nesterov's method, while appearing more robust to\nnoise in some cases.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 22:07:18 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 20:44:41 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Diakonikolas", "Jelena", ""], ["Orecchia", "Lorenzo", ""]]}, {"id": "1706.04685", "submitter": "Gabriel Schamberg", "authors": "Gabriel Schamberg, Demba Ba, Todd P. Coleman", "title": "A Modularized Efficient Framework for Non-Markov Time Series Estimation", "comments": "Made correction to residuals in Section III.D., fixed typos, and\n  added information on the official published version", "journal-ref": "IEEE Transactions on Signal Processing, vol. 66, no. 12, pp.\n  3140-3154, June 15, 2018", "doi": "10.1109/TSP.2018.2793870", "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a compartmentalized approach to finding the maximum a-posteriori\n(MAP) estimate of a latent time series that obeys a dynamic stochastic model\nand is observed through noisy measurements. We specifically consider modern\nsignal processing problems with non-Markov signal dynamics (e.g. group\nsparsity) and/or non-Gaussian measurement models (e.g. point process\nobservation models used in neuroscience). Through the use of auxiliary\nvariables in the MAP estimation problem, we show that a consensus formulation\nof the alternating direction method of multipliers (ADMM) enables iteratively\ncomputing separate estimates based on the likelihood and prior and subsequently\n\"averaging\" them in an appropriate sense using a Kalman smoother. As such, this\ncan be applied to a broad class of problem settings and only requires modular\nadjustments when interchanging various aspects of the statistical model. Under\nbroad log-concavity assumptions, we show that the separate estimation problems\nare convex optimization problems and that the iterative algorithm converges to\nthe MAP estimate. As such, this framework can capture non-Markov latent time\nseries models and non-Gaussian measurement models. We provide example\napplications involving (i) group-sparsity priors, within the context of\nelectrophysiologic specrotemporal estimation, and (ii) non-Gaussian measurement\nmodels, within the context of dynamic analyses of learning with neural spiking\nand behavioral observations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 22:27:35 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 18:58:05 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 17:40:48 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Schamberg", "Gabriel", ""], ["Ba", "Demba", ""], ["Coleman", "Todd P.", ""]]}, {"id": "1706.04957", "submitter": "Matthias Joachim Ehrhardt", "authors": "Antonin Chambolle, Matthias J. Ehrhardt, Peter Richt\\'arik,\n  Carola-Bibiane Sch\\\"onlieb", "title": "Stochastic Primal-Dual Hybrid Gradient Algorithm with Arbitrary Sampling\n  and Imaging Applications", "comments": "25 pages, 8 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic extension of the primal-dual hybrid gradient\nalgorithm studied by Chambolle and Pock in 2011 to solve saddle point problems\nthat are separable in the dual variable. The analysis is carried out for\ngeneral convex-concave saddle point problems and problems that are either\npartially smooth / strongly convex or fully smooth / strongly convex. We\nperform the analysis for arbitrary samplings of dual variables, and obtain\nknown deterministic results as a special case. Several variants of our\nstochastic method significantly outperform the deterministic variant on a\nvariety of imaging tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 16:43:16 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 12:16:17 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Chambolle", "Antonin", ""], ["Ehrhardt", "Matthias J.", ""], ["Richt\u00e1rik", "Peter", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1706.05736", "submitter": "Joel Tropp", "authors": "Joel A. Tropp, Alp Yurtsever, Madeleine Udell, Volkan Cevher", "title": "Fixed-Rank Approximation of a Positive-Semidefinite Matrix from\n  Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several important applications, such as streaming PCA and semidefinite\nprogramming, involve a large-scale positive-semidefinite (psd) matrix that is\npresented as a sequence of linear updates. Because of storage limitations, it\nmay only be possible to retain a sketch of the psd matrix. This paper develops\na new algorithm for fixed-rank psd approximation from a sketch. The approach\ncombines the Nystrom approximation with a novel mechanism for rank truncation.\nTheoretical analysis establishes that the proposed method can achieve any\nprescribed relative error in the Schatten 1-norm and that it exploits the\nspectral decay of the input matrix. Computer experiments show that the proposed\nmethod dominates alternative techniques for fixed-rank psd matrix approximation\nacross a wide range of examples.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 22:13:45 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Tropp", "Joel A.", ""], ["Yurtsever", "Alp", ""], ["Udell", "Madeleine", ""], ["Cevher", "Volkan", ""]]}, {"id": "1706.05988", "submitter": "Siegfried Cools", "authors": "Siegfried Cools, Wim Vanroose", "title": "Numerically Stable Variants of the Communication-hiding Pipelined\n  Conjugate Gradients Algorithm for the Parallel Solution of Large Scale\n  Symmetric Linear Systems", "comments": "18 pages, 4 figures, 4 algorithms, 1 table", "journal-ref": "Advances in Parallel Computing, volume 32, \"Parallel Computing is\n  Everywhere\", pp. 77-86, IOS Press Amsterdam, September 2017", "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By reducing the number of global synchronization bottlenecks per iteration\nand hiding communication behind useful computational work, pipelined Krylov\nsubspace methods achieve significantly improved parallel scalability on\npresent-day HPC hardware. However, this typically comes at the cost of a\nreduced maximal attainable accuracy. This paper presents and compares several\nstabilized versions of the communication-hiding pipelined Conjugate Gradients\nmethod. The main novel contribution of this work is the reformulation of the\nmulti-term recurrence pipelined CG algorithm by introducing shifts in the\nrecursions for specific auxiliary variables. These shifts reduce the\namplification of local rounding errors on the residual. The stability analysis\npresented in this work provides a rigorous method for selection of the optimal\nshift value in practice. It is shown that, given a proper choice for the shift\nparameter, the resulting shifted pipelined CG algorithm restores the attainable\naccuracy and displays nearly identical robustness to local rounding error\npropagation compared to classical CG. Numerical results on a variety of SPD\nbenchmark problems compare different stabilization techniques for the pipelined\nCG algorithm, showing that the shifted pipelined CG algorithm is able to attain\na high accuracy while displaying excellent parallel performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 14:45:00 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 12:18:12 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Cools", "Siegfried", ""], ["Vanroose", "Wim", ""]]}, {"id": "1706.06191", "submitter": "Niklas Kolbe", "authors": "Niklas Kolbe and Nikolaos Sfakianakis", "title": "An adaptive rectangular mesh administration and refinement technique\n  with application in cancer invasion models", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an administration technique for the bookkeeping of adaptive mesh\nrefinement on (hyper-)rectangular meshes. Our technique is a unified approach\nfor h-refinement on 1-, 2- and 3D domains, which is easy to use and avoids\ntraversing the connectivity graph of the ancestry of mesh cells. Due to the\nemployed rectangular mesh structure, the identification of the siblings and the\nneighbouring cells is greatly simplified. The administration technique is\nparticularly designed for smooth meshes, where the smoothness is dynamically\nused in the matrix operations. It has a small memory footprint that makes it\naffordable for a wide range of mesh resolutions over a large class of problems.\nWe present three applications of this technique, one of which addresses\nh-refinement and its benefits in a 2D tumour growth and invasion problem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 21:59:24 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 10:13:35 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kolbe", "Niklas", ""], ["Sfakianakis", "Nikolaos", ""]]}, {"id": "1706.06461", "submitter": "Shoham Sabach", "authors": "J\\'er\\^ome Bolte, Shoham Sabach, Marc Teboulle, Yakov Vaisbourd", "title": "First Order Methods beyond Convexity and Lipschitz Gradient Continuity\n  with Applications to Quadratic Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on nonconvex and nonsmooth minimization problems with a composite\nobjective, where the differentiable part of the objective is freed from the\nusual and restrictive global Lipschitz gradient continuity assumption. This\nlongstanding smoothness restriction is pervasive in first order methods (FOM),\nand was recently circumvent for convex composite optimization by Bauschke,\nBolte and Teboulle, through a simple and elegant framework which captures, all\nat once, the geometry of the function and of the feasible set. Building on this\nwork, we tackle genuine nonconvex problems. We first complement and extend\ntheir approach to derive a full extended descent lemma by introducing the\nnotion of smooth adaptable functions. We then consider a Bregman-based proximal\ngradient methods for the nonconvex composite model with smooth adaptable\nfunctions, which is proven to globally converge to a critical point under\nnatural assumptions on the problem's data. To illustrate the power and\npotential of our general framework and results, we consider a broad class of\nquadratic inverse problems with sparsity constraints which arises in many\nfundamental applications, and we apply our approach to derive new globally\nconvergent schemes for this class.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 14:21:27 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Bolte", "J\u00e9r\u00f4me", ""], ["Sabach", "Shoham", ""], ["Teboulle", "Marc", ""], ["Vaisbourd", "Yakov", ""]]}, {"id": "1706.07273", "submitter": "Thilo Moshagen", "authors": "Thilo Moshagen", "title": "On meeting Energy Balance Errors in Cosimulations", "comments": "37 pages. arXiv admin note: text overlap with arXiv:1704.06931", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In engineering, it is a common desire to couple existing simulation tools\ntogether into one big system by passing information from subsystems as\nparameters into the subsystems under influence. As executed at fixed time\npoints, this data exchange gives the global method a strong explicit component,\nand as flows of conserved quantities are passed across subsystem boundaries, it\nis not ensured that systemwide balances are fulfilled: the system is not solved\nas one single equation system. These balance errors can accumulate and make\nsimulation results inaccurate. Use of higher-order extrapolation in exchanged\ndata can reduce this problem but cannot solve it. The remaining balance error\nhas been handled in past work with balance correction methods which compensate\nthese errors by adding corrections for the balances to the signal in next\ncoupling time step. Further past work combined smooth extrapolation of\nexchanged data and balance correction. This gives rise to the problem that\nestablishing balance of one quantity a posteriori due to the time delay in\ngeneral cannot establish or even disturbs the balances of quantities that\ndepend on the exchanged quantities, usually energy. In this work, a method is\nsuggested which allows to choose the quantity that should be balanced to be\nthat energy, and to accurately balance it.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 09:46:37 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Moshagen", "Thilo", ""]]}, {"id": "1706.07632", "submitter": "Xiaozhe Hu", "authors": "Xiaozhe Hu, Carmen Rodrigo, Francisco J. Gaspar", "title": "Using hierarchical matrices in the solution of the time-fractional heat\n  equation by multigrid waveform relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with the efficient numerical solution of the time-fractional\nheat equation discretized on non-uniform temporal meshes. Non-uniform grids are\nessential to capture the singularities of \"typical\" solutions of\ntime-fractional problems. We propose an efficient space-time multigrid method\nbased on the waveform relaxation technique, which accounts for the nonlocal\ncharacter of the fractional differential operator. To maintain an optimal\ncomplexity, which can be obtained for the case of uniform grids, we approximate\nthe coefficient matrix corresponding to the temporal discretization by its\nhierarchical matrix (${\\cal H}$-matrix) representation. In particular, the\nproposed method has a computational cost of ${\\cal O}(k N M \\log(M))$, where\n$M$ is the number of time steps, $N$ is the number of spatial grid points, and\n$k$ is a parameter which controls the accuracy of the ${\\cal H}$-matrix\napproximation. The efficiency and the good convergence of the algorithm, which\ncan be theoretically justified by a semi-algebraic mode analysis, are\ndemonstrated through numerical experiments in both one- and two-dimensional\nspaces.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 10:56:22 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 12:57:05 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 15:30:44 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Hu", "Xiaozhe", ""], ["Rodrigo", "Carmen", ""], ["Gaspar", "Francisco J.", ""]]}, {"id": "1706.07883", "submitter": "Ruoxi Wang", "authors": "Ruoxi Wang, Yingzhou Li, Eric Darve", "title": "On the numerical rank of radial basis function kernels in high dimension", "comments": null, "journal-ref": "SIAM Journal on Matrix Analysis and Applications, 2018, Vol. 39,\n  No. 4 : pp. 1810-1835", "doi": "10.1137/17M1135803", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank approximations are popular methods to reduce the high computational\ncost of algorithms involving large-scale kernel matrices. The success of\nlow-rank methods hinges on the matrix rank of the kernel matrix, and in\npractice, these methods are effective even for high-dimensional datasets. Their\npractical success motivates our analysis of the function rank, an upper bound\nof the matrix rank. In this paper, we consider radial basis functions (RBF),\napproximate the RBF kernel with a low-rank representation that is a finite sum\nof separate products and provide explicit upper bounds on the function rank and\nthe $L_\\infty$ error for such approximations. Our three main results are as\nfollows. First, for a fixed precision, the function rank of RBFs, in the worst\ncase, grows polynomially with the data dimension. Second, precise error bounds\nfor the low-rank approximations in the $L_\\infty$ norm are derived in terms of\nthe function smoothness and the domain diameters. Finally, a group pattern in\nthe magnitude of singular values for RBF kernel matrices is observed and\nanalyzed, and is explained by a grouping of the expansion terms in the kernel's\nlow-rank representation. Empirical results verify the theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 23:12:54 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 20:36:29 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 23:17:52 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Wang", "Ruoxi", ""], ["Li", "Yingzhou", ""], ["Darve", "Eric", ""]]}, {"id": "1706.08004", "submitter": "Vitoriano Ruas", "authors": "Vitoriano Ruas", "title": "Methods of arbitrary optimal order with tetrahedral finite-element\n  meshes forming polyhedral approximations of curved domains", "comments": "Version 2 resulted from a mere revision of Version 1. Version 3\n  incorporated several new results, mainly a lengthy L2-error analysis and a\n  numerical comparison with the isoparametric technique. This fourth version\n  provides more detailed and accurate proofs enriched with two additional\n  figures, together with many new remarks and clarifcations", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent papers the author introduced a simple alternative to isoparametric\nfinite elements of the n-simplex type, to enhance the accuracy of\napproximations of second-order boundary value problems with Dirichlet\nconditions, posed in smooth curved domains. This technique is based upon\ntrial-functions consisting of piecewise polynomials defined on straight-edged\ntriangular or tetrahedral meshes, interpolating the Dirichlet boundary\nconditions at points of the true boundary. In contrast the test-functions are\ndefined upon the standard degrees of freedom associated with the underlying\nmethod for polytopic domains. While method's mathematical analysis for both\nsecond- and fourth-order problems in two-dimensional domains was carried out in\narxiv NA-1701.00663 and in a submitted paper, this article is devoted to the\nstudy of the three-dimensional case, in which the method is nonconforming.\nWell-posedness, uniform stability and optimal a priori error estimates in the\nenergy norm are demonstrated for a tetrahedron-based Lagrange family of finite\nelements. Novel L2-error estimates for the class of problems considered in this\nwork are also proved. A series of numerical examples illustrates the potential\nof the new technique. In particular its better accuracy at equivalent cost as\ncompared to the isoparametric technique is highlighted. Moreover the great\ngenerality of the new approach is exemplified through a method with degrees of\nfreedom other than nodal values.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 21:13:42 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 13:51:16 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 20:59:59 GMT"}, {"version": "v4", "created": "Tue, 24 Mar 2020 03:28:37 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Ruas", "Vitoriano", ""]]}, {"id": "1706.08569", "submitter": "Saverio Perugini", "authors": "Tyler M. Masthay and Saverio Perugini", "title": "Parareal Algorithm Implementation and Simulation in Julia", "comments": "6 pages, 2 figures, 2 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a full implementation of the parareal algorithm---an integration\ntechnique to solve differential equations in parallel---in the Julia\nprogramming language for a fully general, first-order, initial-value problem.\nWe provide a brief overview of Julia---a concurrent programming language for\nscientific computing. Our implementation of the parareal algorithm accepts both\ncoarse and fine integrators as functional arguments. We use Euler's method and\nanother Runge-Kutta integration technique as the integrators in our\nexperiments. We also present a simulation of the algorithm for purposes of\npedagogy and as a tool for investigating the performance of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 19:27:58 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 20:21:25 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Masthay", "Tyler M.", ""], ["Perugini", "Saverio", ""]]}, {"id": "1706.08841", "submitter": "Allen Tannenbaum", "authors": "Yongxin Chen, Eldad Haber, Kaoru Yamamoto, Tryphon T. Georgiou, and\n  Allen Tannenbaum", "title": "An Efficient Algorithm for Matrix-Valued and Vector-Valued Optimal Mass\n  Transport", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient algorithm for recent generalizations of optimal mass\ntransport theory to matrix-valued and vector-valued densities. These\ngeneralizations lead to several applications including diffusion tensor\nimaging, color images processing, and multi-modality imaging. The algorithm is\nbased on sequential quadratic programming (SQP). By approximating the Hessian\nof the cost and solving each iteration in an inexact manner, we are able to\nsolve each iteration with relatively low cost while still maintaining a fast\nconvergent rate. The core of the algorithm is solving a weighted Poisson\nequation, where different efficient preconditioners may be employed. We utilize\nincomplete Cholesky factorization, which yields an efficient and\nstraightforward solver for our problem. Several illustrative examples are\npresented for both the matrix and vector-valued cases.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:00:36 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Chen", "Yongxin", ""], ["Haber", "Eldad", ""], ["Yamamoto", "Kaoru", ""], ["Georgiou", "Tryphon T.", ""], ["Tannenbaum", "Allen", ""]]}, {"id": "1706.09776", "submitter": "Micha{\\l} Bosy", "authors": "Gabriel R. Barrenechea, Micha{\\l} Bosy and Victorita Dolean", "title": "Numerical assessment of two-level domain decomposition preconditioners\n  for incompressible Stokes and elasticity equations", "comments": null, "journal-ref": "Electronic Transactions on Numerical Analysis ETNA 49 (2018) 41-63", "doi": "10.1553/etna_vol49s41", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving the linear elasticity and Stokes equations by an optimal domain\ndecomposition method derived algebraically involves the use of non standard\ninterface conditions. The one-level domain decomposition preconditioners are\nbased on the solution of local problems. This has the undesired consequence\nthat the results are not scalable, it means that the number of iterations\nneeded to reach convergence increases with the number of subdomains. This is\nthe reason why in this work we introduce, and test numerically, two-level\npreconditioners. Such preconditioners use a coarse space in their construction.\nWe consider the nearly incompressible elasticity problems and Stokes equations,\nand discretise them by using two finite element methods, namely, the hybrid\ndiscontinuous Galerkin and Taylor-Hood discretisations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 14:35:02 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Barrenechea", "Gabriel R.", ""], ["Bosy", "Micha\u0142", ""], ["Dolean", "Victorita", ""]]}]