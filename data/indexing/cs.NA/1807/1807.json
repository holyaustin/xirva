[{"id": "1807.00091", "submitter": "Chaolong Jiang", "authors": "Chaolong Jiang and Yongzhong Song and Yushun Wang", "title": "A linearized and conservative Fourier pseudo-spectral method for the\n  damped nonlinear Schr\\\"{o}dinger equation in three dimensions", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a linearized Fourier pseudo-spectral method, which\npreserves the total mass and energy conservation laws, for the damped nonlinear\nSchr\\\"{o}dinger equation in three dimensions. With the aid of the semi-norm\nequivalence between the Fourier pseudo-spectral method and the finite\ndifference method, an optimal $L^2$-error estimate for the proposed method\nwithout any restriction on the grid ratio is established by analyzing the real\nand imaginary parts of the error function. Numerical results are addressed to\nconfirm our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 00:11:04 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 13:11:43 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 02:39:47 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Jiang", "Chaolong", ""], ["Song", "Yongzhong", ""], ["Wang", "Yushun", ""]]}, {"id": "1807.00261", "submitter": "Huan Li", "authors": "Huan Li and Zhouchen Lin", "title": "On the Complexity Analysis of the Primal Solutions for the Accelerated\n  Randomized Dual Coordinate Ascent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual first-order methods are essential techniques for large-scale constrained\nconvex optimization. However, when recovering the primal solutions, we need\n$T(\\epsilon^{-2})$ iterations to achieve an $\\epsilon$-optimal primal solution\nwhen we apply an algorithm to the non-strongly convex dual problem with\n$T(\\epsilon^{-1})$ iterations to achieve an $\\epsilon$-optimal dual solution,\nwhere $T(x)$ can be $x$ or $\\sqrt{x}$. In this paper, we prove that the\niteration complexity of the primal solutions and dual solutions have the same\n$O\\left(\\frac{1}{\\sqrt{\\epsilon}}\\right)$ order of magnitude for the\naccelerated randomized dual coordinate ascent. When the dual function further\nsatisfies the quadratic functional growth condition, by restarting the\nalgorithm at any period, we establish the linear iteration complexity for both\nthe primal solutions and dual solutions even if the condition number is\nunknown. When applied to the regularized empirical risk minimization problem,\nwe prove the iteration complexity of $O\\left(n\\log\nn+\\sqrt{\\frac{n}{\\epsilon}}\\right)$ in both primal space and dual space, where\n$n$ is the number of samples. Our result takes out the $\\left(\\log\n\\frac{1}{\\epsilon}\\right)$ factor compared with the methods based on\nsmoothing/regularization or Catalyst reduction. As far as we know, this is the\nfirst time that the optimal $O\\left(\\sqrt{\\frac{n}{\\epsilon}}\\right)$ iteration\ncomplexity in the primal space is established for the dual coordinate ascent\nbased stochastic algorithms. We also establish the accelerated linear\ncomplexity for some problems with nonsmooth loss, i.e., the least absolute\ndeviation and SVM.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 03:21:21 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 05:23:11 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Li", "Huan", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1807.00402", "submitter": "Giovanni Migliorati", "authors": "Giovanni Migliorati", "title": "Adaptive approximation by optimal weighted least squares methods", "comments": "the version of the manuscript accepted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given any domain $X\\subseteq \\mathbb{R}^d$ and a probability measure $\\rho$\non $X$, we study the problem of approximating in $L^2(X,\\rho)$ a given function\n$u:X\\to\\mathbb{R}$, using its noiseless pointwise evaluations at random\nsamples. For any given linear space $V\\subset L^2(X,\\rho)$ with dimension $n$,\nprevious works have shown that stable and optimally converging Weighted\nLeast-Squares (WLS) estimators can be constructed using $m$ random samples\ndistributed according to an auxiliary probability measure $\\mu$ that depends on\n$V$, with $m$ being linearly proportional to $n$ up to a logarithmic term. As a\nfirst contribution, we present novel results on the stability and accuracy of\nWLS estimators with a given approximation space, using random samples that are\nmore structured than those used in the previous analysis. As a second\ncontribution, we study approximation by WLS estimators in the adaptive setting.\nFor any sequence of nested spaces $(V_k)_{k} \\subset L^2(X,\\rho)$, we show that\na sequence of WLS estimators of $u$, one for each space $V_k$, can be\nsequentially constructed such that: i) the estimators remain provably stable\nwith high probability and optimally converging in expectation, simultaneously\nfor all iterations from one to $k$, and ii) the overall number of samples\nnecessary to construct all the first $k$ estimators remains linearly\nproportional to the dimension of $V_k$. We propose two sampling algorithms that\nachieve this goal. The first one is a purely random algorithm that recycles\nmost of the samples from the previous iterations. The second algorithm recycles\nall the samples from all the previous iterations. Such an achievement is made\npossible by crucially exploiting the structure of the random samples. Finally\nwe develop numerical methods for the adaptive approximation of functions in\nhigh dimension.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 21:51:46 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 10:25:37 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Migliorati", "Giovanni", ""]]}, {"id": "1807.00440", "submitter": "Aslam Abdullah", "authors": "Aslam Abdullah", "title": "Influence of the Forward Difference Scheme for the Time Derivative on\n  the Stability of Wave Equation Numerical Solution", "comments": "5 pages, 1 figure, 1 table, 45 equations, 15 references, not yet\n  published anywhere else", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on numerical stability of difference equations has been quite\nintensive in the past century. The choice of difference schemes for the\nderivative terms in these equations contributes to a wide range of the\nstability analysis issues - one of which is how a chosen scheme may directly or\nindirectly contribute to such stability. In the present paper, how far the\nforward difference scheme for the time derivative in the wave equation\ninfluences the stability of the equation numerical solution, is particularly\ninvestigated. The stability analysis of the corresponding difference equation\ninvolving four schemes, namely Lax's, central, forward, and rearward\ndifferences, were carried out, and the resulting stability criteria were\ncompared. The results indicate that the instability of the solution of wave\nequation is not always due to the forward difference scheme for the time\nderivative. Rather, it is shown in this paper that the stability criterion is\nstill possible when the spatial derivative is represented by an appropriate\ndifference scheme. This sheds light on the degree of applicability of a\ndifference scheme for a hyperbolic equation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 02:43:01 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Abdullah", "Aslam", ""]]}, {"id": "1807.00653", "submitter": "Andre Gustavo Carlon", "authors": "Andre Gustavo Carlon, Ben Mansour Dia, Luis FR Espath, Rafael Holdorf\n  Lopez, and Raul Tempone", "title": "Nesterov-aided Stochastic Gradient Methods using Laplace Approximation\n  for Bayesian Design Optimization", "comments": "36 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the best setup for experiments is the primary concern for Optimal\nExperimental Design (OED). Here, we focus on the Bayesian experimental design\nproblem of finding the setup that maximizes the Shannon expected information\ngain. We use the stochastic gradient descent and its accelerated counterpart,\nwhich employs Nesterov's method, to solve the optimization problem in OED. We\nadapt a restart technique, originally proposed for the acceleration in\ndeterministic optimization, to improve stochastic optimization methods. We\ncombine these optimization methods with three estimators of the objective\nfunction: the double-loop Monte Carlo estimator (DLMC), the Monte Carlo\nestimator using the Laplace approximation for the posterior distribution (MCLA)\nand the double-loop Monte Carlo estimator with Laplace-based importance\nsampling (DLMCIS). Using stochastic gradient methods and Laplace-based\nestimators together allows us to use expensive and complex models, such as\nthose that require solving partial differential equations (PDEs). From a\ntheoretical viewpoint, we derive an explicit formula to compute the gradient\nestimator of the Monte Carlo methods, including MCLA and DLMCIS. From a\ncomputational standpoint, we study four examples: three based on analytical\nfunctions and one using the finite element method. The last example is an\nelectrical impedance tomography experiment based on the complete electrode\nmodel. In these examples, the accelerated stochastic gradient descent method\nusing MCLA converges to local maxima with up to five orders of magnitude fewer\nmodel evaluations than gradient descent with DLMC.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 13:29:57 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 16:06:29 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 17:48:01 GMT"}, {"version": "v4", "created": "Tue, 3 Sep 2019 21:13:38 GMT"}, {"version": "v5", "created": "Mon, 3 Feb 2020 15:14:34 GMT"}, {"version": "v6", "created": "Wed, 26 Feb 2020 19:28:06 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Carlon", "Andre Gustavo", ""], ["Dia", "Ben Mansour", ""], ["Espath", "Luis FR", ""], ["Lopez", "Rafael Holdorf", ""], ["Tempone", "Raul", ""]]}, {"id": "1807.01117", "submitter": "Matthias R\\\"othlin", "authors": "Matthias R\\\"othlin, Hagen Klippel, Konrad Wegener", "title": "Meshless Methods for Large Deformation Elastodynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Meshless methods are a promising candidate to reliably simulate materials\nundergoing large deformations. Unlike mesh based methods like the FEM, meshless\nmethods are not limited in the amount of deformation they can reproduce since\nthere are no mesh regularity constraints to consider. However, other numerical\nissues like zero energy modes, the tensile instability and disorder of the\ndiscretization points due to the deformation may impose limits on the\ndeformations possible. It is thus worthwhile to benchmark a wide array of these\nmethods since a proper review to this end has been missing from the literature\nso far. In the interest of reproducibility, the complete source code of all\nmethods considered is made public.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 12:29:15 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 12:51:56 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2018 13:04:58 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["R\u00f6thlin", "Matthias", ""], ["Klippel", "Hagen", ""], ["Wegener", "Konrad", ""]]}, {"id": "1807.01212", "submitter": "Thomas Kruse", "authors": "Martin Hutzenthaler and Arnulf Jentzen and Thomas Kruse and Tuan Anh\n  Nguyen and Philippe von Wurstemberger", "title": "Overcoming the curse of dimensionality in the numerical approximation of\n  semilinear parabolic partial differential equations", "comments": null, "journal-ref": "Proceedings of the Royal Society A 476, no. 2244 (2020): 20190630", "doi": "10.1098/rspa.2019.0630", "report-no": null, "categories": "math.PR cs.NA math.AP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a long time it is well-known that high-dimensional linear parabolic\npartial differential equations (PDEs) can be approximated by Monte Carlo\nmethods with a computational effort which grows polynomially both in the\ndimension and in the reciprocal of the prescribed accuracy. In other words,\nlinear PDEs do not suffer from the curse of dimensionality. For general\nsemilinear PDEs with Lipschitz coefficients, however, it remained an open\nquestion whether these suffer from the curse of dimensionality. In this paper\nwe partially solve this open problem. More precisely, we prove in the case of\nsemilinear heat equations with gradient-independent and globally Lipschitz\ncontinuous nonlinearities that the computational effort of a variant of the\nrecently introduced multilevel Picard approximations grows polynomially both in\nthe dimension and in the reciprocal of the required accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 14:41:16 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 14:52:21 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 18:49:42 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Hutzenthaler", "Martin", ""], ["Jentzen", "Arnulf", ""], ["Kruse", "Thomas", ""], ["Nguyen", "Tuan Anh", ""], ["von Wurstemberger", "Philippe", ""]]}, {"id": "1807.01261", "submitter": "R\\'emi Abgrall", "authors": "Remi Abgrall and Elise le Meledo and Philipp Oeffner", "title": "On the Connection between Residual Distribution Schemes and Flux\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short paper, we are considering the connection between the\n\\emph{Residual Distribution Schemes} (RD) and the \\emph{Flux Reconstruction}\n(FR) approach. We demonstrate that flux reconstruction can be recast into the\nRD framework and vice versa. Because of this close connection we are able to\napply known results from RD schemes to FR methods. In this context we propose a\nfirst demonstration of entropy stability for the FR schemes under consideration\nand show how to construct entropy stable numerical schemes based on our FR\nmethods. Simultaneously, we do not restrict the mesh to tensor structures or\ntriangle elements, but rather allow polygons. The key of our analysis is a\nproper choice of the correction functions for which we present an approach\nhere.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:14:59 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 12:05:25 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Abgrall", "Remi", ""], ["Meledo", "Elise le", ""], ["Oeffner", "Philipp", ""]]}, {"id": "1807.01359", "submitter": "Sebastian Dominguez", "authors": "Sebasti\\'an Dom\\'inguez and Nilima Nigam and Jiguang Sun", "title": "Revisiting the Jones eigenproblem in fluid-structure interaction", "comments": null, "journal-ref": null, "doi": "10.1137/18M1198235", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Jones eigenvalue problem first described by D.S. Jones in 1983 concerns\nunusual modes in bounded elastic bodies: time-harmonic displacements whose\ntractions and normal components are both identically zero on the boundary. This\nproblem is usually associated with a lack of unique solvability for certain\nmodels of fluid-structure interaction. The boundary conditions in this problem\nappear, at first glance, to rule out {\\it any} non-trivial modes unless the\ndomain possesses significant geometric symmetries. Indeed, Jones modes were\nshown to not be possible in most $C^\\infty$ domains (see article by T. Harg\\'e\n1990). However, we should in this paper that while the existence of Jones modes\nsensitively depends on the domain geometry, such modes {\\it do} exist in a\nbroad class of domains. This paper presents the first detailed theoretical and\ncomputational investigation of this eigenvalue problem in Lipschitz domains. We\nalso analytically demonstrate Jones modes on some simple geometries.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 19:44:45 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 20:51:50 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Dom\u00ednguez", "Sebasti\u00e1n", ""], ["Nigam", "Nilima", ""], ["Sun", "Jiguang", ""]]}, {"id": "1807.01480", "submitter": "Mats G Larson", "authors": "Erik Burman, Peter Hansbo, Mats G. Larson, Andre Massing, Sara Zahedi", "title": "A Stabilized Cut Streamline Diffusion Finite Element Method for\n  Convection-Diffusion Problems on Surfaces", "comments": "26 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a stabilized cut finite element method for the stationary\nconvection diffusion problem on a surface embedded in ${\\mathbb{R}}^d$. The cut\nfinite element method is based on using an embedding of the surface into a\nthree dimensional mesh consisting of tetrahedra and then using the restriction\nof the standard piecewise linear continuous elements to a piecewise linear\napproximation of the surface. The stabilization consists of a standard\nstreamline diffusion stabilization term on the discrete surface and a so called\nnormal gradient stabilization term on the full tetrahedral elements in the\nactive mesh. We prove optimal order a priori error estimates in the standard\nnorm associated with the streamline diffusion method and bounds for the\ncondition number of the resulting stiffness matrix. The condition number is of\noptimal order $O(h^{-1})$ for a specific choice of method parameters. Numerical\nexample supporting our theoretical results are also included.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 08:34:32 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Burman", "Erik", ""], ["Hansbo", "Peter", ""], ["Larson", "Mats G.", ""], ["Massing", "Andre", ""], ["Zahedi", "Sara", ""]]}, {"id": "1807.01524", "submitter": "Shun Zhang", "authors": "Qunjie Liu, Shun Zhang", "title": "Adaptive Least-Squares Finite Element Methods for Linear Transport\n  Equations Based on an H(div) Flux Reformulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the least-squares finite element methods (LSFEM) for\nthe linear hyperbolic transport equations. The linear transport equation\nnaturally allows discontinuous solutions and discontinuous inflow conditions,\nwhile the normal component of the flux across the mesh faces needs to be\ncontinuous. Traditional LSFEMs using continuous finite element approximations\nwill introduce unnecessary extra error for discontinuous solutions and boundary\nconditions. In order to separate the continuity requirements, a new flux\nvariable is introduced. With this reformulation, the continuities of the flux\nand the solution can be handled separately in natural\n$H(\\mbox{div};\\Omega)\\times L^2(\\Omega)$ conforming finite element spaces.\nSeveral variants of the methods are developed to handle the inflow boundary\ncondition strongly or weakly.\n  With the reformulation, the new LSFEMs can handle discontinuous solutions and\nboundary conditions much better than the traditional LSFEMs with continuous\npolynomial approximations. With least-squares functionals as a posteriori error\nestimators, the adaptive methods can naturally identify error sources including\nsingularity and non-matching discontinuity. For discontinuity aligned mesh, no\nextra error is introduced. If an $RT_0 \\times P_0$ pair is used to approximate\nthe flux and the solution, the new adaptive LSFEMs can approximate\ndiscontinuous solutions with almost no overshooting even when the mesh is not\naligned with discontinuity.\n  Existence and uniqueness of the solutions and a priori and a posteriori error\nestimates are established for the proposed methods. Extensive numerical tests\nare performed to show the effectiveness of the methods developed in the paper.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 11:29:30 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 06:32:49 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Liu", "Qunjie", ""], ["Zhang", "Shun", ""]]}, {"id": "1807.01589", "submitter": "Longhao Yuan", "authors": "Longhao Yuan, Jianting Cao, Qiang Wu and Qibin Zhao", "title": "Higher-dimension Tensor Completion via Low-rank Tensor Ring\n  Decomposition", "comments": "APSIPA2018 conference paper. arXiv admin note: substantial text\n  overlap with arXiv:1805.08468", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of incomplete data is common in signal processing and machine\nlearning. Tensor completion algorithms aim to recover the incomplete data from\nits partially observed entries. In this paper, taking advantages of high\ncompressibility and flexibility of recently proposed tensor ring (TR)\ndecomposition, we propose a new tensor completion approach named tensor ring\nweighted optimization (TR-WOPT). It finds the latent factors of the incomplete\ntensor by gradient descent algorithm, then the latent factors are employed to\npredict the missing entries of the tensor. We conduct various tensor completion\nexperiments on synthetic data and real-world data. The simulation results show\nthat TR-WOPT performs well in various high-dimension tensors. Furthermore,\nimage completion results show that our proposed algorithm outperforms the\nstate-of-the-art algorithms in many situations. Especially when the missing\nrate of the test images is high (e.g., over 0.9), the performance of our\nTR-WOPT is significantly better than the compared algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 04:47:35 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 02:46:30 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Yuan", "Longhao", ""], ["Cao", "Jianting", ""], ["Wu", "Qiang", ""], ["Zhao", "Qibin", ""]]}, {"id": "1807.01741", "submitter": "Michael Feischl", "authors": "Michael Feischl and Daniel Peterseim", "title": "Sparse Compression of Expected Solution Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the expected solution operator of prototypical linear elliptic\npartial differential operators with random coefficients is well approximated by\na computable sparse matrix. This result is based on a random localized\northogonal multiresolution decomposition of the solution space that allows both\nthe sparse approximate inversion of the random operator represented in this\nbasis as well as its stochastic averaging. The approximate expected solution\noperator can be interpreted in terms of classical Haar wavelets. When combined\nwith a suitable sampling approach for the expectation, this construction leads\nto an efficient method for computing a sparse representation of the expected\nsolution operator.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 18:51:05 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 12:37:40 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Feischl", "Michael", ""], ["Peterseim", "Daniel", ""]]}, {"id": "1807.01778", "submitter": "Chunfeng Cui", "authors": "Chunfeng Cui and Zheng Zhang", "title": "Uncertainty Quantification of Electronic and Photonic ICs with\n  Non-Gaussian Correlated Process Variations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the invention of generalized polynomial chaos in 2002, uncertainty\nquantification has impacted many engineering fields, including variation-aware\ndesign automation of integrated circuits and integrated photonics. Due to the\nfast convergence rate, the generalized polynomial chaos expansion has achieved\norders-of-magnitude speedup than Monte Carlo in many applications. However,\nalmost all existing generalized polynomial chaos methods have a strong\nassumption: the uncertain parameters are mutually independent or Gaussian\ncorrelated. This assumption rarely holds in many realistic applications, and it\nhas been a long-standing challenge for both theorists and practitioners.\n  This paper propose a rigorous and efficient solution to address the challenge\nof non-Gaussian correlation. We first extend generalized polynomial chaos, and\npropose a class of smooth basis functions to efficiently handle non-Gaussian\ncorrelations. Then, we consider high-dimensional parameters, and develop a\nscalable tensor method to compute the proposed basis functions. Finally, we\ndevelop a sparse solver with adaptive sample selections to solve\nhigh-dimensional uncertainty quantification problems. We validate our theory\nand algorithm by electronic and photonic ICs with 19 to 57 non-Gaussian\ncorrelated variation parameters. The results show that our approach outperforms\nMonte Carlo by $2500\\times$ to $3000\\times$ in terms of efficiency. Moreover,\nour method can accurately predict the output density functions with multiple\npeaks caused by non-Gaussian correlations, which is hard to handle by existing\nmethods.\n  Based on the results in this paper, many novel uncertainty quantification\nalgorithms can be developed and can be further applied to a broad range of\nengineering domains.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 23:38:08 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Cui", "Chunfeng", ""], ["Zhang", "Zheng", ""]]}, {"id": "1807.01883", "submitter": "Yuwei Fan", "authors": "Yuwei Fan and Lin Lin and Lexing Ying and Leonardo Zepeda-Nunez", "title": "A multiscale neural network based on hierarchical matrices", "comments": "26 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a new multiscale artificial neural network based on\nthe structure of $\\mathcal{H}$-matrices. This network generalizes the latter to\nthe nonlinear case by introducing a local deep neural network at each spatial\nscale. Numerical results indicate that the network is able to efficiently\napproximate discrete nonlinear maps obtained from discretized nonlinear partial\ndifferential equations, such as those arising from nonlinear Schr\\\"odinger\nequations and the Kohn-Sham density functional theory.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 07:47:24 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 05:34:25 GMT"}, {"version": "v3", "created": "Wed, 26 Sep 2018 22:19:37 GMT"}, {"version": "v4", "created": "Mon, 11 Nov 2019 06:06:49 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Fan", "Yuwei", ""], ["Lin", "Lin", ""], ["Ying", "Lexing", ""], ["Zepeda-Nunez", "Leonardo", ""]]}, {"id": "1807.02356", "submitter": "Gabriel Stoltz", "authors": "Tony Leli\\`evre, Mathias Rousset and Gabriel Stoltz", "title": "Hybrid Monte Carlo methods for sampling probability measures on\n  submanifolds", "comments": "V3 corrects an error in the pseudo-code of V2", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability measures supported on submanifolds can be sampled by adding an\nextra momentum variable to the state of the system, and discretizing the\nassociated Hamiltonian dynamics with some stochastic perturbation in the extra\nvariable. In order to avoid biases in the invariant probability measures\nsampled by discretizations of these stochastically perturbed Hamiltonian\ndynamics, a Metropolis rejection procedure can be considered. The so-obtained\nscheme belongs to the class of generalized Hybrid Monte Carlo (GHMC)\nalgorithms. We show here how to generalize to GHMC a procedure suggested by\nGoodman, Holmes-Cerfon and Zappa for Metropolis random walks on submanifolds,\nwhere a reverse projection check is performed to enforce the reversibility of\nthe algorithm for large timesteps and hence avoid biases in the invariant\nmeasure. We also provide a full mathematical analysis of such procedures, as\nwell as numerical experiments demonstrating the importance of the reverse\nprojection check on simple toy examples.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 11:18:25 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 19:38:48 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 18:52:07 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Leli\u00e8vre", "Tony", ""], ["Rousset", "Mathias", ""], ["Stoltz", "Gabriel", ""]]}, {"id": "1807.02474", "submitter": "Camille Carvalho", "authors": "S. Khatri, and A. D. Kim, and Ricado Cortez, and Camille Carvalho", "title": "Close evaluation of layer potentials in three dimensions", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and effective method for evaluating double-and\nsingle-layer potentials for Laplace's equation in three dimensions close to the\nboundary. The close evaluation of these layer potentials is challenging because\nthey are nearly singular integrals. The method we propose is based on writing\nthese layer potentials in spherical coordinates where the point at which their\nkernels are peaked maps to the north pole. An N-point Gauss-Legendre quadrature\nrule is used for integration with respect to the the polar angle rather than\nthe cosine of the polar angle. A 2N-point periodic trapezoid rule is used to\ncompute the integral with respect to the azimuthal angle which acts as a\nnatural and effective averaging operation in this coordinate system. The\nnumerical method resulting from combining these two quadrature rules in this\nrotated coordinate system yields results that are consistent with asymptotic\nbehaviors of the double- and single-layer potentials at close evaluation\ndistances. In particular, we show that the error in computing the double-layer\npotential, after applying a subtraction method, is quadratic with respect to\nthe evaluation distance from the boundary, and the error is linear for the\nsingle-layer potential. We improve upon the single-layer potential by\nintroducing an alternate approximation based on a perturbation expansion and\nobtain an error that is quadratic with respect to the evaluation distance from\nthe boundary.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 16:20:39 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 21:25:40 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 03:03:58 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Khatri", "S.", ""], ["Kim", "A. D.", ""], ["Cortez", "Ricado", ""], ["Carvalho", "Camille", ""]]}, {"id": "1807.02513", "submitter": "Oscar Mickelin", "authors": "Oscar Mickelin and Sertac Karaman", "title": "On Algorithms for and Computing with the Tensor Ring Decomposition", "comments": "24 pages, 3 figures, 6 tables, implementation of algorithms available\n  at https://github.com/oscarmickelin/tensor-ring-decomposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decompositions such as the canonical format and the tensor train\nformat have been widely utilized to reduce storage costs and operational\ncomplexities for high-dimensional data, achieving linear scaling with the input\ndimension instead of exponential scaling. In this paper, we investigate even\nlower storage-cost representations in the tensor ring format, which is an\nextension of the tensor train format with variable end-ranks. Firstly, we\nintroduce two algorithms for converting a tensor in full format to tensor ring\nformat with low storage cost. Secondly, we detail a rounding operation for\ntensor rings and show how this requires new definitions of common linear\nalgebra operations in the format to obtain storage-cost savings. Lastly, we\nintroduce algorithms for transforming the graph structure of graph-based tensor\nformats, with orders of magnitude lower complexity than existing literature.\nThe efficiency of all algorithms is demonstrated on a number of numerical\nexamples, and in certain cases, we demonstrate significantly higher compression\nratios when compared to previous approaches to using the tensor ring format.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 17:58:45 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 17:43:11 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 17:25:56 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mickelin", "Oscar", ""], ["Karaman", "Sertac", ""]]}, {"id": "1807.02718", "submitter": "Thomas G. Anderson", "authors": "Thomas G. Anderson, Oscar P. Bruno, Mark Lyon", "title": "High-order, Dispersionless \"Fast-Hybrid\" Wave Equation Solver. Part I:\n  $\\mathcal{O}(1)$ Sampling Cost via Incident-Field Windowing and Recentering", "comments": "33 pages, 8 figures, revised and extended manuscript (and now\n  including direct comparisons to existing CQ and TDIE solver implementations)\n  (Part I of II)", "journal-ref": "SIAM J. Sci. Comput. Vol. 42 (2020), No. 2, pp. A1348--A1379", "doi": "10.1137/19M1251953", "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a frequency/time hybrid integral-equation method for the\ntime dependent wave equation in two and three-dimensional spatial domains.\nRelying on Fourier Transformation in time, the method utilizes a fixed\n(time-independent) number of frequency-domain integral-equation solutions to\nevaluate, with superalgebraically-small errors, time domain solutions for\narbitrarily long times. The approach relies on two main elements, namely, 1) A\nsmooth time-windowing methodology that enables accurate band-limited\nrepresentations for arbitrarily-long time signals, and 2) A novel Fourier\ntransform approach which, in a time-parallel manner and without causing\nspurious periodicity effects, delivers numerically dispersionless\nspectrally-accurate solutions. A similar hybrid technique can be obtained on\nthe basis of Laplace transforms instead of Fourier transforms, but we do not\nconsider the Laplace-based method in the present contribution. The algorithm\ncan handle dispersive media, it can tackle complex physical structures, it\nenables parallelization in time in a straightforward manner, and it allows for\ntime leaping---that is, solution sampling at any given time $T$ at\n$\\mathcal{O}(1)$-bounded sampling cost, for arbitrarily large values of $T$,\nand without requirement of evaluation of the solution at intermediate times.\nThe proposed frequency-time hybridization strategy, which generalizes to any\nlinear partial differential equation in the time domain for which\nfrequency-domain solutions can be obtained (including e.g. the time-domain\nMaxwell equations), and which is applicable in a wide range of scientific and\nengineering contexts, provides significant advantages over other available\nalternatives such as volumetric discretization, time-domain integral equations,\nand convolution-quadrature approaches.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 21:17:02 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 19:02:25 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 18:44:14 GMT"}, {"version": "v4", "created": "Tue, 24 Dec 2019 18:42:52 GMT"}, {"version": "v5", "created": "Thu, 2 Jan 2020 21:36:55 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Anderson", "Thomas G.", ""], ["Bruno", "Oscar P.", ""], ["Lyon", "Mark", ""]]}, {"id": "1807.02775", "submitter": "Varun Shankar", "authors": "Varun Shankar, Akil Narayan, and Robert M. Kirby", "title": "RBF-LOI: Augmenting Radial Basis Functions (RBFs) with Least Orthogonal\n  Interpolation (LOI) for Solving PDEs on Surfaces", "comments": "18 pages, 5 figures, accepted to Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2018.07.015", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for the solution of PDEs on manifolds $\\mathbb{M}\n\\subset \\mathbb{R}^d$ of co-dimension one using stable scale-free radial basis\nfunction (RBF) interpolation. Our method involves augmenting polyharmonic\nspline (PHS) RBFs with polynomials to generate RBF-finite difference (RBF-FD)\nformulas. These polynomial basis elements are obtained using the\nrecently-developed \\emph{least orthogonal interpolation} technique (LOI) on\neach RBF-FD stencil to obtain \\emph{local} restrictions of polynomials in\n$\\mathbb{R}^3$ to stencils on $\\mathbb{M}$. The resulting RBF-LOI method uses\nCartesian coordinates, does not require any intrinsic coordinate systems or\nprojections of points onto tangent planes, and our tests illustrate robustness\nto stagnation errors. We show that our method produces high orders of\nconvergence for PDEs on the sphere and torus, and present some applications to\nreaction-diffusion PDEs motivated by biology.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 08:11:15 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Shankar", "Varun", ""], ["Narayan", "Akil", ""], ["Kirby", "Robert M.", ""]]}, {"id": "1807.02862", "submitter": "Hemant Tyagi", "authors": "St\\'ephane Chr\\'etien and Hemant Tyagi", "title": "Multi-kernel unmixing and super-resolution using the Modified Matrix\n  Pencil method", "comments": "50 pages, 10 figures, made notational changes and corrected typos\n  after reviewer feedback, to appear in Journal of Fourier Analysis and\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NA math.IT math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider $L$ groups of point sources or spike trains, with the\n$l^{\\text{th}}$ group represented by $x_l(t)$. For a function $g:\\mathbb{R}\n\\rightarrow \\mathbb{R}$, let $g_l(t) = g(t/\\mu_l)$ denote a point spread\nfunction with scale $\\mu_l > 0$, and with $\\mu_1 < \\cdots < \\mu_L$. With $y(t)\n= \\sum_{l=1}^{L} (g_l \\star x_l)(t)$, our goal is to recover the source\nparameters given samples of $y$, or given the Fourier samples of $y$. This\nproblem is a generalization of the usual super-resolution setup wherein $L =\n1$; we call this the multi-kernel unmixing super-resolution problem. Assuming\naccess to Fourier samples of $y$, we derive an algorithm for this problem for\nestimating the source parameters of each group, along with precise\nnon-asymptotic guarantees. Our approach involves estimating the group\nparameters sequentially in the order of increasing scale parameters, i.e., from\ngroup $1$ to $L$. In particular, the estimation process at stage $1 \\leq l \\leq\nL$ involves (i) carefully sampling the tail of the Fourier transform of $y$,\n(ii) a \\emph{deflation} step wherein we subtract the contribution of the groups\nprocessed thus far from the obtained Fourier samples, and (iii) applying\nMoitra's modified Matrix Pencil method on a deconvolved version of the samples\nin (ii).\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 18:01:39 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 15:55:21 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 12:38:57 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Chr\u00e9tien", "St\u00e9phane", ""], ["Tyagi", "Hemant", ""]]}, {"id": "1807.03074", "submitter": "Jon Lee", "authors": "Marcia Fampa, Jon Lee", "title": "On Sparse Reflexive Generalized Inverses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sparse generalized inverses $H$ of a rank-$r$ real matrix $A$. We\ngive a construction for reflexive generalized inverses having at most $r^2$\nnonzeros. For $r=1$ and for $r=2$ with $A$ nonnegative, we demonstrate how to\nminimize the (vector) 1-norm over reflexive generalized inverses. For general\n$r$, we efficiently find reflexive generalized inverses with 1-norm within\napproximately a factor of $r^2$ of the minimum 1-norm generalized inverse.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 12:33:36 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 14:45:06 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Fampa", "Marcia", ""], ["Lee", "Jon", ""]]}, {"id": "1807.03097", "submitter": "Felix Wolf", "authors": "J\\\"urgen D\\\"olz and Stefan Kurz and Sebastian Sch\\\"ops and Felix Wolf", "title": "Isogeometric Boundary Elements in Electromagnetism: Rigorous Analysis,\n  Fast Methods, and Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to three-dimensional electromagnetic scattering\nproblems via fast isogeometric boundary element methods. Starting with an\ninvestigation of the theoretical setting around the electric field integral\nequation within the isogeometric framework, we show existence, uniqueness, and\nquasi-optimality of the isogeometric approach. For a fast and efficient\ncomputation, we then introduce and analyze an interpolation-based fast\nmultipole method tailored to the isogeometric setting, which admits competitive\nalgorithmic and complexity properties. This is followed by a series of\nnumerical examples of industrial scope, together with a detailed presentation\nand interpretation of the results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 13:14:05 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 12:39:13 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["D\u00f6lz", "J\u00fcrgen", ""], ["Kurz", "Stefan", ""], ["Sch\u00f6ps", "Sebastian", ""], ["Wolf", "Felix", ""]]}, {"id": "1807.03140", "submitter": "Victor Selivanov", "authors": "Svetlana Selivanova, Victor Selivanov", "title": "Bit Complexity of Computing Solutions for Symmetric Hyperbolic Systems\n  of PDEs with Guaranteed Precision", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish upper bounds of bit complexity of computing solution operators\nfor symmetric hyperbolic systems of PDEs. Here we continue the research started\nin in our revious publications where computability, in the rigorous sense of\ncomputable analysis, has been established for solution operators of Cauchy and\ndissipative boundary-value problems for such systems.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 07:59:37 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 05:49:57 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Selivanova", "Svetlana", ""], ["Selivanov", "Victor", ""]]}, {"id": "1807.03141", "submitter": "Juan Carlos Cort\\'es J.-C. Cort\\'es", "authors": "J. Calatayud, J.-C. Cort\\'es, M. Jornet", "title": "Improving the approximation of the first and second order statistics of\n  the response process to the random Legendre differential equation", "comments": "13 pages; 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with uncertainty quantification for the random\nLegendre differential equation, with input coefficient $A$ and initial\nconditions $X_0$ and $X_1$. In a previous study [Calbo G. et al, Comput. Math.\nAppl., 61(9), 2782--2792 (2011)], a mean square convergent power series\nsolution on $(-1/e,1/e)$ was constructed, under the assumptions of mean fourth\nintegrability of $X_0$ and $X_1$, independence, and at most exponential growth\nof the absolute moments of $A$. In this paper, we relax these conditions to\nconstruct an $\\mathrm{L}^p$ solution ($1\\leq p\\leq\\infty$) to the random\nLegendre differential equation on the whole domain $(-1,1)$, as in its\ndeterministic counterpart. Our hypotheses assume no independence and less\nintegrability of $X_0$ and $X_1$. Moreover, the growth condition on the moments\nof $A$ is characterized by the boundedness of $A$, which simplifies the proofs\nsignificantly. We also provide approximations of the expectation and variance\nof the response process. The numerical experiments show the wide applicability\nof our findings. A comparison with Monte Carlo simulations and gPC expansions\nis performed.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 19:12:06 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Calatayud", "J.", ""], ["Cort\u00e9s", "J. -C.", ""], ["Jornet", "M.", ""]]}, {"id": "1807.03183", "submitter": "G\\\"unther Koliander", "authors": "Luis Daniel Abreu and Antti Haimi and G\\\"unther Koliander and Jos\\'e\n  Luis Romero", "title": "Filtering with Wavelet Zeros and Gaussian Analytic Functions", "comments": "29 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.CA math.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the continuous wavelet transform (WT) of white Gaussian noise and\nestablish a connection to the theory of Gaussian analytic functions. Based on\nthis connection, we propose a methodology that detects components of a signal\nin white noise based on the distribution of the zeros of its continuous WT. To\nillustrate that the continuous theory can be employed in a discrete setting, we\nestablish a uniform convergence result for the discretized continuous WT and\napply the proposed method to a variety of acoustic signals.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 14:14:42 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 13:26:34 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 09:19:13 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Abreu", "Luis Daniel", ""], ["Haimi", "Antti", ""], ["Koliander", "G\u00fcnther", ""], ["Romero", "Jos\u00e9 Luis", ""]]}, {"id": "1807.03199", "submitter": "Avram Sidi", "authors": "Avram Sidi", "title": "A Convergence Study for Reduced Rank Extrapolation on Nonlinear Systems", "comments": null, "journal-ref": "Numerical Algorithms, 84:957--982, 2020", "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced Rank Extrapolation (RRE) is a polynomial type method used to\naccelerate the convergence of sequences of vectors $\\{\\boldsymbol{x}_m\\}$. It\nis applied successfully in different disciplines of science and engineering in\nthe solution of large and sparse systems of linear and nonlinear equations of\nvery large dimension. If $\\boldsymbol{s}$ is the solution to the system of\nequations $\\boldsymbol{x}=\\boldsymbol{f}(\\boldsymbol{x})$, first, a vector\nsequence $\\{\\boldsymbol{x}_m\\}$ is generated via the fixed-point iterative\nscheme $\\boldsymbol{x}_{m+1}=\\boldsymbol{f}(\\boldsymbol{x}_m)$, $m=0,1,\\ldots,$\nand next, RRE is applied to this sequence to accelerate its convergence. RRE\nproduces approximations $\\boldsymbol{s}_{n,k}$ to $\\boldsymbol{s}$ that are of\nthe form $\\boldsymbol{s}_{n,k}=\\sum^k_{i=0}\\gamma_i\\boldsymbol{x}_{n+i}$ for\nsome scalars $\\gamma_i$ depending (nonlinearly) on $\\boldsymbol{x}_n,\n\\boldsymbol{x}_{n+1},\\ldots,\\boldsymbol{x}_{n+k+1}$ and satisfying\n$\\sum^k_{i=0}\\gamma_i=1$. The convergence properties of RRE when applied in\nconjunction with linear $\\boldsymbol{f}(\\boldsymbol{x})$ have been analyzed in\ndifferent publications. In this work, we discuss the convergence of the\n$\\boldsymbol{s}_{n,k}$ obtained from RRE with nonlinear\n$\\boldsymbol{f}(\\boldsymbol{x})$ (i)\\,when $n\\to\\infty$ with fixed $k$, and\n(ii)\\,in two so-called {\\em cycling} modes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 14:43:01 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 09:03:24 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Sidi", "Avram", ""]]}, {"id": "1807.03712", "submitter": "Olivier Zahm", "authors": "Olivier Zahm and Tiangang Cui and Kody Law and Alessio Spantini and\n  Youssef Marzouk", "title": "Certified dimension reduction in nonlinear Bayesian inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NA math.NA stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a dimension reduction technique for Bayesian inverse problems with\nnonlinear forward operators, non-Gaussian priors, and non-Gaussian observation\nnoise. The likelihood function is approximated by a ridge function, i.e., a map\nwhich depends non-trivially only on a few linear combinations of the\nparameters. We build this ridge approximation by minimizing an upper bound on\nthe Kullback--Leibler divergence between the posterior distribution and its\napproximation. This bound, obtained via logarithmic Sobolev inequalities,\nallows one to certify the error of the posterior approximation. Computing the\nbound requires computing the second moment matrix of the gradient of the\nlog-likelihood function. In practice, a sample-based approximation of the upper\nbound is then required. We provide an analysis that enables control of the\nposterior approximation error due to this sampling. Numerical and theoretical\ncomparisons with existing methods illustrate the benefits of the proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 07:49:11 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 08:38:57 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 12:38:20 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Zahm", "Olivier", ""], ["Cui", "Tiangang", ""], ["Law", "Kody", ""], ["Spantini", "Alessio", ""], ["Marzouk", "Youssef", ""]]}, {"id": "1807.03832", "submitter": "Jason Hicken", "authors": "Jason Edward Hicken and Jared Crean", "title": "A Family of Entropy-Conservative Flux Functions for the Euler Equations", "comments": "Further numerical tests revealed that the flux is not high-order\n  accurate (it is limited to 2nd order) despite the theoretical results. The\n  source of this problem is believed to be related to finite-precision\n  arithmetic, but further study is needed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy-conservative numerical flux functions can be used to construct\nhigh-order, entropy-stable discretizations of the Euler and Navier-Stokes\nequations. The purpose of this short communication is to present a novel family\nof such entropy-conservative flux functions. The proposed flux functions are\nsolutions to quadratic optimization problems and admit closed-form,\ncomputationally affordable expressions. We establish the properties of the flux\nfunctions including their continuous differentiability, which is necessary for\nhigh-order discretizations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 19:16:31 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 15:45:49 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Hicken", "Jason Edward", ""], ["Crean", "Jared", ""]]}, {"id": "1807.04020", "submitter": "Nicolas Gillis", "authors": "Atif Muhammad Syed, Sameer Qazi, Nicolas Gillis", "title": "Improved SVD-based Initialization for Nonnegative Matrix Factorization\n  using Low-Rank Correction", "comments": "12 pages, 1 figure, 5 tables, submitted to pattern recognition\n  letters", "journal-ref": "Pattern Recognition Letters 122, pp. 53-59, 2019", "doi": "10.1016/j.patrec.2019.02.018", "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the iterative nature of most nonnegative matrix factorization\n(\\textsc{NMF}) algorithms, initialization is a key aspect as it significantly\ninfluences both the convergence and the final solution obtained. Many\ninitialization schemes have been proposed for NMF, among which one of the most\npopular class of methods are based on the singular value decomposition (SVD).\nHowever, these SVD-based initializations do not satisfy a rather natural\ncondition, namely that the error should decrease as the rank of factorization\nincreases. In this paper, we propose a novel SVD-based \\textsc{NMF}\ninitialization to specifically address this shortcoming by taking into account\nthe SVD factors that were discarded to obtain a nonnegative initialization.\nThis method, referred to as nonnegative SVD with low-rank correction\n(NNSVD-LRC), allows us to significantly reduce the initial error at a\nnegligible additional computational cost using the low-rank structure of the\ndiscarded SVD factors. NNSVD-LRC has two other advantages compared to previous\nSVD-based initializations: (1) it provably generates sparse initial factors,\nand (2) it is faster as it only requires to compute a truncated SVD of rank\n$\\lceil r/2 + 1 \\rceil$ where $r$ is the factorization rank of the sought NMF\ndecomposition (as opposed to a rank-$r$ truncated SVD for other methods). We\nshow on several standard dense and sparse data sets that our new method\ncompetes favorably with state-of-the-art SVD-based initializations for NMF.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 09:21:31 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Syed", "Atif Muhammad", ""], ["Qazi", "Sameer", ""], ["Gillis", "Nicolas", ""]]}, {"id": "1807.04131", "submitter": "Mario Fern\\'andez-Pend\\'as", "authors": "Tijana Radivojevi\\'c, Mario Fern\\'andez-Pend\\'as, Jes\\'us Mar\\'ia\n  Sanz-Serna, Elena Akhmatskaya", "title": "Multi-stage splitting integrators for sampling with modified Hamiltonian\n  Monte Carlo methods", "comments": "31 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1706.04032", "journal-ref": null, "doi": "10.1016/j.jcp.2018.07.023", "report-no": null, "categories": "physics.comp-ph cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modified Hamiltonian Monte Carlo (MHMC) methods combine the ideas behind two\npopular sampling approaches: Hamiltonian Monte Carlo (HMC) and importance\nsampling. As in the HMC case, the bulk of the computational cost of MHMC\nalgorithms lies in the numerical integration of a Hamiltonian system of\ndifferential equations. We suggest novel integrators designed to enhance\naccuracy and sampling performance of MHMC methods. The novel integrators belong\nto families of splitting algorithms and are therefore easily implemented. We\nidentify optimal integrators within the families by minimizing the energy error\nor the average energy error. We derive and discuss in detail the modified\nHamiltonians of the new integrators, as the evaluation of those Hamiltonians is\nkey to the efficiency of the overall algorithms. Numerical experiments show\nthat the use of the new integrators may improve very significantly the sampling\nperformance of MHMC methods, in both statistical and molecular dynamics\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 08:32:19 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Radivojevi\u0107", "Tijana", ""], ["Fern\u00e1ndez-Pend\u00e1s", "Mario", ""], ["Sanz-Serna", "Jes\u00fas Mar\u00eda", ""], ["Akhmatskaya", "Elena", ""]]}, {"id": "1807.04181", "submitter": "Martin Wilhelm", "authors": "Martin Wilhelm", "title": "On error representation in exact-decisions number types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accuracy-driven computation is a strategy widely used in exact-decisions\nnumber types for robust geometric algorithms. This work provides an overview on\nthe usage of error bounds in accuracy-driven computation, compares different\napproaches on the representation and computation of these error bounds and\npoints out some caveats. The stated claims are supported by experiments.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:01:39 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Wilhelm", "Martin", ""]]}, {"id": "1807.04195", "submitter": "Sheehan Olver", "authors": "Sheehan Olver, Yuan Xu", "title": "Orthogonal structure on a quadratic curve", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal polynomials on quadratic curves in the plane are studied. These\ninclude orthogonal polynomials on ellipses, parabolas, hyperbolas, and two\nlines. For an integral with respect to an appropriate weight function defined\non any quadratic curve, an explicit basis of orthogonal polynomials is\nconstructed in terms of two families of orthogonal polynomials in one variable.\nConvergence of the Fourier orthogonal expansions is also studied in each case.\nAs an application, we see that the resulting bases can be used to interpolate\nfunctions on the real line with singularities of the form $|x|$, $\\sqrt{x^2+\n\\epsilon^2}$, or $1/x$, with exponential convergence.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:28:33 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 22:49:43 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Olver", "Sheehan", ""], ["Xu", "Yuan", ""]]}, {"id": "1807.04638", "submitter": "Monica Hernandez", "authors": "Monica Hernandez", "title": "PDE-constrained LDDMM via geodesic shooting and inexact\n  Gauss-Newton-Krylov optimization using the incremental adjoint Jacobi\n  equations", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6560/aaf598", "report-no": null, "categories": "cs.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of non-rigid registration methods proposed in the framework of\nPDE-constrained Large Deformation Diffeomorphic Metric Mapping is a\nparticularly interesting family of physically meaningful diffeomorphic\nregistration methods. Inexact Newton-Krylov optimization has shown an excellent\nnumerical accuracy and an extraordinarily fast convergence rate in this\nframework. However, the Galerkin representation of the non-stationary velocity\nfields does not provide proper geodesic paths. In this work, we propose a\nmethod for PDE-constrained LDDMM parameterized in the space of initial velocity\nfields under the EPDiff equation. The derivation of the gradient and the\nHessian-vector products are performed on the final velocity field and\ntransported backward using the adjoint and the incremental adjoint Jacobi\nequations. This way, we avoid the complex dependence on the initial velocity\nfield in the derivations and the computation of the adjoint equation and its\nincremental counterpart. The proposed method provides geodesics in the\nframework of PDE-constrained LDDMM, and it shows performance competitive to\nbenchmark PDE-constrained LDDMM and EPDiff-LDDMM methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 14:08:16 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Hernandez", "Monica", ""]]}, {"id": "1807.05319", "submitter": "Pedro Vilanova", "authors": "Markos A. Katsoulakis and Pedro Vilanova", "title": "Information-based Variational Model Reduction of high-dimensional\n  Reaction Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present new scalable, information theory-based variational\nmethods for the efficient model reduction of high-dimensional deterministic and\nstochastic reaction networks. The proposed methodology combines, (a)\ninformation theoretic tools for sensitivity analysis that allow us to identify\nthe proper coarse variables of the reaction network, with (b) variational\napproximate inference methods for training a best-fit reduced model. This\napproach takes advantage of both physicochemical modeling and data-based\napproaches and allows to construct optimal parameterized reduced dynamics in\nthe number of variables, reactions and parameters, while controlling the\ninformation loss due to the reduction. We demonstrate the effectiveness of our\nmodel reduction method on several complex, high-dimensional chemical reaction\nnetworks arising in biochemistry.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 01:20:05 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 12:08:42 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 01:50:10 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Katsoulakis", "Markos A.", ""], ["Vilanova", "Pedro", ""]]}, {"id": "1807.05340", "submitter": "Harry Yserentant", "authors": "Harry Yserentant", "title": "On the expansion of solutions of Laplace-like equations into traces of\n  separable higher dimensional functions", "comments": "Version 4 coincides almost completely with the published version of\n  the paper. The last Version 5 is slightly updated and contains some\n  additional remarks on the asymptotic behavior for large dimensions m and\n  ratios n/m", "journal-ref": "Numerische Mathematik (2020) 146:219-238", "doi": "10.1007/s00211-020-01138-8", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the equation $-\\Delta u+\\mu u=f$ on high-dimensional\nspaces $\\mathbb{R}^m$ where $\\mu$ is a positive constant. If the right-hand\nside $f$ is a rapidly converging series of separable functions, the solution\n$u$ can be represented in the same way. These constructions are based on\napproximations of the function $1/r$ by sums of exponential functions. The aim\nof this paper is to prove results of similar kind for more general right-hand\nsides $f(x)=F(Tx)$ that are composed of a separable function on a space of a\ndimension $n$ greater than $m$ and a linear mapping given by a matrix $T$ of\nfull rank. These results are based on the observation that in the\nhigh-dimensional case, for $\\omega$ in most of the $\\mathbb{R}^n$, the\neuclidian norm of the vector $T^t\\omega$ in the lower dimensional space\n$\\mathbb{R}^m$ behaves like the euclidian norm of $\\omega$.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 06:39:13 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 06:30:58 GMT"}, {"version": "v3", "created": "Sun, 30 Jun 2019 11:47:18 GMT"}, {"version": "v4", "created": "Sat, 21 Mar 2020 15:13:36 GMT"}, {"version": "v5", "created": "Fri, 21 Aug 2020 08:06:18 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Yserentant", "Harry", ""]]}, {"id": "1807.05634", "submitter": "Andre Massing", "authors": "Ceren G\\\"urkan, Simon Sticko, Andr\\'e Massing", "title": "Stabilized CutDG methods for advection-reaction problems", "comments": "Final version accepted by SISC", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop novel stabilized cut discontinuous Galerkin (CutDG) methods for\nadvection-reaction problems. The domain of interest is embedded into a\nstructured, unfitted background mesh in $\\mathbb{R}^d$ where the domain\nboundary can cut through the mesh in an arbitrary fashion. To cope with\nrobustness problems caused by small cut elements, we introduce ghost penalties\nin the vicinity of the embedded boundary to stabilize certain (semi)-norms\nassociated with the advection and reaction operator. A few abstract assumptions\non the ghost penalties are identified enabling us to derive geometrically\nrobust and optimal a priori error and condition number estimates for the\nstationary advection-reaction problem which hold irrespective of the particular\ncut configuration. Possible realizations of suitable ghost penalties are\ndiscussed. The theoretical results are corroborated by a number of\ncomputational studies for various approximation orders and for two and\nthree-dimensional test problems.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 23:47:02 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 23:03:54 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["G\u00fcrkan", "Ceren", ""], ["Sticko", "Simon", ""], ["Massing", "Andr\u00e9", ""]]}, {"id": "1807.05689", "submitter": "Naraparaju Kishore Kumar", "authors": "N. Kishore Kumar, Pankaj Biswas and B. Seshadri Reddy", "title": "A study of spectral element method for elliptic interface problems with\n  nonsmooth solutions in $\\mathbb{R}^{2}$", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The solution of the elliptic partial differential equation has interface\nsingularity at the points which are either the intersections of interfaces or\nthe intersections of interfaces with the boundary of the domain. The\nsingularities that arises in the elliptic interface problems are very complex.\nIn this article, we propose an exponentially accurate nonconforming spectral\nelement method for these problems based on [7, 18]. A geometric mesh is used in\nthe neighbourhood of the singularities and the auxiliary map of the form\n$z=ln\\xi$ is introduced to remove the singularities. The method is essentially\na least-squares method and the solution can be obtained by solving the normal\nequations using the preconditioned conjugate gradient method (PCGM) without\ncomputing the mass and stiffness matrices. Numerical examples are presented to\nshow the exponential accuracy of the method.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 06:12:23 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 09:23:19 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Kumar", "N. Kishore", ""], ["Biswas", "Pankaj", ""], ["Reddy", "B. Seshadri", ""]]}, {"id": "1807.05793", "submitter": "Erdem Altuntac", "authors": "Erdem Altuntac", "title": "Choice of the Parameters in A Primal-Dual Algorithm for Bregman Iterated\n  Variational Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Focus of this work is solving a non-smooth constraint minimization problem by\na primal-dual splitting algorithm involving proximity operators. The problem is\npenalized by the Bregman divergence associated with the non-smooth total\nvariation (TV) functional.\n  We analyse two aspects: Firstly, the convergence of the regularized solution\nof the minimization problem to the minimum norm solution. Second, the\nconvergence of the iteratively regularized minimizer to the minimum norm\nsolution by a primal-dual algorithm. For both aspects, we use the assumption of\na variational source condition (VSC). This work emphasizes the impact of the\nchoice of the parameters in stabilization of a primal-dual algorithm. Rates of\nconvergence are obtained in terms of some concave, positive definite index\nfunction.\n  The algorithm is applied to a simple two dimensional image processing\nproblem. Sufficient error analysis profiles are provided based on the size of\nthe forward operator and the noise level in the measurement.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 11:14:51 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 11:17:24 GMT"}, {"version": "v3", "created": "Sat, 21 Jul 2018 09:11:42 GMT"}, {"version": "v4", "created": "Sun, 5 Aug 2018 08:36:53 GMT"}, {"version": "v5", "created": "Tue, 29 Oct 2019 09:47:17 GMT"}, {"version": "v6", "created": "Wed, 6 Nov 2019 07:55:45 GMT"}, {"version": "v7", "created": "Mon, 24 Feb 2020 15:37:22 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Altuntac", "Erdem", ""]]}, {"id": "1807.06007", "submitter": "Vladislav Malyshkin", "authors": "Vladislav Gennadievich Malyshkin", "title": "On Lebesgue Integral Quadrature", "comments": "Relation to density matrix added. Images fixed. Density matrix\n  appendix fixed. Christoffel function spectrum is added to Appendix B.\n  Numerical examples of the Christoffel weights are added. The optimal\n  clustering solution is added to Appendix C. Notation changes according to\n  arXiv:1906.00460 . Software new version; description update", "journal-ref": null, "doi": "10.2139/ssrn.3229363", "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A new type of quadrature is developed. The Gaussian quadrature, for a given\nmeasure, finds optimal values of a function's argument (nodes) and the\ncorresponding weights. In contrast, the Lebesgue quadrature developed in this\npaper, finds optimal values of function (value-nodes) and the corresponding\nweights. The Gaussian quadrature groups sums by function argument; it can be\nviewed as a $n$-point discrete measure, producing the Riemann integral. The\nLebesgue quadrature groups sums by function value; it can be viewed as a\n$n$-point discrete distribution, producing the Lebesgue integral.\nMathematically, the problem is reduced to a generalized eigenvalue problem:\nLebesgue quadrature value-nodes are the eigenvalues and the corresponding\nweights are the square of the averaged eigenvectors. A numerical estimation of\nan integral as the Lebesgue integral is especially advantageous when analyzing\nirregular and stochastic processes. The approach separates the outcome\n(value-nodes) and the probability of the outcome (weight). For this reason, it\nis especially well-suited for the study of non-Gaussian processes. The software\nimplementing the theory is available from the authors.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 07:05:57 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 12:07:46 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2018 16:54:07 GMT"}, {"version": "v4", "created": "Sun, 30 Jun 2019 22:44:44 GMT"}, {"version": "v5", "created": "Sun, 7 Jul 2019 11:40:18 GMT"}, {"version": "v6", "created": "Mon, 24 Feb 2020 17:06:13 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Malyshkin", "Vladislav Gennadievich", ""]]}, {"id": "1807.06280", "submitter": "Junxiong Jia", "authors": "Junxiong Jia, Qihang Sun, Bangyu Wu, Jigen Peng", "title": "An adaptive augmented regularization method and its applications", "comments": "26 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization method and Bayesian inverse method are two dominating ways for\nsolving inverse problems generated from various fields, e.g., seismic\nexploration and medical imaging. The two methods are related with each other by\nthe MAP estimates of posterior probability distributions. Considering this\nconnection, we construct a prior probability distribution with several\nhyper-parameters and provide the relevant Bayes' formula, then we propose a\ncorresponding adaptive augmented regularization model (AARM). According to the\nmeasured data, the proposed AARM can adjust its form to various regularization\nmodels at each discrete point of the estimated function, which makes the\ncharacterization of local smooth properties of the estimated function possible.\nBy proposing a modified Bregman iterative algorithm, we construct an alternate\niterative algorithm to solve the AARM efficiently. In the end, we provide some\nnumerical examples which clearly indicate that the proposed AARM can generates\na favorable result for some examples compared with several Tikhonov and\nTotal-Variation regularization models.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 08:48:17 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 09:46:30 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Jia", "Junxiong", ""], ["Sun", "Qihang", ""], ["Wu", "Bangyu", ""], ["Peng", "Jigen", ""]]}, {"id": "1807.06507", "submitter": "Alexey Poyda", "authors": "Alexey Poyda and Mikhail Zhizhin", "title": "Optimization of the n-dimensional sliding window inter-channel\n  correlation algorithm for multi-core architecture", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calculating the correlation in a sliding window is a common method of\nstatistical evaluation of the interconnect between two sets of data. And\nalthough the calculation of a single correlation coefficient is not\nresource-intensive and algorithmically complex, sequential computation in a\nlarge number of windows on large data sets can take quite a long time. In this\ncase, each value in the data, falling into different windows, will be processed\nmany times, increasing the complexity of the algorithm and the processing time.\nWe took this fact into account and optimized the correlation calculation in the\nsliding window, reducing the number of operations in the overlapping area of\nthe windows. In addition, we developed a parallel version of the optimized\nalgorithm for the GPU architecture. Experimental studies have shown that for a\n7x7 correlation window sliding in one pixel increments, we were able to\naccelerate the processing of an 12 MPixel image pixels on the GPU by about 60\ntimes compared to the serial version running on the CPU. The article presents\nan optimized version of the algorithm, a scheme for its parallelization, as\nwell as the results of experimental studies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 15:42:01 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Poyda", "Alexey", ""], ["Zhizhin", "Mikhail", ""]]}, {"id": "1807.06565", "submitter": "Chenlin Gu", "authors": "Chenlin Gu", "title": "Uniform estimate of an iterative method for elliptic problems with\n  rapidly oscillating coefficients", "comments": "32 pages, 3 figures", "journal-ref": "Stoch PDE: Anal Comp 8, 787-818 (2020)", "doi": "10.1007/s40072-019-00159-1", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the iterative algorithm proposed by S. Armstrong, A. Hannukainen, T.\nKuusi, J.-C. Mourrat to solve elliptic equations in divergence form with\nstochastic stationary coefficients. Such equations display rapidly oscillating\ncoefficients and thus usually require very expensive numerical calculations,\nwhile this iterative method is comparatively easy to compute. In this article,\nwe strengthen the estimate for the contraction factor achieved by one iteration\nof the algorithm. We obtain an estimate that holds uniformly over the initial\nfunction in the iteration, and which grows only logarithmically with the size\nof the domain.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 17:15:30 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 10:05:10 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 08:23:51 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Gu", "Chenlin", ""]]}, {"id": "1807.06652", "submitter": "Vladimir Salnikov", "authors": "Vladimir Salnikov and Aziz Hamdouni", "title": "From modelling of systems with constraints to generalized geometry and\n  back to numerics", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we describe how some objects from generalized geometry appear in\nthe qualitative analysis and numerical simulation of mechanical systems. In\nparticular we discuss double vector bundles and Dirac structures. It turns out\nthat those objects can be naturally associated to systems with constraints --\nwe recall the mathematical construction in the context of so called implicit\nLagrangian systems. We explain how they can be used to produce new numerical\nmethods, that we call Dirac integrators.\n  On a test example of a simple pendulum in a gravity field we compare the\nDirac integrators with classical explicit and implicit methods, we pay special\nattention to conservation of constrains. Then, on a more advanced example of\nthe Ziegler column we show that the choice of numerical methods can indeed\naffect the conclusions of qualitative analysis of the dynamics of mechanical\nsystems. We also tell why we think that Dirac integrators are appropriate for\nthis kind of systems by explaining the relation with the notions of geometric\ndegree of non-conservativity and kinematic structural stability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:15:40 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Salnikov", "Vladimir", ""], ["Hamdouni", "Aziz", ""]]}, {"id": "1807.07099", "submitter": "Pavel Kharyuk", "authors": "Pavel Kharyuk, Dmitry Nazarenko, Ivan Oseledets", "title": "Comparative study of Discrete Wavelet Transforms and Wavelet Tensor\n  Train decomposition to feature extraction of FTIR data of medicinal plants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier-transform infra-red (FTIR) spectra of samples from 7 plant species\nwere used to explore the influence of preprocessing and feature extraction on\nefficiency of machine learning algorithms. Wavelet Tensor Train (WTT) and\nDiscrete Wavelet Transforms (DWT) were compared as feature extraction\ntechniques for FTIR data of medicinal plants. Various combinations of signal\nprocessing steps showed different behavior when applied to classification and\nclustering tasks. Best results for WTT and DWT found through grid search were\nsimilar, significantly improving quality of clustering as well as\nclassification accuracy for tuned logistic regression in comparison to original\nspectra. Unlike DWT, WTT has only one parameter to be tuned (rank), making it a\nmore versatile and easier to use as a data processing tool in various signal\nprocessing applications.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 18:41:23 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Kharyuk", "Pavel", ""], ["Nazarenko", "Dmitry", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1807.07476", "submitter": "Ehouarn Simon", "authors": "S. Gratton, E. Simon, D. Titley-Peloquin, Ph. L. Toint", "title": "Minimizing convex quadratic with variable precision conjugate gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the method of conjugate gradients, exploiting inaccurate\nmatrix-vector products, for the solution of convex quadratic optimization\nproblems. Theoretical performance bounds are derived, and the necessary\nquantities occurring in the theoretical bounds estimated, leading to a\npractical algorithm. Numerical experiments suggest that this approach has\nsignificant potential, including in the steadily more important context of\nmulti-precision computations\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:10:15 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 09:06:34 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 09:06:50 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Gratton", "S.", ""], ["Simon", "E.", ""], ["Titley-Peloquin", "D.", ""], ["Toint", "Ph. L.", ""]]}, {"id": "1807.07485", "submitter": "Niklas Georg", "authors": "Niklas Georg, Dimitrios Loukrezis, Ulrich R\\\"omer, Sebastian Sch\\\"ops", "title": "Enhanced adaptive surrogate models with applications in uncertainty\n  quantification for nanoplasmonics", "comments": null, "journal-ref": "International Journal for Uncertainty Quantification,\n  10(2):165-193, 2020", "doi": "10.1615/Int.J.UncertaintyQuantification.2020031727", "report-no": null, "categories": "cs.CE cs.NA math.NA physics.comp-ph physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient surrogate modeling technique for uncertainty\nquantification. The method is based on a well-known dimension-adaptive\ncollocation scheme. We improve the scheme by enhancing sparse polynomial\nsurrogates with conformal maps and adjoint error correction. The methodology is\napplied to Maxwell's source problem with random input data. This setting\ncomprises many applications of current interest from computational\nnanoplasmonics, such as grating couplers or optical waveguides. Using a\nnon-trivial benchmark model we show the benefits and drawbacks of using\nenhanced surrogate models through various numerical studies. The proposed\nstrategy allows us to conduct a thorough uncertainty analysis, taking into\naccount a moderately large number of random parameters.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 15:18:54 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 17:10:33 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 08:55:13 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Georg", "Niklas", ""], ["Loukrezis", "Dimitrios", ""], ["R\u00f6mer", "Ulrich", ""], ["Sch\u00f6ps", "Sebastian", ""]]}, {"id": "1807.08084", "submitter": "Renato J Cintra", "authors": "D. F. G. Coelho, R. J. Cintra, A. C. Frery, V. S. Dimitrov", "title": "Fast Matrix Inversion and Determinant Computation for Polarimetric\n  Synthetic Aperture Radar", "comments": "7 pages, 1 figure", "journal-ref": "Computers and Geosciences, no. 119 (2018), pages 109-114", "doi": "10.1016/j.cageo.2018.07.002", "report-no": null, "categories": "cs.NA cs.DS eess.SP math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a fast algorithm for simultaneous inversion and\ndeterminant computation of small sized matrices in the context of fully\nPolarimetric Synthetic Aperture Radar (PolSAR) image processing and analysis.\nThe proposed fast algorithm is based on the computation of the adjoint matrix\nand the symmetry of the input matrix. The algorithm is implemented in a general\npurpose graphical processing unit (GPGPU) and compared to the usual approach\nbased on Cholesky factorization. The assessment with simulated observations and\ndata from an actual PolSAR sensor show a speedup factor of about two when\ncompared to the usual Cholesky factorization. Moreover, the expressions\nprovided here can be implemented in any platform.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 04:52:06 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Coelho", "D. F. G.", ""], ["Cintra", "R. J.", ""], ["Frery", "A. C.", ""], ["Dimitrov", "V. S.", ""]]}, {"id": "1807.08090", "submitter": "Rui Ma", "authors": "Jun Hu and Rui Ma", "title": "Partial relaxation of C^0 vertex continuity of stresses of conforming\n  mixed finite elements for the elasticity problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conforming triangular mixed element recently proposed by Hu and Zhang for\nlinear elasticity is extended by rearranging the global degrees of freedom.\nMore precisely, adaptive meshes $\\mathcal{T}_1$, $\\cdots$, $\\mathcal{T}_N$\nwhich are successively refined from an initial mesh $\\mathcal{T}_0$ through a\nnewest vertex bisection strategy, admit a crucial hierarchical structure,\nnamely, a newly added vertex $\\boldsymbol{x}$ of the mesh $\\mathcal{T}_\\ell$ is\nthe midpoint of an edge $e$ of the coarse mesh $\\mathcal{T}_{\\ell-1}$. Such a\nhierarchical structure is explored to partially relax the $C^0$ vertex\ncontinuity of symmetric matrix-valued functions in the discrete stress space of\nthe original element on $\\mathcal{T}_\\ell$ and results in an extended discrete\nstress space. A feature of this extended discrete stress space is its\nnestedness in the sense that a space on a coarse mesh $\\mathcal{T}$ is a\nsubspace of a space on any refinement $\\hat{\\mathcal{T}}$ of $\\mathcal{T}$,\nwhich allows a proof of convergence of a standard adaptive algorithm. The idea\nis extended to impose a general traction boundary condition on the discrete\nlevel. Numerical experiments are provided to illustrate performance on both\nuniform and adaptive meshes.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 06:11:52 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 17:20:17 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Hu", "Jun", ""], ["Ma", "Rui", ""]]}, {"id": "1807.08197", "submitter": "Vladislav Malyshkin", "authors": "Vladislav Gennadievich Malyshkin", "title": "On Numerical Estimation of Joint Probability Distribution from Lebesgue\n  Integral Quadratures", "comments": "Christoffel function average is added to obtain joint distribution of\n  three processes. A relation to Low Rank Representation (LRR) arXiv:1906.00460\n  is added", "journal-ref": null, "doi": "10.2139/ssrn.3229347", "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important application of Lebesgue integral quadrature arXiv:1807.06007 is\ndeveloped. Given two random processes, $f(x)$ and $g(x)$, two generalized\neigenvalue problems can be formulated and solved. In addition to obtaining two\nLebesgue quadratures (for $f$ and $g$) from two eigenproblems, the projections\nof $f$- and $g$- eigenvectors on each other allow to build a joint distribution\nestimator, the most general form of which is a density-matrix correlation.\nExamples of the density-matrix correlation can be a value-correlation\n$V_{f^{[i]};g^{[j]}}$, similar to a regular correlation concept, and a new one,\na probability-correlation $P_{f^{[i]};g^{[j]}}$. If Christoffel function\naverage is used instead of regular average the approach can be extended to an\nestimation of joint probability of three and more random processes. The theory\nis implemented numerically; the software is available under the GPLv3 license.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 19:52:15 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 07:11:32 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 08:46:31 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 16:01:20 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Malyshkin", "Vladislav Gennadievich", ""]]}, {"id": "1807.08590", "submitter": "Susanne Bradley", "authors": "Susanne Bradley", "title": "Ideal Preconditioners for Saddle Point Systems with a Rank-Deficient\n  Leading Block", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the iterative solution of symmetric saddle point systems with a\nrank-deficient leading block. We develop two preconditioners that, under\ncertain assumptions on the rank structure of the system, yield a preconditioned\nmatrix with a constant number of eigenvalues. We then derive some properties of\nthe inverse of a particular class of saddle point system and exploit these to\ndevelop a third preconditioner, which remains ideal even when the earlier\nassumptions on rank structure are relaxed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 13:17:16 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Bradley", "Susanne", ""]]}, {"id": "1807.08848", "submitter": "Ke Chen", "authors": "Ke Chen, Qin Li, Jianfeng Lu, and Stephen J. Wright", "title": "Random Sampling and Efficient Algorithms for Multiscale PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a numerical framework that uses random sampling to efficiently\ncapture low-rank local solution spaces of multiscale PDE problems arising in\ndomain decomposition. In contrast to existing techniques, our method does not\nrely on detailed analytical understanding of specific multiscale PDEs, in\nparticular, their asymptotic limits. We present the application of the\nframework on two examples --- a linear kinetic equation and an elliptic\nequation with rough media. On these two examples, this framework achieves the\nasymptotic preserving property for the kinetic equations and numerical\nhomogenization for the elliptic equations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 22:22:56 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 20:58:45 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 22:36:05 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Chen", "Ke", ""], ["Li", "Qin", ""], ["Lu", "Jianfeng", ""], ["Wright", "Stephen J.", ""]]}, {"id": "1807.09401", "submitter": "Sergii Siryk", "authors": "Sergii Siryk", "title": "A note on the application of the Guermond-Pasquetti mass lumping\n  correction technique for convection-diffusion problems", "comments": null, "journal-ref": "Journal of Computational Physics, 2019, Volume 376, Pages\n  1273-1291", "doi": "10.1016/j.jcp.2018.10.016", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a careful Fourier analysis of the Guermond-Pasquetti mass lumping\ncorrection technique [Guermond J.-L., Pasquetti R. A correction technique for\nthe dispersive effects of mass lumping for transport problems. - Computer\nMethods in Applied Mechanics and Engineering. - 2013. - Vol. 253. - P. 186-198]\napplied to pure transport and convection-diffusion problems. In particular, it\nis found that increasing the number of corrections reduces the accuracy for\nproblems with diffusion; however all the corrected schemes are more accurate\nthan the consistent Galerkin formulation in this case. For the pure transport\nproblems the situation is the opposite. We also investigate the differences\nbetween two numerical solutions - the consistent solution and the corrected\nones, and show that increasing the number of corrections makes solutions of the\ncorrected schemes closer to the consistent solution in all cases.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 00:23:24 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 11:04:49 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Siryk", "Sergii", ""]]}, {"id": "1807.09655", "submitter": "Pablo de Oliveira Castro", "authors": "Devan Sohier, Pablo de Oliveira Castro, Fran\\c{c}ois F\\'evotte, Bruno\n  Lathuili\\`ere, Eric Petit, Olivier Jamond", "title": "Confidence Intervals for Stochastic Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying errors and losses due to the use of Floating-Point (FP)\ncalculations in industrial scientific computing codes is an important part of\nthe Verification, Validation and Uncertainty Quantification (VVUQ) process.\nStochastic Arithmetic is one way to model and estimate FP losses of accuracy,\nwhich scales well to large, industrial codes. It exists in different flavors,\nsuch as CESTAC or MCA, implemented in various tools such as CADNA, Verificarlo\nor Verrou. These methodologies and tools are based on the idea that FP losses\nof accuracy can be modeled via randomness. Therefore, they share the same need\nto perform a statistical analysis of programs results in order to estimate the\nsignificance of the results. In this paper, we propose a framework to perform a\nsolid statistical analysis of Stochastic Arithmetic. This framework unifies all\nexisting definitions of the number of significant digits (CESTAC and MCA), and\nalso proposes a new quantity of interest: the number of digits contributing to\nthe accuracy of the results. Sound confidence intervals are provided for all\nestimators, both in the case of normally distributed results, and in the\ngeneral case. The use of this framework is demonstrated by two case studies of\nlarge, industrial codes: Europlexus and code_aster.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 09:18:06 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 09:54:28 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 07:39:07 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Sohier", "Devan", ""], ["Castro", "Pablo de Oliveira", ""], ["F\u00e9votte", "Fran\u00e7ois", ""], ["Lathuili\u00e8re", "Bruno", ""], ["Petit", "Eric", ""], ["Jamond", "Olivier", ""]]}, {"id": "1807.09737", "submitter": "Hans Kersting", "authors": "Hans Kersting, T. J. Sullivan, Philipp Hennig", "title": "Convergence Rates of Gaussian ODE Filters", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently-introduced class of probabilistic (uncertainty-aware) solvers for\nordinary differential equations (ODEs) applies Gaussian (Kalman) filtering to\ninitial value problems. These methods model the true solution $x$ and its first\n$q$ derivatives \\emph{a priori} as a Gauss--Markov process $\\boldsymbol{X}$,\nwhich is then iteratively conditioned on information about $\\dot{x}$. This\narticle establishes worst-case local convergence rates of order $q+1$ for a\nwide range of versions of this Gaussian ODE filter, as well as global\nconvergence rates of order $q$ in the case of $q=1$ and an integrated Brownian\nmotion prior, and analyses how inaccurate information on $\\dot{x}$ coming from\napproximate evaluations of $f$ affects these rates. Moreover, we show that, in\nthe globally convergent case, the posterior credible intervals are well\ncalibrated in the sense that they globally contract at the same rate as the\ntruncation error. We illustrate these theoretical results by numerical\nexperiments which might indicate their generalizability to $q \\in\n\\{2,3,\\dots\\}$.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 17:33:55 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 18:11:45 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 16:54:44 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kersting", "Hans", ""], ["Sullivan", "T. J.", ""], ["Hennig", "Philipp", ""]]}, {"id": "1807.10194", "submitter": "Xiaohao Cai", "authors": "Xiaohao Cai, Raymond Chan, Carola-Bibiane Schonlieb, Gabriele Steidl,\n  Tieyong Zeng", "title": "Linkage between piecewise constant Mumford-Shah model and ROF model and\n  its virtue in image segmentation", "comments": "31 pages", "journal-ref": "SIAM Journal on Scientific Computing, 41(6):B1310-B1340, 2019", "doi": null, "report-no": null, "categories": "math.NA cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The piecewise constant Mumford-Shah (PCMS) model and the Rudin-Osher-Fatemi\n(ROF) model are two important variational models in image segmentation and\nimage restoration, respectively. In this paper, we explore a linkage between\nthese models. We prove that for the two-phase segmentation problem a partial\nminimizer of the PCMS model can be obtained by thresholding the minimizer of\nthe ROF model. A similar linkage is still valid for multiphase segmentation\nunder specific assumptions. Thus it opens a new segmentation paradigm: image\nsegmentation can be done via image restoration plus thresholding. This new\nparadigm, which circumvents the innate non-convex property of the PCMS model,\ntherefore improves the segmentation performance in both efficiency (much faster\nthan state-of-the-art methods based on PCMS model, particularly when the phase\nnumber is high) and effectiveness (producing segmentation results with better\nquality) due to the flexibility of the ROF model in tackling degraded images,\nsuch as noisy images, blurry images or images with information loss. As a\nby-product of the new paradigm, we derive a novel segmentation method, called\nthresholded-ROF (T-ROF) method, to illustrate the virtue of managing image\nsegmentation through image restoration techniques. The convergence of the T-ROF\nmethod is proved, and elaborate experimental results and comparisons are\npresented.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 15:28:12 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 00:34:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Cai", "Xiaohao", ""], ["Chan", "Raymond", ""], ["Schonlieb", "Carola-Bibiane", ""], ["Steidl", "Gabriele", ""], ["Zeng", "Tieyong", ""]]}, {"id": "1807.11354", "submitter": "Mohammad Farazmand", "authors": "Mohammad Farazmand", "title": "Multiscale analysis of accelerated gradient methods", "comments": "Minor revisions; Accepted for Publication in SIAM Journal on\n  Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerated gradient descent iterations are widely used in optimization. It\nis known that, in the continuous-time limit, these iterations converge to a\nsecond-order differential equation which we refer to as the accelerated\ngradient flow. Using geometric singular perturbation theory, we show that,\nunder certain conditions, the accelerated gradient flow possesses an attracting\ninvariant slow manifold to which the trajectories of the flow converge\nasymptotically. We obtain a general explicit expression in the form of\nfunctional series expansions that approximates the slow manifold to any\narbitrary order of accuracy. To the leading order, the accelerated gradient\nflow reduced to this slow manifold coincides with the usual gradient descent.\nWe illustrate the implications of our results on three examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 13:58:38 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 16:57:39 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 13:02:32 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Farazmand", "Mohammad", ""]]}]