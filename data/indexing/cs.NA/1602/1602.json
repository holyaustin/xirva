[{"id": "1602.01376", "submitter": "William March", "authors": "Chenhan D. Yu, William B. March, Bo Xiao, and George Biros", "title": "Inv-ASKIT: A Parallel Fast Diret Solver for Kernel Matrices", "comments": "11 pages, 2 figures, to appear in IPDPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel algorithm for computing the approximate factorization\nof an $N$-by-$N$ kernel matrix. Once this factorization has been constructed\n(with $N \\log^2 N $ work), we can solve linear systems with this matrix with $N\n\\log N $ work. Kernel matrices represent pairwise interactions of points in\nmetric spaces. They appear in machine learning, approximation theory, and\ncomputational physics. Kernel matrices are typically dense (matrix\nmultiplication scales quadratically with $N$) and ill-conditioned (solves can\nrequire 100s of Krylov iterations). Thus, fast algorithms for matrix\nmultiplication and factorization are critical for scalability.\n  Recently we introduced ASKIT, a new method for approximating a kernel matrix\nthat resembles N-body methods. Here we introduce INV-ASKIT, a factorization\nscheme based on ASKIT. We describe the new method, derive complexity estimates,\nand conduct an empirical study of its accuracy and scalability. We report\nresults on real-world datasets including \"COVTYPE\" ($0.5$M points in 54\ndimensions), \"SUSY\" ($4.5$M points in 8 dimensions) and \"MNIST\" (2M points in\n784 dimensions) using shared and distributed memory parallelism. In our largest\nrun we approximately factorize a dense matrix of size 32M $\\times$ 32M\n(generated from points in 64 dimensions) on 4,096 Sandy-Bridge cores. To our\nknowledge these results improve the state of the art by several orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 17:23:24 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Yu", "Chenhan D.", ""], ["March", "William B.", ""], ["Xiao", "Bo", ""], ["Biros", "George", ""]]}, {"id": "1602.01506", "submitter": "Michael Friedlander", "authors": "Aleksandr Y. Aravkin, James V. Burke, Dmitriy Drusvyatskiy, Michael P.\n  Friedlander, Scott Roy", "title": "Level-set methods for convex optimization", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex optimization problems arising in applications often have favorable\nobjective functions and complicated constraints, thereby precluding first-order\nmethods from being immediately applicable. We describe an approach that\nexchanges the roles of the objective and constraint functions, and instead\napproximately solves a sequence of parametric level-set problems. A\nzero-finding procedure, based on inexact function evaluations and possibly\ninexact derivative information, leads to an efficient solution scheme for the\noriginal problem. We describe the theoretical and practical properties of this\napproach for a broad range of problems, including low-rank semidefinite\noptimization, sparse optimization, and generalized linear models for inference.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 22:58:44 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""], ["Drusvyatskiy", "Dmitriy", ""], ["Friedlander", "Michael P.", ""], ["Roy", "Scott", ""]]}, {"id": "1602.01626", "submitter": "Daniel Ruprecht", "authors": "Daniel Ruprecht and Robert Speck", "title": "Spectral deferred corrections with fast-wave slow-wave splitting", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing 38(4), pp. A2535-A2557, 2016", "doi": "10.1137/16M1060078", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates a variant of semi-implicit spectral deferred\ncorrections (SISDC) in which the stiff, fast dynamics correspond to fast\npropagating waves (\"fast-wave slow-wave problem\"). We show that for a scalar\ntest problem with two imaginary eigenvalues $i \\lambda_{fast}$, $i\n\\lambda_{slow}$, having $\\Delta t \\left(\\left| \\lambda_{fast} \\right| + \\left|\n\\lambda_{slow} \\right| \\right) < 1$ is sufficient for the fast-wave slow-wave\nSDC (FWSW-SDC) iteration to converge and that in the limit of infinitely fast\nwaves the convergence rate of the non-split version is retained. Stability\nfunction and discrete dispersion relation are derived and show that the method\nis stable for essentially arbitrary fast-wave CFL numbers as long as the slow\ndynamics are resolved. The method causes little numerical diffusion and its\nsemi-discrete phase speed is accurate also for large wave number modes.\nPerformance is studied for an acoustic-advection problem and for the linearised\nBoussinesq equations, describing compressible, stratified flow. FWSW-SDC is\ncompared to a diagonally implicit Runge-Kutta (DIRK) and IMEX Runge-Kutta\n(IMEX) method and found to be competitive in terms of both accuracy and cost.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 10:45:39 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 07:41:57 GMT"}], "update_date": "2016-08-18", "authors_parsed": [["Ruprecht", "Daniel", ""], ["Speck", "Robert", ""]]}, {"id": "1602.01768", "submitter": "Robert M. Gower", "authors": "Robert M. Gower and Peter Richt\\'arik", "title": "Randomized Quasi-Newton Updates are Linearly Convergent Matrix Inversion\n  Algorithms", "comments": "42 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and analyze a broad family of stochastic/randomized algorithms for\ninverting a matrix. We also develop specialized variants maintaining symmetry\nor positive definiteness of the iterates. All methods in the family converge\nglobally and linearly (i.e., the error decays exponentially), with explicit\nrates. In special cases, we obtain stochastic block variants of several\nquasi-Newton updates, including bad Broyden (BB), good Broyden (GB),\nPowell-symmetric-Broyden (PSB), Davidon-Fletcher-Powell (DFP) and\nBroyden-Fletcher-Goldfarb-Shanno (BFGS). Ours are the first stochastic versions\nof these updates shown to converge to an inverse of a fixed matrix. Through a\ndual viewpoint we uncover a fundamental link between quasi-Newton updates and\napproximate inverse preconditioning. Further, we develop an adaptive variant of\nrandomized block BFGS, where we modify the distribution underlying the\nstochasticity of the method throughout the iterative process to achieve faster\nconvergence. By inverting several matrices from varied applications, we\ndemonstrate that AdaRBFGS is highly competitive when compared to the well\nestablished Newton-Schulz and minimal residual methods. In particular, on\nlarge-scale problems our method outperforms the standard methods by orders of\nmagnitude. Development of efficient methods for estimating the inverse of very\nlarge matrices is a much needed tool for preconditioning and variable metric\noptimization methods in the advent of the big data era.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 18:08:22 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2016 16:41:17 GMT"}, {"version": "v3", "created": "Wed, 23 Mar 2016 18:41:22 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Gower", "Robert M.", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1602.02102", "submitter": "Austin Benson", "authors": "Austin R. Benson, David F. Gleich, Lek-Heng Lim", "title": "The Spacey Random Walk: a Stochastic Process for Higher-order Data", "comments": "Updated from V1: Expanded introduction; minor revisions; typos", "journal-ref": "SIAM Review, 59(2). 2017", "doi": "10.1137/16M1074023", "report-no": null, "categories": "cs.NA cs.SI math.DS math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walks are a fundamental model in applied mathematics and are a common\nexample of a Markov chain. The limiting stationary distribution of the Markov\nchain represents the fraction of the time spent in each state during the\nstochastic process. A standard way to compute this distribution for a random\nwalk on a finite set of states is to compute the Perron vector of the\nassociated transition matrix. There are algebraic analogues of this Perron\nvector in terms of transition probability tensors of higher-order Markov\nchains. These vectors are nonnegative, have dimension equal to the dimension of\nthe state space, and sum to one and are derived by making an algebraic\nsubstitution in the equation for the joint-stationary distribution of a\nhigher-order Markov chains. Here, we present the spacey random walk, a\nnon-Markovian stochastic process whose stationary distribution is given by the\ntensor eigenvector. The process itself is a vertex-reinforced random walk, and\nits discrete dynamics are related to a continuous dynamical system. We analyze\nthe convergence properties of these dynamics and discuss numerical methods for\ncomputing the stationary distribution. Finally, we provide several applications\nof the spacey random walk model in population genetics, ranking, and clustering\ndata, and we use the process to analyze taxi trajectory data in New York. This\nexample shows definite non-Markovian structure.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 17:22:21 GMT"}, {"version": "v2", "created": "Mon, 26 Dec 2016 23:33:01 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Benson", "Austin R.", ""], ["Gleich", "David F.", ""], ["Lim", "Lek-Heng", ""]]}, {"id": "1602.02164", "submitter": "David Gamarnik", "authors": "David Gamarnik and Sidhant Misra", "title": "A Note on Alternating Minimization Algorithm for the Matrix Completion\n  Problem", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": "10.1109/LSP.2016.2576979", "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing a low rank matrix from a subset of\nits entries and analyze two variants of the so-called Alternating Minimization\nalgorithm, which has been proposed in the past. We establish that when the\nunderlying matrix has rank $r=1$, has positive bounded entries, and the graph\n$\\mathcal{G}$ underlying the revealed entries has bounded degree and diameter\nwhich is at most logarithmic in the size of the matrix, both algorithms succeed\nin reconstructing the matrix approximately in polynomial time starting from an\narbitrary initialization. We further provide simulation results which suggest\nthat the second algorithm which is based on the message passing type updates,\nperforms significantly better.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 21:07:16 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Gamarnik", "David", ""], ["Misra", "Sidhant", ""]]}, {"id": "1602.02244", "submitter": "Rio Yokota Dr.", "authors": "Rio Yokota, Huda Ibeid, David Keyes", "title": "Fast Multipole Method as a Matrix-Free Hierarchical Low-Rank\n  Approximation", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a large increase in the amount of work on hierarchical\nlow-rank approximation methods, where the interest is shared by multiple\ncommunities that previously did not intersect. This objective of this article\nis two-fold; to provide a thorough review of the recent advancements in this\nfield from both analytical and algebraic perspectives, and to present a\ncomparative benchmark of two highly optimized implementations of contrasting\nmethods for some simple yet representative test cases. We categorize the recent\nadvances in this field from the perspective of compute-memory tradeoff, which\nhas not been considered in much detail in this area. Benchmark tests reveal\nthat there is a large difference in the memory consumption and performance\nbetween the different methods.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 12:04:14 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Yokota", "Rio", ""], ["Ibeid", "Huda", ""], ["Keyes", "David", ""]]}, {"id": "1602.02740", "submitter": "Maarten J. Kronenburg Ph.D.", "authors": "M.J. Kronenburg", "title": "Toom-Cook Multiplication: Some Theoretical and Practical Aspects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toom-Cook multiprecision multiplication is a well-known multiprecision\nmultiplication method, which can make use of multiprocessor systems. In this\npaper the Toom-Cook complexity is derived, some explicit proofs of the\nToom-Cook interpolation method are given, the even-odd method for interpolation\nis explained, and certain aspects of a 32-bit C++ and assembler implementation,\nwhich is in development, are discussed. A performance graph of this\nimplementation is provided. The Toom-Cook method can also be used to\nmultithread other types of multiplication, which is demonstrated for 32-bit GMP\nFFT multiplication.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 20:53:25 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Kronenburg", "M. J.", ""]]}, {"id": "1602.02886", "submitter": "Fabien Rozar", "authors": "F Rozar (IRFM, MDLS), C Steiner (IRMA, TONUS), G Latu (IRFM), M\n  Mehrenberger (IRMA, TONUS), V Grandgirard (IRFM), Julien Bigot (MDLS), T\n  Cartier-Michaud (IRFM), Jean Roman (HiePACS)", "title": "Optilization of the gyroaverage operator based on hermite interpolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gyrokinetic modeling is appropriate for describing Tokamak plasma turbulence,\nand the gyroaverage operator is a cornerstone of this approach. In a\ngyrokinetic code, the gyroaveraging scheme needs to be accurate enough to avoid\nspoiling the data but also requires a low computation cost because it is\napplied often on the main unknown, the 5D guiding-center distribution function,\nand on the 3D electric potentials. In the present paper, we improve a\ngyroaverage scheme based on Hermite interpolation used in the Gysela code. This\ninitial implementation represents a too large fraction of the total execution\ntime. The gyroaverage operator has been reformulated and is now expressed as a\nmatrix-vector product and a cache-friendly algorithm has been setup. Different\ntechniques have been investigated to quicken the computations by more than a\nfactor two. Description of the algorithms is given, together with an analysis\nof the achieved performance.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 08:08:34 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Rozar", "F", "", "IRFM, MDLS"], ["Steiner", "C", "", "IRMA, TONUS"], ["Latu", "G", "", "IRFM"], ["Mehrenberger", "M", "", "IRMA, TONUS"], ["Grandgirard", "V", "", "IRFM"], ["Bigot", "Julien", "", "MDLS"], ["Cartier-Michaud", "T", "", "IRFM"], ["Roman", "Jean", "", "HiePACS"]]}, {"id": "1602.03420", "submitter": "Xin Liang", "authors": "Peter Benner, Xin Liang, Suzana Miodragovi\\'c, Ninoslav Truhar", "title": "Relative Perturbation Theory for Quadratic Hermitian Eigenvalue Problem", "comments": "29 pages", "journal-ref": "Linear Algebra and its Applications, Volume 618, Pages 97-128,\n  2021", "doi": "10.1016/j.laa.2021.01.023", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive new relative perturbation bounds for eigenvectors\nand eigenvalues for regular quadratic eigenvalue problems of the form\n$\\lambda^2 M x + \\lambda C x + K x = 0$, where $M$ and $K$ are nonsingular\nHermitian matrices and $C$ is a general Hermitian matrix. We base our findings\non new results for an equivalent regular Hermitian matrix pair $A-\\lambda B$.\nThe new bounds can be applied to many interesting quadratic eigenvalue problems\nappearing in applications, such as mechanical models with indefinite damping.\nThe quality of our bounds is demonstrated by several numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 15:52:39 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2016 12:54:01 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 03:44:41 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 10:45:43 GMT"}, {"version": "v5", "created": "Thu, 22 Oct 2020 15:08:13 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Benner", "Peter", ""], ["Liang", "Xin", ""], ["Miodragovi\u0107", "Suzana", ""], ["Truhar", "Ninoslav", ""]]}, {"id": "1602.03641", "submitter": "Feng Xing", "authors": "Feng Xing (JAD, COFFEE, BRGM), Roland Masson (JAD, COFFEE), Simon\n  Lopez (BRGM)", "title": "Parallel Vertex Approximate Gradient discretization of hybrid\n  dimensional Darcy flow and transport in discrete fracture networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a parallel numerical algorithm to simulate the flow and\nthe transport in a discrete fracture network taking into account the mass\nexchanges with the surrounding matrix. The discretization of the Darcy fluxes\nis based on the Vertex Approximate Gradient finite volume scheme adapted to\npolyhedral meshes and to heterogeneous anisotropic media, and the transport\nequation is discretized by a first order upwind scheme combined with an Euler\nexplicit integration in time. The parallelization is based on the SPMD (Single\nProgram, Multiple Data) paradigm and relies on a distribution of the mesh on\nthe processes with one layer of ghost cells in order to allow for a local\nassembly of the discrete systems. The linear system for the Darcy flow is\nsolved using different linear solvers and preconditioners implemented in the\nPETSc and Trilinos libraries. The convergence of the scheme is validated on two\noriginal analytical solutions with one and four intersecting fractures. Then,\nthe parallel efficiency of the algorithm is assessed on up to 512 processes\nwith different types of meshes, different matrix fracture permeability ratios,\nand different levels of complexity of the fracture network.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 08:26:07 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 08:03:27 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Xing", "Feng", "", "JAD, COFFEE, BRGM"], ["Masson", "Roland", "", "JAD, COFFEE"], ["Lopez", "Simon", "", "BRGM"]]}, {"id": "1602.04847", "submitter": "Sebastien Bubeck", "authors": "S\\'ebastien Bubeck and Yin-Tat Lee", "title": "Black-box optimization with a politician", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for black-box convex optimization which is\nwell-suited for situations where gradient computations are expensive. We derive\na new method for this framework which leverages several concepts from convex\noptimization, from standard first-order methods (e.g. gradient descent or\nquasi-Newton methods) to analytical centers (i.e. minimizers of self-concordant\nbarriers). We demonstrate empirically that our new technique compares favorably\nwith state of the art algorithms (such as BFGS).\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 21:35:58 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Lee", "Yin-Tat", ""]]}, {"id": "1602.05444", "submitter": "Gerlind Plonka", "authors": "Gerlind Plonka and Katrin Wannenwetsch", "title": "A sparse Fast Fourier Algorithm for Real Nonnegative Vectors", "comments": null, "journal-ref": "Journal of Computational and Applied Mathematics 321 (2017),\n  532-539", "doi": "10.1016/j.cam.2017.03.019", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new fast Fourier transform to recover a real\nnonnegative signal ${\\bf x}$ from its discrete Fourier transform. If the signal\n${\\mathbf x}$ appears to have a short support, i.e., vanishes outside a support\ninterval of length $m < N$, then the algorithm has an arithmetical complexity\nof only ${\\cal O}(m \\log m \\log (N/m)) $ and requires ${\\cal O}(m \\log (N/m))$\nFourier samples for this computation. In contrast to other approaches there is\nno a priori knowledge needed about sparsity or support bounds for the vector\n${\\bf x}$. The algorithm automatically recognizes and exploits a possible short\nsupport of the vector and falls back to a usual radix-2 FFT algorithm if ${\\bf\nx}$ has (almost) full support. The numerical stability of the proposed\nalgorithm ist shown by numerical examples.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 15:00:50 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 08:38:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Plonka", "Gerlind", ""], ["Wannenwetsch", "Katrin", ""]]}, {"id": "1602.05754", "submitter": "Balthasar Reuter", "authors": "Balthasar Reuter, Vadym Aizinger, Manuel Wieland, Florian Frank, Peter\n  Knabner", "title": "FESTUNG: A MATLAB / GNU Octave toolbox for the discontinuous Galerkin\n  method. Part II: Advection operator and slope limiting", "comments": "Updated with the accepted manuscript", "journal-ref": "Computers & Mathematics with Applications, Volume 72, Issue 7,\n  October 2016, Pages 1896-1925", "doi": "10.1016/j.camwa.2016.08.006", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the second in a series of papers on implementing a discontinuous\nGalerkin (DG) method as an open source Matlab / GNU Octave toolbox. The\nintention of this ongoing project is to offer a rapid prototyping package for\napplication development using DG methods. The implementation relies on fully\nvectorized matrix / vector operations and is comprehensively documented.\nParticular attention was paid to maintaining a direct mapping between\ndiscretization terms and code routines as well as to supporting the full code\nfunctionality in GNU Octave. The present work focuses on a two-dimensional\ntime-dependent linear advection equation with space / time-varying\ncoefficients, and provides a general order implementation of several slope\nlimiting schemes for the DG method.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 11:04:06 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 11:41:58 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Reuter", "Balthasar", ""], ["Aizinger", "Vadym", ""], ["Wieland", "Manuel", ""], ["Frank", "Florian", ""], ["Knabner", "Peter", ""]]}, {"id": "1602.05950", "submitter": "David Anderson", "authors": "David G. Anderson and Ming Gu", "title": "An Efficient, Sparsity-Preserving, Online Algorithm for Low-Rank\n  Approximation", "comments": null, "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning, 70: 156-165 (2017)", "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank matrix approximation is a fundamental tool in data analysis for\nprocessing large datasets, reducing noise, and finding important signals. In\nthis work, we present a novel truncated LU factorization called\nSpectrum-Revealing LU (SRLU) for effective low-rank matrix approximation, and\ndevelop a fast algorithm to compute an SRLU factorization. We provide both\nmatrix and singular value approximation error bounds for the SRLU approximation\ncomputed by our algorithm. Our analysis suggests that SRLU is competitive with\nthe best low-rank matrix approximation methods, deterministic or randomized, in\nboth computational complexity and approximation quality. Numeric experiments\nillustrate that SRLU preserves sparsity, highlights important data features and\nvariables, can be efficiently updated, and calculates data approximations\nnearly as accurately as possible. To the best of our knowledge this is the\nfirst practical variant of the LU factorization for effective and efficient\nlow-rank matrix approximation.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 20:58:20 GMT"}, {"version": "v2", "created": "Fri, 18 Aug 2017 05:17:50 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Anderson", "David G.", ""], ["Gu", "Ming", ""]]}, {"id": "1602.06620", "submitter": "Paul Constantine", "authors": "Kerrek Stinson and David F. Gleich and Paul G. Constantine", "title": "A randomized algorithm for enumerating zonotope vertices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a randomized algorithm for enumerating the vertices of a zonotope,\nwhich is a low-dimensional linear projection of a hypercube. The algorithm\nproduces a pair of the zonotope's vertices by sampling a random linear\ncombination of the zonotope generators, where the combination's weights are the\nsigns of the product between the zonotope's generator matrix and random vectors\nwith normally distributed entries. We study the probability of recovering\nparticular vertices and relate it to the vertices' normal cones. This study\nshows that if we terminate the randomized algorithm before all vertices are\nrecovered, then the convex hull of the resulting vertex set approximates the\nzonotope. In high dimensions, we expect the enumeration algorithm to be most\nappropriate as an approximation algorithm---particularly for cases when\nexisting methods are not practical.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 01:35:37 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Stinson", "Kerrek", ""], ["Gleich", "David F.", ""], ["Constantine", "Paul G.", ""]]}, {"id": "1602.07067", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai", "title": "Online Low-Rank Tensor Subspace Tracking from Incomplete Data by CP\n  Decomposition using Recursive Least Squares", "comments": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP 2016)", "journal-ref": null, "doi": "10.1109/ICASSP.2016.7472131", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online tensor subspace tracking algorithm based on the CP\ndecomposition exploiting the recursive least squares (RLS), dubbed OnLine\nLow-rank Subspace tracking by TEnsor CP Decomposition (OLSTEC). Numerical\nevaluations show that the proposed OLSTEC algorithm gives faster convergence\nper iteration comparing with the state-of-the-art online algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 07:40:40 GMT"}, {"version": "v2", "created": "Fri, 19 Aug 2016 23:13:27 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Kasai", "Hiroyuki", ""]]}, {"id": "1602.07558", "submitter": "Maitham Alhubail", "authors": "Maitham Makki Alhubail, Qiqi Wang, John Williams", "title": "The swept rule for breaking the latency barrier in time advancing\n  two-dimensional PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a method to accelerate parallel, explicit time\nintegration of two-dimensional unsteady PDEs. The method is motivated by our\nobservation that latency, not bandwidth, often limits how fast PDEs can be\nsolved in parallel. The method is called the swept rule of space-time domain\ndecomposition. Compared to conventional, space-only domain decomposition, it\ncommunicates similar amount of data, but in fewer messages. The swept rule\nachieves this by decomposing space and time among computing nodes in ways that\nexploit the domains of influence and the domain of dependency, making it\npossible to communicate once per many time steps with no redundant computation.\nBy communicating less often, the swept rule effectively breaks the latency\nbarrier, advancing on average more than one time step per ping-pong latency of\nthe network. The article presents simple theoretical analysis to the\nperformance of the swept rule in two spatial dimensions, and supports the\nanalysis with numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 17:42:36 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 17:00:21 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Alhubail", "Maitham Makki", ""], ["Wang", "Qiqi", ""], ["Williams", "John", ""]]}, {"id": "1602.07764", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli, Alessandro Lazaric, Animashree Anandkumar", "title": "Reinforcement Learning of POMDPs using Spectral Methods", "comments": null, "journal-ref": "29th Annual Conference on Learning Theory, PMLR 49:193-256, 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new reinforcement learning algorithm for partially observable\nMarkov decision processes (POMDP) based on spectral decomposition methods.\nWhile spectral methods have been previously employed for consistent learning of\n(passive) latent variable models such as hidden Markov models, POMDPs are more\nchallenging since the learner interacts with the environment and possibly\nchanges the future observations in the process. We devise a learning algorithm\nrunning through episodes, in each episode we employ spectral techniques to\nlearn the POMDP parameters from a trajectory generated by a fixed policy. At\nthe end of the episode, an optimization oracle returns the optimal memoryless\nplanning policy which maximizes the expected reward based on the estimated\nPOMDP model. We prove an order-optimal regret bound with respect to the optimal\nmemoryless policy and efficient scaling with respect to the dimensionality of\nobservation and action spaces.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 01:25:36 GMT"}, {"version": "v2", "created": "Sun, 29 May 2016 07:15:21 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""], ["Lazaric", "Alessandro", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1602.08391", "submitter": "Vladymyr Shcherbakov", "authors": "V.I. Shcherbakov", "title": "Ultrafast a Distributed Arithmetic in multi-row codes", "comments": "22pages (russian-original) + 19 pages(english-robotic translationn)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the matrix structure of arithmetic processors based\non distributed arithmetic in multi-row codes. Scope - development of\nsupercomputers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 14:44:44 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Shcherbakov", "V. I.", ""]]}, {"id": "1602.08800", "submitter": "Vitaly Bulgakov", "authors": "Vitaly Bulgakov", "title": "Iterative Aggregation Method for Solving Principal Component Analysis\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Motivated by the previously developed multilevel aggregation method for\nsolving structural analysis problems a novel two-level aggregation approach for\nefficient iterative solution of Principal Component Analysis (PCA) problems is\nproposed. The course aggregation model of the original covariance matrix is\nused in the iterative solution of the eigenvalue problem by a power iterations\nmethod. The method is tested on several data sets consisting of large number of\ntext documents.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 02:40:05 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Bulgakov", "Vitaly", ""]]}, {"id": "1602.08895", "submitter": "Rafa{\\l} Nowak", "authors": "Rafa{\\l} Nowak, Pawe{\\l} Wo\\'zny", "title": "New properties of a certain method of summation of generalized\n  hypergeometric series", "comments": "revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper (Appl. Math. Comput. 215, 1622--1645, 2009), the authors\nproposed a method of summation of some slowly convergent series. The purpose of\nthis note is to give more theoretical analysis for this transformation,\nincluding the convergence acceleration theorem in the case of summation of\ngeneralized hypergeometric series. Some new theoretical results and\nillustrative numerical examples are given.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 10:32:13 GMT"}, {"version": "v2", "created": "Fri, 11 Mar 2016 10:51:12 GMT"}, {"version": "v3", "created": "Mon, 5 Sep 2016 10:15:50 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Nowak", "Rafa\u0142", ""], ["Wo\u017any", "Pawe\u0142", ""]]}]