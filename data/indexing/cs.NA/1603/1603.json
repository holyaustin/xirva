[{"id": "1603.00175", "submitter": "Shoji Itoh", "authors": "Shoji Itoh and Masaaki Sugihara", "title": "Structure of the polynomials in preconditioned BiCG algorithms and the\n  switching direction of preconditioned systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theorem that defines the direction of a preconditioned system\nfor the bi-conjugate gradient (BiCG) method, and we extend it to preconditioned\nbi-Lanczos-type algorithms. We show that the direction of a preconditioned\nsystem is switched by construction and by the settings of the initial shadow\nresidual vector. We analyze and compare the polynomial structures of four\npreconditioned BiCG algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 08:14:33 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2016 02:10:13 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 02:48:33 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Itoh", "Shoji", ""], ["Sugihara", "Masaaki", ""]]}, {"id": "1603.00176", "submitter": "Shoji Itoh", "authors": "Shoji Itoh and Masaaki Sugihara", "title": "Structure of the preconditioned system in various preconditioned\n  conjugate gradient squared algorithms", "comments": null, "journal-ref": "Results in Applied Mathematics 2C (2019) 100008", "doi": "10.1016/j.rinam.2019.100008", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An improved preconditioned conjugate gradient squared (PCGS) algorithm has\nrecently been proposed, and it performs much better than the conventional PCGS\nalgorithm. In this paper, the improved PCGS algorithm is verified as a\ncoordinative to the left-preconditioned system, and it has the advantages of\nboth the conventional and the left-PCGS; this is done by comparing, analyzing,\nand executing numerical examinations of various PCGS algorithms, including\nanother improved one. We show that the direction of the preconditioned system\nfor the CGS method is determined by the operations of $\\alpha_k$ and $\\beta_k$\nin the PCGS algorithm. By comparing the logical structures of these algorithms,\nwe show that the direction of the preconditioned system can be switched by the\nconstruction and setting of the initial shadow residual vector.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 08:15:52 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2016 01:58:33 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 08:14:55 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Itoh", "Shoji", ""], ["Sugihara", "Masaaki", ""]]}, {"id": "1603.00210", "submitter": "Jiasong Wu", "authors": "Jiasong Wu, Jieyuan Liu, Youyong Kong, Xu Han, Lotfi Senhadji,\n  Huazhong Shu", "title": "Phase-only signal reconstruction by MagnitudeCut", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new algorithm, called MagnitudeCut, for\nrecovering a signal from the phase of its Fourier transform. We casted our\nrecovering problem into a new convex optimization problem, and then solved it\nby the block coordinate descent algorithm and the interior point algorithm, in\nwhich the iteration process consists of matrix vector product and inner\nproduct. We used the new method for reconstruction of a set of signal/image.\nThe simulation results reveal that the proposed MagnitudeCut method can\nreconstruct the original signal with fewer sampling number of the phase\ninformation than that of the Greedy algorithm and iterative method under the\nsame reconstruction error. Moreover, our algorithm can also reconstruct the\nsymmetric image from its Fourier phase.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 10:09:16 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Wu", "Jiasong", ""], ["Liu", "Jieyuan", ""], ["Kong", "Youyong", ""], ["Han", "Xu", ""], ["Senhadji", "Lotfi", ""], ["Shu", "Huazhong", ""]]}, {"id": "1603.00491", "submitter": "Marat Dukhan", "authors": "Marat Dukhan, Richard Vuduc, Jason Riedy", "title": "Wanted: Floating-Point Add Round-off Error instruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new instruction (FPADDRE) that computes the round-off error in\nfloating-point addition. We explain how this instruction benefits\nhigh-precision arithmetic operations in applications where double precision is\nnot sufficient. Performance estimates on Intel Haswell, Intel Skylake, and AMD\nSteamroller processors, as well as Intel Knights Corner co-processor,\ndemonstrate that such an instruction would improve the latency of double-double\naddition by up to 55% and increase double-double addition throughput by up to\n103%, with smaller, but non-negligible benefits for double-double\nmultiplication. The new instruction delivers up to 2x speedups on three\nbenchmarks that use high-precision floating-point arithmetic: double-double\nmatrix-matrix multiplication, compensated dot product, and polynomial\nevaluation via the compensated Horner scheme.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 21:12:09 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Dukhan", "Marat", ""], ["Vuduc", "Richard", ""], ["Riedy", "Jason", ""]]}, {"id": "1603.01372", "submitter": "Petr  Tichavsky", "authors": "Petr Tichavsky, Anh Huy Phan, Andrzej Cichocki", "title": "Numerical CP Decomposition of Some Difficult Tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a numerical method is proposed for canonical polyadic (CP)\ndecomposition of small size tensors. The focus is primarily on decomposition of\ntensors that correspond to small matrix multiplications. Here, rank of the\ntensors is equal to the smallest number of scalar multiplications that are\nnecessary to accomplish the matrix multiplication. The proposed method is based\non a constrained Levenberg-Marquardt optimization. Numerical results indicate\nthe rank and border ranks of tensors that correspond to multiplication of\nmatrices of the size 2x3 and 3x2, 3x3 and 3x2, 3x3 and 3x3, and 3x4 and 4x3.\nThe ranks are 11, 15, 23 and 29, respectively. In particular, a novel algorithm\nfor multiplying the matrices of the sizes 3x3 and 3x2 with 15 multiplications\nis presented.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 08:18:11 GMT"}], "update_date": "2016-03-07", "authors_parsed": [["Tichavsky", "Petr", ""], ["Phan", "Anh Huy", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1603.01562", "submitter": "Ellen Le", "authors": "Ellen B. Le, Aaron Myers, Tan Bui-Thanh and Quoc P. Nguyen", "title": "A Data-Scalable Randomized Misfit Approach for Solving Large-Scale\n  PDE-Constrained Inverse Problems", "comments": "29 pages", "journal-ref": null, "doi": "10.1088/1361-6420/aa6cbd", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A randomized misfit approach is presented for the efficient solution of\nlarge-scale PDE-constrained inverse problems with high-dimensional data. The\npurpose of this paper is to offer a theory-based framework for random\nprojections in this inverse problem setting. The stochastic approximation to\nthe misfit is analyzed using random projection theory. By expanding beyond mean\nestimator convergence, a practical characterization of randomized misfit\nconvergence can be achieved. The theoretical results developed hold with any\nvalid random projection in the literature. The class of feasible distributions\nis broad yet simple to characterize compared to previous stochastic misfit\nmethods. This class includes very sparse random projections which provide\nadditional computational benefit. A different proof for a variant of the\nJohnson-Lindenstrauss lemma is also provided. This leads to a different\nintuition for the $O(\\epsilon^{-2})$ factor in bounds for Johnson-Lindenstrauss\nresults. The main contribution of this paper is a theoretical result showing\nthe method guarantees a valid solution for small reduced misfit dimensions. The\ninterplay between Johnson-Lindenstrauss theory and Morozov's discrepancy\nprinciple is shown to be essential to the result. The computational cost\nsavings for large-scale PDE-constrained problems with high- dimensional data is\ndiscussed. Numerical verification of the developed theory is presented for\nmodel problems of estimating a distributed parameter in an elliptic partial\ndifferential equation. Results with different random projections are presented\nto demonstrate the viability and accuracy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 18:26:27 GMT"}, {"version": "v2", "created": "Fri, 10 Feb 2017 06:34:51 GMT"}, {"version": "v3", "created": "Mon, 17 Apr 2017 15:52:43 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Le", "Ellen B.", ""], ["Myers", "Aaron", ""], ["Bui-Thanh", "Tan", ""], ["Nguyen", "Quoc P.", ""]]}, {"id": "1603.01765", "submitter": "Mark Tygert", "authors": "Arthur Szlam, Andrew Tulloch, and Mark Tygert", "title": "Accurate principal component analysis via a few iterations of\n  alternating least squares", "comments": "9 pages, 3 tables", "journal-ref": "SIAM Journal on Matrix Analysis and Applications, 38 (2): 425-433,\n  2017", "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A few iterations of alternating least squares with a random starting point\nprovably suffice to produce nearly optimal spectral- and Frobenius-norm\naccuracies of low-rank approximations to a matrix; iterating to convergence is\nunnecessary. Thus, software implementing alternating least squares can be\nretrofitted via appropriate setting of parameters to calculate nearly optimally\naccurate low-rank approximations highly efficiently, with no need for\nconvergence.\n", "versions": [{"version": "v1", "created": "Sat, 5 Mar 2016 22:30:38 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Szlam", "Arthur", ""], ["Tulloch", "Andrew", ""], ["Tygert", "Mark", ""]]}, {"id": "1603.01793", "submitter": "Andrey Shanin V", "authors": "J. Poblet-Puig and A. V. Shanin", "title": "A New Numerical Method for Solving the Acoustic Radiation Problem", "comments": null, "journal-ref": "Poblet-Puig J., Shanin A.V., A new numerical method for solving\n  the acoustic radiation problem. Acoustical Physics. Vol. 64, no. 2. PP.\n  252-259 (2018)", "doi": "10.1134/S1063771018020148", "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A numerical method of solving the problem of acoustic wave radiation in the\npresence of a rigid scatterer is described. It combines the finite element\nmethod and the boundary algebraic equations. In the proposed method, the\nexterior domain around the scatterer is discretized, so that there appear an\ninfinite domain with regular discretization and a relatively small layer with\nirregular mesh. For the infinite regular mesh, the boundary algebraic equation\nmethod is used with spurious resonance suppression according to Burton and\nMiller. In the thin layer with irregular mesh, the finite element method is\nused. The proposed method is characterized by simple implementation, fair\naccuracy, and absence of spurious resonances.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2016 06:21:30 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 08:51:02 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Poblet-Puig", "J.", ""], ["Shanin", "A. V.", ""]]}, {"id": "1603.03532", "submitter": "Bao Xu", "authors": "Bao Xu", "title": "Regularization to orthogonal-polynomials fitting with application to\n  magnetization data", "comments": "10 pages, 1 figure, 3 tables; comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cond-mat.mtrl-sci physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An obstacle encountered in applying orthogonal-polynomials fitting is how to\nselect out the proper fitting expression. By adding a Laplace term to the error\nexpression and introducing the concept of overfitting degree, a regularization\nand corresponding cross validation scheme is proposed for two-variable\npolynomials fitting. While the Fortran implementation of above scheme is\napplied to magnetization data, a satisfactory fitting precision is reached, and\noverfitting problem can be quantitatively assessed, which therefore offers the\nquite reliable base for future comprehensive investigations of magnetocaloric\nand phase-transition properties of magnetic functional materials.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2016 06:13:23 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Xu", "Bao", ""]]}, {"id": "1603.03650", "submitter": "Ilker Bayram", "authors": "\\.Ilker Bayram and Sava\\c{s}kan Bulek", "title": "A Penalty Function Promoting Sparsity Within and Across Groups", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2017.2709260", "report-no": null, "categories": "cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new weakly-convex penalty function for signals with a group\nbehavior. The penalty promotes signals with a few number of active groups,\nwhere within each group, only a few high magnitude coefficients are active. We\nderive the threshold function associated with the proposed penalty and study\nits properties. We discuss how the proposed penalty/threshold function can be\nuseful for signals with isolated non-zeros, such as audio with isolated\nharmonics along the frequency axis, or reflection functions in exploration\nseismology where the non-zeros occur on the boundaries of subsoil layers. We\ndemonstrate the use of the proposed penalty/threshold functions in a convex\ndenoising and a non-convex deconvolution formulation. We provide convergent\nalgorithms for both formulations and compare the performance with\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2016 14:47:38 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 08:06:52 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Bayram", "\u0130lker", ""], ["Bulek", "Sava\u015fkan", ""]]}, {"id": "1603.03945", "submitter": "Piotr Zgliczy\\'nski", "authors": "Ma{\\l}gorzata Moczurad, Piotr Zgliczy\\'nski", "title": "On the Petras algorithm for verified integration of piecewise analytic\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the algorithm for verified integration of piecewise analytic\nfunctions given by Petras. The analysis of the algorithm contained in Patras'\npaper is limited to a narrow class of functions and gives upper bounds only. We\npresent an estimation of the complexity (measured by a number of evaluations of\nan integrand) of the algorithm, both upper and lower bounds, for a wider class\nof functions. We show examples with complexity $\\Theta(|\\ln\\eps|/\\eps^{p-1})$,\nfor any $p >1$, where $\\eps$ is the desired accuracy of the computed integral.\n", "versions": [{"version": "v1", "created": "Sat, 12 Mar 2016 17:24:34 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Moczurad", "Ma\u0142gorzata", ""], ["Zgliczy\u0144ski", "Piotr", ""]]}, {"id": "1603.05621", "submitter": "Yun S. Song", "authors": "Miaoyan Wang, Khanh Dao Duc, Jonathan Fischer, Yun S. Song", "title": "Operator Norm Inequalities between Tensor Unfoldings on the Partition\n  Lattice", "comments": "17 pages, 1 figure", "journal-ref": "Linear Algebra and its Applications, Vol. 520 (2017) 44-66", "doi": "10.1016/j.laa.2017.01.017", "report-no": null, "categories": "math.NA cs.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in higher-order tensors has recently surged in data-intensive\nfields, with a wide range of applications including image processing, blind\nsource separation, community detection, and feature extraction. A common\nparadigm in tensor-related algorithms advocates unfolding (or flattening) the\ntensor into a matrix and applying classical methods developed for matrices.\nDespite the popularity of such techniques, how the functional properties of a\ntensor changes upon unfolding is currently not well understood. In contrast to\nthe body of existing work which has focused almost exclusively on\nmatricizations, we here consider all possible unfoldings of an order-$k$\ntensor, which are in one-to-one correspondence with the set of partitions of\n$\\{1,\\ldots,k\\}$. We derive general inequalities between the $l^p$-norms of\narbitrary unfoldings defined on the partition lattice. In particular, we\ndemonstrate how the spectral norm ($p=2$) of a tensor is bounded by that of its\nunfoldings, and obtain an improved upper bound on the ratio of the Frobenius\nnorm to the spectral norm of an arbitrary tensor. For specially-structured\ntensors satisfying a generalized definition of orthogonal decomposability, we\nprove that the spectral norm remains invariant under specific subsets of\nunfolding operations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 19:09:05 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2017 03:17:08 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Wang", "Miaoyan", ""], ["Duc", "Khanh Dao", ""], ["Fischer", "Jonathan", ""], ["Song", "Yun S.", ""]]}, {"id": "1603.05719", "submitter": "Michael Friedlander", "authors": "Michael P. Friedlander and Gabriel Goh", "title": "Efficient evaluation of scaled proximal operators", "comments": "23 pages", "journal-ref": "Electronic Transactions on Numerical Analysis, 46:1-22, 2017", "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic-support functions [Aravkin, Burke, and Pillonetto; J. Mach. Learn.\nRes. 14(1), 2013] constitute a parametric family of convex functions that\nincludes a range of useful regularization terms found in applications of convex\noptimization. We show how an interior method can be used to efficiently compute\nthe proximal operator of a quadratic-support function under different metrics.\nWhen the metric and the function have the right structure, the proximal map can\nbe computed with cost nearly linear in the input size. We describe how to use\nthis approach to implement quasi-Newton methods for a rich class of nonsmooth\nproblems that arise, for example, in sparse optimization, image denoising, and\nsparse logistic regression.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 22:53:22 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2016 20:08:19 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Friedlander", "Michael P.", ""], ["Goh", "Gabriel", ""]]}, {"id": "1603.05988", "submitter": "Arjun Gambhir", "authors": "Arjun Singh Gambhir, Andreas Stathopoulos, Kostas Orginos", "title": "Deflation as a Method of Variance Reduction for Estimating the Trace of\n  a Matrix Inverse", "comments": "21 pages, 24 figures", "journal-ref": "SIAM J. Sci. Comput., 39(2), A532 to A558, 2017", "doi": "10.1137/16M1066361", "report-no": null, "categories": "hep-lat cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many fields require computing the trace of the inverse of a large, sparse\nmatrix. The typical method used for such computations is the Hutchinson method\nwhich is a Monte Carlo (MC) averaging over matrix quadratures. To improve its\nconvergence, several variance reductions techniques have been proposed. In this\npaper, we study the effects of deflating the near null singular value space. We\nmake two main contributions.\n  First, we analyze the variance of the Hutchinson method as a function of the\ndeflated singular values and vectors. Although this provides good intuition in\ngeneral, by assuming additionally that the singular vectors are random unitary\nmatrices, we arrive at concise formulas for the deflated variance that include\nonly the variance and mean of the singular values. We make the remarkable\nobservation that deflation may increase variance for Hermitian matrices but not\nfor non-Hermitian ones. This is a rare, if not unique, property where\nnon-Hermitian matrices outperform Hermitian ones. The theory can be used as a\nmodel for predicting the benefits of deflation.\n  Second, we use deflation in the context of a large scale application of\n\"disconnected diagrams\" in Lattice QCD. On lattices, Hierarchical Probing (HP)\nhas previously provided an order of magnitude of variance reduction over MC by\nremoving \"error\" from neighboring nodes of increasing distance in the lattice.\nAlthough deflation used directly on MC yields a limited improvement of 30% in\nour problem, when combined with HP they reduce variance by a factor of over 60\ncompared to MC. For this, we pre-computated 1000 smallest singular values of an\nill-conditioned matrix of size 25 million. Using PRIMME and a domain-specific\nAlgebraic Multigrid preconditioner, we perform one of the largest eigenvalue\ncomputations in Lattice QCD at a fraction of the cost of our trace computation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2016 20:34:32 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2016 18:16:55 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Gambhir", "Arjun Singh", ""], ["Stathopoulos", "Andreas", ""], ["Orginos", "Kostas", ""]]}, {"id": "1603.06511", "submitter": "Lijing Zhao", "authors": "Lijing Zhao, Weihua Deng, and Jan S Hesthaven", "title": "Characterization of Image Spaces of Riemann-Liouville Fractional\n  Integral Operators on Sobolev Spaces $W^{m,p}(\\Omega)$", "comments": "24 pages, 2 figures. Been accepted for publication in SCIENCE CHINA\n  Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractional operators are widely used in mathematical models describing\nabnormal and nonlocal phenomena. Although there are extensive numerical methods\nfor solving the corresponding model problems, theoretical analysis such as the\nregularity result, or the relationship between the left-side and right-side\nfractional operators are seldom mentioned. In stead of considering the\nfractional derivative spaces, this paper starts from discussing the image\nspaces of Riemann-Liouville fractional integrals of $L_p(\\Omega)$ functions,\nsince the fractional derivative operators that often used are all\npseudo-differential. Then high regularity situation---the image spaces of\nRiemann-Liouville fractional integral operators on $W^{m,p}(\\Omega)$ space are\nconsidered. Equivalent characterizations of the defined spaces, as well as of\nthe intersection of the left-side and right-side spaces are given. The behavior\nof the functions in the defined spaces at both the nearby boundary point/ponits\nand the points in the domain are demonstrated in a clear way. Besides, tempered\nfractional operators show to be reciprocal to the corresponding\nRiemann-Liouville fractional operators, which is expected to make some efforts\non theoretical support for relevant numerical methods. Last, we also provide\nsome instructions on how to take advantage of the introduced spaces when\nnumerically solving fractional equations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2016 17:35:38 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 06:05:33 GMT"}, {"version": "v3", "created": "Sun, 28 Jun 2020 08:25:17 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Zhao", "Lijing", ""], ["Deng", "Weihua", ""], ["Hesthaven", "Jan S", ""]]}, {"id": "1603.06912", "submitter": "Tao Sun", "authors": "Tao Sun, Lizhi Chenga, Hao Jiang", "title": "A note on the convergence of nonconvex line search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we consider the line search for a class of abstract nonconvex\nalgorithm which have been deeply studied in the Kurdyka-Lojasiewicz theory. We\nprovide a weak convergence result of the line search in general. When the\nobjective function satisfies the Kurdyka-Lojasiewicz property and some certain\nassumption, a global convergence result can be derived. An application is\npresented for the L0-regularized least square minimization in the end of the\npaper.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2016 14:53:54 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Sun", "Tao", ""], ["Chenga", "Lizhi", ""], ["Jiang", "Hao", ""]]}, {"id": "1603.07298", "submitter": "Marcin Bilski", "authors": "Marcin Bilski, Peter Scheiblechner", "title": "Effective approximation of the solutions of algebraic equations", "comments": "44 pages; presentation of the results improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CV cs.NA math.AG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let F be a holomorphic map whose components satisfy some polynomial\nrelations. We present an algorithm for constructing Nash maps locally\napproximating F, whose components satisfy the same relations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 18:39:28 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 20:01:04 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Bilski", "Marcin", ""], ["Scheiblechner", "Peter", ""]]}, {"id": "1603.08785", "submitter": "Nikolaus Hansen", "authors": "Nikolaus Hansen (RANDOPT), Anne Auger (RANDOPT), Raymond Ros (TAO),\n  Olaf Mersmann (TU), Tea Tu\\v{s}ar (IJS), Dimo Brockhoff (RANDOPT)", "title": "COCO: A Platform for Comparing Continuous Optimizers in a Black-Box\n  Setting", "comments": "Optimization Methods and Software, Taylor & Francis, In press,\n  pp.1-31", "journal-ref": null, "doi": "10.1080/10556788.2020.1808977", "report-no": null, "categories": "cs.AI cs.MS cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce COCO, an open source platform for Comparing Continuous\nOptimizers in a black-box setting. COCO aims at automatizing the tedious and\nrepetitive task of benchmarking numerical optimization algorithms to the\ngreatest possible extent. The platform and the underlying methodology allow to\nbenchmark in the same framework deterministic and stochastic solvers for both\nsingle and multiobjective optimization. We present the rationales behind the\n(decade-long) development of the platform as a general proposition for\nguidelines towards better benchmarking. We detail underlying fundamental\nconcepts of COCO such as the definition of a problem as a function instance,\nthe underlying idea of instances, the use of target values, and runtime defined\nby the number of function calls as the central performance measure. Finally, we\ngive a quick overview of the basic code structure and the currently available\ntest suites.\n", "versions": [{"version": "v1", "created": "Tue, 29 Mar 2016 14:18:52 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 06:27:09 GMT"}, {"version": "v3", "created": "Mon, 1 Aug 2016 15:19:31 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2020 14:41:57 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hansen", "Nikolaus", "", "RANDOPT"], ["Auger", "Anne", "", "RANDOPT"], ["Ros", "Raymond", "", "TAO"], ["Mersmann", "Olaf", "", "TU"], ["Tu\u0161ar", "Tea", "", "IJS"], ["Brockhoff", "Dimo", "", "RANDOPT"]]}, {"id": "1603.09133", "submitter": "Daria Sushnikova", "authors": "Daria A. Sushnikova and Ivan V. Oseledets", "title": "\"Compress and eliminate\" solver for symmetric positive definite sparse\n  matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approximate factorization for solving linear systems with\nsymmetric positive definite sparse matrices. In a nutshell the algorithm is to\napply hierarchically block Gaussian elimination and additionally compress the\nfill-in. The systems that have efficient compression of the fill-in mostly\narise from discretization of partial differential equations. We show that the\nresulting factorization can be used as an efficient preconditioner and compare\nthe proposed approach with state-of-art direct and iterative solvers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Mar 2016 11:27:01 GMT"}, {"version": "v2", "created": "Sun, 10 Apr 2016 10:03:17 GMT"}, {"version": "v3", "created": "Sat, 19 Nov 2016 14:38:41 GMT"}, {"version": "v4", "created": "Sat, 5 May 2018 12:36:00 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Sushnikova", "Daria A.", ""], ["Oseledets", "Ivan V.", ""]]}, {"id": "1603.09325", "submitter": "Rebecca Conley", "authors": "Rebecca Conley, Xiangmin Jiao, and Tristan J. Delaney", "title": "A Hybrid Method and Unified Analysis of Generalized Finite Differences\n  and Lagrange Finite Elements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite differences, finite elements, and their generalizations are widely\nused for solving partial differential equations, and their high-order variants\nhave respective advantages and disadvantages. Traditionally, these methods are\ntreated as different (strong vs. weak) formulations and are analyzed using\ndifferent techniques (Fourier analysis or Green's functions vs. functional\nanalysis), except for some special cases on regular grids. Recently, the\nauthors introduced a hybrid method, called Adaptive Extended Stencil FEM or\nAES-FEM (Int. J. Num. Meth. Engrg., 2016, DOI:10.1002/nme.5246), which combines\nfeatures of generalized finite differences and Lagrange finite elements to\nachieve second-order accuracy over unstructured meshes. However, its analysis\nwas incomplete due to the lack of existing mathematical theory that unifies the\nformulations and analysis of these different methods. In this work, we\nintroduce the framework of generalized weighted residuals to unify the\nformulation of finite differences, finite elements, and AES-FEM. In addition,\nwe propose a unified analysis of the well-posedness, convergence, and\nmesh-quality dependency of these different methods. We also report numerical\nresults with AES-FEM to verify our analysis. We show that AES-FEM improves the\naccuracy of generalized finite differences while reducing the mesh-quality\ndependency and simplifying the implementation of high-order finite elements.\n", "versions": [{"version": "v1", "created": "Wed, 30 Mar 2016 19:45:38 GMT"}, {"version": "v2", "created": "Wed, 13 Apr 2016 02:02:13 GMT"}, {"version": "v3", "created": "Tue, 26 Apr 2016 14:45:02 GMT"}, {"version": "v4", "created": "Mon, 9 May 2016 18:22:44 GMT"}, {"version": "v5", "created": "Sat, 1 Sep 2018 03:16:06 GMT"}, {"version": "v6", "created": "Fri, 22 Nov 2019 13:01:23 GMT"}, {"version": "v7", "created": "Sat, 18 Jan 2020 18:01:05 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Conley", "Rebecca", ""], ["Jiao", "Xiangmin", ""], ["Delaney", "Tristan J.", ""]]}, {"id": "1603.09660", "submitter": "Benjamin Marussig", "authors": "Benjamin Marussig, J\\\"urgen Zechner, Gernot Beer and Thomas-Peter\n  Fries", "title": "Stable Isogeometric Analysis of Trimmed Geometries", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2016.07.040", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore extended B-splines as a stable basis for isogeometric analysis\nwith trimmed parameter spaces. The stabilization is accomplished by an\nappropriate substitution of B-splines that may lead to ill-conditioned system\nmatrices. The construction for non-uniform knot vectors is presented. The\nproperties of extended B-splines are examined in the context of interpolation,\npotential, and linear elasticity problems and excellent results are attained.\nThe analysis is performed by an isogeometric boundary element formulation using\ncollocation. It is argued that extended B-splines provide a flexible and simple\nstabilization scheme which ideally suits the isogeometric paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 16:19:05 GMT"}, {"version": "v2", "created": "Fri, 22 Jul 2016 16:43:01 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Marussig", "Benjamin", ""], ["Zechner", "J\u00fcrgen", ""], ["Beer", "Gernot", ""], ["Fries", "Thomas-Peter", ""]]}, {"id": "1603.09678", "submitter": "Samir Omerovi\\'c", "authors": "Samir Omerovi\\'c, Thomas-Peter Fries", "title": "Conformal higher-order remeshing schemes for implicitly defined\n  interface problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new higher-order accurate method is proposed that combines the advantages\nof the classical $p$-version of the FEM on body-fitted meshes with embedded\ndomain methods. A background mesh composed by higher-order Lagrange elements is\nused. Boundaries and interfaces are described implicitly by the level set\nmethod and are within elements. In the elements cut by the boundaries or\ninterfaces, an automatic decomposition into higher-order accurate sub-elements\nis realized. Therefore, the zero level sets are detected and meshed in a first\nstep which is called reconstruction. Then, based on the topological situation\nin the cut element, higher-order sub-elements are mapped to the two sides of\nthe boundary or interface. The quality of the reconstruction and the mapping\nlargely determines the properties of the resulting, automatically generated\nconforming mesh. It is found that optimal convergence rates are possible\nalthough the resulting sub-elements are not always well-shaped.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 16:57:23 GMT"}, {"version": "v2", "created": "Fri, 1 Apr 2016 09:03:57 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Omerovi\u0107", "Samir", ""], ["Fries", "Thomas-Peter", ""]]}]