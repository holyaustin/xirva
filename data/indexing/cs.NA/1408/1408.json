[{"id": "1408.0074", "submitter": "Ross Adelman", "authors": "Ross Adelman, Nail A. Gumerov, and Ramani Duraiswami", "title": "Software for Computing the Spheroidal Wave Functions Using Arbitrary\n  Precision Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spheroidal wave functions, which are the solutions to the Helmholtz\nequation in spheroidal coordinates, are notoriously difficult to compute.\nBecause of this, practically no programming language comes equipped with the\nmeans to compute them. This makes problems that require their use hard to\ntackle. We have developed computational software for calculating these special\nfunctions. Our software is called spheroidal and includes several novel\nfeatures, such as: using arbitrary precision arithmetic; adaptively choosing\nthe number of expansion coefficients to compute and use; and using the\nWronskian to choose from several different methods for computing the spheroidal\nradial functions to improve their accuracy. There are two types of spheroidal\nwave functions: the prolate kind when prolate spheroidal coordinates are used;\nand the oblate kind when oblate spheroidal coordinate are used. In this paper,\nwe describe both, methods for computing them, and our software. We have made\nour software freely available on our webpage.\n", "versions": [{"version": "v1", "created": "Fri, 1 Aug 2014 04:29:30 GMT"}], "update_date": "2014-08-04", "authors_parsed": [["Adelman", "Ross", ""], ["Gumerov", "Nail A.", ""], ["Duraiswami", "Ramani", ""]]}, {"id": "1408.0210", "submitter": "Fabien Casenave", "authors": "Fabien Casenave", "title": "A Fast Summation Method for translation invariant kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a Fast Multipole Method (FMM) where a low-rank approximation of the\nkernel is obtained using the Empirical Interpolation Method (EIM). Contrary to\nclassical interpolation-based FMM, where the interpolation points and basis are\nfixed beforehand, the EIM is a nonlinear approximation method which constructs\ninterpolation points and basis which are adapted to the kernel under\nconsideration. The basis functions are obtained using evaluations of the kernel\nitself. We restrict ourselves to translation-invariant kernels, for which a\nmodified version of the EIM approximation can be used in a multilevel FMM\ncontext; we call the obtained algorithm Empirical Interpolation Fast Multipole\nMethod (EIFMM). An important feature of the EIFMM is a built-in error\nestimation of the interpolation error made by the low-rank approximation of the\nfar-field behavior of the kernel: the algorithm selects the optimal number of\ninterpolation points required to ensure a given accuracy for the result,\nleading to important gains for inhomogeneous kernels.\n", "versions": [{"version": "v1", "created": "Fri, 1 Aug 2014 15:49:16 GMT"}, {"version": "v2", "created": "Wed, 15 Oct 2014 09:47:42 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2015 13:05:44 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Casenave", "Fabien", ""]]}, {"id": "1408.0838", "submitter": "Bjoern Andres", "authors": "Lizhen Qu and Bjoern Andres", "title": "Estimating Maximally Probable Constrained Relations by Mathematical\n  Programming", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating a constrained relation is a fundamental problem in machine\nlearning. Special cases are classification (the problem of estimating a map\nfrom a set of to-be-classified elements to a set of labels), clustering (the\nproblem of estimating an equivalence relation on a set) and ranking (the\nproblem of estimating a linear order on a set). We contribute a family of\nprobability measures on the set of all relations between two finite, non-empty\nsets, which offers a joint abstraction of multi-label classification,\ncorrelation clustering and ranking by linear ordering. Estimating (learning) a\nmaximally probable measure, given (a training set of) related and unrelated\npairs, is a convex optimization problem. Estimating (inferring) a maximally\nprobable relation, given a measure, is a 01-linear program. It is solved in\nlinear time for maps. It is NP-hard for equivalence relations and linear\norders. Practical solutions for all three cases are shown in experiments with\nreal data. Finally, estimating a maximally probable measure and relation\njointly is posed as a mixed-integer nonlinear program. This formulation\nsuggests a mathematical programming approach to semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Aug 2014 23:30:20 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Qu", "Lizhen", ""], ["Andres", "Bjoern", ""]]}, {"id": "1408.1237", "submitter": "Balaji Vasan Srinivasan", "authors": "Balaji Vasan Srinivasan, Qi Hu, Nail A. Gumerov, Raghu Murtugudde,\n  Ramani Duraiswami", "title": "Preconditioned Krylov solvers for kernel regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary computational problem in kernel regression is solution of a dense\nlinear system with the $N\\times N$ kernel matrix. Because a direct solution has\nan O($N^3$) cost, iterative Krylov methods are often used with fast\nmatrix-vector products. For poorly conditioned problems, convergence of the\niteration is slow and preconditioning becomes necessary. We investigate\npreconditioning from the viewpoint of scalability and efficiency. The problems\nthat conventional preconditioners face when applied to kernel methods are\ndemonstrated. A \\emph{novel flexible preconditioner }that not only improves\nconvergence but also allows utilization of fast kernel matrix-vector products\nis introduced. The performance of this preconditioner is first illustrated on\nsynthetic data, and subsequently on a suite of test problems in kernel\nregression and geostatistical kriging.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 10:39:59 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Srinivasan", "Balaji Vasan", ""], ["Hu", "Qi", ""], ["Gumerov", "Nail A.", ""], ["Murtugudde", "Raghu", ""], ["Duraiswami", "Ramani", ""]]}, {"id": "1408.1693", "submitter": "Timothy Hunter", "authors": "Timothy Hunter, Ahmed El Alaoui, Alexandre Bayen", "title": "Computing the log-determinant of symmetric, diagonally dominant matrices\n  in near-linear time", "comments": "Submitted to the SIAM Journal on Computing (SICOMP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new algorithms for computing the log-determinant of symmetric,\ndiagonally dominant matrices. Existing algorithms run with cubic complexity\nwith respect to the size of the matrix in the worst case. Our algorithm\ncomputes an approximation of the log-determinant in time near-linear with\nrespect to the number of non-zero entries and with high probability. This\nalgorithm builds upon the utra-sparsifiers introduced by Spielman and Teng for\nLaplacian matrices and ultimately uses their refined versions introduced by\nKoutis, Miller and Peng in the context of solving linear systems. We also\npresent simpler algorithms that compute upper and lower bounds and that may be\nof more immediate practical interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 Aug 2014 05:15:37 GMT"}], "update_date": "2014-08-11", "authors_parsed": [["Hunter", "Timothy", ""], ["Alaoui", "Ahmed El", ""], ["Bayen", "Alexandre", ""]]}, {"id": "1408.1729", "submitter": "Gerard Awanou", "authors": "Gerard Awanou", "title": "Discrete Aleksandrov solutions of the Monge-Ampere equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the convergence of a wide stencil finite difference scheme to the\nAleksandrov solution of the elliptic Monge-Ampere equation when the right hand\nside is a sum of Dirac masses. The discrete scheme we analyze for the Dirichlet\nproblem, when coupled with a discretization of the second boundary condition,\ncan be used to get a good initial guess for geometric methods solving optimal\ntransport between two measures.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 23:11:28 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2015 18:36:58 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 02:52:02 GMT"}, {"version": "v4", "created": "Thu, 31 Oct 2019 11:08:42 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Awanou", "Gerard", ""]]}, {"id": "1408.2054", "submitter": "David Wipf", "authors": "David Wipf", "title": "Non-Convex Rank Minimization via an Empirical Bayesian Approach", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-914-923", "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications that require matrix solutions of minimal rank, the\nunderlying cost function is non-convex leading to an intractable, NP-hard\noptimization problem. Consequently, the convex nuclear norm is frequently used\nas a surrogate penalty term for matrix rank. The problem is that in many\npractical scenarios there is no longer any guarantee that we can correctly\nestimate generative low-rank matrices of interest, theoretical special cases\nnotwithstanding. Consequently, this paper proposes an alternative empirical\nBayesian procedure build upon a variational approximation that, unlike the\nnuclear norm, retains the same globally minimizing point estimate as the rank\nfunction under many useful constraints. However, locally minimizing solutions\nare largely smoothed away via marginalization, allowing the algorithm to\nsucceed when standard convex relaxations completely fail. While the proposed\nmethodology is generally applicable to a wide range of low-rank applications,\nwe focus our attention on the robust principal component analysis problem\n(RPCA), which involves estimating an unknown low-rank matrix with unknown\nsparse corruptions. Theoretical and empirical evidence are presented to show\nthat our method is potentially superior to related MAP-based approaches, for\nwhich the convex principle component pursuit (PCP) algorithm (Candes et al.,\n2011) can be viewed as a special case.\n", "versions": [{"version": "v1", "created": "Sat, 9 Aug 2014 05:52:02 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Wipf", "David", ""]]}, {"id": "1408.2207", "submitter": "Jamal AmaniRad", "authors": "J.A. Rad, S. Kazem, M. Shaban, K. Parand", "title": "A new operational matrix based on Bernoulli polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, the Bernoulli polynomials are introduced. The properties of\nthese polynomials are employed to construct the operational matrices of\nintegration together with the derivative and product. These properties are then\nutilized to transform the differential equation to a matrix equation which\ncorresponds to a system of algebraic equations with unknown Bernoulli\ncoefficients. This method can be used for many problems such as differential\nequations, integral equations and so on. Numerical examples show the method is\ncomputationally simple and also illustrate the efficiency and accuracy of the\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 10 Aug 2014 09:43:53 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Rad", "J. A.", ""], ["Kazem", "S.", ""], ["Shaban", "M.", ""], ["Parand", "K.", ""]]}, {"id": "1408.2209", "submitter": "Jamal AmaniRad", "authors": "J. A. Rad, S. Kazem, K. Parand", "title": "The meshless method for solving radiative transfer problems in a slab\n  medium based on radial basis functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a numerical meshless method for solving the radiative transfer\nequations in a slab medium with an isotropic scattering is considered. The\nmethod is based on radial basis functions to approximate the solution of an\nintegral-partial differential equation by using collocation method. For this\npurpose different applications of RBFs are used. To this end the numerical\nsolutions are obtained without any mesh generation into the domain of the\nproblems. The results of numerical experiments are compared with the existing\nresults in illustrative examples to confirm the accuracy and efficiency of the\npresented scheme. Also the norm of the residual functions are obtained to show\nthe convergence of the method.\n", "versions": [{"version": "v1", "created": "Sun, 10 Aug 2014 10:23:54 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Rad", "J. A.", ""], ["Kazem", "S.", ""], ["Parand", "K.", ""]]}, {"id": "1408.2597", "submitter": "Yangyang Xu", "authors": "Yangyang Xu and Wotao Yin", "title": "Block stochastic gradient iteration for convex and nonconvex\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic gradient (SG) method can minimize an objective function\ncomposed of a large number of differentiable functions, or solve a stochastic\noptimization problem, to a moderate accuracy. The block coordinate\ndescent/update (BCD) method, on the other hand, handles problems with multiple\nblocks of variables by updating them one at a time; when the blocks of\nvariables are easier to update individually than together, BCD has a lower\nper-iteration cost. This paper introduces a method that combines the features\nof SG and BCD for problems with many components in the objective and with\nmultiple (blocks of) variables.\n  Specifically, a block stochastic gradient (BSG) method is proposed for\nsolving both convex and nonconvex programs. At each iteration, BSG approximates\nthe gradient of the differentiable part of the objective by randomly sampling a\nsmall set of data or sampling a few functions from the sum term in the\nobjective, and then, using those samples, it updates all the blocks of\nvariables in either a deterministic or a randomly shuffled order. Its\nconvergence for both convex and nonconvex cases are established in different\nsenses. In the convex case, the proposed method has the same order of\nconvergence rate as the SG method. In the nonconvex case, its convergence is\nestablished in terms of the expected violation of a first-order optimality\ncondition. The proposed method was numerically tested on problems including\nstochastic least squares and logistic regression, which are convex, as well as\nlow-rank tensor recovery and bilinear logistic regression, which are nonconvex.\n", "versions": [{"version": "v1", "created": "Tue, 12 Aug 2014 01:21:42 GMT"}, {"version": "v2", "created": "Tue, 26 Aug 2014 13:14:26 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2015 04:02:54 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Xu", "Yangyang", ""], ["Yin", "Wotao", ""]]}, {"id": "1408.2940", "submitter": "Christoph Lehrenfeld", "authors": "Christoph Lehrenfeld and Arnold Reusken", "title": "Optimal preconditioners for Nitsche-XFEM discretizations of interface\n  problems", "comments": "20 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, a combination of unfitted finite elements (or XFEM) with\nthe Nitsche method has become a popular discretization method for elliptic\ninterface problems. This development started with the introduction and analysis\nof this Nitsche-XFEM technique in the paper [A. Hansbo, P. Hansbo, Comput.\nMethods Appl. Mech. Engrg. 191 (2002)]. In general, the resulting linear\nsystems have very large condition numbers, which depend not only on the mesh\nsize $h$, but also on how the interface intersects the mesh. This paper is\nconcerned with the design and analysis of optimal preconditioners for such\nlinear systems. We propose an additive subspace preconditioner which is optimal\nin the sense that the resulting condition number is independent of the mesh\nsize $h$ and the interface position. We further show that already the simple\ndiagonal scaling of the stifness matrix results in a condition number that is\nbounded by $ch^{-2}$, with a constant $c$ that does not depend on the location\nof the interface. Both results are proven for the two-dimensional case. Results\nof numerical experiments in two and three dimensions are presented, which\nillustrate the quality of the preconditioner.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 08:35:27 GMT"}], "update_date": "2014-08-14", "authors_parsed": [["Lehrenfeld", "Christoph", ""], ["Reusken", "Arnold", ""]]}, {"id": "1408.2981", "submitter": "Eike Hermann M\\\"uller", "authors": "Andreas Dedner, Eike Hermann M\\\"uller, Robert Scheichl", "title": "Efficient Multigrid Preconditioners for Atmospheric Flow Simulations at\n  High Aspect Ratio", "comments": "22 pages, 6 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.NA physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in fluid modelling require the efficient solution of highly\nanisotropic elliptic partial differential equations (PDEs) in \"flat\" domains.\nFor example, in numerical weather- and climate-prediction an elliptic PDE for\nthe pressure correction has to be solved at every time step in a thin spherical\nshell representing the global atmosphere. This elliptic solve can be one of the\ncomputationally most demanding components in semi-implicit semi-Lagrangian time\nstepping methods which are very popular as they allow for larger model time\nsteps and better overall performance. With increasing model resolution,\nalgorithmically efficient and scalable algorithms are essential to run the code\nunder tight operational time constraints. We discuss the theory and practical\napplication of bespoke geometric multigrid preconditioners for equations of\nthis type. The algorithms deal with the strong anisotropy in the vertical\ndirection by using the tensor-product approach originally analysed by B\\\"{o}rm\nand Hiptmair [Numer. Algorithms, 26/3 (2001), pp. 219-234]. We extend the\nanalysis to three dimensions under slightly weakened assumptions, and\nnumerically demonstrate its efficiency for the solution of the elliptic PDE for\nthe global pressure correction in atmospheric forecast models. For this we\ncompare the performance of different multigrid preconditioners on a\ntensor-product grid with a semi-structured and quasi-uniform horizontal mesh\nand a one dimensional vertical grid. The code is implemented in the Distributed\nand Unified Numerics Environment (DUNE), which provides an easy-to-use and\nscalable environment for algorithms operating on tensor-product grids. Parallel\nscalability of our solvers on up to 20,480 cores is demonstrated on the HECToR\nsupercomputer.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 11:41:02 GMT"}, {"version": "v2", "created": "Tue, 10 Feb 2015 16:00:44 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Dedner", "Andreas", ""], ["M\u00fcller", "Eike Hermann", ""], ["Scheichl", "Robert", ""]]}, {"id": "1408.3115", "submitter": "Tianbao Yang", "authors": "Tianbao Yang, Rong Jin, Shenghuo Zhu, Qihang Lin", "title": "On Data Preconditioning for Regularized Loss Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study data preconditioning, a well-known and long-existing\ntechnique, for boosting the convergence of first-order methods for regularized\nloss minimization. It is well understood that the condition number of the\nproblem, i.e., the ratio of the Lipschitz constant to the strong convexity\nmodulus, has a harsh effect on the convergence of the first-order optimization\nmethods. Therefore, minimizing a small regularized loss for achieving good\ngeneralization performance, yielding an ill conditioned problem, becomes the\nbottleneck for big data problems. We provide a theory on data preconditioning\nfor regularized loss minimization. In particular, our analysis exhibits an\nappropriate data preconditioner and characterizes the conditions on the loss\nfunction and on the data under which data preconditioning can reduce the\ncondition number and therefore boost the convergence for minimizing the\nregularized loss. To make the data preconditioning practically useful, we\nendeavor to employ and analyze a random sampling approach to efficiently\ncompute the preconditioned data. The preliminary experiments validate our\ntheory.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 18:44:18 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 06:29:17 GMT"}, {"version": "v3", "created": "Mon, 5 Jan 2015 15:23:40 GMT"}, {"version": "v4", "created": "Fri, 25 Sep 2015 15:35:10 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Yang", "Tianbao", ""], ["Jin", "Rong", ""], ["Zhu", "Shenghuo", ""], ["Lin", "Qihang", ""]]}, {"id": "1408.3595", "submitter": "Laurent Lessard", "authors": "Laurent Lessard, Benjamin Recht, Andrew Packard", "title": "Analysis and Design of Optimization Algorithms via Integral Quadratic\n  Constraints", "comments": "The previous version of this paper quoted the wrong rate of\n  Nesterov's optimal method when applied to strongly convex functions. With\n  this correction, our bounds are now slightly better than those previously\n  derived for Nesterov's method", "journal-ref": null, "doi": "10.1137/15M1009597", "report-no": null, "categories": "math.OC cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript develops a new framework to analyze and design iterative\noptimization algorithms built on the notion of Integral Quadratic Constraints\n(IQC) from robust control theory. IQCs provide sufficient conditions for the\nstability of complicated interconnected systems, and these conditions can be\nchecked by semidefinite programming. We discuss how to adapt IQC theory to\nstudy optimization algorithms, proving new inequalities about convex functions\nand providing a version of IQC theory adapted for use by optimization\nresearchers. Using these inequalities, we derive numerical upper bounds on\nconvergence rates for the gradient method, the heavy-ball method, Nesterov's\naccelerated method, and related variants by solving small, simple semidefinite\nprogramming problems. We also briefly show how these techniques can be used to\nsearch for optimization algorithms with desired performance characteristics,\nestablishing a new methodology for algorithm design.\n", "versions": [{"version": "v1", "created": "Fri, 15 Aug 2014 17:49:50 GMT"}, {"version": "v2", "created": "Tue, 23 Dec 2014 02:39:49 GMT"}, {"version": "v3", "created": "Wed, 24 Dec 2014 10:21:26 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2015 01:56:29 GMT"}, {"version": "v5", "created": "Thu, 1 Oct 2015 06:13:01 GMT"}, {"version": "v6", "created": "Sun, 25 Oct 2015 20:54:33 GMT"}, {"version": "v7", "created": "Wed, 28 Oct 2015 19:46:52 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Lessard", "Laurent", ""], ["Recht", "Benjamin", ""], ["Packard", "Andrew", ""]]}, {"id": "1408.3622", "submitter": "Hong Zhang", "authors": "Hong Zhang, Adrian Sandu, Paul Tranquilli", "title": "Application of approximate matrix factorization to high order linearly\n  implicit Runge-Kutta methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearly implicit Runge-Kutta methods with approximate matrix factorization\ncan solve efficiently large systems of differential equations that have a stiff\nlinear part, e.g. reaction-diffusion systems. However, the use of approximate\nfactorization usually leads to loss of accuracy, which makes it attractive only\nfor low order time integration schemes. This paper discusses the application of\napproximate matrix factorization with high order methods; an inexpensive\ncorrection procedure applied to each stage allows to retain the high order of\nthe underlying linearly implicit Runge-Kutta scheme. The accuracy and stability\nof the methods are studied. Numerical experiments on reaction-diffusion type\nproblems of different sizes and with different degrees of stiffness illustrate\nthe efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 15 Aug 2014 19:57:39 GMT"}, {"version": "v2", "created": "Mon, 18 Aug 2014 02:20:25 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Zhang", "Hong", ""], ["Sandu", "Adrian", ""], ["Tranquilli", "Paul", ""]]}, {"id": "1408.3807", "submitter": "David Barber", "authors": "David Barber", "title": "On solving Ordinary Differential Equations using Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a set of Gaussian Process based approaches that can be used to\nsolve non-linear Ordinary Differential Equations. We suggest an explicit\nprobabilistic solver and two implicit methods, one analogous to Picard\niteration and the other to gradient matching. All methods have greater accuracy\nthan previously suggested Gaussian Process approaches. We also suggest a\ngeneral approach that can yield error estimates from any standard ODE solver.\n", "versions": [{"version": "v1", "created": "Sun, 17 Aug 2014 09:52:06 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Barber", "David", ""]]}, {"id": "1408.3877", "submitter": "Balthasar Reuter", "authors": "Florian Frank, Balthasar Reuter, Vadym Aizinger, Peter Knabner", "title": "FESTUNG: A MATLAB / GNU Octave toolbox for the discontinuous Galerkin\n  method. Part I: Diffusion operator", "comments": "Updated with published manuscript. Substantial changes were applied\n  to the naming scheme of the included Matlab/GNU Octave codes", "journal-ref": "Computers & Mathematics with Applications, Volume 70, Issue 1,\n  July 2015, Pages 11-46", "doi": "10.1016/j.camwa.2015.04.013", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the first in a series of papers on implementing a discontinuous\nGalerkin method as a MATLAB / GNU Octave toolbox. The main goal is the\ndevelopment of techniques that deliver optimized computational performance\ncombined with a compact, user-friendly interface. Our implementation relies on\nfully vectorized matrix / vector operations and is carefully documented; in\naddition, a direct mapping between discretization terms and code routines is\nmaintained throughout. The present work focuses on a two-dimensional\ntime-dependent diffusion equation with space / time-varying coefficients. The\nspatial discretization is based on the local discontinuous Galerkin formulation\nand is locally mass conservative. Approximations of orders zero through four\nbased on orthogonal polynomials have been implemented; more spaces of arbitrary\ntype and order can be easily accommodated by the code structure. Time\ndiscretization is performed using an implicit Euler method.\n", "versions": [{"version": "v1", "created": "Mon, 18 Aug 2014 00:46:15 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 11:30:41 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Frank", "Florian", ""], ["Reuter", "Balthasar", ""], ["Aizinger", "Vadym", ""], ["Knabner", "Peter", ""]]}, {"id": "1408.4389", "submitter": "Jincheng Mei", "authors": "Jincheng Mei, Kang Zhao and Bao-Liang Lu", "title": "On Unconstrained Quasi-Submodular Function Optimization", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the extensive application of submodularity, its generalizations are\nconstantly being proposed. However, most of them are tailored for special\nproblems. In this paper, we focus on quasi-submodularity, a universal\ngeneralization, which satisfies weaker properties than submodularity but still\nenjoys favorable performance in optimization. Similar to the diminishing return\nproperty of submodularity, we first define a corresponding property called the\n{\\em single sub-crossing}, then we propose two algorithms for unconstrained\nquasi-submodular function minimization and maximization, respectively. The\nproposed algorithms return the reduced lattices in $\\mathcal{O}(n)$ iterations,\nand guarantee the objective function values are strictly monotonically\nincreased or decreased after each iteration. Moreover, any local and global\noptima are definitely contained in the reduced lattices. Experimental results\nverify the effectiveness and efficiency of the proposed algorithms on lattice\nreduction.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 16:43:49 GMT"}, {"version": "v2", "created": "Thu, 13 Nov 2014 11:02:41 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Mei", "Jincheng", ""], ["Zhao", "Kang", ""], ["Lu", "Bao-Liang", ""]]}, {"id": "1408.4536", "submitter": "Quentin Merigot", "authors": "Jean-David Benamou (INRIA Paris-Rocquencourt), Guillaume Carlier\n  (CEREMADE), Quentin M\\'erigot (LJK), Edouard Oudet (LJK)", "title": "Discretization of functionals involving the Monge-Amp\\`ere operator", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient flows in the Wasserstein space have become a powerful tool in the\nanalysis of diffusion equations, following the seminal work of Jordan,\nKinderlehrer and Otto (JKO). The numerical applications of this formulation\nhave been limited by the difficulty to compute the Wasserstein distance in\ndimension >= 2. One step of the JKO scheme is equivalent to a variational\nproblem on the space of convex functions, which involves the Monge-Amp\\`ere\noperator. Convexity constraints are notably difficult to handle numerically,\nbut in our setting the internal energy plays the role of a barrier for these\nconstraints. This enables us to introduce a consistent discretization, which\ninherits convexity properties of the continuous variational problem. We show\nthe effectiveness of our approach on nonlinear diffusion and crowd-motion\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 20 Aug 2014 06:22:41 GMT"}], "update_date": "2014-08-21", "authors_parsed": [["Benamou", "Jean-David", "", "INRIA Paris-Rocquencourt"], ["Carlier", "Guillaume", "", "CEREMADE"], ["M\u00e9rigot", "Quentin", "", "LJK"], ["Oudet", "Edouard", "", "LJK"]]}, {"id": "1408.5535", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Andreas Stathopoulos", "title": "A Preconditioned Hybrid SVD Method for Computing Accurately Singular\n  Triplets of Large Matrices", "comments": "24 pages, 20 figures, and 8 tables. Accepted to SIAM Journal on\n  Scientific Computing", "journal-ref": null, "doi": "10.1137/140979381", "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of a few singular triplets of large, sparse matrices is a\nchallenging task, especially when the smallest magnitude singular values are\nneeded in high accuracy. Most recent efforts try to address this problem\nthrough variations of the Lanczos bidiagonalization method, but they are still\nchallenged even for medium matrix sizes due to the difficulty of the problem.\nWe propose a novel SVD approach that can take advantage of preconditioning and\nof any well designed eigensolver to compute both largest and smallest singular\ntriplets. Accuracy and efficiency is achieved through a hybrid, two-stage\nmeta-method, PHSVDS. In the first stage, PHSVDS solves the normal equations up\nto the best achievable accuracy. If further accuracy is required, the method\nswitches automatically to an eigenvalue problem with the augmented matrix. Thus\nit combines the advantages of the two stages, faster convergence and accuracy,\nrespectively. For the augmented matrix, solving the interior eigenvalue is\nfacilitated by a proper use of the good initial guesses from the first stage\nand an efficient implementation of the refined projection method. We also\ndiscuss how to precondition PHSVDS and to cope with some issues that arise.\nNumerical experiments illustrate the efficiency and robustness of the method.\n", "versions": [{"version": "v1", "created": "Sat, 23 Aug 2014 23:19:39 GMT"}, {"version": "v2", "created": "Tue, 10 Feb 2015 01:49:26 GMT"}, {"version": "v3", "created": "Wed, 13 May 2015 20:25:34 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Wu", "Lingfei", ""], ["Stathopoulos", "Andreas", ""]]}, {"id": "1408.5946", "submitter": "Farbod Roosta-Khorasani", "authors": "Uri Ascher and Farbod Roosta-Khorasani", "title": "Algorithms that satisfy a stopping criterion, probably", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative numerical algorithms are typically equipped with a stopping\ncriterion, where the iteration process is terminated when some error or misfit\nmeasure is deemed to be below a given tolerance. This is a useful setting for\ncomparing algorithm performance, among other purposes. However, in practical\napplications a precise value for such a tolerance is rarely known; rather, only\nsome possibly vague idea of the desired quality of the numerical approximation\nis at hand. We discuss four case studies from different areas of numerical\ncomputation, where uncertainty in the error tolerance value and in the stopping\ncriterion is revealed in different ways. This leads us to think of approaches\nto relax the notion of exactly satisfying a tolerance value. We then\nconcentrate on a {\\em probabilistic} relaxation of the given tolerance. This\nallows, for instance, derivation of proven bounds on the sample size of certain\nMonte Carlo methods. We describe an algorithm that becomes more efficient in a\ncontrolled way as the uncertainty in the tolerance increases, and demonstrate\nthis in the context of some particular applications of inverse problems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Aug 2014 23:23:56 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 02:21:09 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Ascher", "Uri", ""], ["Roosta-Khorasani", "Farbod", ""]]}, {"id": "1408.6143", "submitter": "Florent Pled", "authors": "Florent Pled, Ludovic Chamoin, Pierre Ladev\\`eze", "title": "An enhanced method with local energy minimization for the robust a\n  posteriori construction of equilibrated stress fields in finite element\n  analyses", "comments": "22 pages", "journal-ref": "Computational Mechanics 49, 3 (2012) 357-378", "doi": "10.1007/s00466-011-0645-y", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of global/goal-oriented error estimation applied to\ncomputational mechanics, the need to obtain reliable and guaranteed bounds on\nthe discretization error has motivated the use of residual error estimators.\nThese estimators require the construction of admissible stress fields verifying\nthe equilibrium exactly. This article focuses on a recent method, based on a\nflux-equilibration procedure and called the element equilibration + star-patch\ntechnique (EESPT), that provides for such stress fields. The standard version\nrelies on a strong prolongation condition in order to calculate equilibrated\ntractions along finite element boundaries. Here, we propose an enhanced\nversion, which is based on a weak prolongation condition resulting in a local\nminimization of the complementary energy and leads to optimal tractions in\nselected regions. Geometric and error estimate criteria are introduced to\nselect the relevant zones for optimizing the tractions. We demonstrate how this\noptimization procedure is important and relevant to produce sharper estimators\nat affordable computational cost, especially when the error estimate criterion\nis used. Two- and three-dimensional numerical experiments demonstrate the\nefficiency of the improved technique.\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 18:35:54 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 18:12:59 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Pled", "Florent", ""], ["Chamoin", "Ludovic", ""], ["Ladev\u00e8ze", "Pierre", ""]]}, {"id": "1408.6299", "submitter": "Andreas Mang", "authors": "Andreas Mang and George Biros", "title": "An inexact Newton-Krylov algorithm for constrained diffeomorphic image\n  registration", "comments": "32 pages; 10 figures; 9 tables", "journal-ref": "SIAM J. Imaging Sci., 8(2):1030-1069, 2015", "doi": "10.1137/140984002", "report-no": null, "categories": "math.NA cs.CV cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose numerical algorithms for solving large deformation diffeomorphic\nimage registration problems. We formulate the nonrigid image registration\nproblem as a problem of optimal control. This leads to an infinite-dimensional\npartial differential equation (PDE) constrained optimization problem.\n  The PDE constraint consists, in its simplest form, of a hyperbolic transport\nequation for the evolution of the image intensity. The control variable is the\nvelocity field. Tikhonov regularization on the control ensures well-posedness.\nWe consider standard smoothness regularization based on $H^1$- or\n$H^2$-seminorms. We augment this regularization scheme with a constraint on the\ndivergence of the velocity field rendering the deformation incompressible and\nthus ensuring that the determinant of the deformation gradient is equal to one,\nup to the numerical error.\n  We use a Fourier pseudospectral discretization in space and a Chebyshev\npseudospectral discretization in time. We use a preconditioned, globalized,\nmatrix-free, inexact Newton-Krylov method for numerical optimization. A\nparameter continuation is designed to estimate an optimal regularization\nparameter. Regularity is ensured by controlling the geometric properties of the\ndeformation field. Overall, we arrive at a black-box solver. We study spectral\nproperties of the Hessian, grid convergence, numerical accuracy, computational\nefficiency, and deformation regularity of our scheme. We compare the designed\nNewton-Krylov methods with a globalized preconditioned gradient descent. We\nstudy the influence of a varying number of unknowns in time.\n  The reported results demonstrate excellent numerical accuracy, guaranteed\nlocal deformation regularity, and computational efficiency with an optional\ncontrol on local mass conservation. The Newton-Krylov methods clearly\noutperform the Picard method if high accuracy of the inversion is required.\n", "versions": [{"version": "v1", "created": "Wed, 27 Aug 2014 02:36:11 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2015 23:05:07 GMT"}, {"version": "v3", "created": "Thu, 7 May 2015 13:37:06 GMT"}], "update_date": "2015-05-08", "authors_parsed": [["Mang", "Andreas", ""], ["Biros", "George", ""]]}, {"id": "1408.6497", "submitter": "Amir Gholami", "authors": "Amir Gholami, Dhairya Malhotra, Hari Sundar, George Biros", "title": "FFT, FMM, or Multigrid? A comparative Study of State-Of-the-Art Poisson\n  Solvers for Uniform and Nonuniform Grids in the Unit Cube", "comments": "25 pages; accepted paper in SISC journal", "journal-ref": "SIAM Journal on Scientific Computing 2016 38:3, C280-C306", "doi": "10.1137/15M1010798", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we benchmark and discuss the performance of the scalable\nmethods for the Poisson problem which are used widely in practice: the fast\nFourier transform (FFT), the fast multipole method (FMM), the geometric\nmultigrid (GMG), and algebraic multigrid (AMG). In total we compare five\ndifferent codes, three of which are developed in our group. Our FFT, GMG, and\nFMM are parallel solvers that use high-order approximation schemes for Poisson\nproblems with continuous forcing functions (the source or right-hand side). We\nexamine and report results for weak scaling, strong scaling, and time to\nsolution for uniform and highly refined grids. We present results on the\nStampede system at the Texas Advanced Computing Center and on the Titan system\nat the Oak Ridge National Laboratory. In our largest test case, we solved a\nproblem with 600 billion unknowns on 229,379 cores of Titan. Overall, all\nmethods scale quite well to these problem sizes. We have tested all of the\nmethods with different source functions (the right-hand side in the Poisson\nproblem). Our results indicate that FFT is the method of choice for smooth\nsource functions that require uniform resolution. However, FFT loses its\nperformance advantage when the source function has highly localized features\nlike internal sharp layers. FMM and GMG considerably outperform FFT for those\ncases. The distinction between FMM and GMG is less pronounced and is sensitive\nto the quality (from a performance point of view) of the underlying\nimplementations. The high-order accurate versions of GMG and FMM significantly\noutperform their low-order accurate counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 27 Aug 2014 19:17:39 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2015 20:05:48 GMT"}, {"version": "v3", "created": "Mon, 11 Jul 2016 02:00:41 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Gholami", "Amir", ""], ["Malhotra", "Dhairya", ""], ["Sundar", "Hari", ""], ["Biros", "George", ""]]}]