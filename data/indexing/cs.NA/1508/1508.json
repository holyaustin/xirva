[{"id": "1508.00315", "submitter": "Michael Friedlander", "authors": "Michael P. Friedlander, Ives Macedo", "title": "Low-rank spectral optimization via gauge duality", "comments": "Final version. To appear in SIAM J. Scientific Computing", "journal-ref": "SIAM Journal on Scientific Computing, 38(3):A1616-A1638, 2016", "doi": "10.1137/15M1034283", "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various applications in signal processing and machine learning give rise to\nhighly structured spectral optimization problems characterized by low-rank\nsolutions. Two important examples that motivate this work are optimization\nproblems from phase retrieval and from blind deconvolution, which are designed\nto yield rank-1 solutions. An algorithm is described that is based on solving a\ncertain constrained eigenvalue optimization problem that corresponds to the\ngauge dual which, unlike the more typical Lagrange dual, has an especially\nsimple constraint. The dominant cost at each iteration is the computation of\nrightmost eigenpairs of a Hermitian operator. A range of numerical examples\nillustrate the scalability of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2015 05:05:12 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2015 21:32:41 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2015 23:21:38 GMT"}, {"version": "v4", "created": "Mon, 29 Feb 2016 23:49:13 GMT"}, {"version": "v5", "created": "Wed, 2 Mar 2016 18:41:29 GMT"}, {"version": "v6", "created": "Wed, 23 Mar 2016 17:05:13 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Friedlander", "Michael P.", ""], ["Macedo", "Ives", ""]]}, {"id": "1508.00347", "submitter": "Gautam Munglani", "authors": "Gautam Munglani, Roman Vetter, Falk K. Wittel, Hans J. Herrmann", "title": "Orthotropic rotation-free thin shell elements", "comments": "10 pages, 8 figures", "journal-ref": "Comput. Mech. 56, 785-793 (2015)", "doi": "10.1007/s00466-015-1202-x", "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to simulate orthotropic behaviour in thin shell finite elements is\nproposed. The approach is based on the transformation of shape function\nderivatives, resulting in a new orthogonal basis aligned to a specified\npreferred direction for all elements. This transformation is carried out solely\nin the undeformed state leaving minimal additional impact on the computational\neffort expended to simulate orthotropic materials compared to isotropic,\nresulting in a straightforward and highly efficient implementation. This method\nis implemented for rotation-free triangular shells using the finite element\nframework built on the Kirchhoff--Love theory employing subdivision surfaces.\nThe accuracy of this approach is demonstrated using the deformation of a\npinched hemispherical shell (with a 18{\\deg} hole) standard benchmark. To\nshowcase the efficiency of this implementation, the wrinkling of orthotropic\nsheets under shear displacement is analyzed. It is found that orthotropic\nsubdivision shells are able to capture the wrinkling behavior of sheets\naccurately for coarse meshes without the use of an additional wrinkling model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2015 08:50:12 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Munglani", "Gautam", ""], ["Vetter", "Roman", ""], ["Wittel", "Falk K.", ""], ["Herrmann", "Hans J.", ""]]}, {"id": "1508.01835", "submitter": "Pieter Coulier", "authors": "Pieter Coulier, Hadi Pouransari, and Eric Darve", "title": "The inverse fast multipole method: using a fast approximate direct\n  solver as a preconditioner for dense linear systems", "comments": "Revised version Submitted to the SIAM Journal on Scientific\n  Computing. 35 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although some preconditioners are available for solving dense linear systems,\nthere are still many matrices for which preconditioners are lacking, in\nparticular in cases where the size of the matrix $N$ becomes very large. There\nremains hence a great need to develop general purpose preconditioners whose\ncost scales well with the matrix size $N$. In this paper, we propose a\npreconditioner with broad applicability and with cost $\\mathcal{O}(N)$ for\ndense matrices, when the matrix is given by a smooth kernel. Extending the\nmethod using the same framework to general $\\mathcal{H}^2$-matrices is\nrelatively straightforward. These preconditioners have a controlled accuracy\n(machine accuracy can be achieved if needed) and scale linearly with $N$. They\nare based on an approximate direct solve of the system. The linear scaling of\nthe algorithm is achieved by means of two key ideas. First, the\n$\\mathcal{H}^2$-structure of the dense matrix is exploited to obtain an\nextended sparse system of equations. Second, fill-ins arising when performing\nthe elimination are compressed as low-rank matrices if they correspond to\nwell-separated interactions. This ensures that the sparsity pattern of the\nextended sparse matrix is preserved throughout the elimination, hence resulting\nin a very efficient algorithm with $\\mathcal{O}(N \\log(1/\\varepsilon)^2 )$\ncomputational cost and $\\mathcal{O}(N \\log 1/\\varepsilon )$ memory requirement,\nfor an error tolerance $0 < \\varepsilon < 1$. The solver is inexact, although\nthe error can be controlled and made as small as needed. These solvers are\nrelated to ILU in the sense that the fill-in is controlled. However, in ILU,\nmost of the fill-in is simply discarded whereas here it is approximated using\nlow-rank blocks, with a prescribed tolerance. Numerical examples are discussed\nto demonstrate the linear scaling of the method and to illustrate its\neffectiveness as a preconditioner.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 23:22:43 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2016 18:55:39 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Coulier", "Pieter", ""], ["Pouransari", "Hadi", ""], ["Darve", "Eric", ""]]}, {"id": "1508.02136", "submitter": "Maria Vasilyeva", "authors": "Donald L. Brown, Maria Vasilyeva", "title": "A Generalized Multiscale Finite Element Method for Poroelasticity\n  Problems I: Linear Problems", "comments": "arXiv admin note: text overlap with arXiv:1309.6030 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the numerical solution of poroelasticity problems\nthat are of Biot type and develop a general algorithm for solving coupled\nsystems. We discuss the challenges associated with mechanics and flow problems\nin heterogeneous media. The two primary issues being the multiscale nature of\nthe media and the solutions of the fluid and mechanics variables traditionally\ndeveloped with separate grids and methods. For the numerical solution we\ndevelop and implement a Generalized Multiscale Finite Element Method (GMsFEM)\nthat solves problem on a coarse grid by constructing local multiscale basis\nfunctions. The procedure begins with construction of multiscale bases for both\ndisplacement and pressure in each coarse block. Using a snapshot space and\nlocal spectral problems, we construct a basis of reduced dimension. Finally,\nafter multiplying by a multiscale partitions of unity, the multiscale basis is\nconstructed in the offline phase and the coarse grid problem then can be solved\nfor arbitrary forcing and boundary conditions. We implement this algorithm on\ntwo heterogenous media and compute error between the multiscale solution with\nthe fine-scale solutions. Randomized oversampling and forcing strategies are\nalso tested.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 06:20:54 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Brown", "Donald L.", ""], ["Vasilyeva", "Maria", ""]]}, {"id": "1508.02138", "submitter": "Maria Vasilyeva", "authors": "Donald L. Brown, Maria Vasilyeva", "title": "A Generalized Multiscale Finite Element Method for Poroelasticity\n  Problems II: Nonlinear Coupling", "comments": "arXiv admin note: text overlap with arXiv:1304.5188 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the numerical solution of some nonlinear\nporoelasticity problems that are of Biot type and develop a general algorithm\nfor solving nonlinear coupled systems. We discuss the difficulties associated\nwith flow and mechanics in heterogenous media with nonlinear coupling. The\ncentral issue being how to handle the nonlinearities and the multiscale scale\nnature of the media. To compute an efficient numerical solution we develop and\nimplement a Generalized Multiscale Finite Element Method (GMsFEM) that solves\nnonlinear problems on a coarse grid by constructing local multiscale basis\nfunctions and treating part of the nonlinearity locally as a parametric value.\nAfter linearization with a Picard Iteration, the procedure begins with\nconstruction of multiscale bases for both displacement and pressure in each\ncoarse block by treating the staggered nonlinearity as a parametric value.\nUsing a snapshot space and local spectral problems, we construct an offline\nbasis of reduced dimension. From here an online, parametric dependent, space is\nconstructed. Finally, after multiplying by a multiscale partitions of unity,\nthe multiscale basis is constructed and the coarse grid problem then can be\nsolved for arbitrary forcing and boundary conditions. We implement this\nalgorithm on a geometry with a linear and nonlinear pressure dependent\npermeability field and compute error between the multiscale solution with the\nfine-scale solutions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 06:29:12 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Brown", "Donald L.", ""], ["Vasilyeva", "Maria", ""]]}, {"id": "1508.02345", "submitter": "Alexandros Syrakos", "authors": "Alexandros Syrakos, Georgios Efthimiou, John G. Bartzis, Apostolos\n  Goulas", "title": "Numerical experiments on the efficiency of local grid refinement based\n  on truncation error estimates", "comments": null, "journal-ref": "Journal of Computational Physics 231 (2012) 6725-6753", "doi": "10.1016/j.jcp.2012.06.023", "report-no": null, "categories": "physics.comp-ph cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local grid refinement aims to optimise the relationship between accuracy of\nthe results and number of grid nodes. In the context of the finite volume\nmethod no single local refinement criterion has been globally established as\noptimum for the selection of the control volumes to subdivide, since it is not\neasy to associate the discretisation error with an easily computable quantity\nin each control volume. Often the grid refinement criterion is based on an\nestimate of the truncation error in each control volume, because the truncation\nerror is a natural measure of the discrepancy between the algebraic\nfinite-volume equations and the original differential equations. However, it is\nnot a straightforward task to associate the truncation error with the optimum\ngrid density because of the complexity of the relationship between truncation\nand discretisation errors. In the present work several criteria based on a\ntruncation error estimate are tested and compared on a regularised lid-driven\ncavity case at various Reynolds numbers. It is shown that criteria where the\ntruncation error is weighted by the volume of the grid cells perform better\nthan using just the truncation error as the criterion. Also it is observed that\nthe efficiency of local refinement increases with the Reynolds number. The\ntruncation error is estimated by restricting the solution to a coarser grid and\napplying the coarse grid discrete operator. The complication that high\ntruncation error develops at grid level interfaces is also investigated and\nseveral treatments are tested.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 18:26:27 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Syrakos", "Alexandros", ""], ["Efthimiou", "Georgios", ""], ["Bartzis", "John G.", ""], ["Goulas", "Apostolos", ""]]}, {"id": "1508.02439", "submitter": "Di Wang", "authors": "Di Wang, Satish Rao, Michael W. Mahoney", "title": "Unified Acceleration Method for Packing and Covering Problems via\n  Diameter Reduction", "comments": "Fixed typo in packing LP formulation (page 1), and wrong citation in\n  the discussion of earlier works on page 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear coupling method was introduced recently by Allen-Zhu and Orecchia\nfor solving convex optimization problems with first order methods, and it\nprovides a conceptually simple way to integrate a gradient descent step and\nmirror descent step in each iteration. The high-level approach of the linear\ncoupling method is very flexible, and it has shown initial promise by providing\nimproved algorithms for packing and covering linear programs. Somewhat\nsurprisingly, however, while the dependence of the convergence rate on the\nerror parameter $\\epsilon$ for packing problems was improved to\n$O(1/\\epsilon)$, which corresponds to what accelerated gradient methods are\ndesigned to achieve, the dependence for covering problems was only improved to\n$O(1/\\epsilon^{1.5})$, and even that required a different more complicated\nalgorithm. Given the close connections between packing and covering problems\nand since previous algorithms for these very related problems have led to the\nsame $\\epsilon$ dependence, this discrepancy is surprising, and it leaves open\nthe question of the exact role that the linear coupling is playing in\ncoordinating the complementary gradient and mirror descent step of the\nalgorithm. In this paper, we clarify these issues for linear coupling\nalgorithms for packing and covering linear programs, illustrating that the\nlinear coupling method can lead to improved $O(1/\\epsilon)$ dependence for both\npacking and covering problems in a unified manner, i.e., with the same\nalgorithm and almost identical analysis. Our main technical result is a novel\ndiameter reduction method for covering problems that is of independent interest\nand that may be useful in applying the accelerated linear coupling method to\nother combinatorial problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 21:56:20 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2015 06:41:38 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Wang", "Di", ""], ["Rao", "Satish", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1508.02733", "submitter": "Alexandros Syrakos", "authors": "Alexandros Syrakos, Apostolos Goulas", "title": "Estimate of the truncation error of a finite volume discretisation of\n  the Navier-Stokes equations on colocated grids", "comments": null, "journal-ref": "International Journal for Numerical Methods in Fluids 50 (2006)\n  103-130", "doi": "10.1002/fld.1038", "report-no": null, "categories": "physics.comp-ph cs.NA physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A methodology is proposed for the calculation of the truncation error of\nfinite volume discretisations of the incompressible Navier-Stokes equations on\ncolocated grids. The truncation error is estimated by restricting the solution\nobtained on a given grid to a coarser grid and calculating the image of the\ndiscrete Navier-Stokes operator of the coarse grid on the restricted velocity\nand pressure field. The proposed methodology is not a new concept but its\napplication to colocated finite volume discretisations of the incompressible\nNavier-Stokes equations is made possible by the introduction of a variant of\nthe momentum interpolation technique for mass fluxes where the pressure-part of\nthe mass fluxes is not dependent on the coefficients of the linearised momentum\nequations. The theory presented is supported by a number of numerical\nexperiments. The methodology is developed for two-dimensional flows, but\nextension to three-dimensional cases should not pose problems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 20:37:19 GMT"}], "update_date": "2015-08-13", "authors_parsed": [["Syrakos", "Alexandros", ""], ["Goulas", "Apostolos", ""]]}, {"id": "1508.02935", "submitter": "Robin Stoll", "authors": "Dierk Schleicher and Robin Stoll", "title": "Newton's method in practice: finding all roots of polynomials of degree\n  one million efficiently", "comments": "33 pages, 21 figures", "journal-ref": "Theoretical Computer Science, Volume 681, 2017, Pages 146-166,\n  ISSN 0304-3975", "doi": "10.1016/j.tcs.2017.03.025", "report-no": null, "categories": "math.NA cs.NA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Newton's method to find all roots of several polynomials in one\ncomplex variable of degree up to and exceeding one million and show that the\nmethod, applied to appropriately chosen starting points, can be turned into an\nalgorithm that can be applied routinely to find all roots without deflation and\nwith the inherent numerical stability of Newton's method.\n  We specify an algorithm that provably terminates and finds all roots of any\npolynomial of arbitrary degree, provided all roots are distinct and exact\ncomputation is available. It is known that Newton's method is inherently\nstable, so computing errors do not accumulate; we provide an exact bound on how\nmuch numerical precision is sufficient.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 14:35:21 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 18:25:10 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Schleicher", "Dierk", ""], ["Stoll", "Robin", ""]]}, {"id": "1508.03110", "submitter": "Michael B Hynes", "authors": "Manda Winlaw, Michael B. Hynes, Anthony Caterini, Hans De Sterck", "title": "Algorithmic Acceleration of Parallel ALS for Collaborative Filtering:\n  Speeding up Distributed Big Data Recommendation in Spark", "comments": "Proceedings of ICPADS 2015, Melbourne, AU. 10 pages; 6 figures; 4\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.IR cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering algorithms are important building blocks in many\npractical recommendation systems. For example, many large-scale data processing\nenvironments include collaborative filtering models for which the Alternating\nLeast Squares (ALS) algorithm is used to compute latent factor matrix\ndecompositions. In this paper, we propose an approach to accelerate the\nconvergence of parallel ALS-based optimization methods for collaborative\nfiltering using a nonlinear conjugate gradient (NCG) wrapper around the ALS\niterations. We also provide a parallel implementation of the accelerated\nALS-NCG algorithm in the Apache Spark distributed data processing environment,\nand an efficient line search technique as part of the ALS-NCG implementation\nthat requires only one pass over the data on distributed datasets. In serial\nnumerical experiments on a linux workstation and parallel numerical experiments\non a 16 node cluster with 256 computing cores, we demonstrate that the combined\nALS-NCG method requires many fewer iterations and less time than standalone ALS\nto reach movie rankings with high accuracy on the MovieLens 20M dataset. In\nparallel, ALS-NCG can achieve an acceleration factor of 4 or greater in clock\ntime when an accurate solution is desired; furthermore, the acceleration factor\nincreases as greater numerical precision is required in the solution. In\naddition, the NCG acceleration mechanism is efficient in parallel and scales\nlinearly with problem size on synthetic datasets with up to nearly 1 billion\nratings. The acceleration mechanism is general and may also be applicable to\nother optimization methods for collaborative filtering.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2015 03:37:04 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2015 16:53:49 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2016 23:52:03 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Winlaw", "Manda", ""], ["Hynes", "Michael B.", ""], ["Caterini", "Anthony", ""], ["De Sterck", "Hans", ""]]}, {"id": "1508.03211", "submitter": "Tor Myklebust", "authors": "Tor G. J. Myklebust", "title": "Computing accurate Horner form approximations to special functions in\n  finite precision arithmetic", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various applications, computers are required to compute approximations to\nunivariate elementary and special functions such as $\\exp$ and $\\arctan$ to\nmodest accuracy. This paper proposes a new heuristic for automating the design\nof such implementations. This heuristic takes a certain restricted\nspecification of program structure and the desired error properties as input\nand takes explicit account of roundoff error during evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2015 13:42:35 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Myklebust", "Tor G. J.", ""]]}, {"id": "1508.03280", "submitter": "Matthew Colbrook", "authors": "Jonathan Ben-Artzi, Matthew J. Colbrook, Anders C. Hansen, Olavi\n  Nevanlinna and Markus Seidel", "title": "Computing Spectra -- On the Solvability Complexity Index Hierarchy and\n  Towers of Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.NA math-ph math.LO math.MP math.NA math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes some of the fundamental barriers in the theory of\ncomputations and finally settles the long-standing computational spectral\nproblem. That is to determine the existence of algorithms that can compute\nspectra $\\mathrm{sp}(A)$ of classes of bounded operators $A = \\{a_{ij}\\}_{i,j\n\\in \\mathbb{N}} \\in \\mathcal{B}(l^2(\\mathbb{N}))$, given the matrix elements\n$\\{a_{ij}\\}_{i,j \\in \\mathbb{N}}$, that are sharp in the sense that they\nachieve the boundary of what a digital computer can achieve. Similarly, for a\nSchr\\\"odinger operator $H = -\\Delta+V$, determine the existence of algorithms\nthat can compute the spectrum $\\mathrm{sp}(H)$ given point samples of the\npotential function $V$. In order to solve these problems, we establish the\nSolvability Complexity Index (SCI) hierarchy and provide a collection of new\nalgorithms that allow for problems that were previously out of reach. The SCI\nis the smallest number of limits needed in the computation, yielding a\nclassification hierarchy for all types of problems in computational mathematics\nthat determines the boundaries of what computers can achieve in scientific\ncomputing. In addition, the SCI hierarchy provides classifications of\ncomputational problems that can be used in computer-assisted proofs. The SCI\nhierarchy captures many key computational issues in the history of mathematics\nincluding the insolvability of the quintic, Smale's problem on the existence of\niterative generally convergent algorithm for polynomial root finding, the\ncomputational spectral problem, inverse problems, optimisation etc.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2015 17:42:14 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 12:32:16 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 12:39:36 GMT"}, {"version": "v4", "created": "Mon, 16 Dec 2019 08:30:26 GMT"}, {"version": "v5", "created": "Mon, 15 Jun 2020 17:50:03 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ben-Artzi", "Jonathan", ""], ["Colbrook", "Matthew J.", ""], ["Hansen", "Anders C.", ""], ["Nevanlinna", "Olavi", ""], ["Seidel", "Markus", ""]]}, {"id": "1508.03309", "submitter": "Alexandros Syrakos", "authors": "Alexandros Syrakos, Apostolos Goulas", "title": "Finite volume adaptive solutions using SIMPLE as smoother", "comments": null, "journal-ref": "International Journal for Numerical Methods in Fluids 52 (2006)\n  1215-1245", "doi": "10.1002/fld.1228", "report-no": null, "categories": "physics.comp-ph cs.NA physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new multilevel procedure that can solve the discrete\nNavier-Stokes system arising from finite volume discretizations on composite\ngrids, which may consist of more than one level. SIMPLE is used and tested as\nthe smoother, but the multilevel procedure is such that it does not exclude the\nuse of other smoothers. Local refinement is guided by a criterion based on an\nestimate of the truncation error. The numerical experiments presented test not\nonly the behaviour of the multilevel algebraic solver, but also the efficiency\nof local refinement based on this particular criterion.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2015 19:03:47 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Syrakos", "Alexandros", ""], ["Goulas", "Apostolos", ""]]}, {"id": "1508.04245", "submitter": "Christoph Lehrenfeld", "authors": "Christoph Lehrenfeld and Joachim Sch\\\"oberl", "title": "High order exactly divergence-free Hybrid Discontinuous Galerkin Methods\n  for unsteady incompressible flows", "comments": "21 pages, 3 figures, 4 table", "journal-ref": null, "doi": "10.1016/j.cma.2016.04.025", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an efficient discretization method for the solution\nof the unsteady incompressible Navier-Stokes equations based on a high order\n(Hybrid) Discontinuous Galerkin formulation. The crucial component for the\nefficiency of the discretization method is the disctinction between stiff\nlinear parts and less stiff non-linear parts with respect to their temporal and\nspatial treatment. Exploiting the flexibility of operator-splitting time\nintegration schemes we combine two spatial discretizations which are tailored\nfor two simpler sub-problems: a corresponding hyperbolic transport problem and\nan unsteady Stokes problem. For the hyperbolic transport problem a spatial\ndiscretization with an Upwind Discontinuous Galerkin method and an explicit\ntreatment in the time integration scheme is rather natural and allows for an\nefficient implementation. The treatment of the Stokes part involves the\nsolution of linear systems. In this case a discretization with Hybrid\nDiscontinuous Galerkin methods is better suited. We consider such a\ndiscretization for the Stokes part with two important features:\nH(div)-conforming finite elements to garantuee exactly divergence-free velocity\nsolutions and a projection operator which reduces the number of globally\ncoupled unknowns. We present the method, discuss implementational aspects and\ndemonstrate the performance on two and three dimensional benchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 08:43:34 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 10:12:35 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Lehrenfeld", "Christoph", ""], ["Sch\u00f6berl", "Joachim", ""]]}, {"id": "1508.04467", "submitter": "Zhao Kang", "authors": "Zhao Kang, Chong Peng, Qiang Cheng", "title": "Robust Subspace Clustering via Smoothed Rank Approximation", "comments": "Journal, code is available", "journal-ref": "IEEE Signal Processing Letters, 22(2015)2088-2092", "doi": "10.1109/LSP.2015.2460737", "report-no": null, "categories": "cs.CV cs.IT cs.LG cs.NA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix rank minimizing subject to affine constraints arises in many\napplication areas, ranging from signal processing to machine learning. Nuclear\nnorm is a convex relaxation for this problem which can recover the rank exactly\nunder some restricted and theoretically interesting conditions. However, for\nmany real-world applications, nuclear norm approximation to the rank function\ncan only produce a result far from the optimum. To seek a solution of higher\naccuracy than the nuclear norm, in this paper, we propose a rank approximation\nbased on Logarithm-Determinant. We consider using this rank approximation for\nsubspace clustering application. Our framework can model different kinds of\nerrors and noise. Effective optimization strategy is developed with theoretical\nguarantee to converge to a stationary point. The proposed method gives\npromising results on face clustering and motion segmentation tasks compared to\nthe state-of-the-art subspace clustering algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 21:54:03 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Kang", "Zhao", ""], ["Peng", "Chong", ""], ["Cheng", "Qiang", ""]]}, {"id": "1508.04758", "submitter": "Mark Iwen", "authors": "Xianfeng Hu, Mark Iwen, Hyejin Kim", "title": "Rapidly Computing Sparse Legendre Expansions via Sparse Fourier\n  Transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a general strategy for rapidly computing sparse\nLegendre expansions. The resulting methods yield a new class of fast algorithms\ncapable of approximating a given function $f:[-1,1] \\rightarrow \\mathbb{R}$\nwith a near-optimal linear combination of $s$ Legendre polynomials of degree\n$\\leq N$ in just $(s \\log N)^{\\mathcal{O}(1)}$-time. When $s \\ll N$ these\nalgorithms exhibit sublinear runtime complexities in $N$, as opposed to\ntraditional $\\Omega(N \\log N)$-time methods for computing all of the first $N$\nLegendre coefficients of $f$. Theoretical as well as numerical results\ndemonstrate the promise of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 19:56:59 GMT"}, {"version": "v2", "created": "Sat, 26 Mar 2016 22:12:47 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Hu", "Xianfeng", ""], ["Iwen", "Mark", ""], ["Kim", "Hyejin", ""]]}, {"id": "1508.05273", "submitter": "Pierre Comon", "authors": "Alex Pereira da Silva, Pierre Comon, and Andre Lima Ferrer de Almeida", "title": "Rank-1 Tensor Approximation Methods and Application to Deflation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of the attractiveness of the canonical polyadic (CP) tensor\ndecomposition in various applications, several algorithms have been designed to\ncompute it, but efficient ones are still lacking. Iterative deflation\nalgorithms based on successive rank-1 approximations can be used to perform\nthis task, since the latter are rather easy to compute. We first present an\nalgebraic rank-1 approximation method that performs better than the standard\nhigher-order singular value decomposition (HOSVD) for three-way tensors.\nSecond, we propose a new iterative rank-1 approximation algorithm that improves\nany other rank-1 approximation method. Third, we describe a probabilistic\nframework allowing to study the convergence of deflation CP decomposition\n(DCPD) algorithms based on successive rank-1 approximations. A set of computer\nexperiments then validates theoretical results and demonstrates the efficiency\nof DCPD algorithms compared to other ones.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 14:04:02 GMT"}], "update_date": "2015-08-24", "authors_parsed": [["da Silva", "Alex Pereira", ""], ["Comon", "Pierre", ""], ["de Almeida", "Andre Lima Ferrer", ""]]}, {"id": "1508.05631", "submitter": "Daniel Reem", "authors": "Daniel Reem, Alvaro De Pierro", "title": "A new convergence analysis and perturbation resilience of some\n  accelerated proximal forward-backward algorithms with errors", "comments": "29 pages, to appear in Inverse Problems; a few slight improvements\n  (mainly of Corollaries 3.7-3.8, Remark 2.6, Remark 3.9, Section 4),\n  correction of a few inaccuracies on the level of typos, added (and updated)\n  references, added thanks", "journal-ref": "Inverse Problems 33 (2017), 044001 (28pp)", "doi": "10.1088/1361-6420/33/4/044001", "report-no": null, "categories": "math.OC cs.NA physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in science and engineering involve, as part of their solution\nprocess, the consideration of a separable function which is the sum of two\nconvex functions, one of them possibly non-smooth. Recently a few works have\ndiscussed inexact versions of several accelerated proximal methods aiming at\nsolving this minimization problem. This paper shows that inexact versions of a\nmethod of Beck and Teboulle (FISTA) preserve, in a Hilbert space setting, the\nsame (non-asymptotic) rate of convergence under some assumptions on the decay\nrate of the error terms. The notion of inexactness discussed here seems to be\nrather simple, but, interestingly, when comparing to related works, closely\nrelated decay rates of the errors terms yield closely related convergence\nrates. The derivation sheds some light on the somewhat mysterious origin of\nsome parameters which appear in various accelerated methods. A consequence of\nthe analysis is that the accelerated method is perturbation resilient, making\nit suitable, in principle, for the superiorization methodology. By taking this\ninto account, we re-examine the superiorization methodology and significantly\nextend its scope.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2015 17:48:43 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2015 18:11:16 GMT"}, {"version": "v3", "created": "Wed, 29 Jun 2016 18:25:52 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Reem", "Daniel", ""], ["De Pierro", "Alvaro", ""]]}, {"id": "1508.05856", "submitter": "Matt Challacombe", "authors": "Matt Challacombe and Terry Haut and Nicolas Bock", "title": "A $N$-Body Solver for Square Root Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR-15-26304", "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the Sparse Approximate Matrix Multiply ($\\tt SpAMM$) $n$-body\nsolver for first order Newton Schulz iteration of the matrix square root and\ninverse square root. The solver performs recursive two-sided metric queries on\na modified Cauchy-Schwarz criterion, culling negligible sub-volumes of the\nproduct-tensor for problems with structured decay in the sub-space metric.\nThese sub-structures are shown to bound the relative error in the matrix-matrix\nproduct, and in favorable cases, to enjoy a reduced computational complexity\ngoverned by dimensionality reduction of the product volume. A main contribution\nis demonstration of a new, algebraic locality that develops under contractive\nidentity iteration, with collapse of the metric-subspace onto the identity's\nplane diagonal, resulting in a stronger $\\tt SpAMM$ bound. Also, we carry out a\nfirst order {Fr\\'{e}chet} analyses for single and dual channel instances of the\nsquare root iteration, and look at bifurcations due to ill-conditioning and a\ntoo aggressive $\\tt SpAMM$ approximation. Then, we show that extreme $\\tt\nSpAMM$ approximation and contractive identity iteration can be achieved for\nill-conditioned systems through regularization, and we demonstrate the\npotential for acceleration with a scoping, product representation of the\ninverse factor.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2015 16:03:49 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2015 03:13:31 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Challacombe", "Matt", ""], ["Haut", "Terry", ""], ["Bock", "Nicolas", ""]]}, {"id": "1508.05873", "submitter": "Jie Chen", "authors": "Jingen Ni, Jian Yang, Jie Chen, C\\'edric Richard, Jos\\'e Carlos M.\n  Bermudez", "title": "Stochastic Behavior of the Nonnegative Least Mean Fourth Algorithm for\n  Stationary Gaussian Inputs and Slow Learning", "comments": "11 pages, 8 figures, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some system identification problems impose nonnegativity constraints on the\nparameters to estimate due to inherent physical characteristics of the unknown\nsystem. The nonnegative least-mean-square (NNLMS) algorithm and its variants\nallow to address this problem in an online manner. A nonnegative least mean\nfourth (NNLMF) algorithm has been recently proposed to improve the performance\nof these algorithms in cases where the measurement noise is not Gaussian. This\npaper provides a first theoretical analysis of the stochastic behavior of the\nNNLMF algorithm for stationary Gaussian inputs and slow learning. Simulation\nresults illustrate the accuracy of the proposed analysis.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2015 16:26:38 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Ni", "Jingen", ""], ["Yang", "Jian", ""], ["Chen", "Jie", ""], ["Richard", "C\u00e9dric", ""], ["Bermudez", "Jos\u00e9 Carlos M.", ""]]}, {"id": "1508.06103", "submitter": "Xiaomao Deng", "authors": "Xiaomao Deng, Xiao-chuan Cai and Jun Zou", "title": "Two-level space-time domain decomposition methods for unsteady inverse\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the number of processor cores on supercomputers becomes larger and larger,\nalgorithms with high degree of parallelism attract more attention. In this\nwork, we propose a novel space-time coupled algorithm for solving an inverse\nproblem associated with the time-dependent convection-diffusion equation in\nthree dimensions. We introduce a mixed finite element/finite difference method\nand a one-level and a two-level space-time parallel domain decomposition\npreconditioner for the Karush-Kuhn-Tucker (KKT) system induced from\nreformulating the inverse problem as an output least-squares optimization\nproblem in the space-time domain. The new full space approach eliminates the\nsequential steps of the optimization outer loop and the inner forward and\nbackward time marching processes, thus achieves high degree of parallelism.\nNumerical experiments validate that this approach is effective and robust for\nrecovering unsteady moving sources. We report strong scalability results\nobtained on a supercomputer with more than 1,000 processors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 10:51:51 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Deng", "Xiaomao", ""], ["Cai", "Xiao-chuan", ""], ["Zou", "Jun", ""]]}, {"id": "1508.06429", "submitter": "Shusen Wang", "authors": "Shusen Wang, Zhihua Zhang, Tong Zhang", "title": "Improved Analyses of the Randomized Power Method and Block Lanczos\n  Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power method and block Lanczos method are popular numerical algorithms\nfor computing the truncated singular value decomposition (SVD) and eigenvalue\ndecomposition problems. Especially in the literature of randomized numerical\nlinear algebra, the power method is widely applied to improve the quality of\nrandomized sketching, and relative-error bounds have been well established.\nRecently, Musco & Musco (2015) proposed a block Krylov subspace method that\nfully exploits the intermediate results of the power iteration to accelerate\nconvergence. They showed spectral gap-independent bounds which are stronger\nthan the power method by order-of-magnitude. This paper offers novel error\nanalysis techniques and significantly improves the bounds of both the\nrandomized power method and the block Lanczos method. This paper also\nestablishes the first gap-independent bound for the warm-start block Lanczos\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 09:58:30 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2015 05:12:29 GMT"}], "update_date": "2015-12-21", "authors_parsed": [["Wang", "Shusen", ""], ["Zhang", "Zhihua", ""], ["Zhang", "Tong", ""]]}, {"id": "1508.07240", "submitter": "Sajjad Khaleqi", "authors": "Kourosh Parand, Sajjad Khaleqi", "title": "Rational Chebyshev of Second Kind Collocation Method for Solving a Class\n  of Astrophysics Problems", "comments": "arXiv admin note: text overlap with arXiv:1008.2063", "journal-ref": null, "doi": "10.1140/epjp/i2016-16024-8", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lane-Emden equation has been used to model several phenomenas in\ntheoretical physics, mathematical physics and astrophysics such as the theory\nof stellar structure. This study is an attempt to utilize the collocation\nmethod with the Rational Chebyshev of Second Kind function (RSC) to solve the\nLane-Emden equation over the semi-infinit interval [0; +infinity). According to\nwell-known results and comparing with previous methods, it can be said that\nthis method is efficient and applicable.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 15:18:17 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Parand", "Kourosh", ""], ["Khaleqi", "Sajjad", ""]]}, {"id": "1508.07416", "submitter": "Guoxu Zhou", "authors": "Guoxu Zhou, Qibin Zhao, Yu Zhang, T\\\"ulay Adal{\\i}, Shengli Xie,\n  Andrzej Cichocki", "title": "Linked Component Analysis from Matrices to High Order Tensors:\n  Applications to Biomedical Data", "comments": "20 pages, 11 figures, Proceedings of the IEEE, 2015", "journal-ref": null, "doi": "10.1109/JPROC.2015.2474704", "report-no": null, "categories": "cs.CE cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing availability of various sensor technologies, we now have\naccess to large amounts of multi-block (also called multi-set,\nmulti-relational, or multi-view) data that need to be jointly analyzed to\nexplore their latent connections. Various component analysis methods have\nplayed an increasingly important role for the analysis of such coupled data. In\nthis paper, we first provide a brief review of existing matrix-based (two-way)\ncomponent analysis methods for the joint analysis of such data with a focus on\nbiomedical applications. Then, we discuss their important extensions and\ngeneralization to multi-block multiway (tensor) data. We show how constrained\nmulti-block tensor decomposition methods are able to extract similar or\nstatistically dependent common features that are shared by all blocks, by\nincorporating the multiway nature of data. Special emphasis is given to the\nflexible common and individual feature analysis of multi-block data with the\naim to simultaneously extract common and individual latent components with\ndesired properties and types of diversity. Illustrative examples are given to\ndemonstrate their effectiveness for biomedical data analysis.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2015 08:18:14 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Zhou", "Guoxu", ""], ["Zhao", "Qibin", ""], ["Zhang", "Yu", ""], ["Adal\u0131", "T\u00fclay", ""], ["Xie", "Shengli", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1508.07743", "submitter": "Hugo Jim\\'enez-P\\'erez", "authors": "Hugo Jim\\'enez-P\\'erez, Jean-Pierre Vilotte, Barbara Romanowicz", "title": "On the Poincar\\'e's generating function and the symplectic mid-point\n  rule", "comments": "11 pages, 2 figures. A better exposition of the method of Liouvillian\n  forms including most recent results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph cs.NA math.MP math.NA math.SG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Liouvillian forms to obtain symplectic maps for constructing\nnumerical integrators is a natural alternative to the method of generating\nfunctions, and provides a deeper understanding of the geometry of this\nprocedure. Using Liouvillian forms we study the generating function introduced\nby Poincar\\'e (1899) and its associated symplectic map. We show that in this\nframework, Poincar\\'e's generating function does not correspond to the\nsymplectic mid-point rule, but to the identity map. We give an interpretation\nof this result based on the original framework constructed by Poincar\\'e.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 09:48:53 GMT"}, {"version": "v2", "created": "Sat, 28 May 2016 13:24:43 GMT"}, {"version": "v3", "created": "Sun, 19 Feb 2017 22:52:14 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 01:11:28 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Jim\u00e9nez-P\u00e9rez", "Hugo", ""], ["Vilotte", "Jean-Pierre", ""], ["Romanowicz", "Barbara", ""]]}]