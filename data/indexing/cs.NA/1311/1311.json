[{"id": "1311.0156", "submitter": "Jinshan Zeng", "authors": "Jinshan Zeng, Shaobo Lin, Yao Wang and Zongben Xu", "title": "$L_{1/2}$ Regularization: Convergence of Iterative Half Thresholding\n  Algorithm", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": "10.1109/TSP.2014.2309076", "report-no": null, "categories": "cs.NA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In recent studies on sparse modeling, the nonconvex regularization approaches\n(particularly, $L_{q}$ regularization with $q\\in(0,1)$) have been demonstrated\nto possess capability of gaining much benefit in sparsity-inducing and\nefficiency. As compared with the convex regularization approaches (say, $L_{1}$\nregularization), however, the convergence issue of the corresponding algorithms\nare more difficult to tackle. In this paper, we deal with this difficult issue\nfor a specific but typical nonconvex regularization scheme, the $L_{1/2}$\nregularization, which has been successfully used to many applications. More\nspecifically, we study the convergence of the iterative \\textit{half}\nthresholding algorithm (the \\textit{half} algorithm for short), one of the most\nefficient and important algorithms for solution to the $L_{1/2}$\nregularization. As the main result, we show that under certain conditions, the\n\\textit{half} algorithm converges to a local minimizer of the $L_{1/2}$\nregularization, with an eventually linear convergence rate. The established\nresult provides a theoretical guarantee for a wide range of applications of the\n\\textit{half} algorithm. We provide also a set of simulations to support the\ncorrectness of theoretical assertions and compare the time efficiency of the\n\\textit{half} algorithm with other known typical algorithms for $L_{1/2}$\nregularization like the iteratively reweighted least squares (IRLS) algorithm\nand the iteratively reweighted $l_{1}$ minimization (IRL1) algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2013 12:03:25 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2014 05:37:31 GMT"}, {"version": "v3", "created": "Tue, 15 Apr 2014 20:05:45 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Zeng", "Jinshan", ""], ["Lin", "Shaobo", ""], ["Wang", "Yao", ""], ["Xu", "Zongben", ""]]}, {"id": "1311.0269", "submitter": "Peter Elmer", "authors": "David Abdurachmanov, Peter Elmer, Giulio Eulisse, Shahzad Muzaffar", "title": "Initial explorations of ARM processors for scientific computing", "comments": "Submitted to proceedings of the 15th International Workshop on\n  Advanced Computing and Analysis Techniques in Physics Research (ACAT2013),\n  Beijing. arXiv admin note: text overlap with arXiv:1311.1001", "journal-ref": null, "doi": "10.1088/1742-6596/523/1/012009", "report-no": null, "categories": "physics.comp-ph cs.DC cs.NA hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power efficiency is becoming an ever more important metric for both high\nperformance and high throughput computing. Over the course of next decade it is\nexpected that flops/watt will be a major driver for the evolution of computer\narchitecture. Servers with large numbers of ARM processors, already ubiquitous\nin mobile computing, are a promising alternative to traditional x86-64\ncomputing. We present the results of our initial investigations into the use of\nARM processors for scientific computing applications. In particular we report\nthe results from our work with a current generation ARMv7 development board to\nexplore ARM-specific issues regarding the software development environment,\noperating system, performance benchmarks and issues for porting High Energy\nPhysics software.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2013 19:33:35 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2014 09:23:39 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["Abdurachmanov", "David", ""], ["Elmer", "Peter", ""], ["Eulisse", "Giulio", ""], ["Muzaffar", "Shahzad", ""]]}, {"id": "1311.0272", "submitter": "Peter Elmer", "authors": "Kapil Arya, Gene Cooperman, Andrea Dotti, Peter Elmer", "title": "Use of checkpoint-restart for complex HEP software on traditional\n  architectures and Intel MIC", "comments": "Submitted to proceedings of the 15th International Workshop on\n  Advanced Computing and Analysis Techniques in Physics Research (ACAT2013),\n  Beijing", "journal-ref": null, "doi": "10.1088/1742-6596/523/1/012015", "report-no": null, "categories": "physics.comp-ph cs.DC cs.NA hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process checkpoint-restart is a technology with great potential for use in\nHEP workflows. Use cases include debugging, reducing the startup time of\napplications both in offline batch jobs and the High Level Trigger, permitting\njob preemption in environments where spare CPU cycles are being used\nopportunistically and efficient scheduling of a mix of multicore and\nsingle-threaded jobs. We report on tests of checkpoint-restart technology using\nCMS software, Geant4-MT (multi-threaded Geant4), and the DMTCP (Distributed\nMultithreaded Checkpointing) package. We analyze both single- and\nmulti-threaded applications and test on both standard Intel x86 architectures\nand on Intel MIC. The tests with multi-threaded applications on Intel MIC are\nused to consider scalability and performance. These are considered an indicator\nof what the future may hold for many-core computing.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2013 19:40:39 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2014 08:37:58 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["Arya", "Kapil", ""], ["Cooperman", "Gene", ""], ["Dotti", "Andrea", ""], ["Elmer", "Peter", ""]]}, {"id": "1311.2448", "submitter": "Thakshila Wimalajeewa", "authors": "Thakshila Wimalajeewa, Yonina C. Eldar and Pramod K. Varshney", "title": "Recovery of Sparse Matrices via Matrix Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of recovering an unknown sparse matrix\nX from the matrix sketch Y = AX B^T. The dimension of Y is less than that of X,\nand A and B are known matrices. This problem can be solved using standard\ncompressive sensing (CS) theory after converting it to vector form using the\nKronecker operation. In this case, the measurement matrix assumes a Kronecker\nproduct structure. However, as the matrix dimension increases the associated\ncomputational complexity makes its use prohibitive. We extend two algorithms,\nfast iterative shrinkage threshold algorithm (FISTA) and orthogonal matching\npursuit (OMP) to solve this problem in matrix form without employing the\nKronecker product. While both FISTA and OMP with matrix inputs are shown to be\nequivalent in performance to their vector counterparts with the Kronecker\nproduct, solving them in matrix form is shown to be computationally more\nefficient. We show that the computational gain achieved by FISTA with matrix\ninputs over its vector form is more significant compared to that achieved by\nOMP.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 14:12:28 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Wimalajeewa", "Thakshila", ""], ["Eldar", "Yonina C.", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1311.2661", "submitter": "Srikrishna Sridhar", "authors": "Srikrishna Sridhar, Victor Bittorf, Ji Liu, Ce Zhang, Christopher R\\'e\n  and Stephen J. Wright", "title": "An Approximate, Efficient Solver for LP Rounding", "comments": "Clarified that this manuscript is a full version of an article that\n  is to appear in NIPS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in machine learning can be solved by rounding the solution of\nan appropriate linear program (LP). This paper shows that we can recover\nsolutions of comparable quality by rounding an approximate LP solution instead\nof the ex- act one. These approximate LP solutions can be computed efficiently\nby applying a parallel stochastic-coordinate-descent method to a\nquadratic-penalty formulation of the LP. We derive worst-case runtime and\nsolution quality guarantees of this scheme using novel perturbation and\nconvergence analysis. Our experiments demonstrate that on such combinatorial\nproblems as vertex cover, independent set and multiway-cut, our approximate\nrounding scheme is up to an order of magnitude faster than Cplex (a commercial\nLP solver) while producing solutions of similar quality.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 02:23:43 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2013 03:44:30 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Sridhar", "Srikrishna", ""], ["Bittorf", "Victor", ""], ["Liu", "Ji", ""], ["Zhang", "Ce", ""], ["R\u00e9", "Christopher", ""], ["Wright", "Stephen J.", ""]]}, {"id": "1311.2780", "submitter": "Petr Vabishchevich N.", "authors": "Petr N. Vabishchevich", "title": "A priori estimation of a time step for numerically solving parabolic\n  problems", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with the problem of choosing a time step for the numerical\nsolution of boundary value problems for parabolic equations. The problem\nsolution is derived using the fully implicit scheme, whereas a time step is\nselected via explicit calculations. The selection strategy consists of the\nfollowing steps. First, using the explicit scheme, we calculate the solution at\na new time level. Next, we employ this solution in order to obtain the solution\nat the previous time level (the implicit scheme, explicit calculations). This\nsolution should be close to the solution of our problem at this time level with\na prescribed accuracy. Such an algorithm leads to explicit formulas for the\ncalculation of the time step and takes into account both the dynamics of the\nproblem solution and changes in coefficients of the equation and in its\nright-hand side. The same formulas for the evaluation of the time step we get\nusing a comparison of two approximate solutions, which are obtained using the\nexplicit scheme with the primary time step and the step that is reduced by\nhalf. Numerical results are presented for a model parabolic boundary value\nproblem, which demonstrate the robustness of the developed algorithm for the\ntime step selection.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 13:47:55 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Vabishchevich", "Petr N.", ""]]}, {"id": "1311.2854", "submitter": "Christos Boutsidis", "authors": "Christos Boutsidis and Alex Gittens and Prabhanjan Kambadur", "title": "Spectral Clustering via the Power Method -- Provably", "comments": "ICML 2015, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most important algorithms in data mining\nand machine intelligence; however, its computational complexity limits its\napplication to truly large scale data analysis. The computational bottleneck in\nspectral clustering is computing a few of the top eigenvectors of the\n(normalized) Laplacian matrix corresponding to the graph representing the data\nto be clustered. One way to speed up the computation of these eigenvectors is\nto use the \"power method\" from the numerical linear algebra literature.\nAlthough the power method has been empirically used to speed up spectral\nclustering, the theory behind this approach, to the best of our knowledge,\nremains unexplored. This paper provides the \\emph{first} such rigorous\ntheoretical justification, arguing that a small number of power iterations\nsuffices to obtain near-optimal partitionings using the approximate\neigenvectors. Specifically, we prove that solving the $k$-means clustering\nproblem on the approximate eigenvectors obtained via the power method gives an\nadditive-error approximation to solving the $k$-means problem on the optimal\neigenvectors.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 17:42:34 GMT"}, {"version": "v2", "created": "Sun, 8 Feb 2015 15:55:49 GMT"}, {"version": "v3", "created": "Tue, 12 May 2015 14:39:32 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Boutsidis", "Christos", ""], ["Gittens", "Alex", ""], ["Kambadur", "Prabhanjan", ""]]}, {"id": "1311.3286", "submitter": "Richard Peng", "authors": "Richard Peng, Daniel A. Spielman", "title": "An Efficient Parallel Solver for SDD Linear Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first parallel algorithm for solving systems of linear\nequations in symmetric, diagonally dominant (SDD) matrices that runs in\npolylogarithmic time and nearly-linear work. The heart of our algorithm is a\nconstruction of a sparse approximate inverse chain for the input matrix: a\nsequence of sparse matrices whose product approximates its inverse. Whereas\nother fast algorithms for solving systems of equations in SDD matrices exploit\nlow-stretch spanning trees, our algorithm only requires spectral graph\nsparsifiers.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 20:41:01 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Peng", "Richard", ""], ["Spielman", "Daniel A.", ""]]}, {"id": "1311.3358", "submitter": "Ronald Haynes PhD", "authors": "Ronald D. Haynes and Alexander J.M. Howse", "title": "Generating Equidistributed Meshes in 2D via Domain Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider Schwarz domain decomposition applied to the\ngeneration of 2D spatial meshes by a local equidistribution principle. We\nbriefly review the derivation of the local equidistribution principle and the\nappropriate choice of boundary conditions. We then introduce classical and\noptimized Schwarz domain decomposition methods to solve the resulting system of\nnonlinear equations. The implementation of these iterations are discussed, and\nwe conclude with numerical examples to illustrate the performance of the\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 01:29:15 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["Haynes", "Ronald D.", ""], ["Howse", "Alexander J. M.", ""]]}, {"id": "1311.3731", "submitter": "Victor Pan", "authors": "Ioannis Z. Emiris, Victor Y. Pan and Elias P. Tsigaridas", "title": "Chapter 10: Algebraic Algorithms", "comments": "41.1 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our Chapter in the upcoming Volume I: Computer Science and Software\nEngineering of Computing Handbook (Third edition), Allen Tucker, Teo Gonzales\nand Jorge L. Diaz-Herrera, editors, covers Algebraic Algorithms, both symbolic\nand numerical, for matrix computations and root-finding for polynomials and\nsystems of polynomials equations. We cover part of these large subjects and\ninclude basic bibliography for further study. To meet space limitation we cite\nbooks, surveys, and comprehensive articles with pointers to further references,\nrather than including all the original technical papers.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 05:50:38 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Emiris", "Ioannis Z.", ""], ["Pan", "Victor Y.", ""], ["Tsigaridas", "Elias P.", ""]]}, {"id": "1311.3766", "submitter": "Petr Vabishchevich N.", "authors": "A.E. Kolesov, P.N. Vabishchevich, M.V. Vasilyeva", "title": "Splitting schemes for poroelasticity and thermoelasticity problems", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the coupled systems of linear unsteady partial\ndifferential equations, which arise in the modeling of poroelasticity\nprocesses. Stability estimates of weighted difference schemes for the coupled\nsystem of equations are presented. Approximation in space is based on the\nfinite element method. We construct splitting schemes and give some numerical\ncomparisons for typical poroelasticity problems. The results of numerical\nsimulation of a 3D problem are presented. Special attention is given to using\nhight performance computing systems.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 08:33:42 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Kolesov", "A. E.", ""], ["Vabishchevich", "P. N.", ""], ["Vasilyeva", "M. V.", ""]]}, {"id": "1311.4257", "submitter": "Austin Benson", "authors": "Austin R. Benson, Jack Poulson, Kenneth Tran, Bj\\\"orn Engquist, Lexing\n  Ying", "title": "A parallel directional Fast Multipole Method", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing, 36(4), 2014", "doi": "10.1137/130945569", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a parallel directional fast multipole method (FMM) for\nsolving N-body problems with highly oscillatory kernels, with a focus on the\nHelmholtz kernel in three dimensions. This class of oscillatory kernels\nrequires a more restrictive low-rank criterion than that of the low-frequency\nregime, and thus effective parallelizations must adapt to the modified data\ndependencies. We propose a simple partition at a fixed level of the octree and\nshow that, if the partitions are properly balanced between p processes, the\noverall runtime is essentially O(N log N/p+ p). By the structure of the\nlow-rank criterion, we are able to avoid communication at the top of the\noctree. We demonstrate the effectiveness of our parallelization on several\nchallenging models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 03:47:36 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Benson", "Austin R.", ""], ["Poulson", "Jack", ""], ["Tran", "Kenneth", ""], ["Engquist", "Bj\u00f6rn", ""], ["Ying", "Lexing", ""]]}, {"id": "1311.4296", "submitter": "Francis Bach", "authors": "Stefanie Jegelka, Francis Bach (INRIA Paris - Rocquencourt, LIENS),\n  Suvrit Sra (MPI)", "title": "Reflection methods for user-friendly submodular optimization", "comments": "Neural Information Processing Systems (NIPS), \\'Etats-Unis (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has become evident that submodularity naturally captures widely\noccurring concepts in machine learning, signal processing and computer vision.\nConsequently, there is need for efficient optimization procedures for\nsubmodular functions, especially for minimization problems. While general\nsubmodular minimization is challenging, we propose a new method that exploits\nexisting decomposability of submodular functions. In contrast to previous\napproaches, our method is neither approximate, nor impractical, nor does it\nneed any cumbersome parameter tuning. Moreover, it is easy to implement and\nparallelize. A key component of our method is a formulation of the discrete\nsubmodular minimization problem as a continuous best approximation problem that\nis solved through a sequence of reflections, and its solution can be easily\nthresholded to obtain an optimal discrete solution. This method solves both the\ncontinuous and discrete formulations of the problem, and therefore has\napplications in learning, inference, and reconstruction. In our experiments, we\nillustrate the benefits of our method on two image segmentation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 08:48:13 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Jegelka", "Stefanie", "", "INRIA Paris - Rocquencourt, LIENS"], ["Bach", "Francis", "", "INRIA Paris - Rocquencourt, LIENS"], ["Sra", "Suvrit", "", "MPI"]]}, {"id": "1311.4643", "submitter": "Zohar Karnin", "authors": "Dimitris Achlioptas, Zohar Karnin, Edo Liberty", "title": "Near-Optimal Entrywise Sampling for Data Matrices", "comments": "14 pages, to appear in NIPS' 13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of selecting non-zero entries of a matrix $A$ in\norder to produce a sparse sketch of it, $B$, that minimizes $\\|A-B\\|_2$. For\nlarge $m \\times n$ matrices, such that $n \\gg m$ (for example, representing $n$\nobservations over $m$ attributes) we give sampling distributions that exhibit\nfour important properties. First, they have closed forms computable from\nminimal information regarding $A$. Second, they allow sketching of matrices\nwhose non-zeros are presented to the algorithm in arbitrary order as a stream,\nwith $O(1)$ computation per non-zero. Third, the resulting sketch matrices are\nnot only sparse, but their non-zero entries are highly compressible. Lastly,\nand most importantly, under mild assumptions, our distributions are provably\ncompetitive with the optimal offline distribution. Note that the probabilities\nin the optimal offline distribution may be complex functions of all the entries\nin the matrix. Therefore, regardless of computational complexity, the optimal\ndistribution might be impossible to compute in the streaming model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 08:00:50 GMT"}], "update_date": "2013-11-20", "authors_parsed": [["Achlioptas", "Dimitris", ""], ["Karnin", "Zohar", ""], ["Liberty", "Edo", ""]]}, {"id": "1311.5202", "submitter": "Yanchuang Cao", "authors": "Yanchuang Cao, Lihua Wen, Jinyou Xiao, Yijun Liu", "title": "A fast directional BEM for large-scale acoustic problems based on the\n  Burton-Miller formulation", "comments": "22 pages", "journal-ref": "Engineering Analysis with Boundary Elements. 50(1):47-58. 2015", "doi": "10.1016/j.enganabound.2014.07.006", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a highly efficient fast boundary element method (BEM) for\nsolving large-scale engineering acoustic problems in a broad frequency range is\ndeveloped and implemented. The acoustic problems are modeled by the\nBurton-Miller boundary integral equation (BIE), thus the fictitious frequency\nissue is completely avoided. The BIE is discretized by using the Nystr\\\"om\nmethod based on the curved quadratic elements, leading to simple numerical\nimplementation (no edge or corner problems) and high accuracy in the BEM\nanalysis. The linear systems are solved iteratively and accelerated by using a\nnewly developed kernel-independent wideband fast directional algorithm (FDA)\nfor fast summation of oscillatory kernels. In addition, the computational\nefficiency of the FDA is further promoted by exploiting the low-rank features\nof the translation matrices, resulting in two- to three-fold reduction in the\ncomputational time of the multipole-to-local translations. The high accuracy\nand nearly linear computational complexity of the present method are clearly\ndemonstrated by typical examples. An acoustic scattering problem with\ndimensionless wave number $kD$ (where $k$ is the wave number and $D$ is the\ntypical length of the obstacle) up to 1000 and the degrees of freedom up to 4\nmillion is successfully solved within 10 hours on a computer with one core and\nthe memory usage is 24 GB.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2013 09:09:32 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2014 05:40:18 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Cao", "Yanchuang", ""], ["Wen", "Lihua", ""], ["Xiao", "Jinyou", ""], ["Liu", "Yijun", ""]]}, {"id": "1311.5414", "submitter": "Akitoshi Kawamura", "authors": "Akitoshi Kawamura (University of Tokyo), Hiroyuki Ota (University of\n  Tokyo), Carsten R\\\"osnick (Technische Universit\\\"at Darmstadt), Martin\n  Ziegler (Technische Universit\\\"at Darmstadt)", "title": "Computational Complexity of Smooth Differential Equations", "comments": "15 pages, 3 figures", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 1 (February\n  11, 2014) lmcs:960", "doi": "10.2168/LMCS-10(1:6)2014", "report-no": null, "categories": "cs.CC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of the solutions $h$ to the ordinary\ndifferential equation $h(0)=0$, $h'(t) = g(t, h(t))$ under various assumptions\non the function $g$ has been investigated. Kawamura showed in 2010 that the\nsolution $h$ can be PSPACE-hard even if $g$ is assumed to be Lipschitz\ncontinuous and polynomial-time computable. We place further requirements on the\nsmoothness of $g$ and obtain the following results: the solution $h$ can still\nbe PSPACE-hard if $g$ is assumed to be of class $C^1$; for each $k\\ge2$, the\nsolution $h$ can be hard for the counting hierarchy even if $g$ is of class\n$C^k$.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2013 14:23:05 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2014 17:46:29 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kawamura", "Akitoshi", "", "University of Tokyo"], ["Ota", "Hiroyuki", "", "University of\n  Tokyo"], ["R\u00f6snick", "Carsten", "", "Technische Universit\u00e4t Darmstadt"], ["Ziegler", "Martin", "", "Technische Universit\u00e4t Darmstadt"]]}, {"id": "1311.5750", "submitter": "Xiaotong Yuan", "authors": "Xiao-Tong Yuan, Ping Li, Tong Zhang", "title": "Gradient Hard Thresholding Pursuit for Sparsity-Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hard Thresholding Pursuit (HTP) is an iterative greedy selection procedure\nfor finding sparse solutions of underdetermined linear systems. This method has\nbeen shown to have strong theoretical guarantee and impressive numerical\nperformance. In this paper, we generalize HTP from compressive sensing to a\ngeneric problem setup of sparsity-constrained convex optimization. The proposed\nalgorithm iterates between a standard gradient descent step and a hard\nthresholding step with or without debiasing. We prove that our method enjoys\nthe strong guarantees analogous to HTP in terms of rate of convergence and\nparameter estimation accuracy. Numerical evidences show that our method is\nsuperior to the state-of-the-art greedy selection methods in sparse logistic\nregression and sparse precision matrix estimation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2013 13:52:07 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2013 04:19:39 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Yuan", "Xiao-Tong", ""], ["Li", "Ping", ""], ["Zhang", "Tong", ""]]}, {"id": "1311.7477", "submitter": "Lukas Einkemmer", "authors": "Lukas Einkemmer, Matthias Wiesenberger", "title": "A conservative discontinuous Galerkin scheme for the 2D incompressible\n  Navier--Stokes equations", "comments": null, "journal-ref": "Computer Physics Communications, Volume 185, Issue 11, November\n  2014, Pages 2865-2873", "doi": "10.1016/j.cpc.2014.07.007", "report-no": null, "categories": "physics.comp-ph cs.NA math.NA physics.flu-dyn physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a conservative discretization of the\ntwo-dimensional incompressible Navier--Stokes equations. We propose an\nextension of Arakawa's classical finite difference scheme for fluid flow in the\nvorticity-stream function formulation to a high order discontinuous Galerkin\napproximation. In addition, we show numerical simulations that demonstrate the\naccuracy of the scheme and verify the conservation properties, which are\nessential for long time integration. Furthermore, we discuss the massively\nparallel implementation on graphic processing units.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2013 08:06:51 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Einkemmer", "Lukas", ""], ["Wiesenberger", "Matthias", ""]]}]