[{"id": "1201.0017", "submitter": "Denitsa Staicova", "authors": "Plamen P. Fiziev and Denitsa R. Staicova", "title": "Solving systems of transcendental equations involving the Heun functions", "comments": "17 pages, 4 figures. Typos corrected, one figure added, some sections\n  revised. The article is a rework of the internal report arXiv:1005.5375", "journal-ref": "American Journal of Computational Mathematics Vol. 02 : 02, pp.95\n  (2012)", "doi": "10.4236/ajcm.2012.22013", "report-no": "SU-TH/29-12-2011", "categories": "cs.NA astro-ph.IM gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Heun functions have wide application in modern physics and are expected\nto succeed the hypergeometrical functions in the physical problems of the 21st\ncentury. The numerical work with those functions, however, is complicated and\nrequires filling the gaps in the theory of the Heun functions and also,\ncreating new algorithms able to work with them efficiently.\n  We propose a new algorithm for solving a system of two nonlinear\ntranscendental equations with two complex variables based on the M\\\"uller\nalgorithm. The new algorithm is particularly useful in systems featuring the\nHeun functions and for them, the new algorithm gives distinctly better results\nthan Newton's and Broyden's methods.\n  As an example for its application in physics, the new algorithm was used to\nfind the quasi-normal modes (QNM) of Schwarzschild black hole described by the\nRegge-Wheeler equation. The numerical results obtained by our method are\ncompared with the already published QNM frequencies and are found to coincide\nto a great extent with them. Also discussed are the QNM of the Kerr black hole,\ndescribed by the Teukolsky Master equation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2011 21:00:35 GMT"}, {"version": "v2", "created": "Wed, 1 Feb 2012 19:59:53 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Fiziev", "Plamen P.", ""], ["Staicova", "Denitsa R.", ""]]}, {"id": "1201.0127", "submitter": "Christos Boutsidis", "authors": "Haim Avron, Christos Boutsidis", "title": "Faster Subset Selection for Matrices and Applications", "comments": "To appear in SIAM Journal on Matrix Analysis and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study subset selection for matrices defined as follows: given a matrix\n$\\matX \\in \\R^{n \\times m}$ ($m > n$) and an oversampling parameter $k$ ($n \\le\nk \\le m$), select a subset of $k$ columns from $\\matX$ such that the\npseudo-inverse of the subsampled matrix has as smallest norm as possible. In\nthis work, we focus on the Frobenius and the spectral matrix norms. We describe\nseveral novel (deterministic and randomized) approximation algorithms for this\nproblem with approximation bounds that are optimal up to constant factors.\nAdditionally, we show that the combinatorial problem of finding a low-stretch\nspanning tree in an undirected graph corresponds to subset selection, and\ndiscuss various implications of this reduction.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2011 13:54:29 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 16:52:43 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2012 20:53:05 GMT"}, {"version": "v4", "created": "Fri, 21 Jun 2013 21:05:56 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Avron", "Haim", ""], ["Boutsidis", "Christos", ""]]}, {"id": "1201.0925", "submitter": "Bijan Afsari", "authors": "Bijan Afsari, Roberto Tron, and Ren\\'e Vidal", "title": "On The Convergence of Gradient Descent for Finding the Riemannian Center\n  of Mass", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG cs.CV cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding the global Riemannian center of mass of a set\nof data points on a Riemannian manifold. Specifically, we investigate the\nconvergence of constant step-size gradient descent algorithms for solving this\nproblem. The challenge is that often the underlying cost function is neither\nglobally differentiable nor convex, and despite this one would like to have\nguaranteed convergence to the global minimizer. After some necessary\npreparations we state a conjecture which we argue is the best (in a sense\ndescribed) convergence condition one can hope for. The conjecture specifies\nconditions on the spread of the data points, step-size range, and the location\nof the initial condition (i.e., the region of convergence) of the algorithm.\nThese conditions depend on the topology and the curvature of the manifold and\ncan be conveniently described in terms of the injectivity radius and the\nsectional curvatures of the manifold. For manifolds of constant nonnegative\ncurvature (e.g., the sphere and the rotation group in $\\mathbb{R}^{3}$) we show\nthat the conjecture holds true (we do this by proving and using a comparison\ntheorem which seems to be of a different nature from the standard comparison\ntheorems in Riemannian geometry). For manifolds of arbitrary curvature we prove\nconvergence results which are weaker than the conjectured one (but still\nsuperior over the available results). We also briefly study the effect of the\nconfiguration of the data points on the speed of convergence.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2011 17:59:03 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Afsari", "Bijan", ""], ["Tron", "Roberto", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1201.0942", "submitter": "Anna Kucerova", "authors": "Eliska Janouchova and Anna Kucerova", "title": "Competitive Comparison of Optimal Designs of Experiments for\n  Sampling-based Sensitivity Analysis", "comments": "18 pages, 15 figures, 4 tables, CSC2011 special issue, corrected and\n  extended after the first review", "journal-ref": "Computers & Structures, 124, 47-60, 2013", "doi": "10.1016/j.compstruc.2013.04.009", "report-no": null, "categories": "cs.CE cs.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the numerical models of real-world structures are more precise,\nmore complex and, of course, more time-consuming. Despite the growth of a\ncomputational effort, the exploration of model behaviour remains a complex\ntask. The sensitivity analysis is a basic tool for investigating the\nsensitivity of the model to its inputs. One widely used strategy to assess the\nsensitivity is based on a finite set of simulations for a given sets of input\nparameters, i.e. points in the design space. An estimate of the sensitivity can\nbe then obtained by computing correlations between the input parameters and the\nchosen response of the model. The accuracy of the sensitivity prediction\ndepends on the choice of design points called the design of experiments. The\naim of the presented paper is to review and compare available criteria\ndetermining the quality of the design of experiments suitable for\nsampling-based sensitivity analysis.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 17:35:27 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2012 08:11:50 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Janouchova", "Eliska", ""], ["Kucerova", "Anna", ""]]}, {"id": "1201.2878", "submitter": "John Chapman", "authors": "Andrea Cangiani, John Chapman, Emmanuil Georgoulis and Max Jensen", "title": "Implementation of the Continuous-Discontinuous Galerkin Finite Element\n  Method", "comments": "Enumath 2011", "journal-ref": null, "doi": "10.1007/978-3-642-33134-3_34", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the stationary advection-diffusion problem the standard continuous\nGalerkin method is unstable without some additional control on the mesh or\nmethod. The interior penalty discontinuous Galerkin method is stable but at the\nexpense of an increased number of degrees of freedom. The hybrid method\nproposed in [5] combines the computational complexity of the continuous method\nwith the stability of the discontinuous method without a significant increase\nin degrees of freedom. We discuss the implementation of this method using the\nfinite element library deal.ii and present some numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 16:08:47 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Cangiani", "Andrea", ""], ["Chapman", "John", ""], ["Georgoulis", "Emmanuil", ""], ["Jensen", "Max", ""]]}, {"id": "1201.3120", "submitter": "Christine Klymko", "authors": "Michele Benzi, Ernesto Estrada, and Christine Klymko", "title": "Ranking hubs and authorities using matrix functions", "comments": "28 pages, 6 figures", "journal-ref": "Linear Algebra and its Applications, 438 (2013), pp. 2447-2474", "doi": null, "report-no": null, "categories": "math.NA cs.NA cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notions of subgraph centrality and communicability, based on the\nexponential of the adjacency matrix of the underlying graph, have been\neffectively used in the analysis of undirected networks. In this paper we\npropose an extension of these measures to directed networks, and we apply them\nto the problem of ranking hubs and authorities. The extension is achieved by\nbipartization, i.e., the directed network is mapped onto a bipartite undirected\nnetwork with twice as many nodes in order to obtain a network with a symmetric\nadjacency matrix. We explicitly determine the exponential of this adjacency\nmatrix in terms of the adjacency matrix of the original, directed network, and\nwe give an interpretation of centrality and communicability in this new\ncontext, leading to a technique for ranking hubs and authorities. The matrix\nexponential method for computing hubs and authorities is compared to the well\nknown HITS algorithm, both on small artificial examples and on more realistic\nreal-world networks. A few other ranking algorithms are also discussed and\ncompared with our technique. The use of Gaussian quadrature rules for\ncalculating hub and authority scores is discussed.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 20:37:19 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2012 01:45:27 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2012 15:04:45 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Benzi", "Michele", ""], ["Estrada", "Ernesto", ""], ["Klymko", "Christine", ""]]}, {"id": "1201.3298", "submitter": "Jezabel Curbelo", "authors": "Jezabel Curbelo and Ana M. Mancho", "title": "Spectral numerical schemes for time-dependent convection with viscosity\n  dependent on temperature", "comments": "17 pages, 7 figures", "journal-ref": "Commun. Nonlinear Sci. Numer. Simul. 19, 538 (2014)", "doi": "10.1016/j.cnsns.2013.04.005", "report-no": null, "categories": "physics.comp-ph cs.NA math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes spectral numerical methods to solve the time evolution\nof convection problems with viscosity strongly depending on temperature at\ninfinite Prandtl number. Although we verify the proposed techniques just for\nviscosities that depend exponentially on temperature, the methods are\nextensible to other dependence laws. The set-up is a 2D domain with periodic\nboundary conditions along the horizontal coordinate. This introduces a symmetry\nin the problem, the O(2) symmetry, which is particularly well described by\nspectral methods and motivates the use of these methods in this context. We\nexamine the scope of our techniques by exploring transitions from stationary\nregimes towards time dependent regimes. At a given aspect ratio stable\nstationary solutions become unstable through a Hopf bifurcation, after which\nthe time-dependent regime is solved by the spectral techniques proposed in this\narticle.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 16:01:21 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2012 16:07:21 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2013 19:57:02 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Curbelo", "Jezabel", ""], ["Mancho", "Ana M.", ""]]}, {"id": "1201.3914", "submitter": "Peter Kornerup", "authors": "Peter Kornerup, Jean-Michel Muller and Adrien Panhaleux", "title": "Floating-Point Arithmetic on Round-to-Nearest Representations", "comments": "IMADA-preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we introduced a class of number representations denoted\nRN-representations, allowing an un-biased rounding-to-nearest to take place by\na simple truncation. In this paper we briefly review the binary fixed-point\nrepresentation in an encoding which is essentially an ordinary 2's complement\nrepresentation with an appended round-bit. Not only is this rounding a constant\ntime operation, so is also sign inversion, both of which are at best log-time\noperations on ordinary 2's complement representations. Addition, multiplication\nand division is defined in such a way that rounding information can be carried\nalong in a meaningful way, at minimal cost. Based on the fixed-point encoding\nwe here define a floating point representation, and describe to some detail a\npossible implementation of a floating point arithmetic unit employing this\nrepresentation, including also the directed roundings.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 10:32:38 GMT"}], "update_date": "2012-01-20", "authors_parsed": [["Kornerup", "Peter", ""], ["Muller", "Jean-Michel", ""], ["Panhaleux", "Adrien", ""]]}, {"id": "1201.4049", "submitter": "Anna Kucerova", "authors": "Bojana V. Rosi\\'c and Anna Ku\\v{c}erov\\'a and Jan S\\'ykora and Oliver\n  Pajonk and Alexander Litvinenko and Hermann G. Matthies", "title": "Parameter Identification in a Probabilistic Setting", "comments": "29 pages, 16 figures", "journal-ref": "Engineering Structures, 50, 179-196, 2013", "doi": "10.1016/j.engstruct.2012.12.029", "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter identification problems are formulated in a probabilistic language,\nwhere the randomness reflects the uncertainty about the knowledge of the true\nvalues. This setting allows conceptually easily to incorporate new information,\ne.g. through a measurement, by connecting it to Bayes's theorem. The unknown\nquantity is modelled as a (may be high-dimensional) random variable. Such a\ndescription has two constituents, the measurable function and the measure. One\ngroup of methods is identified as updating the measure, the other group changes\nthe measurable function. We connect both groups with the relatively recent\nmethods of functional approximation of stochastic problems, and introduce\nespecially in combination with the second group of methods a new procedure\nwhich does not need any sampling, hence works completely deterministically. It\nalso seems to be the fastest and more reliable when compared with other\nmethods. We show by example that it also works for highly nonlinear non-smooth\nproblems with non-Gaussian measures.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 13:00:34 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Rosi\u0107", "Bojana V.", ""], ["Ku\u010derov\u00e1", "Anna", ""], ["S\u00fdkora", "Jan", ""], ["Pajonk", "Oliver", ""], ["Litvinenko", "Alexander", ""], ["Matthies", "Hermann G.", ""]]}, {"id": "1201.5430", "submitter": "Ramani Duraiswami", "authors": "Nail A. Gumerov and Ramani Duraiswami", "title": "Efficient FMM accelerated vortex methods in three dimensions via the\n  Lamb-Helmholtz decomposition", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2013.01.021", "report-no": "CS-TR-5002; UMIACS-TR-2012-02", "categories": "physics.comp-ph cs.NA math-ph math.MP physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vortex element methods are often used to efficiently simulate incompressible\nflows using Lagrangian techniques. Use of the FMM (Fast Multipole Method)\nallows considerable speed up of both velocity evaluation and vorticity\nevolution terms in these methods. Both equations require field evaluation of\nconstrained (divergence free) vector valued quantities (velocity, vorticity)\nand cross terms from these. These are usually evaluated by performing several\nFMM accelerated sums of scalar harmonic functions.\n  We present a formulation of the vortex methods based on the Lamb-Helmholtz\ndecomposition of the velocity in terms of two scalar potentials. In its\noriginal form, this decomposition is not invariant with respect to translation,\nviolating a key requirement for the FMM. One of the key contributions of this\npaper is a theory for translation for this representation. The translation\ntheory is developed by introducing \"conversion\" operators, which enable the\nrepresentation to be restored in an arbitrary reference frame. Using this form,\nextremely efficient vortex element computations can be made, which need\nevaluation of just two scalar harmonic FMM sums for evaluating the velocity and\nvorticity evolution terms. Details of the decomposition, translation and\nconversion formulae, and sample numerical results are presented.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2012 02:17:07 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2012 16:23:00 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Gumerov", "Nail A.", ""], ["Duraiswami", "Ramani", ""]]}, {"id": "1201.5810", "submitter": "Ioannis Emiris", "authors": "Ioannis Z. Emiris", "title": "A General Solver Based on Sparse Resultants", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.NA math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse (or toric) elimination exploits the structure of polynomials by\nmeasuring their complexity in terms of Newton polytopes instead of total\ndegree. The sparse, or Newton, resultant generalizes the classical homogeneous\nresultant and its degree is a function of the mixed volumes of the Newton\npolytopes. We sketch the sparse resultant constructions of Canny and Emiris and\nshow how they reduce the problem of root-finding to an eigenproblem. A novel\nmethod for achieving this reduction is presented which does not increase the\ndimension of the problem. Together with an implementation of the sparse\nresultant construction, it provides a general solver for polynomial systems. We\ndiscuss the overall implementation and illustrate its use by applying it to\nconcrete problems from vision, robotics and structural biology. The high\nefficiency and accuracy of the solutions suggest that sparse elimination may be\nthe method of choice for systems of moderate size.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 16:01:53 GMT"}], "update_date": "2012-01-30", "authors_parsed": [["Emiris", "Ioannis Z.", ""]]}, {"id": "1201.5975", "submitter": "Glauco Masotti Dr.", "authors": "Glauco Masotti", "title": "Floating-Point Numbers with Error Estimates (revised)", "comments": "45 pages, 18 figures, 39 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study addresses the problem of precision in floating-point (FP)\ncomputations. A method for estimating the errors which affect intermediate and\nfinal results is proposed and a summary of many software simulations is\ndiscussed. The basic idea consists of representing FP numbers by means of a\ndata structure collecting value and estimated error information. Under certain\nconstraints, the estimate of the absolute error is accurate and has a compact\nstatistical distribution. By monitoring the estimated relative error during a\ncomputation (an ad-hoc definition of relative error has been used), the\nvalidity of results can be ensured. The error estimate enables the\nimplementation of robust algorithms, and the detection of ill-conditioned\nproblems. A dynamic extension of number precision, under the control of error\nestimates, is advocated, in order to compute results within given error bounds.\nA reduced time penalty could be achieved by a specialized FP processor. The\nrealization of a hardwired processor incorporating the method, with current\ntechnology, should not be anymore a problem and would make the practical\nadoption of the method feasible for most applications.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 17:22:28 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Masotti", "Glauco", ""]]}, {"id": "1201.6035", "submitter": "Alex Druinsky", "authors": "Alex Druinsky and Sivan Toledo", "title": "How Accurate is inv(A)*b?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several widely-used textbooks lead the reader to believe that solving a\nlinear system of equations Ax = b by multiplying the vector b by a computed\ninverse inv(A) is inaccurate. Virtually all other textbooks on numerical\nanalysis and numerical linear algebra advise against using computed inverses\nwithout stating whether this is accurate or not. In fact, under reasonable\nassumptions on how the inverse is computed, x = inv(A)*b is as accurate as the\nsolution computed by the best backward-stable solvers. This fact is not new,\nbut obviously obscure. We review the literature on the accuracy of this\ncomputation and present a self-contained numerical analysis of it.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2012 12:55:30 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Druinsky", "Alex", ""], ["Toledo", "Sivan", ""]]}]