[{"id": "1308.1536", "submitter": "Gleb Beliakov", "authors": "Gleb Beliakov and Yuri Matiyasevich", "title": "A Parallel Algorithm for Calculation of Large Determinants with High\n  Accuracy for GPUs and MPI clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.NA math.NA math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel algorithm for calculating very large determinants with\narbitrary precision on computer clusters. This algorithm minimises data\nmovements between the nodes and computes not only the determinant but also all\nminors corresponding to a particular row or column at a little extra cost, and\nalso the determinants and minors of all submatrices in the top left corner at\nno extra cost. We implemented the algorithm in arbitrary precision arithmetic,\nsuitable for very ill conditioned matrices, and empirically estimated the loss\nof precision. The algorithm was applied to studies of Riemann's zeta function.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2013 11:24:07 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2013 11:06:59 GMT"}], "update_date": "2013-08-09", "authors_parsed": [["Beliakov", "Gleb", ""], ["Matiyasevich", "Yuri", ""]]}, {"id": "1308.1827", "submitter": "Mariya Ishteva", "authors": "Mariya Ishteva, Konstantin Usevich, Ivan Markovsky", "title": "Factorization approach to structured low-rank approximation with\n  applications", "comments": "Accepted for publication in SIAM Journal on Matrix Analysis and\n  Applications (SIMAX)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximating an affinely structured matrix, for\nexample a Hankel matrix, by a low-rank matrix with the same structure. This\nproblem occurs in system identification, signal processing and computer\nalgebra, among others. We impose the low-rank by modeling the approximation as\na product of two factors with reduced dimension. The structure of the low-rank\nmodel is enforced by introducing a penalty term in the objective function. The\nproposed local optimization algorithm is able to solve the weighted structured\nlow-rank approximation problem, as well as to deal with the cases of missing or\nfixed elements. In contrast to approaches based on kernel representations (in\nlinear algebraic sense), the proposed algorithm is designed to address the case\nof small targeted rank. We compare it to existing approaches on numerical\nexamples of system identification, approximate greatest common divisor problem,\nand symmetric tensor decomposition and demonstrate its consistently good\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 12:34:09 GMT"}, {"version": "v2", "created": "Tue, 24 Jun 2014 09:25:34 GMT"}], "update_date": "2014-06-25", "authors_parsed": [["Ishteva", "Mariya", ""], ["Usevich", "Konstantin", ""], ["Markovsky", "Ivan", ""]]}, {"id": "1308.1941", "submitter": "Octavio Andres Gonzalez Estrada", "authors": "Octavio Andr\\'es Gonz\\'alez Estrada (IMAM), Juan Jos\\'e R\\'odenas\n  Garc\\'ia (DIMM), St\\'ephane Bordas, E. Nadal (CITV), Pierre Kerfriden, F.J.\n  Fuenmayor (CITV)", "title": "Locally equilibrated stress recovery for goal oriented error estimation\n  in the extended finite element method", "comments": "arXiv admin note: text overlap with arXiv:1209.3102", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal oriented error estimation and adaptive procedures are essential for the\naccurate and efficient evaluation of numerical simulations that involve complex\ndomains. By locally improving the approximation quality we can solve expensive\nproblems which could result intractable otherwise. Here, we present an error\nestimation technique for enriched finite element approximations that is based\non an equilibrated recovery technique, which considers the stress intensity\nfactor as the quantity of interest. The locally equilibrated superconvergent\npatch recovery is used to obtain enhanced stress fields for the primal and dual\nproblems defined to evaluate the error estimate.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 19:21:35 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2013 06:39:01 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Estrada", "Octavio Andr\u00e9s Gonz\u00e1lez", "", "IMAM"], ["Garc\u00eda", "Juan Jos\u00e9 R\u00f3denas", "", "DIMM"], ["Bordas", "St\u00e9phane", "", "CITV"], ["Nadal", "E.", "", "CITV"], ["Kerfriden", "Pierre", "", "CITV"], ["Fuenmayor", "F. J.", "", "CITV"]]}, {"id": "1308.2401", "submitter": "Tiancheng Li", "authors": "Tiancheng Li, Shudong Sun, Juan M. Corchado, Tariq P. Sattar and\n  Shubin Si", "title": "Numerical Fitting-based Likelihood Calculation to Speed up the Particle\n  Filter", "comments": "42 pages, 17 figures, 4 tables and 1 appendix. This paper is a\n  draft/preprint of one paper submitted to the IEEE Transactions", "journal-ref": "Int. J. Adapt. Control Signal Process. vol. 30, pp.1583-1602\n  (2016)", "doi": "10.1002/acs.2656", "report-no": null, "categories": "cs.IT cs.NA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The likelihood calculation of a vast number of particles is the computational\nbottleneck for the particle filter in applications where the observation\ninformation is rich. For fast computing the likelihood of particles, a\nnumerical fitting approach is proposed to construct the Likelihood Probability\nDensity Function (Li-PDF) by using a comparably small number of so-called\nfulcrums. The likelihood of particles is thereby analytically inferred,\nexplicitly or implicitly, based on the Li-PDF instead of directly computed by\nutilizing the observation, which can significantly reduce the computation and\nenables real time filtering. The proposed approach guarantees the estimation\nquality when an appropriate fitting function and properly distributed fulcrums\nare used. The details for construction of the fitting function and fulcrums are\naddressed respectively in detail. In particular, to deal with multivariate\nfitting, the nonparametric kernel density estimator is presented which is\nflexible and convenient for implicit Li-PDF implementation. Simulation\ncomparison with a variety of existing approaches on a benchmark 1-dimensional\nmodel and multi-dimensional robot localization and visual tracking demonstrate\nthe validity of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2013 15:12:56 GMT"}, {"version": "v2", "created": "Wed, 6 Aug 2014 22:40:06 GMT"}, {"version": "v3", "created": "Thu, 16 Oct 2014 17:37:17 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Li", "Tiancheng", ""], ["Sun", "Shudong", ""], ["Corchado", "Juan M.", ""], ["Sattar", "Tariq P.", ""], ["Si", "Shubin", ""]]}, {"id": "1308.2426", "submitter": "Tiancheng Li", "authors": "Tiancheng Li", "title": "Bias of the SIR filter in estimation of the state transition noise", "comments": "9 pages, 2 figures. Interesting experiment evidence of the bias of\n  SIR filter in estimation of the state transition noise", "journal-ref": "12th International Conference Distributed Computing and Artificial\n  Intelligence, pp 87-95 (2015)", "doi": null, "report-no": null, "categories": "cs.SY cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Note investigates the bias of the sampling importance resampling (SIR)\nfilter in estimation of the state transition noise in the state space model.\nThe SIR filter may suffer from sample impoverishment that is caused by the\nresampling and therefore will benefit from a sampling proposal that has a\nheavier tail, e.g. the state transition noise simulated for particle\npreparation is bigger than the true noise involved with the state dynamics.\nThis is because a comparably big transition noise used for particle propagation\ncan spread overlapped particles to counteract impoverishment, giving better\napproximation of the posterior. As such, the SIR filter tends to yield a biased\n(bigger-than-the-truth) estimate of the transition noise if it is unknown and\nneeds to be estimated, at least, in the forward-only filtering estimation. The\nbias is elaborated via the direct roughening approach by means of both\nqualitative logical deduction and quantitative numerical simulation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2013 20:15:49 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Li", "Tiancheng", ""]]}, {"id": "1308.2464", "submitter": "Uri Ascher", "authors": "Hui Huang and Uri Ascher", "title": "Faster gradient descent and the efficient recovery of images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent attention has been devoted to gradient descent algorithms where\nthe steepest descent step size is replaced by a similar one from a previous\niteration or gets updated only once every second step, thus forming a {\\em\nfaster gradient descent method}. For unconstrained convex quadratic\noptimization these methods can converge much faster than steepest descent. But\nthe context of interest here is application to certain ill-posed inverse\nproblems, where the steepest descent method is known to have a smoothing,\nregularizing effect, and where a strict optimization solution is not necessary.\n  Specifically, in this paper we examine the effect of replacing steepest\ndescent by a faster gradient descent algorithm in the practical context of\nimage deblurring and denoising tasks. We also propose several highly efficient\nschemes for carrying out these tasks independently of the step size selection,\nas well as a scheme for the case where both blur and significant noise are\npresent.\n  In the above context there are situations where many steepest descent steps\nare required, thus building slowness into the solution procedure. Our general\nconclusion regarding gradient descent methods is that in such cases the faster\ngradient descent methods offer substantial advantages. In other situations\nwhere no such slowness buildup arises the steepest descent method can still be\nvery effective.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 05:33:39 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Huang", "Hui", ""], ["Ascher", "Uri", ""]]}, {"id": "1308.2475", "submitter": "Farbod Roosta-Khorasani", "authors": "Farbod Roosta-Khorasani and Uri Ascher", "title": "Improved bounds on sample size for implicit matrix trace estimators", "comments": null, "journal-ref": null, "doi": "10.1007/s10208-014-9220-1", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is concerned with Monte-Carlo methods for the estimation of the\ntrace of an implicitly given matrix $A$ whose information is only available\nthrough matrix-vector products. Such a method approximates the trace by an\naverage of $N$ expressions of the form $\\ww^t (A\\ww)$, with random vectors\n$\\ww$ drawn from an appropriate distribution. We prove, discuss and experiment\nwith bounds on the number of realizations $N$ required in order to guarantee a\nprobabilistic bound on the relative error of the trace estimation upon\nemploying Rademacher (Hutchinson), Gaussian and uniform unit vector (with and\nwithout replacement) probability distributions.\n  In total, one necessary bound and six sufficient bounds are proved, improving\nupon and extending similar estimates obtained in the seminal work of Avron and\nToledo (2011) in several dimensions. We first improve their bound on $N$ for\nthe Hutchinson method, dropping a term that relates to $rank(A)$ and making the\nbound comparable with that for the Gaussian estimator.\n  We further prove new sufficient bounds for the Hutchinson, Gaussian and the\nunit vector estimators, as well as a necessary bound for the Gaussian\nestimator, which depend more specifically on properties of the matrix $A$. As\nsuch they may suggest for what type of matrices one distribution or another\nprovides a particularly effective or relatively ineffective stochastic\nestimation method.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 06:57:32 GMT"}, {"version": "v2", "created": "Wed, 30 Jul 2014 23:50:54 GMT"}], "update_date": "2014-08-20", "authors_parsed": [["Roosta-Khorasani", "Farbod", ""], ["Ascher", "Uri", ""]]}, {"id": "1308.3339", "submitter": "Rio Yokota Dr.", "authors": "Huda Ibeid, Rio Yokota, Jennifer Pestana, and David Keyes", "title": "Fast Multipole Preconditioners for Sparse Matrices Arising from Elliptic\n  Equations", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among optimal hierarchical algorithms for the computational solution of\nelliptic problems, the Fast Multipole Method (FMM) stands out for its\nadaptability to emerging architectures, having high arithmetic intensity,\ntunable accuracy, and relaxable global synchronization requirements. We\ndemonstrate that, beyond its traditional use as a solver in problems for which\nexplicit free-space kernel representations are available, the FMM has\napplicability as a preconditioner in finite domain elliptic boundary value\nproblems, by equipping it with boundary integral capability for satisfying\nconditions at finite boundaries and by wrapping it in a Krylov method for\nextensibility to more general operators. Here, we do not discuss the well\ndeveloped applications of FMM to implement matrix-vector multiplications within\nKrylov solvers of boundary element methods. Instead, we propose using FMM for\nthe volume-to-volume contribution of inhomogeneous Poisson-like problems, where\nthe boundary integral is a small part of the overall computation. Our method\nmay be used to precondition sparse matrices arising from finite\ndifference/element discretizations, and can handle a broader range of\nscientific applications. Compared with multigrid methods, it is capable of\ncomparable algebraic convergence rates down to the truncation error of the\ndiscretized PDE, and it offers potentially superior multicore and distributed\nmemory scalability properties on commodity architecture supercomputers.\nCompared with other methods exploiting the low rank character of off-diagonal\nblocks of the dense resolvent operator, FMM-preconditioned Krylov iteration may\nreduce the amount of communication because it is matrix-free and exploits the\ntree structure of FMM. We describe our tests in reproducible detail with freely\navailable codes and outline directions for further extensibility.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 08:53:25 GMT"}, {"version": "v2", "created": "Tue, 8 Apr 2014 20:20:09 GMT"}, {"version": "v3", "created": "Tue, 9 Sep 2014 05:26:14 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2016 09:14:05 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Ibeid", "Huda", ""], ["Yokota", "Rio", ""], ["Pestana", "Jennifer", ""], ["Keyes", "David", ""]]}, {"id": "1308.3558", "submitter": "Wenliang Zhong", "authors": "Leon Wenliang Zhong and James T. Kwok", "title": "Fast Stochastic Alternating Direction Method of Multipliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new stochastic alternating direction method of\nmultipliers (ADMM) algorithm, which incrementally approximates the full\ngradient in the linearized ADMM formulation. Besides having a low per-iteration\ncomplexity as existing stochastic ADMM algorithms, the proposed algorithm\nimproves the convergence rate on convex problems from $O(\\frac 1 {\\sqrt{T}})$\nto $O(\\frac 1 T)$, where $T$ is the number of iterations. This matches the\nconvergence rate of the batch ADMM algorithm, but without the need to visit all\nthe samples in each iteration. Experiments on the graph-guided fused lasso\ndemonstrate that the new algorithm is significantly faster than\nstate-of-the-art stochastic and batch ADMM algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2013 05:48:29 GMT"}], "update_date": "2013-08-19", "authors_parsed": [["Zhong", "Leon Wenliang", ""], ["Kwok", "James T.", ""]]}, {"id": "1308.3860", "submitter": "Harm Derksen", "authors": "Harm Derksen", "title": "On the Nuclear Norm and the Singular Value Decomposition of Tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the rank of a tensor is a problem that has many applications.\nUnfortunately it is often very difficult to determine the rank of a given\ntensor. Inspired by the heuristics of convex relaxation, we consider the\nnuclear norm instead of the rank of a tensor. We determine the nuclear norm of\nvarious tensors of interest. Along the way, we also do a systematic study\nvarious measures of orthogonality in tensor product spaces and we give a new\ngeneralization of the Singular Value Decomposition to higher order tensors.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2013 14:21:56 GMT"}, {"version": "v2", "created": "Mon, 21 Apr 2014 21:15:46 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["Derksen", "Harm", ""]]}, {"id": "1308.3995", "submitter": "Michael Woopen", "authors": "Michael Woopen (1), Aravind Balan (1), Georg May (1) and Jochen\n  Sch\\\"utz (2) ((1) AICES, RWTH Aachen, (2) IGPM, RWTH Aachen)", "title": "A Comparison of Hybridized and Standard DG Methods for Target-Based\n  hp-Adaptive Simulation of Compressible Flow", "comments": null, "journal-ref": "Comp.Fluids 98 (2014) 3-16", "doi": "10.1016/j.compfluid.2014.03.023", "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comparison between hybridized and non-hybridized discontinuous\nGalerkin methods in the context of target-based hp-adaptation for compressible\nflow problems. The aim is to provide a critical assessment of the computational\nefficiency of hybridized DG methods. Hybridization of finite element\ndiscretizations has the main advantage, that the resulting set of algebraic\nequations has globally coupled degrees of freedom only on the skeleton of the\ncomputational mesh. Consequently, solving for these degrees of freedom involves\nthe solution of a potentially much smaller system. This not only reduces\nstorage requirements, but also allows for a faster solution with iterative\nsolvers. Using a discrete-adjoint approach, sensitivities with respect to\noutput functionals are computed to drive the adaptation. From the error\ndistribution given by the adjoint-based error estimator, h- or p-refinement is\nchosen based on the smoothness of the solution which can be quantified by\nproperly-chosen smoothness indicators. Numerical results are shown for\nsubsonic, transonic, and supersonic flow around the NACA0012 airfoil.\nhp-adaptation proves to be superior to pure h-adaptation if discontinuous or\nsingular flow features are involved. In all cases, a higher polynomial degree\nturns out to be beneficial. We show that for polynomial degree of approximation\np=2 and higher, and for a broad range of test cases, HDG performs better than\nDG in terms of runtime and memory requirements.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 12:06:05 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2013 08:24:28 GMT"}, {"version": "v3", "created": "Sun, 22 Sep 2013 19:27:03 GMT"}, {"version": "v4", "created": "Thu, 9 Jan 2014 13:44:40 GMT"}, {"version": "v5", "created": "Wed, 4 Jun 2014 09:31:47 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Woopen", "Michael", "", "AICES, RWTH Aachen"], ["Balan", "Aravind", "", "AICES, RWTH Aachen"], ["May", "Georg", "", "AICES, RWTH Aachen"], ["Sch\u00fctz", "Jochen", "", "IGPM, RWTH Aachen"]]}, {"id": "1308.4088", "submitter": "Michael Sagraloff", "authors": "Michael Sagraloff and Kurt Mehlhorn", "title": "Computing Real Roots of Real Polynomials", "comments": "to appear in the Journal of Symbolic Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the roots of a univariate polynomial is a fundamental and\nlong-studied problem of computational algebra with applications in mathematics,\nengineering, computer science, and the natural sciences. For isolating as well\nas for approximating all complex roots, the best algorithm known is based on an\nalmost optimal method for approximate polynomial factorization, introduced by\nPan in 2002. Pan's factorization algorithm goes back to the splitting circle\nmethod from Schoenhage in 1982. The main drawbacks of Pan's method are that it\nis quite involved and that all roots have to be computed at the same time. For\nthe important special case, where only the real roots have to be computed, much\nsimpler methods are used in practice; however, they considerably lag behind\nPan's method with respect to complexity.\n  In this paper, we resolve this discrepancy by introducing a hybrid of the\nDescartes method and Newton iteration, denoted ANEWDSC, which is simpler than\nPan's method, but achieves a run-time comparable to it. Our algorithm computes\nisolating intervals for the real roots of any real square-free polynomial,\ngiven by an oracle that provides arbitrary good approximations of the\npolynomial's coefficients. ANEWDSC can also be used to only isolate the roots\nin a given interval and to refine the isolating intervals to an arbitrary small\nsize; it achieves near optimal complexity for the latter task.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 18:14:39 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2015 08:47:35 GMT"}], "update_date": "2015-03-12", "authors_parsed": [["Sagraloff", "Michael", ""], ["Mehlhorn", "Kurt", ""]]}, {"id": "1308.4275", "submitter": "Edoardo Di Napoli", "authors": "Edoardo Di Napoli (1), Eric Polizzi (2), Yousef Saad (3) ((1) J\\\"ulich\n  Supercomputing Centre, Forshungszentrum J\\\"ulich, (2) Dept. of Electrical and\n  Computer Engineering, University of Massachusetts, (3) Computer Science &\n  Engineering, University of Minnesota.)", "title": "Efficient estimation of eigenvalue counts in an interval", "comments": "24 pages and 8 figures. Submitted to Numerical Linear Algebra with\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the number of eigenvalues located in a given interval of a large\nsparse Hermitian matrix is an important problem in certain applications and it\nis a prerequisite of eigensolvers based on a divide-and-conquer paradigm. Often\nan exact count is not necessary and methods based on stochastic estimates can\nbe utilized to yield rough approximations. This paper examines a number of\ntechniques tailored to this specific task. It reviews standard approaches and\nexplores new ones based on polynomial and rational approximation filtering\ncombined with a stochastic procedure.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 10:16:16 GMT"}, {"version": "v2", "created": "Tue, 5 Aug 2014 15:52:52 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Di Napoli", "Edoardo", ""], ["Polizzi", "Eric", ""], ["Saad", "Yousef", ""]]}, {"id": "1308.4757", "submitter": "Ziqiang Shi", "authors": "Ziqiang Shi and Rujie Liu", "title": "Online and stochastic Douglas-Rachford splitting method for large scale\n  machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online and stochastic learning has emerged as powerful tool in large scale\noptimization. In this work, we generalize the Douglas-Rachford splitting (DRs)\nmethod for minimizing composite functions to online and stochastic settings (to\nour best knowledge this is the first time DRs been generalized to sequential\nversion). We first establish an $O(1/\\sqrt{T})$ regret bound for batch DRs\nmethod. Then we proved that the online DRs splitting method enjoy an $O(1)$\nregret bound and stochastic DRs splitting has a convergence rate of\n$O(1/\\sqrt{T})$. The proof is simple and intuitive, and the results and\ntechnique can be served as a initiate for the research on the large scale\nmachine learning employ the DRs method. Numerical experiments of the proposed\nmethod demonstrate the effectiveness of the online and stochastic update rule,\nand further confirm our regret and convergence analysis.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 03:40:41 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2013 06:21:25 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2013 06:50:16 GMT"}, {"version": "v4", "created": "Sat, 7 Sep 2013 04:30:41 GMT"}, {"version": "v5", "created": "Wed, 25 Sep 2013 08:20:54 GMT"}, {"version": "v6", "created": "Tue, 16 Aug 2016 07:05:38 GMT"}, {"version": "v7", "created": "Mon, 10 Oct 2016 08:46:25 GMT"}, {"version": "v8", "created": "Tue, 11 Oct 2016 00:52:10 GMT"}, {"version": "v9", "created": "Wed, 21 Dec 2016 07:05:13 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Shi", "Ziqiang", ""], ["Liu", "Rujie", ""]]}, {"id": "1308.5208", "submitter": "Dibakar Datta", "authors": "Dibakar Datta", "title": "Introduction to eXtended Finite Element (XFEM) Method", "comments": "20 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present study the software CrackComput, based on the Xfem and Xcrack\nlibraries has been used for three problems- to experiment on the convergence\nproperties of the method applied to elasto-statics crack problems, comparison\nof stress intensity factors to simplified analytical results and study of the\nBrazilian fracture test. All the problems are treated in two dimensions under\nplane strain assumption and the material is supposed elastic and isotropic. For\nthe first example, comparison for different parameter-enrichment type and\nradius, degree of polynomial has been performed. Second example convergence of\nSIF with the L/h ratio has been performed and compared with the analytical\nsolution. Third example is the study of snapback phenomenon.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 18:54:03 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Datta", "Dibakar", ""]]}, {"id": "1308.5215", "submitter": "Dibakar Datta", "authors": "Dibakar Datta, Jacobo Carrasco Heres", "title": "Numerical Solution of Advection-Diffusion Equation Using Preconditionar\n  as Incomplete LU Decomposition and the BiCGSTAB Aceleration Method", "comments": "70 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present study, an advection-diffusion problem has been considered for\nthe numerical solution. The continuum equation is discretized using both upwind\nand centered scheme. The linear system is solved using the ILU preconditioned\nBiCGSTAB method. Both Dirichlet and Neumann boundary condition has been\nconsidered. The obtained results have been compared for different cases.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 19:27:53 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Datta", "Dibakar", ""], ["Heres", "Jacobo Carrasco", ""]]}, {"id": "1308.5294", "submitter": "Mingyi Hong", "authors": "Xiangfeng Wang and Mingyi Hong and Shiqian Ma and Zhi-Quan Luo", "title": "Solving Multiple-Block Separable Convex Minimization Problems Using\n  Two-Block Alternating Direction Method of Multipliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider solving multiple-block separable convex\nminimization problems using alternating direction method of multipliers (ADMM).\nMotivated by the fact that the existing convergence theory for ADMM is mostly\nlimited to the two-block case, we analyze in this paper, both theoretically and\nnumerically, a new strategy that first transforms a multi-block problem into an\nequivalent two-block problem (either in the primal domain or in the dual\ndomain) and then solves it using the standard two-block ADMM. In particular, we\nderive convergence results for this two-block ADMM approach to solve\nmulti-block separable convex minimization problems, including an improved\nO(1/\\epsilon) iteration complexity result. Moreover, we compare the numerical\nefficiency of this approach with the standard multi-block ADMM on several\nseparable convex minimization problems which include basis pursuit, robust\nprincipal component analysis and latent variable Gaussian graphical model\nselection. The numerical results show that the multiple-block ADMM, although\nlacks theoretical convergence guarantees, typically outperforms two-block\nADMMs.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2013 04:20:28 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Wang", "Xiangfeng", ""], ["Hong", "Mingyi", ""], ["Ma", "Shiqian", ""], ["Luo", "Zhi-Quan", ""]]}, {"id": "1308.5625", "submitter": "Han Wang", "authors": "Habib Ammari, Minh Phuong Tran, Han Wang", "title": "Shape identification and classification in echolocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper aims at proposing the first shape identification and classification\nalgorithm in echolocation. The approach is based on first extracting geometric\nfeatures from the reflected waves and then matching them with precomputed ones\nassociated with a dictionary of targets. The construction of such\nfrequency-dependent shape descriptors is based on some important properties of\nthe scattering coefficients and new invariants. The stability and resolution of\nthe proposed identification algorithm with respect to measurement noise and the\nlimited-view aspect are analytically and numerically quantified.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 16:16:07 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Ammari", "Habib", ""], ["Tran", "Minh Phuong", ""], ["Wang", "Han", ""]]}, {"id": "1308.5626", "submitter": "Arash Ghasemi", "authors": "A. Ghasemi and L. K. Taylor", "title": "A Progressive Statistical Method for Preconditioning Matrix-Free\n  Solution of High-Order Discretization of Linear Time-Dependent Problems", "comments": null, "journal-ref": "Procedia Computer Science, Volume 80, Pages 2266-2270, 2016", "doi": "10.1016/j.procs.2016.05.406", "report-no": "UTC-CECS-SimCenter-2013-02", "categories": "math.ST cs.NA math.NA stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preconditioning of a linear system obtained from spectral discretization of\ntime-dependent PDEs often results in a full matrix which is expensive to\ncompute and store specially when the problem size increases. A matrix-free\nimplementation is usually applied to resolve this issue. In this framework,\npreconditioning is typically challenging since the entries of the matrix are\nnot explicitly available. In this short note, we propose a statistical approach\nto gradually create a preconditioner matrix by collecting the information\nobtained from matrix-vector product in the Arnoldi loop of an unpreconditioned\nKrylov subspace algorithm. The gathered information are then correlated using a\nmultiple regressors estimate where the error is assumed to be normally\ndistributed. This procedure yields a banded diagonal matrix which is then used\nas a preconditioner in the next iterative solve. This is repeated between\niterative solves until a good preconditioner is constructed on fly. This\nstatistically iterative procedure is progressive since the fidelity of the\npreconditioning matrix improves by adding more data obtained from matrix-vector\nproduct during the entire solution procedure. The proposed algorithm is\nvalidated for a sample implementation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 16:17:32 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Ghasemi", "A.", ""], ["Taylor", "L. K.", ""]]}, {"id": "1308.5697", "submitter": "Emmanuel Candes", "authors": "Rafi Witten and Emmanuel Candes", "title": "Randomized algorithms for low-rank matrix factorizations: sharp\n  performance bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of randomized algorithms for numerical linear algebra, e.g.\nfor computing approximate QR and SVD factorizations, has recently become an\nintense area of research. This paper studies one of the most frequently\ndiscussed algorithms in the literature for dimensionality\nreduction---specifically for approximating an input matrix with a low-rank\nelement. We introduce a novel and rather intuitive analysis of the algorithm in\nMartinsson et al. (2008), which allows us to derive sharp estimates and give\nnew insights about its performance. This analysis yields theoretical guarantees\nabout the approximation error and at the same time, ultimate limits of\nperformance (lower bounds) showing that our upper bounds are tight. Numerical\nexperiments complement our study and show the tightness of our predictions\ncompared with empirical observations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 21:00:35 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Witten", "Rafi", ""], ["Candes", "Emmanuel", ""]]}, {"id": "1308.5915", "submitter": "Parter Merav", "authors": "Chen Avin, Michael Borokhovich, Yoram Haddad, Erez Kantor, Zvi Lotker,\n  Merav Parter and David Peleg", "title": "Generalized Perron--Frobenius Theorem for Nonsquare Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Perron--Frobenius (PF) theorem is stated for irreducible\nnonnegative square matrices, and provides a simple characterization of their\neigenvectors and eigenvalues. The importance of this theorem stems from the\nfact that eigenvalue problems on such matrices arise in many fields of science\nand engineering, including dynamical systems theory, economics, statistics and\noptimization. However, many real-life scenarios give rise to nonsquare\nmatrices. A natural question is whether the PF Theorem (along with its\napplications) can be generalized to a nonsquare setting. Our paper provides a\ngeneralization of the PF Theorem to nonsquare matrices. The extension can be\ninterpreted as representing client-server systems with additional degrees of\nfreedom, where each client may choose between multiple servers that can\ncooperate in serving it (while potentially interfering with other clients).\nThis formulation is motivated by applications to power control in wireless\nnetworks, economics and others, all of which extend known examples for the use\nof the original PF Theorem.\n  We show that the option of cooperation between servers does not improve the\nsituation, in the sense that in the optimal solution no cooperation is needed,\nand only one server needs to serve each client. Hence, the additional power of\nhaving several potential servers per client translates into \\emph{choosing} the\nbest single server and not into \\emph{sharing} the load between the servers in\nsome way, as one might have expected.\n  The two main contributions of the paper are (i) a generalized PF Theorem that\ncharacterizes the optimal solution for a non-convex nonsquare problem, and (ii)\nan algorithm for finding the optimal solution in polynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 16:26:57 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Avin", "Chen", ""], ["Borokhovich", "Michael", ""], ["Haddad", "Yoram", ""], ["Kantor", "Erez", ""], ["Lotker", "Zvi", ""], ["Parter", "Merav", ""], ["Peleg", "David", ""]]}, {"id": "1308.5952", "submitter": "Sergey Dolgov", "authors": "S. V. Dolgov and A. P. Smirnov and E. E. Tyrtyshnikov", "title": "Low-rank approximation in the numerical modeling of the Farley-Buneman\n  instability in ionospheric plasma", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2014.01.029", "report-no": null, "categories": "cs.NA math.NA physics.comp-ph physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the numerical modeling of the Farley-Buneman instability\ndevelopment in the earth's ionosphere plasma. The ion behavior is governed by\nthe kinetic Landau equation in the four-dimensional phase space, and since the\nfinite difference discretization on a tensor product grid is used, this\nequation becomes the most computationally challenging part of the scheme. To\nrelax the complexity and memory consumption, an adaptive model reduction using\nthe low-rank separation of variables, namely the Tensor Train format, is\nemployed.\n  The approach was verified via the prototype MATLAB implementation. Numerical\nexperiments demonstrate the possibility of efficient separation of space and\nvelocity variables, resulting in the solution storage reduction by a factor of\norder tens.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 19:14:09 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Dolgov", "S. V.", ""], ["Smirnov", "A. P.", ""], ["Tyrtyshnikov", "E. E.", ""]]}, {"id": "1308.6320", "submitter": "Grady Lemoine", "authors": "Grady I. Lemoine", "title": "Three-Dimensional Mapped-Grid Finite Volume Modeling of\n  Poroelastic-Fluid Wave Propagation", "comments": "28 pages, 7 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the author's previous two-dimensional work with Ou and\nLeVeque to high-resolution finite volume modeling of systems of fluids and\nporoelastic media in three dimensions, using logically rectangular mapped\ngrids. A method is described for calculating consistent cell face areas and\nnormal vectors for a finite volume method on a general non-rectilinear\nhexahedral grid. A novel limiting algorithm is also developed to cope with\ndifficulties encountered in implementing high-resolution finite volume methods\nfor anisotropic media on non-rectilinear grids; the new limiting approach is\ncompatible with any limiter function, and typically reduces solution error even\nin situations where it is not necessary for correct functioning of the\nnumerical method. Dimensional splitting is used to reduce the computational\ncost of the solution. The code implementing the three-dimensional algorithms is\nverified against known plane wave solutions, with particular attention to the\nperformance of the new limiter algorithm in comparison to the classical one. An\nacoustic wave in brine striking an uneven bed of orthotropic layered sandstone\nis also simulated in order to demonstrate the capabilities of the simulation\ncode.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 21:43:16 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Lemoine", "Grady I.", ""]]}, {"id": "1308.6774", "submitter": "Peter Richtarik", "authors": "Rachael Tappenden and Peter Richtarik and Burak Buke", "title": "Separable Approximations and Decomposition Methods for the Augmented\n  Lagrangian", "comments": "28 pages, 6 algorithms, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study decomposition methods based on separable\napproximations for minimizing the augmented Lagrangian. In particular, we study\nand compare the Diagonal Quadratic Approximation Method (DQAM) of Mulvey and\nRuszczy\\'{n}ski and the Parallel Coordinate Descent Method (PCDM) of\nRicht\\'arik and Tak\\'a\\v{c}. We show that the two methods are equivalent for\nfeasibility problems up to the selection of a single step-size parameter.\nFurthermore, we prove an improved complexity bound for PCDM under strong\nconvexity, and show that this bound is at least $8(L'/\\bar{L})(\\omega-1)^2$\ntimes better than the best known bound for DQAM, where $\\omega$ is the degree\nof partial separability and $L'$ and $\\bar{L}$ are the maximum and average of\nthe block Lipschitz constants of the gradient of the quadratic penalty\nappearing in the augmented Lagrangian.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 15:39:32 GMT"}], "update_date": "2013-09-02", "authors_parsed": [["Tappenden", "Rachael", ""], ["Richtarik", "Peter", ""], ["Buke", "Burak", ""]]}]