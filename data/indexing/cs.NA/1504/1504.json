[{"id": "1504.00523", "submitter": "Haishan Ye", "authors": "Haishan Ye and Zhihua Zhang", "title": "Fast Spectral Low Rank Matrix Approximation", "comments": "This paper has some error in proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  First, we extend the results of approximate matrix multiplication from the\nFrobenius norm to the spectral norm. Second, We develop a class of fast\napproximate generalized linear regression algorithms with respect to the\nspectral norm. Finally, We give a fast approximate SVD.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 12:29:34 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2015 13:59:16 GMT"}, {"version": "v3", "created": "Sun, 3 May 2015 09:37:45 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2015 06:12:43 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Ye", "Haishan", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1504.00907", "submitter": "Essex Edwards", "authors": "Essex Edwards and Robert Bridson", "title": "The Discretely-Discontinuous Galerkin Coarse Grid for Domain\n  Decomposition", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algebraic method for constructing a highly effective coarse\ngrid correction to accelerate domain decomposition. The coarse problem is\nconstructed from the original matrix and a small set of input vectors that span\na low-degree polynomial space, but no further knowledge of meshes or continuous\nfunctionals is used. We construct a coarse basis by partitioning the problem\ninto subdomains and using the restriction of each input vector to each\nsubdomain as its own basis function. This basis resembles a Discontinuous\nGalerkin basis on subdomain-sized elements. Constructing the coarse problem by\nGalerkin projection, we prove a high-order convergent error bound for the\ncoarse solutions. Used in a two-level symmetric multiplicative overlapping\nSchwarz preconditioner, the resulting conjugate gradient solver shows optimal\nscaling. Convergence requires a constant number of iterations, independent of\nfine problem size, on a range of scalar and vector-valued second-order and\nfourth-order PDEs.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2015 18:27:01 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Edwards", "Essex", ""], ["Bridson", "Robert", ""]]}, {"id": "1504.01809", "submitter": "Lanchao Liu", "authors": "Lanchao Liu and Zhu Han", "title": "Multi-Block ADMM for Big Data Optimization in Modern Communication\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we review the parallel and distributed optimization algorithms\nbased on the alternating direction method of multipliers (ADMM) for solving\n\"big data\" optimization problems in modern communication networks. We first\nintroduce the canonical formulation of the large-scale optimization problem.\nNext, we describe the general form of ADMM and then focus on several direct\nextensions and sophisticated modifications of ADMM from $2$-block to $N$-block\nsettings to deal with the optimization problem. The iterative schemes and\nconvergence properties of each extension/modification are given, and the\nimplementation on large-scale computing facilities is also illustrated.\nFinally, we numerate several applications in communication networks, such as\nthe security constrained optimal power flow problem in smart grid networks and\nmobile data offloading problem in software defined networks (SDNs).\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 02:48:37 GMT"}], "update_date": "2015-04-09", "authors_parsed": [["Liu", "Lanchao", ""], ["Han", "Zhu", ""]]}, {"id": "1504.02214", "submitter": "Gerlind Plonka", "authors": "Gerlind Plonka and Katrin Wannenwetsch", "title": "A deterministic sparse FFT algorithm for vectors with small support", "comments": "16 pages", "journal-ref": "Numerical Algorithms, 71(4) (2016), 889-905", "doi": "10.1007/s11075-015-0028-0", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the special case where a discrete signal ${\\bf x}$\nof length N is known to vanish outside a support interval of length $m < N$. If\nthe support length $m$ of ${\\bf x}$ or a good bound of it is a-priori known we\nderive a sublinear deterministic algorithm to compute ${\\bf x}$ from its\ndiscrete Fourier transform. In case of exact Fourier measurements we require\nonly ${\\cal O}(m \\log m)$ arithmetical operations. For noisy measurements, we\npropose a stable ${\\cal O}(m \\log N)$ algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 07:50:42 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Plonka", "Gerlind", ""], ["Wannenwetsch", "Katrin", ""]]}, {"id": "1504.02366", "submitter": "Dhagash Mehta", "authors": "Dhagash Mehta, Crina Grosan", "title": "A Collection of Challenging Optimization Problems in Science,\n  Engineering and Economics", "comments": "Accepted as an invited contribution to the special session on\n  Evolutionary Computation for Nonlinear Equation Systems at the 2015 IEEE\n  Congress on Evolutionary Computation (at Sendai International Center, Sendai,\n  Japan, from 25th to 28th May, 2015.)", "journal-ref": null, "doi": "10.1109/CEC.2015.7257223", "report-no": "ADP-15-9/T911", "categories": "cs.NA cs.MS cs.NE math.AG math.NA math.OC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function optimization and finding simultaneous solutions of a system of\nnonlinear equations (SNE) are two closely related and important optimization\nproblems. However, unlike in the case of function optimization in which one is\nrequired to find the global minimum and sometimes local minima, a database of\nchallenging SNEs where one is required to find stationary points (extrama and\nsaddle points) is not readily available. In this article, we initiate building\nsuch a database of important SNE (which also includes related function\noptimization problems), arising from Science, Engineering and Economics. After\nproviding a short review of the most commonly used mathematical and\ncomputational approaches to find solutions of such systems, we provide a\npreliminary list of challenging problems by writing the Mathematical\nformulation down, briefly explaning the origin and importance of the problem\nand giving a short account on the currently known results, for each of the\nproblems. We anticipate that this database will not only help benchmarking\nnovel numerical methods for solving SNEs and function optimization problems but\nalso will help advancing the corresponding research areas.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 16:31:25 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Mehta", "Dhagash", ""], ["Grosan", "Crina", ""]]}, {"id": "1504.02914", "submitter": "Radford M. Neal", "authors": "Radford M. Neal", "title": "Representing numeric data in 32 bits while preserving 64-bit precision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data files often consist of numbers having only a few significant decimal\ndigits, whose information content would allow storage in only 32 bits. However,\nwe may require that arithmetic operations involving these numbers be done with\n64-bit floating-point precision, which precludes simply representing the data\nas 32-bit floating-point values. Decimal floating point gives a compact and\nexact representation, but requires conversion with a slow division operation\nbefore it can be used. Here, I show that interesting subsets of 64-bit\nfloating-point values can be compactly and exactly represented by the 32 bits\nconsisting of the sign, exponent, and high-order part of the mantissa, with the\nlower-order 32 bits of the mantissa filled in by table lookup, indexed by bits\nfrom the part of the mantissa retained, and possibly from the exponent. For\nexample, decimal data with 4 or fewer digits to the left of the decimal point\nand 2 or fewer digits to the right of the decimal point can be represented in\nthis way using the lower-order 5 bits of the retained part of the mantissa as\nthe index. Data consisting of 6 decimal digits with the decimal point in any of\nthe 7 positions before or after one of the digits can also be represented this\nway, and decoded using 19 bits from the mantissa and exponent as the index.\nEncoding with such a scheme is a simple copy of half the 64-bit value, followed\nif necessary by verification that the value can be represented, by checking\nthat it decodes correctly. Decoding requires only extraction of index bits and\na table lookup. Lookup in a small table will usually reference cache; even with\nlarger tables, decoding is still faster than conversion from decimal floating\npoint with a division operation. I discuss how such schemes perform on recent\ncomputer systems, and how they might be used to automatically compress large\narrays in interpretive languages such as R.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2015 20:33:06 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Neal", "Radford M.", ""]]}, {"id": "1504.03026", "submitter": "Leonard Schulman", "authors": "Leonard J. Schulman, Alistair Sinclair", "title": "Analysis of a Classical Matrix Preconditioning Algorithm", "comments": "The previous version (1) (see also STOC'15) handled UB (\"unique\n  balance\") input matrices. In this version (2) we extend the work to handle\n  all input matrices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a classical iterative algorithm for balancing matrices in the\n$L_\\infty$ norm via a scaling transformation. This algorithm, which goes back\nto Osborne and Parlett \\& Reinsch in the 1960s, is implemented as a standard\npreconditioner in many numerical linear algebra packages. Surprisingly, despite\nits widespread use over several decades, no bounds were known on its rate of\nconvergence. In this paper we prove that, for any irreducible $n\\times n$ (real\nor complex) input matrix~$A$, a natural variant of the algorithm converges in\n$O(n^3\\log(n\\rho/\\varepsilon))$ elementary balancing operations, where $\\rho$\nmeasures the initial imbalance of~$A$ and $\\varepsilon$ is the target imbalance\nof the output matrix. (The imbalance of~$A$ is $\\max_i\n|\\log(a_i^{\\text{out}}/a_i^{\\text{in}})|$, where\n$a_i^{\\text{out}},a_i^{\\text{in}}$ are the maximum entries in magnitude in the\n$i$th row and column respectively.) This bound is tight up to the $\\log n$\nfactor. A balancing operation scales the $i$th row and column so that their\nmaximum entries are equal, and requires $O(m/n)$ arithmetic operations on\naverage, where $m$ is the number of non-zero elements in~$A$. Thus the running\ntime of the iterative algorithm is $\\tilde{O}(n^2m)$. This is the first time\nbound of any kind on any variant of the Osborne-Parlett-Reinsch algorithm. We\nalso prove a conjecture of Chen that characterizes those matrices for which the\nlimit of the balancing process is independent of the order in which balancing\noperations are performed.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2015 21:30:05 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2015 07:02:20 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Schulman", "Leonard J.", ""], ["Sinclair", "Alistair", ""]]}, {"id": "1504.03244", "submitter": "Paulo Laerte Natti", "authors": "Camila Foga\\c{c}a de Oliveira, Paulo Laerte Natti, Eliandro Rodrigues\n  Cirilo, Neyva Maria Lopes Romeiro and \\'Erica Regina Takano Natti", "title": "Numerical stability of solitons waves through splices in optical fibers", "comments": "20 pages, 8 figures", "journal-ref": "Acta Scientiarum Technology, 42(1), e46881, 2020", "doi": "10.4025/actascitechnol.v42i1.46881", "report-no": null, "categories": "physics.optics cs.NA math.NA nlin.PS nlin.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The propagation of soliton waves is simulated through splices in optical\nfibers, in which fluctuations of dielectric parameters occur. The mathematical\nmodeling of these local fluctuations of dielectric properties of fibers was\nperformed by Gaussian functions. By simulating soliton wave propagation in\noptical fibers with Gaussian fluctuations in their dielectric properties, it\nwas observed that the perturbed soliton numerical solution presented higher\nsensitivity to fluctuations in the dielectric parameter $\\beta$, a measure of\nthe intensity of nonlinearity in the fiber. In order to verify whether the\nfluctuations of $\\beta$ parameter in the splices of the optical fiber generate\nunstable solitons, the propagation of a soliton wave, subject to this\nperturbation, was simulated for large time intervals. Considering various\ngeometric configurations and intensities of the fluctuations of parameter\n$\\beta$, it was found that the perturbed soliton wave stabilizes, i.e., the\namplitude of the wave oscillations decreases for increasing values of\npropagation distance. It is concluded that the propagation of perturbed soliton\nwave presents numerical stability when subjected to local Gaussian fluctuations\n(perturbations) of the dielectric parameters of the optical fiber.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2015 14:47:04 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 15:07:56 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["de Oliveira", "Camila Foga\u00e7a", ""], ["Natti", "Paulo Laerte", ""], ["Cirilo", "Eliandro Rodrigues", ""], ["Romeiro", "Neyva Maria Lopes", ""], ["Natti", "\u00c9rica Regina Takano", ""]]}, {"id": "1504.03749", "submitter": "Kevin Carlberg", "authors": "Kevin Carlberg, Matthew Barone, Harbir Antil", "title": "Galerkin v. least-squares Petrov--Galerkin projection in nonlinear model\n  reduction", "comments": "Submitted to Journal of Computational Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least-squares Petrov--Galerkin (LSPG) model-reduction techniques such as the\nGauss--Newton with Approximated Tensors (GNAT) method have shown promise, as\nthey have generated stable, accurate solutions for large-scale turbulent,\ncompressible flow problems where standard Galerkin techniques have failed.\nHowever, there has been limited comparative analysis of the two approaches.\nThis is due in part to difficulties arising from the fact that Galerkin\ntechniques perform optimal projection associated with residual minimization at\nthe time-continuous level, while LSPG techniques do so at the time-discrete\nlevel. This work provides a detailed theoretical and computational comparison\nof the two techniques for two common classes of time integrators: linear\nmultistep schemes and Runge--Kutta schemes. We present a number of new\nfindings, including conditions under which the LSPG ROM has a time-continuous\nrepresentation, conditions under which the two techniques are equivalent, and\ntime-discrete error bounds for the two approaches. Perhaps most surprisingly,\nwe demonstrate both theoretically and computationally that decreasing the time\nstep does not necessarily decrease the error for the LSPG ROM; instead, the\ntime step should be `matched' to the spectral content of the reduced basis. In\nnumerical experiments carried out on a turbulent compressible-flow problem with\nover one million unknowns, we show that increasing the time step to an\nintermediate value decreases both the error and the simulation time of the LSPG\nreduced-order model by an order of magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2015 00:19:15 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2015 23:58:15 GMT"}, {"version": "v3", "created": "Tue, 16 Aug 2016 23:34:39 GMT"}], "update_date": "2016-08-18", "authors_parsed": [["Carlberg", "Kevin", ""], ["Barone", "Matthew", ""], ["Antil", "Harbir", ""]]}, {"id": "1504.04179", "submitter": "Petr Vabishchevich N.", "authors": "P.N. Vabishchevich", "title": "Factorized schemes of second-order accuracy for numerical solving\n  unsteady problems", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schemes with the second-order approximation in time are considered for\nnumerical solving the Cauchy problem for an evolutionary equation of first\norder with a self-adjoint operator. The implicit two-level scheme based on the\nPad\\'{e} polynomial approximation is unconditionally stable. It demonstrates\ngood asymptotic properties in time and provides an adequate evolution in time\nfor individual harmonics of the solution (has spectral mimetic stability). In\nfact, the only drawback of this scheme is the necessity to solve an equation\nwith an operator polynomial of second degree at each time level. We consider\nmodifications of these schemes, which are based on solving equations with\noperator polynomials of first degree. Such computational implementations occur,\nfor example, if we apply the fully implicit two-level scheme (the backward\nEuler scheme). A three-level modification of the SM-stable scheme is proposed.\nIts unconditional stability is established in the corresponding norms. The\nemphasis is on the scheme, where the numerical algorithm involves two stages,\nnamely, the backward Euler scheme of first order at the first (prediction)\nstage and the following correction of the approximate solution using a\nfactorized operator. The SM-stability is established for the proposed scheme.\nTo illustrate the theoretical results of the work, a model problem is solved\nnumerically.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 10:45:27 GMT"}], "update_date": "2015-04-17", "authors_parsed": [["Vabishchevich", "P. N.", ""]]}, {"id": "1504.04913", "submitter": "Abdul Lugo", "authors": "Abdul Lugo and Giovanni Calder\\'on", "title": "Un An\\'alisis Comparativo de los M\\'etodos Mim\\'eticos, Diferencias\n  Finitas y Elementos Finitos para problemas Estacionarios", "comments": "in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical methods: mimetic finite differences and finite elements, are\nanalyzed from a numerical point of view. It seeks to conclude on the\nefficiency, order of convergence and computational cost of these methods. The\nanalysis is done in boundary value problems one-dimensional\n(convection-diffusion equation at steady) with different variations in the\ngradient, diffusion coefficient and convective velocity.\n  Key Words: Mimetics methods, Finite Element methods, Finite differences\nmethods, Conservative methods, Convergence.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 01:49:57 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Lugo", "Abdul", ""], ["Calder\u00f3n", "Giovanni", ""]]}, {"id": "1504.05262", "submitter": "Renato J Cintra", "authors": "M. M. S. Lira, H. M. de Oliveira, R. J. Cintra, R. M. Campello de\n  Souza", "title": "Wavelets for Elliptical Waveguide Problems", "comments": "5 pages, 4 figures. in: 2002 WSEAS International Conference on\n  Wavelet Analysis and Multirate Systems, Vouliagmeni, Greece. arXiv admin\n  note: substantial text overlap with arXiv:1501.07255", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New elliptic cylindrical wavelets are introduced, which exploit the\nrelationship between analysing filters and Floquet's solution of Mathieu\ndifferential equations. It is shown that the transfer function of both\nmultiresolution filters is related to the solution of a Mathieu equation of odd\ncharacteristic exponent. The number of notches of these analysing filters can\nbe easily designed. Wavelets derived by this method have potential application\nin the fields of optics, microwaves and electromagnetism.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 23:48:18 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2015 11:13:14 GMT"}], "update_date": "2015-04-24", "authors_parsed": [["Lira", "M. M. S.", ""], ["de Oliveira", "H. M.", ""], ["Cintra", "R. J.", ""], ["de Souza", "R. M. Campello", ""]]}, {"id": "1504.05400", "submitter": "Pascal Bianchi", "authors": "Pascal Bianchi", "title": "Ergodic convergence of a stochastic proximal point algorithm", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to establish the almost sure weak ergodic\nconvergence of a sequence of iterates $(x_n)$ given by $x_{n+1} = (I+\\lambda_n\nA(\\xi_{n+1},\\,.\\,))^{-1}(x_n)$ where $(A(s,\\,.\\,):s\\in E)$ is a collection of\nmaximal monotone operators on a separable Hilbert space, $(\\xi_n)$ is an\nindependent identically distributed sequence of random variables on $E$ and\n$(\\lambda_n)$ is a positive sequence in $\\ell^2\\backslash \\ell^1$. The weighted\naveraged sequence of iterates is shown to converge weakly to a zero (assumed to\nexist) of the Aumann expectation ${\\mathbb E}(A(\\xi_1,\\,.\\,))$ under the\nassumption that the latter is maximal. We consider applications to stochastic\noptimization problems of the form $\\min {\\mathbb E}(f(\\xi_1,x))$ w.r.t. $x\\in\n\\bigcap_{i=1}^m X_i$ where $f$ is a normal convex integrand and $(X_i)$ is a\ncollection of closed convex sets. In this case, the iterations are closely\nrelated to a stochastic proximal algorithm recently proposed by Wang and\nBertsekas.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 12:19:57 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2016 19:15:52 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Bianchi", "Pascal", ""]]}, {"id": "1504.05477", "submitter": "Christopher Musco", "authors": "Cameron Musco and Christopher Musco", "title": "Randomized Block Krylov Methods for Stronger and Faster Approximate\n  Singular Value Decomposition", "comments": "Neural Information Processing Systems 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since being analyzed by Rokhlin, Szlam, and Tygert and popularized by Halko,\nMartinsson, and Tropp, randomized Simultaneous Power Iteration has become the\nmethod of choice for approximate singular value decomposition. It is more\naccurate than simpler sketching algorithms, yet still converges quickly for any\nmatrix, independently of singular value gaps. After $\\tilde{O}(1/\\epsilon)$\niterations, it gives a low-rank approximation within $(1+\\epsilon)$ of optimal\nfor spectral norm error.\n  We give the first provable runtime improvement on Simultaneous Iteration: a\nsimple randomized block Krylov method, closely related to the classic Block\nLanczos algorithm, gives the same guarantees in just\n$\\tilde{O}(1/\\sqrt{\\epsilon})$ iterations and performs substantially better\nexperimentally. Despite their long history, our analysis is the first of a\nKrylov subspace method that does not depend on singular value gaps, which are\nunreliable in practice.\n  Furthermore, while it is a simple accuracy benchmark, even $(1+\\epsilon)$\nerror for spectral norm low-rank approximation does not imply that an algorithm\nreturns high quality principal components, a major issue for data applications.\nWe address this problem for the first time by showing that both Block Krylov\nIteration and a minor modification of Simultaneous Iteration give nearly\noptimal PCA for any matrix. This result further justifies their strength over\nnon-iterative sketching methods.\n  Finally, we give insight beyond the worst case, justifying why both\nalgorithms can run much faster in practice than predicted. We clarify how\nsimple techniques can take advantage of common matrix properties to\nsignificantly improve runtime.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 15:48:44 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2015 23:43:50 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2015 03:55:11 GMT"}, {"version": "v4", "created": "Fri, 30 Oct 2015 19:35:08 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Musco", "Cameron", ""], ["Musco", "Christopher", ""]]}, {"id": "1504.05705", "submitter": "Yves Achdou", "authors": "Yves Achdou (LJLL), Alessio Porretta (DIPMAT)", "title": "Convergence of a finite difference scheme to weak solutions of the\n  system of partial differential equation arising in mean field games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean field type models describing the limiting behavior of stochastic\ndifferential games as the number of players tends to +$\\infty$, have been\nrecently introduced by J-M. Lasry and P-L. Lions. Under suitable assumptions,\nthey lead to a system of two coupled partial differential equations, a forward\nBellman equation and a backward Fokker-Planck equations. Finite difference\nschemes for the approximation of such systems have been proposed in previous\nworks. Here, we prove the convergence of these schemes towards a weak solution\nof the system of partial differential equations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 09:36:54 GMT"}], "update_date": "2015-04-23", "authors_parsed": [["Achdou", "Yves", "", "LJLL"], ["Porretta", "Alessio", "", "DIPMAT"]]}, {"id": "1504.05854", "submitter": "Jordan Frecon", "authors": "Jordan Frecon, Nelly Pustelnik, Patrice Abry and Laurent Condat", "title": "On-the-fly Approximation of Multivariate Total Variation Minimization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2516962", "report-no": null, "categories": "cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of change-point detection, addressed by Total Variation\nminimization strategies, an efficient on-the-fly algorithm has been designed\nleading to exact solutions for univariate data. In this contribution, an\nextension of such an on-the-fly strategy to multivariate data is investigated.\nThe proposed algorithm relies on the local validation of the Karush-Kuhn-Tucker\nconditions on the dual problem. Showing that the non-local nature of the\nmultivariate setting precludes to obtain an exact on-the-fly solution, we\ndevise an on-the-fly algorithm delivering an approximate solution, whose\nquality is controlled by a practitioner-tunable parameter, acting as a\ntrade-off between quality and computational cost. Performance assessment shows\nthat high quality solutions are obtained on-the-fly while benefiting of\ncomputational costs several orders of magnitude lower than standard iterative\nprocedures. The proposed algorithm thus provides practitioners with an\nefficient multivariate change-point detection on-the-fly procedure.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 16:01:55 GMT"}, {"version": "v2", "created": "Sun, 28 Aug 2016 17:48:03 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Frecon", "Jordan", ""], ["Pustelnik", "Nelly", ""], ["Abry", "Patrice", ""], ["Condat", "Laurent", ""]]}, {"id": "1504.06106", "submitter": "Renato J Cintra", "authors": "R. J. Cintra and H. M. de Oliveira", "title": "A Short Survey on Arithmetic Transforms and the Arithmetic Hartley\n  Transform", "comments": "12 pages, 5 figures", "journal-ref": "Revista da Sociedade Brasileira de Telecomunica\\c{c}\\~{o}es\n  (Journal of Communication and Information Systems), v. 19, pp. 68--79, 2004", "doi": "10.14209/jcis.2004.2", "report-no": null, "categories": "math.CA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arithmetic complexity has a main role in the performance of algorithms for\nspectrum evaluation. Arithmetic transform theory offers a method for computing\ntrigonometrical transforms with minimal number of multiplications. In this\npaper, the proposed algorithms for the arithmetic Fourier transform are\nsurveyed. A new arithmetic transform for computing the discrete Hartley\ntransform is introduced: the Arithmetic Hartley transform. The interpolation\nprocess is shown to be the key element of the arithmetic transform theory.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2015 09:37:28 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Cintra", "R. J.", ""], ["de Oliveira", "H. M.", ""]]}, {"id": "1504.06443", "submitter": "Takeo Hoshi", "authors": "Hiroto Imachi, Takeo Hoshi", "title": "Hybrid Numerical Solvers for Massively Parallel Eigenvalue Computation\n  and Their Benchmark with Electronic Structure Calculations", "comments": "9 pages, 8 figures", "journal-ref": "J. Info. Process.24, pp.164-172 (2016)", "doi": "10.2197/ipsjjip.24.164", "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimally hybrid numerical solvers were constructed for massively parallel\ngeneralized eigenvalue problem (GEP).The strong scaling benchmark was carried\nout on the K computer and other supercomputers for electronic structure\ncalculation problems in the matrix sizes of M = 10^4-10^6 with upto 105 cores.\nThe procedure of GEP is decomposed into the two subprocedures of the reducer to\nthe standard eigenvalue problem (SEP) and the solver of SEP. A hybrid solver is\nconstructed, when a routine is chosen for each subprocedure from the three\nparallel solver libraries of ScaLAPACK, ELPA and EigenExa. The hybrid solvers\nwith the two newer libraries, ELPA and EigenExa, give better benchmark results\nthan the conventional ScaLAPACK library. The detailed analysis on the results\nimplies that the reducer can be a bottleneck in next-generation (exa-scale)\nsupercomputers, which indicates the guidance for future research. The code was\ndeveloped as a middleware and a mini-application and will appear online.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2015 09:39:09 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Imachi", "Hiroto", ""], ["Hoshi", "Takeo", ""]]}, {"id": "1504.06622", "submitter": "Dhagash Mehta", "authors": "Tianran Chen, Dhagash Mehta", "title": "An index-resolved fixed-point homotopy and potential energy landscapes", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "ADP-15-15/T917", "categories": "cond-mat.soft cond-mat.mtrl-sci cs.NA math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stationary points (SPs) of the potential energy landscapes can be classified\nby their Morse index, i.e., the number of negative eigenvalues of the Hessian\nevaluated at the SPs. In understanding chemical clusters through their\npotential energy landscapes, only SPs of a particular Morse index are needed.\nWe propose a modification of the \"fixed-point homotopy\" method which can be\nused to directly target stationary points of a specified Morse index. We\ndemonstrate the effectiveness of our approach by applying it to the\nLennard-Jones clusters.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2015 20:00:36 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Chen", "Tianran", ""], ["Mehta", "Dhagash", ""]]}, {"id": "1504.07791", "submitter": "Yangyang Kang", "authors": "Yangyang Kang, Zhihua Zhang, Wu-Jun Li", "title": "On the Global Convergence of Majorization Minimization Algorithms for\n  Nonconvex Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper, we study the global convergence of majorization minimization\n(MM) algorithms for solving nonconvex regularized optimization problems. MM\nalgorithms have received great attention in machine learning. However, when\napplied to nonconvex optimization problems, the convergence of MM algorithms is\na challenging issue. We introduce theory of the Kurdyka- Lojasiewicz inequality\nto address this issue. In particular, we show that many nonconvex problems\nenjoy the Kurdyka- Lojasiewicz property and establish the global convergence\nresult of the corresponding MM procedure. We also extend our result to a well\nknown method that called CCCP (concave-convex procedure).\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 10:06:57 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2015 08:07:34 GMT"}], "update_date": "2015-05-01", "authors_parsed": [["Kang", "Yangyang", ""], ["Zhang", "Zhihua", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1504.08035", "submitter": "Elmar Peise", "authors": "Elmar Peise (1), Paolo Bientinesi (1) ((1) AICES, RWTH Aachen)", "title": "The ELAPS Framework: Experimental Linear Algebra Performance Studies", "comments": "Submitted to SC15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal use of computing resources requires extensive coding, tuning and\nbenchmarking. To boost developer productivity in these time consuming tasks, we\nintroduce the Experimental Linear Algebra Performance Studies framework\n(ELAPS), a multi-platform open source environment for fast yet powerful\nperformance experimentation with dense linear algebra kernels, algorithms, and\nlibraries. ELAPS allows users to construct experiments to investigate how\nperformance and efficiency vary depending on factors such as caching,\nalgorithmic parameters, problem size, and parallelism. Experiments are designed\neither through Python scripts or a specialized GUI, and run on the whole\nspectrum of architectures, ranging from laptops to clusters, accelerators, and\nsupercomputers. The resulting experiment reports provide various metrics and\nstatistics that can be analyzed both numerically and visually. We demonstrate\nthe use of ELAPS in four concrete application scenarios and in as many\ncomputing environments, illustrating its practical value in supporting critical\nperformance decisions.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 21:58:50 GMT"}], "update_date": "2015-05-01", "authors_parsed": [["Peise", "Elmar", "", "AICES, RWTH Aachen"], ["Bientinesi", "Paolo", "", "AICES, RWTH Aachen"]]}]