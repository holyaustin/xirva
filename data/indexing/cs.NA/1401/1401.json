[{"id": "1401.0159", "submitter": "Michael Zibulevsky", "authors": "Michael Zibulevsky", "title": "Speeding-Up Convergence via Sequential Subspace Optimization: Current\n  State and Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an overview paper written in style of research proposal. In recent\nyears we introduced a general framework for large-scale unconstrained\noptimization -- Sequential Subspace Optimization (SESOP) and demonstrated its\nusefulness for sparsity-based signal/image denoising, deconvolution,\ncompressive sensing, computed tomography, diffraction imaging, support vector\nmachines. We explored its combination with Parallel Coordinate Descent and\nSeparable Surrogate Function methods, obtaining state of the art results in\nabove-mentioned areas. There are several methods, that are faster than plain\nSESOP under specific conditions: Trust region Newton method - for problems with\neasily invertible Hessian matrix; Truncated Newton method - when fast\nmultiplication by Hessian is available; Stochastic optimization methods - for\nproblems with large stochastic-type data; Multigrid methods - for problems with\nnested multilevel structure. Each of these methods can be further improved by\nmerge with SESOP. One can also accelerate Augmented Lagrangian method for\nconstrained optimization problems and Alternating Direction Method of\nMultipliers for problems with separable objective function and non-separable\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 15:25:50 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Zibulevsky", "Michael", ""]]}, {"id": "1401.0190", "submitter": "Jerome Jaffre", "authors": "Adi Adimurthi (TIFR-CAM), G. D. Veerappa Gowda (TIFR-CAM), J\\'er\\^ome\n  Jaffr\\'e (Inria Paris-Rocquencourt)", "title": "The DFLU flux for systems of conservation laws", "comments": "This paper is published in the Journal of Computational and Applied\n  Mathematics 247 (2013) 102-123. arXiv admin note: substantial text overlap\n  with arXiv:0908.0320", "journal-ref": "N&deg; RR-8442 (2013)", "doi": null, "report-no": "RR-8442", "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DFLU numerical flux was introduced in order to solve hyperbolic scalar\nconservation laws with a flux function discontinuous in space. We show how this\nflux can be used to solve certain class of systems of conservation laws such as\nsystems modeling polymer flooding in oil reservoir engineering. Furthermore,\nthese results are extended to the case where the flux function is discontinuous\nin the space variable. Such a situation arises for example while dealing with\noil reservoirs which are heterogeneous. Numerical experiments are presented to\nillustrate the efficiency of this new scheme compared to other standard schemes\nlike upstream mobility, Lax-Friedrichs and Force schemes.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 17:09:32 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Adimurthi", "Adi", "", "TIFR-CAM"], ["Gowda", "G. D. Veerappa", "", "TIFR-CAM"], ["Jaffr\u00e9", "J\u00e9r\u00f4me", "", "Inria Paris-Rocquencourt"]]}, {"id": "1401.0193", "submitter": "Jean Roberts", "authors": "Peter Knabner, Jean Roberts (Inria Paris-Rocquencourt)", "title": "Mathematical analysis of a discrete fracture model coupling Darcy flow\n  in the matrix with Darcy-Forchheimer flow in the fracture", "comments": null, "journal-ref": "ESAIM: M2AN 48 (2014) 1451-1472", "doi": "10.1051/m2an/2014003", "report-no": "RR-8443", "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model for flow in a porous medium with a fracture in which the\nflow in the fracture is governed by the Darcy-Forchheimer law while that in the\nsurrounding matrix is governed by Darcy's law. We give an appropriate mixed,\nvariational formulation and show existence and uniqueness of the solution. To\nshow existence we give an analogous formulation for the model in which the\nDarcy-Forchheimer law is the governing equation throughout the domain. We show\nexistence and uniqueness of the solution and show that the solution for the\nmodel with Darcy's law in the matrix is the weak limit of solutions of the\nmodel with the Darcy-Forchheimer law in the entire domain when the Forchheimer\ncoefficient in the matrix tends toward zero.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 17:13:44 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Knabner", "Peter", "", "Inria Paris-Rocquencourt"], ["Roberts", "Jean", "", "Inria Paris-Rocquencourt"]]}, {"id": "1401.0248", "submitter": "Evgeny Latkin", "authors": "Evgeny Latkin", "title": "Twofold fast summation", "comments": "All used tests and testing results available at author's Web site:\n  https://sites.google.com/site/yevgenylatkin/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debugging accumulation of floating-point errors is hard; ideally, computer\nshould track it automatically. Here we consider twofold approximation of an\nexact real with value + error pair of floating-point numbers. Normally, value +\nerror sum is more accurate than value alone, so error can estimate deviation\nbetween value and its exact target. Fast summation algorithm, that provides\ntwofold sum of x[1]+...+x[N] or dot product x[1]*y[1]+...+x[N]*y[N], can be\nsame fast as direct summation sometimes if leveraging processor underused\npotential. This way, we can hit three goals: improve precision, track\ninaccuracy, and do this with little if any loss in performance.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2014 04:25:16 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2014 03:35:24 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Latkin", "Evgeny", ""]]}, {"id": "1401.0798", "submitter": "Petr Vabishchevich N.", "authors": "Petr Vabishchevich and Petr Zakharov", "title": "Domain decomposition methods with overlapping subdomains for\n  time-dependent problems", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain decomposition (DD) methods for solving time-dependent problems can be\nclassified by (i) the method of domain decomposition used, (ii) the choice of\ndecomposition operators (exchange of boundary conditions), and (iii) the\nsplitting scheme employed. To construct homogeneous numerical algorithms,\noverlapping subdomain methods are preferable. Domain decomposition is\nassociated with the corresponding additive representation of the problem\noperator. To solve time-dependent problems with the DD splitting, different\noperator-splitting schemes are used. Various variants of decomposition\noperators differ by distinct types of data exchanges on interfaces. They ensure\nthe convergence of the approximate solution in various spaces of grid\nfunctions.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2014 11:06:43 GMT"}, {"version": "v2", "created": "Thu, 10 Jul 2014 06:35:25 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Vabishchevich", "Petr", ""], ["Zakharov", "Petr", ""]]}, {"id": "1401.1154", "submitter": "Franco Ferrari", "authors": "Franco Ferrari and Yani Zhao", "title": "Monte Carlo Computation of the Vassiliev knot invariant of degree 2 in\n  the integral representation", "comments": "35 pages, 13 figures, LaTeX + RevTeX 4.1, a mistake in the name of\n  one of the authors has been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mathematics there is a wide class of knot invariants that may be expressed\nin the form of multiple line integrals computed along the trajectory C\ndescribing the spatial conformation of the knot. In this work it is addressed\nthe problem of evaluating invariants of this kind in the case in which the knot\nis discrete, i.e. its trajectory is constructed by joining together a set of\nsegments of constant length. Such discrete knots appear almost everywhere in\nnumerical simulations of systems containing one dimensional ring-shaped\nobjects. Examples are polymers, the vortex lines in fluids and superfluids like\nhelium and other quantum liquids. Formally, the trajectory of a discrete knot\nis a piecewise smooth curve characterized by sharp corners at the joints\nbetween contiguous segments. The presence of these corners spoils the\ntopological invariance of the knot invariants considered here and prevents the\ncorrect evaluation of their values. To solve this problem, a smoothing\nprocedure is presented, which eliminates the sharp corners and transforms the\noriginal path C into a curve that is everywhere differentiable. The procedure\nis quite general and can be applied to any discrete knot defined off or on\nlattice. This smoothing algorithm is applied to the computation of the\nVassiliev knot invariant of degree 2 denoted here with the symbol r(C). This is\nthe simplest knot invariant that admits a definition in terms of multiple line\nintegrals. For a fast derivation of r(C), it is used a Monte Carlo integration\ntechnique. It is shown that, after the smoothing, the values of r(C) may be\nevaluated with an arbitrary precision. Several algorithms for the fast\ncomputation of the Vassiliev knot invariant of degree 2 are provided.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 17:45:17 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2014 10:00:21 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Ferrari", "Franco", ""], ["Zhao", "Yani", ""]]}, {"id": "1401.1752", "submitter": "Noreen Jamil", "authors": "Noreen Jamil, Johannes M\\\"uller, Christof Lutteroth and Gerald Weber", "title": "Speeding up SOR Solvers for Constraint-based GUIs with a Warm-Start\n  Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer programs have graphical user interfaces (GUIs), which need good\nlayout to make efficient use of the available screen real estate. Most GUIs do\nnot have a fixed layout, but are resizable and able to adapt themselves.\nConstraints are a powerful tool for specifying adaptable GUI layouts: they are\nused to specify a layout in a general form, and a constraint solver is used to\nfind a satisfying concrete layout, e.g.\\ for a specific GUI size. The\nconstraint solver has to calculate a new layout every time a GUI is resized or\nchanged, so it needs to be efficient to ensure a good user experience. One\napproach for constraint solvers is based on the Gauss-Seidel algorithm and\nsuccessive over-relaxation (SOR).\n  Our observation is that a solution after resizing or changing is similar in\nstructure to a previous solution. Thus, our hypothesis is that we can increase\nthe computational performance of an SOR-based constraint solver if we reuse the\nsolution of a previous layout to warm-start the solving of a new layout. In\nthis paper we report on experiments to test this hypothesis experimentally for\nthree common use cases: big-step resizing, small-step resizing and constraint\nchange. In our experiments, we measured the solving time for randomly generated\nGUI layout specifications of various sizes. For all three cases we found that\nthe performance is improved if an existing solution is used as a starting\nsolution for a new layout.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 10:29:32 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Jamil", "Noreen", ""], ["M\u00fcller", "Johannes", ""], ["Lutteroth", "Christof", ""], ["Weber", "Gerald", ""]]}, {"id": "1401.1842", "submitter": "Shuchin Aeron", "authors": "Jason Gejie Liu and Shuchin Aeron", "title": "Robust Large Scale Non-negative Matrix Factorization using Proximal\n  Point Algorithm", "comments": "Appeared in IEEE GlobalSIP, 2013, TX, Austin", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.NA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust algorithm for non-negative matrix factorization (NMF) is presented\nin this paper with the purpose of dealing with large-scale data, where the\nseparability assumption is satisfied. In particular, we modify the Linear\nProgramming (LP) algorithm of [9] by introducing a reduced set of constraints\nfor exact NMF. In contrast to the previous approaches, the proposed algorithm\ndoes not require the knowledge of factorization rank (extreme rays [3] or\ntopics [7]). Furthermore, motivated by a similar problem arising in the context\nof metabolic network analysis [13], we consider an entirely different regime\nwhere the number of extreme rays or topics can be much larger than the\ndimension of the data vectors. The performance of the algorithm for different\nsynthetic data sets are provided.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 21:39:03 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Liu", "Jason Gejie", ""], ["Aeron", "Shuchin", ""]]}, {"id": "1401.2125", "submitter": "Paul Tranquilli", "authors": "Paul Tranquilli and Adrian Sandu", "title": "Exponential-Krylov methods for ordinary differential equations", "comments": null, "journal-ref": "Journal of Computational Physics. Volume 278, Pages 31 -- 46, 2014", "doi": "10.1016/j.jcp.2014.08.013", "report-no": "Computational Science Laboratory CSLTR-01/2014", "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a new class of exponential-type integrators where all the\nmatrix exponentiations are performed in a single Krylov space of low dimension.\nThe new family, called Lightly Implicit Krylov-Exponential (LIKE), is well\nsuited for solving large scale systems of ODEs or semi-discrete PDEs. The time\ndiscretization and the Krylov space approximation are treated as a single\ncomputational process, and the Krylov space properties are an integral part of\nthe new LIKE order condition theory developed herein. Consequently, LIKE\nmethods require a small number of basis vectors determined solely by the\ntemporal order of accuracy. The subspace size is independent of the ODE under\nconsideration, and there is no need to monitor the errors in linear system\nsolutions at each stage. Numerical results illustrate the favorable properties\nof new family of methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 19:17:40 GMT"}, {"version": "v2", "created": "Thu, 29 Jan 2015 20:26:34 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Tranquilli", "Paul", ""], ["Sandu", "Adrian", ""]]}, {"id": "1401.2288", "submitter": "Hemant Kumar Aggarwal", "authors": "Hemant Kumar Aggarwal and Angshul Majumdar", "title": "Extension of Sparse Randomized Kaczmarz Algorithm for Multiple\n  Measurement Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kaczmarz algorithm is popular for iteratively solving an overdetermined\nsystem of linear equations. The traditional Kaczmarz algorithm can approximate\nthe solution in few sweeps through the equations but a randomized version of\nthe Kaczmarz algorithm was shown to converge exponentially and independent of\nnumber of equations. Recently an algorithm for finding sparse solution to a\nlinear system of equations has been proposed based on weighted randomized\nKaczmarz algorithm. These algorithms solves single measurement vector problem;\nhowever there are applications were multiple-measurements are available. In\nthis work, the objective is to solve a multiple measurement vector problem with\ncommon sparse support by modifying the randomized Kaczmarz algorithm. We have\nalso modeled the problem of face recognition from video as the multiple\nmeasurement vector problem and solved using our proposed technique. We have\ncompared the proposed algorithm with state-of-art spectral projected gradient\nalgorithm for multiple measurement vectors on both real and synthetic datasets.\nThe Monte Carlo simulations confirms that our proposed algorithm have better\nrecovery and convergence rate than the MMV version of spectral projected\ngradient algorithm under fairness constraints.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 11:24:35 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2014 10:05:15 GMT"}, {"version": "v3", "created": "Sun, 2 Feb 2014 08:13:58 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Aggarwal", "Hemant Kumar", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1401.2720", "submitter": "Vedran Novakovic", "authors": "Vedran Novakovi\\'c", "title": "A hierarchically blocked Jacobi SVD algorithm for single and multiple\n  graphics processing units", "comments": "Accepted for publication in SIAM Journal on Scientific Computing", "journal-ref": "SIAM J. Sci. Comput. 37 (2015), C1-C30", "doi": "10.1137/140952429", "report-no": null, "categories": "cs.NA cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hierarchically blocked one-sided Jacobi algorithm for the\nsingular value decomposition (SVD), targeting both single and multiple graphics\nprocessing units (GPUs). The blocking structure reflects the levels of GPU's\nmemory hierarchy. The algorithm may outperform MAGMA's dgesvd, while retaining\nhigh relative accuracy. To this end, we developed a family of parallel pivot\nstrategies on GPU's shared address space, but applicable also to inter-GPU\ncommunication. Unlike common hybrid approaches, our algorithm in a single GPU\nsetting needs a CPU for the controlling purposes only, while utilizing GPU's\nresources to the fullest extent permitted by the hardware. When required by the\nproblem size, the algorithm, in principle, scales to an arbitrary number of GPU\nnodes. The scalability is demonstrated by more than twofold speedup for\nsufficiently large matrices on a Tesla S2050 system with four GPUs vs. a single\nFermi card.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 06:12:17 GMT"}, {"version": "v2", "created": "Sat, 7 Jun 2014 14:23:33 GMT"}, {"version": "v3", "created": "Sat, 27 Sep 2014 22:51:33 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Novakovi\u0107", "Vedran", ""]]}, {"id": "1401.2844", "submitter": "Dmitry Lande", "authors": "Yakiv O. Kalinovsky, Dmitry V. Lande, Yuliya E. Boyarinova, Iana V.\n  Khitsko", "title": "Inifnite hypercomplex number system factorization methods", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of obtaining the set of noncanonical hypercomplex number systems\nby conversion of infinite hypercomplex number system to finite hypercomplex\nnumber system depending on multiplication rules and factorization method is\ndescribed. Systems obtained by this method starting from the 3rddimension are\nnoncanonical. The obtained systems of even dimension can be re-factorized. As a\nresult of it hypercomplex number system of two times less dimension are got.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 14:22:32 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Kalinovsky", "Yakiv O.", ""], ["Lande", "Dmitry V.", ""], ["Boyarinova", "Yuliya E.", ""], ["Khitsko", "Iana V.", ""]]}, {"id": "1401.3301", "submitter": "Caroline Japhet", "authors": "Fran\\c{c}ois Cuvelier, Caroline Japhet, Gilles Scarella", "title": "An efficient way to assemble finite element matrices in vector languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Matlab codes in 2D and 3D have been proposed recently to assemble\nfinite element matrices. In this paper we present simple, compact and efficient\nvectorized algorithms, which are variants of these codes, in arbitrary\ndimension, without the use of any lower level language. They can be easily\nimplemented in many vector languages (e.g. Matlab, Octave, Python, Scilab, R,\nJulia, C++ with STL,...). The principle of these techniques is general, we\npresent it for the assembly of several finite element matrices in arbitrary\ndimension, in the P1 finite element case. We also provide an extension of the\nalgorithms to the case of a system of PDE's. Then we give an extension to\npiecewise polynomials of higher order. We compare numerically the performance\nof these algorithms in Matlab, Octave and Python, with that in FreeFEM++ and in\na compiled language such as C. Examples show that, unlike what is commonly\nbelieved, the performance is not radically worse than that of C : in the\nbest/worst cases, selected vector languages are respectively 2.3/3.5 and\n2.9/4.1 times slower than C in the scalar and vector cases. We also present\nnumerical results which illustrate the computational costs of these algorithms\ncompared to standard algorithms and to other recent ones.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 19:36:39 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 09:17:43 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Cuvelier", "Fran\u00e7ois", ""], ["Japhet", "Caroline", ""], ["Scarella", "Gilles", ""]]}, {"id": "1401.4477", "submitter": "Lukas Einkemmer", "authors": "Nicolas Crouseilles and Lukas Einkemmer and Erwan Faou", "title": "A Hamiltonian splitting for the Vlasov-Maxwell system", "comments": null, "journal-ref": "Journal of Computational Physics, Volume 283, 15 February 2015,\n  Pages 224-240", "doi": "10.1016/j.jcp.2014.11.029", "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new splitting is proposed for solving the Vlasov-Maxwell system. This\nsplitting is based on a decomposition of the Hamiltonian of the Vlasov-Maxwell\nsystem and allows for the construction of arbitrary high order methods by\ncomposition (independent of the specific deterministic method used for the\ndiscretization of the phase space). Moreover, we show that for a spectral\nmethod in space this scheme satisfies Poisson's equation without explicitly\nsolving it. Finally, we present some examples in the context of the time\nevolution of an electromagnetic plasma instability which emphasizes the\nexcellent behavior of the new splitting compared to methods from the\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2014 21:39:09 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Crouseilles", "Nicolas", ""], ["Einkemmer", "Lukas", ""], ["Faou", "Erwan", ""]]}, {"id": "1401.4780", "submitter": "Ji Liu", "authors": "Ji Liu and Stephen J. Wright and Srikrishna Sridhar", "title": "An Asynchronous Parallel Randomized Kaczmarz Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an asynchronous parallel variant of the randomized Kaczmarz (RK)\nalgorithm for solving the linear system $Ax=b$. The analysis shows linear\nconvergence and indicates that nearly linear speedup can be expected if the\nnumber of processors is bounded by a multiple of the number of rows in $A$.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 03:06:43 GMT"}, {"version": "v2", "created": "Sat, 7 Jun 2014 16:33:39 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Liu", "Ji", ""], ["Wright", "Stephen J.", ""], ["Sridhar", "Srikrishna", ""]]}, {"id": "1401.4950", "submitter": "Matthias Petschow", "authors": "Matthias Petschow (1), ((1) AICES, RWTH Aachen)", "title": "MRRR-based Eigensolvers for Multi-core Processors and Supercomputers", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA cs.PF math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real symmetric tridiagonal eigenproblem is of outstanding importance in\nnumerical computations; it arises frequently as part of eigensolvers for\nstandard and generalized dense Hermitian eigenproblems that are based on a\nreduction to tridiagonal form. For its solution, the algorithm of Multiple\nRelatively Robust Representations (MRRR or MR3 in short) - introduced in the\nlate 1990s - is among the fastest methods. To compute k eigenpairs of a real\nn-by-n tridiagonal T, MRRR only requires O(kn) arithmetic operations; in\ncontrast, all the other practical methods require O(k^2 n) or O(n^3) operations\nin the worst case. This thesis centers around the performance and accuracy of\nMRRR.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 15:52:03 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Petschow", "Matthias", "", "AICES, RWTH Aachen"]]}, {"id": "1401.5148", "submitter": "Bahman Kalantari", "authors": "Bahman Kalantari", "title": "Solving Cubic Equations By the Quadratic Formula", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $p(z)$ be a monic cubic complex polynomial with distinct roots and\ndistinct critical points. We say a critical point has the {\\it Voronoi\nproperty} if it lies in the Voronoi cell of a root $\\theta$, $V(\\theta)$, i.e.\nthe set of points that are closer to $\\theta$ than to the other roots. We prove\nat least one critical point has the Voronoi property and characterize the cases\nwhen both satisfy this property. It is known that for any $\\xi \\in V(\\theta)$,\nthe sequence $B_m(\\xi) =\\xi - p(\\xi) d_{m-2}/d_{m-1}$ converges to $\\theta$,\nwhere $d_m$ satisfies the recurrence $d_m =p'(\\xi)d_{m-1}-0.5\np(\\xi)p''(\\xi)d_{m-2} +p^2(\\xi)d_{m-3}$, $d_0 =1, d_{-1}=d_{-2}=0$. Thus by the\nVoronoi property, there is a solution $c$ of $p'(z)=0$ where $B_m(c)$ converges\nto a root of $p(z)$. The speed of convergence is dependent on the ratio of the\ndistances between $c$ and the closest and the second closest roots of $p(z)$.\nThis results in a different algorithm for solving a cubic equation than the\nclassical methods. We give polynomiography for an example.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 02:19:26 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Kalantari", "Bahman", ""]]}, {"id": "1401.5353", "submitter": "Blake Barker", "authors": "Blake Barker", "title": "STABLAB Documentation for KdV : Numerical proof of stability of roll\n  waves in the small-amplitude limit for inclined thin film flow", "comments": "Documentation, 255 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We document the MATLAB code used in the following study: Numerical proof of\nstability of roll waves in the small-amplitude limit for inclined thin film\nflow.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 15:43:52 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Barker", "Blake", ""]]}, {"id": "1401.5522", "submitter": "Bradley Lowery", "authors": "Mathieu Faverge, Julien Herrmann, Julien Langou, Bradley Lowery, Yves\n  Robert and Jack Dongarra", "title": "Designing LU-QR hybrid solvers for performance and stability", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces hybrid LU-QR al- gorithms for solving dense linear\nsystems of the form Ax = b. Throughout a matrix factorization, these al-\ngorithms dynamically alternate LU with local pivoting and QR elimination steps,\nbased upon some robustness criterion. LU elimination steps can be very\nefficiently parallelized, and are twice as cheap in terms of floating- point\noperations, as QR steps. However, LU steps are not necessarily stable, while QR\nsteps are always stable. The hybrid algorithms execute a QR step when a\nrobustness criterion detects some risk for instability, and they execute an LU\nstep otherwise. Ideally, the choice between LU and QR steps must have a small\ncomputational overhead and must provide a satisfactory level of stability with\nas few QR steps as possible. In this paper, we introduce several robustness\ncriteria and we establish upper bounds on the growth factor of the norm of the\nupdated matrix incurred by each of these criteria. In addition, we describe the\nimplementation of the hybrid algorithms through an exten- sion of the PaRSEC\nsoftware to allow for dynamic choices during execution. Finally, we analyze\nboth stability and performance results compared to state-of-the-art linear\nsolvers on parallel distributed multicore platforms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 23:45:16 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Faverge", "Mathieu", ""], ["Herrmann", "Julien", ""], ["Langou", "Julien", ""], ["Lowery", "Bradley", ""], ["Robert", "Yves", ""], ["Dongarra", "Jack", ""]]}, {"id": "1401.5690", "submitter": "Alexander Kobel", "authors": "Alexander Kobel and Michael Sagraloff", "title": "On the Complexity of Computing with Planar Algebraic Curves", "comments": "41 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.NA math.AG math.GT math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give improved bounds for the computational complexity of\ncomputing with planar algebraic curves. More specifically, for arbitrary\ncoprime polynomials $f$, $g \\in \\mathbb{Z}[x,y]$ and an arbitrary polynomial $h\n\\in \\mathbb{Z}[x,y]$, each of total degree less than $n$ and with integer\ncoefficients of absolute value less than $2^\\tau$, we show that each of the\nfollowing problems can be solved in a deterministic way with a number of bit\noperations bounded by $\\tilde{O}(n^6+n^5\\tau)$, where we ignore polylogarithmic\nfactors in $n$ and $\\tau$:\n  (1) The computation of isolating regions in $\\mathbb{C}^2$ for all complex\nsolutions of the system $f = g = 0$,\n  (2) the computation of a separating form for the solutions of $f = g = 0$,\n  (3) the computation of the sign of $h$ at all real valued solutions of $f = g\n= 0$, and\n  (4) the computation of the topology of the planar algebraic curve\n$\\mathcal{C}$ defined as the real valued vanishing set of the polynomial $f$.\n  Our bound improves upon the best currently known bounds for the first three\nproblems by a factor of $n^2$ or more and closes the gap to the\nstate-of-the-art randomized complexity for the last problem.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 14:54:13 GMT"}, {"version": "v2", "created": "Thu, 31 Jul 2014 13:33:25 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Kobel", "Alexander", ""], ["Sagraloff", "Michael", ""]]}, {"id": "1401.6011", "submitter": "Michael Sagraloff", "authors": "Michael Sagraloff", "title": "A Near-Optimal Algorithm for Computing Real Roots of Sparse Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CC cs.SC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $p\\in\\mathbb{Z}[x]$ be an arbitrary polynomial of degree $n$ with $k$\nnon-zero integer coefficients of absolute value less than $2^\\tau$. In this\npaper, we answer the open question whether the real roots of $p$ can be\ncomputed with a number of arithmetic operations over the rational numbers that\nis polynomial in the input size of the sparse representation of $p$. More\nprecisely, we give a deterministic, complete, and certified algorithm that\ndetermines isolating intervals for all real roots of $p$ with\n$O(k^3\\cdot\\log(n\\tau)\\cdot \\log n)$ many exact arithmetic operations over the\nrational numbers.\n  When using approximate but certified arithmetic, the bit complexity of our\nalgorithm is bounded by $\\tilde{O}(k^4\\cdot n\\tau)$, where $\\tilde{O}(\\cdot)$\nmeans that we ignore logarithmic. Hence, for sufficiently sparse polynomials\n(i.e. $k=O(\\log^c (n\\tau))$ for a positive constant $c$), the bit complexity is\n$\\tilde{O}(n\\tau)$. We also prove that the latter bound is optimal up to\nlogarithmic factors.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 15:43:06 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Sagraloff", "Michael", ""]]}, {"id": "1401.6235", "submitter": "Evgeny Latkin", "authors": "Evgeny Latkin", "title": "Twofold fast arithmetic", "comments": "C++ experimental code and test results available via Web:\n  https://sites.google.com/site/yevgenylatkin/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we assure math computations by automatic verifying floating-point\naccuracy? We define fast arithmetic (based on Dekker [1971]) over twofold\napproximations $z\\approx z_0+z_1$, such that $z_0$ is standard result and $z_1$\nassesses inaccuracy $\\Delta z_0=z-z_0$. We propose on-fly tracking $z_1$,\ndetecting if $\\Delta z_0$ appears too high. We believe permanent tracking is\nworth its cost. C++ test code for Intel AVX available via web.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 01:33:54 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2014 05:58:56 GMT"}, {"version": "v3", "created": "Fri, 11 Apr 2014 04:58:06 GMT"}, {"version": "v4", "created": "Thu, 17 Apr 2014 04:28:11 GMT"}, {"version": "v5", "created": "Mon, 21 Apr 2014 07:10:44 GMT"}, {"version": "v6", "created": "Thu, 10 Jul 2014 10:35:43 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Latkin", "Evgeny", ""]]}, {"id": "1401.6236", "submitter": "Michael Cohen", "authors": "Michael B. Cohen, Rasmus Kyng, Jakub W. Pachocki, Richard Peng, Anup\n  Rao", "title": "Preconditioning in Expectation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that preconditioners constructed by random sampling can perform well\nwithout meeting the standard requirements of iterative methods. When applied to\ngraph Laplacians, this leads to ultra-sparsifiers that in expectation behave as\nthe nearly-optimal ones given by [Kolla-Makarychev-Saberi-Teng STOC`10].\nCombining this with the recursive preconditioning framework by [Spielman-Teng\nSTOC`04] and improved embedding algorithms, this leads to algorithms that solve\nsymmetric diagonally dominant linear systems and electrical flow problems in\nexpected time close to $m\\log^{1/2}n$ .\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 01:37:37 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Cohen", "Michael B.", ""], ["Kyng", "Rasmus", ""], ["Pachocki", "Jakub W.", ""], ["Peng", "Richard", ""], ["Rao", "Anup", ""]]}, {"id": "1401.6594", "submitter": "Maciej Balajewicz", "authors": "Maciej Balajewicz, Charbel Farhat", "title": "Reduction of Nonlinear Embedded Boundary Models for Problems with\n  Evolving Interfaces", "comments": null, "journal-ref": "J. Comput. Phys. (2014), vol. 274, pp. 489-504", "doi": "10.1016/j.jcp.2014.06.038", "report-no": null, "categories": "physics.comp-ph cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded boundary methods alleviate many computational challenges, including\nthose associated with meshing complex geometries and solving problems with\nevolving domains and interfaces. Developing model reduction methods for\ncomputational frameworks based on such methods seems however to be challenging.\nIndeed, most popular model reduction techniques are projection-based, and rely\non basis functions obtained from the compression of simulation snapshots. In a\ntraditional interface-fitted computational framework, the computation of such\nbasis functions is straightforward, primarily because the computational domain\ndoes not contain in this case a fictitious region. This is not the case however\nfor an embedded computational framework because the computational domain\ntypically contains in this case both real and ghost regions whose definitions\ncomplicate the collection and compression of simulation snapshots. The problem\nis exacerbated when the interface separating both regions evolves in time. This\npaper addresses this issue by formulating the snapshot compression problem as a\nweighted low-rank approximation problem where the binary weighting identifies\nthe evolving component of the individual simulation snapshots. The proposed\napproach is application independent and therefore comprehensive. It is\nsuccessfully demonstrated for the model reduction of several two-dimensional,\nvortex-dominated, fluid-structure interaction problems.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 23:31:54 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Balajewicz", "Maciej", ""], ["Farhat", "Charbel", ""]]}, {"id": "1401.7129", "submitter": "Viswanadh Konjeti", "authors": "Garimella Rama Murthy", "title": "Towards a Resolution of P = NP Conjecture", "comments": "15 pages. arXiv admin note: substantial text overlap with\n  arXiv:1207.0634", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research paper, the problem of optimization of a quadratic form over\nthe convex hull generated by the corners of hypercube is attempted and solved.\nIt is reasoned that under some conditions, the optimum occurs at the corners of\nhypercube. Results related to the computation of global optimum stable state\n(an NP hard problem) are discussed. An algorithm is proposed. It is hoped that\nthe results shed light on resolving the P not equal to NP problem.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 10:36:04 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Murthy", "Garimella Rama", ""]]}, {"id": "1401.7227", "submitter": "Haran Jackson", "authors": "Haran Jackson, Michele Taroni, David Ponting", "title": "A Two-Level Variant of Additive Schwarz Preconditioning for Use in\n  Reservoir Simulation", "comments": "Submitted to Numerical Linear Algebra with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation time for reservoir simulation is dominated by the linear\nsolver. The sets of linear equations which arise in reservoir simulation have\ntwo distinctive features: the problems are usually highly anisotropic, with a\ndominant vertical flow direction, and the commonly used fully implicit method\nrequires a simultaneous solution for pressure and saturation or molar\nconcentration variables. These variables behave quite differently, with the\npressure feeling long-range effects while the saturations vary locally. In this\npaper we review preconditioned iterative methods used for solving the linear\nsystem equations in reservoir simulation and their parallelisation. We then\npropose a variant of the classical additive Schwarz preconditioner designed to\nachieve better results on a large number of processors and discuss some\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 15:43:58 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2014 00:18:32 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2014 01:58:01 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Jackson", "Haran", ""], ["Taroni", "Michele", ""], ["Ponting", "David", ""]]}, {"id": "1401.7294", "submitter": "Dmitry Kolomenskiy", "authors": "Dmitry Kolomenskiy, Jean-Christophe Nave and Kai Schneider", "title": "Adaptive gradient-augmented level set method with multiresolution error\n  estimation", "comments": null, "journal-ref": null, "doi": "10.1007/s10915-015-0014-7", "report-no": null, "categories": "physics.comp-ph cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A space-time adaptive scheme is presented for solving advection equations in\ntwo space dimensions. The gradient-augmented level set method using a\nsemi-Lagrangian formulation with backward time integration is coupled with a\npoint value multiresolution analysis using Hermite interpolation. Thus locally\nrefined dyadic spatial grids are introduced which are efficiently implemented\nwith dynamic quadtree data structures. For adaptive time integration, an\nembedded Runge-Kutta method is employed. The precision of the new fully\nadaptive method is analysed and speed up of CPU time and memory compression\nwith respect to the uniform grid discretization are reported.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 18:51:52 GMT"}, {"version": "v2", "created": "Tue, 29 Jul 2014 15:52:41 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2015 19:40:16 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Kolomenskiy", "Dmitry", ""], ["Nave", "Jean-Christophe", ""], ["Schneider", "Kai", ""]]}, {"id": "1401.7842", "submitter": "J\\'er\\^ome Bonelle", "authors": "Jerome Bonelle and Alexandre Ern", "title": "Analysis of Compatible Discrete Operator Schemes for the Stokes\n  Equations on Polyhedral Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compatible Discrete Operator schemes preserve basic properties of the\ncontinuous model at the discrete level. They combine discrete differential\noperators that discretize exactly topological laws and discrete Hodge operators\nthat approximate constitutive relations. We devise and analyze two families of\nsuch schemes for the Stokes equations in curl formulation, with the pressure\ndegrees of freedom located at either mesh vertices or cells. The schemes ensure\nlocal mass and momentum conservation. We prove discrete stability by\nestablishing novel discrete Poincar\\'e inequalities. Using commutators related\nto the consistency error, we derive error estimates with first-order\nconvergence rates for smooth solutions. We analyze two strategies for\ndiscretizing the external load, so as to deliver tight error estimates when the\nexternal load has a large irrotational or divergence-free part. Finally,\nnumerical results are presented on three-dimensional polyhedral meshes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 13:43:11 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Bonelle", "Jerome", ""], ["Ern", "Alexandre", ""]]}]