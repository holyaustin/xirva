[{"id": "1502.00182", "submitter": "Mostafa Rahmani", "authors": "Mostafa Rahmani, George Atia", "title": "High Dimensional Low Rank plus Sparse Matrix Decomposition", "comments": "IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2017.2649482", "report-no": null, "categories": "cs.NA cs.DS cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the problem of low rank plus sparse matrix\ndecomposition for big data. Conventional algorithms for matrix decomposition\nuse the entire data to extract the low-rank and sparse components, and are\nbased on optimization problems with complexity that scales with the dimension\nof the data, which limits their scalability. Furthermore, existing randomized\napproaches mostly rely on uniform random sampling, which is quite inefficient\nfor many real world data matrices that exhibit additional structures (e.g.\nclustering). In this paper, a scalable subspace-pursuit approach that\ntransforms the decomposition problem to a subspace learning problem is\nproposed. The decomposition is carried out using a small data sketch formed\nfrom sampled columns/rows. Even when the data is sampled uniformly at random,\nit is shown that the sufficient number of sampled columns/rows is roughly\nO(r\\mu), where \\mu is the coherency parameter and r the rank of the low rank\ncomponent. In addition, adaptive sampling algorithms are proposed to address\nthe problem of column/row sampling from structured data. We provide an analysis\nof the proposed method with adaptive sampling and show that adaptive sampling\nmakes the required number of sampled columns/rows invariant to the distribution\nof the data. The proposed approach is amenable to online implementation and an\nonline scheme is proposed.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 00:57:57 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2016 03:56:48 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 06:41:34 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Atia", "George", ""]]}, {"id": "1502.00190", "submitter": "Chuang Wang", "authors": "Chuang Wang, Ameya Agaskar and Yue M. Lu", "title": "Randomized Kaczmarz Algorithm for Inconsistent Linear Systems: An Exact\n  MSE Analysis", "comments": "5 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.IT cs.NA math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a complete characterization of the randomized Kaczmarz algorithm\n(RKA) for inconsistent linear systems. The Kaczmarz algorithm, known in some\nfields as the algebraic reconstruction technique, is a classical method for\nsolving large-scale overdetermined linear systems through a sequence of\nprojection operators; the randomized Kaczmarz algorithm is a recent proposal by\nStrohmer and Vershynin to randomize the sequence of projections in order to\nguarantee exponential convergence (in mean square) to the solutions. A flurry\nof work followed this development, with renewed interest in the algorithm, its\nextensions, and various bounds on their performance. Earlier, we studied the\nspecial case of consistent linear systems and provided an exact formula for the\nmean squared error (MSE) in the value reconstructed by RKA, as well as a simple\nway to compute the exact decay rate of the error. In this work, we consider the\ncase of inconsistent linear systems, which is a more relevant scenario for most\napplications. First, by using a \"lifting trick\", we derive an exact formula for\nthe MSE given a fixed noise vector added to the measurements. Then we show how\nto average over the noise when it is drawn from a distribution with known first\nand second-order statistics. Finally, we demonstrate the accuracy of our exact\nMSE formulas through numerical simulations, which also illustrate that previous\nupper bounds in the literature may be several orders of magnitude too high.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 02:40:22 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Wang", "Chuang", ""], ["Agaskar", "Ameya", ""], ["Lu", "Yue M.", ""]]}, {"id": "1502.00277", "submitter": "Renato J Cintra", "authors": "H. M. de Oliveira, R. G. F. T\\'avora, R. J. Cintra, R. M. Campello de\n  Souza", "title": "Fast Finite Field Hartley Transforms Based on Hadamard Decomposition", "comments": "6 pages, 3 tables, fixed typos, submitted to the Sixth International\n  Symposium on Communication Theory and Applications (ISCTA'01), 2001", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new transform over finite fields, the finite field Hartley transform\n(FFHT), was recently introduced and a number of promising applications on the\ndesign of efficient multiple access systems and multilevel spread spectrum\nsequences were proposed. The FFHT exhibits interesting symmetries, which are\nexploited to derive tailored fast transform algorithms. The proposed fast\nalgorithms are based on successive decompositions of the FFHT by means of\nHadamard-Walsh transforms (HWT). The introduced decompositions meet the lower\nbound on the multiplicative complexity for all the cases investigated. The\ncomplexity of the new algorithms is compared with that of traditional\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 16:08:55 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["de Oliveira", "H. M.", ""], ["T\u00e1vora", "R. G. F.", ""], ["Cintra", "R. J.", ""], ["de Souza", "R. M. Campello", ""]]}, {"id": "1502.00555", "submitter": "Renato J Cintra", "authors": "P. A. M. Oliveira, R. J. Cintra, F. M. Bayer, S. Kulasekera, A.\n  Madanayake", "title": "A Discrete Tchebichef Transform Approximation for Image and Video Coding", "comments": "13 pages, 5 figures, 2 tables", "journal-ref": "IEEE Signal Processing Letters, vol. 22, issue 8, pp. 1137-1141,\n  2015", "doi": "10.1109/LSP.2015.2389899", "report-no": null, "categories": "stat.ME cs.CV cs.MM cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a low-complexity approximation for the discrete\nTchebichef transform (DTT). The proposed forward and inverse transforms are\nmultiplication-free and require a reduced number of additions and bit-shifting\noperations. Numerical compression simulations demonstrate the efficiency of the\nproposed transform for image and video coding. Furthermore, Xilinx Virtex-6\nFPGA based hardware realization shows 44.9% reduction in dynamic power\nconsumption and 64.7% lower area when compared to the literature.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 14:07:44 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Oliveira", "P. A. M.", ""], ["Cintra", "R. J.", ""], ["Bayer", "F. M.", ""], ["Kulasekera", "S.", ""], ["Madanayake", "A.", ""]]}, {"id": "1502.00592", "submitter": "Renato J Cintra", "authors": "C. J. Tablada, F. M. Bayer, R. J. Cintra", "title": "A Class of DCT Approximations Based on the Feig-Winograd Algorithm", "comments": "26 pages, 4 figures, 5 tables, fixed arithmetic complexity in Table\n  IV", "journal-ref": "Signal Processing, vol. 113, pp. 38-51, August 2015", "doi": "10.1016/j.sigpro.2015.01.011", "report-no": null, "categories": "stat.ME cs.CV cs.MM cs.NA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of matrices based on a parametrization of the Feig-Winograd\nfactorization of 8-point DCT is proposed. Such parametrization induces a matrix\nsubspace, which unifies a number of existing methods for DCT approximation. By\nsolving a comprehensive multicriteria optimization problem, we identified\nseveral new DCT approximations. Obtained solutions were sought to possess the\nfollowing properties: (i) low multiplierless computational complexity, (ii)\northogonality or near orthogonality, (iii) low complexity invertibility, and\n(iv) close proximity and performance to the exact DCT. Proposed approximations\nwere submitted to assessment in terms of proximity to the DCT, coding\nperformance, and suitability for image compression. Considering Pareto\nefficiency, particular new proposed approximations could outperform various\nexisting methods archived in literature.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 19:39:46 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 21:25:18 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Tablada", "C. J.", ""], ["Bayer", "F. M.", ""], ["Cintra", "R. J.", ""]]}, {"id": "1502.00950", "submitter": "Helio M. de Oliveira", "authors": "M.M.S. Lira, H.M. de Oliveira, M.A. Carvalho Jr, R.M. Campello de\n  Souza", "title": "Compactly Supported Wavelets Derived From Legendre Polynomials:\n  Spherical Harmonic Wavelets", "comments": "6 pages, 6 figures, 1 table In: Computational Methods in Circuits and\n  Systems Applications, WSEAS press, pp.211-215, 2003. ISBN: 960-8052-88-2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new family of wavelets is introduced, which is associated with Legendre\npolynomials. These wavelets, termed spherical harmonic or Legendre wavelets,\npossess compact support. The method for the wavelet construction is derived\nfrom the association of ordinary second order differential equations with\nmultiresolution filters. The low-pass filter associated with Legendre\nmultiresolution analysis is a linear phase finite impulse response filter\n(FIR).\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 18:23:32 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Lira", "M. M. S.", ""], ["de Oliveira", "H. M.", ""], ["Carvalho", "M. A.", "Jr"], ["de Souza", "R. M. Campello", ""]]}, {"id": "1502.01038", "submitter": "Renato J Cintra", "authors": "H. M. de Oliveira, R. J. Cintra, R. M. Campello de Souza", "title": "A Factorization Scheme for Some Discrete Hartley Transform Matrices", "comments": "10 pages, 4 figures, 2 tables, International Conference on System\n  Engineering, Communications and Information Technologies, 2001, Punta Arenas.\n  ICSECIT 2001 Proceedings. Punta Arenas: Universidad de Magallanes, 2001", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete transforms such as the discrete Fourier transform (DFT) and the\ndiscrete Hartley transform (DHT) are important tools in numerical analysis. The\nsuccessful application of transform techniques relies on the existence of\nefficient fast transforms. In this paper some fast algorithms are derived. The\ntheoretical lower bound on the multiplicative complexity for the DFT/DHT are\nachieved. The approach is based on the factorization of DHT matrices.\nAlgorithms for short blocklengths such as $N \\in \\{3, 5, 6, 12, 24 \\}$ are\npresented.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 16:06:29 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["de Oliveira", "H. M.", ""], ["Cintra", "R. J.", ""], ["de Souza", "R. M. Campello", ""]]}, {"id": "1502.01066", "submitter": "Amirali Khodadadian Gostar", "authors": "Amirali K. Gostar, Reza Hoseinnezhad and Alireza Bab-Hadiashar", "title": "Information theoretic approach to robust multi-Bernoulli sensor control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NA cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel sensor control solution is presented, formulated within a\nMulti-Bernoulli-based multi-target tracking framework. The proposed method is\nespecially designed for the general multi-target tracking case, where no prior\nknowledge of the clutter distribution or the probability of detection profile\nare available. In an information theoretic approach, our method makes use of\nR\\`{e}nyi divergence as the reward function to be maximized for finding the\noptimal sensor control command at each step. We devise a Monte Carlo sampling\nmethod for computation of the reward. Simulation results demonstrate successful\nperformance of the proposed method in a challenging scenario involving five\ntargets maneuvering in a relatively uncertain space with unknown\ndistance-dependent clutter rate and probability of detection.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 00:15:47 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Gostar", "Amirali K.", ""], ["Hoseinnezhad", "Reza", ""], ["Bab-Hadiashar", "Alireza", ""]]}, {"id": "1502.01321", "submitter": "Sukanta Nayak", "authors": "Sukanta Nayak and Snehashish Chakraverty", "title": "Numerical Solution of Fuzzy Stochastic Differential Equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.AI math-ph math.MP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper an alternative approach to solve uncertain Stochastic\nDifferential Equation (SDE) is proposed. This uncertainty occurs due to the\ninvolved parameters in system and these are considered as Triangular Fuzzy\nNumbers (TFN). Here the proposed fuzzy arithmetic in [2] is used as a tool to\nhandle Fuzzy Stochastic Differential Equation (FSDE). In particular, a system\nof Ito stochastic differential equations is analysed with fuzzy parameters.\nFurther exact and Euler Maruyama approximation methods with fuzzy values are\ndemonstrated and solved some standard SDE.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 05:52:25 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Nayak", "Sukanta", ""], ["Chakraverty", "Snehashish", ""]]}, {"id": "1502.01377", "submitter": "Renato J Cintra", "authors": "R. J. Cintra, V. S. Dimitrov", "title": "The Arithmetic Cosine Transform: Exact and Approximate Algorithms", "comments": "17 pages, 3 figures", "journal-ref": "IEEE Transactions on Signal Processing, vol. 58, no. 6, pp.\n  3076-3085, June 2010", "doi": "10.1109/TSP.2010.2045781", "report-no": null, "categories": "cs.NA math.NA stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new class of transform method --- the\narithmetic cosine transform (ACT). We provide the central mathematical\nproperties of the ACT, necessary in designing efficient and accurate\nimplementations of the new transform method. The key mathematical tools used in\nthe paper come from analytic number theory, in particular the properties of the\nRiemann zeta function. Additionally, we demonstrate that an exact signal\ninterpolation is achievable for any block-length. Approximate calculations were\nalso considered. The numerical examples provided show the potential of the ACT\nfor various digital signal processing applications.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 22:10:21 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Cintra", "R. J.", ""], ["Dimitrov", "V. S.", ""]]}, {"id": "1502.01424", "submitter": "Helio M. de Oliveira", "authors": "V.V. Vermehren, J.E. Wesen and H.M. de Oliveira", "title": "Close Approximations for Daublets and their Spectra", "comments": "6 pages, 6 figures, 3 tables. Conference: International\n  Telecommunication Symposium, ITS 2010, Manaus, AM , Brazil", "journal-ref": null, "doi": "10.14209/SBRT.2010.68", "report-no": null, "categories": "cs.NA math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper offers a new regard on compactly supported wavelets derived from\nFIR filters. Although being continuous wavelets, analytical formulation are\nlacking for such wavelets. Close approximations for daublets (Daubechies\nwavelets) and their spectra are introduced here. The frequency detection\nproperties of daublets are investigated through scalograms derived from these\nnew analytical expressions. These near-daublets have been implemented on the\nMatlab wavelet toolbox and a few scalograms presented. This approach can be\nvaluable for wavelet synthesis from hardware or for application involving\ncontinuous wavelet-based systems, such as wavelet OFDM.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 03:33:34 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Vermehren", "V. V.", ""], ["Wesen", "J. E.", ""], ["de Oliveira", "H. M.", ""]]}, {"id": "1502.01801", "submitter": "Sayan Mitra", "authors": "Chuchu Fan and Sayan Mitra", "title": "Bounded Verification with On-the-Fly Discrepancy Computation", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": "University of Illinois Urbana Champaign, Tech Report\n  UILU-ENG-15-2201", "categories": "cs.SY cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation-based verification algorithms can provide formal safety guarantees\nfor nonlinear and hybrid systems. The previous algorithms rely on user provided\nmodel annotations called discrepancy function, which are crucial for computing\nreachtubes from simulations. In this paper, we eliminate this requirement by\npresenting an algorithm for computing piece-wise exponential discrepancy\nfunctions. The algorithm relies on computing local convergence or divergence\nrates of trajectories along a simulation using a coarse over-approximation of\nthe reach set and bounding the maximal eigenvalue of the Jacobian over this\nover-approximation. The resulting discrepancy function preserves the soundness\nand the relative completeness of the verification algorithm. We also provide a\ncoordinate transformation method to improve the local estimates for the\nconvergence or divergence rates in practical examples. We extend the method to\nget the input-to-state discrepancy of nonlinear dynamical systems which can be\nused for compositional analysis. Our experiments show that the approach is\neffective in terms of running time for several benchmark problems, scales\nreasonably to larger dimensional systems, and compares favorably with respect\nto available tools for nonlinear models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 05:32:03 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Fan", "Chuchu", ""], ["Mitra", "Sayan", ""]]}, {"id": "1502.02009", "submitter": "Robert Nishihara", "authors": "Robert Nishihara, Laurent Lessard, Benjamin Recht, Andrew Packard,\n  Michael I. Jordan", "title": "A General Analysis of the Convergence of ADMM", "comments": "10 pages, 6 figures", "journal-ref": "International Conference on Machine Learning 32, 2015", "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new proof of the linear convergence of the alternating direction\nmethod of multipliers (ADMM) when one of the objective terms is strongly\nconvex. Our proof is based on a framework for analyzing optimization algorithms\nintroduced in Lessard et al. (2014), reducing algorithm convergence to\nverifying the stability of a dynamical system. This approach generalizes a\nnumber of existing results and obviates any assumptions about specific choices\nof algorithm parameters. On a numerical example, we demonstrate that minimizing\nthe derived bound on the convergence rate provides a practical approach to\nselecting algorithm parameters for particular ADMM instances. We complement our\nupper bound by constructing a nearly-matching lower bound on the worst-case\nrate of convergence.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 20:01:58 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2015 19:11:31 GMT"}, {"version": "v3", "created": "Tue, 19 May 2015 03:20:51 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Nishihara", "Robert", ""], ["Lessard", "Laurent", ""], ["Recht", "Benjamin", ""], ["Packard", "Andrew", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1502.02280", "submitter": "Maria Louka A", "authors": "M. A. Louka and N. M. Missirlis", "title": "A comparison of the Extrapolated Successive Overrelaxation and the\n  Preconditioned Simultaneous Displacement methods for augmented linear systems", "comments": "42 pages, 3 figures, 8 tables; Numerische Mathematik, 2015", "journal-ref": null, "doi": "10.1007/s00211-015-0697-6", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the impact of two types of preconditioning on the\nnumerical solution of large sparse augmented linear systems. The first\npreconditioning matrix is the lower triangular part whereas the second is the\nproduct of the lower triangular part with the upper triangular part of the\naugmented system's coefficient matrix. For the first preconditioning matrix we\nform the Generalized Modified Extrapolated Successive Overrelaxation (GMESOR)\nmethod, whereas the second preconditioning matrix yields the Generalized\nModified Preconditioned Simultaneous Displacement (GMPSD) method, which is an\nextrapolated form of the Symmetric Successive Overrelaxation method. We find\nsufficient conditions for each aforementioned iterative method to converge. In\naddition, we develop a geometric approach, for determining the optimum values\nof their parameters and corresponding spectral radii. It is shown that both\niterative methods studied (GMESOR and GMPSD) attain the same rate of\nconvergence. Numerical results confirm our theoretical expectations.\n", "versions": [{"version": "v1", "created": "Sun, 8 Feb 2015 17:49:48 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Louka", "M. A.", ""], ["Missirlis", "N. M.", ""]]}, {"id": "1502.02281", "submitter": "Patrick Johnstone", "authors": "Patrick R. Johnstone and Pierre Moulin", "title": "Local and Global Convergence of an Inertial Version of Forward-Backward\n  Splitting", "comments": "The proofs of Thms. 4.1, 5.1, 5.2, and 5.6 of this manuscript contain\n  several errors. These errors have been fixed in a revised and rewritten\n  manuscript entitled \"Local and Global Convergence of a General Inertial\n  Proximal Splitting Scheme\" arxiv id. 1602.02726. We recommend reading this\n  updated manuscript, available at arXiv:1602.02726", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem of great interest in optimization is to minimize a sum of two\nclosed, proper, and convex functions where one is smooth and the other has a\ncomputationally inexpensive proximal operator. In this paper we analyze a\nfamily of Inertial Forward-Backward Splitting (I-FBS) algorithms for solving\nthis problem. We first apply a global Lyapunov analysis to I-FBS and prove weak\nconvergence of the iterates to a minimizer in a real Hilbert space. We then\nshow that the algorithms achieve local linear convergence for \"sparse\noptimization\", which is the important special case where the nonsmooth term is\nthe $\\ell_1$-norm. This result holds under either a restricted strong convexity\nor a strict complimentary condition and we do not require the objective to be\nstrictly convex. For certain parameter choices we determine an upper bound on\nthe number of iterations until the iterates are confined on a manifold\ncontaining the solution set and linear convergence holds.\n  The local linear convergence result for sparse optimization holds for the\nFast Iterative Shrinkage and Soft Thresholding Algorithm (FISTA) due to Beck\nand Teboulle which is a particular parameter choice for I-FBS. In spite of its\noptimal global objective function convergence rate, we show that FISTA is not\noptimal for sparse optimization with respect to the local convergence rate. We\ndetermine the locally optimal parameter choice for the I-FBS family. Finally we\npropose a method which inherits the excellent global rate of FISTA but also has\nexcellent local rate.\n", "versions": [{"version": "v1", "created": "Sun, 8 Feb 2015 17:50:30 GMT"}, {"version": "v2", "created": "Thu, 19 Feb 2015 17:21:48 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2015 20:59:38 GMT"}, {"version": "v4", "created": "Wed, 24 Jun 2015 04:00:54 GMT"}, {"version": "v5", "created": "Mon, 23 Jan 2017 16:14:18 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Johnstone", "Patrick R.", ""], ["Moulin", "Pierre", ""]]}, {"id": "1502.02887", "submitter": "Pierre Gosselet", "authors": "Valentine Rey, Pierre Gosselet, Christian Rey", "title": "Strict bounding of quantities of interest in computations based on\n  domain decomposition", "comments": "Computer Methods in Applied Mechanics and Engineering, Elsevier,\n  2015, online preview", "journal-ref": null, "doi": "10.1016/j.cma.2015.01.009", "report-no": null, "categories": "physics.comp-ph cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with bounding the error on the estimation of quantities of\ninterest obtained by finite element and domain decomposition methods. The\nproposed bounds are written in order to separate the two errors involved in the\nresolution of reference and adjoint problems : on the one hand the\ndiscretization error due to the finite element method and on the other hand the\nalgebraic error due to the use of the iterative solver. Beside practical\nconsiderations on the parallel computation of the bounds, it is shown that the\ninterface conformity can be slightly relaxed so that local enrichment or\nrefinement are possible in the subdomains bearing singularities or quantities\nof interest which simplifies the improvement of the estimation. Academic\nassessments are given on 2D static linear mechanic problems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 13:13:29 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Rey", "Valentine", ""], ["Gosselet", "Pierre", ""], ["Rey", "Christian", ""]]}, {"id": "1502.03371", "submitter": "Helio M. de Oliveira", "authors": "R.M. Campello de Souza, H.M. de Oliveira and D. Silva", "title": "The Z Transform over Finite Fields", "comments": "6 pages, 5 figures, Proc. IEEE/SBrT Int. Telecomm. Symp., 2002.\n  pp.362-367", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.NA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite field transforms have many applications and, in many cases, can be\nimplemented with a low computational complexity. In this paper, the Z Transform\nover a finite field is introduced and some of its properties are presented.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 16:56:30 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["de Souza", "R. M. Campello", ""], ["de Oliveira", "H. M.", ""], ["Silva", "D.", ""]]}, {"id": "1502.03543", "submitter": "Nithish Divakar Mr.", "authors": "Nithish Divakar", "title": "Primal Dual Affine Scaling on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present an implementation of Primal-Dual Affine scaling method to\nsolve linear optimization problem on GPU based systems. Strategies to convert\nthe system generated by complementary slackness theorem into a symmetric system\nare given. A new CUDA friendly technique to solve the resulting symmetric\npositive definite subsystem is also developed. Various strategies to reduce the\nmemory transfer and storage requirements were also explored.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 05:27:30 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Divakar", "Nithish", ""]]}, {"id": "1502.03645", "submitter": "Andreas Kreienbuehl", "authors": "Andreas Kreienbuehl, Arne Naegel, Daniel Ruprecht, Robert Speck,\n  Gabriel Wittum, and Rolf Krause", "title": "Numerical simulation of skin transport using Parareal", "comments": "11 pages, 8 figures", "journal-ref": "Computing and Visualization in Science 17(2), pp. 99-108, 2015", "doi": "10.1007/s00791-015-0246-y", "report-no": null, "categories": "cs.CE cs.DC cs.NA cs.PF math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-silico investigation of skin permeation is an important but also\ncomputationally demanding problem. To resolve all scales involved in full\ndetail will not only require exascale computing capacities but also suitable\nparallel algorithms. This article investigates the applicability of the\ntime-parallel Parareal algorithm to a brick and mortar setup, a precursory\nproblem to skin permeation. The C++ library Lib4PrM implementing Parareal is\ncombined with the UG4 simulation framework, which provides the spatial\ndiscretization and parallelization. The combination's performance is studied\nwith respect to convergence and speedup. It is confirmed that anisotropies in\nthe domain and jumps in diffusion coefficients only have a minor impact on\nParareal's convergence. The influence of load imbalances in time due to\ndifferences in number of iterations required by the spatial solver as well as\nspatio-temporal weak scaling is discussed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 13:21:09 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 13:23:04 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Kreienbuehl", "Andreas", ""], ["Naegel", "Arne", ""], ["Ruprecht", "Daniel", ""], ["Speck", "Robert", ""], ["Wittum", "Gabriel", ""], ["Krause", "Rolf", ""]]}, {"id": "1502.03805", "submitter": "Yuanyi Xue", "authors": "Yuanyi Xue and Yao Wang", "title": "eOMP: Finding Sparser Representation by Recursively Orthonormalizing the\n  Remaining Atoms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greedy algorithms for minimizing L0-norm of sparse decomposition have\nprofound application impact on many signal processing problems. In the sparse\ncoding setup, given the observations $\\mathrm{y}$ and the redundant dictionary\n$\\mathbf{\\Phi}$, one would seek the most sparse coefficient (signal)\n$\\mathrm{x}$ with a constraint on approximation fidelity. In this work, we\npropose a greedy algorithm based on the classic orthogonal matching pursuit\n(OMP) with improved sparsity on $\\mathrm{x}$ and better recovery rate, which we\nname as eOMP. The key ingredient of the eOMP is recursively performing one-step\northonormalization on the remaining atoms, and evaluating correlations between\nresidual and orthonormalized atoms. We show a proof that the proposed eOMP\nguarantees to maximize the residual reduction at each iteration. Through\nextensive simulations, we show the proposed algorithm has better exact recovery\nrate on i.i.d. Gaussian ensembles with Gaussian signals, and more importantly\nyields smaller L0-norm under the same approximation fidelity compared to the\noriginal OMP, for both synthetic and practical scenarios. The complexity\nanalysis and real running time result also show a manageable complexity\nincrease over the original OMP. We claim that the proposed algorithm has better\npractical perspective for finding more sparse representations than existing\ngreedy algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 20:50:06 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Xue", "Yuanyi", ""], ["Wang", "Yao", ""]]}, {"id": "1502.04390", "submitter": "Yann Dauphin", "authors": "Yann N. Dauphin, Harm de Vries, Yoshua Bengio", "title": "Equilibrated adaptive learning rates for non-convex optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter-specific adaptive learning rate methods are computationally\nefficient ways to reduce the ill-conditioning problems encountered when\ntraining large deep networks. Following recent work that strongly suggests that\nmost of the critical points encountered when training such networks are saddle\npoints, we find how considering the presence of negative eigenvalues of the\nHessian could help us design better suited adaptive learning rate schemes. We\nshow that the popular Jacobi preconditioner has undesirable behavior in the\npresence of both positive and negative curvature, and present theoretical and\nempirical evidence that the so-called equilibration preconditioner is\ncomparatively better suited to non-convex problems. We introduce a novel\nadaptive learning rate scheme, called ESGD, based on the equilibration\npreconditioner. Our experiments show that ESGD performs as well or better than\nRMSProp in terms of convergence speed, always clearly improving over plain\nstochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Sun, 15 Feb 2015 23:41:33 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2015 23:04:39 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Dauphin", "Yann N.", ""], ["de Vries", "Harm", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1502.04689", "submitter": "Zemin Zhang", "authors": "Zemin Zhang, Shuchin Aeron", "title": "Exact tensor completion using t-SVD", "comments": "16 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the problem of completion of multidimensional\narrays (also referred to as tensors) from limited sampling. Our approach is\nbased on a recently proposed tensor-Singular Value Decomposition (t-SVD) [1].\nUsing this factorization one can derive notion of tensor rank, referred to as\nthe tensor tubal rank, which has optimality properties similar to that of\nmatrix rank derived from SVD. As shown in [2] some multidimensional data, such\nas panning video sequences exhibit low tensor tubal rank and we look at the\nproblem of completing such data under random sampling of the data cube. We show\nthat by solving a convex optimization problem, which minimizes the tensor\nnuclear norm obtained as the convex relaxation of tensor tubal rank, one can\nguarantee recovery with overwhelming probability as long as samples in\nproportion to the degrees of freedom in t-SVD are observed. In this sense our\nresults are order-wise optimal. The conditions under which this result holds\nare very similar to the incoherency conditions for the matrix completion,\nalbeit we define incoherency under the algebraic set-up of t-SVD. We show the\nperformance of the algorithm on some real data sets and compare it with other\nexisting approaches based on tensor flattening and Tucker decomposition.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 20:37:35 GMT"}, {"version": "v2", "created": "Fri, 27 Feb 2015 19:31:25 GMT"}], "update_date": "2015-03-02", "authors_parsed": [["Zhang", "Zemin", ""], ["Aeron", "Shuchin", ""]]}, {"id": "1502.04749", "submitter": "Rachel Slaybaugh", "authors": "S. C. Wilson, R. N. Slaybaugh", "title": "Improved Monte Carlo Variance Reduction for Space and Energy\n  Self-Shielding", "comments": "20 pages, 22 figures, 7 tables", "journal-ref": "Nuclear Science and Engineering, 179, 22--41 (2015)", "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continued demand for accurate and computationally efficient transport methods\nto solve optically thick, fixed-source transport problems has inspired research\non variance-reduction (VR) techniques for Monte Carlo (MC). Methods that use\ndeterministic results to create VR maps for MC constitute a dominant branch of\nthis research, with Forward Weighted-Consistent Adjoint Driven Importance\nSampling (FW-CADIS) being a particularly successful example. However, locations\nin which energy and spatial self-shielding are combined, such as thin plates\nembedded in concrete, challenge FW-CADIS. In these cases the deterministic flux\ncannot appropriately capture transport behavior, and the associated VR\nparameters result in high variance in and following the plate.\n  This work presents a new method that improves performance in transport\ncalculations that contain regions of combined space and energy self-shielding\nwithout significant impact on the solution quality in other parts of the\nproblem. This method is based on FW-CADIS and applies a Resonance Factor\ncorrection to the adjoint source. The impact of the Resonance Factor method is\ninvestigated in this work through an example problem. It is clear that this new\nmethod dramatically improves performance in terms of lowering the maximum 95%\nconfidence interval relative error and reducing the compute time. Based on this\nwork, we recommend that the Resonance Factor method be used when the accuracy\nof the solution in the presence of combined space and energy self-shielding is\nimportant.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 23:16:36 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Wilson", "S. C.", ""], ["Slaybaugh", "R. N.", ""]]}, {"id": "1502.05197", "submitter": "Silvia Tozza", "authors": "Silvia Tozza and Maurizio Falcone", "title": "Analysis and approximation of some Shape-from-Shading models for\n  non-Lambertian surfaces", "comments": "Accepted version to Journal of Mathematical Imaging and Vision, 57\n  pages", "journal-ref": null, "doi": null, "report-no": "Roma01.Math.NA", "categories": "math.NA cs.CV cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconstruction of a 3D object or a scene is a classical inverse problem\nin Computer Vision. In the case of a single image this is called the\nShape-from-Shading (SfS) problem and it is known to be ill-posed even in a\nsimplified version like the vertical light source case. A huge number of works\ndeals with the orthographic SfS problem based on the Lambertian reflectance\nmodel, the most common and simplest model which leads to an eikonal type\nequation when the light source is on the vertical axis. In this paper we want\nto study non-Lambertian models since they are more realistic and suitable\nwhenever one has to deal with different kind of surfaces, rough or specular. We\nwill present a unified mathematical formulation of some popular orthographic\nnon-Lambertian models, considering vertical and oblique light directions as\nwell as different viewer positions. These models lead to more complex\nstationary nonlinear partial differential equations of Hamilton-Jacobi type\nwhich can be regarded as the generalization of the classical eikonal equation\ncorresponding to the Lambertian case. However, all the equations corresponding\nto the models considered here (Oren-Nayar and Phong) have a similar structure\nso we can look for weak solutions to this class in the viscosity solution\nframework. Via this unified approach, we are able to develop a semi-Lagrangian\napproximation scheme for the Oren-Nayar and the Phong model and to prove a\ngeneral convergence result. Numerical simulations on synthetic and real images\nwill illustrate the effectiveness of this approach and the main features of the\nscheme, also comparing the results with previous results in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 12:24:41 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 18:49:24 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Tozza", "Silvia", ""], ["Falcone", "Maurizio", ""]]}, {"id": "1502.05880", "submitter": "Helio M. de Oliveira", "authors": "R.C. de Oliveira, H.M. de Oliveira, R.M. Campello de Souza and E.J.P.\n  Santos", "title": "A Flexible Implementation of a Matrix Laurent Series-Based 16-Point Fast\n  Fourier and Hartley Transforms", "comments": "4 pages, 4 figures. IEEE VI Southern Programmable Logic Conference\n  2010", "journal-ref": null, "doi": "10.1109/SPL.2010.5483017", "report-no": null, "categories": "cs.NA cs.DM eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a flexible architecture for implementing a new fast\ncomputation of the discrete Fourier and Hartley transforms, which is based on a\nmatrix Laurent series. The device calculates the transforms based on a single\nbit selection operator. The hardware structure and synthesis are presented,\nwhich handled a 16-point fast transform in 65 nsec, with a Xilinx SPARTAN 3E\ndevice.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 14:14:50 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["de Oliveira", "R. C.", ""], ["de Oliveira", "H. M.", ""], ["de Souza", "R. M. Campello", ""], ["Santos", "E. J. P.", ""]]}, {"id": "1502.06164", "submitter": "Kalyana Babu Nakshatrala", "authors": "M. K. Mudunuru, and K. B. Nakshatrala", "title": "On mesh restrictions to satisfy comparison principles, maximum\n  principles, and the non-negative constraint: Recent developments and new\n  results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns with mesh restrictions that are needed to satisfy several\nimportant mathematical properties -- maximum principles, comparison principles,\nand the non-negative constraint -- for a general linear second-order elliptic\npartial differential equation. We critically review some recent developments in\nthe field of discrete maximum principles, derive new results, and discuss some\npossible future research directions in this area. In particular, we derive\nrestrictions for a three-node triangular (T3) element and a four-node\nquadrilateral (Q4) element to satisfy comparison principles, maximum\nprinciples, and the non-negative constraint under the standard single-field\nGalerkin formulation. Analysis is restricted to uniformly elliptic linear\ndifferential operators in divergence form with Dirichlet boundary conditions\nspecified on the entire boundary of the domain. Various versions of maximum\nprinciples and comparison principles are discussed in both continuous and\ndiscrete settings. In the literature, it is well-known that an acute-angled\ntriangle is sufficient to satisfy the discrete weak maximum principle for pure\nisotropic diffusion. An iterative algorithm is developed to construct\nsimplicial meshes that preserves discrete maximum principles using existing\nopen source mesh generators. Various numerical examples based on different\ntypes of triangulations are presented to show the pros and cons of placing\nrestrictions on a computational mesh. We also quantify local and global mass\nconservation errors using representative numerical examples, and illustrate the\nperformance of metric-based meshes with respect to mass conservation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2015 01:42:34 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Mudunuru", "M. K.", ""], ["Nakshatrala", "K. B.", ""]]}, {"id": "1502.06220", "submitter": "Yaniv Romano", "authors": "Yaniv Romano and Michael Elad", "title": "Boosting of Image Denoising Algorithms", "comments": "33 pages, 9 figures, 3 tables, submitted to SIAM Journal on Imaging\n  Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a generic recursive algorithm for improving image\ndenoising methods. Given the initial denoised image, we suggest repeating the\nfollowing \"SOS\" procedure: (i) (S)trengthen the signal by adding the previous\ndenoised image to the degraded input image, (ii) (O)perate the denoising method\non the strengthened image, and (iii) (S)ubtract the previous denoised image\nfrom the restored signal-strengthened outcome. The convergence of this process\nis studied for the K-SVD image denoising and related algorithms. Still in the\ncontext of K-SVD image denoising, we introduce an interesting interpretation of\nthe SOS algorithm as a technique for closing the gap between the local\npatch-modeling and the global restoration task, thereby leading to improved\nperformance. In a quest for the theoretical origin of the SOS algorithm, we\nprovide a graph-based interpretation of our method, where the SOS recursive\nupdate effectively minimizes a penalty function that aims to denoise the image,\nwhile being regularized by the graph Laplacian. We demonstrate the SOS boosting\nalgorithm for several leading denoising methods (K-SVD, NLM, BM3D, and EPLL),\nshowing tendency to further improve denoising performance.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2015 12:40:48 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2015 13:49:42 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Romano", "Yaniv", ""], ["Elad", "Michael", ""]]}, {"id": "1502.06569", "submitter": "Mohamed Ali", "authors": "M. S. Ali, A. M. Yasser", "title": "Spectra of quark-antiquark bound states via two derived QCD potential", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph cs.NA hep-th math.NA nucl-th physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current paper, we propose two types of quark-antiquark interactions,\nwhich may be tailored to describe various meson sectors. The interactions\ncontain Quantum Chromodynamics (QCD) inspired components, such as the\nCoulomb-like interaction, the confinement linear potential, and the spin-spin\ninteraction. Our scheme relies on the non-relativistic quark model through the\nintroduction of two derived QCD potential models. The application of the two\nproposed potentials resulted in spectra for quark-antiquark bound states, which\nare compared with published experimental data. We found that one of the two\npotentials is favored over the other in terms of high precision comparisons.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 23:25:47 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Ali", "M. S.", ""], ["Yasser", "A. M.", ""]]}, {"id": "1502.06777", "submitter": "Jose Henrique De Morais Goulart", "authors": "Jos\\'e Henrique De Morais Goulart, Maxime Boizard (SATIE), R\\'emy\n  Boyer, G\\'erard Favier, Pierre Comon (GIPSA-CICS)", "title": "Statistical efficiency of structured cpd estimation applied to\n  Wiener-Hammerstein modeling", "comments": "Accepted for publication in the Proceedings of the European Signal\n  Processing Conference (EUSIPCO) Aug 2015, Nice, France. 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of a structured canonical polyadic decomposition (CPD) is\nuseful to address several important modeling problems in real-world\napplications. In this paper, we consider the identification of a nonlinear\nsystem by means of a Wiener-Hammerstein model, assuming a high-order Volterra\nkernel of that system has been previously estimated. Such a kernel, viewed as a\ntensor, admits a CPD with banded circulant factors which comprise the model\nparameters. To estimate them, we formulate specialized estimators based on\nrecently proposed algorithms for the computation of structured CPDs. Then,\nconsidering the presence of additive white Gaussian noise, we derive a\nclosed-form expression for the Cramer-Rao bound (CRB) associated with this\nestimation problem. Finally, we assess the statistical performance of the\nproposed estimators via Monte Carlo simulations, by comparing their mean-square\nerror with the CRB.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 12:07:50 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2015 09:34:07 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Goulart", "Jos\u00e9 Henrique De Morais", "", "SATIE"], ["Boizard", "Maxime", "", "SATIE"], ["Boyer", "R\u00e9my", "", "GIPSA-CICS"], ["Favier", "G\u00e9rard", "", "GIPSA-CICS"], ["Comon", "Pierre", "", "GIPSA-CICS"]]}, {"id": "1502.06795", "submitter": "Christian David", "authors": "Albert Cohen (LPMC), Ronald Devore (TAMU)", "title": "Kolmogorov widths under holomorphic mappings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If $L$ is a bounded linear operator mapping the Banach space $X$ into the\nBanach space $Y$ and $K$ is a compact set in $X$, then the Kolmogorov widths of\nthe image $L(K)$ do not exceed those of $K$ multiplied by the norm of $L$. We\nextend this result from linear maps to holomorphic mappings $u$ from $X$ to $Y$\nin the following sense: when the $n$ widths of $K$ are $O(n^{-r})$ for some\n$r\\textgreater{}1$, then those of $u(K)$ are $O(n^{-s})$ for any $s \\textless{}\nr-1$, We then use these results to prove various theorems about Kolmogorov\nwidths of manifolds consisting of solutions to certain parametrized PDEs.\nResults of this type are important in the numerical analysis of reduced bases\nand other reduced modeling methods, since the best possible performance of such\nmethods is governed by the rate of decay of the Kolmogorov widths of the\nsolution manifold.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 13:09:35 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Cohen", "Albert", "", "LPMC"], ["Devore", "Ronald", "", "TAMU"]]}, {"id": "1502.06797", "submitter": "Christian David", "authors": "Albert Cohen (LPMC), Ronald Devore (TAMU)", "title": "Approximation of high-dimensional parametric PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametrized families of PDEs arise in various contexts such as inverse\nproblems, control and optimization, risk assessment, and uncertainty\nquantification. In most of these applications, the number of parameters is\nlarge or perhaps even infinite. Thus, the development of numerical methods for\nthese parametric problems is faced with the possible curse of dimensionality.\nThis article is directed at (i) identifying and understanding which properties\nof parametric equations allow one to avoid this curse and (ii) developing and\nanalyzing effective numerical methodd which fully exploit these properties and,\nin turn, are immune to the growth in dimensionality. The first part of this\narticle studies the smoothness and approximability of the solution map, that\nis, the map $a\\mapsto u(a)$ where $a$ is the parameter value and $u(a)$ is the\ncorresponding solution to the PDE. It is shown that for many relevant\nparametric PDEs, the parametric smoothness of this map is typically holomorphic\nand also highly anisotropic in that the relevant parameters are of widely\nvarying importance in describing the solution. These two properties are then\nexploited to establish convergence rates of $n$-term approximations to the\nsolution map for which each term is separable in the parametric and physical\nvariables. These results reveal that, at least on a theoretical level, the\nsolution map can be well approximated by discretizations of moderate\ncomplexity, thereby showing how the curse of dimensionality is broken. This\ntheoretical analysis is carried out through concepts of approximation theory\nsuch as best $n$-term approximation, sparsity, and $n$-widths. These notions\ndetermine a priori the best possible performance of numerical methods and thus\nserve as a benchmark for concrete algorithms. The second part of this article\nturns to the development of numerical algorithms based on the theoretically\nestablished sparse separable approximations. The numerical methods studied fall\ninto two general categories. The first uses polynomial expansions in terms of\nthe parameters to approximate the solution map. The second one searches for\nsuitable low dimensional spaces for simultaneously approximating all members of\nthe parametric family. The numerical implementation of these approaches is\ncarried out through adaptive and greedy algorithms. An a priori analysis of the\nperformance of these algorithms establishes how well they meet the theoretical\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 13:10:32 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2015 14:09:11 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Cohen", "Albert", "", "LPMC"], ["Devore", "Ronald", "", "TAMU"]]}, {"id": "1502.07167", "submitter": "George Ovchinnikov", "authors": "I.V. Oseledets, G.V. Ovchinnikov, A. M. Katrutsa", "title": "Linear complexity SimRank computation based on the iterative diagonal\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deterministic linear time complexity IDE-SimRank method\nto approximately compute SimRank with proved error bound. SimRank is a\nwell-known similarity measure between graph vertices which relies on graph\ntopology only and is built on intuition that \"two objects are similar if they\nare related to similar objects\". The fixed point equation for direct SimRank\ncomputation is the discrete Lyapunov equation with specific diagonal matrix in\nthe right hand side. The proposed method is based on estimation of this\ndiagonal matrix with GMRES and use this estimation to compute singe-source and\nsingle pairs queries. These computations are executed with the part of series\nconverging to the discrete Lyapunov equation solution.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 14:08:13 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Oseledets", "I. V.", ""], ["Ovchinnikov", "G. V.", ""], ["Katrutsa", "A. M.", ""]]}, {"id": "1502.07838", "submitter": "Alexander Mikhalev Dr", "authors": "A. Mikhalev, I. V. Oseledets", "title": "Rectangular maximum-volume submatrices and their applications", "comments": "29 pages, 1 figure, 3 tables, submitted to Linear Algebra and its\n  Applications", "journal-ref": "Linear Algebra and its Applications, Volume 538, 1 February 2018,\n  Pages 187-211", "doi": "10.1016/j.laa.2017.10.014", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a definition of the volume for a general rectangular matrix,\nwhich for square matrices is equivalent to the absolute value of the\ndeterminant. We generalize results for square maximum-volume submatrices to the\ncase of rectangular maximal-volume submatrices, show connection of the\nrectangular volume with optimal experimental design and provide estimates for\nthe growth of the coefficients and approximation error in spectral and\nChebyshev norms. Three promising applications of such submatrices are\npresented: recommender systems, finding maximal elements in low-rank matrices\nand preconditioning of overdetermined linear systems. The code is available\nonline.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 09:29:07 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 07:08:20 GMT"}, {"version": "v3", "created": "Thu, 11 May 2017 14:33:59 GMT"}, {"version": "v4", "created": "Mon, 27 Nov 2017 14:03:03 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Mikhalev", "A.", ""], ["Oseledets", "I. V.", ""]]}, {"id": "1502.08014", "submitter": "S S Ahmad", "authors": "Sk. Safique Ahmad and Istkhar Ali", "title": "Localization theorems for matrices and bounds for the zeros of\n  polynomials over a quaternion division algebra", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, Ostrowski and Brauer type theorems are derived for the left\nand right eigenvalues of a quaternionic matrix. Generalizations of Gerschgorin\ntype theorems are discussed for the left and the right eigenvalues of a\nquaternionic matrix. Thereafter a sufficient condition for the stability of a\nquaternionic matrix is given that generalizes the stability condition for a\ncomplex matrix. Finally, a characterization of bounds for the zeros of\nquaternionic polynomials is presented.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jan 2015 06:58:38 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2015 04:49:48 GMT"}, {"version": "v3", "created": "Mon, 19 Sep 2016 09:34:05 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Ahmad", "Sk. Safique", ""], ["Ali", "Istkhar", ""]]}]