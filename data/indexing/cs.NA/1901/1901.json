[{"id": "1901.00201", "submitter": "Petr N. Vabishchevich", "authors": "Raimondas Ciegis and Petr Vabishchevich", "title": "High order numerical schemes for solving fractional powers of elliptic\n  operators", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many recent applications when new materials and technologies are developed\nit is important to describe and simulate new nonlinear and nonlocal diffusion\ntransport processes. A general class of such models deals with nonlocal\nfractional power elliptic operators. In order to solve these problems\nnumerically it is proposed (Petr N. Vabishchevich, Journal of Computational\nPhysics. 2015, Vol. 282, No.1, pp.289--302) to consider equivalent local\nnonstationary initial value pseudo-parabolic problems. Previously such problems\nwere solved by using the standard implicit backward and symmetrical Euler\nmethods. In this paper we use the one-parameter family of three-level finite\ndifference schemes for solving the initial value problem for the first order\nnonstationary pseudo-parabolic problem. The fourth-order approximation scheme\nis developed by selecting the optimal value of the weight parameter. The\nresults of the theoretical analysis are supplemented by results of extensive\ncomputational experiments.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 19:20:09 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Ciegis", "Raimondas", ""], ["Vabishchevich", "Petr", ""]]}, {"id": "1901.00377", "submitter": "Victor Pan", "authors": "Victor Y. Pan and, Jonh Svadlenka", "title": "QRP Variation of Cross--Approximation Iterations for Low Rank\n  Approximation", "comments": "6 pages. arXiv admin note: substantial text overlap with\n  arXiv:1710.07946", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We call matrix algorithms superfast if they use much fewer flops and memory\ncells than the input matrix has entries. Using such algorithms is indispensable\nfor Big Data Mining and Analysis, where the input matrices are so immense that\none can only access a small fraction of all their entries. A natural remedy is\nLow Rank Approximation (LRA) of these matrices, which is routinely computed by\nmeans of Cross-Approximation iterations for more than a decade of worldwide\napplication in computational practice. We point out and extensively test an\nimportant application of superfast LRA to significant acceleration of the\ncelebrated Fast Multipole Method, which turns it into Superfast Multipole\nMethod.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 19:58:14 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 15:13:10 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["and", "Victor Y. Pan", ""], ["Svadlenka", "Jonh", ""]]}, {"id": "1901.00485", "submitter": "Yuyang Wang", "authors": "Alan Edelman, Yuyang Wang", "title": "The GSVD: Where are the ellipses?, Matrix Trigonometry, and more", "comments": "31 pages", "journal-ref": "SIAM Journal on Matrix Analysis and Applications (2020) 41(4)", "doi": "10.1137/18M1234412", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an advanced mathematical theory of the Generalized\nSingular Value Decomposition (GSVD) and its applications. We explore the\ngeometry of the GSVD which provides a long sought for ellipse picture which\nincludes a horizontal and a vertical multiaxis. We further propose that the\nGSVD provides natural coordinates for the Grassmann manifold. This paper proves\na theorem showing how the finite generalized singular values do or do not\nrelate to the singular values of $AB^\\dagger$.\n  We then turn to the applications arguing that this geometrical theory is\nnatural for understanding existing applications and recognizing opportunities\nfor new applications. In particular the generalized singular vectors play a\ndirect and as natural a mathematical role for certain applications as the\nsingular vectors do for the SVD. In the same way that experts on the SVD often\nprefer not to cast SVD problems as eigenproblems, we propose that the GSVD,\noften cast as a generalized eigenproblem, is rather best cast in its natural\nsetting.\n  We illustrate this theoretical approach and the natural multiaxes (with\nlabels from technical domains) in the context of applications where the GSVD\narises: Tikhonov regularization (unregularized vs regularization), Genome\nReconstruction (humans vs yeast), Signal Processing (signal vs noise), and\nstatistical analysis such as ANOVA and discriminant analysis (between clusters\nvs within clusters.) With the aid of our ellipse figure, we encourage in the\nfuture the labelling of the natural multiaxes in any GSVD problem.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 18:36:17 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 04:25:46 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 19:21:30 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 21:54:32 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Edelman", "Alan", ""], ["Wang", "Yuyang", ""]]}, {"id": "1901.00564", "submitter": "Yuan Su", "authors": "Andrew M. Childs and Yuan Su", "title": "Nearly optimal lattice simulation by product formulas", "comments": "24 pages, 3 figures", "journal-ref": "Phys. Rev. Lett. 123, 050503 (2019)", "doi": "10.1103/PhysRevLett.123.050503", "report-no": null, "categories": "quant-ph cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider simulating an $n$-qubit Hamiltonian with nearest-neighbor\ninteractions evolving for time $t$ on a quantum computer. We show that this\nsimulation has gate complexity $(nt)^{1+o(1)}$ using product formulas, a\nstraightforward approach that has been demonstrated by several experimental\ngroups. While it is reasonable to expect this complexity---in particular, this\nwas claimed without rigorous justification by Jordan, Lee, and Preskill---we\nare not aware of a straightforward proof. Our approach is based on an analysis\nof the local error structure of product formulas, as introduced by Descombes\nand Thalhammer and further simplified here. We prove error bounds for canonical\nproduct formulas, which include well-known constructions such as the\nLie-Trotter-Suzuki formulas. We also develop a local error representation for\ntime-dependent Hamiltonian simulation, and we discuss generalizations to\nperiodic boundary conditions, constant-range interactions, and higher\ndimensions. Combined with a previous lower bound, our result implies that\nproduct formulas can simulate lattice Hamiltonians with nearly optimal gate\ncomplexity.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 00:45:45 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 19:01:16 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Childs", "Andrew M.", ""], ["Su", "Yuan", ""]]}, {"id": "1901.00618", "submitter": "Zhongjian Wang", "authors": "Zhongjian Wang, Zhiwen Zhang", "title": "A mesh-free method for interface problems using the deep learning\n  approach", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.108963", "report-no": null, "categories": "physics.comp-ph cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a mesh-free method to solve interface problems\nusing the deep learning approach. Two interface problems are considered. The\nfirst one is an elliptic PDE with a discontinuous and high-contrast\ncoefficient. While the second one is a linear elasticity equation with\ndiscontinuous stress tensor. In both cases, we formulate the PDEs into\nvariational problems, which can be solved via the deep learning approach. To\ndeal with the inhomogeneous boundary conditions, we use a shallow neuron\nnetwork to approximate the boundary conditions. Instead of using an adaptive\nmesh refinement method or specially designed basis functions or numerical\nschemes to compute the PDE solutions, the proposed method has the advantages\nthat it is easy to implement and mesh-free. Finally, we present numerical\nresults to demonstrate the accuracy and efficiency of the proposed method for\ninterface problems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 06:00:35 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Wang", "Zhongjian", ""], ["Zhang", "Zhiwen", ""]]}, {"id": "1901.00682", "submitter": "Jongho Park", "authors": "Chang-Ock Lee, Jongho Park", "title": "A Finite Element Nonoverlapping Domain Decomposition Method with\n  Lagrange Multipliers for the Dual Total Variation Minimizations", "comments": "26 pages, 8 figures", "journal-ref": "J. Sci. Comput. 81 (2019) 2331--2355", "doi": "10.1007/s10915-019-01085-z", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a primal-dual domain decomposition method for\ntotal variation regularized problems appearing in mathematical image\nprocessing. The model problem is transformed into an equivalent constrained\nminimization problem by tearing-and-interconnecting domain decomposition. Then,\nthe continuity constraints on the subdomain interfaces are treated by\nintroducing Lagrange multipliers. The resulting saddle point problem is solved\nby the first order primal-dual algorithm. We apply the proposed method to image\ndenoising, inpainting, and segmentation problems with either $L^2$-fidelity or\n$L^1$-fidelity. Numerical results show that the proposed method outperforms the\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 11:15:00 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 04:08:13 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Lee", "Chang-Ock", ""], ["Park", "Jongho", ""]]}, {"id": "1901.00725", "submitter": "Jan Helmig", "authors": "Jan Helmig, Marek Behr, Stefanie Elgeti", "title": "Boundary-Conforming Finite Element Methods for Twin-Screw Extruders:\n  Unsteady - Temperature-Dependent - Non-Newtonian Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a boundary-conforming space-time finite element method to compute\nthe flow inside co-rotating, self-wiping twin-screw extruders. The mesh update\nis carried out using the newly developed Snapping Reference Mesh Update Method\n(SRMUM). It allows to compute time-dependent flow solutions inside twin-screw\nextruders equipped with conveying screw elements without any need for\nre-meshing and projections of solutions - making it a very efficient method. We\nprovide cases for Newtonian and non-Newtonian fluids in 2D and 3D, that show\nmesh convergence of the solution as well as agreement to experimental results.\nFurthermore, a complex, unsteady and temperature-dependent 3D test case with\nmultiple screw elements illustrates the potential of the method also for\nindustrial applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 18:06:24 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Helmig", "Jan", ""], ["Behr", "Marek", ""], ["Elgeti", "Stefanie", ""]]}, {"id": "1901.00759", "submitter": "Sebastian Sch\\\"ops", "authors": "Annalisa Buffa, Jacopo Corno, Carlo de Falco, Sebastian Sch\\\"ops,\n  Rafael V\\'azquez", "title": "Isogeometric Mortar Coupling for Electromagnetic Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses and analyses two domain decomposition approaches for\nelectromagnetic problems that allow the combination of domains discretised by\neither N\\'ed\\'elec-type polynomial finite elements or spline-based isogeometric\nanalysis. The first approach is a new isogeometric mortar method and the second\none is based on a modal basis for the Lagrange multiplier space, called\nstate-space concatenation in the engineering literature. Spectral correctness\nand in particular inf-sup stability of both approaches are analytically and\nnumerically investigated. The new mortar method is shown to be unconditionally\nstable. Its construction of the discrete Lagrange multiplier space takes\nadvantage of the high continuity of splines, and does not have an analogue for\nN\\'ed\\'elec finite elements. On the other hand, the approach with modal basis\nis easier to implement but relies on application knowledge to ensure stability\nand correctness.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 20:10:54 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Buffa", "Annalisa", ""], ["Corno", "Jacopo", ""], ["de Falco", "Carlo", ""], ["Sch\u00f6ps", "Sebastian", ""], ["V\u00e1zquez", "Rafael", ""]]}, {"id": "1901.00917", "submitter": "Reza Ghaffari", "authors": "Reza Ghaffari, Roger A. Sauer", "title": "A nonlinear thermomechanical formulation for anisotropic volume and\n  surface continua", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A thermomechanical, polar continuum formulation under finite strains is\nproposed for anisotropic materials using a multiplicative decomposition of the\ndeformation gradient. First, the kinematics and conservation laws for three\ndimensional, polar and non-polar continua are obtained. Next, these kinematics\nare connected to their corresponding counterparts for surface continua based on\nKirchhoff-Love kinematics. Likewise, the conservation laws for Kirchhoff-Love\nshells are derived from their three dimensional counterparts. From this, the\nweak forms are obtained for three dimensional non-polar continua and\nKirchhoff-Love shells. These formulations are expressed in tensorial form so\nthat they can be used in both curvilinear and Cartesian coordinates. They can\nbe used to model anisotropic crystals and soft biological materials, and they\ncan be extended to other field equations, like Maxwell's equations to model\nthermo-electro-magneto-mechanical materials.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 21:22:56 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Ghaffari", "Reza", ""], ["Sauer", "Roger A.", ""]]}, {"id": "1901.00961", "submitter": "Jin-Peng Liu", "authors": "Andrew M. Childs and Jin-Peng Liu", "title": "Quantum spectral methods for differential equations", "comments": "29 pages", "journal-ref": null, "doi": "10.1007/s00220-020-03699-z", "report-no": null, "categories": "quant-ph cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed quantum algorithms address computational challenges in\nnumerical analysis by performing linear algebra in Hilbert space. Such\nalgorithms can produce a quantum state proportional to the solution of a\n$d$-dimensional system of linear equations or linear differential equations\nwith complexity $\\mathrm{poly}(\\log d)$. While several of these algorithms\napproximate the solution to within $\\epsilon$ with complexity\n$\\mathrm{poly}(\\log(1/\\epsilon))$, no such algorithm was previously known for\ndifferential equations with time-dependent coefficients. Here we develop a\nquantum algorithm for linear ordinary differential equations based on so-called\nspectral methods, an alternative to finite difference methods that approximates\nthe solution globally. Using this approach, we give a quantum algorithm for\ntime-dependent initial and boundary value problems with complexity\n$\\mathrm{poly}(\\log d, \\log(1/\\epsilon))$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 01:04:00 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Childs", "Andrew M.", ""], ["Liu", "Jin-Peng", ""]]}, {"id": "1901.01188", "submitter": "Agnieszka Miedlar", "authors": "Yousef Saad, Mohamed El-Guide, and Agnieszka Mi\\k{e}dlar", "title": "A rational approximation method for the nonlinear eigenvalue problem", "comments": "26 pages; 26 figures; journal article", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for computing eigenvalues and eigenvectors for\nsome types of nonlinear eigenvalue problems. The main idea is to approximate\nthe functions involved in the eigenvalue problem by rational functions and then\napply a form of linearization. Eigenpairs of the expanded form of this\nlinearization are not extracted directly. Instead, its structure is exploited\nto develop a scheme that allows to extract all eigenvalues in a certain region\nof the complex plane by solving an eigenvalue problem of much smaller\ndimension. Because of its simple implementation and the ability to work\nefficiently in large dimensions, the presented method is appealing when solving\nchallenging engineering problems. A few theoretical results are established to\nexplain why the new approach works and numerical experiments are presented to\nvalidate the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 16:03:04 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 15:58:07 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Saad", "Yousef", ""], ["El-Guide", "Mohamed", ""], ["Mi\u0119dlar", "Agnieszka", ""]]}, {"id": "1901.01600", "submitter": "Lutz K\\\"ammerer", "authors": "Maximilian Bochmann and Lutz K\\\"ammerer and Daniel Potts", "title": "A sparse FFT approach for ODE with random coefficients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a general strategy to solve ordinary differential\nequations (ODE), where some coefficient depend on the spatial variable and on\nadditional random variables. The approach is based on the application of a\nrecently developed dimension-incremental sparse fast Fourier transform. Since\nsuch algorithms require periodic signals, we discuss periodization strategies\nand associated necessary deperiodization modifications within the occuring\nsolution steps.\n  The computed approximate solutions of the ODE depend on the spatial variable\nand on the random variables as well. Certainly, one of the crucial challenges\nof the high dimensional approximation process is to rate the influence of each\nvariable on the solution as well as the determination of the relations and\ncouplings within the set of variables. The suggested approach meets these\nchallenges in a full automatic manner with reasonable computational costs,\ni.e., in contrast to already existing approaches, one does not need to\nseriously restrict the used set of ansatz functions in advance.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jan 2019 19:54:46 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 07:02:36 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Bochmann", "Maximilian", ""], ["K\u00e4mmerer", "Lutz", ""], ["Potts", "Daniel", ""]]}, {"id": "1901.01648", "submitter": "Keith Patarroyo", "authors": "Keith Y. Patarroyo", "title": "A digression on Hermite polynomials", "comments": "43 pages, 4 figures, survey article", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal polynomials are of fundamental importance in many fields of\nmathematics and science, therefore the study of a particular family is always\nrelevant. In this manuscript, we present a survey of some general results of\nthe Hermite polynomials and show a few of their applications in the connection\nproblem of polynomials, probability theory and the combinatorics of a simple\ngraph. Most of the content presented here is well known, except for a few\nsections where we add our own work to the subject, nevertheless, the text is\nmeant to be a self-contained personal exposition.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 02:40:39 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 23:40:40 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Patarroyo", "Keith Y.", ""]]}, {"id": "1901.01652", "submitter": "Longhao Yuan", "authors": "Longhao Yuan, Chao Li, Jianting Cao and Qibin Zhao", "title": "Randomized Tensor Ring Decomposition and Its Application to Large-scale\n  Data Reconstruction", "comments": "ICASSP submission", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682197", "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is an essential technique for multi-way large-scale\ndata, i.e., tensor. Tensor ring (TR) decomposition has become popular due to\nits high representation ability and flexibility. However, the traditional TR\ndecomposition algorithms suffer from high computational cost when facing\nlarge-scale data. In this paper, taking advantages of the recently proposed\ntensor random projection method, we propose two TR decomposition algorithms. By\nemploying random projection on every mode of the large-scale tensor, the TR\ndecomposition can be processed at a much smaller scale. The simulation\nexperiment shows that the proposed algorithms are $4-25$ times faster than\ntraditional algorithms without loss of accuracy, and our algorithms show\nsuperior performance in deep learning dataset compression and hyperspectral\nimage reconstruction experiments compared to other randomized algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 03:01:06 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Yuan", "Longhao", ""], ["Li", "Chao", ""], ["Cao", "Jianting", ""], ["Zhao", "Qibin", ""]]}, {"id": "1901.01685", "submitter": "Roel Tielen", "authors": "R. Tielen, M. M\\\"oller, D. G\\\"oddeke and C. Vuik", "title": "A p-multigrid method enhanced with an ILUT smoother and its comparison\n  to h-multigrid methods within Isogeometric Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, Isogeometric Analysis has shown to be a successful\nalternative to the Finite Element Method (FEM). However, solving the resulting\nlinear systems of equations efficiently remains a challenging task. In this\npaper, we consider a p-multigrid method, in which coarsening is applied in the\napproximation order p instead of the mesh width h. Since the use of classical\nsmoothers (e.g. Gauss-Seidel) results in a p-multigrid method with\ndeteriorating performance for higher values of p, the use of an ILUT smoother\nis investigated. Numerical results and a spectral analysis indicate that the\nresulting p-multigrid method exhibits convergence rates independent of h and p.\nIn particular, we compare both coarsening strategies (e.g. coarsening in h or\np) adopting both smoothers for a variety of two and threedimensional\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 07:13:58 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 07:35:30 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 12:15:23 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Tielen", "R.", ""], ["M\u00f6ller", "M.", ""], ["G\u00f6ddeke", "D.", ""], ["Vuik", "C.", ""]]}, {"id": "1901.01767", "submitter": "Alexander Rieder", "authors": "Jens Markus Melenk and Alexander Rieder", "title": "$hp$-FEM for the fractional heat equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a time dependent problem generated by a nonlocal operator in\nspace. Applying a discretization scheme based on $hp$-Finite Elements and a\nCaffarelli-Silvestre extension we obtain a semidiscrete semigroup. The\ndiscretization in time is carried out by using $hp$-Discontinuous Galerkin\nbased timestepping. We prove exponential convergence for such a method in an\nabstract framework for the discretization in the original domain $\\Omega$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 12:16:39 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 14:21:10 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Melenk", "Jens Markus", ""], ["Rieder", "Alexander", ""]]}, {"id": "1901.01792", "submitter": "Bal\\'azs Kov\\'acs", "authors": "David Hipp and Bal\\'azs Kov\\'acs", "title": "Finite element error analysis of wave equations with dynamic boundary\n  conditions: $L^2$ estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $L^2$ norm error estimates of semi- and full discretisations, using\nbulk--surface finite elements and Runge--Kutta methods, of wave equations with\ndynamic boundary conditions are studied. The analysis resides on an abstract\nformulation and error estimates, via energy techniques, within this abstract\nsetting. Four prototypical linear wave equations with dynamic boundary\nconditions are analysed which fit into the abstract framework. For problems\nwith velocity terms, or with acoustic boundary conditions we prove surprising\nresults: for such problems the spatial convergence order is shown to be less\nthan two. These can also be observed in the presented numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 13:22:57 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 13:13:41 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Hipp", "David", ""], ["Kov\u00e1cs", "Bal\u00e1zs", ""]]}, {"id": "1901.01803", "submitter": "Zhiyuan Sun", "authors": "Ruo Li and Zhiyuan Sun and Fanyi Yang", "title": "Solving Eigenvalue Problems in a Discontinuous Approximation Space by\n  Patch Reconstruction", "comments": null, "journal-ref": null, "doi": "10.1137/19M123693X", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adapt a symmetric interior penalty discontinuous Galerkin method using a\npatch reconstructed approximation space to solve elliptic eigenvalue problems,\nincluding both second and fourth order problems in 2D and 3D. It is a direct\nextension of the method recently proposed to solve corresponding boundary value\nproblems, and the optimal error estimates of the approximation to\neigenfunctions and eigenvalues are instant consequences from existing results.\nThe method enjoys the advantage that it uses only one degree of freedom on each\nelement to achieve very high order accuracy, which is highly preferred for\neigenvalue problems as implied by Zhang's recent study [J. Sci. Comput. 65(2),\n2015]. By numerical results, we illustrate that higher order methods can\nprovide much more reliable eigenvalues. To justify that our method is the right\none for eigenvalue problems, we show that the patch reconstructed approximation\nspace attains the same accuracy with fewer degrees of freedom than classical\ndiscontinuous Galerkin methods. With the increasing of the polynomial order,\nour method can even achieve a better performance than conforming finite element\nmethods, such methods are traditionally the methods of choice to solve problems\nwith high regularities.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 13:46:13 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 08:51:20 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Li", "Ruo", ""], ["Sun", "Zhiyuan", ""], ["Yang", "Fanyi", ""]]}, {"id": "1901.02264", "submitter": "Mathea Vuik", "authors": "B. van 't Hof and M.J. Vuik", "title": "Symmetry-preserving finite-difference discretizations of arbitrary order\n  on structured curvilinear staggered grids", "comments": null, "journal-ref": "Journal of Computational Science, Volume 36, September 2019,\n  101008", "doi": "10.1016/j.jocs.2019.06.005", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetry-preserving (mimetic) discretization aims to preserve certain\nproperties of a continuous differential operator in its discrete counterpart.\nFor these discretizations, stability and (discrete) conservation of mass,\nmomentum and energy are proven in the same way as for the original continuous\nmodel.\n  This paper presents a new finite-difference symmetry-preserving space\ndiscretization. Boundary conditions and time integration are not addressed. The\nnovelty is that it combines arbitrary order of convergence, orthogonal and\nnon-orthogonal structured curvilinear staggered meshes, and the applicability\nto a wide variety of continuous operators, involving chain rules and nonlinear\nadvection, as illustrated by the shallow-water equations.\n  Experiments show exact conservation and convergence corresponding to expected\norder.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 11:35:20 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 13:06:41 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Hof", "B. van 't", ""], ["Vuik", "M. J.", ""]]}, {"id": "1901.02315", "submitter": "Kae-An Liu", "authors": "Kae-An Liu, Hans-Dieter Lang and Costas D. Sarris", "title": "Computation of High-Order Electromagnetic Field Derivatives with FDTD\n  and the Complex-Step Derivative Approximation", "comments": "Submitted to IEEE Transactions on Antennas and Propagation\n  (Aug-31-2018)", "journal-ref": null, "doi": "10.1109/TAP.2019.2905693", "report-no": null, "categories": "cs.NA cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new approach for the computation of electromagnetic\nfield derivatives, up to any order, with respect to the material and geometric\nparameters of a given geometry, in a single Finite-Difference Time-Domain\n(FDTD) simulation. The proposed method is based on embedding the complex-step\nderivative (CSD) approximation into the standard FDTD update equations. Being\nfinite-difference free, CSD provides accurate derivative approximations even\nfor very small perturbations of the design parameters, unlike finite-difference\napproximations that are prone to subtractive cancellation errors. The\navailability of accurate approximations of field derivatives with respect to\ndesign parameters enables studies such as sensitivity analysis of multiple\nobjective functions (as derivatives of those can be derived from field\nderivatives via the chain rule), uncertainty quantification, as well as\nmulti-parametric modeling and optimization of electromagnetic structures. The\ntheory, FDTD implementation and applications of this technique are presented.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 14:12:30 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Liu", "Kae-An", ""], ["Lang", "Hans-Dieter", ""], ["Sarris", "Costas D.", ""]]}, {"id": "1901.02405", "submitter": "Julian Marcon", "authors": "Julian Marcon, David A. Kopriva, Spencer J. Sherwin, Joaquim Peir\\'o", "title": "A High Resolution PDE Approach to Quadrilateral Mesh Generation", "comments": "31 pages, 21 figures, accepted for publication in Journal of\n  Computational Physics", "journal-ref": "Journal of Computational Physics 399C (2019) 108918", "doi": "10.1016/j.jcp.2019.108918", "report-no": null, "categories": "math.NA cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a high order technique to generate quadrilateral decompositions\nand meshes for complex two dimensional domains using spectral elements in a\nfield guided procedure. Inspired by cross field methods, we never actually\ncompute crosses. Instead, we compute a high order accurate guiding field using\na continuous Galerkin (CG) or discontinuous Galerkin (DG) spectral element\nmethod to solve a Laplace equation for each of the field variables using the\nopen source code Nektar++. The spectral method provides spectral convergence\nand sub-element resolution of the fields. The DG approximation allows meshing\nof corners that are not multiples of $\\pi/2$ in a discretization consistent\nmanner, when needed. The high order field can then be exploited to accurately\nfind irregular nodes, and can be accurately integrated using a high order\nseparatrix integration method to avoid features like limit cycles. The result\nis a mesh with naturally curved quadrilateral elements that do not need to be\ncurved a posteriori to eliminate invalid elements. The mesh generation\nprocedure is implemented in the open source mesh generation program NekMesh.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 17:03:21 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 13:44:37 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Marcon", "Julian", ""], ["Kopriva", "David A.", ""], ["Sherwin", "Spencer J.", ""], ["Peir\u00f3", "Joaquim", ""]]}, {"id": "1901.02550", "submitter": "Michael Yereniuk", "authors": "Michael A. Yereniuk, Sarah D. Olson", "title": "Computational framework to capture the spatiotemporal density of cells\n  with a cumulative environmental coupling", "comments": "40 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic agent-based models can account for millions of cells with\nspatiotemporal movement that can be a function of different factors. However,\nthese simulations can be computationally expensive. In this work, we develop a\nnovel computational framework to describe and simulate stochastic cellular\nprocesses that are coupled to the environment. Specifically, through upscaling,\nwe derive a continuum governing equation that considers the cell density as a\nfunction of time, space, and a cumulative variable that is coupled to the\nenvironmental conditions. For this new governing equation, we consider the\nstability through an energy analysis, as well as proving uniqueness and\nwell-posedness. To solve the governing equations in free-space, we propose a\nnumerical method using fundamental solutions. As an application, we study a\ncell moving in an infinite domain that contains a toxic chemical, where a\ncumulative exposure above a critical value results in cell death. We illustrate\nthe validity of this new modeling framework and associated numerical methods by\ncomparing the density of live cells to results from the corresponding\nagent-based model.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 23:09:19 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 18:47:35 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Yereniuk", "Michael A.", ""], ["Olson", "Sarah D.", ""]]}, {"id": "1901.02792", "submitter": "Kevin Carlberg", "authors": "Stefano Pagani, Andrea Manzoni, Kevin Carlberg", "title": "Statistical closure modeling for reduced-order models of stationary\n  systems by the ROMES method", "comments": "Submitted to SIAM/ASA Journal on Uncertainty Quantification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a technique for constructing a statistical closure model\nfor reduced-order models (ROMs) applied to stationary systems modeled as\nparameterized systems of algebraic equations. The proposed technique extends\nthe reduced-order-model error surrogates (ROMES) method to closure modeling.\nThe original ROMES method applied Gaussian-process regression to construct a\nstatistical model that maps cheaply computable error indicators (e.g., residual\nnorm, dual-weighted residuals) to a random variable for either (1) the norm of\nthe state error or (2) the error in a scalar-valued quantity of interest.\nRather than target these two types of errors, this work proposes to construct a\nstatistical model for the state error itself; it achieves this by constructing\nstatistical models for the generalized coordinates characterizing both the\nin-plane error (i.e., the error in the trial subspace) and a low-dimensional\napproximation of the out-of-plane error. The former can be considered a\nstatistical closure model, as it quantifies the error in the ROM generalized\ncoordinates. Because any quantity of interest can be computed as a functional\nof the state, the proposed approach enables any quantity-of-interest error to\nbe statistically quantified a posteriori, as the state-error model can be\npropagated through the associated quantity-of-interest functional. Numerical\nexperiments performed on both linear and nonlinear stationary systems\nillustrate the ability of the technique (1) to improve (expected) ROM\nprediction accuracy by an order of magnitude, (2) to statistically quantify the\nerror in arbitrary quantities of interest, and (3) to realize a more\ncost-effective methodology for reducing the error than a ROM-only approach in\nthe case of nonlinear systems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 16:00:25 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Pagani", "Stefano", ""], ["Manzoni", "Andrea", ""], ["Carlberg", "Kevin", ""]]}, {"id": "1901.02971", "submitter": "L\\'eopold Cambier", "authors": "L\\'eopold Cambier, Chao Chen, Erik G Boman, Sivasankaran Rajamanickam,\n  Raymond S. Tuminaro, Eric Darve", "title": "An Algebraic Sparsified Nested Dissection Algorithm Using Low-Rank\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm for the fast solution of large, sparse, symmetric\npositive-definite linear systems, spaND -- sparsified Nested Dissection. It is\nbased on nested dissection, sparsification and low-rank compression. After\neliminating all interiors at a given level of the elimination tree, the\nalgorithm sparsifies all separators corresponding to the interiors. This\noperation reduces the size of the separators by eliminating some degrees of\nfreedom but without introducing any fill-in. This is done at the expense of a\nsmall and controllable approximation error. The result is an approximate\nfactorization that can be used as an efficient preconditioner. We then perform\nseveral numerical experiments to evaluate this algorithm. We demonstrate that a\nversion using orthogonal factorization and block-diagonal scaling takes fewer\nCG iterations to converge than previous similar algorithms on various kinds of\nproblems. Furthermore, this algorithm is provably guaranteed to never break\ndown and the matrix stays symmetric positive-definite throughout the process.\nWe evaluate the algorithm on some large problems and show it exhibits\nnear-linear scaling. The factorization time is roughly O(N) and the number of\niterations grows slowly with N.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 23:34:40 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 22:49:33 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 17:51:22 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Cambier", "L\u00e9opold", ""], ["Chen", "Chao", ""], ["Boman", "Erik G", ""], ["Rajamanickam", "Sivasankaran", ""], ["Tuminaro", "Raymond S.", ""], ["Darve", "Eric", ""]]}, {"id": "1901.03159", "submitter": "Lei Li", "authors": "Lei Li and Jian-Guo Liu", "title": "A discretization of Caputo derivatives with application to time\n  fractional SDEs and gradient flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a discretization of Caputo derivatives resulted from deconvolving\na scheme for the corresponding Volterra integral. Properties of this\ndiscretization, including signs of the coefficients, comparison principles, and\nstability of the corresponding implicit schemes, are proved by its linkage to\nVolterra integrals with completely monotone kernels. We then apply the backward\nscheme corresponding to this discretization to two time fractional dissipative\nproblems, and these implicit schemes are helpful for the analysis of the\ncorresponding problems. In particular, we show that the overdamped generalized\nLangevin equation with fractional noise has a unique limiting measure for\nstrongly convex potentials and establish the convergence of numerical solutions\nto the strong solutions of time fractional gradient flows. The proposed scheme\nand schemes derived using the same philosophy can be useful for many other\napplications as well.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 13:53:01 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 16:56:06 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Li", "Lei", ""], ["Liu", "Jian-Guo", ""]]}, {"id": "1901.03189", "submitter": "Antoine Tambue", "authors": "Jean Daniel Mukam and Antoine Tambue", "title": "Strong Convergence of the Linear Implicit Euler Method for the Finite\n  Element Discretization of Semilinear non-Autonomous SPDEs Driven by\n  Multiplicative or Additive Noise", "comments": "arXiv admin note: text overlap with arXiv:1809.06234,\n  arXiv:1803.00423, arXiv:1809.04438", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to investigate the numerical approximation of semilinear\nnon-autonomous stochastic partial differential equations (SPDEs) driven by\nmultiplicative or additive noise. Such equations are more realistic than\nautonomous SPDEs while modeling real world phenomena. Numerical approximations\nfor autonomous SPDEs are thoroughly investigated in the literature, while the\nnon-autonomous case is not yet well understood. The non-autonomous SPDE is\ndiscretized in space by the finite element method and in time by the linear\nimplicit Euler method. We break the complexity in the analysis of the time\ndepending, not necessarily self-adjoint linear operators with the corresponding\nsemi group and provide the strong convergence result of the fully discrete\nscheme toward the exact solution in the root-mean-square $L^2$ norm. The\nresults indicate how the converge order depends on the regularity of the\ninitial solution and the noise. In particular, for multiplicative trace class\nnoise we achieve convergence order $\\mathcal{O}(h^{2-\\epsilon}+\\Delta t^{1/2})$\nand for additive noise with trace class, we achieve convergence order\n$\\mathcal{O}(h^{2-\\epsilon}+\\Delta t^{1-\\epsilon})$, for an arbitrarily small\n$\\epsilon>0$. Numerical experiments to sustain our theoretical results are\nprovided.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 23:37:16 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 19:46:32 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 17:26:05 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Mukam", "Jean Daniel", ""], ["Tambue", "Antoine", ""]]}, {"id": "1901.03244", "submitter": "Lisa Maria Kreusser", "authors": "Jan Haskovec, Henrik J\\\"onsson, Lisa Maria Kreusser and Peter\n  Markowich", "title": "Auxin transport model for leaf venation", "comments": null, "journal-ref": "Proceedings of the Royal Society A, 475 (2231), 20190015, 2019", "doi": "10.1098/rspa.2019.0015", "report-no": null, "categories": "math.DS cs.NA math.AP math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The plant hormone auxin controls many aspects of the development of plants.\nOne striking dynamical feature is the self-organisation of leaf venation\npatterns which is driven by high levels of auxin within vein cells. The auxin\ntransport is mediated by specialised membrane-localised proteins. Many venation\nmodels have been based on polarly localised efflux-mediator proteins of the PIN\nfamily. Here, we investigate a modeling framework for auxin transport with a\npositive feedback between auxin fluxes and transport capacities that are not\nnecessarily polar, i.e.\\ directional across a cell wall. Our approach is\nderived from a discrete graph-based model for biological transportation\nnetworks, where cells are represented by graph nodes and intercellular\nmembranes by edges. The edges are not a-priori oriented and the direction of\nauxin flow is determined by its concentration gradient along the edge. We prove\nglobal existence of solutions to the model and the validity of Murray's law for\nits steady states. Moreover, we demonstrate with numerical simulations that the\nmodel is able connect an auxin source-sink pair with a mid-vein and that it can\nalso produce branching vein patterns. A significant innovative aspect of our\napproach is that it allows the passage to a formal macroscopic limit which can\nbe extended to include network growth. We perform mathematical analysis of the\nmacroscopic formulation, showing the global existence of weak solutions for an\nappropriate parameter range.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 16:08:10 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 10:22:37 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Haskovec", "Jan", ""], ["J\u00f6nsson", "Henrik", ""], ["Kreusser", "Lisa Maria", ""], ["Markowich", "Peter", ""]]}, {"id": "1901.03263", "submitter": "Stefan Takacs", "authors": "Stefan Takacs", "title": "A quasi-robust discretization error estimate for discontinuous Galerkin\n  Isogeometric Analysis", "comments": "The author was partially supported by the Austrian Science Fund\n  (FWF): grant S117, and by the bilateral project DNTS-Austria 01/3/2017 (WTZ\n  BG 03/2017), funded by Bulgarian National Science Fund and OeAD (Austria)", "journal-ref": null, "doi": null, "report-no": "RICAM-Report 02/2019", "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isogeometric Analysis is a spline-based discretization method to partial\ndifferential equations which shows the approximation power of a high-order\nmethod. The number of degrees of freedom, however, is as small as the number of\ndegrees of freedom of a low-order method. This does not come for free as the\noriginal formulation of Isogeometric Analysis requires a global geometry\nfunction. Since this is too restrictive for many kinds of applications, the\ndomain is usually decomposed into patches, where each patch is parameterized\nwith its own geometry function. In simpler cases, the patches can be combined\nin a conforming way. However, for non-matching discretizations or for varying\ncoefficients, a non-conforming discretization is desired. An symmetric interior\npenalty discontinuous Galerkin (SIPG) method for Isogeometric Analysis has been\npreviously introduced. In the present paper, we give error estimates that only\ndepend poly-logarithmically on the spline degree. This opens the door towards\nthe construction and the analysis of fast linear solvers, particularly\nmultigrid solvers for non-conforming multipatch Isogeometric Analysis.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 16:49:29 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 08:17:09 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 14:20:46 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Takacs", "Stefan", ""]]}, {"id": "1901.03283", "submitter": "Mario Teixeira Parente", "authors": "Mario Teixeira Parente, Daniel Bittner, Steven Mattis, Gabriele\n  Chiogna, Barbara Wohlmuth", "title": "Bayesian calibration and sensitivity analysis for a karst aquifer model\n  using active subspaces", "comments": "27 pages, 5 figures, 2 tables; 5 pages supplementary information", "journal-ref": "Water Resources Research 55 (8), 7086-7107, 2019", "doi": "10.1029/2019WR024739", "report-no": null, "categories": "stat.CO cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we perform a parameter study for a recently developed karst\nhydrological model. The study consists of a high-dimensional Bayesian inverse\nproblem and a global sensitivity analysis. For the first time in karst\nhydrology, we use the active subspace method to find directions in the\nparameter space that dominate the Bayesian update from the prior to the\nposterior distribution in order to effectively reduce the dimension of the\nproblem and for computational efficiency. Additionally, the calculated active\nsubspace can be exploited to construct sensitivity metrics on each of the\nindividual parameters and be used to construct a natural model surrogate. The\nmodel consists of 21 parameters to reproduce the hydrological behavior of\nspring discharge in a karst aquifer located in the Kerschbaum spring recharge\narea at Waidhofen a.d. Ybbs in Austria. The experimental spatial and time\nseries data for the inference process were collected by the water works in\nWaidhofen. We show that this case study has implicit low-dimensionality, and we\nrun an adjusted Markov chain Monte Carlo algorithm in a low-dimensional\nsubspace to construct samples of the posterior distribution. The results are\nvisualized and verified by plots of the posterior's push-forward distribution\ndisplaying the uncertainty in predicting discharge values due to the\nexperimental noise in the data. Finally, a discussion provides hydrological\ninterpretation of these results for the Kerschbaum area.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 17:24:04 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 11:12:49 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 11:18:13 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Parente", "Mario Teixeira", ""], ["Bittner", "Daniel", ""], ["Mattis", "Steven", ""], ["Chiogna", "Gabriele", ""], ["Wohlmuth", "Barbara", ""]]}, {"id": "1901.03433", "submitter": "Ciro Javier Diaz Penedo", "authors": "Ciro Diaz", "title": "Combined use of mixed and hybrid finite elements method with domain\n  decomposition and spectral methods for a study of renormalization for the KPZ\n  model", "comments": "advisor: Eduardo Abreu. Text in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this work is the numerical approximation of time-dependent\npartial differential equations associated to initial-boundary value problems.\nThis master dissertation is mostly concerned with the actual computation of the\nsolution to nonlinear stochastic evolution problems governed by\nKardar-Parisi-Zhang (KPZ) models. In addition, the dissertation aims to\ncontribute to corroborate, by means of a large set of numerical experiments,\nthat the initial-boundary value problem with periodic boundary conditions for\nthe equation KPZ is ill-posed and that such equation needs to be renormalized.\nThe approach to discretization of KPZ equation perfomed by means of the use of\nhybrid and mixed finite elements with a domain decomposition procedure along\nwith a pertinent mollification of the noise. The obtained solution is compared\nwith the well known solution given by the Cole-Hopf transformation of the\nstochastic heat equation with multiplicative noise. We were able to verify that\nboth solutions exhibit a good agreement, but there is a shift that grows as the\nsupport of the mollifier decreases. For the numerical aproximation of the\nstochastic heat equation we use a state-of-the-art numerical method for\nevaluating semilinear stochastic PDE , which in turn combine spectral\ntechniques, Taylor's expantions and particular numerical treatment to the\nunderlying noise. Furthermore, a state-of-the-art renormalization procedure\nintroduced by Martin Hairer is used to renormalize KPZ equation that is\nvalidated with nontrivial numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 23:51:54 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Diaz", "Ciro", ""]]}, {"id": "1901.03573", "submitter": "S{\\o}lve Eidnes", "authors": "S{\\o}lve Eidnes, Lu Li, Shun Sato", "title": "Linearly implicit structure-preserving schemes for Hamiltonian systems", "comments": "18 pages, 11 figures, 33 subfigures. Submitted to Journal of\n  Computational and Applied Mathematics, proceedings for NUMDIFF-15", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kahan's method and a two-step generalization of the discrete gradient method\nare both linearly implicit methods that can preserve a modified energy for\nHamiltonian systems with a cubic Hamiltonian. These methods are here\ninvestigated and compared. The schemes are applied to the Korteweg-de Vries\nequation and the Camassa-Holm equation, and the numerical results are presented\nand analysed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 12:24:00 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 10:00:50 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 09:59:04 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Eidnes", "S\u00f8lve", ""], ["Li", "Lu", ""], ["Sato", "Shun", ""]]}, {"id": "1901.03708", "submitter": "Martin Hess", "authors": "Martin Hess, Annalisa Quaini, Gianluigi Rozza", "title": "Reduced Basis Model Order Reduction for Navier-Stokes equations in\n  domains with walls of varying curvature", "comments": "arXiv admin note: text overlap with arXiv:1812.11051", "journal-ref": null, "doi": "10.1080/10618562.2019.1645328", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Navier-Stokes equations in a channel with a narrowing and\nwalls of varying curvature. By applying the empirical interpolation method to\ngenerate an affine parameter dependency, the offline-online procedure can be\nused to compute reduced order solutions for parameter variations. The reduced\norder space is computed from the steady-state snapshot solutions by a standard\nPOD procedure. The model is discretised with high-order spectral element ansatz\nfunctions, resulting in 4752 degrees of freedom. The proposed reduced order\nmodel produces accurate approximations of steady-state solutions for a wide\nrange of geometries and kinematic viscosity values. The application that\nmotivated the present study is the onset of asymmetries (i.e., symmetry\nbreaking bifurcation) in blood flow through a regurgitant mitral valve,\ndepending on the Reynolds number and the valve shape. Through our computational\nstudy, we found that the critical Reynolds number for the symmetry breaking\nincreases as the wall curvature increases.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 18:55:15 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 09:50:12 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Hess", "Martin", ""], ["Quaini", "Annalisa", ""], ["Rozza", "Gianluigi", ""]]}, {"id": "1901.03846", "submitter": "Efthymios Karatzas", "authors": "Efthymios N. Karatzas, Francesco Ballarin, Gianluigi Rozza", "title": "Projection-based reduced order models for a cut finite element method in\n  parametrized domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a reduced order modelling technique built on a high\nfidelity embedded mesh finite element method. Such methods, and in particular\nthe CutFEM method, are attractive in the generation of projection-based reduced\norder models thanks to their capabilities to seamlessly handle large\ndeformations of parametrized domains. The combination of embedded methods and\nreduced order models allows us to obtain fast evaluation of parametrized\nproblems, avoiding remeshing as well as the reference domain formulation, often\nused in the reduced order modelling for boundary fitted finite element\nformulations. The resulting novel methodology is presented on linear elliptic\nand Stokes problems, together with several test cases to assess its capability.\nThe role of a proper extension and transport of embedded solutions to a common\nbackground is analyzed in detail.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 10:58:57 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 10:49:13 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Karatzas", "Efthymios N.", ""], ["Ballarin", "Francesco", ""], ["Rozza", "Gianluigi", ""]]}, {"id": "1901.03870", "submitter": "Murat Uzunca", "authors": "Murat Uzunca", "title": "Preservation of the invariants of Lotka-Volterra equations by iterated\n  deferred correction methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply Kahan's nonstandard discretization to three\ndimensional Lotka-Volterra equations in bi-Hamiltonian form. The periodicity of\nthe solutions and all polynomial and non-polynomial invariants are well\npreserved in long-term integration. Applying classical deferred correction\nmethod, we show that the invariants are preserved with increasing accuracy as a\nresults of more accurate numerical solutions. Substantial speedups over the\nKahan's method are achieved at each run with deferred correction method.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 15:00:05 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 17:10:10 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Uzunca", "Murat", ""]]}, {"id": "1901.03958", "submitter": "Bj\\\"orn Sprungk", "authors": "Claudia Schillings, Bj\\\"orn Sprungk, Philipp Wacker", "title": "On the Convergence of the Laplace Approximation and\n  Noise-Level-Robustness of Laplace-based Monte Carlo Methods for Bayesian\n  Inverse Problems", "comments": "50 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian approach to inverse problems provides a rigorous framework for\nthe incorporation and quantification of uncertainties in measurements,\nparameters and models. We are interested in designing numerical methods which\nare robust w.r.t. the size of the observational noise, i.e., methods which\nbehave well in case of concentrated posterior measures. The concentration of\nthe posterior is a highly desirable situation in practice, since it relates to\ninformative or large data. However, it can pose a computational challenge for\nnumerical methods based on the prior or reference measure. We propose to employ\nthe Laplace approximation of the posterior as the base measure for numerical\nintegration in this context. The Laplace approximation is a Gaussian measure\ncentered at the maximum a-posteriori estimate and with covariance matrix\ndepending on the logposterior density. We discuss convergence results of the\nLaplace approximation in terms of the Hellinger distance and analyze the\nefficiency of Monte Carlo methods based on it. In particular, we show that\nLaplace-based importance sampling and Laplace-based quasi-Monte-Carlo methods\nare robust w.r.t. the concentration of the posterior for large classes of\nposterior distributions and integrands whereas prior-based importance sampling\nand plain quasi-Monte Carlo are not. Numerical experiments are presented to\nillustrate the theoretical findings.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 10:47:12 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 09:13:17 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 08:36:40 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 16:02:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Schillings", "Claudia", ""], ["Sprungk", "Bj\u00f6rn", ""], ["Wacker", "Philipp", ""]]}, {"id": "1901.03966", "submitter": "Alexei Lozinski", "authors": "Alexei Lozinski", "title": "CutFEM without cutting the mesh cells: a new way to impose Dirichlet and\n  Neumann boundary conditions on unfitted meshes", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2019.07.008", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method of CutFEM type for the Poisson problem with either\nDirichlet or Neumann boundary conditions. The computational mesh is obtained\nfrom a background (typically uniform Cartesian) mesh by retaining only the\nelements intersecting the domain where the problem is posed. The resulting mesh\ndoes not thus fit the boundary of the problem domain. Several finite element\nmethods (XFEM, CutFEM) adapted to such meshes have been recently proposed. The\noriginality of the present article consists in avoiding integration over the\nelements cut by the boundary of the problem domain, while preserving the\noptimal convergence rates, as confirmed by both the theoretical estimates and\nthe numerical results.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 12:02:58 GMT"}, {"version": "v2", "created": "Sun, 10 Mar 2019 11:52:36 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 20:12:55 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Lozinski", "Alexei", ""]]}, {"id": "1901.04098", "submitter": "Steven Roberts", "authors": "Steven Roberts, Andrey A. Popov, and Adrian Sandu", "title": "ODE Test Problems: a MATLAB suite of initial value problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "CSL-TR-19-1", "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ODE Test Problems (OTP) is an object-oriented MATLAB package offering a broad\nrange of initial value problems which can be used to test numerical methods\nsuch as time integration methods and data assimilation (DA) methods. It\nincludes problems that are linear and nonlinear, homogeneous and\nnonhomogeneous, autonomous and nonautonomous, scalar and high-dimensional,\nstiff and nonstiff, and chaotic and nonchaotic. Many are real-world problems\nfrom fields such as chemistry, astrophysics, meteorology, and electrical\nengineering. OTP also supports partitioned ODEs for testing IMEX methods,\nmultirate methods, and other multimethods. Functions for plotting solutions and\ncreating movies are available for all problems, and exact solutions are\nprovided when available. OTP is desgined for ease of use-meaning that working\nwith and modifying problems is simple and intuitive.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 01:04:05 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Roberts", "Steven", ""], ["Popov", "Andrey A.", ""], ["Sandu", "Adrian", ""]]}, {"id": "1901.04162", "submitter": "Shunchuan Yang", "authors": "Shunchuan Yang, Donglin Su", "title": "Fast Green Function Evaluation for Method of Moment", "comments": null, "journal-ref": null, "doi": "10.1109/LAWP.2019.2926071", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, an approach to accelerate the matrix filling in method of\nmoment (MOM) is presented. Based on the fact that the Green function is\ndependent on the Euclidean distance between the source and the observation\npoints, we constructed an efficient adaptive one-dimensional interpolation\napproach to fast calculate the $Exp$ type function values. In the proposed\nmethod, several adaptive interpolation tables are constructed based on the\nmaximum and minimum distance between any two integration points with local\nrefinement near zero function values to minimize the relative error. An\nefficient approach to obtain the sampling points used in the interpolation\nphase is carefully designed. Then, any function values can be efficiently\ncalculated through a linear interpolation method for Exp and a Lagrange\npolynomial interpolation method for the Green function. In addition, the error\nbound of the proposed method is rigorously investigated. The proposed method\ncan be quite easily integrated into the available MOM codes for different\nintegration equation (IE) formulations with few efforts. Comprehensive\nnumerical experiments validate its accuracy and efficiency through several IE\nformulations. Results show that over 20% efficiency improvement can be achieved\nwithout sacrificing the accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 07:18:27 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 08:04:31 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yang", "Shunchuan", ""], ["Su", "Donglin", ""]]}, {"id": "1901.04255", "submitter": "Yimin Wei", "authors": "Yun Miao, Liqun Qi, Yimin Wei", "title": "Generalized Tensor Function via the Tensor Singular Value Decomposition\n  based on the T-Product", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the definition of generalized tensor function\naccording to the tensor singular value decomposition (T-SVD) via the tensor\nT-product. Also, we introduce the compact singular value decomposition (T-CSVD)\nof tensors via the T-product, from which the projection operators and Moore\nPenrose inverse of tensors are also obtained. We also establish the Cauchy\nintegral formula for tensors by using the partial isometry tensors and applied\nit into the solution of tensor equations. Then we establish the generalized\ntensor power and the Taylor expansion of tensors. Explicit generalized tensor\nfunctions are also listed. We define the tensor bilinear and sesquilinear forms\nand proposed theorems on structures preserved by generalized tensor functions.\nFor complex tensors, we established an isomorphism between complex tensors and\nreal tensors. In the last part of our paper, we find that the block circulant\noperator established an isomorphism between tensors and matrices. This\nisomorphism is used to prove the F-stochastic structure is invariant under\ngeneralized tensor functions. The concept of invariant tensor cones is also\nraised.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 12:12:55 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 07:12:18 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 02:19:36 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Miao", "Yun", ""], ["Qi", "Liqun", ""], ["Wei", "Yimin", ""]]}, {"id": "1901.04289", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson (LFANT)", "title": "Faster arbitrary-precision dot product and matrix multiplication", "comments": null, "journal-ref": "26th IEEE Symposium on Computer Arithmetic (ARITH26), Jun 2019,\n  Kyoto, Japan", "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithms for real and complex dot product and matrix\nmultiplication in arbitrary-precision floating-point and ball arithmetic. A\nlow-overhead dot product is implemented on the level of GMP limb arrays; it is\nabout twice as fast as previous code in MPFR and Arb at precision up to several\nhundred bits. Up to 128 bits, it is 3-4 times as fast, costing 20-30 cycles per\nterm for floating-point evaluation and 40-50 cycles per term for balls. We\nhandle large matrix multiplications even more efficiently via blocks of scaled\ninteger matrices. The new methods are implemented in Arb and significantly\nspeed up polynomial operations and linear algebra.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 13:25:49 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 13:26:16 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Johansson", "Fredrik", "", "LFANT"]]}, {"id": "1901.04480", "submitter": "Nicolas Pignet", "authors": "Micka\\\"el Abbas and Alexandre Ern and Nicolas Pignet", "title": "A Hybrid High-Order method for finite elastoplastic deformations within\n  a logarithmic strain framework", "comments": "32 pages; 16 figures; 1 table. arXiv admin note: substantial text\n  overlap with arXiv:1804.06129", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise and evaluate numerically a Hybrid High-Order (HHO) method for\nfinite plasticity within a logarithmic strain framework. The HHO method uses as\ndiscrete unknowns piecewise polynomials of order $k\\ge1$ on the mesh skeleton,\ntogether with cell-based polynomials that can be eliminated locally by static\ncondensation. The HHO method leads to a primal formulation, supports polyhedral\nmeshes with non-matching interfaces, is free of volumetric locking, the\nintegration of the behavior law is performed only at cell-based quadrature\nnodes, and the tangent matrix in Newton's method is symmetric. Moreover, the\nprinciple of virtual work is satisfied locally with equilibrated tractions.\nVarious two- and three-dimensional benchmarks are presented, as well as\ncomparison against known solutions with an industrial software using conforming\nand mixed finite elements.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 09:05:07 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 18:02:09 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Abbas", "Micka\u00ebl", ""], ["Ern", "Alexandre", ""], ["Pignet", "Nicolas", ""]]}, {"id": "1901.04533", "submitter": "Andrew Horning", "authors": "Andrew Horning and Alex Townsend", "title": "FEAST for differential eigenvalue problems", "comments": "Expanded discussion for clarity in several places, revised statement\n  of theorem 5.2 for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An operator analogue of the FEAST matrix eigensolver is developed to compute\nthe discrete part of the spectrum of a differential operator in a region of\ninterest in the complex plane. Unbounded search regions are handled with a\nnovel rational filter for the right half-plane. If the differential operator is\nnormal or self-adjoint, then the operator analogue preserves that structure and\nrobustly computes eigenvalues to near machine precision accuracy. The algorithm\nis particularly adept at computing high-frequency modes of differential\noperators that possess self-adjoint structure with respect to weighted Hilbert\nspaces.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 19:40:40 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 18:29:55 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 22:50:52 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Horning", "Andrew", ""], ["Townsend", "Alex", ""]]}, {"id": "1901.04667", "submitter": "Chaolong Jiang", "authors": "Chaolong Jiang, Jin Cui, Wenjun Cai, Yushun Wang", "title": "A novel linearized and momentum-preserving Fourier pseudo-spectral\n  scheme for the Rosenau-Korteweg de Vries equation", "comments": "24 pages.arXiv admin note: text overlap with arXiv:1808.06854", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design a novel linearized and momentum-preserving Fourier\npseudo-spectral scheme to solve the Rosenau-Korteweg de Vries equation. With\nthe aid of a new semi-norm equivalence between the Fourier pseudo-spectral\nmethod and the finite difference method, a prior bound of the numerical\nsolution in discrete $L^{\\infty}$-norm is obtained from the discrete momentum\nconservation law. Subsequently, based on the energy method and the bound of the\nnumerical solution, we show that, without any restriction on the mesh ratio,\nthe scheme is convergent with order $O(N^{-s}+\\tau^2)$ in discrete\n$L^\\infty$-norm, where $N$ is the number of collocation points used in the\nspectral method and $\\tau$ is the time step. Numerical results are addressed to\nconfirm our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 05:17:24 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 02:51:26 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Jiang", "Chaolong", ""], ["Cui", "Jin", ""], ["Cai", "Wenjun", ""], ["Wang", "Yushun", ""]]}, {"id": "1901.05031", "submitter": "Jeff Calder", "authors": "Mauricio Flores Rios, Jeff Calder, Gilad Lerman", "title": "Algorithms for $\\ell_p$-based semi-supervised learning on graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV cs.LG cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop fast algorithms for solving the variational and game-theoretic\n$p$-Laplace equations on weighted graphs for $p>2$. The graph $p$-Laplacian for\n$p>2$ has been proposed recently as a replacement for the standard ($p=2$)\ngraph Laplacian in semi-supervised learning problems with very few labels,\nwhere the minimizer of the graph Laplacian becomes degenerate. We present\nseveral efficient and scalable algorithms for both the variational and\ngame-theoretic formulations, and present numerical results on synthetic data\nand real data that illustrate the effectiveness of the $p$-Laplacian\nformulation for semi-supervised learning with few labels.\n  We also prove new discrete to continuum convergence results for $p$-Laplace\nproblems on $k$-nearest neighbor ($k$-NN) graphs, which are more commonly used\nin practice than random geometric graphs. Our analysis shows that, on $k$-NN\ngraphs, the $p$-Laplacian retains information about the data distribution as\n$p\\to \\infty$ and Lipschitz learning ($p=\\infty$) is sensitive to the data\ndistribution. This situation can be contrasted with random geometric graphs,\nwhere the $p$-Laplacian \\emph{forgets} the data distribution as $p\\to \\infty$.\nFinally, we give a general framework for proving discrete to continuum\nconvergence results in graph-based learning that only requires pointwise\nconsistency and a type of monotonicity.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 20:03:12 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:02:30 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Rios", "Mauricio Flores", ""], ["Calder", "Jeff", ""], ["Lerman", "Gilad", ""]]}, {"id": "1901.05188", "submitter": "Anne Reinarz", "authors": "Richard Butler, Tim Dodwell, Anne Reinarz, Anhad Sandhu, Robert\n  Scheichl, Linus Seelinger", "title": "High-performance dune modules for solving large-scale, strongly\n  anisotropic elliptic problems with applications to aerospace composites", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2019.106997", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key innovation in this paper is an open-source, high-performance\niterative solver for high contrast, strongly anisotropic elliptic partial\ndifferential equations implemented within dune-pdelab. The iterative solver\nexploits a robust, scalable two-level additive Schwarz preconditioner, GenEO\n(Spillane et al. 2014). The development of this solver has been motivated by\nthe need to overcome the limitations of commercially available modeling tools\nfor solving structural analysis simulations in aerospace composite\napplications. Our software toolbox dune-composites encapsulates the\nmathematical complexities of the underlying packages within an efficient C++\nframework, providing an application interface to our new high-performance\nsolver. We illustrate its use on a range of industrially motivated examples,\nwhich should enable other scientists to build on and extend dune-composites and\nthe GenEO preconditioner for use in their own applications. We demonstrate the\nscalability of the solver on more than 15,000 cores of the UK national\nsupercomputer Archer, solving an aerospace composite problem with over 200\nmillion degrees of freedom in a few minutes. This scale of computation brings\ncomposites problems that would otherwise be unthinkable into the feasible\nrange. To demonstrate the wider applicability of the new solver, we also\nconfirm the robustness and scalability of the solver on SPE10, a challenging\nbenchmark in subsurface flow/reservoir simulation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 09:05:35 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 13:07:22 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Butler", "Richard", ""], ["Dodwell", "Tim", ""], ["Reinarz", "Anne", ""], ["Sandhu", "Anhad", ""], ["Scheichl", "Robert", ""], ["Seelinger", "Linus", ""]]}, {"id": "1901.05242", "submitter": "Olivier S\\`ete", "authors": "Olivier S\\`ete, Jan Zur", "title": "A Newton method for harmonic mappings in the plane", "comments": "26 pages, 10 figures. Improved visualization of the dynamics of the\n  harmonic Newton map. Some minor further improvements", "journal-ref": "IMA Journal of Numerical Analysis, Volume 40(4), 2020, pp.\n  2777-2801", "doi": "10.1093/imanum/drz042", "report-no": null, "categories": "math.CV cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an iterative root finding method for harmonic mappings in the\ncomplex plane, which is a generalization of Newton's method for analytic\nfunctions. The complex formulation of the method allows an analysis in a\ncomplex variables spirit. For zeros close to poles of $f = h + \\bar{g}$ we\nconstruct initial points for which the harmonic Newton iteration is guaranteed\nto converge. Moreover, we study the number of solutions of $f(z) = \\eta$ close\nto the critical set of $f$ for certain $\\eta \\in \\mathbb{C}$. We provide a\nMatlab implementation of the method, and illustrate our results with several\nexamples and numerical experiments, including phase plots and plots of the\nbasins of attraction.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 11:52:00 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 07:14:09 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["S\u00e8te", "Olivier", ""], ["Zur", "Jan", ""]]}, {"id": "1901.05296", "submitter": "Matthias Wellershoff", "authors": "Rima Alaifari and Matthias Wellershoff", "title": "Stability estimates for phase retrieval from discrete Gabor measurements", "comments": "24 pages, 4 figures; Some small corrections of typos and minor\n  mathematical errors. Added Examples 3.8 and 3.9", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.IT cs.NA eess.SP math.FA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase retrieval refers to the problem of recovering some signal (which is\noften modelled as an element of a Hilbert space) from phaseless measurements.\nIt has been shown that in the deterministic setting phase retrieval from frame\ncoefficients is always unstable in infinite-dimensional Hilbert spaces [7] and\npossibly severely ill-conditioned in finite-dimensional Hilbert spaces [7].\n  Recently, it has also been shown that phase retrieval from measurements\ninduced by the Gabor transform with Gaussian window function is stable under a\nmore relaxed semi-global phase recovery regime based on atoll functions [1].\n  In finite dimensions, we present first evidence that this semi-global\nreconstruction regime allows one to do phase retrieval from measurements of\nbandlimited signals induced by the discrete Gabor transform in such a way that\nthe corresponding stability constant only scales like a low order polynomial in\nthe space dimension. To this end, we utilise reconstruction formulae which have\nbecome common tools in recent years [6,12,18,20].\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 16:01:44 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 15:33:31 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 14:21:15 GMT"}, {"version": "v4", "created": "Wed, 6 Jan 2021 13:11:46 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Alaifari", "Rima", ""], ["Wellershoff", "Matthias", ""]]}, {"id": "1901.05317", "submitter": "Murat Uzunca", "authors": "Murat Uzunca and Ay\\c{s}e Sar{\\i}ayd{\\i}n-Filibelio\\u{g}lu", "title": "Adaptive Discontinuous Galerkin Finite Elements for Advective Allen-Cahn\n  Equation", "comments": "Accepted paper in \"Numerical Algebra, Control & Optimization\"", "journal-ref": "Numerical Algebra, Control & Optimization, 11(2), 269-281, 2021", "doi": "10.3934/naco.2020025", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply a space adaptive interior penalty discontinuous Galerkin method for\nsolving advective Allen-Cahn equation with expanding and contracting velocity\nfields. The advective Allen-Cahn equation is first discretized in time and the\nresulting semi-linear elliptic PDE is solved by an adaptive algorithm using a\nresidual-based a posteriori error estimator. The a posteriori error estimator\ncontains additional terms due to the non-divergence-free velocity field.\nNumerical examples demonstrate the effectiveness and accuracy of the adaptive\napproach by resolving the sharp layers accurately.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 15:59:30 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 15:14:27 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Uzunca", "Murat", ""], ["Sar\u0131ayd\u0131n-Filibelio\u011flu", "Ay\u015fe", ""]]}, {"id": "1901.05509", "submitter": "Michal Wrobel", "authors": "Michal Wrobel and Grzegorz Brus", "title": "Mathematical modelling of Solid Oxide Fuel Cells revisited -- a modified\n  formulation of the problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper a mathematical model of the PEN structure (positive electrode -\nelectrolyte - negative electrode) of the Solid Oxide Fuel Cell (SOFC) is\nanalyzed. It is proved that classical formulation of the problem leads\ninevitably to locally unphysical effects related to negative values of the\nactivation overpotential. Moreover, the active layers' thicknesses are shown to\nbe components of solution and cannot be predefined in an arbitrary way. A\nmodified mathematical formulation of the problem is proposed which includes\nthis novelty alongside an amended definition of the activation overpotential. A\ndedicated computational scheme is developed for the cathode sub-problem. The\naccuracy of computations is investigated by means of a newly introduced\nanalytical benchmark example. The numerical results obtained for LSCF cathode\nare used to discuss certain aspects of the modified formulation and the active\nlayer thickness. The new modelling approach is validated by comparison with\nexperimental data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 19:48:01 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 19:20:18 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Wrobel", "Michal", ""], ["Brus", "Grzegorz", ""]]}, {"id": "1901.06014", "submitter": "Todor M. Mishonov", "authors": "T. M. Mishonov and A. M. Varonov", "title": "Robust formula for $N$-point Pad\\'e approximant calculation based on\n  Wynn identity", "comments": "12 pages, 6 figures, 2 appendix sections; Title and abstract\n  precised, section Introduction restated, figure captions shortened and a new\n  appendix section added, where the Cauchy-Jacobi problem is solved for the\n  case of the first $K$ derivatives at $N$ nodal points", "journal-ref": "Appl. Num. Math., Vol. 157, 291-306, 2020", "doi": "10.1016/j.apnum.2020.06.007", "report-no": null, "categories": "cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performed numerical analysis reveals that Wynn's identity for the compass\n$1/(N-C)+1/(S-C)=1/(W-C)+1/(E-C)=1/\\eta$ (here C stands for center, the other\nletters correspond to the four directions of the compass) gives the long sought\ncriterion, the minimal $|\\eta|$, for the choice of the optimal Pad\\'e\napproximant. The work of this method is illustrated by calculation of\nmultipoint Pad\\'e approximation by a new formula for calculation of this best\nrational approximation. The work of the criterion for the calculation of\noptimal Pad\\'e approximant is illustrated by the frequently seen in the\ntheoretical physics problems of calculation of series summation and multipoint\nPad\\'e approximation used as a predictor for solution of differential equations\nmotivated by the magneto-hydrodynamic problem of heating of solar corona by\nAlv\\'en waves. In such a way, an efficient and valuable control mechanism for\n$N$-point Pad\\'e approximant calculation is proposed. We believe that the\nsuggested method and criterion can be useful for many applied problems in\nnumerous areas not only in physics but in any scientific application where\ndifferential equations are solved. The solution of the Cauchy-Jacobi problem is\nillustrated by a Fortran program. The algorithm is generalized for the case of\nthe first $K$ derivatives at $N$ nodal points.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 15:32:03 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 11:51:38 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Mishonov", "T. M.", ""], ["Varonov", "A. M.", ""]]}, {"id": "1901.06101", "submitter": "Yang Liu", "authors": "Yang Liu, Wissam Sid-Lakhdar, Elizaveta Rebrova, Pieter Ghysels,\n  Xiaoye Sherry Li", "title": "A Parallel Hierarchical Blocked Adaptive Cross Approximation Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hierarchical low-rank decomposition algorithm assuming\nany matrix element can be computed in $O(1)$ time. The proposed algorithm\ncomputes rank-revealing decompositions of sub-matrices with a blocked adaptive\ncross approximation (BACA) algorithm, followed by a hierarchical merge\noperation via truncated singular value decompositions (H-BACA). The proposed\nalgorithm significantly improves the convergence of the baseline ACA algorithm\nand achieves reduced computational complexity compared to the full\ndecompositions such as rank-revealing QR decompositions. Numerical results\ndemonstrate the efficiency, accuracy and parallel efficiency of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 06:39:57 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 18:49:19 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 17:31:46 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Liu", "Yang", ""], ["Sid-Lakhdar", "Wissam", ""], ["Rebrova", "Elizaveta", ""], ["Ghysels", "Pieter", ""], ["Li", "Xiaoye Sherry", ""]]}, {"id": "1901.06148", "submitter": "Simon Hatzesberger", "authors": "Simon Hatzesberger", "title": "Strongly Asymptotically Optimal Schemes for the Strong Approximation of\n  Stochastic Differential Equations with respect to the Supremum Error", "comments": null, "journal-ref": "Journal of Complexity 60C (2020) 101496", "doi": "10.1016/j.jco.2020.101496", "report-no": null, "categories": "math.NA cs.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our subject of study is strong approximation of stochastic differential\nequations (SDEs) with respect to the supremum error criterion, and we seek\napproximations that are strongly asymptotically optimal in specific classes of\napproximations. We hereby focus on two principal types of classes, namely, the\nclasses of approximations that are based only on the evaluation of the initial\nvalue and on at most finitely many sequential evaluations of the driving\nBrownian motion on average and the classes of approximations that are based\nonly on the evaluation of the initial value and on finitely many evaluations of\nthe driving Brownian motion at equidistant sites. For SDEs with globally\nLipschitz continuous coefficients, M\\\"uller-Gronbach [Ann. Appl. Probab. 12\n(2002), no. 2, 664-690] showed that specific Euler-Maruyama schemes relating to\nadaptive and to equidistant time discretizations perform strongly\nasymptotically optimal in these classes. In the present article, we generalize\nthese results to a significantly wider class of SDEs, such as ones with\nsuper-linearly growing coefficients. More precisely, we prove strong asymptotic\noptimality for specific coefficient-modified Euler-Maruyama schemes relating to\nadaptive and to equidistant time discretizations under rather mild assumptions\non the underlying SDE. To illustrate our findings, we present two exemplary\napplications - namely, Euler-Maruyama schemes and tamed Euler schemes - and\nthereby analyze the SDE associated with the Heston-$3/2$-model originating from\nmathematical finance.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 09:33:03 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 14:24:44 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Hatzesberger", "Simon", ""]]}, {"id": "1901.06190", "submitter": "Urbain Vaes", "authors": "B. Aymard, U. Vaes, M. Pradas, S. Kalliadasis", "title": "A linear, second-order, energy stable, fully adaptive finite-element\n  method for phase-field modeling of wetting phenomena", "comments": "Fix some typos and change DOI", "journal-ref": "Journal of Computational Physics: X, Volume 2, March 2019, 100010", "doi": "10.1016/j.jcpx.2019.100010", "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new numerical method to solve the Cahn-Hilliard equation coupled\nwith non-linear wetting boundary conditions. We show that the method is\nmass-conservative and that the discrete solution satisfies a discrete energy\nlaw similar to the one satisfied by the exact solution. We perform several\ntests inspired by realistic situations to verify the accuracy and performance\nof the method: wetting of a chemically heterogeneous substrate in three\ndimensions, wetting-driven nucleation in a complex two-dimensional domain and\nthree-dimensional diffusion through a porous medium.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 11:38:22 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 14:09:12 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Aymard", "B.", ""], ["Vaes", "U.", ""], ["Pradas", "M.", ""], ["Kalliadasis", "S.", ""]]}, {"id": "1901.06300", "submitter": "Jana de Wiljes", "authors": "Jana de Wiljes and Sahani Pathiraja and Sebastian Reich", "title": "Ensemble transform algorithms for nonlinear smoothing problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several numerical tools designed to overcome the challenges of smoothing in a\nnonlinear and non-Gaussian setting are investigated for a class of particle\nsmoothers. The considered family of smoothers is induced by the class of linear\nensemble transform filters which contains classical filters such as the\nstochastic ensemble Kalman filter, the ensemble square root filter and the\nrecently introduced nonlinear ensemble transform filter. Further the ensemble\ntransform particle smoother is introduced and particularly highlighted as it is\nconsistent in the particle limit and does not require assumptions with respect\nto the family of the posterior distribution. The linear update pattern of the\nconsidered class of linear ensemble transform smoothers allows one to implement\nimportant supplementary techniques such as adaptive spread corrections, hybrid\nformulations, and localization in order to facilitate their application to\ncomplex estimation problems. These additional features are derived and\nnumerically investigated for a sequence of increasingly challenging test\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 15:40:48 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 07:27:06 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 16:07:56 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["de Wiljes", "Jana", ""], ["Pathiraja", "Sahani", ""], ["Reich", "Sebastian", ""]]}, {"id": "1901.06373", "submitter": "Giovanni Stabile", "authors": "Giovanni Stabile and Matteo Zancanaro and Gianluigi Rozza", "title": "Efficient Geometrical parametrization for Finite-Volume based Reduced\n  Order Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an approach for the efficient treatment of\nparametrized geometries in the context of POD-Galerkin reduced order methods\nbased on Finite Volume full order approximations. On the contrary to what is\nnormally done in the framework of finite element reduced order methods,\ndifferent geometries are not mapped to a common reference domain: the method\nrelies on basis functions defined on an average deformed configuration and\nmakes use of the Discrete Empirical Interpolation Method (D-EIM) to handle\ntogether non-affinity of the parametrization and non-linearities. In the first\nnumerical example, different mesh motion strategies, based on a Laplacian\nsmoothing technique and on a Radial Basis Function approach, are analyzed and\ncompared on a heat transfer problem. Particular attention is devoted to the\nrole of the non-orthogonal correction. In the second numerical example the\nmethodology is tested on a geometrically parametrized incompressible\nNavier--Stokes problem. In this case, the reduced order model is constructed\nfollowing the same segregated approach used at the full order level\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 18:32:28 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 08:50:00 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 13:53:05 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Stabile", "Giovanni", ""], ["Zancanaro", "Matteo", ""], ["Rozza", "Gianluigi", ""]]}, {"id": "1901.06428", "submitter": "Art Owen", "authors": "Art B. Owen", "title": "Unreasonable effectiveness of Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a comment on the article \"Probabilistic Integration: A Role in\nStatistical Computation?\" by F.-X. Briol, C. J. Oates, M. Girolami, M. A.\nOsborne and D. Sejdinovic to appear in Statistical Science.\n  There is a role for statistical computation in numerical integration.\nHowever, the competition from incumbent methods looks to be stiffer for this\nproblem than for some of the newer problems being handled by probabilistic\nnumerics. One of the challenges is the unreasonable effectiveness of the\ncentral limit theorem. Another is the unreasonable effectiveness of\npseudorandom number generators. A third is the common $O(n^3)$ cost of methods\nbased on Gaussian processes. Despite these advantages, the classical methods\nare weak in places where probabilistic methods could bring an improvement.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 22:01:22 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Owen", "Art B.", ""]]}, {"id": "1901.06527", "submitter": "Laurent Jacques", "authors": "Simon Foucart and Laurent Jacques", "title": "One-Bit Sensing of Low-Rank and Bisparse Matrices", "comments": "4 pages, Submitted to Sampta'19 (July 8-12, 2019), Bordeaux, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note studies the worst-case recovery error of low-rank and bisparse\nmatrices as a function of the number of one-bit measurements used to acquire\nthem. First, by way of the concept of consistency width, precise estimates are\ngiven on how fast the recovery error can in theory decay. Next, an idealized\nrecovery method is proved to reach the fourth-root of the optimal decay rate\nfor Gaussian sensing schemes. This idealized method being impractical, an\nimplementable recovery algorithm is finally proposed in the context of\nfactorized Gaussian sensing schemes. It is shown to provide a recovery error\ndecaying as the sixth-root of the optimal rate.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 14:05:35 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Foucart", "Simon", ""], ["Jacques", "Laurent", ""]]}, {"id": "1901.06639", "submitter": "Joscha Prochno", "authors": "Aicke Hinrichs, David Krieg, Erich Novak, Joscha Prochno, and Mario\n  Ullrich", "title": "Random sections of ellipsoids and the power of random information", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.NA math.MG math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the circumradius of the intersection of an $m$-dimensional ellipsoid\n$\\mathcal E$ with semi-axes $\\sigma_1\\geq\\dots\\geq \\sigma_m$ with random\nsubspaces of codimension $n$. We find that, under certain assumptions on\n$\\sigma$, this random radius $\\mathcal{R}_n=\\mathcal{R}_n(\\sigma)$ is of the\nsame order as the minimal such radius $\\sigma_{n+1}$ with high probability. In\nother situations $\\mathcal{R}_n$ is close to the maximum $\\sigma_1$. The random\nvariable $\\mathcal{R}_n$ naturally corresponds to the worst-case error of the\nbest algorithm based on random information for $L_2$-approximation of functions\nfrom a compactly embedded Hilbert space $H$ with unit ball $\\mathcal E$. In\nparticular, $\\sigma_k$ is the $k$th largest singular value of the embedding\n$H\\hookrightarrow L_2$. In this formulation, one can also consider the case\n$m=\\infty$, and we prove that random information behaves very differently\ndepending on whether $\\sigma \\in \\ell_2$ or not. For $\\sigma \\notin \\ell_2$\nrandom information is completely useless, i.e., $\\mathbb E[\\mathcal{R}_n] =\n\\sigma_1$. For $\\sigma \\in \\ell_2$ the expected radius of random information\ntends to zero at least at rate $o(1/\\sqrt{n})$ as $n\\to\\infty$. In the\nimportant case $\\sigma_k \\asymp k^{-\\alpha} \\ln^{-\\beta}(k+1)$, where $\\alpha >\n0$ and $\\beta\\in\\mathbb R$, we obtain that $$ \\mathbb E [\\mathcal{R}_n(\\sigma)]\n\\asymp \\begin{cases} \\sigma_1 & : \\alpha<1/2 \\,\\text{ or }\\,\n\\beta\\leq\\alpha=1/2 \\\\ \\sigma_n \\, \\sqrt{\\ln(n+1)} & : \\beta>\\alpha=1/2 \\\\\n\\sigma_{n+1} & : \\alpha>1/2. \\end{cases} $$ In the proofs we use a comparison\nresult for Gaussian processes \\`a la Gordon, exponential estimates for sums of\nchi-squared random variables, and estimates for the extreme singular values of\n(structured) Gaussian random matrices. The upper bound is constructive. It is\nproven for the worst case error of a least squares estimator.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 08:05:04 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 06:06:48 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Hinrichs", "Aicke", ""], ["Krieg", "David", ""], ["Novak", "Erich", ""], ["Prochno", "Joscha", ""], ["Ullrich", "Mario", ""]]}, {"id": "1901.06748", "submitter": "Olena Burkovska", "authors": "Olena Burkovska, Max Gunzburger", "title": "Affine approximation of parametrized kernels and model order reduction\n  for nonlocal and fractional Laplace models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider parametrized problems driven by spatially nonlocal integral\noperators with parameter-dependent kernels. In particular, kernels with varying\nnonlocal interaction radius $\\delta > 0$ and fractional Laplace kernels,\nparametrized by the fractional power $s\\in(0,1)$, are studied. In order to\nprovide an efficient and reliable approximation of the solution for different\nvalues of the parameters, we develop the reduced basis method as a parametric\nmodel order reduction approach. Major difficulties arise since the kernels are\nnot affine in the parameters, singular, and discontinuous. Moreover, the\nspatial regularity of the solutions depends on the varying fractional power\n$s$. To address this, we derive regularity and differentiability results with\nrespect to $\\delta$ and $s$, which are of independent interest for other\napplications such as optimization and parameter identification. We then use\nthese results to construct affine approximations of the kernels by local\npolynomials. Finally, we certify the method by providing reliable a posteriori\nerror estimators, which account for all approximation errors, and support the\ntheoretical findings by numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 23:24:03 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 20:08:10 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Burkovska", "Olena", ""], ["Gunzburger", "Max", ""]]}, {"id": "1901.06764", "submitter": "Rasmus J Kyng", "authors": "Deeksha Adil, Rasmus Kyng, Richard Peng, Sushant Sachdeva", "title": "Iterative Refinement for $\\ell_p$-norm Regression", "comments": "Published in SODA 2019. Was initially submitted to SODA on July 12,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give improved algorithms for the $\\ell_{p}$-regression problem, $\\min_{x}\n\\|x\\|_{p}$ such that $A x=b,$ for all $p \\in (1,2) \\cup (2,\\infty).$ Our\nalgorithms obtain a high accuracy solution in $\\tilde{O}_{p}(m^{\\frac{|p-2|}{2p\n+ |p-2|}}) \\le \\tilde{O}_{p}(m^{\\frac{1}{3}})$ iterations, where each iteration\nrequires solving an $m \\times m$ linear system, $m$ being the dimension of the\nambient space.\n  By maintaining an approximate inverse of the linear systems that we solve in\neach iteration, we give algorithms for solving $\\ell_{p}$-regression to $1 /\n\\text{poly}(n)$ accuracy that run in time $\\tilde{O}_p(m^{\\max\\{\\omega,\n7/3\\}}),$ where $\\omega$ is the matrix multiplication constant. For the current\nbest value of $\\omega > 2.37$, we can thus solve $\\ell_{p}$ regression as fast\nas $\\ell_{2}$ regression, for all constant $p$ bounded away from $1.$\n  Our algorithms can be combined with fast graph Laplacian linear equation\nsolvers to give minimum $\\ell_{p}$-norm flow / voltage solutions to $1 /\n\\text{poly}(n)$ accuracy on an undirected graph with $m$ edges in\n$\\tilde{O}_{p}(m^{1 + \\frac{|p-2|}{2p + |p-2|}}) \\le\n\\tilde{O}_{p}(m^{\\frac{4}{3}})$ time.\n  For sparse graphs and for matrices with similar dimensions, our iteration\ncounts and running times improve on the $p$-norm regression algorithm by\n[Bubeck-Cohen-Lee-Li STOC`18] and general-purpose convex optimization\nalgorithms. At the core of our algorithms is an iterative refinement scheme for\n$\\ell_{p}$-norms, using the smoothed $\\ell_{p}$-norms introduced in the work of\nBubeck et al. Given an initial solution, we construct a problem that seeks to\nminimize a quadratically-smoothed $\\ell_{p}$ norm over a subspace, such that a\ncrude solution to this problem allows us to improve the initial solution by a\nconstant factor, leading to algorithms with fast convergence.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 01:42:53 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Adil", "Deeksha", ""], ["Kyng", "Rasmus", ""], ["Peng", "Richard", ""], ["Sachdeva", "Sushant", ""]]}, {"id": "1901.06821", "submitter": "Joel Chaskalovic Jchaska", "authors": "Joel Chaskalovic and Franck Assous", "title": "Explicit k-dependency for $P_k$ finite elements in $W^{m,p}$ error\n  estimates: application to probabilistic laws for accuracy analysis", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an explicit $k-$dependence in $W^{m,p}$ error estimates for $P_k$\nLagrange finite elements. Two laws of probability are established to measure\nthe relative accuracy between $P_{k_1}$ and $P_{k_2}$ finite elements ($k_1 <\nk_2$) in terms of $W^{m,p}$-norms. We further prove a weak asymptotic relation\nin $D'(R)$ between these probabilistic laws when difference $k_2-k_1$ goes to\ninfinity. Moreover, as expected, one finds that $P_{k_2}$ finite element is\n{\\em surely more accurate} than $P_{k_1}$, for sufficiently small values of the\nmesh size $h$. Nevertheless, our results also highlight cases where $P_{k_1}$\nis {\\em more likely accurate} than $P_{k_2}$, for a range of values of $h$.\nHence, this approach brings a new perspective on how to compare two finite\nelements, which is not limited to the rate of convergence.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 08:25:55 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 08:27:48 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 07:52:54 GMT"}, {"version": "v4", "created": "Mon, 9 Sep 2019 11:57:27 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Chaskalovic", "Joel", ""], ["Assous", "Franck", ""]]}, {"id": "1901.06827", "submitter": "Lisa Maria Kreusser", "authors": "Lisa Maria Kreusser and Stanley J. Osher and Bao Wang", "title": "A Deterministic Gradient-Based Approach to Avoid Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Loss functions with a large number of saddle points are one of the major\nobstacles for training modern machine learning models efficiently. First-order\nmethods such as gradient descent are usually the methods of choice for training\nmachine learning models. However, these methods converge to saddle points for\ncertain choices of initial guesses. In this paper, we propose a modification of\nthe recently proposed Laplacian smoothing gradient descent [Osher et al.,\narXiv:1806.06317], called modified Laplacian smoothing gradient descent\n(mLSGD), and demonstrate its potential to avoid saddle points without\nsacrificing the convergence rate. Our analysis is based on the attraction\nregion, formed by all starting points for which the considered numerical scheme\nconverges to a saddle point. We investigate the attraction region's dimension\nboth analytically and numerically. For a canonical class of quadratic\nfunctions, we show that the dimension of the attraction region for mLSGD is\nfloor((n-1)/2), and hence it is significantly smaller than that of the gradient\ndescent whose dimension is n-1.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 08:51:18 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 13:26:13 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kreusser", "Lisa Maria", ""], ["Osher", "Stanley J.", ""], ["Wang", "Bao", ""]]}, {"id": "1901.06885", "submitter": "Georg Muntingh PhD", "authors": "Tom Lyche and Georg Muntingh", "title": "B-spline-like bases for $C^2$ cubics on the Powell-Sabin 12-split", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For spaces of constant, linear, and quadratic splines of maximal smoothness\non the Powell-Sabin 12-split of a triangle, the so-called S-bases were recently\nintroduced. These are simplex spline bases with B-spline-like properties on the\n12-split of a single triangle, which are tied together across triangles in a\nB\\'ezier-like manner.\n  In this paper we give a formal definition of an S-basis in terms of certain\nbasic properties. We proceed to investigate the existence of S-bases for the\naforementioned spaces and additionally the cubic case, resulting in an\nexhaustive list. From their nature as simplex splines, we derive simple\ndifferentiation and recurrence formulas to other S-bases. We establish a\nMarsden identity that gives rise to various quasi-interpolants and domain\npoints forming an intuitive control net, in terms of which conditions for\n$C^0$-, $C^1$-, and $C^2$-smoothness are derived.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 11:33:25 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 16:53:02 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Lyche", "Tom", ""], ["Muntingh", "Georg", ""]]}, {"id": "1901.07189", "submitter": "Kui Ren", "authors": "Kui Ren, Yimin Zhong", "title": "Imaging point sources in heterogeneous environments", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": "10.1088/1361-6420/ab3497", "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging point sources in heterogeneous environments from boundary or\nfar-field measurements has been extensively studied in the past. In most\nexisting results, the environment, represented by the refractive index function\nin the model equation, is assumed known in the imaging process. In this work,\nwe investigate the impact of environment uncertainty on the reconstruction of\npoint sources inside it. Following the techniques developed by El Badia and El\nHajj (C. R. Acad. Sci. Paris, Ser. I, 350 (2012), 1031-1035), we derive\nstability of reconstructing point sources in heterogeneous media with respect\nto measurement error as well as smooth changes in the environment, that is, the\nrefractive index. Numerical simulations with synthetic data are presented to\nfurther explore the derived stability properties.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 07:11:04 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 19:28:36 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Ren", "Kui", ""], ["Zhong", "Yimin", ""]]}, {"id": "1901.07275", "submitter": "Haizhao Yang", "authors": "James Bremer and Qiyuan Pang and Haizhao Yang", "title": "Fast Algorithms for the Multi-dimensional Jacobi Polynomial Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the well-known observation that the solutions of Jacobi's differential\nequation can be represented via non-oscillatory phase and amplitude functions\nto develop a fast algorithm for computing multi-dimensional Jacobi polynomial\ntransforms. More explicitly, it follows from this observation that the matrix\ncorresponding to the discrete Jacobi transform is the Hadamard product of a\nnumerically low-rank matrix and a multi-dimensional discrete Fourier transform\n(DFT) matrix. The application of the Hadamard product can be carried out via\n$O(1)$ fast Fourier transforms (FFTs), resulting in a nearly optimal algorithm\nto compute the multidimensional Jacobi polynomial transform.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 11:56:18 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 14:31:23 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 02:41:26 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Bremer", "James", ""], ["Pang", "Qiyuan", ""], ["Yang", "Haizhao", ""]]}, {"id": "1901.07553", "submitter": "Wayne Isaac Uy", "authors": "Wayne Isaac T. Uy and Mircea D. Grigoriu", "title": "Specification of additional information for solving stochastic inverse\n  problems", "comments": null, "journal-ref": null, "doi": "10.1137/18M120155X", "report-no": null, "categories": "math.NA cs.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods have been developed to identify the probability distribution of a\nrandom vector $Z$ from information consisting of its bounded range and the\nprobability density function or moments of a quantity of interest, $Q(Z)$. The\nmapping from $Z$ to $Q(Z)$ may arise from a stochastic differential equation\nwhose coefficients depend on $Z$. This problem differs from Bayesian inverse\nproblems as the latter is primarily driven by observation noise. We motivate\nthis work by demonstrating that additional information on $Z$ is required to\nrecover its true law. Our objective is to identify what additional information\non $Z$ is needed and propose methods to recover the law of $Z$ under such\ninformation. These methods employ tools such as Bayes' theorem, principle of\nmaximum entropy, and forward uncertainty quantification to obtain solutions to\nthe inverse problem that are consistent with information on $Z$ and $Q(Z)$. The\nadditional information on $Z$ may include its moments or its family of\ndistributions. We justify our objective by considering the capabilities of\nsolutions to this inverse problem to predict the probability law of unobserved\nquantities of interest.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 15:57:56 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 17:30:30 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Uy", "Wayne Isaac T.", ""], ["Grigoriu", "Mircea D.", ""]]}, {"id": "1901.07598", "submitter": "Anna Breger", "authors": "Anna Breger, Jose Ignacio Orlando, Pavol Harar, Monika D\\\"orfler,\n  Sophie Klimscha, Christoph Grechenig, Bianca S. Gerendas, Ursula\n  Schmidt-Erfurth, Martin Ehler", "title": "On orthogonal projections for dimension reduction and applications in\n  augmented target loss functions for learning problems", "comments": null, "journal-ref": "Journal of Mathematical Imaging and Vision, 2019", "doi": "10.1007/s10851-019-00902-2", "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of orthogonal projections on high-dimensional input and target data\nin learning frameworks is studied. First, we investigate the relations between\ntwo standard objectives in dimension reduction, preservation of variance and of\npairwise relative distances. Investigations of their asymptotic correlation as\nwell as numerical experiments show that a projection does usually not satisfy\nboth objectives at once. In a standard classification problem we determine\nprojections on the input data that balance the objectives and compare\nsubsequent results. Next, we extend our application of orthogonal projections\nto deep learning tasks and introduce a general framework of augmented target\nloss functions. These loss functions integrate additional information via\ntransformations and projections of the target data. In two supervised learning\nproblems, clinical image segmentation and music information classification, the\napplication of our proposed augmented target loss functions increase the\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 20:03:38 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 14:59:05 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 16:16:33 GMT"}, {"version": "v4", "created": "Mon, 9 Sep 2019 19:57:22 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Breger", "Anna", ""], ["Orlando", "Jose Ignacio", ""], ["Harar", "Pavol", ""], ["D\u00f6rfler", "Monika", ""], ["Klimscha", "Sophie", ""], ["Grechenig", "Christoph", ""], ["Gerendas", "Bianca S.", ""], ["Schmidt-Erfurth", "Ursula", ""], ["Ehler", "Martin", ""]]}, {"id": "1901.07620", "submitter": "Daewa Kim", "authors": "Daewa Kim and Annalisa Quaini", "title": "A Kinetic Theory Approach to Model Pedestrian Dynamics in Bounded\n  Domains with Obstacles", "comments": "30 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a kinetic theory approach to model the evacuation of a crowd from\nbounded domains. The interactions of a person with other pedestrians and the\nenvironment, which includes walls, exits, and obstacles, are modeled by using\ntools of game theory and are transferred to the crowd dynamics. The model\nallows to weight between two competing behaviors: the search for less congested\nareas and the tendency to follow the stream unconsciously in a panic situation.\nFor the numerical approximation of the solution to our model, we apply an\noperator splitting scheme which breaks the problem into two pure advection\nproblems and a problem involving the interactions. We compare our numerical\nresults against the data reported in a recent empirical study on evacuation\nfrom a room with two exits. For medium and medium-to-large groups of people we\nachieve good agreement between the computed average people density and flow\nrate and the respective measured quantities. Through a series of numerical\ntests we also show that our approach is capable of handling evacuation from a\nroom with one or more exits with variable size, with and without obstacles, and\ncan reproduce lane formation in bidirectional flow in a corridor.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 21:48:02 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 02:03:08 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 02:53:15 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Kim", "Daewa", ""], ["Quaini", "Annalisa", ""]]}, {"id": "1901.07643", "submitter": "Borzou Alipourfard", "authors": "Borzou Alipourfard and Jean X. Gao", "title": "Solving All Regression Models For Learning Gaussian Networks Using\n  Givens Rotations", "comments": "This work has been submitted to a journal for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score based learning (SBL) is a promising approach for learning Bayesian\nnetworks. The initial step in the majority of the SBL algorithms consists of\ncomputing the scores of all possible child and parent-set combinations for the\nvariables. For Bayesian networks with continuous variables, a particular score\nis usually calculated as a function of the regression of the child over the\nvariables in the parent-set. The sheer number of regressions models to be\nsolved necessitates the design of efficient numerical algorithms. In this\npaper, we propose an algorithm for an efficient and exact calculation of\nregressions for all child and parent-set combinations. In the proposed\nalgorithm, we use QR decompositions (QRDs) to capture the dependencies between\nthe regressions for different families and Givens rotations to efficiently\ntraverse through the space of QRDs such that all the regression models are\naccounted for in the shortest path possible. We compare the complexity of the\nsuggested method with different algorithms, mainly those arising in all subset\nregression problems, and show that our algorithm has the smallest algorithmic\ncomplexity. We also explain how to parallelize the proposed method so as to\ndecrease the runtime by a factor proportional to the number of processors\nutilized.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 23:21:36 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 13:07:27 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Alipourfard", "Borzou", ""], ["Gao", "Jean X.", ""]]}, {"id": "1901.07834", "submitter": "Fuminori Tatsuoka", "authors": "Fuminori Tatsuoka, Tomohiro Sogabe, Yuto Miyatake, Shao-Liang Zhang", "title": "Algorithms for the computation of the matrix logarithm based on the\n  double exponential formula", "comments": null, "journal-ref": null, "doi": "10.1016/j.cam.2019.112396", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the computation of the matrix logarithm by using numerical\nquadrature. The efficiency of numerical quadrature depends on the integrand and\nthe choice of quadrature formula. The Gauss--Legendre quadrature has been\nconventionally employed; however, the convergence could be slow for\nill-conditioned matrices. This effect may stem from the rapid change of the\nintegrand values. To avoid such situations, we focus on the double exponential\nformula, which has been developed to address integrands with endpoint\nsingularity. In order to utilize the double exponential formula, we must\ndetermine a suitable finite integration interval, which provides the required\naccuracy and efficiency. In this paper, we present a method for selecting a\nsuitable finite interval based on an error analysis as well as two algorithms,\nand one of these algorithms addresses error control.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 11:56:36 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 12:54:11 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Tatsuoka", "Fuminori", ""], ["Sogabe", "Tomohiro", ""], ["Miyatake", "Yuto", ""], ["Zhang", "Shao-Liang", ""]]}, {"id": "1901.07841", "submitter": "Yufei Zhang", "authors": "Christoph Reisinger, Yufei Zhang", "title": "Error estimates of penalty schemes for quasi-variational inequalities\n  arising from impulse control problems", "comments": "Accepted for publication in SIAM Journal on Control and Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes penalty schemes for a class of weakly coupled systems of\nHamilton-Jacobi-Bellman quasi-variational inequalities (HJBQVIs) arising from\nstochastic hybrid control problems of regime-switching models with both\ncontinuous and impulse controls. We show that the solutions of the penalized\nequations converge monotonically to those of the HJBQVIs. We further establish\nthat the schemes are half-order accurate for HJBQVIs with Lipschitz\ncoefficients, and first-order accurate for equations with more regular\ncoefficients. Moreover, we construct the action regions and optimal impulse\ncontrols based on the error estimates and the penalized solutions. The penalty\nschemes and convergence results are then extended to HJBQVIs with possibly\nnegative impulse costs. We also demonstrate the convergence of monotone\ndiscretizations of the penalized equations, and establish that policy iteration\napplied to the discrete equation is monotonically convergent with an arbitrary\ninitial guess in an infinite dimensional setting. Numerical examples for\ninfinite-horizon optimal switching problems are presented to illustrate the\neffectiveness of the penalty schemes over the conventional direct control\nscheme.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 12:13:14 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 23:02:13 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Reisinger", "Christoph", ""], ["Zhang", "Yufei", ""]]}, {"id": "1901.07892", "submitter": "Nishant Nangia", "authors": "Nishant Nangia, Neelesh A. Patankar, Amneet Pal Singh Bhalla", "title": "A DLM immersed boundary method based wave-structure interaction solver\n  for high density ratio multiphase flows", "comments": "Figures are compressed to comply with arXiv size requirements", "journal-ref": null, "doi": "10.1016/j.jcp.2019.07.004", "report-no": null, "categories": "physics.flu-dyn cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robust immersed boundary (IB) method for high density ratio\nmultiphase flows that is capable of modeling complex wave-structure interaction\n(WSI) problems arising in marine and coastal engineering applications. The\nIB/WSI methodology is enabled by combining the distributed Lagrange multiplier\n(DLM) method of Sharma and Patankar (J Comp Phys, 2005) with a robust level set\nmethod based multiphase flow solver. The fluid solver integrates the\nconservative form of the variable-coefficient incompressible Navier-Stokes\nequations using a hybrid preconditioner and ensures consistent transport of\nmass and momentum at a discrete level. The consistent transport scheme\npreserves the numerical stability of the method in the presence of large\ndensity ratios found in problems involving air, water, and an immersed\nstructure. The air-water interface is captured by the level set method on an\nEulerian grid, whereas the free-surface piercing immersed structure is\nrepresented on a Lagrangian mesh. The fluid-structure interaction (FSI)\ncoupling is mediated via Peskin's regularized delta functions in an implicit\nmanner, which obviates the need to integrate the hydrodynamic stress tensor on\nthe complex surface of the immersed structure. The IB/WSI numerical scheme is\nimplemented within an adaptive mesh refinement (AMR) framework, in which the\nLagrangian structure and the air-water interface are embedded on the finest\nmesh level to capture the thin boundary layers and the vortical structures\narising from WSI. We use a well-balanced force discretization for gravity force\nthat eliminates spurious velocity currents in the hydrostatic limit due to\ndensity variation in the three phases (air, water and solid). An effective wave\ngeneration and absorption technique for a numerical wave tank is presented and\nused to simulate a benchmark case of water wave distortion due to a submerged\nstructure.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 02:47:26 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 21:19:30 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Nangia", "Nishant", ""], ["Patankar", "Neelesh A.", ""], ["Bhalla", "Amneet Pal Singh", ""]]}, {"id": "1901.07993", "submitter": "Anton G. Artemov", "authors": "Anton G. Artemov, Elias Rudberg, Emanuel H. Rubensson", "title": "Parallelization and scalability analysis of inverse factorization using\n  the Chunks and Tasks programming model", "comments": "20 pages, 7 figures, corrected the author list", "journal-ref": null, "doi": "10.1016/j.parco.2019.102548", "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present three methods for distributed memory parallel inverse\nfactorization of block-sparse Hermitian positive definite matrices. The three\nmethods are a recursive variant of the AINV inverse Cholesky algorithm,\niterative refinement, and localized inverse factorization, respectively. All\nthree methods are implemented using the Chunks and Tasks programming model,\nbuilding on the distributed sparse quad-tree matrix representation and parallel\nmatrix-matrix multiplication in the publicly available Chunks and Tasks Matrix\nLibrary (CHTML). Although the algorithms are generally applicable, this work\nwas mainly motivated by the need for efficient and scalable inverse\nfactorization of the basis set overlap matrix in large scale electronic\nstructure calculations. We perform various computational tests on overlap\nmatrices for quasi-linear Glutamic Acid-Alanine molecules and three-dimensional\nwater clusters discretized using the standard Gaussian basis set STO-3G with up\nto more than 10 million basis functions. We show that for such matrices the\ncomputational cost increases only linearly with system size for all the three\nmethods. We show both theoretically and in numerical experiments that the\nmethods based on iterative refinement and localized inverse factorization\noutperform previous parallel implementations in weak scaling tests where the\nsystem size is increased in direct proportion to the number of processes. We\nshow also that compared to the method based on pure iterative refinement the\nlocalized inverse factorization requires much less communication.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:44:44 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 13:29:55 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Artemov", "Anton G.", ""], ["Rudberg", "Elias", ""], ["Rubensson", "Emanuel H.", ""]]}, {"id": "1901.08081", "submitter": "Li Wang", "authors": "Jose A. Carrillo, Katy Craig, Li Wang and Chaozhen Wei", "title": "Primal dual methods for Wasserstein gradient flows", "comments": null, "journal-ref": null, "doi": null, "report-no": "UCSB Math 2019-01", "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining the classical theory of optimal transport with modern operator\nsplitting techniques, we develop a new numerical method for nonlinear, nonlocal\npartial differential equations, arising in models of porous media, materials\nscience, and biological swarming. Our method proceeds as follows: First, we\ndiscretize in time, either via the classical JKO scheme or via a novel\nCrank-Nicolson type method we introduce. Next, we use the Benamou-Brenier\ndynamical characterization of the Wasserstein distance to reduce computing the\nsolution of the discrete time equations to solving fully discrete minimization\nproblems, with strictly convex objective functions and linear constraints.\nThird, we compute the minimizers by applying a recently introduced, provably\nconvergent primal dual splitting scheme for three operators [Yan 2018].\n  By leveraging the PDEs' underlying variational structure, our method\novercomes stability issues present in previous numerical work built on explicit\ntime discretizations, which suffer due to the equations' strong nonlinearities\nand degeneracies. Our method is also naturally positivity and mass preserving\nand, in the case of the JKO scheme, energy decreasing. We prove that minimizers\nof the fully discrete problem converge to minimizers of the spatially\ncontinuous, discrete time problem as the spatial discretization is refined. We\nconclude with simulations of nonlinear PDEs and Wasserstein geodesics in one\nand two dimensions that illustrate the key properties of our approach,\nincluding higher order convergence our novel Crank-Nicolson type method, when\ncompared to the classical JKO method.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 19:06:47 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 03:06:44 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Carrillo", "Jose A.", ""], ["Craig", "Katy", ""], ["Wang", "Li", ""], ["Wei", "Chaozhen", ""]]}, {"id": "1901.08116", "submitter": "Konstantin Pieper", "authors": "Konstantin Pieper, K. Chad Sockwell, Max Gunzburger", "title": "Exponential time differencing for mimetic multilayer ocean models", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.108900", "report-no": null, "categories": "math.NA cs.NA physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework for exponential time discretization of the multilayer rotating\nshallow water equations is developed in combination with a mimetic\ndiscretization in space. The method is based on a combination of existing\nexponential time differencing (ETD) methods and a careful choice of approximate\nJacobians. The discrete Hamiltonian structure and conservation properties of\nthe model are taken into account, in order to ensure stability of the method\nfor large time steps and simulation horizons. In the case of many layers,\nfurther efficiency can be gained by a layer reduction which is based on the\nvertical structure of fast and slow modes. Numerical experiments on the example\nof a mid-latitude regional ocean model confirm long term stability for time\nsteps increased by an order of magnitude over the explicit CFL, while\nmaintaining accuracy for key statistical quantities.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 03:53:26 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 21:23:29 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Pieper", "Konstantin", ""], ["Sockwell", "K. Chad", ""], ["Gunzburger", "Max", ""]]}, {"id": "1901.08393", "submitter": "Alexander Haberl", "authors": "Timo Betcke, Alexander Haberl, and Dirk Praetorius", "title": "Adaptive boundary element methods for the computation of the\n  electrostatic capacity on complex polyhedra", "comments": null, "journal-ref": "Journal of Computational Physics, 397 (2019), 108837", "doi": "10.1016/j.jcp.2019.07.036", "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate computation of the electrostatic capacity of three dimensional\nobjects is a fascinating benchmark problem with a long and rich history. In\nparticular, the capacity of the unit cube has widely been studied, and recent\nadvances allow to compute its capacity to more than ten digits of accuracy.\nHowever, the accurate computation of the capacity for general three dimensional\npolyhedra is still an open problem. In this paper, we propose a new algorithm\nbased on a combination of ZZ-type a posteriori error estimation and effective\noperator preconditioned boundary integral formulations to easily compute the\ncapacity of complex three dimensional polyhedra to 5 digits and more. While\nthis paper focuses on the capacity as a benchmark problem, it also discusses\nimplementational issues of adaptive boundary element solvers, and we provide\ncodes based on the boundary element package Bempp to make the underlying\ntechniques accessible to a wide range of practical problems.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 13:19:52 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 16:46:43 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Betcke", "Timo", ""], ["Haberl", "Alexander", ""], ["Praetorius", "Dirk", ""]]}, {"id": "1901.08411", "submitter": "Gianna Maria Del Corso", "authors": "Roberto Bevilacqua, Gianna M. Del Corso, Luca Gemignani", "title": "Efficient Reduction of Compressed Unitary plus Low-rank Matrices to\n  Hessenberg form", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present fast numerical methods for computing the Hessenberg reduction of a\nunitary plus low-rank matrix $A=G+U V^H$, where $G\\in \\mathbb C^{n\\times n}$ is\na unitary matrix represented in some compressed format using $O(nk)$ parameters\nand $U$ and $V$ are $n\\times k$ matrices with $k< n$. At the core of these\nmethods is a certain structured decomposition, referred to as a LFR\ndecomposition, of $A$ as product of three possibly perturbed unitary $k$\nHessenberg matrices of size $n$. It is shown that in most interesting cases an\ninitial LFR decomposition of $A$ can be computed very cheaply. Then we prove\nstructural properties of LFR decompositions by giving conditions under which\nthe LFR decomposition of $A$ implies its Hessenberg shape. Finally, we describe\na bulge chasing scheme for converting the initial LFR decomposition of $A$ into\nthe LFR decomposition of a Hessenberg matrix by means of unitary\ntransformations. The reduction can be performed at the overall computational\ncost of $O(n^2 k)$ arithmetic operations using $O(nk)$ storage. The computed\nLFR decomposition of the Hessenberg reduction of $A$ can be processed by the\nfast QR algorithm presented in [8] in order to compute the eigenvalues of $A$\nwithin the same costs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 13:57:06 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 09:01:23 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Bevilacqua", "Roberto", ""], ["Del Corso", "Gianna M.", ""], ["Gemignani", "Luca", ""]]}, {"id": "1901.08774", "submitter": "Erik Gengel", "authors": "Erik Gengel, Arkady Pikovsky", "title": "Phase demodulation with iterative Hilbert transform embeddings", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.NA physics.ins-det physics.med-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose an efficient method for demodulation of phase modulated signals\nvia iterated Hilbert transform embeddings. We show that while a usual approach\nbased on one application of the Hilbert transform provides only an\napproximation to a proper phase, with iterations the accuracy is essentially\nimproved, up to precision limited mainly by the discretization effects. We\ndemonstrate that the method is applicable to arbitrarily complex waveforms, and\nto modulations fast compared to the basic frequency. Furthermore, we develop a\nperturbative theory applicable to simple cosine waveforms, showing convergence\nof the technique.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 08:12:37 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Gengel", "Erik", ""], ["Pikovsky", "Arkady", ""]]}, {"id": "1901.08778", "submitter": "Gerlind Plonka", "authors": "Kilian Stampfer and Gerlind Plonka", "title": "The Generalized Operator Based Prony Method", "comments": "31 pages, 2 figures", "journal-ref": "Constructive Approximation 52 (2020), 247-282", "doi": "10.1007/s00365-020-09501-6", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized Prony method introduced by Peter & Plonka (2013) is a\nreconstruction technique for a large variety of sparse signal models that can\nbe represented as sparse expansions into eigenfunctions of a linear operator\n$A$. However, this procedure requires the evaluation of higher powers of the\nlinear operator $A$ that are often expensive to provide.\n  In this paper we propose two important extensions of the generalized Prony\nmethod that simplify the acquisition of the needed samples essentially and at\nthe same time can improve the numerical stability of the method. The first\nextension regards the change of operators from $A$ to $\\varphi(A)$, where\n$\\varphi$ is an analytic function, while $A$ and $\\varphi(A)$ possess the same\nset of eigenfunctions. The goal is now to choose $\\varphi$ such that the powers\nof $\\varphi(A)$ are much simpler to evaluate than the powers of $A$. The second\nextension concerns the choice of the sampling functionals. We show, how new\nsets of different sampling functionals $F_{k}$ can be applied with the goal to\nreduce the needed number of powers of the operator $A$ (resp. $\\varphi(A)$) in\nthe sampling scheme and to simplify the acquisition process for the recovery\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 08:28:05 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 08:27:56 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Stampfer", "Kilian", ""], ["Plonka", "Gerlind", ""]]}, {"id": "1901.08783", "submitter": "Alberto F. Mart\\'in", "authors": "Santiago Badia, Alberto F. Mart\\'in, Marc Olm", "title": "Scalable solvers for complex electromagnetics problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.finel.2019.04.003", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present scalable balancing domain decomposition by\nconstraints methods for linear systems arising from arbitrary order edge finite\nelement discretizations of multi-material and heterogeneous 3D problems. In\norder to enforce the continuity across subdomains of the method, we use a\npartition of the interface objects (edges and faces) into sub-objects\ndetermined by the variation of the physical coefficients of the problem. For\nmulti-material problems, a constant coefficient condition is enough to define\nthis sub-partition of the objects. For arbitrarily heterogeneous problems, a\nrelaxed version of the method is defined, where we only require that the\nmaximal contrast of the physical coefficient in each object is smaller than a\npredefined threshold. Besides, the addition of perturbation terms to the\npreconditioner is empirically shown to be effective in order to deal with the\ncase where the two coefficients of the model problem jump simultaneously across\nthe interface. The new method, in contrast to existing approaches for problems\nin curl-conforming spaces does not require spectral information whilst\nproviding robustness with regard to coefficient jumps and heterogeneous\nmaterials. A detailed set of numerical experiments, which includes the\napplication of the preconditioner to 3D realistic cases, shows excellent weak\nscalability properties of the implementation of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 08:51:38 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 07:43:18 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 16:16:53 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Badia", "Santiago", ""], ["Mart\u00edn", "Alberto F.", ""], ["Olm", "Marc", ""]]}, {"id": "1901.09007", "submitter": "Thomas Trogdon", "authors": "Percy Deift and Thomas Trogdon", "title": "The conjugate gradient algorithm on well-conditioned Wishart matrices is\n  almost deterministic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC cs.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the number of iterations required to solve a random positive\ndefinite linear system with the conjugate gradient algorithm is almost\ndeterministic for large matrices. We treat the case of Wishart matrices $W =\nXX^*$ where $X$ is $n \\times m$ and $n/m \\sim d$ for $0 < d < 1$. Precisely, we\nprove that for most choices of error tolerance, as the matrix increases in\nsize, the probability that the iteration count deviates from an explicit\ndeterministic value tends to zero. In addition, for a fixed iteration count, we\nshow that the norm of the error vector and the norm of the residual converge\nexponentially fast in probability, converge in mean and converge almost surely.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 18:14:49 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 04:05:44 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 18:47:09 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Deift", "Percy", ""], ["Trogdon", "Thomas", ""]]}, {"id": "1901.09162", "submitter": "Carlos Borges", "authors": "Carlos Borges and George Biros", "title": "A domain decomposition preconditioning for the integral equation\n  formulation of the inverse scattering problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose domain decomposition preconditioners for the solution of an\nintegral equation formulation of forward and inverse acoustic scattering\nproblems with point scatterers. We study both forward and inverse problems and\npropose preconditioning techniques to accelerate the iterative solvers. For the\nforward scattering problem, we extend the domain decomposition based\npreconditioning techniques presented for partial differential equations in {\\em\n\"A restricted additive Schwarz preconditioner for general sparse linear\nsystems\", SIAM Journal on Scientific Computing, 21 (1999), pp. 792--797}, to\nintegral equations. We combine this domain decomposition preconditioner with a\nlow-rank correction, which is easy to construct, forming a new preconditioner.\nFor the inverse scattering problem, we use the forward problem preconditioner\nas a building block for constructing a preconditioner for the Gauss-Newton\nHessian. We present numerical results that demonstrate the performance of both\npreconditioning strategies.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 04:58:42 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 15:41:54 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Borges", "Carlos", ""], ["Biros", "George", ""]]}, {"id": "1901.09400", "submitter": "Nicolas Papadakis", "authors": "Nicolas Papadakis", "title": "Approximation of Wasserstein distance with Transshipment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for approximating the p-Wasserstein distance between histograms\ndefined on unstructured discrete grids is presented. It is based on the\ncomputation of a barycenter constrained to be supported on a low dimensional\nsubspace, which corresponds to a transshipment problem. A multi-scale strategy\nis also considered. The method provides sparse transport matrices and can be\napplied to large scale and non structured data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 16:31:52 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 09:46:19 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 10:19:31 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 14:58:41 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Papadakis", "Nicolas", ""]]}, {"id": "1901.09548", "submitter": "Yiping Lu", "authors": "Bin Dong, Haocheng Ju, Yiping Lu, Zuoqiang Shi", "title": "CURE: Curvature Regularization For Missing Data Recovery", "comments": "17 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data recovery is an important and yet challenging problem in imaging\nand data science. Successful models often adopt certain carefully chosen\nregularization. Recently, the low dimension manifold model (LDMM) was\nintroduced by S.Osher et al. and shown effective in image inpainting. They\nobserved that enforcing low dimensionality on image patch manifold serves as a\ngood image regularizer. In this paper, we observe that having only the low\ndimension manifold regularization is not enough sometimes, and we need\nsmoothness as well. For that, we introduce a new regularization by combining\nthe low dimension manifold regularization with a higher order Curvature\nRegularization, and we call this new regularization CURE for short. The key\nstep of solving CURE is to solve a biharmonic equation on a manifold. We\nfurther introduce a weighted version of CURE, called WeCURE, in a similar\nmanner as the weighted nonlocal Laplacian (WNLL) method. Numerical experiments\nfor image inpainting and semi-supervised learning show that the proposed CURE\nand WeCURE significantly outperform LDMM and WNLL respectively.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 08:42:39 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 15:19:31 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 00:28:54 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Dong", "Bin", ""], ["Ju", "Haocheng", ""], ["Lu", "Yiping", ""], ["Shi", "Zuoqiang", ""]]}, {"id": "1901.09635", "submitter": "Mattia Zanella", "authors": "Mattia Zanella", "title": "Structure preserving stochastic Galerkin methods for Fokker-Planck\n  equations with background interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the construction of structure preserving stochastic\nGalerkin schemes for Fokker-Planck type equations with uncertainties and\ninteracting with an external distribution, that we refer to as a background\ndistribution. The proposed methods are capable to preserve physical properties\nin the approximation of statistical moments of the problem like nonnegativity,\nentropy dissipation and asymptotic behaviour of the expected solution. The\nintroduced methods are second order accurate in the transient regimes and high\norder for large times. We present applications of the developed schemes to the\ncase of fixed and dynamic background distribution for models of collective\nbehaviour.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 13:18:56 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 19:26:13 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zanella", "Mattia", ""]]}, {"id": "1901.09670", "submitter": "Jayant A. Gupchup", "authors": "Jayant Gupchup, R\\u{a}zvan Mus\\u{a}loiu-E., Alex Szalay, Andreas\n  Terzis", "title": "Sundial: Using Sunlight to Reconstruct Global Timestamps", "comments": null, "journal-ref": "EWSN 2009 Proceedings of the 6th European Conference on Wireless\n  Sensor Networks", "doi": "10.1007/978-3-642-00224-3_12", "report-no": null, "categories": "cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates postmortem timestamp reconstruction in environmental\nmonitoring networks. In the absence of a time-synchronization protocol, these\nnetworks use multiple pairs of (local, global) timestamps to retroactively\nestimate the motes' clock drift and offset and thus reconstruct the measurement\ntime series. We present Sundial, a novel offline algorithm for reconstructing\nglobal timestamps that is robust to unreliable global clock sources. Sundial\nreconstructs timestamps by correlating annual solar patterns with measurements\nprovided by the motes' inexpensive light sensors. The surprising ability to\naccurately estimate the length of day using light intensity measurements\nenables Sundial to be robust to arbitrary mote clock restarts. Experimental\nresults, based on multiple environmental network deployments spanning a period\nof over 2.5 years, show that Sundial achieves accuracy as high as 10 parts per\nmillion (ppm), using solar radiation readings recorded at 20 minute intervals.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:21:29 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Gupchup", "Jayant", ""], ["Mus\u0103loiu-E.", "R\u0103zvan", ""], ["Szalay", "Alex", ""], ["Terzis", "Andreas", ""]]}, {"id": "1901.09689", "submitter": "Mario Kapl", "authors": "Cesare Bracco and Carlotta Giannelli and Mario Kapl and Rafael\n  V\\'azquez", "title": "Isogeometric analysis with $C^1$ hierarchical functions on planar\n  two-patch geometries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive isogeometric methods for the solution of partial differential\nequations rely on the construction of locally refinable spline spaces. A simple\nand efficient way to obtain these spaces is to apply the multi-level\nconstruction of hierarchical splines, that can be used on single-patch domains\nor in multi-patch domains with $C^0$ continuity across the patch interfaces.\nDue to the benefits of higher continuity in isogeometric methods, recent works\ninvestigated the construction of spline spaces with global $C^1$ continuity on\ntwo or more patches. In this paper, we show how these approaches can be\ncombined with the hierarchical construction to obtain global $C^1$ continuous\nhierarchical splines on two-patch domains. A selection of numerical examples is\npresented to highlight the features and effectivity of the construction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 14:31:15 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:35:43 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Bracco", "Cesare", ""], ["Giannelli", "Carlotta", ""], ["Kapl", "Mario", ""], ["V\u00e1zquez", "Rafael", ""]]}, {"id": "1901.09876", "submitter": "Fushuai Jiang", "authors": "Fushuai Jiang and Garving K. Luli", "title": "Nonnegative $C^2(\\mathbb{R}^2)$ interpolation", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove two improved versions of the Finiteness Principle for\nnonnegative $ C^2(\\mathbb{R}^2) $ interpolation, previously proven by\nFefferman, Israel, and Luli. The first version sharpens the finiteness constant\nto $ 64 $, and the second version carries better computational practicality.\nAlong the way, we also provide detailed construction of nonnegative $ C^2 $\ninterpolants in one-dimension, and prove the nonexistence of a bounded linear $\nC^2 $-extension operator that preserves nonnegativity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 18:41:08 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 23:03:23 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 19:11:35 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 04:37:13 GMT"}, {"version": "v5", "created": "Sun, 19 Jul 2020 01:08:07 GMT"}, {"version": "v6", "created": "Thu, 30 Jul 2020 16:57:44 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Jiang", "Fushuai", ""], ["Luli", "Garving K.", ""]]}, {"id": "1901.09924", "submitter": "Monika Wolfmayr", "authors": "Monika Wolfmayr", "title": "Guaranteed lower bounds for cost functionals of time-periodic parabolic\n  optimization problems", "comments": "27 pages, 10 tables. This work extends the analysis of\n  arXiv:1511.05699", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new technique is shown for deriving computable, guaranteed\nlower bounds of functional type (minorants) for two different cost functionals\nsubject to a parabolic time-periodic boundary value problem. Together with\nprevious results on upper bounds (majorants) for one of the cost functionals,\nboth minorants and majorants lead to two-sided estimates of functional type for\nthe optimal control problem. Both upper and lower bounds are derived for the\nsecond new cost functional subject to the same parabolic PDE-constraints, but\nwhere the target is a desired gradient. The time-periodic optimal control\nproblems are discretized by the multiharmonic finite element method leading to\nlarge systems of linear equations having a saddle point structure. The\nderivation of preconditioners for the minimal residual method for the new\noptimization problem is discussed in more detail. Finally, several numerical\nexperiments for both optimal control problems are presented confirming the\ntheoretical results obtained. This work provides the basis for an adaptive\nscheme for time-periodic optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 18:58:20 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 22:04:11 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 16:58:48 GMT"}, {"version": "v4", "created": "Wed, 22 Apr 2020 21:54:26 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Wolfmayr", "Monika", ""]]}, {"id": "1901.09990", "submitter": "Thomas Yu", "authors": "Jingmin Chen, Thomas Yu, Patrick Brogan, Robert Kusner, Yilin Yang,\n  Andrew Zigerelli", "title": "Numerical Methods for Biomembranes: conforming subdivision methods\n  versus non-conforming PL methods", "comments": "35 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Canham-Helfrich-Evans models of biomembranes consist of a family of\ngeometric constrained variational problems. In this article, we compare two\nclasses of numerical methods for these variational problems based on piecewise\nlinear (PL) and subdivision surfaces (SS). Since SS methods are based on spline\napproximation and can be viewed as higher order versions of PL methods, one may\nexpect that the only difference between the two methods is in the accuracy\norder. In this paper, we prove that a numerical method based on minimizing any\none of the `PL Willmore energies' proposed in the literature would fail to\nconverge to a solution of the continuous problem, whereas a method based on\nminimization of the bona fide Willmore energy, well-defined for SS but not PL\nsurfaces, succeeds. Motivated by this analysis, we propose also a\nregularization method for the PL method based on techniques from conformal\ngeometry. We address a number of implementation issues crucial for the\nefficiency of our solver. A software package called Wmincon accompanies this\narticle, provides parallel implementations of all the relevant geometric\nfunctionals. When combined with a standard constrained optimization solver, the\ngeometric variational problems can then be solved numerically. To this end, we\nrealize that some of the available optimization algorithms/solvers are capable\nof preserving symmetry, while others manage to break symmetry; we explore the\nconsequences of this observation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 20:40:11 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 19:48:59 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Chen", "Jingmin", ""], ["Yu", "Thomas", ""], ["Brogan", "Patrick", ""], ["Kusner", "Robert", ""], ["Yang", "Yilin", ""], ["Zigerelli", "Andrew", ""]]}, {"id": "1901.10068", "submitter": "Wei Ma", "authors": "Wei Ma, Zhen Qian", "title": "Statistical inference of probabilistic origin-destination demand using\n  day-to-day traffic data", "comments": null, "journal-ref": "Transportation Research Part C: Emerging Technologies 88 (2018):\n  227-256", "doi": "10.1016/j.trc.2017.12.015", "report-no": null, "categories": "stat.ME cs.NA cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent transportation network studies on uncertainty and reliability call for\nmodeling the probabilistic O-D demand and probabilistic network flow. Making\nthe best use of day-to-day traffic data collected over many years, this paper\ndevelops a novel theoretical framework for estimating the mean and\nvariance/covariance matrix of O-D demand considering the day-to-day variation\ninduced by travelers' independent route choices. It also estimates the\nprobability distributions of link/path flow and their travel cost where the\nvariance stems from three sources, O-D demand, route choice and unknown errors.\nThe framework estimates O-D demand mean and variance/covariance matrix\niteratively, also known as iterative generalized least squares (IGLS) in\nstatistics. Lasso regularization is employed to obtain sparse covariance matrix\nfor better interpretation and computational efficiency. Though the\nprobabilistic O-D estimation (ODE) works with a much larger solution space than\nthe deterministic ODE, we show that its estimator for O-D demand mean is no\nworse than the best possible estimator by an error that reduces with the\nincrease in sample size. The probabilistic ODE is examined on two small\nnetworks and two real-world large-scale networks. The solution converges\nquickly under the IGLS framework. In all those experiments, the results of the\nprobabilistic ODE are compelling, satisfactory and computationally plausible.\nLasso regularization on the covariance matrix estimation leans to underestimate\nmost of variance/covariance entries. A proper Lasso penalty ensures a good\ntrade-off between bias and variance of the estimation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 02:07:30 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ma", "Wei", ""], ["Qian", "Zhen", ""]]}, {"id": "1901.10199", "submitter": "Davide Palitta", "authors": "Davide Palitta", "title": "The projected Newton-Kleinman method for the algebraic Riccati equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The numerical solution of the algebraic Riccati equation is a challenging\ntask especially for very large problem dimensions. In this paper we present a\nnew algorithm that combines the very appealing computational features of\nprojection methods with the convergence properties of the inexact\nNewton-Kleinman procedure equipped with a line search. In particular, the\nNewton scheme is completely merged in a projection framework with a single\napproximation space so that the Newton-Kleinman iteration is only implicitly\nperformed. Moreover, the line search turns out to be exact in our setting,\ni.e., the existence of a local minimum of the Riccati residual norm along the\ncurrent search direction is guaranteed and the corresponding minimizer is\nchosen as step-size. This property determines a monotone decrease of the\nRiccati residual norm under some mild assumptions. Several numerical results\nare reported to illustrate the potential of our novel approach.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 10:05:44 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 14:43:22 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 19:41:13 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Palitta", "Davide", ""]]}, {"id": "1901.10278", "submitter": "Tran Nhan Tam Quyen", "authors": "Michael Hinze and Tran Nhan Tam Quyen", "title": "Finite element approximation of source term identification with\n  TV-regularization", "comments": "Inverse source problem, boundary observation, total variation\n  regularization, ill-posedness, finite element method, stability and\n  convergence, elliptic boundary value problem", "journal-ref": null, "doi": "10.1088/1361-6420/ab3478", "report-no": null, "categories": "math.NA cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the problem of recovering the source term in an\nelliptic system from a measurement of the state on a part of the boundary. For\nthe particular interest in reconstructing probably discontinuous sources, we\nuse the standard least squares method with the total variation regularization.\nThe finite element method is then applied to discretize the minimization\nproblem, we show the stability and the convergence of this technique.\nFurthermore, we have proposed an algorithm to stably solve the minimization\nproblem. We prove the iterate sequence generated by the derived algorithm\nconverging to a minimizer of the regularization problem, and that convergence\nmeasurement is also established. Finally, a numerical experiment is presented\nto illustrate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 13:38:30 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 16:58:43 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Hinze", "Michael", ""], ["Quyen", "Tran Nhan Tam", ""]]}, {"id": "1901.10375", "submitter": "Stefano Massei", "authors": "Sophie Hautphenne and Stefano Massei", "title": "A low-rank technique for computing the quasi-stationary distribution of\n  subcritical Galton-Watson processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for computing the quasi-stationary distribution of\nsubcritical Galton--Watson branching processes. This algorithm is based on a\nparticular discretization of a well-known functional equation that\ncharacterizes the quasi-stationary distribution of these processes. We provide\na theoretical analysis of the approximate low-rank structure that stems from\nthis discretization, and we extend the procedure to multitype branching\nprocesses. We use numerical examples to demonstrate that our algorithm is both\nmore accurate and more efficient than other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 16:42:42 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 16:29:25 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Hautphenne", "Sophie", ""], ["Massei", "Stefano", ""]]}, {"id": "1901.10559", "submitter": "Osman Asif Malik", "authors": "Osman Asif Malik, Stephen Becker", "title": "Fast Randomized Matrix and Tensor Interpolative Decomposition Using\n  CountSketch", "comments": "25 pages, 2 figures; rearranged text, added references, added more\n  experiments", "journal-ref": "Advances in Computational Mathematics 46, article number: 76, 2020", "doi": "10.1007/s10444-020-09816-9", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new fast randomized algorithm for interpolative decomposition of\nmatrices which utilizes CountSketch. We then extend this approach to the tensor\ninterpolative decomposition problem introduced by Biagioni et al. (J. Comput.\nPhys. 281, pp. 116-134, 2015). Theoretical performance guarantees are provided\nfor both the matrix and tensor settings. Numerical experiments on both\nsynthetic and real data demonstrate that our algorithms maintain the accuracy\nof competing methods, while running in less time, achieving at least an order\nof magnitude speed-up on large matrices and tensors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 21:14:09 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 23:04:01 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Malik", "Osman Asif", ""], ["Becker", "Stephen", ""]]}, {"id": "1901.10750", "submitter": "Maria Cruz Varona", "authors": "Maria Cruz Varona, Raphael Gebhart, Julian Suk and Boris Lohmann", "title": "Practicable Simulation-Free Model Order Reduction by Nonlinear Moment\n  Matching", "comments": "7 pages, 3 figures; submitted to ECC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a practicable simulation-free model order reduction method by\nnonlinear moment matching is developed. Based on the steady-state\ninterpretation of linear moment matching, we comprehensively explain the\nextension of this reduction concept to nonlinear systems presented in [1],\nprovide some new insights and propose some simplifications to achieve a\nfeasible and numerically efficient nonlinear model reduction algorithm. This\nalgorithm relies on the solution of nonlinear systems of equations rather than\non the expensive simulation of the original model or the difficult solution of\na nonlinear partial differential equation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 10:30:28 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Varona", "Maria Cruz", ""], ["Gebhart", "Raphael", ""], ["Suk", "Julian", ""], ["Lohmann", "Boris", ""]]}, {"id": "1901.10759", "submitter": "Fehmi Cirak", "authors": "Qiaoling Zhang, Thomas Takacs and Fehmi Cirak", "title": "Manifold-based B-splines on unstructured meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new manifold-based splines that are able to exactly reproduce\nB-splines on unstructured surface meshes. Such splines can be used in\nisogeometric analysis (IGA) to represent smooth surfaces of arbitrary topology.\nSince prevalent computer-aided design (CAD) models are composed of\ntensor-product B-spline patches, any IGA suitable construction should be able\nto reproduce B-splines. To achieve this goal, we focus on univariate\nmanifold-based constructions that can reproduce B-splines. The manifold-based\nsplines are constructed by smoothly blending together polynomial interpolants\ndefined on overlapping charts. The proposed constructions automatically\nreproduce B-splines in regular parts of the mesh, with no extraordinary\nvertices, and polynomial basis functions in the remaining parts of the mesh. We\nstudy and compare analytically and numerically the finite element convergence\nof several univariate constructions. The obtained results directly carry over\nto the tensor-product case.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 10:43:36 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Zhang", "Qiaoling", ""], ["Takacs", "Thomas", ""], ["Cirak", "Fehmi", ""]]}, {"id": "1901.10763", "submitter": "Anas Batou", "authors": "A. Batou", "title": "An approximate It\\^o-SDE based simulated annealing algorithm for\n  multivariate design optimization problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research concerns design optimization problems involving numerous design\nparameters and large computational models. These problems generally consist in\nnon-convex constrained optimization problems in large and sometimes complex\nsearch spaces. The classical simulated annealing algorithm rapidly loses its\nefficiency in high search space dimension. In this paper a variant of the\nclassical simulated annealing algorithm is constructed by incorporating (1) an\nIt\\^o stochastic differential equation generator (ISDE) for the transition\nprobability and (2) a polyharmonic splines interpolation of the cost function.\nThe control points are selected iteratively during the research of the optimum.\nThe proposed algorithm explores efficiently the design search space to find the\nglobal optimum of the cost function as the best control point. The algorithm is\nillustrated on two applications. The first application consists in a simple\nfunction in relatively high dimension. The second is related to a Finite\nElement model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 11:10:55 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Batou", "A.", ""]]}, {"id": "1901.10854", "submitter": "Martin Hutzenthaler", "authors": "Martin Hutzenthaler, Arnulf Jentzen, Thomas Kruse, Tuan Anh Nguyen", "title": "A proof that rectified deep neural networks overcome the curse of\n  dimensionality in the numerical approximation of semilinear heat equations", "comments": "29 pages", "journal-ref": "SN Partial Differ. Equ. Appl. 1, 10 (2020)", "doi": "10.1007/s42985-019-0006-9", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks and other deep learning methods have very successfully\nbeen applied to the numerical approximation of high-dimensional nonlinear\nparabolic partial differential equations (PDEs), which are widely used in\nfinance, engineering, and natural sciences. In particular, simulations indicate\nthat algorithms based on deep learning overcome the curse of dimensionality in\nthe numerical approximation of solutions of semilinear PDEs. For certain linear\nPDEs this has also been proved mathematically. The key contribution of this\narticle is to rigorously prove this for the first time for a class of nonlinear\nPDEs. More precisely, we prove in the case of semilinear heat equations with\ngradient-independent nonlinearities that the numbers of parameters of the\nemployed deep neural networks grow at most polynomially in both the PDE\ndimension and the reciprocal of the prescribed approximation accuracy. Our\nproof relies on recently introduced multilevel Picard approximations of\nsemilinear PDEs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 14:37:35 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 07:01:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Hutzenthaler", "Martin", ""], ["Jentzen", "Arnulf", ""], ["Kruse", "Thomas", ""], ["Nguyen", "Tuan Anh", ""]]}, {"id": "1901.10888", "submitter": "Yoel Shkolnisky", "authors": "Gabi Pragier and Yoel Shkolnisky", "title": "A common lines approach for ab-initio modeling of cyclically-symmetric\n  molecules", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6420/ab2fb2", "report-no": null, "categories": "cs.CG cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in single particle reconstruction in cryo-electron\nmicroscopy is to find a three-dimensional model of a molecule using its\ntwo-dimensional noisy projection-images. In this paper, we propose a robust\n\"angular reconstitution\" algorithm for molecules with $n$-fold cyclic symmetry,\nthat estimates the orientation parameters of the projections-images. Our\nsuggested method utilizes self common lines which induce identical lines within\nthe Fourier transform of each projection-image. We show that the location of\nself common lines admits quite a few favorable geometrical constraints, thus\nallowing to detect them even in a noisy setting. In addition, for molecules\nwith higher order rotational symmetry, our proposed method exploits the fact\nthat there exist numerous common lines between any two Fourier transformed\nprojection-images of such molecules, thus allowing to determine their relative\norientation even under high levels of noise. The efficacy of our proposed\nmethod is demonstrated using numerical experiments conducted on simulated and\nexperimental data.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 21:05:19 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 18:59:27 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 08:30:10 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Pragier", "Gabi", ""], ["Shkolnisky", "Yoel", ""]]}, {"id": "1901.10961", "submitter": "M. H. van Emden", "authors": "M.H. van Emden", "title": "Egyptian multiplication and some of its ramifications", "comments": "7 pages and 6 figures", "journal-ref": null, "doi": null, "report-no": "DCS-362-IR", "categories": "math.NA cs.NA cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplication and exponentiation can be defined by equations in which one of\nthe operands is written as the sum of powers of two. When these powers are\nnon-negative integers, the operand is integer; without this restriction it is a\nfraction. The defining equation can be used in evaluation mode or in solving\nmode. In the former case we obtain \"Egyptian\" multiplication, dating from the\n17th century BC. In solving mode we obtain an efficient algorithm for division\nby repeated subtraction, dating from the 20th century AD. In the exponentiation\ncase we also distinguish between evaluation mode and solving mode. Evaluation\nmode yields a possibly new algorithm for raising to a fractional power. Solving\nmode yields the algorithm for logarithms invented by Briggs in the 17th century\nAD.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 17:20:16 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 03:31:56 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["van Emden", "M. H.", ""]]}, {"id": "1901.11269", "submitter": "Simon Cotter", "authors": "Simon L. Cotter and Ioannis G. Kevrekidis and Paul Russell", "title": "Transport map accelerated adaptive importance sampling, and application\n  to inverse problems arising from multiscale stochastic reaction networks", "comments": "44 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, Bayesian inverse problems can give rise to probability\ndistributions which contain complexities due to the Hessian varying greatly\nacross parameter space. This complexity often manifests itself as lower\ndimensional manifolds on which the likelihood function is invariant, or varies\nvery little. This can be due to trying to infer unobservable parameters, or due\nto sloppiness in the model which is being used to describe the data. In such a\nsituation, standard sampling methods for characterising the posterior\ndistribution, which do not incorporate information about this structure, will\nbe highly inefficient.\n  In this paper, we seek to develop an approach to tackle this problem when\nusing adaptive importance sampling methods, by using optimal transport maps to\nsimplify posterior distributions which are concentrated on lower dimensional\nmanifolds. This approach is applicable to a whole range of problems for which\nMonte Carlo Markov chain (MCMC) methods mix slowly.\n  We demonstrate the approach by considering inverse problems arising from\npartially observed stochastic reaction networks. In particular, we consider\nsystems which exhibit multiscale behaviour, but for which only the slow\nvariables in the system are observable. We demonstrate that certain multiscale\napproximations lead to more consistent approximations of the posterior than\nothers. The use of optimal transport maps stabilises the ensemble transform\nadaptive importance sampling (ETAIS) method, and allows for efficient sampling\nwith smaller ensemble sizes. This approach allows us to take advantage of the\nlarge increases of efficiency when using adaptive importance sampling methods\nfor previously intractable Bayesian inverse problems with complex posterior\nstructure.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 08:48:52 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:15:20 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cotter", "Simon L.", ""], ["Kevrekidis", "Ioannis G.", ""], ["Russell", "Paul", ""]]}, {"id": "1901.11295", "submitter": "Ling-Ze Bu", "authors": "Ling-Ze Bu, Wei Zhao, Wei Wang", "title": "Second order hierarchical partial least squares regression-polynomial\n  chaos expansion for global sensitivity and reliability analyses of\n  high-dimensional models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To tackle the curse of dimensionality and multicollinearity problems of\npolynomial chaos expansion for analyzing global sensitivity and reliability of\nmodels with high stochastic dimensions, this paper proposes a novel\nnon-intrusive algorithm called second order hierarchical partial least squares\nregression-polynomial chaos expansion. The first step of the innovative\nalgorithm is to divide the polynomials into several groups according to their\ninteraction degrees and nonlinearity degrees, which avoids large data sets and\nreflects the relationship between polynomial chaos expansion and high\ndimensional model representation. Then a hierarchical regression algorithm\nbased on partial least squares regression is devised for extracting latent\nvariables from each group at different variable levels. The optimal interaction\ndegree and the corresponding nonlinearity degrees are automatically estimated\nwith an improved cross validation scheme. Based on the relationship between\nvariables at two adjacent levels, Sobol' sensitivity indices can be obtained by\na simple post-processing of expansion coefficients. Thus, the expansion is\ngreatly simplified through retaining the important inputs, leading to accurate\nreliability analysis without requirements of additional model evaluations.\nFinally, finite element models with three different types of structures\nverified that the proposed method can greatly improve the computational\nefficiency compared with the ordinary least squares regression-based method.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 10:07:19 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 12:25:02 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 06:46:14 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Bu", "Ling-Ze", ""], ["Zhao", "Wei", ""], ["Wang", "Wei", ""]]}, {"id": "1901.11371", "submitter": "Haizhao Yang", "authors": "Yang Liu and Haizhao Yang", "title": "A Hierarchical Butterfly LU Preconditioner for Two-Dimensional\n  Electromagnetic Scattering Problems Involving Open Surfaces", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.109014", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a hierarchical interpolative decomposition butterfly-LU\nfactorization (H-IDBF-LU) preconditioner for solving two-dimensional\nelectric-field integral equations (EFIEs) in electromagnetic scattering\nproblems of perfect electrically conducting objects with open surfaces.\nH-IDBF-LU leverages the interpolative decomposition butterfly factorization\n(IDBF) to compress dense blocks of the discretized EFIE operator to expedite\nits application; this compressed operator also serves as an approximate LU\nfactorization of the EFIE operator leading to an efficient preconditioner in\niterative solvers. Both the memory requirement and computational cost of the\nH-IDBF-LU solver scale as $O(N\\log^2 N)$ in one iteration; the total number of\niterations required for a reasonably good accuracy scales as $O(1)$ to\n$O(\\log^2N)$ in all of our numerical tests. The efficacy and accuracy of the\nproposed preconditioned iterative solver are demonstrated via its application\nto a broad range of scatterers involving up to $100$ million unknowns.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 14:27:13 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 22:29:09 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 21:51:33 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Liu", "Yang", ""], ["Yang", "Haizhao", ""]]}, {"id": "1901.11521", "submitter": "Mikhail A. Botchev", "authors": "Mike A. Botchev", "title": "A nested Schur complement solver with mesh-independent convergence for\n  the time domain photonics modeling", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A nested Schur complement solver is proposed for iterative solution of linear\nsystems arising in exponential and implicit time integration of the Maxwell\nequations with perfectly matched layer (PML) nonreflecting boundary conditions.\nThese linear systems are the so-called double saddle point systems whose\nstructure is handled by the Schur complement solver in a nested, two-level\nfashion. The solver is demonstrated to have a mesh-independent convergence at\nthe outer level, whereas the inner level system is of elliptic type and thus\ncan be treated efficiently by a variety of solvers.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:42:43 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Botchev", "Mike A.", ""]]}]