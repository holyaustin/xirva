[{"id": "1806.00421", "submitter": "Christian Aristide Nikolai Beck", "authors": "Christian Beck, Sebastian Becker, Philipp Grohs, Nor Jaafari, and\n  Arnulf Jentzen", "title": "Solving the Kolmogorov PDE by means of deep learning", "comments": "33 pages, 1 figure Accepted for publication in the Journal of\n  Scientific Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic differential equations (SDEs) and the Kolmogorov partial\ndifferential equations (PDEs) associated to them have been widely used in\nmodels from engineering, finance, and the natural sciences. In particular, SDEs\nand Kolmogorov PDEs, respectively, are highly employed in models for the\napproximative pricing of financial derivatives. Kolmogorov PDEs and SDEs,\nrespectively, can typically not be solved explicitly and it has been and still\nis an active topic of research to design and analyze numerical methods which\nare able to approximately solve Kolmogorov PDEs and SDEs, respectively. Nearly\nall approximation methods for Kolmogorov PDEs in the literature suffer under\nthe curse of dimensionality or only provide approximations of the solution of\nthe PDE at a single fixed space-time point. In this paper we derive and propose\na numerical approximation method which aims to overcome both of the above\nmentioned drawbacks and intends to deliver a numerical approximation of the\nKolmogorov PDE on an entire region $[a,b]^d$ without suffering from the curse\nof dimensionality. Numerical results on examples including the heat equation,\nthe Black-Scholes model, the stochastic Lorenz equation, and the Heston model\nsuggest that the proposed approximation algorithm is quite effective in high\ndimensions in terms of both accuracy and speed.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 16:18:57 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 15:26:22 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Beck", "Christian", ""], ["Becker", "Sebastian", ""], ["Grohs", "Philipp", ""], ["Jaafari", "Nor", ""], ["Jentzen", "Arnulf", ""]]}, {"id": "1806.00565", "submitter": "Lei Zhang", "authors": "Hehu Xie, Lei Zhang, Houman Owhadi", "title": "Fast eigenpairs computation with operator adapted wavelets and\n  hierarchical subspace correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for the fast computation of the eigenpairs of a bijective\npositive symmetric linear operator $\\mathcal{L}$. The method is based on a\ncombination of operator adapted wavelets (gamblets) with hierarchical subspace\ncorrection.First, gamblets provide a raw but fast approximation of the\neigensubspaces of $\\mathcal{L}$ by block-diagonalizing $\\mathcal{L}$ into\nsparse and well-conditioned blocks. Next, the hierarchical subspace correction\nmethod, computes the eigenpairs associated with the Galerkin restriction of\n$\\mathcal{L}$ to a coarse (low dimensional) gamblet subspace, and then,\ncorrects those eigenpairs by solving a hierarchy of linear problems in the\nfiner gamblet subspaces (from coarse to fine, using multigrid iteration). The\nproposed algorithm is robust for the presence of multiple (a continuum of)\nscales and is shown to be of near-linear complexity when $\\mathcal{L}$ is an\n(arbitrary local, e.g.~differential) operator mapping $\\mathcal{H}^s_0(\\Omega)$\nto $\\mathcal{H}^{-s}(\\Omega)$ (e.g.~an elliptic PDE with rough coefficients).\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 01:20:17 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 04:01:51 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 09:54:53 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 08:52:42 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Xie", "Hehu", ""], ["Zhang", "Lei", ""], ["Owhadi", "Houman", ""]]}, {"id": "1806.00860", "submitter": "David Aristoff", "authors": "David Aristoff and Daniel M. Zuckerman", "title": "Optimizing weighted ensemble sampling of steady states", "comments": "28 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose parameter optimization techniques for weighted ensemble sampling\nof Markov chains in the steady-state regime. Weighted ensemble consists of\nreplicas of a Markov chain, each carrying a weight, that are periodically\nresampled according to their weights inside of each of a number of bins that\npartition state space. We derive, from first principles, strategies for\noptimizing the choices of weighted ensemble parameters, in particular the\nchoice of bins and the number of replicas to maintain in each bin. In a simple\nnumerical example, we compare our new strategies with more traditional ones and\nwith direct Monte Carlo.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 19:36:32 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 21:43:49 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 23:39:27 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 01:35:47 GMT"}, {"version": "v5", "created": "Mon, 20 Apr 2020 23:50:47 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Aristoff", "David", ""], ["Zuckerman", "Daniel M.", ""]]}, {"id": "1806.00906", "submitter": "Thomas Richter", "authors": "Thomas Richter", "title": "An averaging scheme for the efficient approximation of time-periodic\n  flow problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study periodic solutions to the Navier-Stokes equations. The transition\nphase of a dynamic Navier-Stokes solution to the periodic-in-time state can be\nexcessively long and it depends on parameters like the domain size and the\nviscosity. Several methods for an accelerated identification of the correct\ninitial data that will yield the periodic state exist. They are mostly based on\nspace-time frameworks for directly computing the periodic state or on\noptimization schemes or shooting methods for quickly finding the correct\ninitial data that yields the periodic solution. They all have a large\ncomputational overhead in common. Here we describe and analyze a simple\naveraging scheme that comes at negligible additional cost. We numerically\ndemonstrate the efficiency and robustness of the scheme for several test-cases\nand we will theoretically show convergence for the linear Stokes problem.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 00:44:21 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 12:57:30 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Richter", "Thomas", ""]]}, {"id": "1806.01062", "submitter": "Felix Wolf", "authors": "Annalisa Buffa, J\\\"urgen D\\\"olz, Stefan Kurz, Sebastian Sch\\\"ops,\n  Rafael V\\'azques, Felix Wolf", "title": "Multipatch Approximation of the de Rham Sequence and its Traces in\n  Isogeometric Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a conforming B-spline discretisation of the de Rham complex on\nmultipatch geometries. We introduce and analyse the properties of interpolation\noperators onto these spaces which commute w.r.t. the surface differential\noperators. Using these results as a basis, we derive new convergence results of\noptimal order w.r.t. the respective energy spaces and provide approximation\nproperties of the spline discretisations of trace spaces for application in the\ntheory of isogeometric boundary element methods. Our analysis allows for a\nstraightforward generalisation to finite element methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 11:52:20 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 13:09:57 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Buffa", "Annalisa", ""], ["D\u00f6lz", "J\u00fcrgen", ""], ["Kurz", "Stefan", ""], ["Sch\u00f6ps", "Sebastian", ""], ["V\u00e1zques", "Rafael", ""], ["Wolf", "Felix", ""]]}, {"id": "1806.01339", "submitter": "Dominique Beaini", "authors": "Dominique Beaini, Sofiane Achiche, Fabrice Nonez, Maxime Raison", "title": "Computing the Spatial Probability of Inclusion inside Partial Contours\n  for Computer Vision Applications", "comments": "Keywords: Computer vision; Stroke analysis; Partial contour;\n  Probability of inclusion; Edge interaction; Image convolution;\n  Electromagnetic potential field", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In Computer Vision, edge detection is one of the favored approaches for\nfeature and object detection in images since it provides information about\ntheir objects boundaries. Other region-based approaches use probabilistic\nanalysis such as clustering and Markov random fields, but those methods cannot\nbe used to analyze edges and their interaction. In fact, only image\nsegmentation can produce regions based on edges, but it requires thresholding\nby simply separating the regions into binary in-out information. Hence, there\nis currently a gap between edge-based and region-based algorithms, since edges\ncannot be used to study the properties of a region and vice versa. The\nobjective of this paper is to present a novel spatial probability analysis that\nallows determining the probability of inclusion inside a set of partial\ncontours (strokes). To answer this objective, we developed a new approach that\nuses electromagnetic convolutions and repulsion optimization to compute the\nrequired probabilities. Hence, it becomes possible to generate a continuous\nspace of probability based only on the edge information, thus bridging the gap\nbetween the edge-based methods and the region-based methods. The developed\nmethod is consistent with the fundamental properties of inclusion probabilities\nand its results are validated by comparing an image with the probability-based\nestimation given by our algorithm. The method can also be generalized to take\ninto consideration the intensity of the edges or to be used for 3D shapes. This\nis the first documented method that allows computing a space of probability\nbased on interacting edges, which opens the path to broader applications such\nas image segmentation and contour completion.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 19:26:51 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 14:49:02 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Beaini", "Dominique", ""], ["Achiche", "Sofiane", ""], ["Nonez", "Fabrice", ""], ["Raison", "Maxime", ""]]}, {"id": "1806.01575", "submitter": "Philipp \\\"Offner", "authors": "Philipp \\\"Offner", "title": "Error boundedness of Correction Procedure via Reconstruction / Flux\n  Reconstruction", "comments": "29 pages, 13 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the long-time error behavior of correction procedure via\nreconstruction / flux reconstruction (CPR/FR) methods for linear hyperbolic\nconservation laws. We show that not only the choice of the numerical flux\n(upwind or central) affects the growth rate and asymptotic value of the error,\nbut that the selection of bases (Gau{\\ss}-Lobatto or Gau{\\ss}-Legendre) is even\nmore important. Using a Gau{\\ss}-Legendre basis, the error reaches the\nasymptotic value faster and to a lower value than when using a Gau{\\ss}-Lobatto\nbasis. Also, the differences in the error caused by the numerical flux are not\nessential for low resolution computations in the Gau{\\ss}-Legendre case. This\nbehavior is better seen on a particular FR scheme which has a strong connection\nwith the discontinuous Galerkin framework but holds also for other flux\nreconstruction schemes with low order resolution computations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 09:26:35 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 17:12:28 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["\u00d6ffner", "Philipp", ""]]}, {"id": "1806.01638", "submitter": "Daniel Gebremedhin", "authors": "Daniel Gebremedhin and Charles Weatherford", "title": "Numerical Integration as an Initial Value Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical integration (NI) packages commonly used in scientific research are\nlimited to returning the value of a definite integral at the upper integration\nlimit, also commonly referred to as numerical quadrature. These quadrature\nalgorithms are typically of a fixed accuracy and have only limited ability to\nadapt to the application. In this article, we will present a highly adaptive\nalgorithm that not only can efficiently compute definite integrals encountered\nin physical problems but also can be applied to other problems such as\nindefinite integrals, integral equations and linear and non-linear eigenvalue\nproblems. More specifically, a finite element based algorithm is presented that\nnumerically solves first order ordinary differential equations (ODE) by\npropagating the solution function from a given initial value (lower integration\nvalue). The algorithm incorporates powerful techniques including, adaptive step\nsize choice of elements, local error checking and enforces continuity of both\nthe integral and the integrand across consecutive elements.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 01:29:49 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Gebremedhin", "Daniel", ""], ["Weatherford", "Charles", ""]]}, {"id": "1806.01656", "submitter": "Mofreh Zaghloul", "authors": "Mofreh R Zaghloul", "title": "Efficient Multi-Accuracy Computations of Complex Functions with Complex\n  Arguments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient multi-accuracy algorithm for the computations of a\nset of special functions of a complex argument, z=x+iy. These functions include\nthe complex probability function w(z), and closely related functions such as\nthe error function erf(z), complementary error function erfc(z), imaginary\nerror function erfi(z), scaled complementary error function, erfcx(z), the\nplasma dispersion function Z(z), Dawson s function Daw(z), and Fresnel\nintegrals S(z) and C(z). Computational results from the present algorithm are\ncompared with results from competitive algorithms and widely used software\npackages showing superior accuracy and efficiency of the present algorithm. In\nparticular, the present results highlight concerns about the accuracy of\nevaluating such special functions using commercial packages like Mathematica\nand free/open source packages like the MIT-C++ package.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 13:38:11 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 14:53:22 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 16:39:04 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zaghloul", "Mofreh R", ""]]}, {"id": "1806.01663", "submitter": "Anna Sinelnikova", "authors": "Anna Sinelnikova", "title": "RG Smoothing Algorithm Which Makes Data Compression", "comments": "This is the work in progress. The author is looking for collaborators\n  in corresponding fields. Any feedback is encouraged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe a new method for smoothing a one-dimensional curve in Euclidian\nspace with an arbitrary number of dimensions. The basic idea is borrowed from\nrenormalization group theory which previously was applied to biological\nmacromolecules. There are two crucial differences from other smoothing methods\nwhich make the algorithm unique: data compression and recursive implementation.\nOne of the simplest forms of the method that is described in this article has\nonly one free parameter - the number of iterative steps. This means that\nhardware implementation should be relatively easy because each loop is simple\nand strictly defined. The method could be beneficially applied to pattern\nrecognition and data compression in future studies.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 12:51:24 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Sinelnikova", "Anna", ""]]}, {"id": "1806.01678", "submitter": "Nate Veldt", "authors": "Nate Veldt and David Gleich and Anthony Wirth and James Saunderson", "title": "A Projection Method for Metric-Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a new approach for solving optimization problems which enforce\ntriangle inequalities on output variables. We refer to this as\nmetric-constrained optimization, and give several examples where problems of\nthis form arise in machine learning applications and theoretical approximation\nalgorithms for graph clustering. Although these problem are interesting from a\ntheoretical perspective, they are challenging to solve in practice due to the\nhigh memory requirement of black-box solvers. In order to address this\nchallenge we first prove that the metric-constrained linear program relaxation\nof correlation clustering is equivalent to a special case of the metric\nnearness problem. We then developed a general solver for metric-constrained\nlinear and quadratic programs by generalizing and improving a simple projection\nalgorithm originally developed for metric nearness. We give several novel\napproximation guarantees for using our framework to find lower bounds for\noptimal solutions to several challenging graph clustering problems. We also\ndemonstrate the power of our framework by solving optimizing problems involving\nup to 10^{8} variables and 10^{11} constraints.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 13:25:30 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Veldt", "Nate", ""], ["Gleich", "David", ""], ["Wirth", "Anthony", ""], ["Saunderson", "James", ""]]}, {"id": "1806.02957", "submitter": "Mohammad Amin Nabian", "authors": "Mohammad Amin Nabian, Hadi Meidani", "title": "A Deep Neural Network Surrogate for High-Dimensional Random Partial\n  Differential Equations", "comments": null, "journal-ref": "Probabilistic Engineering Mechanics, 57, pp.14-25 (2019)", "doi": "10.1016/j.probengmech.2019.05.001", "report-no": null, "categories": "cs.LG cs.NA cs.NE physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing efficient numerical algorithms for the solution of high\ndimensional random Partial Differential Equations (PDEs) has been a challenging\ntask due to the well-known curse of dimensionality. We present a new solution\nframework for these problems based on a deep learning approach. Specifically,\nthe random PDE is approximated by a feed-forward fully-connected deep residual\nnetwork, with either strong or weak enforcement of initial and boundary\nconstraints. The framework is mesh-free, and can handle irregular computational\ndomains. Parameters of the approximating deep neural network are determined\niteratively using variants of the Stochastic Gradient Descent (SGD) algorithm.\nThe satisfactory accuracy of the proposed frameworks is numerically\ndemonstrated on diffusion and heat conduction problems, in comparison with the\nconverged Monte Carlo-based finite element results.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 03:24:50 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 23:59:31 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Nabian", "Mohammad Amin", ""], ["Meidani", "Hadi", ""]]}, {"id": "1806.03085", "submitter": "Gianluca Detommaso", "authors": "Gianluca Detommaso, Tiangang Cui, Alessio Spantini, Youssef Marzouk\n  and Robert Scheichl", "title": "A Stein variational Newton method", "comments": "18 pages, 7 figures", "journal-ref": "NIPS 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein variational gradient descent (SVGD) was recently proposed as a general\npurpose nonparametric variational inference algorithm [Liu & Wang, NIPS 2016]:\nit minimizes the Kullback-Leibler divergence between the target distribution\nand its approximation by implementing a form of functional gradient descent on\na reproducing kernel Hilbert space. In this paper, we accelerate and generalize\nthe SVGD algorithm by including second-order information, thereby approximating\na Newton-like iteration in function space. We also show how second-order\ninformation can lead to more effective choices of kernel. We observe\nsignificant computational gains over the original SVGD algorithm in multiple\ntest cases.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 11:05:29 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 22:11:26 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Detommaso", "Gianluca", ""], ["Cui", "Tiangang", ""], ["Spantini", "Alessio", ""], ["Marzouk", "Youssef", ""], ["Scheichl", "Robert", ""]]}, {"id": "1806.03165", "submitter": "Ganzhao Yuan", "authors": "Ganzhao Yuan, Wei-Shi Zheng, Li Shen, Bernard Ghanem", "title": "A Generalized Matrix Splitting Algorithm", "comments": "arXiv admin note: substantial text overlap with arXiv:1612.02317", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composite function minimization captures a wide spectrum of applications in\nboth computer vision and machine learning. It includes bound constrained\noptimization, $\\ell_1$ norm regularized optimization, and $\\ell_0$ norm\nregularized optimization as special cases. This paper proposes and analyzes a\nnew Generalized Matrix Splitting Algorithm (GMSA) for minimizing composite\nfunctions. It can be viewed as a generalization of the classical Gauss-Seidel\nmethod and the Successive Over-Relaxation method for solving linear systems in\nthe literature. Our algorithm is derived from a novel triangle operator\nmapping, which can be computed exactly using a new generalized Gaussian\nelimination procedure. We establish the global convergence, convergence rate,\nand iteration complexity of GMSA for convex problems. In addition, we also\ndiscuss several important extensions of GMSA. Finally, we validate the\nperformance of our proposed method on three particular applications:\nnonnegative matrix factorization, $\\ell_0$ norm regularized sparse coding, and\n$\\ell_1$ norm regularized Dantzig selector problem. Extensive experiments show\nthat our method achieves state-of-the-art performance in term of both\nefficiency and efficacy.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 14:04:47 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Yuan", "Ganzhao", ""], ["Zheng", "Wei-Shi", ""], ["Shen", "Li", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1806.03196", "submitter": "Joscha Reimer", "authors": "Joscha Reimer", "title": "Approximation of Hermitian Matrices by Positive Semidefinite Matrices\n  using Modified Cholesky Decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithm to approximate Hermitian matrices by positive semidefinite\nHermitian matrices based on modified Cholesky decompositions is presented. In\ncontrast to existing algorithms, this algorithm allows to specify bounds on the\ndiagonal values of the approximation. It has no significant runtime and memory\noverhead compared to the computation of a classical Cholesky decomposition.\nHence it is suitable for large matrices as well as sparse matrices since it\npreserves the sparsity pattern of the original matrix. The algorithm tries to\nminimize the approximation error in the Frobenius norm as well as the condition\nnumber of the approximation. Since these two objectives often contradict each\nother, it is possible to weight these two objectives by parameters of the\nalgorithm. In numerical experiments, the algorithm outperforms existing\nalgorithms regarding these two objectives. A Cholesky decomposition of the\napproximation is calculated as a byproduct. This is useful, for example, if a\ncorresponding linear equation should be solved. A fully documented and\nextensively tested implementation is available. Numerical optimization and\nstatistics are two fields of application in which the algorithm can be of\nparticular interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 14:43:54 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 18:09:06 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Reimer", "Joscha", ""]]}, {"id": "1806.03731", "submitter": "Ivan Graham", "authors": "I.G. Graham, E.A. Spence and J. Zou", "title": "Domain Decomposition with local impedance conditions for the Helmholtz\n  equation with absorption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider one-level additive Schwarz preconditioners for a family of\nHelmholtz problems with absorption and increasing wavenumber $k$. These\nproblems are discretized using the Galerkin method with nodal conforming finite\nelements of any (fixed) order on meshes with diameter $h = h(k)$, chosen to\nmaintain accuracy as $k$ increases. The action of the preconditioner requires\nsolution of independent (parallel) subproblems (with impedance boundary\nconditions) on overlapping subdomains of diameter $H$ and overlap $\\delta\\leq\nH$. The solutions of these subproblems are linked together using\nprolongation/restriction operators defined using a partition of unity. In\nnumerical experiments (with $\\delta \\sim H$) for a model interior impedance\nproblem, we observe robust (i.e. $k-$independent) GMRES convergence as $k$\nincreases. This provides a highly-parallel, $k-$robust one-level domain\ndecomposition method. We provide supporting theory by studying the\npreconditioner applied to a range of absorptive problems, $k^2\\mapsto k^2+\n\\mathrm{i} \\varepsilon$, with absorption parameter $\\varepsilon$. Working in\nthe Helmholtz ``energy'' inner product, and using the underlying theory of\nHelmholtz boundary-value problems, we prove a $k-$independent upper bound on\nthe norm of the preconditioned matrix, valid for all $\\vert \\varepsilon\\vert\n\\lesssim k^2$. We also prove a strictly-positive lower bound on the distance of\nthe field of values of the preconditioned matrix from the origin which holds\nwhen $\\varepsilon/k$ is constant or growing arbitrarily slowly with $k$. These\nresults imply robustness of the preconditioner for the corresponding absorptive\nproblem as k increases and give theoretical support for the observed robustness\nof the preconditioner for the pure Helmholtz problem.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 21:48:56 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 07:02:49 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 17:23:53 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 12:24:00 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Graham", "I. G.", ""], ["Spence", "E. A.", ""], ["Zou", "J.", ""]]}, {"id": "1806.03798", "submitter": "Varun Shankar", "authors": "Varun Shankar and Aaron L. Fogelson", "title": "Hyperviscosity-Based Stabilization for Radial Basis Function-Finite\n  Difference (RBF-FD) Discretizations of Advection-Diffusion Equations", "comments": "30 pages, 8 figures, accepted to Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2018.06.036", "report-no": null, "categories": "math.NA cs.CE cs.NA math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel hyperviscosity formulation for stabilizing RBF-FD\ndiscretizations of the advection-diffusion equation. The amount of\nhyperviscosity is determined quasi-analytically for commonly-used explicit,\nimplicit, and implicit-explicit (IMEX) time integrators by using a simple 1D\nsemi-discrete Von Neumann analysis. The analysis is applied to an analytical\nmodel of spurious growth in RBF-FD solutions that uses auxiliary differential\noperators mimicking the undesirable properties of RBF-FD differentiation\nmatrices. The resulting hyperviscosity formulation is a generalization of\nexisting ones in the literature, but is free of any tuning parameters and can\nbe computed efficiently. To further improve robustness, we introduce a simple\nnew scaling law for polynomial-augmented RBF-FD that relates the degree of\npolyharmonic spline (PHS) RBFs to the degree of the appended polynomial. When\nused in a novel ghost node formulation in conjunction with the\nrecently-developed overlapped RBF-FD method, the resulting method is robust and\nfree of stagnation errors. We validate the high-order convergence rates of our\nmethod on 2D and 3D test cases over a wide range of Peclet numbers (1-1000). We\nthen use our method to solve a 3D coupled problem motivated by models of\nplatelet aggregation and coagulation, again demonstrating high-order\nconvergence rates.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 04:03:57 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Shankar", "Varun", ""], ["Fogelson", "Aaron L.", ""]]}, {"id": "1806.03816", "submitter": "Kiarash Shaloudegi", "authors": "Kiarash Shaloudegi and Andr\\'as Gy\\\"orgy", "title": "Adaptive MCMC via Combining Local Samplers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) methods are widely used in machine learning.\nOne of the major problems with MCMC is the question of how to design chains\nthat mix fast over the whole state space; in particular, how to select the\nparameters of an MCMC algorithm. Here we take a different approach and,\nsimilarly to parallel MCMC methods, instead of trying to find a single chain\nthat samples from the whole distribution, we combine samples from several\nchains run in parallel, each exploring only parts of the state space (e.g., a\nfew modes only). The chains are prioritized based on kernel Stein discrepancy,\nwhich provides a good measure of performance locally. The samples from the\nindependent chains are combined using a novel technique for estimating the\nprobability of different regions of the sample space. Experimental results\ndemonstrate that the proposed algorithm may provide significant speedups in\ndifferent sampling problems. Most importantly, when combined with the\nstate-of-the-art NUTS algorithm as the base MCMC sampler, our method remained\ncompetitive with NUTS on sampling from unimodal distributions, while\nsignificantly outperforming state-of-the-art competitors on synthetic\nmultimodal problems as well as on a challenging sensor localization task.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 05:35:45 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 01:44:04 GMT"}, {"version": "v3", "created": "Thu, 11 Apr 2019 21:12:10 GMT"}, {"version": "v4", "created": "Wed, 8 May 2019 16:48:49 GMT"}, {"version": "v5", "created": "Thu, 9 May 2019 10:15:34 GMT"}, {"version": "v6", "created": "Sat, 13 Jul 2019 02:42:35 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Shaloudegi", "Kiarash", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""]]}, {"id": "1806.03908", "submitter": "Balthasar Reuter", "authors": "Balthasar Reuter and Andreas Rupp and Vadym Aizinger and Florian Frank\n  and Peter Knabner", "title": "FESTUNG: A MATLAB /GNU Octave toolbox for the discontinuous Galerkin\n  method. Part IV: Generic problem framework and model-coupling interface", "comments": "http://www.global-sci.com/intro/online/read?article_id=725.html", "journal-ref": null, "doi": "10.4208/cicp.OA-2019-0132", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the fourth installment in our series on implementing the\ndiscontinuous Galerkin (DG) method as an open source MATLAB /GNU Octave\ntoolbox. Similarly to its predecessors, this part presents new features for\napplication developers employing DG methods and follows our strategy of relying\non fully vectorized constructs and supplying a comprehensive documentation. The\nspecific focus of the current work is the newly added generic problem\nimplementation framework and the highly customizable model-coupling interface\nfor multi-domain and multi-physics simulation tools based on this framework.\nThe functionality of the coupling interface in the FESTUNG toolbox is\nillustrated using a two-way coupled free-surface / groundwater flow system as\nan example application.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 11:16:05 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 16:17:24 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 10:13:31 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Reuter", "Balthasar", ""], ["Rupp", "Andreas", ""], ["Aizinger", "Vadym", ""], ["Frank", "Florian", ""], ["Knabner", "Peter", ""]]}, {"id": "1806.04159", "submitter": "Michael Feischl", "authors": "Josef Dick, Michael Feischl, Christoph Schwab", "title": "Improved Efficiency of a Multi-Index FEM for Computational Uncertainty\n  Quantification", "comments": "revised version published in SINUM", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-index algorithm for the Monte Carlo (MC) discretization of\na linear, elliptic PDE with affine-parametric input. We prove an error vs. work\nanalysis which allows a multi-level finite-element approximation in the\nphysical domain, and apply the multi-index analysis with isotropic,\nunstructured mesh refinement in the physical domain for the solution of the\nforward problem, for the approximation of the random field, and for the\nMonte-Carlo quadrature error. Our approach allows Lipschitz domains and mesh\nhierarchies more general than tensor grids. The improvement in complexity over\nmulti-level MC FEM is obtained from combining spacial discretization, dimension\ntruncation and MC sampling in a multi-index fashion. Our analysis improves cost\nestimates compared to multi-level algorithms for similar problems and\nmathematically underpins the superior practical performance of multi-index\nalgorithms for partial differential equations with random coefficients.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 18:03:00 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 11:55:25 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Dick", "Josef", ""], ["Feischl", "Michael", ""], ["Schwab", "Christoph", ""]]}, {"id": "1806.04164", "submitter": "Ozgur Ergul", "authors": "Ugur Meric Gur and Ozgur Ergul", "title": "Solutions of New Potential Integral Equations Using MLFMA Based on the\n  Approximate Stable Diagonalization", "comments": "The paper was completed in August 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present efficient solutions of recently developed potential integral\nequations (PIEs) using a low-frequency implementation of the multilevel fast\nmultipole algorithm (MLFMA). PIEs enable accurate solutions of low-frequency\nproblems involving small objects and/or small discretization elements with\nrespect to wavelength. As the number of unknowns grows, however, PIEs need to\nbe solved via fast algorithms, which are also tolerant to low-frequency\nbreakdowns. Using an approximate diagonalization in MLFMA, we present a new\nimplementation that can provide accurate, stable, and efficient solutions of\nlow-frequency problems involving large numbers of unknowns. The effectiveness\nof the implementation is demonstrated on canonical problems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 18:08:28 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Gur", "Ugur Meric", ""], ["Ergul", "Ozgur", ""]]}, {"id": "1806.04211", "submitter": "Alice Niemeyer", "authors": "Stephen Linton, Gabriele Nebe, Alice Niemeyer, Richard Parker, Jon\n  Thackray", "title": "A parallel algorithm for Gaussian elimination over finite fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.DC cs.NA math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a parallel Gaussian elimination algorithm for\nmatrices with entries in a finite field. Unlike previous approaches, our\nalgorithm subdivides a very large input matrix into smaller submatrices by\nsubdividing both rows and columns into roughly square blocks sized so that\ncomputing with individual blocks on individual processors provides adequate\nconcurrency. The algorithm also returns the transformation matrix, which\nencodes the row operations used. We go to some lengths to avoid storing any\nunnecessary data as we keep track of the row operations, such as block columns\nof the transformation matrix known to be zero. The algorithm is accompanied by\na concurrency analysis which shows that the improvement in concurrency is of\nthe same order of magnitude as the number of blocks. An implementation of the\nalgorithm has been tested on matrices as large as $1 000 000\\times 1 000 000$\nover small finite fields.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 10:33:55 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Linton", "Stephen", ""], ["Nebe", "Gabriele", ""], ["Niemeyer", "Alice", ""], ["Parker", "Richard", ""], ["Thackray", "Jon", ""]]}, {"id": "1806.04274", "submitter": "Ben Southworth", "authors": "Ben S. Southworth and Thomas A. Manteuffel", "title": "Convergence in Norm of Nonsymmetric Algebraic Multigrid", "comments": "Accepted SIAM Journal on Scientific Computing (Sep. 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic multigrid (AMG) is one of the fastest numerical methods for solving\nlarge sparse linear systems. For SPD matrices, convergence of AMG is well\nmotivated in the $A$-norm, and AMG has proven to be an effective solver for\nmany applications. Recently, several AMG algorithms have been developed that\nare effective on nonsymmetric linear systems. Although motivation was provided\nin each case, the convergence of AMG for nonsymmetric linear systems is still\nnot well understood, and algorithms are based largely on heuristics or\nincomplete theory.\n  For multigrid restriction and interpolation operators, $R$ and $P$,\nrespectively, let $\\Pi:= P(RAP)^{-1}RA$ denote the projection corresponding to\ncoarse-grid correction in AMG. It is invariably the case in the nonsymmetric\nsetting that $\\|\\Pi\\| > 1$ in any known norm. This causes an interesting\ndichotomy: coarse-grid correction is fundamental to AMG achieving fast\nconvergence, but, in this case, can actually increase the error. Here, we\npresent a detailed analysis of nonsymmetric AMG, discussing why SPD theory\nbreaks down in the nonsymmetric setting, and developing a general framework for\nconvergence of NS-AMG. Classical multigrid weak and strong approximation\nproperties are generalized to a \\textit{fractional approximation property}.\nConditions are then developed on $R$ and $P$ to ensure that\n$\\|\\Pi\\|_{\\sqrt{A^*A}}$ is nicely bounded, independent of problem size. This is\nfollowed by the development of conditions for two-grid and multilevel W-cycle\nconvergence in the $\\sqrt{A^*A}$-norm.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 00:11:14 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 01:33:19 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 20:24:14 GMT"}, {"version": "v4", "created": "Mon, 9 Sep 2019 14:41:22 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Southworth", "Ben S.", ""], ["Manteuffel", "Thomas A.", ""]]}, {"id": "1806.04966", "submitter": "Lisa Maria Kreusser", "authors": "Jos\\'e A. Carrillo, Bertram D\\\"uring, Lisa Maria Kreusser,\n  Carola-Bibiane Sch\\\"onlieb", "title": "Stability analysis of line patterns of an anisotropic interaction model", "comments": "41 pages", "journal-ref": "SIAM J. Appl. Dyn. Syst., 18(4), 1798-1845, 2019", "doi": "10.1137/18M1181638", "report-no": null, "categories": "math.DS cs.NA math.AP math.CA math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Motivated by the formation of fingerprint patterns we consider a class of\ninteracting particle models with anisotropic, repulsive-attractive interaction\nforces whose orientations depend on an underlying tensor field. This class of\nmodels can be regarded as a generalization of a gradient flow of a nonlocal\ninteraction potential which has a local repulsion and a long-range attraction\nstructure. In addition, the underlying tensor field introduces an anisotropy\nleading to complex patterns which do not occur in isotropic models. Central to\nthis pattern formation are straight line patterns. For a given spatially\nhomogeneous tensor field, we show that there exists a preferred direction of\nstraight lines, i.e.\\ straight vertical lines can be stable for sufficiently\nmany particles, while many other rotations of the straight lines are unstable\nsteady states, both for a sufficiently large number of particles and in the\ncontinuum limit. For straight vertical lines we consider specific force\ncoefficients for the stability analysis of steady states, show that stability\ncan be achieved for exponentially decaying force coefficients for a\nsufficiently large number of particles and relate these results to the\nK\\\"ucken-Champod model for simulating fingerprint patterns. The mathematical\nanalysis of the steady states is completed with numerical results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 11:55:48 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 13:59:05 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Carrillo", "Jos\u00e9 A.", ""], ["D\u00fcring", "Bertram", ""], ["Kreusser", "Lisa Maria", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1806.05063", "submitter": "Ruming Zhang", "authors": "Ruming Zhang", "title": "Numerical methods for scattering problems from multi-layers with\n  different periodicities", "comments": "arXiv admin note: text overlap with arXiv:1805.11484", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a numerical method to solve scattering problems\nwith multi-periodic layers with different periodicities. The main tool applied\nin this paper is the Bloch transform. With this method, the problem is written\ninto an equivalent coupled family of quasi-periodic problems. As the Bloch\ntransform is only defined for one fixed period, the inhomogeneous layer with\nanother period is simply treated as a non-periodic one. First, we approximate\nthe refractive index by a periodic one where its period is an integer multiple\nof the fixed period, and it is decomposed by finite number of quasi-periodic\nfunctions. Then the coupled system is reduced into a simplified formulation. A\nconvergent finite element method is proposed for the numerical solution, and\nthe numerical method has been applied to several numerical experiments. At the\nend of this paper, relative errors of the numerical solutions will be shown to\nillustrate the convergence of the numerical algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 08:21:02 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 10:07:23 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhang", "Ruming", ""]]}, {"id": "1806.05419", "submitter": "Raja Giryes", "authors": "Tal Levy and Alireza Vahid and Raja Giryes", "title": "Ranking Recovery from Limited Comparisons using Low-Rank Matrix\n  Completion", "comments": "10 Pages, 9 figures. A prediction table for 2018 FIFA soccer world\n  cup is included", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new method for solving the well-known rank aggregation\nproblem from pairwise comparisons using the method of low-rank matrix\ncompletion. The partial and noisy data of pairwise comparisons is transformed\ninto a matrix form. We then use tools from matrix completion, which has served\nas a major component in the low-rank completion solution of the Netflix\nchallenge, to construct the preference of the different objects. In our\napproach, the data of multiple comparisons is used to create an estimate of the\nprobability of object i to win (or be chosen) over object j, where only a\npartial set of comparisons between N objects is known. The data is then\ntransformed into a matrix form for which the noiseless solution has a known\nrank of one. An alternating minimization algorithm, in which the target matrix\ntakes a bilinear form, is then used in combination with maximum likelihood\nestimation for both factors. The reconstructed matrix is used to obtain the\ntrue underlying preference intensity. This work demonstrates the improvement of\nour proposed algorithm over the current state-of-the-art in both simulated\nscenarios and real data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 09:01:46 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Levy", "Tal", ""], ["Vahid", "Alireza", ""], ["Giryes", "Raja", ""]]}, {"id": "1806.05647", "submitter": "Zhe Wang", "authors": "Yingzhou Li, Jianfeng Lu, Zhe Wang", "title": "Coordinate-wise descent methods for leading eigenvalue problem", "comments": null, "journal-ref": null, "doi": "10.1137/18M1202505", "report-no": null, "categories": "math.NA cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leading eigenvalue problems for large scale matrices arise in many\napplications. Coordinate-wise descent methods are considered in this work for\nsuch problems based on a reformulation of the leading eigenvalue problem as a\nnon-convex optimization problem. The convergence of several coordinate-wise\nmethods is analyzed and compared. Numerical examples of applications to quantum\nmany-body problems demonstrate the efficiency and provide benchmarks of the\nproposed coordinate-wise descent methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 17:01:39 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 17:38:42 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2018 20:41:05 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 19:52:34 GMT"}, {"version": "v5", "created": "Thu, 13 Jun 2019 06:05:18 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Li", "Yingzhou", ""], ["Lu", "Jianfeng", ""], ["Wang", "Zhe", ""]]}, {"id": "1806.05744", "submitter": "Bamdad Hosseini Dr.", "authors": "Juan G. Garcia, Bamdad Hosseini, John M Stockie", "title": "Simultaneous model calibration and source inversion in atmospheric\n  dispersion models", "comments": null, "journal-ref": "Pure and Applied Geophysics 178(3):757-776, 2021", "doi": "10.1007/s00024-019-02348-4", "report-no": null, "categories": "math.NA cs.NA physics.ao-ph physics.geo-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a cost-effective method for model calibration and solution of\nsource inversion problems in atmospheric dispersion modelling. We use Gaussian\nprocess emulations of atmospheric dispersion models within a Bayesian framework\nfor solution of inverse problems. The model and source parameters are treated\nas unknowns and we obtain point estimates and approximation of uncertainties\nfor sources while simultaneously calibrating the forward model. The method is\nvalidated in the context of an industrial case study involving emissions from a\nsmelting operation for which cumulative monthly measurements of zinc\nparticulate depositions are available.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 21:21:24 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 21:00:05 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Garcia", "Juan G.", ""], ["Hosseini", "Bamdad", ""], ["Stockie", "John M", ""]]}, {"id": "1806.05826", "submitter": "Joris Tavernier", "authors": "Joris Tavernier, Jaak Simm, Karl Meerbergen and Yves Moreau", "title": "Two-level preconditioning for Ridge Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving linear systems is often the computational bottleneck in real-life\nproblems. Iterative solvers are the only option due to the complexity of direct\nalgorithms or because the system matrix is not explicitly known. Here, we\ndevelop a two-level preconditioner for regularized least squares linear systems\ninvolving a feature or data matrix. Variants of this linear system may appear\nin machine learning applications, such as ridge regression, logistic\nregression, support vector machines and Bayesian regression. We use clustering\nalgorithms to create a coarser level that preserves the principal components of\nthe covariance or Gram matrix. This coarser level approximates the dominant\neigenvectors and is used to build a subspace preconditioner accelerating the\nConjugate Gradient method. We observed speed-ups for artificial and real-life\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 06:59:49 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 10:49:02 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Tavernier", "Joris", ""], ["Simm", "Jaak", ""], ["Meerbergen", "Karl", ""], ["Moreau", "Yves", ""]]}, {"id": "1806.05957", "submitter": "Bor Plestenjak", "authors": "Michiel E. Hochstenbach, Bor Plestenjak", "title": "Computing several eigenvalues of nonlinear eigenvalue problems by\n  selection", "comments": "17 pages; revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing more than one eigenvalue for (large sparse) one-parameter\npolynomial and general nonlinear eigenproblems, as well as for multiparameter\nlinear and nonlinear eigenproblems, is a much harder task than for standard\neigenvalue problems. We present simple but efficient selection methods based on\ndivided differences to do this. In contrast to locking techniques, it is not\nnecessary to keep converged eigenvectors in the search space, so that the\nentire search space may be devoted to new information. The techniques are\napplicable to many types of matrix eigenvalue problems; standard deflation is\npossible only for linear one-parameter problems. The methods are easy to\nunderstand and implement. Although divided differences are well-known in the\ncontext of nonlinear eigenproblems, the proposed selection techniques are new\nfor one-parameter problems. For multiparameter problems, we improve on and\ngeneralize our previous work. We also show how to use divided differences in\nthe framework of homogeneous coordinates, which may be appropriate for\ngeneralized eigenvalue problems with infinite eigenvalues.\n  While the approaches are valuable alternatives for one-parameter nonlinear\neigenproblems, they seem the only option for multiparameter problems.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 13:41:53 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 22:27:38 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 12:19:16 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Hochstenbach", "Michiel E.", ""], ["Plestenjak", "Bor", ""]]}, {"id": "1806.06103", "submitter": "Jeremy Kozdon", "authors": "Jeremy E. Kozdon, Lucas C. Wilcox, Thomas Hagstrom, Jeffrey W. Banks", "title": "Robust Approaches to Handling Complex Geometries with Galerkin\n  Difference Methods", "comments": "30 pages, 14 figures", "journal-ref": "Journal of Computational Physics, 392, 483-510 (2019)", "doi": "10.1016/j.jcp.2019.04.031", "report-no": null, "categories": "math.NA cs.NA", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Galerkin difference (GD) basis is a set of continuous, piecewise\npolynomials defined using a finite difference like grid of degrees of freedom.\nThe one dimensional GD basis functions are naturally extended to multiple\ndimensions using the tensor product constructions to quadrilateral elements for\ndiscretizing partial differential equations. Here we propose two approaches to\nhandling complex geometries using the GD basis within a discontinuous Galerkin\nfinite element setting: (1) using non-conforming, curvilinear GD elements and\n(2) coupling affine GD elements with curvilinear simplicial elements. In both\ncases the (semidiscrete) discontinuous Galerkin method is provably energy\nstable even when variational crimes are committed and in both cases a\nweight-adjusted mass matrix is used, which ensures that only the reference mass\nmatrix must be inverted. Additionally, we give sufficient conditions on the\ntreatment of metric terms for the curvilinear, nonconforming GD elements to\nensure that the scheme is both constant preserving and conservative. Numerical\nexperiments confirm the stability results and demonstrate the accuracy of the\ncoupled schemes.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 19:42:20 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:20:11 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kozdon", "Jeremy E.", ""], ["Wilcox", "Lucas C.", ""], ["Hagstrom", "Thomas", ""], ["Banks", "Jeffrey W.", ""]]}, {"id": "1806.06280", "submitter": "Khomovsky Dmitry Igorevic", "authors": "Dmitry I. Khomovsky", "title": "On using symmetric polynomials for constructing root finding methods", "comments": null, "journal-ref": "Math. Comp. 89 (2020), 2321-2331", "doi": "10.1090/mcom/3531", "report-no": null, "categories": "math.NA cs.NA math.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to constructing iterative methods for finding\npolynomial roots simultaneously. One feature of this approach is using the\nfundamental theorem of symmetric polynomials. Within this framework, we\nreconstruct many of the existing root finding methods. The new results\npresented in this paper are some modifications of the Durand-Kerner method.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 19:16:14 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 21:14:19 GMT"}, {"version": "v3", "created": "Sat, 3 Aug 2019 15:10:26 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Khomovsky", "Dmitry I.", ""]]}, {"id": "1806.06522", "submitter": "Piotr Kowalczyk", "authors": "Piotr Kowalczyk", "title": "Global Complex Roots and Poles Finding Algorithm Based on Phase Analysis\n  for Propagation and Radiation Problems", "comments": null, "journal-ref": "in IEEE Transactions on Antennas and Propagation, vol. 66, no. 12,\n  pp. 7198-7205, Dec. 2018", "doi": "10.1109/TAP.2018.2869213", "report-no": null, "categories": "cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A flexible and effective algorithm for complex roots and poles finding is\npresented. A wide class of analytic functions can be analyzed, and any\narbitrarily shaped search region can be considered. The method is very simple\nand intuitive. It is based on sampling a function at the nodes of a regular\nmesh, and on the analysis of the function phase. As a result, a set of\ncandidate regions is created and then the roots/poles are verified using a\ndiscretized Cauchy's argument principle. The accuracy of the results can be\nimproved by the application of a self-adaptive mesh. The effectiveness of the\npresented technique is supported by numerical tests involving different types\nof structures, where electromagnetic waves are guided and radiated. The results\nare verified, and the computational efficiency of the method is examined.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 07:24:19 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 08:05:45 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Kowalczyk", "Piotr", ""]]}, {"id": "1806.06549", "submitter": "Daan Huybrechs", "authors": "Daan Huybrechs and Arno B. J. Kuijlaars and Nele Lejon", "title": "A numerical method for oscillatory integrals with coalescing saddle\n  points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The value of a highly oscillatory integral is typically determined\nasymptotically by the behaviour of the integrand near a small number of\ncritical points. These include the endpoints of the integration domain and the\nso-called stationary points or saddle points -- roots of the derivative of the\nphase of the integrand -- where the integrand is locally non-oscillatory.\nModern methods for highly oscillatory quadrature exhibit numerical issues when\ntwo such saddle points coalesce. On the other hand, integrals with coalescing\nsaddle points are a classical topic in asymptotic analysis, where they give\nrise to uniform asymptotic expansions in terms of the Airy function. In this\npaper we construct Gaussian quadrature rules that remain uniformly accurate\nwhen two saddle points coalesce. These rules are based on orthogonal\npolynomials in the complex plane. We analyze these polynomials, prove their\nexistence for even degrees, and describe an accurate and efficient numerical\nscheme for the evaluation of oscillatory integrals with coalescing saddle\npoints.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 08:42:45 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 09:21:30 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Huybrechs", "Daan", ""], ["Kuijlaars", "Arno B. J.", ""], ["Lejon", "Nele", ""]]}, {"id": "1806.06631", "submitter": "Vitaly Zankin", "authors": "V. P. Zankin, G. V. Ryzhakov, I. V. Oseledets", "title": "Gradient Descent-based D-optimal Design for the Least-Squares Polynomial\n  Approximation", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel sampling method for Design of Experiments.\nThis method allows to sample such input values of the parameters of a\ncomputational model for which the constructed surrogate model will have the\nleast possible approximation error. High efficiency of the proposed method is\ndemonstrated by its comparison with other sampling techniques (LHS, Sobol'\nsequence sampling, and Maxvol sampling) on the problem of least-squares\npolynomial approximation. Also, numerical experiments for the Lebesgue constant\ngrowth for the points sampled by the proposed method are carried out.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 12:47:27 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 17:39:49 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Zankin", "V. P.", ""], ["Ryzhakov", "G. V.", ""], ["Oseledets", "I. V.", ""]]}, {"id": "1806.06725", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson (LFANT)", "title": "Numerical Evaluation of Elliptic Functions, Elliptic Integrals and\n  Modular Forms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe algorithms to compute elliptic functions and their relatives\n(Jacobi theta functions, modular forms, elliptic integrals, and the\narithmetic-geometric mean) numerically to arbitrary precision with rigorous\nerror bounds for arbitrary complex variables. Implementations in ball\narithmetic are available in the open source Arb library. We discuss the\nalgorithms from a concrete implementation point of view, with focus on\nperformance at tens to thousands of digits of precision.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 14:19:18 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Johansson", "Fredrik", "", "LFANT"]]}, {"id": "1806.06732", "submitter": "Ye Zhang", "authors": "George Baravdish, Olof Svensson, M{\\aa}rten Gulliksson and Ye Zhang", "title": "Damped second order flow applied to image denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new image denoising model: the damped flow\n(DF), which is a second order nonlinear evolution equation associated with a\nclass of energy functionals of image. The existence, uniqueness and\nregularization property of DF are proven. For the numerical implementation,\nbased on the St\\\"{o}rmer-Verlet method, a discrete damped flow, SV-DDF, is\ndeveloped. The convergence of SV-DDF is studied as well. Several numerical\nexperiments, as well as a comparison with other methods, are provided to\ndemonstrate the feasibility and effectiveness of the SV-DDF.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 14:30:56 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 02:47:38 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Baravdish", "George", ""], ["Svensson", "Olof", ""], ["Gulliksson", "M\u00e5rten", ""], ["Zhang", "Ye", ""]]}, {"id": "1806.07235", "submitter": "Antti Ojalammi", "authors": "Antti Hannukainen, Jarmo Malinen, Antti Ojalammi", "title": "Efficient solution of symmetric eigenvalue problems from families of\n  coupled systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient solution of the lowest eigenmodes is studied for a family of\nrelated eigenvalue problems with common $2\\times 2$ block structure. It is\nassumed that the upper diagonal block varies between different versions while\nthe lower diagonal block and the range of the coupling blocks remains\nunchanged. Such block structure naturally arises when studying the effect of a\nsubsystem to the eigenmodes of the full system. The proposed method is based on\ninterpolation of the resolvent function after some of its singularities have\nbeen removed by a spectral projection. Singular value decomposition can be used\nto further reduce the dimension of the computational problem. Error analysis of\nthe method indicates exponential convergence with respect to the number of\ninterpolation points. Theoretical results are illustrated by two numerical\nexamples related to finite element discretisation of the Laplace operator.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 13:51:03 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 11:59:17 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 11:33:39 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Hannukainen", "Antti", ""], ["Malinen", "Jarmo", ""], ["Ojalammi", "Antti", ""]]}, {"id": "1806.07261", "submitter": "Kathryn Lund", "authors": "Kathryn Lund", "title": "The tensor t-function: a definition for functions of third-order tensors", "comments": "18 pages, 17 figures", "journal-ref": null, "doi": "10.1002/nla.2288", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A definition for functions of multidimensional arrays is presented. The\ndefinition is valid for third-order tensors in the tensor t-product formalism,\nwhich regards third-order tensors as block circulant matrices. The tensor\nfunction definition is shown to have similar properties as standard matrix\nfunction definitions in fundamental scenarios. To demonstrate the definition's\npotential in applications, the notion of network communicability is generalized\nto third-order tensors and computed for a small-scale example via block Krylov\nsubspace methods for matrix functions. A complexity analysis for these methods\nin the context of tensors is also provided.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 14:06:56 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 10:54:44 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Lund", "Kathryn", ""]]}, {"id": "1806.07478", "submitter": "Andrew Steyer", "authors": "Andrew J. Steyer", "title": "Test equations and linear stability of implicit-explicit general linear\n  methods", "comments": "The results fail to capture the non-simultaneously diagonalizable\n  case", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eigenvalue perturbation theory is applied to justify using complex-valued\nlinear scalar test equations to characterize the stability of implicit-explicit\ngeneral linear methods (IMEX GLMs) solving autonomous linear ordinary\ndifferential equations (ODEs) when the implicitly treated term is sufficiently\nstiff relative to the explicitly treated term. The stiff and non-stiff matrices\nare not assumed to be simultaneously diagonalizable or triangularizable and\nneither matrix is assumed to be symmetric or negative definite. The stability\nof IMEX GLMs solving complex-valued scalar linear ODEs displaying parabolic and\nhyperbolic stiffness is analyzed and related to the higher dimensional theory.\nThe utility of the theoretical results is highlighted with a stability analysis\nof a family of IMEX Runge-Kutta methods solving IVPs of a linear 2D\nshallow-water model and a linear 1D advection-diffusion model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 21:53:15 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 18:48:39 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Steyer", "Andrew J.", ""]]}, {"id": "1806.07500", "submitter": "Matteo Giacomini", "authors": "Ruben Sevilla, Matteo Giacomini, Antonio Huerta", "title": "A locking-free face-centred finite volume (FCFV) method for linear\n  elasticity", "comments": "29 pages, 20 figures", "journal-ref": "Comput. Struct., 212, 43--57 (2019)", "doi": "10.1016/j.compstruc.2018.10.015", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A face-centred finite volume (FCFV) method is proposed for the linear\nelasticity equation. The FCFV is a mixed hybrid formulation, featuring a system\nof first-order equations, that defines the unknowns on the faces (edges in two\ndimensions) of the mesh elements. The symmetry of the stress tensor is strongly\nenforced using the well-known Voigt notation and the displacement and stress\nfields inside each cell are obtained element-wise by means of explicit\nformulas. The resulting FCFV method is robust and locking-free in the nearly\nincompressible limit. Numerical experiments in two and three dimensions show\noptimal convergence of the displacement and the stress fields without any\nreconstruction. Moreover, the accuracy of the FCFV method is not sensitive to\nmesh distortion and stretching. Classical benchmark tests including Kirch's\nplate and Cook's membrane problems in two dimensions as well as three\ndimensional problems involving shear phenomenons, pressurised thin shells and\ncomplex geometries are presented to show the capability and potential of the\nproposed methodology.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 23:26:55 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Sevilla", "Ruben", ""], ["Giacomini", "Matteo", ""], ["Huerta", "Antonio", ""]]}, {"id": "1806.07705", "submitter": "Zuzana Majdisova", "authors": "Zuzana Majdisova and Vaclav Skala", "title": "Radial Basis Function Approximations: Comparison and Applications", "comments": null, "journal-ref": "Applied Mathematical Modelling, Vol.51, pp.728-743, ISSN\n  0307-904X, Elsevier, November 2017", "doi": "10.1016/j.apm.2017.07.033", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximation of scattered data is often a task in many engineering problems.\nThe Radial Basis Function (RBF) approximation is appropriate for large\nscattered (unordered) datasets in d-dimensional space. This approach is useful\nfor a higher dimension d>2, because the other methods require the conversion of\na scattered dataset to an ordered dataset (i.e. a semi-regular mesh is obtained\nby using some tessellation techniques), which is computationally expensive. The\nRBF approximation is non-separable, as it is based on the distance between two\npoints. This method leads to a solution of Linear System of Equations (LSE)\nAc=h.\n  In this paper several RBF approximation methods are briefly introduced and a\ncomparison of those is made with respect to the stability and accuracy of\ncomputation. The proposed RBF approximation offers lower memory requirements\nand better quality of approximation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 13:06:35 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Majdisova", "Zuzana", ""], ["Skala", "Vaclav", ""]]}, {"id": "1806.07876", "submitter": "Carlos Borges", "authors": "Carlos F. Borges", "title": "An Improved Formula for Jacobi Rotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved form of the algorithm for constructing Jacobi\nrotations. This is simultaneously a more accurate code for finding the\neigenvalues and eigenvectors of a real symmetric 2x2 matrix.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 18:35:52 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Borges", "Carlos F.", ""]]}, {"id": "1806.07985", "submitter": "Grey Ballard", "authors": "Grey Ballard and Koby Hayashi and Ramakrishnan Kannan", "title": "Parallel Nonnegative CP Decomposition of Dense Tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CP tensor decomposition is a low-rank approximation of a tensor. We\npresent a distributed-memory parallel algorithm and implementation of an\nalternating optimization method for computing a CP decomposition of dense\ntensor data that can enforce nonnegativity of the computed low-rank factors.\nThe principal task is to parallelize the matricized-tensor times Khatri-Rao\nproduct (MTTKRP) bottleneck subcomputation. The algorithm is computation\nefficient, using dimension trees to avoid redundant computation across MTTKRPs\nwithin the alternating method. Our approach is also communication efficient,\nusing a data distribution and parallel algorithm across a multidimensional\nprocessor grid that can be tuned to minimize communication. We benchmark our\nsoftware on synthetic as well as hyperspectral image and neuroscience dynamic\nfunctional connectivity data, demonstrating that our algorithm scales well to\n100s of nodes (up to 4096 cores) and is faster and more general than the\ncurrently available parallel software.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 13:52:12 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Ballard", "Grey", ""], ["Hayashi", "Koby", ""], ["Kannan", "Ramakrishnan", ""]]}, {"id": "1806.08048", "submitter": "Juan Pablo Borthagaray", "authors": "Juan Pablo Borthagaray, Ricardo H. Nochetto, Abner J. Salgado", "title": "Weighted Sobolev regularity and rate of approximation of the obstacle\n  problem for the integral fractional Laplacian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain regularity results in weighted Sobolev spaces for the solution of\nthe obstacle problem for the integral fractional Laplacian. The weight is a\npower of the distance to the boundary. These bounds then serve us as a guide in\nthe design and analysis of an optimal finite element scheme over graded meshes.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 02:25:07 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 01:10:19 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 20:35:59 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Borthagaray", "Juan Pablo", ""], ["Nochetto", "Ricardo H.", ""], ["Salgado", "Abner J.", ""]]}, {"id": "1806.08439", "submitter": "Andr\\'es Mauricio Rueda-Ram\\'irez", "authors": "Andr\\'es M. Rueda-Ram\\'irez, Gonzalo Rubio, Esteban Ferrer, Eusebio\n  Valero", "title": "Truncation Error Estimation in the p-Anisotropic Discontinuous Galerkin\n  Spectral Element Method", "comments": null, "journal-ref": null, "doi": "10.1007/s10915-018-0772-0", "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of Discontinuous Galerkin Spectral Element Methods (DGSEM),\n$\\tau$-estimation has been successfully used for p-adaptation algorithms. This\nmethod estimates the truncation error of representations with different\npolynomial orders using the solution on a reference mesh of relatively high\norder.\n  In this paper, we present a novel anisotropic truncation error estimator\nderived from the $\\tau$-estimation procedure for DGSEM. We exploit the tensor\nproduct basis properties of the numerical solution to design a method where the\ntotal truncation error is calculated as a sum of its directional components. We\nshow that the new error estimator is cheaper to evaluate than previous\nimplementations of the $\\tau$-estimation procedure and that it obtains more\naccurate extrapolations of the truncation error for representations of a higher\norder than the reference mesh. The robustness of the method allows performing\nthe p-adaptation strategy with coarser reference solutions, thus further\nreducing the computational cost. The proposed estimator is validated using the\nmethod of manufactured solutions in a test case for the compressible\nNavier-Stokes equations.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 22:23:03 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Rueda-Ram\u00edrez", "Andr\u00e9s M.", ""], ["Rubio", "Gonzalo", ""], ["Ferrer", "Esteban", ""], ["Valero", "Eusebio", ""]]}, {"id": "1806.08474", "submitter": "Shengxin Zhu", "authors": "Shengxin Zhu", "title": "Summation of Gaussian shifts as Jacobi's third Theta function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A proper choice of parameters of the Jacobi modular identity (Jacobi\nImaginary transformation) implies that the summation of Gaussian shifts on\ninfinity periodic grids can be represented as the Jacobi's third Theta\nfunction. As such, connection between summation of Gaussian shifts and the\nsolution to a Schr\\\"{o}dinger equation is explicitly shown. A concise and\ncontrollable upper bound of the saturation error for approximating constant\nfunctions with summation of Gaussian shifts can be immediately obtained in\nterms of the underlying shape parameter of the Gaussian. This shed light on how\nto choose a shape parameter and provides further understanding on using\nGaussians with increasingly flatness.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 03:02:27 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 04:19:08 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 06:10:08 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Zhu", "Shengxin", ""]]}, {"id": "1806.09180", "submitter": "Luca Bonaventura", "authors": "L. Bonaventura and A. Della Rocca", "title": "Convergence analysis of a cell centered finite volume diffusion operator\n  on non-orthogonal polyhedral meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple but successful strategy for building a discrete diffusion operator\nin finite volume schemes of industrial use is to correct the standard two-point\nflux approximation with a term accounting for the local mesh non-orthogonality.\nPractical experience with a variety of different mesh typologies, including\nnon-orthogonal tetrahedral, hexahedral and polyhedral meshes, has shown that\nthis discrete diffusion operator is accurate and robust whenever the mesh is\nnot too distorted and sufficiently regular. In this work, we show that this\napproach can be interpreted as equivalent to introducing an anisotropic\noperator that accounts for the preferential directions induced by the local\nmesh non-orthogonality. This allows to derive a convergence analysis of the\ncorrected method under a quite weak global assumption on mesh distortion. This\nconvergence proof, which is obtained for the first time for this finite volume\nmethod widely employed in industrial software packages such as OpenFOAM,\nprovides a reference framework on how to interpret some of its variants\ncommonly implemented in commercial finite volume codes. Numerical experiments\nare presented that confirm the accuracy and robustness of the results.\nFurthermore, we also show empirically that a least square approach to the\ngradient computation can provide second order convergence even when the mild\nnon-orthogonality condition on the mesh is violated.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 17:03:41 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Bonaventura", "L.", ""], ["Della Rocca", "A.", ""]]}, {"id": "1806.09545", "submitter": "Oliver Sander", "authors": "Christian Engwer, Carsten Gr\\\"aser, Steffen M\\\"uthing, Oliver Sander", "title": "Function space bases in the dune-functions module", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dune-functions Dune module provides interfaces for functions and function\nspace bases. It forms one abstraction level above grids, shape functions, and\nlinear algebra, and provides infrastructure for full discretization frameworks\nlike dune-pdelab and dune-fem. This document describes the function space bases\nprovided by dune-functions. These are based on an abstract description of bases\nfor product spaces as trees of simpler bases. From this description, many\ndifferent numberings of degrees of freedom by multi-indices can be derived in a\nnatural way. We describe the abstract concepts, document the programmer\ninterface, and give a complete example program that solves the stationary\nStokes equation using Taylor-Hood elements.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 15:58:53 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Engwer", "Christian", ""], ["Gr\u00e4ser", "Carsten", ""], ["M\u00fcthing", "Steffen", ""], ["Sander", "Oliver", ""]]}, {"id": "1806.09620", "submitter": "Bach Tran", "authors": "Hoai An Le Thi, Hoai Minh Le, Duy Nhat Phan, Bach Tran", "title": "A DCA-Like Algorithm and its Accelerated Version with Application in\n  Data Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present two variants of DCA (Different of Convex functions\nAlgorithm) to solve the constrained sum of differentiable function and\ncomposite functions minimization problem, with the aim of increasing the\nconvergence speed of DCA. In the first variant, DCA-Like, we introduce a new\ntechnique to iteratively modify the decomposition of the objective function.\nThis successive decomposition could lead to a better majorization and\nconsequently a better convergence speed than the basic DCA. We then incorporate\nthe Nesterov's acceleration technique into DCA-Like to give rise to the second\nvariant, named Accelerated DCA-Like. The convergence properties and the\nconvergence rate under Kudyka-Lojasiewicz assumption of both variants are\nrigorously studied. As an application, we investigate our algorithms for the\nt-distributed stochastic neighbor embedding. Numerical experiments on several\nbenchmark datasets illustrate the efficiency of our algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 17:47:11 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Thi", "Hoai An Le", ""], ["Le", "Hoai Minh", ""], ["Phan", "Duy Nhat", ""], ["Tran", "Bach", ""]]}, {"id": "1806.09706", "submitter": "Christian Lessig", "authors": "Christian Lessig", "title": "A Local Fourier Slice Theorem", "comments": null, "journal-ref": "Optics Express, 2018", "doi": "10.1364/OE.26.029769", "report-no": null, "categories": "cs.NA math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a local Fourier slice equation that enables local and sparse\nprojection of a signal. Our result exploits that a slice in frequency space is\nan iso-parameter set in spherical coordinates. Therefore, the projection of\nsuitable wavelets defined separably in these coordinates can be computed\nanalytically, yielding a sequence of wavelets closed under projection. Our\nlocal Fourier slice equation then realizes projection as reconstruction with\n\"sliced\" wavelets with computational costs that scale linearly in the\ncomplexity of the projected signal. We numerically evaluate the performance of\nour local Fourier slice equation for synthetic test data and tomographic\nreconstruction, demonstrating that locality and sparsity can significantly\nreduce computation times and memory requirements.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 21:18:51 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 13:50:50 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Lessig", "Christian", ""]]}, {"id": "1806.09871", "submitter": "Francisco Nogueira Calmon Sobral", "authors": "J. Gondzio (1) and F. N. C. Sobral (2) ((1) University of Edinburgh,\n  Scotland, United Kingdom, (2) State University of Maring\\'a, Paran\\'a,\n  Brazil)", "title": "Quasi-Newton approaches to Interior Point Methods for quadratic problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "ERGO 18-015", "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interior Point Methods (IPM) rely on the Newton method for solving systems of\nnonlinear equations. Solving the linear systems which arise from this approach\nis the most computationally expensive task of an interior point iteration. If,\ndue to problem's inner structure, there are special techniques for efficiently\nsolving linear systems, IPMs enjoy fast convergence and are able to solve large\nscale optimization problems. It is tempting to try to replace the Newton method\nby quasi-Newton methods. Quasi-Newton approaches to IPMs either are built to\napproximate the Lagrangian function for nonlinear programming problems or\nprovide an inexpensive preconditioner. In this work we study the impact of\nusing quasi-Newton methods applied directly to the nonlinear system of\nequations for general quadratic programming problems. The cost of each\niteration can be compared to the cost of computing correctors in a usual\ninterior point iteration. Numerical experiments show that the new approach is\nable to reduce the overall number of matrix factorizations and is suitable for\na matrix-free implementation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 09:40:55 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Gondzio", "J.", ""], ["Sobral", "F. N. C.", ""]]}, {"id": "1806.09988", "submitter": "David Hartman", "authors": "David Hartman, Milan Hladik", "title": "Regularity radius: Properties, approximation and a not a priori\n  exponential algorithm", "comments": null, "journal-ref": null, "doi": "10.13001/1081-3810.3749", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The radius of regularity sometimes spelled as the radius of nonsingularity is\na measure providing the distance of a given matrix to the nearest singular one.\nDespite its possible application strength this measure is still far from being\nhandled in an efficient way also due to findings of Poljak and Rohn providing\nproof that checking this property is NP-hard for a general matrix. To handle\nthis we can either find approximation algorithms or making known bounds for\nradius of regularity tighter. Improvements of both have been recently shown by\nHartman and Hladik (doi:10.1007/978-3-319-31769-4\\_9) utilizing relaxation to\nsemidefinite programming. These approaches consider general matrices without or\nwith just mild assumptions about the original matrix. This work explores a\nprocess of regularity radius analysis and identifies useful properties enabling\neasier estimation of the corresponding radius values based on utilization of\nproperties of special class of considered matrices. At first, checking\nfiniteness of regularity radius is shown to be a polynomial problem along with\ndetermining a maximal bound on number of nonzero elements of the matrix to\nobtain infinite radius. Further, relationship between maximum (Chebyshev) norm\nand spectral norm is used to construct new bounds for the radius of regularity.\nA new method based on Jansson-Rohn algorithm for testing regularity of an\ninterval matrix is presented which is not a priory exponential along with\nnumerical experiments. For a situation where an input matrix has a special\nform, several results are provided such as exact formulas for several special\nclasses of matrices, e.g., for totally positive and inverse non-negative, or\napproximation algorithms, e.g., rank-one radius matrices. For tridiagonal\nmatrices, an algorithm by Bar-On, Codenotti and Leoncini is utilized to design\na polynomial algorithm to compute the regularity radius.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 13:46:53 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hartman", "David", ""], ["Hladik", "Milan", ""]]}, {"id": "1806.10038", "submitter": "Yury Korolev", "authors": "Martin Burger, Yury Korolev, Julian Rasch", "title": "Convergence rates and structure of solutions of inverse problems with\n  imperfect forward models", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6420/aaf6f5", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to further develop an approach to inverse problems\nwith imperfect forward operators that is based on partially ordered spaces.\nStudying the dual problem yields useful insights into the convergence of the\nregularised solutions and allow us to obtain convergence rates in terms of\nBregman distances - as usual in inverse problems, under an additional\nassumption on the exact solution called the source condition. These results are\nobtained for general absolutely one-homogeneous functionals. In the special\ncase of TV-based regularisation we also study the structure of regularised\nsolutions and prove convergence of their level sets to those of an exact\nsolution. Finally, using the developed theory, we adapt the concept of\ndebiasing to inverse problems with imperfect operators and propose an approach\nto pointwise error estimation in TV-based regularisation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 14:54:56 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 22:07:41 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Burger", "Martin", ""], ["Korolev", "Yury", ""], ["Rasch", "Julian", ""]]}, {"id": "1806.10156", "submitter": "Susanne Claus", "authors": "Susanne Claus, Pierre Kerfriden", "title": "A CutFEM method for two-phase flow problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2019.01.009", "report-no": null, "categories": "cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we present a cut finite element method for two-phase\nNavier-Stokes flows. The main feature of the method is the formulation of a\nunified continuous interior penalty stabilisation approach for, on the one\nhand, stabilising advection and the pressure-velocity coupling and, on the\nother hand, stabilising the cut region. The accuracy of the algorithm is\nenhanced by the development of extended fictitious domains to guarantee a well\ndefined velocity from previous time steps in the current geometry. Finally, the\nrobustness of the moving-interface algorithm is further improved by the\nintroduction of a curvature smoothing technique that reduces spurious\nvelocities. The algorithm is shown to perform remarkably well for low capillary\nnumber flows, and is a first step towards flexible and robust CutFEM algorithms\nfor the simulation of microfluidic devices.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 18:07:04 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Claus", "Susanne", ""], ["Kerfriden", "Pierre", ""]]}, {"id": "1806.10273", "submitter": "Helio M. de Oliveira", "authors": "H. M. de Oliveira and F. Chaves", "title": "von Mises Tapering: A Circular Data Windowing", "comments": "5 pages, 5 figures", "journal-ref": "XXXVI SIMPOSIO BRASILEIRO DE TELECOMUNICACOES E PROCESSAMENTO DE\n  SINAIS-SBrT2018", "doi": "10.14209/SBRT.2018.179", "report-no": null, "categories": "eess.SP cs.NA math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous standard windowing is revisited and a new taper shape is\nintroduced, which is based on the normal circular distribution by von Mises.\nContinuous-time windows are considered and their spectra obtained. A brief\ncomparison with classical window families is performed in terms of their\nspectral properties. These windows can be used as an alternative in spectral\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 02:30:34 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["de Oliveira", "H. M.", ""], ["Chaves", "F.", ""]]}, {"id": "1806.10436", "submitter": "Quentin Wargnier", "authors": "Quentin Wargnier (CMAP), Sylvain Faure (LM-Orsay), Benjamin Graille\n  (LM-Orsay), Thierry Magin (VKI), Marc Massot (CMAP)", "title": "Numerical treatment of the nonconservative product in a multiscale fluid\n  model for plasmas in thermal nonequilibrium: application to solar physics", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing, Society for Industrial and\n  Applied Mathematics, 2020, 42 (2), pp.B492-B519", "doi": "10.1137/18M1194225", "report-no": null, "categories": "math.NA astro-ph.SR cs.NA math.AP physics.class-ph physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution deals with the modeling of collisional multicomponent\nmagnetized plasmas in thermal and chemical nonequilibrium aiming at simulating\nand predicting magnetic reconnections in the chromosphere of the sun. We focus\non the numerical simulation of a simplified fluid model in order to properly\ninvestigate the influence on shock solutions of a nonconservative product\npresent in the electron energy equation. Then, we derive jump conditions based\non travelling wave solutions and propose an original numerical treatment in\norder to avoid non-physical shocks for the solution, that remains valid in the\ncase of coarse-resolution simulations. A key element for the numerical scheme\nproposed is the presence of diffusion in the electron variables, consistent\nwith the physically-sound scaling used in the model developed by Graille et al.\nfollowing a multiscale Chapman-Enskog expansion method [M3AS, 19 (2009)\n527--599]. The numerical strategy is eventually assessed in the framework of a\nsolar physics test case. The computational method is able to capture the\ntravelling wave solutions in both the highly- and coarsely-resolved cases.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 12:23:49 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 07:19:11 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wargnier", "Quentin", "", "CMAP"], ["Faure", "Sylvain", "", "LM-Orsay"], ["Graille", "Benjamin", "", "LM-Orsay"], ["Magin", "Thierry", "", "VKI"], ["Massot", "Marc", "", "CMAP"]]}, {"id": "1806.10578", "submitter": "Lek-Heng Lim", "authors": "Jose Israel Rodriguez, Jin-Hong Du, Yiling You, and Lek-Heng Lim", "title": "Fiber product homotopy method for multiparameter eigenvalue problems", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new homotopy method for solving multiparameter eigenvalue\nproblems (MEPs) called the fiber product homotopy method. For a $k$-parameter\neigenvalue problem with matrices of sizes $n_1,\\dots ,n_k = O(n)$, fiber\nproduct homotopy method requires deformation of $O(1)$ linear equations, while\nexisting homotopy methods for MEPs require $O(n)$ nonlinear equations. We show\nthat the fiber product homotopy method theoretically finds all eigenpairs of an\nMEP with probability one. It is especially well-suited for dimension-deficient\nsingular MEPs, a weakness of all other existing methods, as the fiber product\nhomotopy method is provably convergent with probability one for such problems\nas well, a fact borne out by numerical experiments. More generally, our\nnumerical experiments indicate that the fiber product homotopy method\nsignificantly outperforms the standard Delta method in terms of accuracy, with\nconsistent backward errors on the order of $10^{-16}$, even for\ndimension-deficient singular problems, and without any use of extended\nprecision. In terms of speed, it significantly outperforms previous\nhomotopy-based methods on all problems and outperforms the Delta method on\nlarger problems, and is also highly parallelizable. We show that the fiber\nproduct MEP that we solve in the fiber product homotopy method, although\nmathematically equivalent to a standard MEP, is typically a much better\nconditioned problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 17:23:45 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 07:20:58 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Rodriguez", "Jose Israel", ""], ["Du", "Jin-Hong", ""], ["You", "Yiling", ""], ["Lim", "Lek-Heng", ""]]}, {"id": "1806.10695", "submitter": "John Paul Ward", "authors": "John Paul Ward, Francis J. Narcowich, Joseph D. Ward", "title": "Interpolating splines on graphs for data science applications", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce intrinsic interpolatory bases for data structured on graphs and\nderive properties of those bases. Polyharmonic Lagrange functions are shown to\nsatisfy exponential decay away from their centers. The decay depends on the\ndensity of the zeros of the Lagrange function, showing that they scale with the\ndensity of the data. These results indicate that Lagrange-type bases are ideal\nbuilding blocks for analyzing data on graphs, and we illustrate their use in\nkernel-based machine learning applications.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 20:50:32 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 20:38:51 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 16:08:41 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ward", "John Paul", ""], ["Narcowich", "Francis J.", ""], ["Ward", "Joseph D.", ""]]}, {"id": "1806.10761", "submitter": "Benjamin Peherstorfer", "authors": "Benjamin Peherstorfer, Karen Willcox, Max Gunzburger", "title": "Survey of multifidelity methods in uncertainty propagation, inference,\n  and optimization", "comments": "will appear in SIAM Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many situations across computational science and engineering, multiple\ncomputational models are available that describe a system of interest. These\ndifferent models have varying evaluation costs and varying fidelities.\nTypically, a computationally expensive high-fidelity model describes the system\nwith the accuracy required by the current application at hand, while\nlower-fidelity models are less accurate but computationally cheaper than the\nhigh-fidelity model. Outer-loop applications, such as optimization, inference,\nand uncertainty quantification, require multiple model evaluations at many\ndifferent inputs, which often leads to computational demands that exceed\navailable resources if only the high-fidelity model is used. This work surveys\nmultifidelity methods that accelerate the solution of outer-loop applications\nby combining high-fidelity and low-fidelity model evaluations, where the\nlow-fidelity evaluations arise from an explicit low-fidelity model (e.g., a\nsimplified physics approximation, a reduced model, a data-fit surrogate, etc.)\nthat approximates the same output quantity as the high-fidelity model. The\noverall premise of these multifidelity methods is that low-fidelity models are\nleveraged for speedup while the high-fidelity model is kept in the loop to\nestablish accuracy and/or convergence guarantees. We categorize multifidelity\nmethods according to three classes of strategies: adaptation, fusion, and\nfiltering. The paper reviews multifidelity methods in the outer-loop contexts\nof uncertainty propagation, inference, and optimization.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 04:06:17 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Peherstorfer", "Benjamin", ""], ["Willcox", "Karen", ""], ["Gunzburger", "Max", ""]]}, {"id": "1806.10825", "submitter": "Andrea Natale", "authors": "Thomas Gallou\\\"et (MOKAPLAN), Andrea Natale (MOKAPLAN),\n  Fran\\c{c}ois-Xavier Vialard (MOKAPLAN)", "title": "Generalized compressible flows and solutions of the H(div) geodesic\n  problem", "comments": null, "journal-ref": null, "doi": "10.1007/s00205-019-01453-x", "report-no": null, "categories": "math.AP cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the geodesic problem on the group of diffeomorphism of a domain\nM$\\subset$Rd, equipped with the H(div) metric. The geodesic equations coincide\nwith the Camassa-Holm equation when d=1, and represent one of its possible\nmulti-dimensional generalizations when d>1. We propose a relaxation {\\`a} la\nBrenier of this problem, in which solutions are represented as probability\nmeasures on the space of continuous paths on the cone over M. We use this\nrelaxation to prove that smooth H(div) geodesics are globally length minimizing\nfor short times. We also prove that there exists a unique pressure field\nassociated to solutions of our relaxation. Finally, we propose a numerical\nscheme to construct generalized solutions on the cone and present some\nnumerical results illustrating the relation between the generalized\nCamassa-Holm and incompressible Euler solutions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 08:31:04 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 13:31:45 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 09:26:47 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Gallou\u00ebt", "Thomas", "", "MOKAPLAN"], ["Natale", "Andrea", "", "MOKAPLAN"], ["Vialard", "Fran\u00e7ois-Xavier", "", "MOKAPLAN"]]}, {"id": "1806.10868", "submitter": "Jakub Marecek", "authors": "Vyacheslav Kungurtsev and Jakub Marecek", "title": "A Two-Step Pre-Processing for Semidefinite Programming", "comments": null, "journal-ref": "The 59th Conference on Decision and Control (CDC 2020)", "doi": null, "report-no": null, "categories": "math.OC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semidefinite programming (SDP), a number of pre-processing techniques have\nbeen developed including chordal-completion procedures, which reduce the\ndimension of individual constraints by exploiting sparsity therein, and facial\nreduction, which reduces the dimension of the problem by removing redundant\nrows and columns. This paper suggest that these work in a complementary manner\nand that facial reduction should be used after chordal-completion procedures.\nIn computational experiments on SDP instances from the SDPLib, a benchmark, and\nstructured instances from polynomial and binary quadratic optimisation, we show\nthat such two-step pre-processing with a standard interior-point method\noutperforms the interior point method, with or without the traditional\npre-processing.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 10:28:27 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 22:56:54 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 20:12:23 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kungurtsev", "Vyacheslav", ""], ["Marecek", "Jakub", ""]]}, {"id": "1806.11277", "submitter": "Eran Treister", "authors": "Eran Treister", "title": "Shifted Laplacian multigrid for the elastic Helmholtz equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shifted Laplacian multigrid method is a well known approach for\npreconditioning the indefinite linear system arising from the discretization of\nthe acoustic Helmholtz equation. This equation is used to model wave\npropagation in the frequency domain. However, in some cases the acoustic\nequation is not sufficient for modeling the physics of the wave propagation,\nand one has to consider the elastic Helmholtz equation. Such a case arises in\ngeophysical seismic imaging applications, where the earth's subsurface is the\nelastic medium. The elastic Helmholtz equation is much harder to solve than its\nacoustic counterpart, partially because it is three times larger, and partially\nbecause it models more complicated physics. Despite this, there are very few\nsolvers available for the elastic equation compared to the array of solvers\nthat are available for the acoustic one. In this work we extend the shifted\nLaplacian approach to the elastic Helmholtz equation, by combining the complex\nshift idea with approaches for linear elasticity. We demonstrate the efficiency\nand properties of our solver using numerical experiments for problems with\nheterogeneous media in two and three dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 06:21:37 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Treister", "Eran", ""]]}, {"id": "1806.11404", "submitter": "C Bach", "authors": "C. Bach, L. Song, T. Erhart, F. Duddeck", "title": "Stability conditions for the explicit integration of projection based\n  nonlinear reduced-order and hyper reduced structural mechanics finite element\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projection-based nonlinear model order reduction methods can be used to\nreduce simulation times for the solution of many PDE-constrained problems. It\nhas been observed in literature that such nonlinear reduced-order models (ROMs)\nbased on Galerkin projection sometimes exhibit much larger stable time step\nsizes than their unreduced counterparts. This work provides a detailed\ntheoretical analysis of this phenomenon for structural mechanics. We first show\nthat many desirable system matrix properties are preserved by the Galerkin\nprojection. Next, we prove that the eigenvalues of the linearized Galerkin\nreduced-order system separate the eigenvalues of the linearized original\nsystem. Assuming non-negative Rayleigh damping and a time integration using the\npopular central difference method, we further prove that the theoretical linear\nstability time step of the ROM is in fact always larger than or equal to the\ncritical time step of its corresponding full-order model. We also give\nmathematical expressions for computing the stable time step size. Finally, we\nshow that under certain conditions this increase in the stability time step\neven extends to some hyper-reduction methods. The findings can be used to\ncompute numerical stability time step sizes for the integration of nonlinear\nROMs in structural mechanics, and to speed up simulations by permitting the use\nof larger time steps.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 13:29:40 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Bach", "C.", ""], ["Song", "L.", ""], ["Erhart", "T.", ""], ["Duddeck", "F.", ""]]}, {"id": "1806.11523", "submitter": "Andreas Petersson", "authors": "Andreas Petersson", "title": "Rapid covariance-based sampling of linear SPDE approximations in the\n  multilevel Monte Carlo method", "comments": "18 pages, 5 figures; numerical simulations revised, implementation\n  section added; To appear in Monte Carlo and Quasi-Monte Carlo Methods -\n  MCQMC, Rennes, France, July 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient simulation of the mean value of a non-linear functional of the\nsolution to a linear stochastic partial differential equation (SPDE) with\nadditive Gaussian noise is considered. A Galerkin finite element method is\nemployed along with an implicit Euler scheme to arrive at a fully discrete\napproximation of the mild solution to the equation. A scheme is presented to\ncompute the covariance of this approximation, which allows for rapid sampling\nin a Monte Carlo method. This is then extended to a multilevel Monte Carlo\nmethod, for which a scheme to compute the cross-covariance between the\napproximations at different levels is presented. In contrast to traditional\npath-based methods it is not assumed that the Galerkin subspaces at these\nlevels are nested. The computational complexities of the presented schemes are\ncompared to traditional methods and simulations confirm that, under suitable\nassumptions, the costs of the new schemes are significantly lower.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 16:26:38 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 19:40:19 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 08:34:47 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Petersson", "Andreas", ""]]}, {"id": "1806.11558", "submitter": "Peter Zaspel", "authors": "Helmut Harbrecht, Peter Zaspel", "title": "A scalable H-matrix approach for the solution of boundary integral\n  equations on multi-GPU clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the solution of boundary integral equations by\nmeans of a scalable hierarchical matrix approach on clusters equipped with\ngraphics hardware, i.e. graphics processing units (GPUs). To this end, we\nextend our existing single-GPU hierarchical matrix library hmglib such that it\nis able to scale on many GPUs and such that it can be coupled to arbitrary\napplication codes. Using a model GPU implementation of a boundary element\nmethod (BEM) solver, we are able to achieve more than 67 percent relative\nparallel speed-up going from 128 to 1024 GPUs for a model geometry test case\nwith 1.5 million unknowns and a real-world geometry test case with almost 1.2\nmillion unknowns. On 1024 GPUs of the cluster Titan, it takes less than 6\nminutes to solve the 1.5 million unknowns problem, with 5.7 minutes for the\nsetup phase and 20 seconds for the iterative solver. To the best of the\nauthors' knowledge, we here discuss the first fully GPU-based\ndistributed-memory parallel hierarchical matrix Open Source library using the\ntraditional H-matrix format and adaptive cross approximation with an\napplication to BEM problems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 07:39:20 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Harbrecht", "Helmut", ""], ["Zaspel", "Peter", ""]]}]