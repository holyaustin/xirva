[{"id": "1203.0889", "submitter": "Rio Yokota Dr.", "authors": "Hatem Ltaief and Rio Yokota", "title": "Data-Driven Execution of Fast Multipole Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast multipole methods have O(N) complexity, are compute bound, and require\nvery little synchronization, which makes them a favorable algorithm on\nnext-generation supercomputers. Their most common application is to accelerate\nN-body problems, but they can also be used to solve boundary integral\nequations. When the particle distribution is irregular and the tree structure\nis adaptive, load-balancing becomes a non-trivial question. A common strategy\nfor load-balancing FMMs is to use the work load from the previous step as\nweights to statically repartition the next step. The authors discuss in the\npaper another approach based on data-driven execution to efficiently tackle\nthis challenging load-balancing problem. The core idea consists of breaking the\nmost time-consuming stages of the FMMs into smaller tasks. The algorithm can\nthen be represented as a Directed Acyclic Graph (DAG) where nodes represent\ntasks, and edges represent dependencies among them. The execution of the\nalgorithm is performed by asynchronously scheduling the tasks using the QUARK\nruntime environment, in a way such that data dependencies are not violated for\nnumerical correctness purposes. This asynchronous scheduling results in an\nout-of-order execution. The performance results of the data-driven FMM\nexecution outperform the previous strategy and show linear speedup on a\nquad-socket quad-core Intel Xeon system.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 12:40:45 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Ltaief", "Hatem", ""], ["Yokota", "Rio", ""]]}, {"id": "1203.1017", "submitter": "Dimitrios Diochnos", "authors": "Dimitrios I. Diochnos, Ioannis Z. Emiris, Elias P. Tsigaridas", "title": "On the asymptotic and practical complexity of solving bivariate systems\n  over the reals", "comments": "17 pages, 4 algorithms, 1 table, and 1 figure with 2 sub-figures", "journal-ref": "J. Symb. Comput. 44(7): 818-835 (2009)", "doi": "10.1016/j.jsc.2008.04.009", "report-no": null, "categories": "cs.SC cs.DS cs.MS cs.NA math.AG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with exact real solving of well-constrained,\nbivariate polynomial systems. The main problem is to isolate all common real\nroots in rational rectangles, and to determine their intersection\nmultiplicities. We present three algorithms and analyze their asymptotic bit\ncomplexity, obtaining a bound of $\\sOB(N^{14})$ for the purely projection-based\nmethod, and $\\sOB(N^{12})$ for two subresultant-based methods: this notation\nignores polylogarithmic factors, where $N$ bounds the degree and the bitsize of\nthe polynomials. The previous record bound was $\\sOB(N^{14})$.\n  Our main tool is signed subresultant sequences. We exploit recent advances on\nthe complexity of univariate root isolation, and extend them to sign evaluation\nof bivariate polynomials over two algebraic numbers, and real root counting for\npolynomials over an extension field. Our algorithms apply to the problem of\nsimultaneous inequalities; they also compute the topology of real plane\nalgebraic curves in $\\sOB(N^{12})$, whereas the previous bound was\n$\\sOB(N^{14})$.\n  All algorithms have been implemented in MAPLE, in conjunction with numeric\nfiltering. We compare them against FGB/RS, system solvers from SYNAPS, and\nMAPLE libraries INSULATE and TOP, which compute curve topology. Our software is\namong the most robust, and its runtimes are comparable, or within a small\nconstant factor, with respect to the C/C++ libraries.\n  Key words: real solving, polynomial systems, complexity, MAPLE software\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 19:39:05 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Diochnos", "Dimitrios I.", ""], ["Emiris", "Ioannis Z.", ""], ["Tsigaridas", "Elias P.", ""]]}, {"id": "1203.1278", "submitter": "Octavio Andr\\'es Gonz\\'alez-Estrada", "authors": "Octavio A. Gonz\\'alez-Estrada, Sundararajan Natarajan, Juan Jos\\'e\n  R\\'odenas, Hung Nguyen-Xuan, St\\'ephane P.A. Bordas", "title": "Efficient recovery-based error estimation for the smoothed finite\n  element method for smooth and singular linear elasticity", "comments": "submitted to Computational Mechanics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An error control technique aimed to assess the quality of smoothed finite\nelement approximations is presented in this paper. Finite element techniques\nbased on strain smoothing appeared in 2007 were shown to provide significant\nadvantages compared to conventional finite element approximations. In\nparticular, a widely cited strength of such methods is improved accuracy for\nthe same computational cost. Yet, few attempts have been made to directly\nassess the quality of the results obtained during the simulation by evaluating\nan estimate of the discretization error. Here we propose a recovery type error\nestimator based on an enhanced recovery technique. The salient features of the\nrecovery are: enforcement of local equilibrium and, for singular problems a\n\"smooth+singular\" decomposition of the recovered stress. We evaluate the\nproposed estimator on a number of test cases from linear elastic structural\nmechanics and obtain precise error estimations whose effectivities, both at\nlocal and global levels, are improved compared to recovery procedures not\nimplementing these features.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2012 18:44:59 GMT"}], "update_date": "2012-03-07", "authors_parsed": [["Gonz\u00e1lez-Estrada", "Octavio A.", ""], ["Natarajan", "Sundararajan", ""], ["R\u00f3denas", "Juan Jos\u00e9", ""], ["Nguyen-Xuan", "Hung", ""], ["Bordas", "St\u00e9phane P. A.", ""]]}, {"id": "1203.1448", "submitter": "Barak Pearlmutter", "authors": "Alexey Radul and Barak A. Pearlmutter and Jeffrey Mark Siskind", "title": "AD in Fortran, Part 1: Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose extensions to Fortran which integrate forward and reverse\nAutomatic Differentiation (AD) directly into the programming model.\nIrrespective of implementation technology, embedding AD constructs directly\ninto the language extends the reach and convenience of AD while allowing\nabstraction of concepts of interest to scientific-computing practice, such as\nroot finding, optimization, and finding equilibria of continuous games.\nMultiple different subprograms for these tasks can share common interfaces,\nregardless of whether and how they use AD internally. A programmer can maximize\na function F by calling a library maximizer, XSTAR=ARGMAX(F,X0), which\ninternally constructs derivatives of F by AD, without having to learn how to\nuse any particular AD tool. We illustrate the utility of these extensions by\nexample: programs become much more concise and closer to traditional\nmathematical notation. A companion paper describes how these extensions can be\nimplemented by a program that generates input to existing Fortran-based AD\ntools.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 12:04:05 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 09:51:03 GMT"}], "update_date": "2012-03-09", "authors_parsed": [["Radul", "Alexey", ""], ["Pearlmutter", "Barak A.", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1203.1450", "submitter": "Barak Pearlmutter", "authors": "Alexey Radul and Barak A. Pearlmutter and Jeffrey Mark Siskind", "title": "AD in Fortran, Part 2: Implementation via Prepreprocessor", "comments": null, "journal-ref": "Recent Advances in Algorithmic Differentiation, Springer Lecture\n  Notes in Computational Science and Engineering volume 87, 2012, ISBN\n  978-3-642-30022-6, pages 273-284", "doi": "10.1007/978-3-642-30023-3_25", "report-no": null, "categories": "cs.PL cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an implementation of the Farfel Fortran AD extensions. These\nextensions integrate forward and reverse AD directly into the programming\nmodel, with attendant benefits to flexibility, modularity, and ease of use. The\nimplementation we describe is a \"prepreprocessor\" that generates input to\nexisting Fortran-based AD tools. In essence, blocks of code which are targeted\nfor AD by Farfel constructs are put into subprograms which capture their\nlexical variable context, and these are closure-converted into top-level\nsubprograms and specialized to eliminate EXTERNAL arguments, rendering them\namenable to existing AD preprocessors, which are then invoked, possibly\nrepeatedly if the AD is nested.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 12:16:30 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 09:56:48 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Radul", "Alexey", ""], ["Pearlmutter", "Barak A.", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1203.1554", "submitter": "D\\'avid Papp", "authors": "Sanjay Mehrotra, D\\'avid Papp", "title": "Generating nested quadrature formulas for general weight functions with\n  known moments", "comments": "Minor update in 2016: fixing a typo in the Mathematica code", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of extending quadrature formulas for general weight\nfunctions, and provide a generalization of Patterson's method for the constant\nweight function. The method can be used to compute a nested sequence of\nquadrature formulas for integration with respect to any continuous probability\nmeasure on the real line with finite moments. The advantages of the method\ninclude that it works directly with the moments of the underlying distribution,\nand that for distributions with rational moments the existence of the formulas\ncan be verified by exact rational arithmetic.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 17:46:46 GMT"}, {"version": "v2", "created": "Thu, 21 Apr 2016 15:33:38 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Mehrotra", "Sanjay", ""], ["Papp", "D\u00e1vid", ""]]}, {"id": "1203.1692", "submitter": "Nicolas Bock", "authors": "Nicolas Bock, Matt Challacombe", "title": "An Optimized Sparse Approximate Matrix Multiply for Matrices with Decay", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR 11-06091", "categories": "cs.NA cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an optimized single-precision implementation of the Sparse\nApproximate Matrix Multiply (\\SpAMM{}) [M. Challacombe and N. Bock, arXiv {\\bf\n1011.3534} (2010)], a fast algorithm for matrix-matrix multiplication for\nmatrices with decay that achieves an $\\mathcal{O} (n \\log n)$ computational\ncomplexity with respect to matrix dimension $n$. We find that the max norm of\nthe error achieved with a \\SpAMM{} tolerance below $2 \\times 10^{-8}$ is lower\nthan that of the single-precision {\\tt SGEMM} for dense quantum chemical\nmatrices, while outperforming {\\tt SGEMM} with a cross-over already for small\nmatrices ($n \\sim 1000$). Relative to naive implementations of \\SpAMM{} using\nIntel's Math Kernel Library ({\\tt MKL}) or AMD's Core Math Library ({\\tt\nACML}), our optimized version is found to be significantly faster. Detailed\nperformance comparisons are made for quantum chemical matrices with differently\nstructured sub-blocks. Finally, we discuss the potential of improved hardware\nprefetch to yield 2--3x speedups.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2012 05:33:01 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2012 22:42:22 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2012 21:49:56 GMT"}, {"version": "v4", "created": "Fri, 31 Aug 2012 22:30:22 GMT"}, {"version": "v5", "created": "Tue, 4 Sep 2012 18:10:32 GMT"}], "update_date": "2012-09-05", "authors_parsed": [["Bock", "Nicolas", ""], ["Challacombe", "Matt", ""]]}, {"id": "1203.2210", "submitter": "Risheng Liu", "authors": "Risheng Liu and Zhouchen Lin and Fernando De la Torre and Zhixun Su", "title": "Fixed-Rank Representation for Unsupervised Visual Learning", "comments": "accepted by CVPR 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering and feature extraction are two of the most commonly used\nunsupervised learning techniques in computer vision and pattern recognition.\nState-of-the-art techniques for subspace clustering make use of recent advances\nin sparsity and rank minimization. However, existing techniques are\ncomputationally expensive and may result in degenerate solutions that degrade\nclustering performance in the case of insufficient data sampling. To partially\nsolve these problems, and inspired by existing work on matrix factorization,\nthis paper proposes fixed-rank representation (FRR) as a unified framework for\nunsupervised visual learning. FRR is able to reveal the structure of multiple\nsubspaces in closed-form when the data is noiseless. Furthermore, we prove that\nunder some suitable conditions, even with insufficient observations, FRR can\nstill reveal the true subspace memberships. To achieve robustness to outliers\nand noise, a sparse regularizer is introduced into the FRR framework. Beyond\nsubspace clustering, FRR can be used for unsupervised feature extraction. As a\nnon-trivial byproduct, a fast numerical solver is developed for FRR.\nExperimental results on both synthetic data and real applications validate our\ntheoretical analysis and demonstrate the benefits of FRR for unsupervised\nvisual learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2012 23:35:52 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2012 15:41:17 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Liu", "Risheng", ""], ["Lin", "Zhouchen", ""], ["De la Torre", "Fernando", ""], ["Su", "Zhixun", ""]]}, {"id": "1203.2377", "submitter": "Joseph Grcar", "authors": "Joseph F. Grcar", "title": "Matrix Stretching for Linear Equations", "comments": "68 pages, 14 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": "SAND90-8723", "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stretching is a new sparse matrix method that makes matrices sparser by\nmaking them larger. Stretching has implications for computational complexity\ntheory and applications in scientific and parallel computing. It changes matrix\nsparsity patterns to render linear equations more easily solved by parallel and\nsparse techniques. Some stretchings increase matrix condition numbers only\nmoderately, and thus solve linear equations stably. For example, these\nstretchings solve arrow equations with accuracy and expense preferable to other\nsolution methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2012 21:27:07 GMT"}], "update_date": "2012-03-13", "authors_parsed": [["Grcar", "Joseph F.", ""]]}, {"id": "1203.2739", "submitter": "Kadir Akbudak Mr", "authors": "Kadir Akbudak, Enver Kayaaslan, Cevdet Aykanat", "title": "Analyzing and enhancing OSKI for sparse matrix-vector multiplication", "comments": "arXiv admin note: substantial text overlap with arXiv:1202.3856", "journal-ref": "SIAM J. Sci. Comput., 35(3), C237-C262. 2013 (26 pages)", "doi": "10.1137/100813956", "report-no": "BU-CE-1201", "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (SpMxV) is a kernel operation widely used\nin iterative linear solvers. The same sparse matrix is multiplied by a dense\nvector repeatedly in these solvers. Matrices with irregular sparsity patterns\nmake it difficult to utilize cache locality effectively in SpMxV computations.\nIn this work, we investigate single- and multiple-SpMxV frameworks for\nexploiting cache locality in SpMxV computations. For the single-SpMxV\nframework, we propose two cache-size-aware top-down row/column-reordering\nmethods based on 1D and 2D sparse matrix partitioning by utilizing the\ncolumn-net and enhancing the row-column-net hypergraph models of sparse\nmatrices. The multiple-SpMxV framework depends on splitting a given matrix into\na sum of multiple nonzero-disjoint matrices so that the SpMxV operation is\nperformed as a sequence of multiple input- and output-dependent SpMxV\noperations. For an effective matrix splitting required in this framework, we\npropose a cache-size-aware top-down approach based on 2D sparse matrix\npartitioning by utilizing the row-column-net hypergraph model. The primary\nobjective in all of the three methods is to maximize the exploitation of\ntemporal locality. We evaluate the validity of our models and methods on a wide\nrange of sparse matrices by performing actual runs through using OSKI.\nExperimental results show that proposed methods and models outperform\nstate-of-the-art schemes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2012 08:50:14 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Akbudak", "Kadir", ""], ["Kayaaslan", "Enver", ""], ["Aykanat", "Cevdet", ""]]}, {"id": "1203.2742", "submitter": "Martin Andersen", "authors": "Martin S. Andersen, Joachim Dahl, Lieven Vandenberghe", "title": "Logarithmic barriers for sparse matrix cones", "comments": null, "journal-ref": null, "doi": "10.1080/10556788.2012.684353", "report-no": null, "categories": "math.OC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms are presented for evaluating gradients and Hessians of logarithmic\nbarrier functions for two types of convex cones: the cone of positive\nsemidefinite matrices with a given sparsity pattern, and its dual cone, the\ncone of sparse matrices with the same pattern that have a positive semidefinite\ncompletion. Efficient large-scale algorithms for evaluating these barriers and\ntheir derivatives are important in interior-point methods for nonsymmetric\nconic formulations of sparse semidefinite programs. The algorithms are based on\nthe multifrontal method for sparse Cholesky factorization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2012 08:59:26 GMT"}], "update_date": "2012-06-15", "authors_parsed": [["Andersen", "Martin S.", ""], ["Dahl", "Joachim", ""], ["Vandenberghe", "Lieven", ""]]}, {"id": "1203.3059", "submitter": "Erhan Turan", "authors": "Erhan Turan and Ali Ecder", "title": "Set Reduction In Nonlinear Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an idea to solve nonlinear equations is presented. During the\nsolution of any problem with Newton's Method, it might happen that some of the\nunknowns satisfy the convergence criteria where the others fail. The\nconvergence happens only when all variables reach to the convergence limit. A\nmethod to reduce the dimension of the overall system by excluding some of the\nunknowns that satisfy an intermediate tolerance is introduced. In this\napproach, a smaller system is solved in less amount of time and already\nestablished local solutions are preserved and kept as constants while the other\nvariables that belong to the \"set\" will be relaxed. To realize the idea, an\nalgorithm is given that utilizes applications of pointers to reduce and\nevaluate the sets. Matrix-free Newton-Krylov Techniques are used on a test\nproblem and it is shown that proposed idea improves the overall convergence.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2012 12:00:08 GMT"}], "update_date": "2012-03-15", "authors_parsed": [["Turan", "Erhan", ""], ["Ecder", "Ali", ""]]}, {"id": "1203.3623", "submitter": "Zhe Wang", "authors": "Zhe Wang, Kai Hu, Baolin Yin", "title": "An Improved Traffic Matrix Decomposition Method with Frequency-Domain\n  Regularization", "comments": "Accepted to IEICE Transactions on Information and Systems", "journal-ref": null, "doi": "10.1587/transinf.E96.D.731", "report-no": null, "categories": "cs.NI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel network traffic matrix decomposition method named Stable\nPrincipal Component Pursuit with Frequency-Domain Regularization (SPCP-FDR),\nwhich improves the Stable Principal Component Pursuit (SPCP) method by using a\nfrequency-domain noise regularization function. An experiment demonstrates the\nfeasibility of this new decomposition method.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 06:57:59 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2012 06:05:31 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Wang", "Zhe", ""], ["Hu", "Kai", ""], ["Yin", "Baolin", ""]]}, {"id": "1203.3800", "submitter": "Eduardo Lopez Sandoval", "authors": "E. Lopez-Sandoval, A. Mello, J. J. Godina-Nava and A. R. Samana", "title": "Power Series Method applied to Inverse Analysis in Chemical Kinetics\n  Problem", "comments": "12 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power Series Solution Method has been traditionally used to solve Ordinary\nand Partial Linear Differential Equations. However, despite their usefulness\nthe application of this method has been limited to this particular kind of\nequations. In this work we use the method of power series to solve nonlinear\npartial differential equations. The method is applied to solve three versions\nof nonlinear time-dependent Burgers-Type differential equations in order to\ndemonstrate its scope and applicability.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 12:41:14 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2012 22:44:21 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2012 19:30:58 GMT"}, {"version": "v4", "created": "Tue, 12 Mar 2013 11:45:14 GMT"}, {"version": "v5", "created": "Wed, 8 Apr 2015 20:26:59 GMT"}, {"version": "v6", "created": "Fri, 10 Apr 2015 17:19:40 GMT"}, {"version": "v7", "created": "Mon, 26 Dec 2016 19:20:20 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Lopez-Sandoval", "E.", ""], ["Mello", "A.", ""], ["Godina-Nava", "J. J.", ""], ["Samana", "A. R.", ""]]}, {"id": "1203.4481", "submitter": "Anastasios Kyrillidis", "authors": "Anastasios Kyrillidis and Volkan Cevher", "title": "Matrix Recipes for Hard Thresholding Methods", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present and analyze a new set of low-rank recovery\nalgorithms for linear inverse problems within the class of hard thresholding\nmethods. We provide strategies on how to set up these algorithms via basic\ningredients for different configurations to achieve complexity vs. accuracy\ntradeoffs. Moreover, we study acceleration schemes via memory-based techniques\nand randomized, $\\epsilon$-approximate matrix projections to decrease the\ncomputational costs in the recovery process. For most of the configurations, we\npresent theoretical analysis that guarantees convergence under mild problem\nconditions. Simulation results demonstrate notable performance improvements as\ncompared to state-of-the-art algorithms both in terms of reconstruction\naccuracy and computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2012 15:56:58 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2013 11:27:50 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Kyrillidis", "Anastasios", ""], ["Cevher", "Volkan", ""]]}, {"id": "1203.4617", "submitter": "Vibeke Libby Dr.", "authors": "John Lindgren and Vibeke Libby", "title": "An Arithmetic and Geometric Mean Invariant", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A positive real interval, [a, b], can be partitioned into sub-intervals such\nthat sub-interval widths divided by sub-interval \"average\" values remains\nconstant. That both Arithmetic Mean and Geometric Mean \"average\" values produce\nconstant ratios for the same log scale is the stated invariance proved in this\nshort note. The continuous analog is briefly considered and shown to have\nsimilar properties.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2012 22:45:57 GMT"}], "update_date": "2012-03-22", "authors_parsed": [["Lindgren", "John", ""], ["Libby", "Vibeke", ""]]}, {"id": "1203.4756", "submitter": "Eliyahu Osherovich", "authors": "Eliyahu Osherovich", "title": "Numerical methods for phase retrieval", "comments": "PhD. Thesis", "journal-ref": null, "doi": null, "report-no": "PHD-2012-04", "categories": "physics.optics astro-ph.IM cs.NA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the problem of reconstruction of a signal from the\nmagnitude of its Fourier transform, also known as phase retrieval. The problem\narises in many areas of astronomy, crystallography, optics, and coherent\ndiffraction imaging (CDI). Our main goal is to develop an efficient\nreconstruction method based on continuous optimization techniques. Unlike\ncurrent reconstruction methods, which are based on alternating projections, our\napproach leads to a much faster and more robust method. However, all previous\nattempts to employ continuous optimization methods, such as Newton-type\nalgorithms, to the phase retrieval problem failed. In this work we provide an\nexplanation for this failure, and based on this explanation we devise a\nsufficient condition that allows development of new reconstruction\nmethods---approximately known Fourier phase. We demonstrate that a rough (up to\n$\\pi/2$ radians) Fourier phase estimate practically guarantees successful\nreconstruction by any reasonable method. We also present a new reconstruction\nmethod whose reconstruction time is orders of magnitude faster than that of the\ncurrent method-of-choice in phase retrieval---Hybrid Input-Output (HIO).\nMoreover, our method is capable of successful reconstruction even in the\nsituations where HIO is known to fail. We also extended our method to other\napplications: Fourier domain holography, and interferometry. Additionally we\ndeveloped a new sparsity-based method for sub-wavelength CDI. Using this method\nwe demonstrated experimental resolution exceeding several times the physical\nlimit imposed by the diffraction light properties (so called diffraction\nlimit).\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2012 09:02:13 GMT"}], "update_date": "2012-03-22", "authors_parsed": [["Osherovich", "Eliyahu", ""]]}, {"id": "1203.4757", "submitter": "Eliyahu Osherovich", "authors": "Eliyahu Osherovich, Oren Cohen, Yonina C. Eldar, and Mordechai Segev", "title": "Designing and using prior data in Ankylography: Recovering a 3D object\n  from a single diffraction intensity pattern", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics astro-ph.IM cs.NA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for Ankylography: three-dimensional structure\nreconstruction from a single shot diffraction intensity pattern. Our approach\nallows reconstruction of objects containing many more details than was ever\ndemonstrated, in a faster and more accurate fashion\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2012 14:58:16 GMT"}], "update_date": "2012-03-22", "authors_parsed": [["Osherovich", "Eliyahu", ""], ["Cohen", "Oren", ""], ["Eldar", "Yonina C.", ""], ["Segev", "Mordechai", ""]]}, {"id": "1203.6030", "submitter": "Dohy Hong", "authors": "Dohy Hong", "title": "Revisiting the D-iteration method: from theoretical to practical\n  computation cost", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the D-iteration algorithm in order to better\nexplain its connection to the Gauss-Seidel method and different performance\nresults that were observed. In particular, we study here the practical\ncomputation cost based on the execution runtime compared to the theoretical\nnumber of iterations. We also propose an exact formula of the error for\nPageRank class of equations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2012 17:20:17 GMT"}], "update_date": "2012-03-28", "authors_parsed": [["Hong", "Dohy", ""]]}, {"id": "1203.6705", "submitter": "Ho Yee Cheung", "authors": "Ho Yee Cheung, Tsz Chiu Kwok, Lap Chi Lau", "title": "Fast Matrix Rank Algorithms and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the rank of an m x n matrix A over a\nfield. We present a randomized algorithm to find a set of r = rank(A) linearly\nindependent columns in \\~O(|A| + r^\\omega) field operations, where |A| denotes\nthe number of nonzero entries in A and \\omega < 2.38 is the matrix\nmultiplication exponent. Previously the best known algorithm to find a set of r\nlinearly independent columns is by Gaussian elimination, with running time\nO(mnr^{\\omega-2}). Our algorithm is faster when r < max(m,n), for instance when\nthe matrix is rectangular. We also consider the problem of computing the rank\nof a matrix dynamically, supporting the operations of rank one updates and\nadditions and deletions of rows and columns. We present an algorithm that\nupdates the rank in \\~O(mn) field operations. We show that these algorithms can\nbe used to obtain faster algorithms for various problems in numerical linear\nalgebra, combinatorial optimization and dynamic data structure.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2012 03:15:57 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2012 01:33:55 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Cheung", "Ho Yee", ""], ["Kwok", "Tsz Chiu", ""], ["Lau", "Lap Chi", ""]]}, {"id": "1203.6758", "submitter": "Diana Alina Bistrian PhD", "authors": "Diana Alina Bistrian, Florica Ioana Dragomirescu, George Savii", "title": "Spectral Differentiation Operators and Hydrodynamic Models for Stability\n  of Swirling Fluid Systems", "comments": null, "journal-ref": "Recent Advances in Applied Mathematics Proceedings of the 14th\n  International Conference on Applied Mathematics, Puerto de la Cruz, 2009,\n  ISBN: 978-960-474-138-0, pp.328-333", "doi": null, "report-no": null, "categories": "math.SP cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop hydrodynamic models using spectral differential\noperators to investigate the spatial stability of swirling fluid systems.\nIncluding viscosity as a valid parameter of the fluid, the hydrodynamic model\nis derived using a nodal Lagrangian basis and the polynomial eigenvalue problem\ndescribing the viscous spatial stability is reduced to a generalized eigenvalue\nproblem using the companion vector method. For inviscid study the hydrodynamic\nmodel is obtained by means of a class of shifted orthogonal expansion functions\nand the spectral differentiation matrix is derived to approximate the discrete\nderivatives. The models were applied to a Q-vortex structure, both schemes\nproviding good results.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2012 10:01:00 GMT"}], "update_date": "2012-04-02", "authors_parsed": [["Bistrian", "Diana Alina", ""], ["Dragomirescu", "Florica Ioana", ""], ["Savii", "George", ""]]}]