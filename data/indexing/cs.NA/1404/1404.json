[{"id": "1404.0122", "submitter": "Farbod Roosta-Khorasani", "authors": "Farbod Roosta-Khorasani and G\\'abor J. Sz\\'ekely and Uri Ascher", "title": "Assessing stochastic algorithms for large scale nonlinear least squares\n  problems using extremal probabilities of linear combinations of gamma random\n  variables", "comments": null, "journal-ref": "SIAM/ASA Journal on Uncertainty Quantification. 3 (2015) 61-90", "doi": "10.1137/14096311X", "report-no": null, "categories": "math.NA cs.NA math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers stochastic algorithms for efficiently solving a class\nof large scale non-linear least squares (NLS) problems which frequently arise\nin applications. We propose eight variants of a practical randomized algorithm\nwhere the uncertainties in the major stochastic steps are quantified. Such\nstochastic steps involve approximating the NLS objective function using\nMonte-Carlo methods, and this is equivalent to the estimation of the trace of\ncorresponding symmetric positive semi-definite (SPSD) matrices. For the latter,\nwe prove tight necessary and sufficient conditions on the sample size (which\ntranslates to cost) to satisfy the prescribed probabilistic accuracy. We show\nthat these conditions are practically computable and yield small sample sizes.\nThey are then incorporated in our stochastic algorithm to quantify the\nuncertainty in each randomized step. The bounds we use are applications of more\ngeneral results regarding extremal tail probabilities of linear combinations of\ngamma distributed random variables. We derive and prove new results concerning\nthe maximal and minimal tail probabilities of such linear combinations, which\ncan be considered independently of the rest of this paper.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2014 04:25:42 GMT"}, {"version": "v2", "created": "Fri, 28 Nov 2014 02:32:28 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Roosta-Khorasani", "Farbod", ""], ["Sz\u00e9kely", "G\u00e1bor J.", ""], ["Ascher", "Uri", ""]]}, {"id": "1404.0442", "submitter": "Kevin Carlberg", "authors": "Kevin Carlberg", "title": "Adaptive $h$-refinement for reduced-order models", "comments": "submitted to the International Journal for Numerical Methods in\n  Engineering, Special Issue on Model Reduction", "journal-ref": "International Journal for Numerical Methods in Engineering, Vol.\n  102, No. 5, p.1192-1210 (2014)", "doi": "10.1002/nme.4800", "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a method to adaptively refine reduced-order models \\emph{a\nposteriori} without requiring additional full-order-model solves. The technique\nis analogous to mesh-adaptive $h$-refinement: it enriches the reduced-basis\nspace online by `splitting' a given basis vector into several vectors with\ndisjoint support. The splitting scheme is defined by a tree structure\nconstructed offline via recursive $k$-means clustering of the state variables\nusing snapshot data. The method identifies the vectors to split online using a\ndual-weighted-residual approach that aims to reduce error in an output quantity\nof interest. The resulting method generates a hierarchy of subspaces online\nwithout requiring large-scale operations or full-order-model solves. Further,\nit enables the reduced-order model to satisfy \\emph{any prescribed error\ntolerance} regardless of its original fidelity, as a completely refined\nreduced-order model is mathematically equivalent to the original full-order\nmodel. Experiments on a parameterized inviscid Burgers equation highlight the\nability of the method to capture phenomena (e.g., moving shocks) not contained\nin the span of the original reduced basis.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 03:29:43 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 04:12:34 GMT"}, {"version": "v3", "created": "Fri, 18 Jul 2014 01:09:10 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Carlberg", "Kevin", ""]]}, {"id": "1404.0447", "submitter": "Lin Lin", "authors": "Mathias Jacquelin, Lin Lin, Chao Yang", "title": "PSelInv -- A Distributed Memory Parallel Algorithm for Selected\n  Inversion : the Symmetric Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an efficient parallel implementation of the selected inversion\nalgorithm for distributed memory computer systems, which we call\n\\texttt{PSelInv}. The \\texttt{PSelInv} method computes selected elements of a\ngeneral sparse matrix $A$ that can be decomposed as $A = LU$, where $L$ is\nlower triangular and $U$ is upper triangular. The implementation described in\nthis paper focuses on the case of sparse symmetric matrices. It contains an\ninterface that is compatible with the distributed memory parallel sparse direct\nfactorization \\texttt{SuperLU\\_DIST}. However, the underlying data structure\nand design of \\texttt{PSelInv} allows it to be easily combined with other\nfactorization routines such as \\texttt{PARDISO}. We discuss general\nparallelization strategies such as data and task distribution schemes. In\nparticular, we describe how to exploit the concurrency exposed by the\nelimination tree associated with the $LU$ factorization of $A$. We demonstrate\nthe efficiency and accuracy of \\texttt{PSelInv} by presenting a number of\nnumerical experiments. In particular, we show that \\texttt{PSelInv} can run\nefficiently on more than $4,000$ cores for a modestly sized matrix. We also\ndemonstrate how \\texttt{PSelInv} can be used to accelerate large-scale\nelectronic structure calculations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 03:48:45 GMT"}, {"version": "v2", "created": "Sat, 27 Dec 2014 17:54:15 GMT"}, {"version": "v3", "created": "Thu, 28 May 2015 21:43:52 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Jacquelin", "Mathias", ""], ["Lin", "Lin", ""], ["Yang", "Chao", ""]]}, {"id": "1404.0466", "submitter": "Da Kuang", "authors": "Da Kuang, Alex Gittens, Raffay Hamid", "title": "piCholesky: Polynomial Interpolation of Multiple Cholesky Factors for\n  Efficient Approximate Cross-Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant cost in solving least-square problems using Newton's method is\noften that of factorizing the Hessian matrix over multiple values of the\nregularization parameter ($\\lambda$). We propose an efficient way to\ninterpolate the Cholesky factors of the Hessian matrix computed over a small\nset of $\\lambda$ values. This approximation enables us to optimally minimize\nthe hold-out error while incurring only a fraction of the cost compared to\nexact cross-validation. We provide a formal error bound for our approximation\nscheme and present solutions to a set of key implementation challenges that\nallow our approach to maximally exploit the compute power of modern\narchitectures. We present a thorough empirical analysis over multiple datasets\nto show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 05:33:41 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2015 18:20:16 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Kuang", "Da", ""], ["Gittens", "Alex", ""], ["Hamid", "Raffay", ""]]}, {"id": "1404.0812", "submitter": "Varun Shankar", "authors": "Varun Shankar, Grady B. Wright, Robert M. Kirby and Aaron L. Fogelson", "title": "A Radial Basis Function (RBF)-Finite Difference (FD) Method for\n  Diffusion and Reaction-Diffusion Equations on Surfaces", "comments": "29 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method based on Radial Basis Function\n(RBF)-generated Finite Differences (FD) for numerically solving diffusion and\nreaction-diffusion equations (PDEs) on closed surfaces embedded in\n$\\mathbb{R}^d$. Our method uses a method-of-lines formulation, in which surface\nderivatives that appear in the PDEs are approximated locally using RBF\ninterpolation. The method requires only scattered nodes representing the\nsurface and normal vectors at those scattered nodes. All computations use only\nextrinsic coordinates, thereby avoiding coordinate distortions and\nsingularities. We also present an optimization procedure that allows for the\nstabilization of the discrete differential operators generated by our RBF-FD\nmethod by selecting shape parameters for each stencil that correspond to a\nglobal target condition number. We show the convergence of our method on two\nsurfaces for different stencil sizes, and present applications to nonlinear\nPDEs simulated both on implicit/parametric surfaces and more general surfaces\nrepresented by point clouds.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2014 09:09:03 GMT"}], "update_date": "2014-04-04", "authors_parsed": [["Shankar", "Varun", ""], ["Wright", "Grady B.", ""], ["Kirby", "Robert M.", ""], ["Fogelson", "Aaron L.", ""]]}, {"id": "1404.1165", "submitter": "YiMing Xia", "authors": "YiMing Xia", "title": "A new multiresolution finite element method based on a multiresolution\n  quadrilateral plate element", "comments": "17 pages", "journal-ref": "Journal of Coupled Systems and Multiscale Dynamics 2014,Vol\n  2(2),1-10", "doi": "10.1166/jcsmd.2014.1040", "report-no": null, "categories": "math.NA cs.NA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A new multiresolution quadrilateral plate element is proposed and a\nmultiresolution finite element method is hence presented. The multiresolution\nanalysis (MRA) framework is formulated out of a mutually nesting displacement\nsubspace sequence, whose basis functions are constructed of scaling and\nshifting on the element domain of basic node shape function. The basic node\nshape function is constructed by extending shape function around a specific\nnode. The MRA endows the proposed element with the resolution level (RL) to\nadjust the element node number, thus modulating structural analysis accuracy\naccordingly. As a result, the traditional 4-node quadrilateral plate element\nand method is a monoresolution one and also a special case of the proposed\nelement and method. The meshing for the monoresolution plate element model is\nbased on the empiricism while the RL adjusting for the multiresolution is laid\non the rigorous mathematical basis. The accuracy of a structural analysis is\nactually determined by the RL, not by the mesh. The rational MRA enable the\nimplementation of the multiresolution element method to be more rational and\nefficient than that of the conventional monoresolution plate element method or\nother corresponding MRA methods such as the wavelet finite element method, the\nmeshfree method, and the natural element method etc.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2014 06:59:15 GMT"}, {"version": "v2", "created": "Tue, 21 Oct 2014 04:25:31 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Xia", "YiMing", ""]]}, {"id": "1404.1530", "submitter": "Christos Boutsidis", "authors": "Dimitris Papailiopoulos, Anastasios Kyrillidis, Christos Boutsidis", "title": "Provable Deterministic Leverage Score Sampling", "comments": "20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.NA math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain theoretically a curious empirical phenomenon: \"Approximating a\nmatrix by deterministically selecting a subset of its columns with the\ncorresponding largest leverage scores results in a good low-rank matrix\nsurrogate\". To obtain provable guarantees, previous work requires randomized\nsampling of the columns with probabilities proportional to their leverage\nscores.\n  In this work, we provide a novel theoretical analysis of deterministic\nleverage score sampling. We show that such deterministic sampling can be\nprovably as accurate as its randomized counterparts, if the leverage scores\nfollow a moderately steep power-law decay. We support this power-law assumption\nby providing empirical evidence that such decay laws are abundant in real-world\ndata sets. We then demonstrate empirically the performance of deterministic\nleverage score sampling, which many times matches or outperforms the\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Sun, 6 Apr 2014 00:08:54 GMT"}, {"version": "v2", "created": "Fri, 11 Apr 2014 10:19:07 GMT"}, {"version": "v3", "created": "Tue, 3 Jun 2014 01:23:16 GMT"}], "update_date": "2014-06-04", "authors_parsed": [["Papailiopoulos", "Dimitris", ""], ["Kyrillidis", "Anastasios", ""], ["Boutsidis", "Christos", ""]]}, {"id": "1404.1610", "submitter": "Matthias Chung", "authors": "Julianne Chung and Matthias Chung", "title": "An Efficient Approach for Computing Optimal Low-Rank Regularized Inverse\n  Matrices", "comments": "24 pages, 11 figures", "journal-ref": null, "doi": "10.1088/0266-5611/30/11/114009", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard regularization methods that are used to compute solutions to\nill-posed inverse problems require knowledge of the forward model. In many\nreal-life applications, the forward model is not known, but training data is\nreadily available. In this paper, we develop a new framework that uses training\ndata, as a substitute for knowledge of the forward model, to compute an optimal\nlow-rank regularized inverse matrix directly, allowing for very fast\ncomputation of a regularized solution. We consider a statistical framework\nbased on Bayes and empirical Bayes risk minimization to analyze theoretical\nproperties of the problem. We propose an efficient rank update approach for\ncomputing an optimal low-rank regularized inverse matrix for various error\nmeasures. Numerical experiments demonstrate the benefits and potential\napplications of our approach to problems in signal and image processing.\n", "versions": [{"version": "v1", "created": "Sun, 6 Apr 2014 19:06:37 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Chung", "Julianne", ""], ["Chung", "Matthias", ""]]}, {"id": "1404.1678", "submitter": "Xian-Ming Gu", "authors": "Xian-Ming Gu, Ting-Zhu Huang, Hou-Biao Li, Sheng-Feng Wang, Liang Li", "title": "Two CSCS-based iteration methods for solving absolute value equations", "comments": "22 pages, 2 figures. This manuscript has been accepted (by J. Appl.\n  Anal. Comput., in press) for publication (2017/02). arXiv admin note: text\n  overlap with arXiv:1403.7013 by other authors", "journal-ref": "J. Appl. Anal. Comput. 7(4) (2017) 1336-1356", "doi": "10.11948/2017082", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, two families of HSS-based iteration methods are constructed for\nsolving the system of absolute value equations (AVEs), which is a class of\nnon-differentiable NP-hard problems. In this study, we establish the\nPicard-CSCS iteration method and the nonlinear CSCS-like iteration method for\nAVEs involving the Toeplitz matrix. Then, we analyze the convergence of the\nPicard-CSCS iteration method for solving AVEs. By using the theory about\nnonsmooth analysis, we particularly prove the convergence of the nonlinear\nCSCS-like iterationsolver for AVEs. The advantage of these methods is that they\ndo not require the storage of coefficient matrices at all, and the sub-system\nof linear equations can be solved efficiently via the fast Fourier transforms\n(FFTs). Therefore, computational cost and storage can be saved in practical\nimplementations. Numerical examples including numerical solutions of nonlinear\nfractional diffusion equations are reported to show the effectiveness of the\nproposed methods in comparison with some existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 07:46:25 GMT"}, {"version": "v2", "created": "Tue, 8 Apr 2014 05:17:30 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2015 16:39:08 GMT"}, {"version": "v4", "created": "Sat, 11 Jun 2016 07:35:19 GMT"}, {"version": "v5", "created": "Thu, 1 Dec 2016 03:38:43 GMT"}, {"version": "v6", "created": "Tue, 21 Feb 2017 08:51:17 GMT"}, {"version": "v7", "created": "Wed, 1 Mar 2017 06:48:16 GMT"}, {"version": "v8", "created": "Mon, 13 Jan 2020 07:40:59 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Gu", "Xian-Ming", ""], ["Huang", "Ting-Zhu", ""], ["Li", "Hou-Biao", ""], ["Wang", "Sheng-Feng", ""], ["Li", "Liang", ""]]}, {"id": "1404.1810", "submitter": "Lorenzo Pasquini", "authors": "Lorenzo Pasquini", "title": "A class of AM-QFT algorithms for power-of-two FFT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a class of power-of-two FFT (Fast Fourier Transform)\nalgorithms, called AM-QFT algorithms, that contains the improved QFT (Quick\nFourier Transform), an algorithm recently published, as a special case. The\nmain idea is to apply the Amplitude Modulation Double Sideband - Suppressed\nCarrier (AM DSB-SC) to convert odd-indices signals into even-indices signals,\nand to insert this elaboration into the improved QFT algorithm, substituting\nthe multiplication by secant function. The 8 variants of this class are\nobtained by re-elaboration of the AM DSB-SC idea, and by means of duality. As a\nresult the 8 variants have both the same computational cost and the same memory\nrequirements than improved QFT. Differently, comparing this class of 8 variants\nof AM-QFT algorithm with the split-radix 3add/3mul (one of the most performing\nFFT approach appeared in the literature), we obtain the same number of\nadditions and multiplications, but employing half of the trigonometric\nconstants. This makes the proposed FFT algorithms interesting and useful for\nfixed-point implementations. Some of these variants show advantages versus the\nimproved QFT. In fact one of this variant slightly enhances the numerical\naccuracy of improved QFT, while other four variants use trigonometric constants\nthat are faster to compute in `on the fly' implementations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 15:06:19 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Pasquini", "Lorenzo", ""]]}, {"id": "1404.2670", "submitter": "Brendan Harding", "authors": "Brendan Harding, Markus Hegland, Jay Larson and James Southern", "title": "Scalable and Fault Tolerant Computation with the Sparse Grid Combination\n  Technique", "comments": "23 pages, 4 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper continues to develop a fault tolerant extension of the sparse grid\ncombination technique recently proposed in [B. Harding and M. Hegland, ANZIAM\nJ., 54 (CTAC2012), pp. C394-C411]. The approach is novel for two reasons, first\nit provides several levels in which one can exploit parallelism leading towards\nmassively parallel implementations, and second, it provides algorithm-based\nfault tolerance so that solutions can still be recovered if failures occur\nduring computation. We present a generalisation of the combination technique\nfrom which the fault tolerant algorithm is a consequence. Using a model for the\ntime between faults on each node of a high performance computer we provide\nbounds on the expected error for interpolation with this algorithm. Numerical\nexperiments on the scalar advection PDE demonstrate that the algorithm is\nresilient to faults on a real application. It is observed that the trade-off of\nrecovery time to decreased accuracy of the solution is suitably small. A\ncomparison with traditional checkpoint-restart methods applied to the\ncombination technique show that our approach is highly scalable with respect to\nthe number of faults.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2014 02:14:34 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Harding", "Brendan", ""], ["Hegland", "Markus", ""], ["Larson", "Jay", ""], ["Southern", "James", ""]]}, {"id": "1404.2891", "submitter": "Eric Polizzi", "authors": "Ping Tak Peter Tang, James Kestyn, Eric Polizzi", "title": "A New Highly Parallel Non-Hermitian Eigensolver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calculating portions of eigenvalues and eigenvectors of matrices or matrix\npencils has many applications. An approach to this calculation for Hermitian\nproblems based on a density matrix has been proposed in 2009 and a software\npackage called FEAST has been developed. The density-matrix approach allows\nFEAST's implementation to exploit a key strength of modern computer\narchitectures, namely, multiple levels of parallelism. Consequently, the\nsoftware package has been well received and subsequently commercialized. A\ndetailed theoretical analysis of Hermitian FEAST has also been established very\nrecently. This paper generalizes the FEAST algorithm and theory, for the first\ntime, to tackle non-Hermitian problems. Fundamentally, the new algorithm is\nbasic subspace iteration or Bauer bi-iteration, except applied with a novel\naccelerator based on Cauchy integrals. The resulting algorithm retains the\nmulti-level parallelism of Hermitian FEAST, making it a valuable new tool for\nlarge-scale computational science and engineering problems on leading-edge\ncomputing platforms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2014 17:59:44 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Tang", "Ping Tak Peter", ""], ["Kestyn", "James", ""], ["Polizzi", "Eric", ""]]}, {"id": "1404.3327", "submitter": "Sebastiano Vigna", "authors": "Sebastiano Vigna", "title": "Supremum-Norm Convergence for Step-Asynchronous Successive\n  Overrelaxation on M-matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Step-asynchronous successive overrelaxation updates the values contained in a\nsingle vector using the usual Gau\\ss-Seidel-like weighted rule, but arbitrarily\nmixing old and new values, the only constraint being temporal coherence: you\ncannot use a value before it has been computed. We show that given a\nnonnegative real matrix $A$, a $\\sigma\\geq\\rho(A)$ and a vector $\\boldsymbol\nw>0$ such that $A\\boldsymbol w\\leq\\sigma\\boldsymbol w$, every iteration of\nstep-asynchronous successive overrelaxation for the problem $(sI- A)\\boldsymbol\nx=\\boldsymbol b$, with $s >\\sigma$, reduces geometrically the $\\boldsymbol\nw$-norm of the current error by a factor that we can compute explicitly. Then,\nwe show that given a $\\sigma>\\rho(A)$ it is in principle always possible to\ncompute such a $\\boldsymbol w$. This property makes it possible to estimate the\nsupremum norm of the absolute error at each iteration without any additional\nhypothesis on $A$, even when $A$ is so large that computing the product\n$A\\boldsymbol x$ is feasible, but estimating the supremum norm of $(sI-A)^{-1}$\nis not.\n", "versions": [{"version": "v1", "created": "Sat, 12 Apr 2014 23:25:52 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Vigna", "Sebastiano", ""]]}, {"id": "1404.3451", "submitter": "Sivaram Ambikasaran", "authors": "Jun Lai, Sivaram Ambikasaran, Leslie F. Greengard", "title": "A fast direct solver for high frequency scattering from a large cavity\n  in two dimensions", "comments": "15 pages, 9 figures. Contact author for animation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast direct solver for the simulation of electromagnetic\nscattering from an arbitrarily-shaped, large, empty cavity embedded in an\ninfinite perfectly conducting half space. The governing Maxwell equations are\nreformulated as a well-conditioned second kind integral equation and the\nresulting linear system is solved in nearly linear time using a hierarchical\nmatrix factorization technique. We illustrate the performance of the scheme\nwith several numerical examples for complex cavity shapes over a wide range of\nfrequencies.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 02:38:34 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Lai", "Jun", ""], ["Ambikasaran", "Sivaram", ""], ["Greengard", "Leslie F.", ""]]}, {"id": "1404.3614", "submitter": "Jaroslav Vond\\v{r}ejc", "authors": "Jaroslav Vond\\v{r}ejc, Jan Zeman, Ivo Marek", "title": "Guaranteed upper-lower bounds on homogenized properties by FFT-based\n  Galerkin method", "comments": "37 pages, 20 figures", "journal-ref": "Computer Methods in Applied Mechanics and Engineering, 297, pp.\n  258-291, 2015", "doi": "10.1016/j.cma.2015.09.003", "report-no": null, "categories": "cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guaranteed upper-lower bounds on homogenized coefficients, arising from the\nperiodic cell problem, are calculated in a scalar elliptic setting. Our\napproach builds on the recent variational reformulation of the Moulinec-Suquet\n(1994) Fast Fourier Transform (FFT) homogenization scheme by Vond\\v{r}ejc et\nal. (2014), which is based on the conforming Galerkin approximation with\ntrigonometric polynomials. Upper-lower bounds are obtained by adjusting the\nprimal-dual finite element framework developed independently by Dvo\\v{r}\\'{a}k\n(1993) and Wieckowski (1995) to the FFT-based Galerkin setting. We show that\nthe discretization procedure differs for odd and non-odd number of grid points.\nThanks to the Helmholtz decomposition inherited from the continuous\nformulation, the duality structure is fully preserved for the odd\ndiscretizations. In the latter case, a more complex primal-dual structure is\nobserved due to presence of the trigonometric polynomials associated with the\nNyquist frequencies. These theoretical findings are confirmed with numerical\nexamples. To conclude, the main advantage of the FFT-based approach over\nconventional finite-element schemes is that the primal and the dual problems\nare treated on the same basis, and this property can be extended beyond the\nscalar elliptic setting.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 15:13:41 GMT"}, {"version": "v2", "created": "Thu, 20 Nov 2014 10:58:02 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2015 15:29:22 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Vond\u0159ejc", "Jaroslav", ""], ["Zeman", "Jan", ""], ["Marek", "Ivo", ""]]}, {"id": "1404.3816", "submitter": "Sivaram Ambikasaran", "authors": "Judith Y. Li, Sivaram Ambikasaran, Eric F. Darve, Peter K. Kitanidis", "title": "A Kalman filter powered by $\\mathcal{H}^2$-matrices for quasi-continuous\n  data assimilation problems", "comments": "18 pages, 7 figures. Water Resources Research, 2014", "journal-ref": null, "doi": "10.1002/2013WR014607", "report-no": null, "categories": "math.NA cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuously tracking the movement of a fluid or a plume in the subsurface is\na challenge that is often encountered in applications, such as tracking a plume\nof injected CO$_2$ or of a hazardous substance. Advances in monitoring\ntechniques have made it possible to collect measurements at a high frequency\nwhile the plume moves, which has the potential advantage of providing\ncontinuous high-resolution images of fluid flow with the aid of data\nprocessing. However, the applicability of this approach is limited by the high\ncomputational cost associated with having to analyze large data sets within the\ntime constraints imposed by real-time monitoring. Existing data assimilation\nmethods have computational requirements that increase super-linearly with the\nsize of the unknowns $m$. In this paper, we present the HiKF, a new Kalman\nfilter (KF) variant powered by the hierarchical matrix approach that\ndramatically reduces the computational and storage cost of the standard KF from\n$\\mathcal{O}(m^2)$ to $\\mathcal{O}(m)$, while producing practically the same\nresults. The version of HiKF that is presented here takes advantage of the\nso-called random walk dynamical model, which is tailored to a class of data\nassimilation problems in which measurements are collected quasi-continuously.\nThe proposed method has been applied to a realistic CO$_2$ injection model and\ncompared with the ensemble Kalman filter (EnKF). Numerical results show that\nHiKF can provide estimates that are more accurate than EnKF, and also\ndemonstrate the usefulness of modeling the system dynamics as a random walk in\nthis context.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 04:43:03 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Li", "Judith Y.", ""], ["Ambikasaran", "Sivaram", ""], ["Darve", "Eric F.", ""], ["Kitanidis", "Peter K.", ""]]}, {"id": "1404.4132", "submitter": "Jia-Jie Zhu", "authors": "William W. Hager, Dzung T. Phan, Jia-Jie Zhu", "title": "Projection Algorithms for Non-Convex Minimization with Application to\n  Sparse Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider concave minimization problems over non-convex sets.Optimization\nproblems with this structure arise in sparse principal component analysis. We\nanalyze both a gradient projection algorithm and an approximate Newton\nalgorithm where the Hessian approximation is a multiple of the identity.\nConvergence results are established. In numerical experiments arising in sparse\nprincipal component analysis, it is seen that the performance of the gradient\nprojection algorithm is very similar to that of the truncated power method and\nthe generalized power method. In some cases, the approximate Newton algorithm\nwith a Barzilai-Borwein (BB) Hessian approximation can be substantially faster\nthan the other algorithms, and can converge to a better solution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Apr 2014 03:57:42 GMT"}, {"version": "v2", "created": "Sat, 19 Apr 2014 18:00:21 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2015 01:04:17 GMT"}, {"version": "v4", "created": "Fri, 3 Mar 2017 16:09:13 GMT"}, {"version": "v5", "created": "Sat, 6 Apr 2019 17:19:08 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Hager", "William W.", ""], ["Phan", "Dzung T.", ""], ["Zhu", "Jia-Jie", ""]]}, {"id": "1404.5009", "submitter": "Chunhua Shen", "authors": "Peng Wang, Chunhua Shen, Anton van den Hengel, Philip Torr", "title": "Efficient Semidefinite Branch-and-Cut for MAP-MRF Inference", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Branch-and-Cut (B&C) method for solving general MAP-MRF\ninference problems. The core of our method is a very efficient bounding\nprocedure, which combines scalable semidefinite programming (SDP) and a\ncutting-plane method for seeking violated constraints. In order to further\nspeed up the computation, several strategies have been exploited, including\nmodel reduction, warm start and removal of inactive constraints.\n  We analyze the performance of the proposed method under different settings,\nand demonstrate that our method either outperforms or performs on par with\nstate-of-the-art approaches. Especially when the connectivities are dense or\nwhen the relative magnitudes of the unary costs are low, we achieve the best\nreported results. Experiments show that the proposed algorithm achieves better\napproximation than the state-of-the-art methods within a variety of time\nbudgets on challenging non-submodular MAP-MRF inference problems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Apr 2014 04:47:04 GMT"}, {"version": "v2", "created": "Tue, 16 Dec 2014 03:43:41 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2015 08:23:09 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2015 04:35:30 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Wang", "Peng", ""], ["Shen", "Chunhua", ""], ["Hengel", "Anton van den", ""], ["Torr", "Philip", ""]]}, {"id": "1404.5363", "submitter": "Art Owen", "authors": "Art B. Owen", "title": "A constraint on extensible quadrature rules", "comments": "7 Pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the worst case integration error in a family of functions decays as\n$n^{-\\alpha}$ for some $\\alpha>1$ and simple averages along an extensible\nsequence match that rate at a set of sample sizes $n_1<n_2<\\dots<\\infty$, then\nthese sample sizes must grow at least geometrically. More precisely,\n$n_{k+1}/n_k\\ge \\rho$ must hold for a value $1<\\rho<2$ that increases with\n$\\alpha$. This result always rules out arithmetic sequences but never rules out\nsample size doubling. The same constraint holds in a root mean square setting.\n", "versions": [{"version": "v1", "created": "Tue, 22 Apr 2014 01:26:04 GMT"}, {"version": "v2", "created": "Thu, 29 Jan 2015 02:17:17 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Owen", "Art B.", ""]]}, {"id": "1404.5525", "submitter": "Jonathan Hauenstein", "authors": "Jonathan D. Hauenstein, Victor Pan, and Agnes Szanto", "title": "Global Newton Iteration over Archimedean and non-Archimedean Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study iterative methods on the coefficients of the rational\nunivariate representation (RUR) of a given algebraic set, called global Newton\niteration. We compare two natural approaches to define locally quadratically\nconvergent iterations: the first one involves Newton iteration applied to the\napproximate roots individually and then interpolation to find the RUR of these\napproximate roots; the second one considers the coefficients in the exact RUR\nas zeroes of a high dimensional map defined by polynomial reduction, and\napplies Newton iteration on this map. We prove that over fields with a p-adic\nvaluation these two approaches give the same iteration function, but over\nfields equipped with the usual Archimedean absolute value, they are not\nequivalent. In the latter case, we give explicitly the iteration function for\nboth approaches. Finally, we analyze the parallel complexity of the different\nversions of the global Newton iteration, compare them, and demonstrate that\nthey can be efficiently computed. The motivation for this study comes from the\ncertification of approximate roots of overdetermined and singular polynomial\nsystems via the recovery of an exact RUR from approximate numerical data.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2014 20:00:33 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["Hauenstein", "Jonathan D.", ""], ["Pan", "Victor", ""], ["Szanto", "Agnes", ""]]}, {"id": "1404.5756", "submitter": "Salvatore Cuomo", "authors": "R. Farina, S. Dobricic, A. Storto, S. Masina and S. Cuomo", "title": "A Revised Scheme to Compute Horizontal Covariances in an Oceanographic\n  3D-VAR Assimilation System", "comments": "26 pages", "journal-ref": null, "doi": "10.1016/j.jcp.2015.01.003", "report-no": null, "categories": "cs.NA cs.CE cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an improvement of an oceanographic three dimensional variational\nassimilation scheme (3D-VAR), named OceanVar, by introducing a recursive filter\n(RF) with the third order of accuracy (3rd-RF), instead of a RF with first\norder of accuracy (1st-RF), to approximate horizontal Gaussian covariances. An\nadvantage of the proposed scheme is that the CPU's time can be substantially\nreduced with benefits on the large scale applications. Experiments estimating\nthe impact of 3rd-RF are performed by assimilating oceanographic data in two\nrealistic oceanographic applications. The results evince benefits in terms of\nassimilation process computational time, accuracy of the Gaussian correlation\nmodeling, and show that the 3rd-RF is a suitable tool for operational data\nassimilation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Apr 2014 09:22:17 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Farina", "R.", ""], ["Dobricic", "S.", ""], ["Storto", "A.", ""], ["Masina", "S.", ""], ["Cuomo", "S.", ""]]}, {"id": "1404.6817", "submitter": "Victor Pan", "authors": "Victor Y. Pan", "title": "Novel Approach to Real Polynomial Root-finding and Matrix Eigen-solving", "comments": "17 pages, added algorithm 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Univariate polynomial root-finding is both classical and important for modern\ncomputing. Frequently one seeks just the real roots of a polynomial with real\ncoefficients. They can be approximated at a low computational cost if the\npolynomial has no nonreal roots, but typically nonreal roots are much more\nnumerous than the real ones. We dramatically accelerate the known algorithms in\nthis case by exploiting the correlation between the computations with matrices\nand polynomials, extending the techniques of the matrix sign iteration, and\nexploiting the structure of the companion matrix of the input polynomial. We\nextend some of the proposed techniques to the approximation of the real\neigenvalues of a real nonsymmetric matrix.\n", "versions": [{"version": "v1", "created": "Sun, 27 Apr 2014 19:58:07 GMT"}, {"version": "v2", "created": "Fri, 20 Jun 2014 18:19:32 GMT"}, {"version": "v3", "created": "Mon, 23 Jun 2014 02:54:46 GMT"}, {"version": "v4", "created": "Mon, 30 Jun 2014 02:47:38 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Pan", "Victor Y.", ""]]}, {"id": "1404.6871", "submitter": "Canyi Lu", "authors": "Canyi Lu, Yunchao Wei, Zhouchen Lin, Shuicheng Yan", "title": "Proximal Iteratively Reweighted Algorithm with Multiple Splitting for\n  Nonconvex Sparsity Optimization", "comments": null, "journal-ref": "Twenty-Eighth AAAI Conference on Artificial Intelligence, 2014", "doi": null, "report-no": null, "categories": "cs.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the Proximal Iteratively REweighted (PIRE) algorithm for\nsolving a general problem, which involves a large body of nonconvex sparse and\nstructured sparse related problems. Comparing with previous iterative solvers\nfor nonconvex sparse problem, PIRE is much more general and efficient. The\ncomputational cost of PIRE in each iteration is usually as low as the\nstate-of-the-art convex solvers. We further propose the PIRE algorithm with\nParallel Splitting (PIRE-PS) and PIRE algorithm with Alternative Updating\n(PIRE-AU) to handle the multi-variable problems. In theory, we prove that our\nproposed methods converge and any limit solution is a stationary point.\nExtensive experiments on both synthesis and real data sets demonstrate that our\nmethods achieve comparative learning performance, but are much more efficient,\nby comparing with previous nonconvex solvers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Apr 2014 05:52:30 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Lu", "Canyi", ""], ["Wei", "Yunchao", ""], ["Lin", "Zhouchen", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1404.6979", "submitter": "Ian Stewart", "authors": "I M Stewart", "title": "An adjustable-width window with good dynamic range", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new variable-width window is presented and compared with several other\nwindows, both of variable and fixed widths. The comparison focuses on\nsensitivity and dynamic range. The equivalent noise bandwidth or ENBW (or\nrather, its reciprocal) is used as a proxy for the first; maximum sidelobe\nlevel and high-frequency roll-off in the Fourier transform, for the second. The\nnew window can access any value of ENBW by appropriate choice of the width\nparameter. At any given value of ENBW below about 3, a setting can be found at\nwhich the sidelobes of the window are lower than those of any other in the\nmoderate frequency regime below about 100 cycles.\n", "versions": [{"version": "v1", "created": "Mon, 28 Apr 2014 13:51:35 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Stewart", "I M", ""]]}]