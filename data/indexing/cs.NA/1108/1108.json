[{"id": "1108.0307", "submitter": "Pavel Chigansky", "authors": "Pavel Chigansky and Fima C. Klebaner", "title": "The Euler-Maruyama approximation for the absorption time of the CEV\n  diffusion", "comments": null, "journal-ref": "DCDS-Ser B., Vol. 17 Issue 5 pp. 1455-1471 (2012)", "doi": "10.3934/dcdsb.2012.17.1455", "report-no": null, "categories": "math.PR cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard convergence analysis of the simulation schemes for the hitting\ntimes of diffusions typically requires non-degeneracy of their coefficients on\nthe boundary, which excludes the possibility of absorption. In this paper we\nconsider the CEV diffusion from the mathematical finance and show how a weakly\nconsistent approximation for the absorption time can be constructed, using the\nEuler-Maruyama scheme.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2011 13:19:56 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2012 11:17:54 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2012 07:36:26 GMT"}], "update_date": "2012-03-16", "authors_parsed": [["Chigansky", "Pavel", ""], ["Klebaner", "Fima C.", ""]]}, {"id": "1108.0952", "submitter": "Kalyana Babu Nakshatrala", "authors": "G. S. Payette, K. B. Nakshatrala, J. N. Reddy", "title": "On the performance of high-order finite elements with respect to maximum\n  principles and the non-negative constraint for diffusion-type equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main aim of this paper is to document the performance of $p$-refinement\nwith respect to maximum principles and the non-negative constraint. The model\nproblem is (steady-state) anisotropic diffusion with decay (which is a\nsecond-order elliptic partial differential equation). We considered the\nstandard single-field formulation (which is based on the Galerkin formalism)\nand two least-squares-based mixed formulations. We have employed non-uniform\nLagrange polynomials for altering the polynomial order in each element, and we\nhave used $p = 1, ..., 10$.\n  It will be shown that the violation of the non-negative constraint will not\nvanish with $p$-refinement for anisotropic diffusion. We shall illustrate the\nperformance of $p$-refinement using several representative problems. The\nintended outcome of the paper is twofold. Firstly, this study will caution the\nusers of high-order approximations about its performance with respect to\nmaximum principles and the non-negative constraint. Secondly, this study will\nhelp researchers to develop new methodologies for enforcing maximum principles\nand the non-negative constraint under high-order approximations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2011 22:21:45 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Payette", "G. S.", ""], ["Nakshatrala", "K. B.", ""], ["Reddy", "J. N.", ""]]}, {"id": "1108.1042", "submitter": "Antanas Zilinskas", "authors": "Antanas Zilinskas", "title": "On strong homogeneity of two global optimization algorithms based on\n  statistical models of multimodal objective functions", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": "10.1016/j.amc.2011.07.051", "report-no": null, "categories": "cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of global optimization algorithms, using the arithmetic of\ninfinity, is considered. A relatively simple version of implementation is\nproposed for the algorithms that possess the introduced property of strong\nhomogeneity. It is shown that the P-algorithm and the one-step Bayesian\nalgorithm are strongly homogeneous.\n", "versions": [{"version": "v1", "created": "Thu, 4 Aug 2011 10:43:17 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Zilinskas", "Antanas", ""]]}, {"id": "1108.1235", "submitter": "Valentin Bolborici", "authors": "Valentin Bolborici, Francis P. Dawson, and Mary C. Pugh", "title": "Technical Report: Modeling of Composite Piezoelectric Structures with\n  the Finite Volume Method", "comments": "Portions of this article have been accepted for publication in IEEE's\n  Transactions on Ultrasonics, Ferroelectrics, and Frequency. The authors need\n  to get permission from the IEEE to reuse this copyrighted material", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Piezoelectric devices, such as piezoelectric traveling wave rotary ultrasonic\nmotors, have composite piezoelectric structures. A composite piezoelectric\nstructure consists of a combination of two or more bonded materials, where at\nleast one of them is a piezoelectric transducer. Numerical modeling of\npiezoelectric structures has been done in the past mainly with the finite\nelement method. Alternatively, a finite volume based approach offers the\nfollowing advantages: (a) the ordinary differential equations resulting from\nthe discretization process can be interpreted directly as corresponding\ncircuits and (b) phenomena occurring at boundaries can be treated exactly. This\nreport extends the work of IEEE Transactions on UFFC 57(2010)7:1673-1691 by\npresenting a method for implementing the boundary conditions between the bonded\nmaterials in composite piezoelectric structures. The report concludes with one\nmodeling example of a unimorph structure.\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2011 00:47:23 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2011 18:07:31 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Bolborici", "Valentin", ""], ["Dawson", "Francis P.", ""], ["Pugh", "Mary C.", ""]]}, {"id": "1108.2045", "submitter": "Julian Tercero Becerra-Sagredo", "authors": "Julian Becerra-Sagredo, Carlos Malaga and Francisco Mandujano", "title": "A novel and scalable Multigrid algorithm for many-core architectures", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multigrid algorithms are among the fastest iterative methods known today for\nsolving large linear and some non-linear systems of equations. Greatly\noptimized for serial operation, they still have a great potential for\nparallelism not fully realized. In this work, we present a novel multigrid\nalgorithm designed to work entirely inside many-core architectures like the\ngraphics processing units (GPUs), without memory transfers between the GPU and\nthe central processing unit (CPU), avoiding low bandwitdth communications. The\nalgorithm is denoted as the high occupancy multigrid (HOMG) because it makes\nuse of entire grid operations with interpolations and relaxations fused into\none task, providing useful work for every thread in the grid. For a given\naccuracy, its number of operations scale linearly with the total number of\nnodes in the grid. Perfect scalability is observed for a large number of\nprocessors.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2011 20:39:54 GMT"}], "update_date": "2011-08-11", "authors_parsed": [["Becerra-Sagredo", "Julian", ""], ["Malaga", "Carlos", ""], ["Mandujano", "Francisco", ""]]}, {"id": "1108.3367", "submitter": "Rafa{\\l} Nowak", "authors": "Rafa{\\l} Nowak", "title": "On the convergence acceleration of some continued fractions", "comments": "English improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well known method for convergence acceleration of continued fraction\n$\\K(a_n/b_n)$ is to use the modified approximants $S_n(\\omega_n)$ in place of\nthe classical approximants $S_n(0)$, where $\\omega_n$ are close to tails\n$f^{(n)}$ of continued fraction. Recently, author proposed a method of\niterative character producing tail approximations whose asymptotic expansion's\naccuracy is improving in each step. This method can be applied to continued\nfractions $\\K(a_n/b_n)$, where $a_n$, $b_n$ are polynomials in $n$ ($\\deg\na_n=2$, $\\deg b_n\\leq 1$) for sufficiently large $n$. The purpose of this paper\nis to extend this idea for the class of continued fractions $\\K(a_n/b_n +\na_n'/b_n')$, where $a_n$, $a_n'$, $b_n$, $b_n'$ are polynomials in $n$ ($\\deg\na_n=\\deg a_n', \\deg b_n=\\deg b_n'$). We give examples involving such continued\nfraction expansions of some mathematical constants, as well as elementary and\nspecial functions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Aug 2011 22:15:55 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2012 06:39:40 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Nowak", "Rafa\u0142", ""]]}, {"id": "1108.4879", "submitter": "Brendan Tracey", "authors": "Brendan Tracey, David Wolpert and Juan J. Alonso", "title": "Using Supervised Learning to Improve Monte Carlo Integral Estimation", "comments": "18 pages, 10 figures, originally published by AIAA at the 13th\n  Non-Deterministic Approaches Conference", "journal-ref": "13th AIAA Non-Deterministic Approaches Conference, Denver, CO,\n  April 2011, AIAA Paper 2011-1843", "doi": null, "report-no": null, "categories": "stat.ML cs.CE cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo (MC) techniques are often used to estimate integrals of a\nmultivariate function using randomly generated samples of the function. In\nlight of the increasing interest in uncertainty quantification and robust\ndesign applications in aerospace engineering, the calculation of expected\nvalues of such functions (e.g. performance measures) becomes important.\nHowever, MC techniques often suffer from high variance and slow convergence as\nthe number of samples increases. In this paper we present Stacked Monte Carlo\n(StackMC), a new method for post-processing an existing set of MC samples to\nimprove the associated integral estimate. StackMC is based on the supervised\nlearning techniques of fitting functions and cross validation. It should reduce\nthe variance of any type of Monte Carlo integral estimate (simple sampling,\nimportance sampling, quasi-Monte Carlo, MCMC, etc.) without adding bias. We\nreport on an extensive set of experiments confirming that the StackMC estimate\nof an integral is more accurate than both the associated unprocessed Monte\nCarlo estimate and an estimate based on a functional fit to the MC samples.\nThese experiments run over a wide variety of integration spaces, numbers of\nsample points, dimensions, and fitting functions. In particular, we apply\nStackMC in estimating the expected value of the fuel burn metric of future\ncommercial aircraft and in estimating sonic boom loudness measures. We compare\nthe efficiency of StackMC with that of more standard methods and show that for\nnegligible additional computational cost significant increases in accuracy are\ngained.\n", "versions": [{"version": "v1", "created": "Wed, 24 Aug 2011 16:22:55 GMT"}], "update_date": "2011-08-25", "authors_parsed": [["Tracey", "Brendan", ""], ["Wolpert", "David", ""], ["Alonso", "Juan J.", ""]]}, {"id": "1108.5359", "submitter": "Risheng Liu", "authors": "Risheng Liu and Zhouchen Lin and Siming Wei and Zhixun Su", "title": "Solving Principal Component Pursuit in Linear Time via $l_1$ Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decades, exactly recovering the intrinsic data structure from\ncorrupted observations, which is known as robust principal component analysis\n(RPCA), has attracted tremendous interests and found many applications in\ncomputer vision. Recently, this problem has been formulated as recovering a\nlow-rank component and a sparse component from the observed data matrix. It is\nproved that under some suitable conditions, this problem can be exactly solved\nby principal component pursuit (PCP), i.e., minimizing a combination of nuclear\nnorm and $l_1$ norm. Most of the existing methods for solving PCP require\nsingular value decompositions (SVD) of the data matrix, resulting in a high\ncomputational complexity, hence preventing the applications of RPCA to very\nlarge scale computer vision problems. In this paper, we propose a novel\nalgorithm, called $l_1$ filtering, for \\emph{exactly} solving PCP with an\n$O(r^2(m+n))$ complexity, where $m\\times n$ is the size of data matrix and $r$\nis the rank of the matrix to recover, which is supposed to be much smaller than\n$m$ and $n$. Moreover, $l_1$ filtering is \\emph{highly parallelizable}. It is\nthe first algorithm that can \\emph{exactly} solve a nuclear norm minimization\nproblem in \\emph{linear time} (with respect to the data size). Experiments on\nboth synthetic data and real applications testify to the great advantage of\n$l_1$ filtering in speed over state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 26 Aug 2011 17:40:30 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2011 01:32:34 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2012 08:39:27 GMT"}, {"version": "v4", "created": "Sun, 6 May 2012 06:16:32 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Liu", "Risheng", ""], ["Lin", "Zhouchen", ""], ["Wei", "Siming", ""], ["Su", "Zhixun", ""]]}, {"id": "1108.5815", "submitter": "Rio Yokota Dr.", "authors": "Rio Yokota and Lorena A. Barba", "title": "Hierarchical N-body simulations with auto-tuning for heterogeneous\n  systems", "comments": null, "journal-ref": "Computing in Science and Engineering, May/June 2012 (vol. 14 no.\n  3), pp. 30-39", "doi": "10.1109/MCSE.2012.1", "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the current hybridization of treecodes and FMMs, combined with\nauto-tuning capabilities on heterogeneous architectures, the flexibility of\nfast N-body methods has been greatly enhanced. These features are a requirement\nto developing a black-box software library for fast N-body algorithms on\nheterogeneous systems, which is our immediate goal.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2011 03:27:14 GMT"}, {"version": "v2", "created": "Sat, 10 Dec 2011 06:15:37 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Yokota", "Rio", ""], ["Barba", "Lorena A.", ""]]}, {"id": "1108.5822", "submitter": "Geoffrey Irving", "authors": "Geoffrey Irving", "title": "Banded Householder representation of linear subspaces", "comments": "5 pages, 1 figure, submitted to Linear Algebra and its Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to compactly represent any $n$-dimensional subspace of $R^m$ as a\nbanded product of Householder reflections using $n(m - n)$ floating point\nnumbers. This is optimal since these subspaces form a Grassmannian space\n$Gr_n(m)$ of dimension $n(m - n)$. The representation is stable and easy to\ncompute: any matrix can be factored into the product of a banded Householder\nmatrix and a square matrix using two to three QR decompositions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2011 03:53:31 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2011 05:29:51 GMT"}, {"version": "v3", "created": "Mon, 12 Sep 2011 16:02:56 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Irving", "Geoffrey", ""]]}, {"id": "1108.6210", "submitter": "Olivier Delestre", "authors": "Olivier Delestre (JAD), Pierre-Yves Lagr\\'ee (IJLRA)", "title": "A well-balanced finite volume scheme for 1D hemodynamic simulations", "comments": "6 pages. R\\'esum\\'e en fran\\c{c}ais : Nous nous int\\'eressons \\`a la\n  simulation d'\\'ecoulements sanguins dans des art\\`eres dont les parois sont\n  \\`a \\'elasticit\\'e variable. Ceci est mod\\'elis\\'e \\`a l'aide d'un mod\\`ele\n  unidimensionnel. Nous pr\\'esentons un sch\\'ema \"volume fini \\'equilibr\\'e\"\n  bas\\'e sur les d\\'eveloppements r\\'ecents effectu\\'es pour la r\\'esolution du\n  syst\\`eme de Saint-Venant. Ainsi, nous obtenons un sch\\'ema qui pr\\'eserve le\n  volume de fluide ainsi que les \\'equilibres au repos: Q=0. Le sch\\'ema\n  introduit est test\\'e sur des solutions analytiques", "journal-ref": null, "doi": "10.1051/proc/201235018", "report-no": null, "categories": "math.NA cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in simulating blood flow in arteries with variable\nelasticity with a one dimensional model. We present a well-balanced finite\nvolume scheme based on the recent developments in shallow water equations\ncontext. We thus get a mass conservative scheme which also preserves equilibria\nof Q=0. This numerical method is tested on analytical tests.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2011 12:45:06 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2012 20:18:09 GMT"}], "update_date": "2012-04-10", "authors_parsed": [["Delestre", "Olivier", "", "JAD"], ["Lagr\u00e9e", "Pierre-Yves", "", "IJLRA"]]}, {"id": "1108.6296", "submitter": "Feng Yan", "authors": "Zenglin Xu, Feng Yan, Yuan (Alan) Qi", "title": "Infinite Tucker Decomposition: Nonparametric Bayesian Models for\n  Multiway Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Tensor decomposition is a powerful computational tool for multiway data\nanalysis. Many popular tensor decomposition approaches---such as the Tucker\ndecomposition and CANDECOMP/PARAFAC (CP)---amount to multi-linear\nfactorization. They are insufficient to model (i) complex interactions between\ndata entities, (ii) various data types (e.g. missing data and binary data), and\n(iii) noisy observations and outliers. To address these issues, we propose\ntensor-variate latent nonparametric Bayesian models, coupled with efficient\ninference methods, for multiway data analysis. We name these models InfTucker.\nUsing these InfTucker, we conduct Tucker decomposition in an infinite feature\nspace. Unlike classical tensor decomposition models, our new approaches handle\nboth continuous and binary data in a probabilistic framework. Unlike previous\nBayesian models on matrices and tensors, our models are based on latent\nGaussian or $t$ processes with nonlinear covariance functions. To efficiently\nlearn the InfTucker from data, we develop a variational inference technique on\ntensors. Compared with classical implementation, the new technique reduces both\ntime and space complexities by several orders of magnitude. Our experimental\nresults on chemometrics and social network datasets demonstrate that our new\nmodels achieved significantly higher prediction accuracy than the most\nstate-of-art tensor decomposition\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2011 17:36:26 GMT"}, {"version": "v2", "created": "Sat, 14 Jan 2012 16:11:56 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Xu", "Zenglin", "", "Alan"], ["Yan", "Feng", "", "Alan"], ["Yuan", "", "", "Alan"], ["Qi", "", ""]]}]