[{"id": "1706.00035", "submitter": "William John Gowers", "authors": "William John Gowers and James Laird", "title": "Sequoidal Categories and Transfinite Games: A Coalgebraic Approach to\n  Stateful Objects in Game Semantics", "comments": "Accepted for publication in the proceedings of CALCO 2017, published\n  in the Dagstuhl LIPIcs series. 15pp + 2pp bibliography + 12 pp Appendix (the\n  appendix is not part of the conference version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The non-commutative sequoid operator $\\oslash$ on games was introduced to\ncapture algebraically the presence of state in history-sensitive strategies in\ngame semantics, by imposing a causality relation on the tensor product of\ngames. Coalgebras for the functor $A \\oslash \\_$ - i.e. morphisms from $S$ to\n$A \\oslash S$ - may be viewed as state transformers: if $A \\oslash \\_$ has a\nfinal coalgebra, $!A$, then the anamorphism of such a state transformer\nencapsulates its explicit state, so that it is shared only between successive\ninvocations.\n  We study the conditions under which a final coalgebra $!A$ for $A \\oslash \\_$\nis the carrier of a cofree commutative comonoid on $A$. That is, it is a model\nof the exponential of linear logic in which we can construct imperative objects\nsuch as reference cells coalgebraically, in a game semantics setting. We show\nthat if the tensor decomposes into the sequoid, the final coalgebra $!A$ may be\nendowed with the structure of the cofree commutative comonoid if there is a\nnatural isomorphism from $!(A \\times B)$ to $!A \\otimes !B$. This condition is\nalways satisfied if $!A$ is the bifree algebra for $A \\oslash \\_$, but in\ngeneral it is necessary to impose it, as we establish by giving an example of a\nsequoidally decomposable category of games in which plays will be allowed to\nhave transfinite length. In this category, the final coalgebra for the functor\n$A \\oslash \\_$ is not the cofree commutative comonoid over A: we illustrate\nthis by explicitly contrasting the final sequence for the functor $A \\oslash\n\\_$ with the chain of symmetric tensor powers used in the construction of the\ncofree commutative comonoid as a limit by Melli\\'es, Tabareau and Tasson.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 18:13:31 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Gowers", "William John", ""], ["Laird", "James", ""]]}, {"id": "1706.00096", "submitter": "Andrew Reynolds", "authors": "Andrew Reynolds, Cesare Tinelli, Clark Barrett", "title": "Constraint Solving for Finite Model Finding in SMT Solvers", "comments": "Under consideration for publication in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SMT solvers have been used successfully as reasoning engines for automated\nverification and other applications based on automated reasoning. Current\ntechniques for dealing with quantified formulas in SMT are generally\nincomplete, forcing SMT solvers to report \"unknown\" when they fail to prove the\nunsatisfiability of a formula with quantifiers. This inability to return\ncounter-models limits their usefulness in applications that produce queries\ninvolving quantified formulas. In this paper, we reduce these limitations by\nintegrating finite model finding techniques based on constraint solving into\nthe architecture used by modern SMT solvers. This approach is made possible by\na novel solver for cardinality constraints, as well as techniques for on-demand\ninstantiation of quantified formulas. Experiments show that our approach is\ncompetitive with the state of the art in SMT, and orthogonal to approaches in\nautomated theorem proving.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 21:21:33 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Reynolds", "Andrew", ""], ["Tinelli", "Cesare", ""], ["Barrett", "Clark", ""]]}, {"id": "1706.00266", "submitter": "Andrew Mironov", "authors": "Andrew M. Mironov", "title": "A graph model of message passing processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we consider a graph model of message passing processes and\npresent a method verification of message passing processes. The method is\nillustrated by an example of a verification of sliding window protocol.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 12:23:56 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Mironov", "Andrew M.", ""]]}, {"id": "1706.00269", "submitter": "Andrew Mironov", "authors": "Andrew M. Mironov", "title": "A new method of verification of security protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we introduce a process model of security protocols, where\nprocesses are graphs with edges labelled by actions, and present a new method\nof specification and verification of security protocols based on this model.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 12:27:48 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Mironov", "Andrew M.", ""]]}, {"id": "1706.00270", "submitter": "Benoit Delahaye", "authors": "Anicet Bart (LS2N), Benoit Delahaye (LS2N), Didier Lime (LS2N), Eric\n  Monfroy (LS2N), Charlotte Truchet (LS2N)", "title": "Reachability in Parametric Interval Markov Chains using Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric Interval Markov Chains (pIMCs) are a specification formalism that\nextend Markov Chains (MCs) and Interval Markov Chains (IMCs) by taking into\naccount imprecision in the transition probability values: transitions in pIMCs\nare labeled with parametric intervals of probabilities. In this work, we study\nthe difference between pIMCs and other Markov Chain abstractions models and\ninvestigate the two usual semantics for IMCs: once-and-for-all and\nat-every-step. In particular, we prove that both semantics agree on the\nmaximal/minimal reachability probabilities of a given IMC. We then investigate\nsolutions to several parameter synthesis problems in the context of pIMCs --\nconsistency, qualitative reachability and quantitative reachability -- that\nrely on constraint encodings. Finally, we propose a prototype implementation of\nour constraint encodings with promising results.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 09:49:10 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Bart", "Anicet", "", "LS2N"], ["Delahaye", "Benoit", "", "LS2N"], ["Lime", "Didier", "", "LS2N"], ["Monfroy", "Eric", "", "LS2N"], ["Truchet", "Charlotte", "", "LS2N"]]}, {"id": "1706.00526", "submitter": "Evan Patterson", "authors": "Evan Patterson", "title": "Knowledge Representation in Bicategories of Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the relational ontology log, or relational olog, a knowledge\nrepresentation system based on the category of sets and relations. It is\ninspired by Spivak and Kent's olog, a recent categorical framework for\nknowledge representation. Relational ologs interpolate between ologs and\ndescription logic, the dominant formalism for knowledge representation today.\nIn this paper, we investigate relational ologs both for their own sake and to\ngain insight into the relationship between the algebraic and logical approaches\nto knowledge representation. On a practical level, we show by example that\nrelational ologs have a friendly and intuitive--yet fully precise--graphical\nsyntax, derived from the string diagrams of monoidal categories. We explain\nseveral other useful features of relational ologs not possessed by most\ndescription logics, such as a type system and a rich, flexible notion of\ninstance data. In a more theoretical vein, we draw on categorical logic to show\nhow relational ologs can be translated to and from logical theories in a\nfragment of first-order logic. Although we make extensive use of categorical\nlanguage, this paper is designed to be self-contained and has considerable\nexpository content. The only prerequisites are knowledge of first-order logic\nand the rudiments of category theory.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 00:42:32 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 15:46:36 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Patterson", "Evan", ""]]}, {"id": "1706.00562", "submitter": "Kei Matsumoto", "authors": "Kei Matsumoto", "title": "Coherence Spaces and Uniform Continuity", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-662-54458-7_1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a model of classical linear logic based on\ncoherence spaces endowed with a notion of totality. If we restrict ourselves to\ntotal objects, each coherence space can be regarded as a uniform space and each\nlinear map as a uniformly continuous function. The linear exponential comonad\nthen assigns to each uniform space X the finest uniform space !X compatible\nwith X. By a standard realizability construction, it is possible to consider a\ntheory of representations in our model. Each (separable, metrizable) uniform\nspace, such as the real line, can then be represented by (a partial surjecive\nmap from) a coherence space with totality. The following holds under certain\nmild conditions: a function between uniform spaces X and Y is uniformly\ncontinuous if and only if it is realized by a total linear map between the\ncoherence spaces representing X and Y.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 05:45:29 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Matsumoto", "Kei", ""]]}, {"id": "1706.00677", "submitter": "J\\\"urgen Koslowski", "authors": "J\\\"org Endrullis, Helle Hvid Hansen, Dimitri Hendriks, Andrew\n  Polonsky, Alexandra Silva", "title": "Coinductive Foundations of Infinitary Rewriting and Infinitary\n  Equational Logic", "comments": "arXiv admin note: substantial text overlap with arXiv:1505.01128,\n  arXiv:1306.6224", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (January\n  10, 2018) lmcs:4195", "doi": "10.23638/LMCS-14(1:3)2018", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a coinductive framework for defining and reasoning about the\ninfinitary analogues of equational logic and term rewriting in a uniform,\ncoinductive way. The setup captures rewrite sequences of arbitrary ordinal\nlength, but it has neither the need for ordinals nor for metric convergence.\nThis makes the framework especially suitable for formalizations in theorem\nprovers.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 23:10:08 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 10:08:22 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Endrullis", "J\u00f6rg", ""], ["Hansen", "Helle Hvid", ""], ["Hendriks", "Dimitri", ""], ["Polonsky", "Andrew", ""], ["Silva", "Alexandra", ""]]}, {"id": "1706.00746", "submitter": "Peng Fu", "authors": "Peng Fu", "title": "Representing Nonterminating Rewriting with $\\mathbf{F}_2^\\mu$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We specify a second-order type system $\\mathbf{F}_2^\\mu$ that is tailored for\nrepresenting nonterminations. The nonterminating trace of a term $t$ in a\nrewrite system $\\mathcal{R}$ corresponds to a productive inhabitant $e$ such\nthat $\\Gamma_{\\mathcal{R}} \\vdash e : t$ in $\\mathbf{F}_2^\\mu$, where\n$\\Gamma_{\\mathcal{R}}$ is the environment representing the rewrite system. We\nprove that the productivity checking in $\\mathbf{F}_2^\\mu$ is decidable via a\nmapping to the $\\lambda$-Y calculus. We develop a type checking algorithm for\n$\\mathbf{F}_2^\\mu$ based on second-order matching. We implement the type\nchecking algorithm in a proof-of-concept type checker.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 16:42:52 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Fu", "Peng", ""]]}, {"id": "1706.00753", "submitter": "Raine Ronnholm", "authors": "Lauri Hella, Antti Kuusisto, Raine R\\\"onnholm", "title": "Bounded game-theoretic semantics for modal mu-calculus", "comments": "Significantly extented version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new game-theoretic semantics (GTS) for the modal mu-calculus.\nOur so-called bounded GTS replaces parity games with alternative evaluation\ngames where only finite paths arise; infinite paths are not needed even when\nthe considered transition system is infinite. The novel games offer alternative\napproaches to various constructions in the framework of the mu-calculus. For\nexample, they have already been successfully used as a basis for an approach\nleading to a natural formula size game for the logic. While our main focus is\nintroducing the new GTS, we also consider some applications to demonstrate its\nuses. For example, we consider a natural model transformation procedure that\nreduces model checking games to checking a single, fixed formula in the\nconstructed models, and we also use the GTS to identify new alternative\nvariants of the mu-calculus with PTime model checking.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 16:57:36 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:12:46 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Hella", "Lauri", ""], ["Kuusisto", "Antti", ""], ["R\u00f6nnholm", "Raine", ""]]}, {"id": "1706.01540", "submitter": "Robert Graham", "authors": "Robert Graham", "title": "Synthetic Homology in Homotopy Type Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines homology in homotopy type theory, in the process stable\nhomotopy groups are also defined. Previous research in synthetic homotopy\ntheory is relied on, in particular the definition of cohomology. This work lays\nthe foundation for a computer checked construction of homology.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 21:10:42 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 14:26:59 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 22:21:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Graham", "Robert", ""]]}, {"id": "1706.01668", "submitter": "Ale\\v{s} Bizjak", "authors": "F\\'elix Baschenis, Olivier Gauwin, Anca Muscholl, Gabriele Puppis", "title": "One-way definability of two-way word transducers", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (December\n  7, 2018) lmcs:5021", "doi": "10.23638/LMCS-14(4:22)2018", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Functional transductions realized by two-way transducers (or, equally, by\nstreaming transducers or MSO transductions) are the natural and standard notion\nof \"regular\" mappings from words to words. It was shown in 2013 that it is\ndecidable if such a transduction can be implemented by some one-way transducer,\nbut the given algorithm has non-elementary complexity. We provide an algorithm\nof different flavor solving the above question, that has doubly exponential\nspace complexity. In the special case of sweeping transducers the complexity is\none exponential less. We also show how to construct an equivalent one-way\ntransducer, whenever it exists, in doubly or triply exponential time, again\ndepending on whether the input transducer is sweeping or two-way. In the\nsweeping case our construction is shown to be optimal.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 09:22:33 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 15:19:52 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 15:30:36 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Baschenis", "F\u00e9lix", ""], ["Gauwin", "Olivier", ""], ["Muscholl", "Anca", ""], ["Puppis", "Gabriele", ""]]}, {"id": "1706.02641", "submitter": "Igor Tarasyuk", "authors": "Igor V. Tarasyuk, Peter Buchholz", "title": "Behavioural equivalences for fluid stochastic Petri nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose fluid equivalences to compare and reduce behaviour of labeled\nfluid stochastic Petri nets (LFSPNs) while preserving their discrete and\ncontinuous properties. We define a linear-time relation of fluid trace\nequivalence and its branching-time counterpart, fluid bisimulation equivalence.\nBoth fluid relations take into account the essential features of the LFSPNs\nbehaviour: functional activity, stochastic timing and fluid flow. We consider\nthe LFSPNs whose continuous markings have no influence to the discrete ones and\nwhose discrete part is continuous time stochastic Petri nets. The underlying\nstochastic model for the discrete part of the LFSPNs is continuous time Markov\nchains (CTMCs). The performance analysis of the continuous part of LFSPNs is\naccomplished via the associated stochastic fluid models (SFMs). We show that\nfluid trace equivalence preserves average potential fluid change volume for the\ntransition sequences of every certain length. We prove that fluid bisimulation\nequivalence preserves the aggregated probability functions: stationary\nprobability mass for the underlying CTMC, as well as stationary fluid buffer\nempty probability, fluid density and distribution for the associated SFM.\nHence, the equivalence guarantees identity of a number of discrete and\ncontinuous performance measures. Fluid bisimulation equivalence is then used to\nsimplify the qualitative and quantitative analysis of LFSPNs via quotienting\nthe discrete reachability graph and underlying CTMC. To describe the quotient\nassociated SFM, the quotients of the probability functions are defined. We\ncharacterize logically fluid trace and bisimulation equivalences with two novel\nfluid modal logics $HML_{flt}$ and $HML_{flb}$, based on the Hennessy-Milner\nLogic HML. The application example of a document preparation system\ndemonstrates the behavioural analysis via quotienting by fluid bisimulation\nequivalence.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 15:28:55 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Tarasyuk", "Igor V.", ""], ["Buchholz", "Peter", ""]]}, {"id": "1706.02701", "submitter": "Anna Bernasconi", "authors": "A. Bernasconi (1), C. Menghi (2), P. Spoletini (3), L. D. Zuck (4),\n  and C. Ghezzi (1) ((1) Politecnico di Milano, (2) Chalmers University of\n  Technology - University of Gothenburg, (3) Kennesaw State University, (4)\n  University of Illinois at Chicago)", "title": "From model checking to a temporal proof for partial models: preliminary\n  example", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes in detail the example introduced in the preliminary\nevaluation of THRIVE. Specifically, it evaluates THRIVE over an abstraction of\nthe ground model proposed for a critical component belonging to a medical\ndevice used by optometrists and ophtalmologits to dected visual problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 09:16:11 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Bernasconi", "A.", ""], ["Menghi", "C.", ""], ["Spoletini", "P.", ""], ["Zuck", "L. D.", ""], ["Ghezzi", "C.", ""]]}, {"id": "1706.02717", "submitter": "EPTCS", "authors": "Liam Garvie (University of Strathclyde), Ross Duncan (University of\n  Strathclyde)", "title": "Verifying the Smallest Interesting Colour Code with Quantomatic", "comments": "In Proceedings QPL 2017, arXiv:1802.09737. v2 removes the long\n  appendix with the complete proofs. This is still available in v1 of this\n  paper", "journal-ref": "EPTCS 266, 2018, pp. 147-163", "doi": "10.4204/EPTCS.266.10", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a Quantomatic case study, verifying the basic\nproperties of the Smallest Interesting Colour Code error detecting code.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 18:02:57 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 03:47:53 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Garvie", "Liam", "", "University of Strathclyde"], ["Duncan", "Ross", "", "University of\n  Strathclyde"]]}, {"id": "1706.02801", "submitter": "Pedro S\\'anchez Terraf", "authors": "Jan Pachl and Pedro S\\'anchez Terraf", "title": "Semipullbacks of labelled Markov processes", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (April 14,\n  2021) lmcs:7361", "doi": null, "report-no": null, "categories": "math.PR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A labelled Markov process (LMP) consists of a measurable space $S$ together\nwith an indexed family of Markov kernels from $S$ to itself. This structure has\nbeen used to model probabilistic computations in Computer Science, and one of\nthe main problems in the area is to define and decide whether two LMP $S$ and\n$S'$ \"behave the same\". There are two natural categorical definitions of\nsameness of behavior: $S$ and $S'$ are bisimilar if there exist an LMP $ T$ and\nmeasure preserving maps forming a diagram of the shape $ S\\leftarrow T\n\\rightarrow{S'}$; and they are behaviorally equivalent if there exist some $ U$\nand maps forming a dual diagram $ S\\rightarrow U \\leftarrow{S'}$.\n  These two notions differ for general measurable spaces but Doberkat\n(extending a result by Edalat) proved that they coincide for analytic Borel\nspaces, showing that from every diagram $S\\rightarrow U \\leftarrow{S'}$ one can\nobtain a bisimilarity diagram as above. Moreover, the resulting square of\nmeasure preserving maps is commutative (a semipullback).\n  In this paper, we extend the previous result to measurable spaces $S$\nisomorphic to a universally measurable subset of a Polish space with the trace\nof the Borel $\\sigma$-algebra, using a version of Strassen's theorem on common\nextensions of finitely additive measures.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 00:47:29 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 12:19:54 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 14:43:52 GMT"}, {"version": "v4", "created": "Mon, 12 Apr 2021 18:25:24 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Pachl", "Jan", ""], ["Terraf", "Pedro S\u00e1nchez", ""]]}, {"id": "1706.02854", "submitter": "Christoph Rauch", "authors": "Denisa Diaconescu, George Metcalfe, Laura Schn\\\"uriger", "title": "A Real-Valued Modal Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (January\n  23, 2018) lmcs:4231", "doi": "10.23638/LMCS-14(1:10)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A many-valued modal logic is introduced that combines the usual Kripke frame\nsemantics of the modal logic K with connectives interpreted locally at worlds\nby lattice and group operations over the real numbers. A labelled tableau\nsystem is provided and a coNEXPTIME upper bound obtained for checking validity\nin the logic. Focussing on the modal-multiplicative fragment, the labelled\ntableau system is then used to establish completeness for a sequent calculus\nthat admits cut-elimination and an axiom system that extends the multiplicative\nfragment of Abelian logic.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 07:24:07 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 12:09:51 GMT"}, {"version": "v3", "created": "Mon, 18 Dec 2017 17:58:26 GMT"}, {"version": "v4", "created": "Mon, 22 Jan 2018 17:03:52 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Diaconescu", "Denisa", ""], ["Metcalfe", "George", ""], ["Schn\u00fcriger", "Laura", ""]]}, {"id": "1706.02866", "submitter": "Samuel Mimram", "authors": "Eric Finster, Samuel Mimram", "title": "A Type-Theoretical Definition of Weak {\\omega}-Categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dependent type theory whose models are weak\n{\\omega}-categories, generalizing Brunerie's definition of {\\omega}-groupoids.\nOur type theory is based on the definition of {\\omega}-categories given by\nMaltsiniotis, himself inspired by Grothendieck's approach to the definition of\n{\\omega}-groupoids. In this setup, {\\omega}-categories are defined as\npresheaves preserving globular colimits over a certain category, called a\ncoherator. The coherator encodes all operations required to be present in an\n{\\omega}-category: both the compositions of pasting schemes as well as their\ncoherences. Our main contribution is to provide a canonical type-theoretical\ncharacterization of pasting schemes as contexts which can be derived from\ninference rules. Finally, we present an implementation of a corresponding proof\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 08:39:38 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Finster", "Eric", ""], ["Mimram", "Samuel", ""]]}, {"id": "1706.02881", "submitter": "Thomas Powell", "authors": "Thomas Powell", "title": "Well quasi-orders and the functional interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this article is to study the role of G\\\"odel's functional\ninterpretation in the extraction of programs from proofs in well quasi-order\ntheory. The main focus is on the interpretation of Nash-Williams' famous\nminimal bad sequence construction, and the exploration of a number of much\nbroader problems which are related to this, particularly the question of the\nconstructive meaning of Zorn's lemma and the notion of recursion over the\nnon-wellfounded lexicographic ordering on infinite sequences.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 10:02:25 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Powell", "Thomas", ""]]}, {"id": "1706.03033", "submitter": "Oriol Valent\\'in", "authors": "Glyn Morrill and Oriol Valent\\'in", "title": "Computational Coverage of TLG: Nonlinearity", "comments": "In proceedings of Natural Language and Computer Science (NLCS), 2015,\n  Kyoto,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonlinear connectives (exponentials) in the context of Type Logical\nGrammar (TLG). We devise four conservative extensions of the displacement\ncalculus with brackets, DbC, DbCM, DbCb and DbCbMr which contain the universal\nand existential exponential modalities of linear logic (LL). These modalities\ndo not exhibit the same structural properties as in LL, which in TLG are\nespecially adapted for linguistic purposes. The universal modality ! for TLG\nallows only the commutative and contraction rules, but not weakening, whereas\nthe existential modality ? allows the so-called (intuitionistic) Mingle rule,\nwhich derives a restricted version of weakening. We provide a Curry-Howard\nlabelling for both exponential connectives. As it turns out, controlled\ncontraction by ! gives a way to account for the so-called parasitic gaps, and\ncontrolled Mingle ? iteration, in particular iterated coordination. Finally,\nthe four calculi are proved to be Cut-Free, and decidability is proved for a\nlinguistically sufficient special case of DbCbMr (and hence DbCb).\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 16:48:58 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Morrill", "Glyn", ""], ["Valent\u00edn", "Oriol", ""]]}, {"id": "1706.03207", "submitter": "Rafael Pe\\~naloza", "authors": "Rafael Pe\\~naloza and Nico Potyka", "title": "Towards Statistical Reasoning in Description Logics over Finite Domains\n  (Full Version)", "comments": "16 pages. Extended version of \"Towards Statistical Reasoning in\n  Description Logics over Finite Domains\" published at the 11th International\n  Conference on Scalable Uncertainty Management (SUM 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic extension of the description logic $\\mathcal{ALC}$\nfor reasoning about statistical knowledge. We consider conditional statements\nover proportions of the domain and are interested in the probabilistic-logical\nconsequences of these proportions. After introducing some general reasoning\nproblems and analyzing their properties, we present first algorithms and\ncomplexity results for reasoning in some fragments of Statistical\n$\\mathcal{ALC}$.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 09:22:32 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Pe\u00f1aloza", "Rafael", ""], ["Potyka", "Nico", ""]]}, {"id": "1706.03244", "submitter": "Oriol Valent\\'in", "authors": "Oriol Valent\\'in", "title": "Models for the Displacement Calculus", "comments": "Appears in the proceedings of Formal Gammar (2015-2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The displacement calculus $\\mathbf{D}$ is a conservative extension of the\nLambek calculus $\\mathbf{L1}$ (with empty antecedents allowed in sequents).\n$\\mathbf{L1}$ can be said to be the logic of concatenation, while $\\mathbf{D}$\ncan be said to be the logic of concatenation and intercalation. In many senses,\nit can be claimed that $\\mathbf{D}$ mimics $\\mathbf{L1}$ in that the proof\ntheory, generative capacity and complexity of the former calculus are natural\nextensions of the latter calculus. In this paper, we strengthen this claim. We\npresent the appropriate classes of models for $\\mathbf{D}$ and prove some\ncompleteness results; strikingly, we see that these results and proofs are\nnatural extensions of the corresponding ones for $\\mathbf{L1}$.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 15:04:39 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Valent\u00edn", "Oriol", ""]]}, {"id": "1706.03392", "submitter": "Xaver Newberry", "authors": "X.Y. Newberry", "title": "Getting around the Halting Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Let {\\Theta}(p,n) be a program that either loops or returns only true or\nfalse. The parameter p is the index of a program P and n is its input. Suppose\nthat {\\Theta}(p,n) = true if and only if P halts on n. It follows that if\n{\\Theta}(P,n) = false then P does not halt on n. Let furthermore {\\Theta}^(n) =\n{\\Theta}(n,n) and {\\Theta}*() = {\\Theta}^({\\theta}*). The claim is that in the\nclass {\\Theta} there exists a program H such that H(h,h*) = false, that is, H\nproves that it does not prove that H* halts. This has implications for solving\nthe liar paradox and for generalization of G\\\"odel incompleteness theorem to\nformal systems other than PA.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 19:28:31 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 02:15:00 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 00:19:41 GMT"}, {"version": "v4", "created": "Mon, 31 Aug 2020 23:26:32 GMT"}, {"version": "v5", "created": "Fri, 26 Mar 2021 16:20:36 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Newberry", "X. Y.", ""]]}, {"id": "1706.03577", "submitter": "Thomas Powell", "authors": "Thomas Powell", "title": "A proof theoretic study of abstract termination principles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We carry out a proof theoretic analysis of the wellfoundedness of recursive\npath orders in an abstract setting. We outline a very general termination\nprinciple and extract from its wellfoundedness proof subrecursive bounds on the\nsize of derivation trees which can be defined in G\\\"{o}del's system T plus bar\nrecursion. We then carry out a complexity analysis of these terms, and\ndemonstrate how this can be applied to bound the derivational complexity of\nterm rewrite systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 11:46:45 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 12:34:55 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Powell", "Thomas", ""]]}, {"id": "1706.03711", "submitter": "James Cheney", "authors": "Wilmer Ricciotti and James Cheney", "title": "Strongly Normalizing Audited Computation", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.CSL.2017.36", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auditing is an increasingly important operation for computer programming, for\nexample in security (e.g. to enable history-based access control) and to enable\nreproducibility and accountability (e.g. provenance in scientific programming).\nMost proposed auditing techniques are ad hoc or treat auditing as a\nsecond-class, extralinguistic operation; logical or semantic foundations for\nauditing are not yet well-established. Justification Logic (JL) offers one such\nfoundation; Bavera and Bonelli introduced a computational interpretation of JL\ncalled $\\lambda^h$ that supports auditing. However, $\\lambda^h$ is technically\ncomplex and strong normalization was only established for special cases. In\naddition, we show that the equational theory of $\\lambda^h$ is inconsistent. We\nintroduce a new calculus $\\lambda^{hc}$ that is simpler than $\\lambda^h$,\nconsistent, and strongly normalizing. Our proof of strong normalization is\nformalized in Nominal Isabelle.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 16:19:51 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Ricciotti", "Wilmer", ""], ["Cheney", "James", ""]]}, {"id": "1706.03949", "submitter": "Marco Voigt", "authors": "Marco Voigt", "title": "On Generalizing Decidable Standard Prefix Classes of First-Order Logic", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the separated fragment (SF) of first-order logic has been\nintroduced. Its defining principle is that universally and existentially\nquantified variables may not occur together in atoms. SF properly generalizes\nboth the Bernays-Sch\\\"onfinkel-Ramsey (BSR) fragment and the relational monadic\nfragment. In this paper the restrictions on variable occurrences in SF\nsentences are relaxed such that universally and existentially quantified\nvariables may occur together in the same atom under certain conditions. Still,\nsatisfiability can be decided. This result is established in two ways: firstly,\nby an effective equivalence-preserving translation into the BSR fragment, and,\nsecondly, by a model-theoretic argument.\n  Slight modifications to the described concepts facilitate the definition of\nother decidable classes of first-order sentences. The paper presents a second\nfragment which is novel, has a decidable satisfiability problem, and properly\ncontains the Ackermann fragment and---once more---the relational monadic\nfragment. The definition is again characterized by restrictions on the\noccurrences of variables in atoms. More precisely, after certain\ntransformations, Skolemization yields only unary functions and constants, and\nevery atom contains at most one universally quantified variable. An effective\nsatisfiability-preserving translation into the monadic fragment is devised and\nemployed to prove decidability of the associated satisfiability problem.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 08:20:14 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Voigt", "Marco", ""]]}, {"id": "1706.04023", "submitter": "Gudmund Grov PhD", "authors": "Gudmund Grov, Duncan Cameron, Leon McGregor", "title": "DAReing to reduce the annotation overheads of verified programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern program verifiers use the same uniform program text to both specify\nand implement programs. The program text is also used to provide the necessary\nguidance to ensure that the program satisfies its specification. The amount of\nguidance required is often called the annotation overhead. This can be high and\nis often seen as a hindrance for wider use of program verifiers, as development\ntime is increased and the guidance may obfuscate the program text. In this\npaper we introduce the DARe tool, which automatically removes as much\nunnecessary guidance as possible for the Dafny program verifier. The tool is\nintegrated with the Dafny IDE. To evaluate DARe, we apply it to 252 programs\nfrom the Dafny library and analyse the degree to which it is able to remove\nunnecessary guidance. Our results are very encouraging as a staggering 88% of\nthe guidance can be removed.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 12:25:10 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Grov", "Gudmund", ""], ["Cameron", "Duncan", ""], ["McGregor", "Leon", ""]]}, {"id": "1706.04108", "submitter": "Dmitry Shkatov", "authors": "Mikhail Rybakov and Dmitry Shkatov", "title": "On complexity of propositional Linear-time Temporal Logic with finitely\n  many variables", "comments": null, "journal-ref": "Prifinal version of the paper published in: In van Niekerk J.,\n  Haskins B. (eds). Proceedings of SAICSIT'18. ACM, 2018. pp. 313-316", "doi": "10.1145/3278681.3278718", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known [DemriSchnoebelen02] that both satisfiability and model-checking\nproblems for propositional Linear-time Temporal Logic, LTL, with only a single\npropositional variable in the language are PSPACE-complete, which coincides\nwith the complexity of these problems for LTL with an arbitrary number of\npropositional variables [SislaClarke85]. In the present paper, we show that the\nsame result can be obtained by modifying the original proof of SPACE-hardness\nfor LTL from [SislaClarke85]; i.e., we show how to modify the construction from\n[SislaClarke85] to model the computations of polynomially-space bound Turing\nmachines using only formulas of one variable. We believe that our alternative\nproof of the results from [DemriSchnoebelen02] gives additional insight into\nthe semantic and computational properties of LTL.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 14:58:23 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 09:40:21 GMT"}, {"version": "v3", "created": "Sun, 25 Nov 2018 20:34:08 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Rybakov", "Mikhail", ""], ["Shkatov", "Dmitry", ""]]}, {"id": "1706.04383", "submitter": "Andreas Nuyts", "authors": "Andreas Nuyts", "title": "A Model of Parametric Dependent Type Theory in Bridge/Path Cubical Sets", "comments": "Technical report. 61 pages. Erratum in semantics of the reflection\n  rule was rectified to the extent possible. Citations were added, textual\n  errors corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this text is to prove all technical aspects of our model for\ndependent type theory with parametric quantifiers [Nuyts, Vezzosi and Devriese,\n2017]. It is well-known that any presheaf category constitutes a model of\ndependent type theory [Hofmann, 1997], including a hierarchy of universes if\nthe metatheory has one [Hofmann and Streicher, 1997]. We construct our model by\ndefining the base category BPCube of bridge/path cubes and adapting the general\npresheaf model over BPCube to suit our needs. Our model is heavily based on the\nmodels by Atkey, Ghani and Johann [2014], Huber [2015], Bezem, Coquand and\nHuber [2014], Cohen, Coquand, Huber and M\\\"ortberg [2016], Moulin [2016] and\nBernardy, Coquand and Moulin [2015].\n  In chapter 1, we review the main concepts of categories with families, and\nthe standard presheaf model of dependent type theory, and we establish the\nnotations we will use.\n  In chapter 2, we capture morphisms of CwFs, and natural transformations and\nadjunctions between them, in typing rules. We especially study morphisms of\nCwFs between presheaf categories, that arise from functors between the base\ncategories.\n  In chapter 3, we introduce the category BPCube of bridge/path cubes, and its\npresheaf category Psh(BPCube) of bridge/path cubical sets. There is a rich\ninteraction with the category of cubical sets Psh(Cube) which we investigate\nmore closely using ideas from axiomatic cohesion [Licata and Shulman, 2016].\n  In chapter 4, we define discrete types and show that they form a model of\ndependent type theory. We prove some infrastructural results.\n  In chapter 5, we give an interpretation of the typing rules of ParamDTT\n[Nuyts, Vezzosi and Devriese, 2017] in Psh(BPCube).\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 09:42:37 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 11:41:39 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Nuyts", "Andreas", ""]]}, {"id": "1706.04582", "submitter": "David Narv\\'aez", "authors": "Lane A. Hemaspaandra and David E. Narv\\'aez", "title": "Existence versus Exploitation: The Opacity of Backbones and Backdoors\n  Under a Weak Assumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoors and backbones of Boolean formulas are hidden structural properties.\nA natural goal, already in part realized, is that solver algorithms seek to\nobtain substantially better performance by exploiting these structures.\n  However, the present paper is not intended to improve the performance of SAT\nsolvers, but rather is a cautionary paper. In particular, the theme of this\npaper is that there is a potential chasm between the existence of such\nstructures in the Boolean formula and being able to effectively exploit them.\nThis does not mean that these structures are not useful to solvers. It does\nmean that one must be very careful not to assume that it is computationally\neasy to go from the existence of a structure to being able to get one's hands\non it and/or being able to exploit the structure.\n  For example, in this paper we show that, under the assumption that P $\\neq$\nNP, there are easily recognizable families of Boolean formulas with strong\nbackdoors that are easy to find, yet for which it is hard (in fact,\nNP-complete) to determine whether the formulas are satisfiable. We also show\nthat, also under the assumption P $\\neq$ NP, there are easily recognizable sets\nof Boolean formulas for which it is hard (in fact, NP-complete) to determine\nwhether they have a large backbone.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 16:46:01 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 21:45:55 GMT"}, {"version": "v3", "created": "Fri, 13 Oct 2017 17:54:53 GMT"}, {"version": "v4", "created": "Tue, 24 Oct 2017 15:51:57 GMT"}, {"version": "v5", "created": "Sat, 10 Mar 2018 16:44:58 GMT"}, {"version": "v6", "created": "Tue, 24 Apr 2018 00:47:04 GMT"}, {"version": "v7", "created": "Tue, 3 Jul 2018 18:44:09 GMT"}, {"version": "v8", "created": "Thu, 1 Nov 2018 19:06:35 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Hemaspaandra", "Lane A.", ""], ["Narv\u00e1ez", "David E.", ""]]}, {"id": "1706.04700", "submitter": "Christoph Rauch", "authors": "Lionel Vaux", "title": "Normalizing the Taylor expansion of non-deterministic {\\lambda}-terms,\n  via parallel reduction of resource vectors", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (July 31,\n  2019) lmcs:5657", "doi": "10.23638/LMCS-15(3:9)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been known since Ehrhard and Regnier's seminal work on the Taylor\nexpansion of $\\lambda$-terms that this operation commutes with normalization:\nthe expansion of a $\\lambda$-term is always normalizable and its normal form is\nthe expansion of the B\\\"ohm tree of the term. We generalize this result to the\nnon-uniform setting of the algebraic $\\lambda$-calculus, i.e.\n$\\lambda$-calculus extended with linear combinations of terms. This requires us\nto tackle two difficulties: foremost is the fact that Ehrhard and Regnier's\ntechniques rely heavily on the uniform, deterministic nature of the ordinary\n$\\lambda$-calculus, and thus cannot be adapted; second is the absence of any\nsatisfactory generic extension of the notion of B\\\"ohm tree in presence of\nquantitative non-determinism, which is reflected by the fact that the Taylor\nexpansion of an algebraic $\\lambda$-term is not always normalizable. Our\nsolution is to provide a fine grained study of the dynamics of\n$\\beta$-reduction under Taylor expansion, by introducing a notion of reduction\non resource vectors, i.e. infinite linear combinations of resource\n$\\lambda$-terms. The latter form the multilinear fragment of the differential\n$\\lambda$-calculus, and resource vectors are the target of the Taylor expansion\nof $\\lambda$-terms. We show the reduction of resource vectors contains the\nimage of any $\\beta$-reduction step, from which we deduce that Taylor expansion\nand normalization commute on the nose. We moreover identify a class of\nalgebraic $\\lambda$-terms, encompassing both normalizable algebraic\n$\\lambda$-terms and arbitrary ordinary $\\lambda$-terms: the expansion of these\nis always normalizable, which guides the definition of a generalization of\nB\\\"ohm trees to this setting.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 00:05:11 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 15:06:55 GMT"}, {"version": "v3", "created": "Fri, 22 Sep 2017 11:15:28 GMT"}, {"version": "v4", "created": "Fri, 16 Feb 2018 21:36:07 GMT"}, {"version": "v5", "created": "Wed, 20 Mar 2019 02:44:13 GMT"}, {"version": "v6", "created": "Tue, 30 Jul 2019 11:09:52 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Vaux", "Lionel", ""]]}, {"id": "1706.04889", "submitter": "Wolfgang Dvo\\v{r}\\'ak", "authors": "Krishnendu Chatterjee and Wolfgang Dvo\\v{r}\\'ak and Monika Henzinger\n  and Veronika Loitzenbauer", "title": "Improved Set-based Symbolic Algorithms for Parity Games", "comments": "An extended abstract has been accepted at CSL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph games with {\\omega}-regular winning conditions provide a mathematical\nframework to analyze a wide range of problems in the analysis of reactive\nsystems and programs (such as the synthesis of reactive systems, program\nrepair, and the verification of branching time properties). Parity conditions\nare canonical forms to specify {\\omega}-regular winning conditions. Graph games\nwith parity conditions are equivalent to {\\mu}-calculus model checking, and\nthus a very important algorithmic problem. Symbolic algorithms are of great\nsignificance because they provide scalable algorithms for the analysis of large\nfinite-state systems, as well as algorithms for the analysis of infinite-state\nsystems with finite quotient. A set-based symbolic algorithm uses the basic set\noperations and the one-step predecessor operators. We consider graph games with\n$n$ vertices and parity conditions with $c$ priorities. While many explicit\nalgorithms exist for graph games with parity conditions, for set-based symbolic\nalgorithms there are only two algorithms (notice that we use space to refer to\nthe number of sets stored by a symbolic algorithm): (a) the basic algorithm\nthat requires $O(n^c)$ symbolic operations and linear space; and (b) an\nimproved algorithm that requires $O(n^{c/2+1})$ symbolic operations but also\n$O(n^{c/2+1})$ space (i.e., exponential space). In this work we present two\nset-based symbolic algorithms for parity games: (a) our first algorithm\nrequires $O(n^{c/2+1})$ symbolic operations and only requires linear space; and\n(b) developing on our first algorithm, we present an algorithm that requires\n$O(n^{c/3+1})$ symbolic operations and only linear space. We also present the\nfirst linear space set-based symbolic algorithm for parity games that requires\nat most a sub-exponential number of symbolic operations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 14:30:39 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Dvo\u0159\u00e1k", "Wolfgang", ""], ["Henzinger", "Monika", ""], ["Loitzenbauer", "Veronika", ""]]}, {"id": "1706.05059", "submitter": "Victor Dalmau", "authors": "Victor Dalmau", "title": "Conjunctions of Among Constraints", "comments": "15 pages plus appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many existing global constraints can be encoded as a conjunction of among\nconstraints. An among constraint holds if the number of the variables in its\nscope whose value belongs to a prespecified set, which we call its range, is\nwithin some given bounds. It is known that domain filtering algorithms can\nbenefit from reasoning about the interaction of among constraints so that\nvalues can be filtered out taking into consideration several among constraints\nsimultaneously. The present pa- per embarks into a systematic investigation on\nthe circumstances under which it is possible to obtain efficient and complete\ndomain filtering algorithms for conjunctions of among constraints. We start by\nobserving that restrictions on both the scope and the range of the among\nconstraints are necessary to obtain meaningful results. Then, we derive a\ndomain flow-based filtering algorithm and present several applications. In\nparticular, it is shown that the algorithm unifies and generalizes several\nprevious existing results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 19:51:52 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Dalmau", "Victor", ""]]}, {"id": "1706.05060", "submitter": "Dmitry Shkatov", "authors": "Mikhail Rybakov and Dmitry Shkatov", "title": "Undecidability of first-order modal and intuitionistic logics with two\n  variables and one monadic predicate letter", "comments": "Pre-final version of the paper published in Studia\n  Logica,doi:10.1007/s11225-018-9815-7", "journal-ref": "Studia Logica, 107(2), 2019, 695-717", "doi": "10.1007/s11225-018-9815-7", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the positive fragment of first-order intuitionistic logic in\nthe language with two variables and a single monadic predicate letter, without\nconstants and equality, is undecidable. This holds true regardless of whether\nwe consider semantics with expanding or constant domains. We then generalise\nthis result to intervals [QBL, QKC] and [QBL, QFL], where QKC is the logic of\nthe weak law of the excluded middle and QBL and QFL are first-order\ncounterparts of Visser's basic and formal logics, respectively. We also show\nthat, for most \"natural\" first-order modal logics, the two-variable fragment\nwith a single monadic predicate letter, without constants and equality, is\nundecidable, regardless of whether we consider semantics with expanding or\nconstant domains. These include all sublogics of QKTB, QGL, and QGrz -- among\nthem, QK, QT, QKB, QD, QK4, and QS4.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 19:56:45 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 13:37:20 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2018 10:52:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Rybakov", "Mikhail", ""], ["Shkatov", "Dmitry", ""]]}, {"id": "1706.05066", "submitter": "Kimberly A. Gero", "authors": "Veena Ravishankar, Kimberly A. Gero, Paliath Narendran", "title": "Asymmetric Unification and Disunification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare two kinds of unification problems: Asymmetric Unification and\nDisunification, which are variants of Equational Unification. Asymmetric\nUnification is a type of Equational Unification where the right-hand sides of\nthe equations are in normal form with respect to the given term rewriting\nsystem. In Disunification we solve equations and disequations with respect to\nan equational theory for the case with free constants. We contrast the time\ncomplexities of both and show that the two problems are incomparable: there are\ntheories where one can be solved in Polynomial time while the other is NP-hard.\nThis goes both ways. The time complexity also varies based on the termination\nordering used in the term rewriting system.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 20:16:54 GMT"}, {"version": "v2", "created": "Tue, 22 Aug 2017 15:19:57 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 19:30:53 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Ravishankar", "Veena", ""], ["Gero", "Kimberly A.", ""], ["Narendran", "Paliath", ""]]}, {"id": "1706.05082", "submitter": "Shiraj Arora", "authors": "Shiraj Arora, M. V. Panduranga Rao", "title": "Probabilistic Model Checking of Incomplete Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is crucial for accurate model checking that the model be a complete and\nfaithful representation of the system. Unfortunately, this is not always\npossible, mainly because of two reasons: (i) the model is still under\ndevelopment and (ii) the correctness of implementation of some modules is not\nestablished. In such circumstances, is it still possible to get correct answers\nfor some model checking queries?\n  This paper is a step towards answering this question. We formulate this\nproblem for the Discrete Time Markov Chains (DTMC) modeling formalism and the\nProbabilistic Computation Tree Logic (PCTL) query language. We then propose a\nsimple solution by modifying DTMC and PCTL to accommodate three valued logic.\nThe technique builds on existing model checking algorithms and tools, obviating\nthe need for new ones to account for three valued logic.\n  One of the most useful and popular techniques for modeling complex systems is\nthrough discrete event simulation. Discrete event simulators are essentially\ncode in some programming language. We show an application of our approach on a\npiece of code that contains a module of unknown correctness.\n  A preliminary version of this paper appears in the proceedings of Leveraging\nApplications of Formal Methods, Verification and Validation: Foundational\nTechniques (ISoLA 2016), LNCS 9952, Springer.\n  Keywords: Probabilistic models, Probabilistic Model checking Three-valued\nLogic, Discrete Time Markov Chain, Probabilistic Computation Tree Logic.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 16:28:23 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Arora", "Shiraj", ""], ["Rao", "M. V. Panduranga", ""]]}, {"id": "1706.05088", "submitter": "Lucas Carvalho Cordeiro", "authors": "Daniel P. M. de Mello, Mauro L. de Freitas, Lucas C. Cordeiro, Waldir\n  S. S. Junior, Iury V. de Bessa, Eddie B. L. Filho and Laurent Clavier", "title": "Verification of Magnitude and Phase Responses in Fixed-Point Digital\n  Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the digital signal processing (DSP) area, one of the most important tasks\nis digital filter design. Currently, this procedure is performed with the aid\nof computational tools, which generally assume filter coefficients represented\nwith floating-point arithmetic. Nonetheless, during the implementation phase,\nwhich is often done in digital signal processors or field programmable gate\narrays, the representation of the obtained coefficients can be carried out\nthrough integer or fixed-point arithmetic, which often results in unexpected\nbehavior or even unstable filters. The present work addresses this issue and\nproposes a verification methodology based on the digital-system verifier\n(DSVerifier), with the goal of checking fixed-point digital filters w.r.t.\nimplementation aspects. In particular, DSVerifier checks whether the number of\nbits used in coefficient representation will result in a filter with the same\nfeatures specified during the design phase. Experimental results show that\nerrors regarding frequency response and overflow are likely to be identified\nwith the proposed methodology, which thus improves overall system's\nreliability.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 10:52:04 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["de Mello", "Daniel P. M.", ""], ["de Freitas", "Mauro L.", ""], ["Cordeiro", "Lucas C.", ""], ["Junior", "Waldir S. S.", ""], ["de Bessa", "Iury V.", ""], ["Filho", "Eddie B. L.", ""], ["Clavier", "Laurent", ""]]}, {"id": "1706.05193", "submitter": "Sebastien Tixeuil", "authors": "Arnaud Sangnier (IRIF), Nathalie Sznajder (MoVe), Maria Potop-Butucaru\n  (NPA, LINCS), S\\'ebastien Tixeuil (NPA, IUF, LINCS)", "title": "Parameterized Verification of Algorithms for Oblivious Robots on a Ring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study verification problems for autonomous swarms of mobile robots that\nself-organize and cooperate to solve global objectives. In particular, we focus\nin this paper on the model proposed by Suzuki and Yamashita of anonymous robots\nevolving in a discrete space with a finite number of locations (here, a ring).\nA large number of algorithms have been proposed working for rings whose size is\nnot a priori fixed and can be hence considered as a parameter. Handmade\ncorrectness proofs of these algorithms have been shown to be error-prone, and\nrecent attention had been given to the application of formal methods to\nautomatically prove those. Our work is the first to study the verification\nproblem of such algorithms in the parameter-ized case. We show that safety and\nreachability problems are undecidable for robots evolving asynchronously. On\nthe positive side, we show that safety properties are decidable in the\nsynchronous case, as well as in the asynchronous case for a particular class of\nalgorithms. Several properties on the protocol can be decided as well. Decision\nprocedures rely on an encoding in Presburger arithmetics formulae that can be\nverified by an SMT-solver. Feasibility of our approach is demonstrated by the\nencoding of several case studies.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 09:38:21 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Sangnier", "Arnaud", "", "IRIF"], ["Sznajder", "Nathalie", "", "MoVe"], ["Potop-Butucaru", "Maria", "", "NPA, LINCS"], ["Tixeuil", "S\u00e9bastien", "", "NPA, IUF, LINCS"]]}, {"id": "1706.05261", "submitter": "Kevin Van Horn", "authors": "Kevin S. Van Horn", "title": "From Propositional Logic to Plausible Reasoning: A Uniqueness Theorem", "comments": "Submitted to Int'l Journal of Approximate Reasoning", "journal-ref": "International Journal of Approximate Reasoning 88 (2017), 309--332", "doi": "10.1016/j.ijar.2017.06.003", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the question of extending propositional logic to a logic of\nplausible reasoning, and posit four requirements that any such extension should\nsatisfy. Each is a requirement that some property of classical propositional\nlogic be preserved in the extended logic; as such, the requirements are simpler\nand less problematic than those used in Cox's Theorem and its variants. As with\nCox's Theorem, our requirements imply that the extended logic must be\nisomorphic to (finite-set) probability theory. We also obtain specific\nnumerical values for the probabilities, recovering the classical definition of\nprobability as a theorem, with truth assignments that satisfy the premise\nplaying the role of the \"possible cases.\"\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 13:13:45 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Van Horn", "Kevin S.", ""]]}, {"id": "1706.05271", "submitter": "Youssef El Bakouny", "authors": "Youssef El Bakouny, Tristan Crolard, Dani Mezher", "title": "A Coq-based synthesis of Scala programs which are\n  correct-by-construction", "comments": "2 pages, accepted version of the paper as submitted to FTfJP 2017\n  (Formal Techniques for Java-like Programs), June 18-23, 2017, Barcelona ,\n  Spain", "journal-ref": null, "doi": "10.1145/3103111.3104041", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper introduces Scala-of-Coq, a new compiler that allows a\nCoq-based synthesis of Scala programs which are \"correct-by-construction\". A\ntypical workflow features a user implementing a Coq functional program, proving\nthis program's correctness with regards to its specification and making use of\nScala-of-Coq to synthesize a Scala program that can seamlessly be integrated\ninto an existing industrial Scala or Java application.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 13:33:45 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Bakouny", "Youssef El", ""], ["Crolard", "Tristan", ""], ["Mezher", "Dani", ""]]}, {"id": "1706.05607", "submitter": "Z\\\"umr\\\"ut Ak\\c{c}am", "authors": "Z\\\"umr\\\"ut Ak\\c{c}am, Daniel S. Hono II, Paliath Narendran", "title": "On Problems Dual to Unification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a problem dual to the unification problem,\nnamely the Common Term (CT) problem for string rewriting systems. Our main\nmotivation was in computing fixed points in systems, such as loop invariants in\nprogramming languages. We show that the fixed point problem is reducible to the\ncommon term problem. We also prove that the common term problem is undecidable\nfor dwindling string rewriting systems.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 04:56:57 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 18:05:43 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Ak\u00e7am", "Z\u00fcmr\u00fct", ""], ["Hono", "Daniel S.", "II"], ["Narendran", "Paliath", ""]]}, {"id": "1706.05637", "submitter": "Ofer Strichman", "authors": "Dor Cohen and Ofer Strichman", "title": "The impact of Entropy and Solution Density on selected SAT heuristics", "comments": null, "journal-ref": null, "doi": "10.3390/e20090713", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent article [Oh'15], Oh examined the impact of various key heuristics\n(e.g., deletion strategy, restart policy, decay factor, database reduction) in\ncompetitive SAT solvers. His key findings are that their expected success\ndepends on whether the input formula is satisfiable or not. To further\ninvestigate these findings, we focused on two properties of satisfiable\nformulas: the entropy of the formula, which approximates the freedom we have in\nassigning the variables, and the solution density, which is the number of\nsolutions divided by the search space. We found that both predict better the\neffect of these heuristics, and that satisfiable formulas with small entropy\n`behave' similarly to unsatisfiable formulas.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 12:03:33 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Cohen", "Dor", ""], ["Strichman", "Ofer", ""]]}, {"id": "1706.05905", "submitter": "Andr\\'es Occhipinti Liberman", "authors": "Alexandru Baltag and Andr\\'es Occhipinti Liberman", "title": "Evidence Logics with Relational Evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic evidence logics are logics for reasoning about the evidence and\nevidence-based beliefs of agents in a dynamic environment. In this paper, we\nintroduce a family of logics for reasoning about relational evidence: evidence\nthat involves an orderings of states in terms of their relative plausibility.\nWe provide sound and complete axiomatizations for the logics. We also present\nseveral evidential actions and prove soundness and completeness for the\nassociated dynamic logics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 12:41:35 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Baltag", "Alexandru", ""], ["Liberman", "Andr\u00e9s Occhipinti", ""]]}, {"id": "1706.05945", "submitter": "Joao Marcos", "authors": "Ori Lahav, Jo\\~ao Marcos, Yoni Zohar", "title": "Sequent systems for negative modalities", "comments": "37 pages, preliminary version, to appear in Logica Universalis. arXiv\n  admin note: substantial text overlap with arXiv:1606.04006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-classical negations may fail to be contradictory-forming operators in\nmore than one way, and they often fail also to respect fundamental meta-logical\nproperties such as the replacement property. Such drawbacks are witnessed by\nintricate semantics and proof systems, whose philosophical interpretations and\ncomputational properties are found wanting. In this paper we investigate\ncongruential non-classical negations that live inside very natural systems of\nnormal modal logics over complete distributive lattices; these logics are\nfurther enriched by adjustment connectives that may be used for handling\nreasoning under uncertainty caused by inconsistency or undeterminedness. Using\nsuch straightforward semantics, we study the classes of frames characterized by\nseriality, reflexivity, functionality, symmetry, transitivity, and some\ncombinations thereof, and discuss what they reveal about sub-classical\nproperties of negation. To the logics thereby characterized we apply a general\nmechanism that allows one to endow them with analytic ordinary sequent systems,\nmost of which are even cut-free. We also investigate the exact circumstances\nthat allow for classical negation to be explicitly defined inside our logics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 21:08:23 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 16:10:33 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Lahav", "Ori", ""], ["Marcos", "Jo\u00e3o", ""], ["Zohar", "Yoni", ""]]}, {"id": "1706.05956", "submitter": "Auke Booij", "authors": "Auke Bart Booij", "title": "The HoTT reals coincide with the Escard\\'o-Simpson reals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Escard\\'o and Simpson defined a notion of interval object by a universal\nproperty in any category with binary products. The Homotopy Type Theory book\ndefines a higher-inductive notion of reals, and suggests that the interval may\nsatisfy this universal property. We show that this is indeed the case in the\ncategory of sets of any universe. We also show that the type of HoTT reals is\nthe least Cauchy complete subset of the Dedekind reals containing the\nrationals.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 14:06:15 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Booij", "Auke Bart", ""]]}, {"id": "1706.06139", "submitter": "Alexander Svozil", "authors": "Krishnendu Chatterjee, Monika Henzinger and Alexander Svozil", "title": "Faster Algorithms for Mean-Payoff Parity Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph games provide the foundation for modeling and synthesis of reactive\nprocesses. Such games are played over graphs where the vertices are controlled\nby two adversarial players. We consider graph games where the objective of the\nfirst player is the conjunction of a qualitative objective (specified as a\nparity condition) and a quantitative objective (specified as a mean-payoff\ncondition). There are two variants of the problem, namely, the threshold\nproblem where the quantitative goal is to ensure that the mean-payoff value is\nabove a threshold, and the value problem where the quantitative goal is to\nensure the optimal mean-payoff value; in both cases ensuring the qualitative\nparity objective. The previous best-known algorithms for game graphs with $n$\nvertices, $m$ edges, parity objectives with $d$ priorities, and maximal\nabsolute reward value $W$ for mean-payoff objectives, are as follows:\n$O(n^{d+1} \\cdot m \\cdot W)$ for the threshold problem, and $O(n^{d+2} \\cdot m\n\\cdot W)$ for the value problem. Our main contributions are faster algorithms,\nand the running times of our algorithms are as follows: $O(n^{d-1} \\cdot m\n\\cdot W)$ for the threshold problem, and $O(n^{d} \\cdot m \\cdot W \\cdot \\log\n(n\\cdot W))$ for the value problem. For mean-payoff parity objectives with two\npriorities, our algorithms match the best-known bounds of the algorithms for\nmean-payoff games (without conjunction with parity objectives). Our results are\nrelevant in synthesis of reactive systems with both functional requirement\n(given as a qualitative objective) and performance requirement (given as a\nquantitative objective).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 18:59:10 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Henzinger", "Monika", ""], ["Svozil", "Alexander", ""]]}, {"id": "1706.06243", "submitter": "Luke Miles", "authors": "Cory Siler, Luke Harold Miles, Judy Goldsmith", "title": "The Complexity of Campaigning", "comments": "Will be presented at the 2017 Algorithmic Decision Theory Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In \"The Logic of Campaigning\", Dean and Parikh consider a candidate making\ncampaign statements to appeal to the voters. They model these statements as\nBoolean formulas over variables that represent stances on the issues, and study\noptimal candidate strategies under three proposed models of voter preferences\nbased on the assignments that satisfy these formulas. We prove that voter\nutility evaluation is computationally hard under these preference models (in\none case, #P-hard), along with certain problems related to candidate strategic\nreasoning. Our results raise questions about the desirable characteristics of a\nvoter preference model and to what extent a polynomial-time-evaluable function\ncan capture them.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 02:28:04 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 21:07:09 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Siler", "Cory", ""], ["Miles", "Luke Harold", ""], ["Goldsmith", "Judy", ""]]}, {"id": "1706.06246", "submitter": "Shuling  Wang", "authors": "Dimitar Guelev, Shuling Wang, Naijun Zhan", "title": "Compositional Hoare-style Reasoning about Hybrid CSP in the Duration\n  Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deductive methods for the verification of hybrid systems vary on the format\nof statements in correctness proofs. Building on the example of Hoare\ntriple-based reasoning, we have investigated several such methods for systems\ndescribed in Hybrid CSP, each based on a different assertion language, notation\nfor time, and notation for proofs, and each having its pros and cons with\nrespect to expressive power, compositionality and practical convenience. In\nthis paper we propose a new approach based on weakly monotonic time as the\nsemantics for interleaving, the Duration Calculus (DC) with infinite intervals\nand general fixpoints as the logic language, and a new meaning for Hoare-like\ntriples which unifies assertions and temporal conditions. We include a proof\nsystem for reasoning about the properties of systems written in the new form of\ntriples that is complete relative to validity in DC.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 02:44:22 GMT"}, {"version": "v2", "created": "Wed, 28 Jun 2017 02:13:04 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Guelev", "Dimitar", ""], ["Wang", "Shuling", ""], ["Zhan", "Naijun", ""]]}, {"id": "1706.06462", "submitter": "Kohei Suenaga", "authors": "Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga", "title": "Towards Proof Synthesis Guided by Neural Machine Translation for\n  Intuitionistic Propositional Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the recent evolution of deep neural networks (DNNs) in machine\nlearning, we explore their application to PL-related topics. This paper is the\nfirst step towards this goal; we propose a proof-synthesis method for the\nnegation-free propositional logic in which we use a DNN to obtain a guide of\nproof search. The idea is to view the proof-synthesis problem as a translation\nfrom a proposition to its proof. We train seq2seq, which is a popular network\nin neural machine translation, so that it generates a proof encoded as a\n$\\lambda$-term of a given proposition. We implement the whole framework and\nempirically observe that a generated proof term is close to a correct proof in\nterms of the tree edit distance of AST. This observation justifies using the\noutput from a trained seq2seq model as a guide for proof search.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 14:22:29 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Sekiyama", "Taro", ""], ["Imanishi", "Akifumi", ""], ["Suenaga", "Kohei", ""]]}, {"id": "1706.06486", "submitter": "\\v{L}ubo\\v{s} Koren\\v{c}iak", "authors": "Christel Baier and Clemens Dubslaff and \\v{L}ubo\\v{s} Koren\\v{c}iak\n  and Anton\\'in Ku\\v{c}era and Vojt\\v{e}ch \\v{R}eh\\'ak", "title": "Mean-Payoff Optimization in Continuous-Time Markov Chains with\n  Parametric Alarms", "comments": "This article is a full version of a paper accepted to the Conference\n  on Quantitative Evaluation of SysTems (QEST) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Continuous-time Markov chains with alarms (ACTMCs) allow for alarm events\nthat can be non-exponentially distributed. Within parametric ACTMCs, the\nparameters of alarm-event distributions are not given explicitly and can be\nsubject of parameter synthesis. An algorithm solving the $\\varepsilon$-optimal\nparameter synthesis problem for parametric ACTMCs with long-run average\noptimization objectives is presented. Our approach is based on reduction of the\nproblem to finding long-run average optimal strategies in semi-Markov decision\nprocesses (semi-MDPs) and sufficient discretization of parameter (i.e., action)\nspace. Since the set of actions in the discretized semi-MDP can be very large,\na straightforward approach based on explicit action-space construction fails to\nsolve even simple instances of the problem. The presented algorithm uses an\nenhanced policy iteration on symbolic representations of the action space. The\nsoundness of the algorithm is established for parametric ACTMCs with\nalarm-event distributions satisfying four mild assumptions that are shown to\nhold for uniform, Dirac and Weibull distributions in particular, but are\nsatisfied for many other distributions as well. An experimental implementation\nshows that the symbolic technique substantially improves the efficiency of the\nsynthesis algorithm and allows to solve instances of realistic size.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 14:39:14 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Baier", "Christel", ""], ["Dubslaff", "Clemens", ""], ["Koren\u010diak", "\u013dubo\u0161", ""], ["Ku\u010dera", "Anton\u00edn", ""], ["\u0158eh\u00e1k", "Vojt\u011bch", ""]]}, {"id": "1706.06663", "submitter": "J\\\"urgen Koslowski", "authors": "Sam Sanders", "title": "Grilliot's trick in Nonstandard Analysis", "comments": "21 pages", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (November\n  30, 2017) lmcs:4114", "doi": "10.23638/LMCS-13(4:23)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technique known as Grilliot's trick constitutes a template for explicitly\ndefining the Turing jump functional $(\\exists^2)$ in terms of a given\neffectively discontinuous type two functional. In this paper, we discuss the\nstandard extensionality trick: a technique similar to Grilliot's trick in\nNonstandard Analysis. This nonstandard trick proceeds by deriving from the\nexistence of certain nonstandard discontinuous functionals, the Transfer\nprinciple from Nonstandard analysis limited to $\\Pi_1^0$-formulas; from this\n(generally ineffective) implication, we obtain an effective implication\nexpressing the Turing jump functional in terms of a discontinuous functional\n(and no longer involving Nonstandard Analysis). The advantage of our\nnonstandard approach is that one obtains effective content without paying\nattention to effective content. We also discuss a new class of functionals\nwhich all seem to fall outside the established categories. These functionals\ndirectly derive from the Standard Part axiom of Nonstandard Analysis.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 21:01:47 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 20:38:26 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Sanders", "Sam", ""]]}, {"id": "1706.06845", "submitter": "Rasmus Kr{\\ae}mmer Rendsvig", "authors": "Dominik Klein and Rasmus K. Rendsvig", "title": "Turing Completeness of Finite, Epistemic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we show the class of finite, epistemic programs to be Turing\ncomplete. Epistemic programs is a widely used update mechanism used in\nepistemic logic, where it such are a special type of action models: One which\ndoes not contain postconditions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 11:56:38 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Klein", "Dominik", ""], ["Rendsvig", "Rasmus K.", ""]]}, {"id": "1706.06944", "submitter": "Jorge Martinez Gil Ph.D.", "authors": "Jorge Martinez-Gil, Alejandra Lorena Paoletti, G\\'abor R\\'acz, Attila\n  Sali, Klaus-Dieter Schewe", "title": "Accurate and Efficient Profile Matching in Knowledge Bases", "comments": "45 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A profile describes a set of properties, e.g. a set of skills a person may\nhave, a set of skills required for a particular job, or a set of abilities a\nfootball player may have with respect to a particular team strategy. Profile\nmatching aims to determine how well a given profile fits to a requested\nprofile. The approach taken in this article is grounded in a matching theory\nthat uses filters in lattices to represent profiles, and matching values in the\ninterval [0,1]: the higher the matching value the better is the fit. Such\nlattices can be derived from knowledge bases exploiting description logics to\nrepresent the knowledge about profiles. An interesting first question is, how\nhuman expertise concerning the matching can be exploited to obtain most\naccurate matchings. It will be shown that if a set of filters together with\nmatching values by some human expert is given, then under some mild\nplausibility assumptions a matching measure can be determined such that the\ncomputed matching values preserve the rankings given by the expert. A second\nquestion concerns the efficient querying of databases of profile instances. For\nmatching queries that result in a ranked list of profile instances matching a\ngiven one it will be shown how corresponding top-k queries can be evaluated on\ngrounds of pre-computed matching values, which in turn allows the maintenance\nof the knowledge base to be decoupled from the maintenance of profile\ninstances. In addition, it will be shown how the matching queries can be\nexploited for gap queries that determine how profile instances need to be\nextended in order to improve in the rankings. Finally, the theory of matching\nwill be extended beyond the filters, which lead to a matching theory that\nexploits fuzzy sets or probabilistic logic with maximum entropy semantics. It\nwill be shown that added fuzzy links can be captured by extending the\nunderlying lattice.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 14:54:54 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 15:53:05 GMT"}, {"version": "v3", "created": "Fri, 17 Nov 2017 19:36:51 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Martinez-Gil", "Jorge", ""], ["Paoletti", "Alejandra Lorena", ""], ["R\u00e1cz", "G\u00e1bor", ""], ["Sali", "Attila", ""], ["Schewe", "Klaus-Dieter", ""]]}, {"id": "1706.07351", "submitter": "Lalit Maganti", "authors": "Alessio Lomuscio, Lalit Maganti", "title": "An approach to reachability analysis for feed-forward ReLU neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reachability problem for systems implemented as feed-forward\nneural networks whose activation function is implemented via ReLU functions. We\ndraw a correspondence between establishing whether some arbitrary output can\never be outputed by a neural system and linear problems characterising a neural\nsystem of interest. We present a methodology to solve cases of practical\ninterest by means of a state-of-the-art linear programs solver. We evaluate the\ntechnique presented by discussing the experimental results obtained by\nanalysing reachability properties for a number of benchmarks in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 14:59:49 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Lomuscio", "Alessio", ""], ["Maganti", "Lalit", ""]]}, {"id": "1706.07448", "submitter": "Daniel Kasenberg", "authors": "Daniel Kasenberg and Matthias Scheutz", "title": "Norm Conflict Resolution in Stochastic Domains", "comments": "New version of paper - new evaluations, accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial agents will need to be aware of human moral and social norms, and\nable to use them in decision-making. In particular, artificial agents will need\na principled approach to managing conflicting norms, which are common in human\nsocial interactions. Existing logic-based approaches suffer from normative\nexplosion and are typically designed for deterministic environments;\nreward-based approaches lack principled ways of determining which normative\nalternatives exist in a given environment. We propose a hybrid approach, using\nLinear Temporal Logic (LTL) representations in Markov Decision Processes\n(MDPs), that manages norm conflicts in a systematic manner while accommodating\ndomain stochasticity. We provide a proof-of-concept implementation in a\nsimulated vacuum cleaning domain.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 18:15:48 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 14:29:37 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Kasenberg", "Daniel", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1706.07526", "submitter": "Bas Spitters", "authors": "Egbert Rijke, Michael Shulman, Bas Spitters", "title": "Modalities in homotopy type theory", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (January\n  8, 2020) lmcs:6015", "doi": "10.23638/LMCS-16(1:2)2020", "report-no": null, "categories": "math.CT cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Univalent homotopy type theory (HoTT) may be seen as a language for the\ncategory of $\\infty$-groupoids. It is being developed as a new foundation for\nmathematics and as an internal language for (elementary) higher toposes. We\ndevelop the theory of factorization systems, reflective subuniverses, and\nmodalities in homotopy type theory, including their construction using a\n\"localization\" higher inductive type. This produces in particular the\n($n$-connected, $n$-truncated) factorization system as well as internal\npresentations of subtoposes, through lex modalities. We also develop the\nsemantics of these constructions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 23:57:55 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 08:16:42 GMT"}, {"version": "v3", "created": "Mon, 31 Jul 2017 09:21:08 GMT"}, {"version": "v4", "created": "Fri, 22 Mar 2019 22:59:35 GMT"}, {"version": "v5", "created": "Mon, 11 Nov 2019 19:33:51 GMT"}, {"version": "v6", "created": "Tue, 7 Jan 2020 17:26:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Rijke", "Egbert", ""], ["Shulman", "Michael", ""], ["Spitters", "Bas", ""]]}, {"id": "1706.07946", "submitter": "Thom Fruehwirth", "authors": "Thom Fruehwirth", "title": "Justifications in Constraint Handling Rules for Logical Retraction in\n  Dynamic Algorithms", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/23", "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a straightforward source-to-source transformation that introduces\njustifications for user-defined constraints into the CHR programming language.\nThen a scheme of two rules suffices to allow for logical retraction (deletion,\nremoval) of constraints during computation. Without the need to recompute from\nscratch, these rules remove not only the constraint but also undo all\nconsequences of the rule applications that involved the constraint. We prove a\nconfluence result concerning the rule scheme and show its correctness. When\nalgorithms are written in CHR, constraints represent both data and operations.\nCHR is already incremental by nature, i.e. constraints can be added at runtime.\nLogical retraction adds decrementality. Hence any algorithm written in CHR with\njustifications will become fully dynamic. Operations can be undone and data can\nbe removed at any point in the computation without compromising the correctness\nof the result. We present two classical examples of dynamic algorithms, written\nin our prototype implementation of CHR with justifications that is available\nonline: maintaining the minimum of a changing set of numbers and shortest paths\nin a graph whose edges change.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 12:43:50 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 13:07:20 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Fruehwirth", "Thom", ""]]}, {"id": "1706.07997", "submitter": "Matthijs V\\'ak\\'ar", "authors": "Matthijs V\\'ak\\'ar", "title": "In Search of Effectful Dependent Types", "comments": "PhD thesis, Version submitted to Exam Schools", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world programming languages crucially depend on the availability of\ncomputational effects to achieve programming convenience and expressive power\nas well as program efficiency. Logical frameworks rely on predicates, or\ndependent types, to express detailed logical properties about entities.\nAccording to the Curry-Howard correspondence, programming languages and logical\nframeworks should be very closely related. However, a language that has both\ngood support for real programming and serious proving is still missing from the\nprogramming languages zoo. We believe this is due to a fundamental lack of\nunderstanding of how dependent types should interact with computational\neffects. In this thesis, we make a contribution towards such an understanding,\nwith a focus on semantic methods.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 20:37:29 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 14:29:49 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["V\u00e1k\u00e1r", "Matthijs", ""]]}, {"id": "1706.08270", "submitter": "Sadegh Esmaeil Zadeh Soudjani", "authors": "Sadegh Esmaeil Zadeh Soudjani and Rupak Majumdar and Tigran Nagapetyan", "title": "Multilevel Monte Carlo Method for Statistical Model Checking of Hybrid\n  Systems", "comments": "Accepted in the 14th International Conference on Quantitative\n  Evaluation of Systems (QEST), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study statistical model checking of continuous-time stochastic hybrid\nsystems. The challenge in applying statistical model checking to these systems\nis that one cannot simulate such systems exactly. We employ the multilevel\nMonte Carlo method (MLMC) and work on a sequence of discrete-time stochastic\nprocesses whose executions approximate and converge weakly to that of the\noriginal continuous-time stochastic hybrid system with respect to satisfaction\nof the property of interest. With focus on bounded-horizon reachability, we\nrecast the model checking problem as the computation of the distribution of the\nexit time, which is in turn formulated as the expectation of an indicator\nfunction. This latter computation involves estimating discontinuous\nfunctionals, which reduces the bound on the convergence rate of the Monte Carlo\nalgorithm. We propose a smoothing step with tunable precision and formally\nquantify the error of the MLMC approach in the mean-square sense, which is\ncomposed of smoothing error, bias, and variance. We formulate a general\nadaptive algorithm which balances these error terms. Finally, we describe an\napplication of our technique to verify a model of thermostatically controlled\nloads.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 08:11:09 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Soudjani", "Sadegh Esmaeil Zadeh", ""], ["Majumdar", "Rupak", ""], ["Nagapetyan", "Tigran", ""]]}, {"id": "1706.08325", "submitter": "Matti Karppa", "authors": "Tommi Junttila (1), Matti Karppa (1), Petteri Kaski (1), Jukka Kohonen\n  (1) ((1) Aalto University, Department of Computer Science)", "title": "An adaptive prefix-assignment technique for symmetry reduction", "comments": "Updated manuscript submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technique for symmetry reduction that adaptively\nassigns a prefix of variables in a system of constraints so that the generated\nprefix-assignments are pairwise nonisomorphic under the action of the symmetry\ngroup of the system. The technique is based on McKay's canonical extension\nframework [J.~Algorithms 26 (1998), no.~2, 306--324]. Among key features of the\ntechnique are (i) adaptability---the prefix sequence can be user-prescribed and\ntruncated for compatibility with the group of symmetries; (ii)\nparallelizability---prefix-assignments can be processed in parallel\nindependently of each other; (iii) versatility---the method is applicable\nwhenever the group of symmetries can be concisely represented as the\nautomorphism group of a vertex-colored graph; and (iv) implementability---the\nmethod can be implemented relying on a canonical labeling map for\nvertex-colored graphs as the only nontrivial subroutine. To demonstrate the\npractical applicability of our technique, we have prepared an experimental\nopen-source implementation of the technique and carry out a set of experiments\nthat demonstrate ability to reduce symmetry on hard instances. Furthermore, we\ndemonstrate that the implementation effectively parallelizes to compute\nclusters with multiple nodes via a message-passing interface.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 11:18:27 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 10:58:31 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Junttila", "Tommi", "", "Aalto University, Department of Computer Science"], ["Karppa", "Matti", "", "Aalto University, Department of Computer Science"], ["Kaski", "Petteri", "", "Aalto University, Department of Computer Science"], ["Kohonen", "Jukka", "", "Aalto University, Department of Computer Science"]]}, {"id": "1706.08329", "submitter": "Christoph Wernhard", "authors": "Christoph Wernhard", "title": "The Boolean Solution Problem from the Perspective of Predicate Logic -\n  Extended Version", "comments": null, "journal-ref": null, "doi": null, "report-no": "KRR 17-01", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding solution values for unknowns in Boolean equations was a principal\nreasoning mode in the Algebra of Logic of the 19th century. Schr\\\"oder\ninvestigated it as \"Aufl\\\"osungsproblem\" (\"solution problem\"). It is closely\nrelated to the modern notion of Boolean unification. Today it is commonly\npresented in an algebraic setting, but seems potentially useful also in\nknowledge representation based on predicate logic. We show that it can be\nmodeled on the basis of first-order logic extended by second-order\nquantification. A wealth of classical results transfers, foundations for\nalgorithms unfold, and connections with second-order quantifier elimination and\nCraig interpolation show up. Although for first-order inputs the set of\nsolutions is recursively enumerable, the development of constructive methods\nremains a challenge. We identify some cases that allow constructions, most of\nthem based on Craig interpolation, and show a method to take vocabulary\nrestrictions on solution components into account.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 11:30:06 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 09:19:48 GMT"}, {"version": "v3", "created": "Mon, 18 Dec 2017 22:29:44 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Wernhard", "Christoph", ""]]}, {"id": "1706.08401", "submitter": "Fei Yang", "authors": "Jos Baeten, Bas Luttik and Fei Yang", "title": "Sequential Composition in the Presence of Intermediate Termination", "comments": "26 pages, 7 figures, submitted to EXPRESS/SOS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard operational semantics of the sequential composition operator\ngives rise to unbounded branching and forgetfulness when transparent process\nexpressions are put in sequence. Due to transparency, the correspondence\nbetween context-free and pushdown processes fails modulo bisimilarity, and it\nis not clear how to specify an always terminating half counter. We propose a\nrevised operational semantics for the sequential composition operator in the\ncontext of intermediate termination. With the revised operational semantics, we\neliminate transparency. As a consequence, we establish a correspondence between\ncontext-free processes and pushdown processes. Moreover, we prove the reactive\nTuring powerfulness of TCP with iteration and nesting with the revised\noperational semantics for sequential composition.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 14:33:56 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Baeten", "Jos", ""], ["Luttik", "Bas", ""], ["Yang", "Fei", ""]]}, {"id": "1706.08481", "submitter": "Diego Pinheiro Fernandes", "authors": "Diego Pinheiro Fernandes", "title": "Translations: generalizing relative expressiveness between logics", "comments": "This paper is currently under revision in a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a strong demand for precise means for the comparison of logics in\nterms of expressiveness both from theoretical and from application areas. The\naim of this paper is to propose a sufficiently general and reasonable formal\ncriterion for expressiveness, so as to apply not only to model-theoretic\nlogics, but also to Tarskian and proof-theoretic logics. For model-theoretic\nlogics there is a standard framework of relative expressiveness, based on the\ncapacity of characterizing structures, and a straightforward formal criterion\nissuing from it. The problem is that it only allows the comparison of those\nlogics defined within the same class of models. The urge for a broader\nframework of expressiveness is not new. Nevertheless, the enterprise is complex\nand a reasonable model-theoretic formal criterion is still wanting. Recently\nthere appeared two criteria in this wider framework, one from Garc\\'ia-Matos &\nV\\\"a\\\"an\\\"anen and other from L. Kuijer. We argue that they are not adequate.\nTheir limitations are analyzed and we propose to move to an even broader\nframework lacking model-theoretic notions, which we call \"translational\nexpressiveness\". There is already a criterion in this later framework by\nMossakowski et al., however it turned out to be too lax. We propose some\nadequacy criteria for expressiveness and a formal criterion of translational\nexpressiveness complying with them is given.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:06:21 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Fernandes", "Diego Pinheiro", ""]]}, {"id": "1706.08504", "submitter": "Marco Voigt", "authors": "Marco Voigt", "title": "The Bernays-Sch\\\"onfinkel-Ramsey Fragment with Bounded Difference\n  Constraints over the Reals is Decidable", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order linear real arithmetic enriched with uninterpreted predicate\nsymbols yields an interesting modeling language. However, satisfiability of\nsuch formulas is undecidable, even if we restrict the uninterpreted predicate\nsymbols to arity one. In order to find decidable fragments of this language, it\nis necessary to restrict the expressiveness of the arithmetic part. One\npossible path is to confine arithmetic expressions to difference constraints of\nthe form $x - y \\mathrel{\\#} c$, where $\\#$ ranges over the standard relations\n$<, \\leq, =, \\neq, \\geq, >$ and $x,y$ are universally quantified. However, it\nis known that combining difference constraints with uninterpreted predicate\nsymbols yields an undecidable satisfiability problem again. In this paper, it\nis shown that satisfiability becomes decidable if we in addition bound the\nranges of universally quantified variables. As bounded intervals over the reals\nstill comprise infinitely many values, a trivial instantiation procedure is not\nsufficient to solve the problem.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:51:11 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Voigt", "Marco", ""]]}, {"id": "1706.08608", "submitter": "Normann Decker", "authors": "Normann Decker, Peter Habermehl, Martin Leucker, Arnaud Sangnier, and\n  Daniel Thoma", "title": "Model-checking Counting Temporal Logics on Flat Structures", "comments": "Extended version providing an additional appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study several extensions of linear-time and computation-tree temporal\nlogics with quantifiers that allow for counting how often certain properties\nhold. For most of these extensions, the model-checking problem is undecidable,\nbut we show that decidability can be recovered by considering flat Kripke\nstructures where each state belongs to at most one simple loop. Most decision\nprocedures are based on results on (flat) counter systems where counters are\nused to implement the evaluation of counting operators.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 21:32:16 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Decker", "Normann", ""], ["Habermehl", "Peter", ""], ["Leucker", "Martin", ""], ["Sangnier", "Arnaud", ""], ["Thoma", "Daniel", ""]]}, {"id": "1706.08689", "submitter": "Joao Marcos", "authors": "Carlos Caleiro, S\\'ergio Marcelino, Jo\\~ao Marcos", "title": "Merging fragments of classical logic", "comments": "submitted to FroCoS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the possibility of extending the non-functionally complete\nlogic of a collection of Boolean connectives by the addition of further Boolean\nconnectives that make the resulting set of connectives functionally complete.\nMore precisely, we will be interested in checking whether an axiomatization for\nClassical Propositional Logic may be produced by merging Hilbert-style calculi\nfor two disjoint incomplete fragments of it. We will prove that the answer to\nthat problem is a negative one, unless one of the components includes only\ntop-like connectives.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 06:53:08 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Caleiro", "Carlos", ""], ["Marcelino", "S\u00e9rgio", ""], ["Marcos", "Jo\u00e3o", ""]]}, {"id": "1706.08691", "submitter": "Ale\\v{s} Bizjak", "authors": "Eryk Kopczynski and Tony Tan", "title": "A note on first-order spectra with binary relations", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (April 25,\n  2018) lmcs:4465", "doi": "10.23638/LMCS-14(2:4)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The spectrum of a first-order sentence is the set of the cardinalities of its\nfinite models. In this paper, we consider the spectra of sentences over binary\nrelations that use at least three variables. We show that for every such\nsentence $\\Phi$, there is a sentence $\\Phi'$ that uses the same number of\nvariables, but only one symmetric binary relation, such that its spectrum is\nlinearly proportional to the spectrum of $\\Phi$. Moreover, the models of\n$\\Phi'$ are all bipartite graphs. As a corollary, we obtain that to settle\nAsser's conjecture, i.e., whether the class of spectra is closed under\ncomplement, it is sufficient to consider only sentences using only three\nvariables whose models are restricted to undirected bipartite graphs.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 07:07:35 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 08:19:28 GMT"}, {"version": "v3", "created": "Mon, 5 Mar 2018 06:37:13 GMT"}, {"version": "v4", "created": "Fri, 13 Apr 2018 09:27:42 GMT"}, {"version": "v5", "created": "Tue, 24 Apr 2018 07:46:17 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Kopczynski", "Eryk", ""], ["Tan", "Tony", ""]]}, {"id": "1706.09169", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Ugo Dal Lago", "title": "Automating Sized Type Inference for Complexity Analysis (Technical\n  Report)", "comments": "Technical report of http://dx.doi.org/10.1145/3110287", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduces a new methodology for the complexity analysis of\nhigher-order functional programs, which is based on three ingredients: a\npowerful type system for size analysis and a sound type inference procedure for\nit, a ticking monadic transformation, and constraint solving. Noticeably, the\npresented methodology can be fully automated, and is able to analyse a series\nof examples which cannot be handled by most competitor methodologies. This is\npossible due to the choice of adopting an abstract index language and index\npolymorphism at higher ranks. A prototype implementation is available.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 08:44:10 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Avanzini", "Martin", ""], ["Lago", "Ugo Dal", ""]]}, {"id": "1706.09229", "submitter": "Zakaria Chihani", "authors": "Zakaria Chihani, Fran\\c{c}ois Bobot, S\\'ebastien Bardin", "title": "CDCL-inspired Word-level Learning for Bit-vector Constraint Solving", "comments": "15 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of quantifier-free bit-vectors (QF_BV) is of paramount importance\nin software verification. The standard approach for satisfiability checking\nreduces the bit-vector problem to a Boolean problem, leveraging the powerful\nSAT solving techniques and their conflict-driven clause learning (CDCL)\nmechanisms. Yet, this bit-level approach loses the structure of the initial\nbit-vector problem. We propose a conflict-driven, word-level, combinable\nconstraints learning for the theory of quantifier-free bit-vectors. This work\npaves the way to truly word-level decision procedures for bit-vectors, taking\nfull advantage of word-level propagations recently designed in CP and SMT\ncommunities.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 11:55:45 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Chihani", "Zakaria", ""], ["Bobot", "Fran\u00e7ois", ""], ["Bardin", "S\u00e9bastien", ""]]}, {"id": "1706.09236", "submitter": "Thomas Sturm", "authors": "Pascal Fontaine, Mizuhito Ogawa, Thomas Sturm, Xuan Tung Vu", "title": "Subtropical Satisfiability", "comments": "Accepted into Proc. FROCOS 2017", "journal-ref": "Proc. FROCOS 2017, LNCS 10483, pp.189-206, Springer 2017", "doi": "10.1007/978-3-319-66167-4_11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifier-free nonlinear arithmetic (QF_NRA) appears in many applications of\nsatisfiability modulo theories solving (SMT). Accordingly, efficient reasoning\nfor corresponding constraints in SMT theory solvers is highly relevant. We\npropose a new incomplete but efficient and terminating method to identify\nsatisfiable instances. The method is derived from the subtropical method\nrecently introduced in the context of symbolic computation for computing real\nzeros of single very large multivariate polynomials. Our method takes as input\nconjunctions of strict polynomial inequalities, which represent more than 40%\nof the QF_NRA section of the SMT-LIB library of benchmarks. The method takes an\nabstraction of polynomials as exponent vectors over the natural numbers tagged\nwith the signs of the corresponding coefficients. It then uses, in turn, SMT to\nsolve linear problems over the reals to heuristically find suitable points that\ntranslate back to satisfying points for the original problem. Systematic\nexperiments on the SMT-LIB demonstrate that our method is not a sufficiently\nstrong decision procedure by itself but a valuable heuristic to use within a\nportfolio of techniques.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 12:12:26 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Fontaine", "Pascal", ""], ["Ogawa", "Mizuhito", ""], ["Sturm", "Thomas", ""], ["Vu", "Xuan Tung", ""]]}, {"id": "1706.09334", "submitter": "Christoph Rauch", "authors": "L. Nenzi, L. Bortolussi, V. Ciancia, M. Loreti, M. Massink", "title": "Qualitative and Quantitative Monitoring of Spatio-Temporal Properties\n  with SSTL", "comments": "36 pages with 13 figures", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4, Modal and\n  temporal logics (October 23, 2018) lmcs:4913", "doi": "10.23638/LMCS-14(4:2)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In spatially located, large scale systems, time and space dynamics interact\nand drives the behaviour. Examples of such systems can be found in many smart\ncity applications and Cyber-Physical Systems. In this paper we present the\nSignal Spatio-Temporal Logic (SSTL), a modal logic that can be used to specify\nspatio-temporal properties of linear time and discrete space models. The logic\nis equipped with a Boolean and a quantitative semantics for which efficient\nmonitoring algorithms have been developed. As such, it is suitable for\nreal-time verification of both white box and black box complex systems. These\nalgorithms can also be combined with stochastic model checking routines. SSTL\ncombines the until temporal modality with two spatial modalities, one\nexpressing that something is true somewhere nearby and the other capturing the\nnotion of being surrounded by a region that satisfies a given spatio-temporal\nproperty. The monitoring algorithms are implemented in an open source Java\ntool. We illustrate the use of SSTL analysing the formation of patterns in a\nTuring Reaction-Diffusion system and spatio-temporal aspects of a large\nbike-sharing system.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 15:46:23 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 21:31:02 GMT"}, {"version": "v3", "created": "Fri, 3 Aug 2018 11:19:48 GMT"}, {"version": "v4", "created": "Mon, 22 Oct 2018 10:30:11 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Nenzi", "L.", ""], ["Bortolussi", "L.", ""], ["Ciancia", "V.", ""], ["Loreti", "M.", ""], ["Massink", "M.", ""]]}, {"id": "1706.09370", "submitter": "Johannes Klaus Fichte", "authors": "Johannes K. Fichte, Markus Hecher, Michael Morak, Stefan Woltran", "title": "DynASP2.5: Dynamic Programming on Tree Decompositions in Action", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vibrant theoretical research area are efficient exact parameterized\nalgorithms. Very recent solving competitions such as the PACE challenge show\nthat there is also increasing practical interest in the parameterized\nalgorithms community. An important research question is whether dedicated\nparameterized exact algorithms exhibit certain practical relevance and one can\neven beat well-established problem solvers. We consider the logic-based\ndeclarative modeling language and problem solving framework Answer Set\nProgramming (ASP). State-of-the-art ASP solvers rely considerably on Sat-based\nalgorithms. An ASP solver (DynASP2), which is based on a classical dynamic\nprogramming on tree decompositions, has been published very recently.\nUnfortunately, DynASP2 can outperform modern ASP solvers on programs of small\ntreewidth only if the question of interest is to count the number of solutions.\nIn this paper, we describe underlying concepts of our new implementation\n(DynASP2.5) that shows competitive behavior to state-of-the-art ASP solvers\neven for finding just one solution when solving problems as the Steiner tree\nproblem that have been modeled in ASP on graphs with low treewidth. Our\nimplementation is based on a novel approach that we call multi-pass dynamic\nprogramming (M-DPSINC).\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 17:20:24 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Hecher", "Markus", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "1706.09393", "submitter": "Markus Hecher", "authors": "Johannes K. Fichte, Markus Hecher, Irina Schindler", "title": "Default Logic and Bounded Treewidth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study Reiter's propositional default logic when the\ntreewidth of a certain graph representation (semi-primal graph) of the input\ntheory is bounded. We establish a dynamic programming algorithm on tree\ndecompositions that decides whether a theory has a consistent stable extension\n(Ext). Our algorithm can even be used to enumerate all generating defaults\n(ExtEnum) that lead to stable extensions.\n  We show that our algorithm decides Ext in linear time in the input theory and\ntriple exponential time in the treewidth (so-called fixed-parameter linear\nalgorithm).\n  Further, our algorithm solves ExtEnum with a pre-computation step that is\nlinear in the input theory and triple exponential in the treewidth followed by\na linear delay to output solutions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 17:57:02 GMT"}, {"version": "v2", "created": "Sat, 30 Dec 2017 11:03:22 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Hecher", "Markus", ""], ["Schindler", "Irina", ""]]}, {"id": "1706.09696", "submitter": "Simone Santini", "authors": "Jaun Casanova, Simone Santini", "title": "On the relation between representations and computability", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental results in computability is the existence of\nwell-defined functions that cannot be computed. In this paper we study the\neffects of data representation on computability; we show that, while for each\npossible way of representing data there exist incomputable functions, the\ncomputability of a specific abstract function is never an absolute property,\nbut depends on the representation used for the function domain. We examine the\nscope of this dependency and provide mathematical criteria to favour some\nrepresentations over others. As we shall show, there are strong reasons to\nsuggest that computational enumerability should be an additional axiom for\ncomputation models. We analyze the link between the techniques and effects of\nrepresentation changes and those of oracle machines, showing an important\nconnection between their hierarchies. Finally, these notions enable us to gain\na new insight on the Church-Turing thesis: its interpretation as the underlying\nalgebraic structure to which computation is invariant.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 11:47:21 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Casanova", "Jaun", ""], ["Santini", "Simone", ""]]}, {"id": "1706.09877", "submitter": "Quanlong Wang", "authors": "Kang Feng Ng, Quanlong Wang", "title": "A universal completion of the ZX-calculus", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a universal completion of the ZX-calculus for the\nwhole of pure qubit quantum mechanics. This proof is based on the completeness\nof another graphical language: the ZW-calculus, with direct translations\nbetween these two graphical systems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 17:41:56 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Ng", "Kang Feng", ""], ["Wang", "Quanlong", ""]]}, {"id": "1706.09886", "submitter": "Dominik Wojtczak", "authors": "Mahmoud A. A. Mousa, Sven Schewe, and Dominik Wojtczak", "title": "Optimal Control for Multi-Mode Systems with Discrete Costs", "comments": "extended version of a FORMATS 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies optimal time-bounded control in multi-mode systems with\ndiscrete costs. Multi-mode systems are an important subclass of linear hybrid\nsystems, in which there are no guards on transitions and all invariants are\nglobal. Each state has a continuous cost attached to it, which is linear in the\nsojourn time, while a discrete cost is attached to each transition taken. We\nshow that an optimal control for this model can be computed in NEXPTIME and\napproximated in PSPACE. We also show that the one-dimensional case is simpler:\nalthough the problem is NP-complete (and in LOGSPACE for an infinite time\nhorizon), we develop an FPTAS for finding an approximate solution.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 17:57:19 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Mousa", "Mahmoud A. A.", ""], ["Schewe", "Sven", ""], ["Wojtczak", "Dominik", ""]]}, {"id": "1706.10049", "submitter": "Pengfei Yang", "authors": "Pengfei Yang, David N. Jansen, Lijun Zhang", "title": "Distribution-based bisimulation for labelled Markov processes", "comments": "Accepted by FORMATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a (sub)distribution-based bisimulation for labelled\nMarkov processes and compare it with earlier definitions of state and event\nbisimulation, which both only compare states. In contrast to those state-based\nbisimulations, our distribution bisimulation is weaker, but corresponds more\nclosely to linear properties. We construct a logic and a metric to describe our\ndistribution bisimulation and discuss linearity, continuity and compositional\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 08:01:58 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Yang", "Pengfei", ""], ["Jansen", "David N.", ""], ["Zhang", "Lijun", ""]]}, {"id": "1706.10078", "submitter": "Yi Liu", "authors": "Yi Liu, Xingtong Liu, Lei Zhang, Jian Wang and Chaojing Tang", "title": "Novel Logical Method for Security Analysis of Electronic Payment\n  Protocols", "comments": "16 pages with 1 figures", "journal-ref": null, "doi": "10.1587/transinf.2018EDP7108", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic payment protocols play a vital role in electronic commerce\nsecurity, which is essential for secure operation of electronic commerce\nactivities. Formal method is an effective way to verify the security of\nprotocols. But current formal method lacks the description and analysis of\ntimeliness in electronic payment protocols. In order to improve analysis\nability, a novel approach to analyze security properties such as\naccountability, fairness and timeliness in electronic payment protocols is\nproposed in this paper. This approach extends an existing logical method by\nadding a concise time expression and analysis method. It enables to describe\nthe event time, and extends the time characteristics of logical inference\nrules. We analyzed the Netbill protocol with the new approach and found that\nthe fairness of the protocol is not satisfied, due to timeliness problem. The\nresult illustrates the new approach is able to analyze the key properties of\nelectronic payment protocols. Furthermore, the new approach can be introduced\nto analyze other time properties of cryptographic protocols.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 09:29:28 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Liu", "Yi", ""], ["Liu", "Xingtong", ""], ["Zhang", "Lei", ""], ["Wang", "Jian", ""], ["Tang", "Chaojing", ""]]}, {"id": "1706.10102", "submitter": "Peter Baumgartner", "authors": "Peter Baumgartner, Sylvie Thi\\'ebaux, Felipe Trevizan", "title": "Tableaux for Policy Synthesis for MDPs with PCTL* Constraints", "comments": "This is a long version of a conference paper published at TABLEAUX\n  2017. It contains proofs of the main results and fixes a bug. See the\n  footnote on page 1 for details", "journal-ref": "Proceedings of TABLEAUX 2017, pp. 175--192, Springer 2017", "doi": "10.1007/978-3-319-66902-1_11", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDPs) are the standard formalism for modelling\nsequential decision making in stochastic environments. Policy synthesis\naddresses the problem of how to control or limit the decisions an agent makes\nso that a given specification is met. In this paper we consider PCTL*, the\nprobabilistic counterpart of CTL*, as the specification language. Because in\ngeneral the policy synthesis problem for PCTL* is undecidable, we restrict to\npolicies whose execution history memory is finitely bounded a priori.\n  Surprisingly, no algorithm for policy synthesis for this natural and\nexpressive framework has been developed so far. We close this gap and describe\na tableau-based algorithm that, given an MDP and a PCTL* specification, derives\nin a non-deterministic way a system of (possibly nonlinear) equalities and\ninequalities. The solutions of this system, if any, describe the desired\n(stochastic) policies.\n  Our main result in this paper is the correctness of our method, i.e.,\nsoundness, completeness and termination.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 10:13:26 GMT"}, {"version": "v2", "created": "Sat, 22 Jul 2017 14:02:17 GMT"}, {"version": "v3", "created": "Fri, 6 Oct 2017 01:04:47 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Baumgartner", "Peter", ""], ["Thi\u00e9baux", "Sylvie", ""], ["Trevizan", "Felipe", ""]]}, {"id": "1706.10269", "submitter": "Ricardo David Katz", "authors": "Xavier Allamigeon and Ricardo D. Katz", "title": "A formalization of convex polyhedra based on the simplex method", "comments": "18 pages, 2 figures, extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formalization of convex polyhedra in the proof assistant Coq.\nThe cornerstone of our work is a complete implementation of the simplex method,\ntogether with the proof of its correctness and termination. This allows us to\ndefine the basic predicates over polyhedra in an effective way (i.e., as\nprograms), and relate them with the corresponding usual logical counterparts.\nTo this end, we make an extensive use of the Boolean reflection methodology.\nThe benefit of this approach is that we can easily derive the proof of several\nfundamental results on polyhedra, such as Farkas' Lemma, the duality theorem of\nlinear programming, and Minkowski's Theorem.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 16:50:25 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 18:25:41 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Allamigeon", "Xavier", ""], ["Katz", "Ricardo D.", ""]]}]