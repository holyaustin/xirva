[{"id": "0909.0171", "submitter": "Jacob Vosmaer", "authors": "Mai Gehrke and Jacob Vosmaer", "title": "Canonical extension and canonicity via DCPO presentations", "comments": "17 pages. Definition 5 was revised slightly, without changing any of\n  the results", "journal-ref": "Theoretical Computer Science 412(25), pp. 2714-2723, 2011", "doi": "10.1016/j.tcs.2010.12.032", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The canonical extension of a lattice is in an essential way a two-sided\ncompletion. Domain theory, on the contrary, is primarily concerned with\none-sided completeness. In this paper, we show two things. Firstly, that the\ncanonical extension of a lattice can be given an asymmetric description in two\nstages: a free co-directed meet completion, followed by a completion by\n\\emph{selected} directed joins. Secondly, we show that the general techniques\nfor dcpo presentations of dcpo algebras used in the second stage of the\nconstruction immediately give us the well-known canonicity result for bounded\nlattices with operators.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2009 12:49:20 GMT"}, {"version": "v2", "created": "Tue, 14 Sep 2010 14:17:38 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Gehrke", "Mai", ""], ["Vosmaer", "Jacob", ""]]}, {"id": "0909.0393", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM), Pierre Simonnet (SPE)", "title": "On Recognizable Tree Languages Beyond the Borel Hierarchy", "comments": "To appear in Fundamenta Informaticae", "journal-ref": "Fundamenta Informaticae 95, 2-3 (2009) 287-303", "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the topological complexity of non Borel recognizable tree\nlanguages with regard to the difference hierarchy of analytic sets. We show\nthat, for each integer $n \\geq 1$, there is a $D_{\\omega^n}({\\bf\n\\Sigma}^1_1)$-complete tree language L_n accepted by a (non deterministic)\nMuller tree automaton. On the other hand, we prove that a tree language\naccepted by an unambiguous B\\\"uchi tree automaton must be Borel. Then we\nconsider the game tree languages $W_{(i,k)}$, for Mostowski-Rabin indices $(i,\nk)$. We prove that the $D_{\\omega^n}({\\bf \\Sigma}^1_1)$-complete tree languages\nL_n are Wadge reducible to the game tree language $W_{(i, k)}$ for $k-i \\geq\n2$. In particular these languages $W_{(i, k)}$ are not in any class\n$D_{\\alpha}({\\bf \\Sigma}^1_1)$ for $\\alpha < \\omega^\\omega$.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2009 11:37:15 GMT"}], "update_date": "2009-11-05", "authors_parsed": [["Finkel", "Olivier", "", "ELM"], ["Simonnet", "Pierre", "", "SPE"]]}, {"id": "0909.0736", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM), Dominique Lecomte (IMJ)", "title": "Decision Problems For Turing Machines", "comments": "To appear in Information Processing Letters", "journal-ref": "Information Processing Letters 109, 23-24 (2009) 1223-1226", "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer two questions posed by Castro and Cucker, giving the exact\ncomplexities of two decision problems about cardinalities of omega-languages of\nTuring machines. Firstly, it is $D_2(\\Sigma_1^1)$-complete to determine whether\nthe omega-language of a given Turing machine is countably infinite, where\n$D_2(\\Sigma_1^1)$ is the class of 2-differences of $\\Sigma_1^1$-sets. Secondly,\nit is $\\Sigma_1^1$-complete to determine whether the omega-language of a given\nTuring machine is uncountable.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2009 19:19:48 GMT"}], "update_date": "2009-11-05", "authors_parsed": [["Finkel", "Olivier", "", "ELM"], ["Lecomte", "Dominique", "", "IMJ"]]}, {"id": "0909.0884", "submitter": "Carlo Alberto Furia", "authors": "Carlo A. Furia and Bertrand Meyer", "title": "Inferring Loop Invariants using Postconditions", "comments": "Slightly revised version", "journal-ref": "Fields of Logic and Computation: Essays Dedicated to Yuri Gurevich\n  on the Occasion of His 70th Birthday. Lecture Notes in Computer Science,\n  6300:277--300, Springer, August 2010", "doi": "10.1007/978-3-642-15025-8_15", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the obstacles in automatic program proving is to obtain suitable loop\ninvariants.\n  The invariant of a loop is a weakened form of its postcondition (the loop's\ngoal, also known as its contract); the present work takes advantage of this\nobservation by using the postcondition as the basis for invariant inference,\nusing various heuristics such as \"uncoupling\" which prove useful in many\nimportant algorithms.\n  Thanks to these heuristics, the technique is able to infer invariants for a\nlarge variety of loop examples.\n  We present the theory behind the technique, its implementation (freely\navailable for download and currently relying on Microsoft Research's Boogie\ntool), and the results obtained.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2009 16:13:47 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2010 13:38:24 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Furia", "Carlo A.", ""], ["Meyer", "Bertrand", ""]]}, {"id": "0909.1102", "submitter": "Stefan G\\\"oller", "authors": "Stefan G\\\"oller, Markus Lohrey", "title": "Branching-time model checking of one-counter processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-counter processes (OCPs) are pushdown processes which operate only on a\nunary stack alphabet. We study the computational complexity of model checking\ncomputation tree logic (CTL) over OCPs. A PSPACE upper bound is inherited from\nthe modal mu-calculus for this problem. First, we analyze the periodic\nbehaviour of CTL over OCPs and derive a model checking algorithm whose running\ntime is exponential only in the number of control locations and a syntactic\nnotion of the formula that we call leftward until depth. Thus, model checking\nfixed OCPs against CTL formulas with a fixed leftward until depth is in P. This\ngeneralizes a result of the first author, Mayr, and To for the expression\ncomplexity of CTL's fragment EF. Second, we prove that already over some fixed\nOCP, CTL model checking is PSPACE-hard. Third, we show that there already\nexists a fixed CTL formula for which model checking of OCPs is PSPACE-hard. To\nobtain the latter result, we employ two results from complexity theory: (i)\nConverting a natural number in Chinese remainder presentation into binary\npresentation is in logspace-uniform NC^1 and (ii) PSPACE is AC^0-serializable.\nWe demonstrate that our approach can be used to obtain further results. We show\nthat model-checking CTL's fragment EF over OCPs is hard for P^NP, thus\nestablishing a matching lower bound and answering an open question of the first\nauthor, Mayr, and To. We moreover show that the following problem is hard for\nPSPACE: Given a one-counter Markov decision process, a set of target states\nwith counter value zero each, and an initial state, to decide whether the\nprobability that the initial state will eventually reach one of the target\nstates is arbitrarily close to 1. This improves a previously known lower bound\nfor every level of the Boolean hierarchy by Brazdil et al.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2009 19:12:25 GMT"}], "update_date": "2009-09-08", "authors_parsed": [["G\u00f6ller", "Stefan", ""], ["Lohrey", "Markus", ""]]}, {"id": "0909.1198", "submitter": "Dag Normann", "authors": "Dag Normann", "title": "A rich hierarchy of functionals of finite types", "comments": "21 pages", "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 3 (September\n  24, 2009) lmcs:954", "doi": "10.2168/LMCS-5(3:11)2009", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are considering typed hierarchies of total, continuous functionals using\ncomplete, separable metric spaces at the base types. We pay special attention\nto the so called Urysohn space constructed by P. Urysohn. One of the properties\nof the Urysohn space is that every other separable metric space can be\nisometrically embedded into it. We discuss why the Urysohn space may be\nconsidered as the universal model of possibly infinitary outputs of algorithms.\nThe main result is that all our typed hierarchies may be topologically\nembedded, type by type, into the corresponding hierarchy over the Urysohn\nspace. As a preparation for this, we prove an effective density theorem that is\nalso of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2009 10:16:20 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2009 10:02:03 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Normann", "Dag", ""]]}, {"id": "0909.1645", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee, Laurent Doyen and Thomas A. Henzinger", "title": "Qualitative Analysis of Partially-observable Markov Decision Processes", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-15155-2_24", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study observation-based strategies for partially-observable Markov\ndecision processes (POMDPs) with omega-regular objectives. An observation-based\nstrategy relies on partial information about the history of a play, namely, on\nthe past sequence of observations. We consider the qualitative analysis\nproblem: given a POMDP with an omega-regular objective, whether there is an\nobservation-based strategy to achieve the objective with probability~1\n(almost-sure winning), or with positive probability (positive winning). Our\nmain results are twofold. First, we present a complete picture of the\ncomputational complexity of the qualitative analysis of POMDP s with parity\nobjectives (a canonical form to express omega-regular objectives) and its\nsubclasses. Our contribution consists in establishing several upper and lower\nbounds that were not known in literature. Second, we present optimal bounds\n(matching upper and lower bounds) on the memory required by pure and randomized\nobservation-based strategies for the qualitative analysis of POMDP s with\nparity objectives and its subclasses.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2009 07:47:28 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2010 17:08:14 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2010 19:19:02 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Doyen", "Laurent", ""], ["Henzinger", "Thomas A.", ""]]}, {"id": "0909.1647", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee, Laurent Doyen and Thomas A. Henzinger", "title": "Probabilistic Weighted Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nondeterministic weighted automata are finite automata with numerical weights\non transitions. They define quantitative languages L that assign to each word w\na real number L(w). The value of an infinite word w is computed as the maximal\nvalue of all runs over w, and the value of a run as the maximum, limsup,\nliminf, limit average, or discounted sum of the transition weights. We\nintroduce probabilistic weighted automata, in which the transitions are chosen\nin a randomized (rather than nondeterministic) fashion. Under almost-sure\nsemantics (resp. positive semantics), the value of a word w is the largest real\nv such that the runs over w have value at least v with probability 1 (resp.\npositive probability).\n  We study the classical questions of automata theory for probabilistic\nweighted automata: emptiness and universality, expressiveness, and closure\nunder various operations on languages. For quantitative languages, emptiness\nand universality are defined as whether the value of some (resp. every) word\nexceeds a given threshold. We prove some of these questions to be decidable,\nand others undecidable. Regarding expressive power, we show that probabilities\nallow us to define a wide variety of new classes of quantitative languages,\nexcept for discounted-sum automata, where probabilistic choice is no more\nexpressive than nondeterminism. Finally, we give an almost complete picture of\nthe closure of various classes of probabilistic weighted automata for the\nfollowing pointwise operations on quantitative languages: max, min, sum, and\nnumerical complement.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2009 08:12:39 GMT"}], "update_date": "2009-09-10", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Doyen", "Laurent", ""], ["Henzinger", "Thomas A.", ""]]}, {"id": "0909.2088", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Arithmetical meadows", "comments": "14 pages; sections 4 and 5 permuted", "journal-ref": null, "doi": null, "report-no": "PRG0909", "categories": "math.RA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An inversive meadow is a commutative ring with identity equipped with a\nmultiplicative inverse operation made total by choosing 0 as its value at 0.\nPreviously, inversive meadows were shortly called meadows. A divisive meadow is\nan inversive meadows with the multiplicative inverse operation replaced by a\ndivision operation. In the spirit of Peacock's arithmetical algebra, we\nintroduce variants of inversive and divisive meadows without an additive\nidentity element and an additive inverse operation. We give equational\naxiomatizations of several classes of such variants of inversive and divisive\nmeadows as well as of several instances of them.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2009 05:44:54 GMT"}, {"version": "v2", "created": "Tue, 2 Nov 2010 16:09:04 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "0909.2309", "submitter": "Jun Tanaka", "authors": "Jun Tanaka", "title": "Logic with Verbs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The aim of this paper is to introduce a logic in which nouns and verbs are\nhandled together as a deductive reasoning, and also to observe the relationship\nbetween nouns and verbs as well as between logics and conversations.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2009 07:49:36 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2009 00:49:38 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2009 10:54:13 GMT"}], "update_date": "2010-06-01", "authors_parsed": [["Tanaka", "Jun", ""]]}, {"id": "0909.3596", "submitter": "Chris Preston", "authors": "Chris Preston", "title": "Specifying Data Objects with Initial Algebras", "comments": "120 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a systematic approach to specifying data objects with the\nhelp of initial algebras. The primary aim is to describe the set-up to be found\nin modern functional programming languages such as Haskell and ML, although it\ncan also be applied to more general situations.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2009 16:59:18 GMT"}], "update_date": "2009-09-22", "authors_parsed": [["Preston", "Chris", ""]]}, {"id": "0909.4013", "submitter": "David Monniaux", "authors": "David Monniaux (VERIMAG - IMAG)", "title": "Automatic modular abstractions for template numerical constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for automatically generating abstract transformers for\nstatic analysis by abstract interpretation. The method focuses on linear\nconstraints on programs operating on rational, real or floating-point variables\nand containing linear assignments and tests. In addition to loop-free code, the\nsame method also applies for obtaining least fixed points as functions of the\nprecondition, which permits the analysis of loops and recursive functions. Our\nalgorithms are based on new quantifier elimination and symbolic manipulation\ntechniques. Given the specification of an abstract domain, and a program block,\nour method automatically outputs an implementation of the corresponding\nabstract transformer. It is thus a form of program transformation. The\nmotivation of our work is data-flow synchronous programming languages, used for\nbuilding control-command embedded systems, but it also applies to imperative\nand functional programming.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2009 14:49:17 GMT"}, {"version": "v2", "created": "Mon, 31 May 2010 06:43:29 GMT"}], "update_date": "2010-07-28", "authors_parsed": [["Monniaux", "David", "", "VERIMAG - IMAG"]]}, {"id": "0909.4637", "submitter": "Norbert Schirmer", "authors": "Ernie Cohen and Norbert Schirmer", "title": "A Better Reduction Theorem for Store Buffers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When verifying a concurrent program, it is usual to assume that memory is\nsequentially consistent. However, most modern multiprocessors depend on store\nbuffering for efficiency, and provide native sequential consistency only at a\nsubstantial performance penalty. To regain sequential consistency, a programmer\nhas to follow an appropriate programming discipline. However, na\\\"ive\ndisciplines, such as protecting all shared accesses with locks, are not\nflexible enough for building high-performance multiprocessor software.\n  We present a new discipline for concurrent programming under TSO (total store\norder, with store buffer forwarding). It does not depend on concurrency\nprimitives, such as locks. Instead, threads use ghost operations to acquire and\nrelease ownership of memory addresses. A thread can write to an address only if\nno other thread owns it, and can read from an address only if it owns it or it\nis shared and the thread has flushed its store buffer since it last wrote to an\naddress it did not own. This discipline covers both coarse-grained concurrency\n(where data is protected by locks) as well as fine-grained concurrency (where\natomic operations race to memory).\n  We formalize this discipline in Isabelle/HOL, and prove that if every\nexecution of a program in a system without store buffers follows the\ndiscipline, then every execution of the program with store buffers is\nsequentially consistent. Thus, we can show sequential consistency under TSO by\nordinary assertional reasoning about the program, without having to consider\nstore buffers at all.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2009 08:45:19 GMT"}], "update_date": "2009-09-28", "authors_parsed": [["Cohen", "Ernie", ""], ["Schirmer", "Norbert", ""]]}, {"id": "0909.5038", "submitter": "EPTCS", "authors": "Olga Tveretina (Karlsruhe University), Carsten Sinz (Karlsruhe\n  University), Hans Zantema (Technical University of Eindhoven, Radboud\n  University of Nijmegen)", "title": "An Exponential Lower Bound on OBDD Refutations for Pigeonhole Formulas", "comments": null, "journal-ref": "EPTCS 4, 2009, pp. 13-21", "doi": "10.4204/EPTCS.4.2", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Haken proved that every resolution refutation of the pigeonhole formula has\nat least exponential size. Groote and Zantema proved that a particular OBDD\ncomputation of the pigeonhole formula has an exponential size. Here we show\nthat any arbitrary OBDD refutation of the pigeonhole formula has an exponential\nsize, too: we prove that the size of one of the intermediate OBDDs is at least\n$\\Omega(1.025^n)$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2009 08:55:33 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Tveretina", "Olga", "", "Karlsruhe University"], ["Sinz", "Carsten", "", "Karlsruhe\n  University"], ["Zantema", "Hans", "", "Technical University of Eindhoven, Radboud\n  University of Nijmegen"]]}, {"id": "0909.5045", "submitter": "Emmanuel Polonowski", "authors": "Emmanuel Polonowski", "title": "Deriving SN from PSN: a general proof technique", "comments": null, "journal-ref": "TR-LACL (2006) 1-50", "doi": null, "report-no": "TR-LACL-2006-5", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of explicit substitutions there is two termination\nproperties: preservation of strong normalization (PSN), and strong\nnormalization (SN). Since there are not easily proved, only one of them is\nusually established (and sometimes none). We propose here a connection between\nthem which helps to get SN when one already has PSN. For this purpose, we\nformalize a general proof technique of SN which consists in expanding\nsubstitutions into \"pure\" lambda-terms and to inherit SN of the whole calculus\nby SN of the \"pure\" calculus and by PSN. We apply it successfully to a large\nset of calculi with explicit substitutions, allowing us to establish SN, or, at\nleast, to trace back the failure of SN to that of PSN.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2009 09:26:11 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Polonowski", "Emmanuel", ""]]}, {"id": "0909.5097", "submitter": "Barnaby Martin", "authors": "Barnaby Martin (Durham University, UK.), Manuel Bodirsky (CNRS/LIX,\n  Ecole Polytechnique, France), Martin Hils (Equipe de Logique Mathematique,\n  Universite Paris Diderot - Paris 7, France)", "title": "On the Scope of the Universal-Algebraic Approach to Constraint\n  Satisfaction", "comments": "Extended abstract appeared at 25th Symposium on Logic in Computer\n  Science (LICS 2010). This version will appear in the LMCS special issue\n  associated with LICS 2010", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 3 (September\n  12, 2012) lmcs:674", "doi": "10.2168/LMCS-8(3:13)2012", "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The universal-algebraic approach has proved a powerful tool in the study of\nthe complexity of CSPs. This approach has previously been applied to the study\nof CSPs with finite or (infinite) omega-categorical templates, and relies on\ntwo facts. The first is that in finite or omega-categorical structures A, a\nrelation is primitive positive definable if and only if it is preserved by the\npolymorphisms of A. The second is that every finite or omega-categorical\nstructure is homomorphically equivalent to a core structure. In this paper, we\npresent generalizations of these facts to infinite structures that are not\nnecessarily omega-categorical. (This abstract has been severely curtailed by\nthe space constraints of arXiv -- please read the full abstract in the\narticle.) Finally, we present applications of our general results to the\ndescription and analysis of the complexity of CSPs. In particular, we give\ngeneral hardness criteria based on the absence of polymorphisms that depend on\nmore than one argument, and we present a polymorphism-based description of\nthose CSPs that are first-order definable (and therefore can be solved in\npolynomial time).\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2009 13:56:20 GMT"}, {"version": "v2", "created": "Tue, 4 May 2010 16:02:00 GMT"}, {"version": "v3", "created": "Fri, 28 Jan 2011 17:27:54 GMT"}, {"version": "v4", "created": "Sat, 12 Nov 2011 19:04:55 GMT"}, {"version": "v5", "created": "Tue, 11 Sep 2012 08:10:16 GMT"}, {"version": "v6", "created": "Mon, 18 Mar 2013 13:25:19 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Martin", "Barnaby", "", "Durham University, UK."], ["Bodirsky", "Manuel", "", "CNRS/LIX,\n  Ecole Polytechnique, France"], ["Hils", "Martin", "", "Equipe de Logique Mathematique,\n  Universite Paris Diderot - Paris 7, France"]]}, {"id": "0909.5271", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Partial Komori fields and imperative Komori fields", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": "PRG0911", "categories": "math.RA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the status of 1/0 and ways to deal with it.\nThese matters are treated in the setting of Komori fields, also known as\nnon-trivial cancellation meadows. Different viewpoints on the status of 1/0\nexist in mathematics and theoretical computer science. We give a simple account\nof how mathematicians deal with 1/0 in which a customary convention among\nmathematicians plays a prominent part, and we make plausible that a convincing\naccount, starting from the popular computer science viewpoint that 1/0 is\nundefined, by means of some logic of partial functions is not attainable.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2009 06:10:03 GMT"}], "update_date": "2009-10-13", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "0909.5393", "submitter": "Kusum Lata", "authors": "Kusum Lata, H S Jamadagni", "title": "Formal Verification of Full-Wave Rectifier: A Case Study", "comments": "The IEEE 8th International Conference on ASIC (IEEE ASICON 2009),\n  October 20-23 2009, Changsha, China", "journal-ref": null, "doi": "10.1109/ASICON.2009.5351239", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a case study of formal verification of full-wave rectifier for\nanalog and mixed signal designs. We have used the Checkmate tool from CMU [1],\nwhich is a public domain formal verification tool for hybrid systems. Due to\nthe restriction imposed by Checkmate it necessitates to make the changes in the\nCheckmate implementation to implement the complex and non-linear system.\nFull-wave rectifier has been implemented by using the Checkmate custom blocks\nand the Simulink blocks from MATLAB from Math works. After establishing the\nrequired changes in the Checkmate implementation we are able to efficiently\nverify the safety properties of the full-wave rectifier.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2009 17:37:34 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Lata", "Kusum", ""], ["Jamadagni", "H S", ""]]}, {"id": "0909.5521", "submitter": "Prabhu Manyem", "authors": "Prabhu Manyem", "title": "Clique and Vertex Cover are solvable in polynomial time if the input\n  structure is ordered and contains a successor predicate", "comments": "Manuscript withdrawn, because results are incorrect. If phi = phi_1\n  AND phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and\n  phi_2 are Horn formulae. Furthermore, the cardinality constraint CANNOT be\n  expressed as a universal Horn sentence in ESO (NOT even when the structure is\n  ordered)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, assuming that Graedel's 1991 results are correct (which\nimplies that bounds on the solution values for optimization problems can be\nexpressed in existential second order logic where the first order part is\nuniversal Horn), I will show that Clique and Vertex Cover can be solved in\npolynomial time if the input structure is ordered and contains a successor\npredicate. In the last section, we will argue about the validity of Graedel's\n1991 results. Update: Manuscript withdrawn, because results are incorrect. If\nphi = phi_1 AND phi_2, and phi is a Horn formula, it does NOT mean that both\nphi_1 and phi_2 are Horn formulae. Furthermore, the cardinality constraint\nCANNOT be expressed as a universal Horn sentence in ESO (NOT even when the\nstructure is ordered).\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2009 06:34:47 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2009 11:16:32 GMT"}, {"version": "v3", "created": "Sat, 2 Oct 2010 22:33:43 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Manyem", "Prabhu", ""]]}]