[{"id": "2008.00070", "submitter": "Stepan Kuznetsov", "authors": "Max Kanovich, Stepan Kuznetsov, Andre Scedrov", "title": "Language Models for Some Extensions of the Lambek Calculus", "comments": "Extended version of our WoLLIC 2019 paper. Submitted to Information\n  and Computation (WoLLIC 2019 special issue)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate language interpretations of two extensions of the Lambek\ncalculus: with additive conjunction and disjunction and with additive\nconjunction and the unit constant. For extensions with additive connectives, we\nshow that conjunction and disjunction behave differently. Adding both of them\nleads to incompleteness due to the distributivity law. We show that with\nconjunction only no issues with distributivity arise. In contrast, there exists\na corollary of the distributivity law in the language with disjunction only\nwhich is not derivable in the non-distributive system. Moreover, this\ndifference keeps valid for systems with permutation and/or weakening structural\nrules, that is, intuitionistic linear and affine logics and affine\nmultiplicative-additive Lambek calculus. For the extension of the Lambek with\nthe unit constant, we present a calculus which reflects natural algebraic\nproperties of the empty word. We do not claim completeness for this calculus,\nbut we prove undecidability for the whole range of systems extending this\nminimal calculus and sound w.r.t. language models. As a corollary, we show that\nin the language with the unit there exissts a sequent that is true if all\nvariables are interpreted by regular language, but not true in language models\nin general.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 20:33:54 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kanovich", "Max", ""], ["Kuznetsov", "Stepan", ""], ["Scedrov", "Andre", ""]]}, {"id": "2008.00075", "submitter": "Stepan Kuznetsov", "authors": "Max Kanovich, Stepan Kuznetsov, Andre Scedrov", "title": "The Multiplicative-Additive Lambek Calculus with Subexponential and\n  Bracket Modalities", "comments": "Accepted for publication in the Journal of Logic, Language, and\n  Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a proof-theoretic and algorithmic complexity analysis for systems\nintroduced by Morrill to serve as the core of the CatLog categorial grammar\nparser. We consider two recent versions of Morrill's calculi, and focus on\ntheir fragments including multiplicative (Lambek) connectives, additive\nconjunction and disjunction, brackets and bracket modalities, and the !\nsubexponential modality. For both systems, we resolve issues connected with the\ncut rule and provide necessary modifications, after which we prove\nadmissibility of cut (cut elimination theorem). We also prove algorithmic\nundecidability for both calculi, and show that categorial grammars based on\nthem can generate arbitrary recursively enumerable languages.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 20:42:13 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 20:02:13 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Kanovich", "Max", ""], ["Kuznetsov", "Stepan", ""], ["Scedrov", "Andre", ""]]}, {"id": "2008.00097", "submitter": "Karen Leung Ms", "authors": "Karen Leung, Nikos Ar\\'echiga, Marco Pavone", "title": "Back-propagation through Signal Temporal Logic Specifications: Infusing\n  Logical Structure into Gradient-Based Methods", "comments": "Published in the Workshop on Algorithmic Foundations of Robotics 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CL cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technique, named STLCG, to compute the quantitative\nsemantics of Signal Temporal Logic (STL) formulas using computation graphs.\nSTLCG provides a platform which enables the incorporation of logical\nspecifications into robotics problems that benefit from gradient-based\nsolutions. Specifically, STL is a powerful and expressive formal language that\ncan specify spatial and temporal properties of signals generated by both\ncontinuous and hybrid systems. The quantitative semantics of STL provide a\nrobustness metric, i.e., how much a signal satisfies or violates an STL\nspecification. In this work, we devise a systematic methodology for translating\nSTL robustness formulas into computation graphs. With this representation, and\nby leveraging off-the-shelf automatic differentiation tools, we are able to\nback-propagate through STL robustness formulas and hence enable a natural and\neasy-to-use integration with many gradient-based approaches used in robotics.\nWe demonstrate, through examples stemming from various robotics applications,\nthat STLCG is versatile, computationally efficient, and capable of injecting\nhuman-domain knowledge into the problem formulation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 22:01:39 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 00:04:46 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Leung", "Karen", ""], ["Ar\u00e9chiga", "Nikos", ""], ["Pavone", "Marco", ""]]}, {"id": "2008.00120", "submitter": "Lasse Blaauwbroek", "authors": "Lasse Blaauwbroek, Josef Urban and Herman Geuvers", "title": "The Tactician (extended version): A Seamless, Interactive Tactic Learner\n  and Prover for Coq", "comments": "19 pages, 2 figures. This is an extended version of a paper published\n  in CICM-2020. For the project website, see https://coq-tactician.github.io", "journal-ref": "In CICM. volume 12236 of Lecture Notes in Computer Science, pages\n  271-277. Springer, 2020", "doi": "10.1007/978-3-030-53518-6_17", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Tactician, a tactic learner and prover for the Coq Proof\nAssistant. Tactician helps users make tactical proof decisions while they\nretain control over the general proof strategy. To this end, Tactician learns\nfrom previously written tactic scripts and gives users either suggestions about\nthe next tactic to be executed or altogether takes over the burden of proof\nsynthesis. Tactician's goal is to provide users with a seamless, interactive,\nand intuitive experience together with robust and adaptive proof automation. In\nthis paper, we give an overview of Tactician from the user's point of view,\nregarding both day-to-day usage and issues of package dependency management\nwhile learning in the large. Finally, we give a peek into Tactician's\nimplementation as a Coq plugin and machine learning platform.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 23:47:29 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Blaauwbroek", "Lasse", ""], ["Urban", "Josef", ""], ["Geuvers", "Herman", ""]]}, {"id": "2008.00420", "submitter": "Yijia Chen", "authors": "Yijia Chen and Joerg Flum", "title": "Forbidden Induced Subgraphs and the {\\L}o\\'s-Tarski Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathscr C$ be a class of finite and infinite graphs that is closed\nunder induced subgraphs. The well-known {\\L}o\\'s-Tarski Theorem from classical\nmodel theory implies that $\\mathscr C$ is definable in first-order logic (FO)\nby a sentence $\\varphi$ if and only if $\\mathscr C$ has a finite set of\nforbidden induced finite subgraphs. It provides a powerful tool to show\nnontrivial characterizations of graphs of small vertex cover, of bounded\ntree-depth, of bounded shrub-depth, etc. in terms of forbidden induced finite\nsubgraphs. Furthermore, by the Completeness Theorem, we can compute from\n$\\varphi$ the corresponding forbidden induced subgraphs. We show that this\nmachinery fails on finite graphs.\n  - There is a class $\\mathscr C$ of finite graphs which is definable in FO and\nclosed under induced subgraphs but has no finite set of forbidden induced\nsubgraphs.\n  - Even if we only consider classes $\\mathscr C$ of finite graphs which can be\ncharacterized by a finite set of forbidden induced subgraphs, such a\ncharacterization cannot be computed from an FO-sentence $\\varphi$, which\ndefines $\\mathscr C$, and the size of the characterization cannot be bounded by\n$f(|\\varphi|)$ for any computable function $f$.\n  Besides their importance in graph theory, the above results also\nsignificantly strengthen similar known results for arbitrary structures.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 07:14:38 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Chen", "Yijia", ""], ["Flum", "Joerg", ""]]}, {"id": "2008.00421", "submitter": "Germ\\'an Vidal", "authors": "Fred Mesnard, Etienne Payet, German Vidal", "title": "Concolic Testing in CLP", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 671-686", "doi": "10.1017/S1471068420000216", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concolic testing is a popular software verification technique based on a\ncombination of concrete and symbolic execution. Its main focus is finding bugs\nand generating test cases with the aim of maximizing code coverage. A previous\napproach to concolic testing in logic programming was not sound because it only\ndealt with positive constraints (by means of substitutions) but could not\nrepresent negative constraints. In this paper, we present a novel framework for\nconcolic testing of CLP programs that generalizes the previous technique. In\nthe CLP setting, one can represent both positive and negative constraints in a\nnatural way, thus giving rise to a sound and (potentially) more efficient\ntechnique. Defining verification and testing techniques for CLP programs is\nincreasingly relevant since this framework is becoming popular as an\nintermediate representation to analyze programs written in other programming\nparadigms.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 07:15:43 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 08:43:44 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 07:00:37 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mesnard", "Fred", ""], ["Payet", "Etienne", ""], ["Vidal", "German", ""]]}, {"id": "2008.00583", "submitter": "Eike Neumann", "authors": "Eike Neumann", "title": "Decision problems for linear recurrences involving arbitrary real\n  numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the decidability of the Skolem Problem, the Positivity Problem, and\nthe Ultimate Positivity Problem for linear recurrences with real number initial\nvalues and real number coefficients in the bit-model of real computation. We\nshow that for each problem there exists a correct partial algorithm which halts\nfor all problem instances for which the answer is locally constant, thus\nestablishing that all three problems are as close to decidable as one can\nexpect them to be in this setting. We further show that the algorithms for the\nPositivity Problem and the Ultimate Positivity Problem halt on almost every\ninstance with respect to the usual Lebesgue measure on Euclidean space. In\ncomparison, the analogous problems for exact rational or real algebraic\ncoefficients are known to be decidable only for linear recurrences of fairly\nlow order.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 23:07:54 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 19:51:25 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 14:53:36 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Neumann", "Eike", ""]]}, {"id": "2008.00724", "submitter": "Michael Maher", "authors": "Michael J. Maher", "title": "A lemma on closures and its application to modularity in logic\n  programming semantics", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This note points out a lemma on closures of monotonic increasing functions\nand shows how it is applicable to decomposition and modularity for semantics\ndefined as the least fixedpoint of some monotonic function. In particular it\napplies to numerous semantics of logic programs. An appendix addresses the\nfixedpoints of (possibly non-monotonic) functions that are sandwiched between\nfunctions with the same fixedpoints.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:55:58 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Maher", "Michael J.", ""]]}, {"id": "2008.00956", "submitter": "Paul Tarau", "authors": "Paul Tarau and Eduardo Blanco", "title": "Interactive Text Graph Mining with a Prolog-based Dialog Engine", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP). arXiv admin note: substantial text overlap with arXiv:1909.09742", "journal-ref": "Theory and Practice of Logic Programming 21 (2021) 244-263", "doi": "10.1017/S1471068420000137", "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On top of a neural network-based dependency parser and a graph-based natural\nlanguage processing module we design a Prolog-based dialog engine that explores\ninteractively a ranked fact database extracted from a text document.\n  We reorganize dependency graphs to focus on the most relevant content\nelements of a sentence and integrate sentence identifiers as graph nodes.\n  Additionally, after ranking the graph we take advantage of the implicit\nsemantic information that dependency links and WordNet bring in the form of\nsubject-verb-object, is-a and part-of relations.\n  Working on the Prolog facts and their inferred consequences, the dialog\nengine specializes the text graph with respect to a query and reveals\ninteractively the document's most relevant content elements.\n  The open-source code of the integrated system is available at\nhttps://github.com/ptarau/DeepRank .\n  Under consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 03:29:49 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Tarau", "Paul", ""], ["Blanco", "Eduardo", ""]]}, {"id": "2008.01050", "submitter": "L\\^e Th\\`anh D\\~ung (Tito) Nguy\\^en", "authors": "L\\^e Th\\`anh D\\~ung Nguy\\^en, Camille No\\^us and Pierre Pradic", "title": "Implicit automata in typed $\\lambda$-calculi II: streaming transducers\n  vs categorical semantics", "comments": "105 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We characterize regular string transductions as programs in a linear\n$\\lambda$-calculus with additives. One direction of this equivalence is proved\nby encoding copyless streaming string transducers (SSTs), which compute regular\nfunctions, into our $\\lambda$-calculus. For the converse, we consider a\ncategorical framework for defining automata and transducers over words, which\nallows us to relate register updates in SSTs to the semantics of the linear\n$\\lambda$-calculus in a suitable monoidal closed category. To illustrate the\nrelevance of monoidal closure to automata theory, we also leverage this notion\nto give abstract generalizations of the arguments showing that copyless SSTs\nmay be determinized and that the composition of two regular functions may be\nimplemented by a copyless SST. Our main result is then generalized from strings\nto trees using a similar approach. In doing so, we exhibit a connection between\na feature of streaming tree transducers and the multiplicative/additive\ndistinction of linear logic.\n  Keywords: MSO transductions, implicit complexity, Dialectica categories,\nChurch encodings\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:37:10 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 16:04:39 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Nguy\u00ean", "L\u00ea Th\u00e0nh D\u0169ng", ""], ["No\u00fbs", "Camille", ""], ["Pradic", "Pierre", ""]]}, {"id": "2008.01387", "submitter": "Pamina Georgiou MSc", "authors": "Pamina Georgiou and Bernhard Gleiss and Laura Kov\\'acs", "title": "Trace Logic for Inductive Loop Reasoning", "comments": "Related Version: A compact, peer-reviewed version of this paper will\n  be available in the conference proceedings of Formal Methods of\n  Computer-Aided Design (FMCAD) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose trace logic, an instance of many-sorted first-order logic, to\nautomate the partial correctness verification of programs containing loops.\nTrace logic generalizes semantics of program locations and captures loop\nsemantics by encoding properties at arbitrary timepoints and loop iterations.\nWe guide and automate inductive loop reasoning in trace logic by using generic\ntrace lemmas capturing inductive loop invariants. Our work is implemented in\nthe RAPID framework, by extending and integrating superposition-based\nfirst-order reasoning within RAPID. We successfully used RAPID to prove\ncorrectness of many programs whose functional behavior are best summarized in\nthe first-order theories of linear integer arithmetic, arrays and inductive\ndata types.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:54:22 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 07:14:39 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Georgiou", "Pamina", ""], ["Gleiss", "Bernhard", ""], ["Kov\u00e1cs", "Laura", ""]]}, {"id": "2008.01394", "submitter": "Riccardo Zese", "authors": "Elena Bellodi, Marco Alberti, Fabrizio Riguzzi, Riccardo Zese", "title": "MAP Inference for Probabilistic Logic Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 641-655", "doi": "10.1017/S1471068420000174", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Probabilistic Logic Programming (PLP) the most commonly studied inference\ntask is to compute the marginal probability of a query given a program. In this\npaper, we consider two other important tasks in the PLP setting: the\nMaximum-A-Posteriori (MAP) inference task, which determines the most likely\nvalues for a subset of the random variables given evidence on other variables,\nand the Most Probable Explanation (MPE) task, the instance of MAP where the\nquery variables are the complement of the evidence variables. We present a\nnovel algorithm, included in the PITA reasoner, which tackles these tasks by\nrepresenting each problem as a Binary Decision Diagram and applying a dynamic\nprogramming procedure on it. We compare our algorithm with the version of\nProbLog that admits annotated disjunctions and can perform MAP and MPE\ninference. Experiments on several synthetic datasets show that PITA outperforms\nProbLog in many cases.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 08:10:51 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 15:41:46 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 07:27:13 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Bellodi", "Elena", ""], ["Alberti", "Marco", ""], ["Riguzzi", "Fabrizio", ""], ["Zese", "Riccardo", ""]]}, {"id": "2008.01422", "submitter": "Tom de Jong", "authors": "Tom de Jong and Mart\\'in H\\\"otzel Escard\\'o", "title": "Domain Theory in Constructive and Predicative Univalent Foundations", "comments": "A shorter version of this paper will appear in the proceedings of CSL\n  2021, volume 183 of LIPIcs", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop domain theory in constructive univalent foundations without\nVoevodsky's resizing axioms. In previous work in this direction, we constructed\nthe Scott model of PCF and proved its computational adequacy, based on directed\ncomplete posets (dcpos). Here we further consider algebraic and continuous\ndcpos, and construct Scott's $D_\\infty$ model of the untyped\n$\\lambda$-calculus. A common approach to deal with size issues in a predicative\nfoundation is to work with information systems or abstract bases or formal\ntopologies rather than dcpos, and approximable relations rather than Scott\ncontinuous functions. Here we instead accept that dcpos may be large and work\nwith type universes to account for this. For instance, in the Scott model of\nPCF, the dcpos have carriers in the second universe $\\mathcal{U}_1$ and suprema\nof directed families with indexing type in the first universe $\\mathcal{U}_0$.\nSeeing a poset as a category in the usual way, we can say that these dcpos are\nlarge, but locally small, and have small filtered colimits. In the case of\nalgebraic dcpos, in order to deal with size issues, we proceed mimicking the\ndefinition of accessible category. With such a definition, our construction of\nScott's $D_\\infty$ again gives a large, locally small, algebraic dcpo with\nsmall directed suprema.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 09:06:01 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 14:23:36 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 10:46:57 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["de Jong", "Tom", ""], ["Escard\u00f3", "Mart\u00edn H\u00f6tzel", ""]]}, {"id": "2008.01609", "submitter": "Simon Marynissen", "authors": "Simon Marynissen, Bart Bogaerts and Marc Denecker", "title": "Exploiting Game Theory for Analysing Justifications", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 15+8 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 880-894", "doi": "10.1017/S1471068420000186", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Justification theory is a unifying semantic framework. While it has its roots\nin non-monotonic logics, it can be applied to various areas in computer\nscience, especially in explainable reasoning; its most central concept is a\njustification: an explanation why a property holds (or does not hold) in a\nmodel. In this paper, we continue the study of justification theory by means of\nthree major contributions. The first is studying the relation between\njustification theory and game theory. We show that justification frameworks can\nbe seen as a special type of games. The established connection provides the\ntheoretical foundations for our next two contributions. The second contribution\nis studying under which condition two different dialects of justification\ntheory (graphs as explanations vs trees as explanations) coincide. The third\ncontribution is establishing a precise criterion of when a semantics induced by\njustification theory yields consistent results. In the past proving that such\nsemantics were consistent took cumbersome and elaborate proofs. We show that\nthese criteria are indeed satisfied for all common semantics of logic\nprogramming. This paper is under consideration for acceptance in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:45:08 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Marynissen", "Simon", ""], ["Bogaerts", "Bart", ""], ["Denecker", "Marc", ""]]}, {"id": "2008.01849", "submitter": "Patrick Morandi", "authors": "Guram Bezhanishvili, Luca Carai, Patrick Morandi", "title": "Coalgebras for the powerset functor and Thomason duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the endofunctor $H$ on the category $CABA$ of complete and atomic\nboolean algebras and complete boolean homomorphisms such that the category\n$Alg(H)$ of algebras for $H$ is dually equivalent to the category\n$Coalg(\\mathcal{P})$ of coalgebras for the powerset endofunctor $\\mathcal{P}$\non $Set$. As a consequence, we derive Thomason duality from Tarski duality.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 21:48:53 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:44:31 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bezhanishvili", "Guram", ""], ["Carai", "Luca", ""], ["Morandi", "Patrick", ""]]}, {"id": "2008.01926", "submitter": "Hazhar Rahmani", "authors": "Hazhar Rahmani, Jason M. O'Kane", "title": "What to Do When You Can't Do It All: Temporal Logic Planning with Soft\n  Temporal Logic Constraints", "comments": "To appear in IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a temporal logic planning problem in which the\nobjective is to find an infinite trajectory that satisfies an optimal selection\nfrom a set of soft specifications expressed in linear temporal logic (LTL)\nwhile nevertheless satisfying a hard specification expressed in LTL. Our\nprevious work considered a similar problem in which linear dynamic logic for\nfinite traces (LDLf), rather than LTL, was used to express the soft\nconstraints. In that work, LDLf was used to impose constraints on finite\nprefixes of the infinite trajectory. By using LTL, one is able not only to\nimpose constraints on the finite prefixes of the trajectory, but also to set\n`soft' goals across the entirety of the infinite trajectory. Our algorithm\nfirst constructs a product automaton, on which the planning problem is reduced\nto computing a lasso with minimum cost. Among all such lassos, it is desirable\nto compute a shortest one. Though we prove that computing such a shortest lasso\nis computationally hard, we also introduce an efficient greedy approach to\nsynthesize short lassos nonetheless. We present two case studies describing an\nimplementation of this approach, and report results of our experiment comparing\nour greedy algorithm with an optimal baseline.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 04:18:59 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Rahmani", "Hazhar", ""], ["O'Kane", "Jason M.", ""]]}, {"id": "2008.02015", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno and Yuliya Lierler", "title": "Modular Answer Set Programming as a Formal Specification Language", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 767-782", "doi": "10.1017/S1471068420000265", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of formal verification for Answer Set\nProgramming (ASP), namely, obtaining a formal proof showing that the answer\nsets of a given (non-ground) logic program P correctly correspond to the\nsolutions to the problem encoded by P, regardless of the problem instance. To\nthis aim, we use a formal specification language based on ASP modules, so that\neach module can be proved to capture some informal aspect of the problem in an\nisolated way. This specification language relies on a novel definition of\n(possibly nested, first order) program modules that may incorporate local\nhidden atoms at different levels. Then, verifying the logic program P amounts\nto prove some kind of equivalence between P and its modular specification.\nUnder consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 09:25:51 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 09:40:40 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Lierler", "Yuliya", ""]]}, {"id": "2008.02018", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno, Javier Garea, Javier Romero and Torsten\n  Schaub", "title": "eclingo: A solver for Epistemic Logic Programs", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe eclingo, a solver for epistemic logic programs under Gelfond 1991\nsemantics built upon the Answer Set Programming system clingo. The input\nlanguage of eclingo uses the syntax extension capabilities of clingo to define\nsubjective literals that, as usual in epistemic logic programs, allow for\nchecking the truth of a regular literal in all or in some of the answer sets of\na program. The eclingo solving process follows a guess and check strategy. It\nfirst generates potential truth values for subjective literals and, in a second\nstep, it checks the obtained result with respect to the cautious and brave\nconsequences of the program. This process is implemented using the multi-shot\nfunctionalities of clingo. We have also implemented some optimisations, aiming\nat reducing the search space and, therefore, increasing eclingo's efficiency in\nsome scenarios. Finally, we compare the efficiency of eclingo with two\nstate-of-the-art solvers for epistemic logic programs on a pair of benchmark\nscenarios and show that eclingo generally outperforms their obtained results.\nUnder consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 09:32:05 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Garea", "Javier", ""], ["Romero", "Javier", ""], ["Schaub", "Torsten", ""]]}, {"id": "2008.02025", "submitter": "Patrick L\\\"uhne", "authors": "Jorge Fandinno, Vladimir Lifschitz, Patrick L\\\"uhne and Torsten Schaub", "title": "Verifying Tight Logic Programs with anthem and Vampire", "comments": "Paper submitted to the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages (main part), 12 pages (appendix)", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 735-750", "doi": "10.1017/S1471068420000344", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper continues the line of research aimed at investigating the\nrelationship between logic programs and first-order theories. We extend the\ndefinition of program completion to programs with input and output in a subset\nof the input language of the ASP grounder gringo, study the relationship\nbetween stable models and completion in this context, and describe preliminary\nexperiments with the use of two software tools, anthem and vampire, for\nverifying the correctness of programs with input and output. Proofs of theorems\nare based on a lemma that relates the semantics of programs studied in this\npaper to stable models of first-order formulas. Under consideration for\nacceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:01:33 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 23:32:54 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 21:52:46 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Fandinno", "Jorge", ""], ["Lifschitz", "Vladimir", ""], ["L\u00fchne", "Patrick", ""], ["Schaub", "Torsten", ""]]}, {"id": "2008.02038", "submitter": "Torsten Schaub", "authors": "Pedro Cabalar and Martin Dieguez and Torsten Schaub and Anna Schuhmann", "title": "Towards Metric Temporal Answer Set Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 28 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 783-798", "doi": "10.1017/S1471068420000307", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate upon the theoretical foundations of a metric temporal extension\nof Answer Set Programming. In analogy to previous extensions of ASP with\nconstructs from Linear Temporal and Dynamic Logic, we accomplish this in the\nsetting of the logic of Here-and-There and its non-monotonic extension, called\nEquilibrium Logic. More precisely, we develop our logic on the same semantic\nunderpinnings as its predecessors and thus use a simple time domain of bounded\ntime steps. This allows us to compare all variants in a uniform framework and\nultimately combine them in a common implementation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:30:14 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 14:48:44 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Cabalar", "Pedro", ""], ["Dieguez", "Martin", ""], ["Schaub", "Torsten", ""], ["Schuhmann", "Anna", ""]]}, {"id": "2008.02123", "submitter": "Nicola Botta", "authors": "Nicola Botta and Nuria Brede and Patrik Jansson and Tim Richter", "title": "Extensional equality preservation and verified generic programming", "comments": "Manuscript ID: JFP-2020-0033", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In verified generic programming, one cannot exploit the structure of concrete\ndata types but has to rely on well chosen sets of specifications or abstract\ndata types (ADTs). Functors and monads are at the core of many applications of\nfunctional programming. This raises the question of what useful ADTs for\nverified functors and monads could look like. The functorial map of many\nimportant monads preserves extensional equality. For instance, if $f, g : A\n\\rightarrow B$ are extensionally equal, that is, $\\forall x \\in A, \\ f \\ x = g\n\\ x$, then $map \\ f : List \\ A \\rightarrow List \\ B$ and $map \\ g$ are also\nextensionally equal. This suggests that preservation of extensional equality\ncould be a useful principle in verified generic programming. We explore this\npossibility with a minimalist approach: we deal with (the lack of) extensional\nequality in Martin-L\\\"of's intensional type theories without extending the\ntheories or using full-fledged setoids. Perhaps surprisingly, this minimal\napproach turns out to be extremely useful. It allows one to derive simple\ngeneric proofs of monadic laws but also verified, generic results in dynamical\nsystems and control theory. In turn, these results avoid tedious code\nduplication and ad-hoc proofs. Thus, our work is a contribution towards\npragmatic, verified generic programming.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 13:26:53 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 16:49:16 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Botta", "Nicola", ""], ["Brede", "Nuria", ""], ["Jansson", "Patrik", ""], ["Richter", "Tim", ""]]}, {"id": "2008.02138", "submitter": "Barnaby Martin", "authors": "Stefan Dantchev, Nicola Galesi, Abdul Ghani, Barnaby Martin", "title": "Proof complexity and the binary encoding of combinatorial principles", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.02843,\n  arXiv:1911.00403", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Proof Complexity in light of the unusual binary encoding of\ncertain combinatorial principles. We contrast this Proof Complexity with the\nnormal unary encoding in several refutation systems, based on Resolution and\nInteger Linear Programming. Please consult the article for the full abstract.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:24:19 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Dantchev", "Stefan", ""], ["Galesi", "Nicola", ""], ["Ghani", "Abdul", ""], ["Martin", "Barnaby", ""]]}, {"id": "2008.02140", "submitter": "Francesco Dagnino", "authors": "Francesco Dagnino, Davide Ancona, Elena Zucca", "title": "Flexible coinductive logic programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 818-833", "doi": "10.1017/S147106842000023X", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive definitions of predicates are usually interpreted either\ninductively or coinductively. Recently, a more powerful approach has been\nproposed, called flexible coinduction, to express a variety of intermediate\ninterpretations, necessary in some cases to get the correct meaning. We provide\na detailed formal account of an extension of logic programming supporting\nflexible coinduction. Syntactically, programs are enriched by coclauses,\nclauses with a special meaning used to tune the interpretation of predicates.\nAs usual, the declarative semantics can be expressed as a fixed point which,\nhowever, is not necessarily the least, nor the greatest one, but is determined\nby the coclauses. Correspondingly, the operational semantics is a combination\nof standard SLD resolution and coSLD resolution. We prove that the operational\nsemantics is sound and complete with respect to declarative semantics\nrestricted to finite comodels. This paper is under consideration for acceptance\nin TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 13:57:21 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Dagnino", "Francesco", ""], ["Ancona", "Davide", ""], ["Zucca", "Elena", ""]]}, {"id": "2008.02143", "submitter": "Nicola Botta", "authors": "Nuria Brede and Nicola Botta", "title": "On the correctness of monadic backward induction", "comments": "Manuscript ID: JFP-2020-0032", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In control theory, to solve a finite-horizon sequential decision problem\n(SDP) commonly means to find a list of decision rules that result in an optimal\nexpected total reward (or cost) when taking a given number of decision steps.\nSDPs are routinely solved using Bellman's backward induction. Textbooks\ntypically give more or less formal proofs to show that the backward induction\nalgorithm is correct as solution method for deterministic and stochastic SDPs.\nIn Botta et al. 2017, the authors propose a generic framework for finite\nhorizon, monadic SDPs together with a verified monadic version of backward\ninduction for solving such SDPs. In monadic SDPs, the monad captures a generic\nnotion of uncertainty, while a generic measure function aggregates rewards. In\nthe present paper we extend Botta et al.'s verification result. Under certain\nconditions on the measure function, we obtain a correctness result for monadic\nbackward induction that is comparable to textbook correctness proofs for\nordinary backward induction. The conditions that we impose are fairly general\nand can be cast in category-theoretical terms using the notion of\nEilenberg-Moore-algebra. They hold for familiar measures like the expected\nvalue but also imply that certain measures cannot be used for optimization\nwithin the Botta et al. framework. Our development is formalized in Idris as an\nextension of the framework and the sources are available as supplementary\nmaterial.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:03:46 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 17:29:26 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Brede", "Nuria", ""], ["Botta", "Nicola", ""]]}, {"id": "2008.02232", "submitter": "Jessica Zangari", "authors": "Alessio Fiorentino, Jessica Zangari and Marco Manna", "title": "DaRLing: A Datalog rewriter for OWL 2 RL ontological reasoning under\n  SPARQL queries", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The W3C Web Ontology Language (OWL) is a powerful knowledge representation\nformalism at the basis of many semantic-centric applications. Since its\nunrestricted usage makes reasoning undecidable already in case of very simple\ntasks, expressive yet decidable fragments have been identified. Among them, we\nfocus on OWL 2 RL, which offers a rich variety of semantic constructors, apart\nfrom supporting all RDFS datatypes. Although popular Web resources - such as\nDBpedia - fall in OWL 2 RL, only a few systems have been designed and\nimplemented for this fragment. None of them, however, fully satisfy all the\nfollowing desiderata: (i) being freely available and regularly maintained; (ii)\nsupporting query answering and SPARQL queries; (iii) properly applying the\nsameAs property without adopting the unique name assumption; (iv) dealing with\nconcrete datatypes. To fill the gap, we present DaRLing, a freely available\nDatalog rewriter for OWL 2 RL ontological reasoning under SPARQL queries. In\nparticular, we describe its architecture, the rewriting strategies it\nimplements, and the result of an experimental evaluation that demonstrates its\npractical applicability. This paper is under consideration in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:59:59 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Fiorentino", "Alessio", ""], ["Zangari", "Jessica", ""], ["Manna", "Marco", ""]]}, {"id": "2008.02429", "submitter": "Ryan Riegel", "authors": "Ronald Fagin, Ryan Riegel, Alexander Gray", "title": "Foundations of Reasoning with Uncertainty via Real-valued Logics", "comments": "9 pages (incl. references), 9 pages supplementary. Submitted to\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-valued logics underlie an increasing number of neuro-symbolic\napproaches, though typically their logical inference capabilities are\ncharacterized only qualitatively. We provide foundations for establishing the\ncorrectness and power of such systems. For the first time, we give a sound and\ncomplete axiomatization for a broad class containing all the common real-valued\nlogics. This axiomatization allows us to derive exactly what information can be\ninferred about the combinations of real values of a collection of formulas\ngiven information about the combinations of real values of several other\ncollections of formulas. We then extend the axiomatization to deal with\nweighted subformulas. Finally, we give a decision procedure based on linear\nprogramming for deciding, under certain natural assumptions, whether a set of\nour sentences logically implies another of our sentences.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 02:13:11 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 21:22:08 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Fagin", "Ronald", ""], ["Riegel", "Ryan", ""], ["Gray", "Alexander", ""]]}, {"id": "2008.02483", "submitter": "EPTCS", "authors": "Laurent Fribourg (CNRS & ENS Paris-Saclay, France), Matthias Heizmann\n  (University of Freiburg, Germany)", "title": "Proceedings 8th International Workshop on Verification and Program\n  Transformation and 7th Workshop on Horn Clauses for Verification and\n  Synthesis", "comments": null, "journal-ref": "EPTCS 320, 2020", "doi": "10.4204/EPTCS.320", "report-no": null, "categories": "cs.LO cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proceedings consist of a keynote paper by Alberto followed by 6 invited\npapers written by Lorenzo Clemente (U. Warsaw), Alain Finkel (U. Paris-Saclay),\nJohn Gallagher (Roskilde U. and IMDEA Software Institute) et al., Neil Jones\n(U. Copenhagen) et al., Michael Leuschel (Heinrich-Heine U.) and Maurizio\nProietti (IASI-CNR) et al.. These invited papers are followed by 4 regular\npapers accepted at VPT 2020 and the papers of HCVS 2020 which consist of three\ncontributed papers and an invited paper on the third competition of solvers for\nConstrained Horn Clauses.\n  In addition, the abstracts (in HTML format) of 3 invited talks at VPT 2020 by\nAndrzej Skowron (U. Warsaw), Sophie Renault (EPO) and Moa Johansson (Chalmers\nU.), are included.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 07:11:26 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Fribourg", "Laurent", "", "CNRS & ENS Paris-Saclay, France"], ["Heizmann", "Matthias", "", "University of Freiburg, Germany"]]}, {"id": "2008.02550", "submitter": "Gianvincenzo Alfano", "authors": "Gianvincenzo Alfano, Sergio Greco, Francesco Parisi, Irina Trubitsyna", "title": "On the Semantics of Abstract Argumentation Frameworks: A Logic\n  Programming Approach", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been an increasing interest in frameworks extending Dung's\nabstract Argumentation Framework (AF). Popular extensions include bipolar AFs\nand AFs with recursive attacks and necessary supports. Although the\nrelationships between AF semantics and Partial Stable Models (PSMs) of logic\nprograms has been deeply investigated, this is not the case for more general\nframeworks extending AF.\n  In this paper we explore the relationships between AF-based frameworks and\nPSMs. We show that every AF-based framework $\\Delta$ can be translated into a\nlogic program $P_\\Delta$ so that the extensions prescribed by different\nsemantics of $\\Delta$ coincide with subsets of the PSMs of $P_\\Delta$. We\nprovide a logic programming approach that characterizes, in an elegant and\nuniform way, the semantics of several AF-based frameworks. This result allows\nalso to define the semantics for new AF-based frameworks, such as AFs with\nrecursive attacks and recursive deductive supports.\n  Under consideration for publication in Theory and Practice of Logic\nProgramming.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 10:04:53 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Alfano", "Gianvincenzo", ""], ["Greco", "Sergio", ""], ["Parisi", "Francesco", ""], ["Trubitsyna", "Irina", ""]]}, {"id": "2008.02665", "submitter": "Lionel Vaux Auclair", "authors": "Federico Olimpieri and Lionel Vaux Auclair", "title": "On the Taylor expansion of $\\lambda$-terms and the groupoid structure of\n  their rigid approximants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We show that the normal form of the Taylor expansion of a $\\lambda$-term is\nisomorphic to its B\\\"ohm tree, improving Ehrhard and Regnier's original proof\nalong three independent directions.\n  First, we simplify the final step of the proof by following the left\nreduction strategy directly in the resource calculus, avoiding to introduce an\nabstract machine ad hoc.\n  We also introduce a groupoid of permutations of copies of arguments in a\nrigid variant of the resource calculus, and relate the coefficients of Taylor\nexpansion with this structure, while Ehrhard and Regnier worked with groups of\npermutations of occurrences of variables.\n  Finally, we extend all the results to a non-deterministic setting: by\ncontrast with previous attempts, we show that the uniformity property that was\ncrucial in Ehrhard and Regnier's approach can be preserved in this setting.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:56:15 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 01:21:45 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Olimpieri", "Federico", ""], ["Auclair", "Lionel Vaux", ""]]}, {"id": "2008.02747", "submitter": "Roberta Costabile", "authors": "Roberta Costabile, Gelsomina Catalano, Bernardo Cuteri, Maria Concetta\n  Morelli, Nicola Leone, Marco Manna", "title": "A logic-based decision support system for the diagnosis of headache\n  disorders according to the ICHD-3 international classification", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision support systems play an important role in medical fields as they can\naugment clinicians to deal more efficiently and effectively with complex\ndecision-making processes. In the diagnosis of headache disorders, however,\nexisting approaches and tools are still not optimal. On the one hand, to\nsupport the diagnosis of this complex and vast spectrum of disorders, the\nInternational Headache Society released in 1988 the International\nClassification of Headache Disorders (ICHD), now in its 3rd edition: a 200\npages document classifying more than 300 different kinds of headaches, where\neach is identified via a collection of specific nontrivial diagnostic criteria.\nOn the other hand, the high number of headache disorders and their complex\ncriteria make the medical history process inaccurate and not exhaustive both\nfor clinicians and existing automatic tools. To fill this gap, we present\nHEAD-ASP, a novel decision support system for the diagnosis of headache\ndisorders. Through a REST Web Service, HEAD-ASP implements a dynamic\nquestionnaire that complies with ICHD-3 by exploiting two logical modules to\nreach a complete diagnosis while trying to minimize the total number of\nquestions being posed to patients. Finally, HEAD-ASP is freely available\non-line and it is receiving very positive feedback from the group of\nneurologists that is testing it.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:26:50 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Costabile", "Roberta", ""], ["Catalano", "Gelsomina", ""], ["Cuteri", "Bernardo", ""], ["Morelli", "Maria Concetta", ""], ["Leone", "Nicola", ""], ["Manna", "Marco", ""]]}, {"id": "2008.02857", "submitter": "Linh Anh Nguyen D.Sc.", "authors": "Linh Anh Nguyen, Quang-Thuy Ha, Ngoc Thanh Nguyen, Thi Hong Khanh\n  Nguyen, Thanh-Luong Tran", "title": "Bisimulation and bisimilarity for fuzzy description logics under the\n  G\\\"odel semantics", "comments": "This is a revised and corrected version of the publication\n  \"Bisimulation and bisimilarity for fuzzy description logics under the G\\\"odel\n  semantics\", Fuzzy Sets and Systems 388: 146-178 (2020)", "journal-ref": "Fuzzy Sets and Systems 388: 146-178 (2020)", "doi": "10.1016/j.fss.2019.08.004", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description logics (DLs) are a suitable formalism for representing knowledge\nabout domains in which objects are described not only by attributes but also by\nbinary relations between objects. Fuzzy extensions of DLs can be used for such\ndomains when data and knowledge about them are vague and imprecise. One of the\npossible ways to specify classes of objects in such domains is to use concepts\nin fuzzy DLs. As DLs are variants of modal logics, indiscernibility in DLs is\ncharacterized by bisimilarity. The bisimilarity relation of an interpretation\nis the largest auto-bisimulation of that interpretation. In DLs and their fuzzy\nextensions, such equivalence relations can be used for concept learning. In\nthis paper, we define and study fuzzy bisimulation and bisimilarity for fuzzy\nDLs under the G\\\"odel semantics, as well as crisp bisimulation and strong\nbisimilarity for such logics extended with involutive negation. The considered\nlogics are fuzzy extensions of the DL $\\mathcal{ALC}_{reg}$ (a variant of PDL)\nwith additional features among inverse roles, nominals, (qualified or\nunqualified) number restrictions, the universal role, local reflexivity of a\nrole and involutive negation. We formulate and prove results on invariance of\nconcepts under fuzzy (resp. crisp) bisimulation, conditional invariance of\nfuzzy TBoxex/ABoxes under bisimilarity (resp. strong bisimilarity), and the\nHennessy-Milner property of fuzzy (resp. crisp) bisimulation for fuzzy DLs\nwithout (resp. with) involutive negation under the G\\\"odel semantics. Apart\nfrom these fundamental results, we also provide results on using fuzzy\nbisimulation to separate the expressive powers of fuzzy DLs, as well as results\non using strong bisimilarity to minimize fuzzy interpretations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 20:05:06 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Nguyen", "Linh Anh", ""], ["Ha", "Quang-Thuy", ""], ["Nguyen", "Ngoc Thanh", ""], ["Nguyen", "Thi Hong Khanh", ""], ["Tran", "Thanh-Luong", ""]]}, {"id": "2008.02927", "submitter": "EPTCS", "authors": "Alberto Pettorossi (University of Rome Tor Vergata, Rome, Italy)", "title": "A Historical Account of My Early Research Interests", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483", "journal-ref": "EPTCS 320, 2020, pp. 1-28", "doi": "10.4204/EPTCS.320.1", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a brief account of some of the my early research\ninterests. This historical account starts from my laurea thesis on Signal\nTheory and my master thesis on Computation Theory. It recalls some results in\nCombinatory Logic and Term Rewriting Systems. Some other results concern\nProgram Transformation, Parallel Computation, Theory of Concurrency, and Proof\nof Program Properties. My early research activity has been mainly done in\ncooperation with Andrzej Skowron, Anna Labella, and Maurizio Proietti.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:22:23 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Pettorossi", "Alberto", "", "University of Rome Tor Vergata, Rome, Italy"]]}, {"id": "2008.02929", "submitter": "EPTCS", "authors": "Alain Finkel (Universite Paris-Saclay, ENS Paris-Saclay, CNRS)", "title": "From Well Structured Transition Systems to Program Verification", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483", "journal-ref": "EPTCS 320, 2020, pp. 44-49", "doi": "10.4204/EPTCS.320.3", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the use of the theory of WSTS for verifying programs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:22:54 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Finkel", "Alain", "", "Universite Paris-Saclay, ENS Paris-Saclay, CNRS"]]}, {"id": "2008.02931", "submitter": "EPTCS", "authors": "John P. Gallagher (Roskilde University, Denmark and IMDEA Software\n  Institute, Spain), Manuel Hermenegildo (IMDEA Software Institute, Spain),\n  Bishoksan Kafle (IMDEA Software Institute, Spain), Maximiliano Klemen (IMDEA\n  Software Institute, Spain), Pedro L\\'opez Garc\\'ia (IMDEA Software Institute,\n  Spain), Jos\\'e Morales (IMDEA Software Institute, Spain)", "title": "From Big-Step to Small-Step Semantics and Back with Interpreter\n  Specialisation", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483", "journal-ref": "EPTCS 320, 2020, pp. 50-64", "doi": "10.4204/EPTCS.320.4", "report-no": null, "categories": "cs.PL cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate representations of imperative programs as constrained Horn\nclauses. Starting from operational semantics transition rules, we proceed by\nwriting interpreters as constrained Horn clause programs directly encoding the\nrules. We then specialise an interpreter with respect to a given source program\nto achieve a compilation of the source language to Horn clauses (an instance of\nthe first Futamura projection). The process is described in detail for an\ninterpreter for a subset of C, directly encoding the rules of big-step\noperational semantics for C. A similar translation based on small-step\nsemantics could be carried out, but we show an approach to obtaining a\nsmall-step representation using a linear interpreter for big-step Horn clauses.\nThis interpreter is again specialised to achieve the translation from big-step\nto small-step style. The linear small-step program can be transformed back to a\nbig-step non-linear program using a third interpreter. A regular path\nexpression is computed for the linear program using Tarjan's algorithm, and\nthis regular expression then guides an interpreter to compute a program path.\nThe transformation is realised by specialisation of the path interpreter. In\nall of the transformation phases, we use an established partial evaluator and\nexploit standard logic program transformation to remove redundant data\nstructures and arguments in predicates and rename predicates to make clear\ntheir link to statements in the original source program.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:23:04 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Gallagher", "John P.", "", "Roskilde University, Denmark and IMDEA Software\n  Institute, Spain"], ["Hermenegildo", "Manuel", "", "IMDEA Software Institute, Spain"], ["Kafle", "Bishoksan", "", "IMDEA Software Institute, Spain"], ["Klemen", "Maximiliano", "", "IMDEA\n  Software Institute, Spain"], ["Garc\u00eda", "Pedro L\u00f3pez", "", "IMDEA Software Institute,\n  Spain"], ["Morales", "Jos\u00e9", "", "IMDEA Software Institute, Spain"]]}, {"id": "2008.02934", "submitter": "EPTCS", "authors": "Emanuele De Angelis (CNR-IASI, Rome, Italy), Fabio Fioravanti (DEC,\n  University \"G. d'Annunzio\" of Chieti-Pescara, Italy), Maurizio Proietti\n  (CNR-IASI, Rome, Italy)", "title": "Transformational Verification of Quicksort", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483", "journal-ref": "EPTCS 320, 2020, pp. 95-109", "doi": "10.4204/EPTCS.320.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many transformation techniques developed for constraint logic programs, also\nknown as constrained Horn clauses (CHCs), have found new useful applications in\nthe field of program verification. In this paper, we work out a nontrivial case\nstudy through the transformation-based verification approach. We consider the\nfamiliar Quicksort program for sorting lists, written in a functional\nprogramming language, and we verify the pre/-postconditions that specify the\nintended correctness properties of the functions defined in the program. We\nverify these properties by: (1) translating them into CHCs, (2) transforming\nthe CHCs by removing all list occurrences, and (3) checking the satisfiability\nof the transformed CHCs by using the Eldarica solver over booleans and\nintegers. The transformation mentioned at Point (2) requires an extension of\nthe algorithms for the elimination of inductively defined data structures\npresented in previous work, because during one stage of the transformation we\nuse as lemmas some properties that have been proved at previous stages.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:23:40 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["De Angelis", "Emanuele", "", "CNR-IASI, Rome, Italy"], ["Fioravanti", "Fabio", "", "DEC,\n  University \"G. d'Annunzio\" of Chieti-Pescara, Italy"], ["Proietti", "Maurizio", "", "CNR-IASI, Rome, Italy"]]}, {"id": "2008.02935", "submitter": "EPTCS", "authors": "Horatiu Cirstea (LORIA, CNRS & INRIA & Universit\\'e de Lorraine),\n  Alexis Grall (LORIA, CNRS & INRIA & Universit\\'e de Lorraine), Dominique\n  M\\'ery (LORIA, CNRS & INRIA & Universit\\'e de Lorraine)", "title": "Generating Distributed Programs from Event-B Models", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483", "journal-ref": "EPTCS 320, 2020, pp. 110-124", "doi": "10.4204/EPTCS.320.8", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed algorithms offer challenges in checking that they meet their\nspecifications. Verification techniques can be extended to deal with the\nverification of safety properties of distributed algorithms. In this paper, we\npresent an approach for combining correct-by-construction approaches and\ntransformations of formal models (Event-B) into programs (DistAlgo) to address\nthe design of verified distributed programs. We define a subset LB (Local\nEvent-B) of the Event-B modelling language restricted to events modelling the\nclassical actions of distributed programs as internal or local computations,\nsending messages and receiving messages. We define then transformations of the\nvarious elements of the LB language into DistAlgo programs. The general\nmethodology consists in starting from a statement of the problem to program and\nthen progressively producing an LB model obtained after several refinement\nsteps of the initial LB model. The derivation of the LB model is not described\nin the current paper and has already been addressed in other works. The\ntransformation of LB models into DistAlgo programs is illustrated through a\nsimple example. The refinement process and the soundness of the transformation\nallow one to produce correct-by-construction distributed programs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:23:53 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Cirstea", "Horatiu", "", "LORIA, CNRS & INRIA & Universit\u00e9 de Lorraine"], ["Grall", "Alexis", "", "LORIA, CNRS & INRIA & Universit\u00e9 de Lorraine"], ["M\u00e9ry", "Dominique", "", "LORIA, CNRS & INRIA & Universit\u00e9 de Lorraine"]]}, {"id": "2008.02936", "submitter": "EPTCS", "authors": "G.W. Hamilton (Dublin City University)", "title": "Distilling Programs to Prove Termination", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483. This work owes a lot\n  to the input of Neil Jones, who provided many useful insights and ideas on\n  the subject matter presented here", "journal-ref": "EPTCS 320, 2020, pp. 140-154", "doi": "10.4204/EPTCS.320.10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of determining whether or not any program terminates was shown to\nbe undecidable by Turing, but recent advances in the area have allowed this\ninformation to be determined for a large class of programs. The classic method\nfor deciding whether a program terminates dates back to Turing himself and\ninvolves finding a ranking function that maps a program state to a well-order,\nand then proving that the result of this function decreases for every possible\nprogram transition. More recent approaches to proving termination have involved\nmoving away from the search for a single ranking function and toward a search\nfor a set of ranking functions; this set is a choice of ranking functions and a\ndisjunctive termination argument is used. In this paper, we describe a new\ntechnique for determining whether programs terminate. Our technique is applied\nto the output of the distillation program transformation that converts programs\ninto a simplified form called distilled form. Programs in distilled form are\nconverted into a corresponding labelled transition system and termination can\nbe demonstrated by showing that all possible infinite traces through this\nlabelled transition system would result in an infinite descent of well-founded\ndata values. We demonstrate our technique on a number of examples, and compare\nit to previous work.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:24:20 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Hamilton", "G. W.", "", "Dublin City University"]]}, {"id": "2008.02937", "submitter": "EPTCS", "authors": "John P. Gallagher (Roskilde University, Denmark and IMDEA Software\n  Institute, Spain), Robert Gl\\\"uck (Copenhagen University, Denmark)", "title": "An Experiment Combining Specialization with Abstract Interpretation", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483", "journal-ref": "EPTCS 320, 2020, pp. 155-158", "doi": "10.4204/EPTCS.320.11", "report-no": null, "categories": "cs.PL cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was previously shown that control-flow refinement can be achieved by a\nprogram specializer incorporating property-based abstraction, to improve\ntermination and complexity analysis tools. We now show that this purpose-built\nspecializer can be reconstructed in a more modular way, and that the previous\nresults can be achieved using an off-the-shelf partial evaluation tool, applied\nto an abstract interpreter. The key feature of the abstract interpreter is the\nabstract domain, which is the product of the property-based abstract domain\nwith the concrete domain. This language-independent framework provides a\npractical approach to implementing a variety of powerful specializers, and\ncontributes to a stream of research on using interpreters and specialization to\nachieve program transformations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:24:31 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Gallagher", "John P.", "", "Roskilde University, Denmark and IMDEA Software\n  Institute, Spain"], ["Gl\u00fcck", "Robert", "", "Copenhagen University, Denmark"]]}, {"id": "2008.02939", "submitter": "EPTCS", "authors": "Philipp R\\\"ummer (Uppsala University, Sweden)", "title": "Competition Report: CHC-COMP-20", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483", "journal-ref": "EPTCS 320, 2020, pp. 197-219", "doi": "10.4204/EPTCS.320.15", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CHC-COMP-20 is the third competition of solvers for Constrained Horn Clauses.\nIn this year, 9 solvers participated at the competition, and were evaluated in\nfour separate tracks on problems in linear integer arithmetic, linear real\narithmetic, and arrays. The competition was run in the first week of May 2020\nusing the StarExec computing cluster. This report gives an overview of the\ncompetition design, explains the organisation of the competition, and presents\nthe competition results.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:24:57 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["R\u00fcmmer", "Philipp", "", "Uppsala University, Sweden"]]}, {"id": "2008.03050", "submitter": "Esra Erdem", "authors": "Esra Erdem, Muge Fidan, David Manlove, Patrick Prosser", "title": "A General Framework for Stable Roommates Problems using Answer Set\n  Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Stable Roommates problem (SR) is characterized by the preferences of\nagents over other agents as roommates: each agent ranks all others in strict\norder of preference. A solution to SR is then a partition of the agents into\npairs so that each pair shares a room, and there is no pair of agents that\nwould block this matching (i.e., who prefers the other to their roommate in the\nmatching). There are interesting variations of SR that are motivated by\napplications (e.g., the preference lists may be incomplete (SRI) and involve\nties (SRTI)), and that try to find a more fair solution (e.g., Egalitarian SR).\nUnlike the Stable Marriage problem, every SR instance is not guaranteed to have\na solution. For that reason, there are also variations of SR that try to find a\ngood-enough solution (e.g., Almost SR). Most of these variations are NP-hard.\nWe introduce a formal framework, called SRTI-ASP, utilizing the logic\nprogramming paradigm Answer Set Programming, that is provable and general\nenough to solve many of such variations of SR. Our empirical analysis shows\nthat SRTI-ASP is also promising for applications. This paper is under\nconsideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 09:12:36 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Erdem", "Esra", ""], ["Fidan", "Muge", ""], ["Manlove", "David", ""], ["Prosser", "Patrick", ""]]}, {"id": "2008.03103", "submitter": "Giulio Guerrieri", "authors": "Giulio Guerrieri, Luc Pellissier, Lorenzo Tortora de Falco", "title": "Gluing resource proof-structures: inhabitation and inverting the Taylor\n  expansion", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.07936", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Multiplicative-Exponential Linear Logic (MELL) proof-structure can be\nexpanded into a set of resource proof-structures: its Taylor expansion. We\nintroduce a new criterion characterizing those sets of resource\nproof-structures that are part of the Taylor expansion of some MELL\nproof-structure, through a rewriting system acting both on resource and MELL\nproof-structures. As a consequence, we also prove semi-decidability of the type\ninhabitation problem for cut-free MELL proof-structures.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:33:44 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 17:58:07 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 17:59:05 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 16:57:47 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Guerrieri", "Giulio", ""], ["Pellissier", "Luc", ""], ["de Falco", "Lorenzo Tortora", ""]]}, {"id": "2008.03115", "submitter": "Jamie Tucker-Foltz", "authors": "Jamie Tucker-Foltz", "title": "Approximating Constraint Satisfaction Problems Symmetrically", "comments": "91 pages, 6 figures, master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis investigates the extent to which the optimal value of a\nconstraint satisfaction problem (CSP) can be approximated by some sentence of\nfixed point logic with counting (FPC). It is known that, assuming $\\mathsf{P}\n\\neq \\mathsf{NP}$ and the Unique Games Conjecture, the best polynomial time\napproximation algorithm for any CSP is given by solving and rounding a specific\nsemidefinite programming relaxation. We prove an analogue of this result for\nalgorithms that are definable as FPC-interpretations, which holds without the\nassumption that $\\mathsf{P} \\neq \\mathsf{NP}$. While we are not able to drop\n(an FPC-version of) the Unique Games Conjecture as an assumption, we do present\nsome partial results toward proving it. Specifically, we give a novel\nconstruction which shows that, for all $\\alpha > 0$, there exists a positive\ninteger $q = \\text{poly}(\\frac{1}{\\alpha})$ such that no there is no\nFPC-interpretation giving an $\\alpha$-approximation of Unique Games on a label\nset of size $q$.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 19:48:25 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Tucker-Foltz", "Jamie", ""]]}, {"id": "2008.03172", "submitter": "Diedrich Wolter", "authors": "Mena Leemhuis and \\\"Ozg\\\"ur L. \\\"Oz\\c{c}ep and Diedrich Wolter", "title": "Orthologics for Cones", "comments": "extended version of AI2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications that use knowledge representation (KR) techniques, in\nparticular those that combine data-driven and logic methods, the domain of\nobjects is not an abstract unstructured domain, but it exhibits a dedicated,\ndeep structure of geometric objects. One example is the class of convex sets\nused to model natural concepts in conceptual spaces, which also links via\nconvex optimization techniques to machine learning. In this paper we study\nlogics for such geometric structures. Using the machinery of lattice theory, we\ndescribe an extension of minimal orthologic with a partial modularity rule that\nholds for closed convex cones. This logic combines a feasible data structure\n(exploiting convexity/conicity) with sufficient expressivity, including full\northonegation (exploiting conicity).\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 13:28:27 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Leemhuis", "Mena", ""], ["\u00d6z\u00e7ep", "\u00d6zg\u00fcr L.", ""], ["Wolter", "Diedrich", ""]]}, {"id": "2008.03210", "submitter": "Abhishek Kulkarni", "authors": "Abhishek N. Kulkarni and Jie Fu", "title": "A Theory of Hypergames on Graphs for Synthesizing Dynamic Cyber Defense\n  with Deception", "comments": "32 pages, 10 figures, 2 tables, Accepted Book Chapter in \"Game Theory\n  and Machine Learning for Cyber Security\" by Wiley-IEEE press, Editors:\n  Charles A. Kamhoua, Christopher D. Kiekintveld, Fei Fang, Quanyan Zhu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we present an approach using formal methods to synthesize\nreactive defense strategy in a cyber network, equipped with a set of decoy\nsystems. We first generalize formal graphical security models--attack\ngraphs--to incorporate defender's countermeasures in a game-theoretic model,\ncalled an attack-defend game on graph. This game captures the dynamic\ninteractions between the defender and the attacker and their defense/attack\nobjectives in formal logic. Then, we introduce a class of hypergames to model\nasymmetric information created by decoys in the attacker-defender interactions.\nGiven qualitative security specifications in formal logic, we show that the\nsolution concepts from hypergames and reactive synthesis in formal methods can\nbe extended to synthesize effective dynamic defense strategy using cyber\ndeception. The strategy takes the advantages of the misperception of the\nattacker to ensure security specification is satisfied, which may not be\nsatisfiable when the information is symmetric.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:59:28 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Kulkarni", "Abhishek N.", ""], ["Fu", "Jie", ""]]}, {"id": "2008.03301", "submitter": "Farhad Shakerin", "authors": "Farhad Shakerin, Gopal Gupta", "title": "White-box Induction From SVM Models: Explainable AI with Logic\n  Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of inducing logic programs that explain models\nlearned by the support vector machine (SVM) algorithm. The top-down sequential\ncovering inductive logic programming (ILP) algorithms (e.g., FOIL) apply\nhill-climbing search using heuristics from information theory. A major issue\nwith this class of algorithms is getting stuck in a local optimum. In our new\napproach, however, the data-dependent hill-climbing search is replaced with a\nmodel-dependent search where a globally optimal SVM model is trained first,\nthen the algorithm looks into support vectors as the most influential data\npoints in the model, and induces a clause that would cover the support vector\nand points that are most similar to that support vector. Instead of defining a\nfixed hypothesis search space, our algorithm makes use of SHAP, an\nexample-specific interpreter in explainable AI, to determine a relevant set of\nfeatures. This approach yields an algorithm that captures SVM model's\nunderlying logic and outperforms %GG: the FOIL algorithm --> other ILP\nalgorithms other ILP algorithms in terms of the number of induced clauses and\nclassification evaluation metrics. This paper is under consideration for\npublication in the journal of \"Theory and practice of logic programming\".\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 23:07:14 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Shakerin", "Farhad", ""], ["Gupta", "Gopal", ""]]}, {"id": "2008.03489", "submitter": "Christoph Wernhard", "authors": "Christoph Wernhard", "title": "Craig Interpolation with Clausal First-Order Tableaux", "comments": "This article supersedes the first part (sections 1-8) of\n  arXiv:1802.04982", "journal-ref": null, "doi": "10.1007/s10817-021-09590-3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop foundations for computing Craig-Lyndon interpolants of two given\nformulas with first-order theorem provers that construct clausal tableaux.\nProvers that can be understood in this way include efficient machine-oriented\nsystems based on calculi of two families: goal-oriented such as model\nelimination and the connection method, and bottom-up such as the hypertableau\ncalculus. We present the first interpolation method for first-order proofs\nrepresented by closed tableaux that proceeds in two stages, similar to known\ninterpolation methods for resolution proofs. The first stage is an induction on\nthe tableau structure, which is sufficient to compute propositional\ninterpolants. We show that this can linearly simulate different prominent\npropositional interpolation methods that operate by an induction on a\nresolution deduction tree. In the second stage, interpolant lifting, quantified\nvariables that replace certain terms (constants and compound terms) by\nvariables are introduced. We justify the correctness of interpolant lifting\n(for the case without built-in equality) abstractly on the basis of Herbrand's\ntheorem and for a different characterization of the formulas to be lifted than\nin the literature. In addition, we discuss various subtle aspects that are\nrelevant for the investigation and practical realization of first-order\ninterpolation based on clausal tableaux.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 10:44:53 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 09:33:37 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wernhard", "Christoph", ""]]}, {"id": "2008.03496", "submitter": "Volkan Patoglu", "authors": "Momina Rizwan, Volkan Patoglu, Esra Erdem", "title": "Human Robot Collaborative Assembly Planning: An Answer Set Programming\n  Approach", "comments": "36th International Conference on Logic Programming (ICLP 2020),\n  University Of Calabria, Rende (CS), Italy, September 2020, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For planning an assembly of a product from a given set of parts, robots\nnecessitate certain cognitive skills: high-level planning is needed to decide\nthe order of actuation actions, while geometric reasoning is needed to check\nthe feasibility of these actions. For collaborative assembly tasks with humans,\nrobots require further cognitive capabilities, such as commonsense reasoning,\nsensing, and communication skills, not only to cope with the uncertainty caused\nby incomplete knowledge about the humans' behaviors but also to ensure safer\ncollaborations. We propose a novel method for collaborative assembly planning\nunder uncertainty, that utilizes hybrid conditional planning extended with\ncommonsense reasoning and a rich set of communication actions for collaborative\ntasks. Our method is based on answer set programming. We show the applicability\nof our approach in a real-world assembly domain, where a bi-manual Baxter robot\ncollaborates with a human teammate to assemble furniture. This manuscript is\nunder consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 11:31:36 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rizwan", "Momina", ""], ["Patoglu", "Volkan", ""], ["Erdem", "Esra", ""]]}, {"id": "2008.03526", "submitter": "Antonius Weinzierl", "authors": "Antonius Weinzierl, Richard Taupe and Gerhard Friedrich", "title": "Advancing Lazy-Grounding ASP Solving Techniques -- Restarts, Phase\n  Saving, Heuristics, and More", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer-Set Programming (ASP) is a powerful and expressive knowledge\nrepresentation paradigm with a significant number of applications in\nlogic-based AI. The traditional ground-and-solve approach, however, requires\nASP programs to be grounded upfront and thus suffers from the so-called\ngrounding bottleneck (i.e., ASP programs easily exhaust all available memory\nand thus become unsolvable). As a remedy, lazy-grounding ASP solvers have been\ndeveloped, but many state-of-the-art techniques for grounded ASP solving have\nnot been available to them yet. In this work we present, for the first time,\nadaptions to the lazy-grounding setting for many important techniques, like\nrestarts, phase saving, domain-independent heuristics, and learned-clause\ndeletion. Furthermore, we investigate their effects and in general observe a\nlarge improvement in solving capabilities and also uncover negative effects in\ncertain cases, indicating the need for portfolio solving as known from other\nsolvers. Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 13:55:36 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Weinzierl", "Antonius", ""], ["Taupe", "Richard", ""], ["Friedrich", "Gerhard", ""]]}, {"id": "2008.03573", "submitter": "Esra Erdem", "authors": "Aysu Bogatarkan and Esra Erdem", "title": "Explanation Generation for Multi-Modal Multi-Agent Path Finding with\n  Optimal Resource Utilization using Answer Set Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-agent path finding (MAPF) problem is a combinatorial search problem\nthat aims at finding paths for multiple agents (e.g., robots) in an environment\n(e.g., an autonomous warehouse) such that no two agents collide with each\nother, and subject to some constraints on the lengths of paths. We consider a\ngeneral version of MAPF, called mMAPF, that involves multi-modal transportation\nmodes (e.g., due to velocity constraints) and consumption of different types of\nresources (e.g., batteries). The real-world applications of mMAPF require\nflexibility (e.g., solving variations of mMAPF) as well as explainability. Our\nearlier studies on mMAPF have focused on the former challenge of flexibility.\nIn this study, we focus on the latter challenge of explainability, and\nintroduce a method for generating explanations for queries regarding the\nfeasibility and optimality of solutions, the nonexistence of solutions, and the\nobservations about solutions. Our method is based on answer set programming.\nThis paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 18:34:34 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bogatarkan", "Aysu", ""], ["Erdem", "Esra", ""]]}, {"id": "2008.03584", "submitter": "Tejas Bhojraj", "authors": "Tejas Bhojraj", "title": "Quantum algorithmic randomness", "comments": "This is the final version, to appear in a journal. 17 pages", "journal-ref": "Journal of Mathematical Physics (Vol.62, Issue 2), 2021", "doi": "10.1063/5.0003351", "report-no": null, "categories": "quant-ph cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Martin-L\\\"of randomness (q-MLR) for infinite qubit sequences was\nintroduced by Nies and Scholz. We define a notion of quantum Solovay randomness\nwhich is equivalent to q-MLR. The proof of this goes through a purely linear\nalgebraic result about approximating density matrices by subspaces. We then\nshow that random states form a convex set. Martin-L\\\"of absolute continuity is\nshown to be a special case of q-MLR. Quantum Schnorr randomness is introduced.\nA quantum analogue of the law of large numbers is shown to hold for quantum\nSchnorr random states.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 19:28:01 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 18:59:49 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bhojraj", "Tejas", ""]]}, {"id": "2008.03714", "submitter": "Ekaterina Komendantskaya Dr", "authors": "Ekaterina Komendantskaya and Dmitry Rozplokhas and Henning Basold", "title": "The New Normal: We Cannot Eliminate Cuts in Coinductive Calculi, But We\n  Can Explore Them", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": "Theory and Practice of Logic Programming, 2020", "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequent calculi, cut elimination is a property that guarantees that any\nprovable formula can be proven analytically. For example, Gentzen's classical\nand intuitionistic calculi LK and LJ enjoy cut elimination. The property is\nless studied in coinductive extensions of sequent calculi. In this paper, we\nuse coinductive Horn clause theories to show that cut is not eliminable in a\ncoinductive extension of LJ, a system we call CLJ. We derive two further\npractical results from this study. We show that CoLP by Gupta et al. gives rise\nto cut-free proofs in CLJ with fixpoint terms, and we formulate and implement a\nnovel method of coinductive theory exploration that provides several heuristics\nfor discovery of cut formulae in CLJ.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 12:27:13 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Komendantskaya", "Ekaterina", ""], ["Rozplokhas", "Dmitry", ""], ["Basold", "Henning", ""]]}, {"id": "2008.03719", "submitter": "Daniel Ritter", "authors": "Daniel Ritter and Jan Bro{\\ss}", "title": "A Rule-based Language for Application Integration", "comments": "14 pages, work from 2013/14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although message-based (business) application integration is based on\norchestrated message flows, current modeling languages exclusively cover (parts\nof) the control flow, while under-specifying the data flow. Especially for more\ndata-intensive integration scenarios, this fact adds to the inherent data\nprocessing weakness in conventional integration systems.\n  We argue that with a more data-centric integration language and a relational\nlogic based implementation of integration semantics, optimizations from the\ndata management domain(e.g., data partitioning, parallelization) can be\ncombined with common integration processing (e.g., scatter/gather,\nsplitter/gather). With the Logic Integration Language (LiLa) we redefine\nintegration logic tailored for data-intensive processing and propose a novel\napproach to data-centric integration modeling, from which we derive the\ncontrol-and data flow and apply them to a conventional integration system.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 13:02:12 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ritter", "Daniel", ""], ["Bro\u00df", "Jan", ""]]}, {"id": "2008.03770", "submitter": "Anirban Majumdar", "authors": "Nathalie Bertrand, Patricia Bouyer, Anirban Majumdar", "title": "Synthesizing safe coalition strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent games with a fixed number of agents have been thoroughly studied,\nwith various solution concepts and objectives for the agents. In this paper, we\nconsider concurrent games with an arbitrary number of agents, and study the\nproblem of synthesizing a coalition strategy to achieve a global safety\nobjective. The problem is non-trivial since the agents do not know a priori how\nmany they are when they start the game. We prove that the existence of a safe\narbitrary-large coalition strategy for safety objectives is a PSPACE-hard\nproblem that can be decided in exponential space.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 17:21:46 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 13:46:16 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Bertrand", "Nathalie", ""], ["Bouyer", "Patricia", ""], ["Majumdar", "Anirban", ""]]}, {"id": "2008.04008", "submitter": "Rafael Kiesel", "authors": "Thomas Eiter and Rafael Kiesel", "title": "ASP(AC): Answer Set Programming with Algebraic Constraints", "comments": "32 pages, 16 pages are appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted Logic is a powerful tool for the specification of calculations over\nsemirings that depend on qualitative information. Using a novel combination of\nWeighted Logic and Here-and-There (HT) Logic, in which this dependence is based\non intuitionistic grounds, we introduce Answer Set Programming with Algebraic\nConstraints (ASP(AC)), where rules may contain constraints that compare\nsemiring values to weighted formula evaluations. Such constraints provide\nstreamlined access to a manifold of constructs available in ASP, like\naggregates, choice constraints, and arithmetic operators. They extend some of\nthem and provide a generic framework for defining programs with algebraic\ncomputation, which can be fruitfully used e.g. for provenance semantics of\ndatalog programs. While undecidable in general, expressive fragments of ASP(AC)\ncan be exploited for effective problem-solving in a rich framework. This work\nis under consideration for acceptance in Theory and Practice of Logic\nProgramming.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 10:20:49 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Eiter", "Thomas", ""], ["Kiesel", "Rafael", ""]]}, {"id": "2008.04049", "submitter": "Florian Funke", "authors": "Simon Jantsch, Hans Harder, Florian Funke, Christel Baier", "title": "SWITSS: Computing Small Witnessing Subsystems", "comments": "9 pages; accepted for publication in the Proceedings of FMCAD'20\n  (https://fmcad.org/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Witnessing subsystems for probabilistic reachability thresholds in discrete\nMarkovian models are an important concept both as diagnostic information on why\na property holds, and as input to refinement algorithms. We present SWITSS, a\ntool for the computation of Small WITnessing SubSystems. SWITSS implements\nexact and heuristic approaches based on reducing the problem to (mixed integer)\nlinear programming. Returned subsystems can automatically be rendered\ngraphically and are accompanied with a certificate which proves that the\nsubsystem is indeed a witness.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 12:21:26 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Jantsch", "Simon", ""], ["Harder", "Hans", ""], ["Funke", "Florian", ""], ["Baier", "Christel", ""]]}, {"id": "2008.04108", "submitter": "Jessica Zangari", "authors": "Giovambattista Ianni, Francesco Pacenza and Jessica Zangari", "title": "Incremental maintenance of overgrounded logic programs with tailored\n  simplifications", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The repeated execution of reasoning tasks is desirable in many applicative\nscenarios, such as stream reasoning and event processing. When using answer set\nprogramming in such contexts, one can avoid the iterative generation of ground\nprograms thus achieving a significant payoff in terms of computing time.\nHowever, this may require some additional amount of memory and/or the manual\naddition of operational directives in the declarative knowledge base at hand.\nWe introduce a new strategy for generating series of monotonically growing\npropositional programs. The proposed overgrounded programs with tailoring\n(OPTs) can be updated and reused in combination with consecutive inputs. With\nrespect to earlier approaches, our tailored simplification technique reduces\nthe size of instantiated programs. A maintained OPT slowly grows in size from\nan iteration to another while the update cost decreases, especially in later\niterations. In this paper we formally introduce tailored embeddings, a family\nof equivalence-preserving ground programs which are at the theoretical basis of\nOPTs and we describe their properties. We then illustrate an OPT update\nalgorithm and report about our implementation and its performance. This paper\nis under consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:50:11 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ianni", "Giovambattista", ""], ["Pacenza", "Francesco", ""], ["Zangari", "Jessica", ""]]}, {"id": "2008.04126", "submitter": "Esra Erdem", "authors": "Yusuf Izmirlioglu, Esra Erdem", "title": "Reasoning about Cardinal Directions between 3-Dimensional Extended\n  Objects using Answer Set Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 29 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel formal framework (called 3D-nCDC-ASP) to represent and\nreason about cardinal directions between extended objects in 3-dimensional (3D)\nspace, using Answer Set Programming (ASP). 3D-nCDC-ASP extends Cardinal\nDirectional Calculus (CDC) with a new type of default constraints, and nCDC-ASP\nto 3D. 3D-nCDC-ASP provides a flexible platform offering different types of\nreasoning: Nonmonotonic reasoning with defaults, checking consistency of a set\nof constraints on 3D cardinal directions between objects, explaining\ninconsistencies, and inferring missing CDC relations. We prove the soundness of\n3D-nCDC-ASP, and illustrate its usefulness with applications. This paper is\nunder consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:38:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Izmirlioglu", "Yusuf", ""], ["Erdem", "Esra", ""]]}, {"id": "2008.04165", "submitter": "Alasdair Hill", "authors": "Alasdair Hill, Ekaterina Komendantskaya, Ronald P. A. Petrick", "title": "Proof-Carrying Plans: a Resource Logic for AI Planning", "comments": "PPDP 2020, 13 pages, 9 figures", "journal-ref": null, "doi": "10.1145/3414080.3414094", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trends in AI verification and Explainable AI have raised the question\nof whether AI planning techniques can be verified. In this paper, we present a\nnovel resource logic, the Proof Carrying Plans (PCP) logic that can be used to\nverify plans produced by AI planners. The PCP logic takes inspiration from\nexisting resource logics (such as Linear logic and Separation logic) as well as\nHoare logic when it comes to modelling states and resource-aware plan\nexecution. It also capitalises on the Curry-Howard approach to logics, in its\ntreatment of plans as functions and plan pre- and post-conditions as types.\nThis paper presents two main results. From the theoretical perspective, we show\nthat the PCP logic is sound relative to the standard possible world semantics\nused in AI planning. From the practical perspective, we present a complete Agda\nformalisation of the PCP logic and of its soundness proof. Moreover, we\nshowcase the Curry-Howard, or functional, value of this implementation by\nsupplementing it with the library that parses AI plans into Agda's proofs\nautomatically. We provide evaluation of this library and the resulting Agda\nfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:45:52 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 03:49:19 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Hill", "Alasdair", ""], ["Komendantskaya", "Ekaterina", ""], ["Petrick", "Ronald P. A.", ""]]}, {"id": "2008.04193", "submitter": "Titouan Carette", "authors": "Titouan Carette and Emmanuel Jeandel", "title": "On a recipe for quantum graphical languages", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2020.118", "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different graphical calculi have been proposed to represent quantum\ncomputation. First the ZX- calculus [4], followed by the ZW-calculus [12] and\nthen the ZH-calculus [1]. We can wonder if new Z*-calculi will continue to be\nproposed forever. This article answers negatively. All those language share a\ncommon core structure we call Z*-algebras. We classify Z*-algebras up to\nisomorphism in two dimensional Hilbert spaces and show that they are all\nvariations of the aforementioned calculi. We do the same for linear relations\nand show that the calculus of [2] is essentially the unique one.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:26:08 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Carette", "Titouan", ""], ["Jeandel", "Emmanuel", ""]]}, {"id": "2008.04232", "submitter": "Fabio Mogavero Ph.D.", "authors": "Massimo Benerecetti, Daniele Dell'Erba, Marco Faella, and Fabio\n  Mogavero", "title": "From Quasi-Dominions to Progress Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we revisit the approaches to the solution of parity games based\non progress measures and show how the notion of quasi dominions can be\nintegrated with those approaches. The idea is that, while progress measure\nbased techniques typically focus on one of the two players, little information\nis gathered on the other player during the solution process. Adding quasi\ndominions provides additional information on this player that can be leveraged\nto accelerate convergence to a progress measure. To accommodate quasi\ndominions, however, a non trivial refinement of the approach is necessary. In\nparticular, we need to introduce a novel notion of measure and a new approach\nto prove correctness of the resulting solution technique.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 16:10:23 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Benerecetti", "Massimo", ""], ["Dell'Erba", "Daniele", ""], ["Faella", "Marco", ""], ["Mogavero", "Fabio", ""]]}, {"id": "2008.04534", "submitter": "Thomas Ehrhard", "authors": "Thomas Ehrhard (IRIF)", "title": "Upper approximating probabilities of convergence in probabilistic\n  coherence spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a theory of probabilistic coherence spaces equipped with an\nadditional extensional structure and apply it to approximating probability of\nconvergence of ground type programs of probabilistic PCF whose free variables\nare of ground types. To this end we define an adapted version of Krivine\nMachine which computes polynomial approximations of the semantics of these\nprograms in the model. These polynomials provide approximations from below and\nfrom above of probabilities of convergence; this is made possible by extending\nthe language with an error symbol which is extensionally maximal in the model.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:17:58 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ehrhard", "Thomas", "", "IRIF"]]}, {"id": "2008.04613", "submitter": "Gethin Norman", "authors": "Marta Kwiatkowska, Gethin Norman, David Parker and Gabriel Santos", "title": "Automatic Verification of Concurrent Stochastic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated verification techniques for stochastic games allow formal reasoning\nabout systems that feature competitive or collaborative behaviour among\nrational agents in uncertain or probabilistic settings. Existing tools and\ntechniques focus on turn-based games, where each state of the game is\ncontrolled by a single player, and on zero-sum properties, where two players or\ncoalitions have directly opposing objectives. In this paper, we present\nautomated verification techniques for concurrent stochastic games (CSGs), which\nprovide a more natural model of concurrent decision making and interaction. We\nalso consider (social welfare) Nash equilibria, to formally identify scenarios\nwhere two players or coalitions with distinct goals can collaborate to optimise\ntheir joint performance. We propose an extension of the temporal logic rPATL\nfor specifying quantitative properties in this setting and present\ncorresponding algorithms for verification and strategy synthesis for a variant\nof stopping games. For finite-horizon properties the computation is exact,\nwhile for infinite-horizon it is approximate using value iteration. For\nzero-sum properties it requires solving matrix games via linear programming,\nand for equilibria-based properties we find social welfare or social cost Nash\nequilibria of bimatrix games via the method of labelled polytopes through an\nSMT encoding. We implement this approach in PRISM-games, which required\nextending the tool's modelling language for CSGs, and apply it to case studies\nfrom domains including robotics, computer security and computer networks,\nexplicitly demonstrating the benefits of both CSGs and equilibria-based\nproperties.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 10:24:11 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 14:53:31 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kwiatkowska", "Marta", ""], ["Norman", "Gethin", ""], ["Parker", "David", ""], ["Santos", "Gabriel", ""]]}, {"id": "2008.05102", "submitter": "Aditya Aniruddha Shrotri", "authors": "Supratik Chakraborty, Aditya A. Shrotri and Moshe Y. Vardi", "title": "On Uniformly Sampling Traces of a Transition System (Extended Version)", "comments": "Extended version of paper that will appear in proceedings of\n  International Conference on Computer-Aided Design (ICCAD '20); changed wrong\n  text color in sec 7; added 'extended version'", "journal-ref": null, "doi": "10.1145/3400302.3415707", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in constrained random verification (CRV) concerns generation of\ninput stimuli that result in good coverage of the system's runs in targeted\ncorners of its behavior space. Existing CRV solutions however provide no formal\nguarantees on the distribution of the system's runs. In this paper, we take a\nfirst step towards solving this problem. We present an algorithm based on\nAlgebraic Decision Diagrams for sampling bounded traces (i.e. sequences of\nstates) of a sequential circuit with provable uniformity (or bias) guarantees,\nwhile satisfying given constraints. We have implemented our algorithm in a tool\ncalled TraceSampler. Extensive experiments show that TraceSampler outperforms\nalternative approaches that provide similar uniformity guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 04:28:26 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 00:59:24 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chakraborty", "Supratik", ""], ["Shrotri", "Aditya A.", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "2008.05335", "submitter": "Luca Geatti", "authors": "Alessandro Cimatti, Luca Geatti, Nicola Gigante, Angelo Montanari and\n  Stefano Tonetta", "title": "Reactive Synthesis from Extended Bounded Response LTL Specifications", "comments": "Extended Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive synthesis is a key technique for the design of\ncorrect-by-construction systems and has been thoroughly investigated in the\nlast decades. It consists in the synthesis of a controller that reacts to\nenvironment's inputs satisfying a given temporal logic specification. Common\napproaches are based on the explicit construction of automata and on their\ndeterminization, which limit their scalability.\n  In this paper, we introduce a new fragment of Linear Temporal Logic, called\nExtended Bounded Response LTL (\\LTLEBR), that allows one to combine bounded and\nuniversal unbounded temporal operators (thus covering a large set of practical\ncases), and we show that reactive synthesis from \\LTLEBR specifications can be\nreduced to solving a safety game over a deterministic symbolic automaton built\ndirectly from the specification. We prove the correctness of the proposed\napproach and we successfully evaluate it on various benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 14:13:14 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Cimatti", "Alessandro", ""], ["Geatti", "Luca", ""], ["Gigante", "Nicola", ""], ["Montanari", "Angelo", ""], ["Tonetta", "Stefano", ""]]}, {"id": "2008.05638", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez and Muhammad Najib and Giuseppe Perelli and Michael\n  Wooldridge", "title": "Automated Temporal Equilibrium Analysis: Verification and Synthesis of\n  Multi-Player Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of multi-agent systems, the rational verification problem is\nconcerned with checking which temporal logic properties will hold in a system\nwhen its constituent agents are assumed to behave rationally and strategically\nin pursuit of individual objectives. Typically, those objectives are expressed\nas temporal logic formulae which the relevant agent desires to see satisfied.\nUnfortunately, rational verification is computationally complex, and requires\nspecialised techniques in order to obtain practically useable implementations.\nIn this paper, we present such a technique. This technique relies on a\nreduction of the rational verification problem to the solution of a collection\nof parity games. Our approach has been implemented in the Equilibrium\nVerification Environment (EVE) system. The EVE system takes as input a model of\na concurrent/multi-agent system represented using the Simple Reactive Modules\nLanguage (SRML), where agent goals are represented as Linear Temporal Logic\n(LTL) formulae, together with a claim about the equilibrium behaviour of the\nsystem, also expressed as an LTL formula. EVE can then check whether the LTL\nclaim holds on some (or every) computation of the system that could arise\nthrough agents choosing Nash equilibrium strategies; it can also check whether\na system has a Nash equilibrium, and synthesise individual strategies for\nplayers in the multi-player game. After presenting our basic framework, we\ndescribe our new technique and prove its correctness. We then describe our\nimplementation in the EVE system, and present experimental results which show\nthat EVE performs favourably in comparison to other existing tools that support\nrational verification.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:43:31 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gutierrez", "Julian", ""], ["Najib", "Muhammad", ""], ["Perelli", "Giuseppe", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2008.05643", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez and Aniello Murano and Giuseppe Perelli and Sasha\n  Rubin and Thomas Steeples and Michael Wooldridge", "title": "Equilibria for Games with Combined Qualitative and Quantitative\n  Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overall aim of our research is to develop techniques to reason about the\nequilibrium properties of multi-agent systems. We model multi-agent systems as\nconcurrent games, in which each player is a process that is assumed to act\nindependently and strategically in pursuit of personal preferences. In this\narticle, we study these games in the context of finite-memory strategies, and\nwe assume players' preferences are defined by a qualitative and a quantitative\nobjective, which are related by a lexicographic order: a player first prefers\nto satisfy its qualitative objective (given as a formula of Linear Temporal\nLogic) and then prefers to minimise costs (given by a mean-payoff function).\nOur main result is that deciding the existence of a strict epsilon Nash\nequilibrium in such games is 2ExpTime-complete (and hence decidable), even if\nplayers' deviations are implemented as infinite-memory strategies.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:56:24 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gutierrez", "Julian", ""], ["Murano", "Aniello", ""], ["Perelli", "Giuseppe", ""], ["Rubin", "Sasha", ""], ["Steeples", "Thomas", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2008.05647", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez and Giuseppe Perelli and Michael Wooldridge", "title": "Multi-Player Games with LDL Goals over Finite Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Dynamic Logic on finite traces LDLf is a powerful logic for reasoning\nabout the behaviour of concurrent and multi-agent systems.\n  In this paper, we investigate techniques for both the characterisation and\nverification of equilibria in multi-player games with goals/objectives\nexpressed using logics based on LDLf. This study builds upon a generalisation\nof Boolean games, a logic-based game model of multi-agent systems where players\nhave goals succinctly represented in a logical way.\n  Because LDLf goals are considered, in the settings we study -- Reactive\nModules games and iterated Boolean games with goals over finite traces --\nplayers' goals can be defined to be regular properties while achieved in a\nfinite, but arbitrarily large, trace.\n  In particular, using alternating automata, the paper investigates\nautomata-theoretic approaches to the characterisation and verification of (pure\nstrategy Nash) equilibria, shows that the set of Nash equilibria in\nmulti-player games with LDLf objectives is regular, and provides complexity\nresults for the associated automata constructions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:11:06 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gutierrez", "Julian", ""], ["Perelli", "Giuseppe", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2008.05800", "submitter": "Noleen K\\\"ohler", "authors": "Isolde Adler (1), Noleen K\\\"ohler (1) and Pan Peng (2) ((1) University\n  of Leeds, (2) University of Sheffield)", "title": "On Testability of First-Order Properties in Bounded-Degree Graphs", "comments": "37 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study property testing of properties that are definable in first-order\nlogic (FO) in the bounded-degree graph and relational structure models. We show\nthat any FO property that is defined by a formula with quantifier prefix\n$\\exists^*\\forall^*$ is testable (i.e., testable with constant query\ncomplexity), while there exists an FO property that is expressible by a formula\nwith quantifier prefix $\\forall^*\\exists^*$ that is not testable. In the dense\ngraph model, a similar picture is long known (Alon, Fischer, Krivelevich,\nSzegedy, Combinatorica 2000), despite the very different nature of the two\nmodels. In particular, we obtain our lower bound by a first-order formula that\ndefines a class of bounded-degree expanders, based on zig-zag products of\ngraphs. We expect this to be of independent interest. We then prove testability\nof some first-order properties that speak about isomorphism types of\nneighbourhoods, including testability of $1$-neighbourhood-freeness, and\n$r$-neighbourhood-freeness under a mild assumption on the degrees.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:21:46 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 15:23:38 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Adler", "Isolde", ""], ["K\u00f6hler", "Noleen", ""], ["Peng", "Pan", ""]]}, {"id": "2008.06351", "submitter": "Richard Moot", "authors": "Richard Moot", "title": "Partial Orders, Residuation, and First-Order Linear Logic", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We will investigate proof-theoretic and linguistic aspects of first-order\nlinear logic. We will show that adding partial order constraints in such a way\nthat each sequent defines a unique linear order on the antecedent formulas of a\nsequent allows us to define many useful logical operators. In addition, the\npartial order constraints improve the efficiency of proof search.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 13:06:21 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Moot", "Richard", ""]]}, {"id": "2008.06410", "submitter": "Dileep A", "authors": "A. Dileep, Kuldeep S. Meel, Ammar F. Sabili", "title": "Induction Models on \\mathbb{N}", "comments": "22 pages. This is the full version of the paper published in\n  proceedings of International Conference on Logic for Programming Artificial\n  Intelligence and Reasoning (LPAR), 2020", "journal-ref": "LPAR-23: 23rd International Conference on Logic for Programming,\n  Artificial Intelligence and Reasoning, 2020, Vol. 73, Pages 169-190", "doi": "10.29007/kvp3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical induction is a fundamental tool in computer science and\nmathematics. Henkin initiated the study of formalization of mathematical\ninduction restricted to the setting when the base case B is set to singleton\nset containing 0 and a unary generating function S. The usage of mathematical\ninduction often involves wider set of base cases and k-ary generating functions\nwith different structural restrictions. While subsequent studies have shown\nseveral Induction Models to be equivalent, there does not exist precise logical\ncharacterization of reduction and equivalence among different Induction Models.\nIn this paper, we generalize the definition of Induction Model and demonstrate\nexistence and construction of S for given B and vice versa. We then provide a\nformal characterization of the reduction among different Induction Models that\ncan allow proofs in one Induction Models to be expressed as proofs in another\nInduction Models. The notion of reduction allows us to capture equivalence\namong Induction Models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:13:31 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Dileep", "A.", ""], ["Meel", "Kuldeep S.", ""], ["Sabili", "Ammar F.", ""]]}, {"id": "2008.06453", "submitter": "Davide Ancona", "authors": "Davide Ancona and Angelo Ferrando and Viviana Mascardi", "title": "Can determinism and compositionality coexist in RML? (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Runtime verification (RV) consists in dynamically verifying that the event\ntraces generated by single runs of a system under scrutiny (SUS) are compliant\nwith the formal specification of its expected properties. RML (Runtime\nMonitoring Language) is a simple but expressive Domain Specific Language for\nRV; its semantics is based on a trace calculus formalized by a deterministic\nrewriting system which drives the implementation of the interpreter of the\nmonitors generated by the RML compiler from the specifications. While\ndeterminism of the trace calculus ensures better performances of the generated\nmonitors, it makes the semantics of its operators less intuitive. In this paper\nwe move a first step towards a compositional semantics of the RML trace\ncalculus, by interpreting its basic operators as operations on sets of\ninstantiated event traces and by proving that such an interpretation is\nequivalent to the operational semantics of the calculus.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:33:36 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 15:24:13 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ancona", "Davide", ""], ["Ferrando", "Angelo", ""], ["Mascardi", "Viviana", ""]]}, {"id": "2008.06589", "submitter": "Thomas Wright", "authors": "Thomas Wright, Ian Stark", "title": "Technical Report: Property-Directed Verified Monitoring of Signal\n  Temporal Logic", "comments": "An extended technical report based on paper be presented at the 20th\n  International Conference on Runtime Verification (RV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Signal Temporal Logic monitoring over numerical simulation traces has emerged\nas an effective approach to approximate verification of continuous and hybrid\nsystems. In this report we explore an exact verification procedure for STL\nproperties based on monitoring verified traces in the form of Taylor model\nflowpipes as produced by the Flow* verified integrator. We explore how tight\nintegration with Flow*'s symbolic flowpipe representation can lead to more\nprecise and more efficient monitoring. We then show how the performance of\nmonitoring can be increased substantially by introducing masks, a\nproperty-directed refinement of our method which restricts flowpipe monitoring\nto the time regions relevant to the overall truth of a complex proposition.\nFinally, we apply our implementation of these methods to verifying properties\nof a challenging continuous system, evaluating the impact of each aspect of our\nprocedure on monitoring performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 22:20:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wright", "Thomas", ""], ["Stark", "Ian", ""]]}, {"id": "2008.06812", "submitter": "Yuan Feng", "authors": "Yuan Feng and Mingsheng Ying", "title": "Quantum Hoare logic with classical variables", "comments": "ACM Transactions on Quantum Computing, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hoare logic provides a syntax-oriented method to reason about program\ncorrectness and has been proven effective in the verification of classical and\nprobabilistic programs. Existing proposals for quantum Hoare logic either lack\ncompleteness or support only quantum variables, thus limiting their capability\nin practical use. In this paper, we propose a quantum Hoare logic for a simple\nwhile language which involves both classical and quantum variables. Its\nsoundness and relative completeness are proven for both partial and total\ncorrectness of quantum programs written in the language. Remarkably, with novel\ndefinitions of classical-quantum states and corresponding assertions, the logic\nsystem is quite simple and similar to the traditional Hoare logic for classical\nprograms. Furthermore, to simplify reasoning in real applications, auxiliary\nproof rules are provided which support standard logical operation in the\nclassical part of assertions, and of super-operator application in the quantum\npart. Finally, a series of practical quantum algorithms, in particular the\nwhole algorithm of Shor's factorisation, are formally verified to show the\neffectiveness of the logic.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 23:56:18 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 07:15:59 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Feng", "Yuan", ""], ["Ying", "Mingsheng", ""]]}, {"id": "2008.06824", "submitter": "Balder ten Cate", "authors": "Balder ten Cate and Victor Dalmau", "title": "Conjunctive Queries: Unique Characterizations and Exact Learnability", "comments": null, "journal-ref": "Proceedings of the 24th International Conference on Database\n  Theory (ICDT 2021), pp. 7:1-7:35", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer the question which conjunctive queries are uniquely characterized\nby polynomially many positive and negative examples, and how to construct such\nexamples efficiently. As a consequence, we obtain a new efficient exact\nlearning algorithm for a class of conjunctive queries. At the core of our\ncontributions lie two new polynomial-time algorithms for constructing frontiers\nin the homomorphism lattice of finite structures. We also discuss implications\nfor the unique characterizability and learnability of schema mappings and of\ndescription logic concepts.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 02:54:56 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 06:52:51 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Cate", "Balder ten", ""], ["Dalmau", "Victor", ""]]}, {"id": "2008.06935", "submitter": "Abdulrazaq Abba", "authors": "Abdulrazaq Abba, Ana Cavalcanti, Jeremy Jacob", "title": "Automatic Translation of tock-CSP into Timed Automata", "comments": "An updated version of this paper is available in this link\n  arXiv:2104.13434", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process algebra tock-CSP provides textual notations for modelling\ndiscrete-time behaviours, with the support of various tools for verification.\nSimilarly, automatic verification of Timed Automata (TA) is supported by the\nreal-time verification toolbox UPPAAL. TA and tock-CSP differ in both modelling\nand verification approaches. For instance, liveness requirements are difficult\nto specify with the constructs of tock-CSP, but they are easy to verify in\nUPPAAL. In this work, we translate tock-CSP into TA to take advantage of\nUPPAAL. We have developed a translation technique and tool; our work uses rules\nfor translating tock-CSP into a network of small TA, which address the\ncomplexity of capturing the compositionality of tock-CSP . For validation, we\nuse an experimental approach based on finite approximations to trace sets. We\nplan to use mathematical proof to establish the correctness of the rules that\nwill cover an infinite set of traces.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 15:23:43 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 09:33:52 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Abba", "Abdulrazaq", ""], ["Cavalcanti", "Ana", ""], ["Jacob", "Jeremy", ""]]}, {"id": "2008.07292", "submitter": "Kees Middelburg", "authors": "C. A. Middelburg", "title": "A classical-logic view of a paraconsistent logic", "comments": "18 pages, major revision of version v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the first-order paraconsistent logic\nLPQ$^{\\supset,\\mathsf{F}}$. A sequent-style natural deduction proof system for\nthis logic is presented and, for this proof system, both a model-theoretic\njustification and a logical justification by means of an embedding into\nfirst-order classical logic is given. For no logic that is essentially the same\nas LPQ$^{\\supset,\\mathsf{F}}$, a natural deduction proof system is currently\navailable in the literature. The given embedding provides both a\nclassical-logic explanation of this logic and a logical justification of its\nproof system. The major properties of LPQ$^{\\supset,\\mathsf{F}}$ are also\ntreated.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:17:25 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 13:31:18 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Middelburg", "C. A.", ""]]}, {"id": "2008.07385", "submitter": "Matthias Kunik Dr.", "authors": "Matthias Kunik", "title": "Further results and examples for formal mathematical systems with\n  structural induction", "comments": "43 pages. arXiv admin note: text overlap with arXiv:2005.04951", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the former article \"Formal mathematical systems including a structural\ninduction principle\" we have presented a unified theory for formal mathematical\nsystems including recursive systems closely related to formal grammars,\nincluding the predicate calculus as well as a formal induction principle. In\nthis paper we present some further results and examples in order to illustrate\nhow this theory works.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:52:58 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 13:31:30 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 10:07:55 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 09:44:32 GMT"}, {"version": "v5", "created": "Tue, 25 May 2021 11:24:33 GMT"}, {"version": "v6", "created": "Mon, 28 Jun 2021 07:44:38 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kunik", "Matthias", ""]]}, {"id": "2008.07901", "submitter": "Yanhong Annie Liu", "authors": "David S. Warren and Yanhong A. Liu", "title": "LPOP: Challenges and Advances in Logic and Practice of Programming", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.10247 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes the work presented at the first Logic and Practice of\nProgramming (LPOP) Workshop, which was held in Oxford, UK, on July 18, 2018, in\nconjunction with the Federated Logic Conference (FLoC) 2018. Its focus is\nchallenges and advances in logic and practice of programming. The workshop was\norganized around a challenge problem that specifies issues in role-based access\ncontrol (RBAC), with many participants proposing combined imperative and\ndeclarative solutions expressed in the languages of their choice.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 14:28:46 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Warren", "David S.", ""], ["Liu", "Yanhong A.", ""]]}, {"id": "2008.08245", "submitter": "Yepeng Ding", "authors": "Yepeng Ding, Hiroyuki Sato", "title": "Formalizing and Verifying Decentralized Systems with Extended Concurrent\n  Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized techniques are becoming crucial and ubiquitous with the rapid\nadvancement of distributed ledger technologies such as the blockchain. Numerous\ndecentralized systems have been developed to address security and privacy\nissues with great dependability and reliability via these techniques.\nMeanwhile, formalization and verification of the decentralized systems is the\nkey to ensuring correctness of the design and security properties of the\nimplementation. In this paper, we propose a novel method of formalizing and\nverifying decentralized systems with a kind of extended concurrent separation\nlogic. Our logic extends the standard concurrent separation logic with new\nfeatures including communication encapsulation, environment perception, and\nnode-level reasoning, which enhances modularity and expressiveness. Besides, we\ndevelop our logic with unitarity and compatibility to facilitate\nimplementation. Furthermore, we demonstrate the effectiveness and versatility\nof our method by applying our logic to formalize and verify critical techniques\nin decentralized systems including the consensus mechanism and the smart\ncontract.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 03:40:03 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Ding", "Yepeng", ""], ["Sato", "Hiroyuki", ""]]}, {"id": "2008.08283", "submitter": "Saeed Salehi", "authors": "Saeed Salehi", "title": "Axiomatic (and Non-Axiomatic) Mathematics", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axiomatizing mathematical structures and theories is an objective of\nMathematical Logic. Some axiomatic systems are nowadays mere definitions, such\nas the axioms of Group Theory; but some systems are much deeper, such as the\naxioms of Complete Ordered Fields with which Real Analysis starts. Groups\nabound in mathematical sciences, while by Dedekind's theorem there exists only\none complete ordered field, up to isomorphism. Cayley's theorem in Abstract\nAlgebra implies that the axioms of group theory completely axiomatize the class\nof permutation sets that are closed under composition and inversion. In this\narticle, we survey some old and new results on the first-order axiomatizability\nof various mathematical structures. We will also review identities over\naddition, multiplication, and exponentiation that hold in the set of positive\nreal numbers.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 06:18:55 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Salehi", "Saeed", ""]]}, {"id": "2008.08381", "submitter": "Athar Kharal", "authors": "Athar Kharal, Mansoor H. Alshehri, Nasser Bin Turki, Faisal Z.\n  Duraihem", "title": "On the Notion of a Generalized Mapping on Multiset Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a generalized notion of multiset mapping thus resolving a\nlong standing obstacle in structural study of multiset processing. It has been\nshown that the mapping defined herein can model a vast array of notions as\nspecial cases and also handels diverse situations in multiset rewriting\ntransformations. Specifically, this paper unifies and generalizes the works of\nParikh(1966), Hickman(1980), Khomenko(2003) and Nazmul(2013).\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 11:22:04 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 07:44:15 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Kharal", "Athar", ""], ["Alshehri", "Mansoor H.", ""], ["Turki", "Nasser Bin", ""], ["Duraihem", "Faisal Z.", ""]]}, {"id": "2008.08530", "submitter": "Andreas Nuyts", "authors": "Andreas Nuyts (KU Leuven)", "title": "The Transpension Type: Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The purpose of these notes is to give a categorical semantics for the\ntranspension type (Nuyts and Devriese, Transpension: The Right Adjoint to the\nPi-type, pre-print, 2020), which is right adjoint to a potentially\nsubstructural dependent function type. In section 2 we discuss some\nprerequisites. In section 3, we define multipliers and discuss their\nproperties. In section 4, we study how multipliers lift from base categories to\npresheaf categories. In section 5, we explain how typical presheaf modalities\ncan be used in the presence of the transpension type. In section 6, we study\ncommutation properties of prior modalities, substitution modalities and\nmultiplier modalities.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:13:01 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Nuyts", "Andreas", "", "KU Leuven"]]}, {"id": "2008.08533", "submitter": "Andreas Nuyts", "authors": "Andreas Nuyts (KU Leuven) and Dominique Devriese (Vrije Universiteit\n  Brussel)", "title": "Transpension: The Right Adjoint to the Pi-type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Presheaf models of dependent type theory have been successfully applied to\nmodel HoTT, parametricity, and directed, guarded and nominal type theory. There\nhas been considerable interest in internalizing aspects of these presheaf\nmodels, either to make the resulting language more expressive, or in order to\ncarry out further reasoning internally, allowing greater abstraction and\nsometimes automated verification. While the constructions of presheaf models\nlargely follow a common pattern, approaches towards internalization do not.\nThroughout the literature, various internal presheaf operators ($\\surd$,\n$\\Phi/\\mathsf{extent}$, $\\Psi/\\mathsf{Gel}$, $\\mathsf{Glue}$, $\\mathsf{Weld}$,\n$\\mathsf{mill}$, the strictness axiom and locally fresh names) can be found and\nlittle is known about their relative expressivenes. Moreover, some of these\nrequire that variables whose type is a shape (representable presheaf, e.g. an\ninterval) be used affinely.\n  We propose a novel type former, the transpension type, which is right adjoint\nto universal quantification over a shape. Its structure resembles a dependent\nversion of the suspension type in HoTT. We give general typing rules and a\npresheaf semantics in terms of base category functors dubbed multipliers.\nStructural rules for shape variables and certain aspects of the transpension\ntype depend on characteristics of the multiplier. We demonstrate how the\ntranspension type and the strictness axiom can be combined to implement all and\nimprove some of the aforementioned internalization operators (without formal\nclaim in the case of locally fresh names).\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:24:55 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Nuyts", "Andreas", "", "KU Leuven"], ["Devriese", "Dominique", "", "Vrije Universiteit\n  Brussel"]]}, {"id": "2008.08748", "submitter": "Vu Hoang Nguyen Phan", "authors": "Jeffrey M. Dudek, Vu H. N. Phan, Moshe Y. Vardi", "title": "DPMC: Weighted Model Counting by Dynamic Programming on Project-Join\n  Trees", "comments": "Full version of paper at CP 2020 (26th International Conference on\n  Principles and Practice of Constraint Programming)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unifying dynamic-programming framework to compute exact\nliteral-weighted model counts of formulas in conjunctive normal form. At the\ncenter of our framework are project-join trees, which specify efficient\nproject-join orders to apply additive projections (variable eliminations) and\njoins (clause multiplications). In this framework, model counting is performed\nin two phases. First, the planning phase constructs a project-join tree from a\nformula. Second, the execution phase computes the model count of the formula,\nemploying dynamic programming as guided by the project-join tree. We\nempirically evaluate various methods for the planning phase and compare\nconstraint-satisfaction heuristics with tree-decomposition tools. We also\ninvestigate the performance of different data structures for the execution\nphase and compare algebraic decision diagrams with tensors. We show that our\ndynamic-programming model-counting framework DPMC is competitive with the\nstate-of-the-art exact weighted model counters cachet, c2d, d4, and miniC2D.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:09:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Dudek", "Jeffrey M.", ""], ["Phan", "Vu H. N.", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "2008.08919", "submitter": "Wissam Maamar Kouadri", "authors": "Wissam Maamar Kouadri, Salima Benbernou, Mourad Ouziri, Themis\n  Palpanas, Iheb Ben Amor", "title": "SentiQ: A Probabilistic Logic Approach to Enhance Sentiment Analysis\n  Tool Quality", "comments": "In Proceedings of the 9th KDD Workshop on Issues of Sentiment\n  Discovery and Opinion Mining (WISDOM 20). San Diego, CA, USA, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The opinion expressed in various Web sites and social-media is an essential\ncontributor to the decision making process of several organizations. Existing\nsentiment analysis tools aim to extract the polarity (i.e., positive, negative,\nneutral) from these opinionated contents. Despite the advance of the research\nin the field, sentiment analysis tools give \\textit{inconsistent} polarities,\nwhich is harmful to business decisions. In this paper, we propose SentiQ, an\nunsupervised Markov logic Network-based approach that injects the semantic\ndimension in the tools through rules. It allows to detect and solve\ninconsistencies and then improves the overall accuracy of the tools.\nPreliminary experimental results demonstrate the usefulness of SentiQ.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:30:00 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Kouadri", "Wissam Maamar", ""], ["Benbernou", "Salima", ""], ["Ouziri", "Mourad", ""], ["Palpanas", "Themis", ""], ["Amor", "Iheb Ben", ""]]}, {"id": "2008.08936", "submitter": "Vinh Thong Ta", "authors": "Vinh Thong Ta", "title": "DataProVe: A Data Protection Policy and System Architecture Verification\n  Tool", "comments": "65 pages. Improved algorithm description and explanation. Semantics\n  of policy language added. More complete list of properties, and inference\n  rules added. More figures and discussion section added. Finally, we refer to\n  this version in our (shorter) paper under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a tool, called DataProVe, for specifying high-level\ndata protection policies and system architectures, as well as verifying the\nconformance between them in a fully automated way. The syntax of the policies\nand the architectures is based on semi-formal languages, and the automated\nverification engine relies on logic and resolution based proofs. The\nfunctionality and operation of the tool are presented using different examples.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 12:38:24 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 16:44:57 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 15:57:22 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 07:51:05 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Ta", "Vinh Thong", ""]]}, {"id": "2008.09016", "submitter": "Saeed Salehi", "authors": "Saeed Salehi", "title": "From Intuitionism to Many-Valued Logics through Kripke Models", "comments": "10 pages, to appear in: Mathematics, Logic, and their\n  Philosophies---Essays in Honor of Mohammad Ardeshir (Springer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intuitionistic Propositional Logic is proved to be an infinitely many valued\nlogic by Kurt G\\\"odel (1932), and it is proved by Stanis{\\l}aw Ja\\'skowski\n(1936) to be a countably many valued logic. In this paper, we provide\nalternative proofs for these theorems by using models of Saul Kripke (1959).\nG\\\"odel's proof gave rise to an intermediate propositional logic (between\nintuitionistic and classical), that is known nowadays as G\\\"odel or the\nG\\\"odel-Dummet Logic, and is studied by fuzzy logicians as well. We also\nprovide some results on the inter-definablility of propositional connectives in\nthis logic.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 15:13:38 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Salehi", "Saeed", ""]]}, {"id": "2008.09231", "submitter": "Jialu Bao", "authors": "Jialu Bao, Simon Docherty, Justin Hsu, Alexandra Silva", "title": "A Bunched Logic for Conditional Independence", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independence and conditional independence are fundamental concepts for\nreasoning about groups of random variables in probabilistic programs.\nVerification methods for independence are still nascent, and existing methods\ncannot handle conditional independence. We extend the logic of bunched\nimplications (BI) with a non-commutative conjunction and provide a model based\non Markov kernels; conditional independence can be directly captured as a\nlogical formula in this model. Noting that Markov kernels are Kleisli arrows\nfor the distribution monad, we then introduce a second model based on the\npowerset monad and show how it can capture join dependency, a non-probabilistic\nanalogue of conditional independence from database theory. Finally, we develop\na program logic for verifying conditional independence in probabilistic\nprograms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 23:46:00 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 00:55:54 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Bao", "Jialu", ""], ["Docherty", "Simon", ""], ["Hsu", "Justin", ""], ["Silva", "Alexandra", ""]]}, {"id": "2008.09238", "submitter": "Jim de Groot", "authors": "Jim de Groot, Helle Hvid Hansen, Alexander Kurz", "title": "Logic-Induced Bisimulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We define a new logic-induced notion of bisimulation (called\n$\\rho$-bisimulation) for coalgebraic modal logics given by a logical\nconnection, and investigate its properties. We show that it is structural in\nthe sense that it is defined only in terms of the coalgebra structure and the\none-step modal semantics and, moreover, can be characterised by a form of\nrelation lifting. Furthermore we compare $\\rho$-bisimulations to several\nwell-known equivalence notions, and we prove that the collection of\nbisimulations between two models often forms a complete lattice. The main\ntechnical result is a Hennessy-Milner type theorem which states that, under\ncertain conditions, logical equivalence implies $\\rho$-bisimilarity. In\nparticular, the latter does \\emph{not} rely on a duality between functors\n$\\mathsf{T}$ (the type of the coalgebras) and $\\mathsf{L}$ (which gives the\nlogic), nor on properties of the logical connection $\\rho$.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 00:12:03 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["de Groot", "Jim", ""], ["Hansen", "Helle Hvid", ""], ["Kurz", "Alexander", ""]]}, {"id": "2008.09307", "submitter": "Jingzhou Liu Mr", "authors": "Ethan L. Childerhose, Jingzhou Liu", "title": "A Heuristic Approach to Two Level Boolean Minimization Derived from\n  Karnaugh Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following paper presents a heuristic method by which sum-of-product\nBoolean expressions can be simplified with a specific focus on the removal of\nredundant and selective prime implicants. Existing methods, such as the\nKarnaugh map and the Quine-McCluskey method [1, 2], fail to scale since they\nincrease exponentially in complexity as the quantity of literals increases,\ndoing as such to ensure the solution is algorithmically obtained. By employing\na heuristic model, nearly all expressions can be simplified at an overall\nreduction in computational complexity. This new method was derived from the\nfundamental Boolean laws, Karnaugh mapping, as well as truth tables.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:10:10 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 15:05:21 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 05:27:47 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Childerhose", "Ethan L.", ""], ["Liu", "Jingzhou", ""]]}, {"id": "2008.09511", "submitter": "Peter Lindner", "authors": "Nofar Carmeli, Martin Grohe, Peter Lindner, Christoph Standke", "title": "Tuple-Independent Representations of Infinite Probabilistic Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic databases (PDBs) are probability spaces over database\ninstances. They provide a framework for handling uncertainty in databases, as\noccurs due to data integration, noisy data, data from unreliable sources or\nrandomized processes. Most of the existing theory literature investigated\nfinite, tuple-independent PDBs (TI-PDBs) where the occurrences of tuples are\nindependent events. Only recently, Grohe and Lindner (PODS '19) introduced\nindependence assumptions for PDBs beyond the finite domain assumption. In the\nfinite, a major argument for discussing the theoretical properties of TI-PDBs\nis that they can be used to represent any finite PDB via views. This is no\nlonger the case once the number of tuples is countably infinite. In this paper,\nwe systematically study the representability of infinite PDBs in terms of\nTI-PDBs and the related block-independent disjoint PDBs.\n  The central question is which infinite PDBs are representable as first-order\nviews over tuple-independent PDBs. We give a necessary condition for the\nrepresentability of PDBs and provide a sufficient criterion for\nrepresentability in terms of the probability distribution of a PDB. With\nvarious examples, we explore the limits of our criteria. We show that\nconditioning on first order properties yields no additional power in terms of\nexpressivity. Finally, we discuss the relation between purely logical and\narithmetic reasons for (non-)representability.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:39:47 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Carmeli", "Nofar", ""], ["Grohe", "Martin", ""], ["Lindner", "Peter", ""], ["Standke", "Christoph", ""]]}, {"id": "2008.09514", "submitter": "Yongfeng Zhang", "authors": "Shaoyun Shi, Hanxiong Chen, Weizhi Ma, Jiaxin Mao, Min Zhang, Yongfeng\n  Zhang", "title": "Neural Logic Reasoning", "comments": "Accepted to ACM CIKM 2020. arXiv admin note: substantial text overlap\n  with arXiv:1910.08629", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the success of deep neural networks in many\nresearch areas. The fundamental idea behind the design of most neural networks\nis to learn similarity patterns from data for prediction and inference, which\nlacks the ability of cognitive reasoning. However, the concrete ability of\nreasoning is critical to many theoretical and practical problems. On the other\nhand, traditional symbolic reasoning methods do well in making logical\ninference, but they are mostly hard rule-based reasoning, which limits their\ngeneralization ability to different tasks since difference tasks may require\ndifferent rules. Both reasoning and generalization ability are important for\nprediction tasks such as recommender systems, where reasoning provides strong\nconnection between user history and target items for accurate prediction, and\ngeneralization helps the model to draw a robust user portrait over noisy\ninputs.\n  In this paper, we propose Logic-Integrated Neural Network (LINN) to integrate\nthe power of deep learning and logic reasoning. LINN is a dynamic neural\narchitecture that builds the computational graph according to input logical\nexpressions. It learns basic logical operations such as AND, OR, NOT as neural\nmodules, and conducts propositional logical reasoning through the network for\ninference. Experiments on theoretical task show that LINN achieves significant\nperformance on solving logical equations and variables. Furthermore, we test\nour approach on the practical task of recommendation by formulating the task\ninto a logical inference problem. Experiments show that LINN significantly\noutperforms state-of-the-art recommendation models in Top-K recommendation,\nwhich verifies the potential of LINN in practice.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:53:23 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shi", "Shaoyun", ""], ["Chen", "Hanxiong", ""], ["Ma", "Weizhi", ""], ["Mao", "Jiaxin", ""], ["Zhang", "Min", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2008.09546", "submitter": "Marta Cialdea Mayer", "authors": "Jean-Marc Alliot, Marta Cialdea Mayer, Robert Demolombe, Mart\\'in\n  Di\\'eguez, Luis Fari\\~nas del Cerro", "title": "A framework for modelling Molecular Interaction Maps", "comments": "31 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metabolic networks, formed by a series of metabolic pathways, are made of\nintracellular and extracellular reactions that determine the biochemical\nproperties of a cell, and by a set of interactions that guide and regulate the\nactivity of these reactions. Most of these pathways are formed by an intricate\nand complex network of chain reactions, and can be represented in a human\nreadable form using graphs which describe the cell cycle checkpoint pathways.\n  This paper proposes a method to represent Molecular Interaction Maps\n(graphical representations of complex metabolic networks) in Linear Temporal\nLogic. The logical representation of such networks allows one to reason about\nthem, in order to check, for instance, whether a graph satisfies a given\nproperty $\\phi$, as well as to find out which initial conditons would guarantee\n$\\phi$, or else how can the the graph be updated in order to satisfy $\\phi$.\n  Both the translation and resolution methods have been implemented in a tool\ncapable of addressing such questions thanks to a reduction to propositional\nlogic which allows exploiting classical SAT solvers.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 15:40:47 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Alliot", "Jean-Marc", ""], ["Mayer", "Marta Cialdea", ""], ["Demolombe", "Robert", ""], ["Di\u00e9guez", "Mart\u00edn", ""], ["del Cerro", "Luis Fari\u00f1as", ""]]}, {"id": "2008.09610", "submitter": "W{\\l}odzimierz Drabent", "authors": "W{\\l}odzimierz Drabent", "title": "Implementing backjumping by throw/1 and catch/3 of Prolog", "comments": "7 pages. This version - an extension (Approach 1a)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss how to implement backjumping (or intelligent backtracking) in\nProlog programs by means of exception handling. This seems impossible in a\ngeneral case. We provide a solution, which works in certain cases, in\nparticular for binary programs. We also provide a kind of approximate solution,\nfor arbitrary programs.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:24:26 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 22:03:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Drabent", "W\u0142odzimierz", ""]]}, {"id": "2008.10061", "submitter": "Paul Samuel Maria Teuber", "authors": "Samuel Teuber, Marko Kleine B\\\"uning, Carsten Sinz", "title": "An Incremental Abstraction Scheme for Solving Hard SMT-Instances over\n  Bit-Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision procedures for SMT problems based on the theory of bit-vectors are a\nfundamental component in state-of-the-art software and hardware verifiers.\nWhile very efficient in general, certain SMT instances are still challenging\nfor state-of-the-art solvers (especially when such instances include\ncomputationally costly functions). In this work, we present an approach for the\nquantifier-free bit-vector theory (QF_BV in SMT-LIB) based on incremental SMT\nsolving and abstraction refinement. We define four concrete approximation steps\nfor the multiplication, division and remainder operators and combine them into\nan incremental abstraction scheme. We implement this scheme in a prototype\nextending the SMT solver Boolector and measure both the overall performance and\nthe performance of the single approximation steps. The evaluation shows that\nour abstraction scheme contributes to solving more unsatisfiable benchmark\ninstances, including seven instances with unknown status in SMT-LIB.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 15:48:58 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Teuber", "Samuel", ""], ["B\u00fcning", "Marko Kleine", ""], ["Sinz", "Carsten", ""]]}, {"id": "2008.10131", "submitter": "Daniel Murfet", "authors": "Daniel Murfet, William Troiani", "title": "Gentzen-Mints-Zucker duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Curry-Howard correspondence is often described as relating proofs (in\nintutionistic natural deduction) to programs (terms in simply-typed lambda\ncalculus). However this narrative is hardly a perfect fit, due to the\ncomputational content of cut-elimination and the logical origins of lambda\ncalculus. We revisit Howard's work and interpret it as an isomorphism between a\ncategory of proofs in intuitionistic sequent calculus and a category of terms\nin simply-typed lambda calculus. In our telling of the story the fundamental\nduality is not between proofs and programs but between local (sequent calculus)\nand global (lambda calculus or natural deduction) points of view on a common\nlogico-computational mathematical structure.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 23:20:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Murfet", "Daniel", ""], ["Troiani", "William", ""]]}, {"id": "2008.10426", "submitter": "Nathalie Bertrand", "authors": "Nathalie Bertrand and Patricia Bouyer and Thomas Brihaye and Paulin\n  Fournier", "title": "Taming denumerable Markov decision processes with decisiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisiveness has proven to be an elegant concept for denumerable Markov\nchains: it is general enough to encompass several natural classes of\ndenumerable Markov chains, and is a sufficient condition for simple qualitative\nand approximate quantitative model checking algorithms to exist. In this paper,\nwe explore how to extend the notion of decisiveness to Markov decision\nprocesses. Compared to Markov chains, the extra non-determinism can be resolved\nin an adversarial or cooperative way, yielding two natural notions of\ndecisiveness. We then explore whether these notions yield model checking\nprocedures concerning the infimum and supremum probabilities of reachability\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:25:46 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bertrand", "Nathalie", ""], ["Bouyer", "Patricia", ""], ["Brihaye", "Thomas", ""], ["Fournier", "Paulin", ""]]}, {"id": "2008.10591", "submitter": "Emanuel Martinov", "authors": "Kousha Etessami, Emanuel Martinov", "title": "Qualitative Multi-Objective Reachability for Ordered Branching MDPs", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study qualitative multi-objective reachability problems for Ordered\nBranching Markov Decision Processes (OBMDPs), or equivalently context-free\nMDPs, building on prior results for single-target reachability on Branching\nMarkov Decision Processes (BMDPs).\n  We provide two separate algorithms for \"almost-sure\" and \"limit-sure\"\nmulti-target reachability for OBMDPs. Specifically, given an OBMDP,\n$\\mathcal{A}$, given a starting non-terminal, and given a set of target\nnon-terminals $K$ of size $k = |K|$, our first algorithm decides whether the\nsupremum probability, of generating a tree that contains every target\nnon-terminal in set $K$, is $1$. Our second algorithm decides whether there is\na strategy for the player to almost-surely (with probability $1$) generate a\ntree that contains every target non-terminal in set $K$.\n  The two separate algorithms are needed: we show that indeed, in this context,\n\"almost-sure\" $\\not=$ \"limit-sure\" for multi-target reachability, meaning that\nthere are OBMDPs for which the player may not have any strategy to achieve\nprobability exactly $1$ of reaching all targets in set $K$ in the same\ngenerated tree, but may have a sequence of strategies that achieve probability\narbitrarily close to $1$. Both algorithms run in time $2^{O(k)} \\cdot\n|\\mathcal{A}|^{O(1)}$, where $|\\mathcal{A}|$ is the total bit encoding length\nof the given OBMDP, $\\mathcal{A}$. Hence they run in polynomial time when $k$\nis fixed, and are fixed-parameter tractable with respect to $k$. Moreover, we\nshow that even the qualitative almost-sure (and limit-sure) multi-target\nreachability decision problem is in general NP-hard, when the size $k$ of the\nset $K$ of target non-terminals is not fixed.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:54:21 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Etessami", "Kousha", ""], ["Martinov", "Emanuel", ""]]}, {"id": "2008.11066", "submitter": "Sandro Stucki", "authors": "Vincent Danos, Tobias Heindel, Ricardo Honorato-Zimmer, and Sandro\n  Stucki", "title": "Rate Equations for Graphs", "comments": "to be presented at the 18th International Conference on Computational\n  Methods in Systems Biology (CMSB 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we combine ideas from two different scientific traditions: 1)\ngraph transformation systems (GTSs) stemming from the theory of formal\nlanguages and concurrency, and 2) mean field approximations (MFAs), a\ncollection of approximation techniques ubiquitous in the study of complex\ndynamics. Using existing tools from algebraic graph rewriting, as well as new\nones, we build a framework which generates rate equations for stochastic GTSs\nand from which one can derive MFAs of any order (no longer limited to the\nhumanly computable). The procedure for deriving rate equations and their\napproximations can be automated. An implementation and example models are\navailable online at https://rhz.github.io/fragger. We apply our techniques and\ntools to derive an expression for the mean velocity of a two-legged walker\nprotein on DNA.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:40:24 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 13:28:14 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Danos", "Vincent", ""], ["Heindel", "Tobias", ""], ["Honorato-Zimmer", "Ricardo", ""], ["Stucki", "Sandro", ""]]}, {"id": "2008.11094", "submitter": "Samson Abramsky", "authors": "Samson Abramsky and Dan Marsden", "title": "Comonadic semantics for guarded fragments", "comments": "To appear in LiCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work, Abramsky, Dawar and Wang (LiCS 2017) and Abramsky and Shah\n(CSL 2018) have shown how a range of model comparison games which play a\ncentral role in finite model theory, including Ehrenfeucht-Fraisse, pebbling,\nand bisimulation games, can be captured in terms of resource-indexed comonads\non the category of relational structures. Moreover, the coalgebras for these\ncomonads capture important combinatorial parameters such as tree-width and\ntree-depth.\n  The present paper extends this analysis to quantifier-guarded fragments of\nfirst-order logic. We give a systematic account, covering atomic, loose and\nclique guards. In each case, we show that coKleisli morphisms capture winning\nstrategies for Duplicator in the existential guarded bisimulation game, while\nback-and-forth bisimulation, and hence equivalence in the full guarded\nfragment, is captured by spans of open morphisms. We study the coalgebras for\nthese comonads, and show that they correspond to guarded tree decompositions.\nWe relate these constructions to a syntax-free setting, with a comonad on the\ncategory of hypergraphs.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:18:17 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 09:52:10 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 16:48:11 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Abramsky", "Samson", ""], ["Marsden", "Dan", ""]]}, {"id": "2008.11168", "submitter": "Arno Pauly", "authors": "Arno Pauly", "title": "An update on Weihrauch complexity, and some open questions", "comments": "Extended abstract for invited talk at CCA 2020\n  (http://cca-net.de/cca2020/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an informal survey of progress in Weihrauch complexity (cf\narXiv:1707.03202) in the period 2018-2020. Open questions are emphasised.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 17:01:38 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Pauly", "Arno", ""]]}, {"id": "2008.11499", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "Reactive Bisimulation Semantics for a Process Algebra with Time-Outs", "comments": "A extended abstract of this paper will appear in the proceedings of\n  CONCUR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the counterpart of strong bisimilarity for labelled\ntransition systems extended with time-out transitions. It supports this concept\nthrough a modal characterisation, congruence results for a standard process\nalgebra with recursion, and a complete axiomatisation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 11:44:32 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "2008.11585", "submitter": "Dabas Payal", "authors": "Payal and Sangita Kansal", "title": "Logic Signed Petri Net", "comments": "arXiv admin note: text overlap with arXiv:2001.04374", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper,the authors show the versatility of the Signed Petri Net (SPN)\nintroduced by them by showing the equivalence between a Logic Signed Petri Net\n(LSPN) and Logic Petri Net (LPN).The capacity of each place in all these nets\nis at most one, i.e.,a place has either zero or one token in it.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:17:31 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Payal", "", ""], ["Kansal", "Sangita", ""]]}, {"id": "2008.11753", "submitter": "Petr Jancar", "authors": "Petr Jancar, Petr Osicka, Zdenek Sawa", "title": "Countdown games, and simulation on (succinct) one-counter nets", "comments": "A part of this paper elaborates arxiv-paper 1801.01073 and the\n  related paper presented at Reachability Problems 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer an open complexity question by Hofman, Lasota, Mayr, Totzke (LMCS\n2016) [HLMT16] for simulation preorder of succinct one-counter nets (i.e.,\none-counter automata with no zero tests where counter increments and decrements\nare integers written in binary), by showing that all relations between\nbisimulation equivalence and simulation preorder are EXPSPACE-hard for these\nnets. We describe a reduction from reachability games whose\nEXPSPACE-completeness in the case of succinct one-counter nets was shown by\nHunter [RP 2015], by using other results. We also provide a direct\nself-contained EXPSPACE-completeness proof for a special case of such\nreachability games, namely for a modification of countdown games that were\nshown EXPTIME-complete by Jurdzinski, Sproston, Laroussinie [LMCS 2008]; in our\nmodification the initial counter value is not given but is freely chosen by the\nfirst player. We also present a new simplified proof of the belt theorem that\ngives a simple graphic presentation of simulation preorder on one-counter nets\nand leads to a polynomial-space algorithm; it is an alternative to the proof\nfrom [HLMT16].\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 18:26:49 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Jancar", "Petr", ""], ["Osicka", "Petr", ""], ["Sawa", "Zdenek", ""]]}, {"id": "2008.11943", "submitter": "Simon Kn\\\"auer", "authors": "Manuel Bodirsky and Simon Kn\\\"auer", "title": "Network satisfaction for symmetric relation algebras with a flexible\n  atom", "comments": "32 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robin Hirsch posed in 1996 the Really Big Complexity Problem: classify the\ncomputational complexity of the network satisfaction problem for all finite\nrelation algebras $\\bf A$. We provide a complete classification for the case\nthat $\\bf A$ is symmetric and has a flexible atom; the problem is in this case\nNP-complete or in P. If a finite integral relation algebra has a flexible atom,\nthen it has a normal representation $\\mathfrak{B}$. We can then study the\ncomputational complexity of the network satisfaction problem of ${\\bf A}$ using\nthe universal-algebraic approach, via an analysis of the polymorphisms of\n$\\mathfrak{B}$. We also use a Ramsey-type result of Ne\\v{s}et\\v{r}il and R\\\"odl\nand a complexity dichotomy result of Bulatov for conservative finite-domain\nconstraint satisfaction problems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 06:43:25 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Kn\u00e4uer", "Simon", ""]]}, {"id": "2008.12414", "submitter": "EPTCS", "authors": "Ornela Dardha (University of Glasgow), Jurriaan Rot (Radboud\n  University)", "title": "Proceedings Combined 27th International Workshop on Expressiveness in\n  Concurrency and 17th Workshop on Structural Operational Semantics", "comments": null, "journal-ref": "EPTCS 322, 2020", "doi": "10.4204/EPTCS.322", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of EXPRESS/SOS 2020: the Combined 27th\nInternational Workshop on Expressiveness in Concurrency and the 17th Workshop\non Structural Operational Semantics, which was held online, as an affiliated\nworkshop of CONCUR 2020, the 31st International Conference on Concurrency\nTheory. The EXPRESS/SOS workshop series aims at bringing together researchers\ninterested in the formal semantics of systems and programming concepts, and in\nthe expressiveness of computational models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 23:55:59 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Dardha", "Ornela", "", "University of Glasgow"], ["Rot", "Jurriaan", "", "Radboud\n  University"]]}, {"id": "2008.12545", "submitter": "Philipp K\\\"orner", "authors": "Isabel Wingen, Philipp K\\\"orner", "title": "Effectiveness of Annotation-Based Static Type Inference", "comments": "15 pages. Part of WFLP 2020 pre-proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefits of static type systems are well-known: they offer guarantees that no\ntype error will occur during runtime and, inherently, inferred types serve as\ndocumentation on how functions are called. On the other hand, many type systems\nhave to limit expressiveness of the language because, in general, it is\nundecidable whether a given program is correct regarding types. Another concern\nthat was not addressed so far is that, for logic programming languages such as\nProlog, it is impossible to distinguish between intended and unintended failure\nand, worse, intended and unintended success without additional annotations.\n  In this paper, we elaborate on and discuss the aforementioned issues. As an\nalternative, we present a static type analysis which is based on plspec.\nInstead of ensuring full type-safety, we aim to statically identify type errors\non a best-effort basis without limiting the expressiveness of Prolog programs.\nFinally, we evaluate our approach on real-world code featured in the SWI\ncommunity packages and a large project implementing a model checker.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 09:17:05 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Wingen", "Isabel", ""], ["K\u00f6rner", "Philipp", ""]]}, {"id": "2008.12643", "submitter": "Michael Beeson", "authors": "Michael Beeson", "title": "On the Notion of Equal Figures in Euclid", "comments": "38 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Euclid uses an undefined notion of \"equal figures\", to which he applies the\ncommon notions about equals added to equals or subtracted from equals. When (in\nprevious work) we formalized Euclid Book~I for computer proof-checking, we had\nto add fifteen axioms about undefined relations \"equal triangles\" and \"equal\nquadrilaterals\" to replace Euclid's use of the common notions. In this paper,\nwe offer definitions of \"equal triangles\" and \"equal quadrilaterals\", that\nEuclid could have given, and prove that they have the required properties. This\nremoves the need for adding new axioms. The proof uses the theory of\nproportions. Hence we also discuss the \"early theory of proportions\", which has\na long history.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 19:29:06 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Beeson", "Michael", ""]]}, {"id": "2008.12827", "submitter": "Bj{\\o}rn Kjos-Hanssen", "authors": "Bj{\\o}rn Kjos-Hanssen", "title": "A conflict between some semantic conditions of Carmo and Jones for\n  contrary-to-duty obligations", "comments": null, "journal-ref": "Studia Logica 105 (2017), no. 1, 173--178", "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Carmo and Jones' condition 5(e) conflicts with the other\nconditions on their models for contrary-to-duty obligations. We then propose a\nresolution to the conflict.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:57:37 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kjos-Hanssen", "Bj\u00f8rn", ""]]}, {"id": "2008.13016", "submitter": "Moreno Falaschi", "authors": "Linda Brodo, Roberto Bruni and Moreno Falaschi", "title": "SOS Rules for Equivalences of Reaction Systems", "comments": "Part of WFLP 2020 pre-proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reaction Systems (RSs) are a successful computational framework inspired by\nbiological systems. A RS pairs a set of entities with a set of reactions over\nthem. Entities can be used to enable or inhibit each reaction, and are produced\nby reactions. Entities can also be provided by an external context. RS\nsemantics is defined in terms of an (unlabelled) rewrite system: given the\ncurrent set of entities, a rewrite step consists of the application of all and\nonly the enabled reactions. In this paper we define, for the first time, a\nlabelled transition system for RSs in the structural operational semantics\n(SOS) style. This is achieved by distilling a signature whose operators\ndirectly correspond to the ingredients of RSs and by defining some simple SOS\ninference rules for any such operator to define the behaviour of the RS in a\ncompositional way. The rich information recorded in the labels allows us to\ndefine an assertion language to tailor behavioural equivalences on some\nspecific properties or entities. The SOS approach is suited to drive additional\nenhancements of RSs along features such as quantitative measurements of\nentities and communication between RSs. The SOS rules have been also exploited\nto design a prototype implementation in logic programming.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 17:12:02 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Brodo", "Linda", ""], ["Bruni", "Roberto", ""], ["Falaschi", "Moreno", ""]]}, {"id": "2008.13278", "submitter": "Laura Giordano", "authors": "Laura Giordano, Valentina Gliozzi, Daniele Theseider Dupr\\'e", "title": "On a plausible concept-wise multipreference semantics and its relations\n  with self-organising maps", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": "TR-INF-2020-09-02-UNIPMN", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inthispaperwedescribeaconcept-wisemulti-preferencesemantics for description\nlogic which has its root in the preferential approach for modeling defeasible\nreasoning in knowledge representation. We argue that this proposal, beside\nsatisfying some desired properties, such as KLM postulates, and avoiding the\ndrowning problem, also defines a plausible notion of semantics. We motivate the\nplausibility of the concept-wise multi-preference semantics by developing a\nlogical semantics of self-organising maps, which have been proposed as possible\ncandidates to explain the psychological mechanisms underlying category\ngeneralisation, in terms of multi-preference interpretations.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 21:06:06 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Giordano", "Laura", ""], ["Gliozzi", "Valentina", ""], ["Dupr\u00e9", "Daniele Theseider", ""]]}, {"id": "2008.13355", "submitter": "EPTCS", "authors": "Bas Luttik (Eindhoven University of Technology)", "title": "Divergence-Preserving Branching Bisimilarity", "comments": "In Proceedings EXPRESS/SOS 2020, arXiv:2008.12414", "journal-ref": "EPTCS 322, 2020, pp. 3-11", "doi": "10.4204/EPTCS.322.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note considers the notion of divergence-preserving branching\nbisimilarity. It briefly surveys results pertaining to the notion that have\nbeen obtained in the past one-and-a-half decade, discusses its role in the\nstudy of expressiveness of process calculi, and concludes with some suggestions\nfor future work.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:33:58 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Luttik", "Bas", "", "Eindhoven University of Technology"]]}, {"id": "2008.13356", "submitter": "EPTCS", "authors": "Mark Bouwman (Eindhoven University of Technology), Bas Luttik\n  (Eindhoven University of Technology), Wouter Schols, Tim A.C. Willemse\n  (Eindhoven University of Technology)", "title": "A process algebra with global variables", "comments": "In Proceedings EXPRESS/SOS 2020, arXiv:2008.12414", "journal-ref": "EPTCS 322, 2020, pp. 33-50", "doi": "10.4204/EPTCS.322.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard process algebra, parallel components do not share a common state\nand communicate through synchronisation. The advantage of this type of\ncommunication is that it facilitates compositional reasoning. For modelling and\nanalysing systems in which parallel components operate on shared memory,\nhowever, the communication-through-synchronisation paradigm is sometimes less\nconvenient. In this paper we study a process algebra with a notion of global\nvariable. We also propose an extension of Hennessy-Milner logic with predicates\nto test and set the values of the global variables, and prove correspondence\nresults between validity of formulas in the extended logic and stateless\nbisimilarity and between validity of formulas in the extended logic without the\nset operator and state-based bisimilarity. We shall also present a translation\nfrom the process algebra with global variables to a fragment of mCRL2 that\npreserves the validity of formulas in the extended Hennessy-Milner logic.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:34:25 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bouwman", "Mark", "", "Eindhoven University of Technology"], ["Luttik", "Bas", "", "Eindhoven University of Technology"], ["Schols", "Wouter", "", "Eindhoven University of Technology"], ["Willemse", "Tim A. C.", "", "Eindhoven University of Technology"]]}, {"id": "2008.13357", "submitter": "EPTCS", "authors": "Rob van Glabbeek (Data61, CSIRO)", "title": "Reactive Temporal Logic", "comments": "In Proceedings EXPRESS/SOS 2020, arXiv:2008.12414", "journal-ref": "EPTCS 322, 2020, pp. 51-68", "doi": "10.4204/EPTCS.322.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas standard treatments of temporal logic are adequate for closed\nsystems, having no run-time interactions with their environment, they fall\nshort for reactive systems, interacting with their environments through\nsynchronisation of actions. This paper introduces reactive temporal logic, a\nform of temporal logic adapted for the study of reactive systems. I illustrate\nits use by applying it to formulate definitions of a fair scheduler, and of a\ncorrect mutual exclusion protocol. Previous definitions of these concepts were\nconceptually much more involved or less precise, leading to debates on whether\nor not a given protocol satisfies the implicit requirements.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:34:40 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["van Glabbeek", "Rob", "", "Data61, CSIRO"]]}, {"id": "2008.13359", "submitter": "EPTCS", "authors": "Manfred Schmidt-Schau{\\ss} (Goethe-University, Frankfurt, Germany),\n  David Sabel (LMU, Munich, Germany)", "title": "Correctly Implementing Synchronous Message Passing in the Pi-Calculus By\n  Concurrent Haskell's MVars", "comments": "In Proceedings EXPRESS/SOS 2020, arXiv:2008.12414", "journal-ref": "EPTCS 322, 2020, pp. 88-105", "doi": "10.4204/EPTCS.322.8", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparison of concurrent programming languages and correctness of program\ntransformations in concurrency are the focus of this research. As criterion we\nuse contextual semantics adapted to concurrency, where may -- as well as should\n-- convergence are observed. We investigate the relation between the\nsynchronous pi-calculus and a core language of Concurrent Haskell (CH). The\ncontextual semantics is on the one hand forgiving with respect to the details\nof the operational semantics, and on the other hand implies strong requirements\nfor the interplay between the processes after translation. Our result is that\nCH embraces the synchronous pi-calculus. Our main task is to find and prove\ncorrectness of encodings of pi-calculus channels by CH's concurrency\nprimitives, which are MVars. They behave like (blocking) 1-place buffers\nmodelling the shared-memory. The first developed translation uses an extra\nprivate MVar for every communication.We also automatically generate and check\npotentially correct translations that reuse the MVars where one MVar contains\nthe message and two additional MVars for synchronization are used to model the\nsynchronized communication of a single channel in the pi-calculus.Our automated\nexperimental results lead to the conjecture that one additional MVar is\ninsufficient.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:35:18 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Schmidt-Schau\u00df", "Manfred", "", "Goethe-University, Frankfurt, Germany"], ["Sabel", "David", "", "LMU, Munich, Germany"]]}, {"id": "2008.13601", "submitter": "Enric Rodriguez Carbonell", "authors": "Cristina Borralleras, Daniel Larraz, Albert Oliveras, Enric\n  Rodriguez-Carbonell and Albert Rubio", "title": "Incomplete SMT Techniques for Solving Non-Linear Formulas over the\n  Integers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present new methods for solving the Satisfiability Modulo Theories problem\nover the theory of Quantifier-Free Non-linear Integer Arithmetic, SMT(QF-NIA),\nwhich consists in deciding the satisfiability of ground formulas with integer\npolynomial constraints. Following previous work, we propose to solve\nSMT(QF-NIA) instances by reducing them to linear arithmetic: non-linear\nmonomials are linearized by abstracting them with fresh variables and by\nperforming case splitting on integer variables with finite domain. For\nvariables that do not have a finite domain, we can artificially introduce one\nby imposing a lower and an upper bound, and iteratively enlarge it until a\nsolution is found (or the procedure times out).\n  The key for the success of the approach is to determine, at each iteration,\nwhich domains have to be enlarged. Previously, unsatisfiable cores were used to\nidentify the domains to be changed, but no clue was obtained as to how large\nthe new domains should be. Here we explain two novel ways to guide this process\nby analyzing solutions to optimization problems: (i) to minimize the number of\nviolated artificial domain bounds, solved via a Max-SMT solver, and (ii) to\nminimize the distance with respect to the artificial domains, solved via an\nOptimization Modulo Theories (OMT) solver. Using this SMT-based optimization\ntechnology allows smoothly extending the method to also solve Max-SMT problems\nover non-linear integer arithmetic. Finally we leverage the resulting\nMax-SMT(QF-NIA) techniques to solve $\\exists \\forall$ formulas in a fragment of\nquantified non-linear arithmetic that appears commonly in verification and\nsynthesis applications.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:47:15 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Borralleras", "Cristina", ""], ["Larraz", "Daniel", ""], ["Oliveras", "Albert", ""], ["Rodriguez-Carbonell", "Enric", ""], ["Rubio", "Albert", ""]]}, {"id": "2008.13603", "submitter": "Martin Leinberger", "authors": "Martin Leinberger and Philipp Seifer and Tjitze Rienstra and Ralf\n  L\\\"ammel and Steffen Staab", "title": "Deciding SHACL Shape Containment through Description Logics Reasoning\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shapes Constraint Language (SHACL) allows for formalizing constraints\nover RDF data graphs. A shape groups a set of constraints that may be fulfilled\nby nodes in the RDF graph. We investigate the problem of containment between\nSHACL shapes. One shape is contained in a second shape if every graph node\nmeeting the constraints of the first shape also meets the constraints of the\nsecond. To decide shape containment, we map SHACL shape graphs into description\nlogic axioms such that shape containment can be answered by description logic\nreasoning. We identify several, increasingly tight syntactic restrictions of\nSHACL for which this approach becomes sound and complete.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:50:02 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 15:20:23 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Leinberger", "Martin", ""], ["Seifer", "Philipp", ""], ["Rienstra", "Tjitze", ""], ["L\u00e4mmel", "Ralf", ""], ["Staab", "Steffen", ""]]}, {"id": "2008.13610", "submitter": "Carlo A. Furia", "authors": "Claire Dross, Carlo A. Furia, Marieke Huisman, Rosemary Monahan, Peter\n  M\\\"uller", "title": "VerifyThis 2019: A Program Verification Competition (Extended Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VerifyThis is a series of program verification competitions that emphasize\nthe human aspect: participants tackle the verification of detailed behavioral\nproperties -- something that lies beyond the capabilities of fully automatic\nverification, and requires instead human expertise to suitably encode programs,\nspecifications, and invariants. This paper describes the 8th edition of\nVerifyThis, which took place at ETAPS 2019 in Prague. Thirteen teams entered\nthe competition, which consisted of three verification challenges and spanned\ntwo days of work. The report analyzes how the participating teams fared on\nthese challenges, reflects on what makes a verification challenge more or less\nsuitable for the typical VerifyThis participants, and outlines the difficulties\nof comparing the work of teams using wildly different verification approaches\nin a competition focused on the human aspect.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:58:18 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 10:03:25 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 07:52:53 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Dross", "Claire", ""], ["Furia", "Carlo A.", ""], ["Huisman", "Marieke", ""], ["Monahan", "Rosemary", ""], ["M\u00fcller", "Peter", ""]]}]