[{"id": "1312.0121", "submitter": "Samson Abramsky", "authors": "Samson Abramsky", "title": "Semantics of Interaction", "comments": "34 pages. Appeared in in Proceedings of the 1996 CLiCS Summer School,\n  Isaac Newton Institute, P. Dybjer and A. Pitts, eds. (Cambridge University\n  Press) 1997, 1--31", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an introduction to Game Semantics based on some lecture notes given\nat the CLiCS II summer school in Cambridge in 1995. We will focus on the recent\n(1994) work on Game semantics, which has led to some striking advances in the\nFull Abstraction problem for PCF and other programming languages. Our aim is to\ngive a genuinely elementary first introduction; we therefore present a\nsimplified version of game semantics, which nonetheless contains most of the\nessential concepts. The more complex game semantics used by Abramsky,\nJagadeesan and Malacaria and by Hyland and Ong to construct fully abstract\nmodels for PCF can be seen as refinements of what we present. Some background\nin category theory, type theory and linear logic would be helpful in reading\nthese notes.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2013 16:18:42 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Abramsky", "Samson", ""]]}, {"id": "1312.0127", "submitter": "Kim Bauters", "authors": "Kim Bauters, Steven Schockaert, Martine De Cock, Dirk Vermeir", "title": "Characterizing and Extending Answer Set Semantics using Possibility\n  Theory", "comments": "39 pages and 16 pages appendix with proofs. This article has been\n  accepted for publication in Theory and Practice of Logic Programming,\n  Copyright Cambridge University Press", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 79-116", "doi": "10.1017/S147106841300063X", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a popular framework for modeling\ncombinatorial problems. However, ASP cannot easily be used for reasoning about\nuncertain information. Possibilistic ASP (PASP) is an extension of ASP that\ncombines possibilistic logic and ASP. In PASP a weight is associated with each\nrule, where this weight is interpreted as the certainty with which the\nconclusion can be established when the body is known to hold. As such, it\nallows us to model and reason about uncertain information in an intuitive way.\nIn this paper we present new semantics for PASP, in which rules are interpreted\nas constraints on possibility distributions. Special models of these\nconstraints are then identified as possibilistic answer sets. In addition,\nsince ASP is a special case of PASP in which all the rules are entirely\ncertain, we obtain a new characterization of ASP in terms of constraints on\npossibility distributions. This allows us to uncover a new form of disjunction,\ncalled weak disjunction, that has not been previously considered in the\nliterature. In addition to introducing and motivating the semantics of weak\ndisjunction, we also pinpoint its computational complexity. In particular,\nwhile the complexity of most reasoning tasks coincides with standard\ndisjunctive ASP, we find that brave reasoning for programs with weak\ndisjunctions is easier.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2013 17:12:48 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bauters", "Kim", ""], ["Schockaert", "Steven", ""], ["De Cock", "Martine", ""], ["Vermeir", "Dirk", ""]]}, {"id": "1312.0200", "submitter": "S\\'ebastien Bardin", "authors": "S\\'ebastien Bardin and Arnaud Gotlieb", "title": "A Combined Approach for Constraints over Finite Domains and Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arrays are ubiquitous in the context of software verification. However,\neffective reasoning over arrays is still rare in CP, as local reasoning is\ndramatically ill-conditioned for constraints over arrays. In this paper, we\npropose an approach combining both global symbolic reasoning and local\nconsistency filtering in order to solve constraint systems involving arrays\n(with accesses, updates and size constraints) and finite-domain constraints\nover their elements and indexes. Our approach, named FDCC, is based on a\ncombination of a congruence closure algorithm for the standard theory of arrays\nand a CP solver over finite domains. The tricky part of the work lies in the\nbi-directional communication mechanism between both solvers. We identify the\nsignificant information to share, and design ways to master the communication\noverhead. Experiments on random instances show that FDCC solves more formulas\nthan any portfolio combination of the two solvers taken in isolation, while\noverhead is kept reasonable.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2013 11:06:10 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Bardin", "S\u00e9bastien", ""], ["Gotlieb", "Arnaud", ""]]}, {"id": "1312.0350", "submitter": "EPTCS", "authors": "Wietse Smid (University of Twente), Arend Rensink (University of\n  Twente)", "title": "Class Diagram Restructuring with GROOVE", "comments": "In Proceedings TTC 2013, arXiv:1311.7536", "journal-ref": "EPTCS 135, 2013, pp. 83-87", "doi": "10.4204/EPTCS.135.10", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the GROOVE solution to the \"Class Diagram Restructuring\"\ncase study of the Tool Transformation Contest 2013. We show that the visual\nrule formalism enables the required restructuring to be formulated in a very\nconcise manner. Moreover, the GROOVE functionality for state space exploration\nallows checking confluence. Performance-wise, however, the solution does not\nscale well.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2013 07:00:38 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Smid", "Wietse", "", "University of Twente"], ["Rensink", "Arend", "", "University of\n  Twente"]]}, {"id": "1312.0466", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov", "title": "Intensional Cyberforensics", "comments": "412 pages, 94 figures, 18 tables, 19 algorithms and listings; PhD\n  thesis; v2 corrects some typos and refs; also available on Spectrum at\n  http://spectrum.library.concordia.ca/977460/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LO cs.NI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on the application of intensional logic to cyberforensic\nanalysis and its benefits and difficulties are compared with the\nfinite-state-automata approach. This work extends the use of the intensional\nprogramming paradigm to the modeling and implementation of a cyberforensics\ninvestigation process with backtracing of event reconstruction, in which\nevidence is modeled by multidimensional hierarchical contexts, and proofs or\ndisproofs of claims are undertaken in an eductive manner of evaluation. This\napproach is a practical, context-aware improvement over the finite state\nautomata (FSA) approach we have seen in previous work. As a base implementation\nlanguage model, we use in this approach a new dialect of the Lucid programming\nlanguage, called Forensic Lucid, and we focus on defining hierarchical contexts\nbased on intensional logic for the distributed evaluation of cyberforensic\nexpressions. We also augment the work with credibility factors surrounding\ndigital evidence and witness accounts, which have not been previously modeled.\nThe Forensic Lucid programming language, used for this intensional\ncyberforensic analysis, formally presented through its syntax and operational\nsemantics. In large part, the language is based on its predecessor and\ncodecessor Lucid dialects, such as GIPL, Indexical Lucid, Lucx, Objective\nLucid, and JOOIP bound by the underlying intensional programming paradigm.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2013 14:16:48 GMT"}, {"version": "v2", "created": "Fri, 7 Mar 2014 19:06:53 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["Mokhov", "Serguei A.", ""]]}, {"id": "1312.0686", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "A Process Algebra for Games", "comments": "24 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using formal tools in computer science to describe games is an interesting\nproblem. We give games, exactly two person games, an axiomatic foundation based\non the process algebra ACP (Algebra of Communicating Process). A fresh operator\ncalled opponent's alternative composition operator (OA) is introduced into ACP\nto describe game trees and game strategies, called GameACP. And its sound and\ncomplete axiomatic system is naturally established. To model the outcomes of\ngames (the co-action of the player and the opponent), correspondingly in\nGameACP, the execution of GameACP processes, another operator called playing\noperator (PO) is extended into GameACP. We also establish a sound and complete\naxiomatic system for PO. To overcome the new occurred non-determinacy\nintroduced by GameACP, we extend truly concurrent process algebra APTC for\ngames called GameAPTC. Finally, we give the correctness theorem between the\noutcomes of games and the deductions of GameACP and GameAPTC processes.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2013 02:59:47 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 03:35:00 GMT"}, {"version": "v3", "created": "Sun, 4 May 2014 04:21:19 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2015 07:57:27 GMT"}, {"version": "v5", "created": "Wed, 8 May 2019 13:22:50 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1312.0697", "submitter": "Matthew de Brecht", "authors": "Matthew de Brecht", "title": "Levels of discontinuity, limit-computability, and jump operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general theory of jump operators, which is intended to provide\nan abstraction of the notion of \"limit-computability\" on represented spaces.\nJump operators also provide a framework with a strong categorical flavor for\ninvestigating degrees of discontinuity of functions and hierarchies of sets on\nrepresented spaces. We will provide a thorough investigation within this\nframework of a hierarchy of $\\Delta^0_2$-measurable functions between arbitrary\ncountably based $T_0$-spaces, which captures the notion of computing with\nordinal mind-change bounds. Our abstract approach not only raises new questions\nbut also sheds new light on previous results. For example, we introduce a\nnotion of \"higher order\" descriptive set theoretical objects, we generalize a\nrecent characterization of the computability theoretic notion of \"lowness\" in\nterms of adjoint functors, and we show that our framework encompasses ordinal\nquantifications of the non-constructiveness of Hilbert's finite basis theorem.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2013 04:53:31 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["de Brecht", "Matthew", ""]]}, {"id": "1312.0714", "submitter": "Andrei Rusu", "authors": "Andrei Rusu", "title": "On sufficient conditions for expressibility of constants in the 4-valued\n  extension of the propositional provability logic $GL$", "comments": "17 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In the present paper we consider the simplest non-classical extension $GL4$\nof the well-known propositional provability logic $GL$ together with the notion\nof expressibility of formulas in a logic proposed by A. V. Kuznetsov.\nConditions for expressibility of constants in the 4-valued extension\n$L\\mathfrak{B}_2$ of $GL$ are found out, which were first announced in a\nauthor's paper in 1996.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2013 06:54:59 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["Rusu", "Andrei", ""]]}, {"id": "1312.1070", "submitter": "Aravind Acharya", "authors": "K Vasanta Lakshmi, Aravind Acharya, Raghavan Komondoor", "title": "Checking Temporal Properties of Presburger Counter Systems using\n  Reachability Analysis", "comments": "34 pages, 7 figures, 3 algorithms, 10 theorems, Appendix with proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counter systems are a well-known and powerful modeling notation for\nspecifying infinite-state systems. In this paper we target the problem of\nchecking temporal properties of counter systems. We first focus on checking\nliveness properties only, and propose two semi decision techniques for these\nproperties. Both these techniques return a formula that encodes the set of\nreachable states of a given system that satisfy a given liveness property. A\nnovel aspect of our techniques is that they use reachability analysis\ntechniques, which are well studied in the literature, as black boxes, and are\nhence able to compute precise answers on a much wider class of systems than\nprevious approaches for the same problem. Secondly, they compute their results\nby iterative expansion or contraction, and hence permit an approximate solution\nto be obtained at any point. We state the formal properties of our techniques,\nand also provide experimental results using standard benchmarks to show the\nusefulness of our approaches. Finally, we provide a technique for checking\narbitrary CTL temporal properties, which use the liveness property checking\ntechniques mentioned above as black boxes.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 09:08:15 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 11:09:10 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Lakshmi", "K Vasanta", ""], ["Acharya", "Aravind", ""], ["Komondoor", "Raghavan", ""]]}, {"id": "1312.1094", "submitter": "Christoph Rauch", "authors": "Thomas Seiller", "title": "Interaction Graphs: Exponentials", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (August\n  30, 2019) lmcs:5730", "doi": "10.23638/LMCS-15(3:25)2019", "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is the fourth of a series exposing a systematic combinatorial\napproach to Girard's Geometry of Interaction (GoI) program. The GoI program\naims at obtaining particular realisability models for linear logic that\naccounts for the dynamics of cut-elimination. This fourth paper tackles the\ncomplex issue of defining exponential connectives in this framework. For that\npurpose, we use the notion of \\emph{graphings}, a generalisation of graphs\nwhich was defined in earlier work. We explain how to define a GoI for\nElementary Linear Logic (ELL) with second-order quantification, a sub-system of\nlinear logic that captures the class of elementary time computable functions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 10:13:24 GMT"}, {"version": "v2", "created": "Sat, 24 May 2014 14:58:22 GMT"}, {"version": "v3", "created": "Tue, 8 Jul 2014 08:54:08 GMT"}, {"version": "v4", "created": "Fri, 23 Aug 2019 13:32:56 GMT"}, {"version": "v5", "created": "Thu, 29 Aug 2019 10:52:56 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Seiller", "Thomas", ""]]}, {"id": "1312.1120", "submitter": "Samson Abramsky", "authors": "Samson Abramsky and Radha Jagadeesan", "title": "A Game Semantics for Generic Polymorphism", "comments": "41 pages", "journal-ref": "Annals of Pure and Applied Logic, vol 133, 3-37, 2005", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genericity is the idea that the same program can work at many different data\ntypes. Longo, Milstead and Soloviev proposed to capture the inability of\ngeneric programs to probe the structure of their instances by the following\nequational principle: if two generic programs, viewed as terms of type $\\forall\nX. \\, A[X]$, are equal at any given instance $A[T]$, then they are equal at all\ninstances. They proved that this rule is admissible in a certain extension of\nSystem F, but finding a semantically motivated model satisfying this principle\nremained an open problem.\n  In the present paper, we construct a categorical model of polymorphism, based\non game semantics, which contains a large collection of generic types. This\nmodel builds on two novel constructions:\n  -- A direct interpretation of variable types as games, with a natural notion\nof substitution of games. This allows moves in games A[T] to be decomposed into\nthe generic part from A, and the part pertaining to the instance T. This leads\nto a simple and natural notion of generic strategy.\n  -- A \"relative polymorphic product\" which expresses quantification over the\ntype variable X in the variable type A with respect to a \"universe'\" which is\nexplicitly given as an additional parameter B. We then solve a recursive\nequation involving this relative product to obtain a universe in a suitably\n\"absolute\" sense.\n  Full Completeness for ML types (universal closures of quantifier-free types)\nis proved for this model.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 11:54:34 GMT"}], "update_date": "2013-12-05", "authors_parsed": [["Abramsky", "Samson", ""], ["Jagadeesan", "Radha", ""]]}, {"id": "1312.1225", "submitter": "Alasdair Armstrong", "authors": "Alasdair Armstrong, Victor B. F. Gomes, Georg Struth", "title": "Algebraic Principles for Rely-Guarantee Style Concurrency Verification\n  Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide simple equational principles for deriving rely-guarantee-style\ninference rules and refinement laws based on idempotent semirings. We link the\nalgebraic layer with concrete models of programs based on languages and\nexecution traces. We have implemented the approach in Isabelle/HOL as a\nlightweight concurrency verification tool that supports reasoning about the\ncontrol and data flow of concurrent programs with shared variables at different\nlevels of abstraction. This is illustrated on two simple verification examples.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 16:03:39 GMT"}], "update_date": "2013-12-05", "authors_parsed": [["Armstrong", "Alasdair", ""], ["Gomes", "Victor B. F.", ""], ["Struth", "Georg", ""]]}, {"id": "1312.1399", "submitter": "Matija Pretnar", "authors": "Gordon D Plotkin (Laboratory for Foundations of Computer Science,\n  School of Informatics, Universit), Matija Pretnar (Faculty for mathematics\n  and physics, University of Ljubljana)", "title": "Handling Algebraic Effects", "comments": "36 pages", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 4 (December\n  17, 2013) lmcs:705", "doi": "10.2168/LMCS-9(4:23)2013", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic effects are computational effects that can be represented by an\nequational theory whose operations produce the effects at hand. The free model\nof this theory induces the expected computational monad for the corresponding\neffect. Algebraic effects include exceptions, state, nondeterminism,\ninteractive input/output, and time, and their combinations. Exception handling,\nhowever, has so far received no algebraic treatment. We present such a\ntreatment, in which each handler yields a model of the theory for exceptions,\nand each handling construct yields the homomorphism induced by the universal\nproperty of the free model. We further generalise exception handlers to\narbitrary algebraic effects. The resulting programming construct includes many\npreviously unrelated examples from both theory and practice, including\nrelabelling and restriction in Milner's CCS, timeout, rollback, and stream\nredirection.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 00:52:00 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2013 20:40:07 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Plotkin", "Gordon D", "", "Laboratory for Foundations of Computer Science,\n  School of Informatics, Universit"], ["Pretnar", "Matija", "", "Faculty for mathematics\n  and physics, University of Ljubljana"]]}, {"id": "1312.1411", "submitter": "Vincent Nimal", "authors": "Jade Alglave, Daniel Kroening, Vincent Nimal, Daniel Poetzl", "title": "Don't sit on the fence: A static analysis approach to automatic fence\n  insertion", "comments": "19 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern architectures rely on memory fences to prevent undesired weakenings of\nmemory consistency. As the fences' semantics may be subtle, the automation of\ntheir placement is highly desirable. But precise methods for restoring\nconsistency do not scale to deployed systems code. We choose to trade some\nprecision for genuine scalability: our technique is suitable for large code\nbases. We implement it in our new musketeer tool, and detail experiments on\nmore than 350 executables of packages found in Debian Linux 7.1, e.g. memcached\n(about 10000 LoC).\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 02:11:11 GMT"}, {"version": "v2", "created": "Mon, 9 Jun 2014 17:54:46 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Alglave", "Jade", ""], ["Kroening", "Daniel", ""], ["Nimal", "Vincent", ""], ["Poetzl", "Daniel", ""]]}, {"id": "1312.1672", "submitter": "Ronald de Haan", "authors": "Ronald de Haan, Stefan Szeider", "title": "The Parameterized Complexity of Reasoning Problems Beyond NP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's propositional satisfiability (SAT) solvers are extremely powerful and\ncan be used as an efficient back-end for solving NP-complete problems. However,\nmany fundamental problems in knowledge representation and reasoning are located\nat the second level of the Polynomial Hierarchy or even higher, and hence\npolynomial-time transformations to SAT are not possible, unless the hierarchy\ncollapses. Recent research shows that in certain cases one can break through\nthese complexity barriers by fixed-parameter tractable (fpt) reductions which\nexploit structural aspects of problem instances in terms of problem parameters.\nIn this paper we develop a general theoretical framework that supports the\nclassification of parameterized problems on whether they admit such an\nfpt-reduction to SAT or not. This framework is based on several new\nparameterized complexity classes. As a running example, we use the framework to\nclassify the complexity of the consistency problem for disjunctive answer set\nprogramming, with respect to various natural parameters. We underpin the\nrobustness of our theory by providing a characterization of the new complexity\nclasses in terms of weighted QBF satisfiability, alternating Turing machines,\nand first-order model checking. In addition, we provide a compendium of\nparameterized problems that are complete for the new complexity classes,\nincluding problems related to Knowledge Representation and Reasoning, Logic,\nand Combinatorics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 20:20:06 GMT"}, {"version": "v2", "created": "Wed, 9 Jul 2014 13:01:25 GMT"}, {"version": "v3", "created": "Fri, 31 Oct 2014 16:33:04 GMT"}, {"version": "v4", "created": "Fri, 1 Jul 2016 17:37:52 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["de Haan", "Ronald", ""], ["Szeider", "Stefan", ""]]}, {"id": "1312.2334", "submitter": "Matija Pretnar", "authors": "Matija Pretnar (University of Ljubljana)", "title": "Inferring Algebraic Effects", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 3 (September\n  12, 2014) lmcs:1004", "doi": "10.2168/LMCS-10(3:21)2014", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a complete polymorphic effect inference algorithm for an ML-style\nlanguage with handlers of not only exceptions, but of any other algebraic\neffect such as input & output, mutable references and many others. Our main aim\nis to offer the programmer a useful insight into the effectful behaviour of\nprograms. Handlers help here by cutting down possible effects and the resulting\nlengthy output that often plagues precise effect systems. Additionally, we\npresent a set of methods that further simplify the displayed types, some even\nby deliberately hiding inferred information from the programmer.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 08:13:19 GMT"}, {"version": "v2", "created": "Mon, 8 Sep 2014 18:38:58 GMT"}, {"version": "v3", "created": "Thu, 11 Sep 2014 19:51:32 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Pretnar", "Matija", "", "University of Ljubljana"]]}, {"id": "1312.2551", "submitter": "Dmitry Lesnik", "authors": "Dmitry Lesnik, Tobias Schaefer", "title": "A state vector algebra for algorithmic implementation of second-order\n  logic", "comments": "This paper has been withdrawn by the author due to numerous errors\n  found", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mathematical framework for mapping second-order logic relations\nonto a simple state vector algebra. Using this algebra, basic theorems of set\ntheory can be proven in an algorithmic way, hence by an expert system. We\nillustrate the use of the algebra with simple examples and show that, in\nprinciple, all theorems of basic set theory can be recovered in an elementary\nway. The developed technique can be used for an automated theorem proving in\nthe 1st and 2nd order logic.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 19:25:18 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 17:43:49 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2015 01:34:11 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Lesnik", "Dmitry", ""], ["Schaefer", "Tobias", ""]]}, {"id": "1312.2552", "submitter": "Carlos Olarte", "authors": "Moreno Falaschi, Carlos Olarte, Catuscia Palamidessi", "title": "Abstract Interpretation of Temporal Concurrent Constraint Programs", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 312-357", "doi": "10.1017/S1471068413000641", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Timed Concurrent Constraint Programming (tcc) is a declarative model for\nconcurrency offering a logic for specifying reactive systems, i.e. systems that\ncontinuously interact with the environment. The universal tcc formalism (utcc)\nis an extension of tcc with the ability to express mobility. Here mobility is\nunderstood as communication of private names as typically done for mobile\nsystems and security protocols. In this paper we consider the denotational\nsemantics for tcc, and we extend it to a \"collecting\" semantics for utcc based\non closure operators over sequences of constraints. Relying on this semantics,\nwe formalize a general framework for data flow analyses of tcc and utcc\nprograms by abstract interpretation techniques. The concrete and abstract\nsemantics we propose are compositional, thus allowing us to reduce the\ncomplexity of data flow analyses. We show that our method is sound and\nparametric with respect to the abstract domain. Thus, different analyses can be\nperformed by instantiating the framework. We illustrate how it is possible to\nreuse abstract domains previously defined for logic programming to perform, for\ninstance, a groundness analysis for tcc programs. We show the applicability of\nthis analysis in the context of reactive systems. Furthermore, we make also use\nof the abstract semantics to exhibit a secrecy flaw in a security protocol. We\nalso show how it is possible to make an analysis which may show that tcc\nprograms are suspension free. This can be useful for several purposes, such as\nfor optimizing compilation or for debugging.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 19:28:24 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Falaschi", "Moreno", ""], ["Olarte", "Carlos", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "1312.2696", "submitter": "EPTCS", "authors": "James Caldwell (University of Wyoming)", "title": "Structural Induction Principles for Functional Programmers", "comments": "In Proceedings TFPIE 2013, arXiv:1312.2216", "journal-ref": "EPTCS 136, 2013, pp. 16-26", "doi": "10.4204/EPTCS.136.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User defined recursive types are a fundamental feature of modern functional\nprogramming languages like Haskell, Clean, and the ML family of languages.\nProperties of programs defined by recursion on the structure of recursive types\nare generally proved by structural induction on the type. It is well known in\nthe theorem proving community how to generate structural induction principles\nfrom data type declarations. These methods deserve to be better know in the\nfunctional programming community. Existing functional programming textbooks\ngloss over this material. And yet, if functional programmers do not know how to\nwrite down the structural induction principle for a new type - how are they\nsupposed to reason about it? In this paper we describe an algorithm to generate\nstructural induction principles from data type declarations. We also discuss\nhow these methods are taught in the functional programming course at the\nUniversity of Wyoming. A Haskell implementation of the algorithm is included in\nan appendix.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 08:00:53 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Caldwell", "James", "", "University of Wyoming"]]}, {"id": "1312.2699", "submitter": "EPTCS", "authors": "Cinzia Di Giusto, Jorge A. P\\'erez", "title": "Session Types with Runtime Adaptation: Overview and Examples", "comments": "In Proceedings PLACES 2013, arXiv:1312.2218", "journal-ref": "EPTCS 137, 2013, pp. 21-32", "doi": "10.4204/EPTCS.137.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work, we have developed a session types discipline for a calculus\nthat features the usual constructs for session establishment and communication,\nbut also two novel constructs that enable communicating processes to be\nstopped, duplicated, or discarded at runtime. The aim is to understand whether\nknown techniques for the static analysis of structured communications scale up\nto the challenging context of context-aware, adaptable distributed systems, in\nwhich disciplined interaction and runtime adaptation are intertwined concerns.\nIn this short note, we summarize the main features of our session-typed\nframework with runtime adaptation, and recall its basic correctness properties.\nWe illustrate our framework by means of examples. In particular, we present a\nsession representation of supervision trees, a mechanism for enforcing\nfault-tolerant applications in the Erlang language.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 08:03:27 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Di Giusto", "Cinzia", ""], ["P\u00e9rez", "Jorge A.", ""]]}, {"id": "1312.2700", "submitter": "EPTCS", "authors": "Yoichi Hirai (National Institute of Advanced Industrial Science and\n  Technology)", "title": "Session Types in Abelian Logic", "comments": "In Proceedings PLACES 2013, arXiv:1312.2218", "journal-ref": "EPTCS 137, 2013, pp. 33-52", "doi": "10.4204/EPTCS.137.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There was a PhD student who says \"I found a pair of wooden shoes. I put a\ncoin in the left and a key in the right. Next morning, I found those objects in\nthe opposite shoes.\" We do not claim existence of such shoes, but propose a\nsimilar programming abstraction in the context of typed lambda calculi. The\nresult, which we call the Amida calculus, extends Abramsky's linear lambda\ncalculus LF and characterizes Abelian logic.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 08:03:46 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Hirai", "Yoichi", "", "National Institute of Advanced Industrial Science and\n  Technology"]]}, {"id": "1312.2701", "submitter": "EPTCS", "authors": "Laura Bocchi (Imperial College, London), Romain Demangeon (Imperial\n  College, London)", "title": "Embedding Session Types in HML", "comments": "In Proceedings PLACES 2013, arXiv:1312.2218", "journal-ref": "EPTCS 137, 2013, pp. 53-62", "doi": "10.4204/EPTCS.137.5", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on the enhancement of multiparty session types with logical\nannotations enable the effective verification of properties on (1) the\nstructure of the conversations, (2) the sorts of the messages, and (3) the\nactual values exchanged. In [3] we extend this work to enable the specification\nand verification of mutual effects of multiple cross-session interactions. Here\nwe give a sound and complete embedding into the Hennessy-Milner logic to\njustify the expressiveness of the approach in [3] and to provide it with a\nlogical background that will enable us to compare it with similar approaches.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 08:03:49 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Bocchi", "Laura", "", "Imperial College, London"], ["Demangeon", "Romain", "", "Imperial\n  College, London"]]}, {"id": "1312.2702", "submitter": "EPTCS", "authors": "Tarmo Uustalu", "title": "Coinductive Big-Step Semantics for Concurrency", "comments": "In Proceedings PLACES 2013, arXiv:1312.2218", "journal-ref": "EPTCS 137, 2013, pp. 63-78", "doi": "10.4204/EPTCS.137.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a paper presented at SOS 2010, we developed a framework for big-step\nsemantics for interactive input-output in combination with divergence, based on\ncoinductive and mixed inductive-coinductive notions of resumptions, evaluation\nand termination-sensitive weak bisimilarity. In contrast to standard\ninductively defined big-step semantics, this framework handles divergence\nproperly; in particular, runs that produce some observable effects and then\ndiverge, are not \"lost\". Here we scale this approach for shared-variable\nconcurrency on a simple example language. We develop the metatheory of our\nsemantics in a constructive logic.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 08:03:57 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Uustalu", "Tarmo", ""]]}, {"id": "1312.2705", "submitter": "EPTCS", "authors": "Eduardo R. B. Marques (LASIGE/FCUL, Universidade of Lisbon), Francisco\n  Martins (LASIGE/FCUL, Universidade of Lisbon), Vasco T. Vasconcelos\n  (LASIGE/FCUL, Universidade of Lisbon), Nicholas Ng (Imperial College London),\n  Nuno Martins (LASIGE/FCUL, Universidade of Lisbon)", "title": "Towards deductive verification of MPI programs against session types", "comments": "In Proceedings PLACES 2013, arXiv:1312.2218", "journal-ref": "EPTCS 137, 2013, pp. 103-113", "doi": "10.4204/EPTCS.137.9", "report-no": null, "categories": "cs.DC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Message Passing Interface (MPI) is the de facto standard message-passing\ninfrastructure for developing parallel applications. Two decades after the\nfirst version of the library specification, MPI-based applications are nowadays\nroutinely deployed on super and cluster computers. These applications, written\nin C or Fortran, exhibit intricate message passing behaviours, making it hard\nto statically verify important properties such as the absence of deadlocks. Our\nwork builds on session types, a theory for describing protocols that provides\nfor correct-by-construction guarantees in this regard. We annotate MPI\nprimitives and C code with session type contracts, written in the language of a\nsoftware verifier for C. Annotated code is then checked for correctness with\nthe software verifier. We present preliminary results and discuss the\nchallenges that lie ahead for verifying realistic MPI program compliance\nagainst session types.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 08:04:28 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Marques", "Eduardo R. B.", "", "LASIGE/FCUL, Universidade of Lisbon"], ["Martins", "Francisco", "", "LASIGE/FCUL, Universidade of Lisbon"], ["Vasconcelos", "Vasco T.", "", "LASIGE/FCUL, Universidade of Lisbon"], ["Ng", "Nicholas", "", "Imperial College London"], ["Martins", "Nuno", "", "LASIGE/FCUL, Universidade of Lisbon"]]}, {"id": "1312.2706", "submitter": "EPTCS", "authors": "Romain Demeyer, Wim Vanhoof", "title": "Static Application-Level Race Detection in STM Haskell using Contracts", "comments": "In Proceedings PLACES 2013, arXiv:1312.2218. rde@info.fundp.ac.be;\n  wim.vanhoof@unamur.be", "journal-ref": "EPTCS 137, 2013, pp. 115-134", "doi": "10.4204/EPTCS.137.10", "report-no": null, "categories": "cs.LO cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing concurrent programs is a hard task, even when using high-level\nsynchronization primitives such as transactional memories together with a\nfunctional language with well-controlled side-effects such as Haskell, because\nthe interferences generated by the processes to each other can occur at\ndifferent levels and in a very subtle way. The problem occurs when a thread\nleaves or exposes the shared data in an inconsistent state with respect to the\napplication logic or the real meaning of the data. In this paper, we propose to\nassociate contracts to transactions and we define a program transformation that\nmakes it possible to extend static contract checking in the context of STM\nHaskell. As a result, we are able to check statically that each transaction of\na STM Haskell program handles the shared data in a such way that a given\nconsistency property, expressed in the form of a user-defined boolean function,\nis preserved. This ensures that bad interference will not occur during the\nexecution of the concurrent program.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 08:04:37 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Demeyer", "Romain", ""], ["Vanhoof", "Wim", ""]]}, {"id": "1312.2867", "submitter": "Chanabasayya Vastrad M", "authors": "Doreswamy and Chanabasayya M. Vastrad", "title": "Study Of E-Smooth Support Vector Regression And Comparison With E-\n  Support Vector Regression And Potential Support Vector Machines For\n  Prediction For The Antitubercular Activity Of Oxazolines And Oxazoles\n  Derivatives", "comments": null, "journal-ref": "Published International Journal on Soft Computing, Artificial\n  Intelligence and Applications (IJSCAI), Vol.2, No.2, April 2013", "doi": "10.5121/ijscai.2013.2204", "report-no": null, "categories": "cs.CE cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A new smoothing method for solving ? -support vector regression (?-SVR),\ntolerating a small error in fitting a given data sets nonlinearly is proposed\nin this study. Which is a smooth unconstrained optimization reformulation of\nthe traditional linear programming associated with a ?-insensitive support\nvector regression. We term this redeveloped problem as ?-smooth support vector\nregression (?-SSVR). The performance and predictive ability of ?-SSVR are\ninvestigated and compared with other methods such as LIBSVM (?-SVR) and P-SVM\nmethods. In the present study, two Oxazolines and Oxazoles molecular descriptor\ndata sets were evaluated. We demonstrate the merits of our algorithm in a\nseries of experiments. Primary experimental results illustrate that our\nproposed approach improves the regression performance and the learning\nefficiency. In both studied cases, the predictive ability of the ?- SSVR model\nis comparable or superior to those obtained by LIBSVM and P-SVM. The results\nindicate that ?-SSVR can be used as an alternative powerful modeling method for\nregression studies. The experimental results show that the presented algorithm\n?-SSVR, plays better precisely and effectively than LIBSVMand P-SVM in\npredicting antitubercular activity.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 16:44:56 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Doreswamy", "", ""], ["Vastrad", "Chanabasayya M.", ""]]}, {"id": "1312.2894", "submitter": "Marta  Cialdea Mayer", "authors": "Marta Cialdea Mayer", "title": "A Proof Procedure for Hybrid Logic with Binders, Transitivity and\n  Relation Hierarchies (extended version)", "comments": "arXiv admin note: text overlap with arXiv:1210.5734", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous works, a tableau calculus has been defined, which constitutes a\ndecision procedure for hybrid logic with the converse and global modalities and\na restricted use of the binder. This work shows how to extend such a calculus\nto multi-modal logic enriched with features largely used in description logics:\ntransitivity and relation inclusion assertions.\n  The separate addition of either transitive relations or relation hierarchies\nto the considered decidable fragment of multi-modal hybrid logic can easily be\nshown to stay decidable, by resorting to results already proved in the\nliterature. However, such results do not directly allow for concluding whether\nthe logic including both features is still decidable. The existence of a\nterminating, sound and complete calculus for the considered logic proves that\nthe addition of transitive relations and relation hierarchies to such an\nexpressive decidable fragment of hybrid logic does not endanger decidability.\n  A further result proved in this work is that the logic extending the\nconsidered fragment with the addition of graded modalities (the modal\ncounterpart of number restrictions of description logics) has an undecidable\nsatisfiability problem, unless further syntactical restrictions are placed on\nthe universal graded modality.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 17:41:28 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Mayer", "Marta Cialdea", ""]]}, {"id": "1312.3059", "submitter": "Toshiyasu Arai", "authors": "Toshiyasu Arai", "title": "A polynomial time complete disjunction property in intuitionistic\n  propositional logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the polynomial time algorithms due to Buss and Mints(APAL 1999) and\nFerrari, Fiorentini and Fiorino(LPAR 2002) to yield a polynomial time complete\ndisjunction property in intuitionistic propositional logic.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 07:48:26 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Arai", "Toshiyasu", ""]]}, {"id": "1312.3372", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "On resources and tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Essentially being an extended abstract of the author's 1998 PhD thesis, this\npaper introduces an extension of the language of linear logic with a semantics\nwhich treats sentences as tasks rather than true/false statements. A resource\nis understood as an agent capable of accomplishing the task expressed by such a\nsentence. It is argued that the corresponding logic can be used as a planning\nlogic, whose advantage over the traditional comprehensive planning logics is\nthat it avoids the representationalframe problem and significantly alleviates\nthe inferential frame problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 23:39:01 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "1312.3412", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM, IMJ)", "title": "The Determinacy of Context-Free Games", "comments": "This paper is an extended version of a STACS 2012 conference paper\n  [arXiv:1112.1186]. It will appear in the Journal of Symbolic Logic", "journal-ref": "Journal of Symbolic Logic 78, 4 (2013) 1115-1134", "doi": null, "report-no": "EXT-JSL-STACS12", "categories": "cs.LO cs.GT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the determinacy of Gale-Stewart games whose winning sets are\naccepted by real-time 1-counter B\\\"uchi automata is equivalent to the\ndeterminacy of (effective) analytic Gale-Stewart games which is known to be a\nlarge cardinal assumption. We show also that the determinacy of Wadge games\nbetween two players in charge of omega-languages accepted by 1-counter B\\\"uchi\nautomata is equivalent to the (effective) analytic Wadge determinacy. Using\nsome results of set theory we prove that one can effectively construct a\n1-counter B\\\"uchi automaton A and a B\\\"uchi automaton B such that: (1) There\nexists a model of ZFC in which Player 2 has a winning strategy in the Wadge\ngame W(L(A), L(B)); (2) There exists a model of ZFC in which the Wadge game\nW(L(A), L(B)) is not determined. Moreover these are the only two possibilities,\ni.e. there are no models of ZFC in which Player 1 has a winning strategy in the\nWadge game W(L(A), L(B)).\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2013 07:33:31 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Finkel", "Olivier", "", "ELM, IMJ"]]}, {"id": "1312.3416", "submitter": "Michele Loreti", "authors": "Diego Latella, Michele Loreti, and Mieke Massink", "title": "On-the-fly Fast Mean-Field Model-Checking: Extended Version", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel, scalable, on-the-fly model-checking procedure is presented to verify\nbounded PCTL properties of selected individuals in the context of very large\nsystems of independent interacting objects. The proposed procedure combines\non-the-fly model checking techniques with deterministic mean-field\napproximation in discrete time. The asymptotic correctness of the procedure is\nshown and some results of the application of a prototype implementation of the\nFlyFast model-checker are presented.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2013 08:03:44 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Latella", "Diego", ""], ["Loreti", "Michele", ""], ["Massink", "Mieke", ""]]}, {"id": "1312.3797", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM, IMJ)", "title": "Infinite Games Specified by 2-Tape Automata", "comments": "arXiv admin note: substantial text overlap with arXiv:1312.3412", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the determinacy of Gale-Stewart games whose winning sets are\ninfinitary rational relations accepted by 2-tape B\\\"uchi automata is equivalent\nto the determinacy of (effective) analytic Gale-Stewart games which is known to\nbe a large cardinal assumption. Then we prove that winning strategies, when\nthey exist, can be very complex, i.e. highly non-effective, in these games. We\nprove the same results for Gale-Stewart games with winning sets accepted by\nreal-time 1-counter B\\\"uchi automata, then extending previous results obtained\nabout these games. Then we consider the strenghs of determinacy for these\ngames, and we prove that there is a transfinite sequence of 2-tape B\\\"uchi\nautomata (respectively, of real-time 1-counter B\\\"uchi automata) $A_\\alpha$,\nindexed by recursive ordinals, such that the games $G(L(A_\\alpha))$ have\nstrictly increasing strenghs of determinacy. Moreover there is a 2-tape B\\\"uchi\nautomaton (respectively, a real-time 1-counter B\\\"uchi automaton) B such that\nthe determinacy of G(L(B)) is equivalent to the (effective) analytic\ndeterminacy and thus has the maximal strength of determinacy. We show also that\nthe determinacy of Wadge games between two players in charge of infinitary\nrational relations accepted by 2-tape B\\\"uchi automata is equivalent to the\n(effective) analytic determinacy, and thus not provable in ZFC.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2013 12:50:37 GMT"}], "update_date": "2013-12-16", "authors_parsed": [["Finkel", "Olivier", "", "ELM, IMJ"]]}, {"id": "1312.3910", "submitter": "Petr Jancar", "authors": "Petr Jancar", "title": "Bisimulation equivalence of first-order grammars is Ackermann-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bisimulation equivalence (or bisimilarity) of first-order grammars is\ndecidable, as follows from the decidability result by Senizergues (1998, 2005)\nthat has been given in an equivalent framework of equational graphs with finite\nout-degree, or of pushdown automata (PDA) with only deterministic and popping\nepsilon-transitions. Benedikt, Goeller, Kiefer, and Murawski (2013) have shown\nthat the bisimilarity problem for PDA (even) without epsilon-transitions is\nnonelementary. Here we show Ackermann-hardness for bisimilarity of first-order\ngrammars. The grammars do not use explicit epsilon-transitions, but they\ncorrespond to the above mentioned PDA with (deterministic and popping)\nepsilon-transitions, and this feature is substantial in the presented\nlower-bound proof. The proof is based on a (polynomial) reduction from the\nreachability problem of reset (or lossy) counter machines, for which the\nAckermann-hardness has been shown by Schnoebelen (2010); in fact, this\nreachability problem is known to be Ackermann-complete in the hierarchy of\nfast-growing complexity classes defined by Schmitz (2013).\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2013 19:19:42 GMT"}], "update_date": "2013-12-16", "authors_parsed": [["Jancar", "Petr", ""]]}, {"id": "1312.3927", "submitter": "Christine Ga", "authors": "Christine Ga{\\ss}ner (Universit\\\"at Greifswald)", "title": "Strong Turing Degrees for Additive BSS RAM's", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 4 (December\n  25, 2013) lmcs:732", "doi": "10.2168/LMCS-9(4:25)2013", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the additive real BSS machines using only constants 0 and 1 and order\ntests we consider the corresponding Turing reducibility and characterize some\nsemi-decidable decision problems over the reals. In order to refine,\nstep-by-step, a linear hierarchy of Turing degrees with respect to this model,\nwe define several halting problems for classes of additive machines with\ndifferent abilities and construct further suitable decision problems. In the\nconstruction we use methods of the classical recursion theory as well as\ntechniques for proving bounds resulting from algebraic properties. In this way\nwe extend a known hierarchy of problems below the halting problem for the\nadditive machines using only equality tests and we present a further\nsubhierarchy of semi-decidable problems between the halting problems for the\nadditive machines using only equality tests and using order tests,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2013 20:01:44 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2013 10:14:08 GMT"}, {"version": "v3", "created": "Tue, 24 Dec 2013 01:20:06 GMT"}], "update_date": "2016-03-27", "authors_parsed": [["Ga\u00dfner", "Christine", "", "Universit\u00e4t Greifswald"]]}, {"id": "1312.4043", "submitter": "Alejandro Sanchez", "authors": "Alejandro S\\'anchez, C\\'esar S\\'anchez", "title": "Parametrized Invariance for Infinite State Processes", "comments": "15 pages plus appendix. Typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the uniform verification problem for infinite state processes, which\nconsists of proving that the parallel composition of an arbitrary number of\nprocesses satisfies a temporal property. Our practical motivation is to build a\ngeneral framework for the temporal verification of concurrent datatypes. The\ncontribution of this paper is a general method for the verification of safety\nproperties of parametrized programs that manipulate complex local and global\ndata, including mutable state in the heap. This method is based on the\nseparation between two concerns: (1) the interaction between executing\nthreads---handled by novel parametrized invariance rules---,and the data being\nmanipulated---handled by specialized decision procedures. The proof rules\ndischarge automatically a finite collection of verification conditions (VCs),\nthe number depending only on the size of the program description and the\nspecification, but not on the number of processes in any given instance or on\nthe kind of data manipulated. Moreover, all VCs are quantifier free, which\neases the development of decision procedures for complex data-types on top of\noff-the-shelf SMT solvers. We discuss the practical verification (of shape and\nalso functional correctness properties) of a concurrent list implementation\nbased on the method presented in this paper. Our tool also all VCs using a\ndecision procedure for a theory of list layouts in the heap built on top of\nstate-of-the-art SMT solvers.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2013 13:12:56 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2014 12:59:20 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["S\u00e1nchez", "Alejandro", ""], ["S\u00e1nchez", "C\u00e9sar", ""]]}, {"id": "1312.4126", "submitter": "Ana\\\"el Grandjean", "authors": "Bruno Durand and Guilhem Gamard and Anael Grandjean", "title": "Aperiodic tilings and entropy", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-09698-8_15", "report-no": null, "categories": "cs.LO math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a construction of Kari-Culik aperiodic tile set -\nthe smallest known until now. With the help of this construction, we prove that\nthis tileset has positive entropy. We also explain why this result was not\nexpected.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2013 09:09:51 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2013 16:16:22 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Durand", "Bruno", ""], ["Gamard", "Guilhem", ""], ["Grandjean", "Anael", ""]]}, {"id": "1312.4287", "submitter": "Guido Governatori", "authors": "Guido Governatori, Francesco Olivieri, Simone Scannapieco, Antonino\n  Rotolo, Matteo Cristani", "title": "Strategic Argumentation is NP-Complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the complexity of strategic argumentation for dialogue\ngames. A dialogue game is a 2-player game where the parties play arguments. We\nshow how to model dialogue games in a skeptical, non-monotonic formalism, and\nwe show that the problem of deciding what move (set of rules) to play at each\nturn is an NP-complete problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 10:09:06 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Governatori", "Guido", ""], ["Olivieri", "Francesco", ""], ["Scannapieco", "Simone", ""], ["Rotolo", "Antonino", ""], ["Cristani", "Matteo", ""]]}, {"id": "1312.4381", "submitter": "Jesse Alama", "authors": "Jesse Alama", "title": "A machine-assisted view of paraconsistency", "comments": "7 pages. Submitted to EBL 2014 (Encontro Brasileiro de L\\'ogica /\n  Brazilian Logic Meeting 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a newcomer, paraconsistent logics can be difficult to grasp. Even experts\nin logic can find the concept of paraconsistency to be suspicious or misguided,\nif not actually wrong. The problem is that although they usually have much in\ncommon with more familiar logics (such as intuitionistic or classical logic),\nparaconsistent logics necessarily disagree in other parts of the logical\nterrain which one might have thought were not up for debate. Thus, one's\nlogical intuitions may need to be recalibrated to work skillfully with\nparaconsistency. To get started, one should clearly appreciate the possibility\nof paraconsistent logics and the genuineness of the distinctions to which\nparaconsistency points. For this purpose, one typically encounters matrices\ninvolving more than two truth values to characterize suitable consequence\nrelations. In the eyes of a two-valued skeptic, such an approach might seem\ndubious. Even a non-skeptic might wonder if there's another way. To this end,\nto explore the basic notions of paraconsistent logic with the assistance of\nautomated reasoning techniques. Such an approach has merit because by\ndelegating some of the logical work to a machine, one's logical \"biases\" become\nexternalized. The result is a new way to appreciate that the distinctions to\nwhich paraconsistent logic points are indeed genuine. Our approach can even\nsuggest new questions and problems for the paraconsistent logic community.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 14:43:54 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Alama", "Jesse", ""]]}, {"id": "1312.4507", "submitter": "Alejandro Diaz-Caro", "authors": "Alejandro D\\'iaz-Caro (LIPN), Giulio Manzonetto (LIPN), Michele Pagani\n  (LIPN)", "title": "Call-by-value non-determinism in a linear logic type discipline", "comments": null, "journal-ref": "Logical Foundations of Computer Science 7734 (2013) 164-178", "doi": "10.1007/978-3-642-35722-0_12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the call-by-value lambda-calculus extended with a may-convergent\nnon-deterministic choice and a must-convergent parallel composition. Inspired\nby recent works on the relational semantics of linear logic and non-idempotent\nintersection types, we endow this calculus with a type system based on the\nso-called Girard's second translation of intuitionistic logic into linear\nlogic. We prove that a term is typable if and only if it is converging, and\nthat its typing tree carries enough information to give a bound on the length\nof its lazy call-by-value reduction. Moreover, when the typing tree is minimal,\nsuch a bound becomes the exact length of the reduction.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 20:29:41 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["D\u00edaz-Caro", "Alejandro", "", "LIPN"], ["Manzonetto", "Giulio", "", "LIPN"], ["Pagani", "Michele", "", "LIPN"]]}, {"id": "1312.4524", "submitter": "Konrad W. Schwerdtfeger", "authors": "Konrad W. Schwerdtfeger", "title": "A Computational Trichotomy for Connectivity of Boolean Satisfiability", "comments": "27 pages; severe error in the proof of Lemma 19 (now Lemma 23)\n  corrected; all results remain true, but some new definitions and lemmas were\n  necessary; also, a further error of Gopalan et al.'s paper is explained and\n  corrected; several other improvements. Text overlap with arXiv:cs/0609072 due\n  to corrections of that paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For Boolean satisfiability problems, the structure of the solution space is\ncharacterized by the solution graph, where the vertices are the solutions, and\ntwo solutions are connected iff they differ in exactly one variable. In 2006,\nGopalan et al. studied connectivity properties of the solution graph and\nrelated complexity issues for CSPs, motivated mainly by research on\nsatisfiability algorithms and the satisfiability threshold. They proved\ndichotomies for the diameter of connected components and for the complexity of\nthe st-connectivity question, and conjectured a trichotomy for the connectivity\nquestion.\n  Building on this work, we here prove the trichotomy: Connectivity is either\nin P, coNP-complete, or PSPACE-complete. Also, we correct a minor mistake of\nGopalan et al., which leads to a slight shift of the boundaries towards the\nhard side.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 20:59:09 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2013 22:41:37 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2013 20:52:49 GMT"}, {"version": "v4", "created": "Mon, 30 Dec 2013 20:59:36 GMT"}, {"version": "v5", "created": "Mon, 20 Jul 2015 19:59:30 GMT"}, {"version": "v6", "created": "Sun, 25 Oct 2015 11:19:38 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Schwerdtfeger", "Konrad W.", ""]]}, {"id": "1312.4652", "submitter": "Vladimir Naidenko G.", "authors": "Vladimir Naidenko (Institute of Mathematics, National Academy of\n  Sciences of Belarus)", "title": "Logics for complexity classes", "comments": "This article has been accepted for publication in Logic Journal of\n  IGPL Published by Oxford University Press; 23 pages, 2 figures", "journal-ref": "Logic Journal of the IGPL (2014) 22 (6): 1075-1093", "doi": "10.1093/jigpal/jzu027", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new syntactic characterization of problems complete via Turing reductions\nis presented. General canonical forms are developed in order to define such\nproblems. One of these forms allows us to define complete problems on ordered\nstructures, and another form to define them on unordered non-Aristotelian\nstructures. Using the canonical forms, logics are developed for complete\nproblems in various complexity classes. Evidence is shown that there cannot be\nany complete problem on Aristotelian structures for several complexity classes.\nOur approach is extended beyond complete problems. Using a similar form, a\nlogic is developed to capture the complexity class $NP\\cap coNP$ which very\nlikely contains no complete problem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 05:54:04 GMT"}, {"version": "v2", "created": "Mon, 29 Sep 2014 10:01:02 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Naidenko", "Vladimir", "", "Institute of Mathematics, National Academy of\n  Sciences of Belarus"]]}, {"id": "1312.4814", "submitter": "Hugo Daniel Macedo", "authors": "Hugo Daniel Macedo (INRIA Paris-Rocquencourt), Tayssir Touili (LIAFA)", "title": "Mining Malware Specifications through Static Reachability Analysis", "comments": "Lecture notes in computer science (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of malicious software (malware) is growing out of control.\nSyntactic signature based detection cannot cope with such growth and manual\nconstruction of malware signature databases needs to be replaced by computer\nlearning based approaches. Currently, a single modern signature capturing the\nsemantics of a malicious behavior can be used to replace an arbitrarily large\nnumber of old-fashioned syntactical signatures. However teaching computers to\nlearn such behaviors is a challenge. Existing work relies on dynamic analysis\nto extract malicious behaviors, but such technique does not guarantee the\ncoverage of all behaviors. To sidestep this limitation we show how to learn\nmalware signatures using static reachability analysis. The idea is to model\nbinary programs using pushdown systems (that can be used to model the stack\noperations occurring during the binary code execution), use reachability\nanalysis to extract behaviors in the form of trees, and use subtrees that are\ncommon among the trees extracted from a training set of malware files as\nsignatures. To detect malware we propose to use a tree automaton to compactly\nstore malicious behavior trees and check if any of the subtrees extracted from\nthe file under analysis is malicious. Experimental data shows that our approach\ncan be used to learn signatures from a training set of malware files and use\nthem to detect a test set of malware that is 5 times the size of the training\nset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 15:08:39 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Macedo", "Hugo Daniel", "", "INRIA Paris-Rocquencourt"], ["Touili", "Tayssir", "", "LIAFA"]]}, {"id": "1312.4828", "submitter": "Federico Cerutti", "authors": "Federico Cerutti, Alice Toniolo, Nir Oren, Timothy J. Norman", "title": "Subjective Logic Operators in Trust Assessment: an Empirical Study", "comments": "Submitted to Information Systems Frontiers Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational trust mechanisms aim to produce trust ratings from both direct\nand indirect information about agents' behaviour. Subjective Logic (SL) has\nbeen widely adopted as the core of such systems via its fusion and discount\noperators. In recent research we revisited the semantics of these operators to\nexplore an alternative, geometric interpretation. In this paper we present a\nprincipled desiderata for discounting and fusion operators in SL. Building upon\nthis we present operators that satisfy these desirable properties, including a\nfamily of discount operators. We then show, through a rigorous empirical study,\nthat specific, geometrically interpreted operators significantly outperform\nstandard SL operators in estimating ground truth. These novel operators offer\nreal advantages for computational models of trust and reputation, in which they\nmay be employed without modifying other aspects of an existing system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 09:22:21 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Cerutti", "Federico", ""], ["Toniolo", "Alice", ""], ["Oren", "Nir", ""], ["Norman", "Timothy J.", ""]]}, {"id": "1312.4840", "submitter": "James Cheney", "authors": "James Cheney", "title": "A simple sequent calculus for nominal logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nominal logic is a variant of first-order logic that provides support for\nreasoning about bound names in abstract syntax. A key feature of nominal logic\nis the new-quantifier, which quantifies over fresh names (names not appearing\nin any values considered so far). Previous attempts have been made to develop\nconvenient rules for reasoning with the new-quantifier, but we argue that none\nof these attempts is completely satisfactory.\n  In this article we develop a new sequent calculus for nominal logic in which\nthe rules for the new- quantifier are much simpler than in previous attempts.\nWe also prove several structural and metatheoretic properties, including\ncut-elimination, consistency, and equivalence to Pitts' axiomatization of\nnominal logic.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 15:58:24 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Cheney", "James", ""]]}, {"id": "1312.4917", "submitter": "Pierre Lescanne", "authors": "Pierre Lescanne (LIP)", "title": "An exercise on streams: convergence acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents convergence acceleration, a method for computing\nefficiently the limit of numerical sequences as a typical application of\nstreams and higher-order functions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 19:53:28 GMT"}, {"version": "v2", "created": "Mon, 3 Mar 2014 19:43:27 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Lescanne", "Pierre", "", "LIP"]]}, {"id": "1312.5420", "submitter": "Olivier Hermant", "authors": "M\\'elanie Boudard (PRISM), Olivier Hermant (CRI)", "title": "Polarizing Double Negation Translations", "comments": null, "journal-ref": "LPAR 8312 (2013) 182-197", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Double-negation translations are used to encode and decode classical proofs\nin intuitionistic logic. We show that, in the cut-free fragment, we can\nsimplify the translations and introduce fewer negations. To achieve this, we\nconsider the polarization of the formul{\\ae}{} and adapt those translation to\nthe different connectives and quantifiers. We show that the embedding results\nstill hold, using a customized version of the focused classical sequent\ncalculus. We also prove the latter equivalent to more usual versions of the\nsequent calculus. This polarization process allows lighter embeddings, and\nsheds some light on the relationship between intuitionistic and classical\nconnectives.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 06:54:17 GMT"}], "update_date": "2013-12-20", "authors_parsed": [["Boudard", "M\u00e9lanie", "", "PRISM"], ["Hermant", "Olivier", "", "CRI"]]}, {"id": "1312.5686", "submitter": "Sylvain Schmitz", "authors": "Sylvain Schmitz", "title": "Complexity Hierarchies Beyond Elementary", "comments": "Version 3 is the published version in TOCT 8(1:3), 2016. I will keep\n  updating the catalogue of problems from Section 6 in future revisions", "journal-ref": "ACM Transactions on Computation Theory vol. 8, number 1, article\n  3, 2016", "doi": "10.1145/2858784", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hierarchy of fast-growing complexity classes and show its\nsuitability for completeness statements of many non elementary problems. This\nhierarchy allows the classification of many decision problems with a\nnon-elementary complexity, which occur naturally in logic, combinatorics,\nformal languages, verification, etc., with complexities ranging from simple\ntowers of exponentials to Ackermannian and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 18:30:18 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2013 22:45:45 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2016 10:57:51 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Schmitz", "Sylvain", ""]]}, {"id": "1312.5951", "submitter": "Ebrahim Ardeshir-Larijani", "authors": "Ebrahim Ardeshir-Larijani and Simon J. Gay and Rajagopal Nagarajan", "title": "Automated Verification of Quantum Protocols by Equivalence Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a technique and a tool for formal verification of\nvarious quantum information processing protocols. The tool uses stabilizer\nformalism and is capable of representing concurrent quantum protocol, thus is\nmore expressive than quantum circuits. We also report on experimental results\nof using our Quantum Equivalence Checker (QEC) to analyse a range of quantum\ninformation processing protocols.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 14:18:30 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Ardeshir-Larijani", "Ebrahim", ""], ["Gay", "Simon J.", ""], ["Nagarajan", "Rajagopal", ""]]}, {"id": "1312.6149", "submitter": "Michael Fink", "authors": "Amelia Harrison, Vladimir Lifschitz and Fangkai Yang", "title": "On the Semantics of Gringo", "comments": "Proceedings of Answer Set Programming and Other Computing Paradigms\n  (ASPOCP 2013), 6th International Workshop, August 25, 2013, Istanbul, Turkey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Input languages of answer set solvers are based on the mathematically simple\nconcept of a stable model. But many useful constructs available in these\nlanguages, including local variables, conditional literals, and aggregates,\ncannot be easily explained in terms of stable models in the sense of the\noriginal definition of this concept and its straightforward generalizations.\nManuals written by designers of answer set solvers usually explain such\nconstructs using examples and informal comments that appeal to the user's\nintuition, without references to any precise semantics. We propose to approach\nthe problem of defining the semantics of gringo programs by translating them\ninto the language of infinitary propositional formulas. This semantics allows\nus to study equivalent transformations of gringo programs using natural\ndeduction in infinitary propositional logic.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 21:33:55 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Harrison", "Amelia", ""], ["Lifschitz", "Vladimir", ""], ["Yang", "Fangkai", ""]]}, {"id": "1312.6155", "submitter": "Stefan Ratschan", "authors": "Milan Hlad\\'ik, Stefan Ratschan", "title": "Efficient Solution of a Class of Quantified Constraints with Quantifier\n  Prefix Exists-Forall", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various applications the search for certificates for certain properties\n(e.g., stability of dynamical systems, program termination) can be formulated\nas a quantified constraint solving problem with quantifier prefix\nexists-forall. In this paper, we present an algorithm for solving a certain\nclass of such problems based on interval techniques in combination with\nconservative linear programming approximation. In comparison with previous\nwork, the method is more general - allowing general Boolean structure in the\ninput constraint, and more efficient - using splitting heuristics that learn\nfrom the success of previous linear programming approximations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 21:41:18 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 15:02:33 GMT"}, {"version": "v3", "created": "Tue, 24 Jun 2014 20:07:13 GMT"}], "update_date": "2014-06-26", "authors_parsed": [["Hlad\u00edk", "Milan", ""], ["Ratschan", "Stefan", ""]]}, {"id": "1312.6323", "submitter": "Daniel M Leivant", "authors": "Daniel M Leivant (Indiana University)", "title": "Global semantic typing for inductive and coinductive computing", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (December\n  25, 2014) lmcs:1116", "doi": "10.2168/LMCS-10(4:18)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive and coinductive types are commonly construed as ontological\n(Church-style) types, denoting canonical data-sets such as natural numbers,\nlists, and streams. For various purposes, notably the study of programs in the\ncontext of global semantics, it is preferable to think of types as semantical\nproperties (Curry-style). Intrinsic theories were introduced in the late 1990s\nto provide a purely logical framework for reasoning about programs and their\nsemantic types. We extend them here to data given by any combination of\ninductive and coinductive definitions. This approach is of interest because it\nfits tightly with syntactic, semantic, and proof theoretic fundamentals of\nformal logic, with potential applications in implicit computational complexity\nas well as extraction of programs from proofs. We prove a Canonicity Theorem,\nshowing that the global definition of program typing, via the usual (Tarskian)\nsemantics of first-order logic, agrees with their operational semantics in the\nintended model. Finally, we show that every intrinsic theory is interpretable\nin a conservative extension of first-order arithmetic. This means that\nquantification over infinite data objects does not lead, on its own, to\nproof-theoretic strength beyond that of Peano Arithmetic. Intrinsic theories\nare perfectly amenable to formulas-as-types Curry-Howard morphisms, and were\nused to characterize major computational complexity classes Their extensions\ndescribed here have similar potential which has already been applied.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2013 00:01:46 GMT"}, {"version": "v2", "created": "Wed, 24 Dec 2014 15:12:16 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Leivant", "Daniel M", "", "Indiana University"]]}, {"id": "1312.6679", "submitter": "Konrad W. Schwerdtfeger", "authors": "Konrad W. Schwerdtfeger", "title": "The Connectivity of Boolean Satisfiability: Dichotomies for Formulas and\n  Circuits", "comments": "20 pages, several improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For Boolean satisfiability problems, the structure of the solution space is\ncharacterized by the solution graph, where the vertices are the solutions, and\ntwo solutions are connected iff they differ in exactly one variable. In 2006,\nGopalan et al. studied connectivity properties of the solution graph and\nrelated complexity issues for CSPs, motivated mainly by research on\nsatisfiability algorithms and the satisfiability threshold. They proved\ndichotomies for the diameter of connected components and for the complexity of\nthe st-connectivity question, and conjectured a trichotomy for the connectivity\nquestion. Recently, we were able to establish the trichotomy [arXiv:1312.4524].\n  Here, we consider connectivity issues of satisfiability problems defined by\nBoolean circuits and propositional formulas that use gates, resp. connectives,\nfrom a fixed set of Boolean functions. We obtain dichotomies for the diameter\nand the two connectivity problems: on one side, the diameter is linear in the\nnumber of variables, and both problems are in P, while on the other side, the\ndiameter can be exponential, and the problems are PSPACE-complete. For\npartially quantified formulas, we show an analogous dichotomy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 20:59:20 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2013 20:55:08 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2015 11:20:26 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Schwerdtfeger", "Konrad W.", ""]]}, {"id": "1312.7062", "submitter": "EPTCS", "authors": "Anton Wijs (Eindhoven University of Technology), Dragan\n  Bo\\v{s}na\\v{c}ki (Eindhoven University of Technology), Stefan Edelkamp\n  (University of Bremen)", "title": "Proceedings 2nd Workshop on GRAPH Inspection and Traversal Engineering", "comments": null, "journal-ref": "EPTCS 138, 2013", "doi": "10.4204/EPTCS.138", "report-no": null, "categories": "cs.DS cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the proceedings of the Second Workshop on GRAPH Inspection and\nTraversal Engineering (GRAPHITE 2013), which took place on March 24, 2013 in\nRome, Italy, as a satellite event of the 16th European Joint Conferences on\nTheory and Practice of Software (ETAPS 2013).\n  The topic of the GRAPHITE workshop is graph analysis in all its forms in\ncomputer science. Graphs are used to represent data in many application areas,\nand they are subjected to various computational algorithms in order to acquire\nthe desired information. These graph algorithms tend to have common\ncharacteristics, such as duplicate detection to guarantee their termination,\nindependent of their application domain. Over the past few years, it has been\nshown that the scalability of such algorithms can be dramatically improved by\nusing, e.g., external memory, by exploiting parallel architectures, such as\nclusters, multi-core CPUs, and graphics processing units, and by using\nheuristics to guide the search. Novel techniques to further scale graph search\nalgorithms, and new applications of graph search are within the scope of this\nworkshop.\n  Another topic of interest of the event is more related to the structural\nproperties of graphs: which kind of graph characteristics are relevant for a\nparticular application area, and how can these be measured? Finally, any novel\nway of using graphs for a particular application area is on topic.\n  The goal of this event is to gather scientists from different communities,\nsuch as model checking, artificial intelligence planning, game playing, and\nalgorithm engineering, who do research on graph search algorithms, such that\nawareness of each others' work is increased.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2013 07:26:41 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Wijs", "Anton", "", "Eindhoven University of Technology"], ["Bo\u0161na\u010dki", "Dragan", "", "Eindhoven University of Technology"], ["Edelkamp", "Stefan", "", "University of Bremen"]]}, {"id": "1312.7275", "submitter": "Michael Pfender", "authors": "Michael Pfender", "title": "Arithmetical Foundations - Recursion. Evaluation. Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Primitive recursion, mu-recursion, universal object and universe theories,\ncomplexity controlled iteration, code evaluation, soundness, decidability,\nG\\\"odel incompleteness theorems, inconsistency provability for set theory,\nconstructive consistency.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 15:51:49 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2015 14:02:57 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Pfender", "Michael", ""]]}, {"id": "1312.7284", "submitter": "Naohi Eguchi", "authors": "Martin Avanzini and Naohi Eguchi", "title": "A New Term Rewriting Characterisation of ETIME functions", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adopting former term rewriting characterisations of polytime and\nexponential-time computable functions, we introduce a new reduction order, the\nPath Order for ETIME (POE* for short), that is sound and complete for ETIME\ncomputable functions. The proposed reduction order for ETIME makes contrasts to\nthose related complexity classes clear.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 15:38:47 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2013 12:52:51 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Avanzini", "Martin", ""], ["Eguchi", "Naohi", ""]]}, {"id": "1312.7305", "submitter": "Vasco Brattka", "authors": "Vasco Brattka, Guido Gherardi and Rupert H\\\"olzl", "title": "Probabilistic Computability and Choice", "comments": "Information and Computation (accepted for publication)", "journal-ref": "Information and Computation 242 (2015) 249-286", "doi": "10.1016/j.ic.2015.03.005", "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational power of randomized computations on infinite\nobjects, such as real numbers. In particular, we introduce the concept of a Las\nVegas computable multi-valued function, which is a function that can be\ncomputed on a probabilistic Turing machine that receives a random binary\nsequence as auxiliary input. The machine can take advantage of this random\nsequence, but it always has to produce a correct result or to stop the\ncomputation after finite time if the random advice is not successful. With\npositive probability the random advice has to be successful. We characterize\nthe class of Las Vegas computable functions in the Weihrauch lattice with the\nhelp of probabilistic choice principles and Weak Weak K\\H{o}nig's Lemma. Among\nother things we prove an Independent Choice Theorem that implies that Las Vegas\ncomputable functions are closed under composition. In a case study we show that\nNash equilibria are Las Vegas computable, while zeros of continuous functions\nwith sign changes cannot be computed on Las Vegas machines. However, we show\nthat the latter problem admits randomized algorithms with weaker failure\nrecognition mechanisms. The last mentioned results can be interpreted such that\nthe Intermediate Value Theorem is reducible to the jump of Weak Weak\nK\\H{o}nig's Lemma, but not to Weak Weak K\\H{o}nig's Lemma itself. These\nexamples also demonstrate that Las Vegas computable functions form a proper\nsuperclass of the class of computable functions and a proper subclass of the\nclass of non-deterministically computable functions. We also study the impact\nof specific lower bounds on the success probabilities, which leads to a strict\nhierarchy of classes. In particular, the classical technique of probability\namplification fails for computations on infinite objects. We also investigate\nthe dependency on the underlying probability space.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 18:07:46 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2014 16:07:08 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2015 15:37:50 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Brattka", "Vasco", ""], ["Gherardi", "Guido", ""], ["H\u00f6lzl", "Rupert", ""]]}, {"id": "1312.7523", "submitter": "Luca Bortolussi", "authors": "Ezio Bartocci and Luca Bortolussi and Guido Sanguinetti", "title": "Learning Temporal Logical Properties Discriminating ECG models of\n  Cardiac Arrhytmias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to learn the formulae characterising the emergent\nbehaviour of a dynamical system from system observations. At a high level, the\napproach starts by devising a statistical dynamical model of the system which\noptimally fits the observations. We then propose general optimisation\nstrategies for selecting high support formulae (under the learnt model of the\nsystem) either within a discrete set of formulae of bounded complexity, or a\nparametric family of formulae. We illustrate and apply the methodology on an\nin-depth case study of characterising cardiac malfunction from\nelectro-cardiogram data, where our approach enables us to quantitatively\ndetermine the diagnostic power of a formula in discriminating between different\ncardiac conditions.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2013 11:44:26 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Bartocci", "Ezio", ""], ["Bortolussi", "Luca", ""], ["Sanguinetti", "Guido", ""]]}, {"id": "1312.7603", "submitter": "Daniel Bundala", "authors": "Daniel Bundala, Jo\\\"el Ouaknine", "title": "On the Complexity of Temporal-Logic Path Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a formula in a temporal logic such as LTL or MTL, a fundamental problem\nis the complexity of evaluating the formula on a given finite word. For LTL,\nthe complexity of this task was recently shown to be in NC. In this paper, we\npresent an NC algorithm for MTL, a quantitative (or metric) extension of LTL,\nand give an NCC algorithm for UTL, the unary fragment of LTL. At the time of\nwriting, MTL is the most expressive logic with an NC path-checking algorithm,\nand UTL is the most expressive fragment of LTL with a more efficient\npath-checking algorithm than for full LTL (subject to standard\ncomplexity-theoretic assumptions). We then establish a connection between LTL\npath checking and planar circuits, which we exploit to show that any further\nprogress in determining the precise complexity of LTL path checking would\nimmediately entail more efficient evaluation algorithms than are known for a\ncertain class of planar circuits. The connection further implies that the\ncomplexity of LTL path checking depends on the Boolean connectives allowed:\nadding Boolean exclusive or yields a temporal logic with P-complete\npath-checking problem.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2013 23:38:16 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 11:29:47 GMT"}, {"version": "v3", "created": "Mon, 28 Apr 2014 16:07:05 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Bundala", "Daniel", ""], ["Ouaknine", "Jo\u00ebl", ""]]}, {"id": "1312.7605", "submitter": "Juraj Stacho", "authors": "Barnaby Martin, Juraj Stacho", "title": "Constraint Satisfaction with Counting Quantifiers 2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study constraint satisfaction problems (CSPs) in the presence of counting\nquantifiers $\\exists^{\\geq j}$, asserting the existence of $j$ distinct\nwitnesses for the variable in question. As a continuation of our previous (CSR\n2012) paper, we focus on the complexity of undirected graph templates. As our\nmain contribution, we settle the two principal open questions proposed in (CSR\n2012). Firstly, we complete the classification of clique templates by proving a\nfull trichotomy for all possible combinations of counting quantifiers and\nclique sizes, placing each case either in P, NP-complete or Pspace-complete.\nThis involves resolution of the cases in which we have the single quantifier\n$\\exists^{\\geq j}$ on the clique $K_{2j}$. Secondly, we confirm a conjecture\nfrom (CSR 2012), which proposes a full dichotomy for $\\exists$ and\n$\\exists^{\\geq 2}$ on all finite undirected graphs. The main thrust of this\nsecond result is the solution of the complexity for the infinite path which we\nprove is a polynomial-time solvable problem. By adapting the algorithm for the\ninfinite path we are then able to solve the problem for finite paths, and then\ntrees and forests. Thus as a corollary to this work, combining with the other\ncases from (CSR 2012), we obtain a full dichotomy for $\\exists$ and\n$\\exists^{\\geq 2}$ quantifiers on finite graphs, each such problem being either\nin P or NP-hard. Finally, we persevere with the work of (CSR 2012) in exploring\ncases in which there is dichotomy between P and Pspace-complete, in contrast\nwith situations in which the intermediate NP-completeness may appear.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 00:06:43 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Martin", "Barnaby", ""], ["Stacho", "Juraj", ""]]}, {"id": "1312.7645", "submitter": "Rob van Glabbeek", "authors": "Ansgar Fehnker, Rob van Glabbeek, Peter H\\\"ofner, Annabelle McIver,\n  Marius Portmann and Wee Lum Tan", "title": "A Process Algebra for Wireless Mesh Networks used for Modelling,\n  Verifying and Analysing AODV", "comments": null, "journal-ref": null, "doi": null, "report-no": "Technical Report 5513, NICTA, 2013", "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose AWN (Algebra for Wireless Networks), a process algebra tailored to\nthe modelling of Mobile Ad hoc Network (MANET) and Wireless Mesh Network (WMN)\nprotocols. It combines novel treatments of local broadcast, conditional unicast\nand data structures.\n  In this framework we present a rigorous analysis of the Ad hoc On-Demand\nDistance Vector (AODV) protocol, a popular routing protocol designed for MANETs\nand WMNs, and one of the four protocols currently standardised by the IETF\nMANET working group.\n  We give a complete and unambiguous specification of this protocol, thereby\nformalising the RFC of AODV, the de facto standard specification, given in\nEnglish prose. In doing so, we had to make non-evident assumptions to resolve\nambiguities occurring in that specification. Our formalisation models the exact\ndetails of the core functionality of AODV, such as route maintenance and error\nhandling, and only omits timing aspects.\n  The process algebra allows us to formalise and (dis)prove crucial properties\nof mesh network routing protocols such as loop freedom and packet delivery. We\nare the first to provide a detailed proof of loop freedom of AODV. In contrast\nto evaluations using simulation or model checking, our proof is generic and\nholds for any possible network scenario in terms of network topology, node\nmobility, etc. Due to ambiguities and contradictions the RFC specification\nallows several interpretations; we show for more than 5000 of them whether they\nare loop free or not, thereby demonstrating how the reasoning and proofs can\nrelatively easily be adapted to protocol variants.\n  Using our formal and unambiguous specification, we find shortcomings of AODV\nthat affect performance, e.g. the establishment of non-optimal routes, and some\nroutes not being found at all. We formalise improvements in the same process\nalgebra; carrying over the proofs is again easy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 07:18:04 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Fehnker", "Ansgar", ""], ["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""], ["McIver", "Annabelle", ""], ["Portmann", "Marius", ""], ["Tan", "Wee Lum", ""]]}, {"id": "1312.7699", "submitter": "Michael Pinsker", "authors": "Manuel Bodirsky and Michael Pinsker and Andr\\'as Pongr\\'acz", "title": "Reconstructing the topology of clones", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function clones are sets of functions on a fixed domain that are closed under\ncomposition and contain the projections. They carry a natural algebraic\nstructure, provided by the laws of composition which hold in them, as well as a\nnatural topological structure, provided by the topology of pointwise\nconvergence, under which composition of functions becomes continuous. Inspired\nby recent results indicating the importance of the topological ego of function\nclones even for originally algebraic problems, we study questions of the\nfollowing type: In which situations does the algebraic structure of a function\nclone determine its topological structure? We pay particular attention to\nfunction clones which contain an oligomorphic permutation group, and discuss\napplications of this situation in model theory and theoretical computer\nscience.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 12:51:42 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2014 20:23:18 GMT"}, {"version": "v3", "created": "Sat, 14 May 2016 17:43:46 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Pinsker", "Michael", ""], ["Pongr\u00e1cz", "Andr\u00e1s", ""]]}, {"id": "1312.7758", "submitter": "Clemens Dubslaff", "authors": "Clemens Dubslaff, Sascha Kl\\\"uppelholz, Christel Baier", "title": "Probabilistic Model Checking for Energy Analysis in Software Product\n  Lines", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a software product line (SPL), a collection of software products is\ndefined by their commonalities in terms of features rather than explicitly\nspecifying all products one-by-one. Several verification techniques were\nadapted to establish temporal properties of SPLs. Symbolic and family-based\nmodel checking have been proven to be successful for tackling the combinatorial\nblow-up arising when reasoning about several feature combinations. However,\nmost formal verification approaches for SPLs presented in the literature focus\non the static SPLs, where the features of a product are fixed and cannot be\nchanged during runtime. This is in contrast to dynamic SPLs, allowing to adapt\nfeature combinations of a product dynamically after deployment. The main\ncontribution of the paper is a compositional modeling framework for dynamic\nSPLs, which supports probabilistic and nondeterministic choices and allows for\nquantitative analysis. We specify the feature changes during runtime within an\nautomata-based coordination component, enabling to reason over strategies how\nto trigger dynamic feature changes for optimizing various quantitative\nobjectives, e.g., energy or monetary costs and reliability. For our framework\nthere is a natural and conceptually simple translation into the input language\nof the prominent probabilistic model checker PRISM. This facilitates the\napplication of PRISM's powerful symbolic engine to the operational behavior of\ndynamic SPLs and their family-based analysis against various quantitative\nqueries. We demonstrate feasibility of our approach by a case study issuing an\nenergy-aware bonding network device.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 16:06:31 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Dubslaff", "Clemens", ""], ["Kl\u00fcppelholz", "Sascha", ""], ["Baier", "Christel", ""]]}, {"id": "1312.7832", "submitter": "Li Fu", "authors": "Li Fu", "title": "Defining implication relation for classical logic", "comments": "15 pages; 1 table. Major revision: added semantics, rules of\n  inference, and truth values of implication relation; elaborated description\n  of relationship to classical logic; corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical logic has a problematic definition of implication -- the \"material\nimplication\". This work presents a definition of implication relation to\nreplace the material implication for classical logic. The \"paradoxes\" of\nmaterial implication are avoided while strength and simplicity of the system\nare reserved with this definition of implication.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 19:33:50 GMT"}, {"version": "v2", "created": "Mon, 19 May 2014 04:59:31 GMT"}, {"version": "v3", "created": "Tue, 12 Jul 2016 17:59:52 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2021 19:19:08 GMT"}, {"version": "v5", "created": "Sat, 8 May 2021 07:18:40 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fu", "Li", ""]]}]