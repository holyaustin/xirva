[{"id": "1201.0345", "submitter": "EPTCS", "authors": "Jean-Yves Marion (LORIA)", "title": "Proceedings Second Workshop on Developments in Implicit Computational\n  Complexity", "comments": "EPTCS 75, 2012", "journal-ref": null, "doi": "10.4204/EPTCS.75", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Second International Workshop on\nDevelopments in Implicit Computational complExity (DICE 2011), which took place\non April 2-3 2011 in Saarbruecken, Germany, as a satellite event of the Joint\nEuropean Conference on Theory and Practice of Software, ETAPS 2011. Implicit\nComputational Complexity aims at studying computational complexity without\nreferring to external measuring conditions or particular machine models, but\ninstead by considering restrictions on programming languages or logical\nprinciples implying complexity properties. The aim of this workshop was to\nbring together researchers working on implicit computational complexity, from\nits logical and semantics aspects to those related to the static analysis of\nprograms, so as to foster their interaction and to give newcomers an overview\nof the current trends in this area.\n  The first DICE workshop was held in 2010 at ETAPS and published in EPTCS,\nvolume 23 (http://eptcs.org/content.cgi?DICE2010).\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2012 11:55:08 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Marion", "Jean-Yves", "", "LORIA"]]}, {"id": "1201.0416", "submitter": "Yuan Feng", "authors": "Yuxin Deng and Yuan Feng", "title": "Open Bisimulation for Quantum Processes", "comments": "25 pages. Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum processes describe concurrent communicating systems that may involve\nquantum information. We propose a notion of open bisimulation for quantum\nprocesses and show that it provides both a sound and complete proof methodology\nfor a natural extensional behavioural equivalence between quantum processes. We\nalso give a modal characterisation of open bisimulation, by extending the\nHennessy-Milner logic to a quantum setting.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2012 03:10:10 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Deng", "Yuxin", ""], ["Feng", "Yuan", ""]]}, {"id": "1201.0540", "submitter": "Steven Obua", "authors": "Steven Obua", "title": "ProofPeer - A Cloud-based Interactive Theorem Proving System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ProofPeer strives to be a system for cloud-based interactive theorem proving.\nAfter illustrating why such a system is needed, the paper presents some of the\ndesign challenges that ProofPeer needs to meet to succeed. Contexts are\npresented as a solution to the problem of sharing proof state among the users\nof ProofPeer. Chronicles are introduced as a way to organize and version\ncontexts.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2012 21:48:33 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Obua", "Steven", ""]]}, {"id": "1201.0557", "submitter": "Libor Barto", "authors": "Libor Barto (Charles University in Prague), Marcin Kozik (Jagiellonian\n  University)", "title": "Absorbing Subalgebras, Cyclic Terms, and the Constraint Satisfaction\n  Problem", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (February\n  20, 2012) lmcs:673", "doi": "10.2168/LMCS-8(1:7)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Algebraic Dichotomy Conjecture states that the Constraint Satisfaction\nProblem over a fixed template is solvable in polynomial time if the algebra of\npolymorphisms associated to the template lies in a Taylor variety, and is\nNP-complete otherwise. This paper provides two new characterizations of\nfinitely generated Taylor varieties. The first characterization is using\nabsorbing subalgebras and the second one cyclic terms. These new conditions\nallow us to reprove the conjecture of Bang-Jensen and Hell (proved by the\nauthors) and the characterization of locally finite Taylor varieties using weak\nnear-unanimity terms (proved by McKenzie and Mar\\'oti) in an elementary and\nself-contained way.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2012 01:27:02 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2012 10:51:15 GMT"}, {"version": "v3", "created": "Fri, 17 Feb 2012 19:26:57 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Barto", "Libor", "", "Charles University in Prague"], ["Kozik", "Marcin", "", "Jagiellonian\n  University"]]}, {"id": "1201.0562", "submitter": "Naohi Eguchi", "authors": "Naohi Eguchi", "title": "A term-rewriting characterization of PSPACE", "comments": "In: T. Arai, C. T. Chong, R. Downey, J. Brendle, Q. Feng, H. Kikyo\n  and H. Ono, editors, Proceedings of the 10th Asian Logic Conference 2008,\n  World Scientific, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isabel Oitavem has introduced a term rewriting system (TRS) which captures\nthe class FPS of polynomial-space computable functions. We propose an\nalternative TRS for FPS. As a consequence, it is obtained that FPS is the\nsmallest class containing certain initial functions and closed under specific\noperations. It turns out that our characterization is relatively simple and\nsuggests an uniform approach to the space-complexity.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2012 03:05:30 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Eguchi", "Naohi", ""]]}, {"id": "1201.0597", "submitter": "Miko&#322;aj Boja&#324;czyk", "authors": "Miko{\\l}aj Boja\\'nczyk (University of Warsaw), S{\\l}awomir Lasota\n  (University of Warsaw)", "title": "An extension of data automata that captures XPath", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (February\n  16, 2012) lmcs:672", "doi": "10.2168/LMCS-8(1:5)2012", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new kind of automata recognizing properties of data words or data\ntrees and prove that the automata capture all queries definable in Regular\nXPath. We show that the automata-theoretic approach may be applied to answer\ndecidability and expressibility questions for XPath.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2012 09:13:14 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2012 10:38:30 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", "", "University of Warsaw"], ["Lasota", "S\u0142awomir", "", "University of Warsaw"]]}, {"id": "1201.0682", "submitter": "Vojt\\v{e}ch \\v{R}eh\\'ak", "authors": "Tom\\'a\\v{s} Babiak, Mojm\\'ir K\\v{r}et\\'insk\\'y, Vojt\\v{e}ch\n  \\v{R}eh\\'ak, and Jan Strej\\v{c}ek", "title": "LTL to B\\\"uchi Automata Translation: Fast and More Deterministic", "comments": "Full version of the paper presented at TACAS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce improvements in the algorithm by Gastin and Oddoux translating\nLTL formulae into B\\\"uchi automata via very weak alternating co-B\\\"uchi\nautomata and generalized B\\\"uchi automata. Several improvements are based on\nspecific properties of any formula where each branch of its syntax tree\ncontains at least one eventually operator and at least one always operator.\nThese changes usually result in faster translations and smaller automata. Other\nimprovements reduce non-determinism in the produced automata. In fact, we\nmodified all the steps of the original algorithm and its implementation known\nas LTL2BA. Experimental results show that our modifications are real\nimprovements. Their implementations within an LTL2BA translation made LTL2BA\nvery competitive with the current version of SPOT, sometimes outperforming it\nsubstantially.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2012 16:04:28 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2012 20:12:37 GMT"}], "update_date": "2012-04-02", "authors_parsed": [["Babiak", "Tom\u00e1\u0161", ""], ["K\u0159et\u00ednsk\u00fd", "Mojm\u00edr", ""], ["\u0158eh\u00e1k", "Vojt\u011bch", ""], ["Strej\u010dek", "Jan", ""]]}, {"id": "1201.0825", "submitter": "Hector Zenil", "authors": "Hector Zenil", "title": "Computer Runtimes and the Length of Proofs: On an Algorithmic\n  Probabilistic Application to Waiting Times in Automatic Theorem Proving", "comments": "forthcoming in M.J. Dinneen, B Khoussainov and A. Nies (eds),\n  \"Computation, Physics and Beyond\", LNCS, Springer (Cristian S. Calude\n  festschrift)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an experimental exploration of the relationship between the\nruntimes of Turing machines and the length of proofs in formal axiomatic\nsystems. We compare the number of halting Turing machines of a given size to\nthe number of provable theorems of first-order logic of a given size, and the\nruntime of the longest-running Turing machine of a given size to the proof\nlength of the most-difficult-to-prove theorem of a given size. It is suggested\nthat theorem provers are subject to the same non-linear tradeoff between time\nand size as computer programs are, affording the possibility of determining\noptimal timeouts and waiting times in automatic theorem proving. I provide the\nstatistics for some small choices of parameters for both of these systems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 05:44:14 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Zenil", "Hector", ""]]}, {"id": "1201.0856", "submitter": "Manuel Bodirsky", "authors": "Manuel Bodirsky", "title": "Complexity Classification in Infinite-Domain Constraint Satisfaction", "comments": "M\\'emoire pour l'obtention d'une HDR \\`a l'universit\\'e Paris 7. 265\n  pages. Version 2 has been prepared after the defence, and contains the\n  official header with information about the HDR jury. Version 10: some more\n  mistakes have been removed. This is the final version of the text, it will no\n  longer be updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DM cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A constraint satisfaction problem (CSP) is a computational problem where the\ninput consists of a finite set of variables and a finite set of constraints,\nand where the task is to decide whether there exists a satisfying assignment of\nvalues to the variables. Depending on the type of constraints that we allow in\nthe input, a CSP might be tractable, or computationally hard. In recent years,\ngeneral criteria have been discovered that imply that a CSP is polynomial-time\ntractable, or that it is NP-hard. Finite-domain CSPs have become a major common\nresearch focus of graph theory, artificial intelligence, and finite model\ntheory. It turned out that the key questions for complexity classification of\nCSPs are closely linked to central questions in universal algebra.\n  This thesis studies CSPs where the variables can take values from an infinite\ndomain. This generalization enhances dramatically the range of computational\nproblems that can be modeled as a CSP. Many problems from areas that have so\nfar seen no interaction with constraint satisfaction theory can be formulated\nusing infinite domains, e.g. problems from temporal and spatial reasoning,\nphylogenetic reconstruction, and operations research.\n  It turns out that the universal-algebraic approach can also be applied to\nstudy large classes of infinite-domain CSPs, yielding elegant complexity\nclassification results. A new tool in this thesis that becomes relevant\nparticularly for infinite domains is Ramsey theory. We demonstrate the\nfeasibility of our approach with two complete complexity classification\nresults: one on CSPs in temporal reasoning, the other on a generalization of\nSchaefer's theorem for propositional logic to logic over graphs. We also study\nthe limits of complexity classification, and present classes of computational\nproblems provably do not exhibit a complexity dichotomy into hard and easy\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 09:39:46 GMT"}, {"version": "v10", "created": "Sat, 20 Apr 2019 07:03:06 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2012 22:21:28 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2012 08:40:59 GMT"}, {"version": "v4", "created": "Thu, 20 Jun 2013 21:36:07 GMT"}, {"version": "v5", "created": "Sat, 13 Jun 2015 06:56:24 GMT"}, {"version": "v6", "created": "Sat, 29 Aug 2015 06:57:29 GMT"}, {"version": "v7", "created": "Mon, 7 Dec 2015 15:33:28 GMT"}, {"version": "v8", "created": "Wed, 14 Sep 2016 14:41:07 GMT"}, {"version": "v9", "created": "Tue, 5 Sep 2017 11:20:55 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Bodirsky", "Manuel", ""]]}, {"id": "1201.0891", "submitter": "Yangjia Li", "authors": "Yangjia Li, Nengkun Yu, and Mingsheng Ying", "title": "Termination of Nondeterministic Quantum Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a language-independent model of nondeterministic quantum programs\nin which a quantum program consists of a finite set of quantum processes. These\nprocesses are represented by quantum Markov chains over the common state space.\nAn execution of a nondeterministic quantum program is modeled by a sequence of\nactions of individual processes. These actions are described by super-operators\non the state Hilbert space. At each step of an execution, a process is chosen\nnondeterministically to perform the next action. A characterization of\nreachable space and a characterization of diverging states of a\nnondeterministic quantum program are presented. We establish a zero-one law for\ntermination probability of the states in the reachable space of a\nnondeterministic quantum program. A combination of these results leads to a\nnecessary and sufficient condition for termination of nondeterministic quantum\nprograms. Based on this condition, an algorithm is found for checking\ntermination of nondeterministic quantum programs within a fixed\nfinite-dimensional state space. A striking difference between nondeterministic\nclassical and quantum programs is shown by example: it is possible that each of\nseveral quantum programs simulates the same classical program which terminates\nwith probability 1, but the nondeterministic program consisting of them\nterminates with probability 0 due to the interference carried in the execution\nof them.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 14:07:20 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Li", "Yangjia", ""], ["Yu", "Nengkun", ""], ["Ying", "Mingsheng", ""]]}, {"id": "1201.0979", "submitter": "Sanjit Seshia", "authors": "Sanjit A. Seshia", "title": "Sciduction: Combining Induction, Deduction, and Structure for\n  Verification and Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even with impressive advances in automated formal methods, certain problems\nin system verification and synthesis remain challenging. Examples include the\nverification of quantitative properties of software involving constraints on\ntiming and energy consumption, and the automatic synthesis of systems from\nspecifications. The major challenges include environment modeling,\nincompleteness in specifications, and the complexity of underlying decision\nproblems.\n  This position paper proposes sciduction, an approach to tackle these\nchallenges by integrating inductive inference, deductive reasoning, and\nstructure hypotheses. Deductive reasoning, which leads from general rules or\nconcepts to conclusions about specific problem instances, includes techniques\nsuch as logical inference and constraint solving. Inductive inference, which\ngeneralizes from specific instances to yield a concept, includes algorithmic\nlearning from examples. Structure hypotheses are used to define the class of\nartifacts, such as invariants or program fragments, generated during\nverification or synthesis. Sciduction constrains inductive and deductive\nreasoning using structure hypotheses, and actively combines inductive and\ndeductive reasoning: for instance, deductive techniques generate examples for\nlearning, and inductive reasoning is used to guide the deductive engines.\n  We illustrate this approach with three applications: (i) timing analysis of\nsoftware; (ii) synthesis of loop-free programs, and (iii) controller synthesis\nfor hybrid systems. Some future applications are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2012 19:58:41 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Seshia", "Sanjit A.", ""]]}, {"id": "1201.1119", "submitter": "EPTCS", "authors": "Daniel Leivant (Indiana University and LORIA Nancy), Ramyaa Ramyaa\n  (Indiana University and Ludwig-Maximilians-Universit\\\"at M\\\"unchen)", "title": "Implicit complexity for coinductive data: a characterization of\n  corecurrence", "comments": "In Proceedings DICE 2011, arXiv:1201.0345", "journal-ref": "EPTCS 75, 2012, pp. 1-14", "doi": "10.4204/EPTCS.75.1", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for reasoning about programs that manipulate\ncoinductive data as well as inductive data. Our approach is based on using\nequational programs, which support a seamless combination of computation and\nreasoning, and using productivity (fairness) as the fundamental assertion,\nrather than bi-simulation. The latter is expressible in terms of the former. As\nan application to this framework, we give an implicit characterization of\ncorecurrence: a function is definable using corecurrence iff its productivity\nis provable using coinduction for formulas in which data-predicates do not\noccur negatively. This is an analog, albeit in weaker form, of a\ncharacterization of recurrence (i.e. primitive recursion) in [Leivant, Unipolar\ninduction, TCS 318, 2004].\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 11:06:38 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Leivant", "Daniel", "", "Indiana University and LORIA Nancy"], ["Ramyaa", "Ramyaa", "", "Indiana University and Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen"]]}, {"id": "1201.1120", "submitter": "EPTCS", "authors": "Cl\\'ement Aubert (LIPN - UMR7030 CNRS - Universit\\'e Paris 13)", "title": "Sublogarithmic uniform Boolean proof nets", "comments": "In Proceedings DICE 2011, arXiv:1201.0345", "journal-ref": "EPTCS 75, 2012, pp. 15-27", "doi": "10.4204/EPTCS.75.2", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a proofs-as-programs correspondence, Terui was able to compare two\nmodels of parallel computation: Boolean circuits and proof nets for\nmultiplicative linear logic. Mogbil et. al. gave a logspace translation\nallowing us to compare their computational power as uniform complexity classes.\nThis paper presents a novel translation in AC0 and focuses on a simpler\nrestricted notion of uniform Boolean proof nets. We can then encode\nconstant-depth circuits and compare complexity classes below logspace, which\nwere out of reach with the previous translations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 11:06:50 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "LIPN - UMR7030 CNRS - Universit\u00e9 Paris 13"]]}, {"id": "1201.1121", "submitter": "EPTCS", "authors": "Evgeny Makarov (INRIA)", "title": "Provably Total Functions of Arithmetic with Basic Terms", "comments": "In Proceedings DICE 2011, arXiv:1201.0345", "journal-ref": "EPTCS 75, 2012, pp. 28-32", "doi": "10.4204/EPTCS.75.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new characterization of provably recursive functions of first-order\narithmetic is described. Its main feature is using only terms consisting of 0,\nthe successor S and variables in the quantifier rules, namely, universal\nelimination and existential introduction.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 11:06:51 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Makarov", "Evgeny", "", "INRIA"]]}, {"id": "1201.1122", "submitter": "EPTCS", "authors": "Lucien Capedevielle (ENS de Lyon)", "title": "A type system for PSPACE derived from light linear logic", "comments": "In Proceedings DICE 2011, arXiv:1201.0345", "journal-ref": "EPTCS 75, 2012, pp. 33-46", "doi": "10.4204/EPTCS.75.4", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polymorphic type system for lambda calculus ensuring that\nwell-typed programs can be executed in polynomial space: dual light affine\nlogic with booleans (DLALB).\n  To build DLALB we start from DLAL (which has a simple type language with a\nlinear and an intuitionistic type arrow, as well as one modality) which\ncharacterizes FPTIME functions. In order to extend its expressiveness we add\ntwo boolean constants and a conditional constructor in the same way as with the\nsystem STAB.\n  We show that the value of a well-typed term can be computed by an alternating\nmachine in polynomial time, thus such a term represents a program of PSPACE\n(given that PSPACE = APTIME).\n  We also prove that all polynomial space decision functions can be represented\nin DLALB.\n  Therefore DLALB characterizes PSPACE predicates.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 11:06:58 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Capedevielle", "Lucien", "", "ENS de Lyon"]]}, {"id": "1201.1272", "submitter": "Bart Jacobs", "authors": "Bart Jacobs, Jorik Mandemaker", "title": "Relating Operator Spaces via Adjunctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter uses categorical techniques to describe relations between\nvarious sets of operators on a Hilbert space, such as self-adjoint, positive,\ndensity, effect and projection operators. These relations, including various\nHilbert-Schmidt isomorphisms of the form tr(A-), are expressed in terms of dual\nadjunctions, and maps between them. Of particular interest is the connection\nwith quantum structures, via a dual adjunction between convex sets and effect\nmodules. The approach systematically uses categories of modules, via their\ndescription as Eilenberg-Moore algebras of a monad.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 19:47:17 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2012 22:02:20 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Jacobs", "Bart", ""], ["Mandemaker", "Jorik", ""]]}, {"id": "1201.1410", "submitter": "Kirstin Peters", "authors": "Kirstin Peters and Uwe Nestmann", "title": "Is it a \"Good\" Encoding of Mixed Choice? (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report contains the proofs to the lemmata and theorems of\n[PN12] as well as some additional material. As main contributions [PN12]\npresents an encoding of mixed choice in the context of the pi-calculus and a\ncriterion to measure whether the degree of distribution in process networks is\npreserved.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2012 13:15:11 GMT"}], "update_date": "2012-01-09", "authors_parsed": [["Peters", "Kirstin", ""], ["Nestmann", "Uwe", ""]]}, {"id": "1201.1705", "submitter": "Denis Cousineau", "authors": "Denis Cousineau (INRIA-Microsoft Research)", "title": "On completeness of reducibility candidates as a semantics of strong\n  normalization", "comments": "24 pages", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (February\n  16, 2012) lmcs:845", "doi": "10.2168/LMCS-8(1:3)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a sound and complete semantic criterion, based on\nreducibility candidates, for strong normalization of theories expressed in\nminimal deduction modulo \\`a la Curry. The use of Curry-style proof-terms\nallows to build this criterion on the classic notion of pre-Heyting algebras\nand makes that criterion concern all theories expressed in minimal deduction\nmodulo. Compared to using Church-style proof-terms, this method provides both a\nsimpler definition of the criterion and a simpler proof of its completeness.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2012 08:12:29 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2012 06:51:49 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Cousineau", "Denis", "", "INRIA-Microsoft Research"]]}, {"id": "1201.1716", "submitter": "Gavin Lowe", "authors": "Tomasz Mazur (Oxford University), Gavin Lowe (Oxford University)", "title": "A type reduction theory for systems with replicated components", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (February\n  16, 2012) lmcs:869", "doi": "10.2168/LMCS-8(1:4)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Parameterised Model Checking Problem asks whether an implementation\nImpl(t) satisfies a specification Spec(t) for all instantiations of parameter\nt. In general, t can determine numerous entities: the number of processes used\nin a network, the type of data, the capacities of buffers, etc. The main theme\nof this paper is automation of uniform verification of a subclass of PMCP with\nthe parameter of the first kind, i.e. the number of processes in the network.\nWe use CSP as our formalism. We present a type reduction theory, which, for a\ngiven verification problem, establishes a function \\phi that maps all\n(sufficiently large) instantiations T of the parameter to some fixed type T^\nand allows us to deduce that if Spec(T^) is refined by \\phi(Impl(T)), then\n(subject to certain assumptions) Spec(T) is refined by Impl(T). The theory can\nbe used in practice by combining it with a suitable abstraction method that\nproduces a t-independent process Abstr that is refined by {\\phi}(Impl(T)) for\nall sufficiently large T. Then, by testing (with a model checker) if the\nabstract model Abstr refines Spec(T^), we can deduce a positive answer to the\noriginal uniform verification problem. The type reduction theory relies on\nsymbolic representation of process behaviour. We develop a symbolic operational\nsemantics for CSP processes that satisfy certain normality requirements, and we\nprovide a set of translation rules that allow us to concretise symbolic\ntransition graphs. Based on this, we prove results that allow us to infer\nbehaviours of a process instantiated with uncollapsed types from known\nbehaviours of the same process instantiated with a reduced type. One of the\nmain advantages of our symbolic operational semantics and the type reduction\ntheory is their generality, which makes them applicable in a wide range of\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2012 09:29:12 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2012 09:56:52 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Mazur", "Tomasz", "", "Oxford University"], ["Lowe", "Gavin", "", "Oxford University"]]}, {"id": "1201.2258", "submitter": "Alwen Tiu", "authors": "Yuxing Deng and Alwen Tiu", "title": "Characterisations of Testing Preorders for a Finite Probabilistic\n  pi-Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two characterisations of the may and must testing preorders for a\nprobabilistic extension of the finite pi-calculus: one based on notions of\nprobabilistic weak simulations, and the other on a probabilistic extension of a\nfragment of Milner-Parrow-Walker modal logic for the pi-calculus. We base our\nnotions of simulations on the similar concepts used in previous work for\nprobabilistic CSP. However, unlike the case with CSP (or other\nnon-value-passing calculi), there are several possible definitions of\nsimulation for the probabilistic pi-calculus, which arise from different ways\nof scoping the name quantification. We show that in order to capture the\ntesting preorders, one needs to use the \"earliest\" simulation relation (in\nanalogy to the notion of early (bi)simulation in the non-probabilistic case).\nThe key ideas in both characterisations are the notion of a \"characteristic\nformula\" of a probabilistic process, and the notion of a \"characteristic test\"\nfor a formula. As in an earlier work on testing equivalence for the pi-calculus\nby Boreale and De Nicola, we extend the language of the $\\pi$-calculus with a\nmismatch operator, without which the formulation of a characteristic test will\nnot be possible.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2012 08:22:46 GMT"}], "update_date": "2012-01-12", "authors_parsed": [["Deng", "Yuxing", ""], ["Tiu", "Alwen", ""]]}, {"id": "1201.2564", "submitter": "Linh Anh Nguyen D.Sc.", "authors": "Linh Anh Nguyen and Son Thanh Cao", "title": "Query-Subquery Nets", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate query-subquery nets and use them to create the first framework\nfor developing algorithms for evaluating queries to Horn knowledge bases with\nthe properties that: the approach is goal-directed; each subquery is processed\nonly once and each supplement tuple, if desired, is transferred only once;\noperations are done set-at-a-time; and any control strategy can be used. Our\nintention is to increase efficiency of query processing by eliminating\nredundant computation, increasing flexibility and reducing the number of\naccesses to the secondary storage. The framework forms a generic evaluation\nmethod called QSQN. To deal with function symbols, we use a term-depth bound\nfor atoms and substitutions occurring in the computation and propose to use\niterative deepening search which iteratively increases the term-depth bound. We\nprove soundness and completeness of our generic evaluation method and show\nthat, when the term-depth bound is fixed, the method has PTIME data complexity.\nWe also present how tail recursion elimination can be incorporated into our\nframework and propose two exemplary control strategies, one is to reduce the\nnumber of accesses to the secondary storage, while the other is depth-first\nsearch.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 14:00:51 GMT"}], "update_date": "2012-01-13", "authors_parsed": [["Nguyen", "Linh Anh", ""], ["Cao", "Son Thanh", ""]]}, {"id": "1201.2829", "submitter": "Yaron Velner", "authors": "Krishnendu Chatterjee and Yaron Velner", "title": "Mean-Payoff Pushdown Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-player games on graphs is central in many problems in formal verification\nand program analysis such as synthesis and verification of open systems. In\nthis work we consider solving recursive game graphs (or pushdown game graphs)\nthat can model the control flow of sequential programs with recursion. While\npushdown games have been studied before with qualitative objectives, such as\nreachability and $\\omega$-regular objectives, in this work we study for the\nfirst time such games with the most well-studied quantitative objective,\nnamely, mean-payoff objectives. In pushdown games two types of strategies are\nrelevant: (1) global strategies, that depend on the entire global history; and\n(2) modular strategies, that have only local memory and thus does not depend on\nthe context of invocation, but only on the history of the current invocation of\nthe module. Our main results are as follows (1) One-player pushdown games with\nmean-payoff objectives under global strategies is decidable in polynomial time.\n(2) Two-player pushdown games with mean-payoff objectives under global\nstrategies is undecidable. (3) One-player pushdown games with mean-payoff\nobjectives under modular strategies is NP-hard. (4) Two-player pushdown games\nwith mean-payoff objectives under modular strategies can be solved in NP (i.e.,\nboth one-player and two-player pushdown games with mean-payoff objectives under\nmodular strategies is NP-complete). We also establish the optimal strategy\ncomplexity showing that global strategies for mean-payoff objectives require\ninfinite memory even in one-player pushdown games; and memoryless modular\nstrategies are sufficient in two-player pushdown games. Finally we also show\nthat all the problems have the same complexity if the stack boundedness\ncondition is added, where along with the mean-payoff objective the player must\nalso ensure that the stack height is bounded.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 13:18:16 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2012 11:43:16 GMT"}, {"version": "v3", "created": "Sun, 15 May 2016 11:27:46 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Velner", "Yaron", ""]]}, {"id": "1201.2956", "submitter": "Matthieu Perrinel M.", "authors": "Matthieu Perrinel", "title": "On paths-based criteria for polynomial time complexity in proof-nets", "comments": "Long version of a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Girard's Light linear logic (LLL) characterized polynomial time in the\nproof-as-program paradigm with a bound on cut elimination. This logic relied on\na stratification principle and a \"one-door\" principle which were generalized\nlater respectively in the systems L^4 and L^3a. Each system was brought with\nits own complex proof of Ptime soundness.\n  In this paper we propose a broad sufficient criterion for Ptime soundness for\nlinear logic subsystems, based on the study of paths inside the proof-nets,\nwhich factorizes proofs of soundness of existing systems and may be used for\nfuture systems. As an additional gain, our bound stands for any reduction\nstrategy whereas most bounds in the literature only stand for a particular\nstrategy.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 21:21:45 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2013 00:09:06 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2013 09:31:41 GMT"}, {"version": "v4", "created": "Thu, 17 Oct 2013 06:01:50 GMT"}, {"version": "v5", "created": "Mon, 19 May 2014 03:52:17 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Perrinel", "Matthieu", ""]]}, {"id": "1201.3142", "submitter": "Joseph Norman", "authors": "Joseph W. Norman", "title": "A Tutorial Introduction to the Logic of Parametric Probability", "comments": "39 pages including 4 page appendix; new title, additional\n  clarifications, correction of bugs introduced into one example in the last\n  revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational method of parametric probability analysis is introduced. It\nis demonstrated how to embed logical formulas from the propositional calculus\ninto parametric probability networks, thereby enabling sound reasoning about\nthe probabilities of logical propositions. An alternative direct probability\nencoding scheme is presented, which allows statements of implication and\nquantification to be modeled directly as constraints on conditional\nprobabilities. Several example problems are solved, from Johnson-Laird's aces\nto Smullyan's zombies. Many apparently challenging problems in logic turn out\nto be simple problems in algebra and computer science: systems of polynomial\nequations or linear optimization problems. This work extends the mathematical\nlogic and parametric probability methods invented by George Boole.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 00:30:31 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2012 05:12:43 GMT"}, {"version": "v3", "created": "Thu, 17 May 2012 19:57:16 GMT"}, {"version": "v4", "created": "Wed, 23 May 2012 19:55:43 GMT"}], "update_date": "2012-05-24", "authors_parsed": [["Norman", "Joseph W.", ""]]}, {"id": "1201.3251", "submitter": "Dimitri Hendriks", "authors": "Clemens Grabmayer and Joerg Endrullis and Dimitri Hendriks and Jan\n  Willem Klop and Lawrence S. Moss", "title": "Automatic Sequences and Zip-Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider infinite sequences of symbols, also known as streams, and the\ndecidability question for equality of streams defined in a restricted format.\nThis restricted format consists of prefixing a symbol at the head of a stream,\nof the stream function `zip', and recursion variables. Here `zip' interleaves\nthe elements of two streams in alternating order, starting with the first\nstream. For example, the Thue-Morse sequence is obtained by the\n`zip-specification' {M = 0 : X, X = 1 : zip(X,Y), Y = 0 : zip(Y,X)}. Our\nanalysis of such systems employs both term rewriting and coalgebraic\ntechniques. We establish decidability for these zip-specifications, employing\nbisimilarity of observation graphs based on a suitably chosen cobasis. The\nimportance of zip-specifications resides in their intimate connection with\nautomatic sequences. We establish a new and simple characterization of\nautomatic sequences. Thus we obtain for the binary zip that a stream is\n2-automatic iff its observation graph using the cobasis (hd,even,odd) is\nfinite. The generalization to zip-k specifications and their relation to\nk-automaticity is straightforward. In fact, zip-specifications can be perceived\nas a term rewriting syntax for automatic sequences. Our study of\nzip-specifications is placed in an even wider perspective by employing the\nobservation graphs in a dynamic logic setting, leading to an alternative\ncharacterization of automatic sequences. We further obtain a natural extension\nof the class of automatic sequences, obtained by `zip-mix' specifications that\nuse zips of different arities in one specification. We also show that\nequivalence is undecidable for a simple extension of the zip-mix format with\nprojections like even and odd. However, it remains open whether zip-mix\nspecifications have a decidable equivalence problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 13:29:28 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2012 11:55:42 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Grabmayer", "Clemens", ""], ["Endrullis", "Joerg", ""], ["Hendriks", "Dimitri", ""], ["Klop", "Jan Willem", ""], ["Moss", "Lawrence S.", ""]]}, {"id": "1201.3601", "submitter": "Freek Wiedijk", "authors": "Freek Wiedijk (Radboud University Nijmegen)", "title": "A Synthesis of the Procedural and Declarative Styles of Interactive\n  Theorem Proving", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 28,\n  2012) lmcs:1046", "doi": "10.2168/LMCS-8(1:30)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a synthesis of the two proof styles of interactive theorem\nproving: the procedural style (where proofs are scripts of commands, like in\nCoq) and the declarative style (where proofs are texts in a controlled natural\nlanguage, like in Isabelle/Isar). Our approach combines the advantages of the\ndeclarative style - the possibility to write formal proofs like normal\nmathematical text - and the procedural style - strong automation and help with\nshaping the proofs, including determining the statements of intermediate steps.\nOur approach is new, and differs significantly from the ways in which the\nprocedural and declarative proof styles have been combined before in the\nIsabelle, Ssreflect and Matita systems. Our approach is generic and can be\nimplemented on top of any procedural interactive theorem prover, regardless of\nits architecture and logical foundations. To show the viability of our proposed\napproach, we fully implemented it as a proof interface called miz3, on top of\nthe HOL Light interactive theorem prover. The declarative language that this\ninterface uses is a slight variant of the language of the Mizar system, and can\nbe used for any interactive theorem prover regardless of its logical\nfoundations. The miz3 interface allows easy access to the full set of tactics\nand formal libraries of HOL Light, and as such has \"industrial strength\". Our\napproach gives a way to automatically convert any procedural proof to a\ndeclarative counterpart, where the converted proof is similar in size to the\noriginal. As all declarative systems have essentially the same proof language,\nthis gives a straightforward way to port proofs between interactive theorem\nprovers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2012 19:44:55 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2012 09:07:41 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Wiedijk", "Freek", "", "Radboud University Nijmegen"]]}, {"id": "1201.3667", "submitter": "Simon Kramer", "authors": "Simon Kramer", "title": "A Logic of Interactive Proofs (Formal Theory of Knowledge Transfer)", "comments": "added Appendix D; related to arXiv:1208.1842, arXiv:1208.5913, and\n  arXiv:1309.1328", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.DC cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a logic of interactive proofs as a framework for an intuitionistic\nfoundation for interactive computation, which we construct via an interactive\nanalog of the Goedel-McKinsey-Tarski-Artemov definition of Intuitionistic Logic\nas embedded into a classical modal logic of proofs, and of the Curry-Howard\nisomorphism between intuitionistic proofs and typed programs. Our interactive\nproofs effectuate a persistent epistemic impact in their intended communities\nof peer reviewers that consists in the induction of the (propositional)\nknowledge of their proof goal by means of the (individual) knowledge of the\nproof with the interpreting reviewer. That is, interactive proofs effectuate a\ntransfer of propositional knowledge (knowable facts) via the transmission of\ncertain individual knowledge (knowable proofs) in multi-agent distributed\nsystems. In other words, we as a community can have the formal common knowledge\nthat a proof is that which if known to one of our peer members would induce the\nknowledge of its proof goal with that member. Last but not least, we prove\nnon-trivial interactive computation as definable within our simply typed\ninteractive Combinatory Logic to be nonetheless equipotent to non-interactive\ncomputation as defined by simply typed Combinatory Logic.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2012 23:33:40 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 09:23:57 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2012 14:45:17 GMT"}, {"version": "v4", "created": "Fri, 19 Sep 2014 10:50:33 GMT"}, {"version": "v5", "created": "Tue, 5 Apr 2016 07:58:48 GMT"}, {"version": "v6", "created": "Tue, 8 Aug 2017 08:48:52 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Kramer", "Simon", ""]]}, {"id": "1201.3731", "submitter": "Assia Mahboubi", "authors": "Assia Mahboubi (INRIA), Cyril Cohen (INRIA)", "title": "Formal proofs in real algebraic geometry: from ordered fields to\n  quantifier elimination", "comments": "40 pages, 4 figures", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (February\n  16, 2012) lmcs:844", "doi": "10.2168/LMCS-8(1:2)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a formalization of discrete real closed fields in the\nCoq proof assistant. This abstract structure captures for instance the theory\nof real algebraic numbers, a decidable subset of real numbers with good\nalgorithmic properties. The theory of real algebraic numbers and more generally\nof semi-algebraic varieties is at the core of a number of effective methods in\nreal analysis, including decision procedures for non linear arithmetic or\noptimization methods for real valued functions. After defining an abstract\nstructure of discrete real closed field and the elementary theory of real roots\nof polynomials, we describe the formalization of an algebraic proof of\nquantifier elimination based on pseudo-remainder sequences following the\nstandard computer algebra literature on the topic. This formalization covers a\nlarge part of the theory which underlies the efficient algorithms implemented\nin practice in computer algebra. The success of this work paves the way for\nformal certification of these efficient methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 09:30:01 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2012 06:39:04 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Mahboubi", "Assia", "", "INRIA"], ["Cohen", "Cyril", "", "INRIA"]]}, {"id": "1201.3733", "submitter": "Yoriyuki Yamagata", "authors": "Yoriyuki Yamagata (National Institute of Advanced Science and\n  Technology)", "title": "Bounded Arithmetic in Free Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 3 (August 10,\n  2012) lmcs:863", "doi": "10.2168/LMCS-8(3:7)2012", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central open questions in bounded arithmetic is whether Buss'\nhierarchy of theories of bounded arithmetic collapses or not. In this paper, we\nreformulate Buss' theories using free logic and conjecture that such theories\nare easier to handle. To show this, we first prove that Buss' theories prove\nconsistencies of induction-free fragments of our theories whose formulae have\nbounded complexity. Next, we prove that although our theories are based on an\napparently weaker logic, we can interpret theories in Buss' hierarchy by our\ntheories using a simple translation. Finally, we investigate finitistic G\\\"odel\nsentences in our systems in the hope of proving that a theory in a lower level\nof Buss' hierarchy cannot prove consistency of induction-free fragments of our\ntheories whose formulae have higher complexity.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 09:34:33 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2012 08:56:04 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2012 19:49:49 GMT"}, {"version": "v4", "created": "Sat, 11 Aug 2012 13:37:36 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Yamagata", "Yoriyuki", "", "National Institute of Advanced Science and\n  Technology"]]}, {"id": "1201.3786", "submitter": "Dimitri Hendriks", "authors": "Dimitri Hendriks and Frits G. W. Dannenberg and Joerg Endrullis and\n  Mark Dow and Jan Willem Klop", "title": "Arithmetic Self-Similarity of Infinite Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define the arithmetic self-similarity (AS) of a one-sided infinite\nsequence sigma to be the set of arithmetic progressions through sigma which are\na vertical shift of sigma. We study the AS of several famlies of sequences,\nviz. completely additive sequences, Toeplitz words and Keane's generalized\nMorse sequences. We give a complete characterization of the AS of completely\nadditive sequences, and classify the set of single-gap Toeplitz patterns that\nyield completely additive Toeplitz words. We show that every arithmetic\nsubsequence of a Toeplitz word generated by a one-gap pattern is again a\nToeplitz word. Finally, we establish that generalized Morse sequences are\nspecific sum-of-digits sequences, and show that their first difference is a\nToeplitz word.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 13:49:12 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2012 15:45:29 GMT"}, {"version": "v3", "created": "Mon, 21 May 2012 09:37:41 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Hendriks", "Dimitri", ""], ["Dannenberg", "Frits G. W.", ""], ["Endrullis", "Joerg", ""], ["Dow", "Mark", ""], ["Klop", "Jan Willem", ""]]}, {"id": "1201.3898", "submitter": "Nicola Gambino", "authors": "Steve Awodey, Nicola Gambino and Kristina Sojakova", "title": "Inductive types in homotopy type theory", "comments": "19 pages; v2: added references and acknowledgements, removed appendix\n  with Coq README file, updated URL for Coq files. To appear in the proceedings\n  of LICS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homotopy type theory is an interpretation of Martin-L\\\"of's constructive type\ntheory into abstract homotopy theory. There results a link between constructive\nmathematics and algebraic topology, providing topological semantics for\nintensional systems of type theory as well as a computational approach to\nalgebraic topology via type theory-based proof assistants such as Coq.\n  The present work investigates inductive types in this setting. Modified rules\nfor inductive types, including types of well-founded trees, or W-types, are\npresented, and the basic homotopical semantics of such types are determined.\nProofs of all results have been formally verified by the Coq proof assistant,\nand the proof scripts for this verification form an essential component of this\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 20:12:30 GMT"}, {"version": "v2", "created": "Wed, 2 May 2012 11:05:17 GMT"}], "update_date": "2012-05-03", "authors_parsed": [["Awodey", "Steve", ""], ["Gambino", "Nicola", ""], ["Sojakova", "Kristina", ""]]}, {"id": "1201.4089", "submitter": "Markus Kr\\\"otzsch", "authors": "Markus Kr\\\"otzsch, Frantisek Simancik, Ian Horrocks", "title": "A Description Logic Primer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper provides a self-contained first introduction to description logics\n(DLs). The main concepts and features are explained with examples before syntax\nand semantics of the DL SROIQ are defined in detail. Additional sections review\nlight-weight DL languages, discuss the relationship to the Web Ontology\nLanguage OWL and give pointers to further reading.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 15:51:01 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 07:17:05 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2013 13:09:48 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Kr\u00f6tzsch", "Markus", ""], ["Simancik", "Frantisek", ""], ["Horrocks", "Ian", ""]]}, {"id": "1201.4307", "submitter": "Alo\\\"is Brunel", "authors": "Alo\\\"is Brunel", "title": "Quantitative classical realizability", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduced by Dal Lago and Hofmann, quantitative realizability is a technique\nused to define models for logics based on Multiplicative Linear Logic. A\nparticularity is that functions are interpreted as bounded time computable\nfunctions. It has been used to give new and uniform proofs of soundness of\nseveral type systems with respect to certain time complexity classes. We\npropose a reformulation of their ideas in the setting of Krivine's classical\nrealizability. The framework obtained generalizes Dal Lago and Hofmann's\nrealizability, and reveals deep connections between quantitative realizability\nand a linear variant of Cohen's forcing.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2012 14:35:09 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2012 13:59:40 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Brunel", "Alo\u00efs", ""]]}, {"id": "1201.4449", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Siddhesh Chaubal and Pritish Kamath", "title": "Faster Algorithms for Alternating Refinement Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One central issue in the formal design and analysis of reactive systems is\nthe notion of refinement that asks whether all behaviors of the implementation\nis allowed by the specification. The local interpretation of behavior leads to\nthe notion of simulation. Alternating transition systems (ATSs) provide a\ngeneral model for composite reactive systems, and the simulation relation for\nATSs is known as alternating simulation. The simulation relation for fair\ntransition systems is called fair simulation. In this work our main\ncontributions are as follows: (1) We present an improved algorithm for fair\nsimulation with B\\\"uchi fairness constraints; our algorithm requires $O(n^3\n\\cdot m)$ time as compared to the previous known $O(n^6)$-time algorithm, where\n$n$ is the number of states and $m$ is the number of transitions. (2) We\npresent a game based algorithm for alternating simulation that requires\n$O(m^2)$-time as compared to the previous known $O((n \\cdot m)^2)$-time\nalgorithm, where $n$ is the number of states and $m$ is the size of transition\nrelation. (3) We present an iterative algorithm for alternating simulation that\nmatches the time complexity of the game based algorithm, but is more space\nefficient than the game based algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2012 08:30:11 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2012 12:49:57 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Chaubal", "Siddhesh", ""], ["Kamath", "Pritish", ""]]}, {"id": "1201.4462", "submitter": "Dan Ghica", "authors": "Dan R. Ghica and Nikos Tzevelekos", "title": "A System-Level Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game semantics is a trace-like denotational semantics for programming\nlanguages where the notion of legal observable behaviour of a term is defined\ncombinatorially, by means of rules of a game between the term (the \"Proponent\")\nand its context (the \"Opponent\"). In general, the richer the computational\nfeatures a language has, the less constrained the rules of the semantic game.\nIn this paper we consider the consequences of taking this relaxation of rules\nto the limit, by granting the Opponent omnipotence, that is, permission to play\nany move without combinatorial restrictions. However, we impose an epistemic\nrestriction by not granting Opponent omniscience, so that Proponent can have\nundisclosed secret moves. We introduce a basic C-like programming language and\nwe define such a semantic model for it. We argue that the resulting semantics\nis an appealingly simple combination of operational and game semantics and we\nshow how certain traces explain system-level attacks, i.e. plausible attacks\nthat are realizable outside of the programming language itself. We also show\nhow allowing Proponent to have secrets ensures that some desirable equivalences\nin the programming language are preserved.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2012 11:27:10 GMT"}], "update_date": "2012-01-24", "authors_parsed": [["Ghica", "Dan R.", ""], ["Tzevelekos", "Nikos", ""]]}, {"id": "1201.4504", "submitter": "Matthew Szudzik", "authors": "Matthew P. Szudzik (Carnegie Mellon)", "title": "Is Turing's Thesis the Consequence of a More General Physical Principle?", "comments": "10 pages, 0 figures; section 1 revised, other minor changes", "journal-ref": "Lecture Notes in Computer Science, vol. 7318, Springer, 2012, pp.\n  714-722", "doi": "10.1007/978-3-642-30870-3_72", "report-no": null, "categories": "math.LO cs.CC cs.LO math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss historical attempts to formulate a physical hypothesis from which\nTuring's thesis may be derived, and also discuss some related attempts to\nestablish the computability of mathematical models in physics. We show that\nthese attempts are all related to a single, unified hypothesis.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2012 19:42:35 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2012 06:43:25 GMT"}, {"version": "v3", "created": "Mon, 2 Apr 2012 09:25:27 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Szudzik", "Matthew P.", "", "Carnegie Mellon"]]}, {"id": "1201.4567", "submitter": "James Royer", "authors": "Norman Danner and James S. Royer", "title": "Ramified Structural Recursion and Corecursion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate feasible computation over a fairly general notion of data and\ncodata. Specifically, we present a direct Bellantoni-Cook-style normal/safe\ntyped programming formalism, RS1, that expresses feasible structural recursions\nand corecursions over data and codata specified by polynomial functors. (Lists,\nstreams, finite trees, infinite trees, etc. are all directly definable.) A\nnovel aspect of RS1 is that it embraces structure-sharing as in standard\nfunctional-programming implementations. As our data representations use\nsharing, our implementation of structural recursions are memoized to avoid the\npossibly exponentially-many repeated subcomputations a naive implementation\nmight perform. We introduce notions of size for representations of data\n(accounting for sharing) and codata (using ideas from type-2 computational\ncomplexity) and establish that type-level 1 RS1-functions have\npolynomial-bounded runtimes and satisfy a polynomial-time completeness\ncondition. Also, restricting RS1 terms to particular types produces\ncharacterizations of some standard complexity classes (e.g., omega-regular\nlanguages, linear-space functions) and some less-standard classes (e.g.,\nlog-space streams).\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2012 16:06:01 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2012 22:18:42 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Danner", "Norman", ""], ["Royer", "James S.", ""]]}, {"id": "1201.4856", "submitter": "Matthew  Bauer", "authors": "Matthew S. Bauer", "title": "A PSPACE-Complete First Order Fragment of Computability Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recently launched research program for developing logic as a formal\ntheory of (interactive) computability, several very interesting logics have\nbeen introduced and axiomatized. These fragments of the larger Computability\nLogic aim not only to describe \"what\" can be computed, but also provide a\nmechanism for extracting computational algorithms from proofs. Among the most\nexpressive and fundamental of these is CL4, known to be (constructively) sound\nand complete with respect to the underlying computational semantics.\nFurthermore, the fragment of CL4 not containing blind quantifiers was shown to\nbe decidable in polynomial space. The present work extends this result and\nproves that this fragment is, in fact, PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2012 20:59:22 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2012 20:00:30 GMT"}, {"version": "v3", "created": "Sun, 31 Mar 2013 20:16:31 GMT"}], "update_date": "2013-04-02", "authors_parsed": [["Bauer", "Matthew S.", ""]]}, {"id": "1201.4871", "submitter": "Alexander  Heu{\\ss}ner", "authors": "Gilles Geeraerts and Alexander Heu{\\ss}ner and Jean-Fran\\c{c}ois\n  Raskin", "title": "Queue-Dispatch Asynchronous Systems", "comments": "38 pages, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make the development of efficient multi-core applications easier,\nlibraries, such as Grand Central Dispatch, have been proposed. When using such\na library, the programmer writes so-called blocks, which are chunks of codes,\nand dispatches them, using synchronous or asynchronous calls, to several types\nof waiting queues. A scheduler is then responsible for dispatching those blocks\non the available cores. Blocks can synchronize via a global memory. In this\npaper, we propose Queue-Dispatch Asynchronous Systems as a mathematical model\nthat faithfully formalizes the synchronization mechanisms and the behavior of\nthe scheduler in those systems. We study in detail their relationships to\nclassical formalisms such as pushdown systems, Petri nets, fifo systems, and\ncounter systems. Our main technical contributions are precise worst-case\ncomplexity results for the Parikh coverability problem for several subclasses\nof our model.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2012 21:19:03 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2012 15:28:10 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2012 07:00:58 GMT"}], "update_date": "2012-10-18", "authors_parsed": [["Geeraerts", "Gilles", ""], ["Heu\u00dfner", "Alexander", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "1201.5070", "submitter": "Martin Huschenbett", "authors": "Martin Huschenbett", "title": "Word Automaticity of Tree Automatic Scattered Linear Orderings Is\n  Decidable", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tree automatic structure is a structure whose domain can be encoded by a\nregular tree language such that each relation is recognisable by a finite\nautomaton processing tuples of trees synchronously. Words can be regarded as\nspecific simple trees and a structure is word automatic if it is encodable\nusing only these trees. The question naturally arises whether a given tree\nautomatic structure is already word automatic. We prove that this problem is\ndecidable for tree automatic scattered linear orderings. Moreover, we show that\nin case of a positive answer a word automatic presentation is computable from\nthe tree automatic presentation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2012 18:03:50 GMT"}], "update_date": "2012-01-25", "authors_parsed": [["Huschenbett", "Martin", ""]]}, {"id": "1201.5073", "submitter": "Mickael Randour", "authors": "Krishnendu Chatterjee and Mickael Randour and Jean-Fran\\c{c}ois Raskin", "title": "Strategy Synthesis for Multi-dimensional Quantitative Objectives", "comments": "Conference version published in CONCUR 2012, LNCS 7454. Journal\n  version published in Acta Informatica, volume 51, issue 3-4, Springer, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-dimensional mean-payoff and energy games provide the mathematical\nfoundation for the quantitative study of reactive systems, and play a central\nrole in the emerging quantitative theory of verification and synthesis. In this\nwork, we study the strategy synthesis problem for games with such\nmulti-dimensional objectives along with a parity condition, a canonical way to\nexpress $\\omega$-regular conditions. While in general, the winning strategies\nin such games may require infinite memory, for synthesis the most relevant\nproblem is the construction of a finite-memory winning strategy (if one\nexists). Our main contributions are as follows. First, we show a tight\nexponential bound (matching upper and lower bounds) on the memory required for\nfinite-memory winning strategies in both multi-dimensional mean-payoff and\nenergy games along with parity objectives. This significantly improves the\ntriple exponential upper bound for multi energy games (without parity) that\ncould be derived from results in literature for games on VASS (vector addition\nsystems with states). Second, we present an optimal symbolic and incremental\nalgorithm to compute a finite-memory winning strategy (if one exists) in such\ngames. Finally, we give a complete characterization of when finite memory of\nstrategies can be traded off for randomness. In particular, we show that for\none-dimension mean-payoff parity games, randomized memoryless strategies are as\npowerful as their pure finite-memory counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2012 18:14:01 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2012 08:45:01 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2012 08:17:40 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2013 15:16:39 GMT"}, {"version": "v5", "created": "Mon, 3 Nov 2014 16:23:34 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Randour", "Mickael", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "1201.5162", "submitter": "David Fern\\'andez-Duque", "authors": "David Fern\\'andez Duque", "title": "A sound and complete axiomatization for Dynamic Topological Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Topological Logic (DTL) is a multimodal system for reasoning about\ndynamical systems. It is defined semantically and, as such, most of the work\ndone in the field has been model-theoretic. In particular, the problem of\nfinding a complete axiomatization for the full language of DTL over the class\nof all dynamical systems has proven to be quite elusive.\n  Here we propose to enrich the language to include a polyadic topological\nmodality, originally introduced by Dawar and Otto in a different context. We\nthen provide a sound axiomatization for DTL over this extended language, and\nprove that it is complete. The polyadic modality is used in an essential way in\nour proof.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 00:21:31 GMT"}], "update_date": "2012-01-26", "authors_parsed": [["Duque", "David Fern\u00e1ndez", ""]]}, {"id": "1201.5240", "submitter": "James Cheney", "authors": "James Cheney (University of Edinburgh)", "title": "A dependent nominal type theory", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (February\n  20, 2012) lmcs:1042", "doi": "10.2168/LMCS-8(1:8)2012", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nominal abstract syntax is an approach to representing names and binding\npioneered by Gabbay and Pitts. So far nominal techniques have mostly been\nstudied using classical logic or model theory, not type theory. Nominal\nextensions to simple, dependent and ML-like polymorphic languages have been\nstudied, but decidability and normalization results have only been established\nfor simple nominal type theories. We present a LF-style dependent type theory\nextended with name-abstraction types, prove soundness and decidability of\nbeta-eta-equivalence checking, discuss adequacy and canonical forms via an\nexample, and discuss extensions such as dependently-typed recursion and\ninduction principles.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 11:47:52 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2012 19:35:23 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Cheney", "James", "", "University of Edinburgh"]]}, {"id": "1201.5346", "submitter": "Valentin Goranko", "authors": "Mai Ajspur and Valentin Goranko and Dmitry Shkatov", "title": "Tableau-based decision procedure for the multi-agent epistemic logic\n  with all coalitional operators for common and distributed knowledge", "comments": "Substantially extended and corrected version of arXiv:0902.2125. To\n  appear in: Logic Journal of the IGPL, special issue on Formal Aspects of\n  Multi-Agent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a conceptually clear, intuitive, and feasible decision procedure\nfor testing satisfiability in the full multi-agent epistemic logic CMAEL(CD)\nwith operators for common and distributed knowledge for all coalitions of\nagents mentioned in the language. To that end, we introduce Hintikka structures\nfor CMAEL(CD) and prove that satisfiability in such structures is equivalent to\nsatisfiability in standard models. Using that result, we design an incremental\ntableau-building procedure that eventually constructs a satisfying Hintikka\nstructure for every satisfiable input set of formulae of CMAEL(CD) and closes\nfor every unsatisfiable input set of formulae.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 19:18:00 GMT"}], "update_date": "2016-11-27", "authors_parsed": [["Ajspur", "Mai", ""], ["Goranko", "Valentin", ""], ["Shkatov", "Dmitry", ""]]}, {"id": "1201.5418", "submitter": "Rafael Caballero", "authors": "R. Caballero, M. Rodriguez-Artalejo and C. A. Romero-Diaz", "title": "A Transformation-based Implementation for CLP with Qualification and\n  Proximity", "comments": "To appear in Theory and Practice of Logic Programming (TPLP). arXiv\n  admin note: significant text overlap with arXiv:1009.1976", "journal-ref": null, "doi": null, "report-no": "12-R01-TPLP", "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Uncertainty in logic programming has been widely investigated in the last\ndecades, leading to multiple extensions of the classical LP paradigm. However,\nfew of these are designed as extensions of the well-established and powerful\nCLP scheme for Constraint Logic Programming. In a previous work we have\nproposed the SQCLP ({\\em proximity-based qualified constraint logic\nprogramming}) scheme as a quite expressive extension of CLP with support for\nqualification values and proximity relations as generalizations of uncertainty\nvalues and similarity relations, respectively. In this paper we provide a\ntransformation technique for transforming SQCLP programs and goals into\nsemantically equivalent CLP programs and goals, and a practical Prolog-based\nimplementation of some particularly useful instances of the SQCLP scheme. We\nalso illustrate, by showing some simple---and working---examples, how the\nprototype can be effectively used as a tool for solving problems where\nqualification values and proximity relations play a key role. Intended use of\nSQCLP includes flexible information retrieval applications.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 23:47:26 GMT"}], "update_date": "2012-01-27", "authors_parsed": [["Caballero", "R.", ""], ["Rodriguez-Artalejo", "M.", ""], ["Romero-Diaz", "C. A.", ""]]}, {"id": "1201.5495", "submitter": "Markus Lohrey", "authors": "Martin Huschenbett (Technical University of Ilmenau), Alexander\n  Kartzow (University of Leipzig), Jiamou Liu (Auckland University of\n  Technology), Markus Lohrey (University of Leipzig)", "title": "Tree-Automatic Well-Founded Trees", "comments": "Will appear in Logical Methods of Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 2 (June 25,\n  2013) lmcs:721", "doi": "10.2168/LMCS-9(2:10)2013", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate tree-automatic well-founded trees. Using Delhomme's\ndecomposition technique for tree-automatic structures, we show that the\n(ordinal) rank of a tree-automatic well-founded tree is strictly below\nomega^omega. Moreover, we make a step towards proving that the ranks of\ntree-automatic well-founded partial orders are bounded by omega^omega^omega: we\nprove this bound for what we call upwards linear partial orders. As an\napplication of our result, we show that the isomorphism problem for\ntree-automatic well-founded trees is complete for level Delta^0_{omega^omega}\nof the hyperarithmetical hierarchy with respect to Turing-reductions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2012 12:09:22 GMT"}, {"version": "v2", "created": "Thu, 30 May 2013 07:32:03 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2013 19:48:51 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Huschenbett", "Martin", "", "Technical University of Ilmenau"], ["Kartzow", "Alexander", "", "University of Leipzig"], ["Liu", "Jiamou", "", "Auckland University of\n  Technology"], ["Lohrey", "Markus", "", "University of Leipzig"]]}, {"id": "1201.5597", "submitter": "Philipp Schlicht", "authors": "Dan Brumleve and Joel David Hamkins and Philipp Schlicht", "title": "The mate-in-n problem of infinite chess is decidable", "comments": "10 pages, 1 figure, CiE 2012. updated author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infinite chess is chess played on an infinite edgeless chessboard. The\nfamiliar chess pieces move about according to their usual chess rules, and each\nplayer strives to place the opposing king into checkmate. The mate-in-n problem\nof infinite chess is the problem of determining whether a designated player can\nforce a win from a given finite position in at most n moves. A naive\nformulation of this problem leads to assertions of high arithmetic complexity\nwith 2n alternating quantifiers---there is a move for white, such that for\nevery black reply, there is a counter-move for white, and so on. In such a\nformulation, the problem does not appear to be decidable; and one cannot expect\nto search an infinitely branching game tree even to finite depth. Nevertheless,\nthe main theorem of this article, confirming a conjecture of the first author\nand C. D. A. Evans, establishes that the mate-in-n problem of infinite chess is\ncomputably decidable, uniformly in the position and in n. Furthermore, there is\na computable strategy for optimal play from such mate-in-n positions. The proof\nproceeds by showing that the mate-in-n problem is expressible in what we call\nthe first-order structure of chess, which we prove (in the relevant fragment)\nis an automatic structure, whose theory is therefore decidable. Indeed, it is\ndefinable in Presburger arithmetic. Unfortunately, this resolution of the\nmate-in-n problem does not appear to settle the decidability of the more\ngeneral winning-position problem, the problem of determining whether a\ndesignated player has a winning strategy from a given position, since a\nposition may admit a winning strategy without any bound on the number of moves\nrequired. This issue is connected with transfinite game values in infinite\nchess, and the exact value of the omega one of chess is not known.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2012 18:26:57 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2012 14:18:54 GMT"}, {"version": "v3", "created": "Wed, 11 Apr 2012 13:32:14 GMT"}, {"version": "v4", "created": "Wed, 16 May 2012 15:32:29 GMT"}], "update_date": "2012-05-17", "authors_parsed": [["Brumleve", "Dan", ""], ["Hamkins", "Joel David", ""], ["Schlicht", "Philipp", ""]]}, {"id": "1201.5653", "submitter": "Eugene Goldberg", "authors": "Eugene Goldberg and Panagiotis Manolios", "title": "Quantifier Elimination by Dependency Sequents", "comments": "All the changes we made with respect to the previous versions are\n  listed in the footnotes. The main change is that we modified the definition\n  of a D-sequent using the notion of scoped redundancy of variables. We\n  modified a few proofs of propositions affected by this change", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of existential quantifier elimination for Boolean\nformulas in Conjunctive Normal Form (CNF). We present a new method for solving\nthis problem called Derivation of Dependency-Sequents (DDS). A\nDependency-sequent (D-sequent) is used to record that a set of quantified\nvariables is redundant under a partial assignment. We introduce a\nresolution-like operation called join that produces a new D-sequent from two\nexisting D-sequents. We also show that DDS is compositional, i.e. if our input\nformula is a conjunction of independent formulas, DDS automatically recognizes\nand exploits this information. We introduce an algorithm based on DDS and\npresent experimental results demonstrating its potential.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2012 21:18:29 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2012 13:51:04 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2012 16:20:02 GMT"}, {"version": "v4", "created": "Sun, 2 Jun 2013 17:49:07 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Goldberg", "Eugene", ""], ["Manolios", "Panagiotis", ""]]}, {"id": "1201.5719", "submitter": "Daniel Borchmann", "authors": "Daniel Borchmann", "title": "Deciding Entailment of Implications with Support and Confidence in\n  Polynomial Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Association Rules are a basic concept of data mining. They are, however, not\nunderstood as logical objects which can be used for reasoning. The purpose of\nthis paper is to investigate a model based semantic for implications with\ncertain constraints on their support and confidence in relational data, which\nthen resemble association rules, and to present a possibility to decide\nentailment for them.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 08:32:38 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2012 06:24:59 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Borchmann", "Daniel", ""]]}, {"id": "1201.5835", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "Sequence encoding without induction", "comments": "7 pages", "journal-ref": "Mathematical Logic Quarterly 58 (2012), no. 3, pp. 244-248", "doi": "10.1002/malq.201200013", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the universally axiomatized, induction-free theory PA^- is a\nsequential theory in the sense of Pudl\\'ak [5], in contrast to the closely\nrelated Robinson's arithmetic.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 17:07:21 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "1201.5853", "submitter": "Fr\\'ed\\'eric Olive", "authors": "Etienne Grandjean and Fr\\'ed\\'eric Olive and Ga\\'etan richard", "title": "Descriptive complexity for pictures languages (extended abstract)", "comments": "33 pages - Submited to Lics 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with descriptive complexity of picture languages of any\ndimension by syntactical fragments of existential second-order logic.\n  - We uniformly generalize to any dimension the characterization by\nGiammarresi et al. \\cite{GRST96} of the class of \\emph{recognizable} picture\nlanguages in existential monadic second-order logic. - We state several logical\ncharacterizations of the class of picture languages recognized in linear time\non nondeterministic cellular automata of any dimension. They are the first\nmachine-independent characterizations of complexity classes of cellular\nautomata.\n  Our characterizations are essentially deduced from normalization results we\nprove for first-order and existential second-order logics over pictures. They\nare obtained in a general and uniform framework that allows to extend them to\nother \"regular\" structures. Finally, we describe some hierarchy results that\nshow the optimality of our logical characterizations and delineate their\nlimits.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 18:07:42 GMT"}], "update_date": "2012-01-30", "authors_parsed": [["Grandjean", "Etienne", ""], ["Olive", "Fr\u00e9d\u00e9ric", ""], ["richard", "Ga\u00e9tan", ""]]}, {"id": "1201.5954", "submitter": "Mnacho Echenim Mr", "authors": "Mnacho Echenim and Nicolas Peltier", "title": "A Calculus for Generating Ground Explanations (Technical Report)", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modification of the superposition calculus that is meant to\ngenerate explanations why a set of clauses is satisfiable. This process is\nrelated to abductive reasoning, and the explanations generated are clauses\nconstructed over so-called abductive constants. We prove the correctness and\ncompleteness of the calculus in the presence of redundancy elimination rules,\nand develop a sufficient condition guaranteeing its termination; this\nsufficient condition is then used to prove that all possible explanations can\nbe generated infinite time for several classes of clause sets, including many\nof interest to the SMT community. We propose a procedure that generates a set\nof explanations that should be useful to a human user and conclude by\nsuggesting several extensions to this novel approach.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 12:35:04 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Echenim", "Mnacho", ""], ["Peltier", "Nicolas", ""]]}, {"id": "1201.6028", "submitter": "Jan Bergstra", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Turing Impossibility Properties for Stack Machine Programming", "comments": "arXiv admin note: substantial text overlap with arXiv:0910.5564", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The strong, intermediate, and weak Turing impossibility properties are\nintroduced. Some facts concerning Turing impossibility for stack machine\nprogramming are trivially adapted from previous work. Several intriguing\nquestions are raised about the Turing impossibility properties concerning\ndifferent method interfaces for stack machine programming.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2012 11:14:58 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1201.6306", "submitter": "Hubie Chen", "authors": "Hubie Chen", "title": "Meditations on Quantified Constraint Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantified constraint satisfaction problem (QCSP) is the problem of\ndeciding, given a structure and a first-order prenex sentence whose\nquantifier-free part is the conjunction of atoms, whether or not the sentence\nholds on the structure. One obtains a family of problems by defining, for each\nstructure B, the problem QCSP(B) to be the QCSP where the structure is fixed to\nbe B. In this article, we offer a viewpoint on the research program of\nunderstanding the complexity of the problems QCSP(B) on finite structures. In\nparticular, we propose and discuss a group of conjectures; throughout, we\nattempt to place the conjectures in relation to existing results and to\nemphasize open issues and potential research directions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2012 18:04:56 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Chen", "Hubie", ""]]}]