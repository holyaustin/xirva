[{"id": "2005.00196", "submitter": "EPTCS", "authors": "Niels Voorneveld", "title": "From Equations to Distinctions: Two Interpretations of Effectful\n  Computations", "comments": "In Proceedings MSFP 2020, arXiv:2004.14735", "journal-ref": "EPTCS 317, 2020, pp. 1-17", "doi": "10.4204/EPTCS.317.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several ways to define program equivalence for functional programs\nwith algebraic effects. We consider two complementing ways to specify\nbehavioural equivalence. One way is to specify a set of axiomatic equations,\nand allow proof methods to show that two programs are equivalent. Another way\nis to specify an Eilenberg-Moore algebra, which generate tests that could\ndistinguish programs. These two methods are said to complement each other if\nany two programs can be shown to be equivalent if and only if there is no test\nto distinguish them.\n  In this paper, we study a generic method to formulate from a set of axiomatic\nequations an Eilenberg-Moore algebra which complements it. We will look at an\nadditional condition which must be satisfied for this to work. We then apply\nthis method to a handful of examples of effects, including probability and\nglobal store, and show they coincide with the usual algebras from the\nliterature. We will moreover study whether or not it is possible to specify a\nset of unary Boolean modalities which could function as distinction-tests\ncomplementing the equational theory.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 03:41:39 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Voorneveld", "Niels", ""]]}, {"id": "2005.00197", "submitter": "EPTCS", "authors": "Anne Baanen (Vrije Universiteit Amsterdam), Wouter Swierstra (Utrecht\n  Univeristy)", "title": "Combining predicate transformer semantics for effects: a case study in\n  parsing regular languages", "comments": "In Proceedings MSFP 2020, arXiv:2004.14735", "journal-ref": "EPTCS 317, 2020, pp. 39-56", "doi": "10.4204/EPTCS.317.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how to verify a parser for regular expressions in a\nfunctional programming language using predicate transformer semantics for a\nvariety of effects. Where our previous work in this area focused on the\nsemantics for a single effect, parsing requires a combination of effects:\nnon-determinism, general recursion and mutable state. Reasoning about such\ncombinations of effects is notoriously difficult, yet our approach using\npredicate transformers enables the careful separation of program syntax,\ncorrectness proofs and termination proofs.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 03:42:21 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Baanen", "Anne", "", "Vrije Universiteit Amsterdam"], ["Swierstra", "Wouter", "", "Utrecht\n  Univeristy"]]}, {"id": "2005.00198", "submitter": "EPTCS", "authors": "Artjoms {\\v{S}}inkarovs (Heriot-Watt University)", "title": "Multi-dimensional Arrays with Levels", "comments": "In Proceedings MSFP 2020, arXiv:2004.14735", "journal-ref": "EPTCS 317, 2020, pp. 57-71", "doi": "10.4204/EPTCS.317.4", "report-no": null, "categories": "cs.DS cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a data structure that generalises rectangular multi-dimensional\narrays. The shape of an n-dimensional array is typically given by a tuple of n\nnatural numbers. Each element in that tuple defines the length of the\ncorresponding axis. If we treat this tuple as an array, the shape of that array\nis described by the single natural number n. A natural number itself can be\nalso treated as an array with the shape described by the natural number 1 (or\nthe element of any singleton set). This observation gives rise to the hierarchy\nof array types where the shape of an array of level l+1 is a level-l array of\nnatural numbers. Such a hierarchy occurs naturally when treating arrays as\ncontainers, which makes it possible to define both rank- and level-polymorphic\noperations. The former can be found in most array languages, whereas the latter\ngives rise to partial selections on a large set of hyperplanes, which is often\nuseful in practice. In this paper we present an Agda formalisation of arrays\nwith levels. We show that the proposed formalism supports standard\nrank-polymorphic array operations, while type system gives static guarantees\nthat indexing is within bounds. We generalise the notion of ranked operator so\nthat it becomes applicable on arrays of arbitrary levels and we show why this\nmay be useful in practice.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 03:42:41 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["{\u0160}inkarovs", "Artjoms", "", "Heriot-Watt University"]]}, {"id": "2005.00199", "submitter": "EPTCS", "authors": "Christopher Jenkins, Aaron Stump, Larry Diehl", "title": "Efficient lambda encodings for Mendler-style coinductive types in\n  Cedille", "comments": "In Proceedings MSFP 2020, arXiv:2004.14735", "journal-ref": "EPTCS 317, 2020, pp. 72-97", "doi": "10.4204/EPTCS.317.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the calculus of dependent lambda eliminations (CDLE), it is possible to\ndefine inductive datatypes via lambda encodings that feature constant-time\ndestructors and a course-of-values induction scheme. This paper begins to\naddress the missing derivations for the dual, coinductive types. Our derivation\nutilizes new methods within CDLE, as there are seemingly fundamental\ndifficulties in adapting previous known approaches for deriving inductive\ntypes. The lambda encodings we present implementing coinductive types feature\nconstant-time constructors and a course-of-values corecursion scheme.\nCoinductive type families are also supported, enabling proofs for many standard\ncoinductive properties such as stream bisimulation. All work is mechanically\nverified by the Cedille tool, an implementation of CDLE.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 03:42:59 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jenkins", "Christopher", ""], ["Stump", "Aaron", ""], ["Diehl", "Larry", ""]]}, {"id": "2005.00207", "submitter": "EPTCS", "authors": "Tejas Bhojraj (Department of Mathematics, University of\n  Wisconsin-Madison)", "title": "Generating Randomness from a Computable, Non-random Sequence of Qubits", "comments": "In Proceedings QPL 2019, arXiv:2004.14750", "journal-ref": "EPTCS 318, 2020, pp. 1-12", "doi": "10.4204/EPTCS.318.1", "report-no": null, "categories": "cs.IT cs.LO math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nies and Scholz introduced the notion of a state to describe an infinite\nsequence of qubits and defined quantum-Martin-Lof randomness for states,\nanalogously to the well known concept of Martin-L\\\"of randomness for elements\nof Cantor space (the space of infinite sequences of bits). We formalize how\n'measurement' of a state in a basis induces a probability measure on Cantor\nspace. A state is 'measurement random' (mR) if the measure induced by it, under\nany computable basis, assigns probability one to the set of Martin-L\\\"of\nrandoms. Equivalently, a state is mR if and only if measuring it in any\ncomputable basis yields a Martin-L\\\"of random with probability one. While\nquantum-Martin-L\\\"of random states are mR, the converse fails: there is a mR\nstate, x which is not quantum-Martin-L\\\"of random. In fact, something stronger\nis true. While x is computable and can be easily constructed, measuring it in\nany computable basis yields an arithmetically random sequence with probability\none. I.e., classical arithmetic randomness can be generated from a computable,\nnon-quantum random sequence of qubits.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:09:49 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Bhojraj", "Tejas", "", "Department of Mathematics, University of\n  Wisconsin-Madison"]]}, {"id": "2005.00208", "submitter": "EPTCS", "authors": "Jean-Simon Pacaud Lemay (University of OXford)", "title": "Why FHilb is Not an Interesting (Co)Differential Category", "comments": "In Proceedings QPL 2019, arXiv:2004.14750", "journal-ref": "EPTCS 318, 2020, pp. 13-26", "doi": "10.4204/EPTCS.318.2", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential categories provide an axiomatization of the basics of\ndifferentiation and categorical models of differential linear logic. As\ndifferentiation is an important tool throughout quantum mechanics and quantum\ninformation, it makes sense to study applications of the theory of differential\ncategories to categorical quantum foundations. In categorical quantum\nfoundations, compact closed categories (and therefore traced symmetric monoidal\ncategories) are one of the main objects of study, in particular the category of\nfinite-dimensional Hilbert spaces FHilb. In this paper, we will explain why the\nonly differential category structure on FHilb is the trivial one. This follows\nfrom a sort of in-compatibility between the trace of FHilb and possible\ndifferential category structure. That said, there are interesting non-trivial\nexamples of traced/compact closed differential categories, which we also\ndiscuss.\n  The goal of this paper is to introduce differential categories to the broader\ncategorical quantum foundation community and hopefully open the door to further\nwork in combining these two fields. While the main result of this paper may\nseem somewhat \"negative\" in achieving this goal, we discuss interesting\npotential applications of differential categories to categorical quantum\nfoundations.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:10:01 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Lemay", "Jean-Simon Pacaud", "", "University of OXford"]]}, {"id": "2005.00209", "submitter": "EPTCS", "authors": "Octavio Zapata", "title": "Effectus of Quantum Probability on Relational Structures", "comments": "In Proceedings QPL 2019, arXiv:2004.14750", "journal-ref": "EPTCS 318, 2020, pp. 53-65", "doi": "10.4204/EPTCS.318.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of effectus from categorical logic is relevant in the emerging\nfield of categorical probability theory. In some cases, stochastic maps are\nrepresented by maps in the Kleisli category of some probability monad. Quantum\nhomomorphisms from combinatorics and quantum information theory are the Kleisli\nmaps of certain sort of quantum monad. We show that the Kleisli category of\nthis quantum monad is an effectus. This gives rise to notions of quantum\nprobabilistic reasoning as predicates, validity, conditioning, and channels.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:10:25 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zapata", "Octavio", ""]]}, {"id": "2005.00210", "submitter": "EPTCS", "authors": "Robert Furber (Aalborg University)", "title": "Scott Continuity in Generalized Probabilistic Theories", "comments": "In Proceedings QPL 2019, arXiv:2004.14750", "journal-ref": "EPTCS 318, 2020, pp. 66-84", "doi": "10.4204/EPTCS.318.5", "report-no": null, "categories": "cs.LO math.OA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scott continuity is a concept from domain theory that had an unexpected\nprevious life in the theory of von Neumann algebras. Scott-continuous states\nare known as normal states, and normal states are exactly the states coming\nfrom density matrices. Given this, and the usefulness of Scott continuity in\ndomain theory, it is natural to ask whether this carries over to generalized\nprobabilistic theories. We show that the answer is no - there are\ninfinite-dimensional convex sets for which the set of Scott-continuous states\non the corresponding set of 2-valued POVMs does not recover the original convex\nset, but is strictly larger. This shows the necessity of the use of topologies\nfor state-effect duality in the general case, rather than purely order\ntheoretic notions.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:10:38 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Furber", "Robert", "", "Aalborg University"]]}, {"id": "2005.00211", "submitter": "EPTCS", "authors": "Giulia Meuli (EPFL), Mathias Soeken (EPFL), Martin Roetteler\n  (Microsoft), Giovanni De Micheli (EPFL)", "title": "ROS: Resource-constrained Oracle Synthesis for Quantum Computers", "comments": "In Proceedings QPL 2019, arXiv:2004.14750", "journal-ref": "EPTCS 318, 2020, pp. 119-130", "doi": "10.4204/EPTCS.318.8", "report-no": null, "categories": "cs.ET cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a completely automatic synthesis framework for oracle functions, a\ncentral part in many quantum algorithms. The proposed framework for\nresource-constrained oracle synthesis (ROS) is a LUT-based hierarchical method\nin which every step is specifically tailored to address hardware resource\nconstraints. ROS embeds a LUT mapper designed to simplify the successive\nsynthesis steps, costing each LUT according to the resources used by its\ncorresponding quantum circuit. In addition, the framework exploits a SAT-based\nquantum garbage management technique. Those two characteristics give ROS the\nability to beat the state-of-the-art hierarchical method both in number of\nqubits and in number of operations. The efficiency of the framework is\ndemonstrated by synthesizing quantum oracles for Grover's algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:11:25 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Meuli", "Giulia", "", "EPFL"], ["Soeken", "Mathias", "", "EPFL"], ["Roetteler", "Martin", "", "Microsoft"], ["De Micheli", "Giovanni", "", "EPFL"]]}, {"id": "2005.00260", "submitter": "Christian Sattler", "authors": "Christian Sattler and Andrea Vezzosi", "title": "Partial Univalence in n-truncated Type Theory", "comments": "21 pages, long version of paper accepted at LICS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is well known that univalence is incompatible with uniqueness of identity\nproofs (UIP), the axiom that all types are h-sets. This is due to finite h-sets\nhaving non-trivial automorphisms as soon as they are not h-propositions.\n  A natural question is then whether univalence restricted to h-propositions is\ncompatible with UIP. We answer this affirmatively by constructing a model where\ntypes are elements of a closed universe defined as a higher inductive type in\nhomotopy type theory. This universe has a path constructor for simultaneous\n\"partial\" univalent completion, i.e., restricted to h-propositions.\n  More generally, we show that univalence restricted to $(n-1)$-types is\nconsistent with the assumption that all types are $n$-truncated. Moreover we\nparametrize our construction by a suitably well-behaved container, to abstract\nfrom a concrete choice of type formers for the universe.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 07:46:32 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Sattler", "Christian", ""], ["Vezzosi", "Andrea", ""]]}, {"id": "2005.00266", "submitter": "Libor Barto", "authors": "Libor Barto, Marcin Kozik, Johnson Tan, Matt Valeriote", "title": "Sensitive instances of the Constraint Satisfaction Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the impact of modifying the constraining relations of a\nConstraint Satisfaction Problem (CSP) instance, with a fixed template, on the\nset of solutions of the instance. More precisely we investigate sensitive\ninstances: an instance of the CSP is called sensitive, if removing any tuple\nfrom any constraining relation invalidates some solution of the instance.\nEquivalently, one could require that every tuple from any one of its\nconstraints extends to a solution of the instance.\n  Clearly, any non-trivial template has instances which are not sensitive.\nTherefore we follow the direction proposed (in the context of strict width) by\nFeder and Vardi (SICOMP 1999) and require that only the instances produced by a\nlocal consistency checking algorithm are sensitive. In the language of the\nalgebraic approach to the CSP we show that a finite idempotent algebra\n$\\mathbf{A}$ has a $k+2$ variable near unanimity term operation if and only if\nany instance that results from running the $(k, k+1)$-consistency algorithm on\nan instance over $\\mathbf{A}^2$ is sensitive.\n  A version of our result, without idempotency but with the sensitivity\ncondition holding in a variety of algebras, settles a question posed by G.\nBergman about systems of projections of algebras that arise from some\nsubalgebra of a finite product of algebras.\n  Our results hold for infinite (albeit in the case of $\\mathbf{A}$ idempotent)\nalgebras as well and exhibit a surprising similarity to the strict width $k$\ncondition proposed by Feder and Vardi. Both conditions can be characterized by\nthe existence of a near unanimity operation, but the arities of the operations\ndiffer by 1.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 08:20:52 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Barto", "Libor", ""], ["Kozik", "Marcin", ""], ["Tan", "Johnson", ""], ["Valeriote", "Matt", ""]]}, {"id": "2005.00404", "submitter": "Stepan Kuznetsov", "authors": "Stepan Kuznetsov", "title": "Complexity of the Infinitary Lambek Calculus with Kleene Star", "comments": "Manuscript accepted to the Review of Symbolic Logic. An updated\n  version will be published by Cambridge University Press", "journal-ref": null, "doi": "10.1017/S1755020320000209", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Lambek calculus, or non-commutative multiplicative\nintuitionistic linear logic, extended with iteration, or Kleene star,\naxiomatised by means of an $\\omega$-rule, and prove that the derivability\nproblem in this calculus is $\\Pi_1^0$-hard. This solves a problem left open by\nBuszkowski (2007), who obtained the same complexity bound for infinitary action\nlogic, which additionally includes additive conjunction and disjunction. As a\nby-product, we prove that any context-free language without the empty word can\nbe generated by a Lambek grammar with unique type assignment, without Lambek's\nnon-emptiness restriction imposed (cf. Safiullin 2007).\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 14:29:28 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Kuznetsov", "Stepan", ""]]}, {"id": "2005.00472", "submitter": "Salomon Sickert", "authors": "Salomon Sickert, Javier Esparza", "title": "An Efficient Normalisation Procedure for Linear Temporal Logic and Very\n  Weak Alternating Automata", "comments": "This is the extended version of the referenced conference paper and\n  contains an appendix with additional material", "journal-ref": null, "doi": "10.1145/3373718.3394743", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the mid 80s, Lichtenstein, Pnueli, and Zuck proved a classical theorem\nstating that every formula of Past LTL (the extension of LTL with past\noperators) is equivalent to a formula of the form $\\bigwedge_{i=1}^n\n\\mathbf{G}\\mathbf{F} \\varphi_i \\vee \\mathbf{F}\\mathbf{G} \\psi_i$, where\n$\\varphi_i$ and $\\psi_i$ contain only past operators. Some years later, Chang,\nManna, and Pnueli built on this result to derive a similar normal form for LTL.\nBoth normalisation procedures have a non-elementary worst-case blow-up, and\nfollow an involved path from formulas to counter-free automata to star-free\nregular expressions and back to formulas. We improve on both points. We present\na direct and purely syntactic normalisation procedure for LTL yielding a normal\nform, comparable to the one by Chang, Manna, and Pnueli, that has only a single\nexponential blow-up. As an application, we derive a simple algorithm to\ntranslate LTL into deterministic Rabin automata. The algorithm normalises the\nformula, translates it into a special very weak alternating automaton, and\napplies a simple determinisation procedure, valid only for these special\nautomata.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 16:24:24 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Sickert", "Salomon", ""], ["Esparza", "Javier", ""]]}, {"id": "2005.00593", "submitter": "Dmitriy Zhuk", "authors": "Dmitriy Zhuk", "title": "Strong subalgebras and the Constraint Satisfaction Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2007 it was conjectured that the Constraint Satisfaction Problem (CSP)\nover a constraint language $\\Gamma$ is tractable if and only if $\\Gamma$ is\npreserved by a weak near-unanimity (WNU) operation. After many efforts and\npartial results, this conjecture was independently proved by Andrei Bulatov and\nthe author in 2017. In this paper we consider one of two main ingredients of my\nproof, that is, strong subalgebras that allow us to reduce domains of the\nvariables iteratively. To explain how this idea works we show the algebraic\nproperties of strong subalgebras and provide self-contained proof of two\nimportant facts about the complexity of the CSP. First, we prove that if a\nconstraint language is not preserved by a WNU operation then the corresponding\nCSP is NP-hard. Second, we characterize all constraint languages that can be\nsolved by local consistency checking. Additionally, we characterize all\nidempotent algebras not having a WNU term of a concrete arity $n$, not having a\nWNU term, having WNU terms of all arities greater than 2. Most of the results\npresented in the paper are not new, but I believe this paper can help to\nunderstand my approach to CSP and the new self-contained proof of known facts\nwill be also useful.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:19:00 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhuk", "Dmitriy", ""]]}, {"id": "2005.00641", "submitter": "Shahar Maoz", "authors": "Gal Amram, Shahar Maoz, Or Pistiner, Jan Oliver Ringert", "title": "Energy mu-Calculus: Symbolic Fixed-Point Algorithms for omega-Regular\n  Energy Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\omega$-regular energy games, which are weighted two-player turn-based games\nwith the quantitative objective to keep the energy levels non-negative, have\nbeen used in the context of verification and synthesis. The logic of modal\n$\\mu$-calculus, when applied over game graphs with $\\omega$-regular winning\nconditions, allows defining symbolic algorithms in the form of fixed-point\nformulas for computing the sets of winning states.\n  In this paper, we introduce energy $\\mu$-calculus, a multi-valued extension\nof the $\\mu$-calculus that serves as a symbolic framework for solving\n$\\omega$-regular energy games. Energy $\\mu$-calculus enables the seamless reuse\nof existing, well-known symbolic $\\mu$-calculus algorithms for $\\omega$-regular\ngames, to solve their corresponding energy augmented variants. We define the\nsyntax and semantics of energy $\\mu$-calculus over symbolic representations of\nthe game graphs, and show how to use it to solve the decision and the minimum\ncredit problems for $\\omega$-regular energy games, for both bounded and\nunbounded energy level accumulations.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 22:48:19 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 13:44:21 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Amram", "Gal", ""], ["Maoz", "Shahar", ""], ["Pistiner", "Or", ""], ["Ringert", "Jan Oliver", ""]]}, {"id": "2005.00746", "submitter": "Kees Middelburg", "authors": "R.J. van Glabbeek, C.A. Middelburg", "title": "On infinite guarded recursive specifications in process algebra", "comments": "9 pages, there is text overlap with earlier papers (arXiv:1703.06822,\n  arXiv:1912.10041, arXiv:2003.00473)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most presentations of ACP with guarded recursion, recursive specifications\nare finite or infinite sets of recursion equations of which the right-hand\nsides are guarded terms. The completeness with respect to bisimulation\nequivalence of the axioms of ACP with guarded recursion has only been proved\nfor the special case where recursive specifications are finite sets of\nrecursion equations of which the right-hand sides are guarded terms of a\nrestricted form known as linear terms. In this note, we widen this completeness\nresult to the general case.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 08:20:15 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["van Glabbeek", "R. J.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "2005.00782", "submitter": "Pei Zhou", "authors": "Pei Zhou, Rahul Khanna, Seyeon Lee, Bill Yuchen Lin, Daniel Ho, Jay\n  Pujara, Xiang Ren", "title": "RICA: Evaluating Robust Inference Capabilities Based on Commonsense\n  Axioms", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models (PTLMs) have achieved impressive performance on\ncommonsense inference benchmarks, but their ability to employ commonsense to\nmake robust inferences, which is crucial for effective communications with\nhumans, is debated. In the pursuit of advancing fluid human-AI communication,\nwe propose a new challenge, RICA: Robust Inference capability based on\nCommonsense Axioms, that evaluates robust commonsense inference despite textual\nperturbations. To generate data for this challenge, we develop a systematic and\nscalable procedure using commonsense knowledge bases and probe PTLMs across two\ndifferent evaluation settings. Extensive experiments on our generated probe\nsets with more than 10k statements show that PTLMs perform no better than\nrandom guessing on the zero-shot setting, are heavily impacted by statistical\nbiases, and are not robust to perturbation attacks. We also find that\nfine-tuning on similar statements offer limited gains, as PTLMs still fail to\ngeneralize to unseen inferences. Our new large-scale benchmark exposes a\nsignificant gap between PTLMs and human-level language understanding and offers\na new challenge for PTLMs to demonstrate commonsense.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 10:36:55 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 04:11:53 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 23:40:23 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zhou", "Pei", ""], ["Khanna", "Rahul", ""], ["Lee", "Seyeon", ""], ["Lin", "Bill Yuchen", ""], ["Ho", "Daniel", ""], ["Pujara", "Jay", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00961", "submitter": "Hiroyuki Kido", "authors": "Hiroyuki Kido", "title": "Bayesian Entailment Hypothesis: How Brains Implement Monotonic and\n  Non-monotonic Reasoning", "comments": "This paper was submitted to IJCAI 2020 and rejected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of Bayesian methods in neuroscience and artificial\nintelligence gives rise to the hypothesis that the brain is a Bayesian machine.\nSince logic, as the laws of thought, is a product and practice of the human\nbrain, it leads to another hypothesis that there is a Bayesian algorithm and\ndata-structure for logical reasoning. In this paper, we give a Bayesian account\nof entailment and characterize its abstract inferential properties. The\nBayesian entailment is shown to be a monotonic consequence relation in an\nextreme case. In general, it is a sort of non-monotonic consequence relation\nwithout Cautious monotony or Cut. The preferential entailment, which is a\nrepresentative non-monotonic consequence relation, is shown to be maximum a\nposteriori entailment, which is an approximation of the Bayesian entailment. We\nfinally discuss merits of our proposals in terms of encoding preferences on\ndefaults, handling change and contradiction, and modeling human entailment.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 01:26:02 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 09:04:54 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 18:00:03 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Kido", "Hiroyuki", ""]]}, {"id": "2005.00990", "submitter": "Philipp R\\\"ummer", "authors": "Anthony W. Lin, Philipp R\\\"ummer", "title": "Regular Model Checking Revisited (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution we revisit regular model checking, a powerful framework\nthat has been successfully applied for the verification of infinite-state\nsystems, especially parameterized systems (concurrent systems with an arbitrary\nnumber of processes). We provide a reformulation of regular model checking with\nlength-preserving transducers in terms of existential second-order theory over\nautomatic structures. We argue that this is a natural formulation that enables\nus tap into powerful synthesis techniques that have been extensively studied in\nthe software verification community. More precisely, in this formulation the\nfirst-order part represents the verification conditions for the desired\ncorrectness property (for which we have complete solvers), whereas the\nexistentially quantified second-order variables represent the relations to be\nsynthesized. We show that many interesting correctness properties can be\nformulated in this way, examples being safety, liveness, bisimilarity, and\ngames. More importantly, we show that this new formulation allows new\ninteresting benchmarks (and old regular model checking benchmarks that were\npreviously believed to be difficult), especially in the domain of parameterized\nsystem verification, to be solved.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 05:29:15 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lin", "Anthony W.", ""], ["R\u00fcmmer", "Philipp", ""]]}, {"id": "2005.01071", "submitter": "Ritam Raha", "authors": "Guillermo A. P\\'erez (1), Ritam Raha (1 and 2) ((1) University of\n  Antwerp, Antwerp, Belgium, (2) LaBRI, University of Bordeaux, Bordeaux,\n  France)", "title": "Revisiting Synthesis for One-Counter Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the (parameter) synthesis problem for one-counter automata with\nparameters. One-counter automata are obtained by extending classical\nfinite-state automata with a counter whose value can range over non-negative\nintegers and be tested for zero. The updates and tests applicable to the\ncounter can further be made parametric by introducing a set of integer-valued\nvariables called parameters. The synthesis problem for such automata asks\nwhether there exists a valuation of the parameters such that all infinite runs\nof the automaton satisfy some omega-regular property. Lechner showed that (the\ncomplement of) the problem can be encoded in a restricted one-alternation\nfragment of Presburger arithmetic with divisibility. In this work (i) we argue\nthat said fragment, called AERPADPLUS, is unfortunately undecidable.\nNevertheless, by a careful re-encoding of the problem into a decidable\nrestriction of AERPADPLUS, (ii) we prove that the synthesis problem is\ndecidable in general and in N2EXP for several fixed omega-regular properties.\nFinally, (iii) we give a polynomial-space algorithm for the special case of the\nproblem where parameters can only be used in tests, and not updates, of the\ncounter.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 12:30:11 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 10:15:25 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 11:16:52 GMT"}, {"version": "v4", "created": "Thu, 29 Apr 2021 17:26:28 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["P\u00e9rez", "Guillermo A.", "", "1 and 2"], ["Raha", "Ritam", "", "1 and 2"]]}, {"id": "2005.01184", "submitter": "Antti Kuusisto", "authors": "Reijo Jaakkola and Antti Kuusisto", "title": "Algebraic classifications for fragments of first-order logic and beyond", "comments": "Significantly updates the first version. The principal set of\n  operations changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complexity and decidability of logics is a major research area involving a\nhuge range of different logical systems. This calls for a unified and\nsystematic approach for the field. We introduce a research program based on an\nalgebraic approach to complexity classifications of fragments of first-order\nlogic (FO) and beyond. Our base system GRA, or general relation algebra, is\nequiexpressive with FO. It resembles cylindric algebra but employs a finite\nsignature with only seven different operators. We provide a comprehensive\nclassification of the decidability and complexity of the systems obtained by\nlimiting the allowed sets of operators. We also give algebraic\ncharacterizations of the best known decidable fragments of FO. Furthermore, to\nmove beyond FO, we introduce the notion of a generalized operator and briefly\nstudy related systems.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 20:47:00 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 10:25:38 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Jaakkola", "Reijo", ""], ["Kuusisto", "Antti", ""]]}, {"id": "2005.01624", "submitter": "Holger Thies", "authors": "Michal Kone\\v{c}n\\'y, Florian Steinberg, Holger Thies", "title": "Continuous and monotone machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a variant of the fuel-based approach to modeling diverging\ncomputation in type theories and use it to abstractly capture the essence of\noracle Turing machines. The resulting objects we call continuous machines. We\nprove that it is possible to translate back and forth between such machines and\nnames in the standard function encoding used in computable analysis. Put\ndifferently, among the operators on Baire space, exactly the partial continuous\nones are implementable by continuous machines and the data that such a machine\nprovides is a description of the operator as a sequentially realizable\nfunctional.\n  Continuous machines are naturally formulated in type theories and we have\nformalized our findings in Coq. Continuous machines, their equivalence to the\nstandard encoding and correctness of basic operations are now part of Incone, a\nCoq library for computable analysis. While the correctness proofs use a\nclassical meta-theory with countable choice, the translations and algorithms\nthat are proven correct are all fully executable. Along the way we formally\nprove some known results such as existence of a self-modulating moduli of\ncontinuity for partial continuous operators on Baire space.\n  To illustrate their versatility we use continuous machines to specify some\nalgorithms that operate on objects that cannot be fully described by finite\nmeans, such as real numbers and functions. We present particularly simple\nalgorithms for finding the multiplicative inverse of a real number and for\ncomposition of partial continuous operators on Baire space. Some of the\nsimplicity is achieved by utilizing the fact that continuous machines are\ncompatible with multivalued semantics. We also connect continuous machines to\nthe construction of precompletions and completions of represented spaces,\ntopics that have recently caught the attention of the computable analysis\ncommunity.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:29:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kone\u010dn\u00fd", "Michal", ""], ["Steinberg", "Florian", ""], ["Thies", "Holger", ""]]}, {"id": "2005.01670", "submitter": "Valeria Vignudelli", "authors": "Filippo Bonchi, Ana Sokolova, Valeria Vignudelli", "title": "Presenting convex sets of probability distributions by convex\n  semilattices and unique bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that every finitely generated convex set of finitely supported\nprobability distributions has a unique base, and use this result to show that\nthe monad of convex sets of probability distributions is presented by the\nalgebraic theory of convex semilattices.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:25:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bonchi", "Filippo", ""], ["Sokolova", "Ana", ""], ["Vignudelli", "Valeria", ""]]}, {"id": "2005.01715", "submitter": "Marc Aiguier", "authors": "Marc Aiguier and Isabelle Bloch and Ramon Pino-P\\'erez", "title": "Abstract Mathematical morphology based on structuring element:\n  Application to morpho-logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general definition of mathematical morphology has been defined within the\nalgebraic framework of complete lattice theory. In this framework, dealing with\ndeterministic and increasing operators, a dilation (respectively an erosion) is\nan operation which is distributive over supremum (respectively infimum). From\nthis simple definition of dilation and erosion, we cannot say much about the\nproperties of them. However, when they form an adjunction, many important\nproperties can be derived such as monotonicity, idempotence, and extensivity or\nanti-extensivity of their composition, preservation of infimum and supremum,\netc. Mathematical morphology has been first developed in the setting of sets,\nand then extended to other algebraic structures such as graphs, hypergraphs or\nsimplicial complexes. For all these algebraic structures, erosion and dilation\nare usually based on structuring elements. The goal is then to match these\nstructuring elements on given objects either to dilate or erode them. One of\nthe advantages of defining erosion and dilation based on structuring elements\nis that these operations are adjoint. Based on this observation, this paper\nproposes to define, at the abstract level of category theory, erosion and\ndilation based on structuring elements. We then define the notion of\nmorpho-category on which erosion and dilation are defined. We then show that\ntopos and more precisely topos of presheaves are good candidates to generate\nmorpho-categories. However, topos do not allow taking into account the notion\nof inclusion between substructures but rather are defined by monics up to\ndomain isomorphism. Therefore we define the notion of morpholizable category\nwhich allows generating morpho-categories where substructures are defined along\ninclusion morphisms. {A direct application of this framework is to generalize\nmodal morpho-logic to other algebraic structures than simple sets.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:11:52 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Aiguier", "Marc", ""], ["Bloch", "Isabelle", ""], ["Pino-P\u00e9rez", "Ramon", ""]]}, {"id": "2005.01778", "submitter": "Mathias Soeken", "authors": "Mathias Soeken", "title": "Determining the Multiplicative Complexity of Boolean Functions using SAT", "comments": "8 pages, 2 tables, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a constructive SAT-based algorithm to determine the multiplicative\ncomplexity of a Boolean function, i.e., the smallest number of AND gates in any\nlogic network that consists of 2-input AND gates, 2-input XOR gates, and\ninverters. In order to speed-up solving time, we make use of several symmetry\nbreaking constraints; these exploit properties of XAGs that may be useful\nbeyond the proposed SAT-based algorithm. We further propose a heuristic\npost-optimization algorithm to reduce the number of XOR gates once the optimum\nnumber of AND gates has been obtained, which also makes use of SAT solvers. Our\nalgorithm is capable to find all optimum XAGs for representatives of all\n5-input affine-equivalent classes, and for a set of frequently occurring\n6-input functions.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 18:29:48 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Soeken", "Mathias", ""]]}, {"id": "2005.01808", "submitter": "Claudia Faggian", "authors": "Beniamino Accattoli, Claudia Faggian, and Giulio Guerrieri", "title": "Factorize Factorization", "comments": "29th EACSL Annual Conference on Computer Science Logic (CSL 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization -- a simple form of standardization -- is concerned with\nreduction strategies, i.e. how a result is computed. We present a new technique\nfor proving factorization theorems for compound rewriting systems in a modular\nway, which is inspired by the Hindley-Rosen technique for confluence.\nSpecifically, our technique is well adapted to deal with extensions of the\ncall-by-name and call-by-value lambda-calculi. The technique is first developed\nabstractly. We isolate a sufficient condition (called linear swap) for lifting\nfactorization from components to the compound system, and which is compatible\nwith beta-reduction. We then closely analyze some common factorization schemas\nfor the lambda-calculus. Concretely, we apply our technique to diverse\nextensions of the lambda-calculus, among which de' Liguoro and Piperno's\nnon-deterministic lambda-calculus and -- for call-by-value -- Carraro and\nGuerrieri's shuffling calculus. For both calculi the literature contains\nfactorization theorems. In both cases, we give a new proof which is neat,\nsimpler than the original, and strikingly shorter.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:31:43 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 16:56:38 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Faggian", "Claudia", ""], ["Guerrieri", "Giulio", ""]]}, {"id": "2005.02073", "submitter": "Valentin Mayer-Eichberger", "authors": "Ignasi Ab\\'io, Valentin Mayer-Eichberger, Peter Stuckey", "title": "Encoding Linear Constraints into SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear integer constraints are one of the most important constraints in\ncombinatorial problems since they are commonly found in many practical\napplications. Typically, encodings to Boolean satisfiability (SAT) format of\nconjunctive normal form perform poorly in problems with these constraints in\ncomparison with SAT modulo theories (SMT), lazy clause generation (LCG) or\nmixed integer programming (MIP) solvers.\n  In this paper we explore and categorize SAT encodings for linear integer\nconstraints. We define new SAT encodings based on multi-valued decision\ndiagrams, and sorting networks. We compare different SAT encodings of linear\nconstraints and demonstrate where one may be preferable to another. We also\ncompare SAT encodings against other solving methods and show they can be better\nthan linear integer (MIP) solvers and sometimes better than LCG or SMT solvers\non appropriate problems. Combining the new encoding with lazy decomposition,\nwhich during runtime only encodes constraints that are important to the solving\nprocess that occurs, gives the best option for many highly combinatorial\nproblems involving linear constraints.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 11:37:43 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Ab\u00edo", "Ignasi", ""], ["Mayer-Eichberger", "Valentin", ""], ["Stuckey", "Peter", ""]]}, {"id": "2005.02094", "submitter": "Bentkamp, A.", "authors": "Alexander Bentkamp, Jasmin Blanchette, Simon Cruanes, Uwe Waldmann", "title": "Superposition for Lambda-Free Higher-Order Logic", "comments": "arXiv admin note: text overlap with arXiv:2102.00453", "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (April 12,\n  2021) lmcs:7349", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce refutationally complete superposition calculi for intentional\nand extensional clausal $\\lambda$-free higher-order logic, two formalisms that\nallow partial application and applied variables. The calculi are parameterized\nby a term order that need not be fully monotonic, making it possible to employ\nthe $\\lambda$-free higher-order lexicographic path and Knuth-Bendix orders. We\nimplemented the calculi in the Zipperposition prover and evaluated them on\nIsabelle/HOL and TPTP benchmarks. They appear promising as a stepping stone\ntowards complete, highly efficient automatic theorem provers for full\nhigher-order logic.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 12:10:21 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 17:01:55 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 11:36:57 GMT"}, {"version": "v4", "created": "Fri, 9 Apr 2021 10:29:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bentkamp", "Alexander", ""], ["Blanchette", "Jasmin", ""], ["Cruanes", "Simon", ""], ["Waldmann", "Uwe", ""]]}, {"id": "2005.02126", "submitter": "Masaki Waga", "authors": "Masaki Waga", "title": "Falsification of Cyber-Physical Systems with Robustness-Guided Black-Box\n  Checking", "comments": "Accepted to HSCC 2020", "journal-ref": null, "doi": "10.1145/3365365.3382193", "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For exhaustive formal verification, industrial-scale cyber-physical systems\n(CPSs) are often too large and complex, and lightweight alternatives (e.g.,\nmonitoring and testing) have attracted the attention of both industrial\npractitioners and academic researchers. Falsification is one popular testing\nmethod of CPSs utilizing stochastic optimization. In state-of-the-art\nfalsification methods, the result of the previous falsification trials is\ndiscarded, and we always try to falsify without any prior knowledge. To\nconcisely memorize such prior information on the CPS model and exploit it, we\nemploy Black-box checking (BBC), which is a combination of automata learning\nand model checking. Moreover, we enhance BBC using the robust semantics of STL\nformulas, which is the essential gadget in falsification. Our experiment\nresults suggest that our robustness-guided BBC outperforms a state-of-the-art\nfalsification tool.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 09:51:49 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Waga", "Masaki", ""]]}, {"id": "2005.02384", "submitter": "Pawe{\\l} Parys", "authors": "Pawe{\\l} Parys", "title": "Compositionality of the MSO+U Logic", "comments": "arXiv admin note: text overlap with arXiv:1810.04763", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the MSO+U logic is compositional in the following sense:\nwhether an MSO+U formula holds in a tree T depends only on MSO+U-definable\nproperties of the root of T and of subtrees of T starting directly below the\nroot. Another kind of compositionality follows: every MSO+U formula whose all\nfree variables range only over finite sets of nodes (in particular, whose all\nfree variables are first-order) can be rewritten into an MSO formula having\naccess to properties of subtrees definable by MSO+U sentences (without free\nvariables).\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 11:14:23 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Parys", "Pawe\u0142", ""]]}, {"id": "2005.02576", "submitter": "John Licato", "authors": "Elijah Malaby, Bradley Dragun, John Licato", "title": "Towards Concise, Machine-discovered Proofs of G\\\"odel's Two\n  Incompleteness Theorems", "comments": null, "journal-ref": "In Proceedings of The 2020 International Florida Artificial\n  Intelligence Research Society Conference (FLAIRS-33)", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing interest in applying recent advances in AI to\nautomated reasoning, as it may provide useful heuristics in reasoning over\nformalisms in first-order, second-order, or even meta-logics. To facilitate\nthis research, we present MATR, a new framework for automated theorem proving\nexplicitly designed to easily adapt to unusual logics or integrate new\nreasoning processes. MATR is formalism-agnostic, highly modular, and\nprogrammer-friendly. We explain the high-level design of MATR as well as some\ndetails of its implementation. To demonstrate MATR's utility, we then describe\na formalized metalogic suitable for proofs of G\\\"odel's Incompleteness\nTheorems, and report on our progress using our metalogic in MATR to\nsemi-autonomously generate proofs of both the First and Second Incompleteness\nTheorems.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 03:29:34 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Malaby", "Elijah", ""], ["Dragun", "Bradley", ""], ["Licato", "John", ""]]}, {"id": "2005.02810", "submitter": "Juan Afanador", "authors": "Juan Afanador", "title": "A Formal Critique of the Value of the Colombian P\\'aramo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents conceptual and methodological frameworks to prioritise\ninterventions on the Colombian P\\'aramo. The mode of analysis that our work\ntakes up is that of questioning value and related categories as definite\nempirically perceived phenomena. We contend that the valuation of ecosystem\nservices -- even in its post-normal forms -- and the ecosystem services\nframework not only fail to examine value-based categories, but reproduce the\nproblematic aspects of value-based social relations, which ultimately bear on\nthe ecological issues affecting the P\\'aramo. Upon this premise we set out to\nformalise a (computational) dialogical scenario where arguments stating\ndistinct, and often contradictory, actions delineate possible forms of\nappropriating the P\\'aramo, while motivating the examination of their defining\nsociality.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 11:49:16 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Afanador", "Juan", ""]]}, {"id": "2005.03003", "submitter": "Martin Barrere", "authors": "Mart\\'in Barr\\`ere and Chris Hankin", "title": "Fault Tree Analysis: Identifying Maximum Probability Minimal Cut Sets\n  with MaxSAT", "comments": "Accepted for publication at the 50th IEEE/IFIP International\n  Conference on Dependable Systems and Networks (DSN 2020), Fast Abstracts\n  Track, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.DM cs.LO cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel MaxSAT-based technique to compute Maximum\nProbability Minimal Cut Sets (MPMCSs) in fault trees. We model the MPMCS\nproblem as a Weighted Partial MaxSAT problem and solve it using a parallel\nSAT-solving architecture. The results obtained with our open source tool\nindicate that the approach is effective and efficient.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 19:47:15 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Barr\u00e8re", "Mart\u00edn", ""], ["Hankin", "Chris", ""]]}, {"id": "2005.03074", "submitter": "Lachlan McPheat", "authors": "Lachlan McPheat, Mehrnoosh Sadrzadeh, Hadi Wazni, Gijs Wijnholds", "title": "Categorical Vector Space Semantics for Lambek Calculus with a Relevant\n  Modality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a categorical compositional distributional semantics for Lambek\nCalculus with a Relevant Modality !L*, which has a limited edition of the\ncontraction and permutation rules. The categorical part of the semantics is a\nmonoidal biclosed category with a coalgebra modality, very similar to the\nstructure of a Differential Category. We instantiate this category to finite\ndimensional vector spaces and linear maps via \"quantisation\" functors and work\nwith three concrete interpretations of the coalgebra modality. We apply the\nmodel to construct categorical and concrete semantic interpretations for the\nmotivating example of !L*: the derivation of a phrase with a parasitic gap. The\neffectiveness of the concrete interpretations are evaluated via a\ndisambiguation task, on an extension of a sentence disambiguation dataset to\nparasitic gap phrases, using BERT, Word2Vec, and FastText vectors and\nRelational tensors.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 18:58:21 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 15:39:28 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 16:26:02 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["McPheat", "Lachlan", ""], ["Sadrzadeh", "Mehrnoosh", ""], ["Wazni", "Hadi", ""], ["Wijnholds", "Gijs", ""]]}, {"id": "2005.03089", "submitter": "Michael Kohlhase", "authors": "Michael Kohlhase, Florian Rabe", "title": "Experiences from Exporting Major Proof Assistant Libraries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The interoperability of proof assistants and the integration of their\nlibraries is a highly valued but elusive goal in the field of theorem proving.\nAs a preparatory step, in previous work, we translated the libraries of\nmultiple proof assistants, specifically the ones of Coq, HOL Light, IMPS,\nIsabelle, Mizar, and PVS into a universal format: OMDoc/MMT.\n  Each translation presented tremendous theoretical, technical, and social\nchallenges, some universal and some system-specific, some solvable and some\nstill open. In this paper, we survey these challenges and compare and evaluate\nthe solutions we chose.\n  We believe similar library translations will be an essential part of any\nfuture system interoperability solution and our experiences will prove valuable\nto others undertaking such efforts.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 05:06:42 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kohlhase", "Michael", ""], ["Rabe", "Florian", ""]]}, {"id": "2005.03157", "submitter": "Ana Ozaki", "authors": "Cosimo Persia and Ana Ozaki", "title": "On the Learnability of Possibilistic Theories", "comments": "IJCAI 2020 paper number 5540 (with a copyright notice to IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate learnability of possibilistic theories from entailments in\nlight of Angluin's exact learning model. We consider cases in which only\nmembership, only equivalence, and both kinds of queries can be posed by the\nlearner. We then show that, for a large class of problems, polynomial time\nlearnability results for classical logic can be transferred to the respective\npossibilistic extension. In particular, it follows from our results that the\npossibilistic extension of propositional Horn theories is exactly learnable in\npolynomial time. As polynomial time learnability in the exact model is\ntransferable to the classical probably approximately correct model extended\nwith membership queries, our work also establishes such results in this model.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 22:08:32 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Persia", "Cosimo", ""], ["Ozaki", "Ana", ""]]}, {"id": "2005.03362", "submitter": "Rayna Dimitrova", "authors": "Rayna Dimitrova and Bernd Finkbeiner and Hazem Torfah", "title": "Probabilistic Hyperproperties of Markov Decision Processes", "comments": "Extended version of paper published at ATVA'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties are properties that describe the correctness of a system as a\nrelation between multiple executions. Hyperproperties generalize trace\nproperties and include information-flow security requirements, like\nnoninterference, as well as requirements like symmetry, partial observation,\nrobustness, and fault tolerance. We initiate the study of the specification and\nverification of hyperproperties of Markov decision processes (MDPs). We\nintroduce the temporal logic PHL (Probabilistic Hyper Logic), which extends\nclassic probabilistic logics with quantification over schedulers and traces.\nPHL can express a wide range of hyperproperties for probabilistic systems,\nincluding both classical applications, such as probabilistic noninterference,\nand novel applications in areas such as robotics and planning. While the model\nchecking problem for PHL is in general undecidable, we provide methods both for\nproving and for refuting formulas from a fragment of the logic. The fragment\nincludes many probabilistic hyperproperties of interest.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:57:28 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 15:12:28 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 15:22:07 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Dimitrova", "Rayna", ""], ["Finkbeiner", "Bernd", ""], ["Torfah", "Hazem", ""]]}, {"id": "2005.03555", "submitter": "Philipp J. Meyer", "authors": "Michael Blondin, Javier Esparza, Martin Helfrich, Anton\\'in\n  Ku\\v{c}era, Philipp J. Meyer", "title": "Checking Qualitative Liveness Properties of Replicated Systems with\n  Stochastic Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a sound and complete method for the verification of qualitative\nliveness properties of replicated systems under stochastic scheduling. These\nare systems consisting of a finite-state program, executed by an unknown number\nof indistinguishable agents, where the next agent to make a move is determined\nby the result of a random experiment. We show that if a property of such a\nsystem holds, then there is always a witness in the shape of a Presburger stage\ngraph: a finite graph whose nodes are Presburger-definable sets of\nconfigurations. Due to the high complexity of the verification problem\n(non-elementary), we introduce an incomplete procedure for the construction of\nPresburger stage graphs, and implement it on top of an SMT solver. The\nprocedure makes extensive use of the theory of well-quasi-orders, and of the\nstructural theory of Petri nets and vector addition systems. We apply our\nresults to a set of benchmarks, in particular to a large collection of\npopulation protocols, a model of distributed computation extensively studied by\nthe distributed computing community.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:41:06 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 14:47:24 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Blondin", "Michael", ""], ["Esparza", "Javier", ""], ["Helfrich", "Martin", ""], ["Ku\u010dera", "Anton\u00edn", ""], ["Meyer", "Philipp J.", ""]]}, {"id": "2005.03586", "submitter": "Miroslav Ol\\v{s}\\'ak", "authors": "Miroslav Ol\\v{s}\\'ak", "title": "GeoLogic -- Graphical interactive theorem prover for Euclidean geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain of mathematical logic in computers is dominated by automated theorem\nprovers (ATP) and interactive theorem provers (ITP). Both of these are hard to\naccess by AI from the human-imitation approach: ATPs often use human-unfriendly\nlogical foundations while ITPs are meant for formalizing existing proofs rather\nthan problem solving. We aim to create a simple human-friendly logical system\nfor mathematical problem solving. We picked the case study of Euclidean\ngeometry as it can be easily visualized, has simple logic, and yet potentially\noffers many high-school problems of various difficulty levels. To make the\nenvironment user friendly, we abandoned strict logic required by ITPs, allowing\nto infer topological facts from pictures. We present our system for Euclidean\ngeometry, together with a graphical application GeoLogic, similar to GeoGebra,\nwhich allows users to interactively study and prove properties about the\ngeometrical setup.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:16:01 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ol\u0161\u00e1k", "Miroslav", ""]]}, {"id": "2005.03597", "submitter": "Kai Jia", "authors": "Kai Jia, Martin Rinard", "title": "Efficient Exact Verification of Binarized Neural Networks", "comments": "To be published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerned with the reliability of neural networks, researchers have developed\nverification techniques to prove their robustness. Most verifiers work with\nreal-valued networks. Unfortunately, the exact (complete and sound) verifiers\nface scalability challenges and provide no correctness guarantees due to\nfloating point errors. We argue that Binarized Neural Networks (BNNs) provide\ncomparable robustness and allow exact and significantly more efficient\nverification. We present a new system, EEV, for efficient and exact\nverification of BNNs. EEV consists of two parts: (i) a novel SAT solver that\nspeeds up BNN verification by natively handling the reified cardinality\nconstraints arising in BNN encodings; and (ii) strategies to train\nsolver-friendly robust BNNs by inducing balanced layer-wise sparsity and low\ncardinality bounds, and adaptively cancelling the gradients. We demonstrate the\neffectiveness of EEV by presenting the first exact verification results for\nL-inf-bounded adversarial robustness of nontrivial convolutional BNNs on the\nMNIST and CIFAR10 datasets. Compared to exact verification of real-valued\nnetworks of the same architectures on the same tasks, EEV verifies BNNs\nhundreds to thousands of times faster, while delivering comparable verifiable\naccuracy in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:34:30 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 04:00:16 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Jia", "Kai", ""], ["Rinard", "Martin", ""]]}, {"id": "2005.03620", "submitter": "Marcos Cramer", "authors": "Marcos Cramer, Meghna Bhadra", "title": "Technical Report of \"Deductive Joint Support for Rational Unrestricted\n  Rebuttal\"", "comments": "New version with some minor corrections based on the reviews of the\n  associated paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In ASPIC-style structured argumentation an argument can rebut another\nargument by attacking its conclusion. Two ways of formalizing rebuttal have\nbeen proposed: In restricted rebuttal, the attacked conclusion must have been\narrived at with a defeasible rule, whereas in unrestricted rebuttal, it may\nhave been arrived at with a strict rule, as long as at least one of the\nantecedents of this strict rule was already defeasible. One systematic way of\nchoosing between various possible definitions of a framework for structured\nargumentation is to study what rationality postulates are satisfied by which\ndefinition, for example whether the closure postulate holds, i.e. whether the\naccepted conclusions are closed under strict rules. While having some benefits,\nthe proposal to use unrestricted rebuttal faces the problem that the closure\npostulate only holds for the grounded semantics but fails when other\nargumentation semantics are applied, whereas with restricted rebuttal the\nclosure postulate always holds. In this paper we propose that ASPIC-style\nargumentation can benefit from keeping track not only of the attack relation\nbetween arguments, but also the relation of deductive joint support that holds\nbetween a set of arguments and an argument that was constructed from that set\nusing a strict rule. By taking this deductive joint support relation into\naccount while determining the extensions, the closure postulate holds with\nunrestricted rebuttal under all admissibility-based semantics. We define the\nsemantics of deductive joint support through the flattening method.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:19:18 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 17:18:26 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Cramer", "Marcos", ""], ["Bhadra", "Meghna", ""]]}, {"id": "2005.03630", "submitter": "Pedro S\\'anchez Terraf", "authors": "Mart\\'in Santiago Moroni, Pedro S\\'anchez Terraf", "title": "The Zhou Ordinal of Labelled Markov Processes over Separable Spaces", "comments": "19 pages. v2: role of the logic on Introduction, relation with\n  previous constructions and 1 figure. Many minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist two notions of equivalence of behavior between states of a\nLabelled Markov Process (LMP): state bisimilarity and event bisimilarity. The\nfirst one can be considered as an appropriate generalization to continuous\nspaces of Larsen and Skou's probabilistic bisimilarity, while the second one is\ncharacterized by a natural logic. C. Zhou expressed state bisimilarity as the\ngreatest fixed point of an operator $\\mathcal{O}$, and thus introduced an\nordinal measure of the discrepancy between it and event bisimilarity. We call\nthis ordinal the \"Zhou ordinal\" of $\\mathbb{S}$, $\\mathfrak{Z}(\\mathbb{S})$.\nWhen $\\mathfrak{Z}(\\mathbb{S})=0$, $\\mathbb{S}$ satisfies the Hennessy-Milner\nproperty. The second author proved the existence of an LMP $\\mathbb{S}$ with\n$\\mathfrak{Z}(\\mathbb{S}) \\geq 1$ and Zhou showed that there are LMPs having an\ninfinite Zhou ordinal. In this paper we show that there are LMPs $\\mathbb{S}$\nover separable metrizable spaces having arbitrary large countable\n$\\mathfrak{Z}(\\mathbb{S})$ and that it is consistent with the axioms of\n$\\mathit{ZFC}$ that there is such a process with an uncountable Zhou ordinal.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:36:32 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 19:55:01 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Moroni", "Mart\u00edn Santiago", ""], ["Terraf", "Pedro S\u00e1nchez", ""]]}, {"id": "2005.04022", "submitter": "Jan-Hendrik Lorenz", "authors": "Jan-Hendrik Lorenz and Florian W\\\"orz", "title": "On the Effect of Learned Clauses on Stochastic Local Search", "comments": "Accepted at 'The 23rd International Conference on Theory and\n  Applications of Satisfiability Testing'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two competing paradigms in successful SAT solvers: Conflict-driven\nclause learning (CDCL) and stochastic local search (SLS). CDCL uses systematic\nexploration of the search space and has the ability to learn new clauses. SLS\nexamines the neighborhood of the current complete assignment. Unlike CDCL, it\nlacks the ability to learn from its mistakes. This work revolves around the\nquestion whether it is beneficial for SLS to add new clauses to the original\nformula. We experimentally demonstrate that clauses with a large number of\ncorrect literals w. r. t. a fixed solution are beneficial to the runtime of\nSLS. We call such clauses high-quality clauses.\n  Empirical evaluations show that short clauses learned by CDCL possess the\nhigh-quality attribute. We study several domains of randomly generated\ninstances and deduce the most beneficial strategies to add high-quality clauses\nas a preprocessing step. The strategies are implemented in an SLS solver, and\nit is shown that this considerably improves the state-of-the-art on randomly\ngenerated instances. The results are statistically significant.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 13:33:16 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lorenz", "Jan-Hendrik", ""], ["W\u00f6rz", "Florian", ""]]}, {"id": "2005.04123", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "The ghosts of forgotten things: A study on size after forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forgetting is removing variables from a logical formula while preserving the\nconstraints on the other variables. In spite of being a form of reduction, it\ndoes not always decrease the size of the formula and may sometimes increase it.\nThis article discusses the implications of such an increase and analyzes the\ncomputational properties of the phenomenon. Given a propositional Horn formula,\na set of variables and a maximum allowed size, deciding whether forgetting the\nvariables from the formula can be expressed in that size is $D^p$-hard in\n$\\Sigma^p_2$. The same problem for unrestricted propositional formulae is\n$D^p_2$-hard in $\\Sigma^p_3$. The hardness results employ superredundancy: a\nsuperirredundant clause is in all formulae of minimal size equivalent to a\ngiven one. This concept may be useful outside forgetting.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:56:01 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 07:39:00 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "2005.04145", "submitter": "Micha{\\l} Wrona", "authors": "Micha{\\l} Wrona", "title": "On The Relational Width of First-Order Expansions of Finitely Bounded\n  Homogeneous Binary Cores with Bounded Strict Width", "comments": "A long version of an extended abstract that appeared in LICS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The relational width of a finite structure, if bounded, is always (1,1) or\n(2,3). In this paper we study the relational width of first-order expansions of\nfinitely bounded homogeneous binary cores where binary cores are structures\nwith equality and some anti-reflexive binary relations such that for any two\ndifferent elements a, b in the domain there is exactly one binary relation R\nwith (a, b) in R.\n  Our main result is that first-order expansions of liberal finitely bounded\nhomogeneous binary cores with bounded strict width have relational width (2,\nMaxBound) where MaxBound is the size of the largest forbidden substructure, but\nis not less than 3, and liberal stands for structures that do not forbid\ncertain finite structures of small size. This result is built on a new approach\nand concerns a broad class of structures including reducts of homogeneous\ndigraphs for which the CSP complexity classification has not yet been obtained.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:42:26 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wrona", "Micha\u0142", ""]]}, {"id": "2005.04162", "submitter": "Jens Kosiol", "authors": "Jens Kosiol and Daniel Str\\\"uber and Gabriele Taentzer and Steffen\n  Zschaler", "title": "Graph Consistency as a Graduated Property: Consistency-Sustaining and\n  -Improving Graph Transformations", "comments": "23 pages, accepted for publication at the International Conference on\n  Graph Transformation 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Where graphs are used for modelling and specifying systems, consistency is an\nimportant concern. To be a valid model of a system, the graph structure must\nsatisfy a number of constraints. To date, consistency has primarily been viewed\nas a binary property: a graph either is or is not consistent with respect to a\nset of graph constraints. This has enabled the definition of notions such as\nconstraint-preserving and constraint-guaranteeing graph transformations. Many\npractical applications - for example model repair or evolutionary search -\nimplicitly assume a more graduated notion of consistency, but without an\nexplicit formalisation only limited analysis of these applications is possible.\nIn this paper, we introduce an explicit notion of consistency as a graduated\nproperty, depending on the number of constraint violations in a graph. We\npresent two new characterisations of transformations (and transformation rules)\nenabling reasoning about the gradual introduction of consistency: while\nconsistency-sustaining transformations do not decrease the consistency level,\nconsistency-improving transformations strictly reduce the number of constraint\nviolations. We show how these new definitions refine the existing concepts of\nconstraint-preserving and constraint-guaranteeing transformations. To support a\nstatic analysis based on our characterisations, we present criteria for\ndeciding which form of consistency ensuring transformations is induced by the\napplication of a transformation rule. We illustrate our contributions in the\ncontext of an example from search-based model engineering.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:01:24 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Kosiol", "Jens", ""], ["Str\u00fcber", "Daniel", ""], ["Taentzer", "Gabriele", ""], ["Zschaler", "Steffen", ""]]}, {"id": "2005.04453", "submitter": "L\\'eo Stefanesco", "authors": "Paul-Andr\\'e Melli\\`es and L\\'eo Stefanesco", "title": "Concurrent Separation Logic Meets Template Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An old dream of concurrency theory and programming language semantics has\nbeen to uncover the fundamental synchronization mechanisms which regulate\nsituations as different as game semantics for higher-order programs, and Hoare\nlogic for concurrent programs with shared memory and locks. In this paper, we\nestablish a deep and unexpected connection between two recent lines of work on\nconcurrent separation logic (CSL) and on template game semantics for\ndifferential linear logic (DiLL). Thanks to this connection, we reformulate in\nthe purely conceptual style of template games for DiLL the asynchronous and\ninteractive interpretation of CSL designed by Melli\\`es and Stefanesco. We\nbelieve that the analysis reveals something important about the secret anatomy\nof CSL, and more specifically about the subtle interplay, of a categorical\nnature, between sequential composition, parallel product, errors and locks.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 14:33:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Melli\u00e8s", "Paul-Andr\u00e9", ""], ["Stefanesco", "L\u00e9o", ""]]}, {"id": "2005.04598", "submitter": "Klaus-Dieter Schewe", "authors": "Klaus-Dieter Schewe", "title": "Insignificant Choice Polynomial Time", "comments": "69 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the late 1980s Gurevich conjectured that there is no logic capturing\nPTIME, where logic has to be understood in a very general way comprising\ncomputation models over structures. In this article we first refute Gurevich's\nconjecture. For this we extend the seminal research of Blass, Gurevich and\nShelah on {\\em choiceless polynomial time} (CPT), which exploits deterministic\nAbstract State Machines (ASMs) supporting unbounded parallelism to capture the\nchoiceless fragment of PTIME. CPT is strictly included in PTIME. We observe\nthat choice is unavoidable, but that a restricted version suffices, which\nguarantees that the final result is independent from the choice. Such a version\nof polynomially bounded ASMs, which we call {\\em insignificant choice\npolynomial time} (ICPT) will indeed capture PTIME. Even more, insignificant\nchoice can be captured by ASMs with choice restricted to atoms such that a {\\em\nlocal insignificance condition} is satisfied. As this condition can be\nexpressed in the logic of non-deterministic ASMs, we obtain a logic capturing\nPTIME. Furthermore, using inflationary fixed-points we can capture problems in\nPTIME by fixed-point formulae in a fragment of the logic of non-deterministic\nASMs plus inflationary fixed-points. We use this result for our second\ncontribution showing that PTIME differs from NP. For the proof we build again\non the research on CPT first establishing a limitation on permutation classes\nof the sets that can be activated by an ICPT computation. We then prove an\ninseparability theorem, which characterises classes of structures that cannot\nbe separated by the logic. In particular, this implies that SAT cannot be\ndecided by an ICPT computation.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 07:36:19 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 00:44:13 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 08:36:44 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 14:14:38 GMT"}, {"version": "v5", "created": "Tue, 8 Sep 2020 08:44:59 GMT"}, {"version": "v6", "created": "Tue, 22 Sep 2020 12:23:25 GMT"}, {"version": "v7", "created": "Mon, 1 Feb 2021 07:57:43 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Schewe", "Klaus-Dieter", ""]]}, {"id": "2005.04722", "submitter": "Catalin Hritcu", "authors": "Maximilian Algehed, Jean-Philippe Bernardy, Catalin Hritcu", "title": "Dynamic IFC Theorems for Free!", "comments": "CSF 2021 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that noninterference and transparency, the key soundness theorems for\ndynamic IFC libraries, can be obtained \"for free\", as direct consequences of\nthe more general parametricity theorem of type abstraction. This allows us to\ngive very short soundness proofs for dynamic IFC libraries such as faceted\nvalues and LIO. Our proofs stay short even when fully mechanized for Agda\nimplementations of the libraries in terms of type abstraction.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 17:29:15 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 13:56:57 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Algehed", "Maximilian", ""], ["Bernardy", "Jean-Philippe", ""], ["Hritcu", "Catalin", ""]]}, {"id": "2005.04791", "submitter": "Gordon Belot", "authors": "Gordon Belot", "title": "Absolutely No Free Lunches!", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2020.09.013", "report-no": null, "categories": "cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with learners who aim to learn patterns in infinite\nbinary sequences: shown longer and longer initial segments of a binary\nsequence, they either attempt to predict whether the next bit will be a 0 or\nwill be a 1 or they issue forecast probabilities for these events. Several\nvariants of this problem are considered. In each case, a no-free-lunch result\nof the following form is established: the problem of learning is a formidably\ndifficult one, in that no matter what method is pursued, failure is\nincomparably more common that success; and difficult choices must be faced in\nchoosing a method of learning, since no approach dominates all others in its\nrange of success. In the simplest case, the comparison of the set of situations\nin which a method fails and the set of situations in which it succeeds is a\nmatter of cardinality (countable vs. uncountable); in other cases, it is a\ntopological matter (meagre vs. co-meagre) or a hybrid computational-topological\nmatter (effectively meagre vs. effectively co-meagre).\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 21:32:28 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 21:39:34 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Belot", "Gordon", ""]]}, {"id": "2005.04818", "submitter": "Thomas Hujsa", "authors": "Thomas Hujsa, Bernard Berthomieu, Silvano Dal Zilio, Didier Le Botlan", "title": "On the Petri Nets with a Single Shared Place and Beyond", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Petri nets proved useful to describe various real-world systems, but many of\ntheir properties are very hard to check. To alleviate this difficulty,\nsubclasses are often considered. The class of weighted marked graphs with\nrelaxed place constraint (WMG=< for short), in which each place has at most one\ninput and one output, and the larger class of choice-free (CF) nets, in which\neach place has at most one output, have been extensively studied to this end,\nwith various applications.\n  In this work, we develop new properties related to the fundamental and\nintractable problems of reachability, liveness and reversibility in weighted\nPetri nets. We focus mainly on the homogeneous Petri nets with a single shared\nplace (H1S nets for short), which extend the expressiveness of CF nets by\nallowing one shared place (i.e. a place with at least two outputs and possibly\nseveral inputs) under the homogeneity constraint (i.e. all the output weights\nof the shared place are equal). Indeed, this simple generalization already\nyields new challenging problems and is expressive enough for modeling existing\nuse-cases, justifying a dedicated study.\n  One of our central results is the first characterization of liveness in a\nsubclass of H1S nets more expressive than WMG=< that is expressed by the\ninfeasibility of an integer linear program (ILP) of polynomial size. This trims\ndown the complexity to co-NP, contrasting with the known EXPSPACE-hardness of\nliveness in the more general case of weighted Petri nets. In the same subclass,\nwe obtain a new reachability property related to the live markings, which is a\nvariant of the well-known Keller's theorem. Another central result is a new\nreversibility characterization for the live H1S class, simplifying its\nchecking. Finally, we apply our results to use-cases, highlight their\nscalability and discuss their extensibility to more expressive classes.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 00:29:11 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Hujsa", "Thomas", ""], ["Berthomieu", "Bernard", ""], ["Zilio", "Silvano Dal", ""], ["Botlan", "Didier Le", ""]]}, {"id": "2005.04850", "submitter": "Kuldeep S. Meel", "authors": "Arijit Shaw and Kuldeep S. Meel", "title": "Designing New Phase Selection Heuristics", "comments": "Full version of the paper published in the Proceedings of the 23rd\n  International Conference on Theory and Applications of Satisfiability Testing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CDCL-based SAT solvers have transformed the field of automated reasoning\nowing to their demonstrated efficiency at handling problems arising from\ndiverse domains. The success of CDCL solvers is owed to the design of clever\nheuristics that enable the tight coupling of different components. One of the\ncore components is phase selection, wherein the solver, during branching,\ndecides the polarity of the branch to be explored for a given variable. Most of\nthe state-of-the-art CDCL SAT solvers employ phase-saving as a phase selection\nheuristic, which was proposed to address the potential inefficiencies arising\nfrom far-backtracking. In light of the emergence of chronological backtracking\nin CDCL solvers, we re-examine the efficiency of phase saving. Our empirical\nevaluation leads to a surprising conclusion: The usage of phase saving and\nrandom selection of polarity during chronological backtracking leads to\nindistinguishable runtime performance in terms of instances solved and PAR-2\nscore.\n  We introduce Decaying Polarity Score (DPS) to capture the trend of the\npolarities attained by the variable, and upon observing lack of performance\nimprovement due to DPS, we turn to a more sophisticated heuristic seeking to\ncapture the activity of literals and the trend of polarities: Literal State\nIndependent Decaying Sum (LSIDS). We find the 2019 winning SAT solver,\nMaple_LCM_Dist_ChronoBTv3, augmented with LSIDS solves 6 more instances while\nachieving a reduction of over 125 seconds in PAR-2 score, a significant\nimprovement in the context of the SAT competition.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 03:46:26 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Shaw", "Arijit", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2005.05098", "submitter": "Valentin Mayer-Eichberger", "authors": "Valentin Mayer-Eichberger, Abdallah Saffidine", "title": "Positional Games and QBF: The Corrective Encoding", "comments": "Accepted for publication in the 23rd International Conference on\n  Theory and Applications of Satisfiability Testing (SAT2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positional games are a mathematical class of two-player games comprising\nTic-tac-toe and its generalizations. We propose a novel encoding of these games\ninto Quantified Boolean Formulas (QBF) such that a game instance admits a\nwinning strategy for first player if and only if the corresponding formula is\ntrue. Our approach improves over previous QBF encodings of games in multiple\nways. First, it is generic and lets us encode other positional games, such as\nHex. Second, structural properties of positional games together with a careful\ntreatment of illegal moves let us generate more compact instances that can be\nsolved faster by state-of-the-art QBF solvers. We establish the latter fact\nthrough extensive experiments. Finally, the compactness of our new encoding\nmakes it feasible to translate realistic game problems. We identify a few such\nproblems of historical significance and put them forward to the QBF community\nas milestones of increasing difficulty.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:32:03 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Mayer-Eichberger", "Valentin", ""], ["Saffidine", "Abdallah", ""]]}, {"id": "2005.05108", "submitter": "Joachim Kock", "authors": "Joachim Kock", "title": "Elements of Petri nets and processes", "comments": "44 pages. The math is intended to be in reasonably final form, but\n  the paper may well contain some misconceptions regarding the place of this\n  material in the theory of Petri nets. All feedback and help will be greatly\n  appreciated. v2: fixed a mistake in Section 8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.AT math.CO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formalism for Petri nets based on polynomial-style finite-set\nconfigurations and etale maps. The formalism supports both a geometric\nsemantics in the style of Goltz and Reisig (processes are etale maps from\ngraphs) and an algebraic semantics in terms of free coloured props: the Segal\nspace of P-processes is shown to be the free coloured prop-in-groupoids on P.\nThere is also an unfolding semantics \\`a la Winskel, which bypasses the\nclassical symmetry problems. Since everything is encoded with explicit sets,\nPetri nets and their processes have elements. In particular, individual-token\nsemantics is native, and the benefits of pre-nets in this respect can be\nobtained without the need of numberings. (Collective-token semantics emerges\nfrom rather drastic quotient constructions \\`a la Best--Devillers, involving\ntaking $\\pi_0$ of the groupoids of states.)\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:52:28 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 15:20:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kock", "Joachim", ""]]}, {"id": "2005.05423", "submitter": "Arash Karimi", "authors": "Arash Karimi, Heng Zhang, Jia-Huai You", "title": "Restricted Chase Termination for Existential Rules: a Hierarchical\n  Approach and Experimentation", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The chase procedure for existential rules is an indispensable tool for\nseveral database applications, where its termination guarantees the\ndecidability of these tasks. Most previous studies have focused on the skolem\nchase variant and its termination analysis. It is known that the restricted\nchase variant is a more powerful tool in termination analysis provided a\ndatabase is given. But all-instance termination presents a challenge since the\ncritical database and similar techniques do not work. In this paper, we develop\na novel technique to characterize the activeness of all possible cycles of a\ncertain length for the restricted chase, which leads to the formulation of a\nparameterized class of the finite restricted chase, called\n$k$-$\\mathsf{safe}(\\Phi)$. This approach applies to any class of finite skolem\nchase identified with a condition of acyclicity. More generally, we show that\nthe approach can be applied to the hierarchy of bounded rule sets previously\nonly defined for the skolem chase. Experiments on a collection of ontologies\nfrom the web show the applicability of the proposed methods on real-world\nontologies. Under consideration in Theory and Practice of Logic Programming\n(TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:45:20 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Karimi", "Arash", ""], ["Zhang", "Heng", ""], ["You", "Jia-Huai", ""]]}, {"id": "2005.05433", "submitter": "EPTCS", "authors": "Vladimir Zamdzhiev", "title": "Computational Adequacy for Substructural Lambda Calculi", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 322-334", "doi": "10.4204/EPTCS.333.22", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substructural type systems, such as affine (and linear) type systems, are\ntype systems which impose restrictions on copying (and discarding) of\nvariables, and they have found many applications in computer science, including\nquantum programming. We describe one linear and one affine type systems and we\nformulate abstract categorical models for both of them which are sound and\ncomputationally adequate. We also show, under basic assumptions, that\ninterpreting lambda abstractions via a monoidal closed structure (a popular\nmethod for linear type systems) necessarily leads to degenerate and inadequate\nmodels for call-by-value affine type systems with recursion. In our categorical\ntreatment, a solution to this problem is clearly presented. Our categorical\nmodels are more general than linear/non-linear models used to study linear\nlogic and we present a homogeneous categorical account of both linear and\naffine type systems in a call-by-value setting. We also give examples with many\nconcrete models, including classical and quantum ones.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:58:26 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 00:09:34 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Zamdzhiev", "Vladimir", ""]]}, {"id": "2005.05512", "submitter": "David  McAllester", "authors": "David McAllester", "title": "MathZero, The Classification Problem, and Set-Theoretic Type Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AlphaZero learns to play go, chess and shogi at a superhuman level through\nself play given only the rules of the game. This raises the question of whether\na similar thing could be done for mathematics -- a MathZero. MathZero would\nrequire a formal foundation and an objective. We propose the foundation of\nset-theoretic dependent type theory and an objective defined in terms of the\nclassification problem -- the problem of classifying concept instances up to\nisomorphism. The natural numbers arise as the solution to the classification\nproblem for finite sets. Here we generalize classical Bourbaki set-theoretic\nisomorphism to set-theoretic dependent type theory. To our knowledge we give\nthe first isomorphism inference rules for set-theoretic dependent type theory\nwith propositional set-theoretic equality. The presentation is intended to be\naccessible to mathematicians with no prior exposure to type theory.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:48:48 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 16:30:57 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["McAllester", "David", ""]]}, {"id": "2005.05578", "submitter": "Diego Latella", "authors": "Vincenzo Ciancia, Diego Latella, Mieke Massink, Erik de Vink", "title": "Towards Spatial Bisimilarity for Closure Models: Logical and Coalgebraic\n  Characterisations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topological interpretation of modal logics provides descriptive languages\nand proof systems for reasoning about points of topological spaces. Recent work\nhas been devoted to model checking of spatial logics on discrete spatial\nstructures, such as finite graphs and digital images, with applications in\nvarious case studies including medical image analysis. These recent\ndevelopments required a generalisation step, from topological spaces to closure\nspaces. In this work we initiate the study of bisimilarity and minimisation\nalgorithms that are consistent with the closure spaces semantics. For this\npurpose we employ coalgebraic models. We present a coalgebraic definition of\nbisimilarity for quasi-discrete models, which is adequate with respect to a\nspatial logic with reachability operators, complemented by a free and\nopen-source minimisation tool for finite models. We also discuss the\nnon-quasi-discrete case, by providing a generalisation of the well-known\nset-theoretical notion of topo-bisimilarity, and a categorical definition, in\nthe same spirit as the coalgebraic rendition of neighbourhood frames, but\nemploying the covariant power set functor, instead of the contravariant one. We\nprove its adequacy with respect to infinitary modal logic.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 07:12:02 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Ciancia", "Vincenzo", ""], ["Latella", "Diego", ""], ["Massink", "Mieke", ""], ["de Vink", "Erik", ""]]}, {"id": "2005.05666", "submitter": "Uli Fahrenberg", "authors": "Uli Fahrenberg, Axel Legay", "title": "Featured Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature-based SPL analysis and family-based model checking have seen rapid\ndevelopment. Many model checking problems can be reduced to two-player games on\nfinite graphs. A prominent example is mu-calculus model checking, which is\ngenerally done by translating to parity games, but also many quantitative\nmodel-checking problems can be reduced to (quantitative) games.\n  In their FASE'20 paper, ter Beek et al.\\ introduce parity games with\nvariability in order to develop family-based mu-calculus model checking of\nfeatured transition systems. We generalize their model to general featured\ngames and show how these may be analysed in a family-based manner.\n  We introduce featured reachability games, featured minimum reachability\ngames, featured discounted games, featured energy games, and featured parity\ngames. We show how to compute winners and values of such games in a\nfamily-based manner. We also show that all these featured games admit optimal\nfeatured strategies, which project to optimal strategies for any product.\nFurther, we develop family-based algorithms, using late splitting, to compute\nwinners, values, and optimal strategies for all the featured games we have\nintroduced.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 10:20:51 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 20:20:35 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Fahrenberg", "Uli", ""], ["Legay", "Axel", ""]]}, {"id": "2005.05764", "submitter": "Cyrille Chenavier", "authors": "Cyrille Chenavier and Maxime Lucas", "title": "Strategies for linear rewriting systems: link with parallel rewriting\n  and involutive divisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study rewriting systems whose underlying set of terms is equipped with a\nvector space structure over a given field. We introduce parallel rewriting\nrelations, which are rewriting relations compatible with the vector space\nstructure, as well as rewriting strategies, which consist in choosing one\nrewriting step for each reducible basis element of the vector space. Using\nthese notions, we introduce the S-confluence property and show that it implies\nconfluence. We deduce a proof of the diamond's lemma, based on strategies. We\nillustrate our general framework with rewriting systems over rational Weyl\nalgebras, that are vector spaces over a field of rational functions. In\nparticular, we show that involutive divisions induce rewriting strategies over\nrational Weyl algebras, and using the $S$-confluence property, we show that\ninvolutive sets induce confluent rewriting systems over rational Weyl algebras.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 13:40:39 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 12:25:06 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Chenavier", "Cyrille", ""], ["Lucas", "Maxime", ""]]}, {"id": "2005.05773", "submitter": "Yunhao Yang", "authors": "Yunhao Yang, Andrew Tan", "title": "Approximating Boolean Functions with Disjunctive Normal Form", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theorem states that: Every Boolean function can be $\\epsilon\n-approximated$ by a Disjunctive Normal Form (DNF) of size\n$O_{\\epsilon}(2^{n}/\\log{n})$. This paper will demonstrate this theorem in\ndetail by showing how this theorem is generated and proving its correctness. We\nwill also dive into some specific Boolean functions and explore how these\nBoolean functions can be approximated by a DNF whose size is within the\nuniversal bound $O_{\\epsilon}(2^{n}/\\log{n})$. The Boolean functions we\ninterested in are: Parity Function: the parity function can be\n$\\epsilon-approximated$ by a DNF of width $(1 - 2\\epsilon)n$ and size $2^{(1 -\n2\\epsilon)n}$. Furthermore, we will explore the lower bounds on the DNF's size\nand width. Majority Function: for every constant $1/2 < \\epsilon < 1$, there is\na DNF of size $2^{O(\\sqrt{n})}$ that can $\\epsilon-approximated$ the Majority\nFunction on n bits. Monotone Functions: every monotone function f can be\n$\\epsilon-approximated$ by a DNF g of size $2^{n - \\Omega\\epsilon(n)}$\nsatisfying $g(x) \\le f(x)$ for all x.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 13:51:22 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Yang", "Yunhao", ""], ["Tan", "Andrew", ""]]}, {"id": "2005.05901", "submitter": "Fernando Orejas", "authors": "Leen Lambers and Fernando Orejas", "title": "Initial Conflicts for Transformation Rules with Nested Application\n  Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We extend the theory of initial conflicts in the framework of M-adhesive\ncategories to transformation rules with ACs. We first show that for rules with\nACs, conflicts are in general neither inherited from a bigger context any more,\nnor is it possible to find a finite and complete subset of finite conflicts as\nillustrated for the category of graphs. We define initial conflicts to be\nspecial so-called symbolic transformation pairs, and show that they are\nminimally complete (and in the case of graphs also finite) in this symbolic\nway. We show that initial conflicts represent a proper subset of critical pairs\nagain. We moreover demonstrate that (analogous to the case of rules without\nACs) for each conflict a unique initial conflict exists representing it. We\nconclude with presenting a sufficient condition illustrating important special\ncases for rules with ACs, where we do not only have initial conflicts being\ncomplete in a symbolic way, but also find complete (and in the case of graphs\nalso finite) subsets of conflicts in the classical sense.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 15:06:38 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Lambers", "Leen", ""], ["Orejas", "Fernando", ""]]}, {"id": "2005.05902", "submitter": "Uma Zalakain", "authors": "Uma Zalakain and Ornela Dardha", "title": "{\\pi} with leftovers: a mechanisation in Agda", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Linear type systems need to keep track of how programs use their resources.\nThe standard approach is to use context splits specifying how resources are\n(disjointly) split across subterms. In this approach, context splits\nredundantly echo information which is already present within subterms. An\nalternative approach is to use leftover typing, where in addition to the usual\n(input) usage context, typing judgments have also an output usage context: the\nleftovers. In this approach, the leftovers of one typing derivation are fed as\ninput to the next, threading through linear resources while avoiding context\nsplits. We use leftover typing to define a type system for a resource-aware\n{\\pi}-calculus, a process algebra used to model concurrent systems. Our type\nsystem is parametrised over a set of usage algebras that are general enough to\nencompass shared types (free to reuse and discard), graded types (use exactly n\nnumber of times) and linear types (use exactly once). Linear types are\nimportant in the {\\pi}-calculus: they ensure privacy and safety of\ncommunication and avoid race conditions, while graded and shared types allow\nfor more flexible programming. We provide a framing theorem for our type\nsystem, generalise the weakening and strengthening theorems to include linear\ntypes, and prove subject reduction. Our formalisation is fully mechanised in\nabout 1850 lines of Agda.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 19:49:00 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 13:13:18 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 08:34:17 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Zalakain", "Uma", ""], ["Dardha", "Ornela", ""]]}, {"id": "2005.05912", "submitter": "Julian Nagele", "authors": "Julian Nagele and Maria A Schett", "title": "Blockchain Superoptimizer", "comments": "15 pages", "journal-ref": "Preproceedings of the 29th International Symposium on Logic-based\n  Program Synthesis and Transformation (LOPSTR 2019), pp. 166-180, 2019", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the blockchain-based, distributed computing platform Ethereum, programs\ncalled smart contracts are compiled to bytecode and executed on the Ethereum\nVirtual Machine (EVM). Executing EVM bytecode is subject to monetary fees---a\nclear optimization target. Our aim is to superoptimize EVM bytecode by encoding\nthe operational semantics of EVM instructions as SMT formulas and leveraging a\nconstraint solver to automatically find cheaper bytecode. We implement this\napproach in our EVM Bytecode SuperOptimizer ebso and perform two large scale\nevaluations on real-world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:43:41 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Nagele", "Julian", ""], ["Schett", "Maria A", ""]]}, {"id": "2005.05934", "submitter": "Norine Coenen", "authors": "Norine Coenen, Bernd Finkbeiner, Christopher Hahn, Jana Hofmann", "title": "The Hierarchy of Hyperlogics", "comments": "Originally published at LICS 2019", "journal-ref": "34th Annual ACM/IEEE Symposium on Logic in Computer Science\n  (LICS), Vancouver, BC, Canada, 2019, pp. 1-13", "doi": "10.1109/LICS.2019.8785713", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties, which generalize trace properties by relating multiple\ntraces, are widely studied in information-flow security. Recently, a number of\nlogics for hyperproperties have been proposed, and there is a need to\nunderstand their decidability and relative expressiveness. The new logics have\nbeen obtained from standard logics with two principal extensions: temporal\nlogics, like LTL and CTL$^*$, have been generalized to hyperproperties by\nadding variables for traces or paths. First-order and second-order logics, like\nmonadic first-order logic of order and MSO, have been extended with the\nequal-level predicate. We study the impact of the two extensions across the\nspectrum of linear-time and branching-time logics, in particular for logics\nwith quantification over propositions. The resulting hierarchy of hyperlogics\ndiffers significantly from the classical hierarchy, suggesting that the\nequal-level predicate adds more expressiveness than trace and path variables.\nWithin the hierarchy of hyperlogics, we identify new boundaries on the\ndecidability of the satisfiability problem. Specifically, we show that while\nHyperQPTL and HyperCTL$^*$ are both undecidable in general, formulas within\ntheir $\\exists^*\\forall^*$ fragments are decidable.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:25:44 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Coenen", "Norine", ""], ["Finkbeiner", "Bernd", ""], ["Hahn", "Christopher", ""], ["Hofmann", "Jana", ""]]}, {"id": "2005.05970", "submitter": "Ankush Das", "authors": "Ankush Das and Frank Pfenning", "title": "Session Types with Arithmetic Refinements", "comments": "14 pages. arXiv admin note: text overlap with arXiv:2001.04439", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session types statically prescribe bidirectional communication protocols for\nmessage-passing processes. However, simple session types cannot specify\nproperties beyond the type of exchanged messages. In this paper we extend the\ntype system by using index refinements from linear arithmetic capturing\nintrinsic attributes of data structures and algorithms. We show that, despite\nthe decidability of Presburger arithmetic, type equality and therefore also\nsubtyping and type checking are now undecidable, which stands in contrast to\nanalogous dependent refinement type systems from functional languages. We also\npresent a practical, but incomplete algorithm for type equality, which we have\nused in our implementation of Rast, a concurrent session-typed language with\narithmetic index refinements as well as ergometric and temporal types.\nMoreover, if necessary, the programmer can propose additional type\nbisimulations that are smoothly integrated into the type equality algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 13:41:22 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Das", "Ankush", ""], ["Pfenning", "Frank", ""]]}, {"id": "2005.06115", "submitter": "Borzoo Bonakdarpour", "authors": "Erika Abraham, Ezio Bartocci, Borzoo Bonakdarpour, Oyendrila Dobe", "title": "Probabilistic Hyperproperties with Nondeterminism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of formalizing and checking probabilistic\nhyperproperties for models that allow nondeterminism in actions. We extend the\ntemporal logic \\HyperPCTL, which has been previously introduced for\ndiscrete-time Markov chains, to enable the specification of hyperproperties\nalso for Markov decision processes. We generalize HyperPCTL by allowing\nexplicit and simultaneous quantification over schedulers and probabilistic\ncomputation trees and show that it can express important quantitative\nrequirements in security and privacy. We show that HyperPCTL model checking\nover MDPs is in general undecidable for quantification over probabilistic\nschedulers with memory, but restricting the domain to memoryless\nnon-probabilistic schedulers turns the model checking problem decidable.\nSubsequently, we propose an SMT-based encoding for model checking this language\nand evaluate its performance.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 02:00:31 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 03:47:39 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Abraham", "Erika", ""], ["Bartocci", "Ezio", ""], ["Bonakdarpour", "Borzoo", ""], ["Dobe", "Oyendrila", ""]]}, {"id": "2005.06274", "submitter": "Neng-Fa Zhou", "authors": "Neng-Fa Zhou", "title": "Yet Another Comparison of SAT Encodings for the At-Most-K Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The at-most-k constraint is ubiquitous in combinatorial problems, and\nnumerous SAT encodings are available for the constraint. Prior experiments have\nshown the competitiveness of the sequential-counter encoding for k $>$ 1, and\nhave excluded the parallel-counter encoding, which is more compact that the\nbinary-adder encoding, from consideration due to its incapability of enforcing\narc consistency through unit propagation. This paper presents an experiment\nthat shows astounding performance of the binary-adder encoding for the\nat-most-k constraint.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 03:23:00 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Zhou", "Neng-Fa", ""]]}, {"id": "2005.06285", "submitter": "Stefan G\\\"oller", "authors": "Stefan G\\\"oller and Pawe{\\l} Parys", "title": "Bisimulation Finiteness of Pushdown Systems Is Elementary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that in case a pushdown system is bisimulation equivalent to a finite\nsystem, there is already a bisimulation equivalent finite system whose size is\nelementarily bounded in the description size of the pushdown system. As a\nconsequence we obtain that it is elementarily decidable if a given pushdown\nsystem is bisimulation equivalent to some finite system. This improves a\npreviously best-known ACKERMANN upper bound for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 12:26:50 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["G\u00f6ller", "Stefan", ""], ["Parys", "Pawe\u0142", ""]]}, {"id": "2005.06299", "submitter": "Michael Benedikt", "authors": "Vince Barany, Michael Benedikt, and Balder ten Cate", "title": "Some Model Theory of Guarded Negation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Guarded Negation Fragment (GNFO) is a fragment of first-order logic that\ncontains all positive existential formulas, can express the first-order\ntranslations of basic modal logic and of many description logics, along with\nmany sentences that arise in databases. It has been shown that the syntax of\nGNFO is restrictive enough so that computational problems such as validity and\nsatisfiability are still decidable. This suggests that, in spite of its\nexpressive power, GNFO formulas are amenable to novel optimizations. In this\npaper we study the model theory of GNFO formulas. Our results include effective\npreservation theorems for GNFO, effective Craig Interpolation and Beth\nDefinability results, and the ability to express the certain answers of queries\nwith respect to a large class of GNFO sentences within very restricted logics.\n  This version of the paper contains streamlined and corrected versions of\nresults concerning entailment of a conjunctive query from a set of ground facts\nand a theory consisting of GNFO sentences of a special form (\"dependencies\").\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:05:31 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 02:36:33 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Barany", "Vince", ""], ["Benedikt", "Michael", ""], ["Cate", "Balder ten", ""]]}, {"id": "2005.06411", "submitter": "Andrzej Murawski", "authors": "Andrzej S. Murawski, Steven J. Ramsay, Nikos Tzevelekos", "title": "Bisimilarity in fresh-register automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Register automata are a basic model of computation over infinite alphabets.\nFresh-register automata extend register automata with the capability to\ngenerate fresh symbols in order to model computational scenarios involving name\ncreation. This paper investigates the complexity of the bisimilarity problem\nfor classes of register and fresh-register automata. We examine all main\ndisciplines that have appeared in the literature: general register assignments;\nassignments where duplicate register values are disallowed; and assignments\nwithout duplicates in which registers cannot be empty. In the general case, we\nshow that the problem is EXPTIME-complete.\n  However, the absence of duplicate values in registers enables us to identify\ninherent symmetries inside the associated bisimulation relations, which can be\nused to establish a polynomial bound on the depth of Attacker-winning\nstrategies. Furthermore, they enable a highly succinct representation of the\ncorresponding bisimulations. By exploiting results from group theory and\ncomputational group theory, we can then show solvability in PSPACE and NP\nrespectively for the latter two register disciplines. In each case, we find\nthat freshness does not affect the complexity class of the problem.\n  The results allow us to close a complexity gap for language equivalence of\ndeterministic register automata. We show that deterministic language\ninequivalence for the no-duplicates fragment is NP-complete, which disproves an\nold conjecture of Sakamoto.\n  Finally, we discover that, unlike in the finite-alphabet case, the addition\nof pushdown store makes bisimilarity undecidable, even in the case of visibly\npushdown storage.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:38:19 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Murawski", "Andrzej S.", ""], ["Ramsay", "Steven J.", ""], ["Tzevelekos", "Nikos", ""]]}, {"id": "2005.06503", "submitter": "Pierre Pradic", "authors": "Michael Benedikt and Pierre Pradic", "title": "Generating collection transformations from proofs", "comments": null, "journal-ref": null, "doi": "10.1145/3434295", "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested relations, built up from atomic types via product and set types, form\na rich data model. Over the last decades the nested relational calculus, NRC,\nhas emerged as a standard language for defining transformations on nested\ncollections. NRC is a strongly-typed functional language which allows building\nup transformations using tupling and projections, a singleton-former, and a map\noperation that lifts transformations on tuples to transformations on sets.\n  In this work we describe an alternative declarative method of describing\ntransformations in logic. A formula with distinguished inputs and outputs gives\nan implicit definition if one can prove that for each input there is only one\noutput that satisfies it. Our main result shows that one can synthesize\ntransformations from proofs that a formula provides an implicit definition,\nwhere the proof is in an intuitionistic calculus that captures a natural style\nof reasoning about nested collections. Our polynomial time synthesis procedure\nis based on an analog of Craig's interpolation lemma, starting with a provable\ncontainment between terms representing nested collections and generating an NRC\nexpression that interpolates between them.\n  We further show that NRC expressions that implement an implicit definition\ncan be found when there is a classical proof of functionality, not just when\nthere is an intuitionistic one. That is, whenever a formula implicitly defines\na transformation, there is an NRC expression that implements it.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 18:18:03 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 16:23:50 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 15:37:55 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 20:57:46 GMT"}, {"version": "v5", "created": "Wed, 8 Jul 2020 09:42:58 GMT"}, {"version": "v6", "created": "Wed, 11 Nov 2020 13:51:27 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Benedikt", "Michael", ""], ["Pradic", "Pierre", ""]]}, {"id": "2005.06636", "submitter": "Guy Avni", "authors": "Guy Avni, Isma\\\"el Jecker, {\\DJ}or{\\dj}e \\v{Z}ikeli\\'c", "title": "Infinite-Duration All-Pay Bidding Games", "comments": "The full version of a paper published in SODA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a two-player zero-sum graph game the players move a token throughout a\ngraph to produce an infinite path, which determines the winner or payoff of the\ngame. Traditionally, the players alternate turns in moving the token. In {\\em\nbidding games}, however, the players have budgets, and in each turn, we hold an\n\"auction\" (bidding) to determine which player moves the token: both players\nsimultaneously submit bids and the higher bidder moves the token. The bidding\nmechanisms differ in their payment schemes. Bidding games were largely studied\nwith variants of {\\em first-price} bidding in which only the higher bidder pays\nhis bid. We focus on {\\em all-pay} bidding, where both players pay their bids.\nFinite-duration all-pay bidding games were studied and shown to be technically\nmore challenging than their first-price counterparts. We study for the first\ntime, infinite-duration all-pay bidding games. Our most interesting results are\nfor {\\em mean-payoff} objectives: we portray a complete picture for games\nplayed on strongly-connected graphs. We study both pure (deterministic) and\nmixed (probabilistic) strategies and completely characterize the optimal sure\nand almost-sure (with probability $1$) payoffs that the players can\nrespectively guarantee. We show that mean-payoff games under all-pay bidding\nexhibit the intriguing mathematical properties of their first-price\ncounterparts; namely, an equivalence with {\\em random-turn games} in which in\neach turn, the player who moves is selected according to a (biased) coin toss.\nThe equivalences for all-pay bidding are more intricate and unexpected than for\nfirst-price bidding.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 08:51:46 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 11:24:53 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Avni", "Guy", ""], ["Jecker", "Isma\u00ebl", ""], ["\u017dikeli\u0107", "\u0110or\u0111e", ""]]}, {"id": "2005.06659", "submitter": "EPTCS", "authors": "Fabian Zaiser (University of Oxford), C.-H. Luke Ong (University of\n  Oxford)", "title": "The Extended Theory of Trees and Algebraic (Co)datatypes", "comments": "In Proceedings VPT/HCVS 2020, arXiv:2008.02483", "journal-ref": "EPTCS 320, 2020, pp. 167-196", "doi": "10.4204/EPTCS.320.14", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first-order theory of finite and infinite trees has been studied since\nthe eighties, especially by the logic programming community. Following\nDjelloul, Dao and Fr\\\"uhwirth, we consider an extension of this theory with an\nadditional predicate for finiteness of trees, which is useful for expressing\nproperties about (not just datatypes but also) codatatypes. Based on their\nwork, we present a simplification procedure that determines whether any given\n(not necessarily closed) formula is satisfiable, returning a simplified formula\nwhich enables one to read off all possible models. Our extension makes the\nalgorithm usable for algebraic (co)datatypes, which was impossible in their\noriginal work due to restrictive assumptions. We also provide a prototype\nimplementation of our simplification procedure and evaluate it on instances\nfrom the SMT-LIB.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 23:12:42 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 01:24:42 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Zaiser", "Fabian", "", "University of Oxford"], ["Ong", "C. -H. Luke", "", "University of\n  Oxford"]]}, {"id": "2005.06750", "submitter": "Luca Pulina", "authors": "Massimo Narizzano, Luca Pulina, Armando Tacchella, Simone Vuotto", "title": "Automated Requirements-Based Testing of Black-Box Reactive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to conformance testing of black-box reactive\nsystems. We consider system specifications written as linear temporal logic\nformulas to generate tests as sequences of input/output pairs: inputs are\nextracted from the Buchi automata corresponding to the specifications, and\noutputs are obtained by feeding the inputs to the systems. Conformance is\nchecked by comparing input/output sequences with automata traces to detect\nviolations of the specifications. We consider several criteria for extracting\ntests and for stopping generation, and we compare them experimentally using\nboth indicators of coverage and error-detection. The results show that our\nmethodology can generate test suites with good system coverage and\nerror-detection capability.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 06:55:29 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Narizzano", "Massimo", ""], ["Pulina", "Luca", ""], ["Tacchella", "Armando", ""], ["Vuotto", "Simone", ""]]}, {"id": "2005.06814", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert, Ioana Cristescu (HMS)", "title": "How Reversibility Can Solve Traditional Questions: The Example of\n  Hereditary History-Preserving Bisimulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.FL cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible computation opens up the possibility of overcoming some of the\nhardware's current physical limitations. It also offers theoretical insights,\nas it enriches multiple paradigms and models of computation, and sometimes\nretrospectively enlightens them. Concurrent reversible computation, for\ninstance, offered interesting extensions to the Calculus of Communicating\nSystems, but was still lacking a natural and pertinent bisimulation to study\nprocesses equivalences. Our paper formulates an equivalence exploiting the two\naspects of reversibility: backward moves and memory mechanisms. This\nbisimulation captures classical equivalences relations for denotational models\nof concurrency (History-and hereditary history-preserving bisimulation,\n(H)HPB), that were up to now only partially characterized by process algebras.\nThis result gives an insight on the expressiveness of reversibility, as both\nbackward moves and a memory mechanism-providing 'backward determinism'-are\nneeded to capture HHPB.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 08:55:07 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "HMS"], ["Cristescu", "Ioana", "", "HMS"]]}, {"id": "2005.06818", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert, Ioana Cristescu", "title": "Structural Equivalences for Reversible Calculi of Communicating Systems\n  (Oral communication)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formalization of process algebras usually starts with a minimal core of\noperators and rules for its transition system, and then relax the system to\nimprove its usability and ease the proofs. In the calculus of communicating\nsystems (CCS), the structural congruence plays this role by making e.g.\nparallel composition commutative and associative: without it, the system would\nbe cumbersome to use and reason about, and it can be proven that this change is\ninnocuous in a precise technical sense. For the two reversible calculi\nextending CCS, the situation is less clear: CCS with Communication Keys (CCSK)\nwas first defined without any structural congruence, and then was endowed with\na fragment of CCS's congruence. Reversible CCS (RCCS) made the choice of\n\"backing in\" the structural equivalence, that became part of the \"minimal core\"\nof the system. In this short oral communication, we would like to re-consider\nthe status and role of the structural congruence in general, to question its\nrole in RCCS in particular, and to ask the more general question of the\nstructural equivalences legitimacy.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 08:57:58 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Aubert", "Cl\u00e9ment", ""], ["Cristescu", "Ioana", ""]]}, {"id": "2005.06922", "submitter": "Priyanka Golia", "authors": "Priyanka Golia, Subhajit Roy, and Kuldeep S. Meel", "title": "Manthan: A Data Driven Approach for Boolean Function Synthesis", "comments": "24 pages including references, and 8 figures. To be published in 32nd\n  International Conference on Computer-Aided Verification (CAV-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean functional synthesis is a fundamental problem in computer science\nwith wide-ranging applications and has witnessed a surge of interest resulting\nin progressively improved techniques over the past decade. Despite intense\nalgorithmic development, a large number of problems remain beyond the reach of\nthe state of the art techniques. Motivated by the progress in machine learning,\nwe propose Manthan, a novel data-driven approach to Boolean functional\nsynthesis. Manthan views functional synthesis as a classification problem,\nrelying on advances in constrained sampling for data generation, and advances\nin automated reasoning for a novel proof-guided refinement and provable\nverification. On an extensive and rigorous evaluation over 609 benchmarks, we\ndemonstrate that Manthan significantly improves upon the current state of the\nart, solving 356 benchmarks in comparison to 280, which is the most solved by a\nstate of the art technique; thereby, we demonstrate an increase of 76\nbenchmarks over the current state of the art. Furthermore, Manthan solves 60\nbenchmarks that none of the current state of the art techniques could solve.\nThe significant performance improvements, along with our detailed analysis,\nhighlights several interesting avenues of future work at the intersection of\nmachine learning, constrained sampling, and automated reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 12:44:21 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Golia", "Priyanka", ""], ["Roy", "Subhajit", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2005.07059", "submitter": "Jason Z.S. Hu", "authors": "Jason Z.S. Hu and Jacques Carette", "title": "Formalizing of Category Theory in Agda", "comments": null, "journal-ref": null, "doi": "10.1145/3437992.3439922", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The generality and pervasiness of category theory in modern mathematics makes\nit a frequent and useful target of formalization. It is however quite\nchallenging to formalize, for a variety of reasons. Agda currently (i.e. in\n2020) does not have a standard, working formalization of category theory. We\ndocument our work on solving this dilemma. The formalization revealed a number\nof potential design choices, and we present, motivate and explain the ones we\npicked. In particular, we find that alternative definitions or alternative\nproofs from those found in standard textbooks can be advantageous, as well as\n\"fit\" Agda's type theory more smoothly. Some definitions regarded as equivalent\nin standard textbooks turn out to make different \"universe level\" assumptions,\nwith some being more polymorphic than others. We also pay close attention to\nengineering issues so that the library integrates well with Agda's own standard\nlibrary, as well as being compatible with as many of supported type theories in\nAgda as possible.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:16:19 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 14:27:19 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Hu", "Jason Z. S.", ""], ["Carette", "Jacques", ""]]}, {"id": "2005.07130", "submitter": "Manuel Gieseking", "authors": "Bernd Finkbeiner, Manuel Gieseking, Jesko Hecking-Harbusch,\n  Ernst-R\\\"udiger Olderog", "title": "AdamMC: A Model Checker for Petri Nets with Transits against Flow-LTL\n  (Full Version)", "comments": "22 pages, 5 figures, full version of the corresponding CAV2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The correctness of networks is often described in terms of the individual\ndata flow of components instead of their global behavior. In software-defined\nnetworks, it is far more convenient to specify the correct behavior of packets\nthan the global behavior of the entire network. Petri nets with transits extend\nPetri nets and Flow-LTL extends LTL such that the data flows of tokens can be\ntracked. We present the tool AdamMC as the first model checker for Petri nets\nwith transits against Flow-LTL. We describe how AdamMC can automatically encode\nconcurrent updates of software-defined networks as Petri nets with transits and\nhow common network specifications can be expressed in Flow-LTL. Underlying\nAdamMC is a reduction to a circuit model checking problem. We introduce a new\nreduction method that results in tremendous performance improvements compared\nto a previous prototype. Thereby, AdamMC can handle software-defined networks\nwith up to 82 switches.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:54:14 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 19:14:38 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Gieseking", "Manuel", ""], ["Hecking-Harbusch", "Jesko", ""], ["Olderog", "Ernst-R\u00fcdiger", ""]]}, {"id": "2005.07227", "submitter": "Petr Novotn\\'y", "authors": "Franti\\v{s}ek Blahoudek and Tom\\'a\\v{s} Br\\'azdil and Petr Novotn\\'y\n  and Melkior Ornik and Pranay Thangeda and Ufuk Topcu", "title": "Qualitative Controller Synthesis for Consumption Markov Decision\n  Processes", "comments": "Full version of a paper accepted at CAV'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumption Markov Decision Processes (CMDPs) are probabilistic\ndecision-making models of resource-constrained systems. In a CMDP, the\ncontroller possesses a certain amount of a critical resource, such as electric\npower. Each action of the controller can consume some amount of the resource.\nResource replenishment is only possible in special reload states, in which the\nresource level can be reloaded up to the full capacity of the system. The task\nof the controller is to prevent resource exhaustion, i.e. ensure that the\navailable amount of the resource stays non-negative, while ensuring an\nadditional linear-time property. We study the complexity of strategy synthesis\nin consumption MDPs with almost-sure B\\\"uchi objectives. We show that the\nproblem can be solved in polynomial time. We implement our algorithm and show\nthat it can efficiently solve CMDPs modelling real-world scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 19:23:44 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Blahoudek", "Franti\u0161ek", ""], ["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Novotn\u00fd", "Petr", ""], ["Ornik", "Melkior", ""], ["Thangeda", "Pranay", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2005.07425", "submitter": "Norine Coenen", "authors": "Norine Coenen (1), Bernd Finkbeiner (1), C\\'esar S\\'anchez (2),\n  Leander Tentrup (1) ((1) Reactive Systems Group, Saarland University, (2)\n  IMDEA Software Institute)", "title": "Verifying Hyperliveness", "comments": "Originally published at CAV 2019", "journal-ref": "In: Dillig I., Tasiran S. (eds) Computer Aided Verification. CAV\n  2019. Lecture Notes in Computer Science, vol 11561. Springer, Cham", "doi": "10.1007/978-3-030-25540-4_7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HyperLTL is an extension of linear-time temporal logic for the specification\nof hyperproperties, i.e., temporal properties that relate multiple computation\ntraces. HyperLTL can express information flow policies as well as properties\nlike symmetry in mutual exclusion algorithms or Hamming distances in\nerror-resistant transmission protocols. Previous work on HyperLTL model\nchecking has focussed on the alternation-free fragment of HyperLTL, where\nverification reduces to checking a standard trace property over an appropriate\nself-composition of the system. The alternation-free fragment does, however,\nnot cover general hyperliveness properties. Universal formulas, for example,\ncannot express the secrecy requirement that for every possible value of a\nsecret variable there exists a computation where the value is different while\nthe observations made by the external observer are the same. In this paper, we\nstudy the more difficult case of hyperliveness properties expressed as HyperLTL\nformulas with quantifier alternation. We reduce existential quantification to\nstrategic choice and show that synthesis algorithms can be used to eliminate\nthe existential quantifiers automatically. We furthermore show that this\napproach can be extended to reactive system synthesis, i.e., to automatically\nconstruct a reactive system that is guaranteed to satisfy a given HyperLTL\nformula.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 09:06:25 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Coenen", "Norine", ""], ["Finkbeiner", "Bernd", ""], ["S\u00e1nchez", "C\u00e9sar", ""], ["Tentrup", "Leander", ""]]}, {"id": "2005.07509", "submitter": "Valeria Vignudelli", "authors": "Matteo Mio, Valeria Vignudelli", "title": "Monads and Quantitative Equational Theories for Nondeterminism and\n  Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The monad of convex sets of probability distributions is a well-known tool\nfor modelling the combination of nondeterministic and probabilistic\ncomputational effects. In this work we lift this monad from the category of\nsets to the category of metric spaces, by means of the Hausdorff and\nKantorovich metric liftings. Our main result is the presentation of this lifted\nmonad in terms of the quantitative equational theory of convex semilattices,\nusing the framework of quantitative algebras recently introduced by Mardare,\nPanangaden and Plotkin.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 12:58:28 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Mio", "Matteo", ""], ["Vignudelli", "Valeria", ""]]}, {"id": "2005.08257", "submitter": "Denis Kuperberg", "authors": "David Baelde, Amina Doumane, Denis Kuperberg, Alexis Saurin", "title": "Bouncing threads for infinitary and circular proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We generalize the validity criterion for the infinitary proof system of the\nmultiplicative additive linear logic with fixed points. Our criterion is\ndesigned to take into account axioms and cuts. We show that it is sound and\nenjoys the cut elimination property. We finally study its decidability\nproperties, and prove that it is undecidable in general but becomes decidable\nunder some restrictions.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 14:13:39 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Baelde", "David", ""], ["Doumane", "Amina", ""], ["Kuperberg", "Denis", ""], ["Saurin", "Alexis", ""]]}, {"id": "2005.08384", "submitter": "Christian Anti\\'c", "authors": "Christian Anti\\'c", "title": "Fixed Point Semantics for Stream Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning over streams of input data is an essential part of human\nintelligence. During the last decade {\\em stream reasoning} has emerged as a\nresearch area within the AI-community with many potential applications. In\nfact, the increased availability of streaming data via services like Google and\nFacebook has raised the need for reasoning engines coping with data that\nchanges at high rate. Recently, the rule-based formalism {\\em LARS} for\nnon-monotonic stream reasoning under the answer set semantics has been\nintroduced. Syntactically, LARS programs are logic programs with negation\nincorporating operators for temporal reasoning, most notably {\\em window\noperators} for selecting relevant time points. Unfortunately, by preselecting\n{\\em fixed} intervals for the semantic evaluation of programs, the rigid\nsemantics of LARS programs is not flexible enough to {\\em constructively} cope\nwith rapidly changing data dependencies. Moreover, we show that defining the\nanswer set semantics of LARS in terms of FLP reducts leads to undesirable\ncircular justifications similar to other ASP extensions. This paper fixes all\nof the aforementioned shortcomings of LARS. More precisely, we contribute to\nthe foundations of stream reasoning by providing an operational fixed point\nsemantics for a fully flexible variant of LARS and we show that our semantics\nis sound and constructive in the sense that answer sets are derivable bottom-up\nand free of circular justifications.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 22:25:24 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Anti\u0107", "Christian", ""]]}, {"id": "2005.08856", "submitter": "Maciej Bendkowski", "authors": "Maciej Bendkowski", "title": "How to generate random lambda terms?", "comments": "Fixed typo in the S-combinator", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DS cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey several methods of generating large random lambda-terms, focusing\non their closed and simply-typed variants. We discuss methods of exact- and\napproximate-size generation, as well as methods of achieving size-uniform and\nnon-uniform outcome distributions.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:30:07 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:01:28 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Bendkowski", "Maciej", ""]]}, {"id": "2005.08884", "submitter": "Michael Kohlhase", "authors": "Michael Kohlhase, Florian Rabe, Makarius Wenzel", "title": "Making Isabelle Content Accessible in Knowledge Representation Formats", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The libraries of proof assistants like Isabelle, Coq, HOL are notoriously\ndifficult to interpret by external tools: de facto, only the prover itself can\nparse and process them adequately. In the case of Isabelle, an export of the\nlibrary into a FAIR (Findable, Accessible, Interoperable, and Reusable)\nknowledge exchange format was already envisioned by the authors in 1999 but had\npreviously proved too difficult. After substantial improvements of the Isabelle\nProver IDE (PIDE) and the OMDoc/Mmt format since then, we are now able to\ndeliver such an export. Concretely we present an integration of PIDE and MMT\nthat allows exporting all Isabelle libraries in OMDoc format. Our export covers\nthe full Isabelle distribution and the Archive of Formal Proofs (AFP) -- more\nthan 12 thousand theories and locales resulting in over 65GB of OMDoc/XML. Such\na systematic export of Isabelle content to a well-defined interchange format\nlike OMDoc enables many applications such as dependency management, independent\nproof checking, or library search.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 15:23:55 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kohlhase", "Michael", ""], ["Rabe", "Florian", ""], ["Wenzel", "Makarius", ""]]}, {"id": "2005.09253", "submitter": "Guillermo P\\'erez", "authors": "Damien Busatto-Gaston, Debraj Chakraborty, Shibashis Guha, Guillermo\n  A. P\\'erez, Jean-Fran\\c{c}ois Raskin", "title": "Safe Learning for Near Optimal Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the combination of synthesis, model-based\nlearning, and online sampling techniques to obtain safe and near-optimal\nschedulers for a preemptible task scheduling problem. Our algorithms can handle\nMarkov decision processes (MDPs) that have 1020 states and beyond which cannot\nbe handled with state-of-the art probabilistic model-checkers. We provide\nprobably approximately correct (PAC) guarantees for learning the model.\nAdditionally, we extend Monte-Carlo tree search with advice, computed using\nsafety games or obtained using the earliest-deadline-first scheduler, to safely\nexplore the learned model online. Finally, we implemented and compared our\nalgorithms empirically against shielded deep Q-learning on large task systems.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 07:17:22 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 14:56:39 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Busatto-Gaston", "Damien", ""], ["Chakraborty", "Debraj", ""], ["Guha", "Shibashis", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "2005.09348", "submitter": "Yong Kiam Tan", "authors": "Andrew Sogokon, Stefan Mitsch, Yong Kiam Tan, Katherine Cordwell,\n  Andr\\'e Platzer", "title": "Pegasus: Sound Continuous Invariant Generation", "comments": "Extended version of FM'19 conference paper\n  (https://doi.org/10.1007/978-3-030-30942-8_10), to appear in FMSD", "journal-ref": null, "doi": "10.1007/s10703-020-00355-z", "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous invariants are an important component in deductive verification of\nhybrid and continuous systems. Just like discrete invariants are used to reason\nabout correctness in discrete systems without having to unroll their loops,\ncontinuous invariants are used to reason about differential equations without\nhaving to solve them. Automatic generation of continuous invariants remains one\nof the biggest practical challenges to the automation of formal proofs of\nsafety for hybrid systems. There are at present many disparate methods\navailable for generating continuous invariants; however, this wealth of diverse\ntechniques presents a number of challenges, with different methods having\ndifferent strengths and weaknesses. To address some of these challenges, we\ndevelop Pegasus: an automatic continuous invariant generator which allows for\ncombinations of various methods, and integrate it with the KeYmaera X theorem\nprover for hybrid systems. We describe some of the architectural aspects of\nthis integration, comment on its methods and challenges, and present an\nexperimental evaluation on a suite of benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 10:19:14 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 13:15:45 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sogokon", "Andrew", ""], ["Mitsch", "Stefan", ""], ["Tan", "Yong Kiam", ""], ["Cordwell", "Katherine", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "2005.09452", "submitter": "Boro Sitnikovski", "authors": "Boro Sitnikovski, Biljana Stojcevska, Lidija Goracinova-Ilieva, Irena\n  Stojmenovska", "title": "PubSub implementation in Haskell with formal verification in Coq", "comments": "4 pages, accepted for presentation at the CIIT 2020, 17th\n  International Conference on Informatics and Information Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the cloud, the technology is used on-demand without the need to install\nanything on the desktop. Software as a Service is one of the many cloud\narchitectures. The PubSub messaging pattern is a cloud-based Software as a\nService solution used in complex systems, especially in the notifications part\nwhere there is a need to send a message from one unit to another single unit or\nmultiple units. Haskell is a generic typed programming language which has\npioneered several advanced programming language features. Based on the lambda\ncalculus system, it belongs to the family of functional programming languages.\nCoq, also based on a stricter version of lambda calculus, is a programming\nlanguage that has a more advanced type system than Haskell and is mainly used\nfor theorem proving i.e. proving software correctness. This paper aims to show\nhow PubSub can be used in conjunction with cloud computing (Software as a\nService), as well as to present an example implementation in Haskell and proof\nof correctness in Coq.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 09:45:24 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Sitnikovski", "Boro", ""], ["Stojcevska", "Biljana", ""], ["Goracinova-Ilieva", "Lidija", ""], ["Stojmenovska", "Irena", ""]]}, {"id": "2005.09478", "submitter": "Kacper Topolnicki", "authors": "Kacper Topolnicki", "title": "Monads and \"do\" notation in the Wolfram Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a categorical interpretation of the Wolfram Language and\nintroduces a simple implementation of monadic types and the \"do\" notation. The\nmonadic style of programming combined with the many built in functions of the\nWolfram Language has potential to be a powerful tool in writing Wolfram\nLanguage code. Additionally, using pure functions and the \"do\" notation can\nresult in programs that are very predictable and easy to parallelize.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 09:32:48 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Topolnicki", "Kacper", ""]]}, {"id": "2005.09489", "submitter": "Shankara Narayanan Krishna", "authors": "Parosh Aziz Abdulla, Mohamed Faouzi Atig, Vrunda Dave and Shankara\n  Narayanan Krishna", "title": "On the Separability Problem of String Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the separability problem for straight-line string constraints. The\nseparability problem for languages of a class C by a class S asks: given two\nlanguages A and B in C, does there exist a language I in S separating A and B\n(i.e., I is a superset of A and disjoint from B)? The separability of string\nconstraints is the same as the fundamental problem of interpolation for string\nconstraints. We first show that regular separability of straight line string\nconstraints is undecidable. Our second result is the decidability of the\nseparability problem for straight-line string constraints by piece-wise\ntestable languages, though the precise complexity is open. In our third result,\nwe consider the positive fragment of piece-wise testable languages as a\nseparator, and obtain an EXPSPACE algorithm for the separability of a useful\nclass of straight-line string constraints, and a PSPACE-hardness result.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 05:02:02 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 01:43:11 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Atig", "Mohamed Faouzi", ""], ["Dave", "Vrunda", ""], ["Krishna", "Shankara Narayanan", ""]]}, {"id": "2005.09559", "submitter": "EPTCS", "authors": "Martin Hyland (DPMMS, University of Cambridge), Christine Tasson\n  (IRIF, Universit\\'e de Paris)", "title": "The linear-non-linear substitution 2-monad", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 215-229", "doi": "10.4204/EPTCS.333.15", "report-no": null, "categories": "math.CT cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a general construction on 2-monads. We develop background on\nmaps of 2-monads, their left semi-algebras, and colimits in 2-category. Then,\nwe introduce the construction of a colimit induced by a map of 2-monads, show\nthat we obtain the structure of a 2-monad and give a characterisation of its\nalgebras. Finally, we apply the construction to the map of 2-monads between\nfree symmetric monoidal and the free cartesian 2-monads and combine them into a\nlinear-non-linear 2-monad.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 16:25:21 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 07:30:35 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Hyland", "Martin", "", "DPMMS, University of Cambridge"], ["Tasson", "Christine", "", "IRIF, Universit\u00e9 de Paris"]]}, {"id": "2005.09998", "submitter": "Bram Aerts", "authors": "Bram Aerts, Simon Vandevelde, and Joost Vennekens", "title": "Tackling the DMN Challenges with cDMN: a Tight Integration of DMN and\n  constraint reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an extension to the DMN standard, called cDMN. It aims\nto enlarge the expressivity of DMN in order to solve more complex problems,\nwhile retaining DMN's goal of being readable by domain experts. We test cDMN by\nsolving the most complex challenges posted on the DM Community website. We\ncompare our own cDMN solutions to the solutions that have been submitted to the\nwebsite and find that our approach is competitive, both in readability and\ncompactness. Moreover, cDMN is able to solve more challenges than any other\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 14:50:34 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Aerts", "Bram", ""], ["Vandevelde", "Simon", ""], ["Vennekens", "Joost", ""]]}, {"id": "2005.10015", "submitter": "Nicolas Rolland", "authors": "Paul-Andr\\'e Melli\\`es and Nicolas Rolland", "title": "Comprehension and quotient structures in the language of 2-categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lawvere observed in his celebrated work on hyperdoctrines that the\nset-theoretic schema of comprehension can be elegantly expressed in the\nfunctorial language of categorical logic, as a comprehension structure on the\nfunctor $p:\\mathscr{E}\\to\\mathscr{B}$ defining the hyperdoctrine.\n  In this paper, we formulate and study a strictly ordered hierarchy of three\nnotions of comprehension structure on a given functor\n$p:\\mathscr{E}\\to\\mathscr{B}$, which we call (i) comprehension structure, (ii)\ncomprehension structure with section, and (iii) comprehension structure with\nimage.\n  Our approach is 2-categorical and we thus formulate the three levels of\ncomprehension structure on a general morphism\n$p:\\mathrm{\\mathbf{E}}\\to\\mathrm{\\mathbf{B}}$ in a 2-category $\\mathscr{K}$.\n  This conceptual point of view on comprehension structures enables us to\nrevisit the work by Fumex, Ghani and Johann on the duality between\ncomprehension structures and quotient structures on a given functor\n$p:\\mathscr{E}\\to\\mathscr{B}$.\n  In particular, we show how to lift the comprehension and quotient structures\non a functor $p:\\mathscr{E}\\to\\mathscr{B}$ to the categories of algebras or\ncoalgebras associated to functors $F_{\\mathscr{E}}:\\mathscr{E}\\to\\mathscr{E}$\nand $F_{\\mathscr{B}}:\\mathscr{B}\\to\\mathscr{B}$ of interest, in order to\ninterpret reasoning by induction and coinduction in the traditional language of\ncategorical logic, formulated in an appropriate 2-categorical way.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 12:56:50 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Melli\u00e8s", "Paul-Andr\u00e9", ""], ["Rolland", "Nicolas", ""]]}, {"id": "2005.10058", "submitter": "Sergey A. Slavnov", "authors": "Sergey Slavnov", "title": "On embedding Lambek calculus into commutative categorial grammars", "comments": "Much better presentation in the new version. Added pictures and\n  examples, simplified proofs, improved notation and terminology, computational\n  part reduced almost to zero", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider tensor grammars, which are an example of \\commutative\" grammars,\nbased on the classical (rather than intuitionistic) linear logic. They can be\nseen as a surface representation of abstract categorial grammars ACG in the\nsense that derivations of ACG translate to derivations of tensor grammars and\nthis translation is isomorphic on the level of string languages. The basic\ningredient are tensor terms, which can be seen as encoding and generalizing\nproof-nets. Using tensor terms makes the syntax extremely simple and a direct\ngeometric meaning becomes transparent. Then we address the problem of encoding\nnoncommutative operations in our setting. This turns out possible after\nenriching the system with new unary operators. The resulting system allows\nrepresenting both ACG and Lambek grammars as conservative fragments, while the\nformalism remains, as it seems to us, rather simple and intuitive.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 14:08:56 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 18:23:42 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 08:55:27 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Slavnov", "Sergey", ""]]}, {"id": "2005.10137", "submitter": "Xuefeng Wen", "authors": "Xuefeng Wen", "title": "Some Common Mistakes in the Teaching and Textbooks of Modal Logic", "comments": null, "journal-ref": "This is an English translation of the paper published in Studies\n  in Logic (Chinese), 11(4A), 69-86, 2018", "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss four common mistakes in the teaching and textbooks of modal logic.\nThe first one is missing the axiom\n$\\Diamond\\varphi\\leftrightarrow\\neg\\Box\\neg\\varphi$, when choosing $\\Diamond$\nas the primitive modal operator, misunderstanding that $\\Box$ and $\\Diamond$\nare symmetric. The second one is forgetting to make the set of formulas for\nfiltration closed under subformulas, when proving the finite model property\nthrough filtration, neglecting that $\\Box\\varphi$ and $\\Diamond\\varphi$ may be\nabbreviations of formulas. The third one is giving wrong definitions of\ncanonical relations in minimal canonical models that are unmatched with the\nprimitive modal operators. The final one is misunderstanding the rule of\nnecessitation, without knowing its distinction from the rule of modus ponens.\nTo better understand the rule of necessitation, we summarize six ways of\ndefining deductive consequence in modal logic: omitted definition, classical\ndefinition, ternary definition, reduced definition, bounded definition, and\ndeflationary definition, and show that the last three definitions are\nequivalent to each other.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:35:59 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Wen", "Xuefeng", ""]]}, {"id": "2005.10182", "submitter": "Sandra Kiefer", "authors": "Sandra Kiefer, Brendan D. McKay", "title": "The Iteration Number of Colour Refinement", "comments": "22 pages, 3 figures, full version of a paper accepted at ICALP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Colour Refinement procedure and its generalisation to higher dimensions,\nthe Weisfeiler-Leman algorithm, are central subroutines in approaches to the\ngraph isomorphism problem. In an iterative fashion, Colour Refinement computes\na colouring of the vertices of its input graph.\n  A trivial upper bound on the iteration number of Colour Refinement on graphs\nof order n is n-1. We show that this bound is tight. More precisely, we prove\nvia explicit constructions that there are infinitely many graphs G on which\nColour Refinement takes |G|-1 iterations to stabilise. Modifying the infinite\nfamilies that we present, we show that for every natural number n >= 10, there\nare graphs on n vertices on which Colour Refinement requires at least n-2\niterations to reach stabilisation.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:43:57 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Kiefer", "Sandra", ""], ["McKay", "Brendan D.", ""]]}, {"id": "2005.10382", "submitter": "\\'Akos Hajdu", "authors": "\\'Akos Hajdu, Dejan Jovanovi\\'c, Gabriela Ciocarlie", "title": "Formal Specification and Verification of Solidity Contracts with Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Events in the Solidity language provide a means of communication between the\non-chain services of decentralized applications and the users of those\nservices. Events are commonly used as an abstraction of contract execution that\nis relevant from the users' perspective. Users must, therefore, be able to\nunderstand the meaning and trust the validity of the emitted events. This paper\npresents a source-level approach for the formal specification and verification\nof Solidity contracts with the primary focus on events. Our approach allows\nspecification of events in terms of the on-chain data that they track, and\npredicates that define the correspondence between the blockchain state and the\nabstract view provided by the events. The approach is implemented in\nsolc-verify, a modular verifier for Solidity, and we demonstrate its\napplicability with various examples.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 22:48:25 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Hajdu", "\u00c1kos", ""], ["Jovanovi\u0107", "Dejan", ""], ["Ciocarlie", "Gabriela", ""]]}, {"id": "2005.10947", "submitter": "Jonathan Mize", "authors": "Jonathan J. Mize", "title": "A Novel Semantics for Belief, Knowledge and Psychological Alethic\n  Modality", "comments": "29 pg. & 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently there have been numerous proposed solutions to the problem of\nlogical omniscience in doxastic and epistemic logic. Though these solutions\ndisplay an impressive breadth of subtlety and motivation, the crux of these\napproaches seems to have a common theme-minor revisions around the ubiquitous\nKripke semantics-rooted approach. In addition, the psychological mechanisms at\nwork in and around both belief and knowledge have been left largely untouched.\nIn this paper, we cut straight to the core of the problem of logical\nomniscience, taking a psychologically-rooted approach, taking as bedrock the\n\"quanta\" of given percepts, qualia and cognitions, terming our approach \"PQG\nlogic\", short for percept, qualia, cognition logic. Building atop these quanta,\nwe reach a novel semantics of belief, knowledge, in addition to a semantics for\npsychological necessity and possibility. With these notions we are\nwell-equipped to not only address the problem of logical omniscience but to\nmore deeply investigate the psychical-logical nature of belief and knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 00:00:35 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Mize", "Jonathan J.", ""]]}, {"id": "2005.11023", "submitter": "Wenjun Shi", "authors": "Wenjun Shi, Qinxiang Cao, Yuxin Deng, Hanru Jiang and Yuan Feng", "title": "Symbolic Reasoning about Quantum Circuits in Coq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quantum circuit is a computational unit that transforms an input quantum\nstate to an output one. A natural way to reason about its behavior is to\ncompute explicitly the unitary matrix implemented by it. However, when the\nnumber of qubits increases, the matrix dimension grows exponentially and the\ncomputation becomes intractable.\n  In this paper, we propose a symbolic approach to reasoning about quantum\ncircuits. It is based on a small set of laws involving some basic manipulations\non vectors and matrices. This symbolic reasoning scales better than the\nexplicit one and is well suited to be automated in Coq, as demonstrated with\nsome typical examples.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 06:27:52 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 08:36:41 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 08:00:35 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Shi", "Wenjun", ""], ["Cao", "Qinxiang", ""], ["Deng", "Yuxin", ""], ["Jiang", "Hanru", ""], ["Feng", "Yuan", ""]]}, {"id": "2005.11290", "submitter": "Evan Cavallo", "authors": "Evan Cavallo and Robert Harper", "title": "Internal Parametricity for Cubical Type Theory", "comments": "Respond to reviewer comments, remove section on modal type theory,\n  improve presheaf model presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a computational type theory combining the contentful equality\nstructure of cartesian cubical type theory with internal parametricity\nprimitives. The combined theory supports both univalence and its relational\nequivalent, which we call relativity. We demonstrate the use of the theory by\nanalyzing polymorphic functions between higher inductive types, observe how\ncubical equality regularizes parametric type theory, and examine the\nsimilarities and discrepancies between cubical and parametric type theory,\nwhich are closely related. We also abstract a formal interface to the\ncomputational interpretation and show that this also has a presheaf model.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:30:31 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 13:36:32 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 23:17:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Cavallo", "Evan", ""], ["Harper", "Robert", ""]]}, {"id": "2005.11551", "submitter": "Dexter Kozen", "authors": "Nick Bezhanishvili and Marcello Bonsangue and Helle Hvid Hansen and\n  Dexter Kozen and Clemens Kupke and Prakash Panangaden and Alexandra Silva", "title": "Minimisation in Logical Form", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stone-type dualities provide a powerful mathematical framework for studying\nproperties of logical systems. They have recently been fruitfully explored in\nunderstanding minimisation of various types of automata. In Bezhanishvili et\nal. (2012), a dual equivalence between a category of coalgebras and a category\nof algebras was used to explain minimisation. The algebraic semantics is dual\nto a coalgebraic semantics in which logical equivalence coincides with trace\nequivalence. It follows that maximal quotients of coalgebras correspond to\nminimal subobjects of algebras. Examples include partially observable\ndeterministic finite automata, linear weighted automata viewed as coalgebras\nover finite-dimensional vector spaces, and belief automata, which are\ncoalgebras on compact Hausdorff spaces. In Bonchi et al. (2014), Brzozowski's\ndouble-reversal minimisation algorithm for deterministic finite automata was\ndescribed categorically and its correctness explained via the duality between\nreachability and observability. This work includes generalisations of\nBrzozowski's algorithm to Moore and weighted automata over commutative\nsemirings.\n  In this paper we propose a general categorical framework within which such\nminimisation algorithms can be understood. The goal is to provide a unifying\nperspective based on duality. Our framework consists of a stack of three\ninterconnected adjunctions: a base dual adjunction that can be lifted to a dual\nadjunction between coalgebras and algebras and also to a dual adjunction\nbetween automata. The approach provides an abstract understanding of\nreachability and observability. We illustrate the general framework on range of\nconcrete examples, including deterministic Kripke frames, weighted automata,\ntopological automata (belief automata), and alternating automata.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 15:19:57 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bezhanishvili", "Nick", ""], ["Bonsangue", "Marcello", ""], ["Hansen", "Helle Hvid", ""], ["Kozen", "Dexter", ""], ["Kupke", "Clemens", ""], ["Panangaden", "Prakash", ""], ["Silva", "Alexandra", ""]]}, {"id": "2005.11635", "submitter": "Richard Rohwer", "authors": "Richard Rohwer", "title": "The Optimal 'AND'", "comments": "23 pages, 5 figures, to be submitted (shortened) to NeurIPS20", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LO math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint distribution $P(X,Y)$ cannot be determined from its marginals\n$P(X)$ and $P(Y)$ alone; one also needs one of the conditionals $P(X|Y)$ or\n$P(Y|X)$. But is there a best guess, given only the marginals? Here we answer\nthis question in the affirmative, obtaining in closed form the function of the\nmarginals that has the lowest expected Kullbach-Liebler (KL) divergence between\nthe unknown \"true\" joint probability and the function value. The expectation is\ntaken with respect to Jeffreys' non-informative prior over the possible joint\nprobability values, given the marginals. This distribution can also be used to\nobtain the expected information loss for any other \"aggregation operator\", as\nsuch estimators are often called in fuzzy logic, for any given pair of marginal\ninput values. This enables such such operators, including ours, to be compared\naccording to their expected loss under the minimal knowledge conditions we\nassume. We go on to develop a method for evaluating the expected accuracy of\nany aggregation operator in the absence of knowledge of its inputs. This\nrequires averaging the expected loss over all possible input pairs, weighted by\nan appropriate distribution. We obtain this distribution by marginalizing\nJeffreys' prior over the possible joint distributions (over the 3 functionally\nindependent coordinates of the space of joint distributions over two Boolean\nvariables) onto a joint distribution over the pair of marginal distributions, a\n2-dimensional space with one parameter for each marginal. We report the\nresulting input-averaged expected losses for a few commonly used operators, as\nwell as the optimal operator. Finally, we discuss the potential to develop our\nmethodology into a principled risk management approach to replace the often\nrather arbitrary conditional-independence assumptions made for probabilistic\ngraphical models.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 01:30:58 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Rohwer", "Richard", ""]]}, {"id": "2005.11710", "submitter": "Julien Lange", "authors": "Robert Griesemer, Raymond Hu, Wen Kokke, Julien Lange, Ian Lance\n  Taylor, Bernardo Toninho, Philip Wadler and Nobuko Yoshida", "title": "Featherweight Go", "comments": "Full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a design for generics in Go inspired by previous work on\nFeatherweight Java by Igarashi, Pierce, and Wadler. Whereas subtyping in Java\nis nominal, in Go it is structural, and whereas generics in Java are defined\nvia erasure, in Go we use monomorphisation. Although monomorphisation is widely\nused, we are one of the first to formalise it. Our design also supports a\nsolution to The Expression Problem.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 10:31:39 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 18:34:23 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 12:49:29 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 17:04:10 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Griesemer", "Robert", ""], ["Hu", "Raymond", ""], ["Kokke", "Wen", ""], ["Lange", "Julien", ""], ["Taylor", "Ian Lance", ""], ["Toninho", "Bernardo", ""], ["Wadler", "Philip", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "2005.11737", "submitter": "Sylvain Hall\\'e", "authors": "Kun Xie and Sylvain Hall\\'e", "title": "Efficient Offline Monitoring of Linear Temporal Logic with Bit Vectors", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bitmap is a data structure designed to compactly represent sets of\nintegers; it provides very fast operations for querying and manipulating such\nsets, exploiting bit-level parallelism. In this paper, we describe a technique\nfor the offline verification of arbitrary expressions of Linear Temporal Logic\nusing bitmap manipulation. An event trace is first preprocessed and transformed\ninto a set of bitmaps. The LTL expression is then evaluated through a recursive\nprocedure manipulating these bitmaps. Experimental results show that, for\ncomplex LTL formulas containing almost 20 operators, event traces can be\nevaluated at a throughput of millions of events per second.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 12:53:51 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Xie", "Kun", ""], ["Hall\u00e9", "Sylvain", ""]]}, {"id": "2005.11827", "submitter": "Dejan Ni\\v{c}kovi\\'c", "authors": "Dejan Nickovic and Tomoya Yamaguchi", "title": "RTAMT: Online Robustness Monitors from STL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RTAMT, an online monitoring library for Signal Temporal Logic\n(STL) and its interface-aware variant (IA-STL), providing both discrete- and\ndense-time interpretation of the logic. We also introduce RTAMT4ROS, a tool\nthat integrates RTAMT with Robotic Operating System (ROS), a common environment\nfor developing robotic applications. We evaluate RTAMT and RTAMT4ROS on two\nrobotic case studies.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 19:23:09 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Nickovic", "Dejan", ""], ["Yamaguchi", "Tomoya", ""]]}, {"id": "2005.12175", "submitter": "Guy Avni", "authors": "Parand Alizadeh Alamdari, Guy Avni, Thomas A. Henzinger, Anna Lukina", "title": "Formal Methods with a Touch of Magic", "comments": "Published in FMCAD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and formal methods have complimentary benefits and\ndrawbacks. In this work, we address the controller-design problem with a\ncombination of techniques from both fields. The use of black-box neural\nnetworks in deep reinforcement learning (deep RL) poses a challenge for such a\ncombination. Instead of reasoning formally about the output of deep RL, which\nwe call the {\\em wizard}, we extract from it a decision-tree based model, which\nwe refer to as the {\\em magic book}. Using the extracted model as an\nintermediary, we are able to handle problems that are infeasible for either\ndeep RL or formal methods by themselves. First, we suggest, for the first time,\ncombining a magic book in a synthesis procedure. We synthesize a stand-alone\ncorrect-by-design controller that enjoys the favorable performance of RL.\nSecond, we incorporate a magic book in a bounded model checking (BMC)\nprocedure. BMC allows us to find numerous traces of the plant under the control\nof the wizard, which a user can use to increase the trustworthiness of the\nwizard and direct further training.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:45:03 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 21:12:51 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Alamdari", "Parand Alizadeh", ""], ["Avni", "Guy", ""], ["Henzinger", "Thomas A.", ""], ["Lukina", "Anna", ""]]}, {"id": "2005.12232", "submitter": "Camilo Rocha", "authors": "Stephen Skeirik and Jos\\'e Meseguer and Camilo Rocha", "title": "Verification of the IBOS Browser Security Properties in Reachability\n  Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a rewriting logic specification of the Illinois Browser\nOperating System (IBOS) and defines several security properties, including the\nsame-origin policy (SOP) in reachability logic. It shows how these properties\ncan be deductively verified using our constructor-based reachability logic\ntheorem prover. This paper also highlights the reasoning techniques used in the\nproof and three modularity principles that have been crucial to scale up and\ncomplete the verification effort.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:02:51 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Skeirik", "Stephen", ""], ["Meseguer", "Jos\u00e9", ""], ["Rocha", "Camilo", ""]]}, {"id": "2005.12582", "submitter": "Thomas Ehrhard", "authors": "Thomas Ehrhard (IRIF)", "title": "Differentials and distances in probabilistic coherence spaces (extended\n  version)", "comments": "extended version of arXiv:1902.04836", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In probabilistic coherence spaces, a denotational model of probabilistic\nfunctional languages, morphisms are analytic and therefore smooth. We explore\ntwo related applications of the corresponding derivatives. First we show how\nderivatives allow to compute the expectation of execution time in the weak head\nreduction of probabilistic PCF (pPCF). Next we apply a general notion of\n''local'' differential of morphisms to the proof of a Lipschitz property of\nthese morphisms allowing in turn to relate the observational distance on pPCF\nterms to a distance the model is naturally equipped with. This suggests that\nextending probabilistic programming languages with derivatives, in the spirit\nof the differential lambda-calculus, could be quite meaningful.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 09:03:57 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Ehrhard", "Thomas", "", "IRIF"]]}, {"id": "2005.12737", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Towards United Reasoning for Automatic Induction in Isabelle/HOL", "comments": "This is the pre-print of our short-paper accepted at the 34th Annual\n  Conference of the Japanese Society for Artificial Intelligence, 2020\n  (https://www.ai-gakkai.or.jp/jsai2020/en)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive theorem proving is an important long-standing challenge in computer\nscience. In this extended abstract, we first summarize the recent developments\nof proof by induction for Isabelle/HOL. Then, we propose united reasoning, a\nnovel approach to further automating inductive theorem proving. Upon success,\nunited reasoning takes the best of three schools of reasoning: deductive\nreasoning, inductive reasoning, and inductive reasoning, to prove difficult\ninductive problems automatically.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 08:30:05 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2005.12876", "submitter": "Cezary Kaliszyk", "authors": "Cezary Kaliszyk and Florian Rabe", "title": "A Survey of Languages for Formalizing Mathematics", "comments": "CICM 2020 conference paper preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to work with mathematical content in computer systems, it is\nnecessary to represent it in formal languages. Ideally, these are supported by\ntools that verify the correctness of the content, allow computing with it, and\nproduce human-readable documents. These goals are challenging to combine and\nstate-of-the-art tools typically have to make difficult compromises.\n  In this paper we discuss languages that have been created for this purpose,\nincluding logical languages of proof assistants and other formal systems,\nsemi-formal languages, intermediate languages for exchanging mathematical\nknowledge, and language frameworks that allow building customized languages.\n  We evaluate their advantages based on our experience in designing and\napplying languages and tools for formalizing mathematics. We reach the\nconclusion that no existing language is truly good enough yet and derive ideas\nfor possible future improvements.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:11:42 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Rabe", "Florian", ""]]}, {"id": "2005.12911", "submitter": "Yann Thierry-Mieg", "authors": "Yann Thierry-Mieg (SU, CNRS)", "title": "Symbolic and Structural Model-Checking", "comments": "Extended Journal version of ICATPN 2020 paper (pre-print)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brute-force model-checking consists in exhaustive exploration of the\nstate-space of a Petri net, and meets the dreaded state-space explosion\nproblem.\n  In contrast, this paper shows how to solve model-checking problems using a\ncombination of techniques that stay in complexity proportional to the size of\nthe net structure rather than to the state-space size.\n  We combine an SMT based over-approximation to prove that some behaviors are\nunfeasible, an under-approximation using memory-less sampling of runs to find\nwitness traces or counter-examples, and a set of structural reduction rules\nthat can simplify both the system and the property.\n  This approach was able to win by a clear margin the model-checking contest\n2020 for reachability queries as well as deadlock detection, thus demonstrating\nthe practical effectiveness and general applicability of the system of rules\npresented in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 08:44:36 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 08:55:49 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Thierry-Mieg", "Yann", "", "SU, CNRS"]]}, {"id": "2005.13301", "submitter": "Hari Govind Vediramana Krishnan", "authors": "Hari Govind V K, YuTing Chen, Sharon Shoham, Arie Gurfinkel", "title": "Global Guidance for Local Generalization in Model Checking", "comments": "Published in CAV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SMT-based model checkers, especially IC3-style ones, are currently the most\neffective techniques for verification of infinite state systems. They infer\nglobal inductive invariants via local reasoning about a single step of the\ntransition relation of a system, while employing SMT-based procedures, such as\ninterpolation, to mitigate the limitations of local reasoning and allow for\nbetter generalization. Unfortunately, these mitigations intertwine model\nchecking with heuristics of the underlying SMT-solver, negatively affecting\nstability of model checking. In this paper, we propose to tackle the\nlimitations of locality in a systematic manner. We introduce explicit global\nguidance into the local reasoning performed by IC3-style algorithms. To this\nend, we extend the SMT-IC3 paradigm with three novel rules, designed to\nmitigate fundamental sources of failure that stem from locality. We instantiate\nthese rules for the theory of Linear Integer Arithmetic and implement them on\ntop of SPACER solver in Z3. Our empirical results show that GSPACER, SPACER\nextended with global guidance, is significantly more effective than both SPACER\nand sole global reasoning, and, furthermore, is insensitive to interpolation.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:58:28 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["K", "Hari Govind V", ""], ["Chen", "YuTing", ""], ["Shoham", "Sharon", ""], ["Gurfinkel", "Arie", ""]]}, {"id": "2005.13415", "submitter": "Saeed Nejati", "authors": "Saeed Nejati and Vijay Ganesh", "title": "CDCL(Crypto) SAT Solvers for Cryptanalysis", "comments": "Proceedings of the 29th Annual International Conference on Computer\n  Science and Software Engineering 2019 (CASCON 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last two decades, we have seen a dramatic improvement in the\nefficiency of conflict-driven clause-learning Boolean satisfiability (CDCL SAT)\nsolvers on industrial problems from a variety of domains. The availability of\nsuch powerful general-purpose search tools as SAT solvers has led many\nresearchers to propose SAT-based methods for cryptanalysis, including\ntechniques for finding collisions in hash functions and breaking symmetric\nencryption schemes. Most of the previously proposed SAT-based cryptanalysis\napproaches are blackbox techniques, in the sense that the cryptanalysis problem\nis encoded as a SAT instance and then a CDCL SAT solver is invoked to solve the\nsaid instance. A weakness of this approach is that the encoding thus generated\nmay be too large for any modern solver to solve efficiently. Perhaps a more\nimportant weakness of this approach is that the solver is in no way specialized\nor tuned to solve the given instance. To address these issues, we propose an\napproach called CDCL(Crypto) (inspired by the CDCL(T) paradigm in\nSatisfiability Modulo Theory solvers) to tailor the internal subroutines of the\nCDCL SAT solver with domain-specific knowledge about cryptographic primitives.\nSpecifically, we extend the propagation and conflict analysis subroutines of\nCDCL solvers with specialized codes that have knowledge about the cryptographic\nprimitive being analyzed by the solver. We demonstrate the power of this\napproach in the differential path and algebraic fault analysis of hash\nfunctions. Our initial results are very encouraging and reinforce the notion\nthat this approach is a significant improvement over blackbox SAT-based\ncryptanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 15:19:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Nejati", "Saeed", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2005.13602", "submitter": "Andrei Arusoaie", "authors": "Andrei Arusoaie", "title": "Certifying Findel Derivatives for Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Derivatives are a special type of financial contracts used to hedge risks or\nto speculate on the market fluctuations. In order to avoid ambiguities and\nmisinterpretations, several domain specific languages (DSLs) for specifying\nsuch derivatives have been proposed. The recent development of the blockchain\ntechnologies enables the automatic execution of financial derivatives. Once\ndeployed on the blockchain, a derivative cannot be modified. Therefore, more\ncaution should be taken in order to avoid undesired situations.\n  In this paper, we address the formal verification of financial derivatives\nwritten in a DSL for blockchain, called Findel. We identify a list of\nproperties that, once proved, they exclude several security vulnerabilities\n(e.g., immutable bugs, money losses). We develop an infrastructure that\nprovides means to interactively formalize and prove such properties. To provide\na higher confidence, we also generate proof certificates. We use our\ninfrastructure to certify non-trivial examples that cover the most common types\nof derivatives (forwards/futures, swaps, options).\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 19:21:51 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Arusoaie", "Andrei", ""]]}, {"id": "2005.13654", "submitter": "Matija Pretnar", "authors": "\\v{Z}iga Luk\\v{s}i\\v{c} and Matija Pretnar", "title": "Local Algebraic Effect Theories", "comments": "24 pages, 8 figures", "journal-ref": "LUKSIC, Z, & PRETNAR, M. (2020). Local algebraic effect theories.\n  Journal of Functional Programming, 30, E13", "doi": "10.1017/S0956796819000212", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic effects are computational effects that can be described with a set\nof basic operations and equations between them. As many interesting effect\nhandlers do not respect these equations, most approaches assume a trivial\ntheory, sacrificing both reasoning power and safety.\n  We present an alternative approach where the type system tracks equations\nthat are observed in subparts of the program, yielding a sound and flexible\nlogic, and paving a way for practical optimizations and reasoning tools.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 21:08:54 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Luk\u0161i\u010d", "\u017diga", ""], ["Pretnar", "Matija", ""]]}, {"id": "2005.13811", "submitter": "Thomas Studer", "authors": "Thomas Studer", "title": "No-Go Theorems for Data Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlled query evaluation (CQE) is an approach to guarantee data privacy\nfor database and knowledge base systems. CQE-systems feature a censor function\nthat may distort the answer to a query in order to hide sensitive information.\nWe introduce a high-level formalization of controlled query evaluation and\ndefine several desirable properties of CQE-systems. Finally we establish two\nno-go theorems, which show that certain combinations of these properties cannot\nbe obtained.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 07:10:37 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Studer", "Thomas", ""]]}, {"id": "2005.13954", "submitter": "Ciar\\'an Dunne", "authors": "Ciar\\'an Dunne, J. B. Wells, Fairouz Kamareddine", "title": "Adding an Abstraction Barrier to ZF Set Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much mathematical writing exists that is, explicitly or implicitly, based on\nset theory, often Zermelo-Fraenkel set theory (ZF) or one of its variants. In\nZF, the domain of discourse contains only sets, and hence every mathematical\nobject must be a set. Consequently, in ZF, with the usual encoding of an\nordered pair ${\\langle a, b\\rangle}$, formulas like ${\\{a\\} \\in \\langle a, b\n\\rangle}$ have truth values, and operations like ${\\mathcal P (\\langle a,\nb\\rangle)}$ have results that are sets. Such 'accidental theorems' do not match\nhow people think about the mathematics and also cause practical difficulties\nwhen using set theory in machine-assisted theorem proving. In contrast, in a\nnumber of proof assistants, mathematical objects and concepts can be built of\ntype-theoretic stuff so that many mathematical objects can be, in essence,\nterms of an extended typed ${\\lambda}$-calculus. However, dilemmas and\nfrustration arise when formalizing mathematics in type theory.\n  Motivated by problems of formalizing mathematics with (1) purely\nset-theoretic and (2) type-theoretic approaches, we explore an option with much\nof the flexibility of set theory and some of the useful features of type\ntheory. We present ZFP: a modification of ZF that has ordered pairs as\nprimitive, non-set objects. ZFP has a more natural and abstract axiomatic\ndefinition of ordered pairs free of any notion of representation. This paper\npresents axioms for ZFP, and a proof in ZF (machine-checked in Isabelle/ZF) of\nthe existence of a model for ZFP, which implies that ZFP is consistent if ZF\nis. We discuss the approach used to add this abstraction barrier to ZF.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 12:45:22 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Dunne", "Ciar\u00e1n", ""], ["Wells", "J. B.", ""], ["Kamareddine", "Fairouz", ""]]}, {"id": "2005.14104", "submitter": "Christopher Dean", "authors": "Christopher J. Dean", "title": "Globular Multicategories with Homomorphism Types", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a notion of globular multicategory with homomorphism types.\nThese structures arise when organizing collections of \"higher category-like\"\nobjects such as type theories with identity types. We show how these globular\nmulticategories can be used to construct various weak higher categorical\nstructures of types and terms.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:54:06 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Dean", "Christopher J.", ""]]}, {"id": "2005.14325", "submitter": "Elaine Pimentel", "authors": "Sonia Marin, Luiz Carlos Pereira, Elaine Pimentel, Emerson Sales", "title": "Ecumenical modal logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discussion about how to put together Gentzen's systems for classical and\nintuitionistic logic in a single unified system is back in fashion. Indeed,\nrecently Prawitz and others have been discussing the so called Ecumenical\nSystems, where connectives from these logics can co-exist in peace. In Prawitz'\nsystem, the classical logician and the intuitionistic logician would share the\nuniversal quantifier, conjunction, negation, and the constant for the absurd,\nbut they would each have their own existential quantifier, disjunction, and\nimplication, with different meanings. Prawitz' main idea is that these\ndifferent meanings are given by a semantical framework that can be accepted by\nboth parties. In a recent work, Ecumenical sequent calculi and a nested system\nwere presented, and some very interesting proof theoretical properties of the\nsystems were established. In this work we extend Prawitz' Ecumenical idea to\nalethic K-modalities.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 22:29:23 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Marin", "Sonia", ""], ["Pereira", "Luiz Carlos", ""], ["Pimentel", "Elaine", ""], ["Sales", "Emerson", ""]]}, {"id": "2005.14531", "submitter": "Pac\\^ome Perrotin", "authors": "K\\'evin Perrot, Pac\\^ome Perrotin, Sylvain Sen\\'e", "title": "Optimising attractor computation in Boolean automata networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper details a method for optimising the size of Boolean automata\nnetworks in order to compute their attractors under the parallel update\nschedule. This method relies on the formalism of modules introduced recently\nthat allows for (de)composing such networks. We discuss the practicality of\nthis method by exploring examples. We also propose results that nail the\ncomplexity of most parts of the process, while the complexity of one part of\nthe problem is left open.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 12:33:59 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 13:50:44 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Perrot", "K\u00e9vin", ""], ["Perrotin", "Pac\u00f4me", ""], ["Sen\u00e9", "Sylvain", ""]]}, {"id": "2005.14664", "submitter": "Josef Urban", "authors": "Josef Urban and Jan Jakub\\r{u}v", "title": "First Neural Conjecturing Datasets and Experiments", "comments": "Accepted to CICM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe several datasets and first experiments with creating conjectures\nby neural methods. The datasets are based on the Mizar Mathematical Library\nprocessed in several forms and the problems extracted from it by the MPTP\nsystem and proved by the E prover using the ENIGMA guidance. The conjecturing\nexperiments use the Transformer architecture and in particular its GPT-2\nimplementation.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 16:46:25 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Urban", "Josef", ""], ["Jakub\u016fv", "Jan", ""]]}]