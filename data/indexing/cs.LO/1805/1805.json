[{"id": "1805.00067", "submitter": "Kristina Sojakova", "authors": "Kristina Sojakova and Patricia Johann", "title": "A General Framework for Relational Parametricity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reynolds' original theory of relational parametricity was intended to capture\nthe idea that polymorphically typed System F programs preserve all relations\nbetween inputs. But as Reynolds himself later showed, his theory can only be\nformalized in a meta-theory with an impredicative universe, such as the\nCalculus of Inductive Constructions. Abstracting from Reynolds' ideas, Dunphy\nand Reddy developed their well-known framework for parametricity that uses\nparametric limits in reflexive graph categories and aims to subsume a variety\nof parametric models. As we observe, however, their theory is not sufficiently\ngeneral to subsume the very model that inspired parametricity, namely Reynolds'\noriginal model, expressed inside type theory. To correct this, we develop an\nabstract framework for relational parametricity that generalizes the notion of\na reflexive graph categories and delivers Reynolds' model as a direct instance\nin a natural way. This framework is uniform with respect to a choice of\nmeta-theory, which allows us to obtain the well-known PER model of Longo and\nMoggi as a direct instance in a natural way as well. In addition, we offer two\nnovel relationally parametric models of System F: i) a categorical version of\nReynolds' model, where types are functorial on isomorphisms and all polymorphic\nfunctions respect the functorial action, and ii) a proof-relevant categorical\nversion of Reynolds' model (after Orsanigo), where, additionally, witnesses of\nrelatedness are themselves suitably related. We show that, unlike previously\nexisting frameworks for parametricity, ours recognizes both of these new models\nin a natural way. Our framework is thus descriptive, in that it accounts for\nwell-known models, as well as prescriptive, in that it identifies abstract\nproperties that good models of relational parametricity should satisfy and\nsuggests new constructions of such models.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 19:14:39 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 16:22:25 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 17:45:43 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Sojakova", "Kristina", ""], ["Johann", "Patricia", ""]]}, {"id": "1805.00068", "submitter": "Tobias Kaminski", "authors": "Tobias Kaminski, Thomas Eiter, Katsumi Inoue", "title": "Exploiting Answer Set Programming with External Sources for\n  Meta-Interpretive Learning", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018, 23 pages,\n  LaTeX, 6 PDF figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-Interpretive Learning (MIL) learns logic programs from examples by\ninstantiating meta-rules, which is implemented by the Metagol system based on\nProlog. Viewing MIL-problems as combinatorial search problems, they can\nalternatively be solved by employing Answer Set Programming (ASP), which may\nresult in performance gains as a result of efficient conflict propagation.\nHowever, a straightforward ASP-encoding of MIL results in a huge search space\ndue to a lack of procedural bias and the need for grounding. To address these\nchallenging issues, we encode MIL in the HEX-formalism, which is an extension\nof ASP that allows us to outsource the background knowledge, and we restrict\nthe search space to compensate for a procedural bias in ASP. This way, the\nimport of constants from the background knowledge can for a given type of\nmeta-rules be limited to relevant ones. Moreover, by abstracting from term\nmanipulations in the encoding and by exploiting the HEX interface mechanism,\nthe import of such constants can be entirely avoided in order to mitigate the\ngrounding bottleneck. An experimental evaluation shows promising results.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 19:16:23 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Kaminski", "Tobias", ""], ["Eiter", "Thomas", ""], ["Inoue", "Katsumi", ""]]}, {"id": "1805.00185", "submitter": "Thanh Nguyen", "authors": "Thanh Hai Nguyen, Enrico Pontelli, Tran Cao Son", "title": "Phylotastic: An Experiment in Creating, Manipulating, and Evolving\n  Phylogenetic Biology Workflows Using Logic Programming", "comments": "Paper presented at the 34th International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 17 pages,\n  LaTeX, 10 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary Biologists have long struggled with the challenge of developing\nanalysis workflows in a flexible manner, thus facilitating the reuse of\nphylogenetic knowledge. An evolutionary biology workflow can be viewed as a\nplan which composes web services that can retrieve, manipulate, and produce\nphylogenetic trees. The Phylotastic project was launched two years ago as a\ncollaboration between evolutionary biologists and computer scientists, with the\ngoal of developing an open architecture to facilitate the creation of such\nanalysis workflows. While composition of web services is a problem that has\nbeen extensively explored in the literature, including within the logic\nprogramming domain, the incarnation of the problem in Phylotastic provides a\nnumber of additional challenges. Along with the need to integrate preferences\nand formal ontologies in the description of the desired workflow, evolutionary\nbiologists tend to construct workflows in an incremental manner, by\nsuccessively refining the workflow, by indicating desired changes (e.g.,\nexclusion of certain services, modifications of the desired output). This leads\nto the need of successive iterations of incremental replanning, to develop a\nnew workflow that integrates the requested changes while minimizing the changes\nto the original workflow. This paper illustrates how Phylotastic has addressed\nthe challenges of creating and refining phylogenetic analysis workflows using\nlogic programming technology and how such solutions have been used within the\ngeneral framework of the Phylotastic project. Under consideration in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 04:54:45 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Nguyen", "Thanh Hai", ""], ["Pontelli", "Enrico", ""], ["Son", "Tran Cao", ""]]}, {"id": "1805.00289", "submitter": "Marco Paviotti", "authors": "Rasmus E. M{\\o}gelberg and Marco Paviotti", "title": "Denotational semantics of recursive types in synthetic guarded domain\n  theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Just like any other branch of mathematics, denotational semantics of\nprogramming languages should be formalised in type theory, but adapting\ntraditional domain theoretic semantics, as originally formulated in classical\nset theory to type theory has proven challenging. This paper is part of a\nproject on formulating denotational semantics in type theories with guarded\nrecursion. This should have the benefit of not only giving simpler semantics\nand proofs of properties such as adequacy, but also hopefully in the future to\nscale to languages with advanced features, such as general references, outside\nthe reach of traditional domain theoretic techniques. Working in Guarded\nDependent Type Theory (GDTT), we develop denotational semantics for FPC, the\nsimply typed lambda calculus extended with recursive types, modelling the\nrecursive types of FPC using the guarded recursive types of GDTT. We prove\nsoundness and computational adequacy of the model in GDTT using a logical\nrelation between syntax and semantics constructed also using guarded recursive\ntypes. The denotational semantics is intensional in the sense that it counts\nthe number of unfold-fold reductions needed to compute the value of a term, but\nwe construct a relation relating the denotations of extensionally equal terms,\ni.e., pairs of terms that compute the same value in a different number of\nsteps. Finally we show how the denotational semantics of terms can be executed\ninside type theory and prove that executing the denotation of a boolean term\ncomputes the same value as the operational semantics of FPC.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 12:26:33 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 12:02:20 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["M\u00f8gelberg", "Rasmus E.", ""], ["Paviotti", "Marco", ""]]}, {"id": "1805.00304", "submitter": "Alexander Maletzky", "authors": "Alexander Maletzky and Fabian Immler", "title": "Gr\\\"obner Bases of Modules and Faug\\`ere's $F_4$ Algorithm in\n  Isabelle/HOL", "comments": "extended version of paper submitted to CICM2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an elegant, generic and extensive formalization of Gr\\\"obner bases\nin Isabelle/HOL. The formalization covers all of the essentials of the theory\n(polynomial reduction, S-polynomials, Buchberger's algorithm, Buchberger's\ncriteria for avoiding useless pairs), but also includes more advanced features\nlike reduced Gr\\\"obner bases. Particular highlights are the first-time\nformalization of Faug\\`ere's matrix-based $F_4$ algorithm and the fact that the\nentire theory is formulated for modules and submodules rather than rings and\nideals. All formalized algorithms can be translated into executable code\noperating on concrete data structures, enabling the certified computation of\n(reduced) Gr\\\"obner bases and syzygy modules.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 13:06:56 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Maletzky", "Alexander", ""], ["Immler", "Fabian", ""]]}, {"id": "1805.00468", "submitter": "Benjamin Sherman", "authors": "Benjamin Sherman, Luke Sciarappa, Adam Chlipala, Michael Carbin", "title": "Computable decision making on the reals and other spaces via partiality\n  and nondeterminism", "comments": "This is an extended version of a paper due to appear in the\n  proceedings of the ACM/IEEE Symposium on Logic in Computer Science (LICS) in\n  July 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though many safety-critical software systems use floating point to represent\nreal-world input and output, programmers usually have idealized versions in\nmind that compute with real numbers. Significant deviations from the ideal can\ncause errors and jeopardize safety. Some programming systems implement exact\nreal arithmetic, which resolves this matter but complicates others, such as\ndecision making. In these systems, it is impossible to compute (total and\ndeterministic) discrete decisions based on connected spaces such as\n$\\mathbb{R}$. We present programming-language semantics based on constructive\ntopology with variants allowing nondeterminism and/or partiality. Either\nnondeterminism or partiality suffices to allow computable decision making on\nconnected spaces such as $\\mathbb{R}$. We then introduce pattern matching on\nspaces, a language construct for creating programs on spaces, generalizing\npattern matching in functional programming, where patterns need not represent\ndecidable predicates and also may overlap or be inexhaustive, giving rise to\nnondeterminism or partiality, respectively. Nondeterminism and/or partiality\nalso yield formal logics for constructing approximate decision procedures. We\nimplemented these constructs in the Marshall language for exact real\narithmetic.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 17:58:14 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Sherman", "Benjamin", ""], ["Sciarappa", "Luke", ""], ["Chlipala", "Adam", ""], ["Carbin", "Michael", ""]]}, {"id": "1805.00512", "submitter": "Raphaelle Crubill\\'e", "authors": "Rapha\\\"elle Crubill\\'e", "title": "Probabilistic Stable Functions on Discrete Cones are Power Series (long\n  version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the category Cstabm of measurable cones and measurable stable\nfunctions, which is a denotational model of an higher-order language with\ncontinuous probabilities and full recursion. We look at Cstabm as a model for\ndiscrete probabilities, by showing the existence of a cartesian closed, full\nand faithful functor which embeds probabilistic coherence spaces (a fully\nabstract denotational model of an higher-order language with full recursion and\ndiscrete probabilities) into Cstabm. The proof is based on a generalization of\nBernstein's theorem from real analysis allowing to see stable functions between\ndiscrete cones as generalized power series.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 18:51:53 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Crubill\u00e9", "Rapha\u00eblle", ""]]}, {"id": "1805.00660", "submitter": "Pedro Cabalar", "authors": "Pedro Cabalar, Jorge Fandinno, Luis Fari\\~nas del Cerro and David\n  Pearce", "title": "Functional ASP with Intensional Sets: Application to Gelfond-Zhang\n  Aggregates", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 16 pages,\n  LaTeX, 0 PDF figures (arXiv:)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a variant of Answer Set Programming (ASP) with\nevaluable functions that extends their application to sets of objects,\nsomething that allows a fully logical treatment of aggregates. Formally, we\nstart from the syntax of First Order Logic with equality and the semantics of\nQuantified Equilibrium Logic with evaluable functions (QELF). Then, we proceed\nto incorporate a new kind of logical term, intensional set (a construct\ncommonly used to denote the set of objects characterised by a given formula),\nand to extend QELF semantics for this new type of expression. In our extended\napproach, intensional sets can be arbitrarily used as predicate or function\narguments or even nested inside other intensional sets, just as regular\nfirst-order logical terms. As a result, aggregates can be naturally formed by\nthe application of some evaluable function (count, sum, maximum, etc) to a set\nof objects expressed as an intensional set. This approach has several\nadvantages. First, while other semantics for aggregates depend on some\nsyntactic transformation (either via a reduct or a formula translation), the\nQELF interpretation treats them as regular evaluable functions, providing a\ncompositional semantics and avoiding any kind of syntactic restriction. Second,\naggregates can be explicitly defined now within the logical language by the\nsimple addition of formulas that fix their meaning in terms of multiple\napplications of some (commutative and associative) binary operation. For\ninstance, we can use recursive rules to define sum in terms of integer\naddition. Last, but not least, we prove that the semantics we obtain for\naggregates coincides with the one defined by Gelfond and Zhang for the Alog\nlanguage, when we restrict to that syntactic fragment. (Under consideration for\nacceptance in TPLP)\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 07:58:55 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["del Cerro", "Luis Fari\u00f1as", ""], ["Pearce", "David", ""]]}, {"id": "1805.00748", "submitter": "Salomon Sickert", "authors": "Javier Esparza and Jan Kretinsky and Salomon Sickert", "title": "One Theorem to Rule Them All: A Unified Translation of LTL into\n  {\\omega}-Automata", "comments": null, "journal-ref": null, "doi": "10.1145/3209108.3209161", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified translation of LTL formulas into deterministic Rabin\nautomata, limit-deterministic B\\\"uchi automata, and nondeterministic B\\\"uchi\nautomata. The translations yield automata of asymptotically optimal size\n(double or single exponential, respectively). All three translations are\nderived from one single Master Theorem of purely logical nature. The Master\nTheorem decomposes the language of a formula into a positive boolean\ncombination of languages that can be translated into {\\omega}-automata by\nelementary means. In particular, Safra's, ranking, and breakpoint constructions\nused in other translations are not needed.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 11:55:07 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Esparza", "Javier", ""], ["Kretinsky", "Jan", ""], ["Sickert", "Salomon", ""]]}, {"id": "1805.01325", "submitter": "Li Zhang", "authors": "Li Zhang", "title": "Choice revision on belief bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution we explore choice revision, a sort of belief change in\nwhich the new information is represented by a set of sentences and the agent\ncould accept some of the sentences while rejecting the others. We propose a\ngeneralized version of expansion operation called partial expansion for\ndeveloping models of choice revision. By using the partial expansion and two\nmultiple contraction operations previously introduced in the literature, we\nconstruct two kinds of choice revision on belief bases. For each of them we\npropose a set of postulates and prove a partial or full representation theorem.\nFurthermore, we investigate the operations of making up one's mind derived from\nthese two kinds of choice revision and also give the associated representation\ntheorems.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 14:30:20 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Zhang", "Li", ""]]}, {"id": "1805.01388", "submitter": "Rens Wouter van der Heijden", "authors": "Rens Wouter van der Heijden, Henning Kopp, Frank Kargl", "title": "Multi-Source Fusion Operations in Subjective Logic", "comments": "8 pages, Pre-Print of accepted paper for FUSION 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of multi-source fusion is to combine information from more than\ntwo evidence sources, or subjective opinions from multiple actors. For\nsubjective logic, a number of different fusion operators have been proposed,\neach matching a fusion scenario with different assumptions. However, not all of\nthese operators are associative, and therefore multi-source fusion is not\nwell-defined for these settings. In this paper, we address this challenge, and\ndefine multi-source fusion for weighted belief fusion (WBF) and consensus &\ncompromise fusion (CCF). For WBF, we show the definition to be equivalent to\nthe intuitive formulation under the bijective mapping between subjective logic\nand Dirichlet evidence PDFs. For CCF, since there is no independent\ngeneralization, we show that the resulting multi-source fusion produces valid\nopinions, and explain why our generalization is sound. For completeness, we\nalso provide corrections to previous results for averaging and cumulative\nbelief fusion (ABF and CBF), as well as belief constraint fusion (BCF), which\nis an extension of Dempster's rule. With our generalizations of fusion\noperators, fusing information from multiple sources is now well-defined for all\ndifferent fusion types defined in subjective logic. This enables wider\napplicability of subjective logic in applications where multiple actors\ninteract.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 16:02:24 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["van der Heijden", "Rens Wouter", ""], ["Kopp", "Henning", ""], ["Kargl", "Frank", ""]]}, {"id": "1805.01396", "submitter": "David Jaime Tena Cucala", "authors": "David Tena Cucala, Bernardo Cuenca Grau, Ian Horrocks", "title": "Consequence-based Reasoning for Description Logics with Disjunction,\n  Inverse Roles, Number Restrictions, and Nominals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a consequence-based calculus for concept subsumption and\nclassification in the description logic ALCHOIQ, which extends ALC with role\nhierarchies, inverse roles, number restrictions, and nominals. By using\nstandard transformations, our calculus extends to SROIQ, which covers all of\nOWL 2 DL except for datatypes. A key feature of our calculus is its\npay-as-you-go behaviour: unlike existing algorithms, our calculus is worst-case\noptimal for all the well-known proper fragments of ALCHOIQ, albeit not for the\nfull logic.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 16:06:51 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Cucala", "David Tena", ""], ["Grau", "Bernardo Cuenca", ""], ["Horrocks", "Ian", ""]]}, {"id": "1805.01681", "submitter": "Ian Hayes", "authors": "Ian J. Hayes and Larissa A. Meinicke", "title": "Encoding fairness in a synchronous concurrent program algebra: extended\n  version with proofs", "comments": "Formal Methods 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent program refinement algebra provides a suitable basis for\nsupporting mechanised reasoning about shared-memory concurrent programs in a\ncompositional manner, for example, it supports the rely/guarantee approach of\nJones. The algebra makes use of a synchronous parallel operator motivated by\nAczel's trace model of concurrency and with similarities to Milner's SCCS. This\npaper looks at defining a form of fairness within the program algebra. The\nencoding allows one to reason about the fair execution of a single process in\nisolation as well as define fair-parallel in terms of a base parallel operator,\nof which no fairness properties are assumed. An algebraic theory to support\nfairness and fair-parallel is developed.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 09:35:41 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Hayes", "Ian J.", ""], ["Meinicke", "Larissa A.", ""]]}, {"id": "1805.01823", "submitter": "Jakub Gajarsk\\'y", "authors": "Jakub Gajarsk\\'y, Petr Hlin\\v{e}n\\'y, Daniel Lokshtanov, Jan\n  Obdr\\v{z}\\'alek, M.S. Ramanujan", "title": "A New Perspective on FO Model Checking of Dense Graph Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the first-order (FO) model checking problem of dense graphs, namely\nthose which have FO interpretations in (or are FO transductions of) some sparse\ngraph classes. We give a structural characterization of the graph classes which\nare FO interpretable in graphs of bounded degree. This characterization allows\nus to efficiently compute such an FO interpretation for an input graph. As a\nconsequence, we obtain an FPT algorithm for successor-invariant FO model\nchecking of any graph class which is FO interpretable in (or an FO transduction\nof) a graph class of bounded degree. The approach we use to obtain these\nresults may also be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 15:29:16 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Gajarsk\u00fd", "Jakub", ""], ["Hlin\u011bn\u00fd", "Petr", ""], ["Lokshtanov", "Daniel", ""], ["Obdr\u017e\u00e1lek", "Jan", ""], ["Ramanujan", "M. S.", ""]]}, {"id": "1805.02004", "submitter": "Yohji Akama", "authors": "Yohji Akama", "title": "Confluent terminating extensional lambda-calculi with surjective pairing\n  and terminal type", "comments": "22 page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the lambda-calculus with surjective pairing and terminal type, Curien and\nDi Cosmo were inspired by Knuth-Bendix completion, and introduced a confluent\nrewriting system that (1) extends the naive rewriting system, and (2) is stable\nunder contexts. The rewriting system has (i) a rule that rewrites term of a\nterminal type rewrites to a term constant *, unless the term is not *, (ii)\nrewrite rules for the extensionality of function types and product types, and\nrewrite rules mediating the rewrite rules (i) and (ii). Curien and Di Cosmo\nsupposed that because of (iii), any reducibility method cannot prove the strong\nnormalization (SN) of Curien-Di Cosmo's rewriting system, and they left the SN\nopen. By relativizing Girard's reducibility method to the *-free terms, we\nprove SN of their rewriting, and SN of the extension by polymorphism.\n  The relativization works because: for any SN term t, and for any variable z\nof terminal type not occurring in $t$, t with all the occurrences of * of\nterminal type replaced by the variable z is SN.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 05:31:03 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Akama", "Yohji", ""]]}, {"id": "1805.02038", "submitter": "Barnaby Martin", "authors": "Barnaby Martin, Peter Jonsson, Manuel Bodirsky, Antoine Mottet", "title": "Classification transfer for qualitative reasoning problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study formalisms for temporal and spatial reasoning in the modern context\nof Constraint Satisfaction Problems (CSPs). We show how questions on the\ncomplexity of their subclasses can be solved using existing results via the\npowerful use of primitive positive (pp) interpretations and pp-homotopy. We\ndemonstrate the methodology by giving a full complexity classification of all\nconstraint languages that are first-order definable in Allen's Interval Algebra\nand contain the basic relations (s) and (f). In the case of the Rectangle\nAlgebra we answer in the affirmative the old open question as to whether\nORD-Horn is a maximally tractable subset among the (disjunctive, binary)\nrelations. We then generalise our results for the Rectangle Algebra to the\nr-dimensional Block Algebra.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 10:31:10 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Martin", "Barnaby", ""], ["Jonsson", "Peter", ""], ["Bodirsky", "Manuel", ""], ["Mottet", "Antoine", ""]]}, {"id": "1805.02069", "submitter": "Nicolai Kraus", "authors": "Nicolai Kraus and Thorsten Altenkirch", "title": "Free Higher Groups in Homotopy Type Theory", "comments": "v1: 19 pages, published version; v2: fix typo", "journal-ref": "LICS '18: Proceedings of the 33rd Annual ACM/IEEE Symposium on\n  Logic in Computer Science, 2018", "doi": "10.1145/3209108.3209183", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a type A in homotopy type theory (HoTT), we can define the free\ninfinity-group on A as the loop space of the suspension of A+1. Equivalently,\nthis free higher group can be defined as a higher inductive type F(A) with\nconstructors unit : F(A), cons : A -> F(A) -> F(A), and conditions saying that\nevery cons(a) is an auto-equivalence on F(A). Assuming that A is a set (i.e.\nsatisfies the principle of unique identity proofs), we are interested in the\nquestion whether F(A) is a set as well, which is very much related to an open\nproblem in the HoTT book. We show an approximation to the question, namely that\nthe fundamental groups of F(A) are trivial, i.e. that the 1-truncation of F(A)\nis a set.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 15:30:03 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 13:56:29 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Kraus", "Nicolai", ""], ["Altenkirch", "Thorsten", ""]]}, {"id": "1805.02709", "submitter": "William Farmer", "authors": "Jacques Carette and William M. Farmer and Yasmine Sharoda", "title": "Biform Theories: Project Description", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A biform theory is a combination of an axiomatic theory and an algorithmic\ntheory that supports the integration of reasoning and computation. These are\nideal for specifying and reasoning about algorithms that manipulate\nmathematical expressions. However, formalizing biform theories is challenging\nsince it requires the means to express statements about the interplay of what\nthese algorithms do and what their actions mean mathematically. This paper\ndescribes a project to develop a methodology for expressing, manipulating,\nmanaging, and generating mathematical knowledge as a network of biform\ntheories. It is a subproject of MathScheme, a long-term project at McMaster\nUniversity to produce a framework for integrating formal deduction and symbolic\ncomputation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 18:06:01 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 15:51:42 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Carette", "Jacques", ""], ["Farmer", "William M.", ""], ["Sharoda", "Yasmine", ""]]}, {"id": "1805.02724", "submitter": "Thorsten Wissmann", "authors": "Marcelo Arenas, Martin Mu\\~noz and Cristian Riveros", "title": "Descriptive Complexity for Counting Complexity Classes", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (February\n  10, 2020) lmcs:6079", "doi": "10.23638/LMCS-16(1:9)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Descriptive Complexity has been very successful in characterizing complexity\nclasses of decision problems in terms of the properties definable in some\nlogics. However, descriptive complexity for counting complexity classes, such\nas FP and #P, has not been systematically studied, and it is not as developed\nas its decision counterpart. In this paper, we propose a framework based on\nWeighted Logics to address this issue. Specifically, by focusing on the natural\nnumbers we obtain a logic called Quantitative Second Order Logics (QSO), and\nshow how some of its fragments can be used to capture fundamental counting\ncomplexity classes such as FP, #P and FPSPACE, among others. We also use QSO to\ndefine a hierarchy inside #P, identifying counting complexity classes with good\nclosure and approximation properties, and which admit natural complete\nproblems. Finally, we add recursion to QSO, and show how this extension\nnaturally captures lower counting complexity classes such as #L.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 20:02:30 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 18:09:23 GMT"}, {"version": "v3", "created": "Sun, 25 Aug 2019 23:55:44 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 07:01:30 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Arenas", "Marcelo", ""], ["Mu\u00f1oz", "Martin", ""], ["Riveros", "Cristian", ""]]}, {"id": "1805.02795", "submitter": "Tianheng Tsui", "authors": "Tianheng Tsui", "title": "A new viewpoint of the G\\\"odel's incompleteness theorem and its\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new viewpoint of the G\\\"odel's incompleteness theorem be given in this\narticle which reveals the deep relationship between the logic and computation.\nUpon the results of these studies, an algorithm be given which shows how to\nsearch a proof of statement in first order logic from finite concrete examples,\nand an approach be proposed to improve searching mathematical proof by neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 01:18:11 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Tsui", "Tianheng", ""]]}, {"id": "1805.02858", "submitter": "Adnan Rashid", "authors": "Adnan Rashid and Osman Hasan", "title": "Formal Analysis of Robotic Cell Injection Systems using Theorem Proving", "comments": "16 pages", "journal-ref": "LNCS special issue on the theme of CyPhy 2017", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell injection is an approach used for the delivery of small sample\nsubstances into a biological cell and is widely used in drug development, gene\ninjection, intracytoplasmic sperm injection (ICSI) and in-virto fertilization\n(IVF). Robotic cell injection systems provide the automation of the process as\nopposed to the manual and semi-automated cell injection systems, which require\nexpert operators and involve time consuming processes and also have lower\nsuccess rates. The automation of the cell injection process is achieved by\ncontrolling the injection force and planning the motion of the injection\npipette. Traditionally, these systems are analyzed using paper-and-pencil proof\nand computer simulation methods. However, the former is human-error prone and\nthe later is based on the numerical algorithms, where the approximation of the\nmathematical expressions introduces inaccuracies in the analysis. Formal\nmethods can overcome these limitations and thus provide an accurate analysis of\nthe cell injection systems. Model checking, i.e., a state-based formal method,\nhas been recently proposed for the analysis of these systems. However, it\ninvolves the discretization of the differential equations that are used for\nmodeling the dynamics of the system and thus compromises on the completeness of\nthe analysis of these safety-critical systems. In this paper, we propose to use\nhigher-order-logic theorem proving, a deductive-reasoning based formal method,\nfor the modeling and analysis of the dynamical behaviour of the robotic cell\ninjection systems. The proposed analysis, based on the HOL Light theorem\nprover, enabled us to identify some discrepancies in the simulation and model\nchecking based analysis of the same robotic cell injection system.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 06:57:02 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Rashid", "Adnan", ""], ["Hasan", "Osman", ""]]}, {"id": "1805.02859", "submitter": "Duligur Ibeling", "authors": "Duligur Ibeling, Thomas Icard", "title": "On the Conditional Logic of Simulation Models", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose analyzing conditional reasoning by appeal to a notion of\nintervention on a simulation program, formalizing and subsuming a number of\napproaches to conditional thinking in the recent AI literature. Our main\nresults include a series of axiomatizations, allowing comparison between this\nframework and existing frameworks (normality-ordering models, causal structural\nequation models), and a complexity result establishing NP-completeness of the\nsatisfiability problem. Perhaps surprisingly, some of the basic logical\nprinciples common to all existing approaches are invalidated in our causal\nsimulation approach. We suggest that this additional flexibility is important\nin modeling some intuitive examples.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 07:08:13 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Ibeling", "Duligur", ""], ["Icard", "Thomas", ""]]}, {"id": "1805.02912", "submitter": "Christoph Schwering", "authors": "Yijia Chen, Abdallah Saffidine, Christoph Schwering", "title": "The Complexity of Limited Belief Reasoning -- The Quantifier-Free Case", "comments": "15 pages, 1 figure, 1 table, Twenty-seventh International Joint\n  Conference on Artificial Intelligence (IJCAI-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical view of epistemic logic is that an agent knows all the logical\nconsequences of their knowledge base. This assumption of logical omniscience is\noften unrealistic and makes reasoning computationally intractable. One approach\nto avoid logical omniscience is to limit reasoning to a certain belief level,\nwhich intuitively measures the reasoning \"depth.\" This paper investigates the\ncomputational complexity of reasoning with belief levels. First we show that\nwhile reasoning remains tractable if the level is constant, the complexity\njumps to PSPACE-complete -- that is, beyond classical reasoning -- when the\nbelief level is part of the input. Then we further refine the picture using\nparameterized complexity theory to investigate how the belief level and the\nnumber of non-logical symbols affect the complexity.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 09:20:21 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Chen", "Yijia", ""], ["Saffidine", "Abdallah", ""], ["Schwering", "Christoph", ""]]}, {"id": "1805.02946", "submitter": "Tobias Meggendorfer", "authors": "Jan K\\v{r}et\\'insk\\'y, Tobias Meggendorfer", "title": "Conditional Value-at-Risk for Reachability and Mean Payoff in Markov\n  Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the conditional value-at-risk (CVaR) in the context of Markov\nchains and Markov decision processes with reachability and mean-payoff\nobjectives. CVaR quantifies risk by means of the expectation of the worst\np-quantile. As such it can be used to design risk-averse systems. We consider\nnot only CVaR constraints, but also introduce their conjunction with\nexpectation constraints and quantile constraints (value-at-risk, VaR). We\nderive lower and upper bounds on the computational complexity of the respective\ndecision problems and characterize the structure of the strategies in terms of\nmemory and randomization.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 11:13:28 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Meggendorfer", "Tobias", ""]]}, {"id": "1805.02963", "submitter": "Sebastian Muskalla", "authors": "Matthew Hague, Roland Meyer, Sebastian Muskalla, Martin Zimmermann", "title": "Parity to Safety in Polynomial Time for Pushdown and Collapsible\n  Pushdown Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a direct polynomial-time reduction from parity games played over the\nconfiguration graphs of collapsible pushdown systems to safety games played\nover the same class of graphs. That a polynomial-time reduction would exist was\nknown since both problems are complete for the same complexity class. Coming up\nwith a direct reduction, however, has been an open problem. Our solution to the\npuzzle brings together a number of techniques for pushdown games and adds three\nnew ones. This work contributes to a recent trend of liveness to safety\nreductions which allow the advanced state-of-the-art in safety checking to be\nused for more expressive specifications.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 12:04:03 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 15:06:40 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Hague", "Matthew", ""], ["Meyer", "Roland", ""], ["Muskalla", "Sebastian", ""], ["Zimmermann", "Martin", ""]]}, {"id": "1805.03028", "submitter": "Alexis B\\`es", "authors": "Alexis B\\`es, Christian Choffrut", "title": "Decidability of the existential fragment of some infinitely generated\n  trace monoids: an application to ordinals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diekert, Matiyasevich and Muscholl proved that the existential first-order\ntheory of a trace monoid over a finite alphabet is decidable. We extend this\nresult to a natural class of trace monoids with infinitely many generators. As\nan application, we prove that for every ordinal $\\lambda$ less than\n$\\varepsilon_0$, the existential theory of the set of successor ordinals less\nthan $\\lambda$ equipped with multiplication is decidable.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 14:00:05 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 07:14:31 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["B\u00e8s", "Alexis", ""], ["Choffrut", "Christian", ""]]}, {"id": "1805.03032", "submitter": "Fabio Zanasi", "authors": "Fabio Zanasi", "title": "Interacting Hopf Algebras: the theory of linear systems", "comments": "PhD thesis manuscript, defended on October 5, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As first main contribution, this thesis characterises the PROP SVk of linear\nsubspaces over a field k - an important domain of interpretation for circuit\ndiagrams appearing in diverse research areas. We present by generators and\nequations the PROP IH of string diagrams whose free model is SVk. IH stands for\ninteracting Hopf algebras: its equations arise by distributive laws between\nHopf algebras, which we obtain using Lack's technique for composing PROPs. The\nsignificance of the result is two-fold. First, it offers a canonical\ndiagrammatic syntax for linear algebra: linear maps, kernels, subspaces, etc...\nare all faithfully represented in the graphical language. Second, the equations\nof IH describe familiar algebraic structures - Hopf algebras and Frobenius\nalgebras - which are at the heart of graphical formalisms as seemingly diverse\nas quantum circuits, signal flow graphs, simple electrical circuits and Petri\nnets. Our characterisation enlightens the provenance of these axioms and\nreveals their linear algebraic nature. Our second main contribution is an\napplication of IH to the semantics of signal processing circuits. We develop a\nformal theory of signal flow graphs, featuring a diagrammatic circuit syntax, a\nstructural operational semantics and a denotational semantics. We prove\ncompleteness of the equations of IH for denotational equivalence. Also, we\nstudy full abstraction: it turns out that the purely operational picture is too\nconcrete - two denotationally equal graphs may exhibit different operational\nbehaviour. We classify the ways in which this can occur and show that any graph\ncan be realised - rewritten, using the equations of IH, into an executable form\nwhere the operational behaviour and the denotation coincide. This realisability\ntheorem suggests a reflection about the role of causality in the semantics of\nsignal flow graphs and, more generally, of computing devices.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 08:17:24 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Zanasi", "Fabio", ""]]}, {"id": "1805.03107", "submitter": "Michael F\\\"arber", "authors": "Michael F\\\"arber, Cezary Kaliszyk, Josef Urban", "title": "Machine Learning Guidance and Proof Certification for Connection\n  Tableaux", "comments": "Submitted to JAR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Connection calculi allow for very compact implementations of goal-directed\nproof search. We give an overview of our work related to connection tableaux\ncalculi: First, we show optimised functional implementations of clausal and\nnonclausal proof search, including a consistent Skolemisation procedure for\nmachine learning. Then, we show two guidance methods based on machine learning,\nnamely reordering of proof steps with Naive Bayesian probablities, and\nexpansion of a proof search tree with Monte Carlo Tree Search. Finally, we give\na translation of connection proofs to LK, enabling proof certification and\nautomatic proof search in interactive theorem provers.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 15:30:20 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 14:51:37 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 07:35:16 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["F\u00e4rber", "Michael", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1805.03151", "submitter": "Davide Giacomo Cavezza", "authors": "Davide G. Cavezza, Dalal Alrajeh, Andr\\'as Gy\\\"orgy", "title": "A Weakness Measure for GR(1) Formulae", "comments": "To appear in FM2018 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the theoretical and algorithmic developments for system synthesis\nin recent years, little effort has been dedicated to quantifying the quality of\nthe specifications used for synthesis. When dealing with unrealizable\nspecifications, finding the weakest environment assumptions that would ensure\nrealizability is typically a desirable property; in such context the weakness\nof the assumptions is a major quality parameter. The question of whether one\nassumption is weaker than another is commonly interpreted using implication or,\nequivalently, language inclusion. However, this interpretation does not provide\nany further insight into the weakness of assumptions when implication does not\nhold. To our knowledge, the only measure that is capable of comparing two\nformulae in this case is entropy, but even it fails to provide a sufficiently\nrefined notion of weakness in case of GR(1) formulae, a subset of linear\ntemporal logic formulae which is of particular interest in controller\nsynthesis. In this paper we propose a more refined measure of weakness based on\nthe Hausdorff dimension, a concept that captures the notion of size of the\nomega-language satisfying a linear temporal logic formula. We identify the\nconditions under which this measure is guaranteed to distinguish between weaker\nand stronger GR(1) formulae. We evaluate our proposed weakness measure in the\ncontext of computing GR(1) assumptions refinements.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 16:39:31 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Cavezza", "Davide G.", ""], ["Alrajeh", "Dalal", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""]]}, {"id": "1805.03496", "submitter": "Tom van Dijk", "authors": "Tom van Dijk and R\\\"udiger Ehlers and Armin Biere", "title": "Revisiting Decision Diagrams for SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic variants of clause distribution using decision diagrams to eliminate\nvariables in SAT were shown to perform well on hard combinatorial instances. In\nthis paper we revisit both existing ZDD and BDD variants of this approach. We\nfurther investigate different heuristics for selecting the next variable to\neliminate. Our implementation makes further use of parallel features of the\nopen source BDD library Sylvan.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 13:16:42 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["van Dijk", "Tom", ""], ["Ehlers", "R\u00fcdiger", ""], ["Biere", "Armin", ""]]}, {"id": "1805.03575", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Reversible Truly Concurrent Process Algebra", "comments": "40 pages. arXiv admin note: substantial text overlap with\n  arXiv:1410.5131, arXiv:1611.09035, arXiv:1703.00159", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a reversible version of truly concurrent process algebra CTC which\nis called RCTC. It has good properties modulo several kinds of strongly\nforward-reverse truly concurrent bisimulations and weakly forward-reverse truly\nconcurrent bisimulations. These properties include monoid laws, static laws,\nnew expansion law for strongly forward-reverse truly concurrent bisimulations,\n\\tau laws for weakly forward-reverse truly concurrent bisimulations, and\ncongruences for strongly and weakly forward-reverse truly concurrent\nbisimulations.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 13:27:54 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "1805.03624", "submitter": "Hieronymi, Philipp", "authors": "Philipp Hieronymi, Danny Nguyen and Igor Pak", "title": "Presburger Arithmetic with algebraic scalar multiplications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider Presburger arithmetic (PA) extended by scalar multiplication by\nan algebraic irrational number $\\alpha$, and call this extension\n$\\alpha$-Presburger arithmetic ($\\alpha$-PA). We show that the complexity of\ndeciding sentences in $\\alpha$-PA is substantially harder than in PA. Indeed,\nwhen $\\alpha$ is quadratic and $r\\geq 4$, deciding $\\alpha$-PA sentences with\n$r$ alternating quantifier blocks and at most $c\\ r$ variables and inequalities\nrequires space at least $K 2^{\\cdot^{\\cdot^{\\cdot^{2^{C\\ell(S)}}}}}$ (tower of\nheight $r-3$), where the constants $c, K, C>0$ only depend on $\\alpha$, and\n$\\ell(S)$ is the length of the given $\\alpha$-PA sentence $S$. Furthermore\ndeciding $\\exists^{6}\\forall^{4}\\exists^{11}$ $\\alpha$-PA sentences with at\nmost $k$ inequalities is PSPACE-hard, where $k$ is another constant depending\nonly on~$\\alpha$. When $\\alpha$ is non-quadratic, already four alternating\nquantifier blocks suffice for undecidability of $\\alpha$-PA sentences.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 17:21:29 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 05:34:42 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 01:30:50 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 14:20:42 GMT"}, {"version": "v5", "created": "Thu, 25 Mar 2021 14:12:43 GMT"}, {"version": "v6", "created": "Fri, 21 May 2021 14:44:42 GMT"}, {"version": "v7", "created": "Mon, 19 Jul 2021 13:10:36 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Hieronymi", "Philipp", ""], ["Nguyen", "Danny", ""], ["Pak", "Igor", ""]]}, {"id": "1805.03740", "submitter": "Benedikt Ahrens", "authors": "Benedikt Ahrens, Andr\\'e Hirschowitz, Ambroise Lafont, Marco Maggesi", "title": "Presentable signatures and initial semantics", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (May 26,\n  2021) lmcs:7511", "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a device for specifying and reasoning about syntax for datatypes,\nprogramming languages, and logic calculi. More precisely, we study a notion of\n\"signature\" for specifying syntactic constructions.\n  In the spirit of Initial Semantics, we define the \"syntax generated by a\nsignature\" to be the initial object -- if it exists -- in a suitable category\nof models. In our framework, the existence of an associated syntax to a\nsignature is not automatically guaranteed. We identify, via the notion of\npresentation of a signature, a large class of signatures that do generate a\nsyntax.\n  Our (presentable) signatures subsume classical algebraic signatures (i.e.,\nsignatures for languages with variable binding, such as the pure lambda\ncalculus) and extend them to include several other significant examples of\nsyntactic constructions.\n  One key feature of our notions of signature, syntax, and presentation is that\nthey are highly compositional, in the sense that complex examples can be\nobtained by gluing simpler ones. Moreover, through the Initial Semantics\napproach, our framework provides, beyond the desired algebra of terms, a\nwell-behaved substitution and the induction and recursion principles associated\nto the syntax.\n  This paper builds upon ideas from a previous attempt by Hirschowitz-Maggesi,\nwhich, in turn, was directly inspired by some earlier work of\nGhani-Uustalu-Hamana and Matthes-Uustalu.\n  The main results presented in the paper are computer-checked within the\nUniMath system.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 21:32:06 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 14:48:29 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 16:07:36 GMT"}, {"version": "v4", "created": "Sun, 2 May 2021 13:48:54 GMT"}, {"version": "v5", "created": "Tue, 25 May 2021 11:17:37 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ahrens", "Benedikt", ""], ["Hirschowitz", "Andr\u00e9", ""], ["Lafont", "Ambroise", ""], ["Maggesi", "Marco", ""]]}, {"id": "1805.03852", "submitter": "Yanjing Wang", "authors": "Yanjing Wang and Jeremy Seligman", "title": "When Names Are Not Commonly Known: Epistemic Logic with Assignments", "comments": "18 pages, to appear in proceedings of AiML2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard epistemic logic, agent names are usually assumed to be common\nknowledge implicitly. This is unreasonable for various applications. Inspired\nby term modal logic and assignment operators in dynamic logic, we introduce a\nlightweight modal predicate logic where names can be non-rigid. The language\ncan handle various de dicto and de re distinctions in a natural way. The main\ntechnical result is a complete axiomatisation of this logic over S5 models.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:56:53 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 16:51:53 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Wang", "Yanjing", ""], ["Seligman", "Jeremy", ""]]}, {"id": "1805.03934", "submitter": "Gabriele Vanoni", "authors": "Ugo Dal Lago, Gabriele Vanoni", "title": "On randomised strategies in the $\\lambda$-calculus (long version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study randomised reduction strategies,a notion already known\nin the context of abstract reduction systems, for the $\\lambda$-calculus. We\ndevelop a simple framework that allows us to prove a randomised strategy to be\npositive almost-surely normalising. Then we propose a simple example of\nrandomised strategy for the $\\lambda$-calculus that has such a property and we\nshow why it is non-trivial with respect to classical deterministic strategies\nsuch as leftmost-outermost or rightmost-innermost. We conclude studying this\nstrategy for two sub-$\\lambda$-calculi, namely those where duplication and\nerasure are syntactically forbidden, showing some non-trivial properties.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 12:18:14 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 20:11:24 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Vanoni", "Gabriele", ""]]}, {"id": "1805.04636", "submitter": "EPTCS", "authors": "R\\'egine Laleau (LACL, University of Paris-Est Cr\\'eteil, France),\n  Dominique M\\'ery (LORIA, University of Lorraine, France), Shin Nakajima\n  (National Institute of Informatics, Japan), Elena Troubitsyna (Abo Akademi\n  University, Turku, Finland)", "title": "Proceedings Joint Workshop on Handling IMPlicit and EXplicit knowledge\n  in formal system development (IMPEX) and Formal and Model-Driven Techniques\n  for Developing Trustworthy Systems (FM&MDD)", "comments": null, "journal-ref": "EPTCS 271, 2018", "doi": "10.4204/EPTCS.271", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the joint proceedings of IMPEX 2017, the first workshop\non Handling IMPlicit and EXplicit knowledge in formal system development and\nFM&MDD, the second workshop on Formal and Model-Driven Techniques for\nDeveloping Trustworthy Systems (FM&MDD) held together on November 16, 2017 in\nXi'an, China, as part of ICFEM 2017, 19th International Conference on Formal\nEngineering Methods.\n  IMPEX emphasises mechanisms for reducing heterogeneity of models induced by\nthe absence of explicit semantics expression in the formal techniques used to\nspecify these models. More precisely, the meeting targets to highlight the\nadvances in handling both implicit and explicit semantics in formal system\ndevelopments.\n  The aims of FM&MDD are to advance the understanding in the area of developing\nand applying formal and model-driven techniques for designing trustworthy\nsystems, to discuss the emerging issues in the area, to improve the dialog\nbetween different research communities and between academia and industry, to\ndiscuss a roadmap of the future research in the area and to create a forum for\ndiscussing and disseminating the new ideas and the research results in the area\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 02:29:42 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Laleau", "R\u00e9gine", "", "LACL, University of Paris-Est Cr\u00e9teil, France"], ["M\u00e9ry", "Dominique", "", "LORIA, University of Lorraine, France"], ["Nakajima", "Shin", "", "National Institute of Informatics, Japan"], ["Troubitsyna", "Elena", "", "Abo Akademi\n  University, Turku, Finland"]]}, {"id": "1805.05121", "submitter": "Mathias Soeken", "authors": "Mathias Soeken, Heinz Riener, Winston Haaswijk, Eleonora Testa, Bruno\n  Schmitt, Giulia Meuli, Fereshte Mozafari, Giovanni De Micheli", "title": "The EPFL Logic Synthesis Libraries", "comments": "11 pages, originally accepted at Int'l Workshop on Logic & Synthesis\n  2018, extended for Workshop on Open-Source EDA Technology 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a collection of modular open source C++ libraries for the\ndevelopment of logic synthesis applications. These libraries can be used to\ndevelop applications for the design of classical and emerging technologies, as\nwell as for the implementation of quantum compilers. All libraries are well\ndocumented and well tested. Furthermore, being header-only, the libraries can\nbe readily used as core components in complex logic synthesis systems.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 11:34:47 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 14:02:30 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Soeken", "Mathias", ""], ["Riener", "Heinz", ""], ["Haaswijk", "Winston", ""], ["Testa", "Eleonora", ""], ["Schmitt", "Bruno", ""], ["Meuli", "Giulia", ""], ["Mozafari", "Fereshte", ""], ["De Micheli", "Giovanni", ""]]}, {"id": "1805.05400", "submitter": "Christine Rizkallah", "authors": "Dmitri Garbuzov, William Mansky, Christine Rizkallah, Steve Zdancewic", "title": "Structural Operational Semantics for Control Flow Graph Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compilers use control flow graph (CFG) representations of low-level programs\nbecause they are suited to program analysis and optimizations. However,\nformalizing the behavior and metatheory of CFG programs is non-trivial: CFG\nprograms don't compose well, their semantics depends on auxiliary state, and,\nas a consequence, they do not enjoy a simple equational theory that can be used\nfor reasoning about the correctness of program transformations.\nLambda-calculus-based intermediate representations, in contrast, have\nwell-understood operational semantics and metatheory, including rich equational\ntheories, all of which makes them amenable to formal verification.\n  This paper establishes a tight equivalence between (a variant of) Levy's\ncall-by-push-value (CBPV) calculus and a control flow graph machine whose\ninstructions are in static single assignment (SSA) form. The correspondence is\nmade precise via a series of abstract machines that align the transitions of\nthe structural operational semantics of the CBPV language with the computation\nsteps of the SSA form.\n  The target machine, which is derived from the CBPV language, accurately\ncaptures the execution model of control flow graphs, including direct jumps,\nmutually recursive code blocks, and multi-argument function calls, and the\nclosure-free subset is similar to the SSA intermediate representations found in\nmodern compilers such as LLVM and GCC. The definitions of all the\nlanguage/abstract machine semantics and the theorems relating them are fully\nverified in Coq.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 19:41:47 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Garbuzov", "Dmitri", ""], ["Mansky", "William", ""], ["Rizkallah", "Christine", ""], ["Zdancewic", "Steve", ""]]}, {"id": "1805.05488", "submitter": "Curtis Bright", "authors": "Curtis Bright, Ilias Kotsireas, Albert Heinle, Vijay Ganesh", "title": "Enumeration of Complex Golay Pairs via Programmatic SAT", "comments": "Corrected typos", "journal-ref": null, "doi": "10.1145/3208976.3209006", "report-no": null, "categories": "cs.LO cs.SC math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a complete enumeration of all complex Golay pairs of length up to\n25, verifying that complex Golay pairs do not exist in lengths 23 and 25 but do\nexist in length 24. This independently verifies work done by F. Fiedler in 2013\nthat confirms the 2002 conjecture of Craigen, Holzmann, and Kharaghani that\ncomplex Golay pairs of length 23 don't exist. Our enumeration method relies on\nthe recently proposed SAT+CAS paradigm of combining computer algebra systems\nwith SAT solvers to take advantage of the advances made in the fields of\nsymbolic computation and satisfiability checking. The enumeration proceeds in\ntwo stages: First, we use a fine-tuned computer program and functionality from\ncomputer algebra systems to construct a list containing all sequences which\ncould appear as the first sequence in a complex Golay pair (up to equivalence).\nSecond, we use a programmatic SAT solver to construct all sequences (if any)\nthat pair off with the sequences constructed in the first stage to form a\ncomplex Golay pair.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 22:56:52 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 02:51:10 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Bright", "Curtis", ""], ["Kotsireas", "Ilias", ""], ["Heinle", "Albert", ""], ["Ganesh", "Vijay", ""]]}, {"id": "1805.05514", "submitter": "EPTCS", "authors": "Ahmed Al-Brashdi (University of Southampton), Michael Butler\n  (University of Southampton), Abdolbaghi Rezazadeh (University of Southampton)", "title": "Incremental Database Design using UML-B and Event-B", "comments": "In Proceedings IMPEX 2017 and FM&MDD 2017, arXiv:1805.04636", "journal-ref": "EPTCS 271, 2018, pp. 34-47", "doi": "10.4204/EPTCS.271.3", "report-no": null, "categories": "cs.DB cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correct operation of many critical systems is dependent on the data\nconsistency and integrity properties of underlying databases. Therefore, a\nverifiable and rigorous database design process is highly desirable. This\nresearch aims to investigate and deliver a comprehensive and practical approach\nfor modelling databases in formal methods through layered refinements. The\nmethodology is being guided by a number of case studies, using abstraction and\nrefinement in UML-B and verification with the Rodin tool. UML-B is a graphical\nrepresentation of the Event-B formalism and the Rodin tool supports\nverification for Event-B and UML-B. Our method guides developers to model\nrelational databases in UML-B through layered refinement and to specify the\nnecessary constraints and operations on the database.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 01:18:51 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Al-Brashdi", "Ahmed", "", "University of Southampton"], ["Butler", "Michael", "", "University of Southampton"], ["Rezazadeh", "Abdolbaghi", "", "University of Southampton"]]}, {"id": "1805.05515", "submitter": "EPTCS", "authors": "Sylvain Conchon (Universit\\'e Paris-Sud), David Declerck (Universit\\'e\n  Paris-Sud), Fatiha Za\\\"idi (Universit\\'e Paris-Sud)", "title": "Parameterized Model Checking Modulo Explicit Weak Memory Models", "comments": "In Proceedings IMPEX 2017 and FM&MDD 2017, arXiv:1805.04636", "journal-ref": "EPTCS 271, 2018, pp. 48-63", "doi": "10.4204/EPTCS.271.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modular framework for model checking parameterized array-based\ntransition systems with explicit access operations on weak memory. Our approach\nextends the MCMT (Model Checking Modulo Theories) framework of Ghilardi and\nRanise with explicit weak memory models. We have implemented this new framework\nin Cubicle-W, an extension of the Cubicle model checker. The modular\narchitecture of our tool allows us to change the underlying memory model\nseamlessly (TSO, PSO...). Our first experiments with a TSO-like memory model\nlook promising.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 01:19:21 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Conchon", "Sylvain", "", "Universit\u00e9 Paris-Sud"], ["Declerck", "David", "", "Universit\u00e9\n  Paris-Sud"], ["Za\u00efdi", "Fatiha", "", "Universit\u00e9 Paris-Sud"]]}, {"id": "1805.05518", "submitter": "EPTCS", "authors": "Yamine Ait Ameur (IRIT/INPT-ENSEEIHT, Toulouse, France), Idir Ait\n  Sadoune (LRI/CentraleSupelec/Paris-Saclay University, Plateau de Saclay,\n  France), Kahina Hacid (IRIT/INPT-ENSEEIHT, Toulouse, France), Linda Mohand\n  Oussaid (LRI/CentraleSupelec/Paris-Saclay University, Plateau de Saclay,\n  France)", "title": "Formal Modelling of Ontologies : An Event-B based Approach Using the\n  Rodin Platform", "comments": "In Proceedings IMPEX 2017 and FM&MDD 2017, arXiv:1805.04636", "journal-ref": "EPTCS 271, 2018, pp. 24-33", "doi": "10.4204/EPTCS.271.2", "report-no": null, "categories": "cs.SE cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on the results of the French ANR IMPEX research project\ndealing with making explicit domain knowledge in design models. Ontologies are\nformalised as theories with sets, axioms, theorems and reasoning rules. They\nare integrated to design models through an annotation mechanism. Event-B has\nbeen chosen as the ground formal modelling technique for all our developments.\nIn this paper, we particularly describe how ontologies are formalised as\nEvent-B theories.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 01:20:18 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Ameur", "Yamine Ait", "", "IRIT/INPT-ENSEEIHT, Toulouse, France"], ["Sadoune", "Idir Ait", "", "LRI/CentraleSupelec/Paris-Saclay University, Plateau de Saclay,\n  France"], ["Hacid", "Kahina", "", "IRIT/INPT-ENSEEIHT, Toulouse, France"], ["Oussaid", "Linda Mohand", "", "LRI/CentraleSupelec/Paris-Saclay University, Plateau de Saclay,\n  France"]]}, {"id": "1805.05521", "submitter": "EPTCS", "authors": "Inna Vistbakka ({\\AA}bo Akademi), Elena Troubitsyna ({\\AA}bo Akademi)", "title": "Towards Integrated Modelling of Dynamic Access Control with UML and\n  Event-B", "comments": "In Proceedings IMPEX 2017 and FM&MDD 2017, arXiv:1805.04636", "journal-ref": "EPTCS 271, 2018, pp. 105-116", "doi": "10.4204/EPTCS.271.8", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Role-Based Access Control (RBAC) is a popular authorization model used to\nmanage data-access constraints in a wide range of systems. RBAC usually defines\nthe static view on the access rights. However, to ensure dependability of a\nsystem, it is often necessary to model and verify state-dependent access\nrights. Such a modelling allows us to explicitly define the dependencies\nbetween the system states and permissions to access and modify certain data. In\nthis paper, we present a work-in-progress on combining graphical and formal\nmodelling to specify and verify dynamic access control. The approach is\nillustrated by a case study -- a reporting management system.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 01:21:32 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Vistbakka", "Inna", "", "\u00c5bo Akademi"], ["Troubitsyna", "Elena", "", "\u00c5bo Akademi"]]}, {"id": "1805.05672", "submitter": "Ernst Moritz Hahn", "authors": "Paul Gainer, Ernst Moritz Hahn, and Sven Schewe", "title": "Accelerated Model Checking of Parametric Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric Markov chains occur quite naturally in various applications: they\ncan be used for a conservative analysis of probabilistic systems (no matter how\nthe parameter is chosen, the system works to specification); they can be used\nto find optimal settings for a parameter; they can be used to visualise the\ninfluence of system parameters; and they can be used to make it easy to adjust\nthe analysis for the case that parameters change. Unfortunately, these\nadvancements come at a cost: parametric model checking is---or rather\nwas---often slow. To make the analysis of parametric Markov models scale, we\nneed three ingredients: clever algorithms, the right data structure, and good\nengineering. Clever algorithms are often the main (or sole) selling point; and\nwe face the trouble that this paper focuses on -- the latter ingredients to\nefficient model checking. Consequently, our easiest claim to fame is in the\nspeed-up we have often realised when comparing to the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 09:45:11 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 08:46:33 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 16:45:44 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Gainer", "Paul", ""], ["Hahn", "Ernst Moritz", ""], ["Schewe", "Sven", ""]]}, {"id": "1805.05729", "submitter": "Olivier Bournez", "authors": "Olivier Bournez and Amaury Pouly", "title": "A Survey on Analog Models of Computation", "comments": "To appear as a chapter of \"Handbook of Computability and Complexity\n  in Analysis \" Series:Theory and Applications of Computability Publisher:\n  Springer in cooperation with the Association Computablity in Europe. Editors:\n  Vasco Brattka and Peter Hertling, Handbook of Computability and Complexity in\n  Analysis, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a survey on analog models of computations. Analog can be\nunderstood both as computing by analogy, or as working on the continuum. We\nconsider both approaches, often intertwined, with a point of view mostly\noriented by computation theory.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 14:57:53 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Bournez", "Olivier", ""], ["Pouly", "Amaury", ""]]}, {"id": "1805.05845", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "On the complexity of the correctness problem for non-zeroness test\n  instruction sequences", "comments": "32 pages, minor revision with several obscurities made clear", "journal-ref": "Theoretical Computer Science, 802:1--18, 2020", "doi": "10.1016/j.tcs.2019.03.040", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the question to what extent it can be efficiently\ndetermined whether an arbitrary program correctly solves a given problem. This\nquestion is investigated with programs of a very simple form, namely\ninstruction sequences, and a very simple problem, namely the non-zeroness test\non natural numbers. The instruction sequences concerned are of a kind by which,\nfor each $n > 0$, each function from $\\{0,1\\}^n$ to $\\{0,1\\}$ can be computed.\nThe established results include the time complexities of the problem of\ndetermining whether an arbitrary instruction sequence correctly implements the\nrestriction to $\\{0,1\\}^n$ of the function from $\\{0,1\\}^*$ to $\\{0,1\\}$ that\nmodels the non-zeroness test function, for $n > 0$, under several restrictions\non the arbitrary instruction sequence.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 15:22:51 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 13:26:09 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 16:18:23 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1805.06196", "submitter": "Azalea Raad", "authors": "Azalea Raad, Ori Lahav, Viktor Vafeiadis", "title": "On the Semantics of Snapshot Isolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Snapshot isolation (SI) is a standard transactional consistency model used in\ndatabases, distributed systems and software transactional memory (STM). Its\nsemantics is formally defined both declaratively as an acyclicity axiom, and\noperationally as a concurrent algorithm with memory bearing timestamps.\n  We develop two simpler equivalent operational definitions of SI as lock-based\nreference implementations that do not use timestamps. Our first locking\nimplementation is prescient in that requires a priori knowledge of the data\naccessed by a transaction and carries out transactional writes eagerly\n(in-place). Our second implementation is non-prescient and performs\ntransactional writes lazily by recording them in a local log and propagating\nthem to memory at commit time. Whilst our first implementation is simpler and\nmay be better suited for developing a program logic for SI transactions, our\nsecond implementation is more practical due to its non-prescience. We show that\nboth implementations are sound and complete against the declarative SI\nspecification and thus yield equivalent operational definitions for SI.\n  We further consider, for the first time formally, the use of SI in a context\nwith racy non-transactional accesses, as can arise in STM implementations of\nSI. We introduce robust snapshot isolation (RSI), an adaptation of SI with\nsimilar semantics and guarantees in this mixed setting. We present a\ndeclarative specification of RSI as an acyclicity axiom and analogously develop\ntwo operational models as lock-based reference implementations (one eager, one\nlazy). We show that these operational models are both sound and complete\nagainst the declarative RSI model.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 08:59:47 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 16:36:54 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Raad", "Azalea", ""], ["Lahav", "Ori", ""], ["Vafeiadis", "Viktor", ""]]}, {"id": "1805.06216", "submitter": "Louis Warren", "authors": "Louis Warren and Hannes Diener and Maarten McKubre-Jordens", "title": "The Drinker Paradox and its Dual", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Drinker Paradox is as follows.\n  In every nonempty tavern, there is a person such that if that person is\ndrinking, then everyone in the tavern is drinking.\n  Formally, \\[\n  \\exists x \\big(\\varphi \\rightarrow \\forall y \\varphi[x/y]\\big) \\ . \\] Due to\nits counterintuitive nature it is called a paradox, even though it actually is\na classical tautology. However, it is not minimally (or even\nintuitionistically) provable. The same can be said of its dual, which is\n(equivalent to) the well-known principle of \\emph{independence of premise}, \\[\n  \\varphi \\rightarrow \\exists x \\psi\n  \\ \\vdash \\ \\exists x (\\varphi \\rightarrow \\psi) \\] where $x$ is not free in\n$\\varphi$.\n  In this paper we study the implications of adding these and other formula\nschemata to minimal logic. We show first that these principles are independent\nof the law of excluded middle and of each other, and second how these schemata\nrelate to other well-known principles, such as Markov's Principle of unbounded\nsearch, providing proofs and semantic models where appropriate.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 09:57:52 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 02:48:45 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Warren", "Louis", ""], ["Diener", "Hannes", ""], ["McKubre-Jordens", "Maarten", ""]]}, {"id": "1805.06238", "submitter": "Fabian Reiter", "authors": "Fabian Reiter", "title": "Distributed Automata and Logic", "comments": "PhD thesis, 116 pages. http://www.theses.fr/2017USPCC034", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed automata are finite-state machines that operate on finite\ndirected graphs. Acting as synchronous distributed algorithms, they use their\ninput graph as a network in which identical processors communicate for a\npossibly infinite number of synchronous rounds. For the local variant of those\nautomata, where the number of rounds is bounded by a constant, Hella et al.\n(2012, 2015) have established a logical characterization in terms of basic\nmodal logic. In this thesis, we provide similar logical characterizations for\ntwo more expressive classes of distributed automata.\n  The first class extends local automata with a global acceptance condition and\nthe ability to alternate between nondeterministic and parallel computations. We\nshow that it is equivalent to monadic second-order logic on graphs. By\nrestricting transitions to be nondeterministic or deterministic, we also obtain\ntwo strictly weaker variants for which the emptiness problem is decidable.\n  Our second class transfers the standard notion of asynchronous algorithm to\nthe setting of nonlocal distributed automata. The resulting machines are shown\nto be equivalent to a small fragment of least fixpoint logic, and more\nspecifically, to a restricted variant of the modal {\\mu}-calculus that allows\nleast fixpoints but forbids greatest fixpoints. Exploiting the connection with\nlogic, we additionally prove that the expressive power of those asynchronous\nautomata is independent of whether or not messages can be lost.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 10:42:41 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Reiter", "Fabian", ""]]}, {"id": "1805.06502", "submitter": "Qingxiang Wang", "authors": "Qingxiang Wang, Cezary Kaliszyk, Josef Urban", "title": "First Experiments with Neural Translation of Informal to Formal\n  Mathematics", "comments": "Submission to CICM'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on our experiments to train deep neural networks that automatically\ntranslate informalized LaTeX-written Mizar texts into the formal Mizar\nlanguage. To the best of our knowledge, this is the first time when neural\nnetworks have been adopted in the formalization of mathematics. Using Luong et\nal.'s neural machine translation model (NMT), we tested our aligned\ninformal-formal corpora against various hyperparameters and evaluated their\nresults. Our experiments show that our best performing model configurations are\nable to generate correct Mizar statements on 65.73\\% of the inference data,\nwith the union of all models covering 79.17\\%. These results indicate that\nformalization through artificial neural network is a promising approach for\nautomated formalization of mathematics. We present several case studies to\nillustrate our results.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 09:11:43 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 10:02:22 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Wang", "Qingxiang", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1805.06701", "submitter": "Rupak Majumdar", "authors": "Anthony W. Lin and Rupak Majumdar", "title": "Quadratic Word Equations with Length Constraints, Counter Systems, and\n  Presburger Arithmetic with Divisibility", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word equations are a crucial element in the theoretical foundation of\nconstraint solving over strings, which have received a lot of attention in\nrecent years. A word equation relates two words over string variables and\nconstants. Its solution amounts to a function mapping variables to constant\nstrings that equate the left and right hand sides of the equation. While the\nproblem of solving word equations is decidable, the decidability of the problem\nof solving a word equation with a length constraint (i.e., a constraint\nrelating the lengths of words in the word equation) has remained a\nlong-standing open problem. In this paper, we focus on the subclass of\nquadratic word equations, i.e., in which each variable occurs at most twice. We\nfirst show that the length abstractions of solutions to quadratic word\nequations are in general not Presburger-definable. We then describe a class of\ncounter systems with Presburger transition relations which capture the length\nabstraction of a quadratic word equation with regular constraints. We provide\nan encoding of the effect of a simple loop of the counter systems in the theory\nof existential Presburger Arithmetic with divisibility (PAD). Since PAD is\ndecidable, we get a decision procedure for quadratic words equations with\nlength constraints for which the associated counter system is \\emph{flat}\n(i.e., all nodes belong to at most one cycle). We show a decidability result\n(in fact, also an NP algorithm with a PAD oracle) for a recently proposed\nNP-complete fragment of word equations called regular-oriented word equations,\ntogether with length constraints. Decidability holds when the constraints are\nadditionally extended with regular constraints with a 1-weak control structure.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 11:22:16 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Lin", "Anthony W.", ""], ["Majumdar", "Rupak", ""]]}, {"id": "1805.06736", "submitter": "Patrick Bahr", "authors": "Patrick Bahr", "title": "Strict Ideal Completions of the Lambda Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The infinitary lambda calculi pioneered by Kennaway et al. extend the basic\nlambda calculus by metric completion to infinite terms and reductions.\nDepending on the chosen metric, the resulting infinitary calculi exhibit\ndifferent notions of strictness. To obtain infinitary normalisation and\ninfinitary confluence properties for these calculi, Kennaway et al. extend\n$\\beta$-reduction with infinitely many `$\\bot$-rules', which contract\nmeaningless terms directly to $\\bot$. Three of the resulting B\\\"ohm reduction\ncalculi have unique infinitary normal forms corresponding to B\\\"ohm-like trees.\n  In this paper we develop a corresponding theory of infinitary lambda calculi\nbased on ideal completion instead of metric completion. We show that each of\nour calculi conservatively extends the corresponding metric-based calculus.\nThree of our calculi are infinitarily normalising and confluent; their unique\ninfinitary normal forms are exactly the B\\\"ohm-like trees of the corresponding\nmetric-based calculi. Our calculi dispense with the infinitely many\n$\\bot$-rules of the metric-based calculi. The fully non-strict calculus (called\n$111$) consists of only $\\beta$-reduction, while the other two calculi (called\n$001$ and $101$) require two additional rules that precisely state their\nstrictness properties: $\\lambda x.\\bot \\to \\bot$ (for $001$) and $\\bot\\,M \\to\n\\bot$ (for $001$ and $101$).\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 12:52:31 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Bahr", "Patrick", ""]]}, {"id": "1805.06781", "submitter": "Auke Booij", "authors": "Auke B. Booij", "title": "Extensional constructive real analysis via locators", "comments": "30 pages; to appear in the HoTT/UF Special Issue 2017-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real numbers do not admit an extensional procedure for observing discrete\ninformation, such as the first digit of its decimal expansion, because every\nextensional, computable map from the reals to the integers is constant, as is\nwell known. We overcome this by considering real numbers equipped with\nadditional structure, which we call a locator. With this structure, it is\npossible, for instance, to construct a signed-digit representation or a Cauchy\nsequence, and conversely these intensional representations give rise to a\nlocator. Although the constructions are reminiscent of computable analysis,\ninstead of working with a notion of computability, we simply work\nconstructively to extract observable information, and instead of working with\nrepresentations, we consider a certain locatedness structure on real numbers.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 14:04:47 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 19:31:41 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 10:44:51 GMT"}, {"version": "v4", "created": "Fri, 28 Feb 2020 08:24:40 GMT"}, {"version": "v5", "created": "Sun, 21 Jun 2020 22:08:51 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Booij", "Auke B.", ""]]}, {"id": "1805.06881", "submitter": "Bastien Maubert", "authors": "Aur\\`ele Barri\\`ere, Bastien Maubert, Aniello Murano and Sasha Rubin", "title": "Changing Observations in Epistemic Temporal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study dynamic changes of agents' observational power in logics of\nknowledge and time. We consider CTL*K, the extension of CTL* with knowledge\noperators, and enrich it with a new operator that models a change in an agent's\nway of observing the system. We extend the classic semantics of knowledge for\nperfect-recall agents to account for changes of observation, and we show that\nthis new operator strictly increases the expressivity of CTL*K. We reduce the\nmodel-checking problem for our logic to that for CTL*K, which is known to be\ndecidable. This provides a solution to the model-checking problem for our\nlogic, but its complexity is not optimal. Indeed we provide a direct decision\nprocedure with better complexity.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:45:01 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 14:24:22 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Barri\u00e8re", "Aur\u00e8le", ""], ["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Rubin", "Sasha", ""]]}, {"id": "1805.06908", "submitter": "EPTCS", "authors": "Matthew Amy (University of Waterloo)", "title": "Towards Large-scale Functional Verification of Universal Quantum\n  Circuits", "comments": "In Proceedings QPL 2018, arXiv:1901.09476", "journal-ref": "EPTCS 287, 2019, pp. 1-21", "doi": "10.4204/EPTCS.287.1", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for the formal specification and verification of\nquantum circuits based on the Feynman path integral. Our formalism, built\naround exponential sums of polynomial functions, provides a structured and\nnatural way of specifying quantum operations, particularly for quantum\nimplementations of classical functions. Verification of circuits over all\nlevels of the Clifford hierarchy with respect to either a specification or\nreference circuit is enabled by a novel rewrite system for exponential sums\nwith free variables. Our algorithm is further shown to give a polynomial-time\ndecision procedure for checking the equivalence of Clifford group circuits. We\nevaluate our methods by performing automated verification of optimized\nClifford+T circuits with up to 100 qubits and thousands of T gates, as well as\nthe functional verification of quantum algorithms using hundreds of qubits. Our\nexperiments culminate in the automated verification of the Hidden Shift\nalgorithm for a class of Boolean functions in a fraction of the time it has\ntaken recent algorithms to simulate.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 18:01:20 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 05:34:40 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Amy", "Matthew", "", "University of Waterloo"]]}, {"id": "1805.07195", "submitter": "Christian Sternagel", "authors": "Christian Sternagel", "title": "The remote_build Tool", "comments": "Accepted at Isabelle Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an introduction to the remote_build tool for transparent remote\nsession builds. The intended workflow for a user is to locally issue a build\ncommand for some session heap images and then continue working, while the\nactual build runs on a remote machine and the resulting heap images are\nsynchronized incrementally as soon as they are available.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 11:54:45 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Sternagel", "Christian", ""]]}, {"id": "1805.07211", "submitter": "Ulrich Dorsch", "authors": "Ulrich Dorsch, Stefan Milius, Lutz Schr\\\"oder, Thorsten Wi{\\ss}mann", "title": "Predicate Liftings and Functor Presentations in Coalgebraic Expression\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a generic expression language describing behaviours of finite\ncoalgebras over sets; besides relational systems, this covers, e.g., weighted,\nprobabilistic, and neighbourhood-based system types. We prove a generic\nKleene-type theorem establishing a correspondence between our expressions and\nfinite systems. Our expression language is similar to one introduced in\nprevious work by Myers but has a semantics defined in terms of a particular\nform of predicate liftings as used in coalgebraic modal logic; in fact, our\nexpressions can be regarded as a particular type of modal fixed point formulas.\nThe predicate liftings in question are required to satisfy a natural\npreservation property; we show that this property holds in particular for the\nMoss liftings introduced by Marti and Venema in work on lax extensions.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 16:02:30 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Dorsch", "Ulrich", ""], ["Milius", "Stefan", ""], ["Schr\u00f6der", "Lutz", ""], ["Wi\u00dfmann", "Thorsten", ""]]}, {"id": "1805.07239", "submitter": "Stepan Kochemazov", "authors": "Alexander Semenov, Ilya Otpuschennikov, Irina Gribanova, Oleg Zaikin,\n  Stepan Kochemazov", "title": "Translation of Algorithmic Descriptions of Discrete Functions to SAT\n  with Applications to Cryptanalysis Problems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (March 2,\n  2020) lmcs:6177", "doi": "10.23638/LMCS-16(1:29)2020", "report-no": null, "categories": "cs.LO cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present paper, we propose a technology for translating algorithmic\ndescriptions of discrete functions to SAT. The proposed technology is aimed at\napplications in algebraic cryptanalysis. We describe how cryptanalysis problems\nare reduced to SAT in such a way that it should be perceived as natural by the\ncryptographic community. In~the theoretical part of the paper we justify the\nmain principles of general reduction to SAT for discrete functions from a class\ncontaining the majority of functions employed in cryptography. Then, we\ndescribe the Transalg software tool developed based on these principles with\nSAT-based cryptanalysis specifics in mind. We demonstrate the results of\napplications of Transalg to construction of a number of attacks on various\ncryptographic functions. Some of the corresponding attacks are state of the\nart. We compare the functional capabilities of the proposed tool with that of\nother domain-specific software tools which can be used to reduce cryptanalysis\nproblems to SAT, and also with the CBMC system widely employed in symbolic\nverification. The paper also presents vast experimental data, obtained using\nthe SAT solvers that took first places at the SAT competitions in the recent\nseveral years.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 09:18:14 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 08:42:30 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 05:21:43 GMT"}, {"version": "v4", "created": "Fri, 4 Oct 2019 03:02:26 GMT"}, {"version": "v5", "created": "Thu, 27 Feb 2020 22:29:29 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Semenov", "Alexander", ""], ["Otpuschennikov", "Ilya", ""], ["Gribanova", "Irina", ""], ["Zaikin", "Oleg", ""], ["Kochemazov", "Stepan", ""]]}, {"id": "1805.07433", "submitter": "Nuri Cingillioglu", "authors": "Nuri Cingillioglu, Alessandra Russo", "title": "DeepLogic: Towards End-to-End Differentiable Logical Reasoning", "comments": "Camera-ready AAAI-MAKE19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining machine learning with logic-based expert systems in order to get\nthe best of both worlds are becoming increasingly popular. However, to what\nextent machine learning can already learn to reason over rule-based knowledge\nis still an open problem. In this paper, we explore how symbolic logic, defined\nas logic programs at a character level, is learned to be represented in a\nhigh-dimensional vector space using RNN-based iterative neural networks to\nperform reasoning. We create a new dataset that defines 12 classes of logic\nprograms exemplifying increased level of complexity of logical reasoning and\ntrain the networks in an end-to-end fashion to learn whether a logic program\nentails a given query. We analyse how learning the inference algorithm gives\nrise to representations of atoms, literals and rules within logic programs and\nevaluate against increasing lengths of predicate and constant symbols as well\nas increasing steps of multi-hop reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:36:21 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 13:15:41 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 21:19:06 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Cingillioglu", "Nuri", ""], ["Russo", "Alessandra", ""]]}, {"id": "1805.07434", "submitter": "Camilo Rocha", "authors": "Miguel Romero, Camilo Rocha", "title": "Reachability Analysis for Spatial Concurrent Constraint Systems with\n  Extrusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial concurrent constraint programming (SCCP) is an algebraic model of\nspatial modalities in constrained-based process calculi; it can be used to\nreason about spatial information distributed among the agents of a system. This\nwork presents an executable rewriting logic semantics of SCCP with extrusion\n(i.e., process mobility) that uses rewriting modulo SMT, a novel technique that\ncombines the power of term rewriting, matching algorithms, and SMT-solving. In\nthis setting, constraints are encoded as formulas in a theory with a\nsatisfaction relation decided by an SMT solver, while the topology of the\nspatial hierarchy is encoded as part of the term structure of symbolic states.\nBy being executable, the rewriting logic specification offers support for the\ninherent symbolic and challenging task of reachability analysis in the\nconstrained-based model. The approach is illustrated with examples about the\nautomatic verification of fault-tolerance, consistency, and privacy in\ndistributed spatial and hierarchical systems.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:38:16 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Romero", "Miguel", ""], ["Rocha", "Camilo", ""]]}, {"id": "1805.07563", "submitter": "Josef Urban", "authors": "Cezary Kaliszyk, Josef Urban, Henryk Michalewski, Mirek Ol\\v{s}\\'ak", "title": "Reinforcement Learning of Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a theorem proving algorithm that uses practically no domain\nheuristics for guiding its connection-style proof search. Instead, it runs many\nMonte-Carlo simulations guided by reinforcement learning from previous proof\nattempts. We produce several versions of the prover, parameterized by different\nlearning and guiding algorithms. The strongest version of the system is trained\non a large corpus of mathematical problems and evaluated on previously unseen\nproblems. The trained system solves within the same number of inferences over\n40% more problems than a baseline prover, which is an unusually high\nimprovement in this hard AI domain. To our knowledge this is the first time\nreinforcement learning has been convincingly applied to solving general\nmathematical problems on a large scale.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 10:05:43 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""], ["Michalewski", "Henryk", ""], ["Ol\u0161\u00e1k", "Mirek", ""]]}, {"id": "1805.08347", "submitter": "Jongmin Jerome Baek", "authors": "Min Baek", "title": "How To Solve Moral Conundrums with Computability Theory", "comments": "Conclusion is incorrect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Various moral conundrums plague population ethics: the Non-Identity Problem,\nthe Procreation Asymmetry, the Repugnant Conclusion, and more. I argue that the\naforementioned moral conundrums have a structure neatly accounted for, and\nsolved by, some ideas in computability theory. I introduce a mathematical model\nbased on computability theory and show how previous arguments pertaining to\nthese conundrums fit into the model. This paper proceeds as follows. First, I\ndo a very brief survey of the history of computability theory in moral\nphilosophy. Second, I follow various papers, and show how their arguments fit\ninto, or don't fit into, our model. Third, I discuss the implications of our\nmodel to the question why the human race should or should not continue to\nexist. Finally, I show that our model may be interpreted according to a\nConfucian-Taoist moral principle.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 01:47:16 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 22:46:39 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 23:48:42 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Baek", "Min", ""]]}, {"id": "1805.08425", "submitter": "Ale\\v{s} Bizjak", "authors": "Willem Conradie, Salih Durhan, Guido Sciavicco", "title": "An Integrated First-Order Theory of Points and Intervals over Linear\n  Orders (Part I)", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2 (June 19,\n  2018) lmcs:4599", "doi": "10.23638/LMCS-14(2:15)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are two natural and well-studied approaches to temporal ontology and\nreasoning: point-based and interval-based. Usually, interval-based temporal\nreasoning deals with points as a particular case of duration-less intervals. A\nrecent result by Balbiani, Goranko, and Sciavicco presented an explicit\ntwo-sorted point-interval temporal framework in which time instants (points)\nand time periods (intervals) are considered on a par, allowing the perspective\nto shift between these within the formal discourse. We consider here two-sorted\nfirst-order languages based on the same principle, and therefore including\nrelations, as first studied by Reich, among others, between points, between\nintervals, and inter-sort. We give complete classifications of its\nsub-languages in terms of relative expressive power, thus determining how many,\nand which, are the intrinsically different extensions of two-sorted first-order\nlogic with one or more such relations. This approach roots out the classical\nproblem of whether or not points should be included in a interval-based\nsemantics.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 07:14:47 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 13:55:48 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Conradie", "Willem", ""], ["Durhan", "Salih", ""], ["Sciavicco", "Guido", ""]]}, {"id": "1805.08605", "submitter": "Chris Heunen", "authors": "Chris Heunen, Robin Kaarsgaard, and Martti Karvonen", "title": "Reversible effects as inverse arrows", "comments": "15 pages; corrected Example 3.6", "journal-ref": "Electronic Notes in Theoretical Computer Science 341:179-199, 2018", "doi": "10.1016/j.entcs.2018.11.009", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible computing models settings in which all processes can be reversed.\nApplications include low-power computing, quantum computing, and robotics. It\nis unclear how to represent side-effects in this setting, because conventional\nmethods need not respect reversibility. We model reversible effects by adapting\nHughes' arrows to dagger arrows and inverse arrows. This captures several\nfundamental reversible effects, including serialization and mutable store\ncomputations. Whereas arrows are monoids in the category of profunctors, dagger\narrows are involutive monoids in the category of profunctors, and inverse\narrows satisfy certain additional properties. These semantics inform the design\nof functional reversible programs supporting side-effects.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 14:24:13 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 12:42:28 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Heunen", "Chris", ""], ["Kaarsgaard", "Robin", ""], ["Karvonen", "Martti", ""]]}, {"id": "1805.08606", "submitter": "Daniele Francesco Santamaria", "authors": "Domenico Cantone, Marianna Nicolosi-Asmundo, Daniele Francesco\n  Santamaria", "title": "A set-based reasoner for the description logic $\\shdlssx$ (Extended\n  Version)", "comments": "arXiv admin note: text overlap with arXiv:1804.11222,\n  arXiv:1707.07545, arXiv:1702.03096", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a \\ke-based implementation of a reasoner for a decidable fragment\nof (stratified) set theory expressing the description logic $\\dlssx$\n($\\shdlssx$, for short). Our application solves the main TBox and ABox\nreasoning problems for $\\shdlssx$. In particular, it solves the consistency\nproblem for $\\shdlssx$-knowledge bases represented in set-theoretic terms, and\na generalization of the \\emph{Conjunctive Query Answering} problem in which\nconjunctive queries with variables of three sorts are admitted. The reasoner,\nwhich extends and optimizes a previous prototype for the consistency checking\nof $\\shdlssx$-knowledge bases (see \\cite{cilc17}), is implemented in\n\\textsf{C++}. It supports $\\shdlssx$-knowledge bases serialized in the OWL/XML\nformat, and it admits also rules expressed in SWRL (Semantic Web Rule\nLanguage).\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 18:52:05 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 08:23:07 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Cantone", "Domenico", ""], ["Nicolosi-Asmundo", "Marianna", ""], ["Santamaria", "Daniele Francesco", ""]]}, {"id": "1805.08684", "submitter": "Andreas Nuyts", "authors": "Andreas Nuyts", "title": "Presheaf Models of Relational Modalities in Dependent Type Theory", "comments": "Technical report. 101 pages. Extension of arXiv:1706.04383", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report is an extension of 'A Model of Parametric Dependent Type Theory\nin Bridge/Path Cubical Sets' (Nuyts, arXiv:1706.04383). The purpose of this\ntext is to prove all technical aspects of our model for dependent type theory\nwith parametric quantifiers (Nuyts, Vezzosi and Devriese, 2017) and with\ndegrees of relatedness (Nuyts and Devriese, 2018).\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 13:25:12 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Nuyts", "Andreas", ""]]}, {"id": "1805.08707", "submitter": "Pasquale Iero", "authors": "Pasquale Iero, Allan Third, Paul Piwek", "title": "A syllogistic system for propositions with intermediate quantifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes a formalism that subsumes Peterson's intermediate\nquantifier syllogistic system, and extends the ideas by van Eijck on\nAristotle's logic. Syllogisms are expressed in a concise form making use of and\nextending the Monotonicity Calculus. Contradictory and contrary relationships\nare added so that deduction can derive propositions expressing a form of\nnegation.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 19:33:04 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Iero", "Pasquale", ""], ["Third", "Allan", ""], ["Piwek", "Paul", ""]]}, {"id": "1805.09123", "submitter": "Quang Loc Le", "authors": "Quang Loc Le", "title": "Decidable Logics Combining Word Equations, Regular Expressions and\n  Length Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the satisfiability problem in a logic that combines\nword equations over string variables denoting words of unbounded lengths,\nregular languages to which words belong and Presburger constraints on the\nlength of words. We present a novel decision procedure over two decidable\nfragments that include quadratic word equations (i.e., each string variable\noccurs at most twice). The proposed procedure reduces the problem to solving\nthe satisfiability in the Presburger arithmetic. The procedure combines two\nmain components: (i) an algorithm to derive a complete set of all solutions of\nconjunctions of word equations and regular expressions; and (ii) two methods to\nprecisely compute relational constraints over string lengths implied by the set\nof all solutions.We have implemented a prototype tool and evaluated it over a\nset of satisfiability problems in the logic. The experimental results show that\nthe tool is effective and efficient.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:22:26 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Le", "Quang Loc", ""]]}, {"id": "1805.09157", "submitter": "Vernon Asuncion Va", "authors": "Vernon Asuncion and Yan Zhang", "title": "A New Finitely Controllable Class of Tuple Generating Dependencies: The\n  Triangularly-Guarded Class", "comments": "Submitted for review. arXiv admin note: substantial text overlap with\n  arXiv:1804.05997", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new class of tuple-generating dependencies\n(TGDs) called triangularly-guarded (TG) TGDs. We show that conjunctive query\nanswering under this new class of TGDs is decidable since this new class of\nTGDs also satisfies the finite controllability (FC) property. We further show\nthat this new class strictly contains some other decidable classes such as\nweak-acyclic, guarded, sticky and shy. In this sense, the class TG provides a\nunified representation of all these aforementioned classes of TGDs.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 23:29:09 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Asuncion", "Vernon", ""], ["Zhang", "Yan", ""]]}, {"id": "1805.09256", "submitter": "Silvano Dal Zilio", "authors": "Rafael Scarduelli (LAAS-VERTICS), Pierre-Alain Bourdil, Silvano Dal\n  Zilio (LAAS-VERTICS), Didier Le Botlan (LAAS-VERTICS), P.-A Bourdil", "title": "Time-accurate Middleware for the Virtualization of Communication\n  Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication between devices in avionics systems must be predictable and\ndeterministic, and data must be delivered reliably. To help the system\narchitects comply with these requirements, network protocol standards like\nARINC 429 and AFDX were created. Even though the behaviour of each component in\na network is well defined, it is still necessary to test extensively every\napplications before deployment. But physical test benches used in the aircraft\ndevelopment process are complex and expensive platforms. In order to limit the\nneed for physical tests, we propose a time-accurate middleware for virtualizing\ncommunication protocols that can be used to replace physical tests with\nsimulations. We specified three formal models of AFDX networks that take into\naccount temporal constraints with different levels of precision. We also\ndeveloped a prototype for a network virtualization middleware based on the AFDX\nprotocol specification that provides an easy-to-setup environment for testing\nnetwork configurations. Finally, we used formal models together with\nvirtualization in order to define runtime monitors for checking whether the\nbehavior of the middleware is time-accurate with respect to a real system.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 07:26:06 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Scarduelli", "Rafael", "", "LAAS-VERTICS"], ["Bourdil", "Pierre-Alain", "", "LAAS-VERTICS"], ["Zilio", "Silvano Dal", "", "LAAS-VERTICS"], ["Botlan", "Didier Le", "", "LAAS-VERTICS"], ["Bourdil", "P. -A", ""]]}, {"id": "1805.09390", "submitter": "Cynthia Kop", "authors": "Carsten Fuhs, Cynthia Kop", "title": "The unified higher-order dependency pair framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, two higher-order extensions of the powerful dependency pair\napproach for termination analysis of first-order term rewriting have been\ndefined: the static and the dynamic approach. Both approaches offer distinct\nadvantages and disadvantages. However, a grand unifying theory is thus far\nmissing, and both approaches lack the modularity present in the dependency pair\nframework commonly used in first-order rewriting. Moreover, neither approach\ncan be used to prove non-termination.\n  In this paper, we aim to address this gap by defining a higher-order\ndependency pair framework, integrating both approaches into a shared formal\nsetup. The framework has been implemented in the (fully automatic) higher-order\ntermination tool WANDA.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 19:21:16 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Fuhs", "Carsten", ""], ["Kop", "Cynthia", ""]]}, {"id": "1805.09419", "submitter": "Maciej Bendkowski", "authors": "Maciej Bendkowski, Olivier Bodini, Sergey Dovgal", "title": "Statistical properties of lambda terms", "comments": "Major revision of section 5. In particular, proofs of Lemma 5.7 and\n  Theorem 5.9", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a quantitative, statistical analysis of random lambda terms in the\nde Bruijn notation. Following an analytic approach using multivariate\ngenerating functions, we investigate the distribution of various combinatorial\nparameters of random open and closed lambda terms, including the number of\nredexes, head abstractions, free variables or the de Bruijn index value\nprofile. Moreover, we conduct an average-case complexity analysis of finding\nthe leftmost-outermost redex in random lambda terms showing that it is on\naverage constant. The main technical ingredient of our analysis is a novel\nmethod of dealing with combinatorial parameters inside certain infinite,\nalgebraic systems of multivariate generating functions. Finally, we briefly\ndiscuss the random generation of lambda terms following a given skewed\nparameter distribution and provide empirical results regarding a series of more\ninvolved combinatorial parameters such as the number of open subterms and\nbinding abstractions in closed lambda terms.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 20:45:00 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 14:27:27 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Bendkowski", "Maciej", ""], ["Bodini", "Olivier", ""], ["Dovgal", "Sergey", ""]]}, {"id": "1805.09437", "submitter": "Samara Burns", "authors": "Samara Burns, Richard Zach", "title": "Relational Hypersequents for Modal Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a new approach to modal hypersequents, called relational\nhypersequents, which incorporates an accessibility relation along the\nhypersequent. These systems are an adaptation of Restall's 2009 cut-free\ncomplete hypersequent system for S5. Variation between modal systems in the\nrelational framework occurs only in the presence or absence of structural\nrules, which conforms to Do\\v{s}en's principle. All systems are modular except\nfor that of S5. We provide the first cut-free completeness result for K, T, and\nD, and show how this method fails in the case of B and S4.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 21:39:30 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Burns", "Samara", ""], ["Zach", "Richard", ""]]}, {"id": "1805.09446", "submitter": "Richard Zach", "authors": "Richard Zach", "title": "Non-Analytic Tableaux for Chellas's Conditional Logic CK and Lewis's\n  Logic of Counterfactuals VC", "comments": null, "journal-ref": "Australasian Journal of Logic 15 (3):609-628 (2018)", "doi": "10.26686/ajl.v15i3.4780", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Priest has provided a simple tableau calculus for Chellas's conditional logic\nCk. We provide rules which, when added to Priest's system, result in tableau\ncalculi for Chellas's CK and Lewis's VC. Completeness of these tableaux,\nhowever, relies on the cut rule.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 22:12:41 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zach", "Richard", ""]]}, {"id": "1805.09542", "submitter": "Etienne Miquey", "authors": "\\'Etienne Miquey (GALLINETTE)", "title": "A sequent calculus with dependent types for classical arithmetic", "comments": "LICS 2018 - 33th Annual ACM/IEEE Symposium on Logic in Computer\n  Science, Jul 2018, Oxford, United Kingdom. ACM, pp.720-729, LICS '18\n  Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer\n  Science", "journal-ref": null, "doi": "10.1145/3209108.3209199", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, Herbelin developed a calculus dPA$^\\omega$ in which\nconstructive proofs for the axioms of countable and dependent choices could be\nderived via the encoding of a proof of countable universal quantification as a\nstream of it components. However, the property of normalization (and therefore\nthe one of soundness) was only conjectured. The difficulty for the proof of\nnormalization is due to the simultaneous presence of dependent dependent types\n(for the constructive part of the choice), of control operators (for classical\nlogic), of coinductive objects (to encode functions of type $N\\rightarrow A$\ninto streams $(a_0,a_1,\\ldots)$) and of lazy evaluation with sharing (for these\ncoinductive objects).Building on previous works, we introduce in this paper a\nvariant of dPA$^\\omega$ presented as a sequent calculus. On the one hand, we\ntake advantage of a variant of Krivine classical realizability we developed to\nprove the normalization of classical call-by-need. On the other hand, we\nbenefit of dL, a classical sequent calculus with dependent types in which type\nsafety is ensured using delimited continuations together with a syntactic\nrestriction. By combining the techniques developed in these papers, we manage\nto define a realizability interpretation {\\`a} la Krivine of our calculus that\nallows us to prove normalization and soundness.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 08:22:35 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 12:15:24 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Miquey", "\u00c9tienne", "", "GALLINETTE"]]}, {"id": "1805.09880", "submitter": "Ronald de Haan", "authors": "Ronald de Haan, Iris van de Pol", "title": "On the Computational Complexity of Model Checking for Dynamic Epistemic\n  Logic with S5 Models", "comments": "To appear in the Journal of Applied Logics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic epistemic logic (DEL) is a logical framework for representing and\nreasoning about knowledge change for multiple agents. An important\ncomputational task in this framework is the model checking problem, which has\nbeen shown to be PSPACE-hard even for S5 models and two agents---in the\npresence of other features, such as multi-pointed models. We answer open\nquestions in the literature about the complexity of this problem in more\nrestricted settings. We provide a detailed complexity analysis of the model\nchecking problem for DEL, where we consider various combinations of\nrestrictions, such as the number of agents, whether the models are\nsingle-pointed or multi-pointed, and whether postconditions are allowed in the\nupdates. In particular, we show that the problem is already PSPACE-hard in (1)\nthe case of one agent, multi-pointed S5 models, and no postconditions, and (2)\nthe case of two agents, only single-pointed S5 models, and no postconditions.\nIn addition, we study the setting where only semi-private announcements are\nallowed as updates. We show that for this case the problem is already\nPSPACE-hard when restricted to two agents and three propositional variables.\nThe results that we obtain in this paper help outline the exact boundaries of\nthe restricted settings for which the model checking problem for DEL is\ncomputationally tractable.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 20:11:34 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 13:02:52 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["de Haan", "Ronald", ""], ["van de Pol", "Iris", ""]]}, {"id": "1805.10073", "submitter": "Radu Iosif", "authors": "Marius Bozga, Radu Iosif and Joseph Sifakis", "title": "Checking Deadlock-Freedom of Parametric Component-Based Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an automated method for computing inductive invariants applied to\ncheck deadlock-freedom for parametric component-based systems. The method\ngeneralizes the approach for computing structural trap invariants from bounded\nto parametric systems with general architectures. It symbolically extracts trap\ninvariants from a monadic interaction formula characterizing the system\narchitecture. The paper presents the theoretical foundations of the method\nincluding new results for the first order monadic logic and proves its\nsoundness. It also provides preliminary illustrations on examples.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 10:36:47 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 08:22:35 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 14:53:27 GMT"}, {"version": "v4", "created": "Fri, 15 Feb 2019 12:37:12 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Bozga", "Marius", ""], ["Iosif", "Radu", ""], ["Sifakis", "Joseph", ""]]}, {"id": "1805.10090", "submitter": "Christian Sternagel", "authors": "Christian Sternagel and Sarah Winkler", "title": "Certified Ordered Completion", "comments": "accepted at 7th International Workshop on Confluence 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the one hand, ordered completion is a fundamental technique in equational\ntheorem proving that is employed by automated tools. On the other hand, their\ncomplexity makes such tools inherently error prone. As a remedy to this\nsituation we give an Isabelle/HOL formalization of ordered rewriting and\ncompletion that comes with a formally verified certifier for ordered completion\nproofs. By validating generated proof certificates, our certifier increases the\nreliability of ordered completion tools.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 11:47:27 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Sternagel", "Christian", ""], ["Winkler", "Sarah", ""]]}, {"id": "1805.10250", "submitter": "Ana Ozaki", "authors": "Ana Ozaki and Rafael Pe\\~naloza", "title": "Consequence-Based Axiom Pinpointing", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axiom pinpointing refers to the problem of finding the axioms in an ontology\nthat are relevant for understanding a given entailment or consequence. One\napproach for axiom pinpointing, known as glass-box, is to modify a classical\ndecision procedure for the entailments into a method that computes the\nsolutions for the pinpointing problem. Recently, consequence-based decision\nprocedures have been proposed as a promising alternative for tableaux-based\nreasoners for standard ontology languages. In this work, we present a general\nframework to extend consequence-based algorithms with axiom pinpointing.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:07:01 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Ozaki", "Ana", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "1805.10415", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "A Theory of Encodings and Expressiveness", "comments": "An extended abstract of this paper appeared in the proceedings of\n  FoSSaCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a definition of what it means for one system description\nlanguage to encode another one, thereby enabling an ordering of system\ndescription languages with respect to expressive power. I compare the proposed\ndefinition with other definitions of encoding and expressiveness found in the\nliterature, and illustrate it on a well-known case study: the encoding of the\nsynchronous in the asynchronous $\\pi$-calculus.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 02:45:02 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "1805.10438", "submitter": "Maja Hanne Kirkeby", "authors": "Henning Christiansen, Maja H. Kirkeby", "title": "Confluence of CHR revisited: invariants and modulo equivalence", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/14", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract simulation of one transition system by another is introduced as a\nmeans to simulate a potentially infinite class of similar transition sequences\nwithin a single transition sequence. This is useful for proving confluence\nunder invariants of a given system, as it may reduce the number of proof cases\nto consider from infinity to a finite number. The classical confluence results\nfor Constraint Handling Rules (CHR) can be explained in this way, using CHR as\na simulation of itself. Using an abstract simulation based on a ground\nrepresentation, we extend these results to include confluence under invariant\nand modulo equivalence, which have not been done in a satisfactory way before.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 07:15:12 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 07:38:06 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 14:07:55 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Christiansen", "Henning", ""], ["Kirkeby", "Maja H.", ""]]}, {"id": "1805.10749", "submitter": "Toru Takisaka", "authors": "Toru Takisaka, Yuichiro Oyabu, Natsuki Urabe, Ichiro Hasuo", "title": "Ranking and Repulsing Supermartingales for Reachability in Probabilistic\n  Programs", "comments": null, "journal-ref": "Automated Technology for Verification and Analysis. ATVA 2018.\n  Lecture Notes in Computer Science, vol 11138. Springer, Cham", "doi": "10.1007/978-3-030-01090-4_28", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing reachability probabilities is a fundamental problem in the analysis\nof probabilistic programs. This paper aims at a comprehensive and comparative\naccount on various martingale-based methods for over- and under-approximating\nreachability probabilities. Based on the existing works that stretch across\ndifferent communities (formal verification, control theory, etc.), we offer a\nunifying account. In particular, we emphasize the role of order-theoretic fixed\npoints---a classic topic in computer science---in the analysis of probabilistic\nprograms. This leads us to two new martingale-based techniques, too. We give\nrigorous proofs for their soundness and completeness. We also make an\nexperimental comparison using our implementation of template-based synthesis\nalgorithms for those martingales.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 03:08:48 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 08:43:45 GMT"}, {"version": "v3", "created": "Sat, 15 Sep 2018 02:39:50 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Takisaka", "Toru", ""], ["Oyabu", "Yuichiro", ""], ["Urabe", "Natsuki", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1805.11021", "submitter": "Adrien Guatto", "authors": "Adrien Guatto", "title": "A Generalized Modality for Recursion", "comments": "17 pages, 13 figures, LICS 2018 (extended version); (fixed typos in\n  op. semantics on 2020-08-03)", "journal-ref": null, "doi": "10.1145/3209108.3209148", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nakano's later modality allows types to express that the output of a function\ndoes not immediately depend on its input, and thus that computing its fixpoint\nis safe. This idea, guarded recursion, has proved useful in various contexts,\nfrom functional programming with infinite data structures to formulations of\nstep-indexing internal to type theory. Categorical models have revealed that\nthe later modality corresponds in essence to a simple reindexing of the\ndiscrete time scale.\n  Unfortunately, existing guarded type theories suffer from significant\nlimitations for programming purposes. These limitations stem from the fact that\nthe later modality is not expressive enough to capture precise input-output\ndependencies of functions. As a consequence, guarded type theories reject many\nproductive definitions.\n  Combining insights from guarded type theories and synchronous programming\nlanguages, we propose a new modality for guarded recursion. This modality can\napply any well-behaved reindexing of the time scale to a type. We call such\nreindexings time warps. Several modalities from the literature, including\nlater, correspond to fixed time warps, and thus arise as special cases of ours.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:32:12 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 16:01:32 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Guatto", "Adrien", ""]]}, {"id": "1805.11392", "submitter": "Guillaume Geoffroy", "authors": "Guillaume Geoffroy (AMU, I2M)", "title": "Classical realizability as a classifier for nondeterminism", "comments": null, "journal-ref": "ACM/IEEE Symposium on Logic in Computer Science, Jul 2018, Oxford,\n  United Kingdom", "doi": "10.1145/3209108.3209140", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the language of Krivine's classical realizability may be used to\nspecify various forms of nondeterminism and relate them with properties of\nrealizability models. More specifically, we introduce an abstract notion of\nmulti-evaluation relation which allows us to finely describe various\nnondeterministic behaviours. This defines a hierarchy of computational models,\nordered by their degree of nondeterminism, similar to Sazonov's degrees of\nparallelism. What we show is a duality between the structure of the\ncharacteristic Boolean algebra of a realizability model and the degree of\nnondeterminism in its underlying computational model. ACM Reference Format:\nGuillaume Geoffroy. 2018. Classical realizability as a classifier for\nnondeter-minism.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 12:34:56 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Geoffroy", "Guillaume", "", "AMU, I2M"]]}, {"id": "1805.11550", "submitter": "Justin Hsu", "authors": "Gerco van Heerdt, Justin Hsu, Jo\\\"el Ouaknine, Alexandra Silva", "title": "Convex Language Semantics for Nondeterministic Probabilistic Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore language semantics for automata combining probabilistic and\nnondeterministic behavior. We first show that there are precisely two natural\nsemantics for probabilistic automata with nondeterminism. For both choices, we\nshow that these automata are strictly more expressive than deterministic\nprobabilistic automata, and we prove that the problem of checking language\nequivalence is undecidable by reduction from the threshold problem. However, we\nprovide a discounted metric that can be computed to arbitrarily high precision.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:56:32 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["van Heerdt", "Gerco", ""], ["Hsu", "Justin", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Silva", "Alexandra", ""]]}, {"id": "1805.11608", "submitter": "Arno Pauly", "authors": "Nicolas Basset, Isma\\\"el Jecker, Arno Pauly, Jean-Fran\\c{c}ois Raskin,\n  Marie Van den Bogaard", "title": "Beyond admissibility: Dominance between chains of strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Admissible strategies, i.e. those that are not dominated by any other\nstrategy, are a typical rationality notion in game theory. In many classes of\ngames this is justified by results showing that any strategy is admissible or\ndominated by an admissible strategy. However, in games played on finite graphs\nwith quantitative objectives (as used for reactive synthesis), this is not the\ncase.\n  We consider increasing chains of strategies instead to recover a satisfactory\nrationality notion based on dominance in such games. We start with some\norder-theoretic considerations establishing sufficient criteria for this to\nwork. We then turn our attention to generalised safety/reachability games as a\nparticular application. We propose the notion of maximal uniform chain as the\ndesired dominance-based rationality concept in these games. Decidability of\nsome fundamental questions about uniform chains is established.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:47:40 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Basset", "Nicolas", ""], ["Jecker", "Isma\u00ebl", ""], ["Pauly", "Arno", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Bogaard", "Marie Van den", ""]]}, {"id": "1805.11765", "submitter": "Weijun Zhu", "authors": "Weijun Zhu, Jianwei Wang and Yongwen Fan", "title": "Approximate LTL model checking", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state explosion problem and the exponentially computational complexity\nrestrict the further applications of LTL model checking. To this end, this\nstudy tries to seek an acceptable approximate solution for LTL model checking\nby introducing the Machine Learning (ML) technique, and a method for predicting\nresults of LTL model checking via the Boosted Tree (BT) algorithm is proposed\nin this paper. First, for a number of Kripke structures and LTL formulas, a\ndata set A containing their model checking results is obtained, using the\nexisting LTL model checking algorithm. Second, the LTL model checking problem\ncan be induced to a binary classification problem of machine learning. In other\nwords, some records in A form a training set for the BT algorithm. On the basis\nof it, a ML model M is obtained to predict the results of LTL model checking.\nAs a result, an approximate LTL model checking technique occurs. The\nexperiments show that the new method has the average accuracy of 98.0%, and its\naverage efficiency is 9.4 million times higher than that of the representative\nmodel checking method, if the length of each of LTL formulas equals to 500.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 01:08:37 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 11:31:11 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 10:07:59 GMT"}, {"version": "v4", "created": "Sun, 17 Feb 2019 03:25:44 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Zhu", "Weijun", ""], ["Wang", "Jianwei", ""], ["Fan", "Yongwen", ""]]}, {"id": "1805.11799", "submitter": "Taro Sekiyama", "authors": "Taro Sekiyama and Kohei Suenaga", "title": "Automated proof synthesis for propositional logic with deep neural\n  networks", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the application of deep learning, a machine learning\ntechnique that uses deep neural networks (DNN) in its core, to an automated\ntheorem proving (ATP) problem. To this end, we construct a statistical model\nwhich quantifies the likelihood that a proof is indeed a correct one of a given\nproposition. Based on this model, we give a proof-synthesis procedure that\nsearches for a proof in the order of the likelihood. This procedure uses an\nestimator of the likelihood of an inference rule being applied at each step of\na proof. As an implementation of the estimator, we propose a\nproposition-to-proof architecture, which is a DNN tailored to the automated\nproof synthesis problem. To empirically demonstrate its usefulness, we apply\nour model to synthesize proofs of propositional logic. We train the\nproposition-to-proof model using a training dataset of proposition-proof pairs.\nThe evaluation against a benchmark set shows the very high accuracy and an\nimprovement to the recent work of neural proof synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 04:22:51 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Sekiyama", "Taro", ""], ["Suenaga", "Kohei", ""]]}, {"id": "1805.11988", "submitter": "Ale\\v{s} Bizjak", "authors": "Cl\\'ement Aubert and Marc Bagnol", "title": "Unification and Logarithmic Space", "comments": "arXiv admin note: text overlap with arXiv:1402.4327", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (July 31,\n  2018) lmcs:4725", "doi": "10.23638/LMCS-14(3:6)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an algebraic characterization of the complexity classes Logspace\nand Nlogspace, using an algebra with a composition law based on unification.\nThis new bridge between unification and complexity classes is rooted in proof\ntheory and more specifically linear logic and geometry of interaction. We show\nhow to build a model of computation in the unification algebra and then, by\nmeans of a syntactic representation of finite permutations in the algebra, we\nprove that whether an observation (the algebraic counterpart of a program)\naccepts a word can be decided within logarithmic space. Finally, we show that\nthe construction naturally corresponds to pointer machines, a convenient way of\nunderstanding logarithmic space computation.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:10:53 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 09:58:50 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Aubert", "Cl\u00e9ment", ""], ["Bagnol", "Marc", ""]]}, {"id": "1805.12582", "submitter": "Bastien Maubert", "authors": "Rapha\\\"el Berthon, Bastien Maubert and Aniello Murano", "title": "Decidability results for ATL* with imperfect information and perfect\n  recall", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Alternating-time Temporal Logic (ATL*) is a central logic for multiagent\nsystems. Its extension to the imperfect information setting (ATL*i ) is well\nknown to have an undecidable model-checking problem when agents have perfect\nrecall. Studies have thus mostly focused either on agents without memory, or on\nalternative semantics to retrieve decidability. In this work we establish new\ndecidability results for agents with perfect recall: We first prove a\nmeta-theorem that allows the transfer of decidability results for classes of\nmultiplayer games with imperfect information, such as games with hierarchical\nobservation, to the model-checking problem for ATL*i . We then establish that\nmodel checking ATL* with strategy context and imperfect information is\ndecidable when restricted to hierarchical instances.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 17:45:42 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 15:22:49 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Berthon", "Rapha\u00ebl", ""], ["Maubert", "Bastien", ""], ["Murano", "Aniello", ""]]}, {"id": "1805.12592", "submitter": "Bastien Maubert", "authors": "Rapha\\\"el Berthon, Bastien Maubert, Aniello Murano, Sasha Rubin and\n  Moshe Vardi", "title": "Strategy Logic with Imperfect Information", "comments": null, "journal-ref": null, "doi": "10.1109/LICS.2017.8005136", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension of Strategy Logic for the imperfect-information\nsetting, called SLii, and study its model-checking problem. As this logic\nnaturally captures multi-player games with imperfect information, the problem\nturns out to be undecidable. We introduce a syntactical class of \"hierarchical\ninstances\" for which, intuitively, as one goes down the syntactic tree of the\nformula, strategy quantifications are concerned with finer observations of the\nmodel. We prove that model-checking SLii restricted to hierarchical instances\nis decidable. This result, because it allows for complex patterns of\nexistential and universal quantification on strategies, greatly generalises\nprevious ones, such as decidability of multi-player games with imperfect\ninformation and hierarchical observations, and decidability of distributed\nsynthesis for hierarchical systems. To establish the decidability result, we\nintroduce and study QCTL*ii, an extension of QCTL* (itself an extension of CTL*\nwith second-order quantification over atomic propositions) by parameterising\nits quantifiers with observations. The simple syntax of QCTL* ii allows us to\nprovide a conceptually neat reduction of SLii to QCTL*ii that separates\nconcerns, allowing one to forget about strategies and players and focus solely\non second-order quantification. While the model-checking problem of QCTL*ii is,\nin general, undecidable, we identify a syntactic fragment of hierarchical\nformulas and prove, using an automata-theoretic approach, that it is decidable.\nThe decidability result for SLii follows since the reduction maps hierarchical\ninstances of SLii to hierarchical formulas of QCTL*ii .\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 17:57:29 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 15:29:53 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Berthon", "Rapha\u00ebl", ""], ["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Rubin", "Sasha", ""], ["Vardi", "Moshe", ""]]}]