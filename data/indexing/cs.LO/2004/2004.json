[{"id": "2004.00124", "submitter": "Raul Fervari", "authors": "Carlos Areces, Raul Fervari", "title": "Axiomatizing Hybrid XPath with Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we introduce sound and strongly complete axiomatizations for\nXPath with data constraints extended with hybrid operators. First, we present\nHXPath=, a multi-modal version of XPath with data, extended with nominals and\nthe hybrid operator @. Then, we introduce an axiomatic system for HXPath=, and\nwe prove it is strongly complete with respect to the class of abstract data\nmodels, i.e., data models in which data values are abstracted as equivalence\nrelations. We prove a general completeness result similar to the one presented\nin, e.g., [BtC06], that ensures that certain extensions of the axiomatic system\nwe introduce are also complete. The axiomatic systems that can be obtained in\nthis way cover a large family of hybrid XPath languages over different classes\nof frames, for which we present concrete examples. In addition, we investigate\naxiomatizations over the class of tree models, structures widely used in\npractice. We show that a strongly complete, finitary, first-order\naxiomatization of hybrid XPath over trees does not exist, and we propose two\nalternatives to deal with this issue. We finally introduce filtrations to\ninvestigate the status of decidability of the satisfiability problem for these\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 21:23:24 GMT"}, {"version": "v2", "created": "Sat, 20 Mar 2021 20:32:06 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 22:08:16 GMT"}, {"version": "v4", "created": "Mon, 19 Jul 2021 13:16:46 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Areces", "Carlos", ""], ["Fervari", "Raul", ""]]}, {"id": "2004.00577", "submitter": "Robert Colvin", "authors": "Robert J. Colvin and Kirsten Winter", "title": "An abstract semantics of speculative execution for reasoning about\n  security vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about correctness and security of software is increasingly\ndifficult due to the complexity of modern microarchitectural features such as\nout-of-order execution. A class of security vulnerabilities termed Spectre that\nexploits side effects of speculative, out-of-order execution was announced in\n2018 and has since drawn much attention. In this paper we formalise speculative\nexecution and its side effects with the intention of allowing speculation to be\nreasoned about abstractly at the program level, limiting the exposure to\nprocessor-specific or low-level semantics. To this end we encode and expose\nspeculative execution explicitly in the programming language, rather than\nsolely in the operational semantics; as a result the effects of speculative\nexecution are captured by redefining the meaning of a conditional statement,\nand introducing novel language constructs that model transient execution of an\nalternative branch. We add an abstract cache to the global state of the system,\nand derive some general refinement rules that expose cache side effects due to\nspeculative loads. Underlying this extension is a semantic model that is based\non instruction-level parallelism. The rules are encoded in a simulation tool,\nwhich we use to analyse an abstract specification of a Spectre attack and\nvulnerable code fragments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 00:19:49 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Colvin", "Robert J.", ""], ["Winter", "Kirsten", ""]]}, {"id": "2004.01320", "submitter": "EPTCS", "authors": "Bas van den Heuvel (University of Groningen), Jorge A. P\\'erez\n  (University of Groningen)", "title": "Session Type Systems based on Linear Logic: Classical versus\n  Intuitionistic", "comments": "In Proceedings PLACES 2020, arXiv:2004.01062", "journal-ref": "EPTCS 314, 2020, pp. 1-11", "doi": "10.4204/EPTCS.314.1", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session type systems have been given logical foundations via Curry-Howard\ncorrespondences based on both intuitionistic and classical linear logic. The\ntype systems derived from the two logics enforce communication correctness on\nthe same class of pi-calculus processes, but they are significantly different.\nCaires, Pfenning and Toninho informally observed that, unlike the classical\ntype system, the intuitionistic type system enforces locality for shared\nchannels, i.e. received channels cannot be used for replicated input. In this\npaper, we revisit this observation from a formal standpoint. We develop United\nLinear Logic (ULL), a logic encompassing both classical and intuitionistic\nlinear logic. Then, following the Curry-Howard correspondences for session\ntypes, we define piULL, a session type system for the pi-calculus based on ULL.\nUsing piULL we can formally assess the difference between the intuitionistic\nand classical type systems, and justify the role of locality and symmetry\ntherein.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 01:25:03 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Heuvel", "Bas van den", "", "University of Groningen"], ["P\u00e9rez", "Jorge A.", "", "University of Groningen"]]}, {"id": "2004.01324", "submitter": "EPTCS", "authors": "Filipe Casal (LASIGE, Faculdade de Ci\\^encias, Universidade de Lisboa,\n  Portugal), Andreia Mordido (LASIGE, Faculdade de Ci\\^encias, Universidade de\n  Lisboa, Portugal), Vasco T. Vasconcelos (LASIGE, Faculdade de Ci\\^encias,\n  Universidade de Lisboa, Portugal)", "title": "Mixed Sessions: the Other Side of the Tape", "comments": "In Proceedings PLACES 2020, arXiv:2004.01062", "journal-ref": "EPTCS 314, 2020, pp. 46-60", "doi": "10.4204/EPTCS.314.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original paper on Mixed Sessions introduce the side A of the tape: there\nis an encoding of classical sessions into mixed sessions. Here we present side\nB: there is a translation of (a subset of) mixed sessions into classical\nsession types. We prove that the translation is a minimal encoding, according\nto the criteria put forward by Kouzapas, P\\'erez, and Yoshida.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 01:26:04 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Casal", "Filipe", "", "LASIGE, Faculdade de Ci\u00eancias, Universidade de Lisboa,\n  Portugal"], ["Mordido", "Andreia", "", "LASIGE, Faculdade de Ci\u00eancias, Universidade de\n  Lisboa, Portugal"], ["Vasconcelos", "Vasco T.", "", "LASIGE, Faculdade de Ci\u00eancias,\n  Universidade de Lisboa, Portugal"]]}, {"id": "2004.01410", "submitter": "Zeynep G\\\"ozen Saribatur", "authors": "Zeynep G. Saribatur and Thomas Eiter", "title": "Omission-based Abstraction for Answer Set Programs", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 21 (2021) 145-195", "doi": "10.1017/S1471068420000095", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction is a well-known approach to simplify a complex problem by\nover-approximating it with a deliberate loss of information. It was not\nconsidered so far in Answer Set Programming (ASP), a convenient tool for\nproblem solving. We introduce a method to automatically abstract ASP programs\nthat preserves their structure by reducing the vocabulary while ensuring an\nover-approximation (i.e., each original answer set maps to some abstract answer\nset). This allows for generating partial answer set candidates that can help\nwith approximation of reasoning. Computing the abstract answer sets is\nintuitively easier due to a smaller search space, at the cost of encountering\nspurious answer sets. Faithful (non-spurious) abstractions may be used to\nrepresent projected answer sets and to guide solvers in answer set\nconstruction. For dealing with spurious answer sets, we employ an ASP debugging\napproach to help with abstraction refinement, which determines atoms as badly\nomitted and adds them back in the abstraction. As a show case, we apply\nabstraction to explain unsatisfiability of ASP programs in terms of blocker\nsets, which are the sets of atoms such that abstraction to them preserves\nunsatisfiability. Their usefulness is demonstrated by experimental results.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 07:39:41 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Saribatur", "Zeynep G.", ""], ["Eiter", "Thomas", ""]]}, {"id": "2004.01709", "submitter": "Thorsten Wissmann", "authors": "Bassel Mannaa, Rasmus Ejlers M{\\o}gelberg, Niccol\\`o Veltri", "title": "Ticking clocks as dependent right adjoints: Denotational semantics for\n  clocked type theory", "comments": "31 pages. Second version is a minor revision. arXiv admin note: text\n  overlap with arXiv:1804.06687", "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 4 (December\n  15, 2020) lmcs:6980", "doi": "10.23638/LMCS-16(4:17)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clocked Type Theory (CloTT) is a type theory for guarded recursion useful for\nprogramming with coinductive types, allowing productivity to be encoded in\ntypes, and for reasoning about advanced programming language features using an\nabstract form of step-indexing. CloTT has previously been shown to enjoy a\nnumber of syntactic properties including strong normalisation, canonicity and\ndecidability of the equational theory. In this paper we present a denotational\nsemantics for CloTT useful, e.g., for studying future extensions of CloTT with\nconstructions such as path types.\n  The main challenge for constructing this model is to model the notion of\nticks on a clock used in CloTT for coinductive reasoning about coinductive\ntypes. We build on a category previously used to model guarded recursion with\nmultiple clocks. In this category there is an object of clocks but no object of\nticks, and so tick-assumptions in a context can not be modelled using standard\ntools. Instead we model ticks using dependent right adjoint functors, a\ngeneralisation of the category theoretic notion of adjunction to the setting of\ncategories with families. Dependent right adjoints are known to model\nFitch-style modal types, but in the case of CloTT, the modal operators\nconstitute a family indexed internally in the type theory by clocks. We model\nthis family using a dependent right adjoint on the slice category over the\nobject of clocks. Finally we show how to model the tick constant of CloTT using\na semantic substitution.\n  This work improves on a previous model by the first two named authors which\nnot only had a flaw but was also considerably more complicated.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 13:29:18 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 07:16:26 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 12:12:49 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Mannaa", "Bassel", ""], ["M\u00f8gelberg", "Rasmus Ejlers", ""], ["Veltri", "Niccol\u00f2", ""]]}, {"id": "2004.01859", "submitter": "Riccardo De Masellis", "authors": "Giuseppe De Giacomo, Riccardo De Masellis, Fabrizio Maria Maggi and\n  Marco Montali", "title": "Monitoring Constraints and Metaconstraints with Temporal Logics on\n  Finite Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Runtime monitoring is one of the central tasks in the area of operational\ndecision support for business process management. In particular, it helps\nprocess executors to check on-the-fly whether a running process instance\nsatisfies business constraints of interest, providing an immediate feedback\nwhen deviations occur. We study runtime monitoring of properties expressed in\nLTL on finite traces (LTLf), and in its extension LDLf. LDLf is a powerful\nlogic that captures all monadic second order logic on finite traces, and that\nis obtained by combining regular expressions with LTLf, adopting the syntax of\npropositional dynamic logic (PDL). Interestingly, in spite of its greater\nexpressivity, \\LDLf has exactly the same computational complexity of LTLf.\n  We show that LDLf is able to declaratively express, in the logic itself, not\nonly the constraints to be monitored, but also the de-facto standard RV-LTL\nmonitors. On the one hand, this enables us to directly employ the standard\ncharacterization of LDLf based on finite-state automata to monitor constraints\nin a fine-grained way. On the other hand, it provides the basis for\ndeclaratively expressing sophisticated metaconstraints that predicate on the\nmonitoring state of other constraints, and to check them by relying on standard\nlogical services instead of ad-hoc algorithms.\n  In addition, we devise a direct translation of LDLf formulae into\nnondeterministic finite-state automata, avoiding to detour to Buchi automata or\nalternating automata. We then report on how this approach has been effectively\nimplemented using Java to manipulate LDLf formulae and their corresponding\nmonitors, and the well-known ProM process mining suite as underlying\noperational decision support infrastructure.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 05:23:16 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 10:56:25 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["De Giacomo", "Giuseppe", ""], ["De Masellis", "Riccardo", ""], ["Maggi", "Fabrizio Maria", ""], ["Montali", "Marco", ""]]}, {"id": "2004.02120", "submitter": "Y\\`i N. W\\'ang", "authors": "Y\\`i N. W\\'ang and Thomas {\\AA}gotnes", "title": "Simpler completeness proofs for modal logics with intersection", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a significant interest in extending various modal logics with\nintersection, the most prominent examples being epistemic and doxastic logics\nwith distributed knowledge. Completeness proofs for such logics tend to be\ncomplicated, in particular on model classes such as S5 like in standard\nepistemic logic, mainly due to the undefinability of intersection of modalities\nin standard modal logics. A standard proof method for the S5 case was outlined\nin [8] and later explicated in more detail in [13], using an\n\"unraveling-folding method\" case to achieve a treelike model to deal with the\nproblem of undefinability. This method, however, is not easily adapted to other\nlogics, due to the level of detail and reliance on S5. In this paper we propose\na simpler proof technique by building a treelike canonical model directly,\nwhich avoids the complications in the processes of unraveling and folding. We\ndemonstrate the technique by showing completeness of the normal modal logics K,\nD, T, B, S4 and S5 extended with intersection modalities. Furthermore, these\ntreelike canonical models are compatible with Fischer-Ladner-style closures,\nand we combine the methods to show the completeness of the mentioned logics\nfurther extended with transitive closure of union modalities known from PDL or\nepistemic logic. Some of these completeness results are new.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 07:55:21 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["W\u00e1ng", "Y\u00ec N.", ""], ["\u00c5gotnes", "Thomas", ""]]}, {"id": "2004.02282", "submitter": "Petr Hlin\\v{e}n\\'y", "authors": "Onur \\c{C}a\\u{g}{\\i}r{\\i}c{\\i}, Petr Hlin\\v{e}n\\'y, Filip Pokr\\'yvka,\n  Abhisekh Sankaran", "title": "Clique-Width of Point Configurations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While structural width parameters (of the input) belong to the standard\ntoolbox of graph algorithms, it is not the usual case in computational\ngeometry. As a case study we propose a natural extension of the structural\ngraph parameter of clique-width to geometric point configurations represented\nby their order type. We study basic properties of this clique-width notion, and\nrelate it to the monadic second-order logic of point configurations. As an\napplication, we provide several linear FPT time algorithms for geometric point\nproblems which are NP-hard in general, in the special case that the input point\nset is of bounded clique-width and the clique-width expression is also given.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 19:08:52 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["\u00c7a\u011f\u0131r\u0131c\u0131", "Onur", ""], ["Hlin\u011bn\u00fd", "Petr", ""], ["Pokr\u00fdvka", "Filip", ""], ["Sankaran", "Abhisekh", ""]]}, {"id": "2004.02462", "submitter": "Yuval Jacoby", "authors": "Yuval Jacoby, Clark Barrett, Guy Katz", "title": "Verifying Recurrent Neural Networks using Invariant Inference", "comments": "This is the extended version of a paper with the same title that\n  appeared at ATVA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are revolutionizing the way complex systems are\ndeveloped. However, these automatically-generated networks are opaque to\nhumans, making it difficult to reason about them and guarantee their\ncorrectness. Here, we propose a novel approach for verifying properties of a\nwidespread variant of neural networks, called recurrent neural networks.\nRecurrent neural networks play a key role in, e.g., natural language\nprocessing, and their verification is crucial for guaranteeing the reliability\nof many critical systems. Our approach is based on the inference of invariants,\nwhich allow us to reduce the complex problem of verifying recurrent networks\ninto simpler, non-recurrent problems. Experiments with a proof-of-concept\nimplementation of our approach demonstrate that it performs orders-of-magnitude\nbetter than the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 08:08:24 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 08:38:35 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Jacoby", "Yuval", ""], ["Barrett", "Clark", ""], ["Katz", "Guy", ""]]}, {"id": "2004.02610", "submitter": "Chuanzheng Wang", "authors": "Chuanzheng Wang, Yinan Li, Stephen L. Smith, Jun Liu", "title": "Continuous Motion Planning with Temporal Logic Specifications using Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a model-free reinforcement learning method to\nsynthesize control policies for motion planning problems with continuous states\nand actions. The robot is modelled as a labeled discrete-time Markov decision\nprocess (MDP) with continuous state and action spaces. Linear temporal logics\n(LTL) are used to specify high-level tasks. We then train deep neural networks\nto approximate the value function and policy using an actor-critic\nreinforcement learning method. The LTL specification is converted into an\nannotated limit-deterministic B\\\"uchi automaton (LDBA) for continuously shaping\nthe reward so that dense rewards are available during training. A na\\\"ive way\nof solving a motion planning problem with LTL specifications using\nreinforcement learning is to sample a trajectory and then assign a high reward\nfor training if the trajectory satisfies the entire LTL formula. However, the\nsampling complexity needed to find such a trajectory is too high when we have a\ncomplex LTL formula for continuous state and action spaces. As a result, it is\nvery unlikely that we get enough reward for training if all sample trajectories\nstart from the initial state in the automata. In this paper, we propose a\nmethod that samples not only an initial state from the state space, but also an\narbitrary state in the automata at the beginning of each training episode. We\ntest our algorithm in simulation using a car-like robot and find out that our\nmethod can learn policies for different working configurations and LTL\nspecifications successfully.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:58:03 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 19:18:54 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wang", "Chuanzheng", ""], ["Li", "Yinan", ""], ["Smith", "Stephen L.", ""], ["Liu", "Jun", ""]]}, {"id": "2004.02671", "submitter": "Nassim Dehouche", "authors": "Nassim Dehouche", "title": "On Evaluating the Quality of Rule-Based Classification Systems", "comments": "ICIC Express Letters Volume 11, Number 10, October 2017", "journal-ref": "ICIC Express Letters ICIC International c 2013 ISSN 1881-803X ICIC\n  Express Letters Volume 11, Number 10, October 2017 c 2013 ISSN 1881-803X\n  Volume 11, Number 10, October 2017", "doi": "10.24507/icicel.11.10.1515", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two indicators are classically used to evaluate the quality of rule-based\nclassification systems: predictive accuracy, i.e. the system's ability to\nsuccessfully reproduce learning data and coverage, i.e. the proportion of\npossible cases for which the logical rules constituting the system apply. In\nthis work, we claim that these two indicators may be insufficient, and\nadditional measures of quality may need to be developed. We theoretically show\nthat classification systems presenting \"good\" predictive accuracy and coverage\ncan, nonetheless, be trivially improved and illustrate this proposition with\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:41:49 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Dehouche", "Nassim", ""]]}, {"id": "2004.02770", "submitter": "Fahad Siddiqui", "authors": "Fahad Siddiqui, Matthew Hagan, Sakir Sezer", "title": "Establishing Cyber Resilience in Embedded Systems for Securing\n  Next-Generation Critical Infrastructure", "comments": "6 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mass integration and deployment of intelligent technologies within\ncritical commercial, industrial and public environments have a significant\nimpact on business operations and society as a whole. Though integration of\nthese critical intelligent technologies pose serious embedded security\nchallenges for technology manufacturers which are required to be systematically\napproached, in-line with international security regulations. This paper\nestablish security foundation for such intelligent technologies by deriving\nembedded security requirements to realise the core security functions laid out\nby international security authorities, and proposing microarchitectural\ncharacteristics to establish cyber resilience in embedded systems. To bridge\nthe research gap between embedded and operational security domains, a detailed\nreview of existing embedded security methods, microarchitectures and design\npractises is presented. The existing embedded security methods have been found\nad-hoc, passive and strongly rely on building and maintaining trust. To the\nbest of our knowledge to date, no existing embedded security microarchitecture\nor defence mechanism provides continuity of data stream or security once trust\nhas broken. This functionality is critical for embedded technologies deployed\nin critical infrastructure to enhance and maintain security, and to gain\nevidence of the security breach to effectively evaluate, improve and deploy\nactive response and mitigation strategies. To this end, the paper proposes\nthree microarchitectural characteristics that shall be designed and integrated\ninto embedded architectures to establish, maintain and improve cyber resilience\nin embedded systems for next-generation critical infrastructure.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:56:46 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Siddiqui", "Fahad", ""], ["Hagan", "Matthew", ""], ["Sezer", "Sakir", ""]]}, {"id": "2004.02983", "submitter": "Brijesh Dongol", "authors": "Sadegh Dalvandi, Brijesh Dongol, and Simon Doherty", "title": "Integrating Owicki-Gries for C11-Style Memory Models into Isabelle/HOL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weak memory presents a new challenge for program verification and has\nresulted in the development of a variety of specialised logics. For C11-style\nmemory models, our previous work has shown that it is possible to extend Hoare\nlogic and Owicki-Gries reasoning to verify correctness of weak memory programs.\nThe technique introduces a set of high-level assertions over C11 states\ntogether with a set of basic Hoare-style axioms over atomic weak memory\nstatements (e.g., reads/writes), but retains all other standard proof\nobligations for compound statements. This paper takes this line of work further\nby showing Nipkow and Nieto's encoding of Owicki-Gries in the Isabelle theorem\nprover can be extended to handle C11-style weak memory models in a\nstraightforward manner. We exemplify our techniques over several litmus tests\nfrom the literature and a non-trivial example: Peterson's algorithm adapted for\nC11. For the examples we consider, the proof outlines can be automatically\ndischarged using the existing Isabelle tactics developed by Nipkow and Nieto.\nThe benefit here is that programs can be written using a familiar pseudocode\nsyntax with assertions embedded directly into the program.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 20:20:30 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 21:58:52 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Dalvandi", "Sadegh", ""], ["Dongol", "Brijesh", ""], ["Doherty", "Simon", ""]]}, {"id": "2004.03170", "submitter": "Francesco Ranzato", "authors": "Francesco Ranzato", "title": "Decidability and Synthesis of Abstract Inductive Invariants", "comments": null, "journal-ref": "Proceedings of CONCUR 2020", "doi": "10.4230/LIPIcs.CONCUR.2020.48", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decidability and synthesis of inductive invariants ranging in a given domain\nplay an important role in many software and hardware verification systems. We\nconsider here inductive invariants belonging to an abstract domain $A$ as\ndefined in abstract interpretation, namely, ensuring the existence of the best\napproximation in $A$ of any system property. In this setting, we study the\ndecidability of the existence of abstract inductive invariants in $A$ of\ntransition systems and their corresponding algorithmic synthesis. Our model\nrelies on some general results which relate the existence of abstract inductive\ninvariants with least fixed points of best correct approximations in $A$ of the\ntransfer functions of transition systems and their completeness properties.\nThis approach allows us to derive decidability and synthesis results for\nabstract inductive invariants which are applied to the well-known Kildall's\nconstant propagation and Karr's affine equalities abstract domains. Moreover,\nwe show that a recent general algorithm for synthesizing inductive invariants\nin domains of logical formulae can be systematically derived from our results\nand generalized to a range of algorithms for computing abstract inductive\ninvariants.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 07:31:52 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 16:04:11 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ranzato", "Francesco", ""]]}, {"id": "2004.03557", "submitter": "Stelios Tsampas", "authors": "Stelios Tsampas, Andreas Nuyts, Dominique Devriese and Frank Piessens", "title": "A categorical approach to secure compilation", "comments": "Accepted in Coalgebraic Methods in Computer Science, ver. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach to secure compilation based on maps of\ndistributive laws. We demonstrate through four examples that the coherence\ncriterion for maps of distributive laws can potentially be a viable alternative\nfor compiler security instead of full abstraction, which is the preservation\nand reflection of contextual equivalence. To that end, we also make use of the\nwell-behavedness properties of distributive laws to construct a categorical\nargument for the contextual connotations of bisimilarity.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:32:21 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Tsampas", "Stelios", ""], ["Nuyts", "Andreas", ""], ["Devriese", "Dominique", ""], ["Piessens", "Frank", ""]]}, {"id": "2004.03592", "submitter": "Ahana Pradhan", "authors": "Ahana Pradhan and Rushikesh K. Joshi", "title": "A Structural Approach to Dynamic Migration in Petri Net Models of\n  Structured Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of dynamic evolution of workflow processes, the change region\nidentifies the part of the old process from which migration to the new process\nis guaranteed to be inconsistent. However, this approach may lead to\noverestimated regions, incorrectly identifying migratable instances as\nnon-migratable. This overestimation causes delays due to postponement of\nimmediate migration. The paper analyzes this overestimation problem on a class\nof Petri nets models. Structural properties leading to conditions for minimal\nchange regions and overestimations are developed resulting into classification\nof change regions into two types of change regions called Structural Change\nRegions and Perfect Structural Change Regions. Necessary and sufficient\nconditions for perfect regions are identified. The paper also discusses ways\nfor computing the same in terms of structural properties of the old and the new\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 07:05:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Pradhan", "Ahana", ""], ["Joshi", "Rushikesh K.", ""]]}, {"id": "2004.03719", "submitter": "Christoph Strnadl", "authors": "Christoph F. Strnadl", "title": "The Mathematical Syntax of Architectures", "comments": "22 pages, 4 figures, 1 table, 12 definitions, 2 theorems, 1 lemma, 1\n  corollary. This is a considerably extended version of the initial submission\n  with new material in almost every section including minor technical\n  amendments and (typographical) corrections", "journal-ref": null, "doi": null, "report-no": "Report no.: SAG-CTO-20-002", "categories": "cs.LO cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite several (accepted) standards, core notions typically employed in\ninformation technology or system engineering architectures lack the precise and\nexact foundations encountered in logic, algebra, and other branches of\nmathematics.\n  In this contribution we define the syntactical aspects of the term\narchitecture in a mathematically rigorous way. We motivate our particular\nchoice by demonstrating (i) how commonly understood and expected properties of\nan architecture--as defined by various standards--can be suitably identified or\nderived within our formalization, (ii) how our concept is fully compatible with\nreal life (business) architectures, and (iii) how our definition complements\nrecent foundational work in this area (Wilkinson 2018, Dickersen 2020).\n  We furthermore develop a rigorous notion of architectural similarity based on\nthe notion of homomorphisms allowing the class of architectures to be regarded\nas a category, Arch. We demonstrate the applicability of our concepts to theory\nby deriving theorems on the classification of certain types of architectures.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 21:18:31 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 08:19:16 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Strnadl", "Christoph F.", ""]]}, {"id": "2004.03924", "submitter": "Dominik Wagner", "authors": "Carol Mak, C.-H. Luke Ong, Hugo Paquet and Dominik Wagner", "title": "Densities of Almost Surely Terminating Probabilistic Programs are\n  Differentiable Almost Everywhere", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-72019-3_16", "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the differential properties of higher-order statistical\nprobabilistic programs with recursion and conditioning. Our starting point is\nan open problem posed by Hongseok Yang: what class of statistical probabilistic\nprograms have densities that are differentiable almost everywhere? To formalise\nthe problem, we consider Statistical PCF (SPCF), an extension of call-by-value\nPCF with real numbers, and constructs for sampling and conditioning. We give\nSPCF a sampling-style operational semantics a la Borgstrom et al., and study\nthe associated weight (commonly referred to as the density) function and value\nfunction on the set of possible execution traces. Our main result is that\nalmost-surely terminating SPCF programs, generated from a set of primitive\nfunctions (e.g. the set of analytic functions) satisfying mild closure\nproperties, have weight and value functions that are almost-everywhere\ndifferentiable. We use a stochastic form of symbolic execution to reason about\nalmost-everywhere differentiability. A by-product of this work is that\nalmost-surely terminating deterministic (S)PCF programs with real parameters\ndenote functions that are almost-everywhere differentiable. Our result is of\npractical interest, as almost-everywhere differentiability of the density\nfunction is required to hold for the correctness of major gradient-based\ninference algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 10:40:14 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 16:00:29 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Mak", "Carol", ""], ["Ong", "C. -H. Luke", ""], ["Paquet", "Hugo", ""], ["Wagner", "Dominik", ""]]}, {"id": "2004.04034", "submitter": "James Davenport", "authors": "Erika {\\'A}brah\\'am, James Davenport, Matthew England, Gereon Kremer,\n  and Zak Tonks", "title": "New Opportunities for the Formal Proof of Computational Real Geometry?", "comments": null, "journal-ref": "Proceedings of the 5th Workshop on Satisfiability Checking and\n  Symbolic Computation (SC2 '20), CEUR Workshop Proceedings 2752, pp. 178-188,\n  2020", "doi": null, "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to explore the question \"to what extent could we\nproduce formal, machine-verifiable, proofs in real algebraic geometry?\" The\nquestion has been asked before but as yet the leading algorithms for answering\nsuch questions have not been formalised. We present a thesis that a new\nalgorithm for ascertaining satisfiability of formulae over the reals via\nCylindrical Algebraic Coverings [\\'{A}brah\\'{a}m, Davenport, England, Kremer,\n\\emph{Deciding the Consistency of Non-Linear Real Arithmetic Constraints with a\nConflict Driver Search Using Cylindrical Algebraic Coverings}, 2020] might\nprovide trace and outputs that allow the results to be more susceptible to\nmachine verification than those of competing algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 15:04:18 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["{\u00c1}brah\u00e1m", "Erika", ""], ["Davenport", "James", ""], ["England", "Matthew", ""], ["Kremer", "Gereon", ""], ["Tonks", "Zak", ""]]}, {"id": "2004.04128", "submitter": "Adriana Correia", "authors": "A. D. Correia, H. T. C. Stoof, M. Moortgat", "title": "Putting a Spin on Language: A Quantum Interpretation of Unary\n  Connectives for Linguistic Applications", "comments": "24 pages, 4 figures, QPL20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extended versions of the Lambek Calculus currently used in computational\nlinguistics rely on unary modalities to allow for the controlled application of\nstructural rules affecting word order and phrase structure. These controlled\nstructural operations give rise to derivational ambiguities that are missed by\nthe original Lambek Calculus or its pregroup simplification. Proposals for\ncompositional interpretation of extended Lambek Calculus in the compact closed\ncategory of FVect and linear maps have been made, but in these proposals the\nsyntax-semantics mapping ignores the control modalities, effectively\nrestricting their role to the syntax. Our aim is to turn the modalities into\nfirst-class citizens of the vectorial interpretation. Building on the\ndirectional density matrix semantics, we extend the interpretation of the type\nsystem with an extra spin density matrix space. The interpretation of proofs\nthen results in ambiguous derivations being tensored with orthogonal spin\nstates. Our method introduces a way of simultaneously representing co existing\ninterpretations of ambiguous utterances, and provides a uniform framework for\nthe integration of lexical and derivational ambiguity.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:25:11 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 14:47:12 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Correia", "A. D.", ""], ["Stoof", "H. T. C.", ""], ["Moortgat", "M.", ""]]}, {"id": "2004.04147", "submitter": "Lia Morra", "authors": "Lia Morra, Francesco Manigrasso, Giuseppe Canto, Claudio Gianfrate,\n  Enrico Guarino, Fabrizio Lamberti", "title": "Slicing and dicing soccer: automatic detection of complex events from\n  spatio-temporal data", "comments": "accepted at 17th International Conference on Image Analysis and\n  Recognition ICIAR 2020", "journal-ref": null, "doi": "10.1007/978-3-030-50347-5_11", "report-no": null, "categories": "cs.CV cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic detection of events in sport videos has im-portant applications\nfor data analytics, as well as for broadcasting andmedia companies. This paper\npresents a comprehensive approach for de-tecting a wide range of complex events\nin soccer videos starting frompositional data. The event detector is designed\nas a two-tier system thatdetectsatomicandcomplex events. Atomic events are\ndetected basedon temporal and logical combinations of the detected objects,\ntheir rel-ative distances, as well as spatio-temporal features such as velocity\nandacceleration. Complex events are defined as temporal and logical\ncom-binations of atomic and complex events, and are expressed by meansof a\ndeclarative Interval Temporal Logic (ITL). The effectiveness of theproposed\napproach is demonstrated over 16 different events, includingcomplex situations\nsuch as tackles and filtering passes. By formalizingevents based on principled\nITL, it is possible to easily perform reason-ing tasks, such as understanding\nwhich passes or crosses result in a goalbeing scored. To counterbalance the\nlack of suitable, annotated publicdatasets, we built on an open source soccer\nsimulation engine to re-lease the synthetic SoccER (Soccer Event Recognition)\ndataset, whichincludes complete positional data and annotations for more than\n1.6 mil-lion atomic events and 9,000 complex events. The dataset and code\nareavailable at https://gitlab.com/grains2/slicing-and-dicing-soccer\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:57:50 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 07:30:55 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Morra", "Lia", ""], ["Manigrasso", "Francesco", ""], ["Canto", "Giuseppe", ""], ["Gianfrate", "Claudio", ""], ["Guarino", "Enrico", ""], ["Lamberti", "Fabrizio", ""]]}, {"id": "2004.04214", "submitter": "Peeyush Kushwahah", "authors": "Peeyush Kushwaha, Rahul Purandare, and Matthew B. Dwyer", "title": "Optimal Runtime Verification of Finite State Properties over Lossy Event\n  Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring programs for finite state properties is challenging due to high\nmemory and execution time overheads it incurs. Some events if skipped or lost\nnaturally can reduce both overheads, but lead to uncertainty about the current\nmonitor state. In this work, we present a theoretical framework to model these\nlossy event streams and provide a construction for a monitor which observes\nthem without producing false positives. The constructed monitor is optimally\nsound among all complete monitors. We model several loss types of practical\nrelevance using our framework and provide construction of smaller approximate\nmonitors for properties with a large number of states.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 19:23:25 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Kushwaha", "Peeyush", ""], ["Purandare", "Rahul", ""], ["Dwyer", "Matthew B.", ""]]}, {"id": "2004.04526", "submitter": "EPTCS", "authors": "Mario Rom\\'an (Tallinn University of Technology)", "title": "Open Diagrams via Coend Calculus", "comments": "In Proceedings ACT 2020, arXiv:2101.07888", "journal-ref": "EPTCS 333, 2021, pp. 65-78", "doi": "10.4204/EPTCS.333.5", "report-no": null, "categories": "math.CT cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morphisms in a monoidal category are usually interpreted as processes, and\ngraphically depicted as square boxes. In practice, we are faced with the\nproblem of interpreting what non-square boxes ought to represent in terms of\nthe monoidal category and, more importantly, how should they be composed.\nExamples of this situation include lenses or learners. We propose a description\nof these non-square boxes, which we call open diagrams, using the monoidal\nbicategory of profunctors. A graphical coend calculus can then be used to\nreason about open diagrams and their compositions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 13:15:06 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 12:55:34 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 13:45:34 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2021 00:02:44 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Rom\u00e1n", "Mario", "", "Tallinn University of Technology"]]}, {"id": "2004.04854", "submitter": "Yoni Zohar", "authors": "Ying Sheng, Yoni Zohar, Christophe Ringeissen, Jane Lange, Pascal\n  Fontaine, Clark Barrett", "title": "Politeness for the Theory of Algebraic Datatypes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic datatypes, and among them lists and trees, have attracted a lot of\ninterest in automated reasoning and Satisfiability Modulo Theories (SMT). Since\nits latest stable version, the SMT-LIB standard defines a theory of algebraic\ndatatypes, which is currently supported by several mainstream SMT solvers. In\nthis paper, we study this particular theory of datatypes and prove that it is\nstrongly polite, showing also how it can be combined with other arbitrary\ndisjoint theories using polite combination. Our results cover both inductive\nand finite datatypes, as well as their union. The combination method uses a\nnew, simple, and natural notion of additivity, that enables deducing strong\npoliteness from (weak) politeness.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:32:12 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 01:56:31 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 15:58:30 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Sheng", "Ying", ""], ["Zohar", "Yoni", ""], ["Ringeissen", "Christophe", ""], ["Lange", "Jane", ""], ["Fontaine", "Pascal", ""], ["Barrett", "Clark", ""]]}, {"id": "2004.04896", "submitter": "Nouraldin Jaber", "authors": "Nouraldin Jaber (1), Swen Jacobs (2), Christopher Wagner (1), Milind\n  Kulkarni (1), Roopsha Samanta (1) ((1) Purdue University, (2) CISPA Helmholtz\n  Center for Information Security)", "title": "Parameterized Verification of Systems with Global Synchronization and\n  Guards", "comments": "Conference version published at CAV 2020; this version contains a\n  correction of guard-compatibility conditions C2.1 and C2.2", "journal-ref": "Lecture Notes in Computer Science, vol 12224. Springer (2020)", "doi": "10.1007/978-3-030-53288-8_15", "report-no": null, "categories": "cs.FL cs.DC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by distributed applications that use consensus or other agreement\nprotocols for global coordination, we define a new computational model for\nparameterized systems that is based on a general global synchronization\nprimitive and allows for global transition guards. Our model generalizes many\nexisting models in the literature, including broadcast protocols and guarded\nprotocols. We show that reachability properties are decidable for systems\nwithout guards, and give sufficient conditions under which they remain\ndecidable in the presence of guards. Furthermore, we investigate cutoffs for\nreachability properties and provide sufficient conditions for small cutoffs in\na number of cases that are inspired by our target applications.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 03:59:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 17:23:55 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 02:47:55 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Jaber", "Nouraldin", ""], ["Jacobs", "Swen", ""], ["Wagner", "Christopher", ""], ["Kulkarni", "Milind", ""], ["Samanta", "Roopsha", ""]]}, {"id": "2004.05287", "submitter": "Cole Comfort", "authors": "Cole Comfort", "title": "The ZX& calculus: A complete graphical calculus for classical circuits\n  using spiders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a complete presentation for the fragment, ZX&, of the ZX-calculus\ngenerated by the Z and X spiders (corresponding to copying and addition) along\nwith the not gate and the and gate. To prove completeness, we freely add a unit\nand counit to the category TOF generated by the Toffoli gate and ancillary\nbits, showing that this yields the full subcategory of finite ordinals and\nfunctions with objects powers of two; and then perform a two way translation\nbetween this category and ZX&. A translation to some extension of TOF, as\nopposed to some fragment of the ZX-calculus, is a natural choice because of the\nmultiplicative nature of the Toffoli gate. To this end, we show that freely\nadding counits to the semi-Frobenius algebras of a discrete inverse category is\nthe same as constructing the cartesian completion. In particular, for a\ndiscrete inverse category, the category of classical channels, the Cartesian\ncompletion and adding counits all produce the same category. Therefore,\napplying these constructions to TOF produces the full subcategory of finite\nordinals and partial maps with objects powers of two. By glueing together the\nfree counit completion and the free unit completion, this yields \"qubit\nmultirelations\".\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 03:02:24 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 04:36:20 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 23:25:54 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 13:16:13 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Comfort", "Cole", ""]]}, {"id": "2004.05392", "submitter": "Dieter Spreen", "authors": "Dieter Spreen", "title": "Computing with Continuous Objects: A Uniform Co-inductive Approach", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.DS math.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A uniform approach to computing with infinite objects like real numbers,\ntuples of these, compacts sets, and uniformly continuous maps is presented. In\nwork of Berger it was shown how to extract certified algorithms working with\nthe signed digit representation from constructive proofs. Berger and the\npresent author generalised this approach to complete metric spaces and showed\nhow to deal with compact sets. Here, we unify this work and lay the foundations\nfor doing a similar thing for the much more comprehensive class of compact\nHausdorff spaces occurring in applications. The approach is of the same\ncomputational power as Weihrauch's Type-Two Theory of Effectivity.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 13:02:44 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 08:04:57 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 15:31:20 GMT"}, {"version": "v4", "created": "Wed, 7 Oct 2020 12:46:28 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2020 17:16:07 GMT"}, {"version": "v6", "created": "Sat, 6 Mar 2021 18:06:05 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Spreen", "Dieter", ""]]}, {"id": "2004.05400", "submitter": "Jurriaan Rot", "authors": "Jurriaan Rot, Bart Jacobs, Paul Levy", "title": "Steps and Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the theory of coalgebras, trace semantics can be defined in various\ndistinct ways, including through algebraic logics, the Kleisli category of a\nmonad or its Eilenberg-Moore category. This paper elaborates two new unifying\nideas: 1) coalgebraic trace semantics is naturally presented in terms of\ncorecursive algebras, and 2) all three approaches arise as instances of the\nsame abstract setting. Our perspective puts the different approaches under a\ncommon roof, and allows to derive conditions under which some of them coincide.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 13:32:00 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Rot", "Jurriaan", ""], ["Jacobs", "Bart", ""], ["Levy", "Paul", ""]]}, {"id": "2004.05688", "submitter": "Gershom Bazerman", "authors": "Gershom Bazerman, Raymond Puzio", "title": "The Topological and Logical Structure of Concurrency and Dependency via\n  Distributive Lattices", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is motivated by the desire to study package management using the\ntoolkit of the semantics of functional languages. As it transpires, this is\ndeeply related to the semantics of concurrent computation. The models we\nproduce are not solely of theoretical interest, but amenable to analysis and\ncomputation. This work makes a number of related contributions. First, it\nrelates the specification of branching dependency structures, which exist in\nfields from knowledge-representation to package management, to the\nspecification of semantics of concurrent computation. Second, it relates\ndependency structures to lattices in a precise way, establishing a full\ncorrespondence with a particular subclass of lattices. It then makes use of\nthis as a key ingredient, coupled with the underappreciated Bruns-Lakser\ncompletion, in relating dependency structures to locales -- objects equipped\nwith both topological and logical properties. It then provides an example of\nhow this interplay of properties can be of use -- using topological properties\nof the dependency structure to equip internal logics of associated locales with\na modality representing contraction relations (i.e. \"versioning\"). This\napproach lets us see linking (or rather, the choice of what to link against,\ni.e. \"solving\") as an effect. Finally, it discusses how such constructions may\nrelate to important questions in complexity theory, including solutions of\nsatisfiability problems. Along the way, we will see how this approach relates\nto familiar objects such as package version policies, Merkle-trees, the nix\noperating system, and distributed version control tooling like git.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 20:17:03 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Bazerman", "Gershom", ""], ["Puzio", "Raymond", ""]]}, {"id": "2004.05802", "submitter": "Hans van Ditmarsch", "authors": "Hans van Ditmarsch", "title": "To Be Announced", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this survey we review dynamic epistemic logics with modalities for\nquantification over information change. Of such logics we present complete\naxiomatizations, focussing on axioms involving the interaction between\nknowledge and such quantifiers, we report on their relative expressivity, on\ndecidability and on the complexity of model checking and satisfiability, and on\napplications. We focus on open problems and new directions for research.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:34:02 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 18:11:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["van Ditmarsch", "Hans", ""]]}, {"id": "2004.05853", "submitter": "Eugene Goldberg", "authors": "Eugene Goldberg", "title": "Generation Of A Complete Set Of Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the problems of formal verification is that it is not functionally\ncomplete due the incompleteness of specifications. An implementation meeting an\nincomplete specification may still have a lot of bugs. In testing, this issue\nis addressed by replacing functional completeness with $\\mathit{structural}$\none. The latter is achieved by generating a set of tests probing every piece of\na design implementation. We show that a similar approach can be used in formal\nverification. The idea here is to generate a property of the implementation at\nhand that is not implied by the specification. Finding such a property means\nthat the specification is not complete. If this is an $\\mathit{unwanted}$\nproperty, the implementation is buggy. Otherwise, a new specification property\nneeds to be added. Generation of implementation properties related to different\nparts of the design followed by adding new specification properties produces a\n$\\mathit{structurally}$-$\\mathit{complete\\:specification}$. Implementation\nproperties are built by $\\mathit{partial\\: quantifier\\:elimination}$, a\ntechnique where only a part of the formula is taken out of the scope of\nquantifiers. An implementation property is generated by applying partial\nquantifier elimination to a formula defining the \"truth table\" of the\nimplementation. We show how our approach works on specifications of\ncombinational and sequential circuits.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 10:27:12 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 13:00:07 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 14:15:39 GMT"}, {"version": "v4", "created": "Mon, 12 Oct 2020 23:35:52 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Goldberg", "Eugene", ""]]}, {"id": "2004.05936", "submitter": "Michael Pinsker", "authors": "Antoine Mottet, Michael Pinsker", "title": "Cores over Ramsey structures", "comments": "9 pages", "journal-ref": null, "doi": "10.1017/jsl.2021.6", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that if an $\\omega$-categorical structure has an\n$\\omega$-categorical homogeneous Ramsey expansion, then so does its\nmodel-complete core.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:44:05 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 16:53:56 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2021 19:41:15 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Mottet", "Antoine", ""], ["Pinsker", "Michael", ""]]}, {"id": "2004.05943", "submitter": "Irene Guessarian", "authors": "Patrick Cegielski, Serge Grigorieff, Irene Guessarian", "title": "Congruence Preservation, Lattices and Recognizability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Looking at some monoids and (semi)rings (natural numbers, integers and p-adic\nintegers), and more generally, residually finite algebras (in a strong sense),\nwe prove the equivalence of two ways for a function on such an algebra to\nbehave like the operations of the algebra. The first way is to preserve\ncongruences or stable preorders. The second way is to demand that preimages of\nrecognizable sets belong to the lattice or the Boolean algebra generated by the\npreimages of recognizable sets by derived unary operation of the algebra (such\nas translations, quotients,. . . ).\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:57:37 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Cegielski", "Patrick", ""], ["Grigorieff", "Serge", ""], ["Guessarian", "Irene", ""]]}, {"id": "2004.06572", "submitter": "Benedikt Ahrens", "authors": "Benedikt Ahrens, Paige Randall North, Michael Shulman, Dimitris\n  Tsementzis", "title": "A Higher Structure Identity Principle", "comments": "Long version of publication in LICS 2020 (DOI:\n  10.1145/3373718.3394755); v2: added sections \"Axioms and Theories\" and\n  \"Version History\", other minor changes; v3: added examples", "journal-ref": null, "doi": "10.1145/3373718.3394755", "report-no": null, "categories": "math.LO cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ordinary Structure Identity Principle states that any property of\nset-level structures (e.g., posets, groups, rings, fields) definable in\nUnivalent Foundations is invariant under isomorphism: more specifically,\nidentifications of structures coincide with isomorphisms. We prove a version of\nthis principle for a wide range of higher-categorical structures, adapting\nFOLDS-signatures to specify a general class of structures, and using two-level\ntype theory to treat all categorical dimensions uniformly. As in the previously\nknown case of 1-categories (which is an instance of our theory), the structures\nthemselves must satisfy a local univalence principle, stating that\nidentifications coincide with \"isomorphisms\" between elements of the structure.\nOur main technical achievement is a definition of such isomorphisms, which we\ncall \"indiscernibilities\", using only the dependency structure rather than any\nnotion of composition.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:57:13 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 01:31:23 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 12:32:12 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ahrens", "Benedikt", ""], ["North", "Paige Randall", ""], ["Shulman", "Michael", ""], ["Tsementzis", "Dimitris", ""]]}, {"id": "2004.06637", "submitter": "Clemens Dubslaff", "authors": "Clemens Dubslaff, Andrey Morozov, Christel Baier, Klaus Janschek", "title": "Reduction Methods on Probabilistic Control-flow Programs for Reliability\n  Analysis", "comments": "This paper is a preprint of the corresponding ESREL/PSAM 2020\n  conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PF cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern safety-critical systems are heterogeneous, complex, and highly\ndynamic. They require reliability evaluation methods that go beyond the\nclassical static methods such as fault trees, event trees, or reliability block\ndiagrams. Promising dynamic reliability analysis methods employ probabilistic\nmodel checking on various probabilistic state-based models. However, such\nmethods have to tackle the well-known state-space explosion problem. To compete\nwith this problem, reduction methods such as symmetry reduction and\npartial-order reduction have been successfully applied to probabilistic models\nby means of discrete Markov chains or Markov decision processes. Such models\nare usually specified using probabilistic programs provided in guarded command\nlanguage. In this paper, we propose two automated reduction methods for\nprobabilistic programs that operate on a purely syntactic level: reset value\noptimization and register allocation optimization. The presented techniques\nrely on concepts well known from compiler construction such as live range\nanalysis and register allocation through interference graph coloring. Applied\non a redundancy system model for an aircraft velocity control loop modeled in\nSIMULINK, we show effectiveness of our implementation of the reduction methods.\nWe demonstrate that model-size reductions in three orders of magnitude are\npossible and show that we can achieve significant speedups for a reliability\nanalysis.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 16:27:36 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Dubslaff", "Clemens", ""], ["Morozov", "Andrey", ""], ["Baier", "Christel", ""], ["Janschek", "Klaus", ""]]}, {"id": "2004.06997", "submitter": "Zsolt Zombori", "authors": "Zsolt Zombori, Josef Urban, Chad E. Brown", "title": "Prolog Technology Reinforcement Learning Prover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning toolkit for experiments with guiding\nautomated theorem proving in the connection calculus. The core of the toolkit\nis a compact and easy to extend Prolog-based automated theorem prover called\nplCoP. plCoP builds on the leanCoP Prolog implementation and adds\nlearning-guided Monte-Carlo Tree Search as done in the rlCoP system. Other\ncomponents include a Python interface to plCoP and machine learners, and an\nexternal proof checker that verifies the validity of plCoP proofs. The toolkit\nis evaluated on two benchmarks and we demonstrate its extendability by two\nadditions: (1) guidance is extended to reduction steps and (2) the standard\nleanCoP calculus is extended with rewrite steps and their learned guidance. We\nargue that the Prolog setting is suitable for combining statistical and\nsymbolic learning methods. The complete toolkit is publicly released.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 10:52:04 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Zombori", "Zsolt", ""], ["Urban", "Josef", ""], ["Brown", "Chad E.", ""]]}, {"id": "2004.07058", "submitter": "Christoph L\\\"uders", "authors": "Christoph L\\\"uders", "title": "Computing Tropical Prevarieties with Satisfiability Modulo Theories\n  (SMT) Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel way to use SMT (Satisfiability Modulo Theories) solvers to compute\nthe tropical prevariety (resp. equilibrium) of a polynomial system is\npresented. The new method is benchmarked against a naive approach that uses\npurely polyhedral methods. It turns out that the SMT approach is faster than\nthe polyhedral approach for models that would otherwise take more than one\nminute to compute, in many cases by a factor of 60 or more, and in the worst\ncase is only slower by a factor of two. Furthermore, the new approach is an\nanytime algorithm, thus offering a way to compute parts of the solution when\nthe polyhedral approach is infeasible.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 12:37:17 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 08:39:10 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 17:34:32 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["L\u00fcders", "Christoph", ""]]}, {"id": "2004.07221", "submitter": "Vladislav Ryzhikov Dr", "authors": "Alessandro Artale, Roman Kontchakov, Alisa Kovtunova, Vladislav\n  Ryzhikov, Frank Wolter, Michael Zakharyaschev", "title": "First-Order Rewritability of Ontology-Mediated Queries in Linear\n  Temporal Logic", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2021.103536", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate ontology-based data access to temporal data. We consider\ntemporal ontologies given in linear temporal logic LTL interpreted over\ndiscrete time (Z,<). Queries are given in LTL or MFO(<), monadic first-order\nlogic with a built-in linear order. Our concern is first-order rewritability of\nontology-mediated queries (OMQs) consisting of a temporal ontology and a query.\nBy taking account of the temporal operators used in the ontology and\ndistinguishing between ontologies given in full LTL and its core, Krom and Horn\nfragments, we identify a hierarchy of OMQs with atomic queries by proving\nrewritability into either FO(<), first-order logic with the built-in linear\norder, or FO(<,E), which extends FO(<) with the standard arithmetic predicates\nsaying that \"x is equivalent to 0 modulo n\", for any fixed n > 1, or FO(RPR),\nwhich extends FO(<) with relational primitive recursion. In terms of circuit\ncomplexity, FO(<,E)- and FO(RPR)-rewritability guarantee OMQ answering in\nuniform AC0 and, respectively, NC1.\n  We obtain similar hierarchies for more expressive types of queries: positive\nLTL-formulas, monotone MFO(<)- and arbitrary MFO(<)-formulas. Our results are\ndirectly applicable if the temporal data to be accessed is one-dimensional;\nmoreover, they lay foundations for investigating ontology-based access using\ncombinations of temporal and description logics over two-dimensional temporal\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:22:10 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 17:47:40 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 10:00:54 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 10:30:51 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Artale", "Alessandro", ""], ["Kontchakov", "Roman", ""], ["Kovtunova", "Alisa", ""], ["Ryzhikov", "Vladislav", ""], ["Wolter", "Frank", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "2004.07390", "submitter": "Dominique Larchey-Wendling", "authors": "Dominik Kirst and Dominique Larchey-Wendling", "title": "Trakhtenbrot's Theorem in Coq, A Constructive Approach to Finite Model\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study finite first-order satisfiability (FSAT) in the constructive setting\nof dependent type theory. Employing synthetic accounts of enumerability and\ndecidability, we give a full classification of FSAT depending on the\nfirst-order signature of non-logical symbols. On the one hand, our development\nfocuses on Trakhtenbrot's theorem, stating that FSAT is undecidable as soon as\nthe signature contains an at least binary relation symbol. Our proof proceeds\nby a many-one reduction chain starting from the Post correspondence problem. On\nthe other hand, we establish the decidability of FSAT for monadic first-order\nlogic, i.e. where the signature only contains at most unary function and\nrelation symbols, as well as the enumerability of FSAT for arbitrary enumerable\nsignatures. All our results are mechanised in the framework of a growing Coq\nlibrary of synthetic undecidability proofs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 23:26:04 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Kirst", "Dominik", ""], ["Larchey-Wendling", "Dominique", ""]]}, {"id": "2004.07506", "submitter": "Christoph Benzm\\\"uller", "authors": "Alexander Steen and Christoph Benzm\\\"uller", "title": "On Reductions of Hintikka Sets for Higher-Order Logic", "comments": "10 pages; improved version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steen's (2018) Hintikka set properties for Church's type theory based on\nprimitive equality are reduced to the Hintikka set properties of Brown (2007).\nUsing this reduction, a model existence theorem for Steen's properties is\nderived.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 07:53:12 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 01:49:51 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 13:57:07 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Steen", "Alexander", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2004.07578", "submitter": "Nicolas Peltier", "authors": "Mnacho Echenim, Radu Iosif, and Nicolas Peltier", "title": "Entailment Checking in Separation Logic with Inductive Definitions is\n  2-EXPTIME hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The entailment between separation logic formulae with inductive predicates,\nalso known as symbolic heaps, has been shown to be decidable for a large class\nof inductive definitions. Recently, a 2-EXPTIME algorithm was proposed and an\nEXPTIME-hard bound was established; however no precise lower bound is known. In\nthis paper, we show that deciding entailment between predicate atoms is\n2-EXPTIME-hard. The proof is based on a reduction from the membership problem\nfor exponential-space bounded alternating Turing machines.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 10:38:43 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Echenim", "Mnacho", ""], ["Iosif", "Radu", ""], ["Peltier", "Nicolas", ""]]}, {"id": "2004.07749", "submitter": "Alberto Pettorossi", "authors": "Emanuele De Angelis (1 and 3), Fabio Fioravanti (1), Alberto\n  Pettorossi (2 and 3), Maurizio Proietti (3) ((1) DEC, University G.\n  D'Annunzio, Pescara, Italy, (2) DICII, University of Rome Tor Vergata, Roma,\n  Italy, (3) CNR-IASI, Roma, Italy)", "title": "Removing Algebraic Data Types from Constrained Horn Clauses Using\n  Difference Predicates", "comments": "10th International Joint Conference on Automated Reasoning (IJCAR\n  2020) - version with appendix; added DOI of the final authenticated Springer\n  publication; minor corrections", "journal-ref": "Lecture Notes in Computer Science, vol 12166. Springer, Cham,\n  2020, pp. 83-102", "doi": "10.1007/978-3-030-51074-9_6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of proving the satisfiability of Constrained Horn\nClauses (CHCs) with Algebraic Data Types (ADTs), such as lists and trees. We\npropose a new technique for transforming CHCs with ADTs into CHCs where\npredicates are defined over basic types, such as integers and booleans, only.\nThus, our technique avoids the explicit use of inductive proof rules during\nsatisfiability proofs. The main extension over previous techniques for ADT\nremoval is a new transformation rule, called differential replacement, which\nallows us to introduce auxiliary predicates corresponding to the lemmas that\nare often needed when making inductive proofs. We present an algorithm that\nuses the new rule, together with the traditional folding/unfolding\ntransformation rules, for the automatic removal of ADTs. We prove that if the\nset of the transformed clauses is satisfiable, then so is the set of the\noriginal clauses. By an experimental evaluation, we show that the use of the\ndifferential replacement rule significantly improves the effectiveness of ADT\nremoval, and we show that our transformation-based approach is competitive with\nrespect to a well-established technique that extends the CVC4 solver with\ninduction.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:30:17 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 12:59:09 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 21:24:23 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["De Angelis", "Emanuele", "", "1 and 3"], ["Fioravanti", "Fabio", "", "2 and 3"], ["Pettorossi", "Alberto", "", "2 and 3"], ["Proietti", "Maurizio", ""]]}, {"id": "2004.07904", "submitter": "Philippe Balbiani", "authors": "Philippe Balbiani, \\c{C}i\\u{g}dem Gencer, Maryam Rostamigiv, Tinko\n  Tinchev", "title": "About the unification types of the modal logics determined by classes of\n  deterministic frames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unification problem in a propositional logic is to determine, given a\nformula F, whether there exists a substitution s such that s(F) is in that\nlogic. In that case, s is a unifier of F. When a unifiable formula has minimal\ncomplete sets of unifiers, the formula is either infinitary, finitary, or\nunitary, depending on the cardinality of its minimal complete sets of unifiers.\nIn this paper, we study the unification types of some modal logics determined\nby classes of deterministic frames.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 19:53:41 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Balbiani", "Philippe", ""], ["Gencer", "\u00c7i\u011fdem", ""], ["Rostamigiv", "Maryam", ""], ["Tinchev", "Tinko", ""]]}, {"id": "2004.07940", "submitter": "St\\'ephane Graham-Lengrand", "authors": "St\\'ephane Graham-Lengrand, Dejan Jovanovi\\'c, and Bruno Dutertre", "title": "Solving bitvectors with MCSAT: explanations from bits and pieces (long\n  version)", "comments": "24 pages, long version of IJCAR'2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a decision procedure for the theory of fixed-sized bitvectors in\nthe MCSAT framework. MCSAT is an alternative to CDCL(T) for SMT solving and can\nbe seen as an extension of CDCL to domains other than the Booleans. Our\nprocedure uses BDDs to record and update the sets of feasible values of\nbitvector variables. For explaining conflicts and propagations, we develop\nspecialized word-level interpolation for two common fragments of the theory.\nFor full generality, explaining conflicts outside of the covered fragments\nresorts to local bitblasting. The approach is implemented in the Yices 2 SMT\nsolver and we present experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 20:42:23 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Graham-Lengrand", "St\u00e9phane", ""], ["Jovanovi\u0107", "Dejan", ""], ["Dutertre", "Bruno", ""]]}, {"id": "2004.08059", "submitter": "Ji Guan", "authors": "Ji Guan and Nengkun Yu", "title": "A Probabilistic Logic for Verifying Continuous-time Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The execution of a continuous-time Markov chain (CTMC) can be regarded as a\ncontinuous class of probability distributions over states. In this paper, we\npropose a probabilistic linear-time temporal logic, namely continuous-time\nlinear logic (CLL), to reason about the execution of CTMCs. We define the\nsyntax of CLL over the space of probability distributions. The syntax of CLL\nincludes multiphase until formulas. We derive a corresponding model-checking\nalgorithm for CLL formulas. The correctness of the model-checking algorithm\ndepends on Schanuel's conjecture, a central open problem in transcendental\nnumber theory.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 04:20:40 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 02:23:56 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Guan", "Ji", ""], ["Yu", "Nengkun", ""]]}, {"id": "2004.08144", "submitter": "Marc Van Zee", "authors": "Marc van Zee, Dragan Doder, Leendert van der Torre, Mehdi Dastani,\n  Thomas Icard, Eric Pacuit", "title": "Intention as Commitment toward Time", "comments": "83 pages, 4 figures, Artificial Intelligence journal pre-print", "journal-ref": "Artificial Intelligence, Volume 283, June 2020, 103270", "doi": "10.1016/j.artint.2020.103270", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the interplay among intention, time, and belief in\ndynamic environments. The first contribution is a logic for reasoning about\nintention, time and belief, in which assumptions of intentions are represented\nby preconditions of intended actions. Intentions and beliefs are coherent as\nlong as these assumptions are not violated, i.e. as long as intended actions\ncan be performed such that their preconditions hold as well. The second\ncontribution is the formalization of what-if scenarios: what happens with\nintentions and beliefs if a new (possibly conflicting) intention is adopted, or\na new fact is learned? An agent is committed to its intended actions as long as\nits belief-intention database is coherent. We conceptualize intention as\ncommitment toward time and we develop AGM-based postulates for the iterated\nrevision of belief-intention databases, and we prove a Katsuno-Mendelzon-style\nrepresentation theorem.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 09:47:39 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["van Zee", "Marc", ""], ["Doder", "Dragan", ""], ["van der Torre", "Leendert", ""], ["Dastani", "Mehdi", ""], ["Icard", "Thomas", ""], ["Pacuit", "Eric", ""]]}, {"id": "2004.08200", "submitter": "Brijesh Dongol", "authors": "Eleni Bila, Simon Doherty, Brijesh Dongol, John Derrick, Gerhard\n  Schellhorn, and Heike Wehrheim", "title": "Defining and Verifying Durable Opacity: Correctness for Persistent\n  Software Transactional Memory", "comments": "This is the full version of the paper that is to appear in FORTE 2020\n  (https://www.discotec.org/2020/forte)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-volatile memory (NVM), aka persistent memory, is a new paradigm for\nmemory that preserves its contents even after power loss. The expected ubiquity\nof NVM has stimulated interest in the design of novel concepts ensuring\ncorrectness of concurrent programming abstractions in the face of persistency.\nSo far, this has lead to the design of a number of persistent concurrent data\nstructures, built to satisfy an associated notion of correctness: durable\nlinearizability.\n  In this paper, we transfer the principle of durable concurrent correctness to\nthe area of software transactional memory (STM). Software transactional memory\nalgorithms allow for concurrent access to shared state. Like linearizability\nfor concurrent data structures, opacity is the established notion of\ncorrectness for STMs. First, we provide a novel definition of durable opacity\nextending opacity to handle crashes and recovery in the context of NVM. Second,\nwe develop a durably opaque version of an existing STM algorithm, namely the\nTransactional Mutex Lock (TML). Third, we design a proof technique for durable\nopacity based on refinement between TML and an operational characterisation of\ndurable opacity by adapting the TMS2 specification. Finally, we apply this\nproof technique to show that the durable version of TML is indeed durably\nopaque. The correctness proof is mechanized within Isabelle.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 12:20:36 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Bila", "Eleni", ""], ["Doherty", "Simon", ""], ["Dongol", "Brijesh", ""], ["Derrick", "John", ""], ["Schellhorn", "Gerhard", ""], ["Wehrheim", "Heike", ""]]}, {"id": "2004.08212", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski and Josef Urban", "title": "Stateful Premise Selection by Recurrent Neural Networks", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a new learning-based method for selecting facts\n(premises) when proving new goals over large formal libraries. Unlike previous\nmethods that choose sets of facts independently of each other by their rank,\nthe new method uses the notion of \\emph{state} that is updated each time a\nchoice of a fact is made. Our stateful architecture is based on recurrent\nneural networks which have been recently very successful in stateful tasks such\nas language translation. The new method is combined with data augmentation\ntechniques, evaluated in several ways on a standard large-theory benchmark, and\ncompared to state-of-the-art premise approach based on gradient boosted trees.\nIt is shown to perform significantly better and to solve many new problems.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:59:37 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""]]}, {"id": "2004.08213", "submitter": "Sebastiaan J. Van Zelst", "authors": "Sebastiaan J. van Zelst", "title": "Translating Workflow Nets to Process Trees: An Algorithmic Approach", "comments": null, "journal-ref": null, "doi": "10.3390/a13110279", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since their recent introduction, process trees have been frequently used as a\nprocess modeling formalism in many process mining algorithms. A process tree is\na tree-based model of a process, in which internal vertices represent\nbehavioral control-flow relations and leaves represent process activities. A\nprocess tree is easily translated into a sound Workflow net (WF-net), however,\nthe reverse is not the case. Yet, an algorithm that translates a WF-net into a\nprocess tree is of great interest, e.g., the explicit knowledge of the\ncontrol-flow hierarchy in a WF-net allows one to more easily reason on its\nbehavior. Hence, in this paper, we present such an algorithm, i.e., it detects\nwhether a WF-net corresponds to a process tree, and, if so, constructs it. We\nprove that, if a process tree is discovered, the language of the process tree\nequals the language of the original WF-net. Conducted experiments show, that\nthe algorithm's corresponding implementation has a quadratic time-complexity in\nthe size of the WF-net. Furthermore, the experiments show strong evidence of\nprocess tree rediscoverability.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 10:56:33 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["van Zelst", "Sebastiaan J.", ""]]}, {"id": "2004.08311", "submitter": "Alisa Kovtunova", "authors": "Christian Alrabbaa, Franz Baader, Stefan Borgwardt, Patrick Koopmann,\n  and Alisa Kovtunova", "title": "Finding Small Proofs for Description Logic Entailments: Theory and\n  Practice (Extended Technical Report)", "comments": "Extended version of a paper accepted at LPAR23", "journal-ref": "LPAR-23: 23rd International Conference on Logic for Programming,\n  Artificial Intelligence and Reasoning, vol 73, 2020, pages 32--67", "doi": "10.29007/nhpp", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic-based approaches to AI have the advantage that their behaviour can in\nprinciple be explained by providing their users with proofs for the derived\nconsequences. However, if such proofs get very large, then it may be hard to\nunderstand a consequence even if the individual derivation steps are easy to\ncomprehend. This motivates our interest in finding small proofs for Description\nLogic (DL) entailments. Instead of concentrating on a specific DL and proof\ncalculus for this DL, we introduce a general framework in which proofs are\nrepresented as labeled, directed hypergraphs, where each hyperedge corresponds\nto a single sound derivation step. On the theoretical side, we investigate the\ncomplexity of deciding whether a certain consequence has a proof of size at\nmost $n$ along the following orthogonal dimensions: (i) the underlying proof\nsystem is polynomial or exponential; (ii) proofs may or may not reuse already\nderived consequences; and (iii) the number $n$ is represented in unary or\nbinary. We have determined the exact worst-case complexity of this decision\nproblem for all but one of the possible combinations of these options. On the\npractical side, we have developed and implemented an approach for generating\nproofs for expressive DLs based on a non-standard reasoning task called\nforgetting. We have evaluated this approach on a set of realistic ontologies\nand compared the obtained proofs with proofs generated by the DL reasoner ELK,\nfinding that forgetting-based proofs are often better w.r.t. different measures\nof proof complexity.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 15:44:18 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 13:53:28 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Alrabbaa", "Christian", ""], ["Baader", "Franz", ""], ["Borgwardt", "Stefan", ""], ["Koopmann", "Patrick", ""], ["Kovtunova", "Alisa", ""]]}, {"id": "2004.08380", "submitter": "Samuel Balco", "authors": "Samuel Balco and Alexander Kurz", "title": "Completeness of Nominal PROPs", "comments": "arXiv admin note: text overlap with arXiv:1904.07534", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce nominal string diagrams as string diagrams internal in the\ncategory of nominal sets. This leads us to define nominal PROPs and nominal\nmonoidal theories. We show that the categories of ordinary PROPs and nominal\nPROPs are equivalent. This equivalence is then extended to symmetric monoidal\ntheories and nominal monoidal theories, which allows us to transfer\ncompleteness results between ordinary and nominal calculi for string diagrams.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 19:17:55 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Balco", "Samuel", ""], ["Kurz", "Alexander", ""]]}, {"id": "2004.08440", "submitter": "Haoze Wu", "authors": "Haoze Wu, Alex Ozdemir, Aleksandar Zelji\\'c, Ahmed Irfan, Kyle Julian,\n  Divya Gopinath, Sadjad Fouladi, Guy Katz, Corina Pasareanu and Clark Barrett", "title": "Parallelization Techniques for Verifying Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent successes with parallel optimization techniques for\nsolving Boolean satisfiability, we investigate a set of strategies and\nheuristics that aim to leverage parallel computing to improve the scalability\nof neural network verification. We introduce an algorithm based on partitioning\nthe verification problem in an iterative manner and explore two partitioning\nstrategies, that work by partitioning the input space or by case splitting on\nthe phases of the neuron activations, respectively. We also introduce a highly\nparallelizable pre-processing algorithm that uses the neuron activation phases\nto simplify the neural network verification problems. An extensive experimental\nevaluation shows the benefit of these techniques on both existing benchmarks\nand new benchmarks from the aviation domain. A preliminary experiment with\nultra-scaling our algorithm using a large distributed cloud-based platform also\nshows promising results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 20:21:47 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 20:43:08 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 16:15:13 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Wu", "Haoze", ""], ["Ozdemir", "Alex", ""], ["Zelji\u0107", "Aleksandar", ""], ["Irfan", "Ahmed", ""], ["Julian", "Kyle", ""], ["Gopinath", "Divya", ""], ["Fouladi", "Sadjad", ""], ["Katz", "Guy", ""], ["Pasareanu", "Corina", ""], ["Barrett", "Clark", ""]]}, {"id": "2004.08487", "submitter": "Michael Shulman", "authors": "Michael Shulman", "title": "*-autonomous envelopes and 2-conservativity of duals", "comments": "19 pages. v2: Further emphasis on 2-conservativity, a terminology\n  change from previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show the doctrine of $\\ast$-autonomous categories is \"2-conservative\" over\nthe doctrine of closed symmetric monoidal categories, i.e. the universal map\nfrom a closed symmetric monoidal category to the $\\ast$-autonomous category\nthat it freely generates is fully faithful. This implies that linear logics and\ngraphical calculi for $\\ast$-autonomous categories can also be interpreted\ncanonically in closed symmetric monoidal categories. In particular, our result\nimplies that every closed symmetric monoidal category can be fully embedded in\na $\\ast$-autonomous category, preserving both tensor products and\ninternal-homs. But in fact we prove this directly first with a Yoneda-style\nembedding (an enhanced \"Hyland envelope\" that can be regarded as a\npolycategorical form of Day convolution), and deduce 2-conservativity\nafterwards from double gluing and a technique of Lafont. Since our method uses\npolycategories, it also applies to other fragments of $\\ast$-autonomous\nstructure, such as linear distributivity. It can also be enhanced to preserve\nany desired family of nonempty limits and colimits.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 23:27:07 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 18:24:50 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Shulman", "Michael", ""]]}, {"id": "2004.08599", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "Three Modern Roles for Logic in AI", "comments": "To be published in PODS 2020", "journal-ref": null, "doi": "10.1145/3375395.3389131", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three modern roles for logic in artificial intelligence, which\nare based on the theory of tractable Boolean circuits: (1) logic as a basis for\ncomputation, (2) logic for learning from a combination of data and knowledge,\nand (3) logic for reasoning about the behavior of machine learning systems.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 11:51:13 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "2004.08858", "submitter": "Zarathustra Amadeus Goertzel", "authors": "Zarathustra Amadeus Goertzel", "title": "Make E Smart Again", "comments": "8 pages, 2 figures, IJCAR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work in progress, we demonstrate a new use-case for the ENIGMA\nsystem. The ENIGMA system using the XGBoost implementation of gradient boosted\ndecision trees has demonstrated high capability to learn to guide the E theorem\nprover's inferences in real-time. Here, we strip E to the bare bones: we\nreplace the KBO term ordering with an identity relation as the minimal possible\nordering, disable literal selection, and replace evolved strategies with a\nsimple combination of the clause weight and FIFO (first in first out) clause\nevaluation functions. We experimentally demonstrate that ENIGMA can learn to\nguide E as well as the smart, evolved strategies even without these standard\nautomated theorem prover functionalities. To this end, we experiment with\nXGBoost's meta-parameters over a dozen loops.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:14:45 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Goertzel", "Zarathustra Amadeus", ""]]}, {"id": "2004.09171", "submitter": "\\'Etienne Andr\\'e", "authors": "\\'Etienne Andr\\'e, Didier Lime and Olivier H. Roux", "title": "Reachability and liveness in parametric timed automata", "comments": "This manuscript is an extended version of two conference papers\n  published in the proceedings of ICFEM 2016 and ACSD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study timed systems in which some timing features are unknown parameters.\nParametric timed automata (PTAs) are a classical formalism for such systems but\nfor which most interesting problems are undecidable. Notably, the parametric\nreachability emptiness problem, i.e., whether at least one parameter valuation\nallows to reach some given discrete state, is undecidable.\nLower-bound/upper-bound parametric timed automata (L/U-PTAs) achieve\ndecidability for reachability properties by enforcing a separation of\nparameters used as upper bounds in the automaton constraints, and those used as\nlower bounds.\n  In this paper, we first study reachability. We exhibit a subclass of PTAs\n(namely integer-points PTAs) with bounded rational-valued parameters for which\nthe parametric reachability emptiness problem is decidable. Using this class,\nwe present further results improving the boundary between decidability and\nundecidability for PTAs and their subclasses such as L/U-PTAs.\n  We then study liveness. We prove that:\n  (1) the existence of at least one parameter valuation for which there exists\nan infinite run in an L/U-PTA is PSPACE-complete;\n  (2) the existence of a parameter valuation such that the system has a\ndeadlock is however undecidable;\n  (3) the problem of the existence of a valuation for which a run remains in a\ngiven set of locations exhibits a very thin border between decidability and\nundecidability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:55:30 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Andr\u00e9", "\u00c9tienne", ""], ["Lime", "Didier", ""], ["Roux", "Olivier H.", ""]]}, {"id": "2004.09450", "submitter": "Matthias Schr\\\"oder", "authors": "Matthias Schr\\\"oder", "title": "Admissibly Represented Spaces and Qcb-Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic concept of Type Two Theory of Effectivity (TTE) is the notion of an\nadmissibly represented space. Admissibly represented spaces are closely related\nto qcb-spaces. The latter form a well-behaved subclass of topological spaces.\nWe give a survey of basic facts about Type Two Theory of Effectivity,\nadmissibly represented spaces, qcb-spaces and effective qcb-spaces. Moreover,\nwe discuss the relationship of qcb-spaces to other categories relevant to\nComputable Analysis.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:06:51 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Schr\u00f6der", "Matthias", ""]]}, {"id": "2004.09503", "submitter": "Eugene Goldberg", "authors": "Eugene Goldberg", "title": "On Verifying Designs With Incomplete Specification", "comments": "arXiv admin note: text overlap with arXiv:2004.05853", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incompleteness of a specification $\\mathit{Spec}$ creates two problems.\nFirst, an implementation $\\mathit{Impl}$ of $\\mathit{Spec}$ may have some\n$\\mathit{unwanted}$ properties that $\\mathit{Spec}$ does not forbid. Second,\n$\\mathit{Impl}$ may break some $\\mathit{desired}$ properties that are not in\n$\\mathit{Spec}$. In either case, $\\mathit{Spec}$ fails to expose bugs of\n$\\mathit{Impl}$. In an earlier paper, we addressed the first problem above by a\ntechnique called Partial Quantifier Elimination (PQE). In contrast to complete\nQE, in PQE, one takes out of the scope of quantifiers only a small piece of the\nformula. We used PQE to generate properties of $\\mathit{Impl}$ i.e. those\n$\\mathit{consistent}$ with $\\mathit{Impl}$. Generation of an unwanted property\nmeans that $\\mathit{Impl}$ is buggy. In this paper, we address the second\nproblem above by using PQE to generate false properties i.e those that are\n$\\mathit{inconsistent}$ with $\\mathit{Impl}$. Such properties are meant to\nimitate the missing properties of $\\mathit{Spec}$ that are not satisfied by\n$\\mathit{Impl}$ (if any). A false property is generated by modifying a piece of\na quantified formula describing 'the truth table' of $\\mathit{Impl}$ and taking\nthis piece out of the scope of quantifiers. By modifying different pieces of\nthis formula one can generate a \"structurally complete\" set of false\nproperties. By generating tests detecting false properties of $\\mathit{Impl}$\none produces a high quality test set. We apply our approach to verification of\ncombinational and sequential circuits.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 03:52:31 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Goldberg", "Eugene", ""]]}, {"id": "2004.09621", "submitter": "Igor Walukiewicz", "authors": "A.R. Balasubramanian and Igor Walukiewicz", "title": "Characterizing consensus in the Heard-Of model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Heard-Of model is a simple and relatively expressive model of distributed\ncomputation. Because of this, it has gained a considerable attention of the\nverification community. We give a characterization of all algorithms solving\nconsensus in a fragment of this model. The fragment is big enough to cover many\nprominent consensus algorithms. The characterization is purely syntactic: it is\nexpressed in terms of some conditions on the text of the algorithm. One of the\nrecent methods of verification of distributed algorithms is to abstract an\nalgorithm to the Heard-Of model and then to verify the abstract algorithm using\nsemi-automatic procedures. Our results allow, in some cases, to avoid the\nsecond step in this methodology.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 20:35:46 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Balasubramanian", "A. R.", ""], ["Walukiewicz", "Igor", ""]]}, {"id": "2004.09777", "submitter": "Bruno Courcelle", "authors": "Bruno Courcelle (LaBRI)", "title": "Betweenness of partial orders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a monadic second-order sentence that characterizes the ternary\nrelations that are the betweenness relations of finite or infinite partial\norders. We prove that no first-order sentence can do that. We characterize the\npartial orders that can be reconstructed from their betweenness relations. We\npropose a polynomial time algorithm that tests if a finite relation is the\nbe-tweenness of a partial order.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 07:14:52 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Courcelle", "Bruno", "", "LaBRI"]]}, {"id": "2004.10030", "submitter": "Marie-Laure Mugnier", "authors": "Stathis Delivorias, Michel Lecl\\`ere, Marie-Laure Mugnier, Federico\n  Ulliana", "title": "Characterizing Boundedness in Chase Variants", "comments": "Under consideration for publication in Theory and Practice of Logic\n  Programming", "journal-ref": "Theory and Practice of Logic Programming 21 (2021) 51-79", "doi": "10.1017/S1471068420000083", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existential rules are a positive fragment of first-order logic that\ngeneralizes function-free Horn rules by allowing existentially quantified\nvariables in rule heads. This family of languages has recently attracted\nsignificant interest in the context of ontology-mediated query answering.\nForward chaining, also known as the chase, is a fundamental tool for computing\nuniversal models of knowledge bases, which consist of existential rules and\nfacts. Several chase variants have been defined, which differ on the way they\nhandle redundancies. A set of existential rules is bounded if it ensures the\nexistence of a bound on the depth of the chase, independently from any set of\nfacts. Deciding if a set of rules is bounded is an undecidable problem for all\nchase variants. Nevertheless, when computing universal models, knowing that a\nset of rules is bounded for some chase variant does not help much in practice\nif the bound remains unknown or even very large. Hence, we investigate the\ndecidability of the k-boundedness problem, which asks whether the depth of the\nchase for a given set of rules is bounded by an integer k. We identify a\ngeneral property which, when satisfied by a chase variant, leads to the\ndecidability of k-boundedness. We then show that the main chase variants\nsatisfy this property, namely the oblivious, semi-oblivious (aka Skolem), and\nrestricted chase, as well as their breadth-first versions. This paper is under\nconsideration for publication in Theory and Practice of Logic Programming.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:07:10 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Delivorias", "Stathis", ""], ["Lecl\u00e8re", "Michel", ""], ["Mugnier", "Marie-Laure", ""], ["Ulliana", "Federico", ""]]}, {"id": "2004.10127", "submitter": "Thorsten Wissmann", "authors": "Bruno Courcelle", "title": "Axiomatization of betweenness in order-theoretic trees", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (February\n  3, 2021) lmcs:7150", "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ternary betweenness relation of a tree, B(x,y,z) expresses that y is on\nthe unique path between x and z. This notion can be extended to order-theoretic\ntrees defined as partial orders such that the set of nodes larger than any node\nis linearly ordered. In such generalized trees, the unique \"path\" between two\nnodes can have infinitely many nodes.\n  We generalize some results obtained in a previous article for the betweenness\nof join-trees. Join-trees are order-theoretic trees such that any two nodes\nhave a least upper-bound. The motivation was to define conveniently the\nrank-width of a countable graph. We called quasi-tree the structure based on\nthe betweenness relation of a join-tree. We proved that quasi-trees are\naxiomatized by a first-order sentence.\n  Here, we obtain a monadic second-order axiomatization of betweenness in\norder-theoretic trees. We also define and compare several induced betweenness\nrelations, i.e., restrictions to sets of nodes of the betweenness relations in\ngeneralized trees of different kinds. We prove that induced betweenness in\nquasi-trees is characterized by a first-order sentence. The proof uses\norder-theoretic trees.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 16:13:27 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 10:56:32 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 10:09:57 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 16:44:15 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Courcelle", "Bruno", ""]]}, {"id": "2004.10263", "submitter": "Grant Passmore", "authors": "Grant Olney Passmore, Simon Cruanes, Denis Ignatovich, Dave Aitken,\n  Matt Bray, Elijah Kagan, Kostya Kanishev, Ewen Maclean, and Nicola Mometto", "title": "The Imandra Automated Reasoning System (system description)", "comments": "To appear in Proceedings of The International Joint Conference on\n  Automated Reasoning (IJCAR) 2020, Lecture Notes in Artificial Intelligence,\n  Springer-Verlag", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Imandra, a modern computational logic theorem prover designed to\nbridge the gap between decision procedures such as SMT, semi-automatic\ninductive provers of the Boyer-Moore family like ACL2, and interactive proof\nassistants for typed higher-order logics. Imandra's logic is computational,\nbased on a pure subset of OCaml in which all functions are terminating, with\nrestrictions on types and higher-order functions that allow conjectures to be\ntranslated into multi-sorted first-order logic with theories, including\narithmetic and datatypes. Imandra has novel features supporting large-scale\nindustrial applications, including a seamless integration of bounded and\nunbounded verification, first-class computable counterexamples, efficiently\nexecutable models and a cloud-native architecture supporting live multiuser\ncollaboration.\n  The core reasoning mechanisms of Imandra are (i) a semi-complete procedure\nfor finding models of formulas in the logic mentioned above, centered around\nthe lazy expansion of recursive functions, and (ii) an inductive waterfall and\nsimplifier which \"lifts\" many Boyer-Moore ideas to our typed higher-order\nsetting.\n  These mechanisms are tightly integrated and subject to many forms of user\ncontrol. Imandra's user interfaces include an interactive toplevel, Jupyter\nnotebooks and asynchronous document-based verification (in the spirit of\nIsabelle's Prover IDE) with VS Code.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:57:34 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Passmore", "Grant Olney", ""], ["Cruanes", "Simon", ""], ["Ignatovich", "Denis", ""], ["Aitken", "Dave", ""], ["Bray", "Matt", ""], ["Kagan", "Elijah", ""], ["Kanishev", "Kostya", ""], ["Maclean", "Ewen", ""], ["Mometto", "Nicola", ""]]}, {"id": "2004.10413", "submitter": "Jesko Hecking-Harbusch", "authors": "Jesko Hecking-Harbusch and Niklas O. Metzger", "title": "Efficient Trace Encodings of Bounded Synthesis for Asynchronous\n  Distributed Systems", "comments": null, "journal-ref": "Proceedings of the 17th International Symposium on Automated\n  Technology for Verification and Analysis (ATVA 2019), Springer LNCS 11781,\n  pages 369-386, 2019", "doi": "10.1007/978-3-030-31784-3_22", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manual implementation of distributed systems is an error-prone task\nbecause of the asynchronous interplay of components and the environment.\nBounded synthesis automatically generates an implementation for the\nspecification of the distributed system if one exists. So far, bounded\nsynthesis for distributed systems does not utilize their asynchronous nature.\nInstead, concurrent behavior of components is encoded by all interleavings and\nonly then checked against the specification. We close this gap by identifying\ntrue concurrency in synthesis of asynchronous distributed systems represented\nas Petri games. This defines when several interleavings can be subsumed by one\ntrue concurrent trace. Thereby, fewer and shorter verification problems have to\nbe solved in each iteration of the bounded synthesis algorithm. For Petri\ngames, experimental results show that our implementation using true concurrency\noutperforms the implementation based on checking all interleavings.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 06:49:10 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 13:10:26 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Hecking-Harbusch", "Jesko", ""], ["Metzger", "Niklas O.", ""]]}, {"id": "2004.10654", "submitter": "Joost Joosten", "authors": "Ad\\'an Cabello and Joost J. Joosten", "title": "Hidden variables simulating quantum contextuality increasingly violate\n  the Holevo bound", "comments": null, "journal-ref": "In Unconventional Computing, Springer LNCS 6714 (64-76), ISSN\n  0302-9743. Proceedings of the 10th International Conference UC 2011, Turku,\n  Finland 2011", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper from 2011 we approach some questions about quantum\ncontextuality with tools from formal logic. In particular, we consider an\nexperiment associated with the Peres-Mermin square. The language of all\npossible sequences of outcomes of the experiment is classified in the Chomsky\nhierarchy and seen to be a regular language. Next, we make the rather evident\nobservation that a finite set of hidden finite valued variables can never\naccount for indeterminism in an ideally isolated repeatable experiment. We see\nthat, when the language of possible outcomes of the experiment is regular, as\nis the case with the Peres-Mermin square, the amount of binary-valued hidden\nvariables needed to de-randomize the model for all sequences of experiments up\nto length n grows as bad as it could be: linearly in n. We introduce a very\nabstract model of machine that simulates nature in a particular sense. A\nlower-bound on the number of memory states of such machines is proved if they\nwere to simulate the experiment that corresponds to the Peres-Mermin square.\nMoreover, the proof of this lower bound is seen to scale to a certain\ngeneralization of the Peres- Mermin square. For this scaled experiment it is\nseen that the Holevo bound is violated and that the degree of violation\nincreases uniformly.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 12:14:04 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Cabello", "Ad\u00e1n", ""], ["Joosten", "Joost J.", ""]]}, {"id": "2004.10655", "submitter": "Jennifer Paykin", "authors": "Jennifer Paykin, Brian Huffman, Daniel M. Zimmerman, Peter A. Beerel", "title": "Formal Verification of Flow Equivalence in Desynchronized Designs", "comments": "To appear in ASYNC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seminal work by Cortadella, Kondratyev, Lavagno, and Sotiriou includes a\nhand-written proof that a particular handshaking protocol preserves flow\nequivalence, a notion of equivalence between synchronous latch-based\nspecifications and their desynchronized bundled-data asynchronous\nimplementations. In this work we identify a counterexample to Cortadella et\nal.'s proof illustrating how their protocol can in fact lead to a violation of\nflow equivalence. However, two of the less concurrent protocols identified in\ntheir paper do preserve flow equivalence. To verify this fact, we formalize\nflow equivalence in the Coq proof assistant and provide mechanized,\nmachine-checkable proofs of our results.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:28:19 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Paykin", "Jennifer", ""], ["Huffman", "Brian", ""], ["Zimmerman", "Daniel M.", ""], ["Beerel", "Peter A.", ""]]}, {"id": "2004.10659", "submitter": "Edward Haeusler", "authors": "Edward Hermann Haeusler", "title": "Exponentially Huge Natural Deduction proofs are Redundant: Preliminary\n  results on $M_\\supset$", "comments": "This version has a simpler proof of the main result than the\n  previous. Moreover, we decided to focus only on the use of this result to\n  compress Natural Deduction huge proofs. Any relationship with computational\n  complexity is discussed in an article that will appear in a logic journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the size of a labelled tree by comparing the amount of (labelled)\nnodes with the size of the set of labels. Roughly speaking, a exponentially big\nlabelled tree, is any labelled tree that has an exponential gap between its\nsize, number of nodes, and the size of its labelling set. The number of\nsub-formulas of any formula is linear on the size of it, and hence any\nexponentially big proof has a size $a^n$, where $a>1$ and $n$ is the size of\nits conclusion. In this article, we show that the linearly height labelled\ntrees whose sizes have an exponential gap with the size of their labelling sets\nposses at least one sub-tree that occurs exponentially many times in them.\nNatural Deduction proofs and derivations in minimal implicational logic\n($M_\\supset$) are essentially labelled trees. By the sub-formula principle any\nnormal derivation of a formula $\\alpha$ from a set of formulas\n$\\Gamma=\\{\\gamma_1,\\ldots,\\gamma_n\\}$ in $M_\\supset$, establishing\n$\\Gamma\\vdash_{M_\\supset}\\alpha$, has only sub-formulas of the formulas\n$\\alpha,\\gamma_1,\\ldots,\\gamma_n$ occurring in it. By this relationship between\nlabelled trees and derivations in $M_\\supset$, we show that any normal proof of\na tautology in $M_\\supset$ that is exponential on the size of its conclusion\nhas a sub-proof that occurs exponentially many times in it. Thus, any normal\nand linearly height bounded proof in $M_\\supset$ is inherently redundant.\nFinally, we briefly discuss how this redundancy provides us with a highly\nefficient compression method for propositional proofs. We also provide some\nexamples that serve to convince us that exponentially big proofs are more\nfrequent than one can imagine.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 05:26:52 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 04:06:59 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Haeusler", "Edward Hermann", ""]]}, {"id": "2004.10667", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Simple Dataset for Proof Method Recommendation in Isabelle/HOL (Dataset\n  Description)", "comments": "This is the preprint of our short paper accepted at the 13th\n  Conference on Intelligent Computer Mathematics (CICM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a growing number of researchers have applied machine learning to\nassist users of interactive theorem provers. However, the expressive nature of\nunderlying logics and esoteric structures of proof documents impede machine\nlearning practitioners, who often do not have much expertise in formal logic,\nlet alone Isabelle/HOL, from achieving a large scale success in this field. In\nthis data description, we present a simple dataset that contains data on over\n400k proof method applications along with over 100 extracted features for each\nin a format that can be processed easily without any knowledge about formal\nlogic. Our simple data format allows machine learning practitioners to try\nmachine learning tools to predict proof methods in Isabelle/HOL without\nrequiring domain expertise in logic.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:00:11 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 06:38:37 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 07:46:04 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2004.10741", "submitter": "James Hefford", "authors": "James Hefford, Vincent Wang, Matthew Wilson", "title": "Categories of Semantic Concepts", "comments": "Accepted at SemSpace 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO math.CT quant-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modelling concept representation is a foundational problem in the study of\ncognition and linguistics. This work builds on the confluence of conceptual\ntools from G\\\"ardenfors semantic spaces, categorical compositional linguistics,\nand applied category theory to present a domain-independent and categorical\nformalism of 'concept'.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:50:04 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 20:15:30 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Hefford", "James", ""], ["Wang", "Vincent", ""], ["Wilson", "Matthew", ""]]}, {"id": "2004.11185", "submitter": "Matteo Mio", "authors": "Christophe Lucas, Matteo Mio", "title": "Proof Theory of Riesz Spaces and Modal Riesz Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design hypersequent calculus proof systems for the theories of Riesz\nspaces and modal Riesz spaces and prove the key theorems: soundness,\ncompleteness and cut elimination. These are then used to obtain completely\nsyntactic proofs of some interesting results concerning the two theories. Most\nnotably, we prove a novel result: the theory of modal Riesz spaces is\ndecidable. This work has applications in the field of logics of probabilistic\nprograms since modal Riesz spaces provide the algebraic semantics of the Riesz\nmodal logic underlying the probabilistic mu-calculus.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 14:25:48 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 16:46:50 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Lucas", "Christophe", ""], ["Mio", "Matteo", ""]]}, {"id": "2004.11196", "submitter": "Peter Streufert", "authors": "Peter A. Streufert", "title": "The Category of Node-and-Choice Extensive-Form Games", "comments": "49 pages, 10 figures; revision makes only expositional changes (an\n  improved introduction and a new running example)", "journal-ref": null, "doi": null, "report-no": "Western University (University of Western Ontario) Department of\n  Economics Research Report #2020-04", "categories": "econ.TH cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops the category $\\mathbf{NCG}$. Its objects are\nnode-and-choice games, which include essentially all extensive-form games. Its\nmorphisms allow arbitrary transformations of a game's nodes, choices, and\nplayers, as well as monotonic transformations of the utility functions of the\ngame's players. Among the morphisms are subgame inclusions. Several\ncharacterizations and numerous properties of the isomorphisms are derived. For\nexample, it is shown that isomorphisms preserve the game-theoretic concepts of\nno-absentmindedness, perfect-information, and (pure-strategy) Nash-equilibrium.\nFinally, full subcategories are defined for choice-sequence games and\nchoice-set games, and relationships among these two subcategories and\n$\\mathbf{NCG}$ itself are expressed and derived via isomorphic inclusions and\nequivalences.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 14:41:59 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 14:49:55 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Streufert", "Peter A.", ""]]}, {"id": "2004.11282", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "On the proof complexity of logics of bounded branching", "comments": "58 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the proof complexity of extended Frege (EF) systems for basic\ntransitive modal logics (K4, S4, GL, ...) augmented with the bounded branching\naxioms $\\mathbf{BB}_k$. First, we study feasibility of the disjunction property\nand more general extension rules in EF systems for these logics: we show that\nthe corresponding decision problems reduce to total coNP search problems (or\nequivalently, disjoint NP pairs, in the binary case); more precisely, the\ndecision problem for extension rules is equivalent to a certain special case of\ninterpolation for the classical EF system. Next, we use this characterization\nto prove superpolynomial (or even exponential, with stronger hypotheses)\nseparations between EF and substitution Frege (SF) systems for all transitive\nlogics contained in $\\mathbf{S4.2GrzBB_2}$ or $\\mathbf{GL.2BB_2}$ under some\nassumptions weaker than $\\mathrm{PSPACE \\ne NP}$. We also prove analogous\nresults for superintuitionistic logics: we characterize the decision complexity\nof multi-conclusion Visser's rules in EF systems for Gabbay--de Jongh logics\n$\\mathbf T_k$, and we show conditional separations between EF and SF for all\nintermediate logics contained in $\\mathbf{T_2 + KC}$.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 16:11:12 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "2004.11375", "submitter": "Wolfgang Gatterbauer", "authors": "Aristotelis Leventidis, Jiahui Zhang, Cody Dunne, Wolfgang\n  Gatterbauer, H.V. Jagadish, Mirek Riedewald", "title": "QueryVis: Logic-based diagrams help users understand complicated SQL\n  queries faster", "comments": "Full version of paper appearing in SIGMOD 2020", "journal-ref": null, "doi": "10.1145/3318464.3389767", "report-no": null, "categories": "cs.DB cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the meaning of existing SQL queries is critical for code\nmaintenance and reuse. Yet SQL can be hard to read, even for expert users or\nthe original creator of a query. We conjecture that it is possible to capture\nthe logical intent of queries in \\emph{automatically-generated visual diagrams}\nthat can help users understand the meaning of queries faster and more\naccurately than SQL text alone. We present initial steps in that direction with\nvisual diagrams that are based on the first-order logic foundation of SQL and\ncan capture the meaning of deeply nested queries. Our diagrams build upon a\nrich history of diagrammatic reasoning systems in logic and were designed using\na large body of human-computer interaction best practices: they are\n\\emph{minimal} in that no visual element is superfluous; they are\n\\emph{unambiguous} in that no two queries with different semantics map to the\nsame visualization; and they \\emph{extend} previously existing visual\nrepresentations of relational schemata and conjunctive queries in a natural\nway. An experimental evaluation involving 42 users on Amazon Mechanical Turk\nshows that with only a 2--3 minute static tutorial, participants could\ninterpret queries meaningfully faster with our diagrams than when reading SQL\nalone. Moreover, we have evidence that our visual diagrams result in\nparticipants making fewer errors than with SQL. We believe that more regular\nexposure to diagrammatic representations of SQL can give rise to a\n\\emph{pattern-based} and thus more intuitive use and re-use of SQL. All details\non the experimental study, the evaluation stimuli, raw data, and analyses, and\nsource code are available at https://osf.io/mycr2\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:55:32 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Leventidis", "Aristotelis", ""], ["Zhang", "Jiahui", ""], ["Dunne", "Cody", ""], ["Gatterbauer", "Wolfgang", ""], ["Jagadish", "H. V.", ""], ["Riedewald", "Mirek", ""]]}, {"id": "2004.11441", "submitter": "Jakob Piribauer", "authors": "Jakob Piribauer and Christel Baier", "title": "On Skolem-hardness and saturation points in Markov decision processes", "comments": "Conference version accepted for publication at ICALP'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Skolem problem and the related Positivity problem for linear recurrence\nsequences are outstanding number-theoretic problems whose decidability has been\nopen for many decades. In this paper, the inherent mathematical difficulty of a\nseries of optimization problems on Markov decision processes (MDPs) is shown by\na reduction from the Positivity problem to the associated decision problems\nwhich establishes that the problems are also at least as hard as the Skolem\nproblem as an immediate consequence. The optimization problems under\nconsideration are two non-classical variants of the stochastic shortest path\nproblem (SSPP) in terms of expected partial or conditional accumulated weights,\nthe optimization of the conditional value-at-risk for accumulated weights, and\ntwo problems addressing the long-run satisfaction of path properties, namely\nthe optimization of long-run probabilities of regular co-safety properties and\nthe model-checking problem of the logic frequency-LTL. To prove the Positivity-\nand hence Skolem-hardness for the latter two problems, a new auxiliary path\nmeasure, called weighted long-run frequency, is introduced and the\nPositivity-hardness of the corresponding decision problem is shown as an\nintermediate step. For the partial and conditional SSPP on MDPs with\nnon-negative weights and for the optimization of long-run probabilities of\nconstrained reachability properties (a U b), solutions are known that rely on\nthe identification of a bound on the accumulated weight or the number of\nconsecutive visits to certain sates, called a saturation point, from which on\noptimal schedulers behave memorylessly. In this paper, it is shown that also\nthe optimization of the conditional value-at-risk for the classical SSPP and of\nweighted long-run frequencies on MDPs with non-negative weights can be solved\nin pseudo-polynomial time exploiting the existence of a saturation point.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 19:56:50 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Piribauer", "Jakob", ""], ["Baier", "Christel", ""]]}, {"id": "2004.11661", "submitter": "Edon Kelmendi", "authors": "Shaull Almagor, Edon Kelmendi, Jo\\\"el Ouaknine, James Worrell", "title": "Invariants for Continuous Linear Dynamical Systems", "comments": "Full version of a ICALP 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous linear dynamical systems are used extensively in mathematics,\ncomputer science, physics, and engineering to model the evolution of a system\nover time. A central technique for certifying safety properties of such systems\nis by synthesising inductive invariants. This is the task of finding a set of\nstates that is closed under the dynamics of the system and is disjoint from a\ngiven set of error states. In this paper we study the problem of synthesising\ninductive invariants that are definable in o-minimal expansions of the ordered\nfield of real numbers. In particular, assuming Schanuel's conjecture in\ntranscendental number theory, we establish effective synthesis of o-minimal\ninvariants in the case of semi-algebraic error sets. Without using Schanuel's\nconjecture, we give a procedure for synthesizing o-minimal invariants that\ncontain all but a bounded initial segment of the orbit and are disjoint from a\ngiven semi-algebraic error set. We further prove that effective synthesis of\nsemi-algebraic invariants that contain the whole orbit, is at least as hard as\na certain open problem in transcendental number theory.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 11:23:30 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 06:49:37 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Almagor", "Shaull", ""], ["Kelmendi", "Edon", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Worrell", "James", ""]]}, {"id": "2004.11792", "submitter": "Lars Stoltenow", "authors": "Mathias H\\\"ulsbusch, Barbara K\\\"onig, Sebastian K\\\"upper, Lars\n  Stoltenow", "title": "Conditional Bisimilarity for Reactive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reactive systems \\`a la Leifer and Milner, an abstract categorical framework\nfor rewriting, provide a suitable framework for deriving bisimulation\ncongruences. This is done by synthesizing interactions with the environment in\norder to obtain a compositional semantics. We enrich the notion of reactive\nsystems by conditions on two levels: first, as in earlier work, we consider\nrules enriched with application conditions and second, we investigate the\nnotion of conditional bisimilarity. Conditional bisimilarity allows us to say\nthat two system states are bisimilar provided that the environment satisfies a\ngiven condition. We present several equivalent definitions of conditional\nbisimilarity, including one that is useful for concrete proofs and that employs\nan up-to-context technique, and we compare with related behavioural\nequivalences. We instantiate reactive systems in order to obtain DPO graph\nrewriting and consider a case study in this setting.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:17:35 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 18:14:43 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["H\u00fclsbusch", "Mathias", ""], ["K\u00f6nig", "Barbara", ""], ["K\u00fcpper", "Sebastian", ""], ["Stoltenow", "Lars", ""]]}, {"id": "2004.12171", "submitter": "Mani A", "authors": "Mani A and Sandor Radeleczki", "title": "Algebraic Approach to Directed Rough Sets", "comments": "37 pages, Forthcoming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In relational approach to general rough sets, ideas of directed relations are\nsupplemented with additional conditions for multiple algebraic approaches in\nthis research paper. The relations are also specialized to representations of\ngeneral parthood that are upper-directed, reflexive and antisymmetric for a\nbetter behaved groupoidal semantics over the set of roughly equivalent objects\nby the first author. Another distinct algebraic semantics over the set of\napproximations, and a new knowledge interpretation are also invented in this\nresearch by her. Because of minimal conditions imposed on the relations,\nneighborhood granulations are used in the construction of all approximations\n(granular and pointwise). Necessary and sufficient conditions for the lattice\nof local upper approximations to be completely distributive are proved by the\nsecond author. These results are related to formal concept analysis.\nApplications to student centered learning and decision making are also\noutlined.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 15:39:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["A", "Mani", ""], ["Radeleczki", "Sandor", ""]]}, {"id": "2004.12371", "submitter": "Matthew Hague", "authors": "Matthew Hague, Anthony Widjaja Lin, Philipp R\\\"ummer, Zhilin Wu", "title": "Monadic Decomposition in Integer Linear Arithmetic (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monadic decomposability is a notion of variable independence, which asks\nwhether a given formula in a first-order theory is expressible as a Boolean\ncombination of monadic predicates in the theory. Recently, Veanes et al. showed\nthe usefulness of monadic decomposability in the context of SMT (i.e. the input\nformula is quantifier-free), and found various interesting applications\nincluding string analysis. However, checking monadic decomposability is\nundecidable in general. Decidability for certain theories is known (e.g.\nPresburger Arithmetic, Tarski's Real-Closed Field), but there are very few\nresults regarding their computational complexity. In this paper, we study\nmonadic decomposability of integer linear arithmetic in the setting of SMT. We\nshow that this decision problem is coNP-complete and, when monadically\ndecomposable, a formula admits a decomposition of exponential size in the worst\ncase. We provide a new application of our results to string constraint solving\nwith length constraints. We then extend our results to variadic\ndecomposability, where predicates could admit multiple free variables (in\ncontrast to monadic decomposability). Finally, we give an application to\nquantifier elimination in integer linear arithmetic where the variables in a\nblock of quantifiers, if independent, could be eliminated with an exponential\n(instead of the standard doubly exponential) blow-up.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 13:06:11 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Hague", "Matthew", ""], ["Lin", "Anthony Widjaja", ""], ["R\u00fcmmer", "Philipp", ""], ["Wu", "Zhilin", ""]]}, {"id": "2004.12403", "submitter": "EPTCS", "authors": "Ansgar Fehnker (University of Twente), Hubert Garavel (INRIA Grenoble\n  Rh\\^one-Alpes)", "title": "Proceedings of the 4th Workshop on Models for Formal Analysis of Real\n  Systems", "comments": null, "journal-ref": "EPTCS 316, 2020", "doi": "10.4204/EPTCS.316", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of MARS 2020, the fourth workshop on\nModels for Formal Analysis of Real Systems held as part of ETAPS 2020, the\nEuropean Joint Conferences on Theory and Practice of Software.\n  The MARS workshop brings together researchers from different communities who\nare developing formal models of real systems in areas where complex models\noccur, such as networks, cyber-physical systems, hardware/software codesign,\nbiology, etc.\n  The MARS workshops stem from two observations:\n  (1) Large case studies are essential to show that specification formalisms\nand modelling techniques are applicable to real systems, whereas many research\npapers only consider toy examples or tiny case studies.\n  (2) Developing an accurate model of a real system takes a large amount of\ntime, often months or years. In most scientific papers, however, salient\ndetails of the model need to be skipped due to lack of space, and to leave room\nfor formal verification methodologies and results.\n  The MARS workshop remedies these issues, emphasising modelling over\nverification, so as to retain lessons learnt from formal modelling, which are\nnot usually discussed elsewhere.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 14:59:03 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Fehnker", "Ansgar", "", "University of Twente"], ["Garavel", "Hubert", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes"]]}, {"id": "2004.12682", "submitter": "Martin L\\\"uck", "authors": "Martin L\\\"uck", "title": "On the Complexity of Linear Temporal Logic with Team Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A specification given as a formula in linear temporal logic (LTL) defines a\nsystem by its set of traces. However, certain features such as information flow\nsecurity constraints are rather modeled as so-called hyperproperties, which are\nsets of sets of traces. One logical approach to this is team logic, which is a\nlogical framework for the specification of dependence and independence of\ninformation. LTL with team semantics has recently been discovered as a logic\nfor hyperproperties. We study the complexity theoretic aspects of LTL with\nso-called synchronous team semantics and Boolean negation, and prove that both\nits model checking and satisfiability problems are highly undecidable, and\nequivalent to the decision problem of third-order arithmetic. Furthermore, we\nprove that this complexity already appears at small temporal depth and with\nonly the \"future\" modality F. Finally, we also introduce a team-semantical\ngeneralization of stutter-invariance.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 10:00:32 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["L\u00fcck", "Martin", ""]]}, {"id": "2004.12699", "submitter": "Lucas Carvalho Cordeiro", "authors": "Mikhail R. Gadelha, Lucas C. Cordeiro and Denis A. Nicole", "title": "An Efficient Floating-Point Bit-Blasting API for Verifying C Programs", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new SMT bit-blasting API for floating-points and evaluate it\nusing different out-of-the-shelf SMT solvers during the verification of several\nC programs. The new floating-point API is part of the SMT backend in ESBMC, a\nstate-of-the-art bounded model checker for C and C++. For the evaluation, we\ncompared our floating-point API against the native floating-point APIs in Z3\nand MathSAT. We show that Boolector, when using floating-point API, outperforms\nthe solvers with native support for floating-points, correctly verifying more\nprograms in less time. Experimental results also show that our floating-point\nAPI implemented in ESBMC is on par with other state-of-the-art software\nverifiers. Furthermore, when verifying programs with floating-point arithmetic,\nour new floating-point API produced no wrong answers.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 10:40:04 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 09:13:04 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Gadelha", "Mikhail R.", ""], ["Cordeiro", "Lucas C.", ""], ["Nicole", "Denis A.", ""]]}, {"id": "2004.12713", "submitter": "Reynald Affeldt", "authors": "Reynald Affeldt and Jacques Garrigue and Takafumi Saikawa", "title": "Formal Adventures in Convex and Conical Spaces", "comments": "to be published in CICM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex sets appear in various mathematical theories, and are used to define\nnotions such as convex functions and hulls. As an abstraction from the usual\ndefinition of convex sets in vector spaces, we formalize in Coq an intrinsic\naxiomatization of convex sets, namely convex spaces, based on an operation\ntaking barycenters of points. A convex space corresponds to a specific type\nthat does not refer to a surrounding vector space. This simplifies the\ndefinitions of functions on it. We show applications including the convexity of\ninformation-theoretic functions defined over types of distributions. We also\nshow how convex spaces are embedded in conical spaces, which are abstract real\ncones, and use the embedding as an effective device to ease calculations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 11:22:58 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 18:43:47 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Affeldt", "Reynald", ""], ["Garrigue", "Jacques", ""], ["Saikawa", "Takafumi", ""]]}, {"id": "2004.12734", "submitter": "Yusuke Kawamoto", "authors": "Yusuke Kawamoto", "title": "An Epistemic Approach to the Formal Specification of Statistical Machine\n  Learning", "comments": "Accepted in Software and Systems Modeling https://rdcu.be/b7ssR This\n  paper is the journal version of the SEFM'19 conference paper arxiv:1907.10327", "journal-ref": null, "doi": "10.1007/s10270-020-00825-2", "report-no": null, "categories": "cs.LO cs.AI cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an epistemic approach to formalizing statistical properties of\nmachine learning. Specifically, we introduce a formal model for supervised\nlearning based on a Kripke model where each possible world corresponds to a\npossible dataset and modal operators are interpreted as transformation and\ntesting on datasets. Then we formalize various notions of the classification\nperformance, robustness, and fairness of statistical classifiers by using our\nextension of statistical epistemic logic (StatEL). In this formalization, we\nshow relationships among properties of classifiers, and relevance between\nclassification performance and robustness. As far as we know, this is the first\nwork that uses epistemic models and logical formulas to express statistical\nproperties of machine learning, and would be a starting point to develop\ntheories of formal specification of machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:16:45 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:52:54 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 17:51:14 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kawamoto", "Yusuke", ""]]}, {"id": "2004.12739", "submitter": "Nils Vortmeier", "authors": "Samir Datta, Pankaj Kumar, Anish Mukherjee, Anuj Tawari, Nils\n  Vortmeier, Thomas Zeume", "title": "Dynamic complexity of Reachability: How many changes can we handle?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2015, it was shown that reachability for arbitrary directed graphs can be\nupdated by first-order formulas after inserting or deleting single edges.\nLater, in 2018, this was extended for changes of size $\\frac{\\log n}{\\log \\log\nn}$, where $n$ is the size of the graph. Changes of polylogarithmic size can be\nhandled when also majority quantifiers may be used.\n  In this paper we extend these results by showing that, for changes of\npolylogarithmic size, first-order update formulas suffice for maintaining (1)\nundirected reachability, and (2) directed reachability under insertions. For\nclasses of directed graphs for which efficient parallel algorithms can compute\nnon-zero circulation weights, reachability can be maintained with update\nformulas that may use \"modulo 2\" quantifiers under changes of polylogarithmic\nsize. Examples for these classes include the class of planar graphs and graphs\nwith bounded treewidth. The latter is shown here.\n  As the logics we consider cannot maintain reachability under changes of\nlarger sizes, our results are optimal with respect to the size of the changes.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:27:37 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Datta", "Samir", ""], ["Kumar", "Pankaj", ""], ["Mukherjee", "Anish", ""], ["Tawari", "Anuj", ""], ["Vortmeier", "Nils", ""], ["Zeume", "Thomas", ""]]}, {"id": "2004.12740", "submitter": "Clemens Grabmayer", "authors": "Clemens Grabmayer and Wan Fokkink", "title": "A Complete Proof System for 1-Free Regular Expressions Modulo\n  Bisimilarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robin Milner (1984) gave a sound proof system for bisimilarity of regular\nexpressions interpreted as processes: Basic Process Algebra with unary Kleene\nstar iteration, deadlock 0, successful termination 1, and a fixed-point rule.\nHe asked whether this system is complete. Despite intensive research over the\nlast 35 years, the problem is still open.\n  This paper gives a partial positive answer to Milner's problem. We prove that\nthe adaptation of Milner's system over the subclass of regular expressions that\narises by dropping the constant 1, and by changing to binary Kleene star\niteration is complete. The crucial tool we use is a graph structure property\nthat guarantees expressibility of a process graph by a regular expression, and\nis preserved by going over from a process graph to its bisimulation collapse.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:27:57 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Grabmayer", "Clemens", ""], ["Fokkink", "Wan", ""]]}, {"id": "2004.12859", "submitter": "Julia Gabet", "authors": "Julia Gabet, Nobuko Yoshida", "title": "Static Race Detection and Mutex Safety and Liveness for Go Programs\n  (extended version)", "comments": "To be published in: ECOOP 2020; 26 pages + references and appendix;\n  Main body: 17 figures + 1 table; Appendix: 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Go is a popular concurrent programming language thanks to its ability to\nefficiently combine concurrency and systems programming. In Go programs, a\nnumber of concurrency bugs can be caused by a mixture of data races and\ncommunication problems. In this paper, we develop a theory based on behavioural\ntypes to statically detect data races and deadlocks in Go programs. We first\nspecify lock safety and liveness and data race properties over a Go program\nmodel, using the happens-before relation defined in the Go memory model. We\nrepresent these properties of programs in a $\\mu$-calculus model of types, and\nvalidate them using type-level model-checking. We then extend the framework to\naccount for Go's channels, and implement a static verification tool which can\ndetect concurrency errors. This is, to the best of our knowledge, the first\nstatic verification framework of this kind for the Go language, uniformly\nanalysing concurrency errors caused by a mix of shared memory accesses and\nasynchronous message-passing communications.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:12:11 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Gabet", "Julia", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "2004.12891", "submitter": "Gianluca Curzi", "authors": "Gianluca Curzi and Michele Pagani", "title": "The Benefit of Being Non-Lazy in Probabilistic {\\lambda}-calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the probabilistic applicative bisimilarity (PAB), a coinductive\nrelation comparing the applicative behaviour of probabilistic untyped lambda\nterms according to a specific operational semantics. This notion has been\nstudied with respect to the two standard parameter passing policies,\ncall-by-value (cbv) and call-by-name (cbn), using a lazy reduction strategy not\nreducing within the body of a function. In particular, PAB has been proven to\nbe fully abstract with respect to the contextual equivalence in cbv but not in\nlazy cbn. We overcome this issue of cbn by relaxing the laziness constraint: we\nprove that PAB is fully abstract with respect to the standard head reduction\ncontextual equivalence. Our proof is based on the Leventis Separation Theorem,\nusing probabilistic Nakajima trees as a tree-like representation of the\ncontextual equivalence classes. Finally, we prove also that the inequality full\nabstraction fails, showing that the probabilistic applicative similarity is\nstrictly contained in the contextual preorder.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:53:27 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Curzi", "Gianluca", ""], ["Pagani", "Michele", ""]]}, {"id": "2004.12921", "submitter": "\\\"Amin Baumeler", "authors": "\\\"Amin Baumeler and Eleftherios Tselentis", "title": "Equivalence of grandfather and information antinomy under intervention", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal loops, e.g., in time travel, come with two main problems. Most\nprominently, the grandfather antinomy describes the potentiality to\ninconsistencies; a problem of logical nature. The other problem is called\ninformation antinomy and is lesser known. Yet, it describes a variant of the\nformer: There are not too few consistent solutions---namely none---, but too\nmany. At a first glance, the information antinomy does not seem as problematic\nas the grandfather antinomy, because there is no apparent logical\ncontradiction. In this work we show that, however, both problems are equivalent\nunder interventions: If parties can intervene in such a way that the\ninformation antinomy arises, then they can also intervene to generate a\ncontradiction, and vice versa.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:34:51 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Baumeler", "\u00c4min", ""], ["Tselentis", "Eleftherios", ""]]}, {"id": "2004.12941", "submitter": "Anupam Das", "authors": "Cameron Calk, Anupam Das, Tim Waring", "title": "Beyond formulas-as-cographs: an extension of Boolean logic to arbitrary\n  graphs", "comments": "47 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a graph-based extension of Boolean logic called Boolean Graph\nLogic (BGL). Construing formula trees as the cotrees of cographs, we may state\nsemantic notions such as evaluation and entailment in purely graph-theoretic\nterms, whence we recover the definition of BGL. Naturally, it is conservative\nover usual Boolean logic.\n  Our contributions are the following:\n  (1) We give a natural semantics of BGL based on Boolean relations, i.e. it is\na multivalued semantics, and show adequacy of this semantics for the\ncorresponding notions of entailment. (2) We show that the complexity of\nevaluation is NP-complete for arbitrary graphs (as opposed to ALOGTIME-complete\nfor formulas), while entailment is $\\Pi^p_2$-complete (as opposed to\ncoNP-complete for formulas). (3) We give a 'recursive' algorithm for evaluation\nby induction on the modular decomposition of graphs. (Though this is not\npolynomial-time, cf. point (2) above). (4) We characterise evaluation in a\ngame-theoretic setting, in terms of both static and sequentical strategies,\nextending the classical notion of positional game forms beyond cographs. (5) We\ngive an axiomatisation of BGL, inspired by deep-inference proof theory, and\nshow soundness and completeness for the corresponding notions of entailment.\n  One particular feature of the graph-theoretic setting is that it escapes\ncertain no-go theorems such as a recent result of Das and Strassburger, that\nthere is no linear axiomatisation of the linear fragment of Boolean logic\n(equivalently the multiplicative fragment of Japaridze's Computability Logic or\nBlass' game semantics for Mutliplicative Linear Logic).\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:58:39 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Calk", "Cameron", ""], ["Das", "Anupam", ""], ["Waring", "Tim", ""]]}, {"id": "2004.13237", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "An ASP-Based Approach to Counterfactual Explanations for Classification", "comments": "Revised and extended version. To appear in Proc. RuleML+RR, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose answer-set programs that specify and compute counterfactual\ninterventions as a basis for causality-based explanations to decisions produced\nby classification models. They can be applied with black-box models and models\nthat can be specified as logic programs, such as rule-based classifiers. The\nmain focus in on the specification and computation of maximum responsibility\ncausal explanations. The use of additional semantic knowledge is investigated.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 01:36:26 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 03:56:13 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "2004.13285", "submitter": "EPTCS", "authors": "Ryan Barry, Rob van Glabbeek, Peter H\\\"ofner", "title": "Formalising the Optimised Link State Routing Protocol", "comments": "In Proceedings MARS 2020, arXiv:2004.12403", "journal-ref": "EPTCS 316, 2020, pp. 40-71", "doi": "10.4204/EPTCS.316.3", "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing protocol specifications are traditionally written in plain English.\nOften this yields ambiguities, inaccuracies or even contradictions. Formal\nmethods techniques, such as process algebras, avoid these problems, thus\nleading to more precise and verifiable descriptions of protocols. In this paper\nwe use the timed process algebra T-AWN for modelling the Optimised Link State\nRouting protocol (OLSR) version 2.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:21:53 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Barry", "Ryan", ""], ["van Glabbeek", "Rob", ""], ["H\u00f6fner", "Peter", ""]]}, {"id": "2004.13286", "submitter": "EPTCS", "authors": "Jack Drury, Peter H\\\"ofner, Weiyou Wang", "title": "Formal Models of the OSPF Routing Protocol", "comments": "In Proceedings MARS 2020, arXiv:2004.12403", "journal-ref": "EPTCS 316, 2020, pp. 72-120", "doi": "10.4204/EPTCS.316.4", "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present three formal models of the OSPF routing protocol. The first two\nare formalised in the timed process algebra T-AWN, which is not only tailored\nto routing protocols, but also specifies protocols in pseudo-code that is\neasily readable. The difference between the two models lies in the level of\ndetail (level of abstraction). From the more abstract model we then generate\nthe third model. It is based on networks of timed automata and can be executed\nin the model checker Uppaal.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:22:18 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Drury", "Jack", ""], ["H\u00f6fner", "Peter", ""], ["Wang", "Weiyou", ""]]}, {"id": "2004.13287", "submitter": "EPTCS", "authors": "Clemens Dubslaff, Andrey Morozov, Christel Baier, Klaus Janschek", "title": "Iterative Variable Reordering: Taming Huge System Families", "comments": "In Proceedings MARS 2020, arXiv:2004.12403", "journal-ref": "EPTCS 316, 2020, pp. 121-133", "doi": "10.4204/EPTCS.316.5", "report-no": null, "categories": "cs.LO cs.PF cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the verification of systems using model-checking techniques, symbolic\nrepresentations based on binary decision diagrams (BDDs) often help to tackle\nthe well-known state-space explosion problem. Symbolic BDD-based\nrepresentations have been also shown to be successful for the analysis of\nfamilies of systems that arise, e.g., through configurable parameters or\nfollowing the feature-oriented modeling approach. The state space of such\nsystem families face an additional exponential blowup in the number of\nparameters or features. It is well known that the order of variables in ordered\nBDDs is crucial for the size of the model representation. Especially for\nautomatically generated models from real-world systems, family models might\neven be not constructible due to bad variable orders. In this paper we describe\na technique, called iterative variable reordering, that can enable the\nconstruction of large-scale family models. We exemplify feasibility of our\napproach by means of an aircraft velocity control system with redundancy\nmechanisms modeled in the input language of the probabilistic model checker\nPRISM. We show that standard reordering and dynamic reordering techniques fail\nto construct the family model due to memory and time constraints, respectively,\nwhile the new iterative approach succeeds to generate a symbolic family model.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:23:14 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Dubslaff", "Clemens", ""], ["Morozov", "Andrey", ""], ["Baier", "Christel", ""], ["Janschek", "Klaus", ""]]}, {"id": "2004.13289", "submitter": "EPTCS", "authors": "Radu Mateescu, Wendelin Serwe, Aymane Bouzafour, Marc Renaudin", "title": "Modeling an Asynchronous Circuit Dedicated to the Protection Against\n  Physical Attacks", "comments": "In Proceedings MARS 2020, arXiv:2004.12403", "journal-ref": "EPTCS 316, 2020, pp. 200-239", "doi": "10.4204/EPTCS.316.8", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous circuits have several advantages for security applications, in\nparticular their good resistance to attacks. In this paper, we report on\nexperiments with modeling, at various abstraction levels, a patented\nasynchronous circuit for detecting physical attacks, such as cutting wires or\nproducing short-circuits.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:24:07 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Mateescu", "Radu", ""], ["Serwe", "Wendelin", ""], ["Bouzafour", "Aymane", ""], ["Renaudin", "Marc", ""]]}, {"id": "2004.13472", "submitter": "Peng Fu", "authors": "Peng Fu, Kohei Kishida, Peter Selinger", "title": "Linear Dependent Type Theory for Quantum Programming Languages", "comments": "submitted to LMCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern quantum programming languages integrate quantum resources and\nclassical control. They must, on the one hand, be linearly typed to reflect the\nno-cloning property of quantum resources. On the other hand, high-level and\npractical languages should also support quantum circuits as first-class\ncitizens, as well as families of circuits that are indexed by some classical\nparameters. Quantum programming languages thus need linear dependent type\ntheory. This paper defines a general semantic structure for such a type theory\nvia certain fibrations of monoidal categories. The categorical model of the\nquantum circuit description language Proto-Quipper-M by Rios and Selinger\n(2017) constitutes an example of such a fibration, which means that the\nlanguage can readily be integrated with dependent types. We then devise both a\ngeneral linear dependent type system and a dependently typed extension of\nProto-Quipper-M, and provide them with operational semantics as well as a\nprototype implementation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:11:06 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 18:38:54 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Fu", "Peng", ""], ["Kishida", "Kohei", ""], ["Selinger", "Peter", ""]]}, {"id": "2004.13789", "submitter": "Rapha\\\"el Berthon", "authors": "Rapha\\\"el Berthon, Shibashis Guha, Jean-Fran\\c{c}ois Raskin", "title": "Mixing Probabilistic and non-Probabilistic Objectives in Markov Decision\n  Processes", "comments": "Paper accepted to LICS 2020 - Full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider algorithms to decide the existence of strategies\nin MDPs for Boolean combinations of objectives. These objectives are\nomega-regular properties that need to be enforced either surely, almost surely,\nexistentially, or with non-zero probability. In this setting, relevant\nstrategies are randomized infinite memory strategies: both infinite memory and\nrandomization may be needed to play optimally. We provide algorithms to solve\nthe general case of Boolean combinations and we also investigate relevant\nsubcases. We further report on complexity bounds for these problems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 19:48:15 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Berthon", "Rapha\u00ebl", ""], ["Guha", "Shibashis", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "2004.14084", "submitter": "Yuki Nishida", "authors": "Yuki Nishida and Atsushi Igarashi", "title": "Compilation of Coordinated Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, we have proposed coordinated choices, which are nondeterministic\nchoices equipped with names. The main characteristic of coordinated choices is\nthat they synchronize nondeterministic decision among choices of the same name.\n  The motivation of the synchronization mechanism is to solve a theoretical\nproblem. So, as a practical programming language, we still want to use\ncoordinated choices like standard ones. In other words, we want to avoid\nsynchronization. Now, there are two problems: (i) practically, it is a bit\ncomplicated work to write a program using coordinated choices in which\nexecution synchronization never happens; and (ii) theoretically, it is unknown\nwhether any programs using standard choices can be written by using only\ncoordinated ones.\n  In this paper, we define two simply typed lambda calculi called\n$\\lambda^\\parallel$ equipped with standard choices and\n$\\lambda^{\\parallel\\omega}$ equipped with coordinated choices, and give\ncompilation rules from the former into the latter. The challenge is to show the\ncorrectness of the compilation because behavioral correspondence between\nexpressions before and after compiling cannot be defined directly by the\ncompilation rules. For the challenge, we give an effect system for\n$\\lambda^{\\parallel\\omega}$ that characterizes expressions in which execution\nsynchronization never happens. Then, we show that all compiled expressions can\nbe typed by the effect system. As a result, we can easily show the correctness\nbecause the main concern of the correctness is whether synchronization happens\nor not.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 11:15:19 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Nishida", "Yuki", ""], ["Igarashi", "Atsushi", ""]]}, {"id": "2004.14195", "submitter": "Valery Isaev", "authors": "Valery Isaev", "title": "Models of Homotopy Type Theory with an Interval Type", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, we construct a class of models of an extension of\nhomotopy type theory, which we call homotopy type theory with an interval type.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:38:53 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 23:26:19 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Isaev", "Valery", ""]]}, {"id": "2004.14378", "submitter": "Johannes Klaus Fichte", "authors": "Johannes K. Fichte, Norbert Manthey, Julian Stecklina, Andr\\'e\n  Schidler", "title": "Towards Faster Reasoners By Using Transparent Huge Pages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various state-of-the-art automated reasoning (AR) tools are widely used as\nbackend tools in research of knowledge representation and reasoning as well as\nin industrial applications. In testing and verification, those tools often run\ncontinuously or nightly. In this work, we present an approach to reduce the\nruntime of AR tools by 10% on average and up to 20% for long running tasks. Our\nimprovement addresses the high memory usage that comes with the data structures\nused in AR tools, which are based on conflict driven no-good learning. We\nestablish a general way to enable faster memory access by using the memory\ncache line of modern hardware more effectively. Therefore, we extend the\nstandard C library (glibc) by dynamically allowing to use a memory management\nfeature called huge pages. Huge pages allow to reduce the overhead that is\nrequired to translate memory addresses between the virtual memory of the\noperating system and the physical memory of the hardware. In that way, we can\nreduce runtime, costs, and energy consumption of AR tools and applications with\nsimilar memory access patterns simply by linking the tool against this new\nglibc library when compiling it. In every day industrial applications this\neasily allows to be more eco-friendly in computation. To back up the claimed\nspeed-up, we present experimental results for tools that are commonly used in\nthe AR community, including the domains ASP, BMC, MaxSAT, SAT, and SMT.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:57:19 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Manthey", "Norbert", ""], ["Stecklina", "Julian", ""], ["Schidler", "Andr\u00e9", ""]]}, {"id": "2004.14384", "submitter": "Mohamed Wagdy Eldesouki", "authors": "Mohamed Abdelghany, Waqar Ahmad, and Sofiene Tahar", "title": "A Formally Verified HOL4 Algebra for Event Trees", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event Tree (ET) analysis is widely used as a forward deductive safety\nanalysis technique for decision-making at the critical-system design stage. ET\nis a schematic diagram representing all possible operating states and external\nevents in a system so that one of these possible scenarios can occur. In this\nreport, we propose to use the HOL4 theorem prover for the formal modeling and\nstep-analysis of ET diagrams. To this end, we developed a formalization of ETs\nin higher-order logic, which is based on a generic list datatype that can: (i)\nconstruct an arbitrary level of ET diagrams; (ii) reduce the irrelevant ET\nbranches; (iii) partition ET paths; and (iv) perform the probabilistic analysis\nbased on the occurrence of certain events. For illustration purposes, we\nconduct the formal ET stepwise analysis of an electrical power grid and also\ndetermine its System Average Interruption Frequency Index (SAIFI), which is an\nimportant indicator for system reliability.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 15:55:07 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Abdelghany", "Mohamed", ""], ["Ahmad", "Waqar", ""], ["Tahar", "Sofiene", ""]]}, {"id": "2004.14561", "submitter": "Yong Kiam Tan", "authors": "Yong Kiam Tan, Andr\\'e Platzer", "title": "An Axiomatic Approach to Existence and Liveness for Differential\n  Equations", "comments": "Significantly extended version of arXiv:1904.07984", "journal-ref": null, "doi": "10.1007/s00165-020-00525-0", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an axiomatic approach for deductive verification of\nexistence and liveness for ordinary differential equations (ODEs) with\ndifferential dynamic logic (dL). The approach yields proofs that the solution\nof a given ODE exists long enough to reach a given target region without\nleaving a given evolution domain. Numerous subtleties complicate the\ngeneralization of discrete liveness verification techniques, such as loop\nvariants, to the continuous setting. For example, ODE solutions may blow up in\nfinite time or their progress towards the goal may converge to zero. These\nsubtleties are handled in dL by successively refining ODE liveness properties\nusing ODE invariance properties which have a complete axiomatization. This\napproach is widely applicable: several liveness arguments from the literature\nare surveyed and derived as special instances of axiomatic refinement in dL.\nThese derivations also correct several soundness errors in the surveyed\nliterature, which further highlights the subtlety of ODE liveness reasoning and\nthe utility of an axiomatic approach. An important special case of this\napproach deduces (global) existence properties of ODEs, which are a fundamental\npart of every ODE liveness argument. Thus, all generalizations of existence\nproperties and their proofs immediately lead to corresponding generalizations\nof ODE liveness arguments. Overall, the resulting library of common refinement\nsteps enables both the sound development and justification of new ODE existence\nand of liveness proof rules from dL axioms. These insights are put into\npractice through an implementation of ODE liveness proofs in the KeYmaera X\ntheorem prover for hybrid systems.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 03:30:53 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 14:29:39 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Tan", "Yong Kiam", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "2004.14692", "submitter": "S. Akshay", "authors": "Kuldeep S. Meel and S. Akshay", "title": "Sparse Hashing for Scalable Approximate Model Counting: Theory and\n  Practice", "comments": "Full version of paper accepted in LICS2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a CNF formula F on n variables, the problem of model counting or #SAT\nis to compute the number of satisfying assignments of F . Model counting is a\nfundamental but hard problem in computer science with varied applications.\nRecent years have witnessed a surge of effort towards developing efficient\nalgorithmic techniques that combine the classical 2-universal hashing with the\nremarkable progress in SAT solving over the past decade. These techniques\naugment the CNF formula F with random XOR constraints and invoke an NP oracle\nrepeatedly on the resultant CNF-XOR formulas. In practice, calls to the NP\noracle calls are replaced a SAT solver whose runtime performance is adversely\naffected by size of XOR constraints. The standard construction of 2-universal\nhash functions chooses every variable with probability p = 1/2 leading to XOR\nconstraints of size n/2 in expectation. Consequently, the challenge is to\ndesign sparse hash functions where variables can be chosen with smaller\nprobability and lead to smaller sized XOR constraints.\n  In this paper, we address this challenge from theoretical and practical\nperspectives. First, we formalize a relaxation of universal hashing, called\nconcentrated hashing and establish a novel and beautiful connection between\nconcentration measures of these hash functions and isoperimetric inequalities\non boolean hypercubes. This allows us to obtain (log m) tight bounds on\nvariance and dispersion index and show that p = O( log(m)/m ) suffices for\ndesign of sparse hash functions from {0, 1}^n to {0, 1}^m. We then use sparse\nhash functions belonging to this concentrated hash family to develop new\napproximate counting algorithms. A comprehensive experimental evaluation of our\nalgorithm on 1893 benchmarks demonstrates that usage of sparse hash functions\ncan lead to significant speedups.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 11:17:26 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Meel", "Kuldeep S.", ""], ["Akshay", "S.", ""]]}, {"id": "2004.14750", "submitter": "EPTCS", "authors": "Bob Coecke (University of Oxford), Matthew Leifer (Chapman University)", "title": "Proceedings 16th International Conference on Quantum Physics and Logic", "comments": null, "journal-ref": "EPTCS 318, 2020", "doi": "10.4204/EPTCS.318", "report-no": null, "categories": "cs.LO cs.FL cs.IT cs.PL math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the 16th International Conference on\nQuantum Physics and Logic (QPL 2017), which was held June 10-14, 2019. Quantum\nPhysics and Logic is an annual conference that brings together researchers\nworking on mathematical foundations of quantum physics, quantum computing, and\nrelated areas, with a focus on structural perspectives and the use of logical\ntools, ordered algebraic and category-theoretic structures, formal languages,\nsemantical methods, and other computer science techniques applied to the study\nof physical behaviour in general. Work that applies structures and methods\ninspired by quantum theory to other fields (including computer science) is also\nwelcome.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 13:14:56 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Coecke", "Bob", "", "University of Oxford"], ["Leifer", "Matthew", "", "Chapman University"]]}, {"id": "2004.14789", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet, Eun Jung Kim, St\\'ephan Thomass\\'e, R\\'emi Watrigant", "title": "Twin-width I: tractable FO model checking", "comments": "48 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a width invariant defined on permutations by Guillemot and Marx\n[SODA '14], we introduce the notion of twin-width on graphs and on matrices.\nProper minor-closed classes, bounded rank-width graphs, map graphs, $K_t$-free\nunit $d$-dimensional ball graphs, posets with antichains of bounded size, and\nproper subclasses of dimension-2 posets all have bounded twin-width. On all\nthese classes (except map graphs without geometric embedding) we show how to\ncompute in polynomial time a sequence of $d$-contractions, witness that the\ntwin-width is at most $d$. We show that FO model checking, that is deciding if\na given first-order formula $\\phi$ evaluates to true for a given binary\nstructure $G$ on a domain $D$, is FPT in $|\\phi|$ on classes of bounded\ntwin-width, provided the witness is given. More precisely, being given a\n$d$-contraction sequence for $G$, our algorithm runs in time $f(d,|\\phi|) \\cdot\n|D|$ where $f$ is a computable but non-elementary function. We also prove that\nbounded twin-width is preserved by FO interpretations and transductions\n(allowing operations such as squaring or complementing a graph). This unifies\nand significantly extends the knowledge on fixed-parameter tractability of FO\nmodel checking on non-monotone classes, such as the FPT algorithm on\nbounded-width posets by Gajarsk\\'y et al. [FOCS '15].\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:05:41 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 13:47:30 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Kim", "Eun Jung", ""], ["Thomass\u00e9", "St\u00e9phan", ""], ["Watrigant", "R\u00e9mi", ""]]}, {"id": "2004.14835", "submitter": "Kevin Batz", "authors": "Kevin Batz, Sebastian Junges, Benjamin Lucien Kaminski, Joost-Pieter\n  Katoen, Christoph Matheja, Philipp Schr\\\"oer", "title": "PrIC3: Property Directed Reachability for MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IC3 has been a leap forward in symbolic model checking. This paper proposes\nPrIC3 (pronounced pricy-three), a conservative extension of IC3 to symbolic\nmodel checking of MDPs. Our main focus is to develop the theory underlying\nPrIC3. Alongside, we present a first implementation of PrIC3 including the key\ningredients from IC3 such as generalization, repushing, and propagation.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:45:31 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 17:18:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Batz", "Kevin", ""], ["Junges", "Sebastian", ""], ["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""], ["Matheja", "Christoph", ""], ["Schr\u00f6er", "Philipp", ""]]}, {"id": "2004.14839", "submitter": "Hitomi Yanaka", "authors": "Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, and Kentaro Inui", "title": "Do Neural Models Learn Systematicity of Monotonicity Inference in\n  Natural Language?", "comments": "accepted by ACL2020 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of language models using neural networks, it remains\nunclear to what extent neural models have the generalization ability to perform\ninferences. In this paper, we introduce a method for evaluating whether neural\nmodels can learn systematicity of monotonicity inference in natural language,\nnamely, the regularity for performing arbitrary inferences with generalization\non composition. We consider four aspects of monotonicity inferences and test\nwhether the models can systematically interpret lexical and logical phenomena\non different training/test splits. A series of experiments show that three\nneural models systematically draw inferences on unseen combinations of lexical\nand logical phenomena when the syntactic structures of the sentences are\nsimilar between the training and test sets. However, the performance of the\nmodels significantly decreases when the structures are slightly changed in the\ntest set while retaining all vocabularies and constituents already appearing in\nthe training set. This indicates that the generalization ability of neural\nmodels is limited to cases where the syntactic structures are nearly the same\nas those in the training set.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:48:39 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 12:35:41 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Yanaka", "Hitomi", ""], ["Mineshima", "Koji", ""], ["Bekki", "Daisuke", ""], ["Inui", "Kentaro", ""]]}, {"id": "2004.14931", "submitter": "Andreas Pavlogiannis", "authors": "Umang Mathur and Andreas Pavlogiannis and Mahesh Viswanathan", "title": "The Complexity of Dynamic Data Race Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing concurrent programs is notoriously hard due to scheduling\nnon-determinism. The most common concurrency bugs are data races, which are\naccesses to a shared resource that can be executed concurrently. Dynamic\ndata-race prediction is the most standard technique for detecting data races:\ngiven an observed, data-race-free trace $t$, the task is to determine whether\n$t$ can be reordered to a trace $t^*$ that exposes a data-race. Although the\nproblem has received significant practical attention for over three decades,\nits complexity has remained elusive. In this work, we address this lacuna,\nidentifying sources of intractability and conditions under which the problem is\nefficiently solvable. Given a trace $t$ of size $n$ over $k$ threads, our main\nresults are as follows.\n  First, we establish a general $O(k\\cdot n^{2\\cdot (k-1)})$ upper-bound, as\nwell as an $O(n^k)$ upper-bound when certain parameters of $t$ are constant. In\naddition, we show that the problem is NP-hard and even W[1]-hard parameterized\nby $k$, and thus unlikely to be fixed-parameter tractable. Second, we study the\nproblem over acyclic communication topologies, such as server-clients\nhierarchies. We establish an $O(k^2\\cdot d\\cdot n^2\\cdot \\log n)$ upper-bound,\nwhere $d$ is the number of shared variables accessed in $t$. In addition, we\nshow that even for traces with $k=2$ threads, the problem has no\n$O(n^{2-\\epsilon})$ algorithm under Orthogonal Vectors. Since any trace with 2\nthreads defines an acyclic topology, our upper-bound for this case is optimal\nwrt polynomial improvements for up to moderate values of $k$ and $d$. Finally,\nwe study a distance-bounded version of the problem, where the task is to expose\na data race by a witness trace that is similar to $t$. We develop an algorithm\nthat works in $O(n)$ time when certain parameters of $t$ are constant.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 16:33:11 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 08:51:52 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mathur", "Umang", ""], ["Pavlogiannis", "Andreas", ""], ["Viswanathan", "Mahesh", ""]]}, {"id": "2004.14971", "submitter": "Hao Zheng", "authors": "Hao Zheng, Yingying Zhang, Chris Myers", "title": "Local State Space Analysis to Assist Partial Order Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach to more efficient partial order reduction for\nmodel checking concurrent systems. This approach utilizes a compositional\nreachability analysis to generate over-approximate local state transition\nmodels for all processes in a concurrent system where an independence relation\nand other useful information can be extracted. The extracted independence\nrelation, compared to what can be obtained by statically analyzing the system\ndescriptions, is more precise and refined, therefore leads to more efficient\npartial order reduction. This approach is demonstrated on a set of concurrent\nsystem examples. Significantly higher reduction in state space has been\nobserved in several cases compared to what can be obtained using SPIN.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:19:41 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zheng", "Hao", ""], ["Zhang", "Yingying", ""], ["Myers", "Chris", ""]]}]