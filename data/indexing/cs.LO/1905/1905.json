[{"id": "1905.00325", "submitter": "Florian Kamm\\\"uller", "authors": "Florian Kamm\\\"uller", "title": "QKD in Isabelle -- Bayesian Calculation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a first step towards a formalisation of the Quantum\nKey Distribution algorithm in Isabelle. We focus on the formalisation of the\nmain probabilistic argument why Bob cannot be certain about the key bit sent by\nAlice before he does not have the chance to compare the chosen polarization\nscheme. This means that any adversary Eve is in the same position as Bob and\ncannot be certain about the transmitted keybits. We introduce the necessary\nbasic probability theory, present a graphical depiction of the protocol steps\nand their probabilities, and finally how this is translated into a formal proof\nof the security argument.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 14:27:16 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Kamm\u00fcller", "Florian", ""]]}, {"id": "1905.00456", "submitter": "Igor Tarasyuk", "authors": "Igor V. Tarasyuk", "title": "Discrete time stochastic and deterministic Petri box calculus", "comments": "arXiv admin note: substantial text overlap with arXiv:1702.07478", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension with deterministically timed multiactions of discrete\ntime stochastic and immediate Petri box calculus (dtsiPBC), previously\npresented by I.V. Tarasyuk, H. Maci\\`a and V. Valero. In dtsdPBC, non-negative\nintegers specify multiactions with fixed (including zero) time delays. The step\noperational semantics is constructed via labeled probabilistic transition\nsystems. The denotational semantics is defined on the basis of a subclass of\nlabeled discrete time stochastic Petri nets with deterministic transitions. The\nconsistency of both semantics is demonstrated. In order to evaluate\nperformance, the corresponding semi-Markov chains and (reduced) discrete time\nMarkov chains are analyzed.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 19:15:47 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Tarasyuk", "Igor V.", ""]]}, {"id": "1905.00708", "submitter": "Klemens Esterle", "authors": "Klemens Esterle, Vincent Aravantinos, Alois Knoll", "title": "From Specifications to Behavior: Maneuver Verification in a Semantic\n  State Space", "comments": "Published at IEEE Intelligent Vehicles Symposium (IV), 2019", "journal-ref": null, "doi": "10.1109/IVS.2019.8814241", "report-no": null, "categories": "cs.RO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To realize a market entry of autonomous vehicles in the foreseeable future,\nthe behavior planning system will need to abide by the same rules that humans\nfollow. Product liability cannot be enforced without a proper solution to the\napproval trap. In this paper, we define a semantic abstraction of the\ncontinuous space and formalize traffic rules in linear temporal logic (LTL).\nSequences in the semantic state space represent maneuvers a high-level planner\ncould choose to execute. We check these maneuvers against the formalized\ntraffic rules using runtime verification. By using the standard model checker\nNuSMV, we demonstrate the effectiveness of our approach and provide runtime\nproperties for the maneuver verification. We show that high-level behavior can\nbe verified in a semantic state space to fulfill a set of formalized rules,\nwhich could serve as a step towards safety of the intended functionality.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 12:54:33 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 13:09:13 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Esterle", "Klemens", ""], ["Aravantinos", "Vincent", ""], ["Knoll", "Alois", ""]]}, {"id": "1905.00784", "submitter": "Aline Goeminne", "authors": "Thomas Brihaye, V\\'eronique Bruy\\`ere, Aline Goeminne,\n  Jean-Fran\\c{c}ois Raskin and Marie van den Bogaard", "title": "The Complexity of Subgame Perfect Equilibria in Quantitative\n  Reachability Games", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 4 (November\n  5, 2020) lmcs:6883", "doi": "10.23638/LMCS-16(4:8)2020", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study multiplayer quantitative reachability games played on a finite\ndirected graph, where the objective of each player is to reach his target set\nof vertices as quickly as possible. Instead of the well-known notion of Nash\nequilibrium (NE), we focus on the notion of subgame perfect equilibrium (SPE),\na refinement of NE well-suited in the framework of games played on graphs. It\nis known that there always exists an SPE in quantitative reachability games and\nthat the constrained existence problem is decidable. We here prove that this\nproblem is PSPACE-complete. To obtain this result, we propose a new algorithm\nthat iteratively builds a set of constraints characterizing the set of SPE\noutcomes in quantitative reachability games. This set of constraints is\nobtained by iterating an operator that reinforces the constraints up to\nobtaining a fixpoint. With this fixpoint, the set of SPE outcomes can be\nrepresented by a finite graph of size at most exponential. A careful inspection\nof the computation allows us to establish PSPACE membership.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 14:47:15 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 13:19:51 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2019 13:04:43 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 10:55:43 GMT"}, {"version": "v5", "created": "Sat, 27 Jun 2020 17:51:24 GMT"}, {"version": "v6", "created": "Tue, 13 Oct 2020 12:36:53 GMT"}, {"version": "v7", "created": "Wed, 4 Nov 2020 17:54:25 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Brihaye", "Thomas", ""], ["Bruy\u00e8re", "V\u00e9ronique", ""], ["Goeminne", "Aline", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Bogaard", "Marie van den", ""]]}, {"id": "1905.00787", "submitter": "Christoph Benzm\\\"uller", "authors": "Daniel Kirchner, Christoph Benzm\\\"uller, Edward N. Zalta", "title": "Computer Science and Metaphysics: A Cross-Fertilization", "comments": "39 pages, 3 figures", "journal-ref": "Open Philosophy, 2019", "doi": "10.1515/opphil-2019-0015", "report-no": null, "categories": "cs.LO cs.AI cs.CL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational philosophy is the use of mechanized computational techniques to\nunearth philosophical insights that are either difficult or impossible to find\nusing traditional philosophical methods. Computational metaphysics is\ncomputational philosophy with a focus on metaphysics. In this paper, we (a)\ndevelop results in modal metaphysics whose discovery was computer assisted, and\n(b) conclude that these results work not only to the obvious benefit of\nphilosophy but also, less obviously, to the benefit of computer science, since\nthe new computational techniques that led to these results may be more broadly\napplicable within computer science. The paper includes a description of our\nbackground methodology and how it evolved, and a discussion of our new results.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:51:32 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 07:23:18 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 08:32:06 GMT"}, {"version": "v4", "created": "Sun, 11 Aug 2019 12:47:34 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Kirchner", "Daniel", ""], ["Benzm\u00fcller", "Christoph", ""], ["Zalta", "Edward N.", ""]]}, {"id": "1905.00810", "submitter": "Riccardo De Masellis", "authors": "Riccardo De Masellis and Valentin Goranko", "title": "Logic-based Specification and Verification of Homogeneous Dynamic\n  Multi-agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a logic-based framework for formal specification and algorithmic\nverification of homogeneous and dynamic concurrent multi-agent transition\nsystems (HDMAS). Homogeneity means that all agents have the same available\nactions at any given state and the actions have the same effects regardless of\nwhich agents perform them. The state transitions are therefore determined only\nby the vector of numbers of agents performing each action and are specified\nsymbolically, by means of conditions on these numbers definable in Presburger\narithmetic. The agents are divided into controllable (by the system\nsupervisor/controller) and uncontrollable, representing the environment or\nadversary. Dynamicity means that the numbers of controllable and uncontrollable\nagents may vary throughout the system evolution, possibly at every transition.\n  As a language for formal specification we use a suitably extended version of\nAlternating-time Temporal Logic (ATL), where one can specify properties of the\ntype \"a coalition of (at least) $n$ controllable agents can ensure against (at\nmost) $m$ uncontrollable agents that any possible evolution of the system\nsatisfies a given objective $\\varphi$\", where $\\varphi$ is specified again as a\nformula of that language and each of $n$ and $m$ is either a fixed number or a\nvariable that can be quantified over.\n  We provide formal semantics to our logic $\\mathcal{L}_{HDMAS}$ and define\nnormal form of its formulae. We then prove that every formula in\n$\\mathcal{L}_{HDMAS}$ is equivalent in the finite to one in a normal form and\ndevelop an algorithm for global model checking of formulae in normal form in\nfinite HDMAS models, which invokes model checking truth of Presburger formulae.\nWe establish worst case complexity estimates for the model checking algorithm\nand illustrate it on a running example.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 15:32:17 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 15:39:14 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 13:49:06 GMT"}, {"version": "v4", "created": "Thu, 19 Mar 2020 19:19:00 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["De Masellis", "Riccardo", ""], ["Goranko", "Valentin", ""]]}, {"id": "1905.00993", "submitter": "Norihiro Yamada", "authors": "Norihiro Yamada", "title": "Game Semantics of Martin-L\\\"of Type Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new game semantics of Martin-L\\\"of type theory (MLTT) equipped\nwith One-, Zero-, N-, Pi-, Sigma- and Id-types. Our game semantics interprets\nMLTT more accurately than existing ones. Another advantage of our game\nsemantics over existing ones is its interpretation of Sigma-types that is\ndirect and compatible with the game semantics of product types . Besides, its\nmathematical structure is novel and useful; e.g., the category of our games has\nall finite limits, which is a key step to an extension of the present work to\nhomotopy type theory, and our games interpret subtyping on dependent types for\nthe first time as game semantics. Finally, we provide a new, game-semantic\nproof of the independence of Markov's principle from MLTT, which demonstrates\nan advantage of our game semantics over extensional models of MLTT such as the\neffective topos.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 00:05:11 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:50:18 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 00:47:41 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 23:34:41 GMT"}, {"version": "v5", "created": "Fri, 4 Jun 2021 19:19:38 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yamada", "Norihiro", ""]]}, {"id": "1905.01305", "submitter": "Alejandro D\\'iaz-Caro", "authors": "Alejandro D\\'iaz-Caro and Octavio Malherbe", "title": "A categorical construction for the computational definition of vector\n  spaces", "comments": "39 pages. Applied Categorical Structures (2020). arXiv admin note:\n  text overlap with arXiv:1806.09236", "journal-ref": "Applied Categorical Structures 28(5):807-844, 2020", "doi": "10.1007/s10485-020-09598-7", "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lambda-S is an extension to first-order lambda calculus unifying two\napproaches of non-cloning in quantum lambda-calculi. One is to forbid\nduplication of variables, while the other is to consider all lambda-terms as\nalgebraic linear functions. The type system of Lambda-S has a constructor S\nsuch that a type A is considered as the base of a vector space while S(A) is\nits span. Lambda-S can also be seen as a language for the computational\nmanipulation of vector spaces: The vector spaces axioms are given as a rewrite\nsystem, describing the computational steps to be performed. In this paper we\ngive an abstract categorical semantics of Lambda-S* (a fragment of Lambda-S),\nshowing that S can be interpreted as the composition of two functors in an\nadjunction relation between a Cartesian category and an additive symmetric\nmonoidal category. The right adjoint is a forgetful functor U, which is hidden\nin the language, and plays a central role in the computational reasoning.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 19:31:05 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 18:39:04 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["D\u00edaz-Caro", "Alejandro", ""], ["Malherbe", "Octavio", ""]]}, {"id": "1905.01545", "submitter": "Luciano Caroprese", "authors": "Luciano Caroprese and Ester Zumpano", "title": "A Logic Framework for P2P Deductive Databases", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 1-43", "doi": "10.1017/S1471068419000073", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a logic framework for modeling the interaction among\ndeductive databases in a P2P (Peer to Peer) environment. Each peer joining a\nP2P system provides or imports data from its neighbors by using a set of\nmapping rules, i.e. a set of semantic correspondences to a set of peers\nbelonging to the same environment. Two different types of mapping rules are\ndefined: mapping rules allowing to import a maximal set of atoms not leading to\ninconsistency (called maximal mapping rules) and mapping rules allowing to\nimport a minimal set of atoms needed to restore consistency (called minimal\nmapping rules). Implicitly, the use of maximal mapping rules states it is\npreferable to import as long as no inconsistencies arise; whereas the use of\nminimal mapping rules states that it is preferable not to import unless a\ninconsistency exists. The paper presents three different declarative semantics\nof a P2P system: (i) the Max Weak Model Semantics, in which mapping rules are\nused to import as much knowledge as possible} from a peer's neighborhood\nwithout violating local integrity constraints; (ii) the Min Weak Model\nSemantics, in which the P2P system can be locally inconsistent and the\ninformation provided by the neighbors is used to restore consistency, that is\nto only integrate the missing portion of a correct, but incomplete database;\n(iii) the Max-Min Weak Model Semantics that unifies the previous two different\nperspectives captured by the Max Weak Model Semantics and Min Weak Model\nSemantics. This last semantics allows to characterize each peer in the\nneighborhood as a resource used either to enrich (integrate) or to fix (repair)\nthe knowledge, so as to define a kind of integrate-repair strategy for each\npeer.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 19:39:06 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Caroprese", "Luciano", ""], ["Zumpano", "Ester", ""]]}, {"id": "1905.01647", "submitter": "Gijs Wijnholds", "authors": "Gijs Wijnholds and Mehrnoosh Sadrzadeh", "title": "A Typedriven Vector Semantics for Ellipsis with Anaphora using Lambek\n  Calculus with Limited Contraction", "comments": "Forthcoming in: Journal of Logic, Language and Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a vector space semantics for verb phrase ellipsis with anaphora\nusing type-driven compositional distributional semantics based on the Lambek\ncalculus with limited contraction (LCC) of J\\\"ager (2006). Distributional\nsemantics has a lot to say about the statistical collocation-based meanings of\ncontent words, but provides little guidance on how to treat function words.\nFormal semantics on the other hand, has powerful mechanisms for dealing with\nrelative pronouns, coordinators, and the like. Type-driven compositional\ndistributional semantics brings these two models together. We review previous\ncompositional distributional models of relative pronouns, coordination and a\nrestricted account of ellipsis in the DisCoCat framework of Coecke et al.\n(2010, 2013). We show how DisCoCat cannot deal with general forms of ellipsis,\nwhich rely on copying of information, and develop a novel way of connecting\ntypelogical grammar to distributional semantics by assigning vector\ninterpretable lambda terms to derivations of LCC in the style of Muskens &\nSadrzadeh (2016). What follows is an account of (verb phrase) ellipsis in which\nword meanings can be copied: the meaning of a sentence is now a program with\nnon-linear access to individual word embeddings. We present the theoretical\nsetting, work out examples, and demonstrate our results on a toy distributional\nmodel motivated by data.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 10:30:03 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wijnholds", "Gijs", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "1905.01688", "submitter": "Markus Hecher", "authors": "Markus Hecher", "title": "Answer Set Solving exploiting Treewidth and its Limits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized algorithms have been subject to extensive research of recent\nyears and allow to solve hard problems by exploiting a parameter of the\ncorresponding problem instances. There, one goal is to devise algorithms, where\nthe runtime is exponential exclusively in this parameter. One particular\nwell-studied structural parameter is treewidth. Typically, a parameterized\nalgorithm utilizing treewidth takes or computes a tree decomposition, which is\nan arrangement of a graph into a tree, and evaluates the problem in parts by\ndynamic programming on the tree decomposition. In our research, we want to\nexploit treewidth in the context of Answer Set Programming (ASP), a declarative\nmodeling and solving framework, which has been successfully applied in several\napplication domains and industries for years. So far, we presented algorithms\nfor ASP for the full ASP-Core-2 syntax, which is competitive especially when it\ncomes to counting answer sets. Since dynamic programming on tree decomposition\nlands itself well to counting, we designed a framework for projected model\ncounting, which applies to ASP, abstract argumentation and even to problems\nhigher in the polynomial hierarchy. Given standard assumptions in computational\ncomplexity, we established a novel methodology for showing lower bounds, and we\nshowed that most worst-case runtimes of our algorithms cannot be significantly\nimproved.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 14:18:10 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Hecher", "Markus", ""]]}, {"id": "1905.01735", "submitter": "Makarius Wenzel", "authors": "Makarius Wenzel", "title": "Interaction with Formal Mathematical Documents in Isabelle/PIDE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isabelle/PIDE has emerged over more than 10 years as the standard Prover IDE\nfor interactive theorem proving in Isabelle. The well-established Archive of\nFormal Proofs (AFP) testifies the success of such applications of formalized\nmathematics in Isabelle/HOL. More recently, the scope of PIDE has widened\ntowards languages that are not connected to logic and proof in Isabelle, but\ntaken from a broader repertoire of mathematics on the computer. The present\npaper provides a general overview of the PIDE project and its underlying\ndocument model, with built-in parallel evaluation and asynchronous interaction.\nThere is also some discussion of original aims and approaches, successes and\nfailures, later changes to the plan, and ideas for the future.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 19:34:13 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wenzel", "Makarius", ""]]}, {"id": "1905.02059", "submitter": "Jefferson de Barros Santos", "authors": "Jefferson de Barros Santos, Bruno Lopes Vieira, Edward Hermann\n  Haeusler", "title": "A Sequent Calculus Proof Search Procedure and Counter-model Generation\n  based on Natural Deduction Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a previously published ENTCS paper (Santos et al. (2016)), we introduced a\nsequent calculus called $\\mathbf{LMT^{\\rightarrow}}$ for Minimal Implicational\nPropositional Logic ($\\mathbf{LMT^{\\rightarrow}}$). This calculus provides a\nproof search procedure for $\\mathbf{LMT^{\\rightarrow}}$ that works in a\nbottom-up approach. We proved there that $\\mathbf{LMT^{\\rightarrow}}$ is sound\nand complete. We also suggested a strategy to guarantee termination of the\nproof search procedure. In this current paper, we refined this strategy and\npresented a new strategy for $\\mathbf{LMT^{\\rightarrow}}$ termination.\nConsidering this new strategy, we also provide a (new) completeness proof for\nthe system, which improves the previous version. Besides that, we present\nexplicit upper bounds on the proof search procedure, derived from this new\nstrategy. We also provide a full soundness proof of the system.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 14:27:50 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 13:42:42 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 15:09:31 GMT"}, {"version": "v4", "created": "Sat, 1 Feb 2020 21:43:54 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Santos", "Jefferson de Barros", ""], ["Vieira", "Bruno Lopes", ""], ["Haeusler", "Edward Hermann", ""]]}, {"id": "1905.02303", "submitter": "Alexander Feldman", "authors": "Alexander Feldman and Johan de Kleer and Ion Matei", "title": "Design Space Exploration as Quantified Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.ET cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel algorithms for design and design space exploration. The\ndesigns discovered by these algorithms are compositions of function types\nspecified in component libraries. Our algorithms reduce the design problem to\nquantified satisfiability and use advanced solvers to find solutions that\nrepresent useful systems.\n  The algorithms we present in this paper are sound and complete and are\nguaranteed to discover correct designs of optimal size, if they exist. We apply\nour method to the design of Boolean systems and discover new and more optimal\nclassical digital and quantum circuits for common arithmetic functions such as\naddition and multiplication.\n  The performance of our algorithms is evaluated through extensive\nexperimentation. We created a benchmark consisting of specifications of\nscalable synthetic digital circuits and real-world mirochips. We have generated\nmultiple circuits functionally equivalent to the ones in the benchmark. The\nquantified satisfiability method shows more than four orders of magnitude\nspeed-up, compared to a generate and test method that enumerates all\nnon-isomorphic circuit topologies.\n  Our approach generalizes circuit optimization. It uses arbitrary component\nlibraries and has applications to areas such as digital circuit design,\ndiagnostics, abductive reasoning, test vector generation, and combinatorial\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 00:39:16 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 02:01:25 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 22:55:06 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Feldman", "Alexander", ""], ["de Kleer", "Johan", ""], ["Matei", "Ion", ""]]}, {"id": "1905.02428", "submitter": "Tobias Kaminski", "authors": "Tobias Kaminski", "title": "Integrated Algorithms for HEX-Programs and Applications in Machine\n  Learning", "comments": "7 pages, submitted for the Doctoral Consortium at the 15th\n  International Conference on Logic Programming and Non-monotonic Reasoning\n  (LPNMR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes my doctoral research on evaluation algorithms for\nHEX-programs, which extend Answer Set Programming with means for interfacing\nexternal computations. The focus is on integrating different subprocesses of\nHEX-evaluation, such as solving and external calls as well as grounding, and on\napplications of HEX-programs in the area of Machine Learning.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 09:22:36 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Kaminski", "Tobias", ""]]}, {"id": "1905.02617", "submitter": "Brigitte Pientka", "authors": "Brigitte Pientka, David Thibodeau, Andreas Abel, Francisco Ferreira,\n  and Rebecca Zucchini", "title": "A Type Theory for Defining Logics and Proofs", "comments": "arXiv admin note: substantial text overlap with arXiv:1901.03378", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a Martin-L\\\"of-style dependent type theory, called Cocon, that\nallows us to mix the intensional function space that is used to represent\nhigher-order abstract syntax (HOAS) trees with the extensional function space\nthat describes (recursive) computations. We mediate between HOAS\nrepresentations and computations using contextual modal types. Our type theory\nalso supports an infinite hierarchy of universes and hence supports type-level\ncomputation thereby providing metaprogramming and (small-scale) reflection. Our\nmain contribution is the development of a Kripke-style model for Cocon that\nallows us to prove normalization. From the normalization proof, we derive\nsubject reduction and consistency. Our work lays the foundation to incorporate\nthe methodology of logical frameworks into systems such as Agda and bridges the\nlongstanding gap between these two worlds.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 14:43:01 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Pientka", "Brigitte", ""], ["Thibodeau", "David", ""], ["Abel", "Andreas", ""], ["Ferreira", "Francisco", ""], ["Zucchini", "Rebecca", ""]]}, {"id": "1905.02828", "submitter": "Akhil Dixit", "authors": "Akhil A. Dixit, Phokion G. Kolaitis", "title": "A SAT-based System for Consistent Query Answering", "comments": "25 pages including appendix, to appear in the 22nd International\n  Conference on Theory and Applications of Satisfiability Testing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An inconsistent database is a database that violates one or more integrity\nconstraints, such as functional dependencies. Consistent Query Answering is a\nrigorous and principled approach to the semantics of queries posed against\ninconsistent databases. The consistent answers to a query on an inconsistent\ndatabase is the intersection of the answers to the query on every repair, i.e.,\non every consistent database that differs from the given inconsistent one in a\nminimal way. Computing the consistent answers of a fixed conjunctive query on a\ngiven inconsistent database can be a coNP-hard problem, even though every fixed\nconjunctive query is efficiently computable on a given consistent database.\n  We designed, implemented, and evaluated CAvSAT, a SAT-based system for\nconsistent query answering. CAvSAT leverages a set of natural reductions from\nthe complement of consistent query answering to SAT and to Weighted MaxSAT. The\nsystem is capable of handling unions of conjunctive queries and arbitrary\ndenial constraints, which include functional dependencies as a special case. We\nreport results from experiments evaluating CAvSAT on both synthetic and\nreal-world databases. These results provide evidence that a SAT-based approach\ncan give rise to a comprehensive and scalable system for consistent query\nanswering.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 22:31:49 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Dixit", "Akhil A.", ""], ["Kolaitis", "Phokion G.", ""]]}, {"id": "1905.02838", "submitter": "Patrick Trentin", "authors": "Patrick Trentin and Roberto Sebastiani", "title": "Optimization Modulo the Theories of Signed Bit-Vectors and\n  Floating-Point Numbers", "comments": "27 pages, 7 figures, 2 tables; Shorter, official, publication at\n  CADE-27 (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization Modulo Theories (OMT) is an important extension of SMT which\nallows for finding models that optimize given objective functions, typically\nconsisting in linear-arithmetic or pseudo-Boolean terms. However, many SMT and\nOMT applications, in particular from SW and HW verification, require handling\nbit-precise representations of numbers, which in SMT are handled by means of\nthe theory of Bit-Vectors (BV) for the integers and that of Floating-Point\nNumbers (FP) for the reals respectively. Whereas an approach for OMT with\n(unsigned) BV has been proposed by Nadel & Ryvchin, unfortunately we are not\naware of any existing approach for OMT with FP. In this paper we fill this gap.\nWe present a novel OMT approach, based on the novel concept of attractor and\ndynamic attractor, which extends the work of Nadel & Ryvchin to signed BV and,\nmost importantly, to FP. We have implemented some OMT(BV) and OMT(FP)\nprocedures on top of OptiMathSAT and tested the latter ones on modified\nproblems from the SMT-LIB repository. The empirical results support the\nvalidity and feasibility of the novel approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 23:01:41 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Trentin", "Patrick", ""], ["Sebastiani", "Roberto", ""]]}, {"id": "1905.03008", "submitter": "Moritz Lichter", "authors": "Moritz Lichter, Ilia Ponomarenko, Pascal Schweitzer", "title": "Walk refinement, walk logic, and the iteration number of the\n  Weisfeiler-Leman algorithm", "comments": "To appear at LICS 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the 2-dimensional Weisfeiler-Leman algorithm stabilizes n-vertex\ngraphs after at most O(n log n) iterations. This implies that if such graphs\nare distinguishable in 3-variable first order logic with counting, then they\ncan also be distinguished in this logic by a formula of quantifier depth at\nmost O(n log n).\n  For this we exploit a new refinement based on counting walks and argue that\nits iteration number differs from the classic Weisfeiler-Leman refinement by at\nmost a logarithmic factor. We then prove matching linear upper and lower bounds\non the number of iterations of the walk refinement. This is achieved with an\nalgebraic approach by exploiting properties of semisimple matrix algebras. We\nalso define a walk logic and a bijective walk pebble game that precisely\ncorrespond to the new walk refinement.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 11:16:04 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 05:34:28 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Lichter", "Moritz", ""], ["Ponomarenko", "Ilia", ""], ["Schweitzer", "Pascal", ""]]}, {"id": "1905.03014", "submitter": "Andrew Swan", "authors": "Andrew Swan and Taichi Uemura", "title": "On Church's Thesis in Cubical Assemblies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Church's thesis, the axiom stating that all functions on the\nnaturals are computable, does not hold in the cubical assemblies model of\ncubical type theory.\n  We show that nevertheless Church's thesis is consistent with univalent type\ntheory by constructing a reflective subuniverse of cubical assemblies where it\nholds.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 11:47:34 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Swan", "Andrew", ""], ["Uemura", "Taichi", ""]]}, {"id": "1905.03190", "submitter": "Arno Pauly", "authors": "Takayuki Kihara and Arno Pauly", "title": "Convex choice, finite choice and sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Weihrauch degrees of closed choice for finite sets, closed\nchoice for convex sets and sorting infinite sequences over finite alphabets.\nOur main results are: One, that choice for finite sets of cardinality $i + 1$\nis reducible to choice for convex sets in dimension $j$, which in turn is\nreducible to sorting infinite sequences over an alphabet of size $k + 1$, iff\n$i \\leq j \\leq k$. Two, that convex choice in dimension two is not reducible to\nthe product of convex choice in dimension one with itself. Three, that\nsequential composition of one-dimensional convex choice is not reducible to\nconvex choice in any dimension. The latter solves an open question raised at a\nDagstuhl seminar on Weihrauch reducibility in 2015. Our proofs invoke Kleene's\nrecursion theorem, and we describe in some detail how Kleene's recursion\ntheorem gives rise to a technique for proving separations of Weihrauch degrees.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 03:27:00 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Kihara", "Takayuki", ""], ["Pauly", "Arno", ""]]}, {"id": "1905.03196", "submitter": "Patrick L\\\"uhne", "authors": "Patrick L\\\"uhne", "title": "Discovering and Proving Invariants in Answer Set Programming and\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming (ASP) and planning are two widely used paradigms for\nsolving logic programs with declarative programming. In both cases, the quality\nof the input programs has a major influence on the quality and performance of\nthe solving or planning process. Hence, programmers need to understand how to\nmake their programs efficient and still correct. In my PhD studies, I explore\nhow input programs can be improved and verified automatically as a means to\nsupport programmers. One of my research directions consists in discovering\ninvariants in planning programs without human support, which I implemented in a\nsystem called ginkgo. Studying dynamic systems in greater depth, I then\ndeveloped plasp 3 with members of my research group, which is a significant\nstep forward in effective planning in ASP. As a second research direction, I am\nconcerned with automating the verification of ASP programs against formal\nspecifications. For this joint work with Lifschitz's group at the University of\nTexas, I developed a verification system called anthem. In my future PhD\nstudies, I will extend my research concerning the discovery and verification of\nASP and planning problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 16:32:52 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["L\u00fchne", "Patrick", ""]]}, {"id": "1905.03334", "submitter": "Da Shen", "authors": "Da Shen, Yuliya Lierler", "title": "SMT-based Constraint Answer Set Solver EZSMT+", "comments": "This is an extended abstract submitted to LPNMR-DC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint answer set programming integrates answer set programming with\nconstraint processing. System EZSMT+ is a constraint answer set programming\ntool that utilizes satisfiability modulo theory solvers for search. Its\ntheoretical foundation lies on generalizations of Niemela's characterization of\nanswer sets of a logic program via so called level rankings.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:57:00 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 17:26:41 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Shen", "Da", ""], ["Lierler", "Yuliya", ""]]}, {"id": "1905.03477", "submitter": "Robert Goldblatt", "authors": "Robert Goldblatt and Ian Hodkinson", "title": "Strong completeness of modal logics over 0-dimensional metric spaces", "comments": null, "journal-ref": "The Review of Symbolic Logic 13 (2020) 611-632", "doi": "10.1017/S1755020319000534", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove strong completeness results for some modal logics with the universal\nmodality, with respect to their topological semantics over 0-dimensional\ndense-in-themselves metric spaces. We also use failure of compactness to show\nthat, for some languages and spaces, no standard modal deductive system is\nstrongly complete.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 07:41:19 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 22:20:47 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Goldblatt", "Robert", ""], ["Hodkinson", "Ian", ""]]}, {"id": "1905.03588", "submitter": "Antoine Amarilli", "authors": "Milad Aghajohari and Guy Avni and Thomas A. Henzinger", "title": "Determinacy in Discrete-Bidding Infinite-Duration Games", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (February\n  3, 2021) lmcs:7148", "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In two-player games on graphs, the players move a token through a graph to\nproduce an infinite path, which determines the winner of the game. Such games\nare central in formal methods since they model the interaction between a\nnon-terminating system and its environment. In bidding games the players bid\nfor the right to move the token: in each round, the players simultaneously\nsubmit bids, and the higher bidder moves the token and pays the other player.\nBidding games are known to have a clean and elegant mathematical structure that\nrelies on the ability of the players to submit arbitrarily small bids. Many\napplications, however, require a fixed granularity for the bids, which can\nrepresent, for example, the monetary value expressed in cents. We study, for\nthe first time, the combination of discrete-bidding and infinite-duration\ngames. Our most important result proves that these games form a large\ndetermined subclass of concurrent games, where determinacy is the strong\nproperty that there always exists exactly one player who can guarantee winning\nthe game. In particular, we show that, in contrast to non-discrete bidding\ngames, the mechanism with which tied bids are resolved plays an important role\nin discrete-bidding games. We study several natural tie-breaking mechanisms and\nshow that, while some do not admit determinacy, most natural mechanisms imply\ndeterminacy for every pair of initial budgets.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:08:10 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 08:17:05 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 13:56:15 GMT"}, {"version": "v4", "created": "Thu, 17 Sep 2020 07:23:25 GMT"}, {"version": "v5", "created": "Fri, 25 Dec 2020 08:32:17 GMT"}, {"version": "v6", "created": "Mon, 1 Feb 2021 19:37:17 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Aghajohari", "Milad", ""], ["Avni", "Guy", ""], ["Henzinger", "Thomas A.", ""]]}, {"id": "1905.03651", "submitter": "Marco Voigt", "authors": "Andreas Teucke and Marco Voigt and Christoph Weidenbach", "title": "On the Expressivity and Applicability of Model Representation Formalisms", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of first-order calculi employ an explicit model representation\nformalism for automated reasoning and for detecting satisfiability. Many of\nthese formalisms can represent infinite Herbrand models. The first-order\nfragment of monadic, shallow, linear, Horn (MSLH) clauses, is such a formalism\nused in the approximation refinement calculus. Our first result is a finite\nmodel property for MSLH clause sets. Therefore, MSLH clause sets cannot\nrepresent models of clause sets with inherently infinite models. Through a\ntranslation to tree automata, we further show that this limitation also applies\nto the linear fragments of implicit generalizations, which is the formalism\nused in the model-evolution calculus, to atoms with disequality constraints,\nthe formalisms used in the non-redundant clause learning calculus (NRCL), and\nto atoms with membership constraints, a formalism used for example in decision\nprocedures for algebraic data types. Although these formalisms cannot represent\nmodels of clause sets with inherently infinite models, through an additional\napproximation step they can. This is our second main result. For clause sets\nincluding the definition of an equivalence relation with the help of an\nadditional, novel approximation, called reflexive relation splitting, the\napproximation refinement calculus can automatically show satisfiability through\nthe MSLH clause set formalism.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:23:16 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Teucke", "Andreas", ""], ["Voigt", "Marco", ""], ["Weidenbach", "Christoph", ""]]}, {"id": "1905.03835", "submitter": "Guy Avni", "authors": "Guy Avni and Thomas A. Henzinger and {\\DJ}or{\\dj}e \\v{Z}ikeli\\'c", "title": "Bidding Mechanisms in Graph Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two-player games on graphs, the players move a token through a graph to\nproduce an infinite path, which determines the winner or payoff of the game. We\nstudy {\\em bidding games} in which the players bid for the right to move the\ntoken. Several bidding rules were studied previously. In {\\em Richman} bidding,\nin each round, the players simultaneously submit bids, and the higher bidder\nmoves the token and pays the other player. {\\em Poorman} bidding is similar\nexcept that the winner of the bidding pays the \"bank\" rather than the other\nplayer. {\\em Taxman} bidding spans the spectrum between Richman and poorman\nbidding. They are parameterized by a constant $\\tau \\in [0,1]$: portion $\\tau$\nof the winning bid is paid to the other player, and portion $1-\\tau$ to the\nbank. We present, for the first time, results on {\\em infinite-duration} taxman\ngames. Our most interesting results concern quantitative taxman games, namely\n{\\em mean-payoff} games, where poorman and Richman bidding differ. A central\nquantity in these games is the {\\em ratio} between the two players' initial\nbudgets. While in poorman mean-payoff games, the optimal payoff a player can\nguarantee depends on the initial ratio, in Richman bidding, the payoff depends\nonly on the structure of the game. In both games the optimal payoffs can be\nfound using (different) probabilistic connections with {\\em random-turn based}\ngames in which in each turn, a coin is tossed to determine which player moves.\nThe payoff with Richman bidding equals the payoff of a random-turn based game\nwith an un-biased coin, and with poorman bidding, the coin is biased according\nto the initial budget ratio. We give a complete classification of mean-payoff\ntaxman games using a probabilistic connection. Our results show that Richman\nbidding is the exception; namely, for every $\\tau <1$, the value of the game\ndepends on the initial ratio.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 19:58:42 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Avni", "Guy", ""], ["Henzinger", "Thomas A.", ""], ["\u017dikeli\u0107", "\u0110or\u0111e", ""]]}, {"id": "1905.03855", "submitter": "Laura Giordano", "authors": "Laura Giordano and Valentina Gliozzi", "title": "A reconstruction of the multipreference closure", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes a preferential approach for dealing with exceptions in\nKLM preferential logics, based on the rational closure. It is well known that\nthe rational closure does not allow an independent handling of the inheritance\nof different defeasible properties of concepts. Several solutions have been\nproposed to face this problem and the lexicographic closure is the most notable\none. In this work, we consider an alternative closure construction, called the\nMulti Preference closure (MP-closure), that has been first considered for\nreasoning with exceptions in DLs. Here, we reconstruct the notion of MP-closure\nin the propositional case and we show that it is a natural variant of Lehmann's\nlexicographic closure. Abandoning Maximal Entropy (an alternative route already\nconsidered but not explored by Lehmann) leads to a construction which exploits\na different lexicographic ordering w.r.t. the lexicographic closure, and\ndetermines a preferential consequence relation rather than a rational\nconsequence relation. We show that, building on the MP-closure semantics,\nrationality can be recovered, at least from the semantic point of view,\nresulting in a rational consequence relation which is stronger than the\nrational closure, but incomparable with the lexicographic closure. We also show\nthat the MP-closure is stronger than the Relevant Closure.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 08:44:24 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 17:47:15 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Giordano", "Laura", ""], ["Gliozzi", "Valentina", ""]]}, {"id": "1905.04058", "submitter": "Sam Sanders", "authors": "Sam Sanders", "title": "Nets and Reverse Mathematics, a pilot study", "comments": "34 pages, 1 figure, to appear in 'Computability'", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nets are generalisations of sequences involving possibly uncountable index\nsets; this notion was introduced about a century ago by Moore and Smith. They\nalso established the generalisation to nets of various basic theorems of\nanalysis due to Bolzano-Weierstrass, Dini, Arzela, and others. More recently,\nnets are central to the development of domain theory, providing intuitive\ndefinitions of the associated Scott and Lawson topologies, among others. This\npaper deals with the Reverse Mathematics study of basic theorems about nets. We\nrestrict ourselves to nets indexed by subsets of Baire space, and therefore\nthird-order arithmetic, as such nets suffice to obtain our main results. Over\nKohlenbach's base theory of higher-order Reverse Mathematics, the\nBolzano-Weierstrass theorem for nets implies the Heine-Borel theorem for\nuncountable covers. We establish similar results for other basic theorems about\nnets and even some equivalences, e.g. for Dini's theorem for nets. Finally, we\nshow that replacing nets by sequences is hard, but that replacing sequences by\nnets can obviate the need for the Axiom of Choice, a foundational concern in\ndomain theory. In an appendix, we study the power of more general index sets,\nestablishing that the 'size' of a net is directly proportional to the power of\nthe associated convergence theorem.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 10:37:01 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 13:01:42 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sanders", "Sam", ""]]}, {"id": "1905.04146", "submitter": "Ionu\\c{t} \\c{T}u\\c{t}u", "authors": "Daniel G\\u{a}in\\u{a}, Ionu\\c{t} \\c{T}u\\c{t}u", "title": "Horn Clauses in Hybrid-Dynamic First-Order Logic", "comments": "submitted to the 44th International Symposium on Mathematical\n  Foundations of Computer Science, MFCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid-dynamic first-order logic as a formal foundation for\nspecifying and reasoning about reconfigurable systems. As the name suggests,\nthe formalism we develop extends (many-sorted) first-order logic with features\nthat are common to hybrid logics and to dynamic logics. This provides certain\nkey advantages for dealing with reconfigurable systems, such as: (a) a\nsignature of nominals, including operation and relation symbols, that allows\nreferences to specific possible worlds / system configurations -- as in the\ncase of hybrid logics; (b) distinguished signatures of rigid and flexible\nsymbols, where the rigid symbols are interpreted uniformly across possible\nworlds; this supports a rigid form of quantification, which ensures that\nvariables have the same interpretation regardless of the possible world where\nthey are evaluated; (c) hybrid terms, which increase the expressive power of\nthe logic in the context of rigid symbols; and (d) modal operators over\ndynamic-logic actions, which are defined as regular expressions over binary\nnominal relations. We then study Horn clauses in this hybrid-dynamic logic, and\ndevelop a series of results that lead to an initial-semantics theorem for\narbitrary sets of clauses. This shows that a significant fragment of\nhybrid-dynamic first-order logic has good computational properties, and can\nserve as a basis for defining executable languages for reconfigurable systems.\nLastly, we set out the foundations of logic programming in this fragment by\nproving a hybrid-dynamic variant of Herbrand's theorem, which reduces the\nsemantic entailment of a logic-programming query by a program to the search of\na suitable answer substitution.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:59:50 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["G\u0103in\u0103", "Daniel", ""], ["\u0162u\u0163u", "Ionu\u0163", ""]]}, {"id": "1905.04332", "submitter": "David Mestel", "authors": "David Mestel", "title": "Quantifying information flow in interactive systems", "comments": "32nd IEEE Symposium on Computer Security Foundations (CSF 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of quantifying information flow in interactive\nsystems, modelled as finite-state transducers in the style of Goguen and\nMeseguer. Our main result is that if the system is deterministic then the\ninformation flow is either logarithmic or linear, and there is a\npolynomial-time algorithm to distinguish the two cases and compute the rate of\nlogarithmic flow. To achieve this we first extend the theory of information\nleakage through channels to the case of interactive systems, and establish a\nnumber of results which greatly simplify computation. We then show that for\ndeterministic systems the information flow corresponds to the growth rate of\nantichains inside a certain regular language, a property called the width of\nthe language. In a companion work we have shown that there is a dichotomy\nbetween polynomial and exponential antichain growth, and a polynomial time\nalgorithm to distinguish the two cases and to compute the order of polynomial\ngrowth. We observe that these two cases correspond to logarithmic and linear\ninformation flow respectively. Finally, we formulate several attractive open\nproblems, covering the cases of probabilistic systems, systems with more than\ntwo users and nondeterministic systems where the nondeterminism is assumed to\nbe innocent rather than demonic.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 18:24:56 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Mestel", "David", ""]]}, {"id": "1905.04689", "submitter": "Mani A", "authors": "A. Mani", "title": "Rough Contact in General Rough Mereology", "comments": "11 Pages. Women in Logic Workshop, Vancouver'2019: 34th Annual\n  ACM/IEEE Symposium on Logic in Computer Science (LICS) 2019. This preprint\n  uses the same updated framework of arXiv:1811.06560", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theories of rough mereology have originated from diverse semantic\nconsiderations from contexts relating to study of databases, to human\nreasoning. These ideas of origin, especially in the latter context, are\nintensely complex. In this research, concepts of rough contact relations are\nintroduced and rough mereologies are situated in relation to general spatial\nmereology by the present author. These considerations are restricted to her\nrough mereologies that seek to avoid contamination.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 10:42:20 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1905.04725", "submitter": "Sopo Pkhakadze", "authors": "Sopo Pkhakadze", "title": "Sequent-Type Proof Systems for Three-Valued Default Logic", "comments": "This is an extended abstract summarising the research questions and\n  goals of my master's thesis in computational logic, written at the Technische\n  Universit\\\"at Wien. The abstract is accepted for publication and presentation\n  at the Doctoral Consortium of the 15th International Conference on Logic\n  Programming and Non-Monotonic Reasoning (LPNMR 2019) in Philadelphia, PA,\n  USA, June 4-7, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequent-type proof systems constitute an important and widely-used class of\ncalculi well-suited for analysing proof search. In my master's thesis, I\nintroduce sequent-type calculi for a variant of default logic employing\n\\Lukasiewicz's three-valued logic as the underlying base logic. This version of\ndefault logic has been introduced by Radzikowska addressing some\nrepresentational shortcomings of standard default logic. More specifically, the\ncalculi discussed in my thesis axiomatise brave and skeptical reasoning for\nthis version of default logic, respectively following the sequent method first\nintroduced in the context of nonmonotonic reasoning by Bonatti and Olivetti,\nwhich employ a complementary calculus for axiomatising invalid formulas, taking\ncare of expressing the consistency condition of defaults.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 13:59:46 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Pkhakadze", "Sopo", ""]]}, {"id": "1905.04755", "submitter": "Ralf Wimmer", "authors": "Aile Ge-Ernst and Christoph Scholl and Juraj S\\'i\\v{c} and Ralf Wimmer", "title": "Solving Dependency Quantified Boolean Formulas Using Quantifier\n  Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency quantified Boolean formulas (DQBFs) are a powerful formalism,\nwhich subsumes quantified Boolean formulas (QBFs) and allows an explicit\nspecification of dependencies of existential variables on universal variables.\nDriven by the needs of various applications which can be encoded by DQBFs in a\nnatural, compact, and elegant way, research on DQBF solving has emerged in the\npast few years. However, research focused on closed DQBFs in prenex form (where\nall quantifiers are placed in front of a propositional formula), while\nnon-prenex DQBFs have almost not been studied in the literature. In this paper,\nwe provide a formal definition for syntax and semantics of non-closed\nnon-prenex DQBFs and prove useful properties enabling quantifier localization.\nMoreover, we make use of our theory by integrating quantifier localization into\na state-of-the-art DQBF solver. Experiments with prenex DQBF benchmarks,\nincluding all instances from the QBFEVAL'18-'20 competitions, clearly show that\nquantifier localization pays off in this context.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 17:55:23 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 16:25:19 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Ge-Ernst", "Aile", ""], ["Scholl", "Christoph", ""], ["S\u00ed\u010d", "Juraj", ""], ["Wimmer", "Ralf", ""]]}, {"id": "1905.05036", "submitter": "Ioana Leustean", "authors": "Ioana Leustean, Natalia Moanga and Traian Florin Serbanuta", "title": "Operational semantics and program verification using many-sorted hybrid\n  modal logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework to allow: (a) specifying the operational\nsemantics of a programming language; and (b) stating and proving properties\nabout program correctness. Our framework is based on a many-sorted system of\nhybrid modal logic, for which we prove completeness results. We believe that\nour approach to program verification improves over the existing approaches\nwithin modal logic as (1) it is based on operational semantics which allows for\na more natural description of the execution than Hoare's style weakest\nprecondition used by dynamic logic; (2) being multi-sorted, it allows for a\nclearer encoding of semantics, with a smaller representational distance to its\nintended meaning.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:50:21 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Leustean", "Ioana", ""], ["Moanga", "Natalia", ""], ["Serbanuta", "Traian Florin", ""]]}, {"id": "1905.05248", "submitter": "Philipp Wanko", "authors": "Philipp Wanko", "title": "Design Space Exploration via Answer Set Programming Modulo Theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of embedded systems, that are ubiquitously used in mobile devices\nand cars, is becoming continuously more complex such that efficient\nsystem-level design methods are becoming crucial. My research aims at\ndeveloping systems that help the designer express the complex design problem in\na declarative way and explore the design space to obtain divers sets of\nsolutions with desirable properties. To that end, we employ knowledge\nrepresentation and reasoning capabilities of ASP in combination with background\ntheories. As a result, for the first time, we proposed a sophisticated\nmethodology that allows for the direct integration of multi-objective\noptimization of non-linear objectives into ASP. This includes unique results of\ndiverse sub-problems covered in several publications which I will present in\nthis work.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 08:44:47 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Wanko", "Philipp", ""]]}, {"id": "1905.05276", "submitter": "Felipe S. Abrah\\~ao", "authors": "Felipe S. Abrah\\~ao, Klaus Wehmuth, Artur Ziviani", "title": "Transtemporal edges and crosslayer edges in incompressible high-order\n  networks", "comments": "Accepted extended abstract in\n  http://csbc2019.sbc.org.br/eventos/4etc/ The results of this paper are also\n  contained in arXiv:1812.01170", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DM cs.LO cs.SI math.GN math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents some outcomes of a theoretical investigation of\nincompressible high-order networks defined by a generalized graph\nrepresentation. We study some of their network topological properties and how\nthese may be related to real-world complex networks. We show that these\nnetworks have very short diameter, high k-connectivity, degrees of the order of\nhalf of the network size within a strong-asymptotically dominated standard\ndeviation, and rigidity with respect to automorphisms. In addition, we\ndemonstrate that incompressible dynamic (or dynamic multilayered) networks have\ntranstemporal (or crosslayer) edges and, thus, a snapshot-like representation\nof dynamic networks is inaccurate for capturing the presence of such edges that\ncompose underlying structures of some real-world networks.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 20:31:02 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Abrah\u00e3o", "Felipe S.", ""], ["Wehmuth", "Klaus", ""], ["Ziviani", "Artur", ""]]}, {"id": "1905.05500", "submitter": "Simon Foster", "authors": "Simon Foster, James Baxter, Ana Cavalcanti, Jim Woodcock, and Frank\n  Zeyda", "title": "Unifying Semantic Foundations for Automated Verification Tools in\n  Isabelle/UTP", "comments": "40 pages, Accepted for Science of Computer Programming, June 2020", "journal-ref": null, "doi": "10.1016/j.scico.2020.102510", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing complexity and diversity of models used in the engineering of\ndependable systems implies that a variety of formal methods, across differing\nabstractions, paradigms, and presentations, must be integrated. Such an\nintegration relies on unified semantic foundations for the various notations,\nand co-ordination of a variety of automated verification tools. The\ncontribution of this paper is Isabelle/UTP, an implementation of Hoare and He's\nUnifying Theories of Programming, a framework for unification of formal\nsemantics. Isabelle/UTP permits the mechanisation of computational theories for\ndiverse paradigms, and their use in constructing formalised semantic models.\nThese can be further applied in the development of verification tools,\nharnessing Isabelle's proof automation facilities. Several layers of\nmathematical foundations are developed, including lenses to model variables and\nstate spaces as algebraic objects, alphabetised predicates and relations to\nmodel programs, including algebraic and axiomatic semantics, proof tools for\nHoare logic and refinement calculus, and UTP theories to encode computational\nparadigms.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:16:36 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 14:22:15 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 11:26:22 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Foster", "Simon", ""], ["Baxter", "James", ""], ["Cavalcanti", "Ana", ""], ["Woodcock", "Jim", ""], ["Zeyda", "Frank", ""]]}, {"id": "1905.05607", "submitter": "George Rahonis", "authors": "Maria Pittou and George Rahonis", "title": "Modelling architectures of parametric weighted component-based systems", "comments": "34 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:1904.02222", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of complex software systems usually lies in multiple coordinating\ncomponents with an unknown number of instances. For such systems a main\nchallenge is modelling efficiently their architecture that determines the\ntopology and the interaction principles among the components. To achieve\nwell-founded design there is need to address the quantitative aspects of\nsoftware architectures. In this paper we study the modelling problem of\nsoftware architectures applied on parametric weighted component-based systems\nwhere the parameter is the number of instances of each component. For this, we\nintroduce a weighted first-order extended interaction logic over a commutative\nsemiring in order to serve as a modelling language for parametric quantitative\narchitectures. We prove that the equivalence problem of formulas of that logic\nis decidable in the class (of subsemirings) of skew fields. Moreover, we show\nthat our weighted logic can efficiently describe well-known parametric\narchitectures with quantitative characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 13:48:07 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 23:34:47 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 20:39:43 GMT"}, {"version": "v4", "created": "Sun, 26 Apr 2020 16:55:48 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Pittou", "Maria", ""], ["Rahonis", "George", ""]]}, {"id": "1905.05636", "submitter": "EPTCS", "authors": "John C. Baez (University of California, Riverside), Christian Williams\n  (University of California, Riverside)", "title": "Enriched Lawvere Theories for Operational Semantics", "comments": "In Proceedings ACT 2019, arXiv:2009.06334", "journal-ref": "EPTCS 323, 2020, pp. 106-135", "doi": "10.4204/EPTCS.323.8", "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enriched Lawvere theories are a generalization of Lawvere theories that allow\nus to describe the operational semantics of formal systems. For example, a\ngraph enriched Lawvere theory describes structures that have a graph of\noperations of each arity, where the vertices are operations and the edges are\nrewrites between operations. Enriched theories can be used to equip systems\nwith operational semantics, and maps between enriching categories can serve to\ntranslate between different forms of operational and denotational semantics.\nThe Grothendieck construction lets us study all models of all enriched theories\nin all contexts in a single category. We illustrate these ideas with the\nSKI-combinator calculus, a variable-free version of the lambda calculus.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:25:40 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 10:10:28 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 02:14:53 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Baez", "John C.", "", "University of California, Riverside"], ["Williams", "Christian", "", "University of California, Riverside"]]}, {"id": "1905.05665", "submitter": "Marcelo Finger", "authors": "Marcelo Finger", "title": "Quantitative Logic Reasoning", "comments": "Appeared as a chapter in Trends in Logic series", "journal-ref": "In W. Carnielli and J. Malinowski, editors, Contradictions, from\n  Consistency to Inconsistency, Trends in Logic, pages 241-272. Springer\n  International Publishing, 2018", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show several similarities among logic systems that deal\nsimultaneously with deductive and quantitative inference. We claim it is\nappropriate to call the tasks those systems perform as Quantitative Logic\nReasoning. Analogous properties hold throughout that class, for whose members\nthere exists a set of linear algebraic techniques applicable in the study of\nsatisfiability decision problems. In this presentation, we consider as\nQuantitative Logic Reasoning the tasks performed by propositional Probabilistic\nLogic; first-order logic with counting quantifiers over a fragment containing\nunary and limited binary predicates; and propositional Lukasiewicz\nInfinitely-valued Probabilistic Logic\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 15:19:30 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Finger", "Marcelo", ""]]}, {"id": "1905.05801", "submitter": "Joseph Vandehey", "authors": "Olivier Carton and Joseph Vandehey", "title": "Preservation of normality by non-oblivious group selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give two different proofs of the fact that non-oblivious selection via\nregular group sets preserves normality. Non-oblivious here means that whether\nor not a symbol is selected can depend on the symbol itself. One proof relies\non the incompressibility of normal sequences, the other on the use of augmented\ndynamical systems.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 01:19:52 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Carton", "Olivier", ""], ["Vandehey", "Joseph", ""]]}, {"id": "1905.05970", "submitter": "Bohua Zhan", "authors": "Bohua Zhan", "title": "HolPy: Interactive Theorem Proving in Python", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HolPy is an interactive theorem proving system implemented in Python. It uses\nhigher-order logic as the logical foundation. Its main features include a\npervasive use of macros in producing, checking, and storing proofs, a\nJSON-based format for theories, and an API for implementing proof automation\nand other extensions in Python. A point-and-click-based user interface is\nimplemented for general-purpose theorem proving. We describe the main design\ndecisions of HolPy, current applications, and plans for the future.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:39:00 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 11:49:24 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zhan", "Bohua", ""]]}, {"id": "1905.06143", "submitter": "Reuben Rowe", "authors": "Simon Docherty and Reuben N. S. Rowe", "title": "A Non-wellfounded, Labelled Proof System for Propositional Dynamic Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define a infinitary labelled sequent calculus for PDL, G3PDL^{\\infty}. A\nfinitarily representable cyclic system, G3PDL^{\\omega}, is then given. We show\nthat both are sound and complete with respect to standard models of PDL and,\nfurther, that G3PDL^{\\infty} is cut-free complete. We additionally investigate\nproof-search strategies in the cyclic system for the fragment of PDL without\ntests.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:50:15 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 22:46:40 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Docherty", "Simon", ""], ["Rowe", "Reuben N. S.", ""]]}, {"id": "1905.06184", "submitter": "Simon Marynissen", "authors": "Simon Marynissen", "title": "Extensions to Justification Theory", "comments": "7 pages, extended abstract for LPNMR 2019 doctoral consortium (15th\n  International Conference on Logic Programming and Non-monotonic Reasoning,\n  Saint Joseph's University, Philadelphia, PA (USA))", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Justification theory is a unifying framework for semantics of non-monotonic\nlogics. It is built on the notion of a justification, which intuitively is a\ngraph that explains the truth value of certain facts in a structure. Knowledge\nrepresentation languages covered by justification theory include logic\nprograms, argumentation frameworks, inductive definitions, and nested inductive\nand coinductive definitions. In addition, justifications are also used for\nimplementation purposes. They are used to compute unfounded sets in modern ASP\nsolvers, can be used to check for relevance of atoms in complete search\nalgorithms, and recent lazy grounding algorithms are built on top of them. In\nthis extended abstract, we lay out possible extensions to justification theory.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 12:50:19 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Marynissen", "Simon", ""]]}, {"id": "1905.06192", "submitter": "Simon Foster", "authors": "Yakoub Nemouchi, Simon Foster, Mario Gleirscher, and Tim Kelly", "title": "Mechanised Assurance Cases with Integrated Formal Methods in Isabelle", "comments": "17 pages, submitted to FM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assurance cases are often required as a means to certify a critical system.\nUse of formal methods in assurance can improve automation, and overcome\nproblems with ambiguity, faulty reasoning, and inadequate evidentiary support.\nHowever, assurance cases can rarely be fully formalised, as the use of formal\nmethods is contingent on models validated by informal processes. Consequently,\nwe need assurance techniques that support both formal and informal artifacts,\nwith explicated inferential links and assumptions that can be checked by\nevaluation. Our contribution is a mechanical framework for developing assurance\ncases with integrated formal methods based in the Isabelle system. We\ndemonstrate an embedding of the Structured Assurance Case Meta-model (SACM)\nusing Isabelle/DOF, and show how this can be linked to formal analysis\ntechniques originating from our verification framework, Isabelle/UTP. We\nvalidate our approach by mechanising a fragment of the Tokeneer security case,\nwith evidence supplied by formal verification.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:55:08 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Nemouchi", "Yakoub", ""], ["Foster", "Simon", ""], ["Gleirscher", "Mario", ""], ["Kelly", "Tim", ""]]}, {"id": "1905.06233", "submitter": "Horatiu Cirstea", "authors": "Horatiu Cirstea and Pierre-Etienne Moreau", "title": "Generic Encodings of Constructor Rewriting Systems", "comments": "Added appendix with proofs and extended examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rewriting is a formalism widely used in computer science and mathematical\nlogic. The classical formalism has been extended, in the context of functional\nlanguages, with an order over the rules and, in the context of rewrite based\nlanguages, with the negation over patterns. We propose in this paper a concise\nand clear algorithm computing the difference over patterns which can be used to\ndefine generic encodings of constructor term rewriting systems with negation\nand order into classical term rewriting systems. As a direct consequence,\nestablished methods used for term rewriting systems can be applied to analyze\nproperties of the extended systems. The approach can also be seen as a generic\ncompiler which targets any language providing basic pattern matching\nprimitives. The formalism provides also a new method for deciding if a set of\npatterns subsumes a given pattern and thus, for checking the presence of\nuseless patterns or the completeness of a set of patterns.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 14:06:09 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 11:07:38 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Cirstea", "Horatiu", ""], ["Moreau", "Pierre-Etienne", ""]]}, {"id": "1905.06544", "submitter": "EPTCS", "authors": "Oleg Kiselyov (Tohoku University, Japan)", "title": "Effects Without Monads: Non-determinism -- Back to the Meta Language", "comments": "In Proceedings ML 2017, arXiv:1905.05909", "journal-ref": "EPTCS 294, 2019, pp. 15-40", "doi": "10.4204/EPTCS.294.2", "report-no": null, "categories": "cs.PL cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reflect on programming with complicated effects, recalling an\nundeservingly forgotten alternative to monadic programming and checking to see\nhow well it can actually work in modern functional languages. We adopt and\nargue the position of factoring an effectful program into a first-order\neffectful DSL with a rich, higher-order 'macro' system. Not all programs can be\nthus factored. Although the approach is not general-purpose, it does admit\ninteresting programs. The effectful DSL is likewise rather problem-specific and\nlacks general-purpose monadic composition, or even functions. On the upside, it\nexpresses the problem elegantly, is simple to implement and reason about, and\nlends itself to non-standard interpretations such as code generation\n(compilation) and abstract interpretation. A specialized DSL is liable to be\nfrequently extended; the experience with the tagless-final style of DSL\nembedding shown that the DSL evolution can be made painless, with the maximum\ncode reuse. We illustrate the argument on a simple but representative example\nof a rather complicated effect -- non-determinism, including committed choice.\nUnexpectedly, it turns out we can write interesting non-deterministic programs\nin an ML-like language just as naturally and elegantly as in the\nfunctional-logic language Curry -- and not only run them but also statically\nanalyze, optimize and compile. The richness of the Meta Language does, in\nreality, compensate for the simplicity of the effectful DSL. The key idea goes\nback to the origins of ML as the Meta Language for the Edinburgh LCF theorem\nprover. Instead of using ML to build theorems, we now build (DSL) programs.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 06:11:37 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Kiselyov", "Oleg", "", "Tohoku University, Japan"]]}, {"id": "1905.06627", "submitter": "Maciej Olejnik", "authors": "Xiaowei Huang, Marta Kwiatkowska, Maciej Olejnik", "title": "Reasoning about Cognitive Trust in Stochastic Multiagent Systems", "comments": "to be published in TOCL ACM journal", "journal-ref": null, "doi": "10.1145/3329123", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of stochastic multiagent systems modelled as\nstochastic multiplayer games and formulate an automated verification framework\nfor quantifying and reasoning about agents' trust. To capture human trust, we\nwork with a cognitive notion of trust defined as a subjective evaluation that\nagent A makes about agent B's ability to complete a task, which in turn may\nlead to a decision by A to rely on B. We propose a probabilistic rational\ntemporal logic PRTL*, which extends the probabilistic computation tree logic\nPCTL* with reasoning about mental attitudes (beliefs, goals and intentions),\nand includes novel operators that can express concepts of social trust such as\ncompetence, disposition and dependence. The logic can express, for example,\nthat `agent A will eventually trust agent B with probability at least p that B\nwill behave in a way that ensures the successful completion of a given task'.\nWe study the complexity of the automated verification problem and, while the\ngeneral problem is undecidable, we identify restrictions on the logic and the\nsystem that result in decidable, or even tractable, subproblems.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 09:54:09 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Huang", "Xiaowei", ""], ["Kwiatkowska", "Marta", ""], ["Olejnik", "Maciej", ""]]}, {"id": "1905.06668", "submitter": "Achim Blumensath", "authors": "Achim Blumensath and Felix Wolf", "title": "Bisimulation Invariant Monadic-Second Order Logic in the Finite", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider bisimulation-invariant monadic second-order logic over various\nclasses of finite transition systems. We present several combinatorial\ncharacterisations of when the expressive power of this fragment coincides with\nthat of the modal mu-calculus. Using these characterisations we prove for some\nsimple classes of transition systems that this is indeed the case. In\nparticular, we show that, over the class of all finite transition systems with\nCantor-Bendixson rank at most k, bisimulation-invariant MSO coincides with\nL_mu.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 11:37:41 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Blumensath", "Achim", ""], ["Wolf", "Felix", ""]]}, {"id": "1905.07030", "submitter": "Daoming Lyu", "authors": "Daoming Lyu", "title": "Knowledge-Based Sequential Decision-Making Under Uncertainty", "comments": "5 pages, submitted for the Doctoral Consortium at the 15th\n  International Conference on Logic Programming and Non-monotonic Reasoning\n  (LPNMR 2019). arXiv admin note: text overlap with arXiv:1811.00090", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) algorithms have achieved great success on\nsequential decision-making problems, yet is criticized for the lack of\ndata-efficiency and explainability. Especially, explainability of subtasks is\ncritical in hierarchical decision-making since it enhances the transparency of\nblack-box-style DRL methods and helps the RL practitioners to understand the\nhigh-level behavior of the system better. To improve the data-efficiency and\nexplainability of DRL, declarative knowledge is introduced in this work and a\nnovel algorithm is proposed by integrating DRL with symbolic planning.\nExperimental analysis on publicly available benchmarks validates the\nexplainability of the subtasks and shows that our method can outperform the\nstate-of-the-art approach in terms of data-efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:56:03 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 02:01:40 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lyu", "Daoming", ""]]}, {"id": "1905.07139", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Yu-Fang Chen, Vojt\\v{e}ch Havlena, Ond\\v{r}ej Leng\\'al", "title": "Simulations in Rank-Based B\\\"uchi Automata Complementation (Technical\n  Report)", "comments": "An extended version of a paper to appear in Proc. of APLAS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complementation of B\\\"uchi automata is an essential technique used in some\napproaches for termination analysis of programs. The long search for an optimal\ncomplementation construction climaxed with the work of Schewe, who proposed a\nworst-case optimal rank-based procedure that generates complements of a size\nmatching the theoretical lower bound of $(0.76n)^n$, modulo a polynomial factor\nof $O(n^2)$. Although worst-case optimal, the procedure in many cases produces\nautomata that are unnecessarily large. In this paper, we propose several ways\nof how to use the direct and delayed simulation relations to reduce the size of\nthe automaton obtained in the rank-based complementation procedure. Our\ntechniques are based on either (i) ignoring macrostates that cannot be used for\naccepting a word in the complement or (ii) saturating macrostates with\nsimulation-smaller states, in order to decrease their total number. We\nexperimentally showed that our techniques can indeed considerably decrease the\nsize of the output of the complementation.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:26:49 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 15:10:27 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Chen", "Yu-Fang", ""], ["Havlena", "Vojt\u011bch", ""], ["Leng\u00e1l", "Ond\u0159ej", ""]]}, {"id": "1905.07244", "submitter": "Makarius Wenzel", "authors": "Makarius Wenzel", "title": "Isabelle technology for the Archive of Formal Proofs with application to\n  MMT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an overview of the Isabelle technology behind the Archive of Formal\nProofs (AFP). Interactive development and quasi-interactive build jobs impose\nsignificant demands of scalability on the logic (usually Isabelle/HOL), on\nIsabelle/ML for mathematical tool implementation, and on Isabelle/Scala for\nphysical system integration --- all integrated in Isabelle/PIDE (the Prover\nIDE). Continuous growth of AFP has demanded continuous improvements of Isabelle\nperformance. This is a report on the situation in Isabelle2019 (June 2019),\nwith notable add-ons like prover session exports and headless PIDE for\nautomated updates based on semantic information. An example application is\nIsabelle/MMT, which is able to turn all of Isabelle + AFP into OMDoc and RDF\ntriples, but it is straight-forward to reuse the Isabelle technology for other\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 13:06:00 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 17:21:09 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Wenzel", "Makarius", ""]]}, {"id": "1905.07408", "submitter": "EPTCS", "authors": "Giovanni de Felice (University of Oxford), Konstantinos Meichanetzidis\n  (University of Oxford, Cambridge Quantum Computing Ltd.), Alexis Toumi\n  (University of Oxford)", "title": "Functorial Question Answering", "comments": "In Proceedings ACT 2019, arXiv:2009.06334", "journal-ref": "EPTCS 323, 2020, pp. 84-94", "doi": "10.4204/EPTCS.323.6", "report-no": null, "categories": "cs.CL cs.DB cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional compositional (DisCo) models are functors that compute the\nmeaning of a sentence from the meaning of its words. We show that DisCo models\nin the category of sets and relations correspond precisely to relational\ndatabases. As a consequence, we get complexity-theoretic reductions from\nsemantics and entailment of a fragment of natural language to evaluation and\ncontainment of conjunctive queries, respectively. Finally, we define question\nanswering as an NP-complete problem.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 15:23:39 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 14:35:12 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 02:14:18 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["de Felice", "Giovanni", "", "University of Oxford"], ["Meichanetzidis", "Konstantinos", "", "University of Oxford, Cambridge Quantum Computing Ltd."], ["Toumi", "Alexis", "", "University of Oxford"]]}, {"id": "1905.07550", "submitter": "Man Luo", "authors": "Man Luo", "title": "Strong equivalence for $\\rm LP^{MLN}$ programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong equivalence is a well-studied and important concept in answer set\nprogramming (ASP). $\\rm LP^{MLN}$ is a probabilistic extension of answer set\nprograms with the weight scheme adapted from Markov Logic. Because of the\nsemantic differences, strong equivalence for ASP does not simply carry over to\n$\\rm LP^{MLN}$. I study the concept of strong equivalence in $\\rm LP^{MLN}$\nwith the goal of extending strong equivalence to $\\rm LP^{MLN}$ programs. My\nstudy shows that the verification of strong equivalence in $\\rm LP^{MLN}$ can\nbe reduced to equivalence checking in classical logic plus weight\nconsideration.The result allows us to leverage an answer set solver for\nchecking strong equivalence in $\\rm LP^{MLN}$. Furthermore, this study also\nsuggests us a few reformulations of the $\\rm LP^{MLN}$ semantics using choice\nrules, logic of here and there, and the second-order logic. I will present my\nwork result of strong equivalence for $\\rm LP^{MLN}$ and talk about my next\nsteps for research: one is approximately strong equivalence, and another is the\nintegration of fuzzy logic with neural network.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 07:48:16 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Luo", "Man", ""]]}, {"id": "1905.07551", "submitter": "Benjam\\'in Bedregal Prof.", "authors": "Annaxsuel A. de Lima, Benjam\\'in Bedregal, Ivan Mezzomo", "title": "Ordinal Sums of Fuzzy Negations: Main Classes and Natural Negations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of fuzzy logic, ordinal sums provide a method for constructing\nnew functions from existing functions, which can be triangular norms,\ntriangular conorms, fuzzy negations, copulas, overlaps, uninorms, fuzzy\nimplications, among others. As our main contribution, we establish conditions\nfor the ordinal sum of a family of fuzzy negations to be a fuzzy negation of a\nspecific class, such as strong, strict, continuous, invertible and frontier.\nAlso, we relate the natural negation of the ordinal sum on families of t-norms,\nt-conorms and fuzzy implications with the ordinal sum of the natural negations\nof the respective families of t-norms, t- conorms and fuzzy implications. This\nmotivated us to introduces a new kind of ordinal sum for families of fuzzy\nimplications.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 08:08:30 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["de Lima", "Annaxsuel A.", ""], ["Bedregal", "Benjam\u00edn", ""], ["Mezzomo", "Ivan", ""]]}, {"id": "1905.07621", "submitter": "Danko Ilik", "authors": "Danko Ilik", "title": "Applications of the analogy between formulas and exponential polynomials\n  to equivalence and normal forms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show some applications of the formulas-as-polynomials correspondence: 1) a\nmethod for (dis)proving formula isomorphism and equivalence based on showing\n(in)equality; 2) a constructive analogue of the arithmetical hierarchy, based\non the exp-log normal form. The results are valid intuitionistically, as well\nas classically.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 18:25:58 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ilik", "Danko", ""]]}, {"id": "1905.07696", "submitter": "Guido Governatori", "authors": "Guido Governatori and Antonino Rotolo", "title": "Is Free Choice Permission Admissible in Classical Deontic Logic?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore how, and if, free choice permission (FCP) can be\naccepted when we consider deontic conflicts between certain types of\npermissions and obligations. As is well known, FCP can license, under some\nminimal conditions, the derivation of an indefinite number of permissions. We\ndiscuss this and other drawbacks and present six Hilbert-style classical\ndeontic systems admitting a guarded version of FCP. The systems that we present\nare not too weak from the inferential viewpoint, as far as permission is\nconcerned, and do not commit to weakening any specific logic for obligations.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 07:15:10 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 14:46:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Governatori", "Guido", ""], ["Rotolo", "Antonino", ""]]}, {"id": "1905.07805", "submitter": "Idan Berkovits", "authors": "Idan Berkovits, Marijana Lazic, Giuliano Losa, Oded Padon, Sharon\n  Shoham", "title": "Verification of Threshold-Based Distributed Algorithms by Decomposition\n  to Decidable Logics", "comments": "23 pages, extended version of the paper with the same title presented\n  in CAV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of fault-tolerant distributed protocols is an immensely\ndifficult task. Often, in these protocols, thresholds on set cardinalities are\nused both in the process code and in its correctness proof, e.g., a process can\nperform an action only if it has received an acknowledgment from at least half\nof its peers. Verification of threshold-based protocols is extremely\nchallenging as it involves two kinds of reasoning: first-order reasoning about\nthe unbounded state of the protocol, together with reasoning about sets and\ncardinalities. In this work, we develop a new methodology for decomposing the\nverification task of such protocols into two decidable logics: EPR and BAPA.\nOur key insight is that such protocols use thresholds in a restricted way as a\nmeans to obtain certain properties of \"intersection\" between sets. We define a\nlanguage for expressing such properties, and present two translations: to EPR\nand BAPA. The EPR translation allows verifying the protocol while assuming\nthese properties, and the BAPA translation allows verifying the correctness of\nthe properties. We further develop an algorithm for automatically generating\nthe properties needed for verifying a given protocol, facilitating fully\nautomated deductive verification. Using this technique we have verified several\nchallenging protocols, including Byzantine one-step consensus, hybrid reliable\nbroadcast and fast Byzantine Paxos.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 20:40:05 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Berkovits", "Idan", ""], ["Lazic", "Marijana", ""], ["Losa", "Giuliano", ""], ["Padon", "Oded", ""], ["Shoham", "Sharon", ""]]}, {"id": "1905.07961", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski, Josef Urban", "title": "Guiding Inferences in Connection Tableau by Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dataset and experiments on applying recurrent neural networks\n(RNNs) for guiding clause selection in the connection tableau proof calculus.\nThe RNN encodes a sequence of literals from the current branch of the partial\nproof tree to a hidden vector state; using it, the system selects a clause for\nextending the proof tree. The training data and learning setup are described,\nand the results are discussed and compared with state of the art using gradient\nboosted trees. Additionally, we perform a conjecturing experiment in which the\nRNN does not just select an existing clause, but completely constructs the next\ntableau goal.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 09:47:41 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 11:56:26 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""]]}, {"id": "1905.08368", "submitter": "M\\'ario Pereira", "authors": "M\\'ario Pereira", "title": "Desfuncionalizar para Provar", "comments": "in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the idea of using defunctionalization as a proof\ntechnique for higher-order programs. Defunctionalization builds on substituting\nfunctional values by a first-order representation. Thus, its interest is that\none can use an existing program verification tool, without further extensions\nin order to support higher-order. This papers illustrates and discusses this\napproach by means of several running examples, built and verified using the\nWhy3 verification framework.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 22:28:49 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Pereira", "M\u00e1rio", ""]]}, {"id": "1905.08406", "submitter": "Sidi Mohamed Beillahi", "authors": "Sidi Mohamed Beillahi, Ahmed Bouajjani and Constantin Enea", "title": "Checking Robustness Against Snapshot Isolation", "comments": "CAV 2019: 31st International Conference on Computer-Aided\n  Verification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transactional access to databases is an important abstraction allowing\nprogrammers to consider blocks of actions (transactions) as executing in\nisolation. The strongest consistency model is {\\em serializability}, which\nensures the atomicity abstraction of transactions executing over a sequentially\nconsistent memory. Since ensuring serializability carries a significant penalty\non availability, modern databases provide weaker consistency models, one of the\nmost prominent being \\emph{snapshot isolation}. In general, the correctness of\na program relying on serializable transactions may be broken when using weaker\nmodels. However, certain programs may also be insensitive to consistency\nrelaxations, i.e., all their properties holding under serializability are\npreserved even when they are executed over a weak consistent database and\nwithout additional synchronization.\n  In this paper, we address the issue of verifying if a given program is {\\em\nrobust against snapshot isolation}, i.e., all its behaviors are serializable\neven if it is executed over a database ensuring snapshot isolation. We show\nthat this verification problem is polynomial time reducible to a state\nreachability problem in transactional programs over a sequentially consistent\nshared memory. This reduction opens the door to the reuse of the classic\nverification technology for reasoning about weakly-consistent programs. In\nparticular, we show that it can be used to derive a proof technique based on\nLipton's reduction theory that allows to prove programs robust.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 02:12:09 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 15:29:00 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Beillahi", "Sidi Mohamed", ""], ["Bouajjani", "Ahmed", ""], ["Enea", "Constantin", ""]]}, {"id": "1905.08531", "submitter": "Mathias Ruggaard Pedersen", "authors": "Mathias Ruggaard Pedersen", "title": "Behavioural Preorders on Stochastic Systems - Logical, Topological, and\n  Computational Aspects", "comments": "PhD dissertation from Aalborg University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer systems can be found everywhere: in space, in our homes, in our\ncars, in our pockets, and sometimes even in our own bodies. For concerns of\nsafety, economy, and convenience, it is important that such systems work\ncorrectly. However, it is a notoriously difficult task to ensure that the\nsoftware running on computers behaves correctly.\n  One approach to ease this task is that of model checking, where a model of\nthe system is made using some mathematical formalism. Requirements expressed in\na formal language can then be verified against the model in order to give\nguarantees that the model satisfies the requirements.\n  For many computer systems, time is an important factor. As such, we need our\nformalisms and requirement languages to be able to incorporate real time.\n  We therefore develop formalisms and algorithms that allow us to compare and\nexpress properties about real-time systems. We first introduce a logical\nformalism for reasoning about upper and lower bounds on time, and study the\nproperties of this formalism, including axiomatisation and algorithms for\nchecking when a formula is satisfied.\n  We then consider the question of when a system is faster than another system.\nWe show that this is a difficult question which can not be answered in general,\nbut we identify special cases where this question can be answered. We also show\nthat under this notion of faster-than, a local increase in speed may lead to a\nglobal decrease in speed, and we take step towards avoiding this.\n  Finally, we consider how to compare the real-time behaviour of systems not\njust qualitatively, but also quantitatively. Thus, we are interested in knowing\nhow much one system is faster or slower than another system. This is done by\nintroducing a distance between systems. We show how to compute this distance\nand that it behaves well with respect to certain properties.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:30:30 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Pedersen", "Mathias Ruggaard", ""]]}, {"id": "1905.08554", "submitter": "Jana Wagemaker", "authors": "Jana Wagemaker, Marcello Bonsangue, Tobias Kapp\\'e, Jurriaan Rot,\n  Alexandra Silva", "title": "Completeness and Incompleteness of Synchronous Kleene Algebra", "comments": "Accepted at MPC 2019", "journal-ref": null, "doi": "10.1007/978-3-030-33636-3_14", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronous Kleene algebra (SKA), an extension of Kleene algebra (KA), was\nproposed by Prisacariu as a tool for reasoning about programs that may execute\nsynchronously, i.e., in lock-step. We provide a countermodel witnessing that\nthe axioms of SKA are incomplete w.r.t. its language semantics, by exploiting a\nlack of interaction between the synchronous product operator and the Kleene\nstar. We then propose an alternative set of axioms for SKA, based on Salomaa's\naxiomatisation of regular languages, and show that these provide a sound and\ncomplete characterisation w.r.t. the original language semantics.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 11:20:22 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 13:17:27 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Wagemaker", "Jana", ""], ["Bonsangue", "Marcello", ""], ["Kapp\u00e9", "Tobias", ""], ["Rot", "Jurriaan", ""], ["Silva", "Alexandra", ""]]}, {"id": "1905.08664", "submitter": "Juergen Giesl", "authors": "Florian Frohn and J\\\"urgen Giesl", "title": "Termination of Triangular Integer Loops is Decidable", "comments": "Full version (with proofs) of a paper published in the Proceedings of\n  the 31st International Conference on Computer Aided Verification (CAV '19),\n  New York, NY, USA, Lecture Notes in Computer Science, Springer-Verlag, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem whether termination of affine integer loops is\ndecidable. Since Tiwari conjectured decidability in 2004, only special cases\nhave been solved. We complement this work by proving decidability for the case\nthat the update matrix is triangular.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 14:26:01 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Frohn", "Florian", ""], ["Giesl", "J\u00fcrgen", ""]]}, {"id": "1905.08697", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Vojt\\v{e}ch Havlena, Luk\\'a\\v{s} Hol\\'ik, Ond\\v{r}ej Leng\\'al,\n  Tom\\'a\\v{s} Vojnar", "title": "Automata Terms in a Lazy WSkS Decision Procedure (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a lazy decision procedure for the logic WSkS. It builds a\nterm-based symbolic representation of the state space of the tree automaton\n(TA) constructed by the classical WSkS decision procedure. The classical\ndecision procedure transforms the symbolic representation into a TA via a\nbottom-up traversal and then tests its language non-emptiness, which\ncorresponds to satisfiability of the formula. On the other hand, we start\nevaluating the representation from the top, construct the state space on the\nfly, and utilize opportunities to prune away parts of the state space\nirrelevant to the language emptiness test. In order to do so, we needed to\nextend the notion of language terms (denoting language derivatives) used in our\nprevious procedure for the linear fragment of the logic (the so-called WS1S)\ninto automata terms. We implemented our decision procedure and identified\nclasses of formulae on which our prototype implementation is significantly\nfaster than the classical procedure implemented in the Mona tool.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:28:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Havlena", "Vojt\u011bch", ""], ["Hol\u00edk", "Luk\u00e1\u0161", ""], ["Leng\u00e1l", "Ond\u0159ej", ""], ["Vojnar", "Tom\u00e1\u0161", ""]]}, {"id": "1905.08842", "submitter": "David A. Plaisted", "authors": "David A. Plaisted", "title": "Properties and Extensions of Alternating Path Relevance - I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When proving theorems from large sets of logical assertions, it can be\nhelpful to restrict the search for a proof to those assertions that are\nrelevant, that is, closely related to the theorem in some sense. For example,\nin the Watson system, a large knowledge base must rapidly be searched for\nrelevant facts. It is possible to define formal concepts of relevance for\npropositional and first-order logic. Various concepts of relevance have been\ndefined for this, and some have yielded good results on large problems. We\nconsider here in particular a concept based on alternating paths.We present\nefficient graph-based methods for computing alternating path relevance and give\nsome results indicating its effectiveness. We also propose an alternating path\nbased extension of this relevance method to DPLL with an improved time bound,\nand give other extensions to alternating path relevance intended to improve its\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 19:26:00 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Plaisted", "David A.", ""]]}, {"id": "1905.08877", "submitter": "Robin Cockett Dr.", "authors": "J. Robin B. Cockett, Priyaa V. Srinivasan", "title": "Complete Positivity for Mixed Unitary Categories", "comments": "Lots of figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we generalize the $\\CP^\\infty$-construction of dagger\nmonoidal categories to mixed unitary categories. Mixed unitary categories\nprovide a setting, which generalizes (compact) dagger monoidal categories and\nin which one may study quantum processes of arbitrary (infinite) dimensions.\n  We show that the existing results for the $\\CP^\\infty$-construction hold in\nthis more general setting. In particular, we generalize the notion of\nenvironment structures to mixed unitary categories and show that the\n$\\CP^\\infty$-construction on mixed unitary categories is characterized by this\ngeneralized environment structure.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 21:35:18 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Cockett", "J. Robin B.", ""], ["Srinivasan", "Priyaa V.", ""]]}, {"id": "1905.09083", "submitter": "Ismail Berrada", "authors": "Rachid Oucheikh, Ismail Berrada, Outman El Hichami", "title": "A Hypergraph Based Approach for the 4-Constraint Satisfaction Problem\n  Tractability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Constraint Satisfaction Problem (CSP) is a framework for modeling and solving\na variety of real-world problems. Once the problem is expressed as a finite set\nof constraints, the goal is to find the variables' values satisfying them. Even\nthough the problem is in general NP-complete, there are some approximation and\npractical techniques to tackle its intractability. One of the most widely used\ntechniques is the Constraint Propagation. It consists in explicitly excluding\nvalues or combination of values for some variables whenever they make a given\nsubset of constraints unsatisfied. In this paper, we deal with a CSP subclass\nwhich we call 4-CSP and whose constraint network infers relations of the form:\n$\\{ x \\sim \\alpha, x-y \\sim \\beta , (x-y) - (z-t) \\sim \\lambda \\}$, where $x,\ny, z$ and $t$ are real variables, $\\alpha , \\beta$ and $ \\lambda $ are real\nconstants and $ \\sim \\in \\{\\leq , \\geq \\} $. The paper provides the first\ngraph-based proofs of the 4-CSP tractability and elaborates algorithms for\n4-CSP resolution based on the positive linear dependence theory, the hypergraph\nclosure and the constraint propagation technique. Time and space complexities\nof the resolution algorithms are proved to be polynomial.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 11:43:49 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Oucheikh", "Rachid", ""], ["Berrada", "Ismail", ""], ["Hichami", "Outman El", ""]]}, {"id": "1905.09181", "submitter": "Robin Kaarsgaard", "authors": "Robin Kaarsgaard", "title": "Condition/Decision Duality and the Internal Logic of Extensive\n  Restriction Categories", "comments": "19 pages, including 6 page appendix of proofs. Accepted for MFPS XXXV", "journal-ref": null, "doi": "10.1016/j.entcs.2019.09.010", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In flowchart languages, predicates play an interesting double role. In the\ntextual representation, they are often presented as conditions, i.e.,\nexpressions which are easily combined with other conditions (often via Boolean\ncombinators) to form new conditions, though they only play a supporting role in\naiding branching statements choose a branch to follow. On the other hand, in\nthe graphical representation they are typically presented as decisions,\nintrinsically capable of directing control flow yet mostly oblivious to Boolean\ncombination. While categorical treatments of flowchart languages are abundant,\nnone of them provide a treatment of this dual nature of predicates. In the\npresent paper, we argue that extensive restriction categories are precisely\ncategories that capture such a condition/decision duality, by means of\nmorphisms which, coincidentally, are also called decisions. Further, we show\nthat having these categorical decisions amounts to having an internal logic:\nAnalogous to how subobjects of an object in a topos form a Heyting algebra, we\nshow that decisions on an object in an extensive restriction category form a De\nMorgan quasilattice, the algebraic structure associated with the (three-valued)\nweak Kleene logic $\\mathbf{K}^w_3$. Full classical propositional logic can be\nrecovered by restricting to total decisions, yielding extensive categories in\nthe usual sense, and confirming (from a different direction) a result from\neffectus theory that predicates on objects in extensive categories form Boolean\nalgebras. As an application, since (categorical) decisions are partial\nisomorphisms, this approach provides naturally reversible models of classical\npropositional logic and weak Kleene logic.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:02:10 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kaarsgaard", "Robin", ""]]}, {"id": "1905.09221", "submitter": "Loris Bozzato", "authors": "Loris Bozzato, Thomas Eiter, Luciano Serafini", "title": "A Note on Reasoning on $\\textit{DL-Lite}_{\\cal R}$ with Defeasibility", "comments": "Part of this work will appear as a paper in Proceedings of 32nd\n  International Workshop on Description Logics (DL2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation of defeasible information is of interest in description\nlogics, as it is related to the need of accommodating exceptional instances in\nknowledge bases. In this direction, in our previous works we presented a\ndatalog translation for reasoning on (contextualized) OWL RL knowledge bases\nwith a notion of justified exceptions on defeasible axioms. While it covers a\nrelevant fragment of OWL, the resulting reasoning process needs a complex\nencoding in order to capture reasoning on negative information. In this paper,\nwe consider the case of knowledge bases in $\\textit{DL-Lite}_{\\cal R}$, i.e.\nthe language underlying OWL QL. We provide a definition for\n$\\textit{DL-Lite}_{\\cal R}$ knowledge bases with defeasible axioms and study\ntheir properties. The limited form of $\\textit{DL-Lite}_{\\cal R}$ axioms allows\nus to formulate a simpler encoding into datalog (under answer set semantics)\nwith direct rules for reasoning on negative information. The resulting\nmaterialization method gives rise to a complete reasoning procedure for\ninstance checking in $\\textit{DL-Lite}_{\\cal R}$ with defeasible axioms.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:18:06 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Bozzato", "Loris", ""], ["Eiter", "Thomas", ""], ["Serafini", "Luciano", ""]]}, {"id": "1905.09227", "submitter": "Franz Brau{\\ss}e", "authors": "Franz Brau{\\ss}e, Konstantin Korovin, Margarita Korovina, Norbert Th.\n  M\\\"uller", "title": "A CDCL-style calculus for solving non-linear constraints", "comments": "17 pages, 3 figures; accepted at FroCoS 2019; software available at\n  <http://informatik.uni-trier.de/~brausse/ksmt/>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel approach for checking satisfiability of\nnon-linear constraints over the reals, called ksmt. The procedure is based on\nconflict resolution in CDCL style calculus, using a composition of symbolical\nand numerical methods. To deal with the non-linear components in case of\nconflicts we use numerically constructed restricted linearisations. This\napproach covers a large number of computable non-linear real functions such as\npolynomials, rational or trigonometrical functions and beyond. A prototypical\nimplementation has been evaluated on several non-linear SMT-LIB examples and\nthe results have been compared with state-of-the-art SMT solvers.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:24:40 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 17:35:30 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Brau\u00dfe", "Franz", ""], ["Korovin", "Konstantin", ""], ["Korovina", "Margarita", ""], ["M\u00fcller", "Norbert Th.", ""]]}, {"id": "1905.09381", "submitter": "Kaiyu Yang", "authors": "Kaiyu Yang, Jia Deng", "title": "Learning to Prove Theorems via Interacting with Proof Assistants", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans prove theorems by relying on substantial high-level reasoning and\nproblem-specific insights. Proof assistants offer a formalism that resembles\nhuman mathematical reasoning, representing theorems in higher-order logic and\nproofs as high-level tactics. However, human experts have to construct proofs\nmanually by entering tactics into the proof assistant. In this paper, we study\nthe problem of using machine learning to automate the interaction with proof\nassistants. We construct CoqGym, a large-scale dataset and learning environment\ncontaining 71K human-written proofs from 123 projects developed with the Coq\nproof assistant. We develop ASTactic, a deep learning-based model that\ngenerates tactics as programs in the form of abstract syntax trees (ASTs).\nExperiments show that ASTactic trained on CoqGym can generate effective tactics\nand can be used to prove new theorems not previously provable by automated\nmethods. Code is available at https://github.com/princeton-vl/CoqGym.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:56:02 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Yang", "Kaiyu", ""], ["Deng", "Jia", ""]]}, {"id": "1905.09450", "submitter": "Tadeusz Litak", "authors": "Tadeusz Litak, Albert Visser", "title": "Lewisian Fixed Points I: Two Incomparable Constructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our paper is the first study of what one might call \"reverse mathematics of\nexplicit fixpoints\". We study two methods of constructing such fixpoints for\nformulas whose principal connective is the intuitionistic Lewis arrow. Our main\nmotivation comes from metatheory of constructive arithmetic, but the systems in\nquestion allows several natural semantics. The first of these methods, inspired\nby de Jongh and Visser, turns out to yield a well-understood modal system. The\nsecond one by de Jongh and Sambin, seemingly simpler, leads to a modal theory\nthat proves harder to axiomatize in an elegant way. Apart from showing that\nboth theories are incomparable, we axiomatize their join and investigate\nseveral subtheories, whose axioms are obtained as fixpoints of simple formulas.\nWe also show that they are extension stable, that is, their validity in the\ncorresponding preservativity logic of a given arithmetical theory transfer to\nits finite extensions.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 03:29:54 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Litak", "Tadeusz", ""], ["Visser", "Albert", ""]]}, {"id": "1905.09520", "submitter": "Katherine Cordwell", "authors": "Katherine Cordwell and Andr\\'e Platzer", "title": "Towards Physical Hybrid Systems", "comments": "CADE 2019", "journal-ref": null, "doi": "10.1007/978-3-030-29436-6_13", "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some hybrid systems models are unsafe for mathematically correct but\nphysically unrealistic reasons. For example, mathematical models can classify a\nsystem as being unsafe on a set that is too small to have physical importance.\nIn particular, differences in measure zero sets in models of cyber-physical\nsystems (CPS) have significant mathematical impact on the mathematical safety\nof these models even though differences on measure zero sets have no tangible\nphysical effect in a real system. We develop the concept of \"physical hybrid\nsystems\" (PHS) to help reunite mathematical models with physical reality. We\nmodify a hybrid systems logic (differential temporal dynamic logic) by adding a\nfirst-class operator to elide distinctions on measure zero sets of time within\nCPS models. This approach facilitates modeling since it admits the verification\nof a wider class of models, including some physically realistic models that\nwould otherwise be classified as mathematically unsafe. We also develop a proof\ncalculus to help with the verification of PHS.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:00:17 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 14:35:09 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Cordwell", "Katherine", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "1905.09536", "submitter": "Agi Kurucz", "authors": "Christopher Hampson, Stanislav Kikot, Agi Kurucz, Sergio Marcelino", "title": "Non-finitely axiomatisable modal product logics with infinite canonical\n  axiomatisations", "comments": null, "journal-ref": null, "doi": "10.1016/j.apal.2020.102786", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our concern is the axiomatisation problem for modal and algebraic logics that\ncorrespond to various fragments of two-variable first-order logic with counting\nquantifiers. In particular, we consider modal products with Diff, the\npropositional unimodal logic of the difference operator. We show that the\ntwo-dimensional product logic Diff x Diff is non-finitely axiomatisable, but\ncan be axiomatised by infinitely many Sahlqvist axioms. We also show that its\n`square' version (the modal counterpart of the substitution and equality free\nfragment of two-variable first-order logic with counting to two) is\nnon-finitely axiomatisable over Diff x Diff, but can be axiomatised by adding\ninfinitely many Sahlqvist axioms. These are the first examples of products of\nfinitely axiomatisable modal logics that are not finitely axiomatisable, but\naxiomatisable by explicit infinite sets of canonical axioms.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:47:12 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 11:07:21 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hampson", "Christopher", ""], ["Kikot", "Stanislav", ""], ["Kurucz", "Agi", ""], ["Marcelino", "Sergio", ""]]}, {"id": "1905.09544", "submitter": "J\\\"urgen Giesl", "authors": "J\\\"urgen Giesl, Peter Giesl and Marcel Hark", "title": "Computing Expected Runtimes for Constant Probability Programs", "comments": "Full version (with proofs) of a paper published in the Proceedings of\n  the 27th International Conference on Automated Deduction (CADE '19), Natal,\n  Brazil, Lecture Notes in Computer Science 11716, pages 269-286,\n  Springer-Verlag, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the class of constant probability (CP) programs and show that\nclassical results from probability theory directly yield a simple decision\nprocedure for (positive) almost sure termination of programs in this class.\nMoreover, asymptotically tight bounds on their expected runtime can always be\ncomputed easily. Based on this, we present an algorithm to infer the exact\nexpected runtime of any CP program.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:10:09 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 15:43:18 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 09:42:05 GMT"}, {"version": "v4", "created": "Wed, 18 Sep 2019 12:22:58 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Giesl", "J\u00fcrgen", ""], ["Giesl", "Peter", ""], ["Hark", "Marcel", ""]]}, {"id": "1905.09926", "submitter": "Luisa Iturrioz", "authors": "Luisa Iturrioz", "title": "Rough sets and three-valued structures", "comments": "10 pages", "journal-ref": "This article is published in 'Logic at Work', chapter 33,\n  Or{\\l}owska E. (ed.), Essays Dedicated to the Memory of Helena Rasiowa,\n  Physica-Verlag, Heidelberg, 1999, 596--603", "doi": null, "report-no": null, "categories": "math.LO cs.DM cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In recent years, many papers have been published showing relationships\nbetween rough sets and some lattice theoretical structures. We present here\nsome strong relations between rough sets and three-valued {\\L}ukasiewicz\nalgebras.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 16:25:57 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Iturrioz", "Luisa", ""]]}, {"id": "1905.09928", "submitter": "Luisa Iturrioz", "authors": "Luisa Iturrioz", "title": "About a 'concrete' Rauszer Boolean algebra generated by a preorder", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.DM cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Inspired by the fundamental results obtained by P. Halmos and A. Monteiro,\nconcerning equivalence relations and monadic Boolean algebras, we recall the\n`concrete' Rauszer Boolean algebra pointed out by C. Rauszer (1971), via un\npreorder R. On this algebra we can consider one of the several binary\noperations defined, in an abstract way, by A. Monteiro (1971). The\nHeyting-Brouwer subalgebra of constants (fixpoints), allows us to give a\ngeneral framework to find representations of several special algebraic\nstructures related to logic.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 16:36:31 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Iturrioz", "Luisa", ""]]}, {"id": "1905.09996", "submitter": "Peizun Liu", "authors": "Peizun Liu and Thomas Wahl and Akash LaL", "title": "Verifying Asynchronous Event-Driven Programs Using Partial Abstract\n  Transformers (Extended Manuscript)", "comments": "This is an extended technical report of a paper published in CAV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of analyzing asynchronous event-driven programs, in\nwhich concurrent agents communicate via unbounded message queues. The safety\nverification problem for such programs is undecidable. We present in this paper\na technique that combines queue-bounded exploration with a convergence test: if\nthe sequence of certain abstractions of the reachable states, for increasing\nqueue bounds k, converges, we can prove any property of the program that is\npreserved by the abstraction. If the abstract state space is finite,\nconvergence is guaranteed; the challenge is to catch the point k_max where it\nhappens. We further demonstrate how simple invariants formulated over the\nconcrete domain can be used to eliminate spurious abstract states, which\notherwise prevent the sequence from converging. We have implemented our\ntechnique for the P programming language for event-driven programs. We show\nexperimentally that the sequence of abstractions often converges fully\nautomatically, in hard cases with minimal designer support in the form of\nsequentially provable invariants, and that this happens for a value of k_max\nsmall enough to allow the method to succeed in practice.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:48:26 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Liu", "Peizun", ""], ["Wahl", "Thomas", ""], ["LaL", "Akash", ""]]}, {"id": "1905.10006", "submitter": "Markus N Rabe", "authors": "Aditya Paliwal, Sarah Loos, Markus Rabe, Kshitij Bansal, Christian\n  Szegedy", "title": "Graph Representations for Higher-Order Logic and Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first use of graph neural networks (GNNs) for\nhigher-order proof search and demonstrates that GNNs can improve upon\nstate-of-the-art results in this domain. Interactive, higher-order theorem\nprovers allow for the formalization of most mathematical theories and have been\nshown to pose a significant challenge for deep learning. Higher-order logic is\nhighly expressive and, even though it is well-structured with a clearly defined\ngrammar and semantics, there still remains no well-established method to\nconvert formulas into graph-based representations. In this paper, we consider\nseveral graphical representations of higher-order logic and evaluate them\nagainst the HOList benchmark for higher-order theorem proving.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 02:42:22 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 00:06:34 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Paliwal", "Aditya", ""], ["Loos", "Sarah", ""], ["Rabe", "Markus", ""], ["Bansal", "Kshitij", ""], ["Szegedy", "Christian", ""]]}, {"id": "1905.10338", "submitter": "Mitko Yanchev", "authors": "Mitko Yanchev (Sofia University `St. Kliment Ohridski', Bulgaria)", "title": "Decidability of an Expressive Description Logic with Rational Grading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper syntactic objects---concept constructors called part\nrestrictions which realize rational grading are considered in Description\nLogics (DLs). Being able to convey statements about a rational part of a set of\nsuccessors, part restrictions essentially enrich the expressive capabilities of\nDLs. We examine an extension of well-studied DL ALCQIHR+ with part\nrestrictions, and prove that the reasoning in the extended logic is still\ndecidable. The proof uses tableaux technique augmented with indices technique,\ndesigned for dealing with part restrictions.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:04:16 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Yanchev", "Mitko", "", "Sofia University `St. Kliment Ohridski', Bulgaria"]]}, {"id": "1905.10434", "submitter": "Yoni Zohar", "authors": "Aina Niemetz, Mathias Preiner, Andrew Reynolds, Yoni Zohar, Clark\n  Barrett, Cesare Tinelli", "title": "Towards Bit-Width-Independent Proofs in SMT Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many SMT solvers implement efficient SAT-based procedures for solving\nfixed-size bit-vector formulas. These approaches, however, cannot be used\ndirectly to reason about bit-vectors of symbolic bit-width. To address this\nshortcoming, we propose a translation from bit-vector formulas of non-fixed\nbit-width to formulas in a logic supported by SMT solvers that includes\nnon-linear integer arithmetic, uninterpreted functions, and universal\nquantification. While this logic is undecidable, this approach can still solve\nmany formulas by capitalizing on advancements in SMT solving for non-linear\narithmetic and universally quantified formulas. We provide several case studies\nin which we have applied this approach with promising results, including the\nbit-width independent verification of invertibility conditions, compiler\noptimizations, and bit-vector rewrites.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 20:16:08 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:35:35 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 21:06:30 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Niemetz", "Aina", ""], ["Preiner", "Mathias", ""], ["Reynolds", "Andrew", ""], ["Zohar", "Yoni", ""], ["Barrett", "Clark", ""], ["Tinelli", "Cesare", ""]]}, {"id": "1905.10494", "submitter": "Hirohiko Kushida", "authors": "Hirohiko Kushida", "title": "On the Constructive Truth and Falsity in Peano Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Artemov [4] offered the notion of constructive consistency for\nPeano Arithmetic and generalized it to constructive truth and falsity in the\nspirit of Brouwer-Heyting-Kolmogorov semantics and its formalization, the Logic\nof Proofs. In this paper, we provide a complete description of constructive\ntruth and falsity for Friedman's constant fragment of Peano Arithmetic. For\nthis purpose, we generalize the constructive falsity to n-constructive falsity\nwhere n is any positive natural number. We also establish similar\nclassification results for constructive truth and n-constructive falsity of\nFriedman's formulas. Then, we discuss `extremely' independent sentences in the\nsense that they are classically true but %unprovable in Peano Arithmetic\nneither constructively true nor n-constructive false for any n.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 01:31:54 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Kushida", "Hirohiko", ""]]}, {"id": "1905.10501", "submitter": "Kshitij Bansal", "authors": "Kshitij Bansal, Christian Szegedy, Markus N. Rabe, Sarah M. Loos,\n  Viktor Toman", "title": "Learning to Reason in Large Theories without Imitation", "comments": "Major revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate how to do automated theorem proving in the\npresence of a large knowledge base of potential premises without learning from\nhuman proofs. We suggest an exploration mechanism that mixes in additional\npremises selected by a tf-idf (term frequency-inverse document frequency) based\nlookup in a deep reinforcement learning scenario. This helps with exploring and\nlearning which premises are relevant for proving a new theorem. Our experiments\nshow that the theorem prover trained with this exploration mechanism\noutperforms provers that are trained only on human proofs. It approaches the\nperformance of a prover trained by a combination of imitation and reinforcement\nlearning. We perform multiple experiments to understand the importance of the\nunderlying assumptions that make our exploration approach work, thus explaining\nour design choices.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 02:36:25 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 21:53:06 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 23:20:59 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Bansal", "Kshitij", ""], ["Szegedy", "Christian", ""], ["Rabe", "Markus N.", ""], ["Loos", "Sarah M.", ""], ["Toman", "Viktor", ""]]}, {"id": "1905.10728", "submitter": "Jan Malakhovski", "authors": "Jan Malakhovski and Sergei Soloviev", "title": "Programming with Applicative-like expressions", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fact that Applicative type class allows one to express simple parsers in\na variable-less combinatorial style is well appreciated among Haskell\nprogrammers for its conceptual simplicity, ease of use, and usefulness for\nsemi-automated code generation (metaprogramming).\n  We notice that such Applicative computations can be interpreted as providing\na mechanism to construct a data type with \"ports\" \"pluggable\" by\nsubcomputations. We observe that it is this property that makes them so much\nmore convenient in practice than the usual way of building the same\ncomputations using conventional composition. We distill this observation into a\nmore general algebraic structure of (and/or technique for expressing)\n\"Applicative-like\" computations and demonstrate several other instances of this\nstructure.\n  Our interest in all of this comes from the fact that the aforementioned\ninstances allow us to express arbitrary transformations between simple data\ntypes of a single constructor (similarly to how Applicative parsing allows to\ntransform from streams of Chars to such data types) using a style that closely\nfollows conventional Applicative computations, thus greatly simplifying (if not\ncompletely automating away) a lot of boiler-plate code present in many\nfunctional programs.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 04:56:24 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Malakhovski", "Jan", ""], ["Soloviev", "Sergei", ""]]}, {"id": "1905.10976", "submitter": "Xinyu Wang", "authors": "Xinyu Wang", "title": "Epistemic Logic with Partial Dependency Operator", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-662-60292-8_28", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce $\\textit{partial}$ dependency modality\n$\\mathcal{D}$ into epistemic logic so as to reason about $\\textit{partial}$\ndependency relationship in Kripke models. The resulted dependence epistemic\nlogic possesses decent expressivity and beautiful properties. Several\ninteresting examples are provided, which highlight this logic's practical\nusage. The logic's bisimulation is then discussed, and we give a sound and\nstrongly complete axiomatization for a sub-language of the logic.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 05:04:36 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 06:26:38 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Wang", "Xinyu", ""]]}, {"id": "1905.11157", "submitter": "Paritosh Pandya", "authors": "Paritosh K. Pandya and Amol Wakankar", "title": "Specification and Reactive Synthesis of Robust Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the synthesis of robust controllers from logical\nspecification of regular properties given in an interval temporal logic QDDC.\nOur specification encompasses both hard robustness and soft robustness. Here,\nhard robustness guarantees invariance of commitment under user-specified\nrelaxed (weakened) assumptions. A systematic framework for logically specifying\nthe assumption weakening by means of a formula, called Robustness Criterion, is\npresented. The soft robustness pertains to the ability of the controller to\nmaintain the commitment for as many inputs as possible, irrespective of any\nassumption. We present a uniform method for the synthesis of a robust\ncontroller which guarantees the specified hard robustness and it optimizes the\nspecified soft robustness. The method is implemented using a tool DCSynth,\nwhich provides soft requirement optimized controller synthesis. Through the\ncase study of a synchronous bus arbiter, we experimentally show the impact of\nhard robustness criteria as well as soft robustness on the ability of the\nsynthesized controllers to meet the commitment \"as much as possible\". Both, the\nworst-case and the expected case behaviors are analyzed.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 12:10:55 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Pandya", "Paritosh K.", ""], ["Wakankar", "Amol", ""]]}, {"id": "1905.11187", "submitter": "Florian Frohn", "authors": "Florian Frohn and J\\\"urgen Giesl", "title": "Proving Non-Termination via Loop Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first approach to prove non-termination of integer programs\nthat is based on loop acceleration. If our technique cannot show\nnon-termination of a loop, it tries to accelerate it instead in order to find\npaths to other non-terminating loops automatically. The prerequisites for our\nnovel loop acceleration technique generalize a simple yet effective\nnon-termination criterion. Thus, we can use the same program transformations to\nfacilitate both non-termination proving and loop acceleration. In particular,\nwe present a novel invariant inference technique that is tailored to our\napproach. An extensive evaluation of our fully automated tool LoAT shows that\nit is competitive with the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:15:30 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 10:46:28 GMT"}, {"version": "v3", "created": "Thu, 8 Aug 2019 08:06:40 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Frohn", "Florian", ""], ["Giesl", "J\u00fcrgen", ""]]}, {"id": "1905.11190", "submitter": "Amir-Hossein Karimi", "authors": "Amir-Hossein Karimi, Gilles Barthe, Borja Balle, Isabel Valera", "title": "Model-Agnostic Counterfactual Explanations for Consequential Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models are being increasingly used to support consequential\ndecision making at the individual level in contexts such as pretrial bail and\nloan approval. As a result, there is increasing social and legal pressure to\nprovide explanations that help the affected individuals not only to understand\nwhy a prediction was output, but also how to act to obtain a desired outcome.\nTo this end, several works have proposed optimization-based methods to generate\nnearest counterfactual explanations. However, these methods are often\nrestricted to a particular subset of models (e.g., decision trees or linear\nmodels) and differentiable distance functions. In contrast, we build on\nstandard theory and tools from formal verification and propose a novel\nalgorithm that solves a sequence of satisfiability problems, where both the\ndistance function (objective) and predictive model (constraints) are\nrepresented as logic formulae. As shown by our experiments on real-world data,\nour algorithm is: i) model-agnostic ({non-}linear, {non-}differentiable,\n{non-}convex); ii) data-type-agnostic (heterogeneous features); iii)\ndistance-agnostic ($\\ell_0, \\ell_1, \\ell_\\infty$, and combinations thereof);\niv) able to generate plausible and diverse counterfactuals for any sample\n(i.e., 100% coverage); and v) at provably optimal distances.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:22:39 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 08:00:19 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 10:21:41 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 16:49:52 GMT"}, {"version": "v5", "created": "Fri, 28 Feb 2020 16:24:45 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["Barthe", "Gilles", ""], ["Balle", "Borja", ""], ["Valera", "Isabel", ""]]}, {"id": "1905.11226", "submitter": "Farhad Shakerin", "authors": "Farhad Shakerin, Gopal Gupta", "title": "Induction of Non-Monotonic Rules From Statistical Learning Models Using\n  High-Utility Itemset Mining", "comments": "arXiv admin note: text overlap with arXiv:1808.00629", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast and scalable algorithm to induce non-monotonic logic\nprograms from statistical learning models. We reduce the problem of search for\nbest clauses to instances of the High-Utility Itemset Mining (HUIM) problem. In\nthe HUIM problem, feature values and their importance are treated as\ntransactions and utilities respectively. We make use of TreeExplainer, a fast\nand scalable implementation of the Explainable AI tool SHAP, to extract locally\nimportant features and their weights from ensemble tree models. Our experiments\nwith UCI standard benchmarks suggest a significant improvement in terms of\nclassification evaluation metrics and running time of the training algorithm\ncompared to ALEPH, a state-of-the-art Inductive Logic Programming (ILP) system.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 06:05:10 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 02:53:52 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Shakerin", "Farhad", ""], ["Gupta", "Gopal", ""]]}, {"id": "1905.11537", "submitter": "Nicolas Markey", "authors": "Patricia Bouyer, Orna Kupferman, Nicolas Markey, Bastien Maubert,\n  Aniello Murano, and Giuseppe Perelli", "title": "Reasoning about Quality and Fuzziness of Strategic Behaviours", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal logics are extensively used for the specification of on-going\nbehaviours of reactive systems. Two significant developments in this area are\nthe extension of traditional temporal logics with modalities that enable the\nspecification of on-going strategic behaviours in multi-agent systems, and the\ntransition of temporal logics to a quantitative setting, where different\nsatisfaction values enable the specifier to formalise concepts such as\ncertainty or quality. We introduce and study FSL---a quantitative extension of\nSL (Strategy Logic), one of the most natural and expressive logics describing\nstrategic behaviours. The satisfaction value of an FSL formula is a real value\nin [0,1], reflecting `how much' or `how well' the strategic on-going objectives\nof the underlying agents are satisfied. We demonstrate the applications of FSL\nin quantitative reasoning about multi-agent systems, by showing how it can\nexpress concepts of stability in multi-agent systems, and how it generalises\nsome fuzzy temporal logics. We also provide a model-checking algorithm for our\nlogic, based on a quantitative extension of Quantified CTL*.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 23:11:44 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Bouyer", "Patricia", ""], ["Kupferman", "Orna", ""], ["Markey", "Nicolas", ""], ["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Perelli", "Giuseppe", ""]]}, {"id": "1905.11625", "submitter": "Mingshuai Chen", "authors": "Mingshuai Chen, Jian Wang, Jie An, Bohua Zhan, Deepak Kapur, and\n  Naijun Zhan", "title": "NIL: Learning Nonlinear Interpolants", "comments": "Full version of the paper in Proc. of CADE-27, with typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear interpolants have been shown useful for the verification of\nprograms and hybrid systems in contexts of theorem proving, model checking,\nabstract interpretation, etc. The underlying synthesis problem, however, is\nchallenging and existing methods have limitations on the form of formulae to be\ninterpolated. We leverage classification techniques with space transformations\nand kernel tricks as established in the realm of machine learning, and present\na counterexample-guided method named NIL for synthesizing polynomial\ninterpolants, thereby yielding a unified framework tackling the interpolation\nproblem for the general quantifier-free theory of nonlinear arithmetic,\npossibly involving transcendental functions. We prove the soundness of NIL and\npropose sufficient conditions under which NIL is guaranteed to converge, i.e.,\nthe derived sequence of candidate interpolants converges to an actual\ninterpolant, and is complete, namely the algorithm terminates by producing an\ninterpolant if there exists one. The applicability and effectiveness of our\ntechnique are demonstrated experimentally on a collection of representative\nbenchmarks from the literature, where in particular, our method suffices to\naddress more interpolation tasks, including those with perturbations in\nparameters, and in many cases synthesizes simpler interpolants compared with\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:19:44 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 11:39:26 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 08:20:57 GMT"}, {"version": "v4", "created": "Mon, 26 Aug 2019 03:47:27 GMT"}, {"version": "v5", "created": "Wed, 28 Aug 2019 12:41:54 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Chen", "Mingshuai", ""], ["Wang", "Jian", ""], ["An", "Jie", ""], ["Zhan", "Bohua", ""], ["Kapur", "Deepak", ""], ["Zhan", "Naijun", ""]]}, {"id": "1905.11733", "submitter": "Nao Hirokawa", "authors": "Nao Hirokawa, Julian Nagele, Vincent van Oostrom, and Michio\n  Oyamaguchi", "title": "Confluence by Critical Pair Analysis Revisited (Extended Version)", "comments": "Added a reference to the conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two methods for proving confluence of left-linear term rewrite\nsystems. One is hot-decreasingness, combining the parallel/development\nclosedness theorems with rule labelling based on a terminating subsystem. The\nother is critical-pair-closing system, allowing to boil down the confluence\nproblem to confluence of a special subsystem whose duplicating rules are\nrelatively terminating.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 10:46:05 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 04:47:15 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hirokawa", "Nao", ""], ["Nagele", "Julian", ""], ["van Oostrom", "Vincent", ""], ["Oyamaguchi", "Michio", ""]]}, {"id": "1905.11958", "submitter": "Harun Siljak", "authors": "Anna Philippou, Kyriaki Psara and Harun Siljak", "title": "Controlling Reversibility in Reversing Petri Nets with Application to\n  Wireless Communications", "comments": "RC 2019", "journal-ref": null, "doi": "10.1007/978-3-030-21500-2_15", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Petri nets are a formalism for modelling and reasoning about the behaviour of\ndistributed systems. Recently, a reversible approach to Petri nets, Reversing\nPetri Nets (RPN), has been proposed, allowing transitions to be reversed\nspontaneously in or out of causal order. In this work we propose an approach\nfor controlling the reversal of actions of an RPN, by associating transitions\nwith conditions whose satisfaction/violation allows the execution of\ntransitions in the forward/reversed direction, respectively. We illustrate the\nframework with a model of a novel, distributed algorithm for antenna selection\nin distributed antenna arrays.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:28:54 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Philippou", "Anna", ""], ["Psara", "Kyriaki", ""], ["Siljak", "Harun", ""]]}, {"id": "1905.12071", "submitter": "Blai Bonet", "authors": "Blai Bonet, Raquel Fuentetaja, Yolanda E-Martin, Daniel Borrajo", "title": "Guarantees for Sound Abstractions for Generalized Planning (Extended\n  Paper)", "comments": "This paper extends IJCAI-19 paper with an appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized planning is about finding plans that solve collections of\nplanning instances, often infinite collections, rather than single instances.\nRecently it has been shown how to reduce the planning problem for generalized\nplanning to the planning problem for a qualitative numerical problem; the\nlatter being a reformulation that simultaneously captures all the instances in\nthe collection. An important thread of research thus consists in finding such\nreformulations, or abstractions, automatically. A recent proposal learns the\nabstractions inductively from a finite and small sample of transitions from\ninstances in the collection. However, as in all inductive processes, the\nlearned abstraction is not guaranteed to be correct for the whole collection.\nIn this work we address this limitation by performing an analysis of the\nabstraction with respect to the collection, and show how to obtain formal\nguarantees for generalization. These guarantees, in the form of first-order\nformulas, may be used to 1) define subcollections of instances on which the\nabstraction is guaranteed to be sound, 2) obtain necessary conditions for\ngeneralization under certain assumptions, and 3) do automated synthesis of\ncomplex invariants for planning problems. Our framework is general, it can be\nextended or combined with other approaches, and it has applications that go\nbeyond generalized planning.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:23:53 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:18:07 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Bonet", "Blai", ""], ["Fuentetaja", "Raquel", ""], ["E-Martin", "Yolanda", ""], ["Borrajo", "Daniel", ""]]}, {"id": "1905.12262", "submitter": "Antonio Bruto da Costa", "authors": "Antonio Anastasio Bruto da Costa and Pallab Dasgupta", "title": "Learning Temporal Causal Sequence Relationships from Real-Time\n  Time-Series", "comments": "This article appears in the Journal of Artificial Intelligence", "journal-ref": "Journal of Artificial Intelligence Research, Volume 70 (2021)\n  205-243", "doi": "10.1613/jair.1.12395", "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to mine temporal causal sequences that explain observed events\n(consequents) in time-series traces. Causal explanations of key events in a\ntime-series has applications in design debugging, anomaly detection, planning,\nroot-cause analysis and many more. We make use of decision trees and interval\narithmetic to mine sequences that explain defining events in the time-series.\nWe propose modified decision tree construction metrics to handle the\nnon-determinism introduced by the temporal dimension. The mined sequences are\nexpressed in a readable temporal logic language that is easy to interpret. The\napplication of the proposed methodology is illustrated through various\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 07:55:55 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 10:40:20 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 11:39:02 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 15:29:02 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 13:07:07 GMT"}, {"version": "v6", "created": "Sun, 24 Jan 2021 21:50:40 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["da Costa", "Antonio Anastasio Bruto", ""], ["Dasgupta", "Pallab", ""]]}, {"id": "1905.12422", "submitter": "Bastien Maubert", "authors": "Bastien Maubert, Sophie Pinchinat, Fran\\c{c}ois Schwarzentruber", "title": "Reachability Games in Dynamic Epistemic Logic", "comments": "Long version of a work accepted at the conference IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define reachability games based on Dynamic Epistemic Logic (DEL), where\nthe players' actions are finely described as DEL action models. We first\nconsider the setting where an external controller with perfect information\ninteracts with an environment and aims at reaching some epistemic goal state\nregarding the passive agents of the system. We study the problem of strategy\nexistence for the controller, which generalises the classic epistemic planning\nproblem, and we solve it for several types of actions such as public\nannouncements and public actions. We then consider a yet richer setting where\nagents themselves are players, whose strategies must be based on their\nobservations. We establish several (un)decidability results for the problem of\nexistence of a distributed strategy, depending on the type of actions the\nplayers can use, and relate them to results from the literature on multiplayer\ngames with imperfect information.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:27:06 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Maubert", "Bastien", ""], ["Pinchinat", "Sophie", ""], ["Schwarzentruber", "Fran\u00e7ois", ""]]}, {"id": "1905.12524", "submitter": "Viorica  Sofronie-Stokkermans", "authors": "Dennis Peuter and Viorica Sofronie-Stokkermans", "title": "On Invariant Synthesis for Parametric Systems", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study possibilities for automated invariant generation in parametric\nsystems. We use (a refinement of) an algorithm for symbol elimination in theory\nextensions to devise a method for iteratively strengthening certain classes of\nsafety properties to obtain invariants of the system. We identify conditions\nunder which the method is correct and complete, and situations in which the\nmethod is guaranteed to terminate. We illustrate the ideas on various examples.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 15:22:00 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Peuter", "Dennis", ""], ["Sofronie-Stokkermans", "Viorica", ""]]}, {"id": "1905.12594", "submitter": "Hengchu Zhang", "authors": "Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, Aaron\n  Roth", "title": "Fuzzi: A Three-Level Logic for Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curators of sensitive datasets sometimes need to know whether queries against\nthe data are differentially private [Dwork et al. 2006]. Two sorts of logics\nhave been proposed for checking this property: (1) type systems and other\nstatic analyses, which fully automate straightforward reasoning with concepts\nlike \"program sensitivity\" and \"privacy loss,\" and (2) full-blown program\nlogics such as apRHL (an approximate, probabilistic, relational Hoare logic)\n[Barthe et al. 2016], which support more flexible reasoning about subtle\nprivacy-preserving algorithmic techniques but offer only minimal automation.\n  We propose a three-level logic for differential privacy in an imperative\nsetting and present a prototype implementation called Fuzzi. Fuzzi's lowest\nlevel is a general-purpose logic; its middle level is apRHL; and its top level\nis a novel sensitivity logic adapted from the linear-logic-inspired type system\nof Fuzz, a differentially private functional language [Reed and Pierce 2010].\nThe key novelty is a high degree of integration between the sensitivity logic\nand the two lower-level logics: the judgments and proofs of the sensitivity\nlogic can be easily translated into apRHL; conversely, privacy properties of\nkey algorithmic building blocks can be proved manually in apRHL and the base\nlogic, then packaged up as typing rules that can be applied by a checker for\nthe sensitivity logic to automatically construct privacy proofs for composite\nprograms of arbitrary size.\n  We demonstrate Fuzzi's utility by implementing four different private\nmachine-learning algorithms and showing that Fuzzi's checker is able to derive\ntight sensitivity bounds.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:13:41 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Zhang", "Hengchu", ""], ["Roth", "Edo", ""], ["Haeberlen", "Andreas", ""], ["Pierce", "Benjamin C.", ""], ["Roth", "Aaron", ""]]}, {"id": "1905.12944", "submitter": "Kirill Krinkin", "authors": "Ren\\'e Haberland, Kirill Krinkin", "title": "A Non-repetitive Logic for Verification of Dynamic Memory with Explicit\n  Heap Conjunction and Disjunction", "comments": "9 pages, 7 figures", "journal-ref": "IARIA ADVCOMP, Oct.2016, p.1-9, ISBN 978-1-61208-506-7, ISSN\n  2308-4499", "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we review existing points-to Separation Logics for dynamic\nmemory reasoning and we find that different usages of heap separation tend to\nbe an obstacle. Hence, two total and strict spatial heap operations are\nproposed upon heap graphs, for conjunction and disjunction -- similar to\nlogical conjuncts. Heap conjunction implies that there exists a free heap\nvertex to connect to or an explicit destination vertex is provided.\nEssentially, Burstall's properties do not change. By heap we refer to an\narbitrary simple directed graph, which is finite and may contain composite\nvertices representing class objects. Arbitrary heap memory access is\nrestricted, as well as type punning, late class binding and further\nrestrictions. Properties of the new logic are investigated, and as a result\ngroup properties are shown. Both expecting and superficial heaps are\nspecifiable. Equivalence transformations may make denotated heaps inconsistent,\nalthough those may be detected and patched by the two generic linear\ncanonization steps presented. The properties help to motivate a later full\nintroduction of a set of equivalences over heap for future work. Partial heaps\nare considered as a useful specification technique that help to reduce\nincompleteness issues with specifications. Finally, the logic proposed may be\nconsidered for extension for the Object Constraint Language.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:18:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Haberland", "Ren\u00e9", ""], ["Krinkin", "Kirill", ""]]}, {"id": "1905.12990", "submitter": "Vladislav Ryzhikov Dr", "authors": "Vladislav Ryzhikov, Przemyslaw Andrzej Walega, Michael Zakharyaschev", "title": "Data Complexity and Rewritability of Ontology-Mediated Queries in Metric\n  Temporal Logic under the Event-Based Semantics (Full Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the data complexity of answering queries mediated by metric\ntemporal logic ontologies under the event-based semantics assuming that data\ninstances are finite timed words timestamped with binary fractions. We identify\nclasses of ontology-mediated queries answering which can be done in AC0, NC1,\nL, NL, P, and coNP for data complexity, provide their rewritings to first-order\nlogic and its extensions with primitive recursion, transitive closure or\ndatalog, and establish lower complexity bounds.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:08:28 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 09:14:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Ryzhikov", "Vladislav", ""], ["Walega", "Przemyslaw Andrzej", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1905.12991", "submitter": "Alessandro Gianola", "authors": "Diego Calvanese, Silvio Ghilardi, Alessandro Gianola, Marco Montali,\n  Andrey Rivkin", "title": "Formal Modeling and SMT-Based Parameterized Verification of Multi-Case\n  Data-Aware BPMN", "comments": "This article builds upon arXiv:1906.07811, extending it in two\n  respects. First, while arXiv:1906.07811 focuses on the verification of DABs\n  considering a single, running case, we consider here the possibility of\n  (unboundedly many) cases running concurrently. Second, we provide full proofs\n  of the technical results, including those from arXiv:1906.07811 and those for\n  this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DAB -- a data-aware extension of the BPMN de-facto standard with\nthe ability of operating over case and persistent data (partitioned into a\nread-only catalog and a read-write repository), and that balances between\nexpressiveness and the possibility of supporting parameterized verification of\nsafety properties on top of it. In particular, we take inspiration from the\nliterature on verification of artifact systems, and consider verification\nproblems where safety properties are checked irrespectively of the content of\nthe read-only catalog, possibly considering an unbounded number of active cases\nand tuples in the catalog and repository. Such problems are tackled using fully\nimplemented array-based backward reachability techniques belonging to the\nwell-established tradition of SMT model checking. We also identify relevant\nclasses of DABs for which the backward reachability procedure implemented in\nthe MCMT array-based model checker is sound and complete, and then further\nstrengthen such classes to ensure termination.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:09:19 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 00:41:38 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 15:03:14 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Calvanese", "Diego", ""], ["Ghilardi", "Silvio", ""], ["Gianola", "Alessandro", ""], ["Montali", "Marco", ""], ["Rivkin", "Andrey", ""]]}, {"id": "1905.13100", "submitter": "Zsolt Zombori", "authors": "Zsolt Zombori, Adri\\'an Csisz\\'arik, Henryk Michalewski, Cezary\n  Kaliszyk, Josef Urban", "title": "Towards Finding Longer Proofs", "comments": "16 pages, 3 figures, published at TABLEAUX2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning (RL) based guidance system for automated\ntheorem proving geared towards Finding Longer Proofs (FLoP). Unlike most\nlearning based approaches, we focus on generalising from very little training\ndata and achieving near complete confidence. We use several simple, structured\ndatasets with very long proofs to show that FLoP can successfully generalise a\nsingle training proof to a large class of related problems. On these\nbenchmarks, FLoP is competitive with strong theorem provers despite using very\nlimited search, due to its ability to solve problems that are prohibitively\nlong for other systems.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:23:26 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 14:15:58 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zombori", "Zsolt", ""], ["Csisz\u00e1rik", "Adri\u00e1n", ""], ["Michalewski", "Henryk", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1905.13157", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "Rules with parameters in modal logic II", "comments": "67 pages", "journal-ref": "Annals of Pure and Applied Logic 171 (2020), no. 10, article no.\n  102829", "doi": "10.1016/j.apal.2020.102829", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the computational complexity of admissibility and unifiability\nwith parameters in transitive modal logics. The class of cluster-extensible\n(clx) logics was introduced in the first part of this series of papers. We\ncompletely classify the complexity of unifiability or inadmissibility in any\nclx logic as being complete for one of $\\Sigma^{\\exp}_2$, NEXP, coNEXP, PSPACE,\nor $\\Pi^p_2$. In addition to the main case where arbitrary parameters are\nallowed, we consider restricted problems with the number of parameters bounded\nby a constant, and the parameter-free case. Our upper bounds are specific to\nclx logics, but we also include similar results for logics of bounded depth and\nwidth. In contrast, our lower bounds are very general: they apply each to a\nclass of all transitive logics whose frames allow occurrence of certain finite\nsubframes. We also discuss the baseline problem of complexity of derivability:\nit is coNP-complete or PSPACE-complete for each clx logic. In particular, we\nprove PSPACE-hardness of derivability for a broad class of transitive logics\nthat includes all logics with the disjunction property.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:27:12 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 17:18:21 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "1905.13190", "submitter": "Sandra Kiefer", "authors": "Miko{\\l}aj Boja\\'nczyk, Sandra Kiefer, Nathan Lhote", "title": "String-to-String Interpretations with Polynomial-Size Output", "comments": "35 pages, full version of a paper accepted for the 46th International\n  Colloquium on Automata, Languages and Programming (ICALP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String-to-string MSO interpretations are like Courcelle's MSO transductions,\nexcept that a single output position can be represented using a tuple of input\npositions instead of just a single input position. In particular, the output\nlength is polynomial in the input length, as opposed to MSO transductions,\nwhich have output of linear length. We show that string-to-string MSO\ninterpretations are exactly the polyregular functions. The latter class has\nvarious characterizations, one of which is that it consists of the\nstring-to-string functions recognized by pebble transducers.\n  Our main result implies the surprising fact that string-to-string MSO\ninterpretations are closed under composition.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:21:26 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", ""], ["Kiefer", "Sandra", ""], ["Lhote", "Nathan", ""]]}, {"id": "1905.13411", "submitter": "Markus N Rabe", "authors": "Markus N. Rabe, Leander Tentrup, Cameron Rasmussen, and Sanjit A.\n  Seshia", "title": "Understanding and Extending Incremental Determinization for 2QBF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental determinization is a recently proposed algorithm for solving\nquantified Boolean formulas with one quantifier alternation. In this paper, we\nformalize incremental determinization as a set of inference rules to help\nunderstand the design space of similar algorithms. We then present additional\ninference rules that extend incremental determinization in two ways. The first\nextension integrates the popular CEGAR principle and the second extension\nallows us to analyze different cases in isolation. The experimental evaluation\ndemonstrates that the extensions significantly improve the performance.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 04:35:07 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Rabe", "Markus N.", ""], ["Tentrup", "Leander", ""], ["Rasmussen", "Cameron", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1905.13429", "submitter": "Andr\\'e Platzer", "authors": "Andr\\'e Platzer and Yong Kiam Tan", "title": "Differential Equation Invariance Axiomatization", "comments": "Significantly extended version of arXiv:1802.01226", "journal-ref": "J. ACM 67(1), Article 6, 2020, 66 pages", "doi": "10.1145/3380825", "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proves the completeness of an axiomatization for differential\nequation invariants described by Noetherian functions. First, the differential\nequation axioms of differential dynamic logic are shown to be complete for\nreasoning about analytic invariants. Completeness crucially exploits\ndifferential ghosts, which introduce additional variables that can be chosen to\nevolve freely along new differential equations. Cleverly chosen differential\nghosts are the proof-theoretical counterpart of dark matter. They create new\nhypothetical state, whose relationship to the original state variables\nsatisfies invariants that did not exist before. The reflection of these new\ninvariants in the original system then enables its analysis.\n  An extended axiomatization with existence and uniqueness axioms is complete\nfor all local progress properties, and, with a real induction axiom, is\ncomplete for all semianalytic invariants. This parsimonious axiomatization\nserves as the logical foundation for reasoning about invariants of differential\nequations. Indeed, it is precisely this logical treatment that enables the\ngeneralization of completeness to the Noetherian case.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:04:32 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 02:26:02 GMT"}, {"version": "v3", "created": "Sat, 8 Feb 2020 01:55:19 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Platzer", "Andr\u00e9", ""], ["Tan", "Yong Kiam", ""]]}, {"id": "1905.13467", "submitter": "Lo\\\"ic Paulev\\'e", "authors": "Thomas Chatain, Stefan Haar, Juraj Kol\\v{c}\\'ak, Lo\\\"ic Paulev\\'e,\n  Aalok Thakkar", "title": "Concurrency in Boolean networks", "comments": "Accepted in Natural Computing, 2019", "journal-ref": null, "doi": "10.1007/s11047-019-09748-4", "report-no": null, "categories": "cs.LO cs.DM cs.FL q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean networks (BNs) are widely used to model the qualitative dynamics of\nbiological systems. Besides the logical rules determining the evolution of each\ncomponent with respect to the state of its regulators, the scheduling of\ncomponent updates can have a dramatic impact on the predicted behaviours. In\nthis paper, we explore the use of Read (contextual) Petri Nets (RPNs) to study\ndynamics of BNs from a concurrency theory perspective. After showing\nbi-directional translations between RPNs and BNs and analogies between results\non synchronism sensitivity, we illustrate that usual updating modes for BNs can\nmiss plausible behaviours, i.e., incorrectly conclude on the\nabsence/impossibility of reaching specific configurations. We propose an\nencoding of BNs capitalizing on the RPN semantics enabling more behaviour than\nthe generalized asynchronous updating mode. The proposed encoding ensures a\ncorrect abstraction of any multivalued refinement, as one may expect to achieve\nwhen modelling biological systems with no assumption on its time features.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 09:01:08 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Chatain", "Thomas", ""], ["Haar", "Stefan", ""], ["Kol\u010d\u00e1k", "Juraj", ""], ["Paulev\u00e9", "Lo\u00efc", ""], ["Thakkar", "Aalok", ""]]}, {"id": "1905.13511", "submitter": "Christopher Hahn", "authors": "Bernd Finkbeiner, Christopher Hahn, Philip Lukert, Marvin Stenger,\n  Leander Tentrup", "title": "Synthesizing Reactive Systems from Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reactive synthesis problem for hyperproperties given as formulas\nof the temporal logic HyperLTL. Hyperproperties generalize trace properties,\ni.e., sets of traces, to sets of sets of traces. Typical examples are\ninformation-flow policies like noninterference, which stipulate that no\nsensitive data must leak into the public domain. Such properties cannot be\nexpressed in standard linear or branching-time temporal logics like LTL, CTL,\nor CTL$^*$. We show that, while the synthesis problem is undecidable for full\nHyperLTL, it remains decidable for the $\\exists^*$, $\\exists^*\\forall^1$, and\nthe $\\mathit{linear}\\;\\forall^*$ fragments. Beyond these fragments, the\nsynthesis problem immediately becomes undecidable. For universal HyperLTL, we\npresent a semi-decision procedure that constructs implementations and\ncounterexamples up to a given bound. We report encouraging experimental results\nobtained with a prototype implementation on example specifications with\nhyperproperties like symmetric responses, secrecy, and information-flow.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 11:09:20 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Hahn", "Christopher", ""], ["Lukert", "Philip", ""], ["Stenger", "Marvin", ""], ["Tentrup", "Leander", ""]]}, {"id": "1905.13514", "submitter": "Christopher Hahn", "authors": "Bernd Finkbeiner, Christopher Hahn, Hazem Torfah", "title": "Model Checking Quantitative Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties are properties of sets of computation traces. In this paper,\nwe study quantitative hyperproperties, which we define as hyperproperties that\nexpress a bound on the number of traces that may appear in a certain relation.\nFor example, quantitative non-interference limits the amount of information\nabout certain secret inputs that is leaked through the observable outputs of a\nsystem. Quantitative non-interference thus bounds the number of traces that\nhave the same observable input but different observable output. We study\nquantitative hyperproperties in the setting of HyperLTL, a temporal logic for\nhyperproperties. We show that, while quantitative hyperproperties can be\nexpressed in HyperLTL, the running time of the HyperLTL model checking\nalgorithm is, depending on the type of property, exponential or even doubly\nexponential in the quantitative bound. We improve this complexity with a new\nmodel checking algorithm based on model-counting. The new algorithm needs only\nlogarithmic space in the bound and therefore improves, depending on the\nproperty, exponentially or even doubly exponentially over the model checking\nalgorithm of HyperLTL. In the worst case, the new algorithm needs polynomial\nspace in the size of the system. Our Max#Sat-based prototype implementation\ndemonstrates, however, that the counting approach is viable on systems with\nnontrivial quantitative information flow requirements such as a passcode\nchecker.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 11:16:45 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Hahn", "Christopher", ""], ["Torfah", "Hazem", ""]]}, {"id": "1905.13517", "submitter": "Christopher Hahn", "authors": "Christopher Hahn, Marvin Stenger, Leander Tentrup", "title": "Constraint-Based Monitoring of Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying hyperproperties at runtime is a challenging problem as\nhyperproperties, such as non-interference and observational determinism, relate\nmultiple computation traces with each other. It is necessary to store\npreviously seen traces, because every new incoming trace needs to be compatible\nwith every run of the system observed so far. Furthermore, the new incoming\ntrace poses requirements on future traces. In our monitoring approach, we focus\non those requirements by rewriting a hyperproperty in the temporal logic\nHyperLTL to a Boolean constraint system. A hyperproperty is then violated by\nmultiple runs of the system if the constraint system becomes unsatisfiable. We\ncompare our implementation, which utilizes either BDDs or a SAT solver to store\nand evaluate constraints, to the automata-based monitoring tool RVHyper.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 11:22:14 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hahn", "Christopher", ""], ["Stenger", "Marvin", ""], ["Tentrup", "Leander", ""]]}]