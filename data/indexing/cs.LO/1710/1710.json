[{"id": "1710.00787", "submitter": "Michael Beeson", "authors": "Michael Beeson and Julien Narboux and Freek Wiedijk", "title": "Proof-checking Euclid", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We used computer proof-checking methods to verify the correctness of our\nproofs of the propositions in Euclid Book I. We used axioms as close as\npossible to those of Euclid, in a language closely related to that used in\nTarski's formal geometry. We used proofs as close as possible to those given by\nEuclid, but filling Euclid's gaps and correcting errors. Euclid Book I has 48\npropositions, we proved 235 theorems. The extras were partly \"Book Zero\",\npreliminaries of a very fundamental nature, partly propositions that Euclid\nomitted but were used implicitly, partly advanced theorems that we found\nnecessary to fill Euclid's gaps, and partly just variants of Euclid's\npropositions. We wrote these proofs in a simple fragment of first-order logic\ncorresponding to Euclid's logic, debugged them using a custom software tool,\nand then checked them in the well-known and trusted proof checkers HOL Light\nand Coq.\n", "versions": [{"version": "v1", "created": "Mon, 2 Oct 2017 16:57:09 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 22:57:42 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Beeson", "Michael", ""], ["Narboux", "Julien", ""], ["Wiedijk", "Freek", ""]]}, {"id": "1710.02198", "submitter": "Mikolas Janota", "authors": "Mikol\\'a\\v{s} Janota", "title": "QFUN: Towards Machine Learning in QBF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on the QBF solver QFUN that has won the non-CNF track in\nthe recent QBF evaluation. The solver is motivated by the fact that it is easy\nto construct Quantified Boolean Formulas (QBFs) with short winning strategies\n(Skolem/Herbrand functions) but are hard to solve by nowadays solvers. This\npaper argues that a solver benefits from generalizing a set of individual wins\ninto a strategy. This idea is realized on top of the competitive RAReQS\nalgorithm by utilizing machine learning. The results of the implemented\nprototype are highly encouraging.\n", "versions": [{"version": "v1", "created": "Thu, 5 Oct 2017 20:10:50 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Janota", "Mikol\u00e1\u0161", ""]]}, {"id": "1710.02332", "submitter": "L\\'eo Stefanesco", "authors": "Paul-Andr\\'e Melli\\`es and L\\'eo Stefanesco", "title": "A Game Semantics of Concurrent Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a game-theoretic account of concurrent separation\nlogic. To every execution trace of the Code confronted to the Environment, we\nassociate a specification game where Eve plays for the Code, and Adam for the\nEnvironment. The purpose of Eve and Adam is to decompose every intermediate\nmachine state of the execution trace into three pieces: one piece for the Code,\none piece for the Environment, and one piece for the available shared\nresources. We establish the soundness of concurrent separation logic by\ninterpreting every derivation tree of the logic as a winning strategy of this\nspecification game.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 09:57:40 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Melli\u00e8s", "Paul-Andr\u00e9", ""], ["Stefanesco", "L\u00e9o", ""]]}, {"id": "1710.02594", "submitter": "Danel Ahman", "authors": "Danel Ahman", "title": "Fibred Computational Effects", "comments": "PhD thesis. Final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependent types provide a lightweight and modular means to integrate\nprogramming and formal program verification. In particular, the types of\nprograms written in dependently typed programming languages (Agda, Idris, F*,\netc.) can be used to express specifications of program correctness. These\nspecifications can vary from being as simple as requiring the divisor in the\ndivision function to be non-zero, to as complex as specifying the correctness\nof compilers of industrial-strength languages. Successful compilation of a\nprogram then guarantees that it satisfies its type-based specification.\n  While dependent types allow many runtime errors to be eliminated by rejecting\nerroneous programs at compile-time, dependently typed languages are yet to gain\npopularity in the wider programming community. One reason for this is their\nlimited support for computational effects, an integral part of all widely used\nprogramming languages, ranging from imperative languages, such as C, to\nfunctional languages, such as ML and Haskell. For example, in addition to\nsimply turning their inputs to outputs, programs written in these programming\nlanguages can raise exceptions, access computer's memory, communicate over a\nnetwork, render images on a screen, etc.\n  Therefore, if dependently typed programming languages are to truly live up to\ntheir promise of seamlessly integrating programming and formal program\nverification, we must first understand how to properly account for\ncomputational effects in such languages. While there already exists work on\nthis topic, ingredients needed for a comprehensive theory are generally\nmissing. For example, foundations are often not settled; available effects may\nbe limited; or effects may not be treated systematically.\n  In this thesis we address these shortcomings by providing a comprehensive\ntreatment of the combination of dependent types and general computational\neffects.\n", "versions": [{"version": "v1", "created": "Fri, 6 Oct 2017 21:36:20 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Ahman", "Danel", ""]]}, {"id": "1710.02723", "submitter": "Anthony Bordg", "authors": "Anthony Bordg", "title": "Univalent Foundations and the UniMath Library", "comments": null, "journal-ref": "In: Centrone S., Kant D., Sarikaya D. (eds) Reflections on the\n  Foundations of Mathematics. Synthese Library, vol 407, 2019. Springer, Cham", "doi": "10.1007/978-3-030-15655-8_8", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a concise presentation of the Univalent Foundations of mathematics\noutlining the main ideas, followed by a discussion of the UniMath library of\nformalized mathematics implementing the ideas of the Univalent Foundations\n(section 1), and the challenges one faces in attempting to design a large-scale\nlibrary of formalized mathematics (section 2). This leads us to a general\ndiscussion about the links between architecture and mathematics where a meeting\nof minds is revealed between architects and mathematicians (section 3). On the\nway our odyssey from the foundations to the \"horizon\" of mathematics will lead\nus to meet the mathematicians David Hilbert and Nicolas Bourbaki as well as the\narchitect Christopher Alexander.\n", "versions": [{"version": "v1", "created": "Sat, 7 Oct 2017 19:13:44 GMT"}, {"version": "v2", "created": "Sun, 15 Oct 2017 19:30:21 GMT"}, {"version": "v3", "created": "Tue, 14 Nov 2017 16:09:39 GMT"}, {"version": "v4", "created": "Wed, 29 Aug 2018 13:54:59 GMT"}, {"version": "v5", "created": "Mon, 17 Sep 2018 12:56:57 GMT"}, {"version": "v6", "created": "Tue, 25 Sep 2018 10:56:12 GMT"}, {"version": "v7", "created": "Sun, 17 Nov 2019 17:34:35 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bordg", "Anthony", ""]]}, {"id": "1710.02770", "submitter": "EPTCS", "authors": "Alex Groce (Northern Arizona University, USA), Stefan Leue (University\n  of Konstanz, Germany)", "title": "Proceedings 2nd International Workshop on Causal Reasoning for Embedded\n  and safety-critical Systems Technologies", "comments": null, "journal-ref": "EPTCS 259, 2017", "doi": "10.4204/EPTCS.259", "report-no": null, "categories": "cs.LO cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The second international CREST workshop continued the focus of the first\nCREST workshop: addressing approaches to causal reasoning in engineering\ncomplex embedded and safety-critical systems. Relevant approaches to causal\nreasoning have been (usually independently) proposed by a variety of\ncommunities: AI, concurrency, model-based diagnosis, software engineering,\nsecurity engineering, and formal methods. The goal of CREST is to bring\ntogether researchers and practitioners from these communities to exchange\nideas, especially between communities, in order to advance the science of\ndetermining root cause(s) for failures of critical systems. The growing\ncomplexity of failures such as power grid blackouts, airplane crashes, security\nand privacy violations, and malfunctioning medical devices or automotive\nsystems makes the goals of CREST more relevant than ever before.\n", "versions": [{"version": "v1", "created": "Sun, 8 Oct 2017 02:41:19 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Groce", "Alex", "", "Northern Arizona University, USA"], ["Leue", "Stefan", "", "University\n  of Konstanz, Germany"]]}, {"id": "1710.03021", "submitter": "Simon Docherty", "authors": "Simon Docherty and David Pym", "title": "Stone-Type Dualities for Separation Logics", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (March 14,\n  2019) lmcs:5284", "doi": "10.23638/LMCS-15(1:27)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stone-type duality theorems, which relate algebraic and\nrelational/topological models, are important tools in logic because -- in\naddition to elegant abstraction -- they strengthen soundness and completeness\nto a categorical equivalence, yielding a framework through which both algebraic\nand topological methods can be brought to bear on a logic. We give a systematic\ntreatment of Stone-type duality for the structures that interpret bunched\nlogics, starting with the weakest systems, recovering the familiar BI and\nBoolean BI (BBI), and extending to both classical and intuitionistic Separation\nLogic. We demonstrate the uniformity and modularity of this analysis by\nadditionally capturing the bunched logics obtained by extending BI and BBI with\nmodalities and multiplicative connectives corresponding to disjunction,\nnegation and falsum. This includes the logic of separating modalities (LSM), De\nMorgan BI (DMBI), Classical BI (CBI), and the sub-classical family of logics\nextending Bi-intuitionistic (B)BI (Bi(B)BI). We additionally obtain as\ncorollaries soundness and completeness theorems for the specific Kripke-style\nmodels of these logics as presented in the literature: for DMBI, the\nsub-classical logics extending BiBI and a new bunched logic, Concurrent Kleene\nBI (connecting our work to Concurrent Separation Logic), this is the first time\nsoundness and completeness theorems have been proved. We thus obtain a\ncomprehensive semantic account of the multiplicative variants of all standard\npropositional connectives in the bunched logic setting. This approach\nsynthesises a variety of techniques from modal, substructural and categorical\nlogic and contextualizes the \"resource semantics\" interpretation underpinning\nSeparation Logic amongst them.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 10:30:29 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 18:54:50 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 15:41:18 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Docherty", "Simon", ""], ["Pym", "David", ""]]}, {"id": "1710.03090", "submitter": "Noson S. Yanofsky", "authors": "Noson S. Yanofsky", "title": "Theoretical Computer Science for the Working Category Theorist", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical computer science discusses foundational issues about\ncomputations. It asks and answers questions such as \"What is a computation?\",\n\"What is computable?\", \"What is efficiently computable?\",\"What is\ninformation?\", \"What is random?\", \"What is an algorithm?\", etc. We will present\nmany of the major themes and theorems with the basic language of category\ntheory. Surprisingly, many interesting theorems and concepts of theoretical\ncomputer science are easy consequences of functoriality and composition when\nyou look at the right categories and functors connecting them.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 19:19:00 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Yanofsky", "Noson S.", ""]]}, {"id": "1710.03107", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Georg N\\\"uhrenberg, Chung-Hao Huang, Harald Ruess", "title": "Verification of Binarized Neural Networks via Inter-Neuron Factoring", "comments": "Version 2: add proofs for hardness of PTAS approximability, remove\n  experiments on randomized examples and some not-so-important optimizations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of formal verification of Binarized Neural Networks\n(BNN), which have recently been proposed as a energy-efficient alternative to\ntraditional learning networks. The verification of BNNs, using the reduction to\nhardware verification, can be even more scalable by factoring computations\namong neurons within the same layer. By proving the NP-hardness of finding\noptimal factoring as well as the hardness of PTAS approximability, we design\npolynomial-time search heuristics to generate factoring solutions. The overall\nframework allows applying verification techniques to moderately-sized BNNs for\nembedded devices with thousands of neurons and inputs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 14:11:55 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 10:30:08 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["N\u00fchrenberg", "Georg", ""], ["Huang", "Chung-Hao", ""], ["Ruess", "Harald", ""]]}, {"id": "1710.03115", "submitter": "Thorsten Wissmann", "authors": "Hadrian Andradi and Weng Kin Ho", "title": "Topological Scott Convergence Theorem", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (March 22,\n  2019) lmcs:5302", "doi": "10.23638/LMCS-15(1:29)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, J. D. Lawson encouraged the domain theory community to consider the\nscientific program of developing domain theory in the wider context of $T_0$\nspaces instead of restricting to posets. In this paper, we respond to this\ncalling with an attempt to formulate a topological version of the Scott\nConvergence Theorem, i.e., an order-theoretic characterisation of those posets\nfor which the Scott-convergence $\\mathcal{S}$ is topological. To do this, we\nmake use of the $\\mathcal{ID}$ replacement principle to create topological\nanalogues of well-known domain-theoretic concepts, e.g.,\n$\\mathcal{I}$-continuous spaces correspond to continuous posets, as\n$\\mathcal{I}$-convergence corresponds to $\\mathcal{S}$-convergence. In this\npaper, we consider two novel topological concepts, namely, the\n$\\mathcal{I}$-stable spaces and the $\\mathcal{DI}$ spaces, and as a result we\nobtain some necessary (respectively, sufficient) conditions under which the\nconvergence structure $\\mathcal{I}$ is topological.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 14:21:05 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 07:40:33 GMT"}, {"version": "v3", "created": "Wed, 16 Jan 2019 07:05:16 GMT"}, {"version": "v4", "created": "Thu, 21 Mar 2019 11:12:57 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Andradi", "Hadrian", ""], ["Ho", "Weng Kin", ""]]}, {"id": "1710.03148", "submitter": "Stanislav Zivny", "authors": "Clement Carbonnel, Miguel Romero, Stanislav Zivny", "title": "The complexity of general-valued CSPs seen from the other side", "comments": "v2: Full version of a FOCS'18 paper; improved presentation and small\n  corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constraint satisfaction problem (CSP) is concerned with homomorphisms\nbetween two structures. For CSPs with restricted left-hand side structures, the\nresults of Dalmau, Kolaitis, and Vardi [CP'02], Grohe [FOCS'03/JACM'07], and\nAtserias, Bulatov, and Dalmau [ICALP'07] establish the precise borderline of\npolynomial-time solvability (subject to complexity-theoretic assumptions) and\nof solvability by bounded-consistency algorithms (unconditionally) as bounded\ntreewidth modulo homomorphic equivalence.\n  The general-valued constraint satisfaction problem (VCSP) is a generalisation\nof the CSP concerned with homomorphisms between two valued structures. For\nVCSPs with restricted left-hand side valued structures, we establish the\nprecise borderline of polynomial-time solvability (subject to\ncomplexity-theoretic assumptions) and of solvability by the $k$-th level of the\nSherali-Adams LP hierarchy (unconditionally). We also obtain results on related\nproblems concerned with finding a solution and recognising the tractable cases;\nthe latter has an application in database theory.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 15:32:14 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 16:31:28 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Carbonnel", "Clement", ""], ["Romero", "Miguel", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1710.03352", "submitter": "Robert Colvin", "authors": "Ian J. Hayes, Larissa A. Meinicke, Kirsten Winter, Robert J. Colvin", "title": "A synchronous program algebra: a basis for reasoning about shared-memory\n  and event-based concurrency", "comments": "Extended version of a Formal Methods 2016 paper, \"An algebra of\n  synchronous atomic steps\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research started with an algebra for reasoning about rely/guarantee\nconcurrency for a shared memory model. The approach taken led to a more\nabstract algebra of atomic steps, in which atomic steps synchronise (rather\nthan interleave) when composed in parallel. The algebra of rely/guarantee\nconcurrency then becomes an instantiation of the more abstract algebra. Many of\nthe core properties needed for rely/guarantee reasoning can be shown to hold in\nthe abstract algebra where their proofs are simpler and hence allow a higher\ndegree of automation. The algebra has been encoded in Isabelle/HOL to provide a\nbasis for tool support for program verification.\n  In rely/guarantee concurrency, programs are specified to guarantee certain\nbehaviours until assumptions about the behaviour of their environment are\nviolated. When assumptions are violated, program behaviour is unconstrained\n(aborting), and guarantees need no longer hold. To support these guarantees a\nsecond synchronous operator, weak conjunction, was introduced: both processes\nin a weak conjunction must agree to take each atomic step, unless one aborts in\nwhich case the whole aborts. In developing the laws for parallel and weak\nconjunction we found many properties were shared by the operators and that the\nproofs of many laws were essentially the same. This insight led to the idea of\ngeneralising synchronisation to an abstract operator with only the axioms that\nare shared by the parallel and weak conjunction operator, so that those two\noperators can be viewed as instantiations of the abstract synchronisation\noperator. The main differences between parallel and weak conjunction are how\nthey combine individual atomic steps; that is left open in the axioms for the\nabstract operator.\n", "versions": [{"version": "v1", "created": "Mon, 9 Oct 2017 23:48:19 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Hayes", "Ian J.", ""], ["Meinicke", "Larissa A.", ""], ["Winter", "Kirsten", ""], ["Colvin", "Robert J.", ""]]}, {"id": "1710.03390", "submitter": "EPTCS", "authors": "Sjur K Dyrkolbotn (Western Norway University of Applied Sciences)", "title": "On Preemption and Overdetermination in Formal Theories of Causality", "comments": "In Proceedings CREST 2017, arXiv:1710.02770", "journal-ref": "EPTCS 259, 2017, pp. 1-15", "doi": "10.4204/EPTCS.259.1", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges when looking for the causes of a complex event is\nto determine the causal status of factors that are neither individually\nnecessary nor individually sufficient to produce that event. In order to reason\nabout how such factors should be taken into account, we need a vocabulary to\ndistinguish different cases. In philosophy, the concept of overdetermination\nand the concept of preemption serve an important purpose in this regard,\nalthough their exact meaning tends to remain elusive. In this paper, I provide\ntheory-neutral definitions of these concepts using structural equations in the\nHalpern-Pearl tradition. While my definitions do not presuppose any particular\ncausal theory, they take such a theory as a variable parameter. This enables us\nto specify formal constraints on theories of causality, in terms of a\npre-theoretic understanding of what preemption and overdetermination actually\nmean. I demonstrate the usefulness of this by presenting and arguing for what I\ncall the principle of presumption. Roughly speaking, this principle states that\na possible cause can only be regarded as having been preempted if there is\nindependent evidence to support such an inference. I conclude by showing that\nthe principle of presumption is violated by the two main theories of causality\nformulated in the Halpern-Pearl tradition. The paper concludes by defining the\nclass of empirical causal theories, characterised in terms of a fixed-point of\ncounterfactual reasoning about difference-making. It is argued that theories of\nactual causality ought to be empirical.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 03:50:30 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Dyrkolbotn", "Sjur K", "", "Western Norway University of Applied Sciences"]]}, {"id": "1710.03391", "submitter": "EPTCS", "authors": "Bernd Finkbeiner (Universit\\\"at des Saarlandes), Andrey Kupriyanov\n  (Institute of Science and Technology Austria)", "title": "Causality-based Model Checking", "comments": "In Proceedings CREST 2017, arXiv:1710.02770", "journal-ref": "EPTCS 259, 2017, pp. 31-38", "doi": "10.4204/EPTCS.259.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking is usually based on a comprehensive traversal of the state\nspace. Causality-based model checking is a radically different approach that\ninstead analyzes the cause-effect relationships in a program. We give an\noverview on a new class of model checking algorithms that capture the causal\nrelationships in a special data structure called concurrent traces. Concurrent\ntraces identify key events in an execution history and link them through their\ncause-effect relationships. The model checker builds a tableau of concurrent\ntraces, where the case splits represent different causal explanations of a\nhypothetical error. Causality-based model checking has been implemented in the\nARCTOR tool, and applied to previously intractable multi-threaded benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 03:51:18 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Finkbeiner", "Bernd", "", "Universit\u00e4t des Saarlandes"], ["Kupriyanov", "Andrey", "", "Institute of Science and Technology Austria"]]}, {"id": "1710.03393", "submitter": "EPTCS", "authors": "Gregor G\\\"ossler (INRIA, France), Oleg Sokolsky (University of\n  Pennsylvania, Philadelphia, USA), Jean-Bernard Stefani (INRIA, France)", "title": "Counterfactual Causality from First Principles?", "comments": "In Proceedings CREST 2017, arXiv:1710.02770", "journal-ref": "EPTCS 259, 2017, pp. 47-53", "doi": "10.4204/EPTCS.259.5", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this position paper we discuss three main shortcomings of existing\napproaches to counterfactual causality from the computer science perspective,\nand sketch lines of work to try and overcome these issues: (1) causality\ndefinitions should be driven by a set of precisely specified requirements\nrather than specific examples; (2) causality frameworks should support system\ndynamics; (3) causality analysis should have a well-understood behavior in\npresence of abstraction.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 03:52:07 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["G\u00f6ssler", "Gregor", "", "INRIA, France"], ["Sokolsky", "Oleg", "", "University of\n  Pennsylvania, Philadelphia, USA"], ["Stefani", "Jean-Bernard", "", "INRIA, France"]]}, {"id": "1710.03481", "submitter": "Davide Grossi", "authors": "Agneau Belanyek, Davide Grossi, Wiebe van der Hoek", "title": "A Note on Nesting in Dyadic Deontic Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper reports on some results concerning Aqvist's dyadic logic known as\nsystem G, which is one of the most influential logics for reasoning with dyadic\nobligations (\"it ought to be the case that ... if it is the case that ...\").\nAlthough this logic has been known in the literature for a while, many of its\nproperties still await in-depth consideration. In this short paper we show:\nthat any formula in system G including nested modal operators is equivalent to\nsome formula with no nesting; that the universal modality introduced by Aqvist\nin the first presentation of the system is definable in terms of the deontic\nmodality.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 09:45:25 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Belanyek", "Agneau", ""], ["Grossi", "Davide", ""], ["van der Hoek", "Wiebe", ""]]}, {"id": "1710.03571", "submitter": "Plamen L. Simeonov", "authors": "Plamen L. Simeonov and Andr\\'ee C. Ehresmann", "title": "Adapting a Formal Model Theory to Applications in Augmented Personalized\n  Medicine", "comments": "56 pages, 18 figures, technical application paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to advance an extensible theory of living systems\nusing an approach to biomathematics and biocomputation that suitably addresses\nself-organized, self-referential and anticipatory systems with multi-temporal\nmulti-agents. Our first step is to provide foundations for modelling of\nemergent and evolving dynamic multi-level organic complexes and their\nsustentative processes in artificial and natural life systems. Main\napplications are in life sciences, medicine, ecology and astrobiology, as well\nas robotics, industrial automation and man-machine interface. Since 2011 over\n100 scientists from a number of disciplines have been exploring a substantial\nset of theoretical frameworks for a comprehensive theory of life known as\nIntegral Biomathics. That effort identified the need for a robust core model of\norganisms as dynamic wholes, using advanced and adequately computable\nmathematics. The work described here for that core combines the advantages of a\nsituation and context aware multivalent computational logic for active\nself-organizing networks, Wandering Logic Intelligence (WLI), and a multi-scale\ndynamic category theory, Memory Evolutive Systems (MES), hence WLIMES. This is\npresented to the modeller via a formal augmented reality language as a first\nstep towards practical modelling and simulation of multi-level living systems.\nInitial work focuses on the design and implementation of this visual language\nand calculus (VLC) and its graphical user interface. The results will be\nintegrated within the current methodology and practices of theoretical biology\nand (personalized) medicine to deepen and to enhance the holistic understanding\nof life.\n", "versions": [{"version": "v1", "created": "Sun, 1 Oct 2017 20:10:11 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 11:15:57 GMT"}, {"version": "v3", "created": "Sun, 29 Oct 2017 11:14:32 GMT"}, {"version": "v4", "created": "Mon, 13 Nov 2017 01:37:31 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Simeonov", "Plamen L.", ""], ["Ehresmann", "Andr\u00e9e C.", ""]]}, {"id": "1710.03702", "submitter": "Eike Neumann", "authors": "Michal Kone\\v{c}n\\'y and Eike Neumann", "title": "Representations and evaluation strategies for feasibly approximable\n  functions", "comments": "33 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A famous result due to Ko and Friedman (1982) asserts that the problems of\nintegration and maximisation of a univariate real function are computationally\nhard in a well-defined sense. Yet, both functionals are routinely computed at\ngreat speed in practice. We aim to resolve this apparent paradox by studying\nclasses of functions which can be feasibly integrated and maximised, together\nwith representations for these classes of functions which encode the\ninformation which is necessary to uniformly compute integral and maximum in\npolynomial time. The theoretical framework for this is the second-order\ncomplexity theory for operators in analysis which was introduced by Kawamura\nand Cook (2012). The representations we study are based on rigorous\napproximation by polynomials, piecewise polynomials, and rational functions. We\ncompare these representations with respect to polytime reducibility as well as\nwith respect to their ability to quickly evaluate symbolic expressions in a\ngiven language. We show that the representation based on rigorous approximation\nby piecewise polynomials is polytime equivalent to the representation based on\nrigorous approximation by rational functions. With this representation, all\nterms in a certain language, which is expressive enough to contain the maximum\nand integral of most functions of practical interest, can be evaluated in\npolynomial time. By contrast, both the representation based on polynomial\napproximation and the standard representation based on function evaluation,\nwhich implicitly underlies the Ko-Friedman result, require exponential time to\nevaluate certain terms in this language. We confirm our theoretical results by\nan implementation in Haskell, which provides some evidence that second-order\npolynomial time computability is similarly closely tied with practical\nfeasibility as its first-order counterpart.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 16:17:52 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 16:17:12 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 21:01:19 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Kone\u010dn\u00fd", "Michal", ""], ["Neumann", "Eike", ""]]}, {"id": "1710.03875", "submitter": "Marcell Vazquez-Chanlatte", "authors": "Marcell Vazquez-Chanlatte, Susmit Jha, Ashish Tiwari, Mark K. Ho,\n  Sanjit A. Seshia", "title": "Learning Task Specifications from Demonstrations", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world applications often naturally decompose into several sub-tasks. In\nmany settings (e.g., robotics) demonstrations provide a natural way to specify\nthe sub-tasks. However, most methods for learning from demonstrations either do\nnot provide guarantees that the artifacts learned for the sub-tasks can be\nsafely recombined or limit the types of composition available. Motivated by\nthis deficit, we consider the problem of inferring Boolean non-Markovian\nrewards (also known as logical trace properties or specifications) from\ndemonstrations provided by an agent operating in an uncertain, stochastic\nenvironment. Crucially, specifications admit well-defined composition rules\nthat are typically easy to interpret. In this paper, we formulate the\nspecification inference task as a maximum a posteriori (MAP) probability\ninference problem, apply the principle of maximum entropy to derive an analytic\ndemonstration likelihood model and give an efficient approach to search for the\nmost likely specification in a large candidate pool of specifications. In our\nexperiments, we demonstrate how learning specifications can help avoid common\nproblems that often arise due to ad-hoc reward composition.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 01:31:14 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 06:03:22 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2018 00:32:09 GMT"}, {"version": "v4", "created": "Tue, 14 Aug 2018 03:32:12 GMT"}, {"version": "v5", "created": "Sat, 27 Oct 2018 16:49:13 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Vazquez-Chanlatte", "Marcell", ""], ["Jha", "Susmit", ""], ["Tiwari", "Ashish", ""], ["Ho", "Mark K.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1710.03894", "submitter": "Thorsten Wissmann", "authors": "Brendan Fong and Fabio Zanasi", "title": "Universal Constructions for (Co)Relations: categories, monoidal\n  categories, and props", "comments": "22 pages + 3 page appendix, extended version of arXiv:1703.08247", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3,\n  Categorical models and logic (September 3, 2018) lmcs:4796", "doi": "10.23638/LMCS-14(3:14)2018", "report-no": null, "categories": "cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Calculi of string diagrams are increasingly used to present the syntax and\nalgebraic structure of various families of circuits, including signal flow\ngraphs, electrical circuits and quantum processes. In many such approaches, the\nsemantic interpretation for diagrams is given in terms of relations or\ncorelations (generalised equivalence relations) of some kind. In this paper we\nshow how semantic categories of both relations and corelations can be\ncharacterised as colimits of simpler categories. This modular perspective is\nimportant as it simplifies the task of giving a complete axiomatisation for\nsemantic equivalence of string diagrams. Moreover, our general result unifies\nvarious theorems that are independently found in literature and are relevant\nfor program semantics, quantum computation and control theory.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 03:34:28 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 02:41:46 GMT"}, {"version": "v3", "created": "Fri, 31 Aug 2018 11:19:30 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Fong", "Brendan", ""], ["Zanasi", "Fabio", ""]]}, {"id": "1710.03928", "submitter": "Christopher M. Poskitt", "authors": "Claudio Corrodi, Alexander Heu{\\ss}ner, Christopher M. Poskitt", "title": "A Semantics Comparison Workbench for a Concurrent, Asynchronous,\n  Distributed Programming Language", "comments": "Accepted by Formal Aspects of Computing", "journal-ref": "Formal Asp. Comput. 30(1): 163-192 (2018)", "doi": "10.1007/s00165-017-0443-1", "report-no": null, "categories": "cs.SE cs.DC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of high-level languages and libraries have been proposed that offer\nnovel and simple to use abstractions for concurrent, asynchronous, and\ndistributed programming. The execution models that realise them, however, often\nchange over time---whether to improve performance, or to extend them to new\nlanguage features---potentially affecting behavioural and safety properties of\nexisting programs. This is exemplified by SCOOP, a message-passing approach to\nconcurrent object-oriented programming that has seen multiple changes proposed\nand implemented, with demonstrable consequences for an idiomatic usage of its\ncore abstraction. We propose a semantics comparison workbench for SCOOP with\nfully and semi-automatic tools for analysing and comparing the state spaces of\nprograms with respect to different execution models or semantics. We\ndemonstrate its use in checking the consistency of properties across semantics\nby applying it to a set of representative programs, and highlighting a\ndeadlock-related discrepancy between the principal execution models of SCOOP.\nFurthermore, we demonstrate the extensibility of the workbench by generalising\nthe formalisation of an execution model to support recently proposed extensions\nfor distributed programming. Our workbench is based on a modular and\nparameterisable graph transformation semantics implemented in the GROOVE tool.\nWe discuss how graph transformations are leveraged to atomically model\nintricate language abstractions, how the visual yet algebraic nature of the\nmodel can be used to ascertain soundness, and highlight how the approach could\nbe applied to similar languages.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 06:36:58 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Corrodi", "Claudio", ""], ["Heu\u00dfner", "Alexander", ""], ["Poskitt", "Christopher M.", ""]]}, {"id": "1710.03979", "submitter": "Stavros Tripakis", "authors": "Viorel Preoteasa, Iulia Dragomir, Stavros Tripakis", "title": "The Refinement Calculus of Reactive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Refinement Calculus of Reactive Systems (RCRS) is a compositional formal\nframework for modeling and reasoning about reactive systems. RCRS provides a\nlanguage which allows to describe atomic components as symbolic transition\nsystems or QLTL formulas, and composite components formed using three primitive\ncomposition operators: serial, parallel, and feedback. The semantics of the\nlanguage is given in terms of monotonic property transformers, an extension to\nreactive systems of monotonic predicate transformers, which have been used to\ngive compositional semantics to sequential programs. RCRS allows to specify\nboth safety and liveness properties. It also allows to model input-output\nsystems which are both non-deterministic and non-input-receptive (i.e., which\nmay reject some inputs at some points in time), and can thus be seen as a\nbehavioral type system. RCRS provides a set of techniques for symbolic\ncomputer-aided reasoning, including compositional static analysis and\nverification. RCRS comes with a publicly available implementation which\nincludes a complete formalization of the RCRS theory in the Isabelle proof\nassistant.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 09:41:59 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 11:19:27 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Preoteasa", "Viorel", ""], ["Dragomir", "Iulia", ""], ["Tripakis", "Stavros", ""]]}, {"id": "1710.04002", "submitter": "Thorsten Wissmann", "authors": "Olivier Finkel, Olivier Carton, Dominique Lecomte", "title": "Polishness of some topologies related to word or tree automata", "comments": "This paper is an extended version of a paper which appeared in the\n  proceedings of the 26th EACSL Annual Conference on Computer Science and\n  Logic, CSL 2017. The main addition with regard to the conference paper\n  consists in the study of the B\\\"uchi topology and of the Muller topology in\n  the case of a space of trees, which now forms Section 4", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (May 8,\n  2019) lmcs:5440", "doi": "10.23638/LMCS-15(2:9)2019", "report-no": null, "categories": "math.LO cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove that the B\\\"uchi topology and the automatic topology are Polish. We\nalso show that this cannot be fully extended to the case of a space of infinite\nlabelled binary trees; in particular the B\\\"uchi and the Muller topologies are\nnot Polish in this case.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 11:09:18 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 11:34:31 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 09:33:25 GMT"}, {"version": "v4", "created": "Tue, 7 May 2019 07:58:58 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Finkel", "Olivier", ""], ["Carton", "Olivier", ""], ["Lecomte", "Dominique", ""]]}, {"id": "1710.04171", "submitter": "Danny Nguyen", "authors": "Danny Nguyen, Igor Pak", "title": "VC-dimension of short Presburger formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study VC-dimension of short formulas in Presburger Arithmetic, defined to\nhave a bounded number of variables, quantifiers and atoms. We give both lower\nand upper bounds, which are tight up to a polynomial factor in the bit length\nof the formula.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 16:57:26 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Nguyen", "Danny", ""], ["Pak", "Igor", ""]]}, {"id": "1710.04570", "submitter": "Roberto Bruni", "authors": "Roberto Bruni, Hern\\'an Melgratti, Ugo Montanari", "title": "Concurrency and Probability: Removing Confusion, Compositionally", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 4 (December\n  19, 2019) lmcs:5990", "doi": "10.23638/LMCS-15(4:17)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assigning a satisfactory truly concurrent semantics to Petri nets with\nconfusion and distributed decisions is a long standing problem, especially if\none wants to resolve decisions by drawing from some probability distribution.\nHere we propose a general solution based on a recursive, static decomposition\nof (occurrence) nets in loci of decision, called structural branching cells\n(s-cells). Each s-cell exposes a set of alternatives, called transactions. Our\nsolution transforms a given Petri net into another net whose transitions are\nthe transactions of the s-cells and whose places are those of the original net,\nwith some auxiliary structure for bookkeeping. The resulting net is\nconfusion-free, and thus conflicting alternatives can be equipped with\nprobabilistic choices, while nonintersecting alternatives are purely concurrent\nand their probability distributions are independent. The validity of the\nconstruction is witnessed by a tight correspondence with the recursively\nstopped configurations of Abbes and Benveniste. Some advantages of our approach\nare that: i) s-cells are defined statically and locally in a compositional way;\nii) our resulting nets faithfully account for concurrency.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 15:40:11 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 08:43:28 GMT"}, {"version": "v3", "created": "Fri, 8 Mar 2019 09:12:23 GMT"}, {"version": "v4", "created": "Thu, 24 Oct 2019 10:35:15 GMT"}, {"version": "v5", "created": "Wed, 18 Dec 2019 14:03:17 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bruni", "Roberto", ""], ["Melgratti", "Hern\u00e1n", ""], ["Montanari", "Ugo", ""]]}, {"id": "1710.04628", "submitter": "Sebastian Enqvist", "authors": "Sebastian Enqvist", "title": "Flat modal fixpoint logics with the converse modality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a generic completeness result for a class of modal fixpoint logics\ncorresponding to flat fragments of the two-way mu-calculus, extending earlier\nwork by Santocanale and Venema. We observe that Santocanale and Venema's proof\nthat least fixpoints in the Lindenbaum-Tarski algebra of certain flat fixpoint\nlogics are constructive, using finitary adjoints, no longer works when the\nconverse modality is introduced. Instead, our completeness proof directly\nconstructs a model for a consistent formula, using the induction rule in a way\nthat is similar to the standard completeness proof for propositional dynamic\nlogic. This approach is combined with the concept of a focus, which has\npreviously been used in tableau based reasoning for modal fixpoint logics.\n", "versions": [{"version": "v1", "created": "Thu, 12 Oct 2017 17:28:47 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Enqvist", "Sebastian", ""]]}, {"id": "1710.05096", "submitter": "Hilmar Lapp", "authors": "David Carral, Pascal Hitzler, Hilmar Lapp, Sebastian Rudolph", "title": "On the Ontological Modeling of Trees", "comments": "Proceedings of the 8th Workshop on Ontology Design and Patterns, WOP\n  2017, co-located with the 16th International Semantic Web Conference,\n  ISWC2017, Vienna, Austria, October 2017. To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trees -- i.e., the type of data structure known under this name -- are\ncentral to many aspects of knowledge organization. We investigate some central\ndesign choices concerning the ontological modeling of such trees. In\nparticular, we consider the limits of what is expressible in the Web Ontology\nLanguage, and provide a reusable ontology design pattern for trees.\n", "versions": [{"version": "v1", "created": "Fri, 13 Oct 2017 22:58:41 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Carral", "David", ""], ["Hitzler", "Pascal", ""], ["Lapp", "Hilmar", ""], ["Rudolph", "Sebastian", ""]]}, {"id": "1710.05247", "submitter": "Aditya Aniruddha Shrotri", "authors": "Kuldeep S. Meel (1), Aditya A. Shrotri (2), Moshe Y. Vardi (2) ((1)\n  National University of Singapore, (2) Rice University)", "title": "On Hashing-Based Approaches to Approximate DNF-Counting", "comments": "Full version of paper accepted to FSTTCS 2017. 12 pages +\n  Acknowledgements + References + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Propositional model counting is a fundamental problem in artificial\nintelligence with a wide variety of applications, such as probabilistic\ninference, decision making under uncertainty, and probabilistic databases.\nConsequently, the problem is of theoretical as well as practical interest. When\nthe constraints are expressed as DNF formulas, Monte Carlo-based techniques\nhave been shown to provide a fully polynomial randomized approximation scheme\n(FPRAS). For CNF constraints, hashing-based approximation techniques have been\ndemonstrated to be highly successful. Furthermore, it was shown that\nhashing-based techniques also yield an FPRAS for DNF counting without usage of\nMonte Carlo sampling. Our analysis, however, shows that the proposed\nhashing-based approach to DNF counting provides poor time complexity compared\nto the Monte Carlo-based DNF counting techniques. Given the success of\nhashing-based techniques for CNF constraints, it is natural to ask: Can\nhashing-based techniques provide an efficient FPRAS for DNF counting? In this\npaper, we provide a positive answer to this question. To this end, we introduce\ntwo novel algorithmic techniques: \\emph{Symbolic Hashing} and \\emph{Stochastic\nCell Counting}, along with a new hash family of \\emph{Row-Echelon hash\nfunctions}. These innovations allow us to design a hashing-based FPRAS for DNF\ncounting of similar complexity (up to polylog factors) as that of prior works.\nFurthermore, we expect these techniques to have potential applications beyond\nDNF counting.\n", "versions": [{"version": "v1", "created": "Sat, 14 Oct 2017 23:22:09 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Meel", "Kuldeep S.", ""], ["Shrotri", "Aditya A.", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1710.05341", "submitter": "Anthony Young", "authors": "Anthony P. Young", "title": "The Complete Extensions do not form a Complete Semilattice", "comments": "10 pages, 2 figures, 11 references [Update 26/10/2017] This note\n  contains an error that invalidates its title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his seminal paper that inaugurated abstract argumentation, Dung proved\nthat the set of complete extensions forms a complete semilattice with respect\nto set inclusion. In this note we demonstrate that this proof is incorrect with\ncounterexamples. We then trace the error in the proof and explain why it arose.\nWe then examine the implications for the grounded extension.\n  [Reason for withdrawal continued] Page 4, Example 2 is not a counterexample\nto Dung 1995 Theorem 25(3). It was believed to be a counter-example because the\nauthor misunderstood ``glb'' to be set-theoretic intersection. But in this\ncase, ``glb'' is defined to be other than set-theoretic intersection such that\nTheorem 25(3) is true.\n  The author was motivated to fully understand the lattice-theoretic claims of\nDung 1995 in writing this note and was not aware that this issue is probably\nfolklore; the author bears full responsibility for this error.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 14:49:40 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 04:55:17 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Young", "Anthony P.", ""]]}, {"id": "1710.05368", "submitter": "Paul G\\\"olz", "authors": "Bernd Finkbeiner (Saarland University), and Paul G\\\"olz (Saarland\n  University)", "title": "Synthesis in Distributed Environments", "comments": "12 pages excluding references and appendices, 29 pages total, 5\n  figures. Version without appendices to be published in conference proceedings\n  of FSTTCS 2017. Appendix A includes notation for multisets. Appendix B\n  includes detailed proofs that have been omitted due to space constraints.\n  Appendix C contains an algorithm for symbolic evaluation of commitments and\n  its runtime analysis", "journal-ref": null, "doi": "10.4230/LIPIcs.FSTTCS.2017.28", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most approaches to the synthesis of reactive systems study the problem in\nterms of a two-player game with complete observation. In many applications,\nhowever, the system's environment consists of several distinct entities, and\nthe system must actively communicate with these entities in order to obtain\ninformation available in the environment. In this paper, we model such\nenvironments as a team of players and keep track of the information known to\neach individual player. This allows us to synthesize programs that interact\nwith a distributed environment and leverage multiple interacting sources of\ninformation.\n  The synthesis problem in distributed environments corresponds to solving a\nspecial class of Petri games, i.e., multi-player games played over Petri nets,\nwhere the net has a distinguished token representing the system and an\narbitrary number of tokens representing the environment. While, in general,\neven the decidability of Petri games is an open question, we show that the\nsynthesis problem in distributed environments can be solved in polynomial time\nfor nets with up to two environment tokens. For an arbitrary but fixed number\nof three or more environment tokens, the problem is NP-complete. If the number\nof environment tokens grows with the size of the net, the problem is\nEXPTIME-complete.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 18:01:31 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Finkbeiner", "Bernd", "", "Saarland University"], ["G\u00f6lz", "Paul", "", "Saarland\n  University"]]}, {"id": "1710.05388", "submitter": "J\\\"urgen Koslowski", "authors": "Massimo Bartoletti and Tiziana Cimoli and Maurizio Murgia", "title": "Timed Session Types", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (December\n  8, 2017) lmcs:4133", "doi": "10.23638/LMCS-13(4:25)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timed session types formalise timed communication protocols between two\nparticipants at the endpoints of a session. They feature a decidable compliance\nrelation, which generalises to the timed setting the progress-based compliance\nbetween untimed session types. We show a sound and complete technique to decide\nwhen a timed session type admits a compliant one. Then, we show how to\nconstruct the most precise session type compliant with a given one, according\nto the subtyping preorder induced by compliance. Decidability of subtyping\nfollows from these results.\n", "versions": [{"version": "v1", "created": "Sun, 15 Oct 2017 20:01:27 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 19:59:53 GMT"}, {"version": "v3", "created": "Thu, 7 Dec 2017 11:01:58 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Cimoli", "Tiziana", ""], ["Murgia", "Maurizio", ""]]}, {"id": "1710.05582", "submitter": "Witold Charatonik", "authors": "Bartosz Bednarczyk and Witold Charatonik", "title": "Modulo Counting on Words and Trees", "comments": "Full version of a paper published in proceedings of FSTTCS 2017\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the satisfiability problem for the two-variable fragment of the\nfirst-order logic extended with modulo counting quantifiers and interpreted\nover finite words or trees. We prove a small-model property of this logic,\nwhich gives a technique for deciding the satisfiability problem. In the case of\nwords this gives a new proof of EXPSPACE upper bound, and in the case of trees\nit gives a 2EXPTIME algorithm. This algorithm is optimal: we prove a matching\nlower bound by a generic reduction from alternating Turing machines working in\nexponential space; the reduction involves a development of a new version of\ntiling games.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 09:24:07 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Bednarczyk", "Bartosz", ""], ["Charatonik", "Witold", ""]]}, {"id": "1710.05633", "submitter": "R\\\"udiger Ehlers", "authors": "Ruediger Ehlers, Bernd Finkbeiner", "title": "Symmetric Synthesis", "comments": "Full Version of the paper with the same name accepted at FSTTCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of determining whether a given temporal specification\ncan be implemented by a symmetric system, i.e., a system composed from\nidentical components. Symmetry is an important goal in the design of\ndistributed systems, because systems that are composed from identical\ncomponents are easier to build and maintain. We show that for the class of\nrotation-symmetric architectures, i.e., multi-process architectures where all\nprocesses have access to all system inputs, but see different rotations of the\ninputs, the symmetric synthesis problem is EXPTIME-complete in the number of\nprocesses. In architectures where the processes do not have access to all input\nvariables, the symmetric synthesis problem becomes undecidable, even in cases\nwhere the standard distributed synthesis problem is decidable.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 11:49:48 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Ehlers", "Ruediger", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "1710.05661", "submitter": "Marc Aiguier", "authors": "Marc Aiguier and Isabelle Bloch", "title": "Dual Logic Concepts based on Mathematical Morphology in Stratified\n  Institutions: Applications to Spatial Reasoning", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several logical operators are defined as dual pairs, in different types of\nlogics. Such dual pairs of operators also occur in other algebraic theories,\nsuch as mathematical morphology. Based on this observation, this paper proposes\nto define, at the abstract level of institutions, a pair of abstract dual and\nlogical operators as morphological erosion and dilation. Standard quantifiers\nand modalities are then derived from these two abstract logical operators.\nThese operators are studied both on sets of states and sets of models. To cope\nwith the lack of explicit set of states in institutions, the proposed abstract\nlogical dual operators are defined in an extension of institutions, the\nstratified institutions, which take into account the notion of open sentences,\nthe satisfaction of which is parametrized by sets of states. A hint on the\npotential interest of the proposed framework for spatial reasoning is also\nprovided.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 12:50:03 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Aiguier", "Marc", ""], ["Bloch", "Isabelle", ""]]}, {"id": "1710.05706", "submitter": "Laurent Bartholdi", "authors": "Laurent Bartholdi, Thorsten Groth, Igor Lysenok", "title": "Commutator width in the first Grigorchuk group", "comments": "Wrt v1: improved presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be the first Grigorchuk group. We show that the commutator width of\n$G$ is $2$: every element $g\\in [G,G]$ is a product of two commutators, and\nalso of six conjugates of $a$. Furthermore, we show that every finitely\ngenerated subgroup $H\\leq G$ has finite commutator width, which however can be\narbitrarily large, and that $G$ contains a subgroup of infinite commutator\nwidth. The proofs were assisted by the computer algebra system GAP.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 14:08:15 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 11:01:19 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 08:49:22 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bartholdi", "Laurent", ""], ["Groth", "Thorsten", ""], ["Lysenok", "Igor", ""]]}, {"id": "1710.05763", "submitter": "Pedro R. D'Argenio", "authors": "Pedro R. D'Argenio, Marcus Gerhold, Arnd Hartmanns, and Sean Sedwards", "title": "A Hierarchy of Scheduler Classes for Stochastic Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic automata are a formal compositional model for concurrent\nstochastic timed systems, with general distributions and non-deterministic\nchoices. Measures of interest are defined over schedulers that resolve the\nnondeterminism. In this paper we investigate the power of various theoretically\nand practically motivated classes of schedulers, considering the classic\ncomplete-information view and a restriction to non-prophetic schedulers. We\nprove a hierarchy of scheduler classes w.r.t. unbounded probabilistic\nreachability. We find that, unlike Markovian formalisms, stochastic automata\ndistinguish most classes even in this basic setting. Verification and strategy\nsynthesis methods thus face a tradeoff between powerful and efficient classes.\nUsing lightweight scheduler sampling, we explore this tradeoff and demonstrate\nthe concept of a useful approximative verification technique for stochastic\nautomata.\n", "versions": [{"version": "v1", "created": "Mon, 16 Oct 2017 14:47:28 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["D'Argenio", "Pedro R.", ""], ["Gerhold", "Marcus", ""], ["Hartmanns", "Arnd", ""], ["Sedwards", "Sean", ""]]}, {"id": "1710.06187", "submitter": "Dmitry Vlasov", "authors": "Dmitry Vlasov", "title": "System Description: Russell - A Logical Framework for Deductive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Russell is a logical framework for the specification and implementation of\ndeductive systems. It is a high-level language with respect to Metamath\nlanguage, so inherently it uses a Metamath foundations, i.e. it doesn't rely on\nany particular formal calculus, but rather is a pure logical framework. The\nmain difference with Metamath is in the proof language and approach to syntax:\nthe proofs have a declarative form, i.e. consist of actual expressions, which\nare used in proofs, while syntactic grammar rules are separated from the\nmeaningful rules of inference.\n  Russell is implemented in c++14 and is distributed under GPL v3 license. The\nrepository contains translators from Metamath to Russell and back. Original\nMetamath theorem base (almost 30 000 theorems) can be translated to Russell,\nverified, translated back to Metamath and verified with the original Metamath\nverifier. Russell can be downloaded from the repository\nhttps://github.com/dmitry-vlasov/russell\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 09:50:44 GMT"}, {"version": "v2", "created": "Sun, 3 Dec 2017 15:10:14 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Vlasov", "Dmitry", ""]]}, {"id": "1710.06494", "submitter": "J\\\"urgen Koslowski", "authors": "Dimitrios Kouzapas and Anna Philippou", "title": "Privacy by typing in the $\\pi$-calculus", "comments": "43 pages", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (December\n  20, 2017) lmcs:4152", "doi": "10.23638/LMCS-13(4:27)2017", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a formal framework for studying privacy in\ninformation systems. The proposal follows a two-axes schema where the first\naxis considers privacy as a taxonomy of rights and the second axis involves the\nways an information system stores and manipulates information. We develop a\ncorrespondence between the above schema and an associated model of computation.\nIn particular, we propose the \\Pcalc, a calculus based on the $\\pi$-calculus\nwith groups extended with constructs for reasoning about private data. The\nprivacy requirements of an information system are captured via a privacy policy\nlanguage. The correspondence between the privacy model and the \\Pcalc semantics\nis established using a type system for the calculus and a satisfiability\ndefinition between types and privacy policies. We deploy a type preservation\ntheorem to show that a system respects a policy and it is safe if the typing of\nthe system satisfies the policy. We illustrate our methodology via analysis of\ntwo use cases: a privacy-aware scheme for electronic traffic pricing and a\nprivacy-preserving technique for speed-limit enforcement.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 20:22:17 GMT"}, {"version": "v2", "created": "Sun, 17 Dec 2017 22:08:36 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kouzapas", "Dimitrios", ""], ["Philippou", "Anna", ""]]}, {"id": "1710.06500", "submitter": "Randal E. Bryant", "authors": "Randal E. Bryant", "title": "Chain Reduction for Binary and Zero-Suppressed Decision Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chain reduction enables reduced ordered binary decision diagrams (BDDs) and\nzero-suppressed binary decision diagrams (ZDDs) to each take advantage of the\nothers' ability to symbolically represent Boolean functions in compact form.\nFor any Boolean function, its chain-reduced ZDD (CZDD) representation will be\nno larger than its ZDD representation, and at most twice the size of its BDD\nrepresentation. The chain-reduced BDD (CBDD) of a function will be no larger\nthan its BDD representation, and at most three times the size of its CZDD\nrepresentation. Extensions to the standard algorithms for operating on BDDs and\nZDDs enable them to operate on the chain-reduced versions. Experimental\nevaluations on representative benchmarks for encoding word lists, solving\ncombinatorial problems, and operating on digital circuits indicate that chain\nreduction can provide significant benefits in terms of both memory and\nexecution time.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 21:01:37 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Bryant", "Randal E.", ""]]}, {"id": "1710.06515", "submitter": "Quang Loc Le", "authors": "Quang Loc Le", "title": "Enhancing Inductive Entailment Proofs in Separation Logic with Lemma\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach to lemma synthesis to support advanced\ninductive entailment procedures based on separation logic. We first propose a\nmechanism where lemmas are automatically proven and systematically applied. The\nlemmas may include universal guard and/or unknown predicate. While the former\nis critical for expressivity, the latter is essential for supporting\nrelationships between multiple predicates. We further introduce lemma synthesis\nto support (i) automated inductive reasoning together with frame inference and\n(ii) theorem exploration. For (i) we automatically discover and prove auxiliary\nlemmas during an inductive proof; and for (ii) we automatically generate a\nuseful set of lemmas to relate user-defined or system-generated predicates. We\nhave implemented our proposed approach into an existing verification system and\ntested its capability in inductive reasoning and theorem exploration. The\nexperimental results show that the enhanced system can automatically synthesize\nuseful lemmas to facilitate reasoning on a broad range of non-trivial inductive\nproofs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 22:13:25 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 10:10:29 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Le", "Quang Loc", ""]]}, {"id": "1710.06744", "submitter": "Christoph Rauch", "authors": "Clovis Eberhart (LAMA), Tom Hirschowitz (LAMA), Thomas Seiller (IHES)", "title": "An intensionally fully-abstract sheaf model for $\\pi$ (expanded version)", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (November\n  15, 2017) lmcs:4069", "doi": "10.23638/LMCS-13(4:9)2017", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following previous work on CCS, we propose a compositional model for the\n$\\pi$-calculus in which processes are interpreted as sheaves on certain simple\nsites. Such sheaves are a concurrent form of innocent strategies, in the sense\nof Hyland-Ong/Nickau game semantics. We define an analogue of fair testing\nequivalence in the model and show that our interpretation is intensionally\nfully abstract for it. That is, the interpretation preserves and reflects fair\ntesting equivalence; and furthermore, any innocent strategy is fair testing\nequivalent to the interpretation of some process. The central part of our work\nis the construction of our sites, relying on a combinatorial presentation of\n$\\pi$-calculus traces in the spirit of string diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 18 Oct 2017 14:21:10 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 09:48:28 GMT"}, {"version": "v3", "created": "Tue, 14 Nov 2017 10:50:00 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Eberhart", "Clovis", "", "LAMA"], ["Hirschowitz", "Tom", "", "LAMA"], ["Seiller", "Thomas", "", "IHES"]]}, {"id": "1710.07163", "submitter": "Patricia Bouyer", "authors": "Patricia Bouyer", "title": "Games on graphs with a public signal monitoring", "comments": "28 pages", "journal-ref": "FoSSaCS 2018", "doi": "10.1007/978-3-319-89366-2_29", "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pure Nash equilibria in games on graphs with an imperfect monitoring\nbased on a public signal. In such games, deviations and players responsible for\nthose deviations can be hard to detect and track. We propose a generic\nepistemic game abstraction, which conveniently allows to represent the\nknowledge of the players about these deviations, and give a characterization of\nNash equilibria in terms of winning strategies in the abstraction. We then use\nthe abstraction to develop algorithms for some payoff functions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 14:43:56 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 09:40:50 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Bouyer", "Patricia", ""]]}, {"id": "1710.07191", "submitter": "Oded Padon", "authors": "Oded Padon, Giuliano Losa, Mooly Sagiv, Sharon Shoham", "title": "Paxos Made EPR: Decidable Reasoning about Distributed Protocols", "comments": "61 pages. Full version of paper by the same title presented in OOPSLA\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed protocols such as Paxos play an important role in many computer\nsystems. Therefore, a bug in a distributed protocol may have tremendous\neffects. Accordingly, a lot of effort has been invested in verifying such\nprotocols. However, checking invariants of such protocols is undecidable and\nhard in practice, as it requires reasoning about an unbounded number of nodes\nand messages. Moreover, protocol actions and invariants involve both quantifier\nalternations and higher-order concepts such as set cardinalities and\narithmetic.\n  This paper makes a step towards automatic verification of such protocols. We\naim at a technique that can verify correct protocols and identify bugs in\nincorrect protocols. To this end, we develop a methodology for deductive\nverification based on effectively propositional logic (EPR)---a decidable\nfragment of first-order logic (also known as the Bernays-Sch\\\"onfinkel-Ramsey\nclass). In addition to decidability, EPR also enjoys the finite model property,\nallowing to display violations as finite structures which are intuitive for\nusers. Our methodology involves modeling protocols using general\n(uninterpreted) first-order logic, and then systematically transforming the\nmodel to obtain a model and an inductive invariant that are decidable to check.\nThe steps of the transformations are also mechanically checked, ensuring the\nsoundness of the method. We have used our methodology to verify the safety of\nPaxos, and several of its variants, including Multi-Paxos, Vertical Paxos, Fast\nPaxos, Flexible Paxos and Stoppable Paxos. To the best of our knowledge, this\nwork is the first to verify these protocols using a decidable logic, and the\nfirst formal verification of Vertical Paxos, Fast Paxos and Stoppable Paxos.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 15:37:42 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Padon", "Oded", ""], ["Losa", "Giuliano", ""], ["Sagiv", "Mooly", ""], ["Shoham", "Sharon", ""]]}, {"id": "1710.07258", "submitter": "Michael Blondin", "authors": "Michael Blondin, Alain Finkel, Jean Goubault-Larrecq", "title": "Forward Analysis for WSTS, Part III: Karp-Miller Trees", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 2 (June 23,\n  2020) lmcs:6591", "doi": "10.23638/LMCS-16(2:13)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is a sequel of \"Forward Analysis for WSTS, Part I: Completions\"\n[STACS 2009, LZI Intl. Proc. in Informatics 3, 433-444] and \"Forward Analysis\nfor WSTS, Part II: Complete WSTS\" [Logical Methods in Computer Science 8(3),\n2012]. In these two papers, we provided a framework to conduct forward\nreachability analyses of WSTS, using finite representations of downward-closed\nsets. We further develop this framework to obtain a generic Karp-Miller\nalgorithm for the new class of very-WSTS. This allows us to show that\ncoverability sets of very-WSTS can be computed as their finite ideal\ndecompositions. Under natural effectiveness assumptions, we also show that LTL\nmodel checking for very-WSTS is decidable. The termination of our procedure\nrests on a new notion of acceleration levels, which we study. We characterize\nthose domains that allow for only finitely many accelerations, based on ordinal\nranks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Oct 2017 17:29:38 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 16:17:37 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 23:45:39 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 00:21:30 GMT"}, {"version": "v5", "created": "Mon, 22 Jun 2020 07:38:58 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Blondin", "Michael", ""], ["Finkel", "Alain", ""], ["Goubault-Larrecq", "Jean", ""]]}, {"id": "1710.07516", "submitter": "Anton Salikhmetov", "authors": "Anton Salikhmetov", "title": "An impure solution to the problem of matching fans", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm to solve the problem of matching fans in interaction\nnet implementations of optimal reduction for the pure untyped lambda calculus\nwithout use of any additional agent types. The algorithm relies upon a specific\ninteraction nets reduction strategy and involves side effects in one of\ninteraction rules.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 12:57:00 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 11:20:22 GMT"}, {"version": "v3", "created": "Sun, 1 Apr 2018 10:33:10 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Salikhmetov", "Anton", ""]]}, {"id": "1710.07528", "submitter": "Georg Zetzsche", "authors": "Georg Zetzsche", "title": "The Emptiness Problem for Valence Automata over Graph Monoids", "comments": "Preprint of contribution to special issue on RP2015 (Information &\n  Computation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work studies which storage mechanisms in automata permit decidability of\nthe emptiness problem. The question is formalized using valence automata, an\nabstract model of automata in which the storage mechanism is given by a monoid.\nFor each of a variety of storage mechanisms, one can choose a (typically\ninfinite) monoid $M$ such that valence automata over $M$ are equivalent to\n(one-way) automata with this type of storage. In fact, many important storage\nmechanisms can be realized by monoids defined by finite graphs, called graph\nmonoids. Examples include pushdown stacks, partially blind counters (which\nbehave like Petri net places), blind counters (which may attain negative\nvalues), and combinations thereof.\n  Hence, we study for which graph monoids the emptiness problem for valence\nautomata is decidable. A particular model realized by graph monoids is that of\nPetri nets with a pushdown stack. For these, decidability is a long-standing\nopen question and we do not answer it here.\n  However, if one excludes subgraphs corresponding to this model, a\ncharacterization can be achieved. Moreover, we provide a description of those\nstorage mechanisms for which decidability remains open. This leads to a model\nthat naturally generalizes both pushdown Petri nets and the priority\nmulticounter machines introduced by Reinhardt.\n  The cases that are proven decidable constitute a natural and apparently new\nextension of Petri nets with decidable reachability. It is finally shown that\nthis model can be combined with another such extension by Atig and Ganty: We\npresent a further decidability result that subsumes both of these Petri net\nextensions.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 13:44:30 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Zetzsche", "Georg", ""]]}, {"id": "1710.07660", "submitter": "Yuepeng Wang", "authors": "Yuepeng Wang, Isil Dillig, Shuvendu K. Lahiri, William R. Cook", "title": "Verifying Equivalence of Database-Driven Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of verifying equivalence between a pair of\nprograms that operate over databases with different schemas. This problem is\nparticularly important in the context of web applications, which typically\nundergo database refactoring either for performance or maintainability reasons.\nWhile web applications should have the same externally observable behavior\nbefore and after schema migration, there are no existing tools for proving\nequivalence of such programs. This paper takes a first step towards solving\nthis problem by formalizing the equivalence and refinement checking problems\nfor database-driven applications. We also propose a proof methodology based on\nthe notion of bisimulation invariants over relational algebra with updates and\ndescribe a technique for synthesizing such bisimulation invariants. We have\nimplemented the proposed technique in a tool called Mediator for verifying\nequivalence between database-driven applications written in our intermediate\nlanguage and evaluate our tool on 21 benchmarks extracted from textbooks and\nreal-world web applications. Our results show that the proposed methodology can\nsuccessfully verify 20 of these benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Oct 2017 18:38:40 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Wang", "Yuepeng", ""], ["Dillig", "Isil", ""], ["Lahiri", "Shuvendu K.", ""], ["Cook", "William R.", ""]]}, {"id": "1710.07903", "submitter": "Guillermo P\\'erez", "authors": "Stephane Le Roux and Guillermo A. Perez", "title": "The Complexity of Graph-Based Reductions for Reachability in Markov\n  Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the never-worse relation (NWR) for Markov decision processes with an\ninfinite-horizon reachability objective. A state q is never worse than a state\np if the maximal probability of reaching the target set of states from p is at\nmost the same value from q, regard- less of the probabilities labelling the\ntransitions. Extremal-probability states, end components, and essential states\nare all special cases of the equivalence relation induced by the NWR. Using the\nNWR, states in the same equivalence class can be collapsed. Then, actions\nleading to sub- optimal states can be removed. We show the natural decision\nproblem associated to computing the NWR is coNP-complete. Finally, we ex- tend\na previously known incomplete polynomial-time iterative algorithm to\nunder-approximate the NWR.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 07:40:11 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 12:00:26 GMT"}, {"version": "v3", "created": "Sun, 28 Jan 2018 11:03:47 GMT"}, {"version": "v4", "created": "Sat, 24 Feb 2018 12:26:03 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Roux", "Stephane Le", ""], ["Perez", "Guillermo A.", ""]]}, {"id": "1710.07997", "submitter": "Wiktor Daszczuk", "authors": "Wiktor B. Daszczuk", "title": "Timed Concurrent State Machines", "comments": "13 pages, 4 figures", "journal-ref": "Computer Science, vol. 8, 2007, pp. 23-36", "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timed Concurrent State Machines are an application of Alur's Timed Automata\nconcept to coincidence-based (rather than interleaving) CSM modeling technique.\nTCSM support the idea of testing automata, allowing to specify time properties\neasier than temporal formulas. Also, calculation of a global state space in\nreal-time domain (Region Concurrent State Machines) is defined, allowing to\nstore a verified system in ready-to-verification form, and to multiply it by\nvarious testing automata.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 18:41:28 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Daszczuk", "Wiktor B.", ""]]}, {"id": "1710.08195", "submitter": "Stavros Tripakis", "authors": "Iulia Dragomir and Viorel Preoteasa and Stavros Tripakis", "title": "The Refinement Calculus of Reactive Systems Toolset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Refinement Calculus of Reactive Systems Toolset, an\nenvironment for compositional modeling and reasoning about reactive systems,\nbuilt on top of Isabelle, Simulink, and Python.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 10:57:35 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 08:49:28 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 14:12:32 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Dragomir", "Iulia", ""], ["Preoteasa", "Viorel", ""], ["Tripakis", "Stavros", ""]]}, {"id": "1710.08326", "submitter": "Ranald Clouston", "authors": "Ranald Clouston", "title": "Fitch-Style Modal Lambda Calculi", "comments": "Accepted paper at the 21st International Conference on Foundations of\n  Software Science and Computation Structures (FoSSaCS 2018). This version\n  includes appendices containing many proof details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitch-style modal deduction, in which modalities are eliminated by opening a\nsubordinate proof, and introduced by shutting one, were investigated in the\n1990s as a basis for lambda calculi. We show that such calculi have good\ncomputational properties for a variety of intuitionistic modal logics.\nSemantics are given in cartesian closed categories equipped with an adjunction\nof endofunctors, with the necessity modality interpreted by the right adjoint.\nWhere this functor is an idempotent comonad, a coherence result on the\nsemantics allows us to present a calculus for intuitionistic S4 that is simpler\nthan others in the literature. We show the calculi can be extended \\`{a} la\ntense logic with the left adjoint of necessity, and are then complete for the\ncategorical semantics.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 15:15:27 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 15:05:17 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Clouston", "Ranald", ""]]}, {"id": "1710.08350", "submitter": "Thorsten Wissmann", "authors": "Michele Boreale", "title": "Algebra, coalgebra, and minimization in polynomial differential\n  equations", "comments": "27 pages, extended and revised version of FOSSACS 2017 paper", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (February\n  15, 2019) lmcs:5192", "doi": "10.23638/LMCS-15(1:14)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider reasoning and minimization in systems of polynomial ordinary\ndifferential equations (ode's). The ring of multivariate polynomials is\nemployed as a syntax for denoting system behaviours. We endow this set with a\ntransition system structure based on the concept of Lie-derivative, thus\ninducing a notion of L-bisimulation. We prove that two states (variables) are\nL-bisimilar if and only if they correspond to the same solution in the ode's\nsystem. We then characterize L-bisimilarity algebraically, in terms of certain\nideals in the polynomial ring that are invariant under Lie-derivation. This\ncharacterization allows us to develop a complete algorithm, based on building\nan ascending chain of ideals, for computing the largest L-bisimulation\ncontaining all valid identities that are instances of a user-specified\ntemplate. A specific largest L-bisimulation can be used to build a reduced\nsystem of ode's, equivalent to the original one, but minimal among all those\nobtainable by linear aggregation of the original equations. A computationally\nless demanding approximate reduction and linearization technique is also\nproposed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 15:51:14 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 13:38:46 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 13:56:32 GMT"}, {"version": "v4", "created": "Thu, 14 Feb 2019 15:47:46 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Boreale", "Michele", ""]]}, {"id": "1710.08444", "submitter": "Vasileios Koutavas", "authors": "Edsko de Vries, Vasileios Koutavas", "title": "Locally Nameless Permutation Types", "comments": "Coq code in ancillary files", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define \"Locally Nameless Permutation Types\", which fuse permutation types\nas used in Nominal Isabelle with the locally nameless representation. We show\nthat this combination is particularly useful when formalizing programming\nlanguages where bound names may become free during execution (\"extrusion\"),\ncommon in process calculi. It inherits the generic definition of permutations\nand support, and associated lemmas, from the Nominal approach, and the ability\nto stay close to pencil-and-paper proofs from the locally nameless approach. We\nexplain how to use cofinite quantification in this setting, show why reasoning\nabout renaming is more important here than in languages without extrusion, and\nprovide results about infinite support, necessary when reasoning about\ncountable choice.\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 18:30:04 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["de Vries", "Edsko", ""], ["Koutavas", "Vasileios", ""]]}, {"id": "1710.08647", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Milan Ceska and Vojtech Havlena and Lukas Holik and Ondrej Lengal and\n  Tomas Vojnar", "title": "Approximate Reduction of Finite Automata for High-Speed Network\n  Intrusion Detection (Technical Report)", "comments": "An extended version of a paper accepted at TACAS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximate reduction of non-deterministic\nautomata that appear in hardware-accelerated network intrusion detection\nsystems (NIDSes). We define an error distance of a reduced automaton from the\noriginal one as the probability of packets being incorrectly classified by the\nreduced automaton (wrt the probabilistic distribution of packets in the network\ntraffic). We use this notion to design an approximate reduction procedure that\nachieves a great size reduction (much beyond the state-of-the-art\nlanguage-preserving techniques) with a controlled and small error. We have\nimplemented our approach and evaluated it on use cases from Snort, a popular\nNIDS. Our results provide experimental evidence that the method can be highly\nefficient in practice, allowing NIDSes to follow the rapid growth in the speed\nof networks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 08:33:34 GMT"}, {"version": "v2", "created": "Sat, 27 Jan 2018 22:23:47 GMT"}, {"version": "v3", "created": "Wed, 21 Feb 2018 13:48:13 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Ceska", "Milan", ""], ["Havlena", "Vojtech", ""], ["Holik", "Lukas", ""], ["Lengal", "Ondrej", ""], ["Vojnar", "Tomas", ""]]}, {"id": "1710.08668", "submitter": "Yotam Feldman", "authors": "Yotam M. Y. Feldman, Oded Padon, Neil Immerman, Mooly Sagiv and Sharon\n  Shoham", "title": "Bounded Quantifier Instantiation for Checking Inductive Invariants", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (August\n  21, 2019) lmcs:5700", "doi": "10.23638/LMCS-15(3:18)2019", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of checking whether a proposed invariant $\\varphi$\nexpressed in first-order logic with quantifier alternation is inductive, i.e.\npreserved by a piece of code. While the problem is undecidable, modern SMT\nsolvers can sometimes solve it automatically. However, they employ powerful\nquantifier instantiation methods that may diverge, especially when $\\varphi$ is\nnot preserved. A notable difficulty arises due to counterexamples of infinite\nsize.\n  This paper studies Bounded-Horizon instantiation, a natural method for\nguaranteeing the termination of SMT solvers. The method bounds the depth of\nterms used in the quantifier instantiation process. We show that this method is\nsurprisingly powerful for checking quantified invariants in uninterpreted\ndomains. Furthermore, by producing partial models it can help the user diagnose\nthe case when $\\varphi$ is not inductive, especially when the underlying reason\nis the existence of infinite counterexamples.\n  Our main technical result is that Bounded-Horizon is at least as powerful as\ninstrumentation, which is a manual method to guarantee convergence of the\nsolver by modifying the program so that it admits a purely universal invariant.\nWe show that with a bound of 1 we can simulate a natural class of\ninstrumentations, without the need to modify the code and in a fully automatic\nway. We also report on a prototype implementation on top of Z3, which we used\nto verify several examples by Bounded-Horizon of bound 1.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 09:18:55 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 20:36:00 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 08:41:52 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Feldman", "Yotam M. Y.", ""], ["Padon", "Oded", ""], ["Immerman", "Neil", ""], ["Sagiv", "Mooly", ""], ["Shoham", "Sharon", ""]]}, {"id": "1710.08755", "submitter": "Tatsuji Kawai", "authors": "Tatsuji Kawai", "title": "Formally continuous functions on Baire space", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A function from Baire space to the natural numbers is called formally\ncontinuous if it is induced by a morphism between the corresponding formal\nspaces. We compare formal continuity to two other notions of continuity on\nBaire space working in Bishop constructive mathematics: one is a function\ninduced by a Brouwer-operation (i.e. inductively defined neighbourhood\nfunction); the other is a function uniformly continuous near every compact\nimage. We show that formal continuity is equivalent to the former while it is\nstrictly stronger than the latter.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 13:27:16 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Kawai", "Tatsuji", ""]]}, {"id": "1710.08996", "submitter": "Daniel Hausmann", "authors": "Daniel Hausmann, Lutz Schr\\\"oder and Hans-Peter Deifel", "title": "Permutation Games for the Weakly Aconjunctive $\\mu$-Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a natural notion of limit-deterministic parity automata and\npresent a method that uses such automata to construct satisfiability games for\nthe weakly aconjunctive fragment of the $\\mu$-calculus. To this end we devise a\nmethod that determinizes limit-deterministic parity automata of size $n$ with\n$k$ priorities through limit-deterministic B\\\"uchi automata to deterministic\nparity automata of size $\\mathcal{O}((nk)!)$ and with $\\mathcal{O}(nk)$\npriorities. The construction relies on limit-determinism to avoid the full\ncomplexity of the Safra/Piterman-construction by using partial permutations of\nstates in place of Safra-Trees. By showing that limit-deterministic parity\nautomata can be used to recognize unsuccessful branches in pre-tableaux for the\nweakly aconjunctive $\\mu$-calculus, we obtain satisfiability games of size\n$\\mathcal{O}((nk)!)$ with $\\mathcal{O}(nk)$ priorities for weakly aconjunctive\ninput formulas of size $n$ and alternation-depth $k$. A prototypical\nimplementation that employs a tableau-based global caching algorithm to solve\nthese games on-the-fly shows promising initial results.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 21:22:13 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 19:43:36 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Hausmann", "Daniel", ""], ["Schr\u00f6der", "Lutz", ""], ["Deifel", "Hans-Peter", ""]]}, {"id": "1710.09010", "submitter": "Justin Hsu", "authors": "Tetsuya Sato, Gilles Barthe, Marco Gaboardi, Justin Hsu, Shin-ya\n  Katsumata", "title": "Approximate Span Liftings", "comments": null, "journal-ref": null, "doi": "10.1109/LICS.2019.8785668", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop new abstractions for reasoning about relaxations of differential\nprivacy: R\\'enyi differential privacy, zero-concentrated differential privacy,\nand truncated concentrated differential privacy, which express different bounds\non statistical divergences between two output probability distributions. In\norder to reason about such properties compositionally, we introduce approximate\nspan-lifting, a novel construction extending the approximate relational lifting\napproaches previously developed for standard differential privacy to a more\ngeneral class of divergences, and also to continuous distributions. As an\napplication, we develop a program logic based on approximate span-liftings\ncapable of proving relaxations of differential privacy and other statistical\ndivergence properties.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 22:30:15 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 16:04:04 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2018 09:58:48 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Sato", "Tetsuya", ""], ["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""], ["Hsu", "Justin", ""], ["Katsumata", "Shin-ya", ""]]}, {"id": "1710.09083", "submitter": "Wiktor Daszczuk", "authors": "Wiktor B. Daszczuk", "title": "State Space Reduction for Reachability Graph of CSM Automata", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": "ICS WUT Research Report No 10/2000", "categories": "cs.SE cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical CTL temporal logics are built over systems with interleaving model\nconcurrency. Many attempts are made to fight a state space explosion problem\n(for instance, compositional model checking). There are some methods of\nreduction of a state space based on independence of actions. However, in CSM\nmodel, which is based on coincidences rather than on interleaving, independence\nof actions cannot be defined. Therefore a state space reduction basing on\nidentical temporal consequences rather than on independence of action is\nproposed. The new reduction is not as good as for interleaving systems, because\nall successors of a state (in depth of two levels) must be obtained before a\nreduction may be applied. This leads to reduction of space required for\nrepresentation of a state space, but not in time of state space construction.\nYet much savings may occur in regular state spaces for CSM systems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 06:17:03 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Daszczuk", "Wiktor B.", ""]]}, {"id": "1710.09102", "submitter": "Robert K\\\"unnemann", "authors": "Robert K\\\"unnemann", "title": "Sufficient and necessary causation are dual", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causation has been the issue of philosophic debate since Hippocrates. Recent\nwork defines actual causation in terms of Pearl/Halpern's causality framework,\nformalizing necessary causes (IJCAI'15). This has inspired causality notions in\nthe security domain (CSF'15), which, perhaps surprisingly, formalize sufficient\ncauses instead. We provide an explicit relation between necessary and\nsufficient causes.\n", "versions": [{"version": "v1", "created": "Wed, 25 Oct 2017 07:57:56 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["K\u00fcnnemann", "Robert", ""]]}, {"id": "1710.09635", "submitter": "Quang-Trung Ta", "authors": "Quang-Trung Ta, Ton Chanh Le, Siau-Cheng Khoo, Wei-Ngan Chin", "title": "Automated Lemma Synthesis in Symbolic-Heap Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The symbolic-heap fragment of separation logic has been actively developed\nand advocated for verifying the memory-safety property of computer programs. At\npresent, one of its biggest challenges is to effectively prove entailments\ncontaining inductive heap predicates. These entailments are usually proof\nobligations generated when verifying programs that manipulate complex data\nstructures like linked lists, trees, or graphs.\n  To assist in proving such entailments, this paper introduces a lemma\nsynthesis framework, which automatically discovers lemmas to serve as eureka\nsteps in the proofs. Mathematical induction and template-based constraint\nsolving are two pillars of our framework. To derive the supporting lemmas for a\ngiven entailment, the framework firstly identifies possible lemma templates\nfrom the entailment's heap structure. It then sets up unknown relations among\neach template's variables and conducts structural induction proof to generate\nconstraints about these relations. Finally, it solves the constraints to find\nout actual definitions of the unknown relations, thus discovers the lemmas. We\nhave integrated this framework into a prototype prover and have experimented it\non various entailment benchmarks. The experimental results show that our\nlemma-synthesis-assisted prover can prove many entailments that could not be\nhandled by existing techniques. This new proposal opens up more opportunities\nto automatically reason with complex inductive heap predicates.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 10:49:29 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 15:41:02 GMT"}, {"version": "v3", "created": "Wed, 8 Nov 2017 07:01:50 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Ta", "Quang-Trung", ""], ["Le", "Ton Chanh", ""], ["Khoo", "Siau-Cheng", ""], ["Chin", "Wei-Ngan", ""]]}, {"id": "1710.09844", "submitter": "Kartik Nagar", "authors": "Gowtham Kaki, Kartik Nagar, Mahsa Nazafzadeh and Suresh Jagannathan", "title": "Alone Together: Compositional Reasoning and Inference for Weak Isolation", "comments": "46 pages, 12 figures", "journal-ref": null, "doi": "10.1145/3158115", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serializability is a well-understood correctness criterion that simplifies\nreasoning about the behavior of concurrent transactions by ensuring they are\nisolated from each other while they execute. However, enforcing serializable\nisolation comes at a steep cost in performance and hence database systems in\npractice support, and often encourage, developers to implement transactions\nusing weaker alternatives. Unfortunately, the semantics of weak isolation is\npoorly understood, and usually explained only informally in terms of low-level\nimplementation artifacts. Consequently, verifying high-level correctness\nproperties in such environments remains a challenging problem.\n  To address this issue, we present a novel program logic that enables\ncompositional reasoning about the behavior of concurrently executing\nweakly-isolated transactions. Recognizing that the proof burden necessary to\nuse this logic may dissuade application developers, we also describe an\ninference procedure based on this foundation that ascertains the weakest\nisolation level that still guarantees the safety of high-level consistency\ninvariants associated with such transactions. The key to effective inference is\nthe observation that weakly-isolated transactions can be viewed as functional\n(monadic) computations over an abstract database state, allowing us to treat\ntheir operations as state transformers over the database. This interpretation\nenables automated verification using off-the-shelf SMT solvers. Case studies\nand experiments of real-world applications (written in an embedded DSL in\nOCaml) demonstrate the utility of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 18:00:07 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 21:43:32 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Kaki", "Gowtham", ""], ["Nagar", "Kartik", ""], ["Nazafzadeh", "Mahsa", ""], ["Jagannathan", "Suresh", ""]]}, {"id": "1710.09864", "submitter": "Emil Je\\v{r}\\'abek", "authors": "Emil Je\\v{r}\\'abek", "title": "Recursive functions and existentially closed structures", "comments": "42 pages; to appear in Journal of Mathematical Logic", "journal-ref": "Journal of Mathematical Logic 20 (2020), no. 1, article no.\n  2050002, 52 pp", "doi": "10.1142/S0219061320500026", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to clarify the relationship between various\nconditions implying essential undecidability: our main result is that there\nexists a theory $T$ in which all partially recursive functions are\nrepresentable, yet $T$ does not interpret Robinson's theory $R$. To this end,\nwe borrow tools from model theory--specifically, we investigate model-theoretic\nproperties of the model completion of the empty theory in a language with\nfunction symbols. We obtain a certain characterization of $\\exists\\forall$\ntheories interpretable in existential theories in the process.\n", "versions": [{"version": "v1", "created": "Thu, 26 Oct 2017 18:44:06 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 07:47:48 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Je\u0159\u00e1bek", "Emil", ""]]}, {"id": "1710.09951", "submitter": "Justin Hsu", "authors": "Justin Hsu", "title": "Probabilistic Couplings for Probabilistic Reasoning", "comments": "PhD thesis, University of Pennsylvania, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis explores proofs by coupling from the perspective of formal\nverification. Long employed in probability theory and theoretical computer\nscience, these proofs construct couplings between the output distributions of\ntwo probabilistic processes. Couplings can imply various guarantees comparing\ntwo runs of a probabilistic computation. We first show that proofs in the\nprogram logic pRHL describe couplings. We formalize couplings that establish\nvarious probabilistic properties, including distribution equivalence,\nconvergence, and stochastic domination. Then we give a proofs-as-programs\ninterpretation: a coupling proof encodes a probabilistic product program, whose\nproperties imply relational properties of the original programs. We design the\nlogic xpRHL to construct the product, with extensions to model shift coupling\nand path coupling. We then propose an approximate version of probabilistic\ncoupling and a corresponding proof technique---proof by approximate\ncoupling---inspired by the logic apRHL, a version of pRHL for building\napproximate liftings. Drawing on ideas from existing privacy proofs, we extend\napRHL with novel proof rules for constructing new approximate couplings. We\ngive an approximate coupling proof of privacy for the Sparse Vector mechanism,\na well-known algorithm from the privacy literature whose privacy proof is\nnotoriously subtle, and produce the first formalized proof of privacy for\nSparse Vector in apRHL. Finally, we propose several more sophisticated\nconstructions for approximate couplings: a principle for showing\naccuracy-dependent privacy, a generalization of the advanced composition\ntheorem, and an optimal approximate coupling relating two subsets. We also show\nequivalences between our approximate couplings and other existing definitions.\nThese ingredients support the first formalized proof of privacy for the Between\nThresholds mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 00:13:45 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 00:44:30 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Hsu", "Justin", ""]]}, {"id": "1710.10109", "submitter": "Laurent Bartholdi", "authors": "Laurent Bartholdi, Ivan Mitrofanov", "title": "The word and order problems for self-similar and automata groups", "comments": "Fixed broken references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the word problem is undecidable in functionally recursive\ngroups, and that the order problem is undecidable in automata groups, even\nunder the assumption that they are contracting.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 12:51:10 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 20:13:02 GMT"}, {"version": "v3", "created": "Thu, 23 Nov 2017 10:30:30 GMT"}, {"version": "v4", "created": "Mon, 27 Nov 2017 17:51:43 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Bartholdi", "Laurent", ""], ["Mitrofanov", "Ivan", ""]]}, {"id": "1710.10203", "submitter": "James Laird", "authors": "James Laird", "title": "Intensional and Extensional Semantics of Bounded and Unbounded\n  Nondeterminism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give extensional and intensional characterizations of nondeterministic\nfunctional programs: as structure preserving functions between biorders, and as\nnondeterministic sequential algorithms on ordered concrete data structures\nwhich compute them. A fundamental result establishes that the extensional and\nintensional representations of non-deterministic programs are equivalent, by\nshowing how to construct a unique sequential algorithm which computes a given\nmonotone and stable function, and describing the conditions on sequential\nalgorithms which correspond to continuity with respect to each order.\n  We illustrate by defining may and must-testing denotational semantics for a\nsequential functional language with bounded and unbounded choice operators. We\nprove that these are computationally adequate, despite the non-continuity of\nthe must-testing semantics of unbounded nondeterminism. In the bounded case, we\nprove that our continuous models are fully abstract with respect to may and\nmust-testing by identifying a simple universal type, which may also form the\nbasis for models of the untyped lambda-calculus. In the unbounded case we\nobserve that our model contains computable functions which are not denoted by\nterms, by identifying a further \"weak continuity\" property of the definable\nelements, and use this to establish that it is not fully abstract.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 15:38:20 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 14:52:54 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 21:27:24 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Laird", "James", ""]]}, {"id": "1710.10205", "submitter": "Paolo Pistone", "authors": "Paolo Pistone", "title": "Polymorphism and the obstinate circularity of second order logic: a\n  victims' tale", "comments": null, "journal-ref": null, "doi": "10.1017/bsl.2017.43", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The investigations on higher-order type theories and on the related notion of\nparametric polymorphism constitute the technical counterpart of the old\nfoundational problem of the circularity (or impredicativity) of second and\nhigher order logic. However, the epistemological significance of such\ninvestigations, and of their often non trivial results, has not received much\nattention in the contemporary foundational debate. The results recalled in this\npaper suggest that the question of the circularity of second order logic cannot\nbe reduced to the simple assessment of a vicious circle. Through a comparison\nbetween the faulty consistency arguments given by Frege and Martin-L\\\"of,\nrespectively for the logical system of the Grundgesetze (shown inconsistent by\nRussell's paradox) and for the intuitionistic type theory with a type of all\ntypes (shown inconsistent by Girard's paradox), and the normalization argument\nfor second order type theory (or System F), we indicate a bunch of subtle\nmathematical problems and logical concepts hidden behind the hazardous idea of\nimpredicative quantification, constituting a vast (and largely unexplored)\ndomain for foundational research.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 15:41:23 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Pistone", "Paolo", ""]]}, {"id": "1710.10292", "submitter": "Florian Zuleger", "authors": "Florian Zuleger", "title": "Ranking Functions for Vector Addition Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector addition systems are an important model in theoretical computer\nscience and have been used for the analysis of systems in a variety of areas.\nTermination is a crucial property of vector addition systems and has received\nconsiderable interest in the literature. In this paper we give a complete\nmethod for the construction of ranking functions for vector addition systems\nwith states. The interest in ranking functions is motivated by the fact that\nranking functions provide valuable additional information in case of\ntermination: They provide an explanation for the progress of the vector\naddition system, which can be reported to the user of a verification tool, and\ncan be used as certificates for termination. Moreover, we show how ranking\nfunctions can be used for the computational complexity analysis of vector\naddition systems (here complexity refers to the number of steps the vector\naddition system under analysis can take in terms of the given initial vector).\n", "versions": [{"version": "v1", "created": "Mon, 23 Oct 2017 09:22:06 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Zuleger", "Florian", ""]]}, {"id": "1710.10294", "submitter": "Ralf Wimmer", "authors": "Sebastian Junges, Nils Jansen, Ralf Wimmer, Tim Quatmann, Leonore\n  Winterer, Joost-Pieter Katoen, Bernd Becker", "title": "Permissive Finite-State Controllers of POMDPs using Parameter Synthesis", "comments": "This is an extended version of the paper: S. Junges, N. Jansen, R.\n  Wimmer, T. Quatmann, L. Winterer, J.-P. Katoen, B. Becker: Finite-state\n  Controllers of POMDPs via Parameter Synthesis. Proceedings of the Conference\n  on Uncertainty in Artificial Intelligence (UAI 2018), Monterey, CA, USA,\n  August 6-10, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study finite-state controllers (FSCs) for partially observable Markov\ndecision processes (POMDPs) that are provably correct with respect to given\nspecifications. The key insight is that computing (randomised) FSCs on POMDPs\nis equivalent to - and computationally as hard as - synthesis for parametric\nMarkov chains (pMCs). This correspondence allows to use tools for parameter\nsynthesis in pMCs to compute correct-by-construction FSCs on POMDPs for a\nvariety of specifications. Our experimental evaluation shows comparable\nperformance to well-known POMDP solvers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 09:57:25 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 16:46:42 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Junges", "Sebastian", ""], ["Jansen", "Nils", ""], ["Wimmer", "Ralf", ""], ["Quatmann", "Tim", ""], ["Winterer", "Leonore", ""], ["Katoen", "Joost-Pieter", ""], ["Becker", "Bernd", ""]]}, {"id": "1710.10307", "submitter": "Guillaume Brunerie", "authors": "Guillaume Brunerie", "title": "The James construction and $\\pi_4(\\mathbb{S}^3)$ in homotopy type theory", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the first part of this paper we present a formalization in Agda of the\nJames construction in homotopy type theory. We include several fragments of\ncode to show what the Agda code looks like, and we explain several techniques\nthat we used in the formalization. In the second part, we use the James\nconstruction to give a constructive proof that $\\pi_4(\\mathbb{S}^3)$ is of the\nform $\\mathbb{Z}/n\\mathbb{Z}$ (but we do not compute the $n$ here).\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 19:12:40 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Brunerie", "Guillaume", ""]]}, {"id": "1710.10402", "submitter": "Thorsten Wissmann", "authors": "Ana Sokolova and Harald Woracek", "title": "Termination in Convex Sets of Distributions", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (November\n  20, 2018) lmcs:4983", "doi": "10.23638/LMCS-14(4:17)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convex algebras, also called (semi)convex sets, are at the heart of modelling\nprobabilistic systems including probabilistic automata. Abstractly, they are\nthe Eilenberg-Moore algebras of the finitely supported distribution monad.\nConcretely, they have been studied for decades within algebra and convex\ngeometry.\n  In this paper we study the problem of extending a convex algebra by a single\npoint. Such extensions enable the modelling of termination in probabilistic\nsystems. We provide a full description of all possible extensions for a\nparticular class of convex algebras: For a fixed convex subset $D$ of a vector\nspace satisfying additional technical condition, we consider the algebra of\nconvex subsets of $D$. This class contains the convex algebras of convex\nsubsets of distributions, modelling (nondeterministic) probabilistic automata.\nWe also provide a full description of all possible extensions for the class of\nfree convex algebras, modelling fully probabilistic systems. Finally, we show\nthat there is a unique functorial extension, the so-called black-hole\nextension.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 06:44:29 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 13:20:00 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2018 17:15:36 GMT"}, {"version": "v4", "created": "Tue, 30 Oct 2018 09:23:23 GMT"}, {"version": "v5", "created": "Mon, 19 Nov 2018 08:47:25 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Sokolova", "Ana", ""], ["Woracek", "Harald", ""]]}, {"id": "1710.10706", "submitter": "Sebastian Enqvist", "authors": "Sebastian Enqvist and Yde Venema", "title": "Disjunctive bases: normal forms and model theory for modal logics", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (March 27,\n  2019) lmcs:5313", "doi": "10.23638/LMCS-15(1:30)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the concept of a disjunctive basis as a generic framework for\nnormal forms in modal logic based on coalgebra. Disjunctive bases were defined\nin previous work on completeness for modal fixpoint logics, where they played a\ncentral role in the proof of a generic completeness theorem for coalgebraic\nmu-calculi. Believing the concept has a much wider significance, here we\ninvestigate it more thoroughly in its own right. We show that the presence of a\ndisjunctive basis at the \"one-step\" level entails a number of good properties\nfor a coalgebraic mu-calculus, in particular, a simulation theorem showing that\nevery alternating automaton can be transformed into an equivalent\nnondeterministic one. Based on this, we prove a Lyndon theorem for the full\nfixpoint logic, its fixpoint-free fragment and its one-step fragment, a Uniform\nInterpolation result, for both the full mu-calculus and its fixpoint-free\nfragment, and a Janin-Walukiewicz-style characterization theorem for the\nmu-calculus under slightly stronger assumptions.\n  We also raise the questions, when a disjunctive basis exists, and how\ndisjunctive bases are related to Moss' coalgebraic \"nabla\" modalities. Nabla\nformulas provide disjunctive bases for many coalgebraic modal logics, but there\nare cases where disjunctive bases give useful normal forms even when nabla\nformulas fail to do so, our prime example being graded modal logic. We also\nshow that disjunctive bases are preserved by forming sums, products and\ncompositions of coalgebraic modal logics, providing tools for modular\nconstruction of modal logics admitting disjunctive bases. Finally, we consider\nthe problem of giving a category-theoretic formulation of disjunctive bases,\nand provide a partial solution.\n", "versions": [{"version": "v1", "created": "Sun, 29 Oct 2017 22:16:41 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 22:14:24 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 10:53:16 GMT"}, {"version": "v4", "created": "Mon, 25 Feb 2019 17:06:22 GMT"}, {"version": "v5", "created": "Wed, 6 Mar 2019 14:48:11 GMT"}, {"version": "v6", "created": "Tue, 26 Mar 2019 13:35:31 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Enqvist", "Sebastian", ""], ["Venema", "Yde", ""]]}, {"id": "1710.10756", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Ondrej Lengal and Anthony W. Lin and Rupak Majumdar and Philipp\n  Ruemmer", "title": "Fair Termination for Parameterized Probabilistic Concurrent Systems\n  (Technical Report)", "comments": "A technical report of a TACAS'17 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of automatically verifying that a parameterized\nfamily of probabilistic concurrent systems terminates with probability one for\nall instances against adversarial schedulers. A parameterized family defines an\ninfinite-state system: for each number n, the family consists of an instance\nwith n finite-state processes. In contrast to safety, the parameterized\nverification of liveness is currently still considered extremely challenging\nespecially in the presence of probabilities in the model. One major challenge\nis to provide a sufficiently powerful symbolic framework. One well-known\nsymbolic framework for the parameterized verification of non-probabilistic\nconcurrent systems is regular model checking. Although the framework was\nrecently extended to probabilistic systems, incorporating fairness in the\nframework - often crucial for verifying termination - has been especially\ndifficult due to the presence of an infinite number of fairness constraints\n(one for each process). Our main contribution is a systematic,\nregularity-preserving, encoding of finitary fairness (a realistic notion of\nfairness proposed by Alur & Henzinger) in the framework of regular model\nchecking for probabilistic parameterized systems. Our encoding reduces\ntermination with finitary fairness to verifying parameterized termination\nwithout fairness over probabilistic systems in regular model checking (for\nwhich a verification framework already exists). We show that our algorithm\ncould verify termination for many interesting examples from distributed\nalgorithms (Herman's protocol) and evolutionary biology (Moran process, cell\ncycle switch), which do not hold under the standard notion of fairness. To the\nbest of our knowledge, our algorithm is the first fully-automatic method that\ncan prove termination for these examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 03:33:46 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Lengal", "Ondrej", ""], ["Lin", "Anthony W.", ""], ["Majumdar", "Rupak", ""], ["Ruemmer", "Philipp", ""]]}, {"id": "1710.10805", "submitter": "Ranald Clouston", "authors": "Zh\\'e H\\'ou, Ranald Clouston, Rajeev Gor\\'e, Alwen Tiu", "title": "Modular Labelled Sequent Calculi for Abstract Separation Logics", "comments": "Accepted for publication in ACM Transactions on Computational Logic\n  (TOCL). arXiv admin note: text overlap with arXiv:1307.5592", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract separation logics are a family of extensions of Hoare logic for\nreasoning about programs that manipulate resources such as memory locations.\nThese logics are \"abstract\" because they are independent of any particular\nconcrete resource model. Their assertion languages, called propositional\nabstract separation logics (PASLs), extend the logic of (Boolean) Bunched\nImplications (BBI) in various ways. In particular, these logics contain the\nconnectives $*$ and $-\\!*$, denoting the composition and extension of resources\nrespectively.\n  This added expressive power comes at a price since the resulting logics are\nall undecidable. Given their wide applicability, even a semi-decision procedure\nfor these logics is desirable. Although several PASLs and their relationships\nwith BBI are discussed in the literature, the proof theory and automated\nreasoning for these logics were open problems solved by the conference version\nof this paper, which developed a modular proof theory for various PASLs using\ncut-free labelled sequent calculi. This paper non-trivially improves upon this\nprevious work by giving a general framework of calculi on which any new axiom\nin the logic satisfying a certain form corresponds to an inference rule in our\nframework, and the completeness proof is generalised to consider such axioms.\n  Our base calculus handles Calcagno et al.'s original logic of separation\nalgebras by adding sound rules for partial-determinism and cancellativity,\nwhile preserving cut-elimination. We then show that many important properties\nin separation logic, such as indivisible unit, disjointness, splittability, and\ncross-split, can be expressed in our general axiom form. Thus our framework\noffers inference rules and completeness for these properties for free. Finally,\nwe show how our calculi reduce to calculi with global label substitutions,\nenabling more efficient implementation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 08:38:02 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 14:46:57 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 15:00:23 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["H\u00f3u", "Zh\u00e9", ""], ["Clouston", "Ranald", ""], ["Gor\u00e9", "Rajeev", ""], ["Tiu", "Alwen", ""]]}, {"id": "1710.10941", "submitter": "Simon Huber", "authors": "Marc Bezem, Thierry Coquand, Simon Huber", "title": "The univalence axiom in cubical sets", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we show that Voevodsky's univalence axiom holds in the model of\ntype theory based on symmetric cubical sets. We will also discuss Swan's\nconstruction of the identity type in this variation of cubical sets. This\nproves that we have a model of type theory supporting dependent products,\ndependent sums, univalent universes, and identity types with the usual\njudgmental equality, and this model is formulated in a constructive metatheory.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 13:53:15 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Bezem", "Marc", ""], ["Coquand", "Thierry", ""], ["Huber", "Simon", ""]]}, {"id": "1710.10991", "submitter": "Thorsten Wissmann", "authors": "Bertram Felgenhauer", "title": "Deciding Confluence and Normal Form Properties of Ground Term Rewrite\n  Systems Efficiently", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (October\n  29, 2018) lmcs:4925", "doi": "10.23638/LMCS-14(4:7)2018", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is known that the first-order theory of rewriting is decidable for ground\nterm rewrite systems, but the general technique uses tree automata and often\ntakes exponential time. For many properties, including confluence (CR),\nuniqueness of normal forms with respect to reductions (UNR) and with respect to\nconversions (UNC), polynomial time decision procedures are known for ground\nterm rewrite systems. However, this is not the case for the normal form\nproperty (NFP). In this work, we present a cubic time algorithm for NFP, an\nalmost cubic time algorithm for UNR, and an almost linear time algorithm for\nUNC, improving previous bounds. We also present a cubic time algorithm for CR.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 14:51:25 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 23:32:21 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 15:22:39 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Felgenhauer", "Bertram", ""]]}, {"id": "1710.11204", "submitter": "Haoze Wu", "authors": "Haoze Wu", "title": "Improve SAT-solving with Machine Learning", "comments": "2 pages, SIGCSE SRC 2017", "journal-ref": "In Proceedings of the 2017 ACM SIGCSE Technical Symposium on\n  Computer Science Education (SIGCSE '17). ACM, New York, NY, USA, 787-788\n  (2017)", "doi": "10.1145/3017680.3022464", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project, we aimed to improve the runtime of Minisat, a\nConflict-Driven Clause Learning (CDCL) solver that solves the Propositional\nBoolean Satisfiability (SAT) problem. We first used a logistic regression model\nto predict the satisfiability of propositional boolean formulae after fixing\nthe values of a certain fraction of the variables in each formula. We then\napplied the logistic model and added a preprocessing period to Minisat to\ndetermine the preferable initial value (either true or false) of each boolean\nvariable using a Monte-Carlo approach. Concretely, for each Monte-Carlo trial,\nwe fixed the values of a certain ratio of randomly selected variables, and\ncalculated the confidence that the resulting sub-formula is satisfiable with\nour logistic regression model. The initial value of each variable was set based\non the mean confidence scores of the trials that started from the literals of\nthat variable. We were particularly interested in setting the initial values of\nthe backbone variables correctly, which are variables that have the same value\nin all solutions of a SAT formula. Our Monte-Carlo method was able to set 78%\nof the backbones correctly. Excluding the preprocessing time, compared with the\ndefault setting of Minisat, the runtime of Minisat for satisfiable formulae\ndecreased by 23%. However, our method did not outperform vanilla Minisat in\nruntime, as the decrease in the conflicts was outweighed by the long runtime of\nthe preprocessing period.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 19:13:28 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Wu", "Haoze", ""]]}, {"id": "1710.11500", "submitter": "Luigi Santocanale", "authors": "Luigi Santocanale (LIF)", "title": "The equational theory of the natural join and inner union is decidable", "comments": "arXiv admin note: text overlap with arXiv:1607.02988", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The natural join and the inner union operations combine relations of a\ndatabase. Tropashko and Spight [24] realized that these two operations are the\nmeet and join operations in a class of lattices, known by now as the relational\nlattices. They proposed then lattice theory as an algebraic approach to the\ntheory of databases, alternative to the relational algebra. Previous works [17,\n22] proved that the quasiequational theory of these lattices-that is, the set\nof definite Horn sentences valid in all the relational lattices-is undecidable,\neven when the signature is restricted to the pure lattice signature. We prove\nhere that the equational theory of relational lattices is decidable. That, is\nwe provide an algorithm to decide if two lattice theoretic terms t, s are made\nequal under all intepretations in some relational lattice. We achieve this goal\nby showing that if an inclusion t $\\le$ s fails in any of these lattices, then\nit fails in a relational lattice whose size is bound by a triple exponential\nfunction of the sizes of t and s.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 13:28:14 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Santocanale", "Luigi", "", "LIF"]]}]