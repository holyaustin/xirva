[{"id": "2006.00604", "submitter": "Johannes Marti", "authors": "Johannes Marti", "title": "Conditional Logic is Complete for Convexity in the Plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove completeness of preferential conditional logic with respect to\nconvexity over finite sets of points in the Euclidean plane. A conditional is\ndefined to be true in a finite set of points if all extreme points of the set\ninterpreting the antecedent satisfy the consequent. Equivalently, a conditional\nis true if the antecedent is contained in the convex hull of the points that\nsatisfy both the antecedent and consequent. Our result is then that every\nconsistent formula without nested conditionals is satisfiable in a model based\non a finite set of points in the plane. The proof relies on a result by Richter\nand Rogers showing that every finite abstract convex geometry can be\nrepresented by convex polygons in the plane.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 20:35:54 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 07:17:58 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 20:13:51 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Marti", "Johannes", ""]]}, {"id": "2006.00875", "submitter": "Michael Benedikt", "authors": "Michael Benedikt and Pierre Bourhis and Louis Jachiet and Efthymia\n  Tsamoura", "title": "Balancing expressiveness and inexpressiveness in view design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of data publishing mechanisms that allow a collection of\nautonomous distributed datasources to collaborate to support queries. A common\nmechanism for data publishing is via views: functions that expose derived data\nto users, usually specified as declarative queries. Our autonomy assumption is\nthat the views must be on individual sources, but with the intention of\nsupporting integrated queries. In deciding what data to expose to users, two\nconsiderations must be balanced. The views must be sufficiently expressive to\nsupport queries that users want to ask -- the utility of the publishing\nmechanism. But there may also be some expressiveness restriction. Here we\nconsider two restrictions, a minimal information requirement, saying that the\nviews should reveal as little as possible while supporting the utility query,\nand a non-disclosure requirement, formalizing the need to prevent external\nusers from computing information that data owners do not want revealed.\n  We investigate the problem of designing views that satisfy both an\nexpressiveness and an inexpressiveness requirement, for views in a restricted\ndeclarative language (conjunctive queries), and for arbitrary views.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 12:13:41 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 14:11:43 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Benedikt", "Michael", ""], ["Bourhis", "Pierre", ""], ["Jachiet", "Louis", ""], ["Tsamoura", "Efthymia", ""]]}, {"id": "2006.00915", "submitter": "A. Jesse Jiryu Davis", "authors": "A. Jesse Jiryu Davis and Max Hirschhorn and Judah Schvimer", "title": "eXtreme Modelling in Practice", "comments": null, "journal-ref": "PVLDB (Proceedings of the VLDB Endowment), Vol. 13, No. 9, pp.\n  1346-1358 (2020)", "doi": "10.14778/3397230.3397233", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal modelling is a powerful tool for developing complex systems. At\nMongoDB, we use TLA+ to model and verify multiple aspects of several systems.\nEnsuring conformance between a specification and its implementation can add\nvalue to any specification; it can avoid transcription errors, prevent bugs as\na large organization rapidly develops the specified code, and even keep\nmultiple implementations of the same specification in sync. In this paper, we\nexplore model-based testing as a tool for ensuring specification-implementation\nconformance. We attempted two case studies: model-based trace-checking (MBTC)\nin the MongoDB Server's replication protocol and model-based test-case\ngeneration (MBTCG) in MongoDB Realm Sync's operational transformation\nalgorithm. We found MBTC to be impractical for testing that the Server\nconformed to a highly abstract specification. MBTCG was highly successful for\nRealm Sync, however. We analyze why one technique succeeded and the other\nfailed, and advise future implementers making similar attempts at model-based\ntesting.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 23:51:06 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Davis", "A. Jesse Jiryu", ""], ["Hirschhorn", "Max", ""], ["Schvimer", "Judah", ""]]}, {"id": "2006.01128", "submitter": "J\\'anos V\\'egh", "authors": "J\\'anos V\\'egh", "title": "Introducing temporal behavior to computing science", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The abstraction introduced by von Neumann correctly reflected the state of\nthe art 70 years ago.\n  Although it omitted data transmission time between components of the\ncomputer, it served as an excellent base for classic computing for decades.\n  Modern computer components and architectures, however, require to consider\ntheir temporal behavior: data transmission time in contemporary systems may be\nhigher than their processing time.\n  Using the classic paradigm leaves some issues unexplained, from enormously\nhigh power consumption to days-long training of artificial neural networks to\nfailures of some cutting-edge supercomputer projects.\n  The paper introduces the up to now missing timely behavior (a temporal logic)\ninto computing, while keeps the solid computing science base.\n  The careful analysis discovers that with considering the timely behavior of\ncomponents and architectural principles, the mystic issues have a trivial\nexplanation.\n  Some classic design principles must be revised, and the temporal logic\nenables us to design a more powerful and efficient computing.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 13:21:29 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 12:26:49 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 15:00:53 GMT"}, {"version": "v4", "created": "Sat, 26 Sep 2020 18:58:45 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["V\u00e9gh", "J\u00e1nos", ""]]}, {"id": "2006.01193", "submitter": "Michael Benedikt", "authors": "Michael Benedikt and Egor V. Kostylev and Tony Tan", "title": "Two variable logic with ultimately periodic counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the extension of two variable logic with quantifiers that state\nthat the number of elements where a formula holds should belong to a given\nultimately periodic set. We show that both satisfiability and finite\nsatisfiability of the logic are decidable. We also show that the spectrum of\nany sentence is definable in Presburger arithmetic. In the process we present\nseveral refinements to the ``biregular graph method''. In this method,\ndecidability issues concerning two-variable logics are reduced to questions\nabout Presburger definability of integer vectors associated with partitioned\ngraphs, where nodes in a partition satisfy certain constraints on their in- and\nout-degrees.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 18:32:00 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Benedikt", "Michael", ""], ["Kostylev", "Egor V.", ""], ["Tan", "Tony", ""]]}, {"id": "2006.01621", "submitter": "Aina Niemetz", "authors": "Aina Niemetz and Mathias Preiner", "title": "Bitwuzla at the SMT-COMP 2020", "comments": "System description for SMT-COMP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Bitwuzla, our Satisfiability Modulo Theories (SMT)\nsolver for the theories of bit-vectors, floating-points, arrays and\nuninterpreted functions and their combinations. We discuss selected features\nand provide details of its configuration and participation in the 2020 edition\nof the annual SMT competition.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 02:42:59 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Niemetz", "Aina", ""], ["Preiner", "Mathias", ""]]}, {"id": "2006.01889", "submitter": "Paulius Dilkas", "authors": "Paulius Dilkas, Vaishak Belle", "title": "Generating Random Logic Programs Using Constraint Programming", "comments": "This is an extended version of the paper published in CP 2020", "journal-ref": "In: Simonis H. (eds) Principles and Practice of Constraint\n  Programming. CP 2020. Lecture Notes in Computer Science, vol 12333. Springer,\n  Cham (2020)", "doi": "10.1007/978-3-030-58475-7_48", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing algorithms across a wide range of problem instances is crucial to\nensure the validity of any claim about one algorithm's superiority over\nanother. However, when it comes to inference algorithms for probabilistic logic\nprograms, experimental evaluations are limited to only a few programs. Existing\nmethods to generate random logic programs are limited to propositional programs\nand often impose stringent syntactic restrictions. We present a novel approach\nto generating random logic programs and random probabilistic logic programs\nusing constraint programming, introducing a new constraint to control the\nindependence structure of the underlying probability distribution. We also\nprovide a combinatorial argument for the correctness of the model, show how the\nmodel scales with parameter values, and use the model to compare probabilistic\ninference algorithms across a range of synthetic problems. Our model allows\ninference algorithm developers to evaluate and compare the algorithms across a\nwide range of instances, providing a detailed picture of their (comparative)\nstrengths and weaknesses.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:12:53 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 16:40:31 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Dilkas", "Paulius", ""], ["Belle", "Vaishak", ""]]}, {"id": "2006.02020", "submitter": "Andr\\'e C. R. Martins", "authors": "Andr\\'e C. R. Martins", "title": "Embracing undecidability: Cognitive needs and theory evaluation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.hist-ph cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many ways we can not know. Even in systems that we created\nourselves, as, for example, systems in mathematical logic, Go\\\"edel and\nTarski's theorems impose limits on what we can know. As we try to speak of the\nreal world, things get even harder. We want to compare the results of our\nmathematical theories to observations, and that means the use of inductive\nmethods. While we can demonstrate how an ideal probabilistic induction should\nwork, the requirements of such a method include a few infinities. Furthermore,\nit would not be even enough to be able to compute those methods and obtain\npredictions. There are cases where underdeterminacy might be unavoidable, such\nas the interpretation of quantum mechanics or the current status of string\ntheory. Despite that, scientists still behave as if they were able to know the\ntruth. As it becomes clear that such behavior can cause severe cognitive\nmistakes, the need to accept our limits, both our natural human limits and the\nlimits of the tools we have created, become apparent. This essay will discuss\nhow we must accept that knowledge is almost only limited to formal systems.\nMoreover, even in those, there will always be undecidable propositions. We will\nalso see how those questions influence the evaluation of current theories in\nphysics.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 03:09:01 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Martins", "Andr\u00e9 C. R.", ""]]}, {"id": "2006.02078", "submitter": "Nadia Labai", "authors": "Nadia Labai, Magdalena Ortiz, Mantas \\v{S}imkus", "title": "An ExpTime Upper Bound for $\\mathcal{ALC}$ with Integers (Extended\n  Version)", "comments": "This is a pre-print containing the proofs omitted from the conference\n  version. 36 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concrete domains, especially those that allow to compare features with\nnumeric values, have long been recognized as a very desirable extension of\ndescription logics (DLs), and significant efforts have been invested into\nadding them to usual DLs while keeping the complexity of reasoning in check.\nFor expressive DLs and in the presence of general TBoxes, for standard\nreasoning tasks like consistency, the most general decidability results are for\nthe so-called $\\omega$-admissible domains, which are required to be dense.\nSupporting non-dense domains for features that range over integers or natural\nnumbers remained largely open, despite often being singled out as a highly\ndesirable extension. The decidability of some extensions of $\\mathcal{ALC}$\nwith non-dense domains has been shown, but existing results rely on powerful\nmachinery that does not allow to infer any elementary bounds on the complexity\nof the problem. In this paper, we study an extension of $\\mathcal{ALC}$ with a\nrich integer domain that allows for comparisons (between features, and between\nfeatures and constants coded in unary), and prove that consistency can be\nsolved using automata-theoretic techniques in single exponential time, and thus\nhas no higher worst-case complexity than standard $\\mathcal{ALC}$. Our upper\nbounds apply to some extensions of DLs with concrete domains known from the\nliterature, support general TBoxes, and allow for comparing values along paths\nof ordinary (not necessarily functional) roles.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 07:28:39 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Labai", "Nadia", ""], ["Ortiz", "Magdalena", ""], ["\u0160imkus", "Mantas", ""]]}, {"id": "2006.02081", "submitter": "Olivier Bailleux", "authors": "Olivier Bailleux (LIB), Yacine Boufkhad (LIAFA)", "title": "Constraint Reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a commentary on the CP 2003 paper \"Efficient cnf encoding of boolean\ncardinality constraints\". After recalling its context, we outline a\nclassification of Constraints with respect to their deductive power regarding\nGeneral Arc Consistency (GAC).\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 07:37:05 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Bailleux", "Olivier", "", "LIB"], ["Boufkhad", "Yacine", "", "LIAFA"]]}, {"id": "2006.02417", "submitter": "Cosimo Perini Brogi", "authors": "Cosimo Perini Brogi", "title": "Curry-Howard-Lambek Correspondence for Intuitionistic Belief", "comments": "Submitted to Studia Logica on January 31st, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduces a natural deduction calculus for intuitionistic logic\nof belief $\\mathsf{IEL}^{-}$ which is easily turned into a modal\n$\\lambda$-calculus giving a computational semantics for deductions in\n$\\mathsf{IEL}^{-}$. By using that interpretation, it is also proved that\n$\\mathsf{IEL}^{-}$ has good proof-theoretic properties. The correspondence\nbetween deductions and typed terms is then extended to a categorical semantics\nfor identity of proofs in $\\mathsf{IEL}^{-}$ showing the general structure of\nsuch a modality for belief in an intuitionistic framework.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 17:46:24 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 09:35:06 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Brogi", "Cosimo Perini", ""]]}, {"id": "2006.02847", "submitter": "Linda Anticoli", "authors": "Linda Anticoli and Leonardo Taglialegne", "title": "Quantum Markov Chain Semantics for Quip-E Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we present a mapping from a fragment of the quantum programming\nlanguage Quipper, called Quip-E, to the semantics of the QPMC model checker,\naiming at the automatic verification of quantum programs. As a main outcome, we\ndefine a structural operational semantics for the Quip-E language corresponding\nto quantum Markov chains, and we use it as a basis for analysing quantum\nprograms through the QPMC model checker. The properties of the semantics are\nproved and contextualised in the development of a tool translating from quantum\nprograms to quantum Markov chains.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 13:37:11 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Anticoli", "Linda", ""], ["Taglialegne", "Leonardo", ""]]}, {"id": "2006.02854", "submitter": "Christian Anti\\'c", "authors": "Christian Anti\\'c", "title": "Analogical Proportions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analogy-making is at the core of human intelligence and creativity with\napplications to such diverse tasks as commonsense reasoning, learning, language\nacquisition, and story telling. This paper contributes to the foundations of\nartificial general intelligence by introducing from first principles an\nabstract algebraic framework of analogical proportions of the form `$a$ is to\n$b$ what $c$ is to $d$' in the general setting of universal algebra. This\nenables us to compare mathematical objects possibly across different domains in\na uniform way which is crucial for AI-systems. The main idea is to define\nsolutions to analogical equations in terms of maximal sets of algebraic\njustifications, which amounts to deriving abstract terms of concrete elements\nfrom a `known' source domain which can then be instantiated in an `unknown'\ntarget domain to obtain analogous elements. It turns out that our notion of\nanalogical proportions has appealing mathematical properties. For example, we\nshow that analogical proportions preserve functional dependencies across\ndifferent domains, which is desirable. We study Lepage's axioms of analogical\nproportions and argue why we disagree with his symmetry, central permutation,\nstrong reflexivity, and strong determinism axioms. We compare our framework\nwith two prominent and recently introduced frameworks of analogical proportions\nfrom the literature in the concrete domains of sets and numbers, and we show\nthat in each case we either disagree with the notion from the literature\njustified by some plausible counter-example or we can show that our model\nyields strictly more reasonable solutions. This provides evidence for its\napplicability. In a broader sense, this paper is a first step towards a theory\nof analogical reasoning and learning systems with potential applications to\nfundamental AI-problems like commonsense reasoning and computational learning\nand creativity.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 13:44:36 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 13:54:42 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 14:30:38 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 14:52:31 GMT"}, {"version": "v5", "created": "Sat, 17 Apr 2021 14:36:37 GMT"}, {"version": "v6", "created": "Tue, 25 May 2021 12:12:56 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Anti\u0107", "Christian", ""]]}, {"id": "2006.02887", "submitter": "Francesco Dagnino", "authors": "Francesco Dagnino", "title": "Foundations of regular coinduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inference systems are a widespread framework used to define possibly\nrecursive predicates by means of inference rules. They allow both inductive and\ncoinductive interpretations that are fairly well-studied. In this paper, we\nconsider a middle way interpretation, called regular, which combines advantages\nof both approaches: it allows non-well-founded reasoning while being finite. We\nshow that the natural proof-theoretic definition of the regular interpretation,\nbased on regular trees, coincides with a rational fixed point. Then, we provide\nan equivalent inductive characterization, which leads to an algorithm which\nlooks for a regular derivation of a judgment. Relying on these results, we\ndefine proof techniques for regular reasoning: the regular coinduction\nprinciple, to prove completeness, and an inductive technique to prove\nsoundness, based on the inductive characterization of the regular\ninterpretation. Finally, we show the regular approach can be smoothly extended\nto inference systems with corules, a recently introduced, generalised\nframework, which allows one to refine the coinductive interpretation, proving\nthat also this flexible regular interpretation admits an equivalent inductive\ncharacterisation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 14:33:39 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 12:45:07 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 15:30:23 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 10:45:38 GMT"}, {"version": "v5", "created": "Thu, 20 May 2021 14:52:28 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Dagnino", "Francesco", ""]]}, {"id": "2006.03432", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka", "title": "Lifted Inference in 2-Variable Markov Logic Networks with Function and\n  Cardinality Constraints Using Discrete Fourier Transform", "comments": "arXiv admin note: text overlap with arXiv:2002.10259, This version:\n  fixed a typo in Section 3.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that inference in 2-variable Markov logic networks\n(MLNs) with cardinality and function constraints is domain-liftable. To obtain\nthis result we use existing domain-lifted algorithms for weighted first-order\nmodel counting (Van den Broeck et al, KR 2014) together with discrete Fourier\ntransform of certain distributions associated to MLNs.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 11:07:54 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 13:15:21 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kuzelka", "Ondrej", ""]]}, {"id": "2006.03472", "submitter": "Emile van Krieken", "authors": "Emile van Krieken, Erman Acar, Frank van Harmelen", "title": "Analyzing Differentiable Fuzzy Implications", "comments": "10 pages, 10 figures, accepted to 17th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2020). arXiv admin\n  note: substantial text overlap with arXiv:2002.06100", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining symbolic and neural approaches has gained considerable attention in\nthe AI community, as it is often argued that the strengths and weaknesses of\nthese approaches are complementary. One such trend in the literature are weakly\nsupervised learning techniques that employ operators from fuzzy logics. In\nparticular, they use prior background knowledge described in such logics to\nhelp the training of a neural network from unlabeled and noisy data. By\ninterpreting logical symbols using neural networks (or grounding them), this\nbackground knowledge can be added to regular loss functions, hence making\nreasoning a part of learning.\n  In this paper, we investigate how implications from the fuzzy logic\nliterature behave in a differentiable setting. In such a setting, we analyze\nthe differences between the formal properties of these fuzzy implications. It\nturns out that various fuzzy implications, including some of the most\nwell-known, are highly unsuitable for use in a differentiable learning setting.\nA further finding shows a strong imbalance between gradients driven by the\nantecedent and the consequent of the implication. Furthermore, we introduce a\nnew family of fuzzy implications (called sigmoidal implications) to tackle this\nphenomenon. Finally, we empirically show that it is possible to use\nDifferentiable Fuzzy Logics for semi-supervised learning, and show that\nsigmoidal implications outperform other choices of fuzzy implications.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:34:37 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["van Krieken", "Emile", ""], ["Acar", "Erman", ""], ["van Harmelen", "Frank", ""]]}, {"id": "2006.03525", "submitter": "Boro Sitnikovski", "authors": "Boro Sitnikovski", "title": "Formalizing line editors in Coq", "comments": "\"Collapsed\" Coq code to reduce the page size, changed title from\n  \"text editors\" to \"line editors\". Associated files are available at\n  https://github.com/bor0/formal-ed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text editors represent one of the fundamental tools that writers use -\nsoftware developers, book authors, mathematicians. A text editor must work as\nintended in that it should allow the users to do their job. We start by\nintroducing a small subset of a text editor - line editor. Next, we will give a\nconcrete definition (specification) of what a complete text editor means.\nAfterward, we will provide an implementation of a line editor in Coq, and then\nwe will prove that it is a complete text editor.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 15:58:01 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 22:58:07 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Sitnikovski", "Boro", ""]]}, {"id": "2006.03751", "submitter": "Samuel Huang", "authors": "Samuel Huang and Rance Cleaveland", "title": "Temporal-Logic Query Checking over Finite Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a technique for inferring temporal-logic properties for\nsets of finite data streams. Such data streams arise in many domains, including\nserver logs, program testing, and financial and marketing data; temporal-logic\nformulas that are satisfied by all data streams in a set can provide insight\ninto the underlying dynamics of the system generating these streams. Our\napproach makes use of so-called Linear Temporal Logic (LTL) queries, which are\nLTL formulas containing a missing subformula and interpreted over finite data\nstreams. Solving such a query involves computing a subformula that can be\ninserted into the query so that the resulting grounded formula is satisfied by\nall data streams in the set. We describe an automaton-driven approach to\nsolving this query-checking problem and demonstrate a working implementation\nvia a pilot study.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 01:36:12 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Huang", "Samuel", ""], ["Cleaveland", "Rance", ""]]}, {"id": "2006.04202", "submitter": "Jeremy Sproston", "authors": "Jeremy Sproston", "title": "Probabilistic Timed Automata with One Clock and Initialised\n  Clock-Dependent Probabilities", "comments": "Full version of a paper published at FORTE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clock-dependent probabilistic timed automata extend classical timed automata\nwith discrete probabilistic choice, where the probabilities are allowed to\ndepend on the exact values of the clocks. Previous work has shown that the\nquantitative reachability problem for clock-dependent probabilistic timed\nautomata with at least three clocks is undecidable. In this paper, we consider\nthe subclass of clock-dependent probabilistic timed automata that have one\nclock, that have clock dependencies described by affine functions, and that\nsatisfy an initialisation condition requiring that, at some point between\ntaking edges with non-trivial clock dependencies, the clock must have an\ninteger value. We present an approach for solving in polynomial time\nquantitative and qualitative reachability problems of such one-clock\ninitialised clock-dependent probabilistic timed automata. Our results are\nobtained by a transformation to interval Markov decision processes.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 16:54:00 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 00:56:40 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sproston", "Jeremy", ""]]}, {"id": "2006.04232", "submitter": "Esma Balk{\\i}r", "authors": "Esma Balkir, Daniel Gildea and Shay Cohen", "title": "Tensors over Semirings for Latent-Variable Weighted Logic Programs", "comments": "Accepted to IWPT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semiring parsing is an elegant framework for describing parsers by using\nsemiring weighted logic programs. In this paper we present a generalization of\nthis concept: latent-variable semiring parsing. With our framework, any\nsemiring weighted logic program can be latentified by transforming weights from\nscalar values of a semiring to rank-n arrays, or tensors, of semiring values,\nallowing the modelling of latent variables within the semiring parsing\nframework. Semiring is too strong a notion when dealing with tensors, and we\nhave to resort to a weaker structure: a partial semiring. We prove that this\ngeneralization preserves all the desired properties of the original semiring\nframework while strictly increasing its expressiveness.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 18:52:58 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Balkir", "Esma", ""], ["Gildea", "Daniel", ""], ["Cohen", "Shay", ""]]}, {"id": "2006.04399", "submitter": "Yannick Forster", "authors": "Yannick Forster, Dominik Kirst, Dominik Wehr", "title": "Completeness Theorems for First-Order Logic Analysed in Constructive\n  Type Theory (Extended Version)", "comments": "extended version of\n  https://link.springer.com/chapter/10.1007/978-3-030-36755-8_4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study various formulations of the completeness of first-order logic\nphrased in constructive type theory and mechanised in the Coq proof assistant.\nSpecifically, we examine the completeness of variants of classical and\nintuitionistic natural deduction and sequent calculi with respect to\nmodel-theoretic, algebraic, and game-theoretic semantics. As completeness with\nrespect to the standard model-theoretic semantics \\`a la Tarski and Kripke is\nnot readily constructive, we analyse connections of completeness theorems to\nMarkov's Principle and Weak K\\\"onig's Lemma and discuss non-standard semantics\nadmitting assumption-free completeness. We contribute a reusable Coq library\nfor first-order logic containing all results covered in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 07:59:02 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Forster", "Yannick", ""], ["Kirst", "Dominik", ""], ["Wehr", "Dominik", ""]]}, {"id": "2006.04652", "submitter": "Adriano Peron", "authors": "Laura Bozzelli, Alberto Molinari, Angelo Montanari, Adriano Peron,\n  Pietro Sala", "title": "Satisfiability and Model Checking for the Logic of Sub-Intervals under\n  the Homogeneity Assumption", "comments": "arXiv admin note: text overlap with arXiv:1901.03880", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressive power of interval temporal logics (ITLs) makes them really\nfascinating, and one of the most natural choices as specification and planning\nlanguage. However, for a long time, due to their high computational complexity,\nthey were considered not suitable for practical purposes. The recent discovery\nof several computationally well-behaved ITLs has finally changed the scenario.\nIn this paper, we investigate the finite satisfiability and model checking\nproblems for the ITL D featuring the sub-interval relation, under the\nhomogeneity assumption (that constrains a proposition letter to hold over an\ninterval if and only if it holds over all its points). First we prove that the\nsatisfiability problem for D, over finite linear orders, is PSPACE-complete;\nthen we show that its model checking problem, over finite Kripke structures, is\nPSPACE-complete as well. The paper enrich the set of tractable interval\ntemporal logics with a meaningful representative.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:56:08 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 13:39:36 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Bozzelli", "Laura", ""], ["Molinari", "Alberto", ""], ["Montanari", "Angelo", ""], ["Peron", "Adriano", ""], ["Sala", "Pietro", ""]]}, {"id": "2006.04673", "submitter": "Hykel Hosni", "authors": "Tommaso Flaminio, Lluis Godo and Hykel Hosni", "title": "Boolean algebras of conditionals, probability and logic", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2020.103347", "report-no": null, "categories": "math.LO cs.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an investigation on the structure of conditional events\nand on the probability measures which arise naturally in this context. In\nparticular we introduce a construction which defines a (finite) {\\em Boolean\nalgebra of conditionals} from any (finite) Boolean algebra of events. By doing\nso we distinguish the properties of conditional events which depend on\nprobability and those which are intrinsic to the logico-algebraic structure of\nconditionals. Our main result provides a way to regard standard two-place\nconditional probabilities as one-place probability functions on conditional\nevents. We also consider a logical counterpart of our Boolean algebras of\nconditionals with links to preferential consequence relations for non-monotonic\nreasoning. The overall framework of this paper provides a novel perspective on\nthe rich interplay between logic and probability in the representation of\nconditional knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:26:28 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Flaminio", "Tommaso", ""], ["Godo", "Lluis", ""], ["Hosni", "Hykel", ""]]}, {"id": "2006.05080", "submitter": "Pierre Clairambault", "authors": "Pierre Clairambault (LIP, PLUME)", "title": "Learning to Count up to Symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop the theory of how to count, in thin concurrent\ngames, the configurations of a strategy witnessing that it reaches a certain\nconfiguration of the game. This plays a central role in many recent\ndevelopments in concurrent games, whenever one aims to relate concurrent\nstrategies with weighted relational models. The difficulty, of course, is\nsymmetry: in the presence of symmetry many configurations of the strategy are,\nmorally, different instances of the same, only differing on the inessential\nchoice of copy indices. How do we know which ones to count? The purpose of the\npaper is to clarify that, uncovering many strange phenomena and fascinating\npathological examples along the way. To illustrate the results, we show that a\ncollapse operation to a simple weighted relational model simply counting\nwitnesses is preserved under composition, provided the strategies involved do\nnot deadlock.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 07:19:44 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Clairambault", "Pierre", "", "LIP, PLUME"]]}, {"id": "2006.05156", "submitter": "Alessio Mansutti", "authors": "St\\'ephane Demri, \\'Etienne Lozes, Alessio Mansutti", "title": "A Complete Axiomatisation for Quantifier-Free Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the first complete axiomatisation for quantifier-free separation\nlogic. The logic is equipped with the standard concrete heaplet semantics and\nthe proof system has no external feature such as nominals/labels. It is not\npossible to rely completely on proof systems for Boolean BI as the concrete\nsemantics needs to be taken into account. Therefore, we present the first\ninternal Hilbert-style axiomatisation for quantifier-free separation logic. The\ncalculus is divided in three parts: the axiomatisation of core formulae where\nBoolean combinations of core formulae capture the expressivity of the whole\nlogic, axioms and inference rules to simulate a bottom-up elimination of\nseparating connectives, and finally structural axioms and inference rules from\npropositional calculus and Boolean BI with the magic wand.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 09:49:52 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 13:27:21 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Demri", "St\u00e9phane", ""], ["Lozes", "\u00c9tienne", ""], ["Mansutti", "Alessio", ""]]}, {"id": "2006.05396", "submitter": "Lutz Schr\\\"oder", "authors": "Jonas Forster and Lutz Schr\\\"oder", "title": "Non-iterative Modal Logics are Coalgebraic", "comments": "Full version of conference paper in Advances in Modal Logic, AiML\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modal logic is \\emph{non-iterative} if it can be defined by axioms that do\nnot nest modal operators, and \\emph{rank-1} if additionally all propositional\nvariables in axioms are in scope of a modal operator. It is known that every\nsyntactically defined rank-1 modal logic can be equipped with a canonical\ncoalgebraic semantics, ensuring soundness and strong completeness. In the\npresent work, we extend this result to non-iterative modal logics, showing that\nevery non-iterative modal logic can be equipped with a canonical coalgebraic\nsemantics defined in terms of a copointed functor, again ensuring soundness and\nstrong completeness via a canonical model construction. Like in the rank-1\ncase, the canonical coalgebraic semantics is equivalent to a neighbourhood\nsemantics with suitable frame conditions, so the known strong completeness of\nnon-iterative modal logics over neighbourhood semantics is implied. As an\nillustration of these results, we discuss deontic logics with factual\ndetachment, which is captured by axioms that are non-iterative but not rank~1.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 16:48:06 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 12:47:12 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Forster", "Jonas", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "2006.05401", "submitter": "Madalina Erascu", "authors": "Madalina Erascu and Flavia Micota and Daniela Zaharie", "title": "Scalable Optimal Deployment in the Cloud of Component-based Applications\n  using Optimization Modulo Theory, Mathematical Programming and Symmetry\n  Breaking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Cloud resource provisioning for component-based applications\nconsists in the allocation of virtual machines (VMs) offers from various Cloud\nProviders to a set of applications such that the constraints induced by the\ninteractions between components and by the components hardware/software\nrequirements are satisfied and the performance objectives are optimized (e.g.\ncosts are minimized). It can be formulated as a constraint optimization\nproblem, hence, in principle the optimization can be carried out automatically.\nIn the case the set of VM offers is large (several hundreds), the computational\nrequirement is huge, making the automatic optimization practically impossible\nwith the current general optimization modulo theory (OMT) and mathematical\nprogramming (MP) tools. We overcame the difficulty by methodologically\nanalyzing the particularities of the problem with the aim of identifying search\nspace reduction methods. These are methods exploiting:(1) the symmetries of the\ngeneral Cloud deployment problem, (2) the graph representation associated to\nthe structural constraints specific to each particular application, and (3)\ntheir combination. An extensive experimental analysis has been conducted on\nfour classes of real-world problems, using six symmetry breaking strategies and\ntwo types of optimization solvers. As a result, the combination of a variable\nreduction strategy with a column-wise symmetry breaker leads to a scalable\ndeployment solution, when OMT is used to solve the resulting optimization\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 16:56:46 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Erascu", "Madalina", ""], ["Micota", "Flavia", ""], ["Zaharie", "Daniela", ""]]}, {"id": "2006.05433", "submitter": "Jean-Louis Krivine", "authors": "Jean-Louis Krivine", "title": "A program for the full axiom of choice", "comments": "22 pages - The paper has been formatted for publication in Log. Meth.\n  Comp. Sc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of classical realizability is a framework for the Curry-Howard\ncorrespondence which enables to associate a program with each proof in\nZermelo-Fraenkel set theory. But, almost all the applications of mathematics in\nphysics, probability, statistics, etc. use Analysis i.e. the axiom of dependent\nchoice (DC) or even the (full) axiom of choice (AC). It is therefore important\nto find explicit programs for these axioms. Various solutions have been found\nfor DC, for instance the lambda-term called \"bar recursion\" or the instruction\n\"quote\" of LISP. We present here the first program for AC.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 18:07:21 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 07:59:38 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 22:04:21 GMT"}, {"version": "v4", "created": "Fri, 9 Jul 2021 14:06:57 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Krivine", "Jean-Louis", ""]]}, {"id": "2006.05436", "submitter": "Bj\\\"orn Lellmann", "authors": "Tiziano Dalmonte, Bj\\\"orn Lellmann, Nicola Olivetti and Elaine\n  Pimentel", "title": "Hypersequent calculi for non-normal modal and deontic logics:\n  Countermodels and optimal complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some hypersequent calculi for all systems of the classical cube\nand their extensions with axioms $T$, $P$, $D$, and, for every $n\\geq 1$, rule\n$RD^+_n$. The calculi are internal as they only employ the language of the\nlogic, plus additional structural connectives. We show that the calculi are\ncomplete with respect to the corresponding axiomatisation by a syntactic proof\nof cut elimination. Then we define a terminating root-first proof search\nstrategy based on the hypersequent calculi and show that it is optimal for\ncoNP-complete logics. Moreover, we obtain that from every saturated leaf of a\nfailed proof it is possible to define a countermodel of the root hypersequent\nin the bi-neighbourhood semantics, and for regular logics also in the\nrelational semantics. We finish the paper by giving a translation between\nhypersequent rule applications and derivations in a labelled system for the\nclassical cube.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 18:12:47 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Dalmonte", "Tiziano", ""], ["Lellmann", "Bj\u00f6rn", ""], ["Olivetti", "Nicola", ""], ["Pimentel", "Elaine", ""]]}, {"id": "2006.05449", "submitter": "Florian Lonsing", "authors": "Florian Lonsing, Subhasish Mitra, and Clark Barrett", "title": "A Theoretical Framework for Symbolic Quick Error Detection", "comments": "preprint of a paper to appear at FMCAD 2020, including appendix", "journal-ref": null, "doi": "10.34727/2020/isbn.978-3-85448-042-6_9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic quick error detection (SQED) is a formal pre-silicon verification\ntechnique targeted at processor designs. It leverages bounded model checking\n(BMC) to check a design for counterexamples to a self-consistency property:\ngiven the instruction set architecture (ISA) of the design, executing an\ninstruction sequence twice on the same inputs must always produce the same\noutputs. Self-consistency is a universal, implementation-independent property.\nConsequently, in contrast to traditional verification approaches that use\nimplementation-specific assertions (often generated manually), SQED does not\nrequire a full formal design specification or manually-written properties. Case\nstudies have shown that SQED is effective for commercial designs and that SQED\nsubstantially improves design productivity. However, until now there has been\nno formal characterization of its bug-finding capabilities. We aim to close\nthis gap by laying a formal foundation for SQED. We use a transition-system\nprocessor model and define the notion of a bug using an abstract specification\nrelation. We prove the soundness of SQED, i.e., that any bug reported by SQED\nis in fact a real bug in the processor. Importantly, this result holds\nregardless of what the actual specification relation is. We next describe\nconditions under which SQED is complete, that is, what kinds of bugs it is\nguaranteed to find. We show that for a large class of bugs, SQED can always\nfind a trace exhibiting the bug. Ultimately, we prove full completeness of a\nvariant of SQED that uses specialized state reset instructions. Our results\nenable a rigorous understanding of SQED and its bug-finding capabilities and\ngive insights on how to optimize implementations of SQED in practice.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 18:46:26 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 04:11:22 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Lonsing", "Florian", ""], ["Mitra", "Subhasish", ""], ["Barrett", "Clark", ""]]}, {"id": "2006.05463", "submitter": "Elli Anastasiadi", "authors": "Luca Aceto, Antonis Achilleos, Elli Anastasiadi, Anna Ingolfsdottir", "title": "An axiomatization of verdict equivalence over regular monitors", "comments": "Preprint submitted to Journal of logical and algebraic methods in\n  programing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitors are a key tool in the field of runtime verification, where they are\nused to check for system properties by analysing execution traces generated by\nprocesses. Work on runtime monitoring carried out in a series of papers by\nAceto et al. has specified monitors using a variation on the regular fragment\nof Milner's CCS and studied two trace-based notions of equivalence over\nmonitors, namely verdict and $\\omega$-verdict equivalence. This article is\ndevoted to the study of the equational logic of monitors modulo those two\nnotions of equivalence. It presents complete equational axiomatizations of\nverdict and $\\omega$-verdict equivalence for closed and open terms over\nrecursion-free monitors.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 19:09:43 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Aceto", "Luca", ""], ["Achilleos", "Antonis", ""], ["Anastasiadi", "Elli", ""], ["Ingolfsdottir", "Anna", ""]]}, {"id": "2006.05498", "submitter": "Mahmoud Salamati", "authors": "Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani", "title": "On Decidability of Time-bounded Reachability in CTMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the time-bounded reachability problem for continuous-time Markov\ndecision processes. We show that the problem is decidable subject to Schanuel's\nconjecture. Our decision procedure relies on the structure of optimal policies\nand the conditional decidability (under Schanuel's conjecture) of the theory of\nreals extended with exponential and trigonometric functions over bounded\ndomains. We further show that any unconditional decidability result would imply\nunconditional decidability of the bounded continuous Skolem problem, or\nequivalently, the problem of checking if an exponential polynomial has a\nnon-tangential zero in a bounded interval. We note that the latter problems are\nalso decidable subject to Schanuel's conjecture but finding unconditional\ndecision procedures remain longstanding open problems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 20:55:57 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Majumdar", "Rupak", ""], ["Salamati", "Mahmoud", ""], ["Soudjani", "Sadegh", ""]]}, {"id": "2006.05600", "submitter": "Thomas Hujsa", "authors": "Thomas Hujsa, Bernard Berthomieu, Silvano Dal Zilio, Didier Le Botlan", "title": "Checking marking reachability with the state equation in Petri net\n  subclasses", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although decidable, the marking reachability problem for Petri nets is\nwell-known to be intractable in general, and a non-elementary lower bound has\nbeen recently uncovered. In order to alleviate this difficulty, various\nstructural and behavioral restrictions have been considered, allowing to relate\nreachability to properties that are easier to check. For a given initial\nmarking, the set of potentially reachable markings is described by the state\nequation solutions and over-approximates the set of reachable markings.\n  In this paper, we delineate several subclasses of weighted Petri nets in\nwhich the set of reachable markings equals the set of potentially reachable\nones, a property we call the PR-R equality. When fulfilled, this property\nallows to use linear algebra to answer the reachability questions, avoiding a\nbrute-force analysis of the state space. Notably, we provide conditions under\nwhich this equality holds in classes much more expressive than marked graphs,\nadding places with several ingoing and outgoing transitions, which allows to\nmodel real applications with shared buffers. To achieve it, we investigate the\nrelationship between liveness, reversibility, boundedness and potential\nreachability in Petri nets. We also show that this equality does not hold in\nclasses with close modeling capability when the conditions are relaxed.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 01:26:18 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Hujsa", "Thomas", ""], ["Berthomieu", "Bernard", ""], ["Zilio", "Silvano Dal", ""], ["Botlan", "Didier Le", ""]]}, {"id": "2006.05642", "submitter": "Tatsuji Kawai", "authors": "Tatsuji Kawai", "title": "Predicative theories of continuous lattices", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (May 27,\n  2021) lmcs:7520", "doi": null, "report-no": null, "categories": "cs.LO math.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a notion of strong proximity join-semilattice, a predicative\nnotion of continuous lattice which arises as the Karoubi envelop of the\ncategory of algebraic lattices. Strong proximity join-semilattices can be\ncharacterised by the coalgebras of the lower powerlocale on the wider category\nof proximity posets (also known as abstract bases or R-structures). Moreover,\nlocally compact locales can be characterised in terms of strong proximity\njoin-semilattices by the coalgebras of the double powerlocale on the category\nof proximity posets. We also provide more logical characterisation of a strong\nproximity join-semilattice, called a strong continuous finitary cover, which\nuses an entailment relation to present the underlying join-semilattice. We show\nthat this structure naturally corresponds to the notion of continuous lattice\nin the predicative point-free topology. Our result makes the predicative and\nfinitary aspect of the notion of continuous lattice in point-free topology more\nexplicit.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 03:45:07 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 08:56:50 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 07:47:33 GMT"}, {"version": "v4", "created": "Wed, 26 May 2021 17:09:49 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Kawai", "Tatsuji", ""]]}, {"id": "2006.05833", "submitter": "Xiutao Feng", "authors": "Zhe Cen, Xiutao Feng, Zhangyi Wang, Chunping Cao", "title": "Minimizing Deduction System and its Application", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a deduction system with some propositions and some known relations among\nthese propositions, people usually care about the minimum of propositions by\nwhich all other propositions can be deduced according to these known relations.\nHere we call it a minimizing deduction system. Its common solution is the guess\nand determine method. In this paper we propose a method of solving the\nminimizing deduction system based on MILP. Firstly, we introduce the\nconceptions of state variable, path variable and state copy, which enable us to\ncharacterize all rules by inequalities. Then we reduce the deduction problem to\na MILP problem and solve it by the Gurobi optimizer. As its applications, we\nanalyze the security of two stream ciphers SNOW2.0 and Enocoro-128v2 in\nresistance to guess and determine attacks. For SNOW 2.0, it is surprising that\nit takes less than 0.1s to get the best solution of 9 known variables in a\npersonal Macbook Air(Early 2015, Double Intel Core i5 1.6GHZ, 4GB DDR3). For\nEnocoro-128v2, we get the best solution of 18 known variables within 3 minutes.\nWhat's more, we propose two improvements to reduce the number of variables and\ninequalities which significantly decrease the scale of the MILP problem.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 13:42:16 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Cen", "Zhe", ""], ["Feng", "Xiutao", ""], ["Wang", "Zhangyi", ""], ["Cao", "Chunping", ""]]}, {"id": "2006.05896", "submitter": "Carl Allen", "authors": "Carl Allen, Ivana Bala\\v{z}evi\\'c, Timothy Hospedales", "title": "A Probabilistic Model for Discriminative and Neuro-Symbolic\n  Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much progress has been made in semi-supervised learning (SSL) by combining\nmethods that exploit different aspects of the data distribution, e.g.\nconsistency regularisation relies on properties of $p(x)$, whereas entropy\nminimisation pertains to the label distribution $p(y|x)$. Focusing on the\nlatter, we present a probabilistic model for discriminative SSL, that mirrors\nits classical generative counterpart. Under the assumption $y|x$ is\ndeterministic, the prior over latent variables becomes discrete. We show that\nseveral well-known SSL methods can be interpreted as approximating this prior,\nand can be improved upon. We extend the discriminative model to neuro-symbolic\nSSL, where label features satisfy logical rules, by showing such rules relate\ndirectly to the above prior, thus justifying a family of methods that link\nstatistical learning and logical reasoning, and unifying them with regular SSL.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 15:30:54 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 16:34:19 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 13:04:04 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 12:20:00 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Allen", "Carl", ""], ["Bala\u017eevi\u0107", "Ivana", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2006.06077", "submitter": "W{\\l}odzimierz Drabent", "authors": "W{\\l}odzimierz Drabent", "title": "S-semantics -- an example", "comments": "15 pages, 1 figure. This version -- some errors corrected + small\n  modifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The s-semantics makes it possible to explicitly deal with variables in\nprogram answers. So it seems suitable for programs using nonground data\nstructures, like open lists. However it is difficult to find published examples\nof using the s-semantics to reason about particular programs.\n  Here we apply s-semantics to prove correctness and completeness of\nFr\\\"uhwirth's $n$ queens program. This is compared with a proof, published\nelsewhere, based on the standard semantics and Herbrand interpretations.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 21:45:25 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 22:06:45 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Drabent", "W\u0142odzimierz", ""]]}, {"id": "2006.06099", "submitter": "Alberto Larrauri", "authors": "L\\'azaro Alberto Larrauri (Universitat Polit\\`ecnica de Catalunya)", "title": "Probabilities of first order sentences on sparse random relational\n  structures: An application to definability on random CNF formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the convergence law for sparse random graphs proven by Lynch to\narbitrary relational languages. We consider a finite relational vocabulary\n$\\sigma$ and a first order theory $T$ for $\\sigma$ composed of symmetry and\nanti-reflexivity axioms. We define a binomial random model of finite\n$\\sigma$-structures that satisfy $T$ and show that first order properties have\nwell defined asymptotic probabilities when the expected number of tuples\nsatisfying each relation in $\\sigma$ is linear. It is also shown that these\nlimit probabilities are well-behaved with respect to several parameters that\nrepresent the density of tuples in each relation $R$ in the vocabulary\n$\\sigma$. An application of these results to the problem of random Boolean\nsatisfiability is presented. We show that in a random $k$-CNF formula on $n$\nvariables, where each possible clause occurs with probability $\\sim c/n^{k-1}$,\nindependently any first order property of $k$-CNF formulas that implies\nunsatisfiability does almost surely not hold as $n$ tends to infinity.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 22:53:09 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 17:21:27 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Larrauri", "L\u00e1zaro Alberto", "", "Universitat Polit\u00e8cnica de Catalunya"]]}, {"id": "2006.06343", "submitter": "Emilio Gamba", "authors": "Bart Bogaerts, Emilio Gamba, Tias Guns", "title": "A framework for step-wise explaining how to solve constraint\n  satisfaction problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2021.103550", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the problem of step-wise explaining how to solve constraint\nsatisfaction problems, with a use case on logic grid puzzles. More\nspecifically, we study the problem of explaining the inference steps that one\ncan take during propagation, in a way that is easy to interpret for a person.\nThereby, we aim to give the constraint solver explainable agency, which can\nhelp in building trust in the solver by being able to understand and even learn\nfrom the explanations. The main challenge is that of finding a sequence of\nsimple explanations, where each explanation should aim to be as cognitively\neasy as possible for a human to verify and understand. This contrasts with the\narbitrary combination of facts and constraints that the solver may use when\npropagating. We propose the use of a cost function to quantify how simple an\nindividual explanation of an inference step is, and identify the\nexplanation-production problem of finding the best sequence of explanations of\na CSP. Our approach is agnostic of the underlying constraint propagation\nmechanisms, and can provide explanations even for inference steps resulting\nfrom combinations of constraints. In case multiple constraints are involved, we\nalso develop a mechanism that allows to break the most difficult steps up and\nthus gives the user the ability to zoom in on specific parts of the\nexplanation. Our proposed algorithm iteratively constructs the explanation\nsequence by using an optimistic estimate of the cost function to guide the\nsearch for the best explanation at each step. Our experiments on logic grid\npuzzles show the feasibility of the approach in terms of the quality of the\nindividual explanations and the resulting explanation sequences obtained.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 11:35:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bogaerts", "Bart", ""], ["Gamba", "Emilio", ""], ["Guns", "Tias", ""]]}, {"id": "2006.06415", "submitter": "Gordon Plotkin", "authors": "Gordon D. Plotkin", "title": "A complete equational axiomatisation of partial differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalise the well-known rules of partial differentiation in a version of\nequational logic with function variables and binding constructs. We prove the\nresulting theory is complete with respect to polynomial interpretations. The\nproof makes use of Severi's interpolation theorem that all multivariate Hermite\nproblems are solvable. We also present a number of related results, such as\ndecidability and equational completeness.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 13:26:16 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 18:29:55 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Plotkin", "Gordon D.", ""]]}, {"id": "2006.06953", "submitter": "Fabian M\\\"uller", "authors": "Anselm Haak, Arne Meier, Fabian M\\\"uller, Heribert Vollmer", "title": "Enumerating Teams in First-Order Team Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We start the study of the enumeration complexity of different satisfiability\nproblems in first-order team logics. Since many of our problems go beyond DelP,\nwe use a framework for hard enumeration analogous to the polynomial hierarchy,\nwhich was recently introduced by Creignou et al. (Discret. Appl. Math. 2019).\nWe show that the problem to enumerate all satisfying teams of a fixed formula\nin a given first-order structure is DelNP-complete for certain formulas of\ndependence logic and independence logic. For inclusion logic formulas, this\nproblem is even in DelP. Furthermore, we study the variants of this problems\nwhere only maximal, minimal, maximum and minimum solutions, respectively, are\nconsidered. For the most part these share the same complexity as the original\nproblem. An exception is the minimum-variant for inclusion logic, which is\nDelNP-complete.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 05:48:22 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 06:21:46 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Haak", "Anselm", ""], ["Meier", "Arne", ""], ["M\u00fcller", "Fabian", ""], ["Vollmer", "Heribert", ""]]}, {"id": "2006.07067", "submitter": "Siddharth Bhaskar", "authors": "Siddharth Bhaskar, Steven Lindell, Scott Weinstein", "title": "Traversal-invariant characterizations of logarithmic space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a novel descriptive-complexity theoretic characterization of L and NL\ncomputable queries over finite structures using traversal invariance. We\nsummarize this as (N)L = FO + (breadth-first) traversal-invariance.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 10:41:59 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Bhaskar", "Siddharth", ""], ["Lindell", "Steven", ""], ["Weinstein", "Scott", ""]]}, {"id": "2006.07292", "submitter": "Bishwamittra Ghosh", "authors": "Bishwamittra Ghosh and Daniel Neider", "title": "A Formal Language Approach to Explaining RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents LEXR, a framework for explaining the decision making of\nrecurrent neural networks (RNNs) using a formal description language called\nLinear Temporal Logic (LTL). LTL is the de facto standard for the specification\nof temporal properties in the context of formal verification and features many\ndesirable properties that make the generated explanations easy for humans to\ninterpret: it is a descriptive language, it has a variable-free syntax, and it\ncan easily be translated into plain English. To generate explanations, LEXR\nfollows the principle of counterexample-guided inductive synthesis and combines\nValiant's probably approximately correct learning (PAC) with constraint\nsolving. We prove that LEXR's explanations satisfy the PAC guarantee (provided\nthe RNN can be described by LTL) and show empirically that these explanations\nare more accurate and easier-to-understand than the ones generated by recent\nalgorithms that extract deterministic finite automata from RNNs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 16:17:53 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ghosh", "Bishwamittra", ""], ["Neider", "Daniel", ""]]}, {"id": "2006.07440", "submitter": "Sarat Chandra Varanasi", "authors": "Sarat Chandra Varanasi, Neeraj Mittal, Gopal Gupta", "title": "Pointer Data Structure Synthesis from Answer Set Programming\n  Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an inductive proof-technique to generate imperative programs for\npointer data structures from behavioural specifications expressed in the Answer\nSet Programming (ASP) formalism. ASP is a non-monotonic logic based formalism\nthat employs negation-as-failure which helps emulate the human thought process,\nallowing domain experts to model desired system behaviour succinctly. We argue\nin this paper that ASP's reliance on negation-as-failure makes it a better\nformalism than those based on first-order logic for writing formal\nspecifications. We assume the a domain expert provides the representation of\ninductively defined data structures along with a specification of its\noperations. Our procedures combined with our novel proof-technique reason over\nthe specifications and automatically generate an imperative program. Our\nproof-technique leverages the idea of partial deduction to simplify logical\nspecifications. By algebraically simplifying logical specifications we arrive\nat a residual specification which can be interpreted as an appropriate\nimperative program. This work is in the realm of constructing programs that are\ncorrect according to a given specification.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 19:45:35 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 03:23:33 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Varanasi", "Sarat Chandra", ""], ["Mittal", "Neeraj", ""], ["Gupta", "Gopal", ""]]}, {"id": "2006.07674", "submitter": "Andr\\'es Ezequiel Viso", "authors": "Alexis Mart\\'in, Alejandro R\\'ios, Andr\\'es Viso", "title": "Pure Pattern Calculus \\`a la de Bruijn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known in the field of programming languages that dealing with\nvariable names and binders may lead to conflicts such as undesired captures\nwhen implementing interpreters or compilers. This situation has been overcome\nby resorting to de Bruijn indices for calculi where binders capture only one\nvariable name, like the $\\lambda$-calculus. The advantage of this approach\nrelies on the fact that so-called $\\alpha$-equivalence becomes syntactical\nequality when working with indices.\n  In recent years pattern calculi have gained considerable attention given\ntheir expressiveness. They turn out to be notoriously convenient to study the\nfoundations of modern functional programming languages modeling features like\npattern matching, path polymorphism, pattern polymorphism, etc. However, the\nliterature falls short when it comes to dealing with $\\alpha$-conversion and\nbinders capturing simultaneously several variable names. Such is the case of\nthe Pure Pattern Calculus (PPC): a natural extension of $\\lambda$-calculus that\nallows to abstract virtually any term.\n  This paper extends de Bruijn's ideas to properly overcome the multi-binding\nproblem by introducing a novel presentation of PPC with bidimensional indices,\nin an effort to implement a prototype for a typed functional programming\nlanguage based on PPC that captures path polymorphism.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 16:27:35 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 20:20:18 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Mart\u00edn", "Alexis", ""], ["R\u00edos", "Alejandro", ""], ["Viso", "Andr\u00e9s", ""]]}, {"id": "2006.08174", "submitter": "Dominique Lecomte", "authors": "Olivier Finkel (ELM), Dominique Lecomte (IMJ)", "title": "Some complete $\\omega$-powers of a one-counter language, for any Borel\n  class of finite rank", "comments": null, "journal-ref": "Archive for Mathematical Logic, Springer Verlag, In press", "doi": null, "report-no": null, "categories": "math.LO cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that, for any natural number n $\\ge$ 1, we can find a finite\nalphabet $\\Sigma$ and a finitary language L over $\\Sigma$ accepted by a\none-counter automaton, such that the $\\omega$-power L $\\infty$ := {w 0 w 1. ..\n$\\in$ $\\Sigma$ $\\omega$ | $\\forall$i $\\in$ $\\omega$ w i $\\in$ L} is $\\Pi$ 0\nn-complete. We prove a similar result for the class $\\Sigma$ 0 n .\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 07:02:23 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Finkel", "Olivier", "", "ELM"], ["Lecomte", "Dominique", "", "IMJ"]]}, {"id": "2006.08480", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "Symbolic Logic meets Machine Learning: A Brief Survey in Infinite\n  Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tension between deduction and induction is perhaps the most fundamental\nissue in areas such as philosophy, cognition and artificial intelligence (AI).\nThe deduction camp concerns itself with questions about the expressiveness of\nformal languages for capturing knowledge about the world, together with proof\nsystems for reasoning from such knowledge bases. The learning camp attempts to\ngeneralize from examples about partial descriptions about the world. In AI,\nhistorically, these camps have loosely divided the development of the field,\nbut advances in cross-over areas such as statistical relational learning,\nneuro-symbolic systems, and high-level control have illustrated that the\ndichotomy is not very constructive, and perhaps even ill-formed. In this\narticle, we survey work that provides further evidence for the connections\nbetween logic and learning. Our narrative is structured in terms of three\nstrands: logic versus learning, machine learning for logic, and logic for\nmachine learning, but naturally, there is considerable overlap. We place an\nemphasis on the following \"sore\" point: there is a common misconception that\nlogic is for discrete properties, whereas probability theory and machine\nlearning, more generally, is for continuous properties. We report on results\nthat challenge this view on the limitations of logic, and expose the role that\nlogic can play for learning in infinite domains.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:29:49 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "2006.08854", "submitter": "Harley Eades PhD", "authors": "Harley Eades III and Dominic Orchard", "title": "Grading Adjoint Logic", "comments": "Extended abstract of a talk presented at LINEARITY/TLLA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new logic that combines Adjoint Logic with Graded Necessity\nModalities. This results in a very expressive system capable of controlling\nwhen and how structural rules are used. We give a sequent calculus, natural\ndeduction, and term assignment for Graded Adjoint Logic.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 01:11:08 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Eades", "Harley", "III"], ["Orchard", "Dominic", ""]]}, {"id": "2006.08945", "submitter": "Evan Patterson", "authors": "Evan Patterson", "title": "The algebra and machine representation of statistical models", "comments": "Revised and extended version of author's PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LO math.CT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the twin movements of open science and open source bring an ever greater\nshare of the scientific process into the digital realm, new opportunities arise\nfor the meta-scientific study of science itself, including of data science and\nstatistics. Future science will likely see machines play an active role in\nprocessing, organizing, and perhaps even creating scientific knowledge. To make\nthis possible, large engineering efforts must be undertaken to transform\nscientific artifacts into useful computational resources, and conceptual\nadvances must be made in the organization of scientific theories, models,\nexperiments, and data.\n  This dissertation takes steps toward digitizing and systematizing two major\nartifacts of data science, statistical models and data analyses. Using tools\nfrom algebra, particularly categorical logic, a precise analogy is drawn\nbetween models in statistics and logic, enabling statistical models to be seen\nas models of theories, in the logical sense. Statistical theories, being\nalgebraic structures, are amenable to machine representation and are equipped\nwith morphisms that formalize the relations between different statistical\nmethods. Turning from mathematics to engineering, a software system for\ncreating machine representations of data analyses, in the form of Python or R\nprograms, is designed and implemented. The representations aim to capture the\nsemantics of data analyses, independent of the programming language and\nlibraries in which they are implemented.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 06:33:50 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Patterson", "Evan", ""]]}, {"id": "2006.09132", "submitter": "Amaury Pouly", "authors": "Mohan Dantam, Amaury Pouly", "title": "On the Decidability of Reachability in Continuous Time Linear\n  Time-Invariant Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the decidability of state-to-state reachability in linear\ntime-invariant control systems over continuous time. We analyse this problem\nwith respect to the allowable control sets, which are assumed to be the image\nunder a linear map of the unit hypercube. This naturally models bounded\n(sometimes called saturated) controls. Decidability of the version of the\nreachability problem in which control sets are affine subspaces of\n$\\mathbb{R}^n$ is a fundamental result in control theory. Our first result is\ndecidability in two dimensions ($n=2$) if the matrix $A$ satisfies some\nspectral conditions, and conditional decidablility in general. If the\ntransformation matrix $A$ is diagonal with rational entries (or rational\nmultiples of the same algebraic number) then the reachability problem is\ndecidable. If the transformation matrix $A$ only has real eigenvalues, the\nreachability problem is conditionally decidable. The time-bounded reachability\nproblem is conditionally decidable, and unconditionally decidable in two\ndimensions. Some of our decidability results are conditional in that they rely\non the decidability of certain mathematical theories, namely the theory of the\nreals with exponential ($\\mathfrak{R}_{\\exp}$) and with bounded sine\n($\\mathfrak{R}_{\\exp,\\sin}$). We also obtain a hardness result for a mild\ngeneralization of the problem where the target is simple set (hypercube of\ndimension $n-1$ or hyperplane) instead of a point, and the control set is a\nconvex bounded polytope. In this case, we show that the problem is at least as\nhard as the \\emph{Continuous Positivity problem} or the \\emph{Nontangential\nContinuous Positivity problem}.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 13:20:30 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 17:13:24 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Dantam", "Mohan", ""], ["Pouly", "Amaury", ""]]}, {"id": "2006.09265", "submitter": "Wenda Li", "authors": "Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson", "title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "comments": "9 pages, published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-defined benchmark is essential for measuring and accelerating research\nprogress of machine learning models. In this paper, we present a benchmark for\nhigh-level mathematical reasoning and study the reasoning capabilities of\nneural sequence-to-sequence models. We build a non-synthetic dataset from the\nlargest repository of proofs written by human experts in a theorem prover. The\ndataset has a broad coverage of undergraduate and research-level mathematical\nand computer science theorems. In our defined task, a model is required to fill\nin a missing intermediate proposition given surrounding proofs. This task\nprovides a starting point for the long-term goal of having machines generate\nhuman-readable proofs automatically. Our experiments and analysis reveal that\nwhile the task is challenging, neural models can capture non-trivial\nmathematical reasoning. We further design a hierarchical transformer that\noutperforms the transformer baseline.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 21:09:23 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 16:45:18 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Li", "Wenda", ""], ["Yu", "Lei", ""], ["Wu", "Yuhuai", ""], ["Paulson", "Lawrence C.", ""]]}, {"id": "2006.09291", "submitter": "Leonardo Montecchi", "authors": "Leonardo Montecchi and Paolo Lollini and Andrea Bondavalli", "title": "Stochastic Activity Networks Templates: Supporting Variability in\n  Performability Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based evaluation is extensively used to estimate performance and\nreliability of dependable systems. Traditionally, those systems were small and\nself-contained, and the main challenge for model-based evaluation has been the\nefficiency of the solution process. Recently, the problem of specifying and\nmaintaining complex models has increasingly gained attention, as modern systems\nare characterized by many components and complex interactions. Components share\nsimilarities, but also exhibit variations in their behavior due to different\nconfigurations or roles in the system. From the modeling perspective,\nvariations lead to replicating and altering a small set of base models multiple\ntimes. Variability is taken into account only informally, by defining a sample\nmodel and explaining its possible variations. In this paper we address the\nproblem of including variability in performability models, focusing on\nStochastic Activity Networks (SANs). We introduce the formal definition of\nStochastic Activity Networks Templates (SAN-T), a formalism based on SANs with\nthe addition of variability aspects. Differently from other approaches,\nparameters can also affect the structure of the model, like the number of cases\nof activities. We apply the SAN-T formalism to the modeling of the backbone\nnetwork of an environmental monitoring infrastructure. In particular, we show\nhow existing SAN models from the literature can be generalized using the newly\nintroduced formalism.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 03:07:11 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 16:31:14 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Montecchi", "Leonardo", ""], ["Lollini", "Paolo", ""], ["Bondavalli", "Andrea", ""]]}, {"id": "2006.09292", "submitter": "Yasmine Sharoda", "authors": "Jacques Carette, William M. Farmer, Yasmine Sharoda", "title": "Leveraging the Information Contained in Theory Presentations", "comments": "Accepted at: Conference on Intelligent Computer Mathematics (CICM\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theorem prover without an extensive library is much less useful to its\npotential users. Algebra, the study of algebraic structures, is a core\ncomponent of such libraries. Algebraic theories also are themselves structured,\nthe study of which was started as Universal Algebra. Various constructions\n(homomorphism, term algebras, products, etc) and their properties are both\nuniversal and constructive. Thus they are ripe for being automated.\nUnfortunately, current practice still requires library builders to write these\nby hand.\n  We first highlight specific redundancies in libraries of existing systems.\nThen we describe a framework for generating these derived concepts from theory\ndefinitions. We demonstrate the usefulness of this framework on a test library\nof 227 theories.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 20:40:55 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Carette", "Jacques", ""], ["Farmer", "William M.", ""], ["Sharoda", "Yasmine", ""]]}, {"id": "2006.09488", "submitter": "Yuri Gurevich", "authors": "Andreas Blass and Yuri Gurevich", "title": "Circuits: An abstract viewpoint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our primary purpose is to isolate the abstract, mathematical properties of\ncircuits -- both classical Boolean circuits and quantum circuits -- that are\nessential for their computational interpretation. A secondary purpose is to\nclarify the similarities and differences between the classical and quantum\nsituations. The general philosophy in this note is to include the\nmathematically essential aspects of circuits but to omit any of the additional\nstructures that are usually included for convenience. We shall, however, retain\nthe assumption that circuits are finite; this assumption does no harm to the\napplicability of our approach and is necessary for some of our work.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 20:00:35 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Blass", "Andreas", ""], ["Gurevich", "Yuri", ""]]}, {"id": "2006.09599", "submitter": "Andrei Bulatov", "authors": "Andrei A. Bulatov", "title": "Local structure of idempotent algebras I", "comments": "This is the first part of a revised and modified version of the paper\n  arXiv:1601.07403 (2016). In this version a typo in the definition of thin\n  affine edges is corrected. No statements or proofs changed, as they use the\n  correct definition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We refine and advance the study of the local structure of idempotent finite\nalgebras started in [A.Bulatov, The Graph of a Relational Structure and\nConstraint Satisfaction Problems, LICS, 2004]. We introduce a graph-like\nstructure on an arbitrary finite idempotent algebra including those admitting\ntype 1. We show that this graph is connected, its edges can be classified into\n4 types corresponding to the local behavior (set, semilattice, majority, or\naffine) of certain term operations. We also show that if the variety generated\nby the algebra omits type 1, then the structure of the algebra can be\n`improved' without introducing type 1 by choosing an appropriate reduct of the\noriginal algebra. Taylor minimal idempotent algebras introduced recently is a\nspecial case of such reducts. Then we refine this structure demonstrating that\nthe edges of the graph of an algebra omitting type 1 can be made `thin', that\nis, there are term operations that behave very similar to semilattice,\nmajority, or affine operations on 2-element subsets of the algebra. Finally, we\nprove certain connectivity properties of the refined structures.\n  This research is motivated by the study of the Constraint Satisfaction\nProblem, although the problem itself does not really show up in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 01:55:02 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 13:34:25 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Bulatov", "Andrei A.", ""]]}, {"id": "2006.09705", "submitter": "Raheleh Jalali", "authors": "Raheleh Jalali", "title": "Proof Complexity of Substructural Logics", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the proof complexity of a wide range of\nsubstructural systems. For any proof system $\\mathbf{P}$ at least as strong as\nFull Lambek calculus, $\\mathbf{FL}$, and polynomially simulated by the extended\nFrege system for some infinite branching super-intuitionistic logic, we present\nan exponential lower bound on the proof lengths. More precisely, we will\nprovide a sequence of $\\mathbf{P}$-provable formulas $\\{A_n\\}_{n=1}^{\\infty}$\nsuch that the length of the shortest $\\mathbf{P}$-proof for $A_n$ is\nexponential in the length of $A_n$. The lower bound also extends to the number\nof proof-lines (proof-lengths) in any Frege system (extended Frege system) for\na logic between $\\mathsf{FL}$ and any infinite branching super-intuitionistic\nlogic. We will also prove a similar result for the proof systems and logics\nextending Visser's basic propositional calculus $\\mathbf{BPC}$ and its logic\n$\\mathsf{BPC}$, respectively. Finally, in the classical substructural setting,\nwe will establish an exponential lower bound on the number of proof-lines in\nany proof system polynomially simulated by the cut-free version of\n$\\mathbf{CFL_{ew}}$.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 08:04:13 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 13:19:08 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Jalali", "Raheleh", ""]]}, {"id": "2006.09868", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "Logic, Probability and Action: A Situation Calculus Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unification of logic and probability is a long-standing concern in AI,\nand more generally, in the philosophy of science. In essence, logic provides an\neasy way to specify properties that must hold in every possible world, and\nprobability allows us to further quantify the weight and ratio of the worlds\nthat must satisfy a property. To that end, numerous developments have been\nundertaken, culminating in proposals such as probabilistic relational models.\nWhile this progress has been notable, a general-purpose first-order knowledge\nrepresentation language to reason about probabilities and dynamics, including\nin continuous settings, is still to emerge. In this paper, we survey recent\nresults pertaining to the integration of logic, probability and actions in the\nsituation calculus, which is arguably one of the oldest and most well-known\nformalisms. We then explore reduction theorems and programming interfaces for\nthe language. These results are motivated in the context of cognitive robotics\n(as envisioned by Reiter and his colleagues) for the sake of concreteness.\nOverall, the advantage of proving results for such a general language is that\nit becomes possible to adapt them to any special-purpose fragment, including\nbut not limited to popular probabilistic relational models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 13:49:53 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "2006.09877", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet, Colin Geniet, Eun Jung Kim, St\\'ephan Thomass\\'e,\n  R\\'emi Watrigant", "title": "Twin-width II: small classes", "comments": "37 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The twin-width of a graph $G$ is the minimum integer $d$ such that $G$ has a\n$d$-contraction sequence, that is, a sequence of $|V(G)|-1$ iterated vertex\nidentifications for which the overall maximum number of red edges incident to a\nsingle vertex is at most $d$, where a red edge appears between two sets of\nidentified vertices if they are not homogeneous in $G$. We show that if a graph\nadmits a $d$-contraction sequence, then it also has a linear-arity tree of\n$f(d)$-contractions, for some function $f$. First this permits to show that\nevery bounded twin-width class is small, i.e., has at most $n!c^n$ graphs\nlabeled by $[n]$, for some constant $c$. This unifies and extends the same\nresult for bounded treewidth graphs [Beineke and Pippert, JCT '69], proper\nsubclasses of permutations graphs [Marcus and Tardos, JCTA '04], and proper\nminor-free classes [Norine et al., JCTB '06]. The second consequence is an\n$O(\\log n)$-adjacency labeling scheme for bounded twin-width graphs, confirming\nseveral cases of the implicit graph conjecture. We then explore the \"small\nconjecture\" that, conversely, every small hereditary class has bounded\ntwin-width. Inspired by sorting networks of logarithmic depth, we show that\n$\\log_{\\Theta(\\log \\log d)}n$-subdivisions of $K_n$ (a small class when $d$ is\nconstant) have twin-width at most $d$. We obtain a rather sharp converse with a\nsurprisingly direct proof: the $\\log_{d+1}n$-subdivision of $K_n$ has\ntwin-width at least $d$. Secondly graphs with bounded stack or queue number\n(also small classes) have bounded twin-width. Thirdly we show that cubic\nexpanders obtained by iterated random 2-lifts from $K_4$~[Bilu and Linial,\nCombinatorica '06] have bounded twin-width, too. We suggest a promising\nconnection between the small conjecture and group theory. Finally we define a\nrobust notion of sparse twin-width and discuss how it compares with other\nsparse classes.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 13:57:09 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Geniet", "Colin", ""], ["Kim", "Eun Jung", ""], ["Thomass\u00e9", "St\u00e9phan", ""], ["Watrigant", "R\u00e9mi", ""]]}, {"id": "2006.09884", "submitter": "Victor Magron", "authors": "Grigory Devadze and Victor Magron and Stefan Streif", "title": "Computer-assisted proofs for Lyapunov stability via Sums of Squares\n  certificates and Constructive Analysis", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a computer-assisted approach to ensure that a given continuous or\ndiscrete-time polynomial system is (asymptotically) stable. Our framework\nrelies on constructive analysis together with formally certified sums of\nsquares Lyapunov functions. The crucial steps are formalized within of the\nproof assistant Minlog. We illustrate our approach with various examples issued\nfrom the control system literature.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 14:03:33 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Devadze", "Grigory", ""], ["Magron", "Victor", ""], ["Streif", "Stefan", ""]]}, {"id": "2006.10239", "submitter": "Andrei Bulatov", "authors": "Andrei A. Bulatov", "title": "Local structure of idempotent algebras II", "comments": "In this version a typo in the definition of thin affine edges is\n  corrected. No statements or proofs changed, as they use the correct\n  definition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we continue the study of edge-colored graphs associated with\nfinite idempotent algebras initiated in arXiv:2006.09599. We prove stronger\nconnectivity properties of such graphs that will allows us to demonstrate\nseveral useful structural features of subdirect products of idempotent algebras\nsuch as rectangularity and 2-decomposition.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 02:34:42 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 13:37:27 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Bulatov", "Andrei A.", ""]]}, {"id": "2006.10387", "submitter": "Mohammad Torabi Dashti", "authors": "Mohammad Torabi Dashti and David Basin", "title": "A Theory of Black-Box Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of testing a system with respect to a requirement is to refute\nthe hypothesis that the system satisfies the requirement. We build a theory of\ntests and refutation based on the elementary notions of satisfaction and\nrefinement. We use this theory to characterize the requirements that can be\nrefuted through black-box testing and, dually, verified through such tests. We\nconsider refutation in finite time and obtain the finite falsifiability of\nhyper-safety temporal requirements as a special case. We extend our theory with\ncomputational constraints and separate refutation from enforcement in the\ncontext of temporal hyper-properties. Overall, our theory provides a basis to\nanalyze the scope and reach of black-box tests and to bridge results from\ndiverse areas including testing, verification, and enforcement.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 09:46:01 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Dashti", "Mohammad Torabi", ""], ["Basin", "David", ""]]}, {"id": "2006.10439", "submitter": "Christopher Curry", "authors": "Christopher Curry and Quang Loc Le", "title": "Bi-Abduction for Shapes with Ordered Data", "comments": "24 pages, 5 figures, 6 tables. Submitted to Science of Computer\n  Programming journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape analysis is of great importance for the verification of the correctness\nand memory-safety of heap-manipulating programs, yet such analyses have been\nshown to be highly difficult problems. The integration of separation logic into\nshape analyses has improved the effectiveness of the techniques, but the most\nsignificant advancement in this area is bi-abductive inference. Enabled by\nseparation logic, bi-abduction - a combination of abductive inference and frame\ninference - is the key enabler for compositional reasoning, helping to scale up\nverification significantly. Indeed, the success of bi-abduction has led to the\ndevelopment of Infer, the tool used daily to verify Facebook's codebase of\nmillions of lines of code. However, this success currently stays largely within\nthe shape domain. To extend this impact towards the combination of shape and\narithmetic domains, in this work, we present a novel one-stage bi-abductive\nprocedure for a combination of data structures and ordering values. The\nprocedure is designed in the spirit of the Unfold-and-Match paradigm where the\ninference is utilized to derive any mismatched portion. We have also\nimplemented a prototype solver, based on the Cyclist library, and demonstrate\nits capabilities over a range of benchmarks from the SL-COMP competition. The\nexperimental results show that our proposal shows promise for the specification\ninference in an automated verification of heap-manipulating programs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 11:37:04 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Curry", "Christopher", ""], ["Le", "Quang Loc", ""]]}, {"id": "2006.10604", "submitter": "Margherita Zorzi", "authors": "Davide Trotta and Margherita Zorzi", "title": "Compositional theories for embedded languages", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded programming style allows to split the syntax in two parts,\nrepresenting respectively a host language H and a core language C embedded in\nH. This formally models several situations in which a user writes code in a\nmain language and delegates some tasks to an ad hoc domain specific language.\nMoreover, as showed in recent years, a particular case of the host-core\napproach allows a flexible management of data linearity, which is particularly\nuseful in non-classical computational paradigms such as quantum computing. The\ndefinition of a systematised type theory to capture and standardize common\nproperties of embedded languages is unexplored. The aim of this paper is to\npresent a flexible fragment of such a type theory, together with its\ncategorical semantics in terms of enriched categories, following previous\ninvestigations. We present the calculus HC0 and we use the notion of internal\nlanguage of a category to relate the language to the class of its models,\nshowing the equivalence between the category of models and the one of theories.\nThis provides a stronger result w.r.t. standard soundness and completeness\nsince it involves not only the models but also morphisms between models. We\nobserve that the definition of the morphisms between models highlights further\nadvantages of the embedded languages and we discuss some concrete instances,\nextensions and specializations of the syntax and the semantics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 15:18:25 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 16:42:36 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Trotta", "Davide", ""], ["Zorzi", "Margherita", ""]]}, {"id": "2006.11097", "submitter": "Antonis Bikakis Dr.", "authors": "Antonis Bikakis, Patrice Caire", "title": "Contextual and Possibilistic Reasoning for Coalition Formation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiagent systems, agents often have to rely on other agents to reach\ntheir goals, for example when they lack a needed resource or do not have the\ncapability to perform a required action. Agents therefore need to cooperate.\nThen, some of the questions raised are: Which agent(s) to cooperate with? What\nare the potential coalitions in which agents can achieve their goals? As the\nnumber of possibilities is potentially quite large, how to automate the\nprocess? And then, how to select the most appropriate coalition, taking into\naccount the uncertainty in the agents' abilities to carry out certain tasks? In\nthis article, we address the question of how to find and evaluate coalitions\namong agents in multiagent systems using MCS tools, while taking into\nconsideration the uncertainty around the agents' actions. Our methodology is\nthe following: We first compute the solution space for the formation of\ncoalitions using a contextual reasoning approach. Second, we model agents as\ncontexts in Multi-Context Systems (MCS), and dependence relations among agents\nseeking to achieve their goals, as bridge rules. Third, we systematically\ncompute all potential coalitions using algorithms for MCS equilibria, and given\na set of functional and non-functional requirements, we propose ways to select\nthe best solutions. Finally, in order to handle the uncertainty in the agents'\nactions, we extend our approach with features of possibilistic reasoning. We\nillustrate our approach with an example from robotics.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 11:59:55 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 18:45:37 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Bikakis", "Antonis", ""], ["Caire", "Patrice", ""]]}, {"id": "2006.11152", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Common equivalence and size after forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forgetting variables from a propositional formula may increase its size.\nIntroducing new variables is a way to shorten it. Both operations can be\nexpressed in terms of common equivalence, a weakened version of equivalence. In\nturn, common equivalence can be expressed in terms of forgetting. An algorithm\nfor forgetting and checking common equivalence in polynomial space is given for\nthe Horn case; it is polynomial-time for the subclass of single-head formulae.\nMinimizing after forgetting is polynomial-time if the formula is also acyclic\nand variables cannot be introduced, NP-hard when they can.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:27:51 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 12:07:40 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "2006.11159", "submitter": "Martin Van Harmelen", "authors": "Martin van Harmelen, Jonas Groschwitz", "title": "Graphs with Multiple Sources per Vertex", "comments": "Supervision by Jonas Groschwitz", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several attempts have been made at constructing Abstract Meaning\nRepresentations (AMRs) compositionally, and recently the idea of using s-graphs\nwith the HR-algebra (Koller, 2015) has been simplified to reduce the number of\noptions when parsing (Groschwitz et al., 2017). This apply-modify algebra\n(AM-algebra) is a linguistically plausible graph algebra with two classes of\noperations, both of rank two: the apply operation is used to combine a\npredicate with its argument; the modify operation is used to modify a\npredicate. While the AM-algebra correctly handles relative clauses and complex\ncases of coordination, it cannot parse reflexive sentences like: \"The raven\nwashes herself.\" To facilitate processing of such reflexive sentences, this\npaper proposes to change the definition of s-graphs underlying the AM-algebra\nto allow vertices with multiple sources, and additionally proposes an adaption\nto the type system of the algebra to correctly handle such vertices.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:43:12 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["van Harmelen", "Martin", ""], ["Groschwitz", "Jonas", ""]]}, {"id": "2006.11169", "submitter": "Ian Pratt-Hartmann", "authors": "Ian Pratt-Hartmann and Lidia Tendera", "title": "The Fluted Fragment with Transitive Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the satisfiability problem for the fluted fragment extended with\ntransitive relations. The logic enjoys the finite model property when only one\ntransitive relation is available and the finite model property is lost when\nadditionally either equality or a second transitive relation is allowed. We\nshow that the satisfiability problem for the fluted fragment with one\ntransitive relation and equality remains decidable. On the other hand we show\nthat the satisfiability problem is undecidable already for the two-variable\nfragment of the logic in the presence of three transitive relations (or two\ntransitive relations and equality).\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:56:32 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Pratt-Hartmann", "Ian", ""], ["Tendera", "Lidia", ""]]}, {"id": "2006.11259", "submitter": "Eser Ayg\\\"un", "authors": "Eser Ayg\\\"un, Zafarali Ahmed, Ankit Anand, Vlad Firoiu, Xavier Glorot,\n  Laurent Orseau, Doina Precup, Shibl Mourad", "title": "Learning to Prove from Synthetic Theorems", "comments": "17 pages, 6 figures, submitted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in applying machine learning to automated theorem proving\nis the scarcity of training data, which is a key ingredient in training\nsuccessful deep learning models. To tackle this problem, we propose an approach\nthat relies on training with synthetic theorems, generated from a set of\naxioms. We show that such theorems can be used to train an automated prover and\nthat the learned prover transfers successfully to human-generated theorems. We\ndemonstrate that a prover trained exclusively on synthetic theorems can solve a\nsubstantial fraction of problems in TPTP, a benchmark dataset that is used to\ncompare state-of-the-art heuristic provers. Our approach outperforms a model\ntrained on human-generated problems in most axiom sets, thereby showing the\npromise of using synthetic data for this task.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 17:48:09 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Ayg\u00fcn", "Eser", ""], ["Ahmed", "Zafarali", ""], ["Anand", "Ankit", ""], ["Firoiu", "Vlad", ""], ["Glorot", "Xavier", ""], ["Orseau", "Laurent", ""], ["Precup", "Doina", ""], ["Mourad", "Shibl", ""]]}, {"id": "2006.11363", "submitter": "Andr\\'es P\\'aez", "authors": "Andr\\'es P\\'aez", "title": "Moore's Paradox and the logic of belief", "comments": null, "journal-ref": "Manuscrito 43(2), 2020", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moores Paradox is a test case for any formal theory of belief. In Knowledge\nand Belief, Hintikka developed a multimodal logic for statements that express\nsentences containing the epistemic notions of knowledge and belief. His account\npurports to offer an explanation of the paradox. In this paper I argue that\nHintikkas interpretation of one of the doxastic operators is philosophically\nproblematic and leads to an unnecessarily strong logical system. I offer a\nweaker alternative that captures in a more accurate way our logical intuitions\nabout the notion of belief without sacrificing the possibility of providing an\nexplanation for problematic cases such as Moores Paradox.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 20:41:19 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["P\u00e1ez", "Andr\u00e9s", ""]]}, {"id": "2006.11713", "submitter": "Andrei Bulatov", "authors": "Andrei A. Bulatov", "title": "Graphs of relational structures: restricted types", "comments": "The conference version of the paper appeared in LICS 2016. In this\n  version a typo in the definition of thin affine edges is corrected. No\n  statements or proofs changed, as they use the correct definition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algebraic approach to the Constraint Satisfaction Problem (CSP) uses high\norder symmetries of relational structures -- polymorphisms -- to study the\ncomplexity of the CSP. In this paper we further develop one of the methods the\nalgebraic approach can be implemented, and apply it to some kinds of the CSP.\nThis method was introduced in our LICS 2004 paper and involves the study of the\nlocal structure of finite algebras and relational structures. It associates\nwith an algebra A or a relational structure S a graph, whose vertices are the\nelements of A (or S), the edges represent subsets of A such that the\nrestriction of some term operation of A is `good' on the subset, that is, act\nas an operation of one of the 3 types: semilattice, majority, or affine. In\nthis paper we use this theory and consider algebras with edges from a\nrestricted set of types. We prove type restrictions are preserved under the\nstandard algebraic constructions. Then we show that if the types edges in a\nrelational structure are restricted, then the corresponding CSP can be solved\nin polynomial time by specific algorithms. In particular, we give a new,\nsomewhat more intuitive proof of the Bounded Width Theorem: the CSP over\nalgebra A has bounded width if and only if A does not contain affine edges.\nActually, this result shows that bounded width implies width (2,3). Finally, we\nprove that algebras without semilattice edges have few subalgebras of powers,\nthat is, the CSP over such algebras is also polynomial time. The methods and\nresults obtained in this paper are important ingredients of the 2017 proof of\nthe Dichotomy Conjecture by the author. The Dichotomy Conjecture was also\nproved independently by Zhuk.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 04:52:35 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 13:41:16 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Bulatov", "Andrei A.", ""]]}, {"id": "2006.11736", "submitter": "Andr\\'as Kov\\'acs", "authors": "Andr\\'as Kov\\'acs, Ambrus Kaposi", "title": "Large and Infinitary Quotient Inductive-Inductive Types", "comments": null, "journal-ref": "Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in\n  Computer Science, July 2020, Pages 648-661", "doi": "10.1145/3373718.3394770", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quotient inductive-inductive types (QIITs) are generalized inductive types\nwhich allow sorts to be indexed over previously declared sorts, and allow usage\nof equality constructors. QIITs are especially useful for algebraic\ndescriptions of type theories and constructive definitions of real, ordinal and\nsurreal numbers. We develop new metatheory for large QIITs, large elimination,\nrecursive equations and infinitary constructors. As in prior work, we describe\nQIITs using a type theory where each context represents a QIIT signature.\nHowever, in our case the theory of signatures can also describe its own\nsignature, modulo universe sizes. We bootstrap the model theory of signatures\nusing self-description and a Church-coded notion of signature, without using\ncomplicated raw syntax or assuming an existing internal QIIT of signatures. We\ngive semantics to described QIITs by modeling each signature as a finitely\ncomplete CwF (category with families) of algebras. Compared to the case of\nfinitary QIITs, we additionally need to show invariance under algebra\nisomorphisms in the semantics. We do this by modeling signature types as\nisofibrations. Finally, we show by a term model construction that every QIIT is\nconstructible from the syntax of the theory of signatures.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 08:33:17 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 11:00:55 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kov\u00e1cs", "Andr\u00e1s", ""], ["Kaposi", "Ambrus", ""]]}, {"id": "2006.12254", "submitter": "Michael Pinsker", "authors": "Manuel Bodirsky, Antoine Mottet, Miroslav Ol\\v{s}\\'ak, Jakub\n  Opr\\v{s}al, Michael Pinsker, Ross Willard", "title": "\\omega-categorical structures avoiding height 1 identities", "comments": "24 pages. arXiv admin note: text overlap with arXiv:1901.04237", "journal-ref": null, "doi": "10.1090/tran/8179", "report-no": null, "categories": "math.LO cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algebraic dichotomy conjecture for Constraint Satisfaction Problems\n(CSPs) of reducts of (infinite) finitely bounded homogeneous structures states\nthat such CSPs are polynomial-time tractable if the model-complete core of the\ntemplate has a pseudo-Siggers polymorphism, and NP-complete otherwise.\n  One of the important questions related to the dichotomy conjecture is\nwhether, similarly to the case of finite structures, the condition of having a\npseudo-Siggers polymorphism can be replaced by the condition of having\npolymorphisms satisfying a fixed set of identities of height 1, i.e.,\nidentities which do not contain any nesting of functional symbols. We provide a\nnegative answer to this question by constructing for each non-trivial set of\nheight 1 identities a structure within the range of the conjecture whose\npolymorphisms do not satisfy these identities, but whose CSP is tractable\nnevertheless.\n  An equivalent formulation of the dichotomy conjecture characterizes\ntractability of the CSP via the local satisfaction of non-trivial height 1\nidentities by polymorphisms of the structure. We show that local satisfaction\nand global satisfaction of non-trivial height 1 identities differ for\n$\\omega$-categorical structures with less than doubly exponential orbit growth,\nthereby resolving one of the main open problems in the algebraic theory of such\nstructures.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 09:08:28 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 10:40:18 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Mottet", "Antoine", ""], ["Ol\u0161\u00e1k", "Miroslav", ""], ["Opr\u0161al", "Jakub", ""], ["Pinsker", "Michael", ""], ["Willard", "Ross", ""]]}, {"id": "2006.12465", "submitter": "Jurriaan Rot", "authors": "Clemens Kupke and Jurriaan Rot", "title": "Expressive Logics for Coinductive Predicates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical Hennessy-Milner theorem says that two states of an image-finite\ntransition system are bisimilar if and only if they satisfy the same formulas\nin a certain modal logic. In this paper we study this type of result in a\ngeneral context, moving from transition systems to coalgebras and from\nbisimilarity to coinductive predicates. We formulate when a logic fully\ncharacterises a coinductive predicate on coalgebras, by providing suitable\nnotions of adequacy and expressivity, and give sufficient conditions on the\nsemantics. The approach is illustrated with logics characterising similarity,\ndivergence and a behavioural metric on automata.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:46:16 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 12:53:04 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Kupke", "Clemens", ""], ["Rot", "Jurriaan", ""]]}, {"id": "2006.12789", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and David Fuenmayor and Bertram Lomfeld", "title": "Encoding Legal Balancing: Automating an Abstract Ethico-Legal Value\n  Ontology in Preference Logic", "comments": "46 pages, 18 figures; extended and improved version of our\n  contribution to the 1st Workshop on Models of Legal Reasoning (MLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling machines to legal balancing is a non-trivial task challenged by a\nmultitude of factors some of which are addressed and explored in this work. We\npropose a holistic approach to formal modelling at different abstraction layers\nsupported by a pluralistic framework in which the encoding of an ethico-legal\nvalue ontology is developed in combination with the exploration of a\nformalisation logic, with legal domain knowledge and with exemplary use cases\nuntil a reflective equilibrium is reached. Our work is enabled by a\nmeta-logical approach to universal logical reasoning and it applies the\nrecently introduced LOGIKEY methodology for designing normative theories for\nethical and legal reasoning. We explore and illustrate the application of the\nmultilayered LOGIKEY approach for the modelling of legal and world knowledge\nthat is constrained by context-dependent value preferences. The framework is\nthen exemplary applied for explaining and resolving legal conflicts in property\nlaw (wild animal cases) within a modern proof assistant system.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 06:57:15 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 06:32:03 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 21:09:44 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Fuenmayor", "David", ""], ["Lomfeld", "Bertram", ""]]}, {"id": "2006.12868", "submitter": "Todd Waugh Ambridge", "authors": "Dan R. Ghica and Todd Waugh Ambridge", "title": "A Constructive, Type-Theoretic Approach to Regression via Global\n  Optimisation", "comments": "20 pages, formalisation of proofs available at\n  https://github.com/tnttodda/RegressionInTypeArxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the connections between deterministic, complete, and general\nglobal optimisation of continuous functions and a general concept of regression\nfrom the perspective of constructive type theory via the concept of\n'searchability'. We see how the property of convergence of global optimisation\nis a straightforward consequence of searchability. The abstract setting allows\nus to generalise searchability and continuity to higher-order functions, so\nthat we can formulate novel convergence criteria for regression, derived from\nthe convergence of global optimisation. All the theory and the motivating\nexamples are fully formalised in the proof assistant Agda.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 10:01:59 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ghica", "Dan R.", ""], ["Ambridge", "Todd Waugh", ""]]}, {"id": "2006.13155", "submitter": "Ryan Riegel", "authors": "Ryan Riegel, Alexander Gray, Francois Luus, Naweed Khan, Ndivhuwo\n  Makondo, Ismail Yunus Akhalwaya, Haifeng Qian, Ronald Fagin, Francisco\n  Barahona, Udit Sharma, Shajith Ikbal, Hima Karanam, Sumit Neelam, Ankita\n  Likhyani, Santosh Srivastava", "title": "Logical Neural Networks", "comments": "10 pages (incl. references), 38 pages supplementary, 7 figures, 9\n  tables, 6 algorithms. In submission to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework seamlessly providing key properties of both\nneural nets (learning) and symbolic logic (knowledge and reasoning). Every\nneuron has a meaning as a component of a formula in a weighted real-valued\nlogic, yielding a highly intepretable disentangled representation. Inference is\nomnidirectional rather than focused on predefined target variables, and\ncorresponds to logical reasoning, including classical first-order logic theorem\nproving as a special case. The model is end-to-end differentiable, and learning\nminimizes a novel loss function capturing logical contradiction, yielding\nresilience to inconsistent knowledge. It also enables the open-world assumption\nby maintaining bounds on truth values which can have probabilistic semantics,\nyielding resilience to incomplete knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 16:55:45 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Riegel", "Ryan", ""], ["Gray", "Alexander", ""], ["Luus", "Francois", ""], ["Khan", "Naweed", ""], ["Makondo", "Ndivhuwo", ""], ["Akhalwaya", "Ismail Yunus", ""], ["Qian", "Haifeng", ""], ["Fagin", "Ronald", ""], ["Barahona", "Francisco", ""], ["Sharma", "Udit", ""], ["Ikbal", "Shajith", ""], ["Karanam", "Hima", ""], ["Neelam", "Sumit", ""], ["Likhyani", "Ankita", ""], ["Srivastava", "Santosh", ""]]}, {"id": "2006.13613", "submitter": "Daisuke Ishii", "authors": "Daisuke Ishii, Saito Fujii", "title": "Formalizing the Soundness of the Encoding Methods of SAT-based Model\n  Checking", "comments": "Accepted to be published in the 14th International Symposium on\n  Theoretical Aspects of Software Engineering (TASE), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the effective model checking methods is to utilize the efficient\ndecision procedure of SAT (or SMT) solvers. In a SAT-based model checking, a\nsystem and its property are encoded into a set of logic formulas and the safety\nis checked based on the satisfiability of the formulas. As the encoding methods\nare improved and crafted (e.g., k-induction and IC3/PDR), verifying their\ncorrectness becomes more important. This research aims at a formal verification\nof the SMC methods using the Coq proof assistant. Our contributions are\ntwofold: (1) We specify the basic encoding methods, k-induction and (a\nsimplified version of) IC3/PDR in Coq as a set of simple and modular encoding\npredicates. (2) We provide a formal proof of the soundness of the encoding\nmethods based on our formalized lemmas on state sequences and paths.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 10:49:41 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ishii", "Daisuke", ""], ["Fujii", "Saito", ""]]}, {"id": "2006.13635", "submitter": "Dan Frumin", "authors": "Dan Frumin, Robbert Krebbers, Lars Birkedal", "title": "ReLoC Reloaded: A Mechanized Relational Logic for Fine-Grained\n  Concurrency and Logical Atomicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new version of ReLoC: a relational separation logic for proving\nrefinements of programs with higher-order state, fine-grained concurrency,\npolymorphism and recursive types. The core of ReLoC is its refinement judgment\n$e \\precsim e' : \\tau$, which states that a program $e$ refines a program $e'$\nat type $\\tau$. ReLoC provides type-directed structural rules and symbolic\nexecution rules in separation-logic style for manipulating the judgment,\nwhereas in prior work on refinements for languages with higher-order state and\nconcurrency, such proofs were carried out by unfolding the judgment into its\ndefinition in the model. ReLoC's abstract proof rules make it simpler to carry\nout refinement proofs, and enable us to generalize the notion of logically\natomic specifications to the relational case, which we call logically atomic\nrelational specifications.\n  We build ReLoC on top of the Iris framework for separation logic in Coq,\nallowing us to leverage features of Iris to prove soundness of ReLoC, and to\ncarry out refinement proofs in ReLoC. We implement tactics for interactive\nproofs in ReLoC, allowing us to mechanize several case studies in Coq, and\nthereby demonstrate the practicality of ReLoC.\n  ReLoC Reloaded extends ReLoC (LICS'18) with various technical improvements, a\nnew Coq mechanization, and support for Iris's prophecy variables. The latter\nallows us to carry out refinement proofs that involve reasoning about the\nprogram's future. We also expand ReLoC's notion of logically atomic relational\nspecifications with a new flavor based on the HOCAP pattern by Svendsen et al.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 11:15:20 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 17:40:07 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 16:55:56 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Frumin", "Dan", ""], ["Krebbers", "Robbert", ""], ["Birkedal", "Lars", ""]]}, {"id": "2006.13735", "submitter": "Pranav Ashok", "authors": "Pranav Ashok and Vahid Hashemi and Jan K\\v{r}et\\'insk\\'y and Stefanie\n  Mohr", "title": "DeepAbstract: Neural Network Abstraction for Accelerating Verification", "comments": "Accepted at ATVA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While abstraction is a classic tool of verification to scale it up, it is not\nused very often for verifying neural networks. However, it can help with the\nstill open task of scaling existing algorithms to state-of-the-art network\narchitectures. We introduce an abstraction framework applicable to\nfully-connected feed-forward neural networks based on clustering of neurons\nthat behave similarly on some inputs. For the particular case of ReLU, we\nadditionally provide error bounds incurred by the abstraction. We show how the\nabstraction reduces the size of the network, while preserving its accuracy, and\nhow verification results on the abstract network can be transferred back to the\noriginal network.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 13:51:03 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ashok", "Pranav", ""], ["Hashemi", "Vahid", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Mohr", "Stefanie", ""]]}, {"id": "2006.14947", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe, Zhe Xu, Ufuk Topcu", "title": "Distributed Policy Synthesis of Multi-Agent Systems With Graph Temporal\n  Logic Specifications", "comments": "Final version of IEEE Transactions on Control of Network Systems.\n  arXiv admin note: substantial text overlap with arXiv:2001.09066", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the distributed synthesis of policies for multi-agent systems to\nperform \\emph{spatial-temporal} tasks. We formalize the synthesis problem as a\n\\emph{factored} Markov decision process subject to \\emph{graph temporal logic}\nspecifications. The transition function and task of each agent are functions of\nthe agent itself and its neighboring agents. In this work, we develop another\ndistributed synthesis method, which improves the scalability and runtime by two\norders of magnitude compared to our prior work. The synthesis method decomposes\nthe problem into a set of smaller problems, one for each agent by leveraging\nthe structure in the model, and the specifications. We show that the running\ntime of the method is linear in the number of agents. The size of the problem\nfor each agent is exponential only in the number of neighboring agents, which\nis typically much smaller than the number of agents. We demonstrate the\napplicability of the method in case studies on disease control, urban security,\nand search and rescue. The numerical examples show that the method scales to\nhundreds of agents with hundreds of states per agent and can also handle\nsignificantly larger state spaces than our prior work.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 00:56:28 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 02:41:05 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 16:00:35 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Xu", "Zhe", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2006.15000", "submitter": "Vadim Malvone", "authors": "Francesco Belardinelli, Catalin Dima, Vadim Malvone, and Ferucio\n  Tiplea", "title": "A Hennessy-Milner Theorem for ATL with Imperfect Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a history-based variant of alternating bisimulation with\nimperfect information allows it to be related to a variant of Alternating-time\nTemporal Logic (ATL) with imperfect information by a full Hennessy-Milner\ntheorem. The variant of ATL we consider has a common knowledge semantics, which\nrequires that the uniform strategy available for a coalition to accomplish some\ngoal must be common knowledge inside the coalition, while other semantic\nvariants of ATL with imperfect information do not accommodate a Hennessy-Milner\ntheorem. We also show that the existence of a history-based alternating\nbisimulation between two finite Concurrent Game Structures with imperfect\ninformation (iCGS) is undecidable.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 14:12:11 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Belardinelli", "Francesco", ""], ["Dima", "Catalin", ""], ["Malvone", "Vadim", ""], ["Tiplea", "Ferucio", ""]]}, {"id": "2006.15135", "submitter": "Yannick Forster", "authors": "Bohdan Liesnikov and Marcel Ullrich and Yannick Forster", "title": "Generating induction principles and subterm relations for inductive\n  types using MetaCoq", "comments": "accepted for presentation at the Coq Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement three Coq plugins regarding inductive types in MetaCoq. The\nfirst plugin is a simple syntax transformation generating alternative\nconstructors for inductive types by abstracting over concrete indices in the\ntypes of the constructors. The second plugin re-implements Coq's\n$\\texttt{Scheme Induction}$ command in MetaCoq, and extends it to nested\ninductive types, e.g. types like rose trees which use $\\texttt{list}$ in their\ndefinition, similar to the Elpi-plugin by Tassi. The third plugin implements\nthe $\\texttt{Derive Subterm}$ command provided by the Equations package in\nMetaCoq.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:42:57 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Liesnikov", "Bohdan", ""], ["Ullrich", "Marcel", ""], ["Forster", "Yannick", ""]]}, {"id": "2006.15136", "submitter": "Matilde Marcolli", "authors": "Yuri Manin and Matilde Marcolli", "title": "Homotopy Theoretic and Categorical Models of Neural Information Networks", "comments": "80 pages LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a novel mathematical formalism for the modeling of\nneural information networks endowed with additional structure in the form of\nassignments of resources, either computational or metabolic or informational.\nThe starting point for this construction is the notion of summing functors and\nof Segal's Gamma-spaces in homotopy theory. The main results in this paper\ninclude functorial assignments of concurrent/distributed computing\narchitectures and associated binary codes to networks and their subsystems, a\ncategorical form of the Hopfield network dynamics, which recovers the usual\nHopfield equations when applied to a suitable category of weighted codes, a\nfunctorial assignment to networks of corresponding information structures and\ninformation cohomology, and a cohomological version of integrated information.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 12:29:37 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Manin", "Yuri", ""], ["Marcolli", "Matilde", ""]]}, {"id": "2006.15137", "submitter": "Pierre Lescanne", "authors": "Pierre Lescanne (LIP)", "title": "Extensive Infinite Games and Escalation, an exercise in Agda", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Escalation in games is when agents keep playing forever. Based on formal\nproofs we claim that if agents assume that resource are infinite, escalation is\nrational.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 09:26:02 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Lescanne", "Pierre", "", "LIP"]]}, {"id": "2006.15750", "submitter": "Steffen Lewitzka", "authors": "Steffen Lewitzka", "title": "Access-based Intuitionistic Knowledge", "comments": "28 pages", "journal-ref": "Journal of Logic and Computation, Oxford University Press, 2021", "doi": "10.1093/logcom/exaa086", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of access-based intuitionistic knowledge which\nrelies on the intuition that agent $i$ knows $\\varphi$ if $i$ has found access\nto a proof of $\\varphi$. Basic principles are distribution and factivity of\nknowledge as well as $\\square\\varphi\\rightarrow K_i\\varphi$ and\n$K_i(\\varphi\\vee\\psi) \\rightarrow (K_i\\varphi\\vee K_i\\psi)$, where\n$\\square\\varphi$ reads `$\\varphi$ is proved'. The formalization extends a\nfamily of classical modal logics designed in [Lewitzka 2015, 2017, 2019] as\ncombinations of $IPC$ and $CPC$ and as systems for the reasoning about proof,\ni.e. intuitionistic truth. We adopt a formalization of common knowledge from\n[Lewitzka 2011] and interpret it here as access-based common knowledge. We\ncompare our proposal with recent approaches to intuitionistic knowledge\n[Artemov and Protopopescu 2016; Lewitzka 2017, 2019] and bring together these\ndifferent concepts in a unifying semantic framework based on Heyting algebra\nexpansions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 00:01:44 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Lewitzka", "Steffen", ""]]}, {"id": "2006.16039", "submitter": "Adam \\'O Conghaile", "authors": "Adam \\'O Conghaile and Anuj Dawar", "title": "Game Comonads & Generalised Quantifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game comonads, introduced by Abramsky, Dawar and Wang and developed by\nAbramsky and Shah, give an interesting categorical semantics to some\nSpoiler-Duplicator games that are common in finite model theory. In particular\nthey expose connections between one-sided and two-sided games, and parameters\nsuch as treewidth and treedepth and corresponding notions of decomposition. In\nthe present paper, we expand the realm of game comonads to logics with\ngeneralised quantifiers. In particular, we introduce a comonad graded by two\nparameter $n \\leq k$ such that isomorphisms in the resulting Kleisli category\nare exactly Duplicator winning strategies in Hella's $n$-bijection game with\n$k$ pebbles. We define a one-sided version of this game which allows us to\nprovide a categorical semantics for a number of logics with generalised\nquantifiers. We also give a novel notion of tree decomposition that emerges\nfrom the construction.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 13:33:18 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 16:49:37 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 11:16:55 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Conghaile", "Adam \u00d3", ""], ["Dawar", "Anuj", ""]]}, {"id": "2006.16129", "submitter": "Cameron Calk", "authors": "Cameron Calk, Eric Goubault, Philippe Malbos, Georg Struth", "title": "Algebraic coherent confluence and higher-dimensional globular Kleene\n  algebras", "comments": "Pre-print (second version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the formalisation of confluence results in Kleene algebras to a\nformalisation of coherent proofs by confluence. To this end, we introduce the\nstructure of modal higher-dimensional globular Kleene algebra, a\nhigher-dimensional generalisation of modal and concurrent Kleene algebra. We\ngive a calculation of a coherent Church-Rosser theorem and Newman's lemma in\nhigher-dimensional Kleene algebras. We interpret these results in the context\nof higher-dimensional rewriting systems described by polygraphs.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 15:47:06 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 14:08:52 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Calk", "Cameron", ""], ["Goubault", "Eric", ""], ["Malbos", "Philippe", ""], ["Struth", "Georg", ""]]}, {"id": "2006.16450", "submitter": "Bruno Bentzen", "authors": "Bruno Bentzen", "title": "Sense, reference, and computation", "comments": "Special issue on Philosophical Logic", "journal-ref": "Perspectiva Filosofica, 47(2), pp.179-203, 2020", "doi": null, "report-no": null, "categories": "math.HO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I revisit Frege's theory of sense and reference in the\nconstructive setting of the meaning explanations of type theory, extending and\nsharpening a program--value analysis of sense and reference proposed by\nMartin-L\\\"of building on previous work of Dummett. I propose a computational\nidentity criterion for senses and argue that it validates what I see as the\nmost plausible interpretation of Frege's equipollence principle for both\nsentences and singular terms. Before doing so, I examine Frege's implementation\nof his theory of sense and reference in the logical framework of Grundgesetze,\nhis doctrine of truth values, and views on sameness of sense as equipollence of\nassertions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 01:02:11 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 17:05:10 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Bentzen", "Bruno", ""]]}, {"id": "2006.16453", "submitter": "Bruno Bentzen", "authors": "Bruno Bentzen", "title": "Frege's theory of types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frege never explicitly advocated a doctrine of types like Russell, but a\nnaive type theory can be found in his concept-script in his 1893 Grundgesetze\nder Arithmetik. Frege did not endorse a semantic account of typing, unlike most\ntype theorists who use different types for booleans, natural numbers, products,\netc. His concept-script is confined to a syntactic approach where object terms\nare identified with closed terms but the behavior of function terms alternates\nbetween that of closed terms of a function type and open terms. My aim in this\npaper is to rehabilitate Frege as a key figure in the history of type theory\nwith an exegetical account of the developments anticipated in his\nconcept-script from the perspective of modern type theory.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 01:13:38 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 19:29:30 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bentzen", "Bruno", ""]]}, {"id": "2006.16688", "submitter": "Florian Lorber", "authors": "Roderick Bloem, Peter Gj{\\o}l Jensen, Bettina K\\\"onighofer, Kim\n  Guldstrand Larsen, Florian Lorber and Alexander Palmisano", "title": "It's Time to Play Safe: Shield Synthesis for Timed Systems", "comments": "Submitted to RV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Erroneous behaviour in safety critical real-time systems may inflict serious\nconsequences. In this paper, we show how to synthesize timed shields from timed\nsafety properties given as timed automata. A timed shield enforces the safety\nof a running system while interfering with the system as little as possible. We\npresent timed post-shields and timed pre-shields. A timed pre-shield is placed\nbefore the system and provides a set of safe outputs. This set restricts the\nchoices of the system. A timed post-shield is implemented after the system. It\nmonitors the system and corrects the system's output only if necessary. We\nfurther extend the timed post-shield construction to provide a guarantee on the\nrecovery phase, i.e., the time between a specification violation and the point\nat which full control can be handed back to the system. In our experimental\nresults, we use timed post-shields to ensure the safety in a reinforcement\nlearning setting for controlling a platoon of cars, during the learning and\nexecution phase, and study the effect.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 11:21:42 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Bloem", "Roderick", ""], ["Jensen", "Peter Gj\u00f8l", ""], ["K\u00f6nighofer", "Bettina", ""], ["Larsen", "Kim Guldstrand", ""], ["Lorber", "Florian", ""], ["Palmisano", "Alexander", ""]]}, {"id": "2006.16723", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei and Guanghui Qin and Minjie Xu and Jason Eisner", "title": "Neural Datalog Through Time: Informed Temporal Modeling via Logical\n  Specification", "comments": "ICML 2020 camera-ready (new Appendix A.3, rewritten Appendix F)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning how to predict future events from patterns of past events is\ndifficult when the set of possible event types is large. Training an\nunrestricted neural model might overfit to spurious patterns. To exploit\ndomain-specific knowledge of how past events might affect an event's present\nprobability, we propose using a temporal deductive database to track structured\nfacts over time. Rules serve to prove facts from other facts and from past\nevents. Each fact has a time-varying state---a vector computed by a neural net\nwhose topology is determined by the fact's provenance, including its experience\nof past events. The possible event types at any time are given by special\nfacts, whose probabilities are neurally modeled alongside their states. In both\nsynthetic and real-world domains, we show that neural probabilistic models\nderived from concise Datalog programs improve prediction by encoding\nappropriate domain knowledge in their architecture.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:26:04 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 02:58:01 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mei", "Hongyuan", ""], ["Qin", "Guanghui", ""], ["Xu", "Minjie", ""], ["Eisner", "Jason", ""]]}, {"id": "2006.16949", "submitter": "Nathanael Arkor", "authors": "Nathanael Arkor, Marcelo Fiore", "title": "Algebraic models of simple type theories: a polynomial approach", "comments": "14 pages", "journal-ref": "Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in\n  Computer Science, July 2020, Pages 88-101", "doi": "10.1145/3373718.3394771", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop algebraic models of simple type theories, laying out a framework\nthat extends universal algebra to incorporate both algebraic sorting and\nvariable binding. Examples of simple type theories include the unityped and\nsimply-typed $\\lambda$-calculi, the computational $\\lambda$-calculus, and\npredicate logic.\n  Simple type theories are given models in presheaf categories, with structure\nspecified by algebras of polynomial endofunctors that correspond to natural\ndeduction rules. Initial models, which we construct, abstractly describe the\nsyntax of simple type theories. Taking substitution structure into\nconsideration, we further provide sound and complete semantics in structured\ncartesian multicategories. This development generalises Lambek's correspondence\nbetween the simply-typed $\\lambda$-calculus and cartesian-closed categories, to\narbitrary simple type theories.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 16:40:53 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Arkor", "Nathanael", ""], ["Fiore", "Marcelo", ""]]}]