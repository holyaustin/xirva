[{"id": "1005.0253", "submitter": "Amir M. Ben-Amram", "authors": "Amir M. Ben-Amram (Tel-Aviv Academic College)", "title": "Size-Change Termination, Monotonicity Constraints and Ranking Functions", "comments": "revised version of September 21", "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 3 (July 11,\n  2010) lmcs:1001", "doi": "10.2168/LMCS-6(3:2)2010", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Size-Change Termination (SCT) is a method of proving program termination\nbased on the impossibility of infinite descent. To this end we may use a\nprogram abstraction in which transitions are described by monotonicity\nconstraints over (abstract) variables. When only constraints of the form x>y'\nand x>=y' are allowed, we have size-change graphs. Both theory and practice are\nnow more evolved in this restricted framework then in the general framework of\nmonotonicity constraints. This paper shows that it is possible to extend and\nadapt some theory from the domain of size-change graphs to the general case,\nthus complementing previous work on monotonicity constraints. In particular, we\npresent precise decision procedures for termination; and we provide a procedure\nto construct explicit global ranking functions from monotonicity constraints in\nsingly-exponential time, which is better than what has been published so far\neven for size-change graphs.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2010 10:58:12 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2010 17:02:26 GMT"}, {"version": "v3", "created": "Mon, 20 Sep 2010 14:00:51 GMT"}, {"version": "v4", "created": "Tue, 21 Sep 2010 15:11:14 GMT"}, {"version": "v5", "created": "Thu, 3 Mar 2011 16:05:06 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Ben-Amram", "Amir M.", "", "Tel-Aviv Academic College"]]}, {"id": "1005.0349", "submitter": "Enrico Tassi", "authors": "Andrea Asperti, Enrico Tassi", "title": "Smart matching", "comments": "To appear in The 9th International Conference on Mathematical\n  Knowledge Management: MKM 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most annoying aspects in the formalization of mathematics is the\nneed of transforming notions to match a given, existing result. This kind of\ntransformations, often based on a conspicuous background knowledge in the given\nscientific domain (mostly expressed in the form of equalities or isomorphisms),\nare usually implicit in the mathematical discourse, and it would be highly\ndesirable to obtain a similar behavior in interactive provers. The paper\ndescribes the superposition-based implementation of this feature inside the\nMatita interactive theorem prover, focusing in particular on the so called\nsmart application tactic, supporting smart matching between a goal and a given\nresult.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2010 17:16:32 GMT"}], "update_date": "2010-05-04", "authors_parsed": [["Asperti", "Andrea", ""], ["Tassi", "Enrico", ""]]}, {"id": "1005.0484", "submitter": "Samuel Bucheli", "authors": "Samuel Bucheli, Roman Kuznets, Thomas Studer", "title": "Explicit Evidence Systems with Common Knowledge", "comments": null, "journal-ref": null, "doi": "10.3166/JANCL.21.35-60", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Justification logics are epistemic logics that explicitly include\njustifications for the agents' knowledge. We develop a multi-agent\njustification logic with evidence terms for individual agents as well as for\ncommon knowledge. We define a Kripke-style semantics that is similar to\nFitting's semantics for the Logic of Proofs LP. We show the soundness,\ncompleteness, and finite model property of our multi-agent justification logic\nwith respect to this Kripke-style semantics. We demonstrate that our logic is a\nconservative extension of Yavorskaya's minimal bimodal explicit evidence logic,\nwhich is a two-agent version of LP. We discuss the relationship of our logic to\nthe multi-agent modal logic S4 with common knowledge. Finally, we give a brief\nanalysis of the coordinated attack problem in the newly developed language of\nour logic.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2010 10:22:48 GMT"}], "update_date": "2014-04-17", "authors_parsed": [["Bucheli", "Samuel", ""], ["Kuznets", "Roman", ""], ["Studer", "Thomas", ""]]}, {"id": "1005.0505", "submitter": "Manfred Kufleitner", "authors": "Luc Dartois, Manfred Kufleitner, Alexander Lauser", "title": "Rankers over Infinite Words", "comments": "To be presented at the 14th Int. Conference on Developments in\n  Language Theory (DLT 2010).", "journal-ref": null, "doi": null, "report-no": "TR no. 2010/01, University of Stuttgart, Computer Science", "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the four fragments FO2, the intersection of Sigma2 and FO2, the\nintersection of Pi2 and FO2, and Delta2 of first-order logic FO[<] over finite\nand infinite words. For all four fragments, we give characterizations in terms\nof rankers. In particular, we generalize the notion of a ranker to infinite\nwords in two possible ways. Both extensions are natural in the sense that over\nfinite words, they coincide with classical rankers and over infinite words,\nthey both have the full expressive power of FO2. Moreover, the first extension\nof rankers admits a characterization of the intersection of Sigma2 and FO2\nwhile the other leads to a characterization of the intersection of Pi2 and FO2.\nBoth versions of rankers yield characterizations of the fragment Delta2. As a\nbyproduct, we also obtain characterizations based on unambiguous temporal logic\nand unambiguous interval temporal logic.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2010 12:30:02 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Dartois", "Luc", ""], ["Kufleitner", "Manfred", ""], ["Lauser", "Alexander", ""]]}, {"id": "1005.0518", "submitter": "EPTCS", "authors": "Amir M. Ben-Amram", "title": "On Decidable Growth-Rate Properties of Imperative Programs", "comments": null, "journal-ref": "EPTCS 23, 2010, pp. 1-14", "doi": "10.4204/EPTCS.23.1", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2008, Ben-Amram, Jones and Kristiansen showed that for a simple \"core\"\nprogramming language - an imperative language with bounded loops, and\narithmetics limited to addition and multiplication - it was possible to decide\nprecisely whether a program had certain growth-rate properties, namely\npolynomial (or linear) bounds on computed values, or on the running time.\n  This work emphasized the role of the core language in mitigating the\nnotorious undecidability of program properties, so that one deals with\ndecidable problems.\n  A natural and intriguing problem was whether more elements can be added to\nthe core language, improving its utility, while keeping the growth-rate\nproperties decidable. In particular, the method presented could not handle a\ncommand that resets a variable to zero. This paper shows how to handle resets.\nThe analysis is given in a logical style (proof rules), and its complexity is\nshown to be PSPACE-complete (in contrast, without resets, the problem was\nPTIME). The analysis algorithm evolved from the previous solution in an\ninteresting way: focus was shifted from proving a bound to disproving it, and\nthe algorithm works top-down rather than bottom-up.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2010 13:28:22 GMT"}], "update_date": "2010-05-20", "authors_parsed": [["Ben-Amram", "Amir M.", ""]]}, {"id": "1005.0521", "submitter": "EPTCS", "authors": "Ugo Dal Lago, Simone Martini, Margherita Zorzi", "title": "General Ramified Recurrence is Sound for Polynomial Time", "comments": null, "journal-ref": "EPTCS 23, 2010, pp. 47-62", "doi": "10.4204/EPTCS.23.4", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leivant's ramified recurrence is one of the earliest examples of an implicit\ncharacterization of the polytime functions as a subalgebra of the primitive\nrecursive functions. Leivant's result, however, is originally stated and proved\nonly for word algebras, i.e. free algebras whose constructors take at most one\nargument. This paper presents an extension of these results to ramified\nfunctions on any free algebras, provided the underlying terms are represented\nas graphs rather than trees, so that sharing of identical subterms can be\nexploited.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2010 13:29:02 GMT"}], "update_date": "2010-05-05", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Martini", "Simone", ""], ["Zorzi", "Margherita", ""]]}, {"id": "1005.0522", "submitter": "EPTCS", "authors": "Luca Roversi (Universit\\`a di Torino), Luca Vercelli (Universit\\`a di\n  Torino)", "title": "Safe Recursion on Notation into a Light Logic by Levels", "comments": null, "journal-ref": "EPTCS 23, 2010, pp. 63-77", "doi": "10.4204/EPTCS.23.5", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We embed Safe Recursion on Notation (SRN) into Light Affine Logic by Levels\n(LALL), derived from the logic L4. LALL is an intuitionistic deductive system,\nwith a polynomial time cut elimination strategy.\n  The embedding allows to represent every term t of SRN as a family of proof\nnets |t|^l in LALL. Every proof net |t|^l in the family simulates t on\narguments whose bit length is bounded by the integer l. The embedding is based\non two crucial features. One is the recursive type in LALL that encodes Scott\nbinary numerals, i.e. Scott words, as proof nets. Scott words represent the\narguments of t in place of the more standard Church binary numerals. Also, the\nembedding exploits the \"fuzzy\" borders of paragraph boxes that LALL inherits\nfrom L4 to \"freely\" duplicate the arguments, especially the safe ones, of t.\nFinally, the type of |t|^l depends on the number of composition and recursion\nschemes used to define t, namely the structural complexity of t. Moreover, the\nsize of |t|^l is a polynomial in l, whose degree depends on the structural\ncomplexity of t.\n  So, this work makes closer both the predicative recursive theoretic\nprinciples SRN relies on, and the proof theoretic one, called /stratification/,\nat the base of Light Linear Logic.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2010 13:29:08 GMT"}], "update_date": "2010-05-20", "authors_parsed": [["Roversi", "Luca", "", "Universit\u00e0 di Torino"], ["Vercelli", "Luca", "", "Universit\u00e0 di\n  Torino"]]}, {"id": "1005.0524", "submitter": "EPTCS", "authors": "Alo\\\"is Brunel (ENS Lyon), Kazushige Terui (RIMS, Kyoto University)", "title": "Church => Scott = Ptime: an application of resource sensitive\n  realizability", "comments": null, "journal-ref": "EPTCS 23, 2010, pp. 31-46", "doi": "10.4204/EPTCS.23.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variant of linear logic with second order quantifiers and type\nfixpoints, both restricted to purely linear formulas. The Church encodings of\nbinary words are typed by a standard non-linear type `Church,' while the Scott\nencodings (purely linear representations of words) are by a linear type\n`Scott.' We give a characterization of polynomial time functions, which is\nderived from (Leivant and Marion 93): a function is computable in polynomial\ntime if and only if it can be represented by a term of type Church => Scott.\n  To prove soundness, we employ a resource sensitive realizability technique\ndeveloped by Hofmann and Dal Lago.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2010 13:36:11 GMT"}], "update_date": "2010-05-05", "authors_parsed": [["Brunel", "Alo\u00efs", "", "ENS Lyon"], ["Terui", "Kazushige", "", "RIMS, Kyoto University"]]}, {"id": "1005.0653", "submitter": "EPTCS", "authors": "Patrick Baillot (ENS Lyon)", "title": "Proceedings International Workshop on Developments in Implicit\n  Computational complExity", "comments": null, "journal-ref": "EPTCS 23, 2010", "doi": "10.4204/EPTCS.23", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the International Workshop on\nDevelopments in Implicit Computational complExity (DICE 2010), which took place\non March 27-28 2010 in Paphos, Cyprus, as a satellite event of the Joint\nEuropean Conference on Theory and Practice of Software, ETAPS 2010.\n  Implicit Computational Complexity aims at studying computational complexity\nwithout referring to external measuring conditions or particular machine\nmodels, but instead by considering restrictions on programming languages or\nlogical principles implying complexity properties. The aim of this workshop was\nto bring together researchers working on implicit computational complexity,\nfrom its logical and semantical aspects to those related to the static analysis\nof programs, so as to foster their interaction and to give newcomers an\noverview of the current trends in this area.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2010 00:20:40 GMT"}], "update_date": "2010-05-20", "authors_parsed": [["Baillot", "Patrick", "", "ENS Lyon"]]}, {"id": "1005.0737", "submitter": "V\\'eronique Cortier", "authors": "Mathieu Baudet, V\\'eronique Cortier and St\\'ephanie Delaune", "title": "YAPA: A generic tool for computing intruder knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about the knowledge of an attacker is a necessary step in many\nformal analyses of security protocols. In the framework of the applied pi\ncalculus, as in similar languages based on equational logics, knowledge is\ntypically expressed by two relations: deducibility and static equivalence.\nSeveral decision procedures have been proposed for these relations under a\nvariety of equational theories. However, each theory has its particular\nalgorithm, and none has been implemented so far. We provide a generic procedure\nfor deducibility and static equivalence that takes as input any convergent\nrewrite system. We show that our algorithm covers most of the existing decision\nprocedures for convergent theories. We also provide an efficient\nimplementation, and compare it briefly with the tools ProVerif and KiSs.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2010 12:51:51 GMT"}], "update_date": "2010-05-06", "authors_parsed": [["Baudet", "Mathieu", ""], ["Cortier", "V\u00e9ronique", ""], ["Delaune", "St\u00e9phanie", ""]]}, {"id": "1005.0824", "submitter": "Francois Clement", "authors": "Sylvie Boldo (INRIA Saclay - Ile de France, LRI), Fran\\c{c}ois\n  Cl\\'ement (INRIA Rocquencourt), Jean-Christophe Filli\\^atre (INRIA Saclay -\n  Ile de France, LRI), Micaela Mayero (LIPN, Inria Grenoble Rh\\^one-Alpes / LIP\n  Laboratoire de l'Informatique du Parall\\'elisme), Guillaume Melquiond (INRIA\n  Saclay - Ile de France, LRI), Pierre Weis (INRIA Rocquencourt)", "title": "Formal Proof of a Wave Equation Resolution Scheme: the Method Error", "comments": "replaces arXiv:1001.4898", "journal-ref": "Interactive Theorem Proving 6172 (2010) 147-162", "doi": "10.1007/978-3-642-14052-5_12", "report-no": "arXiv:1005.0824", "categories": "cs.LO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular finite difference numerical schemes for the resolution of the\none-dimensional acoustic wave equation are well-known to be convergent. We\npresent a comprehensive formalization of the simplest one and formally prove\nits convergence in Coq. The main difficulties lie in the proper definition of\nasymptotic behaviors and the implicit way they are handled in the mathematical\npen-and-paper proofs. To our knowledge, this is the first time such kind of\nmathematical proof is machine-checked.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2010 19:38:02 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2011 16:19:46 GMT"}], "update_date": "2011-11-15", "authors_parsed": [["Boldo", "Sylvie", "", "INRIA Saclay - Ile de France, LRI"], ["Cl\u00e9ment", "Fran\u00e7ois", "", "INRIA Rocquencourt"], ["Filli\u00e2tre", "Jean-Christophe", "", "INRIA Saclay -\n  Ile de France, LRI"], ["Mayero", "Micaela", "", "LIPN, Inria Grenoble Rh\u00f4ne-Alpes / LIP\n  Laboratoire de l'Informatique du Parall\u00e9lisme"], ["Melquiond", "Guillaume", "", "INRIA\n  Saclay - Ile de France, LRI"], ["Weis", "Pierre", "", "INRIA Rocquencourt"]]}, {"id": "1005.0835", "submitter": "Roberto Amadio", "authors": "Roberto Amadio (PPS), Patrick Baillot (LIP), Antoine Madet (PPS)", "title": "An affine-intuitionistic system of types and effects: confluence and\n  termination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an affine-intuitionistic system of types and effects which can be\nregarded as an extension of Barber-Plotkin Dual Intuitionistic Linear Logic to\nmulti-threaded programs with effects. In the system, dynamically generated\nvalues such as references or channels are abstracted into a finite set of\nregions. We introduce a discipline of region usage that entails the confluence\n(and hence determinacy) of the typable programs. Further, we show that a\ndiscipline of region stratification guarantees termination.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2010 19:52:17 GMT"}], "update_date": "2010-05-20", "authors_parsed": [["Amadio", "Roberto", "", "PPS"], ["Baillot", "Patrick", "", "LIP"], ["Madet", "Antoine", "", "PPS"]]}, {"id": "1005.1141", "submitter": "Manuel Bodirsky", "authors": "Manuel Bodirsky, Peter Jonsson, Timo von Oertzen", "title": "Horn versus full first-order: complexity dichotomies in algebraic\n  constraint satisfaction", "comments": "15 pages; in this version, some editing mistakes in the conclusion\n  have been fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We study techniques for deciding the computational complexity of\ninfinite-domain constraint satisfaction problems. For certain fundamental\nalgebraic structures Delta, we prove definability dichotomy theorems of the\nfollowing form: for every first-order expansion Gamma of Delta, either Gamma\nhas a quantifier-free Horn definition in Delta, or there is an element d of\nGamma such that all non-empty relations in Gamma contain a tuple of the form\n(d,...,d), or all relations with a first-order definition in Delta have a\nprimitive positive definition in Gamma. The results imply that several families\nof constraint satisfaction problems exhibit a complexity dichotomy: the\nproblems are in P or NP-hard, depending on the choice of the allowed relations.\nAs concrete examples, we investigate fundamental algebraic constraint\nsatisfaction problems. The first class consists of all first-order expansions\nof (Q;+). The second class is the affine variant of the first class. In both\ncases, we obtain full dichotomies by utilising our general methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2010 06:53:19 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2010 16:55:10 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Jonsson", "Peter", ""], ["von Oertzen", "Timo", ""]]}, {"id": "1005.1327", "submitter": "Axel Legay", "authors": "Axel Legay, Benoit Delahaye", "title": "Statistical Model Checking : An Overview", "comments": "none", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative properties of stochastic systems are usually specified in logics\nthat allow one to compare the measure of executions satisfying certain temporal\nproperties with thresholds. The model checking problem for stochastic systems\nwith respect to such logics is typically solved by a numerical approach that\niteratively computes (or approximates) the exact measure of paths satisfying\nrelevant subformulas; the algorithms themselves depend on the class of systems\nbeing analyzed as well as the logic used for specifying the properties. Another\napproach to solve the model checking problem is to \\emph{simulate} the system\nfor finitely many runs, and use \\emph{hypothesis testing} to infer whether the\nsamples provide a \\emph{statistical} evidence for the satisfaction or violation\nof the specification. In this short paper, we survey the statistical approach,\nand outline its main advantages in terms of efficiency, uniformity, and\nsimplicity.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2010 10:14:02 GMT"}], "update_date": "2010-05-11", "authors_parsed": [["Legay", "Axel", ""], ["Delahaye", "Benoit", ""]]}, {"id": "1005.1716", "submitter": "Christian Drescher", "authors": "Christian Drescher and Martin Gebser and Benjamin Kaufmann and Torsten\n  Schaub", "title": "Heuristics in Conflict Resolution", "comments": null, "journal-ref": "Proceedings of the Twelfth International Workshop on Nonmonotonic\n  Reasoning (2008) 141-149", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern solvers for Boolean Satisfiability (SAT) and Answer Set Programming\n(ASP) are based on sophisticated Boolean constraint solving techniques. In both\nareas, conflict-driven learning and related techniques constitute key features\nwhose application is enabled by conflict analysis. Although various conflict\nanalysis schemes have been proposed, implemented, and studied both\ntheoretically and practically in the SAT area, the heuristic aspects involved\nin conflict analysis have not yet received much attention. Assuming a fixed\nconflict analysis scheme, we address the open question of how to identify\n\"good'' reasons for conflicts, and we investigate several heuristics for\nconflict analysis in ASP solving. To our knowledge, a systematic study like\nours has not yet been performed in the SAT area, thus, it might be beneficial\nfor both the field of ASP as well as the one of SAT solving.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2010 05:32:37 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Drescher", "Christian", ""], ["Gebser", "Martin", ""], ["Kaufmann", "Benjamin", ""], ["Schaub", "Torsten", ""]]}, {"id": "1005.2340", "submitter": "James Brotherston", "authors": "James Brotherston (Imperial College London), Cristiano Calcagno\n  (Imperial College London)", "title": "Classical BI: Its Semantics and Proof Theory", "comments": "42 pages, 8 figures", "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 3 (July 20,\n  2010) lmcs:1014", "doi": "10.2168/LMCS-6(3:3)2010", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Classical BI (CBI), a new addition to the family of bunched logics\nwhich originates in O'Hearn and Pym's logic of bunched implications BI. CBI\ndiffers from existing bunched logics in that its multiplicative connectives\nbehave classically rather than intuitionistically (including in particular a\nmultiplicative version of classical negation). At the semantic level,\nCBI-formulas have the normal bunched logic reading as declarative statements\nabout resources, but its resource models necessarily feature more structure\nthan those for other bunched logics; principally, they satisfy the requirement\nthat every resource has a unique dual. At the proof-theoretic level, a very\nnatural formalism for CBI is provided by a display calculus \\`a la Belnap,\nwhich can be seen as a generalisation of the bunched sequent calculus for BI.\nIn this paper we formulate the aforementioned model theory and proof theory for\nCBI, and prove some fundamental results about the logic, most notably\ncompleteness of the proof theory with respect to the semantics.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2010 15:12:02 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2010 21:17:56 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Brotherston", "James", "", "Imperial College London"], ["Calcagno", "Cristiano", "", "Imperial College London"]]}, {"id": "1005.2395", "submitter": "Jean-Louis Krivine", "authors": "Jean-Louis Krivine", "title": "Realizability algebras: a program to well order R", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (August 9,\n  2011) lmcs:1070", "doi": "10.2168/LMCS-7(3:2)2011", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of classical realizability is a framework in which we can develop\nthe proof-program correspondence. Using this framework, we show how to\ntransform into programs the proofs in classical analysis with dependent choice\nand the existence of a well ordering of the real line. The principal tools are:\nThe notion of realizability algebra, which is a three-sorted variant of the\nwell known combinatory algebra of Curry. An adaptation of the method of forcing\nused in set theory to prove consistency results. Here, it is used in another\nway, to obtain programs associated with a well ordering of R and the existence\nof a non trivial ultrafilter on N.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2010 18:55:59 GMT"}, {"version": "v2", "created": "Tue, 10 May 2011 07:21:09 GMT"}, {"version": "v3", "created": "Thu, 14 Jul 2011 22:24:16 GMT"}, {"version": "v4", "created": "Wed, 10 Aug 2011 18:02:33 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Krivine", "Jean-Louis", ""]]}, {"id": "1005.2654", "submitter": "Saeed Salehi", "authors": "Saeed Salehi", "title": "Herbrand Consistency of Some Arithmetical Theories", "comments": null, "journal-ref": "The Journal of Symbolic Logic 77:3 (2012) 807--827", "doi": "10.2178/jsl/1344862163", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  G\\\"odel's second incompleteness theorem is proved for Herbrand consistency of\nsome arithmetical theories with bounded induction, by using a technique of\nlogarithmic shrinking the witnesses of bounded formulas, due to Z. Adamowicz\n[Herbrand consistency and bounded arithmetic, \\textit{Fundamenta Mathematicae}\n171 (2002) 279--292]. In that paper, it was shown that one cannot always shrink\nthe witness of a bounded formula logarithmically, but in the presence of\nHerbrand consistency, for theories ${\\rm I\\Delta_0+\\Omega_m}$ with $m\\geqslant\n2$, any witness for any bounded formula can be shortened logarithmically. This\nimmediately implies the unprovability of Herbrand consistency of a theory\n$T\\supseteq {\\rm I\\Delta_0+\\Omega_2}$ in $T$ itself.\n  In this paper, the above results are generalized for ${\\rm\nI\\Delta_0+\\Omega_1}$. Also after tailoring the definition of Herbrand\nconsistency for ${\\rm I\\Delta_0}$ we prove the corresponding theorems for ${\\rm\nI\\Delta_0}$. Thus the Herbrand version of G\\\"odel's second incompleteness\ntheorem follows for the theories ${\\rm I\\Delta_0+\\Omega_1}$ and ${\\rm\nI\\Delta_0}$.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2010 07:33:49 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2010 14:03:16 GMT"}, {"version": "v3", "created": "Sat, 10 Dec 2016 09:26:50 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Salehi", "Saeed", ""]]}, {"id": "1005.2672", "submitter": "Carst Tankink", "authors": "Carst Tankink and Herman Geuvers and James McKinna and Freek Wiedijk", "title": "Proviola: A Tool for Proof Re-animation", "comments": "Accepted for the 9th International Conference on Mathematical\n  Knowledge Management (MKM 2010), 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DL cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve on existing models of interaction with a proof assistant (PA), in\nparticular for storage and replay of proofs, we in- troduce three related\nconcepts, those of: a proof movie, consisting of frames which record both user\ninput and the corresponding PA response; a camera, which films a user's\ninteractive session with a PA as a movie; and a proviola, which replays a movie\nframe-by-frame to a third party. In this paper we describe the movie data\nstructure and we discuss a proto- type implementation of the camera and\nproviola based on the ProofWeb system. ProofWeb uncouples the interaction with\na PA via a web- interface (the client) from the actual PA that resides on the\nserver. Our camera films a movie by \"listening\" to the ProofWeb communication.\nThe first reason for developing movies is to uncouple the reviewing of a formal\nproof from the PA used to develop it: the movie concept enables users to\ndiscuss small code fragments without the need to install the PA or to load a\nwhole library into it. Other advantages include the possibility to develop a\nseparate com- mentary track to discuss or explain the PA interaction. We assert\nthat a combined camera+proviola provides a generic layer between a client\n(user) and a server (PA). Finally we claim that movies are the right type of\ndata to be stored in an encyclopedia of formalized mathematics, based on our\nexperience in filming the Coq standard library.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2010 12:54:28 GMT"}], "update_date": "2010-05-18", "authors_parsed": [["Tankink", "Carst", ""], ["Geuvers", "Herman", ""], ["McKinna", "James", ""], ["Wiedijk", "Freek", ""]]}, {"id": "1005.2897", "submitter": "Alejandro D", "authors": "Ali Assaf (\\'Ecole Polytechnique & INRIA), Alejandro D\\'iaz-Caro\n  (Universidad Nacional de Quilmes, Buenos Aires, Argentina), Simon Perdrix\n  (CNRS & LORIA), Christine Tasson (PPS, Universit\\'e Paris-Diderot), Beno\\^i t\n  Valiron (PPS, Universit\\'e Paris-Diderot)", "title": "Call-by-value, call-by-name and the vectorial behaviour of the algebraic\n  \\lambda-calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (December\n  9, 2014) lmcs:927", "doi": "10.2168/LMCS-10(4:8)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the relationship between the algebraic lambda-calculus, a fragment\nof the differential lambda-calculus and the linear-algebraic lambda-calculus, a\ncandidate lambda-calculus for quantum computation. Both calculi are algebraic:\neach one is equipped with an additive and a scalar-multiplicative structure,\nand their set of terms is closed under linear combinations. However, the two\nlanguages were built using different approaches: the former is a call-by-name\nlanguage whereas the latter is call-by-value; the former considers algebraic\nequalities whereas the latter approaches them through rewrite rules. In this\npaper, we analyse how these different approaches relate to one another. To this\nend, we propose four canonical languages based on each of the possible choices:\ncall-by-name versus call-by-value, algebraic equality versus algebraic\nrewriting. We show that the various languages simulate one another. Due to\nsubtle interaction between beta-reduction and algebraic rewriting, to make the\nlanguages consistent some additional hypotheses such as confluence or\nnormalisation might be required. We carefully devise the required properties\nfor each proof, making them general enough to be valid for any sub-language\nsatisfying the corresponding properties.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2010 12:07:08 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2011 15:56:29 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2014 17:44:09 GMT"}, {"version": "v4", "created": "Sat, 27 Sep 2014 15:15:57 GMT"}, {"version": "v5", "created": "Thu, 30 Oct 2014 15:59:53 GMT"}, {"version": "v6", "created": "Mon, 8 Dec 2014 18:16:31 GMT"}, {"version": "v7", "created": "Tue, 9 Dec 2014 10:59:47 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Assaf", "Ali", "", "\u00c9cole Polytechnique & INRIA"], ["D\u00edaz-Caro", "Alejandro", "", "Universidad Nacional de Quilmes, Buenos Aires, Argentina"], ["Perdrix", "Simon", "", "CNRS & LORIA"], ["Tasson", "Christine", "", "PPS, Universit\u00e9 Paris-Diderot"], ["Valiron", "Beno\u00ee t", "", "PPS, Universit\u00e9 Paris-Diderot"]]}, {"id": "1005.2907", "submitter": "Ugo de Liguoro", "authors": "Stefano Berardi and Ugo de'Liguoro", "title": "Interactive Realizers and Monads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a realizability interpretation of a system for quantifier free\narithmetic which is equivalent to the fragment of classical arithmetic without\n\"nested\" quantifiers, called here EM1-arithmetic. We interpret classical proofs\nas interactive learning strategies, namely as processes going through several\nstages of knowledge and learning by interacting with the \"environment\" and with\neach other. We give a categorical presentation of the interpretation through\nthe construction of two suitable monads.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2010 12:39:44 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Berardi", "Stefano", ""], ["de'Liguoro", "Ugo", ""]]}, {"id": "1005.3014", "submitter": "Cameron Freer", "authors": "Nathanael L. Ackerman, Cameron E. Freer, Daniel M. Roy", "title": "On the computability of conditional probability", "comments": "44 pages, 3 figures. Final published version", "journal-ref": "Journal of the ACM, 66:3 (2019), pp. 23:1-23:40", "doi": "10.1145/3321699", "report-no": null, "categories": "math.LO cs.LO math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As inductive inference and machine learning methods in computer science see\ncontinued success, researchers are aiming to describe ever more complex\nprobabilistic models and inference algorithms. It is natural to ask whether\nthere is a universal computational procedure for probabilistic inference. We\ninvestigate the computability of conditional probability, a fundamental notion\nin probability theory and a cornerstone of Bayesian statistics. We show that\nthere are computable joint distributions with noncomputable conditional\ndistributions, ruling out the prospect of general inference algorithms, even\ninefficient ones. Specifically, we construct a pair of computable random\nvariables in the unit interval such that the conditional distribution of the\nfirst variable given the second encodes the halting problem. Nevertheless,\nprobabilistic inference is possible in many common modeling settings, and we\nprove several results giving broadly applicable conditions under which\nconditional distributions are computable. In particular, conditional\ndistributions become computable when measurements are corrupted by independent\ncomputable noise with a sufficiently smooth bounded density.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2010 19:58:54 GMT"}, {"version": "v2", "created": "Sat, 17 Dec 2011 00:11:50 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2019 02:03:29 GMT"}, {"version": "v4", "created": "Sat, 16 Nov 2019 06:49:45 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Ackerman", "Nathanael L.", ""], ["Freer", "Cameron E.", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1005.3199", "submitter": "Savas Konur PhD", "authors": "Savas Konur", "title": "A Survey on Temporal Logics", "comments": null, "journal-ref": "Frontiers of Computer Science 7(3): 370-403 (2013)", "doi": null, "report-no": "ULCS-08-021", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys main and recent studies on temporal logics in a broad\nsense by presenting various logic systems, dealing with various time\nstructures, and discussing important features, such as decidability (or\nundecidability) results, expressiveness and proof systems.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2010 13:39:36 GMT"}, {"version": "v2", "created": "Mon, 20 Sep 2010 17:37:48 GMT"}, {"version": "v3", "created": "Mon, 25 Apr 2011 15:40:58 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Konur", "Savas", ""]]}, {"id": "1005.3200", "submitter": "Savas Konur PhD", "authors": "Savas Konur", "title": "Real-time and Probabilistic Temporal Logics: An Overview", "comments": null, "journal-ref": "Frontiers of Computer Science 7(3): 370-403 (2013)", "doi": null, "report-no": "ULCS-08-020", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last two decades, there has been an extensive study on logical\nformalisms for specifying and verifying real-time systems. Temporal logics have\nbeen an important research subject within this direction. Although numerous\nlogics have been introduced for the formal specification of real-time and\ncomplex systems, an up to date comprehensive analysis of these logics does not\nexist in the literature. In this paper we analyse real-time and probabilistic\ntemporal logics which have been widely used in this field. We extrapolate the\nnotions of decidability, axiomatizability, expressiveness, model checking, etc.\nfor each logic analysed. We also provide a comparison of features of the\ntemporal logics discussed.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2010 13:41:16 GMT"}, {"version": "v2", "created": "Mon, 20 Sep 2010 17:37:27 GMT"}, {"version": "v3", "created": "Mon, 25 Apr 2011 15:43:16 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Konur", "Savas", ""]]}, {"id": "1005.3731", "submitter": "Jordi Levy", "authors": "Jordi Levy, Mateu Villaret", "title": "Nominal Unification from a Higher-Order Perspective", "comments": null, "journal-ref": "ACM Transactions on Computational Logics, Vol. 13, Num. 2, pp. 10,\n  year 2012", "doi": "10.1145/2159531.2159532", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nominal Logic is a version of first-order logic with equality, name-binding,\nrenaming via name-swapping and freshness of names. Contrarily to higher-order\nlogic, bindable names, called atoms, and instantiable variables are considered\nas distinct entities. Moreover, atoms are capturable by instantiations,\nbreaking a fundamental principle of lambda-calculus. Despite these differences,\nnominal unification can be seen from a higher-order perspective. From this\nview, we show that nominal unification can be reduced to a particular fragment\nof higher-order unification problems: Higher-Order Pattern Unification. This\nreduction proves that nominal unification can be decided in quadratic\ndeterministic time, using the linear algorithm for Higher-Order Pattern\nUnification. We also prove that the translation preserves most generality of\nunifiers.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2010 15:10:27 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Levy", "Jordi", ""], ["Villaret", "Mateu", ""]]}, {"id": "1005.3986", "submitter": "Richard McKinley", "authors": "Richard McKinley", "title": "Proof nets for Herbrand's Theorem", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the connection between two central results in the proof\ntheory of classical logic: Gentzen's cut-elimination for the sequent calculus\nand Herbrands \"fundamental theorem\". Starting from Miller's\nexpansion-tree-proofs, a highly structured way presentation of Herbrand's\ntheorem, we define a calculus of weakening-free proof nets for (prenex)\nfirst-order classical logic, and give a weakly-normalizing cut-elimination\nprocedure. It is not possible to formulate the usual counterexamples to\nconfluence of cut-elimination in this calculus, but it is nonetheless\nnonconfluent, lending credence to the view that classical logic is inherently\nnonconfluent.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2010 15:22:52 GMT"}], "update_date": "2010-05-24", "authors_parsed": [["McKinley", "Richard", ""]]}, {"id": "1005.4379", "submitter": "Zachary Snow", "authors": "Zachary Snow and David Baelde and Gopalan Nadathur", "title": "A Meta-Programming Approach to Realizing Dependently Typed Logic\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependently typed lambda calculi such as the Logical Framework (LF) can\nencode relationships between terms in types and can naturally capture\ncorrespondences between formulas and their proofs. Such calculi can also be\ngiven a logic programming interpretation: the Twelf system is based on such an\ninterpretation of LF. We consider here whether a conventional logic programming\nlanguage can provide the benefits of a Twelf-like system for encoding type and\nproof-and-formula dependencies. In particular, we present a simple mapping from\nLF specifications to a set of formulas in the higher-order hereditary Harrop\n(hohh) language, that relates derivations and proof-search between the two\nframeworks. We then show that this encoding can be improved by exploiting\nknowledge of the well-formedness of the original LF specifications to elide\nmuch redundant type-checking information. The resulting logic program has a\nstructure that closely resembles the original specification, thereby allowing\nLF specifications to be viewed as hohh meta-programs. Using the Teyjus\nimplementation of lambdaProlog, we show that our translation provides an\nefficient means for executing LF specifications, complementing the ability that\nthe Twelf system provides for reasoning about them.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2010 17:03:47 GMT"}], "update_date": "2010-05-25", "authors_parsed": [["Snow", "Zachary", ""], ["Baelde", "David", ""], ["Nadathur", "Gopalan", ""]]}, {"id": "1005.4447", "submitter": "Alexander Lyaletski", "authors": "Alexander Lyaletski (1), Konstantin Verchinine (2) ((1) Kiev National\n  Taras Shevchenko University, (2) Math-Info Department, Paris 12 University)", "title": "Evidence Algorithm and System for Automated Deduction: A Retrospective\n  View", "comments": "To appear in The 9th International Conference on Mathematical\n  Knowledge Management: MKM 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A research project aimed at the development of an automated theorem proving\nsystem was started in Kiev (Ukraine) in early 1960s. The mastermind of the\nproject, Academician V.Glushkov, baptized it \"Evidence Algorithm\", EA. The work\non the project lasted, off and on, more than 40 years. In the framework of the\nproject, the Russian and English versions of the System for Automated\nDeduction, SAD, were constructed. They may be already seen as powerful\ntheorem-proving assistants.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2010 22:18:29 GMT"}], "update_date": "2010-05-26", "authors_parsed": [["Lyaletski", "Alexander", ""], ["Verchinine", "Konstantin", ""]]}, {"id": "1005.4508", "submitter": "Alwen F Tiu", "authors": "Alwen F Tiu (The Australian National University), Rajeev Gore (The\n  Australian National University), Jeremy Dawson (The Australian National\n  University)", "title": "A Proof Theoretic Analysis of Intruder Theories", "comments": "Extended version of RTA 2009 paper", "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 3 (September\n  1, 2010) lmcs:877", "doi": "10.2168/LMCS-6(3:12)2010", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of intruder deduction in security protocol analysis:\nthat is, deciding whether a given message M can be deduced from a set of\nmessages Gamma under the theory of blind signatures and arbitrary convergent\nequational theories modulo associativity and commutativity (AC) of certain\nbinary operators. The traditional formulations of intruder deduction are\nusually given in natural-deduction-like systems and proving decidability\nrequires significant effort in showing that the rules are \"local\" in some\nsense. By using the well-known translation between natural deduction and\nsequent calculus, we recast the intruder deduction problem as proof search in\nsequent calculus, in which locality is immediate. Using standard proof\ntheoretic methods, such as permutability of rules and cut elimination, we show\nthat the intruder deduction problem can be reduced, in polynomial time, to the\nelementary deduction problem, which amounts to solving certain equations in the\nunderlying individual equational theories. We show that this result extends to\ncombinations of disjoint AC-convergent theories whereby the decidability of\nintruder deduction under the combined theory reduces to the decidability of\nelementary deduction in each constituent theory. To further demonstrate the\nutility of the sequent-based approach, we show that, for Dolev-Yao intruders,\nour sequent-based techniques can be used to solve the more difficult problem of\nsolving deducibility constraints, where the sequents to be deduced may contain\ngaps (or variables) representing possible messages the intruder may produce.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2010 08:38:17 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2010 10:35:12 GMT"}, {"version": "v3", "created": "Wed, 1 Sep 2010 14:39:42 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Tiu", "Alwen F", "", "The Australian National University"], ["Gore", "Rajeev", "", "The\n  Australian National University"], ["Dawson", "Jeremy", "", "The Australian National\n  University"]]}, {"id": "1005.4616", "submitter": "Lunjin Lu", "authors": "Lunjin Lu", "title": "Parametrizing Program Analysis by Lifting to Cardinal Power Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parametric analysis is an analysis whose input and output are parametrized\nwith a number of parameters which can be instantiated to abstract properties\nafter analysis is completed. This paper proposes to use Cousot and Cousot's\nCardinal power domain to capture functional dependencies of analysis output on\nits input and obtain a parametric analysis by parametrizing a non-parametric\nbase analysis. We illustrate the method by parametrizing a $\\pos$ based\ngroundness analysis of logic programs to a parametric groundness analysis. In\naddition, a prototype implementation shows that generality of the parametric\ngroundness analysis comes with a negligible extra cost.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2010 16:07:06 GMT"}], "update_date": "2010-05-26", "authors_parsed": [["Lu", "Lunjin", ""]]}, {"id": "1005.4844", "submitter": "David Monniaux", "authors": "David Monniaux", "title": "Automatic Modular Abstractions for Template Numerical Constraints", "comments": "final version submitted to LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 3 (July 20,\n  2010) lmcs:1015", "doi": "10.2168/LMCS-6(3:4)2010", "report-no": "LMCS-2009-385", "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for automatically generating abstract transformers for\nstatic analysis by abstract interpretation. The method focuses on linear\nconstraints on programs operating on rational, real or floating-point variables\nand containing linear assignments and tests. Given the specification of an\nabstract domain, and a program block, our method automatically outputs an\nimplementation of the corresponding abstract transformer. It is thus a form of\nprogram transformation. In addition to loop-free code, the same method also\napplies for obtaining least fixed points as functions of the precondition,\nwhich permits the analysis of loops and recursive functions. The motivation of\nour work is data-flow synchronous programming languages, used for building\ncontrol-command embedded systems, but it also applies to imperative and\nfunctional programming. Our algorithms are based on quantifier elimination and\nsymbolic manipulation techniques over linear arithmetic formulas. We also give\nless general results for nonlinear constraints and nonlinear program\nconstructs.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2010 15:25:52 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Monniaux", "David", ""]]}, {"id": "1005.5124", "submitter": "Manfred Kerber", "authors": "Manfred Kerber", "title": "Proofs, proofs, proofs, and proofs", "comments": "10 pages, To appear in The 9th International Conference on\n  Mathematical Knowledge Management: MKM 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In logic there is a clear concept of what constitutes a proof and what not. A\nproof is essentially defined as a finite sequence of formulae which are either\naxioms or derived by proof rules from formulae earlier in the sequence.\nSociologically, however, it is more difficult to say what should constitute a\nproof and what not. In this paper we will look at different forms of proofs and\ntry to clarify the concept of proof in the wider meaning of the term. This has\nimplications on how proofs should be represented formally.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2010 17:21:06 GMT"}], "update_date": "2010-05-28", "authors_parsed": [["Kerber", "Manfred", ""]]}, {"id": "1005.5142", "submitter": "Pedro S\\'anchez Terraf", "authors": "Pedro S\\'anchez Terraf", "title": "Unprovability of the Logical Characterization of Bisimulation", "comments": "Extended introduction and comments; extra section on semi-pullbacks;\n  11 pages Some background details added; extra example on the non-locality of\n  state bisimilarity; 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We quickly review labelled Markov processes (LMP) and provide a\ncounterexample showing that in general measurable spaces, event bisimilarity\nand state bisimilarity differ in LMP. This shows that the logic in Desharnais\n[*] does not characterize state bisimulation in non-analytic measurable spaces.\nFurthermore we show that, under current foundations of Mathematics, such\nlogical characterization is unprovable for spaces that are projections of a\ncoanalytic set. Underlying this construction there is a proof that stationary\nMarkov processes over general measurable spaces do not have semi-pullbacks.\n([*] J. Desharnais, Labelled Markov Processes. School of Computer Science.\nMcGill University, Montr\\'eal (1999))\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2010 18:13:27 GMT"}, {"version": "v2", "created": "Fri, 6 Aug 2010 19:19:18 GMT"}, {"version": "v3", "created": "Fri, 10 Dec 2010 16:53:06 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Terraf", "Pedro S\u00e1nchez", ""]]}, {"id": "1005.5608", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "On Infinitary Rational Relations and Borel Sets", "comments": null, "journal-ref": "Fourth International Conference on Discrete Mathematics and\n  Theoretical Computer Science DMTCS'03, 7 - 12 July 2003, Dijon, France.,\n  France (2003)", "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove in this paper that there exists some infinitary rational relations\nwhich are Sigma^0_3-complete Borel sets and some others which are\nPi^0_3-complete. This implies that there exists some infinitary rational\nrelations which are Delta^0_4-sets but not (Sigma^0_3U Pi^0_3)-sets. These\nresults give additional answers to questions of Simonnet and of Lescow and\nThomas.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2010 07:50:09 GMT"}], "update_date": "2010-07-26", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}, {"id": "1005.5623", "submitter": "Everardo Barcenas", "authors": "Everardo Barcenas (INRIA Rh\\^one-Alpes / LIG Laboratoire\n  d'Informatique de Grenoble), Pierre Geneves (INRIA Rh\\^one-Alpes / LIG\n  Laboratoire d'Informatique de Grenoble), Nabil Layaida (INRIA Rh\\^one-Alpes /\n  LIG Laboratoire d'Informatique de Grenoble), Alan Schmitt (INRIA\n  Rh\\^one-Alpes / LIG Laboratoire d'Informatique de Grenoble)", "title": "A Tree Logic with Graded Paths and Nominals", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-7251", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular tree grammars and regular path expressions constitute core constructs\nwidely used in programming languages and type systems. Nevertheless, there has\nbeen little research so far on reasoning frameworks for path expressions where\nnode cardinality constraints occur along a path in a tree. We present a logic\ncapable of expressing deep counting along paths which may include arbitrary\nrecursive forward and backward navigation. The counting extensions can be seen\nas a generalization of graded modalities that count immediate successor nodes.\nWhile the combination of graded modalities, nominals, and inverse modalities\nyields undecidable logics over graphs, we show that these features can be\ncombined in a tree logic decidable in exponential time.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2010 08:52:06 GMT"}], "update_date": "2010-06-02", "authors_parsed": [["Barcenas", "Everardo", "", "INRIA Rh\u00f4ne-Alpes / LIG Laboratoire\n  d'Informatique de Grenoble"], ["Geneves", "Pierre", "", "INRIA Rh\u00f4ne-Alpes / LIG\n  Laboratoire d'Informatique de Grenoble"], ["Layaida", "Nabil", "", "INRIA Rh\u00f4ne-Alpes /\n  LIG Laboratoire d'Informatique de Grenoble"], ["Schmitt", "Alan", "", "INRIA\n  Rh\u00f4ne-Alpes / LIG Laboratoire d'Informatique de Grenoble"]]}, {"id": "1005.5633", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "On Omega Context Free Languages which are Borel Sets of Infinite Rank", "comments": "The supremum of the set of Borel ranks of omega-context-free\n  languages is actually greater than the first non-recursive ordinal. This has\n  been proved later in a paper \"Borel Ranks and Wadge Degrees of Omega Context\n  Free Languages\" published in the journal Mathematical Structures in Computer\n  Science (2006)", "journal-ref": "Theoretical Computer Science 299 (1-3) (2003) 327-346", "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a continuation of the study of topological properties of omega\ncontext free languages (omega-CFL). We proved before that the class of\nomega-CFL exhausts the hierarchy of Borel sets of finite rank, and that there\nexist some omega-CFL which are analytic but non Borel sets. We prove here that\nthere exist some omega context free languages which are Borel sets of infinite\n(but not finite) rank, giving additional answer to questions of Lescow and\nThomas [Logical Specifications of Infinite Computations, In:\"A Decade of\nConcurrency\", Springer LNCS 803 (1994), 583-621].\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2010 09:16:55 GMT"}], "update_date": "2010-06-02", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}, {"id": "1005.5635", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (ELM)", "title": "An Effective Extension of the Wagner Hierarchy to Blind Counter Automata", "comments": null, "journal-ref": "Computer Science Logic , 15th International Workshop, CSL 2001,\n  10th Annual Conference of the European Association for Computer Science\n  Logic, Paris, September 10-13, 2001., France (2001)", "doi": null, "report-no": null, "categories": "cs.LO cs.FL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extension of the Wagner hierarchy to blind counter automata accepting\ninfinite words with a Muller acceptance condition is effective. We determine\nprecisely this hierarchy.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2010 09:19:39 GMT"}], "update_date": "2010-06-02", "authors_parsed": [["Finkel", "Olivier", "", "ELM"]]}, {"id": "1005.5648", "submitter": "Dimitri Hendriks", "authors": "Joerg Endrullis (Vrije Universiteit Amsterdam), Dimitri Hendriks\n  (Vrije Universiteit Amsterdam)", "title": "Transforming Outermost into Context-Sensitive Rewriting", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 2 (June 29,\n  2010) lmcs:1105", "doi": "10.2168/LMCS-6(2:5)2010", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define two transformations from term rewriting systems (TRSs) to\ncontext-sensitive TRSs in such a way that termination of the target system\nimplies outermost termination of the original system. In the transformation\nbased on 'context extension', each outermost rewrite step is modeled by exactly\none step in the transformed system. This transformation turns out to be\ncomplete for the class of left-linear TRSs. The second transformation is called\n`dynamic labeling' and results in smaller sized context-sensitive TRSs. Here\neach modeled step is adjoined with a small number of auxiliary steps. As a\nresult state-of-the-art termination methods for context-sensitive rewriting\nbecome available for proving termination of outermost rewriting. Both\ntransformations have been implemented in Jambox, making it the most successful\ntool in the category of outermost rewriting of the last edition of the annual\ntermination competition.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2010 09:57:45 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2010 12:54:58 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Endrullis", "Joerg", "", "Vrije Universiteit Amsterdam"], ["Hendriks", "Dimitri", "", "Vrije Universiteit Amsterdam"]]}, {"id": "1005.5662", "submitter": "Inge Bethke", "authors": "Jan A. Bergstra and Inge Bethke", "title": "On the contribution of backward jumps to instruction sequence\n  expressiveness", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the expressiveness of backward jumps in a framework of\nformalized sequential programming called program algebra. We show that - if\nexpressiveness is measured in terms of the computability of partial Boolean\nfunctions - then backward jumps are superfluous. If we, however, want to\nprevent explosion of the length of programs, then backward jumps are essential.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2010 11:46:43 GMT"}], "update_date": "2010-06-01", "authors_parsed": [["Bergstra", "Jan A.", ""], ["Bethke", "Inge", ""]]}]