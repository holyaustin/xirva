[{"id": "1702.00063", "submitter": "Nils Jansen", "authors": "Murat Cubuktepe, Nils Jansen, Sebastian Junges, Joost-Pieter Katoen,\n  Ivan Papusha, Hasan A. Poonawala, Ufuk Topcu", "title": "Sequential Convex Programming for the Efficient Verification of\n  Parametric MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective verification problems of parametric Markov decision processes\nunder optimality criteria can be naturally expressed as nonlinear programs. We\nobserve that many of these computationally demanding problems belong to the\nsubclass of signomial programs. This insight allows for a sequential\noptimization algorithm to efficiently compute sound but possibly suboptimal\nsolutions. Each stage of this algorithm solves a geometric programming problem.\nThese geometric programs are obtained by convexifying the nonconvex constraints\nof the original problem. Direct applications of the encodings as nonlinear pro-\ngrams are model repair and parameter synthesis. We demonstrate the scalability\nand quality of our approach by well-known benchmarks\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 04:20:54 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["Papusha", "Ivan", ""], ["Poonawala", "Hasan A.", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1702.00268", "submitter": "Matteo Acclavio", "authors": "Matteo Acclavio", "title": "Proof Diagrams for Multiplicative Linear Logic: Syntax and Semantics", "comments": "pre-print, submitted", "journal-ref": "Journal of Automated Reasoning (2018)", "doi": "10.1007/s10817-018-9466-4", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof nets are a syntax for linear logic proofs which gives a coarser notion\nof proof equivalence with respect to syntactic equality together with an\nintuitive geometrical representation of proofs.\n  In this paper we give an alternative $2$-dimensional syntax for\nmultiplicative linear logic derivations. The syntax of string diagrams\nauthorizes the definition of a framework where the sequentializability of a\nterm, i.e. deciding whether the term corresponds to a correct derivation, can\nbe verified in linear time.\n  Furthermore, we can use this syntax to define a denotational semantics for\nmultiplicative linear logic with units by means of equivalence classes of proof\ndiagrams modulo a terminating rewriting.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 14:16:36 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Acclavio", "Matteo", ""]]}, {"id": "1702.00374", "submitter": "Justin Hsu", "authors": "Arthur Azevedo de Amorim, Marco Gaboardi, Justin Hsu, Shin-ya\n  Katsumata, Ikram Cherigui", "title": "A Semantic Account of Metric Preservation", "comments": null, "journal-ref": null, "doi": "10.1145/3009837.3009890", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program sensitivity measures how robust a program is to small changes in its\ninput, and is a fundamental notion in domains ranging from differential privacy\nto cyber-physical systems. A natural way to formalize program sensitivity is in\nterms of metrics on the input and output spaces, requiring that an\n$r$-sensitive function map inputs that are at distance $d$ to outputs that are\nat distance at most $r \\cdot d$. Program sensitivity is thus an analogue of\nLipschitz continuity for programs.\n  Reed and Pierce introduced Fuzz, a functional language with a linear type\nsystem that can express program sensitivity. They show soundness operationally,\nin the form of a metric preservation property. Inspired by their work, we study\nprogram sensitivity and metric preservation from a denotational point of view.\nIn particular, we introduce metric CPOs, a novel semantic structure for\nreasoning about computation on metric spaces, by endowing CPOs with a\ncompatible notion of distance. This structure is useful for reasoning about\nmetric properties of programs, and specifically about program sensitivity. We\ndemonstrate metric CPOs by giving a model for the deterministic fragment of\nFuzz.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 17:50:42 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 16:29:58 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["de Amorim", "Arthur Azevedo", ""], ["Gaboardi", "Marco", ""], ["Hsu", "Justin", ""], ["Katsumata", "Shin-ya", ""], ["Cherigui", "Ikram", ""]]}, {"id": "1702.00736", "submitter": "Artur Je\\.z", "authors": "Artur Je\\.z", "title": "Word equations in linear space", "comments": "Presented at ICALP 2017, submitted to a journal. Second version\n  includeds simpliefied construction and clearer notation as well as fixes some\n  small errors from the first version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satisfiability of word equations is an important problem in the intersection\nof formal languages and algebra: Given two sequences consisting of letters and\nvariables we are to decide whether there is a substitution for the variables\nthat turns this equation into true equality of strings. The exact computational\ncomplexity of this problem remains unknown, with the best lower and upper\nbounds being, respectively, NP and PSPACE. Recently, the novel technique of\nrecompression was applied to this problem, simplifying the known proofs and\nlowering the space complexity to (nondeterministic) O(n log n). In this paper\nwe show that satisfiability of word equations is in nondeterministic linear\nspace, thus the language of satisfiable word equations is context-sensitive,\nand by the famous Immerman-Szelepcsenyi theorem: the language of unsatisfiable\nword equations is also context-sensitive. We use the known recompression-based\nalgorithm and additionally employ Huffman coding for letters. The proof,\nhowever, uses analysis of how the fragments of the equation depend on each\nother as well as a new strategy for nondeterministic choices of the algorithm,\nwhich uses several new ideas to limit the space occupied by the letters.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 16:18:31 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 12:50:42 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Je\u017c", "Artur", ""]]}, {"id": "1702.00780", "submitter": "Andrea Cohen", "authors": "Zimi Li, Andrea Cohen, Simon Parsons", "title": "Two forms of minimality in ASPIC+", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many systems of structured argumentation explicitly require that the facts\nand rules that make up the argument for a conclusion be the minimal set\nrequired to derive the conclusion. ASPIC+ does not place such a requirement on\narguments, instead requiring that every rule and fact that are part of an\nargument be used in its construction. Thus ASPIC+ arguments are minimal in the\nsense that removing any element of the argument would lead to a structure that\nis not an argument. In this brief note we discuss these two types of minimality\nand show how the first kind of minimality can, if desired, be recovered in\nASPIC+.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 18:45:38 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Li", "Zimi", ""], ["Cohen", "Andrea", ""], ["Parsons", "Simon", ""]]}, {"id": "1702.00847", "submitter": "Benjamin Kiesl", "authors": "Benjamin Kiesl, Martin Suda, Martina Seidl, Hans Tompits, Armin Biere", "title": "Blocked Clauses in First-Order Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blocked clauses provide the basis for powerful reasoning techniques used in\nSAT, QBF, and DQBF solving. Their definition, which relies on a simple\nsyntactic criterion, guarantees that they are both redundant and easy to find.\nIn this paper, we lift the notion of blocked clauses to first-order logic. We\nintroduce two types of blocked clauses, one for first-order logic with equality\nand the other for first-order logic without equality, and prove their\nredundancy. In addition, we give a polynomial algorithm for checking whether a\nclause is blocked. Based on our new notions of blocking, we implemented a novel\nfirst-order preprocessing tool. Our experiments showed that many first-order\nproblems in the TPTP library contain a large number of blocked clauses.\nMoreover, we observed that their elimination can improve the performance of\nmodern theorem provers, especially on satisfiable problem instances.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 22:16:16 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Kiesl", "Benjamin", ""], ["Suda", "Martin", ""], ["Seidl", "Martina", ""], ["Tompits", "Hans", ""], ["Biere", "Armin", ""]]}, {"id": "1702.00934", "submitter": "EPTCS", "authors": "Emmanuel Jeandel, Simon Perdrix, Renaud Vilmart", "title": "Y-Calculus: A Language for Real Matrices Derived from the ZX-Calculus", "comments": "In Proceedings QPL 2017, arXiv:1802.09737", "journal-ref": "EPTCS 266, 2018, pp. 23-57", "doi": "10.4204/EPTCS.266.2", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a ZX-like diagrammatic language devoted to manipulating real\nmatrices - and rebits -, with its own set of axioms. We prove the necessity of\nsome non trivial axioms of these. We show that some restriction of the language\nis complete. We exhibit two interpretations to and from the ZX-Calculus, thus\nshowing the consistency between the two languages. Finally, we derive from our\nwork a way to extract the real or imaginary part of a ZX-diagram, and prove\nthat a restriction of our language is complete if the equivalent restriction of\nthe ZX-calculus is complete.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 08:36:52 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 03:43:40 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Jeandel", "Emmanuel", ""], ["Perdrix", "Simon", ""], ["Vilmart", "Renaud", ""]]}, {"id": "1702.01135", "submitter": "Guy Katz", "authors": "Guy Katz, Clark Barrett, David Dill, Kyle Julian, Mykel Kochenderfer", "title": "Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks", "comments": "This is the extended version of a paper with the same title that\n  appeared at CAV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have emerged as a widely used and effective means for\ntackling complex, real-world problems. However, a major obstacle in applying\nthem to safety-critical systems is the great difficulty in providing formal\nguarantees about their behavior. We present a novel, scalable, and efficient\ntechnique for verifying properties of deep neural networks (or providing\ncounter-examples). The technique is based on the simplex method, extended to\nhandle the non-convex Rectified Linear Unit (ReLU) activation function, which\nis a crucial ingredient in many modern neural networks. The verification\nprocedure tackles neural networks as a whole, without making any simplifying\nassumptions. We evaluated our technique on a prototype deep neural network\nimplementation of the next-generation airborne collision avoidance system for\nunmanned aircraft (ACAS Xu). Results show that our technique can successfully\nprove properties of networks that are an order of magnitude larger than the\nlargest networks verified using existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 19:26:01 GMT"}, {"version": "v2", "created": "Fri, 19 May 2017 04:50:29 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Katz", "Guy", ""], ["Barrett", "Clark", ""], ["Dill", "David", ""], ["Julian", "Kyle", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "1702.01601", "submitter": "David Fern\\'andez-Duque", "authors": "Philippe Balbiani and David Fern\\'andez-Duque and Emiliano Lorini", "title": "Exploring the bidimensional space: A dynamic logic point of view", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a family of logics for reasoning about agents' positions and\nmotion in the plane which have several potential applications in the area of\nmulti-agent systems (MAS), such as multi-agent planning and robotics. The most\ngeneral logic includes (i) atomic formulas for representing the truth of a\ngiven fact or the presence of a given agent at a certain position of the plane,\n(ii) atomic programs corresponding to the four basic orientations in the plane\n(up, down, left, right) as well as the four program constructs of propositional\ndynamic logic (sequential composition, nondeterministic composition, iteration\nand test). As this logic is not computably enumerable, we study some\ninteresting decidable and axiomatizable fragments of it. We also present a\ndecidable extension of the iteration-free fragment of the logic by special\nprograms representing motion of agents in the plane.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 13:05:58 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Balbiani", "Philippe", ""], ["Fern\u00e1ndez-Duque", "David", ""], ["Lorini", "Emiliano", ""]]}, {"id": "1702.01606", "submitter": "Daniel Gall", "authors": "Daniel Gall and Thom Fr\\\"uhwirth", "title": "An Operational Semantics for the Cognitive Architecture ACT-R and its\n  Translation to Constraint Handling Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational psychology has the aim to explain human cognition by\ncomputational models of cognitive processes. The cognitive architecture ACT-R\nis popular to develop such models. Although ACT-R has a well-defined\npsychological theory and has been used to explain many cognitive processes,\nthere are two problems that make it hard to reason formally about its cognitive\nmodels: First, ACT-R lacks a formalization of its underlying production rule\nsystem and secondly, there are many different implementations and extensions of\nACT-R with technical artifacts complicating formal reasoning even more.\n  This paper describes a formal operational semantics - the very abstract\nsemantics - that abstracts from as many technical details as possible keeping\nit open to extensions and different implementations of the ACT-R theory. In a\nsecond step, this semantics is refined to define some of its abstract features\nthat are found in many implementations of ACT-R - the abstract semantics. It\nconcentrates on the procedural core of ACT-R and is suitable for analysis of\nthe transition system since it still abstracts from details like timing, the\nsub-symbolic layer or conflict resolution.\n  Furthermore, a translation of ACT-R models to the programming language\nConstraint Handling Rules (CHR) is defined. This makes the abstract semantics\nan executable specification of ACT-R. CHR has been used successfully to embed\nother rule-based formalisms like graph transformation systems or functional\nprogramming. There are many results and tools that support formal reasoning\nabout and analysis of CHR programs. The translation of ACT-R models to CHR is\nproven sound and complete w.r.t. the abstract operational semantics of ACT-R.\nThis paves the way to analysis of ACT-R models through CHR. Therefore, to the\nbest of our knowledge, our abstract semantics is the first formulation of ACT-R\nsuitable for both analysis and execution.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 13:19:00 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Gall", "Daniel", ""], ["Fr\u00fchwirth", "Thom", ""]]}, {"id": "1702.01655", "submitter": "Tuan Phong Ngo", "authors": "Parosh Aziz Abdulla, Mohamed Faouzi Atig, Ahmed Bouajjani, Tuan Phong\n  Ngo", "title": "Context-Bounded Model Checking for POWER", "comments": "A preliminary version of this article will appear at TACAS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an under-approximate reachability analysis algorithm for programs\nrunning under the POWER memory model, in the spirit of the work on\ncontext-bounded analysis intitiated by Qadeer et al. in 2005 for detecting bugs\nin concurrent programs (supposed to be running under the classical SC model).\n  To that end, we first introduce a new notion of context-bounding that is\nsuitable for reasoning about computations under POWER, which generalizes the\none defined by Atig et al. in 2011 for the TSO memory model. Then, we provide a\npolynomial size reduction of the context-bounded state reachability problem\nunder POWER to the same problem under SC: Given an input concurrent program P,\nour method produces a concurrent program P' such that, for a fixed number of\ncontext switches, running P' under SC yields the same set of reachable states\nas running P under POWER. The generated program P' contains the same number of\nprocesses as P, and operates on the same data domain. By leveraging the\nstandard model checker CBMC, we have implemented a prototype tool and applied\nit on a set of benchmarks, showing the feasibility of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 15:02:13 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 13:29:31 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 11:44:06 GMT"}, {"version": "v4", "created": "Sat, 1 Dec 2018 08:10:05 GMT"}, {"version": "v5", "created": "Fri, 11 Jan 2019 15:50:01 GMT"}, {"version": "v6", "created": "Sat, 31 Aug 2019 22:12:38 GMT"}, {"version": "v7", "created": "Tue, 24 Sep 2019 03:04:46 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Atig", "Mohamed Faouzi", ""], ["Bouajjani", "Ahmed", ""], ["Ngo", "Tuan Phong", ""]]}, {"id": "1702.01772", "submitter": "Thorsten Wissmann", "authors": "Stefano Gogioso and William Zeng", "title": "Generalised Mermin-type non-locality arguments", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (April 26,\n  2019) lmcs:5402", "doi": "10.23638/LMCS-15(2:3)2019", "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We broadly generalise Mermin-type arguments on GHZ states, and we provide\nexact group-theoretic conditions for non-locality to be achieved. Our results\nare of interest in quantum foundations, where they yield a new hierarchy of\nquantum-realisable All-vs-Nothing arguments. They are also of interest to\nquantum protocols, where they find immediate application to a non-trivial\nextension of the hybrid quantum-classical secret sharing scheme of Hillery,\nBu\\v{z}ek and Berthiaume (HBB). Our proofs are carried out in the graphical\nlanguage of string diagrams for dagger compact categories, and their validity\nextends beyond quantum theory to any theory featuring the relevant algebraic\nstructures.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 19:34:11 GMT"}, {"version": "v2", "created": "Mon, 24 Apr 2017 17:51:10 GMT"}, {"version": "v3", "created": "Sat, 9 Dec 2017 14:41:18 GMT"}, {"version": "v4", "created": "Thu, 25 Apr 2019 09:05:22 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Gogioso", "Stefano", ""], ["Zeng", "William", ""]]}, {"id": "1702.01804", "submitter": "Christoph Rauch", "authors": "Paul Brunet and Damien Pous", "title": "Petri Automata", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  26, 2017) lmcs:3959", "doi": "10.23638/LMCS-13(3:33)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kleene algebra axioms are complete with respect to both language models and\nbinary relation models. In particular, two regular expressions recognise the\nsame language if and only if they are universally equivalent in the model of\nbinary relations. We consider Kleene allegories, i.e., Kleene algebras with two\nadditional operations and a constant which are natural in binary relation\nmodels: intersection, converse, and the full relation. While regular languages\nare closed under those operations, the above characterisation breaks. Putting\ntogether a few results from the literature, we give a characterisation in terms\nof languages of directed and labelled graphs. By taking inspiration from Petri\nnets, we design a finite automata model, Petri automata, allowing to recognise\nsuch graphs. We prove a Kleene theorem for this automata model: the sets of\ngraphs recognisable by Petri automata are precisely the sets of graphs\ndefinable through the extended regular expressions we consider. Petri automata\nallow us to obtain decidability of identity-free relational Kleene lattices,\ni.e., the equational theory generated by binary relations on the signature of\nregular expressions with intersection, but where one forbids unit. This\nrestriction is used to ensure that the corresponding graphs are acyclic. We\nactually show that this decision problem is EXPSPACE-complete.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 21:58:26 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 09:49:13 GMT"}, {"version": "v3", "created": "Mon, 25 Sep 2017 16:35:36 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Brunet", "Paul", ""], ["Pous", "Damien", ""]]}, {"id": "1702.01874", "submitter": "EPTCS", "authors": "Naoki Kobayashi", "title": "Proceedings Eighth Workshop on Intersection Types and Related Systems", "comments": null, "journal-ref": "EPTCS 242, 2017", "doi": "10.4204/EPTCS.242", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a final and revised selection of papers presented at the\nEighth Workshop on Intersection Types and Related Systems (ITRS 2016), held on\nJune 26, 2016 in Porto, in affiliation with FSCD 2016.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 04:21:28 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 06:10:25 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Kobayashi", "Naoki", ""]]}, {"id": "1702.01945", "submitter": "Renaud Vilmart", "authors": "Emmanuel Jeandel (CARTE), Simon Perdrix (CARTE), Renaud Vilmart\n  (CARTE), Quanlong Wang (CARTE)", "title": "ZX-Calculus: Cyclotomic Supplementarity and Incompleteness for\n  Clifford+T quantum mechanics", "comments": "Mathematical Foundations of Computer Science, Aug 2017, Aalborg,\n  Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ZX-Calculus is a powerful graphical language for quantum mechanics and\nquantum information processing. The completeness of the language -- i.e. the\nability to derive any true equation -- is a crucial question. In the quest of a\ncomplete ZX-calculus, supplementarity has been recently proved to be necessary\nfor quantum diagram reasoning (MFCS 2016). Roughly speaking, supplementarity\nconsists in merging two subdiagrams when they are parameterized by antipodal\nangles. We introduce a generalised supplementarity -- called cyclotomic\nsupplementarity -- which consists in merging n subdiagrams at once, when the n\nangles divide the circle into equal parts. We show that when n is an odd prime\nnumber, the cyclotomic supplementarity cannot be derived, leading to a\ncountable family of new axioms for diagrammatic quantum reasoning.We exhibit\nanother new simple axiom that cannot be derived from the existing rules of the\nZX-Calculus, implying in particular the incompleteness of the language for the\nso-called Clifford+T quantum mechanics. We end up with a new axiomatisation of\nan extended ZX-Calculus, including an axiom schema for the cyclotomic\nsupplementarity.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 10:19:04 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 09:12:48 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Jeandel", "Emmanuel", "", "CARTE"], ["Perdrix", "Simon", "", "CARTE"], ["Vilmart", "Renaud", "", "CARTE"], ["Wang", "Quanlong", "", "CARTE"]]}, {"id": "1702.02272", "submitter": "EPTCS", "authors": "Co\\c{s}ku Acay (Carnegie Mellon University), Frank Pfenning (Carnegie\n  Mellon University)", "title": "Intersections and Unions of Session Types", "comments": "In Proceedings ITRS 2016, arXiv:1702.01874", "journal-ref": "EPTCS 242, 2017, pp. 4-19", "doi": "10.4204/EPTCS.242.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work has extended the deep, logical connection between the linear\nsequent calculus and session-typed message-passing concurrent computation with\nequi-recursive types and a natural notion of subtyping. In this paper, we\nextend this further by intersection and union types in order to express\nmultiple behavioral properties of processes in a single type. We prove session\nfidelity and absence of deadlock and illustrate the expressive power of our\nsystem with some simple examples. We observe that we can represent internal and\nexternal choice by intersection and union, respectively, which was previously\nsuggested by Padovani for a different language of session types motivated by\noperational rather than logical concerns.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:19:35 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Acay", "Co\u015fku", "", "Carnegie Mellon University"], ["Pfenning", "Frank", "", "Carnegie\n  Mellon University"]]}, {"id": "1702.02273", "submitter": "EPTCS", "authors": "Steffen van Bakel (Imperial College London, UK)", "title": "Characterisation of Approximation and (Head) Normalisation for\n  $\\lambda\\mu$ using Strict Intersection Types", "comments": "In Proceedings ITRS 2016, arXiv:1702.01874", "journal-ref": "EPTCS 242, 2017, pp. 20-30", "doi": "10.4204/EPTCS.242.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the strict type assignment for lambda-mu that is presented in [van\nBakel'16]. We define a notion of approximants of lambda-mu-terms, show that it\ngenerates a semantics, and that for each typeable term there is an approximant\nthat has the same type. We show that this leads to a characterisation via\nassignable types for all terms that have a head normal form, and to one for all\nterms that have a normal form, as well as to one for all terms that are\nstrongly normalisable.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:19:53 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["van Bakel", "Steffen", "", "Imperial College London, UK"]]}, {"id": "1702.02274", "submitter": "EPTCS", "authors": "Mario Coppo (Universit\\`a di Torino), Mariangiola Dezani-Ciancaglini\n  (Universit\\`a di Torino), Alejandro D\\'iaz-Caro (CONICET and Universidad\n  Nacional de Quilmes), Ines Margaria (Universit\\`a di Torino), Maddalena\n  Zacchi (Universit\\`a di Torino)", "title": "Retractions in Intersection Types", "comments": "In Proceedings ITRS 2016, arXiv:1702.01874", "journal-ref": "EPTCS 242, 2017, pp. 31-47", "doi": "10.4204/EPTCS.242.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with retraction - intended as isomorphic embedding - in\nintersection types building left and right inverses as terms of a lambda\ncalculus with a bottom constant. The main result is a necessary and sufficient\ncondition two strict intersection types must satisfy in order to assure the\nexistence of two terms showing the first type to be a retract of the second\none. Moreover, the characterisation of retraction in the standard intersection\ntypes is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:20:11 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Coppo", "Mario", "", "Universit\u00e0 di Torino"], ["Dezani-Ciancaglini", "Mariangiola", "", "Universit\u00e0 di Torino"], ["D\u00edaz-Caro", "Alejandro", "", "CONICET and Universidad\n  Nacional de Quilmes"], ["Margaria", "Ines", "", "Universit\u00e0 di Torino"], ["Zacchi", "Maddalena", "", "Universit\u00e0 di Torino"]]}, {"id": "1702.02278", "submitter": "EPTCS", "authors": "Pawe{\\l} Parys (University of Warsaw)", "title": "Intersection Types and Counting", "comments": "In Proceedings ITRS 2016, arXiv:1702.01874", "journal-ref": "EPTCS 242, 2017, pp. 48-63", "doi": "10.4204/EPTCS.242.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to the following meta-problem: given a quantitative\nproperty of trees, design a type system such that the desired property for the\ntree generated by an infinitary ground lambda-term corresponds to some property\nof a derivation of a type for this lambda-term, in this type system.\n  Our approach is presented in the particular case of the language finiteness\nproblem for nondeterministic higher-order recursion schemes (HORSes): given a\nnondeterministic HORS, decide whether the set of all finite trees generated by\nthis HORS is finite. We give a type system such that the HORS can generate a\ntree of an arbitrarily large finite size if and only if in the type system we\ncan obtain derivations that are arbitrarily large, in an appropriate sense; the\nlatter condition can be easily decided.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:28:00 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 06:22:04 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Parys", "Pawe\u0142", "", "University of Warsaw"]]}, {"id": "1702.02280", "submitter": "EPTCS", "authors": "Oleg Kiselyov (Tohoku University, Japan)", "title": "Generating Code with Polymorphic let: A Ballad of Value Restriction,\n  Copying and Sharing", "comments": "In Proceedings ML/OCaml 2015, arXiv:1702.01872", "journal-ref": "EPTCS 241, 2017, pp. 1-22", "doi": "10.4204/EPTCS.241.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Getting polymorphism and effects such as mutation to live together in the\nsame language is a tale worth telling, under the recurring refrain of copying\nvs. sharing. We add new stanzas to the tale, about the ordeal to generate code\nwith polymorphism and effects, and be sure it type-checks. Generating\nwell-typed-by-construction polymorphic let-expressions is impossible in the\nHindley-Milner type system: even the author believed that.\n  The polymorphic-let generator turns out to exist. We present its derivation\nand the application for the lightweight implementation of quotation via a novel\nand unexpectedly simple source-to-source transformation to code-generating\ncombinators.\n  However, generating let-expressions with polymorphic functions demands more\nthan even the relaxed value restriction can deliver. We need a new deal for\nlet-polymorphism in ML. We conjecture the weaker restriction and implement it\nin a practically-useful code-generation library. Its formal justification is\nformulated as the research program.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:29:19 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Kiselyov", "Oleg", "", "Tohoku University, Japan"]]}, {"id": "1702.02369", "submitter": "Daniel Dietsch", "authors": "Marius Greitschus, Daniel Dietsch, Andreas Podelski", "title": "Refining Trace Abstraction using Abstract Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The CEGAR loop in software model checking notoriously diverges when the\nabstraction refinement procedure does not derive a loop invariant. An\nabstraction refinement procedure based on an SMT solver is applied to a trace,\ni.e., a restricted form of a program (without loops). In this paper, we present\na new abstraction refinement procedure that aims at circumventing this\nrestriction whenever possible. We apply abstract interpretation to a program\nthat we derive from the given trace. If the program contains a loop, we are\nguaranteed to obtain a loop invariant. We call an SMT solver only in the case\nwhere the abstract interpretation returns an indefinite answer. That is, the\nidea is to use abstract interpretation and an SMT solver in tandem. An\nexperimental evaluation in the setting of trace abstraction indicates the\npractical potential of this idea.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 11:04:12 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Greitschus", "Marius", ""], ["Dietsch", "Daniel", ""], ["Podelski", "Andreas", ""]]}, {"id": "1702.02385", "submitter": "Patrick Trentin", "authors": "Roberto Sebastiani, Patrick Trentin", "title": "On Optimization Modulo Theories, MaxSMT and Sorting Networks", "comments": "17 pages, submitted at Tacas 17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization Modulo Theories (OMT) is an extension of SMT which allows for\nfinding models that optimize given objectives. (Partial weighted) MaxSMT --or\nequivalently OMT with Pseudo-Boolean objective functions, OMT+PB-- is a\nvery-relevant strict subcase of OMT. We classify existing approaches for MaxSMT\nor OMT+PB in two groups: MaxSAT-based approaches exploit the efficiency of\nstate-of-the-art MAXSAT solvers, but they are specific-purpose and not always\napplicable; OMT-based approaches are general-purpose, but they suffer from\nintrinsic inefficiencies on MaxSMT/OMT+PB problems.\n  We identify a major source of such inefficiencies, and we address it by\nenhancing OMT by means of bidirectional sorting networks. We implemented this\nidea on top of the OptiMathSAT OMT solver. We run an extensive empirical\nevaluation on a variety of problems, comparing MaxSAT-based and OMT-based\ntechniques, with and without sorting networks, implemented on top of\nOptiMathSAT and {\\nu}Z. The results support the effectiveness of this idea, and\nprovide interesting insights about the different approaches.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 11:52:15 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Sebastiani", "Roberto", ""], ["Trentin", "Patrick", ""]]}, {"id": "1702.02397", "submitter": "Cynthia Kop", "authors": "Cynthia Kop", "title": "Quasi-reductivity of Logically Constrained Term Rewriting Systems", "comments": "arXiv admin note: text overlap with arXiv:1409.0166", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers quasi-reductivity - essentially, the property that an\nevaluation cannot get \"stuck\" due to a missing case in pattern matching - in\nthe context of term rewriting with logical constraints.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 12:34:42 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Kop", "Cynthia", ""]]}, {"id": "1702.02439", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Yu-Fang Chen, Chih-Duo Hong, Ond\\v{r}ej Leng\\'al, Shin-Cheng Mu,\n  Nishant Sinha, Bow-Yaw Wang", "title": "An Executable Sequential Specification for Spark Aggregation", "comments": "an extended version of a paper accepted at NETYS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spark is a new promising platform for scalable data-parallel computation. It\nprovides several high-level application programming interfaces (APIs) to\nperform parallel data aggregation. Since execution of parallel aggregation in\nSpark is inherently non-deterministic, a natural requirement for Spark programs\nis to give the same result for any execution on the same data set. We present\nPureSpark, an executable formal Haskell specification for Spark aggregate\ncombinators. Our specification allows us to deduce the precise condition for\ndeterministic outcomes from Spark aggregation. We report case studies analyzing\ndeterministic outcomes and correctness of Spark programs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 14:33:07 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Chen", "Yu-Fang", ""], ["Hong", "Chih-Duo", ""], ["Leng\u00e1l", "Ond\u0159ej", ""], ["Mu", "Shin-Cheng", ""], ["Sinha", "Nishant", ""], ["Wang", "Bow-Yaw", ""]]}, {"id": "1702.02528", "submitter": "Christoph Rauch", "authors": "Giorgio Bacci and Giovanni Bacci and Kim G. Larsen and Radu Mardare", "title": "A Complete Quantitative Deduction System for the Bisimilarity Distance\n  on Markov Chains", "comments": "Logical Methods in Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (November\n  16, 2018) lmcs:4977", "doi": "10.23638/LMCS-14(4:15)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose a complete axiomatization of the bisimilarity\ndistance of Desharnais et al. for the class of finite labelled Markov chains.\nOur axiomatization is given in the style of a quantitative extension of\nequational logic recently proposed by Mardare, Panangaden, and Plotkin (LICS\n2016) that uses equality relations $t \\equiv_\\varepsilon s$ indexed by\nrationals, expressing that `$t$ is approximately equal to $s$ up to an error\n$\\varepsilon$'. Notably, our quantitative deduction system extends in a natural\nway the equational system for probabilistic bisimilarity given by Stark and\nSmolka by introducing an axiom for dealing with the Kantorovich distance\nbetween probability distributions. The axiomatization is then used to propose a\nmetric extension of a Kleene's style representation theorem for finite labelled\nMarkov chains, that was proposed (in a more general coalgebraic fashion) by\nSilva et al. (Inf. Comput. 2011).\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 17:15:33 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 21:23:20 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 14:09:10 GMT"}, {"version": "v4", "created": "Tue, 13 Nov 2018 15:55:09 GMT"}, {"version": "v5", "created": "Thu, 15 Nov 2018 15:43:02 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Bacci", "Giorgio", ""], ["Bacci", "Giovanni", ""], ["Larsen", "Kim G.", ""], ["Mardare", "Radu", ""]]}, {"id": "1702.02589", "submitter": "David Cerna", "authors": "David M. Cerna and Michael Lettmann", "title": "Clausal Analysis of First-order Proof Schemata", "comments": "Submitted to LPAR 2017. Pre-print", "journal-ref": null, "doi": "10.1109/SYNASC.2017.00029", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof schemata are a variant of LK-proofs able to simulate various induction\nschemes in first-order logic by adding so called proof links to the standard\nfirst-order LK-calculus. Proof links allow proofs to reference proofs thus\ngiving proof schemata a recursive structure. Unfortunately, applying reductive\ncut- elimination is non-trivial in the presence of proof links. Borrowing the\nconcept of lazy instantiation from functional programming, we evaluate proof\nlinks locally allowing reductive cut-elimination to proceed past them. Though,\nthis method cannot be used to obtain cut-free proof schemata, we nonetheless\nobtain important results concerning the schematic CERES method, that is a\nmethod of cut-elimination for proof schemata based on resolution. In \"Towards a\nclausal analysis of cut-elimination\", it was shown that reductive\ncut-elimination transforms a given LK-proof in such a way that a subsumption\nrelation holds between the pre- and post-transformation characteristic clause\nsets, i.e. the clause set representing the cut-structure of an LK-proof. Let\nCL(A') be the characteristic clause set of a normal form A' of an LK-proof A\nthat is reached by performing reductive cut-elimination on A without atomic cut\nelimination. Then CL(A') is subsumed by all characteristic clause sets\nextractable from any application of reductive cut-elimination to A. Such a\nnormal form is referred to as an ACNF top and plays an essential role in\nmethods of cut-elimination by resolution. These results can be extended to\nproof schemata through our \"lazy instantiation\" of proof links, and provides an\nessential step toward a complete cut-elimination method for proof schemata.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 19:23:54 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Cerna", "David M.", ""], ["Lettmann", "Michael", ""]]}, {"id": "1702.02890", "submitter": "Johannes Klaus Fichte", "authors": "Johannes Fichte, Markus Hecher, Michael Morak, Stefan Woltran", "title": "Answer Set Solving with Bounded Treewidth Revisited", "comments": "This paper extends and updates a paper that has been presented on the\n  workshop TAASP'16 (arXiv:1612.07601). We provide a higher detail level, full\n  proofs and more examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized algorithms are a way to solve hard problems more efficiently,\ngiven that a specific parameter of the input is small. In this paper, we apply\nthis idea to the field of answer set programming (ASP). To this end, we propose\ntwo kinds of graph representations of programs to exploit their treewidth as a\nparameter. Treewidth roughly measures to which extent the internal structure of\na program resembles a tree. Our main contribution is the design of\nparameterized dynamic programming algorithms, which run in linear time if the\ntreewidth and weights of the given program are bounded. Compared to previous\nwork, our algorithms handle the full syntax of ASP. Finally, we report on an\nempirical evaluation that shows good runtime behaviour for benchmark instances\nof low treewidth, especially for counting answer sets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 16:50:23 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Fichte", "Johannes", ""], ["Hecher", "Markus", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "1702.02972", "submitter": "Nikos Tzevelekos", "authors": "Lars Birkedal, Thomas Dinsdale-Young, Guilhem Jaber, Kasper Svendsen,\n  Nikos Tzevelekos", "title": "Trace Properties from Separation Logic Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formal approach for relating abstract separation logic library\nspecifications with the trace properties they enforce on interactions between a\nclient and a library. Separation logic with abstract predicates enforces a\nresource discipline that constrains when and how calls may be made between a\nclient and a library. Intuitively, this can enforce a protocol on the\ninteraction trace. This intuition is broadly used in the separation logic\ncommunity but has not previously been formalised. We provide just such a\nformalisation. Our approach is based on using wrappers which instrument library\ncode to induce execution traces for the properties under examination. By\nconsidering a separation logic extended with trace resources, we prove that\nwhen a library satisfies its separation logic specification then its wrapped\nversion satisfies the same specification and, moreover, maintains the trace\nproperties as an invariant. Consequently, any client and library implementation\nthat are correct with respect to the separation logic specification will\nsatisfy the trace properties.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 20:26:10 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Birkedal", "Lars", ""], ["Dinsdale-Young", "Thomas", ""], ["Jaber", "Guilhem", ""], ["Svendsen", "Kasper", ""], ["Tzevelekos", "Nikos", ""]]}, {"id": "1702.03085", "submitter": "Pierre Lescanne", "authors": "Pierre Lescanne (LIP)", "title": "Quantitative aspects of linear and affine closed lambda terms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO cs.PL math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affine $\\lambda$-terms are $\\lambda$-terms in which each bound variable\noccurs at most once and linear $\\lambda$-terms are $\\lambda$-terms in which\neach bound variables occurs once. and only once. In this paper we count the\nnumber of closed affine $\\lambda$-terms of size $n$, closed linear\n$\\lambda$-terms of size $n$, affine $\\beta$-normal forms of size $n$ and linear\n$\\beta$-normal forms of ise $n$, for different ways of measuring the size of\n$\\lambda$-terms. From these formulas, we show how we can derive programs for\ngenerating all the terms of size $n$ for each class. For this we use a specific\ndata structure, which are contexts taking into account all the holes at levels\nof abstractions.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 07:32:08 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 14:46:00 GMT"}, {"version": "v3", "created": "Mon, 27 Feb 2017 14:02:40 GMT"}, {"version": "v4", "created": "Mon, 3 Apr 2017 15:21:15 GMT"}, {"version": "v5", "created": "Tue, 23 May 2017 06:10:51 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Lescanne", "Pierre", "", "LIP"]]}, {"id": "1702.03096", "submitter": "Daniele Francesco Santamaria", "authors": "Domenico Cantone and Marianna Nicolosi-Asmundo and Daniele Francesco\n  Santamaria", "title": "A set-theoretical approach for ABox reasoning services (Extended\n  Version)", "comments": "27 pages. Extended version for RR 2017. arXiv admin note: text\n  overlap with arXiv:1606.07337", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the most common ABox reasoning services for the\ndescription logic $\\dlssx$ ($\\shdlssx$, for short) and prove their decidability\nvia a reduction to the satisfiability problem for the set-theoretic fragment\n\\flqsr. The description logic $\\shdlssx$ is very expressive, as it admits\nvarious concept and role constructs, and data types, that allow one to\nrepresent rule-based languages such as SWRL. Decidability results are achieved\nby defining a generalization of the conjunctive query answering problem, called\nHOCQA (Higher Order Conjunctive Query Answering), that can be instantiated to\nthe most wide\\-spread ABox reasoning tasks. We also present a \\ke\\space based\nprocedure for calculating the answer set from $\\shdlssx$ knowledge bases and\nhigher order $\\shdlssx$ conjunctive queries, thus providing means for reasoning\non several well-known ABox reasoning tasks. Our calculus extends a previously\nintroduced \\ke\\space based decision procedure for the CQA problem.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 08:45:38 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 07:35:35 GMT"}, {"version": "v3", "created": "Sat, 25 Feb 2017 15:13:06 GMT"}, {"version": "v4", "created": "Wed, 1 Mar 2017 11:52:29 GMT"}, {"version": "v5", "created": "Sat, 29 Apr 2017 09:48:38 GMT"}, {"version": "v6", "created": "Wed, 3 May 2017 11:06:55 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Cantone", "Domenico", ""], ["Nicolosi-Asmundo", "Marianna", ""], ["Santamaria", "Daniele Francesco", ""]]}, {"id": "1702.03277", "submitter": "Steven Obua", "authors": "Steven Obua, Phil Scott, Jacques Fleuriot", "title": "Local Lexing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel parsing concept called local lexing. It integrates the\nclassically separated stages of lexing and parsing by allowing lexing to be\ndependent upon the parsing progress and by providing a simple mechanism for\nconstraining lexical ambiguity. This makes it possible for language design to\nbe composable not only at the level of context-free grammars, but also at the\nlexical level. It also makes it possible to include lightweight error-handling\ndirectly as part of the language specification instead of leaving it up to the\nimplementation.\n  We present a high-level algorithm for local lexing, which is an extension of\nEarley's algorithm. We have formally verified the correctness of our algorithm\nwith respect to its local lexing semantics in Isabelle/HOL.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 18:28:26 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 17:00:45 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Obua", "Steven", ""], ["Scott", "Phil", ""], ["Fleuriot", "Jacques", ""]]}, {"id": "1702.03288", "submitter": "Christopher Banks", "authors": "Christopher J. Banks and Ian Stark", "title": "A More Sensitive Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic of Behaviour in Context (LBC) is a spatio-temporal logic for expressing\nproperties of continuous-state processes, such as biochemical reaction\nnetworks. LBC builds on the existing Metric Interval Temporal Logic (MITL) and\nadds a \"context modality\" that explores the behaviour of a system when composed\nwith an external process. LBC models are terms of the Continuous {\\pi}-Calculus\n(c{\\pi}), a process algebra with continuous state space. Our previously\npublished LBC model-checking technique required examining many points along the\nbehavioural trajectory of a process; and potentially computing further\ntrajectories branching off at every such point. This raised two difficulties:\nmixing temporal and spatial modalities could require computing a large number\nof trajectories, with costly numerical solution of differential equations; and\nmight still fail to check intermediate values between discrete points on those\ntrajectories. In this paper we make progress against both of these problems\nusing techniques from signal temporal logic and from sensitivity analysis.\nBoolean signals aggressively compress trace information, allowing more\nefficient computation; and sensitivity analysis lets us reliably check formulae\nover a region by calculating a smaller number of sample trajectories.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 18:59:20 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Banks", "Christopher J.", ""], ["Stark", "Ian", ""]]}, {"id": "1702.03363", "submitter": "Yuting Wang", "authors": "Yuting Wang", "title": "A Higher-Order Abstract Syntax Approach to the Verified Compilation of\n  Functional Programs", "comments": "PhD thesis, Dec 2016, University of Minnesota", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the implementation and verification of compilers for functional\nprogramming languages are greatly simplified by employing a higher-order\nrepresentation of syntax known as Higher-Order Abstract Syntax or HOAS. The\nunderlying idea of HOAS is to use a meta-language that provides a built-in and\nlogical treatment of binding related notions. By embedding the meta-language\nwithin a larger programming or reasoning framework, it is possible to absorb\nthe treatment of binding structure in the object language into the meta-theory\nof the system, thereby greatly simplifying the overall implementation and\nreasoning processes.\n  We develop the above argument in this thesis by presenting and demonstrating\nthe effectiveness of an approach to the verified implementation of compiler\ntransformations for functional programs that exploits HOAS. In this approach,\ntransformations on functional programs are first articulated in the form of\nrule-based relational specifications. These specifications are rendered into\nprograms in the language lambda Prolog. On the one hand, these programs serve\ndirectly as implementations. On the other hand, they can be used as input to\nthe Abella system which allows us to prove properties about them and thereby\nabout the implementations. Both lambda Prolog and Abella support the use of the\nHOAS approach. Thus, they constitute a framework that can be used to test out\nthe benefits of the HOAS approach in verified compilation. We use them to\nimplement and verify a compiler for a representative functional programming\nlanguage that embodies the transformations that form the core of many compilers\nfor such languages. In both the programming and the reasoning phases, we show\nhow the use of the HOAS approach significantly simplifies the representation,\nmanipulation, analysis and reasoning of binding structure.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 01:10:54 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Wang", "Yuting", ""]]}, {"id": "1702.03414", "submitter": "Kees Middelburg", "authors": "C. A. Middelburg", "title": "On the strongest three-valued paraconsistent logic contained in\n  classical logic and its dual", "comments": "17 pages, version that is accepted for publication, there is some\n  text overlap between this paper and arXiv:1508.06899 [cs.LO]", "journal-ref": "Journal of Logic and Computation, 31(2):597--611, 2021", "doi": "10.1093/logcom/exaa084", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LP$^{\\supset,\\mathsf{F}}$ is a three-valued paraconsistent propositional\nlogic which is essentially the same as J3. It has most properties that have\nbeen proposed as desirable properties of a reasonable paraconsistent\npropositional logic. However, it follows easily from already published results\nthat there are exactly 8192 different three-valued paraconsistent propositional\nlogics that have the properties concerned. In this paper, properties concerning\nthe logical equivalence relation of a logic are used to distinguish\nLP$^{\\supset,\\mathsf{F}}$ from the others. As one of the bonuses of focussing\non the logical equivalence relation, it is found that only 32 of the 8192\nlogics have a logical equivalence relation that satisfies the identity,\nannihilation, idempotent, and commutative laws for conjunction and disjunction.\nFor most properties of LP$^{\\supset,\\mathsf{F}}$ that have been proposed as\ndesirable properties of a reasonable paraconsistent propositional logic, its\nparacomplete analogue has a comparable property. In this paper, properties\nconcerning the logical equivalence relation of a logic are also used to\ndistinguish the paracomplete analogue of LP$^{\\supset,\\mathsf{F}}$ from the\nother three-valued paracomplete propositional logics with those comparable\nproperties.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 12:04:14 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 10:57:11 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 11:21:26 GMT"}, {"version": "v4", "created": "Thu, 14 Mar 2019 15:50:34 GMT"}, {"version": "v5", "created": "Sun, 24 May 2020 10:52:12 GMT"}, {"version": "v6", "created": "Wed, 23 Sep 2020 09:27:19 GMT"}, {"version": "v7", "created": "Tue, 1 Dec 2020 16:31:04 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Middelburg", "C. A.", ""]]}, {"id": "1702.03450", "submitter": "Mahsa Shirmohammadi", "authors": "Karin Quaas, Mahsa Shirmohammadi, James Worrell", "title": "Revisiting Reachability in Timed Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit a fundamental result in real-time verification, namely that the\nbinary reachability relation between configurations of a given timed automaton\nis definable in linear arithmetic over the integers and reals. In this paper we\ngive a new and simpler proof of this result, building on the well-known\nreachability analysis of timed automata involving difference bound matrices.\nUsing this new proof, we give an exponential-space procedure for model checking\nthe reachability fragment of the logic parametric TCTL. Finally we show that\nthe latter problem is NEXPTIME-hard.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 19:58:06 GMT"}, {"version": "v2", "created": "Tue, 18 Apr 2017 18:46:04 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Quaas", "Karin", ""], ["Shirmohammadi", "Mahsa", ""], ["Worrell", "James", ""]]}, {"id": "1702.03504", "submitter": "Vivek Nigam", "authors": "Max Kanovich, Tajana Ban Kirigin, Vivek Nigam, Andre Scedrov and\n  Carolyn Talcott", "title": "Time, Computational Complexity, and Probability in the Analysis of\n  Distance-Bounding Protocols", "comments": "Extending our POST 2015 paper", "journal-ref": null, "doi": "10.3233/JCS-0560", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many security protocols rely on the assumptions on the physical properties in\nwhich its protocol sessions will be carried out. For instance, Distance\nBounding Protocols take into account the round trip time of messages and the\ntransmission velocity to infer an upper bound of the distance between two\nagents. We classify such security protocols as Cyber-Physical. Time plays a key\nrole in design and analysis of many of these protocols. This paper investigates\nthe foundational differences and the impacts on the analysis when using models\nwith discrete time and models with dense time. We show that there are attacks\nthat can be found by models using dense time, but not when using discrete time.\nWe illustrate this with a novel attack that can be carried out on most Distance\nBounding Protocols. In this attack, one exploits the execution delay of\ninstructions during one clock cycle to convince a verifier that he is in a\nlocation different from his actual position. We additionally present a\nprobabilistic analysis of this novel attack. As a formal model for representing\nand analyzing Cyber-Physical properties, we propose a Multiset Rewriting model\nwith dense time suitable for specifying cyber-physical security protocols. We\nintroduce Circle-Configurations and show that they can be used to symbolically\nsolve the reachability problem for our model, and show that for the important\nclass of balanced theories the reachability problem is PSPACE-complete. We also\nshow how our model can be implemented using the computational rewriting tool\nMaude, the machinery that automatically searches for such attacks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 08:22:54 GMT"}, {"version": "v2", "created": "Wed, 4 Oct 2017 07:10:19 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Kanovich", "Max", ""], ["Kirigin", "Tajana Ban", ""], ["Nigam", "Vivek", ""], ["Scedrov", "Andre", ""], ["Talcott", "Carolyn", ""]]}, {"id": "1702.03511", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Axioms for behavioural congruence of single-pass instruction sequences", "comments": "19 pages, this paper draws somewhat from the preliminaries of\n  arXiv:1502.00238 [cs.PL] and some earlier papers; some remarks added and some\n  remarks reformulated", "journal-ref": "Scientific Annals of Computer Science 27(2):111--135 (2017)", "doi": "10.7561/SACS.2017.2.111", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In program algebra, an algebraic theory of single-pass instruction sequences,\nthree congruences on instruction sequences are paid attention to: instruction\nsequence congruence, structural congruence, and behavioural congruence. Sound\nand complete axiom systems for the first two congruences were already given in\nearly papers on program algebra. The current paper is the first one that is\nconcerned with an axiom system for the third congruence. The presented axiom\nsystem is especially notable for its axioms that have to do with forward jump\ninstructions.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 10:32:38 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 09:13:17 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1702.03523", "submitter": "Anton Salikhmetov", "authors": "Anton Salikhmetov", "title": "A better model of computation for digital physics?", "comments": "4 pages, adapting the \"Preliminaries\" section from arXiv:1609.03644", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is meant to invite the reader to consider interaction nets, a\nrelatively recently discovered model of computation, as a possible alternative\nfor cellular automata which are often employed as the basis for digital\nphysics. Defined as graph-like structures (in contrast to the grids for\ncellular automata), interaction nets possess a set of interesting properties,\nsuch as locality, linearity, and strong confluence, which together result in\nso-called clockless computation in the sense that they do not require any\nglobal clock in order to operate. We believe that an attempt of using\ninteraction nets as a replacement for cellular automata may lead to a new view\nin digital physics.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 13:15:06 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Salikhmetov", "Anton", ""]]}, {"id": "1702.03981", "submitter": "Reuben Rowe", "authors": "Reuben N. S. Rowe and James Brotherston", "title": "Size Relationships in Abstract Cyclic Entailment Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cyclic proof system generalises the standard notion of a proof as a finite\ntree of locally sound inferences by allowing proof objects to be potentially\ninfinite. Regular infinite proofs can be finitely represented as graphs. To\npreclude spurious cyclic reasoning, cyclic proof systems come equipped with a\nwell-founded notion of 'size' for the models that interpret their logical\nstatements. A global soundness condition on proof objects, stated in terms of\nthis notion of size, ensures that any non-well-founded paths in the proof\nobject can be disregarded.\n  We give an abstract definition of a subclass of such cyclic proof systems:\ncyclic entailment systems. In this setting, we consider the problem of\ncomparing the size of a model when interpreted in relation to the antecedent of\nan entailment, with that when interpreted in relation to the consequent.\nSpecifically, we give a further condition on proof objects which ensures that\nmodels of a given entailment are always 'smaller' when interpreted with respect\nto the consequent than when interpreted with respect to the antecedent.\nKnowledge of such relationships is useful in a program verification setting.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 20:43:55 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Rowe", "Reuben N. S.", ""], ["Brotherston", "James", ""]]}, {"id": "1702.04478", "submitter": "Jian Liu", "authors": "Jian Liu and Ying Jiang and Yanyun Chen and Qing Zhou", "title": "VMDV: A 3D Visualization Tool for Modeling, Demonstration, and\n  Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The output of an automated theorem prover is usually presented by using a\ntext format, they are often too heavy to be understood. In model checking\nsetting, it would be helpful if one can observe the structure of models and the\nverification procedures. A 3D visualization tool (\\textsf{VMDV}) is proposed in\nthis paper to address these problems. The facility of \\vmdv is illustrated by\napplying it to a proof systems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 06:56:11 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Liu", "Jian", ""], ["Jiang", "Ying", ""], ["Chen", "Yanyun", ""], ["Zhou", "Qing", ""]]}, {"id": "1702.04551", "submitter": "Bart Bogaerts", "authors": "Marc Denecker and Bart Bogaerts and Joost Vennekens", "title": "A Logical Study of Some Common Principles of Inductive Definition and\n  its Implications for Knowledge Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The definition is a common form of human expert knowledge, a building block\nof formal science and mathematics, a foundation for database theory and is\nsupported in various forms in many knowledge representation and formal\nspecification languages and systems. This paper is a formal study of some of\nthe most common forms of inductive definitions found in scientific text:\nmonotone inductive definition, definition by induction over a well-founded\norder and iterated inductive definitions. We define a logic of definitions\noffering a uniform formal syntax to express definitions of the different sorts,\nand we define its semantics by a faithful formalization of the induction\nprocess. Several fundamental properties of definition by induction emerge: the\nnon-determinism of the induction process, the confluence of induction\nprocesses, the role of the induction order and its relation to the inductive\nrules, how the induction order constrains the induction process and,\nultimately, that the induction order is irrelevant: the defined set does not\ndepend on the induction order. We propose an inductive construction capable of\nconstructing the defined set without using the induction order. We investigate\nborderline definitions of the sort that appears in definitional paradoxes.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 11:20:51 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Denecker", "Marc", ""], ["Bogaerts", "Bart", ""], ["Vennekens", "Joost", ""]]}, {"id": "1702.04603", "submitter": "Christoph Rauch", "authors": "Brijesh Dongol, Ian J. Hayes and Georg Struth", "title": "Convolution Algebras: Relational Convolution, Generalised Modalities and\n  Incidence Algebras", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (February\n  9, 2021) lmcs:7164", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolution is a ubiquitous operation in mathematics and computing. The\nKripke semantics for substructural and interval logics motivates its study for\nquantale-valued functions relative to ternary relations. The resulting notion\nof relational convolution leads to generalised binary and unary modal operators\nfor qualitative and quantitative models, and to more conventional variants,\nwhen ternary relations arise from identities over partial semigroups.\nConvolution-based semantics for fragments of categorial, linear and incidence\n(segment or interval) logics are provided as qualitative applications.\nQuantitative examples include algebras of durations and mean values in the\nduration calculus.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 13:41:16 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 06:11:33 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 07:16:49 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 12:57:29 GMT"}, {"version": "v5", "created": "Mon, 8 Feb 2021 18:25:46 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Dongol", "Brijesh", ""], ["Hayes", "Ian J.", ""], ["Struth", "Georg", ""]]}, {"id": "1702.04650", "submitter": "Julia Padberg", "authors": "Julia Padberg", "title": "Towards M-Adhesive Categories based on Coalgebras and Comma Categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution we investigate several extensions of the powerset that\ncomprise arbitrarily nested subsets, and call them superpower set. This allows\nthe definition of graphs with possibly infinitely nested nodes. additionally we\ndefine edges that are incident to edges. Since we use coalgebraic constructions\nwe refer to these graphs as corecursive graphs. The superpower set functors are\nexamined and then used for the definition of $\\mathcal{M}$-adhesive categories\nwhich are the basic categories for $\\mathcal{M}$-adhesive transformation\nsystems. So, we additionally show that coalgebras $\\mathbf{Sets}_F$ are\n$\\mathcal{M}$-adhesive categories provided the functor $F:\\mathbf{Sets}_F \\to\n\\mathbf{Sets}_F$ preserves pullbacks along monomorphisms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 15:22:39 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 14:29:54 GMT"}, {"version": "v3", "created": "Sat, 15 Jul 2017 06:37:37 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Padberg", "Julia", ""]]}, {"id": "1702.04693", "submitter": "Pedro R. D'Argenio", "authors": "Pedro R. D'Argenio, Gilles Barthe, Sebastian Biewer, Bernd Finkbeiner,\n  Holger Hermanns", "title": "Is your software on dope? Formal analysis of surreptitiously \"enhanced\"\n  programs", "comments": "To appear in the proceedings of ESOP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually, it is the software manufacturer who employs verification or testing\nto ensure that the software embedded in a device meets its main objectives.\nHowever, these days we are confronted with the situation that economical or\ntechnological reasons might make a manufacturer become interested in the\nsoftware slightly deviating from its main objective for dubious reasons.\nExamples include lock-in strategies and the $\\mathrm{NO}_x$ emission scandals\nin automotive industry. This phenomenon is what we call software doping. It is\nturning more widespread as software is embedded in ever more devices of daily\nuse.\n  The primary contribution of this article is to provide a hierarchy of simple\nbut solid formal definitions that enable to distinguish whether a program is\nclean or doped. Moreover, we show that these characterisations provide an\nimmediate framework for analysis by using already existing verification\ntechniques. We exemplify this by applying self-composition on sequential\nprograms and model checking of HyperLTL formulas on reactive models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 17:46:31 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["D'Argenio", "Pedro R.", ""], ["Barthe", "Gilles", ""], ["Biewer", "Sebastian", ""], ["Finkbeiner", "Bernd", ""], ["Hermanns", "Holger", ""]]}, {"id": "1702.04769", "submitter": "Ale\\v{s} Bizjak", "authors": "Matteo Mio, Micha{\\l} Skrzypczak, Henryk Michalewski", "title": "Monadic Second Order Logic with Measure and Category Quantifiers", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 2, Automata\n  and logic (April 10, 2018) lmcs:4433", "doi": "10.23638/LMCS-14(2:2)2018", "report-no": null, "categories": "cs.LO cs.FL math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the extension of Monadic Second Order logic, interpreted over\ninfinite words and trees, with generalized \"for almost all\" quantifiers\ninterpreted using the notions of Baire category and Lebesgue measure.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 20:55:19 GMT"}, {"version": "v2", "created": "Tue, 23 Jan 2018 01:00:18 GMT"}, {"version": "v3", "created": "Wed, 24 Jan 2018 16:53:37 GMT"}, {"version": "v4", "created": "Mon, 9 Apr 2018 11:36:07 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Mio", "Matteo", ""], ["Skrzypczak", "Micha\u0142", ""], ["Michalewski", "Henryk", ""]]}, {"id": "1702.04908", "submitter": "Ohad Kammar", "authors": "Ohad Kammar, Paul B. Levy, Sean K. Moss, Sam Staton", "title": "A monad for full ground reference cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a denotational account of dynamic allocation of potentially cyclic\nmemory cells using a monad on a functor category. We identify the collection of\nheaps as an object in a different functor category equipped with a monad for\nadding hiding/encapsulation capabilities to the heaps. We derive a monad for\nfull ground references supporting effect masking by applying a state monad\ntransformer to the encapsulation monad. To evaluate the monad, we present a\ndenotational semantics for a call-by-value calculus with full ground\nreferences, and validate associated code transformations.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 10:12:00 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 13:26:43 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Kammar", "Ohad", ""], ["Levy", "Paul B.", ""], ["Moss", "Sean K.", ""], ["Staton", "Sam", ""]]}, {"id": "1702.04912", "submitter": "Paolo Capriotti", "authors": "Paolo Capriotti", "title": "Models of Type Theory with Strict Equality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This thesis introduces the idea of two-level type theory, an extension of\nMartin-L\\\"of type theory that adds a notion of strict equality as an internal\nprimitive.\n  A type theory with a strict equality alongside the more conventional form of\nequality, the latter being of fundamental importance for the recent innovation\nof homotopy type theory (HoTT), was first proposed by Voevodsky, and is usually\nreferred to as HTS.\n  Here, we generalise and expand this idea, by developing a semantic framework\nthat gives a systematic account of type formers for two-level systems, and\nproving a conservativity result relating back to a conventional type theory\nlike HoTT.\n  Finally, we show how a two-level theory can be used to provide partial\nsolutions to open problems in HoTT. In particular, we use it to construct\nsemi-simplicial types, and lay out the foundations of an internal theory of\n$(\\infty, 1)$-categories.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 10:19:28 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Capriotti", "Paolo", ""]]}, {"id": "1702.05051", "submitter": "Ranko Lazic", "authors": "Marcin Jurdzinski and Ranko Lazic", "title": "Succinct progress measures for solving parity games", "comments": null, "journal-ref": null, "doi": "10.1109/LICS.2017.8005092", "report-no": null, "categories": "cs.DS cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent breakthrough paper by Calude et al. has given the first algorithm\nfor solving parity games in quasi-polynomial time, where previously the best\nalgorithms were mildly subexponential. We devise an alternative\nquasi-polynomial time algorithm based on progress measures, which allows us to\nreduce the space required from quasi-polynomial to nearly linear. Our key\ntechnical tools are a novel concept of ordered tree coding, and a succinct tree\ncoding result that we prove using bounded adaptive multi-counters, both of\nwhich are interesting in their own right.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 17:02:05 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 14:23:07 GMT"}, {"version": "v3", "created": "Wed, 4 Apr 2018 19:43:23 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Jurdzinski", "Marcin", ""], ["Lazic", "Ranko", ""]]}, {"id": "1702.05073", "submitter": "Norihiro Yamada", "authors": "Norihiro Yamada", "title": "A Game-Semantic Model of Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper introduces a novel notion of `(effective) computability',\ncalled viability, of strategies in game semantics in an intrinsic (i.e.,\nwithout recourse to the standard Church-Turing computability), non-inductive\nand non-axiomatic manner, and shows, as a main technical achievement, that\nviable strategies are Turing complete. Consequently, we have given a\nmathematical foundation of computation in the same sense as Turing machines but\nbeyond computation on natural numbers, e.g., higher-order computation, in a\nmore abstract fashion. As immediate corollaries, some of the well-known\ntheorems in computability theory such as the smn-theorem and the first\nrecursion theorem are generalized. Notably, our game-semantic framework\ndistinguishes `high-level' computational processes that operate directly on\nmathematical objects such as natural numbers (not on their symbolic\nrepresentations) and their `symbolic implementations' that define their\n`computability', which sheds new light on the very concept of computation. This\nwork is intended to be a stepping stone towards a new mathematical foundation\nof computation, intuitionistic logic and constructive mathematics.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 18:27:19 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 18:37:31 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 01:19:41 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Yamada", "Norihiro", ""]]}, {"id": "1702.05079", "submitter": "Dieter Spreen", "authors": "Dieter Spreen", "title": "Information Systems with Witnesses: The Function Space Construction", "comments": "40 pages. arXiv admin note: text overlap with arXiv:1610.02260", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information systems with witnesses have been introduced in [D. Spreen.\nGeneralised information systems capture L-domains. arXiv:1610.02260v2] as a\nlogic-style representation of L-domains: The category of such information\nsystems with approximable mappings as morphisms is equivalent to the category\nof L-domains with Scott continuous functions, which is known to be Cartesian\nclosed. In the present paper a direct proof of the Cartesian closure of the\ncategory of information systems with witnesses and approximable mapppings is\ngiven. As is shown, the collection of approximable mappings between two\ninformation systems with witnesses comes with a natural information system\nstructure.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 18:32:22 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 15:50:17 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Spreen", "Dieter", ""]]}, {"id": "1702.05342", "submitter": "Gabriele Puppis", "authors": "Olivier Carton (IRIF), Thomas Colcombet (CNRS, IRIF), Gabriele Puppis\n  (CNRS, IRIF)", "title": "An algebraic approach to MSO-definability on countable linear orderings", "comments": "The Journal of Symbolic Logic, Association for Symbolic Logic, In\n  press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algebraic notion of recognizability for languages of words\nindexed by countable linear orderings. We prove that this notion is effectively\nequivalent to definability in monadic second-order (MSO) logic. We also provide\nthree logical applications. First, we establish the first known collapse result\nfor the quantifier alternation of MSO logic over countable linear orderings.\nSecond, we solve an open problem posed by Gurevich and Rabinovich, concerning\nthe MSO-definability of sets of rational numbers using the reals in the\nbackground. Third, we establish the MSO-definability of the set of yields\ninduced by an MSO-definable set of trees, confirming a conjecture posed by\nBruy{\\`e}re, Carton, and S{\\'e}nizergues.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 13:58:20 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 13:22:04 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Carton", "Olivier", "", "IRIF"], ["Colcombet", "Thomas", "", "CNRS, IRIF"], ["Puppis", "Gabriele", "", "CNRS, IRIF"]]}, {"id": "1702.05472", "submitter": "Mickael Randour", "authors": "Rapha\\\"el Berthon and Mickael Randour and Jean-Fran\\c{c}ois Raskin", "title": "Threshold Constraints with Guarantees for Parity Objectives in Markov\n  Decision Processes", "comments": "Full version of ICALP 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.FL cs.GT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The beyond worst-case synthesis problem was introduced recently by Bruy\\`ere\net al. [BFRR14]: it aims at building system controllers that provide strict\nworst-case performance guarantees against an antagonistic environment while\nensuring higher expected performance against a stochastic model of the\nenvironment. Our work extends the framework of [BFRR14] and follow-up papers,\nwhich focused on quantitative objectives, by addressing the case of\n$\\omega$-regular conditions encoded as parity objectives, a natural way to\nrepresent functional requirements of systems.\n  We build strategies that satisfy a main parity objective on all plays, while\nensuring a secondary one with sufficient probability. This setting raises new\nchallenges in comparison to quantitative objectives, as one cannot easily mix\ndifferent strategies without endangering the functional properties of the\nsystem. We establish that, for all variants of this problem, deciding the\nexistence of a strategy lies in ${\\sf NP} \\cap {\\sf coNP}$, the same complexity\nclass as classical parity games. Hence, our framework provides additional\nmodeling power while staying in the same complexity class.\n  [BFRR14] V\\'eronique Bruy\\`ere, Emmanuel Filiot, Mickael Randour, and\nJean-Fran\\c{c}ois Raskin. Meet your expectations with guarantees: Beyond\nworst-case synthesis in quantitative games. In Ernst W. Mayr and Natacha\nPortier, editors, 31st International Symposium on Theoretical Aspects of\nComputer Science, STACS 2014, March 5-8, 2014, Lyon, France, volume 25 of\nLIPIcs, pages 199-213. Schloss Dagstuhl - Leibniz - Zentrum fuer Informatik,\n2014.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 18:52:11 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 09:53:04 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Berthon", "Rapha\u00ebl", ""], ["Randour", "Mickael", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "1702.05527", "submitter": "Ale\\v{s} Bizjak", "authors": "Benjamin Kiesl, Martina Seidl, Hans Tompits, Armin Biere", "title": "Local Redundancy in SAT: Generalizations of Blocked Clauses", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (October\n  24, 2018) lmcs:4915", "doi": "10.23638/LMCS-14(4:3)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clause-elimination procedures that simplify formulas in conjunctive normal\nform play an important role in modern SAT solving. Before or during the actual\nsolving process, such procedures identify and remove clauses that are\nirrelevant to the solving result. These simplifications usually rely on\nso-called redundancy properties that characterize cases in which the removal of\na clause does not affect the satisfiability status of a formula. One\nparticularly successful redundancy property is that of blocked clauses, because\nit generalizes several other redundancy properties. To find out whether a\nclause is blocked---and therefore redundant---one only needs to consider its\nresolution environment, i.e., the clauses with which it can be resolved. For\nthis reason, we say that the redundancy property of blocked clauses is local.\nIn this paper, we show that there exist local redundancy properties that are\neven more general than blocked clauses. We present a semantic notion of\nblocking and prove that it constitutes the most general local redundancy\nproperty. We furthermore introduce the syntax-based notions of set-blocking and\nsuper-blocking, and show that the latter coincides with our semantic blocking\nnotion. In addition, we show how semantic blocking can be alternatively\ncharacterized via Davis and Putnam's rule for eliminating atomic formulas.\nFinally, we perform a detailed complexity analysis and relate our novel\nredundancy properties to prominent redundancy properties from the literature.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 21:45:22 GMT"}, {"version": "v2", "created": "Wed, 27 Dec 2017 13:24:48 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 08:00:28 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Kiesl", "Benjamin", ""], ["Seidl", "Martina", ""], ["Tompits", "Hans", ""], ["Biere", "Armin", ""]]}, {"id": "1702.05578", "submitter": "Qiang Yin", "authors": "Qiang Yin, Mingzhang Huang, and Chaodong He", "title": "Two Lower Bounds for BPA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branching bisimilarity on normed Basic Process Algebra (BPA) was claimed to\nbe EXPTIME-hard in previous papers without any explicit proof. Recently it is\nreminded by Jan\\v{c}ar that the claim is not so dependable. In this paper, we\ndevelop a new complete proof for EXPTIME-hardness of branching bisimilarity on\nnormed BPA. We also prove the associate regularity problem on normed BPA is\nPSPACE-hard and in EXPTIME. This improves previous P-hard and NEXPTIME result.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 06:53:15 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Yin", "Qiang", ""], ["Huang", "Mingzhang", ""], ["He", "Chaodong", ""]]}, {"id": "1702.05589", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli, Pierre Bourhis, Louis Jachiet, Stefan Mengel", "title": "A Circuit-Based Approach to Efficient Enumeration", "comments": "45 pages, 1 figure, 36 references. Accepted at ICALP'17. This paper\n  is the full version with appendices of the article in the ICALP proceedings.\n  The main text of this full version is the same as the ICALP proceedings\n  version, except some superficial changes (to fit the proceedings version to\n  12 pages, and to obey LIPIcs-specific formatting requirements)", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2017.111", "report-no": null, "categories": "cs.DS cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of enumerating the satisfying valuations of a circuit\nwhile bounding the delay, i.e., the time needed to compute each successive\nvaluation. We focus on the class of structured d-DNNF circuits originally\nintroduced in knowledge compilation, a sub-area of artificial intelligence. We\npropose an algorithm for these circuits that enumerates valuations with linear\npreprocessing and delay linear in the Hamming weight of each valuation.\nMoreover, valuations of constant Hamming weight can be enumerated with linear\npreprocessing and constant delay.\n  Our results yield a framework for efficient enumeration that applies to all\nproblems whose solutions can be compiled to structured d-DNNFs. In particular,\nwe use it to recapture classical results in database theory, for factorized\ndatabase representations and for MSO evaluation. This gives an independent\nproof of constant-delay enumeration for MSO formulae with first-order free\nvariables on bounded-treewidth structures.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 09:46:32 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 09:03:57 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Amarilli", "Antoine", ""], ["Bourhis", "Pierre", ""], ["Jachiet", "Louis", ""], ["Mengel", "Stefan", ""]]}, {"id": "1702.05591", "submitter": "Lucas Carvalho Cordeiro", "authors": "Lennon Chaves, Iury Bessa, Lucas Cordeiro, Daniel Kroening, Eddie\n  Filho", "title": "Verifying Digital Systems with MATLAB", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A MATLAB toolbox is presented, with the goal of checking occurrences of\ndesign errors typically found in fixed-point digital systems, considering\nfinite word-length effects. In particular, the present toolbox works as a\nfront-end to a recently introduced verification tool, known as Digital-System\nVerifier, and checks overflow, limit cycle, quantization, stability, and\nminimum phase errors, in digital systems represented by transfer-function and\nstate-space equations. It provides a command-line version, with simplified\naccess to specific functions, and a graphical-user interface, which was\ndeveloped as a MATLAB application. The resulting toolbox is important for the\nverification community, since it shows the applicability of verification to\nreal-world systems.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 09:52:02 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Chaves", "Lennon", ""], ["Bessa", "Iury", ""], ["Cordeiro", "Lucas", ""], ["Kroening", "Daniel", ""], ["Filho", "Eddie", ""]]}, {"id": "1702.05752", "submitter": "K. V. Krishna", "authors": "Gayatri Panicker, K. V. Krishna and Purandar Bhaduri", "title": "Axiomatization of if-then-else over monoids of possibly non-halting\n  programs and tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to study the axiomatization of the if-then-else construct over\npossibly non-halting programs and tests, the notion of $C$-sets was introduced\nin the literature by considering the tests from an abstract $C$-algebra. This\npaper extends the notion of $C$-sets to $C$-monoids which include the\ncomposition of programs as well as composition of programs with tests. For the\nclass of $C$-monoids where the $C$-algebras are adas a canonical representation\nin terms of functional $C$-monoids is obtained.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 14:13:03 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Panicker", "Gayatri", ""], ["Krishna", "K. V.", ""], ["Bhaduri", "Purandar", ""]]}, {"id": "1702.05795", "submitter": "Ale\\v{s} Bizjak", "authors": "Simon Docherty and David Pym", "title": "Intuitionistic Layered Graph Logic: Semantics and Proof Theory", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (October\n  31, 2018) lmcs:4942", "doi": "10.23638/LMCS-14(4:11)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Models of complex systems are widely used in the physical and social\nsciences, and the concept of layering, typically building upon graph-theoretic\nstructure, is a common feature. We describe an intuitionistic substructural\nlogic called ILGL that gives an account of layering. The logic is a bunched\nsystem, combining the usual intuitionistic connectives, together with a\nnon-commutative, non-associative conjunction (used to capture layering) and its\nassociated implications. We give soundness and completeness theorems for a\nlabelled tableaux system with respect to a Kripke semantics on graphs. We then\ngive an equivalent relational semantics, itself proven equivalent to an\nalgebraic semantics via a representation theorem. We utilise this result in two\nways. First, we prove decidability of the logic by showing the finite\nembeddability property holds for the algebraic semantics. Second, we prove a\nStone-type duality theorem for the logic. By introducing the notions of ILGL\nhyperdoctrine and indexed layered frame we are able to extend this result to a\npredicate version of the logic and prove soundness and completeness theorems\nfor an extension of the layered graph semantics . We indicate the utility of\npredicate ILGL with a resource-labelled bigraph model.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 21:00:25 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 17:42:24 GMT"}, {"version": "v3", "created": "Sat, 31 Mar 2018 13:09:35 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 14:39:34 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Docherty", "Simon", ""], ["Pym", "David", ""]]}, {"id": "1702.06028", "submitter": "Andrea Cerone", "authors": "Andrea Cerone, Alexey Gotsman, Hongseok Yang", "title": "Algebraic Laws for Weak Consistency (Extended Version)", "comments": "Extended Version of the CONCUR'17 paper", "journal-ref": null, "doi": "10.4230/LIPIcs.CONCUR.2017.22", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern distributed systems often rely on so called weakly-consistent\ndatabases, which achieve scalability by sacrificing the consistency guarantee\nof distributed transaction processing. Such databases have been formalised in\ntwo different styles, one based on abstract executions and the other based on\ndependency graphs. The choice between these styles has been made according to\nintended applications: the former has been used to specify and verify the\nimplementation of these databases, and the latter to prove properties of\nprograms running on top of the databases. In this paper, we present a set of\nnovel algebraic laws (i.e. inequations) that connect these two styles of\nspecifications; the laws relate binary relations used in a specification based\non abstract executions, to those used in a specification based on dependency\ngraphs. We then show that this algebraic connection gives rise to so called\nrobustness criteria, conditions which ensures that a program running on top of\na weakly-consistent database does not exhibit anomalous behaviours due to this\nweak consistency. These criteria make it easy to reason about programs running\non top of these databases, and may become a basis for dynamic or static program\nanalyses. For a certain class of consistency models specifications, we prove a\nfull abstraction result that connects the two styles of specifications.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 15:55:20 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 00:11:58 GMT"}, {"version": "v3", "created": "Thu, 4 May 2017 18:36:07 GMT"}, {"version": "v4", "created": "Tue, 1 Aug 2017 15:47:01 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Cerone", "Andrea", ""], ["Gotsman", "Alexey", ""], ["Yang", "Hongseok", ""]]}, {"id": "1702.06092", "submitter": "Anton Salikhmetov", "authors": "Anton Salikhmetov", "title": "Parallel needed reduction for pure interaction nets", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing interaction nets without any specific strategy benefits from\nconstant time per step. On the other hand, a canonical reduction step for weak\nreduction to interface normal form is linear by depth of terms. In this paper,\nwe refine the weak interaction calculus to reveal the actual cost of its\nreduction. As a result, we obtain a notion of needed reduction that can be\nimplemented in constant time per step without allowing any free ports and\nwithout sacrificing parallelism.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 18:19:37 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Salikhmetov", "Anton", ""]]}, {"id": "1702.06259", "submitter": "Ale\\v{s} Bizjak", "authors": "Kshitij Bansal, Clark Barrett, Andrew Reynolds, Cesare Tinelli", "title": "Reasoning with Finite Sets and Cardinality Constraints in SMT", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (November\n  1, 2018) lmcs:4950", "doi": "10.23638/LMCS-14(4:12)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of deciding the satisfiability of quantifier-free\nformulas in the theory of finite sets with cardinality constraints. Sets are a\ncommon high-level data structure used in programming; thus, such a theory is\nuseful for modeling program constructs directly. More importantly, sets are a\nbasic construct of mathematics and thus natural to use when formalizing the\nproperties of computational systems. We develop a calculus describing a modular\ncombination of a procedure for reasoning about membership constraints with a\nprocedure for reasoning about cardinality constraints. Cardinality reasoning\ninvolves tracking how different sets overlap. For efficiency, we avoid\nconsidering Venn regions directly, as done in previous work. Instead, we\ndevelop a novel technique wherein potentially overlapping regions are\nconsidered incrementally as needed, using a graph to track the interaction\namong the different regions. The calculus has been designed to facilitate its\nimplementation within SMT solvers based on the DPLL($T$) architecture. Our\nexperimental results demonstrate that the new techniques are competitive with\nprevious techniques and can scale much better on certain classes of problems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 04:30:39 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 00:16:38 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 12:18:07 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Bansal", "Kshitij", ""], ["Barrett", "Clark", ""], ["Reynolds", "Andrew", ""], ["Tinelli", "Cesare", ""]]}, {"id": "1702.06370", "submitter": "Christoph Berkholz", "authors": "Christoph Berkholz, Jens Keppeler, Nicole Schweikardt", "title": "Answering Conjunctive Queries under Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of enumerating and counting answers to $k$-ary\nconjunctive queries against relational databases that may be updated by\ninserting or deleting tuples. We exhibit a new notion of q-hierarchical\nconjunctive queries and show that these can be maintained efficiently in the\nfollowing sense. During a linear time preprocessing phase, we can build a data\nstructure that enables constant delay enumeration of the query results; and\nwhen the database is updated, we can update the data structure and restart the\nenumeration phase within constant time. For the special case of self-join free\nconjunctive queries we obtain a dichotomy: if a query is not q-hierarchical,\nthen query enumeration with sublinear$^\\ast$ delay and sublinear update time\n(and arbitrary preprocessing time) is impossible.\n  For answering Boolean conjunctive queries and for the more general problem of\ncounting the number of solutions of k-ary queries we obtain complete\ndichotomies: if the query's homomorphic core is q-hierarchical, then size of\nthe the query result can be computed in linear time and maintained with\nconstant update time. Otherwise, the size of the query result cannot be\nmaintained with sublinear update time. All our lower bounds rely on the\nOMv-conjecture, a conjecture on the hardness of online matrix-vector\nmultiplication that has recently emerged in the field of fine-grained\ncomplexity to characterise the hardness of dynamic problems. The lower bound\nfor the counting problem additionally relies on the orthogonal vectors\nconjecture, which in turn is implied by the strong exponential time hypothesis.\n  $^\\ast)$ By sublinear we mean $O(n^{1-\\varepsilon})$ for some\n$\\varepsilon>0$, where $n$ is the size of the active domain of the current\ndatabase.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 13:15:27 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Berkholz", "Christoph", ""], ["Keppeler", "Jens", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "1702.06439", "submitter": "Gilles Geeraerts", "authors": "Nicolas Basset and Gilles Geeraerts and Jean-Fran\\c{c}ois Raskin and\n  Ocan Sankur", "title": "Admissibility in Concurrent Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the notion of admissibility for randomised strategies\nin concurrent games. Intuitively, an admissible strategy is one where the\nplayer plays `as well as possible', because there is no other strategy that\ndominates it, i.e., that wins (almost surely) against a super set of\nadversarial strategies. We prove that admissible strategies always exist in\nconcurrent games, and we characterise them precisely. Then, when the objectives\nof the players are omega-regular, we show how to perform assume-admissible\nsynthesis, i.e., how to compute admissible strategies that win (almost surely)\nunder the hypothesis that the other players play admissible\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 15:30:28 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Basset", "Nicolas", ""], ["Geeraerts", "Gilles", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Sankur", "Ocan", ""]]}, {"id": "1702.06620", "submitter": "Ale\\v{s} Bizjak", "authors": "Viorica Sofronie-Stokkermans", "title": "On Interpolation and Symbol Elimination in Theory Extensions", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (September\n  24, 2018) lmcs:4848", "doi": "10.23638/LMCS-14(3:23)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we study possibilities of interpolation and symbol elimination\nin extensions of a theory $\\mathcal{T}_0$ with additional function symbols\nwhose properties are axiomatised using a set of clauses. We analyze situations\nin which we can perform such tasks in a hierarchical way, relying on existing\nmechanisms for symbol elimination in $\\mathcal{T}_0$. This is for instance\npossible if the base theory allows quantifier elimination. We analyze\npossibilities of extending such methods to situations in which the base theory\ndoes not allow quantifier elimination but has a model completion which does. We\nillustrate the method on various examples.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 23:38:24 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 20:58:07 GMT"}, {"version": "v3", "created": "Fri, 21 Sep 2018 14:21:30 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Sofronie-Stokkermans", "Viorica", ""]]}, {"id": "1702.06704", "submitter": "Hern\\'an Ponce-de-Le\\'on", "authors": "Hern\\'an Ponce-de-Le\\'on, Florian Furbach, Keijo Heljanko, Roland\n  Meyer", "title": "Portability Analysis for Axiomatic Memory Models. PORTHOS: One Tool for\n  all Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Porthos, the first tool that discovers porting bugs in\nperformance-critical code. Porthos takes as input a program and the memory\nmodels of the source architecture for which the program has been developed and\nthe target model to which it is ported. If the code is not portable, Porthos\nfinds a bug in the form of an unexpected execution - an execution that is\nconsistent with the target but inconsistent with the source memory model.\nTechnically, Porthos implements a bounded model checking method that reduces\nthe portability analysis problem to satisfiability modulo theories (SMT). There\nare two main problems in the reduction that we present novel and efficient\nsolutions for. First, the formulation of the portability problem contains a\nquantifier alternation (consistent + inconsistent). We introduce a formula that\nencodes both in a single existential query. Second, the supported memory models\n(e.g., Power) contain recursive definitions. We compute the required least\nfixed point semantics for recursion (a problem that was left open in [47])\nefficiently in SMT. Finally we present the first experimental analysis of\nportability from TSO to Power.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 08:34:54 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 15:33:39 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Ponce-de-Le\u00f3n", "Hern\u00e1n", ""], ["Furbach", "Florian", ""], ["Heljanko", "Keijo", ""], ["Meyer", "Roland", ""]]}, {"id": "1702.07214", "submitter": "J\\\"urgen Koslowski", "authors": "Furio Honsell, Luigi Liquori, Petar Maksimovic, Ivan Scagnetto", "title": "$\\mathsf{LLF}_{\\cal P}$: a logical framework for modeling external\n  evidence, side conditions, and proof irrelevance using monads", "comments": "Accepted for publication in LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (July 6,\n  2017) lmcs:3771", "doi": "10.23638/LMCS-13(3:2)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the constructive dependent type theory of the Logical Framework\n$\\mathsf{LF}$ with monadic, dependent type constructors indexed with predicates\nover judgements, called Locks. These monads capture various possible proof\nattitudes in establishing the judgment of the object logic encoded by an\n$\\mathsf{LF}$ type. Standard examples are factoring-out the verification of a\nconstraint or delegating it to an external oracle, or supplying some\nnon-apodictic epistemic evidence, or simply discarding the proof witness of a\nprecondition deeming it irrelevant. This new framework, called Lax Logical\nFramework, $\\mathsf{LLF}_{\\cal P}$, is a conservative extension of\n$\\mathsf{LF}$, and hence it is the appropriate metalanguage for dealing\nformally with side-conditions in rules or external evidence in logical systems.\n$\\mathsf{LLF}_{\\cal P}$ arises once the monadic nature of the lock\ntype-constructor, ${\\cal L}^{\\cal P}_{M,\\sigma}[\\cdot]$, introduced by the\nauthors in a series of papers, together with Marina Lenisa, is fully exploited.\nThe nature of the lock monads permits to utilize the very Lock destructor,\n${\\cal U}^{\\cal P}_{M,\\sigma}[\\cdot]$, in place of Moggi's monadic $let_T$,\nthus simplifying the equational theory. The rules for ${\\cal U}^{\\cal\nP}_{M,\\sigma}[\\cdot]$ permit also the removal of the monad once the constraint\nis satisfied. We derive the meta-theory of $\\mathsf{LLF}_{\\cal P}$ by a novel\nindirect method based on the encoding of $\\mathsf{LLF}_{\\cal P}$ in\n$\\mathsf{LF}$. We discuss encodings in $\\mathsf{LLF}_{\\cal P}$ of call-by-value\n$\\lambda$-calculi, Hoare's Logic, and Fitch-Prawitz Naive Set Theory.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 13:56:19 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 18:58:55 GMT"}, {"version": "v3", "created": "Wed, 5 Jul 2017 09:35:43 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Honsell", "Furio", ""], ["Liquori", "Luigi", ""], ["Maksimovic", "Petar", ""], ["Scagnetto", "Ivan", ""]]}, {"id": "1702.07375", "submitter": "Alex Horn", "authors": "Alex Horn, Ali Kheradmand, Mukul R. Prasad", "title": "Delta-net: Real-time Network Verification Using Atoms", "comments": "NSDI'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time network verification promises to automatically detect violations of\nnetwork-wide reachability invariants on the data plane. To be useful in\npractice, these violations need to be detected in the order of milliseconds,\nwithout raising false alarms. To date, most real-time data plane checkers\naddress this problem by exploiting at least one of the following two\nobservations: (i) only small parts of the network tend to be affected by\ntypical changes to the data plane, and (ii) many different packets tend to\nshare the same forwarding behaviour in the entire network. This paper shows how\nto effectively exploit a third characteristic of the problem, namely:\nsimilarity among forwarding behaviour of packets through parts of the network,\nrather than its entirety. We propose the first provably amortized quasi-linear\nalgorithm to do so. We implement our algorithm in a new real-time data plane\nchecker, Delta-net. Our experiments with SDN-IP, a globally deployed ONOS\nsoftware-defined networking application, and several hundred million IP prefix\nrules generated using topologies and BGP updates from real-world deployed\nnetworks, show that Delta-net checks a rule insertion or removal in\napproximately 40 microseconds on average, a more than 10X improvement over the\nstate-of-the-art. We also show that Delta-net eliminates an inherent bottleneck\nin the state-of-the-art that restricts its use in answering Datalog-style \"what\nif\" queries.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 19:57:13 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Horn", "Alex", ""], ["Kheradmand", "Ali", ""], ["Prasad", "Mukul R.", ""]]}, {"id": "1702.07461", "submitter": "Benjamin Susman", "authors": "Yuliya Lierler and Benjamin Susman", "title": "On Relation between Constraint Answer Set Programming and Satisfiability\n  Modulo Theories", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint answer set programming is a promising research direction that\nintegrates answer set programming with constraint processing. It is often\ninformally related to the field of satisfiability modulo theories. Yet, the\nexact formal link is obscured as the terminology and concepts used in these two\nresearch areas differ. In this paper, we connect these two research areas by\nuncovering the precise formal relation between them. We believe that this work\nwill booster the cross-fertilization of the theoretical foundations and the\nexisting solving methods in both areas. As a step in this direction we provide\na translation from constraint answer set programs with integer linear\nconstraints to satisfiability modulo linear integer arithmetic that paves the\nway to utilizing modern satisfiability modulo theories solvers for computing\nanswer sets of constraint answer set programs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 04:15:03 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Lierler", "Yuliya", ""], ["Susman", "Benjamin", ""]]}, {"id": "1702.07478", "submitter": "Igor Tarasyuk", "authors": "Igor V. Tarasyuk, Hermenegilda Maci\\`a, Valent\\'in Valero", "title": "Stochastic equivalence for performance analysis of concurrent systems in\n  dtsiPBC", "comments": "Prepared for submission to Discrete Mathematics and Theoretical\n  Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension with immediate multiactions of discrete time\nstochastic Petri Box Calculus (dtsPBC), presented by I.V. Tarasyuk. The\nresulting algebra dtsiPBC is a discrete time analogue of stochastic Petri Box\nCalculus (sPBC) with immediate multiactions, designed by H. Maci\\`a, V. Valero\net al. within a continuous time domain. The step operational semantics is\nconstructed via labeled probabilistic transition systems. The denotational\nsemantics is based on labeled discrete time stochastic Petri nets with\nimmediate transitions. To evaluate performance, the corresponding semi-Markov\nchains are analyzed. We define step stochastic bisimulation equivalence of\nexpressions that is applied to reduce their transition systems and underlying\nsemi-Markov chains while preserving the functionality and performance\ncharacteristics. We explain how this equivalence can be used to simplify\nperformance analysis of the algebraic processes. In a case study, a method of\nmodeling, performance evaluation and behaviour reduction for concurrent systems\nis outlined and applied to the shared memory system.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 07:07:24 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Tarasyuk", "Igor V.", ""], ["Maci\u00e0", "Hermenegilda", ""], ["Valero", "Valent\u00edn", ""]]}, {"id": "1702.07484", "submitter": "Uli Fahrenberg", "authors": "Uli Fahrenberg, Axel Legay", "title": "Featured Weighted Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A featured transition system is a transition system in which the transitions\nare annotated with feature expressions: Boolean expressions on a finite number\nof given features. Depending on its feature expression, each individual\ntransition can be enabled when some features are present, and disabled for\nother sets of features. The behavior of a featured transition system hence\ndepends on a given set of features. There are algorithms for featured\ntransition systems which can check their properties for all sets of features at\nonce, for example for LTL or CTL properties.\n  Here we introduce a model of featured weighted automata which combines\nfeatured transition systems and (semiring-) weighted automata. We show that\nmethods and techniques from weighted automata extend to featured weighted\nautomata and devise algorithms to compute quantitative properties of featured\nweighted automata for all sets of features at once. We show applications to\nminimum reachability and to energy properties.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 07:40:36 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 06:30:58 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Fahrenberg", "Uli", ""], ["Legay", "Axel", ""]]}, {"id": "1702.07776", "submitter": "Dimitris Tsementzis", "authors": "Dimitris Tsementzis", "title": "A Higher Structure Identity Principle", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a Structure Identity Principle for theories defined on types of\n$h$-level 3 by defining a general notion of saturation for a large class of\nstructures definable in the Univalent Foundations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 21:42:45 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Tsementzis", "Dimitris", ""]]}, {"id": "1702.07838", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "An Algebraic Treatment of Recursion", "comments": "Dedicated to Jan Bergstra, at the occasion of his 65th birthday and\n  retirement", "journal-ref": "In: Liber Amicorum for Jan A. Bergstra (I. Bethke and B. Bredeweg\n  and A. Ponse, eds.), Informatics Institute, University of Amsterdam, 2016,\n  pp. 58-59", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I review the three principal methods to assign meaning to recursion in\nprocess algebra: the denotational, the operational and the algebraic approach,\nand I extend the latter to unguarded recursion.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 06:53:53 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "1702.07844", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek", "title": "A Branching Time Model of CSP", "comments": "Dedicated to Bill Roscoe, on the occasion of his 60th birthday", "journal-ref": "In: Concurrency, Security, and Puzzles; Essays Dedicated to Andrew\n  William Roscoe on the Occasion of His 60th Birthday (Th. Gibson-Robinson and\n  Ph.J. Hopcroft and R. Lazic, eds.), LNCS 10160, Springer, 2017, pp. 272-293", "doi": "10.1007/978-3-319-51046-0_14", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I present a branching time model of CSP that is finer than all other models\nof CSP proposed thus far. It is obtained by taking a semantic equivalence from\nthe linear time - branching time spectrum, namely divergence-preserving coupled\nsimilarity, and showing that it is a congruence for the operators of CSP. This\nequivalence belongs to the bisimulation family of semantic equivalences, in the\nsense that on transition systems without internal actions it coincides with\nstrong bisimilarity. Nevertheless, enough of the equational laws of CSP remain\nto obtain a complete axiomatisation for closed, recursion-free terms.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 07:15:45 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["van Glabbeek", "Rob", ""]]}, {"id": "1702.07847", "submitter": "Lucas Carvalho Cordeiro", "authors": "Lucas Cordeiro", "title": "Automated Verification and Synthesis of Embedded Systems using Machine\n  Learning", "comments": "This paper is a revised version of \"SMT-Based Context-Bounded Model\n  Checking for Embedded Systems: Challenges and Future Trends. ACM SIGSOFT\n  Software Engineering Notes 41(3): 1-6 (2016).\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dependency on the correct functioning of embedded systems is rapidly\ngrowing, mainly due to their wide range of applications, such as micro-grids,\nautomotive device control, health care, surveillance, mobile devices, and\nconsumer electronics. Their structures are becoming more and more complex and\nnow require multi-core processors with scalable shared memory, in order to meet\nincreasing computational power demands. As a consequence, reliability of\nembedded (distributed) software becomes a key issue during system development,\nwhich must be carefully addressed and assured. The present research discusses\nchallenges, problems, and recent advances to ensure correctness and timeliness\nregarding embedded systems. Reliability issues, in the development of\nmicro-grids and cyber-physical systems, are then considered, as a prominent\nverification and synthesis application. In particular, machine learning\ntechniques emerge as one of the main approaches to learn reliable\nimplementations of embedded software for achieving a correct-by-construction\ndesign.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 07:29:24 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 16:00:53 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Cordeiro", "Lucas", ""]]}, {"id": "1702.07889", "submitter": "Michael Maher", "authors": "Michael J. Maher", "title": "Contractibility for Open Global Constraints", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 17(4), 365--407, 2017", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open forms of global constraints allow the addition of new variables to an\nargument during the execution of a constraint program. Such forms are needed\nfor difficult constraint programming problems where problem construction and\nproblem solving are interleaved, and fit naturally within constraint logic\nprogramming. However, in general, filtering that is sound for a global\nconstraint can be unsound when the constraint is open. This paper provides a\nsimple characterization, called contractibility, of the constraints where\nfiltering remains sound when the constraint is open. With this characterization\nwe can easily determine whether a constraint has this property or not. In the\nlatter case, we can use it to derive a contractible approximation to the\nconstraint. We demonstrate this work on both hard and soft constraints. In the\nprocess, we formulate two general classes of soft constraints.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 13:12:26 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Maher", "Michael J.", ""]]}, {"id": "1702.08193", "submitter": "Bj\\\"orn Lellmann", "authors": "Bj\\\"orn Lellmann and Elaine Pimentel", "title": "Modularisation of Sequent Calculi for Normal and Non-normal Modalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the connections between (linear) nested sequent\ncalculi and ordinary sequent calculi for normal and non-normal modal logics. By\nproposing local versions to ordinary sequent rules we obtain linear nested\nsequent calculi for a number of logics, including to our knowledge the first\nnested sequent calculi for a large class of simply dependent multimodal logics,\nand for many standard non-normal modal logics. The resulting systems are\nmodular and have separate left and right introduction rules for the modalities,\nwhich makes them amenable to specification as bipole clauses. While this\ngranulation of the sequent rules introduces more choices for proof search, we\nshow how linear nested sequent calculi can be restricted to blocked\nderivations, which directly correspond to ordinary sequent derivations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 08:57:36 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 12:30:10 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Lellmann", "Bj\u00f6rn", ""], ["Pimentel", "Elaine", ""]]}, {"id": "1702.08256", "submitter": "Florian Lonsing", "authors": "Florian Lonsing and Uwe Egly", "title": "DepQBF 6.0: A Search-Based QBF Solver Beyond Traditional QCDCL", "comments": "12 pages + appendix; to appear in the proceedings of CADE-26, LNCS,\n  Springer, 2017", "journal-ref": null, "doi": "10.1007/978-3-319-63046-5_23", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the latest major release version 6.0 of the quantified Boolean\nformula (QBF) solver DepQBF, which is based on QCDCL. QCDCL is an extension of\nthe conflict-driven clause learning (CDCL) paradigm implemented in state of the\nart propositional satisfiability (SAT) solvers. The Q-resolution calculus\n(QRES) is a QBF proof system which underlies QCDCL. QCDCL solvers can produce\nQRES proofs of QBFs in prenex conjunctive normal form (PCNF) as a byproduct of\nthe solving process. In contrast to traditional QCDCL based on QRES, DepQBF 6.0\nimplements a variant of QCDCL which is based on a generalization of QRES. This\ngeneralization is due to a set of additional axioms and leaves the original\nQ-resolution rules unchanged. The generalization of QRES enables QCDCL to\npotentially produce exponentially shorter proofs than the traditional variant.\nWe present an overview of the features implemented in DepQBF and report on\nexperimental results which demonstrate the effectiveness of generalized QRES in\nQCDCL.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 12:42:33 GMT"}, {"version": "v2", "created": "Tue, 30 May 2017 08:54:32 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Lonsing", "Florian", ""], ["Egly", "Uwe", ""]]}, {"id": "1702.08301", "submitter": "Julien Bringer", "authors": "Julien Bringer and Herve Chabanne and Daniel Le Metayer and Roch\n  Lescuyer", "title": "Biometric Systems Private by Design: Reasoning about privacy properties\n  of biometric system architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to show the applicability, and how, of privacy by design\napproach to biometric systems and the benefit of using formal methods to this\nend. Starting from a general framework that has been introduced at STM in 2014,\nthat enables to define privacy architectures and to formally reason about their\nproperties, we explain how it can be adapted to biometrics. The choice of\nparticular techniques and the role of the components (central server, secure\nmodule, biometric terminal, smart card, etc.) in the architecture have a strong\nimpact on the privacy guarantees provided by a biometric system. In the\nliterature, some architectures have already been analysed in some way. However,\nthe existing proposals were made on a case by case basis, which makes it\ndifficult to compare them and to provide a rationale for the choice of specific\noptions. In this paper, we describe, on different architectures with various\nlevels of protection, how a general framework for the definition of privacy\narchitectures can be used to specify the design options of a biometric systems\nand to reason about them in a formal way.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 14:29:10 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 22:21:22 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Bringer", "Julien", ""], ["Chabanne", "Herve", ""], ["Metayer", "Daniel Le", ""], ["Lescuyer", "Roch", ""]]}, {"id": "1702.08306", "submitter": "J\\\"urgen Koslowski", "authors": "Giorgio Bacci, Giovanni Bacci, Kim G. Larsen, Radu Mardare", "title": "On-the-Fly Computation of Bisimilarity Distances", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (June 30,\n  2017) lmcs:3753", "doi": "10.23638/LMCS-13(2:13)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distance between continuous-time Markov chains (CTMCs) and study\nthe problem of computing it by comparing three different algorithmic\nmethodologies: iterative, linear program, and on-the-fly. In a work presented\nat FoSSaCS'12, Chen et al. characterized the bisimilarity distance of\nDesharnais et al. between discrete-time Markov chains as an optimal solution of\na linear program that can be solved by using the ellipsoid method. Inspired by\ntheir result, we propose a novel linear program characterization to compute the\ndistance in the continuous-time setting. Differently from previous proposals,\nours has a number of constraints that is bounded by a polynomial in the size of\nthe CTMC. This, in particular, proves that the distance we propose can be\ncomputed in polynomial time. Despite its theoretical importance, the proposed\nlinear program characterization turns out to be inefficient in practice.\nNevertheless, driven by the encouraging results of our previous work presented\nat TACAS'13, we propose an efficient on-the-fly algorithm, which, unlike the\nother mentioned solutions, computes the distances between two given states\navoiding an exhaustive exploration of the state space. This technique works by\nsuccessively refining over-approximations of the target distances using a\ngreedy strategy, which ensures that the state space is further explored only\nwhen the current approximations are improved. Tests performed on a consistent\nset of (pseudo)randomly generated CTMCs show that our algorithm improves, on\naverage, the efficiency of the corresponding iterative and linear program\nmethods with orders of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 14:48:44 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 12:09:49 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Bacci", "Giorgio", ""], ["Bacci", "Giovanni", ""], ["Larsen", "Kim G.", ""], ["Mardare", "Radu", ""]]}, {"id": "1702.08328", "submitter": "Thorsten Wissmann", "authors": "Olivier Bournez and Amaury Pouly", "title": "A Universal Ordinary Differential Equation", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (February\n  28, 2020) lmcs:6168", "doi": "10.23638/LMCS-16(1:28)2020", "report-no": null, "categories": "math.CA cs.CC cs.LO cs.SY math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An astonishing fact was established by Lee A. Rubel (1981): there exists a\nfixed non-trivial fourth-order polynomial differential algebraic equation (DAE)\nsuch that for any positive continuous function $\\varphi$ on the reals, and for\nany positive continuous function $\\epsilon(t)$, it has a $\\mathcal{C}^\\infty$\nsolution with $| y(t) - \\varphi(t) | < \\epsilon(t)$ for all $t$. Lee A. Rubel\nprovided an explicit example of such a polynomial DAE. Other examples of\nuniversal DAE have later been proposed by other authors. However, Rubel's DAE\n\\emph{never} has a unique solution, even with a finite number of conditions of\nthe form $y^{(k_i)}(a_i)=b_i$.\n  The question whether one can require the solution that approximates $\\varphi$\nto be the unique solution for a given initial data is a well known open problem\n[Rubel 1981, page 2], [Boshernitzan 1986, Conjecture 6.2]. In this article, we\nsolve it and show that Rubel's statement holds for polynomial ordinary\ndifferential equations (ODEs), and since polynomial ODEs have a unique solution\ngiven an initial data, this positively answers Rubel's open problem. More\nprecisely, we show that there exists a \\textbf{fixed} polynomial ODE such that\nfor any $\\varphi$ and $\\epsilon(t)$ there exists some initial condition that\nyields a solution that is $\\epsilon$-close to $\\varphi$ at all times.\n  In particular, the solution to the ODE is necessarily analytic, and we show\nthat the initial condition is computable from the target function and error\nfunction.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 17:02:15 GMT"}, {"version": "v2", "created": "Sat, 29 Apr 2017 07:08:14 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 21:17:58 GMT"}, {"version": "v4", "created": "Thu, 2 May 2019 20:50:04 GMT"}, {"version": "v5", "created": "Tue, 3 Dec 2019 16:54:47 GMT"}, {"version": "v6", "created": "Thu, 27 Feb 2020 14:14:16 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Bournez", "Olivier", ""], ["Pouly", "Amaury", ""]]}, {"id": "1702.08405", "submitter": "Raine Ronnholm", "authors": "Valentin Goranko, Antti Kuusisto, Raine R\\\"onnholm", "title": "Game-Theoretic Semantics for ATL+ with Applications to Model Checking", "comments": "Extended version of a paper in AAMAS2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop game-theoretic semantics (GTS) for the fragment ATL+ of the full\nAlternating-time Temporal Logic ATL*, essentially extending a recently\nintroduced GTS for ATL. We first show that the new game-theoretic semantics is\nequivalent to the standard semantics of ATL+ (based on perfect recall\nstrategies). We then provide an analysis, based on the new semantics, of the\nmemory and time resources needed for model checking ATL+. Based on that, we\nestablish that strategies that use only a very limited amount of memory suffice\nfor ATL+. Furthermore, using the GTS we provide a new algorithm for model\nchecking of ATL+ and identify a natural hierarchy of tractable fragments of\nATL+ that extend ATL.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 18:07:12 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 06:28:32 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Goranko", "Valentin", ""], ["Kuusisto", "Antti", ""], ["R\u00f6nnholm", "Raine", ""]]}, {"id": "1702.08581", "submitter": "J. Raymundo Marcial-Romero", "authors": "M. A. L\\'opez, J. R. Marcial, G. De Ita, H. A. Montes-Venegas and R.\n  Alejo", "title": "A Linear Time Algorithm for Solving #2SAT on Cactus Formulas", "comments": "5 pages, in Spanish, submitted to IEEE Transactions on Latin America", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An O(n+m)-time algorithm is presented for counting the number of models of a\ntwo Conjunctive Normal Form Formula F that represents a Cactus graph, where n\nis the number of variables and m is the number of clauses of F. Although, it\nwas already known that this class of formulas could be computed in polynomial\ntime, we compare our proposal algorithm with two state of the art\nimplementations for the same problem, sharpSAT and countAntom. The results of\nthe comparison show that our algorithm outperforms both implementations, and it\ncan be considered as a base case for general counting of two Conjunctive Normal\nForm Formulas.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 23:44:11 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["L\u00f3pez", "M. A.", ""], ["Marcial", "J. R.", ""], ["De Ita", "G.", ""], ["Montes-Venegas", "H. A.", ""], ["Alejo", "R.", ""]]}, {"id": "1702.08660", "submitter": "Danny Nguyen", "authors": "Danny Nguyen and Igor Pak", "title": "Complexity of short generating functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give complexity analysis of the class of short generating functions (GF).\nAssuming $\\#P \\not\\subseteq FP/poly$, we show that this class is not closed\nunder taking many intersections, unions or projections of GFs, in the sense\nthat these operations can increase the bitlength of coefficients of GFs by a\nsuper-polynomial factor. We also prove that truncated theta functions are hard\nin this class.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 06:18:10 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 02:19:58 GMT"}, {"version": "v3", "created": "Tue, 2 May 2017 04:16:33 GMT"}, {"version": "v4", "created": "Wed, 11 Oct 2017 18:11:07 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Nguyen", "Danny", ""], ["Pak", "Igor", ""]]}, {"id": "1702.08764", "submitter": "Christoph Berkholz", "authors": "Christoph Berkholz, Jens Keppeler, Nicole Schweikardt", "title": "Answering FO+MOD queries under updates on bounded degree databases", "comments": "This is the full version of a paper with the same title that will be\n  published in the Proceedings of the 20th International Conference on Database\n  Theory (ICDT 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the query evaluation problem for fixed queries over fully\ndynamic databases, where tuples can be inserted or deleted. The task is to\ndesign a dynamic algorithm that immediately reports the new result of a fixed\nquery after every database update. We consider queries in first-order logic\n(FO) and its extension with modulo-counting quantifiers (FO+MOD), and show that\nthey can be efficiently evaluated under updates, provided that the dynamic\ndatabase does not exceed a certain degree bound.\n  In particular, we construct a data structure that allows to answer a Boolean\nFO+MOD query and to compute the size of the result of a non-Boolean query\nwithin constant time after every database update. Furthermore, after every\nupdate we are able to immediately enumerate the new query result with constant\ndelay between the output tuples. The time needed to build the data structure is\nlinear in the size of the database. Our results extend earlier work on the\nevaluation of first-order queries on static databases of bounded degree and\nrely on an effective Hanf normal form for FO+MOD recently obtained by Heimberg,\nKuske, and Schweikardt (LICS 2016).\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 12:46:03 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Berkholz", "Christoph", ""], ["Keppeler", "Jens", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "1702.08841", "submitter": "Luca Reggio", "authors": "Mai Gehrke, Daniela Petrisan, Luca Reggio", "title": "Quantifiers on languages and codensity monads", "comments": "30 pages. Presentation improved and details of several proofs added.\n  The main results are unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL math.CT math.GN math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to the techniques of topo-algebraic recognition for\nlanguages beyond the regular setting as they relate to logic on words. In\nparticular, we provide a general construction on recognisers corresponding to\nadding one layer of various kinds of quantifiers and prove a corresponding\nReutenauer-type theorem. Our main tools are codensity monads and duality\ntheory. Our construction hinges on a measure-theoretic characterisation of the\nprofinite monad of the free S-semimodule monad for finite and commutative\nsemirings S, which generalises our earlier insight that the Vietoris monad on\nBoolean spaces is the codensity monad of the finite powerset functor.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 16:22:56 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 12:52:36 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 18:02:25 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Gehrke", "Mai", ""], ["Petrisan", "Daniela", ""], ["Reggio", "Luca", ""]]}]