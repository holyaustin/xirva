[{"id": "1712.00246", "submitter": "Felix Klein", "authors": "Bernd Finkbeiner, Felix Klein, Ruzica Piskac, Mark Santolucito", "title": "Temporal Stream Logic: Synthesis beyond the Bools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive systems that operate in environments with complex data, such as\nmobile apps or embedded controllers with many sensors, are difficult to\nsynthesize. Synthesis tools usually fail for such systems because the state\nspace resulting from the discretization of the data is too large. We introduce\nTSL, a new temporal logic that separates control and data. We provide a\nCEGAR-based synthesis approach for the construction of implementations that are\nguaranteed to satisfy a TSL specification for all possible instantiations of\nthe data processing functions. TSL provides an attractive trade-off for\nsynthesis. On the one hand, synthesis from TSL, unlike synthesis from standard\ntemporal logics, is undecidable in general. On the other hand, however,\nsynthesis from TSL is scalable, because it is independent of the complexity of\nthe handled data. Among other benchmarks, we have successfully synthesized a\nmusic player Android app and a controller for an autonomous vehicle in the Open\nRace Car Simulator (TORCS.)\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 09:21:17 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 14:32:14 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Klein", "Felix", ""], ["Piskac", "Ruzica", ""], ["Santolucito", "Mark", ""]]}, {"id": "1712.00275", "submitter": "Jianlin Li", "authors": "Hongfei Fu, Yi Li, Jianlin Li, Lijun Zhang", "title": "Verifying Probabilistic Timed Automata Against Omega-Regular Dense-Time\n  Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic timed automata (PTAs) are timed automata (TAs) extended with\ndiscrete probability distributions.They serve as a mathematical model for a\nwide range of applications that involve both stochastic and timed behaviours.\nIn this work, we consider the problem of model-checking linear\n\\emph{dense-time} properties over {PTAs}. In particular, we study linear\ndense-time properties that can be encoded by TAs with infinite acceptance\ncriterion.First, we show that the problem of model-checking PTAs against\ndeterministic-TA specifications can be solved through a product construction.\nBased on the product construction, we prove that the computational complexity\nof the problem with deterministic-TA specifications is EXPTIME-complete. Then\nwe show that when relaxed to general (nondeterministic) TAs, the model-checking\nproblem becomes undecidable.Our results substantially extend state of the art\nwith both the dense-time feature and the nondeterminism in TAs.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 11:18:04 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 09:19:16 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Fu", "Hongfei", ""], ["Li", "Yi", ""], ["Li", "Jianlin", ""], ["Zhang", "Lijun", ""]]}, {"id": "1712.00570", "submitter": "Daisuke Ishii", "authors": "Daisuke Ishii and Alexandre Goldsztejn", "title": "HySIA: Tool for Simulating and Monitoring Hybrid Automata Based on\n  Interval Analysis", "comments": "Appeared in RV'17; the final publication is available at Springer", "journal-ref": null, "doi": "10.1007/978-3-319-67531-2_23", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HySIA: a reliable runtime verification tool for nonlinear hybrid\nautomata (HA) and signal temporal logic (STL) properties. HySIA simulates an HA\nwith interval analysis techniques so that a trajectory is enclosed sharply\nwithin a set of intervals. Then, HySIA computes whether the simulated\ntrajectory satisfies a given STL property; the computation is performed again\nwith interval analysis to achieve reliability. Simulation and verification\nusing HySIA are demonstrated through several example HA and STL formulas.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 08:32:26 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Ishii", "Daisuke", ""], ["Goldsztejn", "Alexandre", ""]]}, {"id": "1712.00810", "submitter": "Ioannis Kokkinis", "authors": "Ioannis Kokkinis", "title": "The Complexity of Satisfiability in Non-Iterated and Iterated\n  Probabilistic Logics", "comments": null, "journal-ref": "Annals of Mathematics and Artificial Intelligence, August 2018,\n  Volume 83, Issue 3-4, pp 351-382", "doi": "10.1007/s10472-018-9593-y", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let L be some extension of classical propositional logic. The non-iterated\nprobabilistic logic over L, is the logic PL that is defined by adding\nnon-nested probabilistic operators in the language of L. For example in PL we\ncan express a statement like \"the probability of truthfulness of A is at 0.3\"\nwhere A is a formula of L. The iterated probabilistic logic over L is the logic\nPPL, where the probabilistic operators may be iterated (nested). For example,\nin PPL we can express a statement like \"this coin is counterfeit with\nprobability 0.6\". In this paper we investigate the influence of probabilistic\noperators in the complexity of satisfiability in PL and PPL. We obtain\ncomplexity bounds, for the aforementioned satisfiability problem, which are\nparameterized in the complexity of satisfiability of conjunctions of positive\nand negative formulas that have neither a probabilistic nor a classical\noperator as a top-connective. As an application of our results we obtain tight\ncomplexity bounds for the satisfiability problem in PL and PPL when L is\nclassical propositional logic or justification logic.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 18:34:24 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 08:05:28 GMT"}, {"version": "v3", "created": "Sun, 10 Feb 2019 12:00:01 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kokkinis", "Ioannis", ""]]}, {"id": "1712.00840", "submitter": "Mehul Bhatt", "authors": "Jakob Suchan and Mehul Bhatt and Przemys{\\l}aw Wa{\\l}\\k{e}ga and Carl\n  Schultz", "title": "Visual Explanation by High-Level Abduction: On Answer-Set Programming\n  Driven Reasoning about Moving Objects", "comments": "Preprint of final publication published as part of AAAI 2018: J.\n  Suchan., M. Bhatt, Wa{\\l}\\k{e}ga, P., Schultz, C. (2018). Visual Explanation\n  by High-Level Abduction: On Answer-Set Programming Driven Reasoning about\n  Moving Objects. In AAAI 2018: Proceedings of the Thirty-Second AAAI\n  Conference on Artificial Intelligence, February 2-7, 2018, New Orleans, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid architecture for systematically computing robust visual\nexplanation(s) encompassing hypothesis formation, belief revision, and default\nreasoning with video data. The architecture consists of two tightly integrated\nsynergistic components: (1) (functional) answer set programming based abductive\nreasoning with space-time tracklets as native entities; and (2) a visual\nprocessing pipeline for detection based object tracking and motion analysis.\n  We present the formal framework, its general implementation as a\n(declarative) method in answer set programming, and an example application and\nevaluation based on two diverse video datasets: the MOTChallenge benchmark\ndeveloped by the vision community, and a recently developed Movie Dataset.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 21:17:07 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Suchan", "Jakob", ""], ["Bhatt", "Mehul", ""], ["Wa\u0142\u0119ga", "Przemys\u0142aw", ""], ["Schultz", "Carl", ""]]}, {"id": "1712.00898", "submitter": "EPTCS", "authors": "Catherine Dubois, Bruno Woltzenlogel Paleo", "title": "Proceedings of the Fifth Workshop on Proof eXchange for Theorem Proving", "comments": null, "journal-ref": "EPTCS 262, 2017", "doi": "10.4204/EPTCS.262", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume of EPTCS contains the proceedings of the Fifth Workshop on Proof\nExchange for Theorem Proving (PxTP 2017), held on September 23-24, 2017 as part\nof the Tableaux, FroCoS and ITP conferences in Brasilia, Brazil. The PxTP\nworkshop series brings together researchers working on various aspects of\ncommunication, integration, and cooperation between reasoning systems and\nformalisms, with a special focus on proofs. The progress in computer-aided\nreasoning, both automated and interactive, during the past decades, made it\npossible to build deduction tools that are increasingly more applicable to a\nwider range of problems and are able to tackle larger problems progressively\nfaster. In recent years, cooperation between such tools in larger systems has\ndemonstrated the potential to reduce the amount of manual intervention.\nCooperation between reasoning systems relies on availability of theoretical\nformalisms and practical tools to exchange problems, proofs, and models. The\nPxTP workshop series strives to encourage such cooperation by inviting\ncontributions on all aspects of cooperation between reasoning tools, whether\nautomatic or interactive.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 04:24:11 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Dubois", "Catherine", ""], ["Paleo", "Bruno Woltzenlogel", ""]]}, {"id": "1712.01001", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "Specifying and Computing Causes for Query Answers in Databases via\n  Database Repairs and Repair Programs", "comments": "To appear in \"Knowledge and Information Systems\" journal. This is the\n  final version, and a much revised, corrected and extended version of:\n  Bertossi, L. \"Characterizing and Computing Causes for Query Answers in\n  Databases from Database Repairs and Repair Programs\". Proc. FoIKs, 2018,\n  Springer LNCS 10833, pp. 55-76", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A correspondence between database tuples as causes for query answers in\ndatabases and tuple-based repairs of inconsistent databases with respect to\ndenial constraints has already been established. In this work, answer-set\nprograms that specify repairs of databases are used as a basis for solving\ncomputational and reasoning problems about causes. Here, causes are also\nintroduced at the attribute level by appealing to a both null-based and\nattribute-based repair semantics. The corresponding repair programs are\npresented, and they are used as a basis for computation and reasoning about\nattribute-level causes. They are extended to deal with the case of causality\nunder integrity constraints.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 11:00:38 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 00:16:47 GMT"}, {"version": "v3", "created": "Wed, 4 Apr 2018 21:38:17 GMT"}, {"version": "v4", "created": "Fri, 4 Jan 2019 16:12:27 GMT"}, {"version": "v5", "created": "Sat, 2 Mar 2019 22:07:45 GMT"}, {"version": "v6", "created": "Fri, 24 Jul 2020 22:50:14 GMT"}, {"version": "v7", "created": "Mon, 28 Sep 2020 19:26:52 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "1712.01014", "submitter": "Francesco Dagnino", "authors": "Francesco Dagnino", "title": "Generalizing inference systems by coaxioms", "comments": "Master Thesis supervised by Davide Ancona and Elena Zucca, University\n  of Genova, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After surveying classical results, we introduce a generalized notion of\ninference system to support structural recursion on non-well-founded data\ntypes. Besides axioms and inference rules with the usual meaning, a generalized\ninference system allows coaxioms, which are, intuitively, axioms which can only\nbe applied \"at infinite depth\" in a proof tree. This notion nicely subsumes\nstandard inference systems and their inductive and coinductive interpretation,\nwhile providing more flexibility. Indeed, the classical results can be extended\nto our generalized framework, interpreting recursive definitions as fixed\npoints which are not necessarily the least, nor the greatest one. This allows\nformal reasoning in cases where the inductive and coinductive interpretation do\nnot provide the intended meaning, or are mixed together.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 11:25:20 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 19:43:58 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Dagnino", "Francesco", ""]]}, {"id": "1712.01063", "submitter": "Cristian Riveros", "authors": "Alejandro Grez, Cristian Riveros, Martin Ugarte, Stijn Vansummeren", "title": "A Second-Order Approach to Complex Event Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex Event Recognition (CER for short) refers to the activity of detecting\npatterns in streams of continuously arriving data. This field has been\ntraditionally approached from a practical point of view, resulting in\nheterogeneous implementations with fundamentally different capabilities. The\nmain reason behind this is that defining formal semantics for a CER language is\nnot trivial: they usually combine first-order variables for joining and\nfiltering events with regular operators like sequencing and Kleene closure.\nMoreover, their semantics usually focus only on the detection of complex\nevents, leaving the concept of output mostly unattended.\n  In this paper, we propose to unify the semantics and output of complex event\nrecognition languages by using second order objects. Specifically, we introduce\na CER language called Second Order Complex Event Logic (SO-CEL for short), that\nuses second order variables for managing and outputting sequences of events.\nThis makes the definition of the main CER operators simple, allowing us to\ndevelop the first steps in understanding its expressive power. We start by\ncomparing SO-CEL with a version that uses first-order variables called FO-CEL,\nshowing that they are equivalent in expressive power when restricted to unary\npredicates but, surprisingly, incomparable in general. Nevertheless, we show\nthat if we restrict to sets of binary predicates, then SO-CEL is strictly more\nexpressive than FO-CEL. Then, we introduce a natural computational model called\nUnary Complex Event Automata (UCEA) that provides a better understanding of\nSO-CEL. We show that, under unary predicates, SO-CEL captures the subclass of\nUCEA that satisfy the so-called *-property. Finally, we identify the operations\nthat SO-CEL is lacking to capture UCEA and introduce a natural extension of the\nlanguage that captures the complete class of UCEA under unary predicates.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 13:33:37 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Grez", "Alejandro", ""], ["Riveros", "Cristian", ""], ["Ugarte", "Martin", ""], ["Vansummeren", "Stijn", ""]]}, {"id": "1712.01103", "submitter": "EPTCS", "authors": "Elizabeth Firman (Tel Aviv University), Shahar Maoz (Tel Aviv\n  University), Jan Oliver Ringert (Tel Aviv University)", "title": "Performance Heuristics for GR(1) Synthesis and Related Algorithms", "comments": "In Proceedings SYNT 2017, arXiv:1711.10224", "journal-ref": "EPTCS 260, 2017, pp. 62-80", "doi": "10.4204/EPTCS.260.7", "report-no": null, "categories": "cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive synthesis for the GR(1) fragment of LTL has been implemented and\nstudied in many works. In this workshop paper we present and evaluate a list of\nheuristics to potentially reduce running times for GR(1) synthesis and related\nalgorithms. The list includes early detection of fixed-points and\nunrealizability, fixed-point recycling, and heuristics for unrealizable core\ncomputations. We evaluate the presented heuristics on SYNTECH15, a total of 78\nspecifications of 6 autonomous Lego robots, written by 3rd year undergraduate\ncomputer science students in a project class we have taught, as well as on\nseveral benchmarks from the literature. The evaluation investigates not only\nthe potential of the suggested heuristics to improve computation times, but\nalso the difference between existing benchmarks and the robot's specifications\nin terms of the effectiveness of the heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 01:27:33 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Firman", "Elizabeth", "", "Tel Aviv University"], ["Maoz", "Shahar", "", "Tel Aviv\n  University"], ["Ringert", "Jan Oliver", "", "Tel Aviv University"]]}, {"id": "1712.01113", "submitter": "Louis Parlant", "authors": "Fredrik Dahlqvist, Louis Parlant and Alexandra Silva", "title": "Layer by layer - Combining Monads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method to incrementally construct programming languages. Our\napproach is categorical: each layer of the language is described as a monad.\nOur method either (i) concretely builds a distributive law between two monads,\ni.e. layers of the language, which then provides a monad structure to the\ncomposition of layers, or (ii) identifies precisely the algebraic obstacles to\nthe existence of a distributive law and gives a best approximant language. The\nrunning example will involve three layers: a basic imperative language enriched\nfirst by adding non-determinism and then probabilistic choice. The first\nextension works seamlessly, but the second encounters an obstacle, which\nresults in a best approximant language structurally very similar to the\nprobabilistic network specification language ProbNetKAT.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 14:50:40 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 16:06:45 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 09:46:24 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Dahlqvist", "Fredrik", ""], ["Parlant", "Louis", ""], ["Silva", "Alexandra", ""]]}, {"id": "1712.01222", "submitter": "Andrew Gacek", "authors": "Andrew Gacek, John Backes, Mike Whalen, Lucas Wagner, Elaheh\n  Ghassabani", "title": "The JKind Model Checker", "comments": "CAV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  JKind is an open-source industrial model checker developed by Rockwell\nCollins and the University of Minnesota. JKind uses multiple parallel engines\nto prove or falsify safety properties of infinite state models. It is portable,\neasy to install, performance competitive with other state-of-the-art model\ncheckers, and has features designed to improve the results presented to users:\ninductive validity cores for proofs and counterexample smoothing for test-case\ngeneration. It serves as the back-end for various industrial applications.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 17:52:17 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 18:21:36 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Gacek", "Andrew", ""], ["Backes", "John", ""], ["Whalen", "Mike", ""], ["Wagner", "Lucas", ""], ["Ghassabani", "Elaheh", ""]]}, {"id": "1712.01485", "submitter": "EPTCS", "authors": "Gilles Dowek (Inria and \\'Ecole Normale Sup\\'erieure de Paris-Saclay)", "title": "Analyzing Individual Proofs as the Basis of Interoperability between\n  Proof Systems", "comments": "In Proceedings PxTP 2017, arXiv:1712.00898", "journal-ref": "EPTCS 262, 2017, pp. 3-12", "doi": "10.4204/EPTCS.262.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the first results of a project of analyzing in which theories\nformal proofs can be ex- pressed. We use this analysis as the basis of\ninteroperability between proof systems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 05:47:09 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Dowek", "Gilles", "", "Inria and \u00c9cole Normale Sup\u00e9rieure de Paris-Saclay"]]}, {"id": "1712.01486", "submitter": "EPTCS", "authors": "Haniel Barbosa (University of Lorraine, CNRS, Inria, and LORIA),\n  Jasmin Christian Blanchette (University of Lorraine, CNRS, Inria, and LORIA,\n  Vrije Universiteit Amsterdam, Max-Planck-Institut f\\\"ur Informatik), Simon\n  Cruanes (University of Lorraine, CNRS, Inria, and LORIA), Daniel El Ouraoui\n  (University of Lorraine, CNRS, Inria, and LORIA), Pascal Fontaine (University\n  of Lorraine, CNRS, Inria, and LORIA)", "title": "Language and Proofs for Higher-Order SMT (Work in Progress)", "comments": "In Proceedings PxTP 2017, arXiv:1712.00898", "journal-ref": "EPTCS 262, 2017, pp. 15-22", "doi": "10.4204/EPTCS.262.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satisfiability modulo theories (SMT) solvers have throughout the years been\nable to cope with increasingly expressive formulas, from ground logics to full\nfirst-order logic modulo theories. Nevertheless, higher-order logic within SMT\nis still little explored. One main goal of the Matryoshka project, which\nstarted in March 2017, is to extend the reasoning capabilities of SMT solvers\nand other automatic provers beyond first-order logic. In this preliminary\nreport, we report on an extension of the SMT-LIB language, the standard input\nformat of SMT solvers, to handle higher-order constructs. We also discuss how\nto augment the proof format of the SMT solver veriT to accommodate these new\nconstructs and the solving techniques they require.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 05:47:28 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Barbosa", "Haniel", "", "University of Lorraine, CNRS, Inria, and LORIA"], ["Blanchette", "Jasmin Christian", "", "University of Lorraine, CNRS, Inria, and LORIA,\n  Vrije Universiteit Amsterdam, Max-Planck-Institut f\u00fcr Informatik"], ["Cruanes", "Simon", "", "University of Lorraine, CNRS, Inria, and LORIA"], ["Ouraoui", "Daniel El", "", "University of Lorraine, CNRS, Inria, and LORIA"], ["Fontaine", "Pascal", "", "University\n  of Lorraine, CNRS, Inria, and LORIA"]]}, {"id": "1712.01487", "submitter": "EPTCS", "authors": "Silvio Ghilardi (Universit\\`a degli Studi di Milano), Elena Pagani\n  (Universit\\`a degli Studi di Milano)", "title": "Counter Simulations via Higher Order Quantifier Elimination: a\n  preliminary report", "comments": "In Proceedings PxTP 2017, arXiv:1712.00898", "journal-ref": "EPTCS 262, 2017, pp. 39-53", "doi": "10.4204/EPTCS.262.5", "report-no": null, "categories": "cs.LO cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quite often, verification tasks for distributed systems are accomplished via\ncounter abstractions. Such abstractions can sometimes be justified via\nsimulations and bisimulations. In this work, we supply logical foundations to\nthis practice, by a specifically designed technique for second order quantifier\nelimination. Our method, once applied to specifications of verification\nproblems for parameterized distributed systems, produces integer variables\nsystems that are ready to be model-checked by current SMT-based tools. We\ndemonstrate the feasibility of the approach with a prototype implementation and\nfirst experiments.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 05:48:30 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Ghilardi", "Silvio", "", "Universit\u00e0 degli Studi di Milano"], ["Pagani", "Elena", "", "Universit\u00e0 degli Studi di Milano"]]}, {"id": "1712.01488", "submitter": "EPTCS", "authors": "Tomer Libal (Inria, Paris), Xaviera Steele (American University of\n  Paris)", "title": "Determinism in the Certification of UNSAT Proofs", "comments": "In Proceedings PxTP 2017, arXiv:1712.00898", "journal-ref": "EPTCS 262, 2017, pp. 55-76", "doi": "10.4204/EPTCS.262.6", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for increased trustworthiness of SAT solvers is very active and\nuses various methods. Some of these methods obtain a proof from the provers\nthen check it, normally by replicating the search based on the proof's\ninformation. Because the certification process involves another nontrivial\nproof search, the trust we can place in it is decreased. Some attempts to amend\nthis use certifiers which have been verified by proofs assistants such as\nIsabelle/HOL and Coq. Our approach is different because it is based on an\nextremely simplified certifier. This certifier enjoys a very high level of\ntrust but is very inefficient. In this paper, we experiment with this approach\nand conclude that by placing some restrictions on the formats, one can mostly\neliminate the need for search and in principle, can certify proofs of arbitrary\nsize.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 05:49:02 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Libal", "Tomer", "", "Inria, Paris"], ["Steele", "Xaviera", "", "American University of\n  Paris"]]}, {"id": "1712.01489", "submitter": "EPTCS", "authors": "Dennis M\\\"uller (Computer Science, FAU Erlangen-N\\\"urnberg), Colin\n  Rothgang (Mathematics, Jacobs University Bremen), Yufei Liu (Mathematics,\n  Jacobs University Bremen), Florian Rabe (Computer Science, Jacobs University\n  Bremen)", "title": "Alignment-based Translations Across Formal Systems Using Interface\n  Theories", "comments": "In Proceedings PxTP 2017, arXiv:1712.00898", "journal-ref": "EPTCS 262, 2017, pp. 77-93", "doi": "10.4204/EPTCS.262.7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating expressions between different logics and theorem provers is\nnotoriously and often prohibitively difficult, due to the large differences\nbetween the logical foundations, the implementations of the systems, and the\nstructure of the respective libraries. Practical solutions for exchanging\ntheorems across theorem provers have remained both weak and brittle.\nConsequently, libraries are not easily reusable across systems, and substantial\neffort must be spent on reformalizing and proving basic results in each system.\nNotably, this problem exists already if we only try to exchange theorem\nstatements and forgo exchanging proofs.\n  In previous work we introduced alignments as a lightweight standard for\nrelating concepts across libraries and conjectured that it would provide a good\nbase for translating expressions. In this paper, we demonstrate the feasibility\nof this approach. We use a foundationally uncommitted framework to write\ninterface theories that abstract from logical foundation, implementation, and\nlibrary structure. Then we use alignments to record how the concepts in the\ninterface theories are realized in several major proof assistant libraries, and\nwe use that information to translate expressions across libraries. Concretely,\nwe present exemplary interface theories for several areas of mathematics and -\nin total - several hundred alignments that were found manually.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 05:49:32 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["M\u00fcller", "Dennis", "", "Computer Science, FAU Erlangen-N\u00fcrnberg"], ["Rothgang", "Colin", "", "Mathematics, Jacobs University Bremen"], ["Liu", "Yufei", "", "Mathematics,\n  Jacobs University Bremen"], ["Rabe", "Florian", "", "Computer Science, Jacobs University\n  Bremen"]]}, {"id": "1712.01631", "submitter": "Pedro Soares", "authors": "Pedro Soares, Ant\\'onio Ravara and Sim\\~ao Melo de Sousa", "title": "Revisiting concurrent separation logic", "comments": null, "journal-ref": "Journal of Logical and Algebraic Methods in Programming, Volume\n  89, 2017, Pages 41-66", "doi": "10.1016/j.jlamp.2017.02.004", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new soundness proof of Concurrent Separation Logic (CSL) based\non a structural operational semantics (SOS). We build on two previous proofs\nand develop new auxiliary notions to achieve the goal. One uses a denotational\nsemantics (based on traces). The other is based on SOS, but was obtained only\nfor a fragment of the logic - the Disjoint CSL - which disallows modifying\nshared variables between concurrent threads. In this work, we lift such a\nrestriction, proving the soundness of full CSL with respect to a SOS. Thus\ncontributing to the development of tools able of ensuring the correctness of\nrealistic concurrent programs. Moreover, given that we used SOS, such tools can\nbe well-integrated in programming environments and even incorporated in\ncompilers.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 14:10:01 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Soares", "Pedro", ""], ["Ravara", "Ant\u00f3nio", ""], ["de Sousa", "Sim\u00e3o Melo", ""]]}, {"id": "1712.01734", "submitter": "Tuba Yavuz", "authors": "Tuba Yavuz", "title": "Partial Predicate Abstraction and Counter-Example Guided Refinement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a counter-example guided abstraction and\napproximation refinement (CEGAAR) technique for {\\em partial predicate\nabstraction}, which combines predicate abstraction and fixpoint approximations\nfor model checking infinite-state systems. The proposed approach incrementally\nconsiders growing sets of predicates for abstraction refinement. The novelty of\nthe approach stems from recognizing source of the imprecision: abstraction or\napproximation. We use Craig interpolation to deal with imprecision due to\nabstraction. In the case of imprecision due to approximation, we delay\napplication of the approximation. Our experimental results on a variety of\nmodels provide insights into effectiveness of partial predicate abstraction as\nwell as refinement techniques in this context.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 16:19:21 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Yavuz", "Tuba", ""]]}, {"id": "1712.01800", "submitter": "Carlo Angiuli", "authors": "Carlo Angiuli and Kuen-Bang Hou and Robert Harper", "title": "Computational Higher Type Theory III: Univalent Universes and Exact\n  Equality", "comments": "71 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the third in a series of papers extending Martin-L\\\"of's meaning\nexplanations of dependent type theory to a Cartesian cubical realizability\nframework that accounts for higher-dimensional types. We extend this framework\nto include a cumulative hierarchy of univalent Kan universes of Kan types,\nexact equality and other pretypes lacking Kan structure, and a cumulative\nhierarchy of pretype universes. As in Parts I and II, the main result is a\ncanonicity theorem stating that closed terms of boolean type evaluate to either\ntrue or false. This establishes the computational interpretation of Cartesian\ncubical higher type theory based on cubical programs equipped with a\ndeterministic operational semantics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 18:26:34 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Angiuli", "Carlo", ""], ["Hou", "Kuen-Bang", ""], ["Harper", "Robert", ""]]}, {"id": "1712.01980", "submitter": "Val Tannen", "authors": "Erich Gr\\\"adel, Val Tannen", "title": "Semiring Provenance for First-Order Model Checking", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a first-order sentence, a model-checking computation tests whether the\nsentence holds true in a given finite structure. Data provenance extracts from\nthis computation an abstraction of the manner in which its result depends on\nthe data items that describe the model. Previous work on provenance was, to a\nlarge extent, restricted to the negation-free fragment of first-order logic and\nshowed how provenance abstractions can be usefully described as elements of\ncommutative semirings --- most generally as multivariate polynomials with\npositive integer coefficients.\n  In this paper we introduce a novel approach to dealing with negation and a\ncorresponding commutative semiring of polynomials with dual indeterminates.\nThese polynomials are used to perform reverse provenance analysis, i.e.,\nfinding models that satisfy various properties under given provenance tracking\nassumptions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 00:35:29 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Gr\u00e4del", "Erich", ""], ["Tannen", "Val", ""]]}, {"id": "1712.02872", "submitter": "Yassmeen Elderhalli", "authors": "Yassmeen Elderhalli, Osman Hasan, Waqar Ahmad, Sofiene Tahar", "title": "Dynamic Fault Trees Analysis using an Integration of Theorem Proving and\n  Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic fault trees (DFTs) have emerged as an important tool for capturing\nthe dynamic behavior of system failure. These DFTs are then analyzed\nqualitatively and quantitatively using stochastic or algebraic methods to judge\nthe failure characteristics of the given system in terms of the failures of its\nsub-components. Model checking has been recently proposed to conduct the\nfailure analysis of systems using DFTs with the motivation to provide a\nrigorous failure analysis of safety-critical systems. However, model checking\nhas not been used for the DFT qualitative analysis and the reduction algorithms\nused in model checking are usually not formally verified. Moreover, the\nanalysis time grows exponentially with the increase of the number of states.\nThese issues limit the usefulness of model checking for analyzing complex\nsystems used in safety-critical domains, where the accuracy and completeness of\nanalysis matters the most. To overcome these limitations, we propose a\ncomprehensive methodology to perform the qualitative and quantitative analysis\nof DFTs using an integration of theorem proving and model checking based\napproaches. For this purpose, we formalized all the basic dynamic fault tree\ngates using higher-order logic based on the algebraic approach and formally\nverified some of the simplification properties. This formalization allows us to\nformally verify the equivalence between the original and reduced DFTs using a\ntheorem prover, and conduct the qualitative analysis. We then use model\nchecking to perform the quantitative analysis of the formally verified reduced\nDFT. We applied our methodology to five benchmarks and the results show that\nthe formally verified reduced DFT was analyzed using model checking with up to\nsix times less states and up to 133000 times faster.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 21:49:40 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Elderhalli", "Yassmeen", ""], ["Hasan", "Osman", ""], ["Ahmad", "Waqar", ""], ["Tahar", "Sofiene", ""]]}, {"id": "1712.03502", "submitter": "Makoto Tatsuta", "authors": "Stefano Berardi and Makoto Tatsuta", "title": "Equivalence of Intuitionistic Inductive Definitions and Intuitionistic\n  Cyclic Proofs under Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cyclic proof system gives us another way of representing inductive\ndefinitions and efficient proof search. In 2011 Brotherston and Simpson\nconjectured the equivalence between the provability of the classical cyclic\nproof system and that of the classical system of Martin-Lof's inductive\ndefinitions.\n  This paper studies the conjecture for intuitionistic logic.\n  This paper first points out that the countermodel of FOSSACS 2017 paper by\nthe same authors shows the conjecture for intuitionistic logic is false in\ngeneral. Then this paper shows the conjecture for intuitionistic logic is true\nunder arithmetic, namely, the provability of the intuitionistic cyclic proof\nsystem is the same as that of the intuitionistic system of Martin-Lof's\ninductive definitions when both systems contain Heyting arithmetic HA.\n  For this purpose, this paper also shows that HA proves Podelski-Rybalchenko\ntheorem for induction and Kleene-Brouwer theorem for induction. These results\nimmediately give another proof to the conjecture under arithmetic for classical\nlogic shown in LICS 2017 paper by the same authors.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 11:01:59 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Berardi", "Stefano", ""], ["Tatsuta", "Makoto", ""]]}, {"id": "1712.03626", "submitter": "Christoph Rauch", "authors": "Olaf Beyersdorff, Joshua Blinkhorn, Luke Hinde", "title": "Size, Cost, and Capacity: A Semantic Technique for Hard Random QBFs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (February\n  13, 2019) lmcs:5184", "doi": "10.23638/LMCS-15(1:13)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a natural extension of the SAT problem, an array of proof systems for\nquantified Boolean formulas (QBF) have been proposed, many of which extend a\npropositional proof system to handle universal quantification. By formalising\nthe construction of the QBF proof system obtained from a propositional proof\nsystem by adding universal reduction (Beyersdorff, Bonacina & Chew, ITCS `16),\nwe present a new technique for proving proof-size lower bounds in these\nsystems. The technique relies only on two semantic measures: the cost of a QBF,\nand the capacity of a proof. By examining the capacity of proofs in several QBF\nsystems, we are able to use the technique to obtain lower bounds based on cost\nalone.\n  As applications of the technique, we first prove exponential lower bounds for\na new family of simple QBFs representing equality. The main application is in\nproving exponential lower bounds with high probability for a class of randomly\ngenerated QBFs, the first `genuine' lower bounds of this kind, which apply to\nthe QBF analogues of resolution, Cutting Planes, and Polynomial Calculus.\nFinally, we employ the technique to give a simple proof of hardness for the\nprominent formulas of Kleine B\\\"uning, Karpinski and Fl\\\"ogel.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 02:20:43 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 10:23:07 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 13:44:47 GMT"}, {"version": "v4", "created": "Tue, 12 Feb 2019 12:54:40 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Beyersdorff", "Olaf", ""], ["Blinkhorn", "Joshua", ""], ["Hinde", "Luke", ""]]}, {"id": "1712.03680", "submitter": "Mathieu Hoyrup", "authors": "Mathieu Hoyrup", "title": "Results in descriptive set theory on some represented spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Descriptive set theory was originally developed on Polish spaces. It was\nlater extended to $\\omega$-continuous domains [Selivanov 2004] and recently to\nquasi-Polish spaces [de Brecht 2013]. All these spaces are countably-based.\nExtending descriptive set theory and its effective counterpart to general\nrepresented spaces, including non-countably-based spaces has been started in\n[Pauly, de Brecht 2015].\n  We study the spaces $\\mathcal{O}(\\mathbb{N}^\\mathbb{N})$,\n$\\mathcal{C}(\\mathbb{N}^\\mathbb{N},2)$ and the Kleene-Kreisel spaces\n$\\mathbb{N}\\langle\\alpha\\rangle$. We show that there is a $\\Sigma^0_2$-subset\nof $\\mathcal{O}(\\mathbb{N}^\\mathbb{N})$ which is not Borel. We show that the\nopen subsets of $\\mathbb{N}^{\\mathbb{N}^\\mathbb{N}}$ cannot be continuously\nindexed by elements of $\\mathbb{N}^\\mathbb{N}$ or even\n$\\mathbb{N}^{\\mathbb{N}^\\mathbb{N}}$, and more generally that the open subsets\nof $\\mathbb{N}\\langle\\alpha\\rangle$ cannot be continuously indexed by elements\nof $\\mathbb{N}\\langle\\alpha\\rangle$. We also derive effective versions of these\nresults.\n  These results give answers to recent open questions on the classification of\nspaces in terms of their base-complexity, introduced in [de Brecht, Schr\\\"oder,\nSelivanov 2016]. In order to obtain these results, we develop general\ntechniques which are refinements of Cantor's diagonal argument involving\nmulti-valued fixed-point free functions and that are interesting on their own\nright.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 09:02:28 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Hoyrup", "Mathieu", ""]]}, {"id": "1712.03759", "submitter": "Ale\\v{s} Bizjak", "authors": "Dietrich Kuske, Jiamou Liu, and Anastasia Moskvina", "title": "Infinite and Bi-infinite Words with Decidable Monadic Theories", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (August\n  21, 2018) lmcs:4767", "doi": "10.23638/LMCS-14(3:9)2018", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study word structures of the form $(D,<,P)$ where $D$ is either\n$\\mathbb{N}$ or $\\mathbb{Z}$, $<$ is the natural linear ordering on $D$ and\n$P\\subseteq D$ is a predicate on $D$. In particular we show:\n  (a) The set of recursive $\\omega$-words with decidable monadic second order\ntheories is $\\Sigma_3$-complete.\n  (b) Known characterisations of the $\\omega$-words with decidable monadic\nsecond order theories are transfered to the corresponding question for\nbi-infinite words.\n  (c) We show that such \"tame\" predicates $P$ exist in every Turing degree.\n  (d) We determine, for $P\\subseteq\\mathbb{Z}$, the number of predicates\n$Q\\subseteq\\mathbb{Z}$ such that $(\\mathbb{Z},\\le,P)$ and $(\\mathbb{Z},\\le,Q)$\nare indistinguishable.\n  Through these results we demonstrate similarities and differences between\nlogical properties of infinite and bi-infinite words.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 13:14:46 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 13:14:07 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2018 11:53:52 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Kuske", "Dietrich", ""], ["Liu", "Jiamou", ""], ["Moskvina", "Anastasia", ""]]}, {"id": "1712.03829", "submitter": "Christoph Rauch", "authors": "Antonio Bucciarelli and Delia Kesner and Simona Ronchi Della Rocca", "title": "Inhabitation for Non-idempotent Intersection Types", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (August 3,\n  2018) lmcs:4738", "doi": "10.23638/LMCS-14(3:7)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The inhabitation problem for intersection types in the lambda-calculus is\nknown to be undecidable. We study the problem in the case of non-idempotent\nintersection, considering several type assignment systems, which characterize\nthe solvable or the strongly normalizing lambda-terms. We prove the\ndecidability of the inhabitation problem for all the systems considered, by\nproviding sound and complete inhabitation algorithms for them.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 15:21:21 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 07:12:03 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 12:47:34 GMT"}, {"version": "v4", "created": "Wed, 13 Jun 2018 10:25:50 GMT"}, {"version": "v5", "created": "Thu, 2 Aug 2018 15:06:00 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Bucciarelli", "Antonio", ""], ["Kesner", "Delia", ""], ["Della Rocca", "Simona Ronchi", ""]]}, {"id": "1712.04162", "submitter": "Luca Pulina", "authors": "Massimo Narizzano, Luca Pulina, Armando Tacchella, Simone Vuotto", "title": "Consistency of Property Specification Patterns with Boolean and\n  Constrained Numerical Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Property Specification Patterns (PSPs) have been proposed to solve recurring\nspecification needs, to ease the formalization of requirements, and enable\nautomated verification thereof. In this paper, we extend PSPs by considering\nBoolean as well as atomic assertions from a constraint system. This extension\nenables us to reason about functional requirements which could not be captured\nby basic PSPs. We contribute an encoding from constrained PSPs to LTL formulas,\nand we show experimental results demonstrating that our approach scales on\nrequirements of realistic size generated using an artificial probabilistic\nmodel. Finally, we show that our extension enables us to prove (in)consistency\nof requirements about an embedded controller for a robotic manipulator.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 08:18:22 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Narizzano", "Massimo", ""], ["Pulina", "Luca", ""], ["Tacchella", "Armando", ""], ["Vuotto", "Simone", ""]]}, {"id": "1712.04375", "submitter": "Lawrence Paulson", "authors": "Lawrence C Paulson", "title": "Computational Logic: Its Origins and Applications", "comments": "accepted by Proceedings of the Royal Society Series A, subject to\n  minor revisions", "journal-ref": null, "doi": "10.1098/rspa.2017.0872", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational Logic is the use of computers to establish facts in a logical\nformalism. Originating in 19th-century attempts to understand the nature of\nmathematical reasoning, the subject now comprises a wide variety of formalisms,\ntechniques and technologies. One strand of work follows the \"LCF approach\"\npioneered by Robin Milner FRS, where proofs can be constructed interactively or\nwith the help of users' code (which does not compromise correctness). A\nrefinement of LCF, called Isabelle, retains these advantages while providing\nflexibility in the choice of logical formalism and much stronger automation.\nThe main application of these techniques has been to prove the correctness of\nhardware and software systems, but increasingly researchers have been applying\nthem to mathematics itself.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 16:20:09 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 16:08:08 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 14:57:08 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Paulson", "Lawrence C", ""]]}, {"id": "1712.04864", "submitter": "Thorsten Wissmann", "authors": "Ian Orton and Andrew M. Pitts", "title": "Axioms for Modelling Cubical Type Theory in a Topos", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (December\n  11, 2018) lmcs:5028", "doi": "10.23638/LMCS-14(4:23)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The homotopical approach to intensional type theory views proofs of equality\nas paths. We explore what is required of an object $I$ in a topos to give such\na path-based model of type theory in which paths are just functions with domain\n$I$. Cohen, Coquand, Huber and M\\\"ortberg give such a model using a particular\ncategory of presheaves. We investigate the extent to which their model\nconstruction can be expressed in the internal type theory of any topos and\nidentify a collection of quite weak axioms for this purpose. This clarifies the\ndefinition and properties of the notion of uniform Kan filling that lies at the\nheart of their constructive interpretation of Voevodsky's univalence axiom.\n(This paper is a revised and expanded version of a paper of the same name that\nappeared in the proceedings of the 25th EACSL Annual Conference on Computer\nScience Logic, CSL 2016.)\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 17:07:44 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 11:31:34 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2018 16:46:43 GMT"}, {"version": "v4", "created": "Sat, 8 Dec 2018 23:07:10 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Orton", "Ian", ""], ["Pitts", "Andrew M.", ""]]}, {"id": "1712.04890", "submitter": "Ian Orton", "authors": "Ian Orton and Andrew M. Pitts", "title": "Decomposing the Univalence Axiom", "comments": "18 pages", "journal-ref": "Leibniz International Proceedings in Informatics (LIPIcs), Vol.\n  104, pp. 6:1-6:19, 2018", "doi": "10.4230/LIPIcs.TYPES.2017.6", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates Voevodsky's univalence axiom in intensional\nMartin-L\\\"of type theory. In particular, it looks at how univalence can be\nderived from simpler axioms. We first present some existing work, collected\ntogether from various published and unpublished sources; we then present a new\ndecomposition of the univalence axiom into simpler axioms. We argue that these\naxioms are easier to verify in certain potential models of univalent type\ntheory, particularly those models based on cubical sets. Finally we show how\nthis decomposition is relevant to an open problem in type theory.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 17:59:52 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 12:46:23 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 17:40:35 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Orton", "Ian", ""], ["Pitts", "Andrew M.", ""]]}, {"id": "1712.04982", "submitter": "Kevin Sullivan", "authors": "Chong Tang, Kevin Sullivan, Jian Xiang, Trent Weiss, Baishakhi Ray", "title": "Interpreted Formalisms for Configurations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imprecise and incomplete specification of system \\textit{configurations}\nthreatens safety, security, functionality, and other critical system properties\nand uselessly enlarges the configuration spaces to be searched by configuration\nengineers and auto-tuners. To address these problems, this paper introduces\n\\textit{interpreted formalisms based on real-world types for configurations}.\nConfiguration values are lifted to values of real-world types, which we\nformalize as \\textit{subset types} in Coq. Values of these types are dependent\npairs whose components are values of underlying Coq types and proofs of\nadditional properties about them. Real-world types both extend and further\nconstrain \\textit{machine-level} configurations, enabling richer, proof-based\nchecking of their consistency with real-world constraints. Tactic-based proof\nscripts are written once to automate the construction of proofs, if proofs\nexist, for configuration fields and whole configurations. \\textit{Failures to\nprove} reveal real-world type errors. Evaluation is based on a case study of\ncombinatorial optimization of Hadoop performance by meta-heuristic search over\nHadoop configurations spaces.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 19:57:07 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 17:08:19 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Tang", "Chong", ""], ["Sullivan", "Kevin", ""], ["Xiang", "Jian", ""], ["Weiss", "Trent", ""], ["Ray", "Baishakhi", ""]]}, {"id": "1712.05310", "submitter": "Hans van Ditmarsch", "authors": "Hans van Ditmarsch, Tim French", "title": "Quantifying over Boolean announcements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various extensions of public announcement logic have been proposed with\nquantification over announcements. The best-known extension is called arbitrary\npublic announcement logic, APAL. It contains a primitive language construct Box\nphi intuitively expressing that 'after every public announcement of a formula,\nformula phi is true.' The logic APAL is undecidable and it has an infinitary\naxiomatization. Now consider restricting the APAL quantification to public\nannouncements of Boolean formulas only, such that Box phi intuitively expresses\nthat 'after every public announcement of a Boolean formula, formula phi is\ntrue.' This logic can therefore called Boolean arbitrary public announcement\nlogic, BAPAL. The logic BAPAL is the subject of this work. It is decidable and\nit has a finitary axiomatization. These results may be considered of interest,\nas for various applications quantification over Booleans is sufficient in\nformal specifications.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 16:07:13 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 12:15:09 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 12:03:39 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["van Ditmarsch", "Hans", ""], ["French", "Tim", ""]]}, {"id": "1712.05363", "submitter": "Paolo Perrone", "authors": "Tobias Fritz and Paolo Perrone", "title": "A Probability Monad as the Colimit of Spaces of Finite Samples", "comments": "56 pages", "journal-ref": "Theory and Applications of Categories, Vol. 34, No. 7, 2019, pp.\n  170-220", "doi": null, "report-no": null, "categories": "math.PR cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study a probability monad on the category of complete metric\nspaces and short maps. It assigns to each space the space of Radon probability\nmeasures on it with finite first moment, equipped with the\nKantorovich-Wasserstein distance. This monad is analogous to the Giry monad on\nthe category of Polish spaces, and it extends a construction due to van Breugel\nfor compact and for 1-bounded complete metric spaces.\n  We prove that this Kantorovich monad arises from a colimit construction on\nfinite power-like constructions, which formalizes the intuition that\nprobability measures are limits of finite samples. The proof relies on a\ncriterion for when an ordinary left Kan extension of lax monoidal functors is a\nmonoidal Kan extension. The colimit characterization allows the development of\nintegration theory and the treatment of measures on spaces of measures, without\nmeasure theory.\n  We also show that the category of algebras of the Kantorovich monad is\nequivalent to the category of closed convex subsets of Banach spaces with short\naffine maps as morphisms.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 17:48:42 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 14:30:24 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 15:23:49 GMT"}, {"version": "v4", "created": "Tue, 12 Mar 2019 13:25:48 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Fritz", "Tobias", ""], ["Perrone", "Paolo", ""]]}, {"id": "1712.05505", "submitter": "Ale\\v{s} Bizjak", "authors": "Daniel de Carvalho", "title": "Taylor expansion in linear logic is invertible", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 4 (December\n  7, 2018) lmcs:5020", "doi": "10.23638/LMCS-14(4:21)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Each Multiplicative Exponential Linear Logic (MELL) proof-net can be expanded\ninto a differential net, which is its Taylor expansion. We prove that two\ndifferent MELL proof-nets have two different Taylor expansions. As a corollary,\nwe prove a completeness result for MELL: We show that the relational model is\ninjective for MELL proof-nets, i.e. the equality between MELL proof-nets in the\nrelational model is exactly axiomatized by cut-elimination.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 01:59:18 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 10:10:19 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 19:12:42 GMT"}, {"version": "v4", "created": "Thu, 6 Dec 2018 15:22:14 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["de Carvalho", "Daniel", ""]]}, {"id": "1712.05513", "submitter": "Umang Mathur", "authors": "P. Madhusudan, Umang Mathur, Shambwaditya Saha, Mahesh Viswanathan", "title": "A Decidable Fragment of Second Order Logic With Applications to\n  Synthesis", "comments": null, "journal-ref": "27th EACSL Annual Conference on Computer Science Logic (CSL 2018),\n  http://drops.dagstuhl.de/opus/volltexte/2018/9698", "doi": "10.4230/LIPIcs.CSL.2018.31", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a fragment of many-sorted second order logic called EQSMT and show\nthat checking satisfiability of sentences in this fragment is decidable. EQSMT\nformulae have an $\\exists^*\\forall^*$ quantifier prefix (over variables,\nfunctions and relations) making EQSMT conducive for modeling synthesis\nproblems. Moreover, EQSMT allows reasoning using a combination of background\ntheories provided that they have a decidable satisfiability problem for the\n$\\exists^*\\forall^*$ FO-fragment (e.g., linear arithmetic). Our decision\nprocedure reduces the satisfiability of EQSMT formulae to satisfiability\nqueries of $\\exists^*\\forall^*$ formulae of each individual background theory,\nallowing us to use existing efficient SMT solvers supporting\n$\\exists^*\\forall^*$ reasoning for these theories; hence our procedure can be\nseen as effectively quantified SMT (EQSMT) reasoning.\n  Errata: We have modified the transformation step-2 (page 9) to correct for a\nslight error. Also, the description above Theorem 10 is different from the\npublished version.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 03:03:11 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 03:17:10 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2018 17:14:43 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Madhusudan", "P.", ""], ["Mathur", "Umang", ""], ["Saha", "Shambwaditya", ""], ["Viswanathan", "Mahesh", ""]]}, {"id": "1712.05581", "submitter": "Daniel Neider", "authors": "Daniel Neider, Pranav Garg, P. Madhusudan, Shambwaditya Saha, Daejun\n  Park", "title": "Invariant Synthesis for Incomplete Verification Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for synthesizing inductive invariants for incomplete\nverification engines, which soundly reduce logical problems in undecidable\ntheories to decidable theories. Our framework is based on the counter-example\nguided inductive synthesis principle (CEGIS) and allows verification engines to\ncommunicate non-provability information to guide invariant synthesis. We show\nprecisely how the verification engine can compute such non-provability\ninformation and how to build effective learning algorithms when invariants are\nexpressed as Boolean combinations of a fixed set of predicates. Moreover, we\nevaluate our framework in two verification settings, one in which verification\nengines need to handle quantified formulas and one in which verification\nengines have to reason about heap properties expressed in an expressive but\nundecidable separation logic. Our experiments show that our invariant synthesis\nframework based on non-provability information can both effectively synthesize\ninductive invariants and adequately strengthen contracts across a large suite\nof programs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 08:38:15 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 12:08:56 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Neider", "Daniel", ""], ["Garg", "Pranav", ""], ["Madhusudan", "P.", ""], ["Saha", "Shambwaditya", ""], ["Park", "Daejun", ""]]}, {"id": "1712.05665", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "A Heuristic Proof Procedure for First-Order Logic", "comments": "6 pages. Some optimizations are added", "journal-ref": "IEICE transactions on information and systems vol.E103-D no.03\n  March 2020", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the efficient proof procedures discussed in {\\em Computability\nlogic} \\cite{Jap03,Japic,Japfin}, we describe a heuristic proof procedure for\nfirst-order logic. This is a variant of Gentzen sequent system and has the\nfollowing features: (a)~ it views sequents as games between the machine and the\nenvironment, and (b)~ it views proofs as a winning strategy of the machine.\n  From this game-based viewpoint, a poweful heuristic can be extracted and a\nfair degree of determinism in proof search can be obtained. This article\nproposes a new deductive system LKg with respect to first-order logic and\nproves its soundness and completeness. We also discuss LKg', a variant of LKg\nwith some optimizations added.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 13:37:53 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 12:26:30 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "1712.06868", "submitter": "Christoph Wernhard", "authors": "Christoph Wernhard", "title": "Heinrich Behmann's Contributions to Second-Order Quantifier Elimination\n  from the View of Computational Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": "KRR 15-05", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For relational monadic formulas (the L\\\"owenheim class) second-order\nquantifier elimination, which is closely related to computation of uniform\ninterpolants, projection and forgetting - operations that currently receive\nmuch attention in knowledge processing - always succeeds. The decidability\nproof for this class by Heinrich Behmann from 1922 explicitly proceeds by\nelimination with equivalence preserving formula rewriting. Here we reconstruct\nthe results from Behmann's publication in detail and discuss related issues\nthat are relevant in the context of modern approaches to second-order\nquantifier elimination in computational logic. In addition, an extensive\ndocumentation of the letters and manuscripts in Behmann's bequest that concern\nsecond-order quantifier elimination is given, including a commented register\nand English abstracts of the German sources with focus on technical material.\nIn the late 1920s Behmann attempted to develop an elimination-based decision\nmethod for formulas with predicates whose arity is larger than one. His\nmanuscripts and the correspondence with Wilhelm Ackermann show technical\naspects that are still of interest today and give insight into the genesis of\nAckermann's landmark paper \"Untersuchungen \\\"uber das Eliminationsproblem der\nmathematischen Logik\" from 1935, which laid the foundation of the two\nprevailing modern approaches to second-order quantifier elimination.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 11:17:23 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Wernhard", "Christoph", ""]]}, {"id": "1712.06901", "submitter": "Ale\\v{s} Bizjak", "authors": "Marco Forti", "title": "A topological interpretation of three Leibnizian principles within the\n  functional extensions", "comments": "arXiv admin note: substantial text overlap with arXiv:1012.4341", "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (July 31,\n  2018) lmcs:4724", "doi": "10.23638/LMCS-14(3:5)2018", "report-no": null, "categories": "math.LO cs.LO math.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Three philosophical principles are often quoted in connection with Leibniz:\n\"objects sharing the same properties are the same object\" (Identity of\nindiscernibles), \"everything can possibly exist, unless it yields\ncontradiction\" (Possibility as consistency), and \"the ideal elements correctly\ndetermine the real things\" (Transfer). Here we give a precise\nlogico-mathematical formulation of these principles within the framework of the\nFunctional Extensions, mathematical structures that generalize at once\ncompactifications, completions, and elementary extensions of models. In this\ncontext, the above Leibnizian principles appear as topological or algebraic\nproperties, namely: a property of separation, a property of compactness, and a\nproperty of directeness, respectively. Abiding by this interpretation, we\nobtain the somehow surprising conclusion that these Leibnizian principles may\nbe fulfilled in pairs, but not all three together.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 12:39:12 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 11:13:44 GMT"}, {"version": "v3", "created": "Sun, 3 Jun 2018 17:38:39 GMT"}, {"version": "v4", "created": "Tue, 17 Jul 2018 11:43:15 GMT"}, {"version": "v5", "created": "Mon, 30 Jul 2018 09:27:47 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Forti", "Marco", ""]]}, {"id": "1712.06906", "submitter": "Ale\\v{s} Bizjak", "authors": "Jan Bessai, Tzu-Chun Chen, Andrej Dudenhefner, Boris D\\\"udder, Ugo\n  de'Liguoro, Jakob Rehof", "title": "Mixin Composition Synthesis based on Intersection Types", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (February\n  27, 2018) lmcs:4319", "doi": "10.23638/LMCS-14(1:18)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a method for synthesizing compositions of mixins using type\ninhabitation in intersection types. First, recursively defined classes and\nmixins, which are functions over classes, are expressed as terms in a lambda\ncalculus with records. Intersection types with records and record-merge are\nused to assign meaningful types to these terms without resorting to recursive\ntypes. Second, typed terms are translated to a repository of typed combinators.\nWe show a relation between record types with record-merge and intersection\ntypes with constructors. This relation is used to prove soundness and partial\ncompleteness of the translation with respect to mixin composition synthesis.\nFurthermore, we demonstrate how a translated repository and goal type can be\nused as input to an existing framework for composition synthesis in bounded\ncombinatory logic via type inhabitation. The computed result is a class typed\nby the goal type and generated by a mixin composition applied to an existing\nclass.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 13:00:51 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 16:34:34 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Bessai", "Jan", ""], ["Chen", "Tzu-Chun", ""], ["Dudenhefner", "Andrej", ""], ["D\u00fcdder", "Boris", ""], ["de'Liguoro", "Ugo", ""], ["Rehof", "Jakob", ""]]}, {"id": "1712.07121", "submitter": "Thorsten Wissmann", "authors": "Thomas Colcombet and Daniela Petri\\c{s}an", "title": "Automata Minimization: a Functorial Approach", "comments": "journal version of the CALCO 2017 paper arXiv:1711.03063", "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (March 23,\n  2020) lmcs:6213", "doi": "10.23638/LMCS-16(1:32)2020", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we regard languages and their acceptors - such as deterministic\nor weighted automata, transducers, or monoids - as functors from input\ncategories that specify the type of the languages and of the machines to\ncategories that specify the type of outputs. Our results are as follows:\n  A) We provide sufficient conditions on the output category so that\nminimization of the corresponding automata is guaranteed.\n  B) We show how to lift adjunctions between the categories for output values\nto adjunctions between categories of automata.\n  C) We show how this framework can be instantiated to unify several phenomena\nin automata theory, starting with determinization, minimization and syntactic\nalgebras. We provide explanations of Choffrut's minimization algorithm for\nsubsequential transducers and of Brzozowski's minimization algorithm in this\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 17:39:30 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 10:28:29 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 14:54:59 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Colcombet", "Thomas", ""], ["Petri\u015fan", "Daniela", ""]]}, {"id": "1712.07344", "submitter": "Yoann Dabrowski", "authors": "Yoann Dabrowski, Marie Kerjean", "title": "Models of Linear Logic based on the Schwartz $\\varepsilon$-product", "comments": "82 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the interpretation of Linear Logic multiplicative disjunction as the\n$\\varepsilon$-product defined by Laurent Schwartz, we construct several models\nof Differential Linear Logic based on usual mathematical notions of smooth\nmaps. This improves on previous results, by R. Blute, T. Ehrhard and C. Tasson,\nbased on convenient smoothness where only intuitionist models were built. We\nisolate a completeness condition, called k-quasi-completeness, and an\nassociated notion stable by duality called k-reflexivity, allowing for a\n$*$-autonomous category of k-reflexive spaces in which the dual of the tensor\nproduct is the reflexive version of the $\\varepsilon$ product. We adapt Meise's\ndefinition of Smooth maps into a first model of Differential Linear Logic, made\nof k-reflexive spaces. We also build two new models of Linear Logic with\nconveniently smooth maps, on categories made respectively of Mackey-complete\nSchwartz spaces and Mackey-complete Nuclear Spaces (with extra reflexivity\nconditions). Varying slightly the notion of smoothness, one also recovers\nmodels of DiLL on the same $*$-autonomous categories. Throughout the article,\nwe work within the setting of Dialogue categories where the tensor product is\nexactly the $\\varepsilon$-product (without reflexivization).\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 07:28:36 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Dabrowski", "Yoann", ""], ["Kerjean", "Marie", ""]]}, {"id": "1712.07511", "submitter": "Ale\\v{s} Bizjak", "authors": "Paolo Baldan, Filippo Bonchi, Henning Kerstan, Barbara K\\\"onig", "title": "Coalgebraic Behavioral Metrics", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (September\n  14, 2018) lmcs:4827", "doi": "10.23638/LMCS-14(3:20)2018", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study different behavioral metrics, such as those arising from both\nbranching and linear-time semantics, in a coalgebraic setting. Given a\ncoalgebra $\\alpha\\colon X \\to HX$ for a functor $H \\colon \\mathrm{Set}\\to\n\\mathrm{Set}$, we define a framework for deriving pseudometrics on $X$ which\nmeasure the behavioral distance of states.\n  A crucial step is the lifting of the functor $H$ on $\\mathrm{Set}$ to a\nfunctor $\\overline{H}$ on the category $\\mathrm{PMet}$ of pseudometric spaces.\nWe present two different approaches which can be viewed as generalizations of\nthe Kantorovich and Wasserstein pseudometrics for probability measures. We show\nthat the pseudometrics provided by the two approaches coincide on several\nnatural examples, but in general they differ.\n  If $H$ has a final coalgebra, every lifting $\\overline{H}$ yields in a\ncanonical way a behavioral distance which is usually branching-time, i.e., it\ngeneralizes bisimilarity. In order to model linear-time metrics (generalizing\ntrace equivalences), we show sufficient conditions for lifting distributive\nlaws and monads. These results enable us to employ the generalized powerset\nconstruction.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 15:00:58 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 13:23:30 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 12:39:09 GMT"}, {"version": "v4", "created": "Thu, 13 Sep 2018 09:13:47 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Baldan", "Paolo", ""], ["Bonchi", "Filippo", ""], ["Kerstan", "Henning", ""], ["K\u00f6nig", "Barbara", ""]]}, {"id": "1712.07622", "submitter": "Sofie Haesaert", "authors": "Sofie Haesaert and Sadegh Soudjani and Alessandro Abate", "title": "Temporal logic control of general Markov decision processes by\n  approximate policy refinement", "comments": "22 pages, 3 figures, Short version presented at the ADHS conference\n  2018 in Oxford", "journal-ref": null, "doi": "10.1016/j.ifacol.2018.08.013", "report-no": null, "categories": "cs.SY cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formal verification and controller synthesis for Markov decision\nprocesses that evolve over uncountable state spaces are computationally hard\nand thus generally rely on the use of approximations. In this work, we consider\nthe correct-by-design control of general Markov decision processes (gMDPs) with\nrespect to temporal logic properties by leveraging approximate probabilistic\nrelations between the original model and its abstraction. We newly work with a\nrobust satisfaction for the construction and verification of control\nstrategies, which allows for both deviations in the outputs of the gMDPs and in\nthe probabilistic transitions. The computation is done over the reduced or\nabstracted models, such that when a property is robustly satisfied on the\nabstract model, it is also satisfied on the original model with respect to a\nrefined control strategy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 18:21:52 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 18:07:04 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Haesaert", "Sofie", ""], ["Soudjani", "Sadegh", ""], ["Abate", "Alessandro", ""]]}, {"id": "1712.07945", "submitter": "Olivier Finkel", "authors": "Olivier Finkel (IMJ-PRG)", "title": "Wadge Degrees of $\\omega$-Languages of Petri Nets", "comments": "arXiv admin note: text overlap with arXiv:0712.1359, arXiv:0804.3266", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that $\\omega$-languages of (non-deterministic) Petri nets and\n$\\omega$-languages of (non-deterministic) Turing machines have the same\ntopological complexity: the Borel and Wadge hierarchies of the class of\n$\\omega$-languages of (non-deterministic) Petri nets are equal to the Borel and\nWadge hierarchies of the class of $\\omega$-languages of (non-deterministic)\nTuring machines which also form the class of effective analytic sets. In\nparticular, for each non-null recursive ordinal $\\alpha < \\omega\\_1^{{\\rm CK}}\n$ there exist some ${\\bf \\Sigma}^0\\_\\alpha$-complete and some ${\\bf\n\\Pi}^0\\_\\alpha$-complete $\\omega$-languages of Petri nets, and the supremum of\nthe set of Borel ranks of $\\omega$-languages of Petri nets is the ordinal\n$\\gamma\\_2^1$, which is strictly greater than the first non-recursive ordinal\n$\\omega\\_1^{{\\rm CK}}$. We also prove that there are some ${\\bf\n\\Sigma}\\_1^1$-complete, hence non-Borel, $\\omega$-languages of Petri nets, and\nthat it is consistent with ZFC that there exist some $\\omega$-languages of\nPetri nets which are neither Borel nor ${\\bf \\Sigma}\\_1^1$-complete. This\nanswers the question of the topological complexity of $\\omega$-languages of\n(non-deterministic) Petri nets which was left open in [DFR14,FS14].\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 15:12:58 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 08:27:40 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Finkel", "Olivier", "", "IMJ-PRG"]]}, {"id": "1712.08345", "submitter": "EPTCS", "authors": "Timo Kehrer (Humboldt-University of Berlin), Alice Miller (University\n  of Glasgow)", "title": "Proceedings Third Workshop on Graphs as Models", "comments": null, "journal-ref": "EPTCS 263, 2017", "doi": "10.4204/EPTCS.263", "report-no": null, "categories": "cs.LO cs.DC cs.DS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are used as models in many areas of computer science and computer\nengineering. For example graphs are used to represent syntax, control and data\nflow, dependency, state spaces, models such as UML and other types of\ndomain-specific models, and social network graphs. In all of these examples,\nthe graph serves as an intuitive yet mathematically precise foundation for many\npurposes, both in theory building as well as in practical applications.\nGraph-based models serve as an abstract communication medium and are used to\ndescribe various concepts and phenomena. Moreover, once such graph-based models\nare constructed, they can be analyzed and transformed to verify the correctness\nof static and dynamic properties, to discover new properties, to deeply study a\nparticular domain of interest or to produce new equivalent and/or optimized\nversions of graph-based models.\n  The Graphs as Models (GaM) workshop series combines the strengths of two\npre-existing workshop series: GT-VMT (Graph Transformation and Visual Modelling\nTechniques) and GRAPHITE (Graph Inspection and Traversal Engineering), but also\nsolicits research from other related areas, such as social network analysis.\nGaM offers a platform for exchanging new ideas and results for active\nresearchers in these areas, with a particular aim of boosting inter- and\ntransdisciplinary research exploiting new applications of graphs as models in\nany area of computational science. This year (2017), the third edition of the\nGaM workshop was co-located with the European Joint Conferences on Theory and\nPractice of Software 2017 (ETAPS'17), held in Uppsala, Sweden.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 08:48:17 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Kehrer", "Timo", "", "Humboldt-University of Berlin"], ["Miller", "Alice", "", "University\n  of Glasgow"]]}, {"id": "1712.08526", "submitter": "Jurriaan Rot", "authors": "Damien Pous, Jurriaan Rot", "title": "Companions, Causality and Codensity", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (August 8,\n  2019) lmcs:5680", "doi": "10.23638/LMCS-15(3:14)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the context of abstract coinduction in complete lattices, the notion of\ncompatible function makes it possible to introduce enhancements of the\ncoinduction proof principle. The largest compatible function, called the\ncompanion, subsumes most enhancements and has been proved to enjoy many good\nproperties. Here we move to universal coalgebra, where the corresponding notion\nis that of a final distributive law. We show that when it exists, the final\ndistributive law is a monad, and that it coincides with the codensity monad of\nthe final sequence of the given functor. On sets, we moreover characterise this\ncodensity monad using a new abstract notion of causality. In particular, we\nrecover the fact that on streams, the functions definable by a distributive law\nor GSOS specification are precisely the causal functions. Going back to\nenhancements of the coinductive proof principle, we finally obtain that any\ncausal function gives rise to a valid up-to-context technique.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 15:39:14 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 18:42:47 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 15:51:59 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Pous", "Damien", ""], ["Rot", "Jurriaan", ""]]}, {"id": "1712.08809", "submitter": "Miguel Romero", "authors": "Miguel Romero", "title": "The tractability frontier of well-designed SPARQL queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of query evaluation of SPARQL queries. We focus on\nthe fundamental fragment of well-designed SPARQL restricted to the AND,\nOPTIONAL and UNION operators. Our main result is a structural characterisation\nof the classes of well-designed queries that can be evaluated in polynomial\ntime. In particular, we introduce a new notion of width called domination\nwidth, which relies on the well-known notion of treewidth. We show that, under\nsome complexity theoretic assumptions, the classes of well-designed queries\nthat can be evaluated in polynomial time are precisely those of bounded\ndomination width.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 17:23:08 GMT"}, {"version": "v2", "created": "Thu, 28 Dec 2017 15:28:25 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 09:56:52 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Romero", "Miguel", ""]]}, {"id": "1712.08858", "submitter": "Tom Hanika", "authors": "Tom Hanika and Jens Zumbr\\\"agel", "title": "Towards Collaborative Conceptual Exploration", "comments": "15 pages, 2 figures", "journal-ref": "Graph-Based Representation and Reasoning, 120-134, LNAI 10872,\n  Springer", "doi": "10.1007/978-3-319-91379-7_10", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In domains with high knowledge distribution a natural objective is to create\nprinciple foundations for collaborative interactive learning environments. We\npresent a first mathematical characterization of a collaborative learning\ngroup, a consortium, based on closure systems of attribute sets and the\nwell-known attribute exploration algorithm from formal concept analysis. To\nthis end, we introduce (weak) local experts for subdomains of a given knowledge\ndomain. These entities are able to refute and potentially accept a given\n(implicational) query for some closure system that is a restriction of the\nwhole domain. On this we build up a consortial expert and show first insights\nabout the ability of such an expert to answer queries. Furthermore, we depict\ntechniques on how to cope with falsely accepted implications and on combining\ncounterexamples. Using notions from combinatorial design theory we further\nexpand those insights as far as providing first results on the decidability\nproblem if a given consortium is able to explore some target domain.\nApplications in conceptual knowledge acquisition as well as in collaborative\ninteractive ontology learning are at hand.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 23:25:08 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 15:16:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hanika", "Tom", ""], ["Zumbr\u00e4gel", "Jens", ""]]}, {"id": "1712.08939", "submitter": "Sebastian Skritek", "authors": "Stefan Mengel, Sebastian Skritek", "title": "On tractable query evaluation for SPARQL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite much work within the last decade on foundational properties of SPARQL\n- the standard query language for RDF data - rather little is known about the\nexact limits of tractability for this language. In particular, this is the case\nfor SPARQL queries that contain the OPTIONAL-operator, even though it is one of\nthe most intensively studied features of SPARQL. The aim of our work is to\nprovide a more thorough picture of tractable classes of SPARQL queries.\n  In general, SPARQL query evaluation is PSPACE-complete in combined\ncomplexity, and it remains PSPACE-hard already for queries containing only the\nOPTIONAL-operator. To amend this situation, research has focused on\n\"well-designed SPARQL queries\" and their recent generalization \"weakly\nwell-designed SPARQL queries\". For these two fragments the evaluation problem\nis coNP-complete in the absence of projection and SigmaP2-complete otherwise.\nMoreover, they have been shown to contain most SPARQL queries asked in\npractical settings.\n  In this paper, we study tractable classes of weakly well-designed queries in\nparameterized complexity considering the equivalent formulation as pattern\ntrees. We give a complete characterization of the tractable classes in the case\nwithout projection. Moreover, we show a characterization of all tractable\nclasses of simple well-designed pattern trees in the presence of projection.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 15:40:08 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Mengel", "Stefan", ""], ["Skritek", "Sebastian", ""]]}, {"id": "1712.09288", "submitter": "EPTCS", "authors": "Robert Y. Lewis (Carnegie Mellon University)", "title": "An Extensible Ad Hoc Interface between Lean and Mathematica", "comments": "In Proceedings PxTP 2017, arXiv:1712.00898", "journal-ref": "EPTCS 262, 2017, pp. 23-37", "doi": "10.4204/EPTCS.262.4", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a user-extensible ad hoc connection between the Lean proof\nassistant and the computer algebra system Mathematica. By reflecting the syntax\nof each system in the other and providing a flexible interface for extending\ntranslation, our connection allows for the exchange of arbitrary information\nbetween the two systems. We show how to make use of the Lean metaprogramming\nframework to verify certain Mathematica computations, so that the rigor of the\nproof assistant is not compromised.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 05:47:47 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Lewis", "Robert Y.", "", "Carnegie Mellon University"]]}, {"id": "1712.09302", "submitter": "G. A. Kavvos", "authors": "G. A. Kavvos", "title": "On the Semantics of Intensionality and Intensional Recursion", "comments": "DPhil thesis, Department of Computer Science & St John's College,\n  University of Oxford", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensionality is a phenomenon that occurs in logic and computation. In the\nmost general sense, a function is intensional if it operates at a level finer\nthan (extensional) equality. This is a familiar setting for computer\nscientists, who often study different programs or processes that are\ninterchangeable, i.e. extensionally equal, even though they are not implemented\nin the same way, so intensionally distinct. Concomitant with intensionality is\nthe phenomenon of intensional recursion, which refers to the ability of a\nprogram to have access to its own code. In computability theory, intensional\nrecursion is enabled by Kleene's Second Recursion Theorem. This thesis is\nconcerned with the crafting of a logical toolkit through which these phenomena\ncan be studied. Our main contribution is a framework in which mathematical and\ncomputational constructions can be considered either extensionally, i.e. as\nabstract values, or intensionally, i.e. as fine-grained descriptions of their\nconstruction. Once this is achieved, it may be used to analyse intensional\nrecursion.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 16:29:51 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Kavvos", "G. A.", ""]]}, {"id": "1712.09402", "submitter": "Chun Tian", "authors": "Chun Tian", "title": "A Formalization of Unique Solutions of Equations in Process Algebra", "comments": "250 pages, Master degree thesis of Computer Science in University of\n  Bologna", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, a comprehensive formalization of Milner's Calculus of\nCommunicating Systems (also known as CCS) has been done in HOL theorem prover\n(HOL4), based on an old work in HOL88. This includes all classical properties\nof strong/weak bisimulation equivalences and observation congruence, a theory\nof congruence for CCS, various versions of \"bisimulation up to\" techniques, and\nseveral deep theorems, namely the \"coarsest congruence contained in weak\nequivalence\", and three versions of the \"unique solution of equations\" theorem\nin Milner's book.\n  This work is further extended to support recent developments in Concurrency\nTheory, namely the \"contraction\" relation and the related \"unique solutions of\ncontractions\" theorem found by Prof. Davide Sangiorgi, University of Bologna.\nAs a result, a rather complete theory of \"contraction\" (and a similar relation\ncalled \"expansion\") for CCS is also formalized in this thesis. Further more, a\nnew variant of contraction called \"observational contraction\" was found by the\nauthor during this work, based on existing contraction relation. It's formally\nproved that, this new relation is preserved by direct sums of CCS processes,\nand has a more elegant form of the \"unique solutions of contractions\" theorem\nwithout any restriction on the CCS grammar.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 21:33:40 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Tian", "Chun", ""]]}, {"id": "1712.09404", "submitter": "Attila Egri-Nagy", "authors": "Attila Egri-Nagy", "title": "The Algebraic View of Computation", "comments": "13 pages, final version will be published elsewhere", "journal-ref": "Philosophies 2018, 3(2), 15\n  https://doi.org/10.3390/philosophies3020015", "doi": "10.3390/philosophies3020015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that computation is an abstract algebraic concept, and a computer is\na result of a morphism (a structure preserving map) from a finite universal\nsemigroup.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 13:07:27 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Egri-Nagy", "Attila", ""]]}, {"id": "1712.09418", "submitter": "Daniel Neider", "authors": "Deepak D'Souza, P. Ezudheen, Pranav Garg, P. Madhusudan, Daniel Neider", "title": "Horn-ICE Learning for Synthesizing Invariants and Contracts", "comments": null, "journal-ref": null, "doi": "10.1145/3276501", "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design learning algorithms for synthesizing invariants using Horn\nimplication counterexamples (Horn-ICE), extending the ICE-learning model. In\nparticular, we describe a decision-tree learning algorithm that learns from\nHorn-ICE samples, works in polynomial time, and uses statistical heuristics to\nlearn small trees that satisfy the samples. Since most verification proofs can\nbe modeled using Horn clauses, Horn-ICE learning is a more robust technique to\nlearn inductive annotations that prove programs correct. Our experiments show\nthat an implementation of our algorithm is able to learn adequate inductive\ninvariants and contracts efficiently for a variety of sequential and concurrent\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 21:14:09 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["D'Souza", "Deepak", ""], ["Ezudheen", "P.", ""], ["Garg", "Pranav", ""], ["Madhusudan", "P.", ""], ["Neider", "Daniel", ""]]}, {"id": "1712.09495", "submitter": "EPTCS", "authors": "Fabio Zanasi (University College London)", "title": "Rewriting in Free Hypergraph Categories", "comments": "In Proceedings GaM 2017, arXiv:1712.08345", "journal-ref": "EPTCS 263, 2017, pp. 16-30", "doi": "10.4204/EPTCS.263.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study rewriting for equational theories in the context of symmetric\nmonoidal categories where there is a separable Frobenius monoid on each object.\nThese categories, also called hypergraph categories, are increasingly relevant:\nFrobenius structures recently appeared in cross-disciplinary applications,\nincluding the study of quantum processes, dynamical systems and natural\nlanguage processing. In this work we give a combinatorial characterisation of\narrows of a free hypergraph category as cospans of labelled hypergraphs and\nestablish a precise correspondence between rewriting modulo Frobenius structure\non the one hand and double-pushout rewriting of hypergraphs on the other. This\ninterpretation allows to use results on hypergraphs to ensure decidability of\nconfluence for rewriting in a free hypergraph category. Our results generalise\nprevious approaches where only categories generated by a single object (props)\nwere considered.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 05:15:21 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 10:07:31 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Zanasi", "Fabio", "", "University College London"]]}, {"id": "1712.09574", "submitter": "Thorsten Wissmann", "authors": "Sergey Goncharov, Lutz Schr\\\"oder, Christoph Rauch, Maciej Pir\\'og", "title": "Guarded and Unguarded Iteration for Generalized Processes", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (July 4,\n  2019) lmcs:5608", "doi": "10.23638/LMCS-15(3:1)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Models of iterated computation, such as (completely) iterative monads, often\ndepend on a notion of guardedness, which guarantees unique solvability of\nrecursive equations and requires roughly that recursive calls happen only under\ncertain guarding operations. On the other hand, many models of iteration do\nadmit unguarded iteration. Solutions are then no longer unique, and in general\nnot even determined as least or greatest fixpoints, being instead governed by\nquasi-equational axioms. Monads that support unguarded iteration in this sense\nare called (complete) Elgot monads. Here, we propose to equip (Kleisli\ncategories of) monads with an abstract notion of guardedness and then require\nsolvability of abstractly guarded recursive equations; examples of such\nabstractly guarded pre-iterative monads include both iterative monads and Elgot\nmonads, the latter by deeming any recursive definition to be abstractly\nguarded. Our main result is then that Elgot monads are precisely the\niteration-congruent retracts of abstractly guarded iterative monads, the latter\nbeing defined as admitting unique solutions of abstractly guarded recursive\nequations; in other words, models of unguarded iteration come about by\nquotienting models of guarded iteration.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 13:10:11 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 23:55:55 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 16:50:19 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 09:09:13 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Goncharov", "Sergey", ""], ["Schr\u00f6der", "Lutz", ""], ["Rauch", "Christoph", ""], ["Pir\u00f3g", "Maciej", ""]]}, {"id": "1712.09603", "submitter": "Christoph Rauch", "authors": "Stefano Berardi, Makoto Tatsuta", "title": "Classical System of Martin-Lof's Inductive Definitions is not Equivalent\n  to Cyclic Proofs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (August 1,\n  2019) lmcs:5661", "doi": "10.23638/LMCS-15(3:10)2019", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A cyclic proof system, called CLKID-omega, gives us another way of\nrepresenting inductive definitions and efficient proof search. The 2005 paper\nby Brotherston showed that the provability of CLKID-omega includes the\nprovability of LKID, first order classical logic with inductive definitions in\nMartin-L\\\"of's style, and conjectured the equivalence. The equivalence has been\nleft an open question since 2011. This paper shows that CLKID-omega and LKID\nare indeed not equivalent. This paper considers a statement called 2-Hydra in\nthese two systems with the first-order language formed by 0, the successor, the\nnatural number predicate, and a binary predicate symbol used to express\n2-Hydra. This paper shows that the 2-Hydra statement is provable in\nCLKID-omega, but the statement is not provable in LKID, by constructing some\nHenkin model where the statement is false.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 15:42:37 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 12:28:33 GMT"}, {"version": "v3", "created": "Sat, 23 Mar 2019 13:50:02 GMT"}, {"version": "v4", "created": "Fri, 26 Apr 2019 13:28:58 GMT"}, {"version": "v5", "created": "Wed, 31 Jul 2019 11:57:41 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Berardi", "Stefano", ""], ["Tatsuta", "Makoto", ""]]}, {"id": "1712.09687", "submitter": "Tim Rockt\\\"aschel", "authors": "Tim Rockt\\\"aschel", "title": "Combining Representation Learning with Logic for Language Processing", "comments": "PhD Thesis, University College London, Submitted and accepted in 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current state-of-the-art in many natural language processing and\nautomated knowledge base completion tasks is held by representation learning\nmethods which learn distributed vector representations of symbols via\ngradient-based optimization. They require little or no hand-crafted features,\nthus avoiding the need for most preprocessing steps and task-specific\nassumptions. However, in many cases representation learning requires a large\namount of annotated training data to generalize well to unseen data. Such\nlabeled training data is provided by human annotators who often use formal\nlogic as the language for specifying annotations. This thesis investigates\ndifferent combinations of representation learning methods with logic for\nreducing the need for annotated training data, and for improving\ngeneralization.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 21:09:36 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1712.10056", "submitter": "Karl Palmskog", "authors": "Edgar Pek, Pranav Garg, Muntasir Raihan Rahman, Karl Palmskog,\n  Indranil Gupta, P. Madhusudan", "title": "Inferring Formal Properties of Production Key-Value Stores", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Production distributed systems are challenging to formally verify, in\nparticular when they are based on distributed protocols that are not rigorously\ndescribed or fully understood. In this paper, we derive models and properties\nfor two core distributed protocols used in eventually consistent production\nkey-value stores such as Riak and Cassandra. We propose a novel modeling called\ncertified program models, where complete distributed systems are captured as\nprograms written in traditional systems languages such as concurrent C.\nSpecifically, we model the read-repair and hinted-handoff recovery protocols as\nconcurrent C programs, test them for conformance with real systems, and then\nverify that they guarantee eventual consistency, modeling precisely the\nspecification as well as the failure assumptions under which the results hold.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 20:58:46 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Pek", "Edgar", ""], ["Garg", "Pranav", ""], ["Rahman", "Muntasir Raihan", ""], ["Palmskog", "Karl", ""], ["Gupta", "Indranil", ""], ["Madhusudan", "P.", ""]]}, {"id": "1712.10213", "submitter": "Simon Foster", "authors": "Simon Foster, Ana Cavalcanti, Jim Woodcock, Frank Zeyda", "title": "Unifying Theories of Time with Generalised Reactive Processes", "comments": "7 pages, accepted for Information Processing Letters, 15th February\n  2018", "journal-ref": null, "doi": "10.1016/j.ipl.2018.02.017", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hoare and He's theory of reactive processes provides a unifying foundation\nfor the formal semantics of concurrent and reactive languages. Though highly\napplicable, their theory is limited to models that can express event histories\nas discrete sequences. In this paper, we show how their theory can be\ngeneralised by using an abstract trace algebra. We show how the algebra,\nnotably, allows us to also consider continuous-time traces and thereby\nfacilitate models of hybrid systems. We then use this algebra to reconstruct\nthe theory of reactive processes in our generic setting, and prove\ncharacteristic laws for sequential and parallel processes, all of which have\nbeen mechanically verified in the Isabelle/HOL proof assistant.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 13:09:25 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 11:25:48 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Foster", "Simon", ""], ["Cavalcanti", "Ana", ""], ["Woodcock", "Jim", ""], ["Zeyda", "Frank", ""]]}, {"id": "1712.10233", "submitter": "Simon Foster", "authors": "Simon Foster, Ana Cavalcanti, Samuel Canham, Jim Woodcock, Frank Zeyda", "title": "Unifying Theories of Reactive Design Contracts", "comments": "43 pages, accepted for publication in Theoretical Computer Science,\n  September 2019", "journal-ref": null, "doi": "10.1016/j.tcs.2019.09.017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design-by-contract is an important technique for model-based design in which\na composite system is specified by a collection of contracts that specify the\nbehavioural assumptions and guarantees of each component. In this paper, we\ndescribe a unifying theory for reactive design contracts that provides the\nbasis for modelling and verification of reactive systems. We provide a language\nfor expression and composition of contracts that is supported by a rich\ncalculational theory. In contrast with other semantic models in the literature,\nour theory of contracts allow us to specify both the evolution of state\nvariables and the permissible interactions with the environment. Moreover, our\nmodel of interaction is abstract, and supports, for instance, discrete time,\ncontinuous time, and hybrid computational models. Being based in Unifying\nTheories of Programming (UTP), our theory can be composed with further\ncomputational theories to support semantics for multi-paradigm languages.\nPractical reasoning support is provided via our proof framework, Isabelle/UTP,\nincluding a proof tactic that reduces a conjecture about a reactive program to\nthree predicates, symbolically characterising its assumptions and guarantees\nabout intermediate and final observations. This allows us to verify programs\nwith a large or infinite state space. Our work advances the state-of-the-art in\nsemantics for reactive languages, description of their contractual\nspecifications, and compositional verification.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 13:58:00 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 13:20:39 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Foster", "Simon", ""], ["Cavalcanti", "Ana", ""], ["Canham", "Samuel", ""], ["Woodcock", "Jim", ""], ["Zeyda", "Frank", ""]]}]