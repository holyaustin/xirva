[{"id": "1904.00058", "submitter": "Andrey Rivkin", "authors": "Marco Montali, Andrey Rivkin", "title": "From DB-nets to Coloured Petri Nets with Priorities (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced formalism of DB-nets has brought in a new conceptual\nway of modelling complex dynamic systems that equally account for the process\nand data dimensions, considering local data as well as persistent,\ntransactional data. DB-nets combine a coloured variant of Petri nets with name\ncreation and management (which we call nu-CPN), with a relational database. The\nintegration of these two components is realized by equipping the net with\nspecial ``view'' places that query the database and expose the resulting\nanswers to the net, with actions that allow transitions to update the content\nof the database, and with special arcs capturing compensation in case of\ntransaction failure. In this work, we study whether this sophisticated model\ncan be encoded back into nu-CPNs. In particular, we show that the meaningful\nfragment of DB-nets where database queries are expressed using unions of\nconjunctive queries with inequalities can be faithfully encoded into $\\nu$-CPNs\nwith transition priorities. This allows us to directly exploit state-of-the-art\ntechnologies such as CPN Tools to simulate and analyse this relevant class of\nDB-nets.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 19:11:42 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Montali", "Marco", ""], ["Rivkin", "Andrey", ""]]}, {"id": "1904.00189", "submitter": "Marie Fortin", "authors": "Marie Fortin", "title": "FO = FO3 for linear orders with monotone binary relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that over the class of linear orders with additional binary relations\nsatisfying some monotonicity conditions, monadic first-order logic has the\nthree-variable property. This generalizes (and gives a new proof of) several\nknown results, including the fact that monadic first-order logic has the\nthree-variable property over linear orders, as well as over (R,<,+1), and\nanswers some open questions mentioned in a paper from Antonopoulos, Hunter,\nRaza and Worrell [FoSSaCS 2015]. Our proof is based on a translation of monadic\nfirst-order logic formulas into formulas of a star-free variant of\nPropositional Dynamic Logic, which are in turn easily expressible in monadic\nfirst-order logic with three variables.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 10:01:33 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Fortin", "Marie", ""]]}, {"id": "1904.00195", "submitter": "Mantas Simkus", "authors": "Tomasz Gogacz, V\\'ictor Guti\\'errez-Basulto, Yazm\\'in A.\n  Ib\\'a\\~nez-Garc\\'ia, Filip Murlak, Magdalena Ortiz, Mantas \\v{S}imkus", "title": "Ontology Focusing: Knowledge-enriched Databases on Demand", "comments": "Manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework to facilitate the on-demand design of\ndata-centric systems by exploiting domain knowledge from an existing ontology.\nIts key ingredient is a process that we call focusing, which allows to obtain a\nschema for a (possibly knowledge-enriched) database semi-automatically, given\nan ontology and a specification of the scope of the desired system. We\nformalize the inputs and outputs of focusing, and identify relevant\ncomputational problems: finding a schema via focusing, testing its consistency,\nand answering queries in the knowledge-enriched databases it produces. These\ndefinitions are fully independent of the ontology language. We then instantiate\nthe framework using selected description logics as ontology languages, and\npopular classes of queries for specifying the scope of the system. For several\nrepresentative combinations, we study the decidability and complexity of the\nidentified computational problems. As a by-product, we isolate (and solve)\nvariants of classical decision problems in description logics, that are\ninteresting in their own right.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 10:39:57 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Gogacz", "Tomasz", ""], ["Guti\u00e9rrez-Basulto", "V\u00edctor", ""], ["Ib\u00e1\u00f1ez-Garc\u00eda", "Yazm\u00edn A.", ""], ["Murlak", "Filip", ""], ["Ortiz", "Magdalena", ""], ["\u0160imkus", "Mantas", ""]]}, {"id": "1904.00617", "submitter": "EPTCS", "authors": "Anders Schlichtkrull (Technical University of Denmark), J{\\o}rgen\n  Villadsen (Technical University of Denmark), Andreas Halkj{\\ae}r From\n  (Technical University of Denmark)", "title": "Students' Proof Assistant (SPA)", "comments": "In Proceedings ThEdu'18, arXiv:1903.12402", "journal-ref": "EPTCS 290, 2019, pp. 1-13", "doi": "10.4204/EPTCS.290.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Students' Proof Assistant (SPA) aims to both teach how to use a proof\nassistant like Isabelle and also to teach how reliable proof assistants are\nbuilt. Technically it is a miniature proof assistant inside the Isabelle proof\nassistant. In addition we conjecture that a good way to teach structured\nproving is with a concrete prover where the connection between semantics, proof\nsystem, and prover is clear. The proofs in Lamport's TLAPS proof assistant have\na very similar structure to those in the declarative prover SPA. To illustrate\nthis we compare a proof of Pelletier's problem 43 in TLAPS, Isabelle/Isar and\nSPA. We also consider Pelletier's problem 34, also known as Andrews's\nChallenge, where students are encouraged to develop their own justification\nfunction and thus obtain a lot of insight into the proof assistant. Although\nSPA is fully functional we have so far only used it in a few educational\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 07:52:18 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Schlichtkrull", "Anders", "", "Technical University of Denmark"], ["Villadsen", "J\u00f8rgen", "", "Technical University of Denmark"], ["From", "Andreas Halkj\u00e6r", "", "Technical University of Denmark"]]}, {"id": "1904.00618", "submitter": "EPTCS", "authors": "J{\\o}rgen Villadsen (Technical University of Denmark), Andreas\n  Halkj{\\ae}r From (Technical University of Denmark), Anders Schlichtkrull\n  (Technical University of Denmark)", "title": "Natural Deduction Assistant (NaDeA)", "comments": "In Proceedings ThEdu'18, arXiv:1903.12402", "journal-ref": "EPTCS 290, 2019, pp. 14-29", "doi": "10.4204/EPTCS.290.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Natural Deduction Assistant (NaDeA) and discuss its advantages\nand disadvantages as a tool for teaching logic. NaDeA is available online and\nis based on a formalization of natural deduction in the Isabelle proof\nassistant. We first provide concise formulations of the main formalization\nresults. We then elaborate on the prerequisites for NaDeA, in particular we\ndescribe a formalization in Isabelle of \"Hilbert's Axioms\" that we use as a\nstarting point in our bachelor course on mathematical logic. We discuss a\nrecent evaluation of NaDeA and also give an overview of the exercises in NaDeA.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 07:52:43 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Villadsen", "J\u00f8rgen", "", "Technical University of Denmark"], ["From", "Andreas Halkj\u00e6r", "", "Technical University of Denmark"], ["Schlichtkrull", "Anders", "", "Technical University of Denmark"]]}, {"id": "1904.00619", "submitter": "EPTCS", "authors": "Nuno Baeta (University of Coimbra), Pedro Quaresma (University of\n  Coimbra)", "title": "Towards Ranking Geometric Automated Theorem Provers", "comments": "In Proceedings ThEdu'18, arXiv:1903.12402", "journal-ref": "EPTCS 290, 2019, pp. 30-37", "doi": "10.4204/EPTCS.290.3", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of geometric automated theorem provers has a long and rich history,\nfrom the early AI approaches of the 1960s, synthetic provers, to today\nalgebraic and synthetic provers.\n  The geometry automated deduction area differs from other areas by the strong\nconnection between the axiomatic theories and its standard models. In many\ncases the geometric constructions are used to establish the theorems'\nstatements, geometric constructions are, in some provers, used to conduct the\nproof, used as counter-examples to close some branches of the automatic proof.\nSynthetic geometry proofs are done using geometric properties, proofs that can\nhave a visual counterpart in the supporting geometric construction.\n  With the growing use of geometry automatic deduction tools as applications in\nother areas, e.g. in education, the need to evaluate them, using different\ncriteria, is felt. Establishing a ranking among geometric automated theorem\nprovers will be useful for the improvement of the current\nmethods/implementations. Improvements could concern wider scope, better\nefficiency, proof readability and proof reliability.\n  To achieve the goal of being able to compare geometric automated theorem\nprovers a common test bench is needed: a common language to describe the\ngeometric problems; a comprehensive repository of geometric problems and a set\nof quality measures.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 07:53:09 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Baeta", "Nuno", "", "University of Coimbra"], ["Quaresma", "Pedro", "", "University of\n  Coimbra"]]}, {"id": "1904.00620", "submitter": "EPTCS", "authors": "Wolfgang Schreiner (Johannes Kepler University, Linz, Austria)", "title": "Theorem and Algorithm Checking for Courses on Logic and Formal Methods", "comments": "In Proceedings ThEdu'18, arXiv:1903.12402", "journal-ref": "EPTCS 290, 2019, pp. 56-75", "doi": "10.4204/EPTCS.290.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RISC Algorithm Language (RISCAL) is a language for the formal modeling of\ntheories and algorithms. A RISCAL specification describes an infinite class of\nmodels each of which has finite size; this allows to fully automatically check\nin such a model the validity of all theorems and the correctness of all\nalgorithms. RISCAL thus enables us to quickly verify/falsify the specific truth\nof propositions in sample instances of a model class before attempting to prove\ntheir general truth in the whole class: the first can be achieved in a fully\nautomatic way while the second typically requires our assistance. RISCAL has\nbeen mainly developed for educational purposes. To this end this paper reports\non some new enhancements of the tool: the automatic generation of checkable\nverification conditions from algorithms, the visualization of the execution of\nprocedures and the evaluation of formulas illustrating the computation of their\nresults, and the generation of Web-based student exercises and assignments from\nRISCAL specifications. Furthermore, we report on our first experience with\nRISCAL in the teaching of courses on logic and formal methods and on further\nplans to use this tool to enhance formal education.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 07:53:52 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Schreiner", "Wolfgang", "", "Johannes Kepler University, Linz, Austria"]]}, {"id": "1904.00827", "submitter": "Peter Dybjer", "authors": "Simon Castellan, Pierre Clairambault, and Peter Dybjer", "title": "Categories with Families: Unityped, Simply Typed, and Dependently Typed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the categorical logic of untyped, simply typed and dependently\ntyped lambda calculus can be structured around the notion of category with\nfamily (cwf). To this end we introduce subcategories of simply typed cwfs\n(scwfs), where types do not depend on variables, and unityped cwfs (ucwfs),\nwhere there is only one type. We prove several equivalence and biequivalence\ntheorems between cwf-based notions and basic notions of categorical logic, such\nas cartesian operads, Lawvere theories, categories with finite products and\nlimits, cartesian closed categories, and locally cartesian closed categories.\nSome of these theorems depend on the restrictions of contextuality (in the\nsense of Cartmell) or democracy (used by Clairambault and Dybjer for their\nbiequivalence theorems). Some theorems are equivalences between notions with\nstrict preservation of chosen structure. Others are biequivalences between\nnotions where properties are only preserved up to isomorphism. In addition to\nthis we discuss various constructions of initial ucwfs, scwfs, and cwfs with\nextra structure.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 13:12:25 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 12:45:46 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Castellan", "Simon", ""], ["Clairambault", "Pierre", ""], ["Dybjer", "Peter", ""]]}, {"id": "1904.00850", "submitter": "Miguel Romero", "authors": "Pablo Barcel\\'o, Diego Figueira, Miguel Romero", "title": "Boundedness of Conjunctive Regular Path Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DM cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the boundedness problem for unions of conjunctive regular path\nqueries with inverses (UC2RPQs). This is the problem of, given a UC2RPQ,\nchecking whether it is equivalent to a union of conjunctive queries (UCQ). We\nshow the problem to be ExpSpace-complete, thus coinciding with the complexity\nof containment for UC2RPQs. As a corollary, when a UC2RPQ is bounded, it is\nequivalent to a UCQ of at most triple-exponential size, and in fact we show\nthat this bound is optimal. We also study better behaved classes of UC2RPQs,\nnamely acyclic UC2RPQs of bounded thickness, and strongly connected UCRPQs,\nwhose boundedness problem are, respectively, PSpace-complete and\n$\\Pi^p_2$-complete. Most upper bounds exploit results on limitedness for\ndistance automata, in particular extending the model with alternation and\ntwo-wayness, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 13:47:58 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Barcel\u00f3", "Pablo", ""], ["Figueira", "Diego", ""], ["Romero", "Miguel", ""]]}, {"id": "1904.00934", "submitter": "Miguel Romero", "authors": "Pablo Barcel\\'o, Miguel Romero, Thomas Zeume", "title": "A More General Theory of Static Approximations for Conjunctive Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conjunctive query (CQ) evaluation is NP-complete, but becomes tractable for\nfragments of bounded hypertreewidth. Approximating a hard CQ by a query from\nsuch a fragment can thus allow for an efficient approximate evaluation. While\nunderapproximations (i.e., approximations that return correct answers only) are\nwell-understood, the dual notion of overapproximations (i.e, approximations\nthat return complete - but not necessarily sound - answers), and also a more\ngeneral notion of approximation based on the symmetric difference of query\nresults, are almost unexplored. In fact, the decidability of the basic problems\nof evaluation, identification, and existence of those approximations has been\nopen.\n  This article establishes a connection between overapproximations and\nexistential pebble games that allows for studying such problems systematically.\nBuilding on this connection, it is shown that the evaluation and identification\nproblem for overapproximations can be solved in polynomial time. While the\ngeneral existence problem remains open, the problem is shown to be decidable in\n2EXPTIME over the class of acyclic CQs and in PTIME for Boolean CQs over binary\nschemata. Additionally we propose a more liberal notion of overapproximations\nto remedy the known shortcoming that queries might not have an\noverapproximation, and study how queries can be overapproximated in the\npresence of tuple generating and equality generating dependencies.\n  The techniques are then extended to symmetric difference approximations and\nused to provide several complexity results for the identification, existence,\nand evaluation problem for this type of approximations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 16:12:04 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Barcel\u00f3", "Pablo", ""], ["Romero", "Miguel", ""], ["Zeume", "Thomas", ""]]}, {"id": "1904.00976", "submitter": "Florence Clerc", "authors": "Linan Chen, Florence Clerc and Prakash Panangaden", "title": "Bisimulation for Feller-Dynkin Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bisimulation is a concept that captures behavioural equivalence. It has been\nstudied extensively on nonprobabilistic systems and on discrete-time Markov\nprocesses and on so-called continuous-time Markov chains. In the latter time is\ncontinuous but the evolution still proceeds in jumps. We propose two\ndefinitions of bisimulation on continuous-time stochastic processes where the\nevolution is a \\emph{flow} through time. We show that they are equivalent and\nwe show that when restricted to discrete-time, our concept of bisimulation\nencompasses the standard discrete-time concept. The concept we introduce is not\na straightforward generalization of discrete-time concepts.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 17:27:17 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Chen", "Linan", ""], ["Clerc", "Florence", ""], ["Panangaden", "Prakash", ""]]}, {"id": "1904.01006", "submitter": "EPTCS", "authors": "Maximilian Dor\\'e (Ludwig Maximilian University Munich), Krysia Broda\n  (Imperial College London)", "title": "Towards Intuitive Reasoning in Axiomatic Geometry", "comments": "In Proceedings ThEdu'18, arXiv:1903.12402", "journal-ref": "EPTCS 290, 2019, pp. 38-55", "doi": "10.4204/EPTCS.290.4", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proving lemmas in synthetic geometry is often a time-consuming endeavour\nsince many intermediate lemmas need to be proven before interesting results can\nbe obtained. Improvements in automated theorem provers (ATP) in recent years\nnow mean they can prove many of these intermediate lemmas. The interactive\ntheorem prover Elfe accepts mathematical texts written in fair English and\nverifies them with the help of ATP. Geometrical texts can thereby easily be\nformalized in Elfe, leaving only the cornerstones of a proof to be derived by\nthe user. This allows for teaching axiomatic geometry to students without prior\nexperience in formalized mathematics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 07:53:27 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Dor\u00e9", "Maximilian", "", "Ludwig Maximilian University Munich"], ["Broda", "Krysia", "", "Imperial College London"]]}, {"id": "1904.01009", "submitter": "L\\'eon Gondelman", "authors": "Marko van Eekelen, Daniil Frumin, Herman Geuvers, L\\'eon Gondelman,\n  Robbert Krebbers, Marc Schoolderman, Sjaak Smetsers, Freek Verbeek, Beno\\^it\n  Viguier, Freek Wiedijk", "title": "A benchmark for C program verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present twenty-five C programs, as a benchmark for C program verification\nusing formal methods. This benchmark can be used for system demonstration, for\ncomparison of verification effort between systems, and as a friendly\ncompetition. For this last purpose, we give a scoring formula that allows a\nverification system to score up to a hundred points.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 12:07:40 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["van Eekelen", "Marko", ""], ["Frumin", "Daniil", ""], ["Geuvers", "Herman", ""], ["Gondelman", "L\u00e9on", ""], ["Krebbers", "Robbert", ""], ["Schoolderman", "Marc", ""], ["Smetsers", "Sjaak", ""], ["Verbeek", "Freek", ""], ["Viguier", "Beno\u00eet", ""], ["Wiedijk", "Freek", ""]]}, {"id": "1904.01079", "submitter": "Mikhail (Michael) Raskin", "authors": "Michael Raskin and Christoph Welzel", "title": "Working with first-order proofs and provers", "comments": "4 pages. Accepted at European Lisp Symposium 2019", "journal-ref": null, "doi": "10.5281/zenodo.2633990", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying software correctness has always been an important and complicated\ntask. Recently, formal proofs of critical properties of algorithms and even\nimplementations are becoming practical. Currently, the most powerful automated\nproof search tools use first-order logic while popular interactive proof\nassistants use higher-order logic.\n  We present our work-in-progress set of tools that aim to eventually provide a\nusable first-order logic computer-assisted proof environment.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 11:45:50 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 04:23:29 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Raskin", "Michael", ""], ["Welzel", "Christoph", ""]]}, {"id": "1904.01094", "submitter": "Ronny Tredup", "authors": "Ronny Tredup", "title": "Hardness Results for the Synthesis of $b$-bounded Petri Nets (Technical\n  Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesis for a type $\\tau$ of Petri nets is the following search problem:\nFor a transition system $A$, find a Petri net $N$ of type $\\tau$ whose state\ngraph is isomorphic to $A$, if there is one. To determine the computational\ncomplexity of synthesis for types of bounded Petri nets we investigate their\ncorresponding decision version, called feasibility. We show that feasibility is\nNP-complete for (pure) $b$-bounded P/T-nets if $b\\in \\mathbb{N}^+$. We extend\n(pure) $b$-bounded P/T-nets by the additive group $\\mathbb{Z}_{b+1}$ of\nintegers modulo $(b+1)$ and show feasibility to be NP-complete for the\nresulting type. To decide if $A$ has the event state separation property is\nshown to be NP-complete for (pure) $b$-bounded and group extended (pure)\n$b$-bounded P/T-nets. Deciding if $A$ has the state separation property is\nproven to be NP-complete for (pure) $b$-bounded P/T-nets.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 17:18:16 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Tredup", "Ronny", ""]]}, {"id": "1904.01117", "submitter": "Marcel Hark", "authors": "Marcel Hark, Benjamin Lucien Kaminski, J\\\"urgen Giesl, Joost-Pieter\n  Katoen", "title": "Aiming Low Is Harder -- Induction for Lower Bounds in Probabilistic\n  Program Verification", "comments": null, "journal-ref": null, "doi": "10.1145/3371105", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new inductive rule for verifying lower bounds on expected values\nof random variables after execution of probabilistic loops as well as on their\nexpected runtimes. Our rule is simple in the sense that loop body semantics\nneed to be applied only finitely often in order to verify that the candidates\nare indeed lower bounds. In particular, it is not necessary to find the limit\nof a sequence as in many previous rules.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 21:35:11 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 10:43:43 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Hark", "Marcel", ""], ["Kaminski", "Benjamin Lucien", ""], ["Giesl", "J\u00fcrgen", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1904.01290", "submitter": "EPTCS", "authors": "Klaas Pruiksma (Carnegie Mellon University), Frank Pfenning (Carnegie\n  Mellon University)", "title": "A Message-Passing Interpretation of Adjoint Logic", "comments": "In Proceedings PLACES 2019, arXiv:1904.00396", "journal-ref": "EPTCS 291, 2019, pp. 60-79", "doi": "10.4204/EPTCS.291.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system of session types based on adjoint logic which generalize\nstandard binary session types. Our system allows us to uniformly capture\nseveral new behaviors in the space of asynchronous message-passing\ncommunication, including multicast, where a process sends a single message to\nmultiple clients, replicable services, which have multiple clients and\nreplicate themselves on-demand to handle requests from those clients, and\ncancellation, where a process discards a channel without communicating along\nit. We provide session fidelity and deadlock-freedom results for this system,\nfrom which we then derive a logically justified form of garbage collection.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 08:47:53 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Pruiksma", "Klaas", "", "Carnegie Mellon University"], ["Pfenning", "Frank", "", "Carnegie\n  Mellon University"]]}, {"id": "1904.01407", "submitter": "Amanda Vidal", "authors": "Amanda Vidal", "title": "On Transitive modal many-valued logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper is focused on the study of modal logics defined from valued Kripke\nframes, and particularly, on computability and expressibility questions of\nmodal logics of transitive Kripke frames evaluated over certain residuated\nlattices. It is shown that a large family of those logics -- including the ones\narising from the standard MV and Product algebras -- yields an undecidable\nconsequence relation. Later on, the behaviour of transitive modal Lukasiewicz\nlogic is compared with that of its non transitive counterpart, exhibiting some\nparticulars concerning computability and equivalence with other logics. We\nconclude the article by showing the undecidability of the validity and the\nlocal SAT questions over transitive models when the Delta operation is added to\nthe logic.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 13:42:42 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Vidal", "Amanda", ""]]}, {"id": "1904.01431", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "Fundamentals of computability logic 2020", "comments": "arXiv admin note: substantial text overlap with arXiv:1612.04513;\n  text overlap with arXiv:1107.3706, arXiv:1107.2284 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is a semitutorial-style survey of computability logic. An\nextended online version of it is maintained at\nhttp://www.csc.villanova.edu/~japaridz/CL/ .\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 13:38:28 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 14:56:04 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 15:06:56 GMT"}, {"version": "v4", "created": "Sun, 1 Nov 2020 18:08:08 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "1904.01503", "submitter": "Sebastian Junges", "authors": "Tobias Winkler, Sebastian Junges, Guillermo A. P\\'erez, Joost-Pieter\n  Katoen", "title": "On the Complexity of Reachability in Parametric Markov Decision\n  Processes", "comments": "Full version with proofs, 42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies parametric Markov decision processes (pMDPs), an extension\nto Markov decision processes (MDPs) where transitions probabilities are\ndescribed by polynomials over a finite set of parameters. Fixing values for all\nparameters yields MDPs. In particular, this paper studies the complexity of\nfinding values for these parameters such that the induced MDP satisfies some\nreachability constraints. We discuss different variants depending on the\ncomparison operator in the constraints and the domain of the parameter values.\nWe improve all known lower bounds for this problem, and notably provide\nETR-completeness results for distinct variants of this problem. Furthermore, we\nprovide insights in the functions describing the induced reachability\nprobabilities, and how pMDPs generalise concurrent stochastic reachability\ngames.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:46:19 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Winkler", "Tobias", ""], ["Junges", "Sebastian", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1904.01677", "submitter": "Josef Urban", "authors": "Jan Jakub\\r{u}v and Josef Urban", "title": "Hammering Mizar by Learning Clause Guidance", "comments": "arXiv admin note: substantial text overlap with arXiv:1903.03182", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a very large improvement of existing hammer-style proof\nautomation over large ITP libraries by combining learning and theorem proving.\nIn particular, we have integrated state-of-the-art machine learners into the E\nautomated theorem prover, and developed methods that allow learning and\nefficient internal guidance of E over the whole Mizar library. The resulting\ntrained system improves the real-time performance of E on the Mizar library by\n70% in a single-strategy setting.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 21:36:40 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Jakub\u016fv", "Jan", ""], ["Urban", "Josef", ""]]}, {"id": "1904.01679", "submitter": "Robin Kaarsgaard", "authors": "Robin Kaarsgaard", "title": "Inversion, Iteration, and the Art of Dual Wielding", "comments": "Accepted for RC 2019", "journal-ref": null, "doi": "10.1007/978-3-030-21500-2_3", "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The humble $\\dagger$ (\"dagger\") is used to denote two different operations in\ncategory theory: Taking the adjoint of a morphism (in dagger categories) and\nfinding the least fixed point of a functional (in categories enriched in\ndomains). While these two operations are usually considered separately from one\nanother, the emergence of reversible notions of computation shows the need to\nconsider how the two ought to interact. In the present paper, we wield both of\nthese daggers at once and consider dagger categories enriched in domains. We\ndevelop a notion of a monotone dagger structure as a dagger structure that is\nwell behaved with respect to the enrichment, and show that such a structure\nleads to pleasant inversion properties of the fixed points that arise as a\nresult. Notably, such a structure guarantees the existence of fixed point\nadjoints, which we show are intimately related to the conjugates arising from a\ncanonical involutive monoidal structure in the enrichment. Finally, we relate\nthe results to applications in the design and semantics of reversible\nprogramming languages.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 21:42:30 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kaarsgaard", "Robin", ""]]}, {"id": "1904.02222", "submitter": "Maria Pittou", "authors": "Maria Pittou, George Rahonis", "title": "Architectures in parametric component-based systems: Qualitative and\n  quantitative modelling", "comments": "53 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key aspects in component-based design is specifying the software\narchitecture that characterizes the topology and the permissible interactions\nof the components of a system. To achieve well-founded design there is need to\naddress both the qualitative and non-functional aspects of architectures. In\nthis paper we study the qualitative and quantitative formal modelling of\narchitectures applied on parametric component-based systems, that consist of an\nunknown number of instances of each component. Specifically, we introduce an\nextended propositional interaction logic and investigate its first-order level\nwhich serves as a formal language for the interactions of parametric systems.\nOur logics achieve to encode the execution order of interactions, which is a\nmain feature in several important architectures, as well as to model recursive\ninteractions. Moreover, we prove the decidability of equivalence,\nsatisfiability, and validity of first-order extended interaction logic\nformulas, and provide several examples of formulas describing well-known\narchitectures. We show the robustness of our theory by effectively extending\nour results for parametric weighted architectures. For this, we study the\nweighted counterparts of our logics over a commutative semiring, and we apply\nthem for modelling the quantitative aspects of concrete architectures. Finally,\nwe prove that the equivalence problem of weighted first-order extended\ninteraction logic formulas is decidable in a large class of semirings, namely\nthe class (of subsemirings) of skew fields.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 20:05:41 GMT"}, {"version": "v10", "created": "Fri, 28 Feb 2020 18:43:37 GMT"}, {"version": "v11", "created": "Mon, 2 Mar 2020 19:45:37 GMT"}, {"version": "v12", "created": "Sat, 25 Apr 2020 09:33:01 GMT"}, {"version": "v13", "created": "Sat, 7 Nov 2020 00:33:14 GMT"}, {"version": "v14", "created": "Tue, 25 May 2021 18:57:30 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 14:09:39 GMT"}, {"version": "v3", "created": "Sat, 18 May 2019 23:26:47 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 20:35:53 GMT"}, {"version": "v5", "created": "Sun, 2 Feb 2020 18:10:33 GMT"}, {"version": "v6", "created": "Tue, 4 Feb 2020 20:59:04 GMT"}, {"version": "v7", "created": "Sun, 9 Feb 2020 20:46:46 GMT"}, {"version": "v8", "created": "Sat, 15 Feb 2020 18:53:09 GMT"}, {"version": "v9", "created": "Sat, 22 Feb 2020 10:19:07 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Pittou", "Maria", ""], ["Rahonis", "George", ""]]}, {"id": "1904.02501", "submitter": "Lucas Carvalho Cordeiro", "authors": "Mikhail R. Gadelha, Felipe R. Monteiro, Enrico Steffinlongo, Lucas C.\n  Cordeiro and Denis A. Nicole", "title": "Beyond k-induction: Learning from Counterexamples to Bidirectionally\n  Explore the State Space", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and evaluate a novel k-induction proof rule called bidirectional\nk-induction (bkind), which substantially improves the k-induction bug-finding\ncapabilities. Particularly, bkind exploits the counterexamples generated by the\nover-approximation step to derive new properties and feed them back to the\nbounded model checking procedure. We also combine an interval invariant\ngenerator and bkind to significantly improve the number of correct verification\nresults. Experimental results show that bkind can considerably reduce the\nverification time compared to the naive k-induction proof rule, since it only\nrequires half the number of steps to find a given safety property violation in\nan unsafe program. The bkind algorithm outperforms 2LS, another\nstate-of-the-art k-induction verifier, and produces more than twice correct\nproofs and about 35% more correct alarms than when analysing a large set of\npublic available benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 11:55:21 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Gadelha", "Mikhail R.", ""], ["Monteiro", "Felipe R.", ""], ["Steffinlongo", "Enrico", ""], ["Cordeiro", "Lucas C.", ""], ["Nicole", "Denis A.", ""]]}, {"id": "1904.02564", "submitter": "Antoine Amarilli", "authors": "Joachim Parrow, Johannes Borgstr\\\"om, Lars-Henrik Eriksson, Ram\\=unas\n  Forsberg Gutkovas, Tjark Weber", "title": "Modal Logics for Nominal Transition Systems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (January\n  28, 2021) lmcs:7137", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define a general notion of transition system where states and action\nlabels can be from arbitrary nominal sets, actions may bind names, and state\npredicates from an arbitrary logic define properties of states. A\nHennessy-Milner logic for these systems is introduced, and proved adequate and\nexpressively complete for bisimulation equivalence. A main technical novelty is\nthe use of finitely supported infinite conjunctions. We show how to treat\ndifferent bisimulation variants such as early, late, open and weak in a\nsystematic way, explore the folklore theorem that state predicates can be\nreplaced by actions, and make substantial comparisons with related work. The\nmain definitions and theorems have been formalised in Nominal Isabelle.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 14:11:42 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 15:33:10 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 09:44:32 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Parrow", "Joachim", ""], ["Borgstr\u00f6m", "Johannes", ""], ["Eriksson", "Lars-Henrik", ""], ["Gutkovas", "Ram\u016bnas Forsberg", ""], ["Weber", "Tjark", ""]]}, {"id": "1904.02729", "submitter": "William Farmer", "authors": "Jacques Carette and William M. Farmer", "title": "Towards Specifying Symbolic Computation", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interesting and useful symbolic computation algorithms manipulate\nmathematical expressions in mathematically meaningful ways. Although these\nalgorithms are commonplace in computer algebra systems, they can be\nsurprisingly difficult to specify in a formal logic since they involve an\ninterplay of syntax and semantics. In this paper we discuss several examples of\nsyntax-based mathematical algorithms, and we show how to specify them in a\nformal logic with undefinedness, quotation, and evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 18:09:27 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 16:43:12 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Carette", "Jacques", ""], ["Farmer", "William M.", ""]]}, {"id": "1904.02991", "submitter": "Albert Atserias", "authors": "Albert Atserias and Moritz M\\\"uller", "title": "Automating Resolution is NP-Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the problem of finding a Resolution refutation that is at most\npolynomially longer than a shortest one is NP-hard. In the parlance of proof\ncomplexity, Resolution is not automatizable unless P = NP. Indeed, we show it\nis NP-hard to distinguish between formulas that have Resolution refutations of\npolynomial length and those that do not have subexponential length refutations.\nThis also implies that Resolution is not automatizable in subexponential time\nor quasi-polynomial time unless NP is included in SUBEXP or QP, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 11:07:11 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 16:56:05 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Atserias", "Albert", ""], ["M\u00fcller", "Moritz", ""]]}, {"id": "1904.03214", "submitter": "Jakub Opr\\v{s}al", "authors": "Andrei Krokhin and Jakub Opr\\v{s}al", "title": "The complexity of 3-colouring $H$-colourable graphs", "comments": "To appear in FOCS 2019", "journal-ref": "Proc. 60th Ann. Symp. FOCS (2019) 1227-1239", "doi": "10.1109/FOCS.2019.00076", "report-no": null, "categories": "cs.CC cs.LO math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of approximation on satisfiable instances for graph\nhomomorphism problems. For a fixed graph $H$, the $H$-colouring problem is to\ndecide whether a given graph has a homomorphism to $H$. By a result of Hell and\nNe\\v{s}et\\v{r}il, this problem is NP-hard for any non-bipartite graph $H$. In\nthe context of promise constraint satisfaction problems, Brakensiek and\nGuruswami conjectured that this hardness result extends to promise graph\nhomomorphism as follows: fix any non-bipartite graph $H$ and another graph $G$\nwith a homomorphism from $H$ to $G$, it is NP-hard to find a homomorphism to\n$G$ from a given $H$-colourable graph. Arguably, the two most important special\ncases of this conjecture are when $H$ is fixed to be the complete graph on 3\nvertices (and $G$ is any graph with a triangle) and when $G$ is the complete\ngraph on 3 vertices (and $H$ is any 3-colourable graph). The former case is\nequivalent to the notoriously difficult approximate graph colouring problem. In\nthis paper, we confirm the Brakensiek-Guruswami conjecture for the latter case.\nOur proofs rely on a novel combination of the universal-algebraic approach to\npromise constraint satisfaction, that was recently developed by Barto, Bul\\'in\nand the authors, with some ideas from algebraic topology.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 18:14:32 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 10:11:05 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Krokhin", "Andrei", ""], ["Opr\u0161al", "Jakub", ""]]}, {"id": "1904.03241", "submitter": "Markus N Rabe", "authors": "Kshitij Bansal, Sarah M. Loos, Markus N. Rabe, Christian Szegedy, and\n  Stewart Wilcox", "title": "HOList: An Environment for Machine Learning of Higher-Order Theorem\n  Proving", "comments": "Accepted at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an environment, benchmark, and deep learning driven automated\ntheorem prover for higher-order logic. Higher-order interactive theorem provers\nenable the formalization of arbitrary mathematical theories and thereby present\nan interesting, open-ended challenge for deep learning. We provide an\nopen-source framework based on the HOL Light theorem prover that can be used as\na reinforcement learning environment. HOL Light comes with a broad coverage of\nbasic mathematical theorems on calculus and the formal proof of the Kepler\nconjecture, from which we derive a challenging benchmark for automated\nreasoning. We also present a deep reinforcement learning driven automated\ntheorem prover, DeepHOL, with strong initial results on this benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 19:04:33 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 00:08:20 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 20:16:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Bansal", "Kshitij", ""], ["Loos", "Sarah M.", ""], ["Rabe", "Markus N.", ""], ["Szegedy", "Christian", ""], ["Wilcox", "Stewart", ""]]}, {"id": "1904.03482", "submitter": "Jad Hamza", "authors": "Jad Hamza, Nicolas Voirol, Viktor Kun\\v{c}ak", "title": "System FR as Foundations for Stainless", "comments": null, "journal-ref": null, "doi": "10.1145/3360592", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design, implementation, and foundation of a verifier for\nhigher-order functional programs with generics and recursive data types. Our\nsystem supports proving safety and termination using preconditions,\npostconditions and assertions. It supports writing proof hints using assertions\nand recursive calls. To formalize the soundness of the system we introduce\nSystem FR, a calculus supporting System F polymorphism, dependent refinement\ntypes, and recursive types (including recursion through contravariant positions\nof function types). Through the use of sized types, System FR supports\nreasoning about termination of lazy data structures such as streams. We\nformalize a reducibility argument using the Coq proof assistant and prove the\nsoundness of a type-checker with respect to call-by-value semantics, ensuring\ntype safety and normalization for typeable programs. Our program verifier is\nimplemented as an alternative verification-condition generator for the\nStainless tool, which relies on existing SMT-based solver backend for\nautomation. We demonstrate the efficiency of our approach by verifying a\ncollection of higher-order functional programs comprising around 14000 lines of\npolymorphic higher-order Scala code, including graph search algorithms, basic\nnumber theory, monad laws, functional data structures, and assignments from\npopular Functional Programming MOOCs.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 16:02:24 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 07:40:00 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Hamza", "Jad", ""], ["Voirol", "Nicolas", ""], ["Kun\u010dak", "Viktor", ""]]}, {"id": "1904.03649", "submitter": "Irmak Sa\\u{g}lam", "authors": "Irmak Saglam, Ebru Aydin Gol", "title": "Cause Mining and Controller Synthesis with STL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal control of cyber-physical systems allows for synthesis of control\nstrategies from rich specifications such as temporal logics. However, the\nclasses of systems that the formal approaches can be applied to is limited due\nto the computational complexity. Furthermore, the synthesis problem becomes\neven harder when non-determinism or stochasticity is considered. In this work,\nwe propose an alternative approach. First, we mark the unwanted events on the\ntraces of the system and generate a controllable cause representing these\nevents as a Signal Temporal Logic (STL) formula. Then, we synthesize a\ncontroller based on this formula to avoid the satisfaction of it. Our approach\nis applicable to any system with finitely many control choices. While we can\nnot guarantee correctness, i.e., the unwanted events will never occur, we show\non an example that the proposed approach reduces the number of the unwanted\nevents. In particular, we validate it for the congestion avoidance problem in a\ntraffic network.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 13:16:29 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 14:34:06 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 16:33:49 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Saglam", "Irmak", ""], ["Gol", "Ebru Aydin", ""]]}, {"id": "1904.03671", "submitter": "Longchun Wang", "authors": "Longchun Wang and Qingguo Li", "title": "The categorical equivalence between disjunctive sequent calculi and\n  algebraic L-domains", "comments": "17pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a purely syntactic representation for the category of\nalgebraic L-domains with Scott-continuous functions as morphisms. The central\ntool used here is the notion of logical states, which builds a bridge between\ndisjunctive sequent calculi and algebraic L-domains. To capture\nScott-continuous functions between algebraic L-domains, the notion of\nconsequence relations between disjunctive sequent calculi is also introduced.\nIt is shown that the category of disjunctive sequent calculi with consequence\nrelations as morphisms is categorical equivalent to that of algebraic L-domains\nwith Scott-continuous functions as morphisms.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 15:29:12 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 12:26:47 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Wang", "Longchun", ""], ["Li", "Qingguo", ""]]}, {"id": "1904.03776", "submitter": "Peter Baumgartner", "authors": "Peter Baumgartner and Uwe Waldmann", "title": "Hierarchic Superposition Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of automated deduction require reasoning in first-order\nlogic modulo background theories, in particular some form of integer\narithmetic. A major unsolved research challenge is to design theorem provers\nthat are \"reasonably complete\" even in the presence of free function symbols\nranging into a background theory sort. The hierarchic superposition calculus of\nBachmair, Ganzinger, and Waldmann already supports such symbols, but, as we\ndemonstrate, not optimally. This paper aims to rectify the situation by\nintroducing a novel form of clause abstraction, a core component in the\nhierarchic superposition calculus for transforming clauses into a form needed\nfor internal operation. We argue for the benefits of the resulting calculus and\nprovide two new completeness results: one for the fragment where all\nbackground-sorted terms are ground and another one for a special case of linear\n(integer or rational) arithmetic as a background theory.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 23:45:28 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 00:08:03 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Baumgartner", "Peter", ""], ["Waldmann", "Uwe", ""]]}, {"id": "1904.03917", "submitter": "Krzysztof R. Apt", "authors": "Krzysztof R. Apt and Ernst-Ruediger Olderog", "title": "Fifty years of Hoare's Logic", "comments": "79 pages. To appear in Formal Aspects of Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a history of Hoare's logic.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 09:45:29 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 08:27:45 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Apt", "Krzysztof R.", ""], ["Olderog", "Ernst-Ruediger", ""]]}, {"id": "1904.03934", "submitter": "Robert Brijder", "authors": "Robert Brijder and Marc Gyssens and Jan Van den Bussche", "title": "On matrices and $K$-relations", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the matrix query language $\\mathsf{MATLANG}$ corresponds to a\nnatural fragment of the positive relational algebra on $K$-relations. The\nfragment is defined by introducing a composition operator and restricting\n$K$-relation arities to two. We then proceed to show that $\\mathsf{MATLANG}$\ncan express all matrix queries expressible in the positive relational algebra\non $K$-relations, when intermediate arities are restricted to three. Thus we\noffer an analogue, in a model with numerical data, to the situation in\nclassical logic, where the algebra of binary relations is equivalent to\nfirst-order logic with three variables.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 10:26:35 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Brijder", "Robert", ""], ["Gyssens", "Marc", ""], ["Bussche", "Jan Van den", ""]]}, {"id": "1904.04090", "submitter": "Thorsten Wissmann", "authors": "J. Leroux and M. Praveen and Ph. Schnoebelen and G. Sutre", "title": "On Functions Weakly Computable by Pushdown Petri Nets and Related\n  Systems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 4 (December\n  18, 2019) lmcs:5984", "doi": "10.23638/LMCS-15(4:15)2019", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider numerical functions weakly computable by grammar-controlled\nvector addition systems (GVASes, a variant of pushdown Petri nets). GVASes can\nweakly compute all fast growing functions $F_\\alpha$ for\n$\\alpha<\\omega^\\omega$, hence they are computationally more powerful than\nstandard vector addition systems. On the other hand they cannot weakly compute\nthe inverses $F_\\alpha^{-1}$ or indeed any sublinear function. The proof relies\non a pumping lemma for runs of GVASes that is of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 14:27:18 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 17:09:00 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 09:51:33 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Leroux", "J.", ""], ["Praveen", "M.", ""], ["Schnoebelen", "Ph.", ""], ["Sutre", "G.", ""]]}, {"id": "1904.04097", "submitter": "Taichi Uemura", "authors": "Taichi Uemura", "title": "A General Framework for the Semantics of Type Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an abstract notion of a type theory to unify the semantics of\nvarious type theories including Martin-L\\\"{o}f type theory, two-level type\ntheory and cubical type theory. We establish basic results in the semantics of\ntype theory: every type theory has a bi-initial model; every model of a type\ntheory has its internal language; the category of theories over a type theory\nis bi-equivalent to a full sub-2-category of the 2-category of models of the\ntype theory.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 14:37:59 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 10:26:13 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Uemura", "Taichi", ""]]}, {"id": "1904.04107", "submitter": "Arno Pauly", "authors": "Takayuki Kihara and Keng Meng Ng and Arno Pauly", "title": "Enumeration degrees and non-metrizable topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GN cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enumeration degrees of sets of natural numbers can be identified with the\ndegrees of difficulty of enumerating neighborhood bases of points in a\nuniversal second-countable $T_0$-space (e.g. the $\\omega$-power of the\nSierpi\\'nski space). Hence, every represented second-countable $T_0$-space\ndetermines a collection of enumeration degrees. For instance, Cantor space\ncaptures the total degrees, and the Hilbert cube captures the continuous\ndegrees by definition. Based on these observations, we utilize general topology\n(particularly non-metrizable topology) to establish a classification theory of\nenumeration degrees of sets of natural numbers.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 14:58:08 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 13:20:59 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Kihara", "Takayuki", ""], ["Ng", "Keng Meng", ""], ["Pauly", "Arno", ""]]}, {"id": "1904.04304", "submitter": "Robert Rand", "authors": "Robert Rand", "title": "Verification Logics for Quantum Programs", "comments": "Originally submitted in March 2016 as a qualifying examination\n  (WPE-II) for the PhD program at the University of Pennsylvania", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.ET cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey the landscape of Hoare logics for quantum programs. We review three\npapers: \"Reasoning about imperative quantum programs\" by Chadha, Mateus and\nSernadas; \"A logic for formal verification of quantum programs\" by Yoshihiko\nKakutani; and \"Floyd-hoare logic for quantum programs\" by Mingsheng Ying. We\ncompare the mathematical foundations of the logics, their underlying languages,\nand the expressivity of their assertions. We also use the languages to verify\nthe Deutsch-Jozsa Algorithm, and discuss their relative usability in practice.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 19:13:07 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Rand", "Robert", ""]]}, {"id": "1904.04442", "submitter": "Zhao Jin", "authors": "Zhao Jin, Hanpin Wang, Lei Zhang, Bowen Zhang, Kun Gao, Yongzhi Cao", "title": "Reasoning about Block-based Cloud Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the massive growth in the storage demands of big data, Cloud Storage\nSystems (CSSs) have been put forward to improve the storage capacity. Compared\nwith traditional storage systems, CSSs have lots of advantages, such as higher\ncapacity, lower cost, and easier scalability. But they are also with higher\ncomplexity. In order to ensure CSSs to be reliable, it is necessary to prove\nthe correctness of CSSs management programs. In fact, we are going to verify\nBlock-based Cloud Storage Systems (BCSSs), since BCSSs are the most popular\nCSSs.\n  In this paper, the correctness of management programs in BCSSs have been\nproven, and a verification framework based on separation logic is proposed to\nfinish the proven process. The main contributions are as follows. (1) A novel\nframework with two-tier heap structure is constructed to reflect the\ncharacteristics of BCSSs, and a modeling language is defined based on it. (2)\nAssertions based on separation logic is constructed to describe the properties\nof BCSSs. (3) The Hoare-style specifications are proposed to reason about the\nBCSSs. The results demonstrate that the correctness and reliability of BCSSs\ncan be verified by the above proposed methods. Furthermore, the proposed\nspecifications is sound in the application of reasoning about BCSSs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 03:19:00 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 05:23:49 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jin", "Zhao", ""], ["Wang", "Hanpin", ""], ["Zhang", "Lei", ""], ["Zhang", "Bowen", ""], ["Gao", "Kun", ""], ["Cao", "Yongzhi", ""]]}, {"id": "1904.04572", "submitter": "Emanuel Kieronski", "authors": "Emanuel Kieronski", "title": "One-dimensional guarded fragments", "comments": "Accepted for MFCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We call a first-order formula one-dimensional if its every maximal block of\nexistential (universal) quantifiers leaves at most one variable free. We\nconsider the one-dimensional restrictions of the guarded fragment, GF, and the\ntri-guarded fragment, TGF, the latter being a recent extension of GF in which\nquantification for subformulas with at most two free variables need not be\nguarded, and which thus may be seen as a unification of GF and the two-variable\nfragment, FO2. We denote the resulting formalisms, resp., GF1, and TGF1. We\nshow that GF1 has an exponential model property and NExpTime-complete\nsatisfiability problem (that is, it is easier than full GF). For TGF1 we show\nthat it is decidable, has the finite model property, and its satisfiability\nproblem is TwoExpTime-complete (NExpTime-complete in the absence of equality).\nAll the above-mentioned results are obtained for signatures with no constants.\nWe finally discuss the impact of their addition, observing that constants do\nnot spoil the decidability but increase the complexity of the satisfiability\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 10:04:13 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 08:56:18 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Kieronski", "Emanuel", ""]]}, {"id": "1904.05131", "submitter": "Lev Gordeev", "authors": "Lev Gordeev", "title": "Predicative proof theory of PDL and basic applications", "comments": "28 pages (incl. 2 appendices), talk at workshop Proods and\n  Computations 2018, HIM (Bonn)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional dynamic logic (PDL) is presented in Sch\\\"{u}tte-style mode as\none-sided semiformal tree-like sequent calculus Seq$_\\omega^{\\text{pdl}}$ with\nstandard cut rule and the omega-rule with principal formulas $\\left[ P^{\\ast\n}\\right] \\!A$. The omega-rule-free derivations in Seq$_{\\omega }^{\\text{pdl}}$\nare finite (trees) and sequents deducible by these finite derivations are valid\nin PDL. Moreover the cut-elimination theorem for Seq$_{\\omega}^{\\text{pdl}}$ is\nprovable in Peano Arithmetic (PA)extended by transfinite induction up to\nVeblen's ordinal $\\varphi_\\omega\\left( 0\\right) $. Hence (by the cutfree\nsubformula property) such predicative extension of PA proves that any given\n$\\left[ P^{\\ast }\\right] $-free sequent is valid in PDL iff it is deducible in\nSeq$_\\omega^{\\text{pdl}}$ by a finite cut- and omega-rule-free derivation,\nwhile PDL-validity of arbitrary star-free sequents is decidable in polynomial\nspace. The former also implies standard Herbrand-style conclusions, which\neventually leads to PSPACE-decidability of PDL-validity of $S$, provided that\n$P$ is atomic and $A$ is in a suitable \\emph{basic conjunctive normal form}.\nFurthermore we consider star-free formulas $A$ in dual \\emph{basic disjunctive\nnormal form}, and corresponding expansions $S=\\left\\langle P^{\\ast\n}\\right\\rangle \\!A\\vee Z$ whose PDL-validity problem is known to be\nEXPTIME-complete. We show that cutfree-derivability in\nSeq$_\\omega^{\\text{pdl}}$ (hence PDL-validity) of such $S$\\ is equivalent to\nplain validity of a suitable \"transparent\" quantified boolean formula\n$\\widehat{S}$. The whole proof can be formalized in PA extended by transfinite\ninduction along $\\varphi_\\omega\\left( 0\\right)$ -- actually in the\ncorresponding primitive recursive weakening, $\\mathbf{PRA}_{\\varphi_{\\omega\n}\\left( 0\\right)}$.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:49:41 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 11:46:27 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Gordeev", "Lev", ""]]}, {"id": "1904.05214", "submitter": "Siddhartha Gadgil", "authors": "Siddhartha Gadgil", "title": "Homogeneous length functions on Groups: Intertwined computer & human\n  proofs", "comments": "to appear in Journal of Automated Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.GR math.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a case of an interplay between human and computer proving which\nplayed a role in the discovery of an interesting mathematical result. The\nunusual feature of the use of computers here was that a computer generated but\nhuman readable proof was read, understood, generalized and abstracted by\nmathematicians to obtain the key lemma in an interesting mathematical result.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 14:35:03 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Gadgil", "Siddhartha", ""]]}, {"id": "1904.05621", "submitter": "Manuel Gieseking", "authors": "Manuel Gieseking and Ernst-R\\\"udiger Olderog", "title": "High-Level Representation of Benchmark Families for Petri Games", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Petri games have been introduced as a multi-player game model representing\ncausal memory to address the synthesis of distributed systems. For Petri games\nwith one environment player and an arbitrary bounded number of system players,\ndeciding the existence of a safety strategy is EXPTIME-complete. This result\nforms the basis of the tool ADAM that implements an algorithm for the synthesis\nof distributed controllers from Petri games. To evaluate the tool, it has been\nchecked on a series of parameterized benchmarks from manufacturing and workflow\nscenarios. In this paper, we introduce a new possibility to represent benchmark\nfamilies for the distributed synthesis problem modeled with Petri games. It\nenables the user to specify an entire benchmark family as one parameterized\nhigh-level net. We describe example benchmark families as a high-level version\nof a Petri game and exhibit an instantiation yielding a concrete 1-bounded\nPetri game. We identify improvements either regarding the size or the\nfunctionality of the benchmark families by examining the high-level Petri\ngames.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 10:56:10 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Gieseking", "Manuel", ""], ["Olderog", "Ernst-R\u00fcdiger", ""]]}, {"id": "1904.06107", "submitter": "Yasir Mahmood", "authors": "Yasir Mahmood and Arne Meier", "title": "Parametrised Complexity of Model Checking and Satisfiability in\n  Propositional Dependence Logic", "comments": "Update includes refined results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we initiate a systematic study of the parametrised complexity\nin the field of Dependence Logics which finds its origin in the Dependence\nLogic of V\\\"a\\\"an\\\"anen from 2007. We study a propositional variant of this\nlogic (PDL) and investigate a variety of parametrisations with respect to the\ncentral decision problems. The model checking problem (MC) of PDL is\nNP-complete. The subject of this research is to identify a list of\nparametrisations (formula-size, treewidth, treedepth, team-size, number of\nvariables) under which MC becomes fixed-parameter tractable. Furthermore, we\nshow that the number of disjunctions or the arity of dependence atoms\n(dep-arity) as a parameter both yield a paraNP-completeness result. Then, we\nconsider the satisfiability problem (SAT) showing a different picture: under\nteam-size, or dep-arity SAT is paraNP-complete whereas under all other\nmentioned parameters the problem is in FPT. Finally, we introduce a variant of\nthe satisfiability problem, asking for teams of a given size, and show for this\nproblem an almost complete picture.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 09:01:47 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 09:54:47 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mahmood", "Yasir", ""], ["Meier", "Arne", ""]]}, {"id": "1904.06152", "submitter": "Felipe R. Monteiro", "authors": "Felipe R. Monteiro, Mikhail R. Gadelha and Lucas C. Cordeiro", "title": "Boost the Impact of Continuous Formal Verification in Industry", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software model checking has experienced significant progress in the last two\ndecades, however, one of its major bottlenecks for practical applications\nremains its scalability and adaptability. Here, we describe an approach to\nintegrate software model checking techniques into the DevOps culture by\nexploiting practices such as continuous integration and regression tests. In\nparticular, our proposed approach looks at the modifications to the software\nsystem since its last verification, and submits them to a continuous formal\nverification process, guided by a set of regression test cases. Our vision is\nto focus on the developer in order to integrate formal verification techniques\ninto the developer workflow by using their main software development\nmethodologies and tools.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 10:47:24 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 21:56:20 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Monteiro", "Felipe R.", ""], ["Gadelha", "Mikhail R.", ""], ["Cordeiro", "Lucas C.", ""]]}, {"id": "1904.06159", "submitter": "EPTCS", "authors": "Thomas Ehrhard, Maribel Fern\\'andez, Valeria de Paiva, Lorenzo Tortora\n  de Falco", "title": "Proceedings Joint International Workshop on Linearity & Trends in Linear\n  Logic and Applications", "comments": null, "journal-ref": "EPTCS 292, 2019", "doi": "10.4204/EPTCS.292", "report-no": null, "categories": "cs.LO cs.CC cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a selection of papers presented at Linearity/TLLA 2018:\nJoint Linearity and TLLA workshops (part of FLOC 2018) held on July 7-8, 2018\nin Oxford. Linearity has been a key feature in several lines of research in\nboth theoretical and practical approaches to computer science. On the\ntheoretical side there is much work stemming from linear logic dealing with\nproof technology, complexity classes and more recently quantum computation. On\nthe practical side there is work on program analysis, expressive operational\nsemantics for programming languages, linear programming languages, program\ntransformation, update analysis and efficient implementation techniques. Linear\nlogic is not only a theoretical tool to analyse the use of resources in logic\nand computation. It is also a corpus of tools, approaches, and methodologies\n(proof nets, exponential decomposition, geometry of interaction, coherent\nspaces, relational models, etc.) that were originally developed for the study\nof linear logic's syntax and semantics and are nowadays applied in several\nother fields.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 11:29:34 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Ehrhard", "Thomas", ""], ["Fern\u00e1ndez", "Maribel", ""], ["de Paiva", "Valeria", ""], ["de Falco", "Lorenzo Tortora", ""]]}, {"id": "1904.06175", "submitter": "Titus Dose", "authors": "Titus Dose", "title": "P-Optimal Proof Systems for Each NP-Complete Set but no Complete\n  Disjoint NP-Pairs Relative to an Oracle", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.08571,\n  arXiv:1909.02839, arXiv:1903.11860", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pudl\\'ak [Pud17] lists several major conjectures from the field of proof\ncomplexity and asks for oracles that separate corresponding relativized\nconjectures. Among these conjectures are:\n  - $\\mathsf{DisjNP}$: The class of all disjoint NP-pairs does not have\nmany-one complete elements.\n  - $\\mathsf{SAT}$: NP does not contain many-one complete sets that have\nP-optimal proof systems.\n  - $\\mathsf{UP}$: UP does not have many-one complete problems.\n  - $\\mathsf{NP}\\cap\\mathsf{coNP}$: $\\text{NP}\\cap\\text{coNP}$ does not have\nmany-one complete problems.\n  As one answer to this question, we construct an oracle relative to which\n$\\mathsf{DisjNP}$, $\\neg \\mathsf{SAT}$, $\\mathsf{UP}$, and\n$\\mathsf{NP}\\cap\\mathsf{coNP}$ hold, i.e., there is no relativizable proof for\nthe implication $\\mathsf{DisjNP}\\wedge \\mathsf{UP}\\wedge\n\\mathsf{NP}\\cap\\mathsf{coNP}\\Rightarrow\\mathsf{SAT}$. In particular, regarding\nthe conjectures by Pudl\\'ak this extends a result by Khaniki [Kha19].\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 05:50:05 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 14:27:39 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 10:31:31 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2019 11:24:09 GMT"}, {"version": "v5", "created": "Mon, 2 Sep 2019 13:04:22 GMT"}, {"version": "v6", "created": "Fri, 13 Sep 2019 17:18:20 GMT"}, {"version": "v7", "created": "Thu, 9 Jan 2020 15:33:37 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Dose", "Titus", ""]]}, {"id": "1904.06227", "submitter": "Fan Yang", "authors": "Fan Yang", "title": "Axiomatizing first-order consequences in inclusion logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inclusion logic is a variant of dependence logic that was shown to have the\nsame expressive power as positive greatest fixed-point logic. Inclusion logic\nis not axiomatizable in full, but its first-order consequences can be\naxiomatized. In this paper, we provide such an explicit partial axiomatization\nby introducing a system of natural deduction for inclusion logic that is sound\nand complete for first-order consequences in inclusion logic.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 13:30:13 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 11:31:31 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yang", "Fan", ""]]}, {"id": "1904.06242", "submitter": "Sahar Mohajerani", "authors": "Sahar Mohajerani, Stephane Lafortune", "title": "Transforming opacity verification to nonblocking verification in modular\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the verification of current-state and K-step opacity for systems\nmodeled as interacting non-deterministic finite-state automata. We describe a\nnew methodology for compositional opacity verification that employs\nabstraction, in the form of a notion called opaque observation equivalence, and\nthat leverages existing compositional nonblocking verification algorithms. The\ncompositional approach is based on a transformation of the system, where the\ntransformed system is nonblocking if and only if the original one is\ncurrent-state opaque. Furthermore, we prove that $K$-step opacity can also be\ninferred if the transformed system is nonblocking. We provide experimental\nresults where current-state opacity is verified efficiently for a large\nscaled-up system.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 14:08:15 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 14:35:55 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Mohajerani", "Sahar", ""], ["Lafortune", "Stephane", ""]]}, {"id": "1904.06319", "submitter": "Robert Rand", "authors": "Kesha Hietala, Robert Rand, Shih-Han Hung, Xiaodi Wu, Michael Hicks", "title": "Verified Optimization in a Quantum Intermediate Representation", "comments": "Superceded by arXiv:1912.02250", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.ET cs.PL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present sqire, a low-level language for quantum computing and\nverification. sqire uses a global register of quantum bits, allowing easy\ncompilation to and from existing `quantum assembly' languages and simplifying\nthe verification process. We demonstrate the power of sqire as an intermediate\nrepresentation of quantum programs by verifying a number of useful\noptimizations, and we demonstrate sqire's use as a tool for general\nverification by proving several quantum programs correct.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 16:54:17 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 20:59:06 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 16:08:47 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2019 06:17:23 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Hietala", "Kesha", ""], ["Rand", "Robert", ""], ["Hung", "Shih-Han", ""], ["Wu", "Xiaodi", ""], ["Hicks", "Michael", ""]]}, {"id": "1904.06538", "submitter": "Marcelo Fiore", "authors": "Marcelo Fiore and Philip Saville", "title": "A type theory for cartesian closed bicategories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct an internal language for cartesian closed bicategories.\nPrecisely, we introduce a type theory modelling the structure of a cartesian\nclosed bicategory and show that its syntactic model satisfies an appropriate\nuniversal property, thereby lifting the Curry-Howard-Lambek correspondence to\nthe bicategorical setting. Our approach is principled and practical. Weak\nsubstitution structure is constructed using a bicategorification of the notion\nof abstract clone from universal algebra, and the rules for products and\nexponentials are synthesised from semantic considerations. The result is a type\ntheory that employs a novel combination of 2-dimensional type theory and\nexplicit substitution, and directly generalises the Simply-Typed Lambda\nCalculus. This work is the first step in a programme aimed at proving coherence\nfor cartesian closed bicategories.\n", "versions": [{"version": "v1", "created": "Sat, 13 Apr 2019 12:54:57 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Fiore", "Marcelo", ""], ["Saville", "Philip", ""]]}, {"id": "1904.06668", "submitter": "Shahar Maoz", "authors": "Shahar Maoz, Jan Oliver Ringert", "title": "Spectra: A Specification Language for Reactive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectra is a new specification language for reactive systems, specifically\ntailored for the context of reactive synthesis. The meaning of Spectra is\ndefined by a translation to a kernel language. Spectra comes with the Spectra\nTools, a set of analyses, including a synthesizer to obtain a\ncorrect-by-construction implementation, several means for executing the\nresulting controller, and additional analyses aimed at helping engineers write\nhigher-quality specifications. We present the language and give an overview of\nthe tool set.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 10:00:43 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Maoz", "Shahar", ""], ["Ringert", "Jan Oliver", ""]]}, {"id": "1904.06766", "submitter": "Peter Lindner", "authors": "Martin Grohe and Peter Lindner", "title": "Infinite Probabilistic Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic databases (PDBs) are used to model uncertainty in data in a\nquantitative way. In the standard formal framework, PDBs are finite probability\nspaces over relational database instances. It has been argued convincingly that\nthis is not compatible with an open world semantics (Ceylan et al., KR 2016)\nand with application scenarios that are modeled by continuous probability\ndistributions (Dalvi et al., CACM 2009).\n  We recently introduced a model of PDBs as infinite probability spaces that\naddresses these issues (Grohe and Lindner, PODS 2019). While that work was\nmainly concerned with countably infinite probability spaces, our focus here is\non uncountable spaces. Such an extension is necessary to model typical\ncontinuous probability distributions that appear in many applications. However,\nan extension beyond countable probability spaces raises nontrivial foundational\nissues concerned with the measurability of events and queries and ultimately\nwith the question whether queries have a well-defined semantics.\n  It turns out that so-called finite point processes are the appropriate model\nfrom probability theory for dealing with probabilistic databases. This model\nallows us to construct suitable (uncountable) probability spaces of database\ninstances in a systematic way. Our main technical results are measurability\nstatements for relational algebra queries as well as aggregate queries and\ndatalog queries.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 21:47:17 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 13:22:08 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 11:45:23 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Grohe", "Martin", ""], ["Lindner", "Peter", ""]]}, {"id": "1904.06782", "submitter": "Yoriyuki Yamagata", "authors": "Yoriyuki Yamagata", "title": "Separation of bounded arithmetic using a consistency statement", "comments": "Too many errors, The correctness proof of translation in Section 6.6\n  has a gap. Section 7 looks problematic", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proves Buss's hierarchy of bounded arithmetics $S^1_2 \\subseteq\nS^2_2 \\subseteq \\cdots \\subseteq S^i_2 \\subseteq \\cdots$ does not entirely\ncollapse. More precisely, we prove that, for a certain $D$, $S^1_2 \\subsetneq\nS^{2D+5}_2$ holds. Further, we can allow any finite set of true quantifier free\nformulas for the BASIC axioms of $S^1_2, S^2_2, \\ldots$. By Takeuti's argument,\nthis implies $\\mathrm{P} \\neq \\mathrm{NP}$. Let $\\mathbf{Ax}$ be a certain\nformulation of BASIC axioms. We prove that $S^1_2 \\not\\vdash\n\\mathrm{Con}(\\mathrm{PV}^-_1(D) + \\mathbf{Ax})$ for sufficiently large $D$,\nwhile $S^{2D+7}_2 \\vdash \\mathrm{Con}(\\mathrm{PV}^-_1(D) + \\mathbf{Ax})$ for a\nsystem $\\mathrm{PV}^-_1(D)$, a fragment of the system $\\mathrm{PV}^-_1$,\ninduction free first order extension of Cook's $\\mathrm{PV}$, of which proofs\ncontain only formulas with less than $D$ connectives. $S^1_2 \\not\\vdash\n\\mathrm{Con}(\\mathrm{PV}^-_1(D) + \\mathbf{Ax})$ is proved by straightforward\nadaption of the proof of $\\mathrm{PV} \\not\\vdash \\mathrm{Con}(\\mathrm{PV}^-)$\nby Buss and Ignjatovi\\'c. $S^{2D+5}_2 \\vdash \\mathrm{Con}(\\mathrm{PV}^-_1(D) +\n\\mathbf{Ax})$ is proved by $S^{2D+7}_2 \\vdash \\mathrm{Con}(\\mathrm{PV}^-_q(D+2)\n+ \\mathbf{Ax})$, where $\\mathrm{PV}^-_q$ is a quantifier-only extension of\n$\\mathrm{PV}^-$. The later statement is proved by an extension of a technique\nused for Yamagata's proof of $S^2_2 \\vdash \\mathrm{Con}(\\mathrm{PV}^-)$, in\nwhich a kind of satisfaction relation $\\mathrm{Sat}$ is defined. By extending\n$\\mathrm{Sat}$ to formulas with less than $D$-quantifiers, $S^{2D+3}_2 \\vdash\n\\mathrm{Con}(\\mathrm{PV}^-_q(D) + \\mathbf{Ax})$ is obtained in a\nstraightforward way.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 23:35:28 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 07:35:10 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Yamagata", "Yoriyuki", ""]]}, {"id": "1904.06844", "submitter": "EPTCS", "authors": "Iliano Cervesato (Carnegie Mellon University), Sharjeel Khan (Carnegie\n  Mellon University), Giselle Reis (Carnegie Mellon University), Dragi\\v{s}a\n  \\v{Z}uni\\'c (Carnegie Mellon University)", "title": "Formalization of Automated Trading Systems in a Concurrent Linear\n  Framework", "comments": "In Proceedings Linearity-TLLA 2018, arXiv:1904.06159", "journal-ref": "EPTCS 292, 2019, pp. 1-14", "doi": "10.4204/EPTCS.292.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a declarative and modular specification of an automated trading\nsystem (ATS) in the concurrent linear framework CLF. We implemented it in Celf,\na CLF type checker which also supports executing CLF specifications. We outline\nthe verification of two representative properties of trading systems using\ngenerative grammars, an approach to reasoning about CLF specifications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 05:15:13 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Cervesato", "Iliano", "", "Carnegie Mellon University"], ["Khan", "Sharjeel", "", "Carnegie\n  Mellon University"], ["Reis", "Giselle", "", "Carnegie Mellon University"], ["\u017duni\u0107", "Dragi\u0161a", "", "Carnegie Mellon University"]]}, {"id": "1904.06845", "submitter": "EPTCS", "authors": "Giulio Guerrieri (Dipartimento di Informatica -- Scienza e Ingegneria\n  (DISI), Universit\\`a di Bologna, Bologna, Italy), Giulio Manzonetto (LIPN,\n  UMR 7030, Universit\\'e Paris 13, Sorbonne Paris Cit\\'e, Villetaneuse, France)", "title": "The Bang Calculus and the Two Girard's Translations", "comments": "In Proceedings Linearity-TLLA 2018, arXiv:1904.06159", "journal-ref": "EPTCS 292, 2019, pp. 15-30", "doi": "10.4204/EPTCS.292.2", "report-no": null, "categories": "cs.LO cs.DM cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the two Girard's translations of intuitionistic implication into\nlinear logic by exploiting the bang calculus, a paradigmatic functional\nlanguage with an explicit box-operator that allows both call-by-name and\ncall-by-value lambda-calculi to be encoded in. We investigate how the bang\ncalculus subsumes both call-by-name and call-by-value lambda-calculi from a\nsyntactic and a semantic viewpoint.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 05:15:31 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Guerrieri", "Giulio", "", "Dipartimento di Informatica -- Scienza e Ingegneria"], ["Manzonetto", "Giulio", "", "LIPN,\n  UMR 7030, Universit\u00e9 Paris 13, Sorbonne Paris Cit\u00e9, Villetaneuse, France"]]}, {"id": "1904.06846", "submitter": "EPTCS", "authors": "Masahito Hasegawa (RIMS, Kyoto University)", "title": "From Linear Logic to Cyclic Sharing", "comments": "In Proceedings Linearity-TLLA 2018, arXiv:1904.06159", "journal-ref": "EPTCS 292, 2019, pp. 31-42", "doi": "10.4204/EPTCS.292.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a translation from Multiplicative Exponential Linear Logic to a\nsimply-typed lambda calculus with cyclic sharing. This translation is derived\nfrom a simple observation on the Int-construction on traced monoidal\ncategories. It turns out that the translation is a mixture of the call-by-name\nCPS translation and the Geometry of Interaction-based interpretation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 05:15:57 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Hasegawa", "Masahito", "", "RIMS, Kyoto University"]]}, {"id": "1904.06847", "submitter": "EPTCS", "authors": "Jiaming Jiang (North Carolina State University), Harley Eades III\n  (Augusta University), Valeria de Paiva (Nuance Communications)", "title": "On the Lambek Calculus with an Exchange Modality", "comments": "In Proceedings Linearity-TLLA 2018, arXiv:1904.06159", "journal-ref": "EPTCS 292, 2019, pp. 43-89", "doi": "10.4204/EPTCS.292.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Commutative/Non-Commutative Logic (CNC logic) and\ntwo categorical models for CNC logic. This work abstracts Benton's\nLinear/Non-Linear Logic by removing the existence of the exchange structural\nrule. One should view this logic as composed of two logics; one sitting to the\nleft of the other. On the left, there is intuitionistic linear logic, and on\nthe right is a mixed commutative/non-commutative formalization of the Lambek\ncalculus. Then both of these logics are connected via a pair of monoidal\nadjoint functors. An exchange modality is then derivable within the logic using\nthe adjunction between both sides. Thus, the adjoint functors allow one to pull\nthe exchange structural rule from the left side to the right side. We then give\na categorical model in terms of a monoidal adjunction, and then a concrete\nmodel in terms of dialectica Lambek spaces.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 05:16:15 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Jiang", "Jiaming", "", "North Carolina State University"], ["Eades", "Harley", "III", "Augusta University"], ["de Paiva", "Valeria", "", "Nuance Communications"]]}, {"id": "1904.06848", "submitter": "EPTCS", "authors": "Wen Kokke (University of Edinburgh), Fabrizio Montesi (University of\n  Southern Denmark), Marco Peressotti (University of Southern Denmark)", "title": "Taking Linear Logic Apart", "comments": "In Proceedings Linearity-TLLA 2018, arXiv:1904.06159", "journal-ref": "EPTCS 292, 2019, pp. 90-103", "doi": "10.4204/EPTCS.292.5", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process calculi based on logic, such as $\\pi$DILL and CP, provide a\nfoundation for deadlock-free concurrent programming. However, in previous work,\nthere is a mismatch between the rules for constructing proofs and the term\nconstructors of the $\\pi$-calculus: the fundamental operator for parallel\ncomposition does not correspond to any rule of linear logic. Kokke et al.\n(2019) introduced Hypersequent Classical Processes (HCP), which addresses this\nmismatch using hypersequents (collections of sequents) to register parallelism\nin the typing judgements. However, the step from CP to HCP is a big one. As of\nyet, HCP does not have reduction semantics, and the addition of delayed actions\nmeans that CP processes interpreted as HCP processes do not behave as they\nwould in CP. We introduce HCP-, a variant of HCP with reduction semantics and\nwithout delayed actions. We prove progress, preservation, and termination, and\nshow that HCP- supports the same communication protocols as CP.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 05:16:51 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Kokke", "Wen", "", "University of Edinburgh"], ["Montesi", "Fabrizio", "", "University of\n  Southern Denmark"], ["Peressotti", "Marco", "", "University of Southern Denmark"]]}, {"id": "1904.06849", "submitter": "EPTCS", "authors": "L\\^e Th\\`anh D\\~ung Nguyen (LIPN, Universit\\'e Paris 13), Thomas\n  Seiller (CNRS)", "title": "Coherent Interaction Graphs", "comments": "In Proceedings Linearity-TLLA 2018, arXiv:1904.06159", "journal-ref": "EPTCS 292, 2019, pp. 104-117", "doi": "10.4204/EPTCS.292.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of coherent graphs, and show how those can be used to\ndefine dynamic semantics for Multiplicative Linear Logic (MLL) extended with\nnon-determinism. Thanks to the use of a coherence relation rather than mere\nformal sums of non-deterministic possibilities, our model enjoys some\nfiniteness and sparsity properties. We also show how studying the semantic\ntypes generated by a single \"test\" within our model of MLL naturally gives rise\nto a notion of proof net, which turns out to be exactly Retor\\'e's\nR&B-cographs. This revisits the old idea that multplicative proof net\ncorrectness is interactive, with a twist: types are characterized not by a set\nof counter-proofs but by a single non-deterministic counter-proof.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 05:17:15 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Nguyen", "L\u00ea Th\u00e0nh D\u0169ng", "", "LIPN, Universit\u00e9 Paris 13"], ["Seiller", "Thomas", "", "CNRS"]]}, {"id": "1904.06850", "submitter": "EPTCS", "authors": "Carlos Olarte (UFRN), Valeria de Paiva (Nuance Communications), Elaine\n  Pimentel (UFRN), Giselle Reis (CMU-Qatar)", "title": "The ILLTP Library for Intuitionistic Linear Logic", "comments": "In Proceedings Linearity-TLLA 2018, arXiv:1904.06159", "journal-ref": "EPTCS 292, 2019, pp. 118-132", "doi": "10.4204/EPTCS.292.7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarking automated theorem proving (ATP) systems using standardized\nproblem sets is a well-established method for measuring their performance.\nHowever, the availability of such libraries for non-classical logics is very\nlimited. In this work we propose a library for benchmarking Girard's\n(propositional) intuitionistic linear logic. For a quick bootstrapping of the\ncollection of problems, and for discussing the selection of relevant problems\nand understanding their meaning as linear logic theorems, we use translations\nof the collection of Kleene's intuitionistic theorems in the traditional\nmonograph \"Introduction to Metamathematics\". We analyze four different\ntranslations of intuitionistic logic into linear logic and compare their proofs\nusing a linear logic based prover with focusing. In order to enhance the set of\nproblems in our library, we apply the three provability-preserving translations\nto the propositional benchmarks in the ILTP Library. Finally, we generate a\ncomprehensive set of reachability problems for Petri nets and encode such\nproblems as linear logic sequents, thus enlarging our collection of problems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 05:17:35 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Olarte", "Carlos", "", "UFRN"], ["de Paiva", "Valeria", "", "Nuance Communications"], ["Pimentel", "Elaine", "", "UFRN"], ["Reis", "Giselle", "", "CMU-Qatar"]]}, {"id": "1904.06919", "submitter": "Jean Christoph Jung", "authors": "Jean Christoph Jung, Fabio Papacchini, Frank Wolter, Michael\n  Zakharyaschev", "title": "Model Comparison Games for Horn Description Logics", "comments": "Full version of LICS'19 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Horn description logics are syntactically defined fragments of standard\ndescription logics that fall within the Horn fragment of first-order logic and\nfor which ontology-mediated query answering is in PTime for data complexity.\nThey were independently introduced in modal logic to capture the intersection\nof Horn first-order logic with modal logic. In this paper, we introduce model\ncomparison games for the basic Horn description logic hornALC (corresponding to\nthe basic Horn modal logic) and use them to obtain an Ehrenfeucht-Fra\\\"iss\\'e\ntype definability result and a van Benthem style expressive completeness result\nfor hornALC. We also establish a finite model theory version of the latter. The\nEhrenfeucht-Fra\\\"iss\\'e type definability result is used to show that checking\nhornALC indistinguishability of models is ExpTime-complete, which is in sharp\ncontrast to ALC indistinguishability (i.e., bisimulation equivalence) checkable\nin PTime. In addition, we explore the behavior of Horn fragments of more\nexpressive description and modal logics by defining a Horn guarded fragment of\nfirst-order logic and introducing model comparison games for it.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 09:17:01 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Jung", "Jean Christoph", ""], ["Papacchini", "Fabio", ""], ["Wolter", "Frank", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1904.06938", "submitter": "Bettina K\\\"onighofer", "authors": "Laura Humphrey, Bettina K\\\"onighofer, Robert K\\\"onighofer, Ufuk Topcu", "title": "Synthesis of Admissible Shields", "comments": null, "journal-ref": "Hardware and Software: Verification and Testing - 12th\n  International Haifa Verification Conference, {HVC} 2016, Haifa, Israel,\n  November 14-17, 2016, Proceedings", "doi": "10.1007/978-3-319-49052-6\\_9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shield synthesis is an approach to enforce a set of safety-critical\nproperties of a reactive system at runtime. A shield monitors the system and\ncorrects any erroneous output values instantaneously. The shield deviates from\nthe given outputs as little as it can and recovers to hand back control to the\nsystem as soon as possible. This paper takes its inspiration from a case study\non mission planning for unmanned aerial vehicles (UAVs) in which k-stabilizing\nshields, which guarantee recovery in a finite time, could not be constructed.\nWe introduce the notion of admissible shields, which improves k-stabilizing\nshields in two ways: (1) whereas k-stabilizing shields take an adversarial view\non the system, admissible shields take a collaborative view. That is, if there\nis no shield that guarantees recovery within k steps regardless of system\nbehavior, the admissible shield will attempt to work with the system to recover\nas soon as possible. (2) Admissible shields can handle system failures during\nthe recovery phase. In our experimental results we show that for UAVs, we can\ngenerate admissible shields, even when k-stabilizing shields do not exist.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 09:57:48 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Humphrey", "Laura", ""], ["K\u00f6nighofer", "Bettina", ""], ["K\u00f6nighofer", "Robert", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1904.06942", "submitter": "Benedikt Bollig", "authors": "Benedikt Bollig and Paul Gastin", "title": "Non-Sequential Theory of Distributed Systems", "comments": "lecture notes, 74 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These lecture notes cover basic automata-theoretic concepts and logical\nformalisms for the modeling and verification of concurrent and distributed\nsystems. Many of these concepts naturally extend the classical automata and\nlogics over words, which provide a framework for modeling sequential systems. A\ndistributed system, on the other hand, combines several (finite or recursive)\nprocesses, and will therefore be modeled as a collection of (finite or\npushdown, respectively) automata. A crucial parameter of a distributed system\nis the kind of interaction that is allowed between processes. In this lecture,\nwe focus on the message-passing paradigm. In general, communication in a\ndistributed system creates complex dependencies between events, which are\nhidden when using a sequential, operational semantics. The approach taken here\nis based on a faithful preservation of the dependencies of concurrent events.\nThat is, an execution of a system is modeled as a partial order, or graph,\nrather than a sequence of events.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 10:11:35 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Bollig", "Benedikt", ""], ["Gastin", "Paul", ""]]}, {"id": "1904.07136", "submitter": "Germ\\'an Andr\\'es Delbianco", "authors": "Aleksandar Nanevski and Anindya Banerjee and Germ\\'an Andr\\'es\n  Delbianco and Ignacio F\\'abregas", "title": "Specifying Concurrent Programs in Separation Logic: Morphisms and\n  Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In addition to pre- and postconditions, program specifications in recent\nseparation logics for concurrency have employed an algebraic structure of\nresources---a form of state transition system---to describe the state-based\nprogram invariants that must be preserved, and to record the permissible atomic\nchanges to program state. In this paper we introduce a novel notion of resource\nmorphism, i.e. structure-preserving function on resources, and show how to\neffectively integrate it into separation logic, using an associated notion of\nmorphism-specific simulation. We apply morphisms and simulations to programs\nverified under one resource, to compositionally adapt them to operate under\nanother resource, thus facilitating proof reuse.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 15:42:33 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 18:28:26 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 15:46:02 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Nanevski", "Aleksandar", ""], ["Banerjee", "Anindya", ""], ["Delbianco", "Germ\u00e1n Andr\u00e9s", ""], ["F\u00e1bregas", "Ignacio", ""]]}, {"id": "1904.07216", "submitter": "Sandra Kiefer", "authors": "Martin Grohe, Sandra Kiefer", "title": "A Linear Upper Bound on the Weisfeiler-Leman Dimension of Graphs of\n  Bounded Genus", "comments": "47 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Weisfeiler-Leman (WL) dimension of a graph is a measure for the inherent\ndescriptive complexity of the graph. While originally derived from a\ncombinatorial graph isomorphism test called the Weisfeiler-Leman algorithm, the\nWL dimension can also be characterised in terms of the number of variables that\nis required to describe the graph up to isomorphism in first-order logic with\ncounting quantifiers.\n  It is known that the WL dimension is upper-bounded for all graphs that\nexclude some fixed graph as a minor (Grohe, JACM 2012). However, the bounds\nthat can be derived from this general result are astronomic. Only recently, it\nwas proved that the WL dimension of planar graphs is at most 3 (Kiefer,\nPonomarenko, and Schweitzer, LICS 2017).\n  In this paper, we prove that the WL dimension of graphs embeddable in a\nsurface of Euler genus $g$ is at most $4g+3$. For the WL dimension of graphs\nembeddable in an orientable surface of Euler genus $g$, our approach yields an\nupper bound of $2g+3$.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 17:49:07 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Grohe", "Martin", ""], ["Kiefer", "Sandra", ""]]}, {"id": "1904.07313", "submitter": "Thorsten Wissmann", "authors": "Nicolas Behr, Vincent Danos and Ilias Garnier", "title": "Combinatorial Conversion and Moment Bisimulation for Stochastic\n  Rewriting Systems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (July 10,\n  2020) lmcs:6628", "doi": "10.23638/LMCS-16(3:3)2020", "report-no": null, "categories": "cs.LO cs.DM math-ph math.MP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a novel method to analyze the dynamics of stochastic rewriting\nsystems evolving over finitary adhesive, extensive categories. Our formalism is\nbased on the so-called rule algebra framework and exhibits an intimate\nrelationship between the combinatorics of the rewriting rules (as encoded in\nthe rule algebra) and the dynamics which these rules generate on observables\n(as encoded in the stochastic mechanics formalism). We introduce the concept of\ncombinatorial conversion, whereby under certain technical conditions the\nevolution equation for (the exponential generating function of) the statistical\nmoments of observables can be expressed as the action of certain differential\noperators on formal power series. This permits us to formulate the novel\nconcept of moment-bisimulation, whereby two dynamical systems are compared in\nterms of their evolution of sets of observables that are in bijection. In\nparticular, we exhibit non-trivial examples of graphical rewriting systems that\nare moment-bisimilar to certain discrete rewriting systems (such as branching\nprocesses or the larger class of stochastic chemical reaction systems). Our\nresults point towards applications of a vast number of existing\nwell-established exact and approximate analysis techniques developed for\nchemical reaction systems to the far richer class of general stochastic\nrewriting systems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 20:13:19 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 10:56:36 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 07:28:23 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Behr", "Nicolas", ""], ["Danos", "Vincent", ""], ["Garnier", "Ilias", ""]]}, {"id": "1904.07388", "submitter": "Stanislav Zivny", "authors": "Clement Carbonnel, Miguel Romero, Stanislav Zivny", "title": "Point-width and Max-CSPs", "comments": "Full version of a LICS'19 paper", "journal-ref": "ACM Transactions on Algorithms 16(4) Article no. 54 (2020)", "doi": "10.1145/3329862", "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of (unbounded-arity) Max-CSPs under structural restrictions is\npoorly understood. The two most general hypergraph properties known to ensure\ntractability of Max-CSPs, $\\beta$-acyclicity and bounded (incidence) MIM-width,\nare incomparable and lead to very different algorithms.\n  We introduce the framework of point decompositions for hypergraphs and use it\nto derive a new sufficient condition for the tractability of (structurally\nrestricted) Max-CSPs, which generalises both bounded MIM-width and\n\\b{eta}-acyclicity. On the way, we give a new characterisation of bounded\nMIM-width and discuss other hypergraph properties which are relevant to the\ncomplexity of Max-CSPs, such as $\\beta$-hypertreewidth.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 01:10:13 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 17:57:23 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Carbonnel", "Clement", ""], ["Romero", "Miguel", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1904.07415", "submitter": "Tristan Knoth", "authors": "Tristan Knoth, Di Wang, Nadia Polikarpova, Jan Hoffmann", "title": "Resource-Guided Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents resource-guided synthesis, a technique for synthesizing\nrecursive programs that satisfy both a functional specification and a symbolic\nresource bound. The technique is type-directed and rests upon a novel type\nsystem that combines polymorphic refinement types with potential annotations of\nautomatic amortized resource analysis. The type system enables efficient\nconstraint-based type checking and can express precise refinement-based\nresource bounds. The proof of type soundness shows that synthesized programs\nare correct by construction. By tightly integrating program exploration and\ntype checking, the synthesizer can leverage the user-provided resource bound to\nguide the search, eagerly rejecting incomplete programs that consume too many\nresources. An implementation in the resource-guided synthesizer ReSyn is used\nto evaluate the technique on a range of recursive data structure manipulations.\nThe experiments show that ReSyn synthesizes programs that are asymptotically\nmore efficient than those generated by a resource-agnostic synthesizer.\nMoreover, synthesis with ReSyn is faster than a naive combination of synthesis\nand resource analysis. ReSyn is also able to generate implementations that have\na constant resource consumption for fixed input sizes, which can be used to\nmitigate side-channel attacks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 02:34:47 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 02:31:37 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Knoth", "Tristan", ""], ["Wang", "Di", ""], ["Polikarpova", "Nadia", ""], ["Hoffmann", "Jan", ""]]}, {"id": "1904.07469", "submitter": "Bin Wen", "authors": "Bin Wen, Jianhou Gan, Juan L.G. Guirao, and Wei Gao", "title": "An extended description logic system with knowledge element based on ALC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of knowledge management and knowledge economy, the knowledge\nelements that directly link and embody the knowledge system have become the\nresearch focus and hotspot in certain areas. The existing knowledge element\nrepresentation methods are limited in functions to deal with the formality,\nlogic and reasoning. Based on description logic ALC and the common knowledge\nelement model, in order to describe the knowledge element, the description\nlogic ALC is expanded. The concept is extended to two diferent ones (that is,\nthe object knowledge element concept and the attribute knowledge element\nconcept). The relationship is extended to three (that is, relationship between\nobject knowledge element concept and attribute knowledge element concept,\nrelationship among object knowledge element concepts, relationship among\nattribute knowledge element concepts), and the inverse relationship constructor\nis added to propose a description logic KEDL system. By demonstrating, the\nrelevant properties, such as completeness, reliability,of the described logic\nsystem KEDL are obtained. Finally, it is verified by the example that the\ndescription logic KEDL system has strong knowledge element description ability.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 05:24:14 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Wen", "Bin", ""], ["Gan", "Jianhou", ""], ["Guirao", "Juan L. G.", ""], ["Gao", "Wei", ""]]}, {"id": "1904.07534", "submitter": "Samuel Balco", "authors": "Samuel Balco, Alexander Kurz", "title": "Nominal String Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce nominal string diagrams as, string diagrams internal in the\ncategory of nominal sets. This requires us to take nominal sets as a monoidal\ncategory, not with the cartesian product, but with the separated product. To\nthis end, we develop the beginnings of a theory of monoidal categories internal\nin a symmetric monoidal category. As an instance, we obtain a notion of a\nnominal PROP as a PROP internal in nominal sets. A 2-dimensional calculus of\nsimultaneous substitutions is an application.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 08:37:12 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Balco", "Samuel", ""], ["Kurz", "Alexander", ""]]}, {"id": "1904.07559", "submitter": "Giovanni Casini", "authors": "Katarina Britz, Giovanni Casini, Thomas Meyer, Kody Moodley, Uli\n  Sattler, Ivan Varzinczak", "title": "Theoretical Foundations of Defeasible Description Logics", "comments": "60 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend description logics (DLs) with non-monotonic reasoning features. We\nstart by investigating a notion of defeasible subsumption in the spirit of\ndefeasible conditionals as studied by Kraus, Lehmann and Magidor in the\npropositional case. In particular, we consider a natural and intuitive\nsemantics for defeasible subsumption, and investigate KLM-style syntactic\nproperties for both preferential and rational subsumption. Our contribution\nincludes two representation results linking our semantic constructions to the\nset of preferential and rational properties considered. Besides showing that\nour semantics is appropriate, these results pave the way for more effective\ndecision procedures for defeasible reasoning in DLs. Indeed, we also analyse\nthe problem of non-monotonic reasoning in DLs at the level of entailment and\npresent an algorithm for the computation of rational closure of a defeasible\nontology. Importantly, our algorithm relies completely on classical entailment\nand shows that the computational complexity of reasoning over defeasible\nontologies is no worse than that of reasoning in the underlying classical DL\nALC.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 09:44:56 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Britz", "Katarina", ""], ["Casini", "Giovanni", ""], ["Meyer", "Thomas", ""], ["Moodley", "Kody", ""], ["Sattler", "Uli", ""], ["Varzinczak", "Ivan", ""]]}, {"id": "1904.07668", "submitter": "Walid Belkhir", "authors": "Walid Belkhir and Nicolas Ratier and Duy Duc Nguyen and Michel\n  Lenczner", "title": "Unification and combination of iterative insertion strategies with\n  one-step traversals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by an ongoing project on the computer aided derivation of\nmultiscale partial differential equation models, we introduce a class of term\ntransformations that consists in navigation strategies and insertion of\ncontexts. We define a unification and combination operations on this class\nwhich enjoy nice algebraic properties like associativity, congruence, and the\nexistence of a neutral and an absorbing element. The main part of this paper is\ndevoted to proving that the unification and combination operations are correct.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 13:49:10 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Belkhir", "Walid", ""], ["Ratier", "Nicolas", ""], ["Nguyen", "Duy Duc", ""], ["Lenczner", "Michel", ""]]}, {"id": "1904.07691", "submitter": "Johannes Marti", "authors": "Sebastian Enqvist and Helle Hvid Hansen and Clemens Kupke and Johannes\n  Marti and Yde Venema", "title": "Completeness for Game Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game logic was introduced by Rohit Parikh in the 1980s as a generalisation of\npropositional dynamic logic (PDL) for reasoning about outcomes that players can\nforce in determined 2-player games. Semantically, the generalisation from\nprograms to games is mirrored by moving from Kripke models to monotone\nneighbourhood models. Parikh proposed a natural PDL-style Hilbert system which\nwas easily proved to be sound, but its completeness has thus far remained an\nopen problem.\n  In this paper, we introduce a cut-free sequent calculus for game logic, and\ntwo cut-free sequent calculi that manipulate annotated formulas, one for game\nlogic and one for the monotone mu-calculus, the variant of the polymodal\nmu-calculus where the semantics is given by monotone neighbourhood models\ninstead of Kripke structures. We show these systems are sound and complete, and\nthat completeness of Parikh's axiomatization follows. Our approach builds on\nrecent ideas and results by Afshari & Leigh (LICS 2017) in that we obtain\ncompleteness via a sequence of proof transformations between the systems. A\ncrucial ingredient is a validity-preserving translation from game logic to the\nmonotone mu-calculus.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 14:09:40 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 17:29:47 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Enqvist", "Sebastian", ""], ["Hansen", "Helle Hvid", ""], ["Kupke", "Clemens", ""], ["Marti", "Johannes", ""], ["Venema", "Yde", ""]]}, {"id": "1904.07736", "submitter": "Swen Jacobs", "authors": "Swen Jacobs and Roderick Bloem and Maximilien Colange and Peter\n  Faymonville and Bernd Finkbeiner and Ayrat Khalimov and Felix Klein and\n  Michael Luttenberger and Philipp J. Meyer and Thibaud Michaud and Mouhammad\n  Sakr and Salomon Sickert and Leander Tentrup and Adam Walker", "title": "The 5th Reactive Synthesis Competition (SYNTCOMP 2018): Benchmarks,\n  Participants & Results", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.11439,\n  arXiv:1609.00507", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the fifth reactive synthesis competition (SYNTCOMP 2018). We\nintroduce four new benchmark classes that have been added to the SYNTCOMP\nlibrary, and briefly describe the evaluation scheme and the experimental setup\nof SYNTCOMP 2018. We give an overview of the participants of SYNTCOMP 2018 and\nhighlight changes compared to previous years. Finally, we present and analyze\nthe results of our experimental evaluation, including a ranking of tools with\nrespect to quantity and quality of solutions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 09:36:53 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Jacobs", "Swen", ""], ["Bloem", "Roderick", ""], ["Colange", "Maximilien", ""], ["Faymonville", "Peter", ""], ["Finkbeiner", "Bernd", ""], ["Khalimov", "Ayrat", ""], ["Klein", "Felix", ""], ["Luttenberger", "Michael", ""], ["Meyer", "Philipp J.", ""], ["Michaud", "Thibaud", ""], ["Sakr", "Mouhammad", ""], ["Sickert", "Salomon", ""], ["Tentrup", "Leander", ""], ["Walker", "Adam", ""]]}, {"id": "1904.07828", "submitter": "Mert Ergurtuna", "authors": "Mert Ergurtuna, Ebru Aydin Gol", "title": "An Efficient Formula Synthesis Method with Past Signal Temporal Logic", "comments": "8 pages, 5 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel method to find temporal properties that lead\nto the unexpected behaviors from labeled dataset. We express these properties\nin past time Signal Temporal Logic (ptSTL). First, we present a novel approach\nfor finding parameters of a template ptSTL formula, which extends the results\non monotonicity based parameter synthesis. The proposed method optimizes a\ngiven monotone criteria while bounding an error. Then, we employ the parameter\nsynthesis method in an iterative unguided formula synthesis framework. In\nparticular, we combine optimized formulas iteratively to describe the causes of\nthe labeled events while bounding the error. We illustrate the proposed\nframework on two examples.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 17:12:24 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Ergurtuna", "Mert", ""], ["Gol", "Ebru Aydin", ""]]}, {"id": "1904.07984", "submitter": "Yong Kiam Tan", "authors": "Yong Kiam Tan and Andr\\'e Platzer", "title": "An Axiomatic Approach to Liveness for Differential Equations", "comments": "FM 2019: 23rd International Symposium on Formal Methods, Porto,\n  Portugal, October 9-11, 2019", "journal-ref": null, "doi": "10.1007/978-3-030-30942-8_23", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for deductive liveness verification for\nordinary differential equations (ODEs) with differential dynamic logic.\nNumerous subtleties complicate the generalization of well-known discrete\nliveness verification techniques, such as loop variants, to the continuous\nsetting. For example, ODE solutions may blow up in finite time or their\nprogress towards the goal may converge to zero. Our approach handles these\nsubtleties by successively refining ODE liveness properties using ODE\ninvariance properties which have a well-understood deductive proof theory. This\napproach is widely applicable: we survey several liveness arguments in the\nliterature and derive them all as special instances of our axiomatic refinement\napproach. We also correct several soundness errors in the surveyed arguments,\nwhich further highlights the subtlety of ODE liveness reasoning and the utility\nof our deductive approach. The library of common refinement steps identified\nthrough our approach enables both the sound development and justification of\nnew ODE liveness proof rules from our axioms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:58:36 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 18:00:03 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tan", "Yong Kiam", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "1904.08337", "submitter": "Emilio Tuosto", "authors": "Laura Bocchi and Hernan Melgratti and Emilio Tuosto", "title": "On Resolving Non-determinism in Choreographies", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (September\n  24, 2020) lmcs:6800", "doi": "10.23638/LMCS-16(3:18)2020", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Choreographies specify multiparty interactions via message passing. A\nrealisation of a choreography is a composition of independent processes that\nbehave as specified by the choreography. Existing relations of\ncorrectness/completeness between choreographies and realisations are based on\nmodels where choices are non-deterministic. Resolving non-deterministic choices\ninto deterministic choices (e.g., conditional statements) is necessary to\ncorrectly characterise the relationship between choreographies and their\nimplementations with concrete programming languages. We introduce a notion of\nrealisability for choreographies - called whole-spectrum implementation - where\nchoices are still non-deterministic in choreographies, but are deterministic in\ntheir implementations. Our notion of whole spectrum implementation rules out\ndeterministic implementations of roles that, no matter which context they are\nplaced in, will never follow one of the branches of a non-deterministic choice.\nWe give a type discipline for checking whole-spectrum implementations. As a\ncase study, we analyse the POP protocol under the lens of whole-spectrum\nimplementation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 16:03:30 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 14:23:44 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 10:14:47 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 20:26:20 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Bocchi", "Laura", ""], ["Melgratti", "Hernan", ""], ["Tuosto", "Emilio", ""]]}, {"id": "1904.08357", "submitter": "EPTCS", "authors": "Nicolas Behr (Universit\\'e de Paris, IRIF, CNRS)", "title": "Sesqui-Pushout Rewriting: Concurrency, Associativity and Rule Algebra\n  Framework", "comments": "In Proceedings GCM 2019, arXiv:1912.08966", "journal-ref": "EPTCS 309, 2019, pp. 23-52", "doi": "10.4204/EPTCS.309.2", "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sesqui-pushout (SqPO) rewriting is a variant of transformations of graph-like\nand other types of structures that fit into the framework of adhesive\ncategories where deletion in unknown context may be implemented. We provide the\nfirst account of a concurrency theorem for this important type of rewriting,\nand we demonstrate the additional mathematical property of a form of\nassociativity for these theories. Associativity may then be exploited to\nconstruct so-called rule algebras (of SqPO type), based upon which in\nparticular a universal framework of continuous-time Markov chains for\nstochastic SqPO rewriting systems may be realized.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 16:50:11 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 01:39:48 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Behr", "Nicolas", "", "Universit\u00e9 de Paris, IRIF, CNRS"]]}, {"id": "1904.08402", "submitter": "Dmitry Chistikov", "authors": "Dmitry Chistikov and Mikhail Vyalyi", "title": "Re-pairing brackets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following one-player game. Take a well-formed sequence of\nopening and closing brackets. As a move, the player can pair any opening\nbracket with any closing bracket to its right, erasing them. The goal is to\nre-pair (erase) the entire sequence, and the complexity of a strategy is\nmeasured by its width: the maximum number of nonempty segments of symbols\n(separated by blank space) seen during the play.\n  For various initial sequences, we prove upper and lower bounds on the minimum\nwidth sufficient for re-pairing. (In particular, the sequence associated with\nthe complete binary tree of height $n$ admits a strategy of width\nsub-exponential in $\\log n$.) Our two key contributions are (1) lower bounds on\nthe width and (2) their application in automata theory: quasi-polynomial lower\nbounds on the translation from one-counter automata to Parikh-equivalent\nnondeterministic finite automata. The latter result answers a question by Atig\net al. (2016).\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:57:41 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Chistikov", "Dmitry", ""], ["Vyalyi", "Mikhail", ""]]}, {"id": "1904.08468", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Towards Evolutionary Theorem Proving for Isabelle/HOL", "comments": "2 pages, This is a pre-print of our poster-only paper accepted at\n  GECCO'19. For the final version, please visit the corresponding ACM website", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mechanized theorem proving is becoming the basis of reliable systems\nprogramming and rigorous mathematics. Despite decades of progress in proof\nautomation, writing mechanized proofs still requires engineers' expertise and\nremains labor intensive. Recently, researchers have extracted heuristics of\ninteractive proof development from existing large proof corpora using\nsupervised learning. However, such existing proof corpora present only one way\nof proving conjectures, while there are often multiple equivalently effective\nways to prove one conjecture. In this abstract, we identify challenges in\ndiscovering heuristics for automatic proof search and propose our novel\napproach to improve heuristics of automatic proof search in Isabelle/HOL using\nevolutionary computation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 19:37:28 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "1904.08562", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling, Carlo Angiuli, Daniel Gratzer", "title": "Cubical Syntax for Reflection-Free Extensional Equality", "comments": "Extended version; International Conference on Formal Structures for\n  Computation and Deduction (FSCD), 2019", "journal-ref": null, "doi": "10.4230/LIPIcs.FSCD.2019.31", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We contribute XTT, a cubical reconstruction of Observational Type Theory\nwhich extends Martin-L\\\"of's intensional type theory with a dependent equality\ntype that enjoys function extensionality and a judgmental version of the\nunicity of identity types principle (UIP): any two elements of the same\nequality type are judgmentally equal. Moreover, we conjecture that the typing\nrelation can be decided in a practical way. In this paper, we establish an\nalgebraic canonicity theorem using a novel cubical extension (independently\nproposed by Awodey) of the logical families or categorical gluing argument\ninspired by Coquand and Shulman: every closed element of boolean type is\nderivably equal to either 'true' or 'false'.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 01:52:13 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 19:43:41 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sterling", "Jonathan", ""], ["Angiuli", "Carlo", ""], ["Gratzer", "Daniel", ""]]}, {"id": "1904.08590", "submitter": "Sayan Mukherjee", "authors": "Paul Gastin, Sayan Mukherjee, B Srivathsan", "title": "Fast algorithms for handling diagonal constraints in timed automata", "comments": "Shorter version of this article to appear in CAV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular method for solving reachability in timed automata proceeds by\nenumerating reachable sets of valuations represented as zones. A na\\\"ive\nenumeration of zones does not terminate. Various termination mechanisms have\nbeen studied over the years. Coming up with efficient termination mechanisms\nhas been remarkably more challenging when the automaton has diagonal\nconstraints in guards.\n  In this paper, we propose a new termination mechanism for timed automata with\ndiagonal constraints based on a new simulation relation between zones.\nExperiments with an implementation of this simulation show significant gains\nover existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 04:37:59 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Gastin", "Paul", ""], ["Mukherjee", "Sayan", ""], ["Srivathsan", "B", ""]]}, {"id": "1904.08641", "submitter": "Sebastian Biewer", "authors": "Sebastian Biewer and Pedro D'Argenio and Holger Hermanns", "title": "Doping Tests for Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The software running in embedded or cyber-physical systems (CPS) is typically\nof proprietary nature, so users do not know precisely what the systems they own\nare (in)capable of doing. Most malfunctionings of such systems are not intended\nby the manufacturer, but some are, which means these cannot be classified as\nbugs or security loopholes. The most prominent examples have become public in\nthe diesel emissions scandal, where millions of cars were found to be equipped\nwith software violating the law, altogether polluting the environment and\nputting human health at risk. The behaviour of the software embedded in these\ncars was intended by the manufacturer, but it was not in the interest of\nsociety, a phenomenon that has been called software doping. Doped software is\nsignificantly different from buggy or insecure software and hence it is not\npossible to use classical verification and testing techniques to discover and\nmitigate software doping.\n  The work presented in this paper builds on existing definitions of software\ndoping and lays the theoretical foundations for conducting software doping\ntests, so as to enable attacking evil manufacturers. The complex nature of\nsoftware doping makes it very hard to effectuate doping tests in practice. We\nexplain the biggest challenges and provide efficient solutions to realise\ndoping tests despite this complexity.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 08:54:48 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Biewer", "Sebastian", ""], ["D'Argenio", "Pedro", ""], ["Hermanns", "Holger", ""]]}, {"id": "1904.08751", "submitter": "EPTCS", "authors": "Walther Neuper (Graz University of Technology)", "title": "Technologies for \"Complete, Transparent & Interactive Models of Math\" in\n  Education", "comments": "In Proceedings ThEdu'18, arXiv:1903.12402", "journal-ref": "EPTCS 290, 2019, pp. 76-95", "doi": "10.4204/EPTCS.290.6", "report-no": null, "categories": "math.HO cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new generation of educational mathematics software is being shaped in ThEdu\nand other academic communities on the side of computer mathematics. Respective\nconcepts and technologies have been clarified to an extent, which calls for\ncooperation with educational sciences in order to optimise the new generation's\nimpact on educational practice. The paper addresses educational scientists who\nwant to examine specific software features and estimate respective effects in\nSTEM education at universities and subsequently at high-school. The key\nfeatures are characterised as a \"complete, transparent and interactive model of\nmathematics\", which offers interactive experience in all relevant aspects in\ndoing mathematics. Interaction uses several layers of formal languages: the\nlanguage of terms, of specifications, of proofs and of program language, which\nare connected by Lucas-Interpretation providing \"next-step-guidance\" as well as\nproviding prover power to check user input. So this paper is structured from\nthe point of view of computer mathematics and thus cannot give a serious\ndescription of effects on educational practice -- this is up to collaboration\nwith educational science; such collaboration is prepared by a series of\nquestions, some of which are biased towards software usability (and mainly to\nbe solved by computer mathematicians) and some of which are biased towards\ngenuine research in educational sciences.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 07:54:15 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Neuper", "Walther", "", "Graz University of Technology"]]}, {"id": "1904.08785", "submitter": "Alejandro D\\'iaz-Caro", "authors": "Alejandro D\\'iaz-Caro, Mauricio Guillermo, Alexandre Miquel, Beno\\^it\n  Valiron", "title": "Realizability in the Unitary Sphere", "comments": "28 pages", "journal-ref": "Proceedings of the 34th Annual ACM/IEEE Symposium on Logic in\n  Computer Science (LICS 2019)", "doi": "10.1109/LICS.2019.8785834", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a semantics for a linear algebraic lambda-calculus\nbased on realizability. This semantics characterizes a notion of unitarity in\nthe system, answering a long standing issue. We derive from the semantics a set\nof typing rules for a simply-typed linear algebraic lambda-calculus, and show\nhow it extends both to classical and quantum lambda-calculi.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 13:48:20 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["D\u00edaz-Caro", "Alejandro", ""], ["Guillermo", "Mauricio", ""], ["Miquel", "Alexandre", ""], ["Valiron", "Beno\u00eet", ""]]}, {"id": "1904.08843", "submitter": "Niels Voorneveld", "authors": "Alex Simpson and Niels Voorneveld", "title": "Behavioural Equivalence via Modalities for Algebraic Effects", "comments": "Journal version, submitted to ACM Transactions on Programming\n  Languages and Systems (TOPLAS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates behavioural equivalence between programs in a\ncall-by-value functional language extended with a signature of (algebraic)\neffect-triggering operations. Two programs are considered as being\nbehaviourally equivalent if they enjoy the same behavioural properties. To\nformulate this, we define a logic whose formulas specify behavioural\nproperties. A crucial ingredient is a collection of modalities expressing\neffect-specific aspects of behaviour. We give a general theory of such\nmodalities. If two conditions, openness and decomposability, are satisfied by\nthe modalities then the logically specified behavioural equivalence coincides\nwith a modality-defined notion of applicative bisimilarity, which can be proven\nto be a congruence by a generalisation of Howe's method. We show that the\nopenness and decomposability conditions hold for several examples of algebraic\neffects: nondeterminism, probabilistic choice, global store and input/output.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 15:26:47 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 11:07:25 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 13:17:07 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Simpson", "Alex", ""], ["Voorneveld", "Niels", ""]]}, {"id": "1904.08847", "submitter": "Ezio Bartocci", "authors": "Ezio Bartocci, Luca Bortolussi, Michele Loreti, Laura Nenzi", "title": "Monitoring Mobile and Spatially Distributed Cyber-Physical Systems", "comments": null, "journal-ref": "MEMOCODE 2017, ACM, pp 146--155, 2017", "doi": "10.1145/3127041.3127050", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems~(CPS) consist of collaborative, networked and tightly\nintertwined computational (logical) and physical components, each operating at\ndifferent spatial and temporal scales. Hence, the spatial and temporal\nrequirements play an essential role for their correct and safe execution.\nFurthermore, the local interactions among the system components result in\nglobal spatio-temporal emergent behaviors often impossible to predict at the\ndesign time. In this work, we pursue a complementary approach by introducing\nSTREL a novel spatio-temporal logic that enables the specification of\nspatio-temporal requirements and their monitoring over the execution of mobile\nand spatially distributed CPS. Our logic extends the Signal Temporal Logic with\ntwo novel spatial operators reach and escape from which is possible to derive\nother spatial modalities such as everywhere, somewhere and surround. These\noperators enable a monitoring procedure where the satisfaction of the property\nat each location depends only on the satisfaction of its neighbours, opening\nthe way to future distributed online monitoring algorithms. We propose both a\nqualitative and quantitative semantics based on constraint semirings, an\nalgebraic structure suitable for constraint satisfaction and optimisation. We\nprove that, for a subclass of models, all the spatial properties expressed with\nreach and escape, using euclidean distance, satisfy all the model\ntransformations using rotation, reflection and translation. Finally, we provide\nan offline monitoring algorithm for STREL and, to demonstrate the feasibility\nof our approach, we show its application using the monitoring of a simulated\nmobile ad-hoc sensor network as running example.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 22:02:33 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Bartocci", "Ezio", ""], ["Bortolussi", "Luca", ""], ["Loreti", "Michele", ""], ["Nenzi", "Laura", ""]]}, {"id": "1904.08850", "submitter": "Thierry Boy de la Tour", "authors": "Thierry Boy de la Tour and Rachid Echahed", "title": "True Parallel Graph Transformations: an Algebraic Approach Based on Weak\n  Spans", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of defining graph transformations by the simultaneous\napplication of direct transformations even when these cannot be applied\nindependently of each other. An algebraic approach is adopted, with production\nrules of the form $L\\xleftarrow{l}K \\xleftarrow{i} I \\xrightarrow{r} R$, called\nweak spans. A parallel coherent transformation is introduced and shown to be a\nconservative extension of the interleaving semantics of parallel independent\ndirect transformations. A categorical construction of finitely attributed\nstructures is proposed, in which parallel coherent transformations can be built\nin a natural way. These notions are introduced and illustrated on detailed\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 14:21:43 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["de la Tour", "Thierry Boy", ""], ["Echahed", "Rachid", ""]]}, {"id": "1904.09193", "submitter": "Pierre Pradic", "authors": "Pierre Pradic and Chad E. Brown", "title": "Cantor-Bernstein implies Excluded Middle", "comments": "6pp", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove in constructive logic that the statement of the Cantor-Bernstein\ntheorem implies excluded middle. This establishes that the Cantor-Bernstein\ntheorem can only be proven assuming the full power of classical logic. The key\ningredient is a theorem of Mart\\'in Escard\\'o stating that quantification over\na particular subset of the Cantor space $2^{\\mathbb{N}}$, the so-called\none-point compactification of $\\mathbb{N}$, preserves decidable predicates.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 13:21:24 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Pradic", "Pierre", ""], ["Brown", "Chad E.", ""]]}, {"id": "1904.09322", "submitter": "Nicolas Behr", "authors": "Nicolas Behr and Jean Krivine", "title": "Compositionality of Rewriting Rules with Conditions", "comments": "64 pages", "journal-ref": "Compositionality 3, 2 (2021)", "doi": "10.32408/compositionality-3-2", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the notion of compositional associative rewriting as recently\nstudied in the rule algebra framework literature to the setting of rewriting\nrules with conditions. Our methodology is category-theoretical in nature, where\nthe definition of rule composition operations encodes the non-deterministic\nsequential concurrent application of rules in Double-Pushout (DPO) and\nSesqui-Pushout (SqPO) rewriting with application conditions based upon\n$\\mathcal{M}$-adhesive categories. We uncover an intricate interplay between\nthe category-theoretical concepts of conditions on rules and morphisms, the\ncompositionality and compatibility of certain shift and transport constructions\nfor conditions, and thirdly the property of associativity of the composition of\nrules.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 19:38:32 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 15:35:30 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Behr", "Nicolas", ""], ["Krivine", "Jean", ""]]}, {"id": "1904.09561", "submitter": "EPTCS", "authors": "Michele Pagani (IRIF, Universit\\'e Paris Diderot, France), Sandra\n  Alves (Porto University)", "title": "Proceedings Twelfth Workshop on Developments in Computational Models and\n  Ninth Workshop on Intersection Types and Related Systems", "comments": null, "journal-ref": "EPTCS 293, 2019", "doi": "10.4204/EPTCS.293", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a final and revised selection of papers presented at\nTwelfth Workshop on Developments in Computational Models (DCM 2018) and the\nNinth Workshop on Intersection Types and Related Systems (ITRS 2018), held on\nJuly 8, 2018 in Oxford, in affiliation with FLOC 2018.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 07:53:20 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Pagani", "Michele", "", "IRIF, Universit\u00e9 Paris Diderot, France"], ["Alves", "Sandra", "", "Porto University"]]}, {"id": "1904.09600", "submitter": "Mathieu Huot", "authors": "Mathieu Huot and Sam Staton", "title": "Quantum channels as a categorical completion", "comments": "12 pages + ref, accepted at LICS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a categorical foundation for the connection between pure and mixed\nstates in quantum information and quantum computation. The foundation is based\non distributive monoidal categories.\n  First, we prove that the category of all quantum channels is a canonical\ncompletion of the category of pure quantum operations (with ancilla\npreparations). More precisely, we prove that the category of completely\npositive trace-preserving maps between finite-dimensional C*-algebras is a\ncanonical completion of the category of finite-dimensional vector spaces and\nisometries.\n  Second, we extend our result to give a foundation to the topological\nrelationships between quantum channels. We do this by generalizing our\ncategorical foundation to the topologically-enriched setting. In particular, we\nshow that the operator norm topology on quantum channels is the canonical\ntopology induced by the norm topology on isometries.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 13:28:53 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 10:50:54 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Huot", "Mathieu", ""], ["Staton", "Sam", ""]]}, {"id": "1904.09650", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago, Thomas Leventis", "title": "On the Taylor Expansion of Probabilistic $\\lambda$-Terms (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalise Ehrhard and Regnier's Taylor expansion from pure to\nprobabilistic $\\lambda$-terms through notions of probabilistic resource terms\nand explicit Taylor expansion. We prove that the Taylor expansion is adequate\nwhen seen as a way to give semantics to probabilistic $\\lambda$-terms, and that\nthere is a precise correspondence with probabilistic B\\\"ohm trees, as\nintroduced by the second author.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 19:31:39 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Leventis", "Thomas", ""]]}, {"id": "1904.09794", "submitter": "Thorsten Wissmann", "authors": "Chuangjie Xu", "title": "A syntactic approach to continuity of T-definable functionals", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (February\n  20, 2020) lmcs:6130", "doi": "10.23638/LMCS-16(1:22)2020", "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a new proof of the well-known fact that all functions $(\\mathbb{N}\n\\to \\mathbb{N}) \\to \\mathbb{N}$ which are definable in G\\\"odel's System T are\ncontinuous via a syntactic approach. Differing from the usual syntactic method,\nwe firstly perform a translation of System T into itself in which natural\nnumbers are translated to functions $(\\mathbb{N} \\to \\mathbb{N}) \\to\n\\mathbb{N}$. Then we inductively define a continuity predicate on the\ntranslated elements and show that the translation of any term in System T\nsatisfies the continuity predicate. We obtain the desired result by relating\nterms and their translations via a parametrized logical relation. Our\nconstructions and proofs have been formalized in the Agda proof assistant.\nBecause Agda is also a programming language, we can execute our proof to\ncompute moduli of continuity of T-definable functions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 10:42:30 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 23:54:45 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 22:20:46 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2020 14:47:45 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Xu", "Chuangjie", ""]]}, {"id": "1904.09810", "submitter": "Tom de Jong", "authors": "Tom de Jong", "title": "The Scott model of PCF in univalent type theory", "comments": "Revised after review process", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop the Scott model of the programming language PCF in univalent type\ntheory. Moreover, we work constructively and predicatively. To account for the\nnon-termination in PCF, we use the lifting monad (also known as the partial map\nclassifier monad) from topos theory, which has been extended to univalent type\ntheory by Escard\\'o and Knapp. Our results show that lifting is a viable\napproach to partiality in univalent type theory. Moreover, we show that the\nScott model can be constructed in a predicative and constructive setting. Other\napproaches to partiality either require some form of choice or quotient\ninductive-inductive types. We show that one can do without these extensions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 12:06:29 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 15:25:50 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 17:35:03 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 10:14:21 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["de Jong", "Tom", ""]]}, {"id": "1904.09828", "submitter": "Alex Churchill", "authors": "Alex Churchill, Stella Biderman, Austin Herrick", "title": "Magic: The Gathering is Turing Complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\textit{Magic: The Gathering}$ is a popular and famously complicated trading\ncard game about magical combat. In this paper we show that optimal play in\nreal-world $\\textit{Magic}$ is at least as hard as the Halting Problem, solving\na problem that has been open for a decade. To do this, we present a methodology\nfor embedding an arbitrary Turing machine into a game of $\\textit{Magic}$ such\nthat the first player is guaranteed to win the game if and only if the Turing\nmachine halts. Our result applies to how real $\\textit{Magic}$ is played, can\nbe achieved using standard-size tournament-legal decks, and does not rely on\nstochasticity or hidden information. Our result is also highly unusual in that\nall moves of both players are forced in the construction. This shows that even\nrecognising who will win a game in which neither player has a non-trivial\ndecision to make for the rest of the game is undecidable. We conclude with a\ndiscussion of the implications for a unified computational theory of games and\nremarks about the playability of such a board in a tournament setting.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 23:48:09 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 10:16:57 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Churchill", "Alex", ""], ["Biderman", "Stella", ""], ["Herrick", "Austin", ""]]}, {"id": "1904.09859", "submitter": "Cynthia Kop", "authors": "{\\L}ukasz Czajka, Cynthia Kop", "title": "Polymorphic Higher-order Termination", "comments": "author copy of a paper accepted for FSCD 2019, with an extended\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalise the termination method of higher-order polynomial\ninterpretations to a setting with impredicative polymorphism. Instead of using\nweakly monotonic functionals, we interpret terms in a suitable extension of\nSystem F-omega. This enables a direct interpretation of rewrite rules which\nmake essential use of impredicative polymorphism. In addition, our\ngeneralisation eases the applicability of the method in the non-polymorphic\nsetting by allowing for the encoding of inductive data types.\n  As an illustration of the potential of our method, we prove termination of a\nsubstantial fragment of full intuitionistic second-order propositional logic\nwith permutative conversions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 13:27:07 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Czajka", "\u0141ukasz", ""], ["Kop", "Cynthia", ""]]}, {"id": "1904.09875", "submitter": "Bill Roscoe", "authors": "David Mestel, A.W. Roscoe", "title": "Translating between models of concurrency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hoare's Communicating Sequential Processes (CSP) admits a rich universe of\nsemantic models closely related to the van Glabbeek spectrum. In this paper we\nstudy finite observational models, of which at least six have been identified\nfor CSP, namely traces, stable failures, revivals, acceptances, refusal testing\nand finite linear observations. We show how to use the recently-introduced\n\\emph{priority} operator to transform refinement questions in these models into\ntrace refinement (language inclusion) tests. Furthermore, we are able to\ngeneralise this to any (rational) finite observational model. As well as being\nof theoretical interest, this is of practical significance since the\nstate-of-the-art refinement checking tool FDR4 currently only supports two such\nmodels. In particular we study how it is possible to check refinement in a\ndiscrete version of the Timed Failures model that supports Timed CSP.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 13:49:39 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Mestel", "David", ""], ["Roscoe", "A. W.", ""]]}, {"id": "1904.09899", "submitter": "Tim Lyon", "authors": "Kees van Berkel and Tim Lyon", "title": "Cut-free Calculi and Relational Semantics for Temporal STIT Logics", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-19570-0_52", "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present cut-free labelled sequent calculi for a central formalism in\nlogics of agency: STIT logics with temporal operators. These include sequent\nsystems for Ldm, Tstit and Xstit. All calculi presented possess essential\nstructural properties such as contraction- and cut-admissibility. The labelled\ncalculi G3Ldm and G3TSTIT are shown sound and complete relative to irreflexive\ntemporal frames. Additionally, we extend current results by showing that also\nXSTIT can be characterized through relational frames, omitting the use of BT+AC\nframes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 14:34:28 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["van Berkel", "Kees", ""], ["Lyon", "Tim", ""]]}, {"id": "1904.09946", "submitter": "Santiago Escobar", "authors": "Fan Yang and Santiago Escobar and Catherine Meadows and Jos\\'e\n  Meseguer", "title": "Strand Spaces with Choice via a Process Algebra Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Roles in cryptographic protocols do not always have a linear execution, but\nmay include choice points causing the protocol to continue along different\npaths. In this paper we address the problem of representing choice in the\nstrand space model of cryptographic protocols, particularly as it is used in\nthe Maude-NPA cryptographic protocol analysis tool. To achieve this goal, we\ndevelop and give formal semantics to a process algebra for cryptographic\nprotocols that supports a rich taxonomy of choice primitives for composing\nstrand spaces. In our taxonomy, deterministic and non-deterministic choices are\nbroken down further. Non-deterministic choice can be either explicit, i.e., one\nof two paths is chosen, or implicit, i.e., the value of a variable is chosen\nnon-deterministically. Likewise, deterministic choice can be either an explicit\nif-then-else choice, i.e., one path is chosen if a predicate is satisfied,\nwhile the other is chosen if it is not, or implicit deterministic choice, i.e.,\nexecution continues only if a certain pattern is matched. We have identified a\nclass of choices which includes finite branching and some cases of infinite\nbranching, which we address in this paper. We provide a bisimulation result\nbetween the expected forwards execution semantics of the new process algebra\nand the original symbolic backwards semantics of Maude-NPA that preserves\nattack reachability. We have fully integrated the process algebra syntax and\nits transformation into strands in Maude-NPA. We illustrate its expressive\npower and naturalness with various examples, and show how it can be effectively\nused in formal analysis. This allows users to write protocols from now on using\nthe process syntax, which is more convenient for expressing choice than the\nstrand space syntax, in which choice can only be specified implicitly, via two\nor more strands that are identical until the choice point.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 16:46:03 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Yang", "Fan", ""], ["Escobar", "Santiago", ""], ["Meadows", "Catherine", ""], ["Meseguer", "Jos\u00e9", ""]]}, {"id": "1904.10035", "submitter": "Samson Abramsky", "authors": "Samson Abramsky, Rui Soares Barbosa, Martti Karvonen and Shane\n  Mansfield", "title": "A comonadic view of simulation and quantum resources", "comments": "To appear in Proceedings of LiCS 2019", "journal-ref": "34th Annual ACM/IEEE Symposium on Logic in Computer Science (LiCS\n  2019)", "doi": "10.1109/LICS.2019.8785677", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study simulation and quantum resources in the setting of the\nsheaf-theoretic approach to contextuality and non-locality. Resources are\nviewed behaviourally, as empirical models. In earlier work, a notion of\nmorphism for these empirical models was proposed and studied. We generalize and\nsimplify the earlier approach, by starting with a very simple notion of\nmorphism, and then extending it to a more useful one by passing to a co-Kleisli\ncategory with respect to a comonad of measurement protocols. We show that these\nmorphisms capture notions of simulation between empirical models obtained via\n`free' operations in a resource theory of contextuality, including the type of\nclassical control used in measurement-based quantum computation schemes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 19:09:15 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Abramsky", "Samson", ""], ["Barbosa", "Rui Soares", ""], ["Karvonen", "Martti", ""], ["Mansfield", "Shane", ""]]}, {"id": "1904.10105", "submitter": "EPTCS", "authors": "Pawe{\\l} Parys (Institute of Informatics, University of Warsaw)", "title": "Intersection Types for Unboundedness Problems", "comments": "In Proceedings DCM 2018 and ITRS 2018 , arXiv:1904.09561", "journal-ref": "EPTCS 293, 2019, pp. 7-27", "doi": "10.4204/EPTCS.293.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intersection types have been originally developed as an extension of simple\ntypes, but they can also be used for refining simple types. In this survey we\nconcentrate on the latter option; more precisely, on the use of intersection\ntypes for describing quantitative properties of simply typed lambda-terms. We\npresent two type systems. The first allows to estimate (by appropriately\ndefined value of a derivation) the number of appearances of a fixed constant\n'a' in the beta-normal form of a considered lambda-term. The second type system\nis more complicated, and allows to estimate the maximal number of appearances\nof the constant 'a' on a single branch.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 00:52:57 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Parys", "Pawe\u0142", "", "Institute of Informatics, University of Warsaw"]]}, {"id": "1904.10106", "submitter": "EPTCS", "authors": "Federico Aschieri", "title": "Natural Deduction and Normalization Proofs for the Intersection Type\n  Discipline", "comments": "In Proceedings DCM 2018 and ITRS 2018, arXiv:1904.09561", "journal-ref": "EPTCS 293, 2019, pp. 29-37", "doi": "10.4204/EPTCS.293.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Refining and extending previous work by Retor\\'e, we develop a systematic\napproach to intersection types via natural deduction. We show how a step of\nbeta reduction can be seen as performing, at the level of typing derivations,\nPrawitz reductions in parallel. Then we derive as immediate consequences of\nSubject Reduction the main theorems about normalization for intersection types:\nfor system D, strong normalization, for system Omega, the leftmost reduction\ntermination for terms typable without Omega.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 00:53:31 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Aschieri", "Federico", ""]]}, {"id": "1904.10108", "submitter": "EPTCS", "authors": "Olivier Laurent (Univ Lyon, EnsL, UCBL, CNRS, LIP, F-69342, LYON Cedex\n  07, France)", "title": "Intersection Subtyping with Constructors", "comments": "In Proceedings DCM 2018 and ITRS 2018 , arXiv:1904.09561", "journal-ref": "EPTCS 293, 2019, pp. 73-84", "doi": "10.4204/EPTCS.293.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of extending the BCD intersection type system with\nadditional type constructors. On the typing side, we focus on adding the usual\nrules for product types. On the subtyping side, we consider a generic way of\ndefining a subtyping relation on families of types which include intersection\ntypes. We find back the BCD subtyping relation by considering the particular\ncase where the type constructors are intersection, omega and arrow. We obtain\nan extension of BCD subtyping to product types as another instance. We show how\nthe preservation of typing by both reduction and expansion is satisfied in all\nthe considered cases. Our approach takes benefits from a \"subformula property\"\nof the proposed presentation of the subtyping relation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 00:54:34 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Laurent", "Olivier", "", "Univ Lyon, EnsL, UCBL, CNRS, LIP, F-69342, LYON Cedex\n  07, France"]]}, {"id": "1904.10109", "submitter": "EPTCS", "authors": "Joseph Razavi, Andrea Schalk", "title": "A Category Theoretic Interpretation of Gandy's Principles for Mechanisms", "comments": "In Proceedings DCM 2018 and ITRS 2018 , arXiv:1904.09561", "journal-ref": "EPTCS 293, 2019, pp. 85-92", "doi": "10.4204/EPTCS.293.7", "report-no": null, "categories": "cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on Gandy's principles for models of computation we give\ncategory-theoretic axioms describing locally deterministic updates to finite\nobjects. Rather than fixing a particular category of states, we describe what\nproperties such a category should have. The computation is modelled by a\nfunctor that encodes updating the computation, and we give an abstract account\nof such functors. We show that every updating functor satisfying our conditions\nis computable.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 01:00:28 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Razavi", "Joseph", ""], ["Schalk", "Andrea", ""]]}, {"id": "1904.10260", "submitter": "Anantha Padmanabha", "authors": "Anantha Padmanabha and R. Ramanujam", "title": "Two variable fragment of Term Modal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Term modal logics (TML) are modal logics with unboundedly many modalities,\nwith quantification over modal indices, so that we can have formulas of the\nform $\\exists y. \\forall x. (\\Box_x P(x,y) \\supset\\Diamond_y P(y,x))$. Like\nFirst order modal logic, TML is also \"notoriously\" undecidable, in the sense\nthat even very simple fragments are undecidable. In this paper, we show the\ndecidability of one interesting fragment, that of two variable TML. This is in\ncontrast to two-variable First order modal logic, which is undecidable.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 11:58:52 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 12:28:20 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 09:17:13 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Padmanabha", "Anantha", ""], ["Ramanujam", "R.", ""]]}, {"id": "1904.10266", "submitter": "Sergey Dovgal", "authors": "Sergey Dovgal", "title": "The birth of the contradictory component in random 2-SAT", "comments": "29 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that, with high probability, the contradictory components of a\nrandom 2-SAT formula in the subcritical phase of the phase transition have only\n3-regular kernels. This follows from the relation between these kernels and the\ncomplex component of a random graph in the subcritical phase. This partly\nsettles the question about the structural similarity between the phase\ntransitions in 2-SAT and random graphs. As a byproduct, we describe the\ntechnique that allows to obtain a full asymptotic expansion of the\nsatisfiability in the subcritical phase. We also obtain the distribution of the\nnumber of contradictory variables and the structure of the spine in the\nsubcritical phase.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 12:07:53 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Dovgal", "Sergey", ""]]}, {"id": "1904.10414", "submitter": "Michael Kohlhase", "authors": "Michael Kohlhase", "title": "The Theorem Prover Museum -- Conserving the System Heritage of Automated\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present the Theorem Prover Museum, and initiative to conserve -- and make\npublicly available -- the sources and source-related artefacts of automated\nreasoning systems. Theorem provers have been at the forefront of Artificial\nIntelligence, stretching the limits of computation, and incubating many\ninnovations we take for granted today. Without the systems themselves as\npreserved cultural artefacts, future historians will have difficulties to study\nthe history of science and engineering in our discipline.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 16:34:41 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Kohlhase", "Michael", ""]]}, {"id": "1904.10570", "submitter": "Jesse Han", "authors": "Jesse Michael Han and Floris van Doorn", "title": "A formalization of forcing and the unprovability of the continuum\n  hypothesis", "comments": "19 pages; extended version of a paper submitted to ITP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a formalization of forcing using Boolean-valued models in the\nLean 3 theorem prover, including the fundamental theorem of forcing and a deep\nembedding of first-order logic with a Boolean-valued soundness theorem. As an\napplication of our framework, we specialize our construction to the Boolean\nalgebra of regular opens of the Cantor space $2^{\\omega_2 \\times \\omega}$ and\nformally verify the failure of the continuum hypothesis in the resulting model.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 23:39:45 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Han", "Jesse Michael", ""], ["van Doorn", "Floris", ""]]}, {"id": "1904.10605", "submitter": "Yosuke Fukuda", "authors": "Yosuke Fukuda and Akira Yoshimizu", "title": "A Linear-logical Reconstruction of Intuitionistic Modal Logic S4", "comments": "Author copy of a paper accepted for FSCD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a \"modal linear logic\" to reformulate intuitionistic modal logic\nS4 (IS4) in terms of linear logic, establishing an S4-version of Girard\ntranslation from IS4 to it. While the Girard translation from intuitionistic\nlogic to linear logic is well-known, its extension to modal logic is\nnon-trivial since a naive combination of the S4 modality and the exponential\nmodality causes an undesirable interaction between the two modalities. To solve\nthe problem, we introduce an extension of intuitionistic multiplicative\nexponential linear logic with a modality combining the S4 modality and the\nexponential modality, and show that it admits a sound translation from IS4.\nThrough the Curry-Howard correspondence we further obtain a Geometry of\nInteraction Machine semantics of the modal lambda-calculus by Pfenning and\nDavies for staged computation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 02:02:43 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Fukuda", "Yosuke", ""], ["Yoshimizu", "Akira", ""]]}, {"id": "1904.10611", "submitter": "David Sprunger", "authors": "David Sprunger and Bart Jacobs", "title": "The differential calculus of causal functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal functions of sequences occur throughout computer science, from theory\nto hardware to machine learning. Mealy machines, synchronous digital circuits,\nsignal flow graphs, and recurrent neural networks all have behaviour that can\nbe described by causal functions. In this work, we examine a differential\ncalculus of causal functions which includes many of the familiar properties of\nstandard multivariable differential calculus. These causal functions operate on\ninfinite sequences, but this work gives a different notion of an\ninfinite-dimensional derivative than either the Fr\\'echet or Gateaux derivative\nused in functional analysis. In addition to showing many standard properties of\ndifferentiation, we show causal differentiation obeys a unique recurrence rule.\nWe use this recurrence rule to compute the derivative of a simple recurrent\nneural network called an Elman network by hand and describe how the computed\nderivative can be used to train the network.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 02:27:16 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Sprunger", "David", ""], ["Jacobs", "Bart", ""]]}, {"id": "1904.10614", "submitter": "Cole Comfort", "authors": "Cole Comfort", "title": "Circuit Relations for Real Stabilizers: Towards TOF+H", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The real stabilizer fragment of quantum mechanics was shown to have a\ncomplete axiomatization in terms of the angle-free fragment of the ZX-calculus.\nThis fragment of the ZX-calculus---although abstractly elegant---is stated in\nterms of identities, such as spider fusion which generally do not have\ninterpretations as circuit transformations.\n  We complete the category CNOT generated by the controlled not gate and the\ncomputational ancillary bits, presented by circuit relations, to the real\nstabilizer fragment of quantum mechanics. This is performed first, by adding\nthe Hadamard gate and the scalar sqrt 2 as generators. We then construct\ntranslations to and from the angle-free fragment of the ZX-calculus, showing\nthat they are inverses.\n  We then discuss how this could potentially lead to a complete axiomatization,\nin terms of circuit relations, for the approximately universal fragment of\nquantum mechanics generated by the Toffoli gate, Hadamard gate and\ncomputational ancillary bits.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 02:43:08 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 22:44:05 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Comfort", "Cole", ""]]}, {"id": "1904.10703", "submitter": "Philippe Schnoebelen", "authors": "Jean Goubault-Larrecq and Simon Halfon and Prateek Karandikar and K.\n  Narayan Kumar and Philippe Schnoebelen", "title": "The Ideal Approach to Computing Closed Subsets in Well-Quasi-Ordering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elegant and general algorithms for handling upwards-closed and\ndownwards-closed subsets of WQOs can be developed using the filter-based and\nideal-based representation for these sets. These algorithms can be built in a\ngeneric or parameterized way, in parallel with the way complex WQOs are\nobtained by combining or modifying simpler WQOs.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 09:06:15 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Goubault-Larrecq", "Jean", ""], ["Halfon", "Simon", ""], ["Karandikar", "Prateek", ""], ["Kumar", "K. Narayan", ""], ["Schnoebelen", "Philippe", ""]]}, {"id": "1904.10800", "submitter": "EPTCS", "authors": "Giulio Guerrieri (University of Bath, Department of Computer Science,\n  Bath, United Kingdom)", "title": "Towards a Semantic Measure of the Execution Time in Call-by-Value\n  lambda-Calculus", "comments": "In Proceedings DCM 2018 and ITRS 2018 , arXiv:1904.09561. arXiv admin\n  note: substantial text overlap with arXiv:1812.10799", "journal-ref": "EPTCS 293, 2019, pp. 57-72", "doi": "10.4204/EPTCS.293.5", "report-no": null, "categories": "cs.LO cs.DM cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the possibility of a semantic account of the execution time\n(i.e. the number of beta-steps leading to the normal form, if any) for the\nshuffling calculus, an extension of Plotkin's call-by-value lambda-calculus.\nFor this purpose, we use a linear logic based denotational model that can be\nseen as a non-idempotent intersection type system: relational semantics. Our\ninvestigation is inspired by similar ones for linear logic proof-nets and\nuntyped call-by-name lambda-calculus. We first prove a qualitative result: a\n(possibly open) term is normalizable for weak reduction (which does not reduce\nunder abstractions) if and only if its interpretation is not empty. We then\nshow that the size of type derivations can be used to measure the execution\ntime. Finally, we show that, differently from the case of linear logic and\ncall-by-name lambda-calculus, the quantitative information enclosed in type\nderivations does not lift to types (i.e. to the interpretation of terms). To\nget a truly semantic measure of execution time in a call-by-value setting, we\nconjecture that a refinement of its syntax and operational semantics is needed.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 00:54:11 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Guerrieri", "Giulio", "", "University of Bath, Department of Computer Science,\n  Bath, United Kingdom"]]}, {"id": "1904.10901", "submitter": "Walid Belkhir", "authors": "Walid Belkhir and Nicolas Ratier and Duy Duc Nguyen Michel Lenczner", "title": "Unification and combination of iterative insertion strategies with\n  rudimentary traversals and failure", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.07668", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of extensions of terms that consists in navigation\nstrategies and insertion of contexts. We introduce an operation of combination\non this class which is associative, admits a neutral element and so that each\nextension is idempotent. The class of extension is also shown to be closed by\ncombination, with a constructive proof. This new framework is general and\nindependent of any application semantics. However it has been introduced for\nthe kernel of a software tool which aims at aiding derivation of multiscale\npartial differential equation models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 13:48:59 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Belkhir", "Walid", ""], ["Ratier", "Nicolas", ""], ["Lenczner", "Duy Duc Nguyen Michel", ""]]}, {"id": "1904.11099", "submitter": "Daniel Huang", "authors": "Daniel Huang", "title": "On Learning to Prove", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of learning a first-order theorem\nprover that uses a representation of beliefs in mathematical claims to\nconstruct proofs. The inspiration for doing so comes from the practices of\nhuman mathematicians where \"plausible reasoning\" is applied in addition to\ndeductive reasoning to find proofs.\n  Towards this end, we introduce a representation of beliefs that assigns\nprobabilities to the exhaustive and mutually exclusive first-order\npossibilities found in Hintikka's theory of distributive normal forms. The\nrepresentation supports Bayesian update, induces a distribution on statements\nthat does not enforce that logically equivalent statements are assigned the\nsame probability, and suggests an embedding of statements into an associated\nHilbert space.\n  We then examine conjecturing as model selection and an alternating-turn game\nof determining consistency. The game is amenable (in principle) to self-play\ntraining to learn beliefs and derive a prover that is complete when logical\nomniscience is attained and sound when beliefs are reasonable. The\nrepresentation has super-exponential space requirements as a function of\nquantifier depth so the ideas in this paper should be taken as theoretical. We\nwill comment on how abstractions can be used to control the space requirements\nat the cost of completeness.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 23:54:59 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 16:55:51 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 05:57:10 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Huang", "Daniel", ""]]}, {"id": "1904.11281", "submitter": "Zeinab Nehai", "authors": "Zeinab Nehai (DILS, UPD7), Fran\\c{c}ois Bobot (DILS)", "title": "Deductive Proof of Ethereum Smart Contracts Using Why3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bug or error is a common problem that any software or computer program may\nencounter. It can occur from badly writing the program, a typing error or bad\nmemory management. However, errors can become a significant issue if the unsafe\nprogram is used for critical systems. Therefore, formal methods for these kinds\nof systems are greatly required. In this paper, we use a formal language that\nperforms deductive verification on an Ethereum Blockchain application based on\nsmart contracts, which are self-executing digital contracts. Blockchain systems\nmanipulate cryptocurrency and transaction information. Therefore , if a bug\noccurs in the blockchain, serious consequences such as a loss of money can\nhappen. Thus, the aim of this paper is to propose a language dedicated to\ndeductive verification, called Why3, as a new language for writing formal and\nverified smart contracts, thereby avoiding attacks exploiting such contract\nexecution vulnerabilities. We first write a Why3 smart contracts program; next\nwe formulate specifications to be proved as absence of RunTime Error properties\nand functional properties, then we verify the behavior of the program using the\nWhy3 system. Finally we compile the Why3 contracts to the Ethereum Virtual\nMachine (EVM). Moreover, we give a set of generic mathematical statements that\nallows verifying functional properties suited to any type of smart contracts\nholding cryptocurrency, showing that Why3 can be a suitable language to write\nsmart contracts. To illustrate our approach, we describe its application to a\nrealistic industrial use case.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 12:04:16 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 13:55:09 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Nehai", "Zeinab", "", "DILS, UPD7"], ["Bobot", "Fran\u00e7ois", "", "DILS"]]}, {"id": "1904.11287", "submitter": "Jules Hedges", "authors": "Jules Hedges", "title": "The game semantics of game theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a reformulation of compositional game theory to reunite game theory\nwith game semantics, by viewing an open game as the System and its choice of\ncontexts as the Environment. Specifically, the system is jointly controlled by\n$n \\geq 0$ noncooperative players, each independently optimising a real-valued\npayoff. The goal of the system is to play a Nash equilibrium, and the goal of\nthe environment is to prevent it. The key to this is the realisation that\nlenses (from functional programming) form a dialectica category, which have an\nexisting game-semantic interpretation.\n  In the second half of this paper, we apply these ideas to build a compact\nclosed category of `computable open games' by replacing the underlying\ndialectica category with a wave-style geometry of interaction category,\nspecifically the Int-construction applied to the cartesian monoidal category of\ndirected-complete partial orders.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 12:18:33 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 11:05:57 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Hedges", "Jules", ""]]}, {"id": "1904.11304", "submitter": "Kenji Miyamoto", "authors": "Kenji Miyamoto, Georg Moser", "title": "The Epsilon Calculus with Equality and Herbrand Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hilbert's epsilon calculus is an extension of elementary or predicate\ncalculus by a term-forming operator $\\varepsilon$ and initial formulas\ninvolving such terms. The fundamental results about the epsilon calculus are\nso-called epsilon theorems, which have been proven by means of the epsilon\nelimination method. It is a procedure of transforming a proof in epsilon\ncalculus into a proof in elementary or predicate calculus through getting rid\nof those initial formulas. One remarkable consequence is a proof of Herbrand's\ntheorem due to Bernays and Hilbert which comes as a corollary of extended first\nepsilon theorem. The contribution of this paper is the upper and lower bounds\nanalysis of the length of Herbrand disjunctions in extended first epsilon\ntheorem for epsilon calculus with equality. We also show that the complexity\nanalysis for Herbrand's theorem with equality is a straightforward consequence\nof the one for extended first epsilon theorem without equality due to Moser and\nZach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 12:53:07 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Miyamoto", "Kenji", ""], ["Moser", "Georg", ""]]}, {"id": "1904.11378", "submitter": "Hannes Diener", "authors": "Hannes Diener and Matthew Hendtlass", "title": "(Seemingly) Impossible Theorems in Constructive Mathematics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove some constructive results that on first and maybe even on second\nglance seem impossible.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 02:33:28 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Diener", "Hannes", ""], ["Hendtlass", "Matthew", ""]]}, {"id": "1904.11381", "submitter": "Jochen Hoenicke", "authors": "Jochen Hoenicke and Tanja Schindler", "title": "Interpolation and the Array Property Fragment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpolation based software model checkers have been successfully employed\nto automatically prove programs correct. Their power comes from interpolating\nSMT solvers that check the feasibility of potential counterexamples and compute\ncandidate invariants, otherwise. This approach works well for quantifier-free\ntheories, like equality theory or linear arithmetic.\n  For quantified formulas, there are SMT solvers that can decide expressive\nfragments of quantified formulas, e. g., EPR, the array property fragment, and\nthe finite almost uninterpreted fragment. However, these solvers do not support\ninterpolation. It is already known that in general EPR does not allow for\ninterpolation. In this paper, we show the same result for the array property\nfragment.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 14:32:29 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Hoenicke", "Jochen", ""], ["Schindler", "Tanja", ""]]}, {"id": "1904.11454", "submitter": "Murat Cubuktepe", "authors": "Bo Wu, Murat Cubuktepe, Suda Bharadwaj, Ufuk Topcu", "title": "Reward-Based Deception with Cognitive Bias", "comments": "Submitted to CDC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deception plays a key role in adversarial or strategic interactions for the\npurpose of self-defence and survival. This paper introduces a general framework\nand solution to address deception. Most existing approaches for deception\nconsider obfuscating crucial information to rational adversaries with abundant\nmemory and computation resources. In this paper, we consider deceiving\nadversaries with bounded rationality and in terms of expected rewards. This\nproblem is commonly encountered in many applications especially involving human\nadversaries. Leveraging the cognitive bias of humans in reward evaluation under\nstochastic outcomes, we introduce a framework to optimally assign resources of\na limited quantity to optimally defend against human adversaries. Modeling such\ncognitive biases follows the so-called prospect theory from behavioral\npsychology literature. Then we formulate the resource allocation problem as a\nsignomial program to minimize the defender's cost in an environment modeled as\na Markov decision process. We use police patrol hour assignment as an\nillustrative example and provide detailed simulation results based on\nreal-world data.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 16:51:24 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Wu", "Bo", ""], ["Cubuktepe", "Murat", ""], ["Bharadwaj", "Suda", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1904.11771", "submitter": "Niels Voorneveld", "authors": "Niels Voorneveld", "title": "Quantitative Logics for Equivalence of Effectful Programs", "comments": "Submitted to MFPS 2019, 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to reason about effects, we can define quantitative formulas to\ndescribe behavioural aspects of effectful programs. These formulas can for\nexample express probabilities that (or sets of correct starting states for\nwhich) a program satisfies a property. Fundamental to this approach is the\nnotion of quantitative modality, which is used to lift a property on values to\na property on computations. Taking all formulas together, we say that two terms\nare equivalent if they satisfy all formulas to the same quantitative degree.\nUnder sufficient conditions on the quantitative modalities, this equivalence is\nequal to a notion of Abramsky's applicative bisimilarity, and is moreover a\ncongruence. We investigate these results in the context of Levy's\ncall-by-push-value with general recursion and algebraic effects. In particular,\nthe results apply to (combinations of) nondeterministic choice, probabilistic\nchoice, and global store.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 11:33:43 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Voorneveld", "Niels", ""]]}, {"id": "1904.11818", "submitter": "Fabian Kunze", "authors": "Yannick Forster, Fabian Kunze", "title": "A certifying extraction with time bounds from Coq to call-by-value\n  $\\lambda$-calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a plugin extracting Coq functions of simple polymorphic types to\nthe (untyped) call-by-value $\\lambda$-calculus L. The plugin is implemented in\nthe MetaCoq framework and entirely written in Coq. We provide Ltac tactics to\nautomatically verify the extracted terms w.r.t a logical relation connecting\nCoq functions with correct extractions and time bounds, essentially performing\na certifying translation and running time validation. We provide three case\nstudies: A universal L-term obtained as extraction from the Coq definition of a\nstep-indexed self-interpreter for \\L, a many-reduction from solvability of\nDiophantine equations to the halting problem of L, and a polynomial-time\nsimulation of Turing machines in L.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 13:00:47 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 12:46:20 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Forster", "Yannick", ""], ["Kunze", "Fabian", ""]]}, {"id": "1904.12084", "submitter": "Zhanfu Yang", "authors": "Zhanfu Yang, Fei Wang, Ziliang Chen, Guannan Wei, Tiark Rompf", "title": "Graph Neural Reasoning for 2-Quantified Boolean Formula Solvers", "comments": "5 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the feasibility of learning GNN (Graph Neural\nNetwork) based solvers and GNN-based heuristics for specified QBF (Quantified\nBoolean Formula) problems. We design and evaluate several GNN architectures for\n2QBF formulae, and conjecture that GNN has limitations in learning 2QBF\nsolvers. Then we show how to learn a heuristic CEGAR 2QBF solver. We further\nexplore generalizing GNN-based heuristics to larger unseen instances, and\nuncover some interesting challenges. In summary, this paper provides a\ncomprehensive surveying view of applying GNN-embeddings to specified QBF\nsolvers, and aims to offer guidance in applying ML to more complicated symbolic\nreasoning problems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 01:30:50 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Yang", "Zhanfu", ""], ["Wang", "Fei", ""], ["Chen", "Ziliang", ""], ["Wei", "Guannan", ""], ["Rompf", "Tiark", ""]]}, {"id": "1904.12085", "submitter": "Peter Streufert", "authors": "Peter A. Streufert (Western University)", "title": "The Category of Node-and-Choice Forms, with Subcategories for\n  Choice-Sequence Forms and Choice-Set Forms", "comments": "43 pages, 9 figures", "journal-ref": "Neoclassical Logics and Their Applications, ed. by S. Ju, A.\n  Palmigiano, and M. Ma, Logic in Asia: Studia Logica Library, pages 15-66.\n  Springer (2020)", "doi": "10.1007/978-981-15-1342-8_2", "report-no": "Western University (University of Western Ontario), Department of\n  Economics Research Report #2018-06. Also Munich Personal RePEc (Research\n  Papers in Economics) Archive #90490. (Only introduction differs.)", "categories": "econ.TH cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature specifies extensive-form games in many styles, and eventually\nI hope to formally translate games across those styles. Toward that end, this\npaper defines $\\mathbf{NCF}$, the category of node-and-choice forms. The\ncategory's objects are extensive forms in essentially any style, and the\ncategory's isomorphisms are made to accord with the literature's small handful\nof ad hoc style equivalences.\n  Further, this paper develops two full subcategories: $\\mathbf{CsqF}$ for\nforms whose nodes are choice-sequences, and $\\mathbf{CsetF}$ for forms whose\nnodes are choice-sets. I show that $\\mathbf{NCF}$ is \"isomorphically enclosed\"\nin $\\mathbf{CsqF}$ in the sense that each $\\mathbf{NCF}$ form is isomorphic to\na $\\mathbf{CsqF}$ form. Similarly, I show that $\\mathbf{CsqF_{\\tilde a}}$ is\nisomorphically enclosed in $\\mathbf{CsetF}$ in the sense that each\n$\\mathbf{CsqF}$ form with no-absentmindedness is isomorphic to a\n$\\mathbf{CsetF}$ form. The converses are found to be almost immediate, and the\nresulting equivalences unify and simplify two ad hoc style equivalences in\nKline and Luckraz 2016 and Streufert 2019.\n  Aside from the larger agenda, this paper already makes three practical\ncontributions. Style equivalences are made easier to derive by [1] a natural\nconcept of isomorphic invariance and [2] the composability of isomorphic\nenclosures. In addition, [3] some new consequences of equivalence are\nsystematically deduced.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 01:30:55 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Streufert", "Peter A.", "", "Western University"]]}, {"id": "1904.12137", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago, Francesco Gavazzo, Akira Yoshimizu", "title": "Differential Logical Relations, Part I: The Simply-Typed Case (Long\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new form of logical relation which, in the spirit of metric\nrelations, allows us to assign each pair of programs a quantity measuring their\ndistance, rather than a boolean value standing for their being equivalent. The\nnovelty of differential logical relations consists in measuring the distance\nbetween terms not (necessarily) by a numerical value, but by a mathematical\nobject which somehow reflects the interactive complexity, i.e. the type, of the\ncompared terms. We exemplify this concept in the simply-typed lambda-calculus,\nand show a form of soundness theorem. We also see how ordinary logical\nrelations and metric relations can be seen as instances of differential logical\nrelations. Finally, we show that differential logical relations can be\norganised in a cartesian closed category, contrarily to metric relations, which\nare well-known not to have such a structure, but only that of a monoidal closed\ncategory.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 09:48:36 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Gavazzo", "Francesco", ""], ["Yoshimizu", "Akira", ""]]}, {"id": "1904.12156", "submitter": "Arne Meier", "authors": "Anselm Haak and Arne Meier and Om Prakash and B. V. Raghavendra Rao", "title": "Parameterised Counting in Logspace", "comments": "Updated technical report to final version at STACS21", "journal-ref": null, "doi": "10.4230/LIPIcs.STACS.2021.45", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new framework for parameterised counting in\nlogspace, inspired by the parameterised space bounded models developed by\nElberfeld, Stockhusen and Tantau (IPEC 2013, Algorithmica 2015). They defined\nthe operators paraW and paraBeta for parameterised space complexity classes by\nallowing bounded nondeterminism with multiple-read and read-once access,\nrespectively. Using these operators, they characterised the parameterised\ncomplexity of natural problems on graphs. In the spirit of the operators paraW\nand paraBeta by Stockhusen and Tantau, we introduce variants based on\ntail-nondeterminism, paraW[1] and paraBeta-Tail. Then, we consider counting\nversions of all four operators applied to logspace and obtain several natural\ncomplete problems for the resulting classes: counting of paths in digraphs,\ncounting first-order models for formulas, and counting graph homomorphisms.\nFurthermore, we show that the complexity of a parameterised variant of the\ndeterminant function for (0,1)-matrices is #paraBeta-Tail-L-hard and can be\nwritten as the difference of two functions in #paraBetaTail-L. For example, we\nshow that the closure of #paraBetaTail-L under parameterised logspace\nparsimonious reductions coincides with #paraBeta-L, that is, modulo\nparameterised reductions, tail-nondeterminism with read-once access is the same\nas read-once nondeterminism. We show that all introduced classes are closed\nunder addition and multiplication, and those without tail-nondeterminism are\nclosed under parameterised logspace parsimonious reductions. Finally, we\nunderline the significance of this topic by providing a promising outlook\nshowing several open problems and options for further directions of research.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 13:12:28 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 09:25:01 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 09:23:44 GMT"}, {"version": "v4", "created": "Mon, 11 May 2020 09:42:28 GMT"}, {"version": "v5", "created": "Fri, 15 Jan 2021 16:03:24 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Haak", "Anselm", ""], ["Meier", "Arne", ""], ["Prakash", "Om", ""], ["Rao", "B. V. Raghavendra", ""]]}, {"id": "1904.12533", "submitter": "Carsten Lutz", "authors": "Carsten Lutz and Leif Sabellek", "title": "A Complete Classification of the Complexity and Rewritability of\n  Ontology-Mediated Queries based on the Description Logic EL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an ultimately fine-grained analysis of the data complexity and\nrewritability of ontology-mediated queries (OMQs) based on an EL ontology and a\nconjunctive query (CQ). Our main results are that every such OMQ is in AC0,\nNL-complete, or PTime-complete and that containment in NL coincides with\nrewritability into linear Datalog (whereas containment in AC0 coincides with\nrewritability into first-order logic). We establish natural characterizations\nof the three cases in terms of bounded depth and (un)bounded pathwidth, and\nshow that every of the associated meta problems such as deciding wether a given\nOMQ is rewritable into linear Datalog is ExpTime-complete. We also give a way\nto construct linear Datalog rewritings when they exist and prove that there is\nno constant Datalog rewritings.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 09:34:54 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Lutz", "Carsten", ""], ["Sabellek", "Leif", ""]]}, {"id": "1904.12829", "submitter": "EPTCS", "authors": "Nicolas Behr (Universit\\'e de Paris, IRIF, CNRS)", "title": "Tracelets and Tracelet Analysis Of Compositional Rewriting Systems", "comments": "In Proceedings ACT 2019, arXiv:2009.06334", "journal-ref": "EPTCS 323, 2020, pp. 44-71", "doi": "10.4204/EPTCS.323.4", "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking advantage of a recently discovered associativity property of rule\ncompositions, we extend the classical concurrency theory for rewriting systems\nover adhesive categories. We introduce the notion of tracelets, which are\ndefined as minimal derivation traces that universally encode sequential\ncompositions of rewriting rules. Tracelets are compositional, capture the\ncausality of equivalence classes of traditional derivation traces, and\nintrinsically suggest a clean mathematical framework for the definition of\nvarious notions of abstractions of traces. We illustrate these features by\nintroducing a first prototype for a framework of tracelet analysis, which as a\nkey application permits to formulate a first-of-its-kind algorithm for the\nstatic generation of minimal derivation traces with prescribed terminal events.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:22:36 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 02:13:39 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Behr", "Nicolas", "", "Universit\u00e9 de Paris, IRIF, CNRS"]]}, {"id": "1904.12927", "submitter": "Florian Lonsing", "authors": "Florian Lonsing and Uwe Egly", "title": "QRATPre+: Effective QBF Preprocessing via Strong Redundancy Properties", "comments": "preprint of a paper to be published at SAT 2019, LNCS, Springer,\n  including appendix", "journal-ref": null, "doi": "10.1007/978-3-030-24258-9_14", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present version 2.0 of QRATPre+, a preprocessor for quantified Boolean\nformulas (QBFs) based on the QRAT proof system and its generalization QRAT+.\nThese systems rely on strong redundancy properties of clauses and universal\nliterals. QRATPre+ is the first implementation of these redundancy properties\nin QRAT and QRAT+ used to simplify QBFs in preprocessing. It is written in C\nand features an API for easy integration in other QBF tools. We present\nimplementation details and report on experimental results demonstrating that\nQRATPre+ improves upon the power of state-of-the-art preprocessors and solvers.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 19:57:59 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 05:26:06 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Lonsing", "Florian", ""], ["Egly", "Uwe", ""]]}, {"id": "1904.13112", "submitter": "Thorsten Wissmann", "authors": "Ludwig Staiger", "title": "On the incomputability of computable dimension", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 2 (May 14,\n  2020) lmcs:6474", "doi": "10.23638/LMCS-16(2:5)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using an iterative tree construction we show that for simple computable\nsubsets of the Cantor space Hausdorff, constructive and computable dimensions\nmight be incomputable.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 09:07:37 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 15:20:13 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 07:37:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Staiger", "Ludwig", ""]]}, {"id": "1904.13196", "submitter": "Marjan Alirezaie", "authors": "Marjan Alirezaie, Martin L\\\"angkvist, Michael Sioutis, Amy Loutfi", "title": "Semantic Referee: A Neural-Symbolic Framework for Enhancing Geospatial\n  Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Understanding why machine learning algorithms may fail is usually the task of\nthe human expert that uses domain knowledge and contextual information to\ndiscover systematic shortcomings in either the data or the algorithm. In this\npaper, we propose a semantic referee, which is able to extract qualitative\nfeatures of the errors emerging from deep machine learning frameworks and\nsuggest corrections. The semantic referee relies on ontological reasoning about\nspatial knowledge in order to characterize errors in terms of their spatial\nrelations with the environment. Using semantics, the reasoner interacts with\nthe learning algorithm as a supervisor. In this paper, the proposed method of\nthe interaction between a neural network classifier and a semantic referee\nshows how to improve the performance of semantic segmentation for satellite\nimagery data.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 12:44:22 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Alirezaie", "Marjan", ""], ["L\u00e4ngkvist", "Martin", ""], ["Sioutis", "Michael", ""], ["Loutfi", "Amy", ""]]}, {"id": "1904.13203", "submitter": "Holger Thies", "authors": "Florian Steinberg and Laurent Thery and Holger Thies", "title": "Computable analysis and notions of continuity in Coq", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (May 12,\n  2021) lmcs:7478", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a number of formal proofs of theorems from the field of computable\nanalysis. Many of our results specify executable algorithms that work on\ninfinite inputs by means of operating on finite approximations and are proven\ncorrect in the sense of computable analysis. The development is done in the\nproof assistant Coq and heavily relies on the Incone library for information\ntheoretic continuity. This library is developed by one of the authors and the\npaper can be used as an introduction to the library as it describes many of its\nmost important features in detail. While the ability to have full executability\nin a formal development of mathematical statements about real numbers and the\nlike is not a feature that is unique to the Incone library, its original\ncontribution is to adhere to the conventions of computable analysis to provide\na general purpose interface for algorithmic reasoning on continuous structures.\nThe results that provide complete computational content include that the\nalgebraic operations and the efficient limit operator on the reals are\ncomputable, that certain countably infinite products are isomorphic to spaces\nof functions, compatibility of the enumeration representation of subsets of\nnatural numbers with the abstract definition of the space of open subsets of\nthe natural numbers, and that continuous realizability implies sequential\ncontinuity. We also formalize proofs of non-computational results that support\nthe correctness of our definitions. These include that the information\ntheoretic notion of continuity used in the library is equivalent to the metric\nnotion of continuity on Baire space, a complete comparison of the different\nconcepts of continuity that arise from metric and represented-space structures\nand the discontinuity of the unrestricted limit operator on the real numbers\nand the task of selecting an element of a closed subset of the natural numbers.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 13:09:57 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 17:14:05 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 13:50:37 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 11:26:49 GMT"}, {"version": "v5", "created": "Tue, 11 May 2021 13:40:45 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Steinberg", "Florian", ""], ["Thery", "Laurent", ""], ["Thies", "Holger", ""]]}, {"id": "1904.13320", "submitter": "Thorsten Wissmann", "authors": "Francesco Ciraulo and Michele Contente", "title": "Overlap Algebras: a Constructive Look at Complete Boolean Algebras", "comments": "Postproceedings of CCC2018: Continuity, Computability,\n  Constructivity. Faro, Portugal, 24-28 Sep 2018", "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (February\n  13, 2020) lmcs:6096", "doi": "10.23638/LMCS-16(1:13)2020", "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notion of a complete Boolean algebra, although completely legitimate in\nconstructive mathematics, fails to capture some natural structures such as the\nlattice of subsets of a given set. Sambin's notion of an overlap algebra,\nalthough classically equivalent to that of a complete Boolean algebra, has\npowersets and other natural structures as instances. In this paper we study the\ncategory of overlap algebras as an extension of the category of sets and\nrelations, and we establish some basic facts about mono-epi-isomorphisms and\n(co)limits; here a morphism is a symmetrizable function (with classical logic\nthis is just a function which preserves joins). Then we specialize to the case\nof morphisms which preserve also finite meets: classically, this is the usual\ncategory of complete Boolean algebras. Finally, we connect overlap algebras\nwith locales, and their morphisms with open maps between locales, thus\nobtaining constructive versions of some results about Boolean locales.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 15:34:07 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 13:30:48 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 06:20:07 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ciraulo", "Francesco", ""], ["Contente", "Michele", ""]]}, {"id": "1904.13338", "submitter": "Eduard Kamburjan", "authors": "Eduard Kamburjan", "title": "Behavioral Program Logic and LAGC Semantics without Continuations\n  (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Behavioral Program Logic (BPL), a dynamic logic for trace\nproperties that incorporates concepts from behavioral types and allows\nreasoning about non-functional properties within a sequent calculus. BPL uses\nbehavioral modalities [s |- {\\tau} ], to verify statements s against behavioral\nspecifications {\\tau}. Behavioral specifications generalize postconditions and\nbehavioral types. They can be used to specify other static analyses, e.g., data\nflow analyses. This enables deductive reasoning about the results of multiple\nanalyses on the same program, potentially implemented in different formalisms.\nOur calculus for BPL verifies the behavioral specification gradually, as common\nfor behavioral types. This vastly simplifies specification, calculus and\ncomposition of local results. We present a sequent calculus for object-oriented\nactors with futures that integrates a pointer analysis and bridges the gap\nbetween behavioral types and deductive verification. This technical report\nintroduces (1) complete LAGC semantics of a Core Active Object language (CAO)\nwithout continuations (2) Behavioral Program Logic and (3) gives an example for\na behavioral type expressed in Behavioral Program Logic, method types. This\nreport contains the soundness proofs for method types. While the semantics\ncover CAO with suspension, the method types do not, to simplify the\npresentation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:09:06 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Kamburjan", "Eduard", ""]]}, {"id": "1904.13354", "submitter": "Thorsten Wissmann", "authors": "Tom de Jong and Jaap van Oosten", "title": "The Sierpinski Object in the Scott Realizability Topos", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (August\n  20, 2020) lmcs:6724", "doi": "10.23638/LMCS-16(3:12)2020", "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the Sierpinski object $\\Sigma$ in the realizability topos based on\nScott's graph model of the $\\lambda$-calculus. Our starting observation is that\nthe object of realizers in this topos is the exponential $\\Sigma ^N$, where $N$\nis the natural numbers object. We define order-discrete objects by\northogonality to $\\Sigma$. We show that the order-discrete objects form a\nreflective subcategory of the topos, and that many fundamental objects in\nhigher-type arithmetic are order-discrete. Building on work by Lietz, we give\nsome new results regarding the internal logic of the topos. Then we consider\n$\\Sigma$ as a dominance; we explicitly construct the lift functor and\ncharacterize $\\Sigma$-subobjects. Contrary to our expectations the dominance\n$\\Sigma$ is not closed under unions. In the last section we build a model for\nhomotopy theory, where the order-discrete objects are exactly those objects\nwhich only have constant paths.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:34:41 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 14:20:52 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 11:55:28 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2020 14:37:18 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["de Jong", "Tom", ""], ["van Oosten", "Jaap", ""]]}]