[{"id": "0906.0049", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov, Joey Paquet, and Mourad Debbabi", "title": "Towards Automated Deduction in Blackmail Case Analysis with Forensic\n  Lucid", "comments": "11 pages, 7 figures; related to arXiv:0904.3789 and arXiv:0905.2449", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work-in-progress focuses on the refinement of application of the\nintensional logic to cyberforensic analysis and its benefits are compared with\nthe finite-state automata approach. This work extends the use of the scientific\nintensional programming paradigm onto modeling and implementation of a\ncyberforensics investigation process with the backtrace of event\nreconstruction, modeling the evidence as multidimensional hierarchical\ncontexts, and proving or disproving the claims with it in the intensional\nmanner of evaluation. This is a practical, context-aware improvement over the\nfinite state automata (FSA) approach we have seen in the related works. As a\nbase implementation language model we use in this approach is a new dialect of\nthe Lucid programming language, that we call Forensic Lucid and in this paper\nwe focus on defining hierarchical contexts based on the intensional logic for\nthe evaluation of cyberforensic expressions.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2009 02:04:15 GMT"}], "update_date": "2009-06-02", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""], ["Debbabi", "Mourad", ""]]}, {"id": "0906.0380", "submitter": "Damiano Mazza", "authors": "Damiano Mazza", "title": "Observational Equivalence and Full Abstraction in the Symmetric\n  Interaction Combinators", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 4 (December\n  22, 2009) lmcs:1150", "doi": "10.2168/LMCS-5(4:6)2009", "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The symmetric interaction combinators are an equally expressive variant of\nLafont's interaction combinators. They are a graph-rewriting model of\ndeterministic computation. We define two notions of observational equivalence\nfor them, analogous to normal form and head normal form equivalence in the\nlambda-calculus. Then, we prove a full abstraction result for each of the two\nequivalences. This is obtained by interpreting nets as certain subsets of the\nCantor space, called edifices, which play the same role as Boehm trees in the\ntheory of the lambda-calculus.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 21:14:58 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2009 16:05:46 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2009 09:11:40 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Mazza", "Damiano", ""]]}, {"id": "0906.1182", "submitter": "Paolo Mancarella", "authors": "P. Mancarella, G. Terreni, F. Sadri, F. Toni, U. Endriss", "title": "The CIFF Proof Procedure for Abductive Logic Programming with\n  Constraints: Theory, Implementation and Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the CIFF proof procedure for abductive logic programming with\nconstraints, and we prove its correctness. CIFF is an extension of the IFF\nproof procedure for abductive logic programming, relaxing the original\nrestrictions over variable quantification (allowedness conditions) and\nincorporating a constraint solver to deal with numerical constraints as in\nconstraint logic programming. Finally, we describe the CIFF system, comparing\nit with state of the art abductive systems and answer set solvers and showing\nhow to use it to program some applications. (To appear in Theory and Practice\nof Logic Programming - TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2009 16:13:23 GMT"}], "update_date": "2009-06-08", "authors_parsed": [["Mancarella", "P.", ""], ["Terreni", "G.", ""], ["Sadri", "F.", ""], ["Toni", "F.", ""], ["Endriss", "U.", ""]]}, {"id": "0906.1199", "submitter": "Yannick Chevalier", "authors": "Yannick Chevalier (LORIA), Kourjieh Mounira (IRIT)", "title": "On the Decidability of (ground) Reachability Problems for Cryptographic\n  Protocols (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of cryptographic protocols in a symbolic model is relative to a\ndeduction system that models the possible actions of an attacker regarding an\nexecution of this protocol. We present in this paper a transformation algorithm\nfor such deduction systems provided the equational theory has the finite\nvariant property. the termination of this transformation entails the\ndecidability of the ground reachability problems. We prove that it is necessary\nto add one other condition to obtain the decidability of non-ground problems,\nand provide one new such criterion.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2009 20:00:15 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Chevalier", "Yannick", "", "LORIA"], ["Mounira", "Kourjieh", "", "IRIT"]]}, {"id": "0906.1350", "submitter": "Jan Schwinghammer", "authors": "Catalin Hritcu and Jan Schwinghammer", "title": "A Step-indexed Semantics of Imperative Objects", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 4 (December\n  18, 2009) lmcs:744", "doi": "10.2168/LMCS-5(4:2)2009", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Step-indexed semantic interpretations of types were proposed as an\nalternative to purely syntactic proofs of type safety using subject reduction.\nThe types are interpreted as sets of values indexed by the number of\ncomputation steps for which these values are guaranteed to behave like proper\nelements of the type. Building on work by Ahmed, Appel and others, we introduce\na step-indexed semantics for the imperative object calculus of Abadi and\nCardelli. Providing a semantic account of this calculus using more\n`traditional', domain-theoretic approaches has proved challenging due to the\ncombination of dynamically allocated objects, higher-order store, and an\nexpressive type system. Here we show that, using step-indexing, one can\ninterpret a rich type discipline with object types, subtyping, recursive and\nbounded quantified types in the presence of state.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2009 11:42:45 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2009 14:58:00 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Hritcu", "Catalin", ""], ["Schwinghammer", "Jan", ""]]}, {"id": "0906.1489", "submitter": "Martin Mundhenk", "authors": "Arne Meier, Martin Mundhenk, Thomas Schneider, Michael Thomas, Volker\n  Weber, Felix Weiss", "title": "The Complexity of Satisfiability for Fragments of Hybrid Logic -- Part I", "comments": null, "journal-ref": null, "doi": "10.1016/j.jal.2010.08.001", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The satisfiability problem of hybrid logics with the downarrow binder is\nknown to be undecidable. This initiated a research program on decidable and\ntractable fragments. In this paper, we investigate the effect of restricting\nthe propositional part of the language on decidability and on the complexity of\nthe satisfiability problem over arbitrary, transitive, total frames, and frames\nbased on equivalence relations. We also consider different sets of modal and\nhybrid operators. We trace the border of decidability and give the precise\ncomplexity of most fragments, in particular for all fragments including\nnegation. For the monotone fragments, we are able to distinguish the easy from\nthe hard cases, depending on the allowed set of operators.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2009 13:17:35 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Meier", "Arne", ""], ["Mundhenk", "Martin", ""], ["Schneider", "Thomas", ""], ["Thomas", "Michael", ""], ["Weber", "Volker", ""], ["Weiss", "Felix", ""]]}, {"id": "0906.1593", "submitter": "Didehvar Farzaad", "authors": "Farzad Didehvar", "title": "On Defining 'I' \"I logy\"", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Could we define I? Throughout this article we give a negative answer to this\nquestion. More exactly, we show that there is no definition for I in a certain\nway. But this negative answer depends on our definition of definability. Here,\nwe try to consider sufficient generalized definition of definability. In the\nmiddle of paper a paradox will arise which makes us to modify the way we use\nthe concept of property and definability.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2009 04:34:54 GMT"}], "update_date": "2009-06-10", "authors_parsed": [["Didehvar", "Farzad", ""]]}, {"id": "0906.1726", "submitter": "Robin Adams", "authors": "Robin Adams, Zhaohui Luo", "title": "Classical Predicative Logic-Enriched Type Theories", "comments": "49 pages. Accepted for publication in special edition of Annals of\n  Pure and Applied Logic on Computation in Classical Logic. v2: Minor mistakes\n  corrected", "journal-ref": null, "doi": "10.1016/j.apal.2010.04.005", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A logic-enriched type theory (LTT) is a type theory extended with a primitive\nmechanism for forming and proving propositions. We construct two LTTs, named\nLTTO and LTTO*, which we claim correspond closely to the classical predicative\nsystems of second order arithmetic ACAO and ACA. We justify this claim by\ntranslating each second-order system into the corresponding LTT, and proving\nthat these translations are conservative. This is part of an ongoing research\nproject to investigate how LTTs may be used to formalise different approaches\nto the foundations of mathematics.\n  The two LTTs we construct are subsystems of the logic-enriched type theory\nLTTW, which is intended to formalise the classical predicative foundation\npresented by Herman Weyl in his monograph Das Kontinuum. The system ACAO has\nalso been claimed to correspond to Weyl's foundation. By casting ACAO and ACA\nas LTTs, we are able to compare them with LTTW. It is a consequence of the work\nin this paper that LTTW is strictly stronger than ACAO.\n  The conservativity proof makes use of a novel technique for proving one LTT\nconservative over another, involving defining an interpretation of the stronger\nsystem out of the expressions of the weaker. This technique should be\napplicable in a wide variety of different cases outside the present work.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2009 13:44:28 GMT"}, {"version": "v2", "created": "Wed, 18 Aug 2010 10:23:52 GMT"}], "update_date": "2010-08-19", "authors_parsed": [["Adams", "Robin", ""], ["Luo", "Zhaohui", ""]]}, {"id": "0906.2154", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze (School of Computer Science and Technology, Shandong\n  University, Department of Co)", "title": "From formulas to cirquents in computability logic", "comments": "LMCS 7 (2:1) 2011", "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 2 (April 21,\n  2011) lmcs:1121", "doi": "10.2168/LMCS-7(2:1)2011", "report-no": null, "categories": "cs.LO cs.AI cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computability logic (CoL) (see http://www.cis.upenn.edu/~giorgi/cl.html) is a\nrecently introduced semantical platform and ambitious program for redeveloping\nlogic as a formal theory of computability, as opposed to the formal theory of\ntruth that logic has more traditionally been. Its expressions represent\ninteractive computational tasks seen as games played by a machine against the\nenvironment, and \"truth\" is understood as existence of an algorithmic winning\nstrategy. With logical operators standing for operations on games, the\nformalism of CoL is open-ended, and has already undergone series of extensions.\nThis article extends the expressive power of CoL in a qualitatively new way,\ngeneralizing formulas (to which the earlier languages of CoL were limited) to\ncircuit-style structures termed cirquents. The latter, unlike formulas, are\nable to account for subgame/subtask sharing between different parts of the\noverall game/task. Among the many advantages offered by this ability is that it\nallows us to capture, refine and generalize the well known\nindependence-friendly logic which, after the present leap forward, naturally\nbecomes a conservative fragment of CoL, just as classical logic had been known\nto be a conservative fragment of the formula-based version of CoL. Technically,\nthis paper is self-contained, and can be read without any prior familiarity\nwith CoL.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2009 16:34:51 GMT"}, {"version": "v2", "created": "Tue, 17 Aug 2010 10:16:42 GMT"}, {"version": "v3", "created": "Sat, 1 Jan 2011 22:31:55 GMT"}, {"version": "v4", "created": "Wed, 20 Apr 2011 16:44:25 GMT"}, {"version": "v5", "created": "Fri, 22 Apr 2011 07:31:58 GMT"}, {"version": "v6", "created": "Mon, 25 Apr 2011 21:46:55 GMT"}, {"version": "v7", "created": "Wed, 27 Apr 2011 16:46:20 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Japaridze", "Giorgi", "", "School of Computer Science and Technology, Shandong\n  University, Department of Co"]]}, {"id": "0906.2228", "submitter": "Hans Tompits", "authors": "David Pearce, Hans Tompits, Stefan Woltran", "title": "Characterising equilibrium logic and nested logic programs: Reductions\n  and complexity", "comments": null, "journal-ref": "Theory and Practice of Logic Programming (2009), 9 : 565-616", "doi": "10.1017/S147106840999010X", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium logic is an approach to nonmonotonic reasoning that extends the\nstable-model and answer-set semantics for logic programs. In particular, it\nincludes the general case of nested logic programs, where arbitrary Boolean\ncombinations are permitted in heads and bodies of rules, as special kinds of\ntheories. In this paper, we present polynomial reductions of the main reasoning\ntasks associated with equilibrium logic and nested logic programs into\nquantified propositional logic, an extension of classical propositional logic\nwhere quantifications over atomic formulas are permitted. We provide reductions\nnot only for decision problems, but also for the central semantical concepts of\nequilibrium logic and nested logic programs. In particular, our encodings map a\ngiven decision problem into some formula such that the latter is valid\nprecisely in case the former holds. The basic tasks we deal with here are the\nconsistency problem, brave reasoning, and skeptical reasoning. Additionally, we\nalso provide encodings for testing equivalence of theories or programs under\ndifferent notions of equivalence, viz. ordinary, strong, and uniform\nequivalence. For all considered reasoning tasks, we analyse their computational\ncomplexity and give strict complexity bounds.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2009 23:24:43 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2009 17:47:12 GMT"}], "update_date": "2009-12-30", "authors_parsed": [["Pearce", "David", ""], ["Tompits", "Hans", ""], ["Woltran", "Stefan", ""]]}, {"id": "0906.2521", "submitter": "Thomas Schwentick", "authors": "Volker Weber", "title": "On the Complexity of Branching-Time Logics", "comments": "The author of this paper, Volker Weber, died after submitting it to\n  CSL 2009. The version published here incorporates a few small changes as\n  suggested by reviewers of CSL. It was prepared by his Ph.D. advisor, Thomas\n  Schwentick", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify the complexity of the satisfiability problem for extensions of\nCTL and UB. The extensions we consider are Boolean combinations of path\nformulas, fairness properties, past modalities, and forgettable past. Our main\nresult shows that satisfiability for CTL with all these extensions is still in\n2-EXPTIME, which strongly contrasts with the nonelementary complexity of CTL*\nwith forgettable past. We give a complete classification of combinations of\nthese extensions, yielding a dichotomy between extensions with\n2-EXPTIME-complete and those with EXPTIME-complete complexity. In particular,\nwe show that satisfiability for the extension of UB with forgettable past is\ncomplete for 2-EXPTIME, contradicting a claim for a stronger logic in the\nliterature. The upper bounds are established with the help of a new kind of\npebble automata.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2009 09:20:10 GMT"}], "update_date": "2009-06-16", "authors_parsed": [["Weber", "Volker", ""]]}, {"id": "0906.2541", "submitter": "Thomas Schwentick", "authors": "Ahmet Kara, Martin Lange, Thomas Schwentick, Volker Weber", "title": "On the Hybrid Extension of CTL and CTL+", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-03816-7_37", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies the expressivity, relative succinctness and complexity of\nsatisfiability for hybrid extensions of the branching-time logics CTL and CTL+\nby variables. Previous complexity results show that only fragments with one\nvariable do have elementary complexity. It is shown that H1CTL+ and H1CTL, the\nhybrid extensions with one variable of CTL+ and CTL, respectively, are\nexpressively equivalent but H1CTL+ is exponentially more succinct than H1CTL.\nOn the other hand, HCTL+, the hybrid extension of CTL with arbitrarily many\nvariables does not capture CTL*, as it even cannot express the simple CTL*\nproperty EGFp. The satisfiability problem for H1CTL+ is complete for triply\nexponential time, this remains true for quite weak fragments and quite strong\nextensions of the logic.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2009 14:35:09 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Kara", "Ahmet", ""], ["Lange", "Martin", ""], ["Schwentick", "Thomas", ""], ["Weber", "Volker", ""]]}, {"id": "0906.2727", "submitter": "Pietro Di Gianantonio", "authors": "Pietro Di Gianantonio, Furio Honsell and Marina Lenisa", "title": "RPO, Second-order Contexts, and Lambda-calculus", "comments": "35 pages, published in Logical Methods in Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 3 (August 6,\n  2009) lmcs:1120", "doi": "10.2168/LMCS-5(3:6)2009", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First, we extend Leifer-Milner RPO theory, by giving general conditions to\nobtain IPO labelled transition systems (and bisimilarities) with a reduced set\nof transitions, and possibly finitely branching. Moreover, we study the weak\nvariant of Leifer-Milner theory, by giving general conditions under which the\nweak bisimilarity is a congruence. Then, we apply such extended RPO technique\nto the lambda-calculus, endowed with lazy and call by value reduction\nstrategies.\n  We show that, contrary to process calculi, one can deal directly with the\nlambda-calculus syntax and apply Leifer-Milner technique to a category of\ncontexts, provided that we work in the framework of weak bisimilarities.\n  However, even in the case of the transition system with minimal contexts, the\nresulting bisimilarity is infinitely branching, due to the fact that, in\nstandard context categories, parametric rules such as the beta-rule can be\nrepresented only by infinitely many ground rules.\n  To overcome this problem, we introduce the general notion of second-order\ncontext category. We show that, by carrying out the RPO construction in this\nsetting, the lazy observational equivalence can be captured as a weak\nbisimilarity equivalence on a finitely branching transition system. This result\nis achieved by considering an encoding of lambda-calculus in Combinatory Logic.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2009 15:44:56 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2009 08:18:28 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Di Gianantonio", "Pietro", ""], ["Honsell", "Furio", ""], ["Lenisa", "Marina", ""]]}, {"id": "0906.2756", "submitter": "Carl Hewitt", "authors": "Carl Hewitt", "title": "Norms and Commitment for iOrgs(TM) Information Systems: Direct Logic(TM)\n  and Participatory Grounding Checking", "comments": "expanded article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental assumption of the Event Calculus is overly simplistic when it\ncomes to organizations in which time-varying properties have to be actively\nmaintained and managed in order to continue to hold and termination by another\naction is not required for a property to no longer hold. I.e., if active\nmeasures are not taken then things will go haywire by default. Similarly\nextension and revision is required for Grounding Checking properties of systems\nbased on a set of ground inferences. Previously Model Checking as been\nperformed using the model of nondeterministic automata based on states\ndetermined by time-points. These nondeterministic automata are not suitable for\niOrgs, which are highly structured and operate asynchronously with only loosely\nbounded nondeterminism. iOrgs Information Systems have been developed as a\ntechnology in which organizations have people that are tightly integrated with\ninformation technology that enables them to function organizationally. iOrgs\nformalize existing practices to provide a framework for addressing issues of\nauthority, accountability, scalability, and robustness using methods that are\nanalogous to human organizations. In general -iOrgs are a natural extension Web\nServices, which are the standard for distributed computing and software\napplication interoperability in large-scale Organizational Computing. -iOrgs\nare structured by Organizational Commitment that is a special case of Physical\nCommitment that is defined to be information pledged. iOrgs norms are used to\nillustrate the following: -Even a very simple microtheory for normative\nreasoning can engender inconsistency In practice, it is impossible to verify\nthe consistency of a theory for a practical domain. -Improved Safety in\nReasoning. It is not safe to use classical logic and probability theory in\npractical reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2009 18:38:17 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2009 21:28:48 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2009 20:03:54 GMT"}, {"version": "v4", "created": "Thu, 8 Apr 2010 10:31:57 GMT"}, {"version": "v5", "created": "Mon, 26 Apr 2010 13:22:51 GMT"}, {"version": "v6", "created": "Sat, 6 Nov 2010 21:47:00 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Hewitt", "Carl", ""]]}, {"id": "0906.2866", "submitter": "Pierre Hyvernat", "authors": "Pierre Hyvernat (LAMA, Iml)", "title": "Predicate Transformers, (co)Monads and Resolutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note contains random thoughts about a factorization theorem for\nclosure/interior operators on a powerset which is reminiscent to the notion of\nresolution for a monad/comonad. The question originated from formal topology\nbut is interesting in itself. The result holds constructively (even if it\nclassically has several variations); but usually not predicatively (in the\nsense that the interpolant will no be given by a set). For those not familiar\nwith predicativity issues, we look at a ``classical'' version where we bound\nthe size of the interpolant.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2009 08:33:18 GMT"}], "update_date": "2009-06-17", "authors_parsed": [["Hyvernat", "Pierre", "", "LAMA, Iml"]]}, {"id": "0906.2995", "submitter": "Manfred Kufleitner", "authors": "Volker Diekert, Manfred Kufleitner", "title": "Fragments of first-order logic over infinite words", "comments": "Conference version presented at 26th International Symposium on\n  Theoretical Aspects of Computer Science, STACS 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give topological and algebraic characterizations as well as language\ntheoretic descriptions of the following subclasses of first-order logic FO[<]\nfor omega-languages: Sigma_2, FO^2, the intersection of FO^2 and Sigma_2, and\nDelta_2 (and by duality Pi_2 and the intersection of FO^2 and Pi_2). These\ndescriptions extend the respective results for finite words. In particular, we\nrelate the above fragments to language classes of certain (unambiguous)\npolynomials. An immediate consequence is the decidability of the membership\nproblem of these classes, but this was shown before by Wilke and Bojanczyk and\nis therefore not our main focus. The paper is about the interplay of algebraic,\ntopological, and language theoretic properties.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2009 18:43:43 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2009 20:52:31 GMT"}], "update_date": "2009-10-02", "authors_parsed": [["Diekert", "Volker", ""], ["Kufleitner", "Manfred", ""]]}, {"id": "0906.3228", "submitter": "EPTCS", "authors": "Klaus Sutner", "title": "Computational Processes and Incompleteness", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 226-234", "doi": "10.4204/EPTCS.1.22", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a formal definition of Wolfram's notion of computational process\nbased on cellular automata, a physics-like model of computation. There is a\nnatural classification of these processes into decidable, intermediate and\ncomplete. It is shown that in the context of standard finite injury priority\narguments one cannot establish the existence of an intermediate computational\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 16:13:53 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Sutner", "Klaus", ""]]}, {"id": "0906.3235", "submitter": "EPTCS", "authors": "Cristian S. Calude", "title": "Simplicity via Provability for Universal Prefix-free Turing Machines", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 16-21", "doi": "10.4204/EPTCS.1.2", "report-no": null, "categories": "cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universality is one of the most important ideas in computability theory.\nThere are various criteria of simplicity for universal Turing machines.\nProbably the most popular one is to count the number of states/symbols. This\ncriterion is more complex than it may appear at a first glance. In this note we\nreview recent results in Algorithmic Information Theory and propose three new\ncriteria of simplicity for universal prefix-free Turing machines. These\ncriteria refer to the possibility of proving various natural properties of such\na machine (its universality, for example) in a formal theory, PA or ZFC. In all\ncases some, but not all, machines are simple.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 16:25:45 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Calude", "Cristian S.", ""]]}, {"id": "0906.3257", "submitter": "EPTCS", "authors": "Gr\\'egory Lafitte", "title": "Busy beavers gone wild", "comments": null, "journal-ref": "EPTCS 1, 2009, pp. 123-129", "doi": "10.4204/EPTCS.1.12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show some incompleteness results a la Chaitin using the busy beaver\nfunctions. Then, with the help of ordinal logics, we show how to obtain a\ntheory in which the values of the busy beaver functions can be provably\nestablished and use this to reveal a structure on the provability of the values\nof these functions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 17:19:05 GMT"}], "update_date": "2009-06-22", "authors_parsed": [["Lafitte", "Gr\u00e9gory", ""]]}, {"id": "0906.3815", "submitter": "Wlodzimierz Drabent", "authors": "W. Drabent, J. Maluszynski", "title": "Hybrid Rules with Well-Founded Semantics", "comments": null, "journal-ref": "Knowledge and Information Systems, 25:137-168, 2010", "doi": "10.1007/s10115-010-0300-5", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general framework is proposed for integration of rules and external first\norder theories. It is based on the well-founded semantics of normal logic\nprograms and inspired by ideas of Constraint Logic Programming (CLP) and\nconstructive negation for logic programs. Hybrid rules are normal clauses\nextended with constraints in the bodies; constraints are certain formulae in\nthe language of the external theory. A hybrid program is a pair of a set of\nhybrid rules and an external theory. Instances of the framework are obtained by\nspecifying the class of external theories, and the class of constraints. An\nexample instance is integration of (non-disjunctive) Datalog with ontologies\nformalized as description logics.\n  The paper defines a declarative semantics of hybrid programs and a\ngoal-driven formal operational semantics. The latter can be seen as a\ngeneralization of SLS-resolution. It provides a basis for hybrid\nimplementations combining Prolog with constraint solvers. Soundness of the\noperational semantics is proven. Sufficient conditions for decidability of the\ndeclarative semantics, and for completeness of the operational semantics are\ngiven.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2009 16:09:24 GMT"}], "update_date": "2010-12-08", "authors_parsed": [["Drabent", "W.", ""], ["Maluszynski", "J.", ""]]}, {"id": "0906.3919", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov and Joey Paquet", "title": "A Type System Theory for Higher-Order Intensional Logic Support for\n  Variable Bindings in Hybrid Intensional-Imperative Programs in GIPSY", "comments": "12 pages, 1 table; 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a type system for a platform called the General Intensional\nProgramming System (GIPSY), designed to support intensional programming\nlanguages built upon intensional logic and their imperative counter-parts for\nthe intensional execution model. In GIPSY, the type system glues the static and\ndynamic typing between intensional and imperative languages in its compiler and\nrun-time environments to support the intensional evaluation of expressions\nwritten in various dialects of the intensional programming language Lucid. The\nintensionality makes expressions to explicitly take into the account a\nmultidimensional context of evaluation with the context being a first-class\nvalue that serves a number of applications that need the notion of context to\nproceed. We describe and discuss the properties of such a type system and the\nrelated type theory as well as particularities of the semantics, design and\nimplementation of the GIPSY type system.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 05:27:49 GMT"}], "update_date": "2009-12-21", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""]]}, {"id": "0906.3994", "submitter": "Emmanuel Beffara", "authors": "Emmanuel Beffara (IML)", "title": "Quantitative testing semantics for non-interleaving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a non-interleaving denotational semantics for the\n?-calculus. The basic idea is to define a notion of test where the outcome is\nnot only whether a given process passes a given test, but also in how many\ndifferent ways it can pass it. More abstractly, the set of possible outcomes\nfor tests forms a semiring, and the set of process interpretations appears as a\nmodule over this semiring, in which basic syntactic constructs are affine\noperators. This notion of test leads to a trace semantics in which traces are\npartial orders, in the style of Mazurkiewicz traces, extended with readiness\ninformation. Our construction has standard may- and must-testing as special\ncases.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 13:02:27 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Beffara", "Emmanuel", "", "IML"]]}, {"id": "0906.4173", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (LIAMA), Cody Roux (INRIA Lorraine - LORIA)", "title": "On the relation between size-based termination and semantic labelling", "comments": null, "journal-ref": "18th EACSL Annual Conference on Computer Science Logic (2009)", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the relationship between two independently developed\ntermination techniques. On the one hand, sized-types based termination (SBT)\nuses types annotated with size expressions and Girard's reducibility\ncandidates, and applies on systems using constructor matching only. On the\nother hand, semantic labelling transforms a rewrite system by annotating each\nfunction symbol with the semantics of its arguments, and applies to any rewrite\nsystem. First, we introduce a simplified version of SBT for the simply-typed\nlambda-calculus. Then, we give new proofs of the correctness of SBT using\nsemantic labelling, both in the first and in the higher-order case. As a\nconsequence, we show that SBT can be extended to systems using matching on\ndefined symbols (e.g. associative functions).\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 06:28:55 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "LIAMA"], ["Roux", "Cody", "", "INRIA Lorraine - LORIA"]]}, {"id": "0906.4216", "submitter": "Viswanath Kasturi", "authors": "Venkata Rao Kuchibhotla, Viswanath Kasturi", "title": "On the Definition of Non-deterministic Mechanisms", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here three different approaches to the problem of modeling\nmathematically the concept of a non-deterministic mechanism. Each of these\nthree approaches leads to a mathematical definition. We then show that all the\nthree mathematical concepts are equivalent to one another. This insight gives\nus the option of approaching the wp-formalism of Dijkstra from a different\nviewpoint that is easier to understand and to teach.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 10:27:40 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Kuchibhotla", "Venkata Rao", ""], ["Kasturi", "Viswanath", ""]]}, {"id": "0906.4315", "submitter": "Sabina Petride", "authors": "Mark Bickford (Cornell University), Robert Constable (Cornell\n  University), Joseph Halpern (Cornell University), Sabina Petride (Cornell\n  University)", "title": "Knowledge-Based Synthesis of Distributed Systems Using Event Structures", "comments": "A preliminary version of this paper appeared in Proceedings of the\n  11th International Conference on Logic for Programming, Artificial\n  Intelligence, and Reasoning LPAR 2004, pp. 449-465", "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 2 (May 21,\n  2011) lmcs:804", "doi": "10.2168/LMCS-7(2:14)2011", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To produce a program guaranteed to satisfy a given specification one can\nsynthesize it from a formal constructive proof that a computation satisfying\nthat specification exists. This process is particularly effective if the\nspecifications are written in a high-level language that makes it easy for\ndesigners to specify their goals. We consider a high-level specification\nlanguage that results from adding knowledge to a fragment of Nuprl specifically\ntailored for specifying distributed protocols, called event theory. We then\nshow how high-level knowledge-based programs can be synthesized from the\nknowledge-based specifications using a proof development system such as Nuprl.\nMethods of Halpern and Zuck then apply to convert these knowledge-based\nprotocols to ordinary protocols. These methods can be expressed as heuristic\ntransformation tactics in Nuprl.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 17:10:42 GMT"}, {"version": "v2", "created": "Fri, 7 Jan 2011 19:30:13 GMT"}, {"version": "v3", "created": "Thu, 19 May 2011 07:14:28 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bickford", "Mark", "", "Cornell University"], ["Constable", "Robert", "", "Cornell\n  University"], ["Halpern", "Joseph", "", "Cornell University"], ["Petride", "Sabina", "", "Cornell\n  University"]]}, {"id": "0906.4321", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern and Leandro Rego", "title": "Reasoning About Knowledge of Unawareness Revisited", "comments": "In Proceedings of Twelfth Conference on Theoretical Aspects of\n  Rationality and Knowledge, 2009, pp. 166-173", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In earlier work, we proposed a logic that extends the Logic of General\nAwareness of Fagin and Halpern [1988] by allowing quantification over primitive\npropositions. This makes it possible to express the fact that an agent knows\nthat there are some facts of which he is unaware. In that logic, it is not\npossible to model an agent who is uncertain about whether he is aware of all\nformulas. To overcome this problem, we keep the syntax of the earlier paper,\nbut allow models where, with each world, a possibly different language is\nassociated. We provide a sound and complete axiomatization for this logic and\nshow that, under natural assumptions, the quantifier-free fragment of the logic\nis characterized by exactly the same axioms as the logic of Heifetz, Meier, and\nSchipper [2008].\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 17:34:16 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Rego", "Leandro", ""]]}, {"id": "0906.4326", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern and Rafael Pass", "title": "A Logical Characterization of Iterated Admissibility", "comments": "In Proceedings of Twelfth Conference on Theoretical Aspects of\n  Rationality and Knowledge, 2009, pp. 146-155", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brandenburger, Friedenberg, and Keisler provide an epistemic characterization\nof iterated admissibility (i.e., iterated deletion of weakly dominated\nstrategies) where uncertainty is represented using LPSs (lexicographic\nprobability sequences). Their characterization holds in a rich structure called\na complete structure, where all types are possible. Here, a logical\ncharaacterization of iterated admisibility is given that involves only standard\nprobability and holds in all structures, not just complete structures. A\nstronger notion of strong admissibility is then defined. Roughly speaking,\nstrong admissibility is meant to capture the intuition that \"all the agent\nknows\" is that the other agents satisfy the appropriate rationality\nassumptions. Strong admissibility makes it possible to relate admissibility,\ncanonical structures (as typically considered in completeness proofs in modal\nlogic), complete structures, and the notion of ``all I know''.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 18:04:05 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Pass", "Rafael", ""]]}, {"id": "0906.4492", "submitter": "Alberto Griggio", "authors": "Alessandro Cimatti, Alberto Griggio, Roberto Sebastiani", "title": "Efficient Generation of Craig Interpolants in Satisfiability Modulo\n  Theories", "comments": "submitted to ACM Transactions on Computational Logic (TOCL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of computing Craig Interpolants has recently received a lot of\ninterest. In this paper, we address the problem of efficient generation of\ninterpolants for some important fragments of first order logic, which are\namenable for effective decision procedures, called Satisfiability Modulo Theory\nsolvers.\n  We make the following contributions.\n  First, we provide interpolation procedures for several basic theories of\ninterest: the theories of linear arithmetic over the rationals, difference\nlogic over rationals and integers, and UTVPI over rationals and integers.\n  Second, we define a novel approach to interpolate combinations of theories,\nthat applies to the Delayed Theory Combination approach.\n  Efficiency is ensured by the fact that the proposed interpolation algorithms\nextend state of the art algorithms for Satisfiability Modulo Theories. Our\nexperimental evaluation shows that the MathSAT SMT solver can produce\ninterpolants with minor overhead in search, and much more efficiently than\nother competitor solvers.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2009 14:47:01 GMT"}], "update_date": "2009-06-25", "authors_parsed": [["Cimatti", "Alessandro", ""], ["Griggio", "Alberto", ""], ["Sebastiani", "Roberto", ""]]}, {"id": "0906.4570", "submitter": "Luca Vigan\\`o", "authors": "Michele Barletta, Silvio Ranise, Luca Vigan\\`o", "title": "Verifying the Interplay of Authorization Policies and Workflow in\n  Service-Oriented Architectures (Full version)", "comments": "16 pages, 4 figures, full version of paper at Symposium on Secure\n  Computing (SecureCom09)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A widespread design approach in distributed applications based on the\nservice-oriented paradigm, such as web-services, consists of clearly separating\nthe enforcement of authorization policies and the workflow of the applications,\nso that the interplay between the policy level and the workflow level is\nabstracted away. While such an approach is attractive because it is quite\nsimple and permits one to reason about crucial properties of the policies under\nconsideration, it does not provide the right level of abstraction to specify\nand reason about the way the workflow may interfere with the policies, and vice\nversa. For example, the creation of a certificate as a side effect of a\nworkflow operation may enable a policy rule to fire and grant access to a\ncertain resource; without executing the operation, the policy rule should\nremain inactive. Similarly, policy queries may be used as guards for workflow\ntransitions.\n  In this paper, we present a two-level formal verification framework to\novercome these problems and formally reason about the interplay of\nauthorization policies and workflow in service-oriented architectures. This\nallows us to define and investigate some verification problems for SO\napplications and give sufficient conditions for their decidability.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 16:31:42 GMT"}], "update_date": "2009-06-26", "authors_parsed": [["Barletta", "Michele", ""], ["Ranise", "Silvio", ""], ["Vigan\u00f2", "Luca", ""]]}, {"id": "0906.4711", "submitter": "Carlo Alberto Furia", "authors": "Carlo A. Furia and Paola Spoletini", "title": "On Relaxing Metric Information in Linear Temporal Logic", "comments": "Minor changes", "journal-ref": "Proceedings of the 18th International Symposium on Temporal\n  Representation and Reasoning (TIME'11). Pgg. 72--79, IEEE Computer Society,\n  September 2011", "doi": "10.1109/TIME.2011.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric LTL formulas rely on the next operator to encode time distances,\nwhereas qualitative LTL formulas use only the until operator. This paper shows\nhow to transform any metric LTL formula M into a qualitative formula Q, such\nthat Q is satisfiable if and only if M is satisfiable over words with\nvariability bounded with respect to the largest distances used in M (i.e.,\noccurrences of next), but the size of Q is independent of such distances.\nBesides the theoretical interest, this result can help simplify the\nverification of systems with time-granularity heterogeneity, where large\ndistances are required to express the coarse-grain dynamics in terms of\nfine-grain time units.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 15:04:50 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2010 07:08:25 GMT"}, {"version": "v3", "created": "Sat, 23 Apr 2011 08:53:19 GMT"}, {"version": "v4", "created": "Fri, 17 Jun 2011 13:42:24 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Furia", "Carlo A.", ""], ["Spoletini", "Paola", ""]]}, {"id": "0906.4725", "submitter": "Ross Duncan", "authors": "Bob Coecke and Ross Duncan", "title": "Interacting Quantum Observables: Categorical Algebra and Diagrammatics", "comments": "81 pages, many figures. Significant changes from previous version.\n  The first sections contain a gentle introduction for physicists to the\n  graphical language, and its use in quantum computation", "journal-ref": "New J. Phys. 13 (2011) 043016", "doi": "10.1088/1367-2630/13/4/043016", "report-no": null, "categories": "quant-ph cs.LO math.CT math.QA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has two tightly intertwined aims: (i) To introduce an intuitive\nand universal graphical calculus for multi-qubit systems, the ZX-calculus,\nwhich greatly simplifies derivations in the area of quantum computation and\ninformation. (ii) To axiomatise complementarity of quantum observables within a\ngeneral framework for physical theories in terms of dagger symmetric monoidal\ncategories. We also axiomatize phase shifts within this framework.\n  Using the well-studied canonical correspondence between graphical calculi and\nsymmetric monoidal categories, our results provide a purely graphical\nformalisation of complementarity for quantum observables. Each individual\nobservable, represented by a commutative special dagger Frobenius algebra,\ngives rise to an abelian group of phase shifts, which we call the phase group.\nWe also identify a strong form of complementarity, satisfied by the Z and X\nspin observables, which yields a scaled variant of a bialgebra.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 15:58:11 GMT"}, {"version": "v2", "created": "Mon, 31 Jan 2011 13:49:04 GMT"}, {"version": "v3", "created": "Thu, 21 Apr 2011 14:18:07 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Coecke", "Bob", ""], ["Duncan", "Ross", ""]]}, {"id": "0906.5181", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov, Joey Paquet, and Mourad Debbabi", "title": "Reasoning About a Simulated Printer Case Investigation with Forensic\n  Lucid", "comments": "18 pages, 3 figures, 7 listings, TOC, index; this article closely\n  relates to arXiv:0906.0049 and arXiv:0904.3789 but to remain stand-alone\n  repeats some of the background and introductory content; abstract presented\n  at HSC'09 and the full updated paper at ICDF2C'11. This is an updated/edited\n  version after ICDF2C proceedings with more references and corrections", "journal-ref": "S. A. Mokhov, J. Paquet, and M. Debbabi. Reasoning about a\n  simulated printer case investigation with Forensic Lucid. In P. Gladyshev and\n  M. K. Rogers, editors, Proceedings of ICDF2C'11, number 0088 in LNICST, pp.\n  282-296. Springer, 2012", "doi": "10.1007/978-3-642-35515-8_23", "report-no": null, "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we model the ACME (a fictitious company name) \"printer case\nincident\" and make its specification in Forensic Lucid, a Lucid- and\nintensional-logic-based programming language for cyberforensic analysis and\nevent reconstruction specification. The printer case involves a dispute between\ntwo parties that was previously solved using the finite-state automata (FSA)\napproach, and is now re-done in a more usable way in Forensic Lucid. Our\nsimulation is based on the said case modeling by encoding concepts like\nevidence and the related witness accounts as an evidential statement context in\na Forensic Lucid program, which is an input to the transition function that\nmodels the possible deductions in the case. We then invoke the transition\nfunction (actually its reverse) with the evidential statement context to see if\nthe evidence we encoded agrees with one's claims and then attempt to\nreconstruct the sequence of events that may explain the claim or disprove it.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2009 00:06:22 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2012 09:41:26 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""], ["Debbabi", "Mourad", ""]]}, {"id": "0906.5488", "submitter": "Rasmus M{\\o}gelberg", "authors": "Rasmus Ejlers M{\\o}gelberg, Alex Simpson", "title": "Relational Parametricity for Computational Effects", "comments": "31 pages, appears in Logical Methods in Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 3 (August 9,\n  2009) lmcs:1113", "doi": "10.2168/LMCS-5(3:7)2009", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to Strachey, a polymorphic program is parametric if it applies a\nuniform algorithm independently of the type instantiations at which it is\napplied. The notion of relational parametricity, introduced by Reynolds, is one\npossible mathematical formulation of this idea. Relational parametricity\nprovides a powerful tool for establishing data abstraction properties, proving\nequivalences of datatypes, and establishing equalities of programs. Such\nproperties have been well studied in a pure functional setting. Many programs,\nhowever, exhibit computational effects, and are not accounted for by the\nstandard theory of relational parametricity. In this paper, we develop a\nfoundational framework for extending the notion of relational parametricity to\nprogramming languages with effects.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2009 11:47:58 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2009 19:09:56 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["M\u00f8gelberg", "Rasmus Ejlers", ""], ["Simpson", "Alex", ""]]}]