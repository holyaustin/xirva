[{"id": "0710.0528", "submitter": "Francesca Scozzari", "authors": "Gianluca Amato and Francesca Scozzari", "title": "On the interaction between sharing and linearity", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, volume 10, issue 01, pp.\n  49-112, 2010", "doi": "10.1017/S1471068409990160", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the analysis of logic programs, abstract domains for detecting sharing and\nlinearity information are widely used. Devising abstract unification algorithms\nfor such domains has proved to be rather hard. At the moment, the available\nalgorithms are correct but not optimal, i.e., they cannot fully exploit the\ninformation conveyed by the abstract domains. In this paper, we define a new\n(infinite) domain ShLin-w which can be thought of as a general framework from\nwhich other domains can be easily derived by abstraction. ShLin-w makes the\ninteraction between sharing and linearity explicit. We provide a constructive\ncharacterization of the optimal abstract unification operator on ShLin-w and we\nlift it to two well-known abstractions of ShLin-w. Namely, to the classical\nSharing X Lin abstract domain and to the more precise ShLin-2 abstract domain\nby Andy King. In the case of single binding substitutions, we obtain optimal\nabstract unification algorithms for such domains.\n  To appear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2007 13:29:28 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2009 09:35:55 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Amato", "Gianluca", ""], ["Scozzari", "Francesca", ""]]}, {"id": "0710.0824", "submitter": "Norman Danner", "authors": "Norman Danner and James S. Royer", "title": "Two algorithms in search of a type system", "comments": "30 pages. Final version to appear in Theory of Computing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": null, "abstract": "  The authors' ATR programming formalism is a version of call-by-value PCF\nunder a complexity-theoretically motivated type system. ATR programs run in\ntype-2 polynomial-time and all standard type-2 basic feasible functionals are\nATR-definable (ATR types are confined to levels 0, 1, and 2). A limitation of\nthe original version of ATR is that the only directly expressible recursions\nare tail-recursions. Here we extend ATR so that a broad range of affine\nrecursions are directly expressible. In particular, the revised ATR can fairly\nnaturally express the classic insertion- and selection-sort algorithms, thus\novercoming a sticking point of most prior implicit-complexity-based formalisms.\nThe paper's main work is in refining the original time-complexity semantics for\nATR to show that these new recursion schemes do not lead out of the realm of\nfeasibility.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2007 16:04:59 GMT"}, {"version": "v2", "created": "Fri, 18 Apr 2008 19:17:30 GMT"}], "update_date": "2008-04-18", "authors_parsed": [["Danner", "Norman", ""], ["Royer", "James S.", ""]]}, {"id": "0710.1153", "submitter": "Patrick Baillot", "authors": "Vincent Atassi, Patrick Baillot, Kazushige Terui", "title": "Verification of Ptime Reducibility for system F Terms: Type Inference\n  in<br> Dual Light Affine Logic", "comments": "32 pages, 8 figures", "journal-ref": "Logical Methods in Computer Science, Volume 3, Issue 4 (November\n  15, 2007) lmcs:1234", "doi": "10.2168/LMCS-3(4:10)2007", "report-no": null, "categories": "cs.LO cs.CC", "license": null, "abstract": "  In a previous work Baillot and Terui introduced Dual light affine logic\n(DLAL) as a variant of Light linear logic suitable for guaranteeing complexity\nproperties on lambda calculus terms: all typable terms can be evaluated in\npolynomial time by beta reduction and all Ptime functions can be represented.\nIn the present work we address the problem of typing lambda-terms in\nsecond-order DLAL. For that we give a procedure which, starting with a term\ntyped in system F, determines whether it is typable in DLAL and outputs a\nconcrete typing if there exists any. We show that our procedure can be run in\ntime polynomial in the size of the original Church typed system F term.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2007 09:24:31 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2007 11:02:50 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Atassi", "Vincent", ""], ["Baillot", "Patrick", ""], ["Terui", "Kazushige", ""]]}, {"id": "0710.1208", "submitter": "Dominique Duval", "authors": "Dominique Duval (LJK)", "title": "Diagrammatic Inference", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagrammatic logics were introduced in 2002, with emphasis on the notions of\nspecifications and models. In this paper we improve the description of the\ninference process, which is seen as a Yoneda functor on a bicategory of\nfractions. A diagrammatic logic is defined from a morphism of limit sketches\n(called a propagator) which gives rise to an adjunction, which in turn\ndetermines a bicategory of fractions. The propagator, the adjunction and the\nbicategory provide respectively the syntax, the models and the inference\nprocess for the logic. Then diagrammatic logics and their morphisms are applied\nto the semantics of side effects in computer languages.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2007 12:36:02 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2009 13:11:34 GMT"}], "update_date": "2009-11-20", "authors_parsed": [["Duval", "Dominique", "", "LJK"]]}, {"id": "0710.2083", "submitter": "Oliver Schulte", "authors": "Oliver Schulte, Flavia Moser, Martin Ester and Zhiyong Lu", "title": "Association Rules in the Relational Calculus", "comments": "16 pages, 13 tables", "journal-ref": null, "doi": null, "report-no": "SFU School of Computing Science, TR 2007-23", "categories": "cs.DB cs.LG cs.LO", "license": null, "abstract": "  One of the most utilized data mining tasks is the search for association\nrules. Association rules represent significant relationships between items in\ntransactions. We extend the concept of association rule to represent a much\nbroader class of associations, which we refer to as \\emph{entity-relationship\nrules.} Semantically, entity-relationship rules express associations between\nproperties of related objects. Syntactically, these rules are based on a broad\nsubclass of safe domain relational calculus queries. We propose a new\ndefinition of support and confidence for entity-relationship rules and for the\nfrequency of entity-relationship queries. We prove that the definition of\nfrequency satisfies standard probability axioms and the Apriori property.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2007 18:00:44 GMT"}], "update_date": "2007-10-11", "authors_parsed": [["Schulte", "Oliver", ""], ["Moser", "Flavia", ""], ["Ester", "Martin", ""], ["Lu", "Zhiyong", ""]]}, {"id": "0710.2419", "submitter": "Luigi Santocanale", "authors": "Walid Belkhir (LIF), Luigi Santocanale (LIF)", "title": "The Variable Hierarchy for the Games mu-Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT math.LO", "license": null, "abstract": "  Parity games are combinatorial representations of closed Boolean mu-terms. By\nadding to them draw positions, they have been organized by Arnold and one of\nthe authors into a mu-calculus. As done by Berwanger et al. for the\npropositional modal mu-calculus, it is possible to classify parity games into\nlevels of a hierarchy according to the number of fixed-point variables. We ask\nwhether this hierarchy collapses w.r.t. the standard interpretation of the\ngames mu-calculus into the class of all complete lattices. We answer this\nquestion negatively by providing, for each n >= 1, a parity game Gn with these\nproperties: it unravels to a mu-term built up with n fixed-point variables, it\nis semantically equivalent to no game with strictly less than n-2 fixed-point\nvariables.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2007 09:50:43 GMT"}, {"version": "v2", "created": "Thu, 13 Mar 2008 13:04:32 GMT"}], "update_date": "2008-03-13", "authors_parsed": [["Belkhir", "Walid", "", "LIF"], ["Santocanale", "Luigi", "", "LIF"]]}, {"id": "0710.2505", "submitter": "Ichiro Hasuo", "authors": "Ichiro Hasuo, Bart Jacobs and Ana Sokolova", "title": "Generic Trace Semantics via Coinduction", "comments": "To appear in Logical Methods in Computer Science. 36 pages", "journal-ref": "Logical Methods in Computer Science, Volume 3, Issue 4 (November\n  19, 2007) lmcs:864", "doi": "10.2168/LMCS-3(4:11)2007", "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  Trace semantics has been defined for various kinds of state-based systems,\nnotably with different forms of branching such as non-determinism vs.\nprobability. In this paper we claim to identify one underlying mathematical\nstructure behind these \"trace semantics,\" namely coinduction in a Kleisli\ncategory. This claim is based on our technical result that, under a suitably\norder-enriched setting, a final coalgebra in a Kleisli category is given by an\ninitial algebra in the category Sets. Formerly the theory of coalgebras has\nbeen employed mostly in Sets where coinduction yields a finer process semantics\nof bisimilarity. Therefore this paper extends the application field of\ncoalgebras, providing a new instance of the principle \"process semantics via\ncoinduction.\"\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2007 16:28:43 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2007 10:36:17 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Hasuo", "Ichiro", ""], ["Jacobs", "Bart", ""], ["Sokolova", "Ana", ""]]}, {"id": "0710.3305", "submitter": "Laurent Vigneron", "authors": "Francis Klay (FT R&D), Judson Santiago (DIMAP - UFRN), Laurent\n  Vigneron (INRIA Lorraine - LORIA / LIFC)", "title": "Automatic Methods for Analyzing Non-Repudiation Protocols with an Active\n  Intruder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": null, "abstract": "  Non-repudiation protocols have an important role in many areas where secured\ntransactions with proofs of participation are necessary. Formal methods are\nclever and without error, therefore using them for verifying such protocols is\ncrucial. In this purpose, we show how to partially represent non-repudiation as\na combination of authentications on the Fair Zhou-Gollmann protocol. After\ndiscussing its limits, we define a new method based on the handling of the\nknowledge of protocol participants. This method is very general and is of\nnatural use, as it consists in adding simple annotations, like for\nauthentication problems. The method is very easy to implement in tools able to\nhandle participants knowledge. We have implemented it in the AVISPA Tool and\nanalyzed the optimistic Cederquist-Corin- Dashti protocol, discovering two\nunknown attacks. This extension of the AVISPA Tool for handling non-repudiation\nopens a highway to the specification of many other properties, without any more\nchange in the tool itself.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2007 14:16:25 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2007 06:40:14 GMT"}], "update_date": "2007-10-22", "authors_parsed": [["Klay", "Francis", "", "FT R&D"], ["Santiago", "Judson", "", "DIMAP - UFRN"], ["Vigneron", "Laurent", "", "INRIA Lorraine - LORIA / LIFC"]]}, {"id": "0710.3332", "submitter": "Jad Saklawi", "authors": "Paul C. Attie and Jad Saklawi", "title": "Model and Program Repair via SAT Solving", "comments": "29 pages, new repair features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  We consider the following \\emph{model repair problem}: given a finite Kripke\nstructure $M$ and a specification formula $\\eta$ in some modal or temporal\nlogic, determine if $M$ contains a substructure $M'$ (with the same initial\nstate) that satisfies $\\eta$. Thus, $M$ can be ``repaired'' to satisfy the\nspecification $\\eta$ by deleting some transitions.\n  We map an instance $(M, \\eta)$ of model repair to a boolean formula\n$\\repfor(M,\\eta)$ such that $(M, \\eta)$ has a solution iff $\\repfor(M,\\eta)$ is\nsatisfiable. Furthermore, a satisfying assignment determines which transitions\nmust be removed from $M$ to generate a model $M'$ of $\\eta$. Thus, we can use\nany SAT solver to repair Kripke structures. Furthermore, using a complete SAT\nsolver yields a complete algorithm: it always finds a repair if one exists.\n  We extend our method to repair finite-state shared memory concurrent\nprograms, to solve the discrete event supervisory control problem\n\\cite{RW87,RW89}, to check for the existence of symmettric solutions\n\\cite{ES93}, and to accomodate any boolean constraint on the existence of\nstates and transitions in the repaired model.\n  Finally, we show that model repair is NP-complete for CTL, and logics with\npolynomial model checking algorithms to which CTL can be reduced in polynomial\ntime. A notable example of such a logic is Alternating-Time Temporal Logic\n(ATL).\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2007 16:56:56 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2007 11:59:57 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2007 18:49:00 GMT"}, {"version": "v4", "created": "Tue, 15 Apr 2008 12:47:15 GMT"}], "update_date": "2008-04-15", "authors_parsed": [["Attie", "Paul C.", ""], ["Saklawi", "Jad", ""]]}, {"id": "0710.3764", "submitter": "Sumit Kumar Jha", "authors": "Sumit Kumar Jha", "title": "Design of a Distributed Reachability Algorithm for Analysis of Linear\n  Hybrid Automata", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  This paper presents the design of a novel distributed algorithm d-IRA for the\nreachability analysis of linear hybrid automata. Recent work on iterative\nrelaxation abstraction (IRA) is leveraged to distribute the computational\nproblem among multiple computational nodes in a non-redundant manner by\nperforming careful infeasibility analysis of linear programs corresponding to\nspurious counterexamples. The d-IRA algorithm is resistant to failure of\nmultiple computational nodes. The experimental results provide promising\nevidence for the possible successful application of this technique.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2007 19:32:39 GMT"}], "update_date": "2007-10-22", "authors_parsed": [["Jha", "Sumit Kumar", ""]]}, {"id": "0710.4499", "submitter": "Colm \\'O D\\'unlaing", "authors": "Colm O. Dunlaing and Natalie Schluter", "title": "Remarks on Jurdzinski and Lorys' proof that palindromes are not a\n  Church-Rosser language", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": "TCDMATH 07-10", "categories": "cs.LO", "license": null, "abstract": "  In 2002 Jurdzinski and Lorys settled a long-standing conjecture that\npalindromes are not a Church-Rosser language. Their proof required a\nsophisticated theory about computation graphs of 2-stack automata. We present\ntheir proof in terms of 1-tape Turing machines.We also provide an alternative\nproof of Buntrock and Otto's result that the set of non-square bitstrings,\nwhich is context-free, is not Church-Rosser.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2007 15:40:32 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2007 10:15:54 GMT"}], "update_date": "2007-10-25", "authors_parsed": [["Dunlaing", "Colm O.", ""], ["Schluter", "Natalie", ""]]}, {"id": "0710.4629", "submitter": "EDA Publishing Association", "authors": "Jacob Katz, Ziyad Hanna, Nachum Dershowitz", "title": "Space-Efficient Bounded Model Checking", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": "10.1109/DATE.2005.276", "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  Current algorithms for bounded model checking use SAT methods for checking\nsatisfiability of Boolean formulae. These methods suffer from the potential\nmemory explosion problem. Methods based on the validity of Quantified Boolean\nFormulae (QBF) allow an exponentially more succinct representation of formulae\nto be checked, because no \"unrolling\" of the transition relation is required.\nThese methods have not been widely used, because of the lack of an efficient\ndecision procedure for QBF. We evaluate the usage of QBF in bounded model\nchecking (BMC), using general-purpose SAT and QBF solvers. We develop a\nspecial-purpose decision procedure for QBF used in BMC, and compare our\ntechnique with the methods using general-purpose SAT and QBF solvers on\nreal-life industrial benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:06:59 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Katz", "Jacob", ""], ["Hanna", "Ziyad", ""], ["Dershowitz", "Nachum", ""]]}, {"id": "0710.4666", "submitter": "EDA Publishing Association", "authors": "Malay K. Ganai, Aarti Gupta, Pranav Ashar", "title": "Verification of Embedded Memory Systems using Efficient Memory Modeling", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  We describe verification techniques for embedded memory systems using\nefficient memory modeling (EMM), without explicitly modeling each memory bit.\nWe extend our previously proposed approach of EMM in Bounded Model Checking\n(BMC) for a single read/write port single memory system, to more commonly\noccurring systems with multiple memories, having multiple read and write ports.\nMore importantly, we augment such EMM to providing correctness proofs, in\naddition to finding real bugs as before. The novelties of our verification\napproach are in a) combining EMM with proof-based abstraction that preserves\nthe correctness of a property up to a certain analysis depth of SAT-based BMC,\nand b) modeling arbitrary initial memory state precisely and thereby, providing\ninductive proofs using SAT-based BMC for embedded memory systems. Similar to\nthe previous approach, we construct a verification model by eliminating memory\narrays, but retaining the memory interface signals with their control logic and\nadding constraints on those signals at every analysis depth to preserve the\ndata forwarding semantics. The size of these EMM constraints depends\nquadratically on the number of memory accesses and the number of read and write\nports; and linearly on the address and data widths and the number of memories.\nWe show the effectiveness of our approach on several industry designs and\nsoftware programs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:44:05 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Ganai", "Malay K.", ""], ["Gupta", "Aarti", ""], ["Ashar", "Pranav", ""]]}, {"id": "0710.4689", "submitter": "EDA Publishing Association", "authors": "K. C. Shashidhar, Maurice Bruynooghe, Francky Catthoor, Gerda Janssens", "title": "Functional Equivalence Checking for Verification of Algebraic\n  Transformations on Array-Intensive Source Code", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  Development of energy and performance-efficient embedded software is\nincreasingly relying on application of complex transformations on the critical\nparts of the source code. Designers applying such nontrivial source code\ntransformations are often faced with the problem of ensuring functional\nequivalence of the original and transformed programs. Currently they have to\nrely on incomplete and time-consuming simulation. Formal automatic verification\nof the transformed program against the original is instead desirable. This\ncalls for equivalence checking tools similar to the ones available for\ncomparing digital circuits. We present such a tool to compare array-intensive\nprograms related through a combination of important global transformations like\nexpression propagations, loop and algebraic transformations. When the\ntransformed program fails to pass the equivalence check, the tool provides\nspecific feedback on the possible locations of errors.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:09:59 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Shashidhar", "K. C.", ""], ["Bruynooghe", "Maurice", ""], ["Catthoor", "Francky", ""], ["Janssens", "Gerda", ""]]}, {"id": "0710.4694", "submitter": "EDA Publishing Association", "authors": "Guowu Yang, William N. N. Hung, Xiaoyu Song, Marek Perkowski", "title": "Exact Synthesis of 3-Qubit Quantum Circuits from Non-Binary Quantum\n  Gates Using Multiple-Valued Logic and Group Theory", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  We propose an approach to optimally synthesize quantum circuits from\nnon-permutative quantum gates such as Controlled-Square-Root-of-Not (i.e.\nControlled-V). Our approach reduces the synthesis problem to multiple-valued\noptimization and uses group theory. We devise a novel technique that transforms\nthe quantum logic synthesis problem from a multi-valued constrained\noptimization problem to a group permutation problem. The transformation enables\nus to utilize group theory to exploit the properties of the synthesis problem.\nAssuming a cost of one for each two-qubit gate, we found all reversible\ncircuits with quantum costs of 4, 5, 6, etc, and give another algorithm to\nrealize these reversible circuits with quantum gates.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:14:41 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Yang", "Guowu", ""], ["Hung", "William N. N.", ""], ["Song", "Xiaoyu", ""], ["Perkowski", "Marek", ""]]}, {"id": "0710.4695", "submitter": "EDA Publishing Association", "authors": "Alan Mishchenko, Robert K. Brayton", "title": "SAT-Based Complete Don't-Care Computation for Network Optimization", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  This paper describes an improved approach to Boolean network optimization\nusing internal don't-cares. The improvements concern the type of don't-cares\ncomputed, their scope, and the computation method. Instead of the traditionally\nused compatible observability don't-cares (CODCs), we introduce and justify the\nuse of complete don't-cares (CDC). To ensure the robustness of the don't-care\ncomputation for very large industrial networks, a optional windowing scheme is\nimplemented that computes substantial subsets of the CDCs in reasonable time.\nFinally, we give a SAT-based don't-care computation algorithm that is more\nefficient than BDD-based algorithms. Experimental results confirm that these\nimprovements work well in practice. Complete don't-cares allow for a reduction\nin the number of literals compared to the CODCs. Windowing guarantees\nrobustness, even for very large benchmarks on which previous methods could not\nbe applied. SAT reduces the runtime and enhances robustness, making don't-cares\naffordable for a variety of other Boolean methods applied to the network.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:15:10 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Mishchenko", "Alan", ""], ["Brayton", "Robert K.", ""]]}, {"id": "0710.4698", "submitter": "EDA Publishing Association", "authors": "Ambar A. Gadkari, S. Ramesh", "title": "Automated Synthesis of Assertion Monitors using Visual Specifications", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  Automated synthesis of monitors from high-level properties plays a\nsignificant role in assertion-based verification. We present here a methodology\nto synthesize assertion monitors from visual specifications given in CESC\n(Clocked Event Sequence Chart). CESC is a visual language designed for\nspecifying system level interactions involving single and multiple clock\ndomains. It has well-defined graphical and textual syntax and formal semantics\nbased on synchronous language paradigm enabling formal analysis of\nspecifications. In this paper we provide an overview of CESC language with few\nillustrative examples. The algorithm for automated synthesis of assertion\nmonitors from CESC specifications is described. A few examples from standard\nbus protocols (OCP-IP and AMBA) are presented to demonstrate the application of\nmonitor synthesis algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:18:46 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Gadkari", "Ambar A.", ""], ["Ramesh", "S.", ""]]}, {"id": "0710.4743", "submitter": "EDA Publishing Association", "authors": "Alan Mishchenko, Robert Brayton, Roland Jiang, Tiziano Villa, Nina\n  Yevtushenko", "title": "Efficient Solution of Language Equations Using Partitioned\n  Representations", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  A class of discrete event synthesis problems can be reduced to solving\nlanguage equations f . X &sube; S, where F is the fixed component and S the\nspecification. Sequential synthesis deals with FSMs when the automata for F and\nS are prefix closed, and are naturally represented by multi-level networks with\nlatches. For this special case, we present an efficient computation, using\npartitioned representations, of the most general prefix-closed solution of the\nabove class of language equations. The transition and the output relations of\nthe FSMs for F and S in their partitioned form are represented by the sets of\noutput and next state functions of the corresponding networks. Experimentally,\nwe show that using partitioned representations is much faster than using\nmonolithic representations, as well as applicable to larger problem instances.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:45:31 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Mishchenko", "Alan", ""], ["Brayton", "Robert", ""], ["Jiang", "Roland", ""], ["Villa", "Tiziano", ""], ["Yevtushenko", "Nina", ""]]}, {"id": "0710.4753", "submitter": "EDA Publishing Association", "authors": "Reinhold Heckmann, Christian Ferdinand", "title": "Verifying Safety-Critical Timing and Memory-Usage Properties of Embedded\n  Software by Abstract Interpretation", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  Static program analysis by abstract interpretation is an efficient method to\ndetermine properties of embedded software. One example is value analysis, which\ndetermines the values stored in the processor registers. Its results are used\nas input to more advanced analyses, which ultimately yield information about\nthe stack usage and the timing behavior of embedded software.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:52:50 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Heckmann", "Reinhold", ""], ["Ferdinand", "Christian", ""]]}, {"id": "0710.4846", "submitter": "EDA Publishing Association", "authors": "M. Borgatti, A. Capello, U. Rossi, J.-L. Lambert, I. Moussa, F. Fummi,\n  G. Pravadelli", "title": "An Integrated Design and Verification Methodology for Reconfigurable\n  Multimedia Systems", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.MM cs.LO", "license": null, "abstract": "  Recently a lot of multimedia applications are emerging on portable\nappliances. They require both the flexibility of upgradeable devices\n(traditionally software based) and a powerful computing engine (typically\nhardware). In this context, programmable HW and dynamic reconfiguration allow\nnovel approaches to the migration of algorithms from SW to HW. Thus, in the\nframe of the Symbad project, we propose an industrial design flow for\nreconfigurable SoC's. The goal of Symbad consists of developing a system level\ndesign platform for hardware and software SoC systems including formal and\nsemi-formal verification techniques.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:24:16 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Borgatti", "M.", ""], ["Capello", "A.", ""], ["Rossi", "U.", ""], ["Lambert", "J. -L.", ""], ["Moussa", "I.", ""], ["Fummi", "F.", ""], ["Pravadelli", "G.", ""]]}, {"id": "0710.4848", "submitter": "EDA Publishing Association", "authors": "Yasushi Umezawa, Takeshi Shimizu", "title": "A Formal Verification Methodology for Checking Data Integrity", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  Formal verification techniques have been playing an important role in\npre-silicon validation processes. One of the most important points considered\nin performing formal verification is to define good verification scopes; we\nshould define clearly what to be verified formally upon designs under tests. We\nconsidered the following three practical requirements when we defined the scope\nof formal verification. They are (a) hard to verify (b) small to handle, and\n(c) easy to understand. Our novel approach is to break down generic properties\nfor system into stereotype properties in block level and to define requirements\nfor Verifiable RTL. Consequently, each designer instead of verification experts\ncan describe properties of the design easily, and formal model checking can be\napplied systematically and thoroughly to all the leaf modules. During the\ndevelopment of a component chip for server platforms, we focused on RAS\n(Reliability, Availability, and Serviceability) features and described more\nthan 2000 properties in PSL. As a result of the formal verification, we found\nseveral critical logic bugs in a short time with limited resources, and\nsuccessfully verified all of them. This paper presents a study of the\nfunctional verification methodology.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:24:36 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Umezawa", "Yasushi", ""], ["Shimizu", "Takeshi", ""]]}, {"id": "0710.4851", "submitter": "EDA Publishing Association", "authors": "Giuseppe Falconeri, Walid Naifer, Nizar Romdhane", "title": "Common Reusable Verification Environment for BCA and RTL Models", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe | Designers'Forum -\n  DATE'05, Munich : Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  This paper deals with a common verification methodology and environment for\nSystemC BCA and RTL models. The aim is to save effort by avoiding the same work\ndone twice by different people and to reuse the same environment for the two\ndesign views. Applying this methodology the verification task starts as soon as\nthe functional specification is signed off and it runs in parallel to the\nmodels and design development. The verification environment is modeled with the\naid of dedicated verification languages and it is applied to both the models.\nThe test suite is exactly the same and thus it's possible to verify the\nalignment between the two models. In fact the final step is to check the\ncycle-by-cycle match of the interface behavior. A regression tool and a bus\nanalyzer have been developed to help the verification and the alignment\nprocess. The former is used to automate the testbench generation and to run the\ntwo test suites. The latter is used to verify the alignment between the two\nmodels comparing the waveforms obtained in each run. The quality metrics used\nto validate the flow are full functional coverage and full alignment at each IP\nport.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 12:25:32 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Falconeri", "Giuseppe", ""], ["Naifer", "Walid", ""], ["Romdhane", "Nizar", ""]]}, {"id": "0710.5130", "submitter": "Manfred Kufleitner", "authors": "Manfred Kufleitner (LaBRI)", "title": "A Proof of the Factorization Forest Theorem", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  We show that for every homomorphism $\\Gamma^+ \\to S$ where $S$ is a finite\nsemigroup there exists a factorization forest of height $\\leq 3 \\abs{S}$. The\nproof is based on Green's relations.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2007 15:59:56 GMT"}], "update_date": "2007-10-29", "authors_parsed": [["Kufleitner", "Manfred", "", "LaBRI"]]}, {"id": "0710.5659", "submitter": "Wolfgang Thomas", "authors": "Stefan W\\\"ohrle and Wolfgang Thomas", "title": "Model Checking Synchronized Products of Infinite Transition Systems", "comments": "18 pages", "journal-ref": "Logical Methods in Computer Science, Volume 3, Issue 4 (November\n  5, 2007) lmcs:755", "doi": "10.2168/LMCS-3(4:5)2007", "report-no": null, "categories": "cs.LO", "license": null, "abstract": "  Formal verification using the model checking paradigm has to deal with two\naspects: The system models are structured, often as products of components, and\nthe specification logic has to be expressive enough to allow the formalization\nof reachability properties. The present paper is a study on what can be\nachieved for infinite transition systems under these premises. As models we\nconsider products of infinite transition systems with different synchronization\nconstraints. We introduce finitely synchronized transition systems, i.e.\nproduct systems which contain only finitely many (parameterized) synchronized\ntransitions, and show that the decidability of FO(R), first-order logic\nextended by reachability predicates, of the product system can be reduced to\nthe decidability of FO(R) of the components. This result is optimal in the\nfollowing sense: (1) If we allow semifinite synchronization, i.e. just in one\ncomponent infinitely many transitions are synchronized, the FO(R)-theory of the\nproduct system is in general undecidable. (2) We cannot extend the expressive\npower of the logic under consideration. Already a weak extension of first-order\nlogic with transitive closure, where we restrict the transitive closure\noperators to arity one and nesting depth two, is undecidable for an\nasynchronous (and hence finitely synchronized) product, namely for the infinite\ngrid.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2007 14:39:09 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2007 11:46:10 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["W\u00f6hrle", "Stefan", ""], ["Thomas", "Wolfgang", ""]]}, {"id": "0710.5895", "submitter": "Wim Vanhoof", "authors": "Francois Gobert, Baudouin Le Charlier", "title": "Source-to-source optimizing transformations of Prolog programs based on\n  abstract interpretation", "comments": "Paper presented at the 17th Workshop on Logic-based Methods in\n  Programming Environments (WLPE2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": null, "abstract": "  Making a Prolog program more efficient by transforming its source code,\nwithout changing its operational semantics, is not an obvious task. It requires\nthe user to have a clear understanding of how the Prolog compiler works, and in\nparticular, of the effects of impure features like the cut. The way a Prolog\ncode is written - e.g., the order of clauses, the order of literals in a\nclause, the use of cuts or negations - influences its efficiency. Furthermore,\ndifferent optimization techniques may be redundant or conflicting when they are\napplied together, depending on the way a procedure is called - e.g., inserting\ncuts and enabling indexing. We present an optimiser, based on abstract\ninterpretation, that automatically performs safe code transformations of Prolog\nprocedures in the context of some class of input calls. The method is more\neffective if procedures are annotated with additional information about modes,\ntypes, sharing, number of solutions and the like. Thus the approach is similar\nto Mercury. It applies to any Prolog program, however.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2007 15:59:50 GMT"}], "update_date": "2007-11-01", "authors_parsed": [["Gobert", "Francois", ""], ["Charlier", "Baudouin Le", ""]]}]