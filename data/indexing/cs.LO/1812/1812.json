[{"id": "1812.00183", "submitter": "Sheerazuddin Syed", "authors": "S Sheerazuddin, S Anand, R S Anish Badhri", "title": "A Scheme to Verify Services with Unboundedly many Clients using NuSMV", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study model checking of client - server systems, where the servers offer\nseveral types of services that may depend, at any time, on how many clients of\nspecific types are active at that time. Since there are unboundedly many\nclients, the state space of such systems is infinite, rendering specification\nand verification hard. This problem can be circumvented by using a\nspecification language which has monadic first-order (MFO) sentences closed\nwith standard temporal modalities. The MFO sentences throw up a bound which\ncan, in turn, be used to bound the state space of the input client - server\nsystem, thereby making the verification problem decidable. This scheme is\nimplemented using the NuSMV tool.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 10:08:50 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Sheerazuddin", "S", ""], ["Anand", "S", ""], ["Badhri", "R S Anish", ""]]}, {"id": "1812.00349", "submitter": "Zhaowei Xu", "authors": "Zhaowei Xu, Mingsheng Ying, Shenggang Ying", "title": "A Logic for Recursive Quantum Programs", "comments": "There are errors in Section 4, i.e., the definition of quantum\n  predicate terms should be repaired. There are also notational abuses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most modern (classical) programming languages support recursion. Recursion\nhas also been successfully applied to the design of several quantum algorithms\nand introduced in a couple of quantum programming languages. So, it can be\nexpected that recursion will become one of the fundamental paradigms of quantum\nprogramming. Several program logics have been developed for verification of\nnon-recursive quantum programs. However, there are as yet no general methods\nfor reasoning about recursive procedures in quantum computing. We fill the gap\nin this paper by presenting a logic for recursive quantum programs. This logic\nis an extension of quantum Hoare logic for quantum While-programs. The\n(relative) completeness of the logic is proved, and its effectiveness is shown\nby a running example: fixed-point Grover's search.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 07:50:45 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 01:55:44 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Xu", "Zhaowei", ""], ["Ying", "Mingsheng", ""], ["Ying", "Shenggang", ""]]}, {"id": "1812.00396", "submitter": "Michael Pinsker", "authors": "Pierre Gillibert, Julius Jonu\\v{s}as, Michael Pinsker", "title": "Pseudo-loop conditions", "comments": "18 pages", "journal-ref": null, "doi": "10.1112/blms.12286", "report-no": null, "categories": "math.RA cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the systematic study of loop conditions of arbitrary finite\nwidth. Each loop condition is a finite set of identities of a particular shape,\nand satisfaction of these identities in an algebra is characterized by it\nforcing a constant tuple into certain invariant relations on powers of the\nalgebra.\n  By showing the equivalence of various loop conditions, we are able to provide\na new and short proof of the recent celebrated result stating the existence of\na weakest non-trivial idempotent strong Mal'cev condition.\n  We then consider pseudo-loop conditions, a modification suitable for\noligomorphic algebras, and show the equivalence of various pseudo-loop\nconditions within this context. This allows us to provide a new and short proof\nof the fact that the satisfaction of non-trivial identities of height 1 in a\nclosed oligomorphic core implies the satisfaction of a fixed single identity.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 14:08:21 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 17:06:43 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 11:23:16 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Gillibert", "Pierre", ""], ["Jonu\u0161as", "Julius", ""], ["Pinsker", "Michael", ""]]}, {"id": "1812.00619", "submitter": "Evgeniy Shishkin", "authors": "Evgeniy Shishkin", "title": "Debugging Smart Contract's Business Logic Using Symbolic Model-Checking", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are a special type of programs running inside a blockchain.\nImmutable and transparent, they provide means to implement fault-tolerant and\ncensorship-resistant services. Unfortunately, its immutability causes a serious\nchallenge of ensuring that a business logic and implementation is correct\nupfront, before publishing in a blockchain. Several big accidents have indeed\nshown that users of this technology need special tools to verify smart contract\ncorrectness. Existing automated checkers are able to detect only well known\nimplementation bugs, leaving the question of business logic correctness far\naside. In this work, we present a symbolic model-checking technique along with\na formal specification method for a subset of Solidity programming language\nthat is able to express both state properties and trace properties; the latter\nconstitutes a weak analogy of temporal properties. We evaluate the proposed\ntechnique on the MiniDAO smart contract, a young brother of notorious TheDAO.\nOur Proof-of-Concept was able to detect a non-trivial error in the business\nlogic of this smart contract in a few seconds.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 09:25:22 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Shishkin", "Evgeniy", ""]]}, {"id": "1812.00996", "submitter": "Robert Colvin", "authors": "Robert J. Colvin, Graeme Smith", "title": "A high-level operational semantics for hardware weak memory models", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.04406", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern processors deploy a variety of weak memory models, which for\nefficiency reasons may execute instructions in an order different to that\nspecified by the program text. The consequences of instruction reordering can\nbe complex and subtle, and can impact on ensuring correctness. In this paper we\nbuild on extensive work elucidating the semantics of assembler-level languages\non hardware architectures with weak memory models (specifically TSO, ARM and\nPOWER) and lift the principles to a straightforward operational semantics which\nallows reasoning at a higher level of abstraction. To this end we introduce a\nwide-spectrum language that encompasses operations on abstract data types as\nwell as low-level assembler code, define its operational semantics using a\nnovel approach to allowing reordering of instructions, and derive some\nrefinement laws that can be used to explain behaviours of real processors. In\nthis framework memory models are mostly distinguished via a pair-wise static\nordering on instruction types that determines when later instructions may be\nreordered before earlier instructions. In addition, memory models may use\ndifferent types of storage systems. For instance, non-multicopy atomic systems\nallow sibling processes to see updates to different variables in different\norders.\n  We encode the semantics in the rewriting engine Maude as a model-checking\ntool, and develop confidence in our framework by validating our semantics\nagainst existing sets of \\textit{litmus tests} -- small assembler programs --\ncomparing our results with those observed on hardware and in existing\nsemantics. We also use the tool as a prototype to model check implementations\nof data structures from the literature against their abstract specifications.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 02:22:40 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Colvin", "Robert J.", ""], ["Smith", "Graeme", ""]]}, {"id": "1812.01317", "submitter": "Lutz Schr\\\"oder", "authors": "Ulrich Dorsch, Stefan Milius, Lutz Schr\\\"oder", "title": "Graded Monads and Graded Logics for the Linear Time -- Branching Time\n  Spectrum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-based models of concurrent systems are traditionally considered under a\nvariety of notions of process equivalence. In the particular case of labelled\ntransition systems, these equivalences range from trace equivalence to (strong)\nbisimilarity, and are organized in what is known as the linear time --\nbranching time spectrum. A combination of universal coalgebra and graded monads\nprovides a generic framework in which the semantics of concurrency can be\nparametrized both over the branching type of the underlying transition systems\nand over the granularity of process equivalence. We show in the present paper\nthat this framework of graded semantics does subsume the most important\nequivalences from the linear time -- branching time spectrum. An important\nfeature of graded semantics is that it allows for the principled extraction of\ncharacteristic modal logics. We have established invariance of these graded\nlogics under the given graded semantics in earlier work; in the present paper,\nwe extend the logical framework with an explicit propositional layer and\nprovide a generic expressiveness criterion that generalizes the classical\nHennessy-Milner theorem to coarser notions of process equivalence. We extract\ngraded logics for a range of graded semantics on labelled transition systems\nand probabilistic systems, and give exemplaric proofs of their expressiveness\nbased on our generic criterion.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 10:28:13 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 09:46:20 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 13:24:40 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Dorsch", "Ulrich", ""], ["Milius", "Stefan", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "1812.01549", "submitter": "Alberto Marcone", "authors": "Takayuki Kihara, Alberto Marcone, Arno Pauly", "title": "Searching for an analogue of ATR in the Weihrauch lattice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are close similarities between the Weihrauch lattice and the zoo of\naxiom systems in reverse mathematics. Following these similarities has often\nallowed researchers to translate results from one setting to the other.\nHowever, amongst the big five axiom systems from reverse mathematics, so far\nATR_0 has no identified counterpart in the Weihrauch degrees. We explore and\nevaluate several candidates, and conclude that the situation is complicated.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 17:38:57 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 15:59:29 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Kihara", "Takayuki", ""], ["Marcone", "Alberto", ""], ["Pauly", "Arno", ""]]}, {"id": "1812.01674", "submitter": "Martin Beaudry", "authors": "Martin Beaudry", "title": "Proving that a Tree Language is not First-Order Definable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore from an algebraic viewpoint the properties of the tree languages\ndefinable with a first-order formula involving the ancestor predicate, using\nthe description of these languages as those recognized by iterated block\nproducts of forest algebras defined from finite counter monoids. Proofs of\nnondefinability are infinite sequences of sets of forests, one for each level\nof the hierarchy of quantification levels that defines the corresponding\nvariety of languages. The forests at a given level are built recursively by\ninserting forests from previous level at the ports of a suitable set of\nmulticontexts. We show that a recursive proof exists for the syntactic algebra\nof every non-definable language. We also investigate certain types of uniform\nrecursive proofs. For this purpose, we define from a forest algebra an algebra\nof mappings and an extended algebra, which we also use to redefine the notion\nof aperiodicity in a way that generalizes the existing ones.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 20:45:43 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Beaudry", "Martin", ""]]}, {"id": "1812.01843", "submitter": "Kuldeep S. Meel", "authors": "Dmitry Malioutov and Kuldeep S. Meel", "title": "MLIC: A MaxSAT-Based framework for learning interpretable classification\n  rules", "comments": "Paper published in Proceedings of International Conference on\n  Constraint Programming (CP), 2018", "journal-ref": null, "doi": "10.1007/978-3-319-98334-9_21", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of machine learning approaches in the industry, government,\nmedicine and science has renewed the interest in interpretable machine\nlearning: many decisions are too important to be delegated to black-box\ntechniques such as deep neural networks or kernel SVMs. Historically, problems\nof learning interpretable classifiers, including classification rules or\ndecision trees, have been approached by greedy heuristic methods as essentially\nall the exact optimization formulations are NP-hard. Our primary contribution\nis a MaxSAT-based framework, called MLIC, which allows principled search for\ninterpretable classification rules expressible in propositional logic. Our\napproach benefits from the revolutionary advances in the constraint\nsatisfaction community to solve large-scale instances of such problems. In\nexperimental evaluations over a collection of benchmarks arising from practical\nscenarios, we demonstrate its effectiveness: we show that the formulation can\nsolve large classification problems with tens or hundreds of thousands of\nexamples and thousands of features, and to provide a tunable balance of\naccuracy vs. interpretability. Furthermore, we show that in many problems\ninterpretability can be obtained at only a minor cost in accuracy. The primary\nobjective of the paper is to show that recent advances in the MaxSAT literature\nmake it realistic to find optimal (or very high quality near-optimal) solutions\nto large-scale classification problems. The key goal of the paper is to excite\nresearchers in both interpretable classification and in the CP community to\ntake it further and propose richer formulations, and to develop bespoke solvers\nattuned to the problem of interpretable ML.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 07:40:32 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Malioutov", "Dmitry", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "1812.01853", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (DEDUCTEAM, LSV), Guillaume Genestier (DEDUCTEAM,\n  LSV, CRI, ENS Paris Saclay)", "title": "Termination of $\\lambda$$\\Pi$ modulo rewriting using the size-change\n  principle (work in progress)", "comments": null, "journal-ref": "16th International Workshop on Termination, Jul 2018, Oxford,\n  United Kingdom", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Size-Change Termination principle was first introduced to study the\ntermination of first-order functional programs. In this work, we show that it\ncan also be used to study the termination of higher-order rewriting in a system\nof dependent types extending LF.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 08:28:41 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "DEDUCTEAM, LSV"], ["Genestier", "Guillaume", "", "DEDUCTEAM,\n  LSV, CRI, ENS Paris Saclay"]]}, {"id": "1812.02008", "submitter": "Christian Johansen", "authors": "Uli Fahrenberg, Christian Johansen, Christopher A. Trotter, Krzysztof\n  Ziemia\\'nski", "title": "Sculptures in Concurrency", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (April 14,\n  2021) lmcs:7363", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a formalization of Pratt's intuitive sculpting process for\nhigher-dimensional automata (HDA). Intuitively, an HDA is a sculpture if it can\nbe embedded in (i.e., sculpted from) a single higher dimensional cell\n(hypercube). A first important result of this paper is that not all HDA can be\nsculpted, exemplified through several natural acyclic HDA, one being the famous\n\"broken box\" example of van Glabbeek. Moreover, we show that even the natural\noperation of unfolding is completely unrelated to sculpting, e.g., there are\nsculptures whose unfoldings cannot be sculpted. We investigate the\nexpressiveness of sculptures, as a proper subclass of HDA, by showing them to\nbe equivalent to regular ST-structures (an event-based counterpart of HDA) and\nto (regular) Chu spaces over 3 (in their concurrent interpretation given by\nPratt). We believe that our results shed new light on the intuitions behind\nsculpting as a method of modeling concurrent behavior, showing the precise\nreaches of its expressiveness. Besides expressiveness, we also develop an\nalgorithm to decide whether an HDA can be sculpted. More importantly, we show\nthat sculptures are equivalent to Euclidean cubical complexes (being the\ngeometrical counterpart of our combinatorial definition), which include the\npopular PV models used for deadlock detection. This exposes a close connection\nbetween geometric and combinatorial models for concurrency which may be of use\nfor both areas.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 14:09:09 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 15:00:44 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 20:27:32 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 10:51:19 GMT"}, {"version": "v5", "created": "Tue, 13 Apr 2021 09:57:52 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Fahrenberg", "Uli", ""], ["Johansen", "Christian", ""], ["Trotter", "Christopher A.", ""], ["Ziemia\u0144ski", "Krzysztof", ""]]}, {"id": "1812.02016", "submitter": "Henning Urbat", "authors": "Stefan Milius and Henning Urbat", "title": "Equational Axiomatization of Algebras with Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a new category theoretic account of equationally\naxiomatizable classes of algebras. Our approach is well-suited for the\ntreatment of algebras equipped with additional computationally relevant\nstructure, such as ordered algebras, continuous algebras, quantitative\nalgebras, nominal algebras, or profinite algebras. Our main contributions are a\ngeneric HSP theorem and a sound and complete equational logic, which are shown\nto encompass numerous flavors of equational axiomizations studied in the\nliterature.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 14:30:54 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 15:25:40 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Milius", "Stefan", ""], ["Urbat", "Henning", ""]]}, {"id": "1812.02243", "submitter": "Antoine Amarilli", "authors": "Henk P. Barendregt", "title": "Gems of Corrado B\\\"ohm", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (September\n  2, 2020) lmcs:6755", "doi": "10.23638/LMCS-16(3:15)2020", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The main scientific heritage of Corrado B\\\"ohm consists of ideas about\ncomputing, concerning concrete algorithms, as well as models of computability.\nThe following will be presented. 1. A compiler that can compile itself. 2.\nStructured programming, eliminating the 'goto' statement. 3. Functional\nprogramming and an early implementation. 4. Separability in {\\lambda}-calculus.\n5. Compiling combinators without parsing. 6. Self-evaluation in\n{\\lambda}-calculus.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 21:56:23 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 12:18:52 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 20:32:59 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 12:02:48 GMT"}, {"version": "v5", "created": "Mon, 31 Aug 2020 18:31:54 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Barendregt", "Henk P.", ""]]}, {"id": "1812.02989", "submitter": "Matthew Hague", "authors": "Matthew Hague and Anthony W. Lin and Chih-Duo Hong", "title": "CSS Minification via Constraint Solving (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minification is a widely-accepted technique which aims at reducing the size\nof the code transmitted over the web. We study the problem of minifying\nCascading Style Sheets (CSS) --- the de facto language for styling web\ndocuments. Traditionally, CSS minifiers focus on simple syntactic\ntransformations (e.g. shortening colour names). In this paper, we propose a new\nminification method based on merging similar rules in a CSS file.\n  We consider safe transformations of CSS files, which preserve the semantics\nof the CSS file. The semantics of CSS files are sensitive to the ordering of\nrules in the file. To automatically identify a rule merging opportunity that\nbest minimises file size, we reduce the rule-merging problem to a problem on\nCSS-graphs, i.e., node-weighted bipartite graphs with a dependency ordering on\nthe edges, where weights capture the number of characters (e.g. in a selector\nor in a property declaration). Roughly speaking, the corresponding CSS-graph\nproblem concerns minimising the total weight of a sequence of bicliques\n(complete bipartite subgraphs) that covers the CSS-graph and respects the edge\norder.\n  We provide the first full formalisation of CSS3 selectors and reduce\ndependency detection to satisfiability of quantifier-free integer linear\narithmetic, for which highly-optimised SMT-solvers are available. To solve the\nabove NP-hard graph optimisation problem, we show how Max-SAT solvers can be\neffectively employed. We have implemented our algorithms using Max-SAT and\nSMT-solvers as backends, and tested against approximately 70 real-world\nexamples (including the top 20 most popular websites). In our benchmarks, our\ntool yields larger savings than six well-known minifiers (which do not perform\nrule-merging, but support many other optimisations). Our experiments also\nsuggest that better savings can be achieved in combination with one of these\nsix minifiers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 11:54:13 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Hague", "Matthew", ""], ["Lin", "Anthony W.", ""], ["Hong", "Chih-Duo", ""]]}, {"id": "1812.03243", "submitter": "Md Kamruzzaman Sarker", "authors": "Md Kamruzzaman Sarker, Pascal Hitzler", "title": "Efficient Concept Induction for Description Logics", "comments": "Accepted at AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept Induction refers to the problem of creating complex Description Logic\nclass descriptions (i.e., TBox axioms) from instance examples (i.e., ABox\ndata). In this paper we look particularly at the case where both a set of\npositive and a set of negative instances are given, and complex class\nexpressions are sought under which the positive but not the negative examples\nfall. Concept induction has found applications in ontology engineering, but\nexisting algorithms have fundamental performance issues in some scenarios,\nmainly because a high number of invokations of an external Description Logic\nreasoner is usually required. In this paper we present a new algorithm for this\nproblem which drastically reduces the number of reasoner invokations needed.\nWhile this comes at the expense of a more limited traversal of the search\nspace, we show that our approach improves execution times by up to several\norders of magnitude, while output correctness, measured in the amount of\ncorrect coverage of the input instances, remains reasonably high in many cases.\nOur approach thus should provide a strong alternative to existing systems, in\nparticular in settings where other systems are prohibitively slow.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 00:10:05 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Sarker", "Md Kamruzzaman", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1812.03375", "submitter": "Jason Rute", "authors": "Jason Rute", "title": "On the close interaction between algorithmic randomness and\n  constructive/computable measure theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a survey of constructive and computable measure theory with an\nemphasis on the close connections with algorithmic randomness. We give a brief\nhistory of constructive measure theory from Brouwer to the present, emphasizing\nhow Schnorr randomness is the randomness notion implicit in the work of\nBrouwer, Bishop, Demuth, and others. We survey a number of recent results\nshowing that classical almost everywhere convergence theorems can be used to\ncharacterize many of the common randomness notions including Schnorr\nrandomness, computable randomness, and Martin-L\\\"of randomness. Last, we go\ninto more detail about computable measure theory, showing how all the major\napproaches are basically equivalent (even though the definitions can vary\ngreatly).\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 19:28:32 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 18:49:20 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Rute", "Jason", ""]]}, {"id": "1812.03508", "submitter": "Jorge Fandinno", "authors": "Jorge Fandinno and Johannes Fichte", "title": "Proceedings of the eleventh Workshop on Answer Set Programming and Other\n  Computing Paradigms 2018", "comments": "Proceedings of the elevent Workshop on Answer Set Programming and\n  Other Computing Paradigms 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the eleventh Workshop on Answer Set Programming\nand Other Computing Paradigms (ASPOCP) 2018, which was held in Oxford, UK, July\n18th, 2018.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 16:05:25 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 09:40:06 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 15:51:23 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Fandinno", "Jorge", ""], ["Fichte", "Johannes", ""]]}, {"id": "1812.03518", "submitter": "Petr Jancar", "authors": "Petr Jancar", "title": "Equivalence of pushdown automata via first-order grammars", "comments": "version accepted to JCSS", "journal-ref": null, "doi": "10.1016/j.jcss.2020.07.004", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decidability proof for bisimulation equivalence of first-order grammars is\ngiven. It is an alternative proof for a result by S\\'enizergues (1998, 2005)\nthat subsumes his affirmative solution of the famous decidability question for\ndeterministic pushdown automata. The presented proof is conceptually simpler,\nand a particular novelty is that it is not given as two semidecision procedures\nbut it provides an explicit algorithm that might be amenable to a complexity\nanalysis.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 16:44:37 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 11:22:53 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jancar", "Petr", ""]]}, {"id": "1812.03624", "submitter": "Amy Felty", "authors": "Mohamed Yousri Mahmoud and Amy P. Felty", "title": "Formalization of Metatheory of the Quipper Quantum Programming Language\n  in a Linear Logic", "comments": "40 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a linear logical framework within the Hybrid system and use it to\nreason about the type system of a quantum lambda calculus. In particular, we\nconsider a practical version of the calculus called Proto-Quipper, which\ncontains the core of Quipper. Quipper is a new quantum programming language\nunder active development and recently has gained much popularity among the\nquantum computing communities. Hybrid is a system that is designed to support\nthe use of higher-order abstract syntax (HOAS) for representing and reasoning\nabout formal systems implemented in the Coq Proof Assistant. In this work, we\nextend the system with a linear specification logic (SL) in order to reason\nabout the linear type system of Quipper. To this end, we formalize the\nsemantics of Proto-Quipper by encoding the typing and evaluation rules in the\nSL, and prove type soundness.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 05:10:13 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Mahmoud", "Mohamed Yousri", ""], ["Felty", "Amy P.", ""]]}, {"id": "1812.03923", "submitter": "\\'I\\~nigo \\'Incer Romeo", "authors": "\\'I\\~nigo \\'Incer Romeo, Marten Lohstroh, Antonio Iannopollo, Edward\n  A. Lee, Alberto Sangiovanni-Vincentelli", "title": "A Metric for Linear Temporal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a measure and a metric on the sets of infinite traces generated by\na set of atomic propositions. To compute these quantities, we first map\nproperties to subsets of the real numbers and then take the Lebesgue measure of\nthe resulting sets. We analyze how this measure is computed for Linear Temporal\nLogic (LTL) formulas. An implementation for computing the measure of bounded\nLTL properties is provided and explained. This implementation leverages SAT\nmodel counting and effects independence checks on subexpressions to compute the\nmeasure and metric compositionally.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 22:24:14 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Romeo", "\u00cd\u00f1igo \u00cdncer", ""], ["Lohstroh", "Marten", ""], ["Iannopollo", "Antonio", ""], ["Lee", "Edward A.", ""], ["Sangiovanni-Vincentelli", "Alberto", ""]]}, {"id": "1812.04088", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Towards Machine Learning Induction", "comments": "This abstract is submitted to the fourth Conference on Artificial\n  Intelligence (AITP2019) and Theorem Proving and to the third Workshop on\n  Learning in Verification (LiVE2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Induction lies at the heart of mathematics and computer science. However,\nautomated theorem proving of inductive problems is still limited in its power.\nIn this abstract, we first summarize our progress in automating inductive\ntheorem proving for Isabelle/HOL. Then, we present MeLoId, our approach to\nsuggesting promising applications of induction without completing a proof\nsearch.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 16:24:33 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 13:33:35 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "1812.04090", "submitter": "Weihao Qu", "authors": "Weihao Qu, Marco Gaboardi and Deepak Garg", "title": "Relational Cost Analysis for Functional-Imperative Programs", "comments": "14 pages", "journal-ref": null, "doi": "10.1145/3341696", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational cost analysis aims at formally establishing bounds on the\ndifference in the evaluation costs of two programs. As a particular case, one\ncan also use relational cost analysis to establish bounds on the difference in\nthe evaluation cost of the same program on two different inputs. One way to\nperform relational cost analysis is to use a relational type-and-effect system\nthat supports reasoning about relations between two executions of two programs.\n  Building on this basic idea, we present a type-and-effect system, called\nARel, for reasoning about the relative cost of array-manipulating, higher-order\nfunctional-imperative programs. The key ingredient of our approach is a new\nlightweight type refinement discipline that we use to track relations\n(differences) between two arrays. This discipline combined with Hoare-style\ntriples built into the types allows us to express and establish precise\nrelative costs of several interesting programs which imperatively update their\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 21:09:47 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 18:24:28 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Qu", "Weihao", ""], ["Gaboardi", "Marco", ""], ["Garg", "Deepak", ""]]}, {"id": "1812.04379", "submitter": "Floris Geerts", "authors": "Floris Geerts", "title": "On the expressive power of linear algebra on graphs", "comments": "51 pages, revised extended version of conference paper (International\n  Conference on Database Theory 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most graph query languages are rooted in logic. By contrast, in this paper we\nconsider graph query languages rooted in linear algebra. More specifically, we\nconsider MATLANG, a matrix query language recently introduced, in which some\nbasic linear algebra functionality is supported. We investigate the problem of\ncharacterising equivalence of graphs, represented by their adjacency matrices,\nfor various fragments of MATLANG. A complete picture is painted of the impact\nof the linear algebra operations in MATLANG on their ability to distinguish\ngraphs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 13:13:38 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 14:54:35 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Geerts", "Floris", ""]]}, {"id": "1812.04413", "submitter": "Piotr Witkowski", "authors": "Bartosz Bednarczyk, Emanuel Kiero\\'nski, Piotr Witkowski", "title": "Completing the Picture: Complexity of Graded Modal Logics with Converse", "comments": "This is an extended version of our JELIA 2019 paper, under\n  consideration in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": "10.1017/S1471068421000065", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complete classification of the complexity of the local and global\nsatisfiability problems for graded modal language over traditional classes of\nframes have already been established. By \"traditional\" classes of frames, we\nmean those characterized by any positive combination of reflexivity, seriality,\nsymmetry, transitivity, and the Euclidean property. In this paper, we fill the\ngaps remaining in an analogous classification of the graded modal language with\ngraded converse modalities. In particular, we show its NExpTime-completeness\nover the class of Euclidean frames, demonstrating this way that over this class\nthe considered language is harder than the language without graded modalities\nor without converse modalities. We also consider its variation disallowing\ngraded converse modalities, but still admitting basic converse modalities. Our\nmost important result for this variation is confirming an earlier conjecture\nthat it is decidable over transitive frames. This contrasts with the\nundecidability of the language with graded converse modalities.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 14:09:35 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 20:26:06 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 10:06:39 GMT"}, {"version": "v4", "created": "Sun, 15 Nov 2020 12:11:00 GMT"}, {"version": "v5", "created": "Thu, 4 Mar 2021 11:55:02 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bednarczyk", "Bartosz", ""], ["Kiero\u0144ski", "Emanuel", ""], ["Witkowski", "Piotr", ""]]}, {"id": "1812.04452", "submitter": "Maciej Bendkowski", "authors": "Maciej Bendkowski", "title": "Towards the average-case analysis of substitution resolution in\n  $\\lambda$-calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substitution resolution supports the computational character of\n$\\beta$-reduction, complementing its execution with a capture-avoiding exchange\nof terms for bound variables. Alas, the meta-level definition of substitution,\nmasking a non-trivial computation, turns $\\beta$-reduction into an atomic\nrewriting rule, despite its varying operational complexity. In the current\npaper we propose a somewhat indirect average-case analysis of substitution\nresolution in the classic $\\lambda$-calculus, based on the quantitative\nanalysis of substitution in $\\lambda\\upsilon$, an extension of\n$\\lambda$-calculus internalising the $\\upsilon$-calculus of explicit\nsubstitutions. Within this framework, we show that for any fixed $n \\geq 0$,\nthe probability that a uniformly random, conditioned on size,\n$\\lambda\\upsilon$-term $\\upsilon$-normalises in $n$ normal-order (i.e.\nleftmost-outermost) reduction steps tends to a computable limit as the term\nsize tends to infinity. For that purpose, we establish an effective hierarchy\n$\\left(\\mathscr{G}_n\\right)_n$ of regular tree grammars partitioning\n$\\upsilon$-normalisable terms into classes of terms normalising in $n$\nnormal-order rewriting steps. The main technical ingredient in our construction\nis an inductive approach to the construction of $\\mathscr{G}_{n+1}$ out of\n$\\mathscr{G}_n$ based, in turn, on the algorithmic construction of finite\nintersection partitions, inspired by Robinson's unification algorithm. Finally,\nwe briefly discuss applications of our approach to other term rewriting\nsystems, focusing on two closely related formalisms, i.e. the full\n$\\lambda\\upsilon$-calculus and combinatory logic.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 15:09:02 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Bendkowski", "Maciej", ""]]}, {"id": "1812.04491", "submitter": "Martin Gebser", "authors": "Yannis Dimopoulos, Martin Gebser, Patrick L\\\"uhne, Javier Romero,\n  Torsten Schaub", "title": "plasp 3: Towards Effective ASP Planning", "comments": "27 pages, under consideration for publication in Theory and Practice\n  of Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 477-504", "doi": "10.1017/S1471068418000583", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the new version of the PDDL-to-ASP translator plasp. First, it\nwidens the range of accepted PDDL features. Second, it contains novel planning\nencodings, some inspired by SAT planning and others exploiting ASP features\nsuch as well-foundedness. All of them are designed for handling multivalued\nfluents in order to capture both PDDL as well as SAS planning formats. Third,\nenabled by multishot ASP solving, it offers advanced planning algorithms also\nborrowed from SAT planning. As a result, plasp provides us with an ASP-based\nframework for studying a variety of planning techniques in a uniform setting.\nFinally, we demonstrate in an empirical analysis that these techniques have a\nsignificant impact on the performance of ASP planning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 15:50:34 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dimopoulos", "Yannis", ""], ["Gebser", "Martin", ""], ["L\u00fchne", "Patrick", ""], ["Romero", "Javier", ""], ["Schaub", "Torsten", ""]]}, {"id": "1812.04580", "submitter": "Kuldeep S. Meel", "authors": "Davin Choo, Mate Soos, Kian Ming A. Chai, and Kuldeep S. Meel", "title": "BOSPHORUS: Bridging ANF and CNF Solvers", "comments": "To Appear in Proceedings of DATE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic Normal Form (ANF) and Conjunctive Normal Form (CNF) are commonly\nused to encode problems in Boolean algebra. ANFs are typically solved via\nGr\"obner basis algorithms, often using more memory than is feasible; while CNFs\nare solved using SAT solvers, which cannot exploit the algebra of polynomials\nnaturally. We propose a paradigm that bridges between ANF and CNF solving\ntechniques: the techniques are applied in an iterative manner to emph{learn\nfacts} to augment the original problems. Experiments on over 1,100 benchmarks\narising from four different applications domains demonstrate that learnt facts\ncan significantly improve runtime and enable more benchmarks to be solved.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 18:05:56 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Choo", "Davin", ""], ["Soos", "Mate", ""], ["Chai", "Kian Ming A.", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "1812.04861", "submitter": "Alexander Gerasimov", "authors": "Alexander S. Gerasimov", "title": "A repetition-free hypersequent calculus for first-order rational Pavelka\n  logic", "comments": "21 pages; corrected a misprint, added an appendix containing errata\n  to a cited article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hypersequent calculus $\\text{G}^3\\text{\\L}\\forall$ for\nfirst-order infinite-valued {\\L}ukasiewicz logic and for an extension of it,\nfirst-order rational Pavelka logic; the calculus is intended for bottom-up\nproof search. In $\\text{G}^3\\text{\\L}\\forall$, there are no structural rules,\nall the rules are invertible, and designations of multisets of formulas are not\nrepeated in any premise of the rules. The calculus $\\text{G}^3\\text{\\L}\\forall$\nproves any sentence that is provable in at least one of the previously known\nhypersequent calculi for the given logics. We study proof-theoretic properties\nof $\\text{G}^3\\text{\\L}\\forall$ and thereby provide foundations for proof\nsearch algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 09:17:06 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 13:50:26 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Gerasimov", "Alexander S.", ""]]}, {"id": "1812.05297", "submitter": "Alexander Gerasimov", "authors": "Alexander S. Gerasimov", "title": "Comparing several calculi for first-order infinite-valued {\\L}ukasiewicz\n  logic", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the viewpoint of provability, we compare some Gentzen-type hypersequent\ncalculi for first-order infinite-valued {\\L}ukasiewicz logic and for\nfirst-order rational Pavelka logic with each other and with H\\'ajek's\nHilbert-type calculi for these logics. The key aspect of our comparison is a\ndensity elimination proof for one of the hypersequent calculi considered.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 07:32:29 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Gerasimov", "Alexander S.", ""]]}, {"id": "1812.05444", "submitter": "Antonella Del Pozzo", "authors": "Zaynah Dargaye (DILS), Antonella Pozzo (DILS), Sara Tucci-Piergiovanni\n  (DILS)", "title": "Pluralize: a Trustworthy Framework for High-Level Smart Contract-Draft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents Pluralize a formal logical framework able to extend the\nexecution of blockchain transactions to events coming from external oracles,\nlike external time, sensor data, human-made declarations, etc. These events are\nby essence non-reliable, since transaction execution can be triggered by\ninformation whose veracity cannot be established by the blockchain. To overcome\nthis problem, the language features a first-order logic and an authority\nalgebra to allow formal reasoning and establish accountability of agents for\nblockchain-enabled transactions. We provide an accountability model that allows\nto formally prove the accountability of agents by a formal proof locally\nexecutable by each agent of the blockchain.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 06:30:10 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Dargaye", "Zaynah", "", "DILS"], ["Pozzo", "Antonella", "", "DILS"], ["Tucci-Piergiovanni", "Sara", "", "DILS"]]}, {"id": "1812.05765", "submitter": "Brendan Fong", "authors": "Brendan Fong and David I Spivak", "title": "Graphical Regular Logic", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular logic can be regarded as the internal language of regular categories,\nbut the logic itself is generally not given a categorical treatment. In this\npaper, we understand the syntax and proof rules of regular logic in terms of\nthe free regular category $\\mathsf{FRg}(\\mathrm{T})$ on a set $\\mathrm{T}$.\nFrom this point of view, regular theories are certain monoidal 2-functors from\na suitable 2-category of contexts---the 2-category of relations in\n$\\mathsf{FRg}(\\mathrm{T})$---to the 2-category of posets. Such functors assign\nto each context the set of formulas in that context, ordered by entailment. We\nrefer to such a 2-functor as a regular calculus because it naturally gives rise\nto a graphical string diagram calculus in the spirit of Joyal and Street. Our\nkey aim to prove that the category of regular categories is essentially\nreflective in that of regular calculi. Along the way, we demonstrate how to use\nthis graphical calculus.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 03:07:29 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 19:36:53 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 17:28:00 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Fong", "Brendan", ""], ["Spivak", "David I", ""]]}, {"id": "1812.05851", "submitter": "Thomas Powell", "authors": "Thomas Powell", "title": "Computational interpretations of classical reasoning: From the epsilon\n  calculus to stateful programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of giving a computational meaning to classical reasoning lies at\nthe heart of logic. This article surveys three famous solutions to this problem\n- the epsilon calculus, modified realizability and the dialectica\ninterpretation - and re-examines them from a modern perspective, with a\nparticular emphasis on connections with algorithms and programming.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 10:34:43 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Powell", "Thomas", ""]]}, {"id": "1812.05873", "submitter": "Jonni Virtema", "authors": "Miika Hannula, {\\AA}sa Hirvonen, Juha Kontinen, Vadim Kulikov, and\n  Jonni Virtema", "title": "Facets of Distribution Identities in Probabilistic Team Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study probabilistic team semantics which is a semantical framework\nallowing the study of logical and probabilistic dependencies simultaneously. We\nexamine and classify the expressive power of logical formalisms arising by\ndifferent probabilistic atoms such as conditional independence and different\nvariants of marginal distribution equivalences. We also relate the framework to\nthe first-order theory of the reals and apply our methods to the open question\non the complexity of the implication problem of conditional independence.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 12:05:19 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:06:16 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Hannula", "Miika", ""], ["Hirvonen", "\u00c5sa", ""], ["Kontinen", "Juha", ""], ["Kulikov", "Vadim", ""], ["Virtema", "Jonni", ""]]}, {"id": "1812.06009", "submitter": "Christoph Rauch", "authors": "Antonio Bucciarelli, Delia Kesner, Simona Ronchi Della Rocca", "title": "Solvability = Typability + Inhabitation", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (January\n  29, 2021) lmcs:7141", "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We extend the classical notion of solvability to a lambda-calculus equipped\nwith pattern matching. We prove that solvability can be characterized by means\nof typability and inhabitation in an intersection type system P based on\nnon-idempotent types. We show first that the system P characterizes the set of\nterms having canonical form, i.e. that a term is typable if and only if it\nreduces to a canonical form. But the set of solvable terms is properly\ncontained in the set of canonical forms. Thus, typability alone is not\nsufficient to characterize solvability, in contrast to the case for the\nlambda-calculus. We then prove that typability, together with inhabitation,\nprovides a full characterization of solvability, in the sense that a term is\nsolvable if and only if it is typable and the types of all its arguments are\ninhabited. We complete the picture by providing an algorithm for the\ninhabitation problem of P.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 16:27:40 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 08:52:00 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 08:16:58 GMT"}, {"version": "v4", "created": "Thu, 28 Jan 2021 13:07:59 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Bucciarelli", "Antonio", ""], ["Kesner", "Delia", ""], ["Della Rocca", "Simona Ronchi", ""]]}, {"id": "1812.06341", "submitter": "Christopher Hampson", "authors": "Christopher Hampson", "title": "Decidable fragments of first-order modal logics with counting\n  quantifiers over varying domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the computational complexity of various natural\none-variable fragments of first-order modal logics with the addition of\ncounting quantifiers, over both constant and varying domains. The addition of\ncounting quantifiers provides us a rich language with which to succinctly\nexpress statements about the quantity of objects satisfying a given first-order\nproperty, using a single variable.\n  Optimal NExpTime upper-bounds are provided for the satisfiability problems of\nthe one-variable fragment of the minimal first-order modal logic QK, over both\nconstant and expanding/decreasing domain models, where counting quantifiers are\nencoded as binary strings. For the case where the counting quantifiers are\nencoded as unary strings, or are restricted to a finite set of quantifiers, it\nis shown that the satisfiability problem over expanding domains is\nPSpace-complete, whereas over decreasing domains the problem is shown to be\nExpTime-hard.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 19:37:14 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Hampson", "Christopher", ""]]}, {"id": "1812.06440", "submitter": "Lidia Tendera", "authors": "I. Pratt-Hartmann, W. Szwast, L. Tendera", "title": "Quine's Fluted Fragment Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fluted fragment, a decidable fragment of first-order logic with\nan unbounded number of variables, originally identified in 1968 by W.V. Quine.\nWe show that the satisfiability problem for this fragment has non-elementary\ncomplexity, thus refuting an earlier published claim by W.C. Purdy that it is\nin NExpTime. More precisely, we consider $\\mathcal{FL}^m$, the intersection of\nthe fluted fragment and the $m$-variable fragment of first-order logic, for all\n$m \\geq 1$. We show that, for $m \\geq 2$, this sub-fragment forces $\\lfloor\nm/2\\rfloor$-tuply exponentially large models, and that its satisfiability\nproblem is $\\lfloor m/2\\rfloor$-NExpTime-hard. We further establish that, for\n$m \\geq 3$, any satisfiable $\\mathcal{FL}^m$-formula has a model of at most\n($m-2$)-tuply exponential size, whence the satisfiability (= finite\nsatisfiability) problem for this fragment is in ($m-2$)-NExpTime. Together with\nother, known, complexity results, this provides tight complexity bounds for\n$\\mathcal{FL}^m$ for all $m \\leq 4$.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 10:42:42 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Pratt-Hartmann", "I.", ""], ["Szwast", "W.", ""], ["Tendera", "L.", ""]]}, {"id": "1812.06480", "submitter": "Tatsuji Kawai", "authors": "Tatsuji Kawai", "title": "Presenting de Groot duality of stably compact spaces", "comments": "Fixed some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a constructive account of the de Groot duality of stably compact\nspaces in the setting of strong proximity lattice, a point-free representation\nof a stably compact space. To this end, we introduce a notion of strong\ncontinuous entailment relation, which can be thought of as a presentation of a\nstrong proximity lattice by generators and relations. The new notion allows us\nto identify de Groot duals of stably compact spaces by analysing the duals of\ntheir presentations. We carry out a number of constructions on strong proximity\nlattices using strong continuous entailment relations and study their de Groot\nduals. The examples include various powerlocales, patch topology, and the space\nof valuations. These examples illustrate the simplicity of our approach by\nwhich we can reason about the de Groot duality of stably compact spaces.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 15:13:14 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 08:23:35 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 01:01:19 GMT"}, {"version": "v4", "created": "Sun, 8 Mar 2020 23:04:25 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kawai", "Tatsuji", ""]]}, {"id": "1812.06569", "submitter": "Suguman Bansal", "authors": "Suguman Bansal, Swarat Chaudhuri, and Moshe Y. Vardi", "title": "Comparator automata in quantitative verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notion of comparison between system runs is fundamental in formal\nverification. This concept is implicitly present in the verification of\nqualitative systems, and is more pronounced in the verification of quantitative\nsystems. In this work, we identify a novel mode of comparison in quantitative\nsystems: the online comparison of the aggregate values of two sequences of\nquantitative weights. This notion is embodied by {\\em comparator automata}\n({\\em comparators}, in short), a new class of automata that read two infinite\nsequences of weights synchronously and relate their aggregate values.\n  We show that {aggregate functions} that can be represented with B\\\"uchi\nautomaton result in comparators that are finite-state and accept by the B\\\"uchi\ncondition as well. Such {\\em $\\omega$-regular comparators} further lead to\ngeneric algorithms for a number of well-studied problems, including the\nquantitative inclusion and winning strategies in quantitative graph games with\nincomplete information, as well as related non-decision problems, such as\nobtaining a finite representation of all counterexamples in the quantitative\ninclusion problem.\n  We study comparators for two aggregate functions: discounted-sum and\nlimit-average. We prove that the discounted-sum comparator is $\\omega$-regular\niff the discount-factor is an integer. Not every aggregate function, however,\nhas an $\\omega$-regular comparator. Specifically, we show that the language of\nsequence-pairs for which limit-average aggregates exist is neither\n$\\omega$-regular nor $\\omega$-context-free. Given this result, we introduce the\nnotion of {\\em prefix-average} as a relaxation of limit-average aggregation,\nand show that it admits $\\omega$-context-free comparators.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 01:04:01 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Bansal", "Suguman", ""], ["Chaudhuri", "Swarat", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1812.06745", "submitter": "Merlin G\\\"ottlinger", "authors": "Merlin G\\\"ottlinger, Lutz Schr\\\"oder", "title": "Trichotomic Argumentation Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Aristotelian trichotomy distinguishes three aspects of argumentation:\nLogos, Ethos, and Pathos. Even rich argumentation representations like the\nArgument Interchange Format (AIF) are only concerned with capturing the Logos\naspect. Inference Anchoring Theory (IAT) adds the possibility to represent\nethical requirements on the illocutionary force edges linking locutions to\nillocutions, thereby allowing to capture some aspects of ethos. With the recent\nextensions AIF+ and Social Argument Interchange Format (S-AIF), which embed\ndialogue and speakers into the AIF argumentation representation, the basis for\nrepresenting all three aspects identified by Aristotle was formed. In the\npresent work, we develop the Trichotomic Argument Interchange Format (T-AIF),\nbuilding on the idea from S-AIF of adding the speakers to the argumentation\ngraph. We capture Logos in the usual known from AIF+, Ethos in form of weighted\nedges between actors representing trust, and Pathos via weighted edges from\nactors to illocutions representing their level of commitment to the\npropositions. This extended structured argumentation representation opens up\nnew possibilities of defining semantic properties on this rich graph in order\nto characterize and profile the reasoning patterns of the participating actors.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 13:12:03 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["G\u00f6ttlinger", "Merlin", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "1812.07072", "submitter": "Nathana\\\"el Fijalkow", "authors": "Nathana\\\"el Fijalkow and Pawe{\\l} Gawrychowski and Pierre Ohlmann", "title": "The complexity of mean payoff games using universal graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of solving mean payoff games. This\nclass of games can be seen as an extension of parity games, and they have\nsimilar complexity status: in both cases solving them is in $\\textbf{NP} \\cap\n\\textbf{coNP}$ and not known to be in $\\textbf{P}$. In a breakthrough result\nCalude, Jain, Khoussainov, Li, and Stephan constructed in 2017 a\nquasipolynomial time algorithm for solving parity games, which was quickly\nfollowed by two other algorithms with the same complexity. Our objective is to\ninvestigate how these techniques can be extended to the study of mean payoff\ngames.\n  The starting point is the notion of separating automata, which has been used\nto present all three quasipolynomial time algorithms for parity games and gives\nthe best complexity to date. The notion naturally extends to mean payoff games\nand yields a class of algorithms for solving mean payoff games. The\ncontribution of this paper is to prove tight bounds on the complexity of\nalgorithms in this class. We construct two new algorithms for solving mean\npayoff games. Our first algorithm depends on the largest weight $N$ (in\nabsolute value) appearing in the graph and runs in sublinear time in $N$,\nimproving over the previously known linear dependence in $N$. Our second\nalgorithm runs in polynomial time for a fixed number $k$ of weights.\n  We complement our upper bounds by providing in both cases almost matching\nlower bounds, showing the limitations of the separating automata approach. We\nshow that we cannot hope to improve on the dependence in $N$ nor break the\nlinear dependence in the exponent in the number $k$ of weights. In particular,\nthis shows that separating automata do not yield a quasipolynomial algorithm\nfor solving mean payoff games.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 22:13:33 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 19:04:26 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", ""], ["Gawrychowski", "Pawe\u0142", ""], ["Ohlmann", "Pierre", ""]]}, {"id": "1812.07079", "submitter": "Emiliano Lorini", "authors": "Emiliano Lorini", "title": "Rethinking Epistemic Logic with Belief Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new semantics for a logic of explicit and implicit beliefs\nbased on the concept of multi-agent belief base. Differently from existing\nKripke-style semantics for epistemic logic in which the notions of possible\nworld and doxastic/epistemic alternative are primitive, in our semantics they\nare non-primitive but are defined from the concept of belief base. We provide a\ncomplete axiomatization and prove decidability for our logic via a finite model\nargument. We also provide a polynomial embedding of our logic into Fagin &\nHalpern's logic of general awareness and establish a complexity result for our\nlogic via the embedding.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 22:30:45 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Lorini", "Emiliano", ""]]}, {"id": "1812.07288", "submitter": "Fredrik Dahlqvist", "authors": "Fredrik Dahlqvist and Alexander Kurz", "title": "The positivication of coalgebraic logics", "comments": "14 pages", "journal-ref": null, "doi": "10.4230/LIPIcs.CALCO.2017.9", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present positive coalgebraic logic in full generality, and show how to\nobtain a positive coalgebraic logic from a boolean one. On the model side this\ninvolves canonically computing an endofunctor $T': Pos\\to Pos$ from an\nendofunctor $T: Set\\to Set$, in a procedure previously defined by the second\nauthor et alii called posetification. On the syntax side, it involves\ncanonically computing a syntax-building functor $L': DL\\to DL$ from a\nsyntax-building functor $L: BA\\to BA$, in a dual procedure which we call\npositivication. These operations are interesting in their own right and we\nexplicitly compute posetifications and positivications in the case of several\nmodal logics. We show how the semantics of a boolean coalgebraic logic can be\ncanonically lifted to define a semantics for its positive fragment, and that\nweak completeness transfers from the boolean case to the positive case.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 10:48:39 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Dahlqvist", "Fredrik", ""], ["Kurz", "Alexander", ""]]}, {"id": "1812.08003", "submitter": "Sebastian Siebertz", "authors": "Kord Eickmeyer, Jan van den Heuvel, Ken-ichi Kawarabayashi, Stephan\n  Kreutzer, Patrice Ossona de Mendez, Micha{\\l} Pilipczuk, Daniel A. Quiroz,\n  Roman Rabinovich, Sebastian Siebertz", "title": "Model-Checking on Ordered Structures", "comments": "arXiv admin note: substantial text overlap with arXiv:1701.08516", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the model-checking problem for first- and monadic second-order logic\non finite relational structures. The problem of verifying whether a formula of\nthese logics is true on a given structure is considered intractable in general,\nbut it does become tractable on interesting classes of structures, such as on\nclasses whose Gaifman graphs have bounded treewidth. In this paper we continue\nthis line of research and study model-checking for first- and monadic\nsecond-order logic in the presence of an ordering on the input structure. We do\nso in two settings: the general ordered case, where the input structures are\nequipped with a fixed order or successor relation, and the order invariant\ncase, where the formulas may resort to an ordering, but their truth must be\nindependent of the particular choice of order. In the first setting we show\nvery strong intractability results for most interesting classes of structures.\nIn contrast, in the order invariant case we obtain tractability results for\norder-invariant monadic second-order formulas on the same classes of graphs as\nin the unordered case. For first-order logic, we obtain tractability of\nsuccessor-invariant formulas on classes whose Gaifman graphs have bounded\nexpansion. Furthermore, we show that model-checking for order-invariant\nfirst-order formulas is tractable on coloured posets of bounded width.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 10:21:15 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Eickmeyer", "Kord", ""], ["Heuvel", "Jan van den", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Kreutzer", "Stephan", ""], ["de Mendez", "Patrice Ossona", ""], ["Pilipczuk", "Micha\u0142", ""], ["Quiroz", "Daniel A.", ""], ["Rabinovich", "Roman", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1812.08079", "submitter": "Jacques Carette", "authors": "Jacques Carette, Russell O'Connor, Yasmine Sharoda", "title": "Building on the Diamonds between Theories: Theory Presentation\n  Combinators", "comments": "Extended version of paper with a similar title at CICM 2012, also\n  listed as arXiv:1204.0053. Submitted to a journal. Almost the entire article\n  has been rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build a large library of mathematics, it seems more efficient to take\nadvantage of the inherent structure of mathematical theories. Various theory\npresentation combinators have been proposed, and some have been implemented, in\nboth legacy and current systems. Surprisingly, the ``standard library'' of most\nsystems do not make pervasive use of these combinators.\n  We present a set of combinators optimized for reuse, via the tiny theories\napproach. Our combinators draw their power from the inherent structure already\npresent in the \\emph{category of contexts} associated to a dependently typed\nlanguage. The current work builds on ideas originating in CLEAR and Specware\nand their descendents (both direct and intellectual). Driven by some design\ncriteria for user-centric library design, our library-building experience via\nthe systematic use of combinators has fed back into the semantics of these\ncombinators, and later into an updated syntax for them.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 20:07:02 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 20:48:12 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Carette", "Jacques", ""], ["O'Connor", "Russell", ""], ["Sharoda", "Yasmine", ""]]}, {"id": "1812.08083", "submitter": "Mona Noori-Hosseini", "authors": "Mona Noori-Hosseini, Bengt Lennartson, Christoforos Hadjicostis", "title": "Incremental Observer Reduction Applied to Opacity Verification and\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of communication networks and mobile devices, the\nprivacy and security concerns on their information flow are raised. Given a\ncritical system that may leak confidential information, the problem consists of\nverifying and also enforcing opacity by designing supervisors, to conceal\nconfidential information from unauthorized persons. To find out what the\nintruder sees, it is required to construct an observer of the system. In this\npaper, we consider incremental observer generation of modular systems, for\nverification and enforcement of current state opacity. The synchronization of\nthe subsystems generate a large state space. Moreover, the observer generation\nwith exponential complexity adds even larger state space. To tackle the\ncomplexity problem, we prove that observer generation can be done locally\nbefore synchronizing the subsystems. The incremental local observer generation\nalong with an abstraction method lead to a significant state space reduction\ncompared to traditional monolithic methods. The existence of shared\nunobservable events is also considered in the incremental approach. Moreover,\nwe present an illustrative example, where the results of verification and\nenforcement of current state opacity are shown on a modular multiple\nfloor/elevator building with an intruder. Furthermore, we extend the current\nstate opacity, current state anonymity, and language based opacity formulations\nfor verification of modular systems.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 22:05:56 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 16:16:45 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 20:39:47 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Noori-Hosseini", "Mona", ""], ["Lennartson", "Bengt", ""], ["Hadjicostis", "Christoforos", ""]]}, {"id": "1812.08441", "submitter": "Etienne Andre", "authors": "Andr\\'e \\'Etienne (LIPN)", "title": "A benchmark library for parametric timed model checking", "comments": null, "journal-ref": "Springer CCIS 1008, pages 75-83, November 2018", "doi": "10.1007/978-3-030-17465-1_12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of real-time systems involving hard timing constraints and\nconcurrency is of utmost importance. Parametric timed model checking allows for\nformal verification in the presence of unknown timing constants or uncertainty\n(e.g. imprecision for periods). With the recent development of several\ntechniques and tools to improve the efficiency of parametric timed model\nchecking, there is a growing need for proper benchmarks to test and compare\nfairly these tools. We present here a benchmark library for parametric timed\nmodel checking made of benchmarks accumulated over the years. Our benchmarks\ninclude academic benchmarks, industrial case studies and examples unsolvable\nusing existing techniques.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 09:37:56 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["\u00c9tienne", "Andr\u00e9", "", "LIPN"]]}, {"id": "1812.08763", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno and Luis Fari\\~nas del Cerro", "title": "Splitting Epistemic Logic Programs", "comments": "Theory and Practice of Logic Programming", "journal-ref": "Theory and Practice of Logic Programming 21 (2021) 296-316", "doi": "10.1017/S1471068420000058", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic logic programs constitute an extension of the stable models\nsemantics to deal with new constructs called subjective literals. Informally\nspeaking, a subjective literal allows checking whether some regular literal is\ntrue in all stable models or in some stable model. As it can be imagined, the\nassociated semantics has proved to be non-trivial, as the truth of the\nsubjective literal may interfere with the set of stable models it is supposed\nto query. As a consequence, no clear agreement has been reached and different\nsemantic proposals have been made in the literature. Unfortunately, comparison\namong these proposals has been limited to a study of their effect on individual\nexamples, rather than identifying general properties to be checked. In this\npaper, we propose an extension of the well-known splitting property for logic\nprograms to the epistemic case. To this aim, we formally define when an\narbitrary semantics satisfies the epistemic splitting property and examine some\nof the consequences that can be derived from that, including its relation to\nconformant planning and to epistemic constraints. Interestingly, we prove\n(through counterexamples) that most of the existing proposals fail to fulfill\nthe epistemic splitting property, except the original semantics proposed by\nGelfond in 1991.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 18:45:08 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 14:30:19 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["del Cerro", "Luis Fari\u00f1as", ""]]}, {"id": "1812.08940", "submitter": "\\'Etienne Andr\\'e", "authors": "\\'Etienne Andr\\'e, Ichiro Hasuo, Masaki Waga", "title": "Offline timed pattern matching under uncertainty", "comments": null, "journal-ref": "ICECCS 2018, IEEE CPS, pages 10-20, December 2018. Best paper\n  award", "doi": "10.1109/ICECCS2018.2018.00010", "report-no": null, "categories": "cs.SY cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a log and a specification, timed pattern matching aims at exhibiting\nfor which start and end dates a specification holds on that log. For example,\n\"a given action is always followed by another action before a given deadline\".\nThis problem has strong connections with monitoring real-time systems. We\naddress here timed pattern matching in presence of an uncertain specification,\ni.e., that may contain timing parameters (e.g., the deadline can be uncertain\nor unknown). That is, we want to know for which start and end dates, and for\nwhat values of the deadline, this property holds. Or what is the minimum or\nmaximum deadline (together with the corresponding start and end dates) for\nwhich this property holds. We propose here a framework for timed pattern\nmatching based on parametric timed model checking. In contrast to most\nparametric timed problems, the solution is effectively computable, and we\nperform experiments using IMITATOR to show the applicability of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 04:28:16 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Andr\u00e9", "\u00c9tienne", ""], ["Hasuo", "Ichiro", ""], ["Waga", "Masaki", ""]]}, {"id": "1812.08949", "submitter": "\\'Etienne Andr\\'e", "authors": "\\'Etienne Andr\\'e, Laurent Fribourg, Jean-Marc Mota and Romain Soulat", "title": "Verification of an industrial asynchronous leader election algorithm\n  using abstractions and parametric model checking", "comments": "This is the author version of the manuscript of the same name\n  published in the proceedings of the 20th International Conference on\n  Verification, Model Checking, and Abstract Interpretation (VMCAI 2019)", "journal-ref": null, "doi": "10.1007/978-3-030-11245-5_19", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The election of a leader in a network is a challenging task, especially when\nthe processes are asynchronous, i.e., execute an algorithm with time-varying\nperiods. Thales developed an industrial election algorithm with an arbitrary\nnumber of processes, that can possibly fail. In this work, we prove the\ncorrectness of a variant of this industrial algorithm. We use a method\ncombining abstraction, the SafeProver solver, and a parametric timed\nmodel-checker. This allows us to prove the correctness of the algorithm for a\nlarge number p of processes (p=5000).\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 05:03:21 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Andr\u00e9", "\u00c9tienne", ""], ["Fribourg", "Laurent", ""], ["Mota", "Jean-Marc", ""], ["Soulat", "Romain", ""]]}, {"id": "1812.09190", "submitter": "Francesco Ciraulo", "authors": "Francesco Ciraulo, Tatsuji Kawai, Samuele Maschio", "title": "Factorizing the Top-Loc adjunction through positive topologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GN cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the category of Sambin's positive topologies as a fibration\nover the category of locales Loc. The fibration is obtained by applying the\nGrothendieck construction to a doctrine over Loc. We then construct an\nadjunction between the category of positive topologies and that of topological\nspaces Top, and show that the well-known adjunction between Top and Loc factors\nthrough the newly constructed adjunction.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 11:30:31 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Ciraulo", "Francesco", ""], ["Kawai", "Tatsuji", ""], ["Maschio", "Samuele", ""]]}, {"id": "1812.09519", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli, Pierre Bourhis, Stefan Mengel, Matthias Niewerth", "title": "Enumeration on Trees with Tractable Combined Complexity and Efficient\n  Updates", "comments": "16 pages of main material, 37 references, 11 pages of appendix. This\n  is the extended version with proofs of the PODS'19 paper. Except for minor\n  rephrasings and formatting differences, the contents are exactly the same as\n  the version published in the PODS'19 proceedings", "journal-ref": null, "doi": "10.1145/3294052.3319702", "report-no": null, "categories": "cs.DB cs.DS cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm to enumerate the results on trees of monadic\nsecond-order (MSO) queries represented by nondeterministic tree automata. After\nlinear time preprocessing (in the input tree), we can enumerate answers with\nlinear delay (in each answer). We allow updates on the tree to take place at\nany time, and we can then restart the enumeration after logarithmic time in the\ntree. Further, all our combined complexities are polynomial in the automaton.\n  Our result follows our previous circuit-based enumeration algorithms based on\ndeterministic tree automata, and is also inspired by our earlier result on\nwords and nondeterministic sequential extended variable-set automata in the\ncontext of document spanners. We extend these results and combine them with a\nrecent tree balancing scheme by Niewerth, so that our enumeration structure\nsupports updates to the underlying tree in logarithmic time (with leaf\ninsertions, leaf deletions, and node relabelings). Our result implies that, for\nMSO queries with free first-order variables, we can enumerate the results with\nlinear preprocessing and constant-delay and update the underlying tree in\nlogarithmic time, which improves on several known results for words and trees.\n  Building on lower bounds from data structure research, we also show\nunconditionally that up to a doubly logarithmic factor the update time of our\nalgorithm is optimal. Thus, unlike other settings, there can be no algorithm\nwith constant update time.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 12:16:35 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 16:14:02 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Amarilli", "Antoine", ""], ["Bourhis", "Pierre", ""], ["Mengel", "Stefan", ""], ["Niewerth", "Matthias", ""]]}, {"id": "1812.09718", "submitter": "Francesco Calimeri", "authors": "Francesco Calimeri, Simona Perri, Jessica Zangari", "title": "Optimizing Answer Set Computation via Heuristic-Based Decomposition", "comments": "28 pages, 6 figures, 4 tables, BEST PAPER AWARD at PADL 2018 (Los\n  Angeles, CA, USA), Under consideration in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 603-628", "doi": "10.1017/S1471068419000036", "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a purely declarative formalism developed in\nthe field of logic programming and nonmonotonic reasoning: computational\nproblems are encoded by logic programs whose answer sets, corresponding to\nsolutions, are computed by an ASP system. Different, semantically equivalent,\nprograms can be defined for the same problem; however, performance of systems\nevaluating them might significantly vary. We propose an approach for\nautomatically transforming an input logic program into an equivalent one that\ncan be evaluated more efficiently. One can make use of existing\ntree-decomposition techniques for rewriting selected rules into a set of\nmultiple ones; the idea is to guide and adaptively apply them on the basis of\nproper new heuristics, to obtain a smart rewriting algorithm to be integrated\ninto an ASP system. The method is rather general: it can be adapted to any\nsystem and implement different preference policies. Furthermore, we define a\nset of new heuristics tailored at optimizing grounding, one of the main phases\nof the ASP computation; we use them in order to implement the approach into the\nASP system DLV, in particular into its grounding subsystem I-DLV, and carry out\nan extensive experimental activity for assessing the impact of the proposal.\nUnder consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 14:35:58 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 17:27:16 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Calimeri", "Francesco", ""], ["Perri", "Simona", ""], ["Zangari", "Jessica", ""]]}, {"id": "1812.09867", "submitter": "Michel de Rougemont", "authors": "Michel de Rougemont and Guillaume Vimont", "title": "The content correlation of multiple streaming edges", "comments": "16 pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study how to detect clusters in a graph defined by a stream of edges,\nwithout storing the entire graph. We extend the approach to dynamic graphs\ndefined by the most recent edges of the stream and to several streams. The {\\em\ncontent correlation }of two streams $\\rho(t)$ is the Jaccard similarity of\ntheir clusters in the windows before time $t$. We propose a simple and\nefficient method to approximate this correlation online and show that for\ndynamic random graphs which follow a power law degree distribution, we can\nguarantee a good approximation. As an application, we follow Twitter streams\nand compute their content correlations online. We then propose a {\\em search by\ncorrelation} where answers to sets of keywords are entirely based on the small\ncorrelations of the streams. Answers are ordered by the correlations, and\nexplanations can be traced with the stored clusters.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 09:19:10 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["de Rougemont", "Michel", ""], ["Vimont", "Guillaume", ""]]}, {"id": "1812.10005", "submitter": "Hsi-Ming Ho", "authors": "Hsi-Ming Ho, Ruoyu Zhou, and Timothy M. Jones", "title": "On Verifying Timed Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the satisfiability and model-checking problems for timed\nhyperproperties specified with HyperMTL, a timed extension of HyperLTL.\nDepending on whether interleaving of events in different traces is allowed, two\npossible semantics can be defined for timed hyperproperties: asynchronous and\nsynchronous. While the satisfiability problem can be decided similarly to\nHyperLTL regardless of the choice of semantics, we show that the model-checking\nproblem, unless the specification is alternation-free, is undecidable even when\nvery restricted timing constraints are allowed. On the positive side, we show\nthat model checking HyperMTL with quantifier alternations is possible under\ncertain conditions in the synchronous semantics, or when there is a fixed bound\non the length of the time domain.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 01:17:41 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Ho", "Hsi-Ming", ""], ["Zhou", "Ruoyu", ""], ["Jones", "Timothy M.", ""]]}, {"id": "1812.10008", "submitter": "George Cherevichenko", "authors": "George Cherevichenko", "title": "Alpha-conversion for lambda terms with explicit weakenings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using explicit weakenings, we can define alpha-conversion by simple equations\nwithout any mention of free variables.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 01:21:52 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Cherevichenko", "George", ""]]}, {"id": "1812.10026", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Induction, Coinduction, and Fixed Points: A Concise Comparative Survey", "comments": "13 pages (split article into three articles)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey article (which hitherto is an ongoing work-in-progress) we\npresent the formulation of the induction and coinduction principles using the\nlanguage and conventions of each of order theory, set theory, programming\nlanguages' type theory, first-order logic, and category theory, for the purpose\nof examining some of the similarities and, more significantly, the\ndissimilarities between these various mathematical disciplines, and hence shed\nsome light on the precise relation between these disciplines.\n  Towards that end, in this article we discuss plenty of related concepts, such\nas fixed points, pre-fixed points, post-fixed points, inductive sets and types,\ncoinductive sets and types, algebras and coalgebras. We conclude the survey by\nhinting at the possibility of a more abstract and unified treatment that uses\nconcepts from category theory such as monads and comonads.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 04:28:54 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 17:23:14 GMT"}, {"version": "v3", "created": "Thu, 17 Jan 2019 13:30:48 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 18:53:17 GMT"}, {"version": "v5", "created": "Mon, 28 Jan 2019 18:10:32 GMT"}, {"version": "v6", "created": "Thu, 7 Feb 2019 18:37:16 GMT"}, {"version": "v7", "created": "Wed, 13 Feb 2019 13:47:52 GMT"}, {"version": "v8", "created": "Mon, 18 Feb 2019 10:16:59 GMT"}, {"version": "v9", "created": "Thu, 28 Feb 2019 04:41:34 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1812.10146", "submitter": "Hsi-Ming Ho", "authors": "Hsi-Ming Ho", "title": "Revisiting Timed Logics with Automata Modalities", "comments": "To appear in HSCC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that (timed) $\\omega$-regular properties such as `p holds at\nevery even position' and `p occurs at least three times within the next 10 time\nunits' cannot be expressed in Metric Interval Temporal Logic ($\\mathsf{MITL}$)\nand Event Clock Logic ($\\mathsf{ECL}$). A standard remedy to this deficiency is\nto extend these with modalities defined in terms of automata. In this paper, we\nshow that the logics $\\mathsf{EMITL}_{0,\\infty}$ (adding non-deterministic\nfinite automata modalities into the fragment of $\\mathsf{MITL}$ with only\nlower- and upper-bound constraints) and $\\mathsf{EECL}$ (adding automata\nmodalities into $\\mathsf{ECL}$) are already as expressive as $\\mathsf{EMITL}$\n(full $\\mathsf{MITL}$ with automata modalities). In particular, the\nsatisfiability and model-checking problems for $\\mathsf{EMITL}_{0,\\infty}$ and\n$\\mathsf{EECL}$ are PSPACE-complete, whereas the same problems for\n$\\mathsf{EMITL}$ are EXPSPACE-complete. We also provide a simple translation\nfrom $\\mathsf{EMITL}_{0,\\infty}$ to diagonal-free timed automata, which enables\npractical satisfiability and model checking based on off-the-shelf tools.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 18:04:15 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Ho", "Hsi-Ming", ""]]}, {"id": "1812.10363", "submitter": "Seth Ahrenbach", "authors": "Seth Ahrenbach", "title": "Reasoning About Safety-Critical Information Flow Between Pilot and\n  Computer", "comments": "Published in the Proceedings from the 9th International Symposium of\n  NASA Formal Methods, 2017", "journal-ref": "In: Barrett C., Davies M., Kahsai T. (eds) NASA Formal Methods.\n  NFM 2017. Lecture Notes in Computer Science, vol 10227. Springer, Cham", "doi": "10.1007/978-3-319-57288-8_25.", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents research results that develop a dynamic logic for\nreasoning about safety-critical information flow among humans and computers.\nThe logic advances previous efforts to develop logics of agent knowledge, which\nmake assumptions that are too strong for realistic human agents. We introduce\nDynamic Agent Safety Logic (DASL), based on Dynamic Epistemic Logic (DEL), with\nextensions to account for safe actions, belief, and the logical relationships\namong knowledge, belief, and safe action. With this logic we can infer which\nsafety-critical information a pilot is missing when executing an unsafe action.\nWe apply the logic to the Air France 447 incident as a case study and provide a\nmechanization of the case study in the Coq proof assistant.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 16:24:50 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Ahrenbach", "Seth", ""]]}, {"id": "1812.10771", "submitter": "Leszek Ko{\\l}odziejczyk", "authors": "Leszek Aleksander Ko{\\l}odziejczyk and Neil Thapen", "title": "Approximate counting and NP search problems", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new class of NP search problems, those which can be proved total\nin the theory $\\mathrm{APC}_2$ of [Je\\v{r}\\'abek 2009]. This is an axiomatic\ntheory in bounded arithmetic which can formalize standard combinatorial\narguments based on approximate counting. In particular, the Ramsey and weak\npigeonhole search problems lie in the class. We give a purely computational\ncharacterization of this class and show that, relative to an oracle, it does\nnot contain the problem CPLS, a strengthening of PLS.\n  As CPLS is provably total in the theory $T^2_2$, this shows that\n$\\mathrm{APC}_2$ does not prove every $\\forall \\Sigma^b_1$ sentence which is\nprovable in bounded arithmetic. This answers the question posed in [Buss,\nKo{\\l}odziejczyk, Thapen 2014] and represents some progress in the programme of\nseparating the levels of the bounded arithmetic hierarchy by low-complexity\nsentences.\n  Our main technical tool is an extension of the \"fixing lemma\" from [Pudl\\'ak,\nThapen 2017], a form of switching lemma, which we use to show that a random\npartial oracle from a certain distribution will, with high probability,\ndetermine an entire computation of a $\\textrm{P}^{\\textrm{NP}}$ oracle machine.\nThe paper is intended to be accessible to someone unfamiliar with NP search\nproblems or with bounded arithmetic.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 17:03:43 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Ko\u0142odziejczyk", "Leszek Aleksander", ""], ["Thapen", "Neil", ""]]}, {"id": "1812.10799", "submitter": "Giulio Guerrieri", "authors": "Giulio Guerrieri (1) ((1) Dipartimento di Informatica -- Scienza e\n  Ingegneria (DISI), Universit\\`a di Bologna, Bologna, Italy)", "title": "Towards a Semantic Measure of the Execution Time in Call-by-Value\n  lambda-Calculus (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the possibility of a semantic account of the execution time\n(i.e. the number of \\beta_v-steps leading to the normal form, if any) for the\nshuffling calculus, an extension of Plotkin's call-by-value {\\lambda}-calculus.\nFor this purpose, we use a linear logic based denotational model that can be\nseen as a non-idempotent intersection type system: relational semantics. Our\ninvestigation is inspired by similar ones for linear logic proof-nets and\nuntyped call-by-name {\\lambda}-calculus. We first prove a qualitative result: a\n(possibly open) term is normalizable for weak reduction (which does not reduce\nunder abstractions) if and only if its interpretation is not empty. We then\nshow that the size of type derivations can be used to measure the execution\ntime. Finally, we show that, differently from the case of linear logic and\ncall-by-name {\\lambda}-calculus, the quantitative information enclosed in type\nderivations does not lift to types (i.e. to the interpretation of terms). To\nget a truly semantic measure of execution time in a call-by-value setting, we\nconjecture that a refinement of its syntax and operational semantics is needed.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 19:11:31 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Guerrieri", "Giulio", ""]]}, {"id": "1812.11003", "submitter": "Thomas Powell", "authors": "Thomas Powell", "title": "Sequential algorithms and the computational content of classical proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a correspondence between the theory of sequential algorithms and\nclassical reasoning, via Kreisel's no-counterexample interpretation. Our\nframework views realizers of the no-counterexample interpretation as dynamic\nprocesses which interact with an oracle, and allows these processes to be\nmodelled at any given level of abstraction. We discuss general constructions on\nalgorithms which represent specific patterns which often appear in classical\nreasoning, and in particular, we develop a computational interpretation of the\nrule of dependent choice which is phrased purely on the level of algorithms,\ngiving us a clearer insight into the computational meaning of proofs in\nclassical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 14:31:32 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Powell", "Thomas", ""]]}, {"id": "1812.11108", "submitter": "Abhishek Kr Singh", "authors": "Abhishek Kr Singh and Raja Natarajan", "title": "Towards a constructive formalization of Perfect Graph Theorems", "comments": "ICLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction between clique number $\\omega(G) $ and chromatic number $\\chi(G)\n$ of a graph is a well studied topic in graph theory. Perfect Graph Theorems\nare probably the most important results in this direction. Graph $G$ is called\n\\emph{perfect} if $\\chi(H)=\\omega(H)$ for every induced subgraph $H$ of $G$.\nThe Strong Perfect Graph Theorem (SPGT) states that a graph is perfect if and\nonly if it does not contain an odd hole (or an odd anti-hole) as its induced\nsubgraph. The Weak Perfect Graph Theorem (WPGT) states that a graph is perfect\nif and only if its complement is perfect. In this paper, we present a formal\nframework for verifying these results. We model finite simple graphs in the\nconstructive type theory of Coq Proof Assistant without adding any axiom to it.\nFinally, we use this framework to present a constructive proof of the\nLov\\'{a}sz Replication Lemma, which is the central idea in the proof of Weak\nPerfect Graph Theorem.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 16:46:37 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Singh", "Abhishek Kr", ""], ["Natarajan", "Raja", ""]]}, {"id": "1812.11573", "submitter": "Jean Goubault-Larrecq", "authors": "Jean Goubault-Larrecq", "title": "A Probabilistic and Non-Deterministic Call-by-Push-Value Language", "comments": "50 pages, revised following comments by reviewers at LICS'19 - long\n  version of the eponymous paper at LICS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is no known way of giving a domain-theoretic semantics to higher-order\nprobabilistic languages, in such a way that the involved domains are continuous\nor quasi-continuous - the latter is required to do any serious mathematics. We\nargue that the problem naturally disappears for languages with two kinds of\ntypes, where one kind is interpreted in a Cartesian-closed category of\ncontinuous dcpos, and the other is interpreted in a category that is closed\nunder the probabilistic powerdomain functor. Such a setting is provided by Paul\nB. Levy's call-by-push-value paradigm. Following this insight, we define a\ncall-by-push-value language, with probabilistic choice sitting inside the value\ntypes, and where conversion from a value type to a computation type involves\ndemonic non-determinism. We give both a domain-theoretic semantics and an\noperational semantics for the resulting language, and we show that they are\nsound and adequate. With the addition of statistical termination testers and\nparallel if, we show that the language is even fully abstract - and those two\nprimitives are required for that.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 17:21:04 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 18:11:52 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 15:47:15 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Goubault-Larrecq", "Jean", ""]]}, {"id": "1812.11664", "submitter": "EPTCS", "authors": "Oleg Kiselyov (Tohoku University, Japan), KC Sivaramakrishnan\n  (University of Cambridge, UK)", "title": "Eff Directly in OCaml", "comments": "In Proceedings ML/OCAML 2016, arXiv:1812.10891", "journal-ref": "EPTCS 285, 2018, pp. 23-58", "doi": "10.4204/EPTCS.285.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The language Eff is an OCaml-like language serving as a prototype\nimplementation of the theory of algebraic effects, intended for experimentation\nwith algebraic effects on a large scale.\n  We present the embedding of Eff into OCaml, using the library of delimited\ncontinuations or the multicore OCaml branch. We demonstrate the correctness of\nthe embedding denotationally, relying on the tagless-final-style\ninterpreter-based denotational semantics, including the novel, direct\ndenotational semantics of multi-prompt delimited control. The embedding is\nsystematic, lightweight, performant and supports even higher-order, 'dynamic'\neffects with their polymorphism. OCaml thus may be regarded as another\nimplementation of Eff, broadening the scope and appeal of that language.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 02:09:18 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Kiselyov", "Oleg", "", "Tohoku University, Japan"], ["Sivaramakrishnan", "KC", "", "University of Cambridge, UK"]]}, {"id": "1812.11741", "submitter": "Tim French Dr", "authors": "Tim French, Andrew Gozzard and Mark Reynolds", "title": "A modal aleatoric calculus for probabilistic reasoning: extended version", "comments": "Long version of paper accepted to appear at the 2019 Indian\n  Conference on Logic and Applictaions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-agent systems where agents actions and beliefs are\ndetermined aleatorically, or \"by the throw of dice\". This system consists of\npossible worlds that assign distributions to independent random variables, and\nagents who assign probabilities to these possible worlds. We present a novel\nsyntax and semantics for such system, and show that they generalise Modal\nLogic. We also give a sound and complete calculus for reasoning in the base\nsemantics, and a sound calculus for the full modal semantics, that we\nconjecture to be complete. Finally we discuss some application to reasoning\nabout game playing agents.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 09:53:28 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["French", "Tim", ""], ["Gozzard", "Andrew", ""], ["Reynolds", "Mark", ""]]}, {"id": "1812.11838", "submitter": "Adri\\'an Riesco", "authors": "Adri\\'an Riesco and Juan Rodr\\'iguez-Hortal\\'a", "title": "Property-based testing for Spark Streaming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream processing has reached the mainstream in the last years, as a new\ngeneration of open source distributed stream processing systems, designed for\nscaling horizontally on commodity hardware, has brought the capability for\nprocessing high volume and high velocity data streams to companies of all\nsizes. In this work we propose a combination of temporal logic and\nproperty-based testing (PBT) for dealing with the challenges of testing\nprograms that employ this programming model. We formalize our approach in a\ndiscrete time temporal logic for finite words, with some additions to improve\nthe expressiveness of properties, which includes timeouts for temporal\noperators and a binding operator for letters. In particular we focus on testing\nSpark Streaming programs written with the Spark API for the functional language\nScala, using the PBT library ScalaCheck. For that we add temporal logic\noperators to a set of new ScalaCheck generators and properties, as part of our\ntesting library sscheck. Under consideration in Theory and Practice of Logic\nProgramming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 15:10:50 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Riesco", "Adri\u00e1n", ""], ["Rodr\u00edguez-Hortal\u00e1", "Juan", ""]]}, {"id": "1812.11948", "submitter": "Matthias Nickles", "authors": "Matthias Nickles", "title": "Differentiable Satisfiability and Differentiable Answer Set Programming\n  for Sampling-Based Multi-Model Optimization", "comments": "Extended and revised version of a paper in the Proceedings of the 5th\n  International Workshop on Probabilistic Logic Programming (PLP2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Differentiable Satisfiability and Differentiable Answer Set\nProgramming (Differentiable SAT/ASP) for multi-model optimization. Models\n(answer sets or satisfying truth assignments) are sampled using a novel SAT/ASP\nsolving approach which uses a gradient descent-based branching mechanism.\nSampling proceeds until the value of a user-defined multi-model cost function\nreaches a given threshold. As major use cases for our approach we propose\ndistribution-aware model sampling and expressive yet scalable probabilistic\nlogic programming. As our main algorithmic approach to Differentiable SAT/ASP,\nwe introduce an enhancement of the state-of-the-art CDNL/CDCL algorithm for\nSAT/ASP solving. Additionally, we present alternative algorithms which use an\nunmodified ASP solver (Clingo/clasp) and map the optimization task to\nconventional answer set optimization or use so-called propagators. We also\nreport on the open source software DelSAT, a recent prototype implementation of\nour main algorithm, and on initial experimental results which indicate that\nDelSATs performance is, when applied to the use case of probabilistic logic\ninference, on par with Markov Logic Network (MLN) inference performance,\ndespite having advantageous properties compared to MLNs, such as the ability to\nexpress inductive definitions and to work with probabilities as weights\ndirectly in all cases. Our experiments also indicate that our main algorithm is\nstrongly superior in terms of performance compared to the presented alternative\napproaches which reduce a common instance of the general problem to regular\nSAT/ASP.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 18:39:58 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Nickles", "Matthias", ""]]}, {"id": "1812.11966", "submitter": "S{\\l}awomir Lasota", "authors": "S{\\l}awomir Lasota", "title": "VASS reachability in three steps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is a product of digestion of the famous proof of decidability of\nthe reachability problem for vector addition systems with states (VASS), as\nfirst established by Mayr in 1981 and then simplified by Kosaraju in 1982. The\nnote is neither intended to be rigorously formal nor complete; it is rather\nintended to be an intuitive but precise enough description of main concepts\nexploited in the proof. Very roughly, the overall idea is to provide a\ndecidable condition Theta on a VASS such that Theta implies reachability and\nits negation implies that the size of VASS can be reduced. With these two\nproperties, the size of input can be incrementally reduced until the problem\nbecomes trivial. We proceed in three steps: we first formulate the condition\nTheta for plain VASS, then adapt it to more general VASS with unconstrained\ncoordinates, and finally to generalized VASS of Kosaraju.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 20:03:59 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 19:44:56 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 11:27:42 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Lasota", "S\u0142awomir", ""]]}, {"id": "1812.11969", "submitter": "Dmitry Maximov", "authors": "Dmitry Maximov", "title": "Game Semantics and Linear Logic in the Cognition Process", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.02216; a\n  comment is added to the second version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A description of the environment cognition process by intelligent systems\nwith a fixed set of system goals is suggested. Such a system is represented by\nthe set of its goals only without any models of the system elements or the\nenvironment. The set has a lattice structure and a monoid structure; thus, the\nstructure of linear logic is defined on the set. The cognition process of some\nenvironment by the system is described on this basis. The environment is\nrepresented as a configuration space of possible system positions which are\nestimated by an information amount (by corresponding sets). This information is\nsupplied to the system by the environment. Thus, it is possible to define the\ncategory of Conway games with a payoff on the configuration space and to choose\nan optimal system's play (i.e., a trajectory). The choice is determined by the\nrequirement of maximal information increasing and takes into account the\nstructure of the system goal set: the linear logic on the set is used to\ndetermine the priority of possible different parallel processes. The survey may\nbe useful to describe the behavior of robots and simple biological systems,\ne.g., ants.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 08:14:25 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 16:41:09 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Maximov", "Dmitry", ""]]}]