[{"id": "1003.0107", "submitter": "Martin Churchill", "authors": "Martin Churchill, James Laird and Guy McCusker", "title": "A Concrete Representation of Observational Equivalence for PCF", "comments": "A result on observational equivalence for PCF and innocent\n  strategies, as presented at the Games for Logic and Programming Languages\n  (GaLoP) workshop in York, March 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The full abstraction result for PCF using game semantics requires one to\nidentify all innocent strategies that are innocently indistinguishable. This\ninvolves a quantification over all innocent tests, cf. quantification over all\ninnocent contexts. Here we present a representation of innocent strategies that\nequates innocently indistinguishable ones, yielding a representation of PCF\nterms that equates precisely those terms that are observational equivalent.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2010 16:27:58 GMT"}], "update_date": "2010-03-02", "authors_parsed": [["Churchill", "Martin", ""], ["Laird", "James", ""], ["McCusker", "Guy", ""]]}, {"id": "1003.0381", "submitter": "Gopinadh Sirigineedi", "authors": "Gopinadh Sirigineedi, Antonios Tsourdos, Brian A. White, Rafal\n  Zbikowski", "title": "Modelling and Verification of Multiple UAV Mission Using SMV", "comments": null, "journal-ref": "EPTCS 20, 2010, pp. 22-33", "doi": "10.4204/EPTCS.20.3", "report-no": null, "categories": "cs.LO cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking has been used to verify the correctness of digital circuits,\nsecurity protocols, communication protocols, as they can be modelled by means\nof finite state transition model. However, modelling the behaviour of hybrid\nsystems like UAVs in a Kripke model is challenging. This work is aimed at\ncapturing the behaviour of an UAV performing cooperative search mission into a\nKripke model, so as to verify it against the temporal properties expressed in\nComputation Tree Logic (CTL). SMV model checker is used for the purpose of\nmodel checking.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 15:50:18 GMT"}], "update_date": "2010-04-01", "authors_parsed": [["Sirigineedi", "Gopinadh", ""], ["Tsourdos", "Antonios", ""], ["White", "Brian A.", ""], ["Zbikowski", "Rafal", ""]]}, {"id": "1003.0404", "submitter": "Uwe Aickelin", "authors": "Feng Gu, Julie Greensmith, Uwe Aickelin", "title": "Exploration Of The Dendritic Cell Algorithm Using The Duration Calculus", "comments": "13 pages, 2 figures, 8th International Conference on Artificial\n  Immune Systems (ICARIS 2009), Lecture Notes in Computer Science 5666, York,\n  UK", "journal-ref": "Proceedings of 8th International Conference on Artificial Immune\n  Systems (ICARIS 2009), Lecture Notes in Computer Science 5666, York, UK", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the newest members in Artificial Immune Systems (AIS), the\nDendritic Cell Algorithm (DCA) has been applied to a range of problems. These\napplications mainly belong to the field of anomaly detection. However,\nreal-time detection, a new challenge to anomaly detection, requires improvement\non the real-time capability of the DCA. To assess such capability, formal\nmethods in the research of rea-time systems can be employed. The findings of\nthe assessment can provide guideline for the future development of the\nalgorithm. Therefore, in this paper we use an interval logic based method,\nnamed the Duration Calculus (DC), to specify a simplified single-cell model of\nthe DCA. Based on the DC specifications with further induction, we find that\neach individual cell in the DCA can perform its function as a detector in\nreal-time. Since the DCA can be seen as many such cells operating in parallel,\nit is potentially capable of performing real-time detection. However, the\nanalysis process of the standard DCA constricts its real-time capability. As a\nresult, we conclude that the analysis process of the standard DCA should be\nreplaced by a real-time analysis component, which can perform periodic analysis\nfor the purpose of real-time detection.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 16:57:54 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Gu", "Feng", ""], ["Greensmith", "Julie", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1003.0425", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "A logical basis for constructive systems", "comments": null, "journal-ref": "Journal of Logic and Computation 22 (2012), pp. 605-642", "doi": "10.1093/logcom/exr009", "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work is devoted to Computability Logic (CoL) -- the\nphilosophical/mathematical platform and long-term project for redeveloping\nclassical logic after replacing truth} by computability in its underlying\nsemantics (see http://www.cis.upenn.edu/~giorgi/cl.html). This article\nelaborates some basic complexity theory for the CoL framework. Then it proves\nsoundness and completeness for the deductive system CL12 with respect to the\nsemantics of CoL, including the version of the latter based on polynomial time\ncomputability instead of computability-in-principle. CL12 is a sequent calculus\nsystem, where the meaning of a sequent intuitively can be characterized as \"the\nsuccedent is algorithmically reducible to the antecedent\", and where formulas\nare built from predicate letters, function letters, variables, constants,\nidentity, negation, parallel and choice connectives, and blind and choice\nquantifiers. A case is made that CL12 is an adequate logical basis for\nconstructive applied theories, including complexity-oriented ones.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 19:00:10 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2010 19:15:47 GMT"}, {"version": "v3", "created": "Mon, 14 Mar 2011 19:10:31 GMT"}], "update_date": "2012-08-03", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "1003.0431", "submitter": "Piotr Kordy", "authors": "Piotr Kordy, Rom Langerak and Jan Willem Polderman", "title": "Re-verification of a Lip Synchronization Protocol using Robust\n  Reachability", "comments": null, "journal-ref": "EPTCS 20, 2010, pp. 49-62", "doi": "10.4204/EPTCS.20.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The timed automata formalism is an important model for specifying and\nanalysing real-time systems. Robustness is the correctness of the model in the\npresence of small drifts on clocks or imprecision in testing guards. A symbolic\nalgorithm for the analysis of the robustness of timed automata has been\nimplemented. In this paper, we re-analyse an industrial case lip\nsynchronization protocol using the new robust reachability algorithm. This lip\nsynchronization protocol is an interesting case because timing aspects are\ncrucial for the correctness of the protocol. Several versions of the model are\nconsidered: with an ideal video stream, with anchored jitter, and with\nnon-anchored jitter.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 19:53:00 GMT"}], "update_date": "2010-04-01", "authors_parsed": [["Kordy", "Piotr", ""], ["Langerak", "Rom", ""], ["Polderman", "Jan Willem", ""]]}, {"id": "1003.0480", "submitter": "Nicolas Brener", "authors": "Nicolas Brener", "title": "A definable number which cannot be approximated algorithmically", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Turing machine (TM) and the Church thesis have formalized the concept of\ncomputable number, this allowed to display non-computable numbers. This paper\ndefines the concept of number \"approachable\" by a TM and shows that some (if\nnot all) known non-computable numbers are approachable by TMs. Then an example\nof a number not approachable by a TM is given.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2010 23:11:22 GMT"}], "update_date": "2010-03-03", "authors_parsed": [["Brener", "Nicolas", ""]]}, {"id": "1003.0773", "submitter": "Aleksandar Kupusinac MSc", "authors": "Aleksandar Kupusinac and Dusan Malbaski", "title": "S-Program Calculus", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a special subset of the first-order predicate logic named\nS-program calculus (briefly S-calculus). The S-calculus is a calculus\nconsisting of so-called S-formulas that are defined over the abstract state\nspace of a virtual machine. We show that S-formulas are a highly general tool\nfor analyzing program semantics inasmuch as Hoare triplets of total and partial\ncorrectness are not more than two S-formulas. Moreover, all the rules of Hoare\nlogic can be derived using S-formulas and axioms/theorems of first-order\npredicate calculus. The S-calculus is a powerful mechanism for proving program\ncorrectness as well as for building additional proving tools using theorems of\nthe predicate logic. Every proof is based on deriving the validity of some\nS-formula, so the procedure may be automated using automatic theorem provers\n(we will use Coq in this paper). As an example of the use of S-calculus, we\nwill prove the four basic properties of Dijsktra's operator wp. The proofs\ngiven by Dijkstra are not completely formalized and we will show that a full\nformalization can be achieved using S-calculus. Finally, we add one more\ntheorem to the above-mentioned four, namely the law of negation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2010 10:36:52 GMT"}], "update_date": "2010-03-04", "authors_parsed": [["Kupusinac", "Aleksandar", ""], ["Malbaski", "Dusan", ""]]}, {"id": "1003.0788", "submitter": "Chenyi  Zhang", "authors": "Chenyi Zhang and Jun Pang", "title": "On Probabilistic Alternating Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents simulation-based relations for probabilistic game\nstructures. The first relation is called probabilistic alternating simulation,\nand the second called probabilistic alternating forward simulation, following\nthe naming convention of Segala and Lynch. We study these relations with\nrespect to the preservation of properties specified in probabilistic\nalternating-time temporal logic.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2010 12:01:49 GMT"}], "update_date": "2010-03-04", "authors_parsed": [["Zhang", "Chenyi", ""], ["Pang", "Jun", ""]]}, {"id": "1003.0802", "submitter": "Barnaby Martin", "authors": "Florent Madelaine and Barnaby Martin", "title": "The complexity of positive first-order logic without equality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of evaluating positive equality-free sentences of\nfirst-order (FO) logic over a fixed, finite structure B. This may be seen as a\nnatural generalisation of the non-uniform quantified constraint satisfaction\nproblem QCSP(B). We introduce surjective hyper-endomorphisms and use them in\nproving a Galois connection that characterises definability in positive\nequality-free FO. Through an algebraic method, we derive a complete complexity\nclassification for our problems as B ranges over structures of size at most\nthree. Specifically, each problem is either in Logspace, is NP-complete, is\nco-NP-complete or is Pspace-complete.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2010 13:35:58 GMT"}], "update_date": "2010-03-04", "authors_parsed": [["Madelaine", "Florent", ""], ["Martin", "Barnaby", ""]]}, {"id": "1003.1057", "submitter": "Joerg Endrullis", "authors": "Joerg Endrullis", "title": "Levels of Undecidability in Infinitary Rewriting: Normalization and\n  Reachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [EGZ09] it has been shown that infinitary strong normalization (SNi) is\nPi-1-1-complete. Suprisingly, it turns out that infinitary weak normalization\n(WNi) is a harder problem, being Pi-1-2-complete, and thereby strictly higher\nin the analytical hierarchy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 14:45:42 GMT"}], "update_date": "2010-03-05", "authors_parsed": [["Endrullis", "Joerg", ""]]}, {"id": "1003.1160", "submitter": "Lunjin Lu", "authors": "Lunjin Lu and Dae-kyoo Kim", "title": "Required Behavior of Sequence Diagrams: Semantics and Conformance", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence diagrams are a widely used design notation for describing software\nbehaviors. Many reusable software artifacts such as design patterns and design\naspects make use of sequence diagrams to describe interaction behaviors. When a\npattern or an aspect is reused in an application, it is important to ensure\nthat the sequence diagrams for the application conform to the corresponding\nsequence diagrams for the pattern or aspect. Reasoning about conformance\nrelationship between sequence diagrams has not been addressed adequately in\nliterature. In this paper, we focus on required behavior specified by a UML\nsequence diagram. A novel trace semantics is given that captures precisely\nrequired behavior specified by a sequence diagram and a conformance relation\nbetween sequence diagrams is formalized based on the semantics. Properties of\nthe trace semantics and the conformance relation are studied.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 23:19:01 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2010 23:27:36 GMT"}, {"version": "v3", "created": "Thu, 19 Aug 2010 19:57:28 GMT"}, {"version": "v4", "created": "Tue, 14 Dec 2010 21:10:27 GMT"}, {"version": "v5", "created": "Thu, 21 Jul 2011 12:30:54 GMT"}], "update_date": "2011-07-22", "authors_parsed": [["Lu", "Lunjin", ""], ["Kim", "Dae-kyoo", ""]]}, {"id": "1003.1632", "submitter": "Adri\\`a Gasc\\'on", "authors": "Adri\\`a Gasc\\'on, Guillem Godoy, Manfred Schmidt-Schau{\\ss}", "title": "Unification and Matching on Compressed Terms", "comments": "This paper is posted at the Computing Research Repository (CoRR) as\n  part of the process of submission to the journal ACM Transactions on\n  Computational Logic (TOCL).", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Term unification plays an important role in many areas of computer science,\nespecially in those related to logic. The universal mechanism of grammar-based\ncompression for terms, in particular the so-called Singleton Tree Grammars\n(STG), have recently drawn considerable attention. Using STGs, terms of\nexponential size and height can be represented in linear space. Furthermore,\nthe term representation by directed acyclic graphs (dags) can be efficiently\nsimulated. The present paper is the result of an investigation on term\nunification and matching when the terms given as input are represented using\ndifferent compression mechanisms for terms such as dags and Singleton Tree\nGrammars. We describe a polynomial time algorithm for context matching with\ndags, when the number of different context variables is fixed for the problem.\nFor the same problem, NP-completeness is obtained when the terms are\nrepresented using the more general formalism of Singleton Tree Grammars. For\nfirst-order unification and matching polynomial time algorithms are presented,\neach of them improving previous results for those problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2010 14:12:51 GMT"}], "update_date": "2010-03-13", "authors_parsed": [["Gasc\u00f3n", "Adri\u00e0", ""], ["Godoy", "Guillem", ""], ["Schmidt-Schau\u00df", "Manfred", ""]]}, {"id": "1003.1684", "submitter": "R\\\"udiger Ehlers", "authors": "Ruediger Ehlers", "title": "Generalised Rabin(1) synthesis", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for the synthesis of finite state systems that is a\ngeneralisation of the generalised reactivity(1) synthesis approach by Piterman,\nPnueli and Sa'ar. In particular, we describe an efficient method to synthesize\nsystems from linear-time temporal logic specifications for which all\nassumptions and guarantees have a Rabin index of one. We show how to build a\nparity game with at most five colours that captures all solutions to the\nsynthesis problem from such a specification. This parity game has a structure\nthat is amenable to symbolic implementations. We furthermore show that the\nresults obtained are in some sense tight, i.e., that there does not exist a\nsimilar synthesis method for assumptions and specifications of higher Rabin\nindex, unless P=NP.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2010 17:36:02 GMT"}, {"version": "v2", "created": "Wed, 22 Dec 2010 23:00:11 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Ehlers", "Ruediger", ""]]}, {"id": "1003.2586", "submitter": "Francesca A. Lisi", "authors": "Francesca A. Lisi", "title": "Inductive Logic Programming in Databases: from Datalog to DL+log", "comments": "30 pages, 3 figures, 2 tables.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address an issue that has been brought to the attention of\nthe database community with the advent of the Semantic Web, i.e. the issue of\nhow ontologies (and semantics conveyed by them) can help solving typical\ndatabase problems, through a better understanding of KR aspects related to\ndatabases. In particular, we investigate this issue from the ILP perspective by\nconsidering two database problems, (i) the definition of views and (ii) the\ndefinition of constraints, for a database whose schema is represented also by\nmeans of an ontology. Both can be reformulated as ILP problems and can benefit\nfrom the expressive and deductive power of the KR framework DL+log. We\nillustrate the application scenarios by means of examples. Keywords: Inductive\nLogic Programming, Relational Databases, Ontologies, Description Logics, Hybrid\nKnowledge Representation and Reasoning Systems. Note: To appear in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2010 17:40:43 GMT"}], "update_date": "2010-03-15", "authors_parsed": [["Lisi", "Francesca A.", ""]]}, {"id": "1003.2700", "submitter": "Agnieszka Lawrynowicz", "authors": "Joanna Jozefowska, Agnieszka Lawrynowicz, Tomasz Lukaszewski", "title": "The role of semantics in mining frequent patterns from knowledge bases\n  in description logics with rules", "comments": "40 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": "RA-01/09", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for mining frequent patterns in a language that\ncombines both Semantic Web ontologies and rules. In particular we consider the\nsetting of using a language that combines description logics with DL-safe\nrules. This setting is important for the practical application of data mining\nto the Semantic Web. We focus on the relation of the semantics of the\nrepresentation formalism to the task of frequent pattern discovery, and for the\ncore of our method, we propose an algorithm that exploits the semantics of the\ncombined knowledge base. We have developed a proof-of-concept data mining\nimplementation of this. Using this we have empirically shown that using the\ncombined knowledge base to perform semantic tests can make data mining faster\nby pruning useless candidate patterns before their evaluation. We have also\nshown that the quality of the set of patterns produced may be improved: the\npatterns are more compact, and there are fewer patterns. We conclude that\nexploiting the semantics of a chosen representation formalism is key to the\ndesign and application of (onto-)relational frequent pattern discovery methods.\nNote: To appear in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2010 12:47:46 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2010 18:20:40 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Jozefowska", "Joanna", ""], ["Lawrynowicz", "Agnieszka", ""], ["Lukaszewski", "Tomasz", ""]]}, {"id": "1003.2790", "submitter": "Lorenz Demey", "authors": "Lorenz Demey", "title": "Some Remarks on the Model Theory of Epistemic Plausibility Models", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": "10.3166/jancl.21.375-395", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical logics of knowledge and belief are usually interpreted on Kripke\nmodels, for which a mathematically well-developed model theory is available.\nHowever, such models are inadequate to capture dynamic phenomena. Therefore,\nepistemic plausibility models have been introduced. Because these are much\nricher structures than Kripke models, they do not straightforwardly inherit the\nmodel-theoretical results of modal logic. Therefore, while epistemic\nplausibility structures are well-suited for modeling purposes, an extensive\ninvestigation of their model theory has been lacking so far. The aim of the\npresent paper is to fill exactly this gap, by initiating a systematic\nexploration of the model theory of epistemic plausibility models. Like in\n'ordinary' modal logic, the focus will be on the notion of bisimulation. We\ndefine various notions of bisimulations (parametrized by a language L) and show\nthat L-bisimilarity implies L-equivalence. We prove a Hennesy-Milner type\nresult, and also two undefinability results. However, our main point is a\nnegative one, viz. that bisimulations cannot straightforwardly be generalized\nto epistemic plausibility models if conditional belief is taken into account.\nWe present two ways of coping with this issue: (i) adding a modality to the\nlanguage, and (ii) putting extra constraints on the models. Finally, we make\nsome remarks about the interaction between bisimulation and dynamic model\nchanges.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2010 15:18:09 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Demey", "Lorenz", ""]]}, {"id": "1003.2801", "submitter": "Andrei Romashchenko", "authors": "Bruno Durand and Andrei Romashchenko and Alexander Shen", "title": "Fixed point theorem and aperiodic tilings", "comments": "8 pages, 5 figures", "journal-ref": "Published in Bulletin of the EATCS (The Logic in Computer Science\n  Column by Yuri Gurevich) no. 97 (2009) pp. 126-136:\n  http://www.eatcs.org/images/bulletin/beatcs97.pdf", "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new simple construction of an aperiodic tile set based on\nself-referential (fixed point) argument. People often say about some discovery\nthat it appeared \"ahead of time\", meaning that it could be fully understood\nonly in the context of ideas developed later. For the topic of this note, the\nconstruction of an aperiodic tile set based on the fixed-point\n(self-referential) approach, the situation is exactly the opposite. It should\nhave been found in 1960s when the question about aperiodic tile sets was first\nasked: all the tools were quite standard and widely used at that time. However,\nthe history had chosen a different path and many nice geometric ad hoc\nconstructions were developed instead (by Berger, Robinson, Penrose, Ammann and\nmany others. In this note we try to correct this error and present a\nconstruction that should have been discovered first but seemed to be unnoticed\nfor more that forty years.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2010 17:29:55 GMT"}], "update_date": "2010-03-16", "authors_parsed": [["Durand", "Bruno", ""], ["Romashchenko", "Andrei", ""], ["Shen", "Alexander", ""]]}, {"id": "1003.3103", "submitter": "Andrei Romashchenko", "authors": "Bruno Durand and Andrei Romashchenko and Alexander Shen", "title": "Effective closed subshifts in 1D can be implemented in 2D", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use fixed point tilings to answer a question posed by\nMichael Hochman and show that every one-dimensional effectively closed subshift\ncan be implemented by a local rule in two dimensions. The proof uses the\nfixed-point construction of an aperiodic tile set and its extensions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2010 08:48:37 GMT"}], "update_date": "2010-03-17", "authors_parsed": [["Durand", "Bruno", ""], ["Romashchenko", "Andrei", ""], ["Shen", "Alexander", ""]]}, {"id": "1003.3139", "submitter": "Andrea Cal\\`i", "authors": "Andrea Cali and Davide Martinenghi", "title": "Querying Incomplete Data over Extended ER Schemata", "comments": "40 pages, 1 figure.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Chen's Entity-Relationship (ER) model, conceptual modeling has been\nplaying a fundamental role in relational data design. In this paper we consider\nan extended ER (EER) model enriched with cardinality constraints, disjointness\nassertions, and is-a relations among both entities and relationships. In this\nsetting, we consider the case of incomplete data, which is likely to occur, for\ninstance, when data from different sources are integrated. In such a context,\nwe address the problem of providing correct answers to conjunctive queries by\nreasoning on the schema. Based on previous results about decidability of the\nproblem, we provide a query answering algorithm that performs rewriting of the\ninitial query into a recursive Datalog query encoding the information about the\nschema. We finally show extensions to more general settings. This paper will\nappear in the special issue of Theory and Practice of Logic Programming (TPLP)\ntitled Logic Programming in Databases: From Datalog to Semantic-Web Rules.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2010 12:55:21 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2010 19:37:01 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Cali", "Andrea", ""], ["Martinenghi", "Davide", ""]]}, {"id": "1003.3629", "submitter": "Massimo Franceschet", "authors": "Massimo Franceschet", "title": "A logic for networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are pervasive in the real world. Nature, society, economy, and\ntechnology are supported by ostensibly different networks that in fact share an\namazing number of interesting structural properties. Network thinking exploded\nin the last decade, boosted by the availability of large databases on the\ntopology of various real networks, mainly the Web and biological networks, and\nconverged to the new discipline of network analysis - the holistic analysis of\ncomplex systems through the study of the network that wires their components.\nPhysicists mainly drove the investigation, studying the structure and function\nof networks using methods and tools of statistical mechanics. Here, we give an\nalternative perspective on network analysis, proposing a logic for specifying\ngeneral properties of networks and a modular algorithm for checking these\nproperties. The logic borrows from two intertwined computing fields: XML\ndatabases and model checking.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 16:49:31 GMT"}], "update_date": "2010-03-19", "authors_parsed": [["Franceschet", "Massimo", ""]]}, {"id": "1003.3649", "submitter": "Aaron Bradley", "authors": "Aaron R. Bradley", "title": "k-Step Relative Inductive Generalization", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new form of SAT-based symbolic model checking. One common idea\nin SAT-based symbolic model checking is to generate new clauses from states\nthat can lead to property violations. Our previous work suggests applying\ninduction to generalize from such states. While effective on some benchmarks,\nthe main problem with inductive generalization is that not all such states can\nbe inductively generalized at a given time in the analysis, resulting in long\nsearches for generalizable states on some benchmarks. This paper introduces the\nidea of inductively generalizing states relative to $k$-step\nover-approximations: a given state is inductively generalized relative to the\nlatest $k$-step over-approximation relative to which the negation of the state\nis itself inductive. This idea motivates an algorithm that inductively\ngeneralizes a given state at the highest level $k$ so far examined, possibly by\ngenerating more than one mutually $k$-step relative inductive clause. We\npresent experimental evidence that the algorithm is effective in practice.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 18:39:30 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Bradley", "Aaron R.", ""]]}, {"id": "1003.3830", "submitter": "Lucas Cordeiro Carvalho", "authors": "Lucas Cordeiro and Bernd Fischer", "title": "Bounded Model Checking of Multi-threaded Software using SMT solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transition from single-core to multi-core processors has made\nmulti-threaded software an important subject in computer aided verification.\nHere, we describe and evaluate an extension of the ESBMC model checker to\nsupport the verification of multi-threaded software with shared variables and\nlocks using bounded model checking (BMC) based on Satisfiability Modulo\nTheories (SMT). We describe three approaches to model check multi-threaded\nsoftware and our modelling of the synchronization primitives of the Pthread\nlibrary. In the lazy approach, we generate all possible interleavings and call\nthe BMC procedure on each of them individually, until we either find a bug, or\nhave systematically explored all interleavings. In the schedule recording\napproach, we encode all possible interleavings into one single formula and then\nexploit the high speed of the SMT solvers. In the underapproximation-widening\napproach, we reduce the state space by abstracting the number of state\nvariables and interleavings from the proofs of unsatisfiability generated by\nthe SMT solvers. In all three approaches, we use partial-order reduction (POR)\ntechniques to reduce the number of interleavings explored. Experiments show\nthat our approaches can analyze larger problems and substantially reduce the\nverification time compared to state-of-the-art techniques that combine classic\nPOR methods with symbolic algorithms and others that implement the\nCounter-Example Guided Abstraction Refinement technique.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2010 16:23:11 GMT"}], "update_date": "2010-03-22", "authors_parsed": [["Cordeiro", "Lucas", ""], ["Fischer", "Bernd", ""]]}, {"id": "1003.4090", "submitter": "Rodrigo Machado", "authors": "Rodrigo Machado (Universidade Federal do Rio Grande do Sul), Reiko\n  Heckel (University of Leicester), Leila Ribeiro (Universidade Federal do Rio\n  Grande do Sul)", "title": "Modeling and Reasoning over Distributed Systems using Aspect-Oriented\n  Graph Grammars", "comments": null, "journal-ref": "EPTCS 21, 2010, pp. 39-50", "doi": "10.4204/EPTCS.21.4", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-orientation is a relatively new paradigm that introduces abstractions\nto modularize the implementation of system-wide policies. It is based on a\ncomposition operation, called aspect weaving, that implicitly modifies a base\nsystem by performing related changes within the system modules. Aspect-oriented\ngraph grammars (AOGG) extend the classic graph grammar formalism by defining\naspects as sets of rule-based modifications over a base graph grammar. Despite\nthe advantages of aspect-oriented concepts regarding modularity, the implicit\nnature of the aspect weaving operation may also introduce issues when reasoning\nabout the system behavior. Since in AOGGs aspect weaving is characterized by\nmeans of rule-based rewriting, we can overcome these problems by using known\nanalysis techniques from the graph transformation literature to study aspect\ncomposition. In this paper, we present a case study of a distributed\nclient-server system with global policies, modeled as an aspect-oriented graph\ngrammar, and discuss how to use the AGG tool to identify potential conflicts in\naspect weaving.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 07:18:30 GMT"}], "update_date": "2010-04-01", "authors_parsed": [["Machado", "Rodrigo", "", "Universidade Federal do Rio Grande do Sul"], ["Heckel", "Reiko", "", "University of Leicester"], ["Ribeiro", "Leila", "", "Universidade Federal do Rio\n  Grande do Sul"]]}, {"id": "1003.4326", "submitter": "Maribel Fern\\'andez", "authors": "Maribel Fern\\'andez, Olivier Namet (King's College London)", "title": "Graph Creation, Visualisation and Transformation", "comments": null, "journal-ref": "EPTCS 21, 2010, pp. 1-11", "doi": "10.4204/EPTCS.21.1", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a tool to create, edit, visualise and compute with interaction\nnets - a form of graph rewriting systems. The editor, called GraphPaper, allows\nusers to create and edit graphs and their transformation rules using an\nintuitive user interface. The editor uses the functionalities of the TULIP\nsystem, which gives us access to a wealth of visualisation algorithms.\nInteraction nets are not only a formalism for the specification of graphs, but\nalso a rewrite-based computation model. We discuss graph rewriting strategies\nand a language to express them in order to perform strategic interaction net\nrewriting.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2010 02:20:44 GMT"}], "update_date": "2010-03-24", "authors_parsed": [["Fern\u00e1ndez", "Maribel", "", "King's College London"], ["Namet", "Olivier", "", "King's College London"]]}, {"id": "1003.4369", "submitter": "Rachid Echahed", "authors": "Ph. Balbiani, R. Echahed, A. Herzig", "title": "A Modal Logic for Termgraph Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modal logic tailored to describe graph transformations and\ndiscuss some of its properties. We focus on a particular class of graphs called\ntermgraphs. They are first-order terms augmented with sharing and cycles.\nTermgraphs allow one to describe classical data-structures (possibly with\npointers) such as doubly-linked lists, circular lists etc. We show how the\nproposed logic can faithfully describe (i) termgraphs as well as (ii) the\napplication of a termgraph rewrite rule (i.e. matching and replacement) and\n(iii) the computation of normal forms with respect to a given rewrite system.\nWe also show how the proposed logic, which is more expressive than\npropositional dynamic logic, can be used to specify shapes of classical\ndata-structures (e.g. binary trees, circular lists etc.).\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2010 10:34:14 GMT"}], "update_date": "2010-03-24", "authors_parsed": [["Balbiani", "Ph.", ""], ["Echahed", "R.", ""], ["Herzig", "A.", ""]]}, {"id": "1003.4394", "submitter": "Mehrnoosh Sadrzadeh", "authors": "Bob Coecke, Mehrnoosh Sadrzadeh, Stephen Clark", "title": "Mathematical Foundations for a Compositional Distributional Model of\n  Meaning", "comments": "to appear", "journal-ref": "Lambek Festschirft, special issue of Linguistic Analysis, 2010.", "doi": null, "report-no": null, "categories": "cs.CL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a mathematical framework for a unification of the distributional\ntheory of meaning in terms of vector space models, and a compositional theory\nfor grammatical types, for which we rely on the algebra of Pregroups,\nintroduced by Lambek. This mathematical framework enables us to compute the\nmeaning of a well-typed sentence from the meanings of its constituents.\nConcretely, the type reductions of Pregroups are `lifted' to morphisms in a\ncategory, a procedure that transforms meanings of constituents into a meaning\nof the (well-typed) whole. Importantly, meanings of whole sentences live in a\nsingle space, independent of the grammatical structure of the sentence. Hence\nthe inner-product can be used to compare meanings of arbitrary sentences, as it\nis for comparing the meanings of words in the distributional model. The\nmathematical structure we employ admits a purely diagrammatic calculus which\nexposes how the information flows between the words in a sentence in order to\nmake up the meaning of the whole sentence. A variation of our `categorical\nmodel' which involves constraining the scalars of the vector spaces to the\nsemiring of Booleans results in a Montague-style Boolean-valued semantics.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2010 12:32:01 GMT"}], "update_date": "2010-03-24", "authors_parsed": [["Coecke", "Bob", ""], ["Sadrzadeh", "Mehrnoosh", ""], ["Clark", "Stephen", ""]]}, {"id": "1003.4552", "submitter": "Bart Jacobs", "authors": "Bart Jacobs", "title": "Involutive Categories and Monoids, with a GNS-correspondence", "comments": null, "journal-ref": null, "doi": "10.1007/s10701-011-9595-7", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops the basics of the theory of involutive categories and\nshows that such categories provide the natural setting in which to describe\ninvolutive monoids. It is shown how categories of Eilenberg-Moore algebras of\ninvolutive monads are involutive, with conjugation for modules and vector\nspaces as special case. The core of the so-called Gelfand-Naimark-Segal (GNS)\nconstruction is identified as a bijective correspondence between states on\ninvolutive monoids and inner products. This correspondence exists in arbritrary\ninvolutive categories.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2010 23:04:47 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Jacobs", "Bart", ""]]}, {"id": "1003.4562", "submitter": "Abubakar Hassan", "authors": "Abubakar Hassan (University of Sussex), Eugen Jiresch (Vienna\n  University of Technology), Shinya Sato (Himeji Dokkyo University)", "title": "An Implementation of Nested Pattern Matching in Interaction Nets", "comments": null, "journal-ref": "EPTCS 21, 2010, pp. 13-25", "doi": "10.4204/EPTCS.21.2", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduction rules in interaction nets are constrained to pattern match exactly\none argument at a time. Consequently, a programmer has to introduce auxiliary\nrules to perform more sophisticated matches. In this paper, we describe the\ndesign and implementation of a system for interaction nets which allows nested\npattern matching on interaction rules. We achieve a system that provides\nconvenient ways to express interaction net programs without defining auxiliary\nrules.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2010 00:52:58 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["Hassan", "Abubakar", "", "University of Sussex"], ["Jiresch", "Eugen", "", "Vienna\n  University of Technology"], ["Sato", "Shinya", "", "Himeji Dokkyo University"]]}, {"id": "1003.4563", "submitter": "Detlef Plump", "authors": "Detlef Plump (The University of York), Sandra Steinert (The University\n  of York)", "title": "The Semantics of Graph Programs", "comments": null, "journal-ref": "EPTCS 21, 2010, pp. 27-38", "doi": "10.4204/EPTCS.21.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GP (for Graph Programs) is a rule-based, nondeterministic programming\nlanguage for solving graph problems at a high level of abstraction, freeing\nprogrammers from handling low-level data structures. The core of GP consists of\nfour constructs: single-step application of a set of conditional\ngraph-transformation rules, sequential composition, branching and iteration. We\npresent a formal semantics for GP in the style of structural operational\nsemantics. A special feature of our semantics is the use of finitely failing\nprograms to define GP's powerful branching and iteration commands.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2010 00:54:29 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["Plump", "Detlef", "", "The University of York"], ["Steinert", "Sandra", "", "The University\n  of York"]]}, {"id": "1003.4719", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "Introduction to clarithmetic I", "comments": null, "journal-ref": "Information and Computation 209 (2011), pp. 1312-1354", "doi": "10.1016/j.ic.2011.07.002", "report-no": null, "categories": "cs.LO cs.CC math.LO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Clarithmetic\" is a generic name for formal number theories similar to Peano\narithmetic, but based on computability logic (see\nhttp://www.cis.upenn.edu/~giorgi/cl.html) instead of the more traditional\nclassical or intuitionistic logics. Formulas of clarithmetical theories\nrepresent interactive computational problems, and their \"truth\" is understood\nas existence of an algorithmic solution. Imposing various complexity\nconstraints on such solutions yields various versions of clarithmetic. The\npresent paper introduces a system of clarithmetic for polynomial time\ncomputability, which is shown to be sound and complete. Sound in the sense that\nevery theorem T of the system represents an interactive number-theoretic\ncomputational problem with a polynomial time solution and, furthermore, such a\nsolution can be efficiently extracted from a proof of T. And complete in the\nsense that every interactive number-theoretic problem with a polynomial time\nsolution is represented by some theorem T of the system. The paper is written\nin a semitutorial style and targets readers with no prior familiarity with\ncomputability logic.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2010 19:33:44 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2010 06:29:45 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2010 15:45:55 GMT"}, {"version": "v4", "created": "Tue, 12 Jul 2011 13:58:06 GMT"}, {"version": "v5", "created": "Sun, 24 Jul 2011 11:50:45 GMT"}, {"version": "v6", "created": "Tue, 23 Aug 2011 12:10:10 GMT"}], "update_date": "2011-08-24", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "1003.4799", "submitter": "Claude Kirchner", "authors": "Claude Kirchner, Pierre-Etienne Moreau, Cl\\'audia Tavares", "title": "A Type System for Tom", "comments": null, "journal-ref": "EPTCS 21, 2010, pp. 51-63", "doi": "10.4204/EPTCS.21.5", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending a given language with new dedicated features is a general and quite\nused approach to make the programming language more adapted to problems. Being\ncloser to the application, this leads to less programming flaws and easier\nmaintenance. But of course one would still like to perform program analysis on\nthese kinds of extended languages, in particular type checking and inference.\nIn this case one has to make the typing of the extended features compatible\nwith the ones in the starting language.\n  The Tom programming language is a typical example of such a situation as it\nconsists of an extension of Java that adds pattern matching, more particularly\nassociative pattern matching, and reduction strategies.\n  This paper presents a type system with subtyping for Tom, that is compatible\nwith Java's type system, and that performs both type checking and type\ninference. We propose an algorithm that checks if all patterns of a Tom program\nare well-typed. In addition, we propose an algorithm based on equality and\nsubtyping constraints that infers types of variables occurring in a pattern.\nBoth algorithms are exemplified and the proposed type system is showed to be\nsound and complete.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 04:37:27 GMT"}], "update_date": "2010-03-26", "authors_parsed": [["Kirchner", "Claude", ""], ["Moreau", "Pierre-Etienne", ""], ["Tavares", "Cl\u00e1udia", ""]]}, {"id": "1003.4800", "submitter": "Gabriel Falconieri Freitas", "authors": "Gabriel Falconieri Freitas, M\\'arcio Corn\\'elio, Tiago Massoni, Rohit\n  Gheyi", "title": "Object-oriented Programming Laws for Annotated Java Programs", "comments": null, "journal-ref": "EPTCS 21, 2010, pp. 65-76", "doi": "10.4204/EPTCS.21.6", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-oriented programming laws have been proposed in the context of\nlanguages that are not combined with a behavioral interface specification\nlanguage (BISL). The strong dependence between source-code and interface\nspecifications may cause a number of difficulties when transforming programs.\nIn this paper we introduce a set of programming laws for object-oriented\nlanguages like Java combined with the Java Modeling Language (JML). The set of\nlaws deals with object-oriented features taking into account their\nspecifications. Some laws deal only with features of the specification\nlanguage. These laws constitute a set of small transformations for the\ndevelopment of more elaborate ones like refactorings.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 04:40:43 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["Freitas", "Gabriel Falconieri", ""], ["Corn\u00e9lio", "M\u00e1rcio", ""], ["Massoni", "Tiago", ""], ["Gheyi", "Rohit", ""]]}, {"id": "1003.4802", "submitter": "Jo\\~ao Marcos", "authors": "Jo\\~ao Marcos", "title": "Automatic Generation of Proof Tactics for Finite-Valued Logics", "comments": null, "journal-ref": "EPTCS 21, 2010, pp. 91-98", "doi": "10.4204/EPTCS.21.8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of flexible tactic-based logical frameworks are nowadays available\nthat can implement a wide range of mathematical theories using a common\nhigher-order metalanguage. Used as proof assistants, one of the advantages of\nsuch powerful systems resides in their responsiveness to extensibility of their\nreasoning capabilities, being designed over rule-based programming languages\nthat allow the user to build her own `programs to construct proofs' - the\nso-called proof tactics.\n  The present contribution discusses the implementation of an algorithm that\ngenerates sound and complete tableau systems for a very inclusive class of\nsufficiently expressive finite-valued propositional logics, and then\nillustrates some of the challenges and difficulties related to the algorithmic\nformation of automated theorem proving tactics for such logics. The procedure\non whose implementation we will report is based on a generalized notion of\nanalyticity of proof systems that is intended to guarantee termination of the\ncorresponding automated tactics on what concerns theoremhood in our targeted\nlogics.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 04:44:58 GMT"}], "update_date": "2010-03-26", "authors_parsed": [["Marcos", "Jo\u00e3o", ""]]}, {"id": "1003.4803", "submitter": "Beno\\^it Boyer", "authors": "Beno\\^it Boyer, Thomas Genet", "title": "Verifying Temporal Regular Properties of Abstractions of Term Rewriting\n  Systems", "comments": null, "journal-ref": "EPTCS 21, 2010, pp. 99-108", "doi": "10.4204/EPTCS.21.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tree automaton completion is an algorithm used for proving safety\nproperties of systems that can be modeled by a term rewriting system. This\nrepresentation and verification technique works well for proving properties of\ninfinite systems like cryptographic protocols or more recently on Java Bytecode\nprograms. This algorithm computes a tree automaton which represents a (regular)\nover approximation of the set of reachable terms by rewriting initial terms.\nThis approach is limited by the lack of information about rewriting relation\nbetween terms. Actually, terms in relation by rewriting are in the same\nequivalence class: there are recognized by the same state in the tree\nautomaton.\n  Our objective is to produce an automaton embedding an abstraction of the\nrewriting relation sufficient to prove temporal properties of the term\nrewriting system.\n  We propose to extend the algorithm to produce an automaton having more\nequivalence classes to distinguish a term or a subterm from its successors\nw.r.t. rewriting. While ground transitions are used to recognize equivalence\nclasses of terms, epsilon-transitions represent the rewriting relation between\nterms. From the completed automaton, it is possible to automatically build a\nKripke structure abstracting the rewriting sequence. States of the Kripke\nstructure are states of the tree automaton and the transition relation is given\nby the set of epsilon-transitions. States of the Kripke structure are labelled\nby the set of terms recognized using ground transitions. On this Kripke\nstructure, we define the Regular Linear Temporal Logic (R-LTL) for expressing\nproperties. Such properties can then be checked using standard model checking\nalgorithms. The only difference between LTL and R-LTL is that predicates are\nreplaced by regular sets of acceptable terms.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 04:46:12 GMT"}], "update_date": "2010-03-26", "authors_parsed": [["Boyer", "Beno\u00eet", ""], ["Genet", "Thomas", ""]]}, {"id": "1003.4812", "submitter": "Mariken Everdij", "authors": "Mariken H.C. Everdij and Henk A.P. Blom", "title": "Bisimulation Relations Between Automata, Stochastic Differential\n  Equations and Petri Nets", "comments": "15 pages, 4 figures, Workshop on Formal Methods for Aerospace (FMA),\n  EPTCS 20m 2010", "journal-ref": "EPTCS 20, 2010, pp. 1-15", "doi": "10.4204/EPTCS.20.1", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Two formal stochastic models are said to be bisimilar if their solutions as a\nstochastic process are probabilistically equivalent. Bisimilarity between two\nstochastic model formalisms means that the strengths of one stochastic model\nformalism can be used by the other stochastic model formalism. The aim of this\npaper is to explain bisimilarity relations between stochastic hybrid automata,\nstochastic differential equations on hybrid space and stochastic hybrid Petri\nnets. These bisimilarity relations make it possible to combine the formal\nverification power of automata with the analysis power of stochastic\ndifferential equations and the compositional specification power of Petri nets.\nThe relations and their combined strengths are illustrated for an air traffic\nexample.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 06:38:50 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Everdij", "Mariken H. C.", ""], ["Blom", "Henk A. P.", ""]]}, {"id": "1003.4865", "submitter": "Oleg Verbitsky", "authors": "Oleg Pikhurko and Oleg Verbitsky", "title": "Logical complexity of graphs: a survey", "comments": "57 pages; 2 figures. This version contains an appendix with an\n  improvement of Theorem 4.7", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the definability of finite graphs in first-order logic with two\nrelation symbols for adjacency and equality of vertices. The logical depth\n$D(G)$ of a graph $G$ is equal to the minimum quantifier depth of a sentence\ndefining $G$ up to isomorphism. The logical width $W(G)$ is the minimum number\nof variables occurring in such a sentence. The logical length $L(G)$ is the\nlength of a shortest defining sentence. We survey known estimates for these\ngraph parameters and discuss their relations to other topics (such as the\nefficiency of the Weisfeiler-Lehman algorithm in isomorphism testing, the\nevolution of a random graph, quantitative characteristics of the zero-one law,\nor the contribution of Frank Ramsey to the research on Hilbert's\nEntscheidungsproblem). Also, we trace the behavior of the descriptive\ncomplexity of a graph as the logic becomes more restrictive (for example, only\ndefinitions with a bounded number of variables or quantifier alternations are\nallowed) or more expressible (after powering with counting quantifiers).\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 11:48:59 GMT"}, {"version": "v2", "created": "Wed, 22 Dec 2010 13:00:27 GMT"}, {"version": "v3", "created": "Tue, 8 Feb 2011 13:47:29 GMT"}, {"version": "v4", "created": "Mon, 29 Apr 2013 08:29:29 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Pikhurko", "Oleg", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "1003.4905", "submitter": "Abbas Dideban", "authors": "Abbas Dideban, Hassane Alla (GIPSA-lab)", "title": "Feedback control logic synthesis for non safe Petri nets", "comments": null, "journal-ref": "Conf\\'erence INCOM 2009, Moscou : Russian Federation (2009)", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of forbidden states of non safe Petri Net\n(PN) modelling discrete events systems. To prevent the forbidden states, it is\npossible to use conditions or predicates associated with transitions.\nGenerally, there are many forbidden states, thus many complex conditions are\nassociated with the transitions. A new idea for computing predicates in non\nsafe Petri nets will be presented. Using this method, we can construct a\nmaximally permissive controller if it exists.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 14:21:46 GMT"}], "update_date": "2010-04-26", "authors_parsed": [["Dideban", "Abbas", "", "GIPSA-lab"], ["Alla", "Hassane", "", "GIPSA-lab"]]}, {"id": "1003.5350", "submitter": "Ian Mackie", "authors": "Daniel J. Dougherty", "title": "An Improved Algorithm for Generating Database Transactions from\n  Relational Algebra Specifications", "comments": null, "journal-ref": "EPTCS 21, 2010, pp. 77-89", "doi": "10.4204/EPTCS.21.7", "report-no": null, "categories": "cs.DB cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alloy is a lightweight modeling formalism based on relational algebra. In\nprior work with Fisler, Giannakopoulos, Krishnamurthi, and Yoo, we have\npresented a tool, Alchemy, that compiles Alloy specifications into\nimplementations that execute against persistent databases. The foundation of\nAlchemy is an algorithm for rewriting relational algebra formulas into code for\ndatabase transactions. In this paper we report on recent progress in improving\nthe robustness and efficiency of this transformation.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2010 08:11:05 GMT"}], "update_date": "2010-03-31", "authors_parsed": [["Dougherty", "Daniel J.", ""]]}, {"id": "1003.5363", "submitter": "EPTCS", "authors": "Manuela Bujorianu (University of Manchester, UK), Michael Fisher\n  (University of Liverpool, UK)", "title": "Proceedings FM-09 Workshop on Formal Methods for Aerospace", "comments": null, "journal-ref": "EPTCS 20, 2010", "doi": "10.4204/EPTCS.20", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main workshop objective was to promote a holistic view and\ninterdisciplinary methods for design, verification and co-ordination of\naerospace systems, by combining formal methods with techniques from control\nengineering and artificial intelligence. The very demanding safety, robustness\nand performance requirements of these systems require unprecedented integration\nof heterogeneous techniques and models. The aim of FMA was to bring together\nactive researchers from all the above areas to discuss and present their work.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2010 12:03:53 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Bujorianu", "Manuela", "", "University of Manchester, UK"], ["Fisher", "Michael", "", "University of Liverpool, UK"]]}, {"id": "1003.5399", "submitter": "Michael Zakharyaschev", "authors": "Roman Kontchakov (Birkbeck College London), Ian Pratt-Hartmann\n  (Department of Computer Science, Manchester University), Frank Wolter\n  (Department of Computer Science, University of Liverpool), Michael\n  Zakharyaschev (Birkbeck College London)", "title": "Spatial logics with connectedness predicates", "comments": "Some results of the paper were presented at LPAR 2008 and ECAI 2000", "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 3 (August 18,\n  2010) lmcs:1229", "doi": "10.2168/LMCS-6(3:7)2010", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider quantifier-free spatial logics, designed for qualitative spatial\nrepresentation and reasoning in AI, and extend them with the means to represent\ntopological connectedness of regions and restrict the number of their connected\ncomponents. We investigate the computational complexity of these logics and\nshow that the connectedness constraints can increase complexity from NP to\nPSpace, ExpTime and, if component counting is allowed, to NExpTime.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2010 22:00:47 GMT"}, {"version": "v2", "created": "Wed, 18 Aug 2010 08:14:54 GMT"}, {"version": "v3", "created": "Mon, 18 Oct 2010 11:56:43 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kontchakov", "Roman", "", "Birkbeck College London"], ["Pratt-Hartmann", "Ian", "", "Department of Computer Science, Manchester University"], ["Wolter", "Frank", "", "Department of Computer Science, University of Liverpool"], ["Zakharyaschev", "Michael", "", "Birkbeck College London"]]}, {"id": "1003.5406", "submitter": "Sreekanth Malladi", "authors": "Sreekanth Malladi", "title": "Disabling equational theories in unification for cryptographic protocol\n  analysis through tagging", "comments": "8 pages, submitted for publication", "journal-ref": null, "doi": null, "report-no": "DSU-BIS-MSIA-Mall2010C", "categories": "cs.CR cs.DM cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show a new tagging scheme for cryptographic protocol\nmessages. Under this tagging, equational theories of operators such as\nexclusive-or, binary addition etc. are effectively disabled, when terms are\nunified. We believe that this result has a significant impact on protocol\nanalysis and security, since unification is at the heart of symbolic protocol\nanalysis. Hence, disabling equational theories in unification implies disabling\nthem altogether in protocol analysis for most operators and theories.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2010 23:54:50 GMT"}, {"version": "v2", "created": "Sat, 10 Apr 2010 03:07:57 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Malladi", "Sreekanth", ""]]}, {"id": "1003.5447", "submitter": "Andrew Gacek", "authors": "Andrew Gacek", "title": "Relating Nominal and Higher-order Abstract Syntax Specifications", "comments": "To appear in PPDP 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nominal abstract syntax and higher-order abstract syntax provide a means for\ndescribing binding structure which is higher-level than traditional techniques.\nThese approaches have spawned two different communities which have developed\nalong similar lines but with subtle differences that make them difficult to\nrelate. The nominal abstract syntax community has devices like names,\nfreshness, name-abstractions with variable capture, and the new-quantifier,\nwhereas the higher-order abstract syntax community has devices like\nlambda-binders, lambda-conversion, raising, and the nabla-quantifier. This\npaper aims to unify these communities and provide a concrete correspondence\nbetween their different devices. In particular, we develop a\nsemantics-preserving translation from alpha-Prolog, a nominal abstract syntax\nbased logic programming language, to G-, a higher-order abstract syntax based\nlogic programming language. We also discuss higher-order judgments, a common\nand powerful tool for specifications with higher-order abstract syntax, and we\nshow how these can be incorporated into G-. This establishes G- as a language\nwith the power of higher-order abstract syntax, the fine-grained variable\ncontrol of nominal specifications, and the desirable properties of higher-order\njudgments.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 07:54:09 GMT"}, {"version": "v2", "created": "Fri, 14 May 2010 07:22:33 GMT"}], "update_date": "2010-05-17", "authors_parsed": [["Gacek", "Andrew", ""]]}, {"id": "1003.5511", "submitter": "EPTCS", "authors": "Marco Gaboardi, Mauro Piccolo", "title": "Categorical Models for a Semantically Linear Lambda-calculus", "comments": null, "journal-ref": "EPTCS 22, 2010, pp. 1-13", "doi": "10.4204/EPTCS.22.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about a categorical approach to model a very simple\nSemantically Linear lambda calculus, named Sll-calculus. This is a core\ncalculus underlying the programming language SlPCF. In particular, in this\nwork, we introduce the notion of Sll-Category, which is able to describe a very\nlarge class of sound models of Sll-calculus. Sll-Category extends in the\nnatural way Benton, Bierman, Hyland and de Paiva's Linear Category, in order to\nsoundly interpret all the constructs of Sll-calculus. This category is general\nenough to catch interesting models in Scott Domains and Coherence Spaces.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 12:01:20 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Gaboardi", "Marco", ""], ["Piccolo", "Mauro", ""]]}, {"id": "1003.5512", "submitter": "EPTCS", "authors": "Paolo Torrini, Reiko Heckel", "title": "Resource-Bound Quantification for Graph Transformation", "comments": null, "journal-ref": "EPTCS 22, 2010, pp. 14-25", "doi": "10.4204/EPTCS.22.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph transformation has been used to model concurrent systems in software\nengineering, as well as in biochemistry and life sciences. The application of a\ntransformation rule can be characterised algebraically as construction of a\ndouble-pushout (DPO) diagram in the category of graphs. We show how\nintuitionistic linear logic can be extended with resource-bound quantification,\nallowing for an implicit handling of the DPO conditions, and how resource logic\ncan be used to reason about graph transformation systems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 12:01:34 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Torrini", "Paolo", ""], ["Heckel", "Reiko", ""]]}, {"id": "1003.5513", "submitter": "EPTCS", "authors": "Edsko de Vries, Adrian Francalanza, Matthew Hennessy", "title": "Uniqueness Typing for Resource Management in Message-Passing Concurrency", "comments": null, "journal-ref": "EPTCS 22, 2010, pp. 26-37", "doi": "10.4204/EPTCS.22.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view channels as the main form of resources in a message-passing\nprogramming paradigm. These channels need to be carefully managed in settings\nwhere resources are scarce. To study this problem, we extend the pi-calculus\nwith primitives for channel allocation and deallocation and allow channels to\nbe reused to communicate values of different types. Inevitably, the added\nexpressiveness increases the possibilities for runtime errors. We define a\nsubstructural type system which combines uniqueness typing and affine typing to\nreject these ill-behaved programs.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 12:01:45 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["de Vries", "Edsko", ""], ["Francalanza", "Adrian", ""], ["Hennessy", "Matthew", ""]]}, {"id": "1003.5515", "submitter": "EPTCS", "authors": "Maribel Fern\\'andez, Nikolaos Siafakas", "title": "Labelled Lambda-calculi with Explicit Copy and Erase", "comments": null, "journal-ref": "EPTCS 22, 2010, pp. 49-64", "doi": "10.4204/EPTCS.22.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two rewriting systems that define labelled explicit substitution\nlambda-calculi. Our work is motivated by the close correspondence between\nLevy's labelled lambda-calculus and paths in proof-nets, which played an\nimportant role in the understanding of the Geometry of Interaction. The\nstructure of the labels in Levy's labelled lambda-calculus relates to the\nmultiplicative information of paths; the novelty of our work is that we design\nlabelled explicit substitution calculi that also keep track of exponential\ninformation present in call-by-value and call-by-name translations of the\nlambda-calculus into linear logic proof-nets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 12:02:10 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Fern\u00e1ndez", "Maribel", ""], ["Siafakas", "Nikolaos", ""]]}, {"id": "1003.5518", "submitter": "EPTCS", "authors": "A. Bucciarelli, A. Carraro, T. Ehrhard, A. Salibra", "title": "On Linear Information Systems", "comments": null, "journal-ref": "EPTCS 22, 2010, pp. 38-48", "doi": "10.4204/EPTCS.22.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scott's information systems provide a categorically equivalent, intensional\ndescription of Scott domains and continuous functions. Following a well\nestablished pattern in denotational semantics, we define a linear version of\ninformation systems, providing a model of intuitionistic linear logic (a\nnew-Seely category), with a \"set-theoretic\" interpretation of exponentials that\nrecovers Scott continuous functions via the co-Kleisli construction. From a\ndomain theoretic point of view, linear information systems are equivalent to\nprime algebraic Scott domains, which in turn generalize prime algebraic\nlattices, already known to provide a model of classical linear logic.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 12:13:18 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["Bucciarelli", "A.", ""], ["Carraro", "A.", ""], ["Ehrhard", "T.", ""], ["Salibra", "A.", ""]]}, {"id": "1003.5716", "submitter": "EPTCS", "authors": "M\\'ario Florido, Ian Mackie", "title": "Proceedings First International Workshop on Linearity", "comments": null, "journal-ref": "EPTCS 22, 2010", "doi": "10.4204/EPTCS.22", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of LINEARITY 2009: the first\nInternational Workshop on Linearity, which took place 12th September 2009 in\nCoimbra, Portugal. The workshop was a satellite event of CSL 2009, the 18th\nEACSL Annual Conference on Computer Science Logic.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2010 01:48:23 GMT"}], "update_date": "2010-03-31", "authors_parsed": [["Florido", "M\u00e1rio", ""], ["Mackie", "Ian", ""]]}, {"id": "1003.5758", "submitter": "EPTCS", "authors": "Ian Mackie, Anamaria Martins Moreira", "title": "Proceedings Tenth International Workshop on Rule-Based Programming", "comments": null, "journal-ref": "EPTCS 21, 2010", "doi": "10.4204/EPTCS.21", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of RULE 2009: the tenth International\nWorkshop on Rule-Based Programming. It took place in June 28th 2009, Brasilia,\nBrazil, as a satellite event of RDP 2009. The first Rule workshop was held in\nMontreal in 2000, and subsequent editions took place in Firenze, Pittsburgh,\nValencia, Aachen, Nara, Seattle, Paris, and Hagenberg.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2010 08:11:40 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["Mackie", "Ian", ""], ["Moreira", "Anamaria Martins", ""]]}, {"id": "1003.5831", "submitter": "Matthew Szudzik", "authors": "Matthew P. Szudzik (Carnegie Mellon)", "title": "The Computable Universe Hypothesis", "comments": "33 pages, 0 figures; minor changes", "journal-ref": "A Computable Universe, World Scientific, 2013, pp. 479-523", "doi": "10.1142/9789814374309_0025", "report-no": null, "categories": "math.LO cs.CC cs.LO math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When can a model of a physical system be regarded as computable? We provide\nthe definition of a computable physical model to answer this question. The\nconnection between our definition and Kreisel's notion of a mechanistic theory\nis discussed, and several examples of computable physical models are given,\nincluding models which feature discrete motion, a model which features\nnon-discrete continuous motion, and probabilistic models such as radioactive\ndecay. We show how computable physical models on effective topological spaces\ncan be formulated using the theory of type-two effectivity (TTE). Various\ncommon operations on computable physical models are described, such as the\noperation of coarse-graining and the formation of statistical ensembles. The\ndefinition of a computable physical model also allows for a precise\nformalization of the computable universe hypothesis--the claim that all the\nlaws of physics are computable.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2010 18:28:26 GMT"}, {"version": "v2", "created": "Mon, 16 Aug 2010 12:34:25 GMT"}, {"version": "v3", "created": "Fri, 17 Dec 2010 16:14:51 GMT"}, {"version": "v4", "created": "Thu, 12 Jan 2012 01:55:08 GMT"}, {"version": "v5", "created": "Fri, 27 Jan 2012 20:52:16 GMT"}, {"version": "v6", "created": "Wed, 7 Aug 2013 20:28:31 GMT"}], "update_date": "2013-08-09", "authors_parsed": [["Szudzik", "Matthew P.", "", "Carnegie Mellon"]]}, {"id": "1003.5954", "submitter": "Adam  Megacz", "authors": "Adam Megacz", "title": "Multi-Stage Programs are Generalized Arrows", "comments": "This paper is obsolete and has been superceded by {\\it Multi-Level\n  Programs are Generalized Arrows} available here:\n  http://arxiv.org/pdf/1007.2885", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lambda calculus, subject to typing restrictions, provides a syntax for\nthe internal language of cartesian closed categories. This paper establishes a\nparallel result: staging annotations, subject to named level restrictions,\nprovide a syntax for the internal language of Freyd categories, which are known\nto be in bijective correspondence with Arrows. The connection is made by\ninterpreting multi-stage type systems as indexed functors from polynomial\ncategories to their reindexings. This result applies only to multi-stage\nlanguages which are (1) homogeneous, (2) allow cross-stage persistence and (3)\nplace no restrictions on the use of structural rules in typing derivations.\nRemoving these restrictions and repeating the construction yields generalized\narrows, of which Arrows are a particular case. A translation from well-typed\nmulti-stage programs to single-stage GArrow terms is provided. The translation\nis defined by induction on the structure of the proof that the multi-stage\nprogram is well-typed, relying on information encoded in the proof's use of\nstructural rules. Metalanguage designers can now factor out the syntactic\nmachinery of metaprogramming by providing a single translation from staging\nsyntax into expressions of generalized arrow type. Object language providers\nneed only implement the functions of the generalized arrow type class in\npoint-free style. Object language users may write metaprograms over these\nobject languages in a point-ful style, using the same binding, scoping,\nabstraction, and application mechanisms in both the object language and\nmetalanguage. This paper's principal contributions are the GArrow definition of\nFigures 2 and 3, the translation in Figure 5 and the category-theoretic\nsemantics of Definition 16. An accompanying Coq proof formalizes the type\nsystem, translation procedure, and key theorems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2010 00:42:30 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2010 06:27:38 GMT"}, {"version": "v3", "created": "Thu, 30 Sep 2010 20:40:44 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Megacz", "Adam", ""]]}, {"id": "1003.6096", "submitter": "Jan Jakubuv", "authors": "Jan Jakubuv and J. B. Wells", "title": "Expressiveness of Generic Process Shape Types", "comments": "Submitted to Trustworthy Global Computing (TGC) 2010.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape types are a general concept of process types which work for many\nprocess calculi. We extend the previously published Poly* system of shape types\nto support name restriction. We evaluate the expressiveness of the extended\nsystem by showing that shape types are more expressive than an implicitly typed\npi-calculus and an explicitly typed Mobile Ambients. We demonstrate that the\nextended system makes it easier to enjoy advantages of shape types which\ninclude polymorphism, principal typings, and a type inference implementation.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2010 16:55:55 GMT"}], "update_date": "2010-04-01", "authors_parsed": [["Jakubuv", "Jan", ""], ["Wells", "J. B.", ""]]}]