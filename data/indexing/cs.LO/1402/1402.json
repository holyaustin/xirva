[{"id": "1402.0033", "submitter": "Marek Zawadowski", "authors": "Justyna Grudzinska, Marek Zawadowski", "title": "Generalized Quantifiers on Dependent Types: A System for Anaphora", "comments": "40 pages; final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a system for the interpretation of anaphoric relationships between\nunbound pronouns and quantifiers. The main technical contribution of our\nproposal consists in combining generalized quantifiers with dependent types.\nEmpirically, our system allows a uniform treatment of all types of unbound\nanaphora, including the notoriously difficult cases such as quantificational\nsubordination, cumulative and branching continuations, and 'donkey anaphora'.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 23:51:08 GMT"}, {"version": "v2", "created": "Sun, 31 Jul 2016 19:41:25 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Grudzinska", "Justyna", ""], ["Zawadowski", "Marek", ""]]}, {"id": "1402.0050", "submitter": "Yuxi Fu", "authors": "Qiang Yin, Yuxi Fu, Chaodong He, Mingzhang Huang and Xiuting Tao", "title": "Branching Bisimilarity Checking for PRS", "comments": "18 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies reveal that branching bisimilarity is decidable for both nBPP\n(normed Basic Parallel Process) and nBPA (normed Basic Process Algebra). These\nresults lead to the question if there are any other models in the hierarchy of\nPRS (Process Rewrite System) whose branching bisimilarity is decidable. It is\nshown in this paper that the branching bisimilarity for both nOCN (normed One\nCounter Net) and nPA (normed Process Algebra) is undecidable. These results\nessentially imply that the question has a negative answer.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 03:39:14 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2014 13:02:04 GMT"}, {"version": "v3", "created": "Mon, 28 Apr 2014 14:20:41 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Yin", "Qiang", ""], ["Fu", "Yuxi", ""], ["He", "Chaodong", ""], ["Huang", "Mingzhang", ""], ["Tao", "Xiuting", ""]]}, {"id": "1402.0081", "submitter": "Jonathan Heras", "authors": "J\\'onathan Heras and Ekaterina Komendantskaya", "title": "Proof Pattern Search in Coq/SSReflect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML4PG is an extension of the Proof General interface, allowing the user to\ninvoke machine-learning algorithms and find proof similarities in Coq/SSReect\nlibraries. In this paper, we present three new improvements to ML4PG. First, a\nnew method of \"recurrent clustering\" is introduced to collect statistical\nfeatures from Coq terms. Now the user can receive suggestions about similar\ndefinitions, types and lemma statements, in addition to proof strategies.\nSecond, Coq proofs are split into patches to capture proof strategies that\ncould arise at different stages of a proof. Finally, we improve ML4PG's output\nintroducing an automaton-shape representation for proof patterns.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 11:52:38 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Heras", "J\u00f3nathan", ""], ["Komendantskaya", "Ekaterina", ""]]}, {"id": "1402.0225", "submitter": "Alexandre Rademaker", "authors": "Edward Hermann Haeusler and Alexandre Rademaker", "title": "An Intuitionisticaly based Description Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This article presents iALC, an intuitionistic version of the classical\ndescription logic ALC, based on the framework for constructive modal logics\npresented by Simpson \\cite{simpson95} and related to description languages, via\nhybrid logics, by dePaiva \\cite{depaiva2003}. This article correcta and extends\nthe presentation of iALC appearing in \\cite{PHR:2010}. It points out the\ndifference between iALC and the intuitionistic hybrid logic presented in\n\\cite{depaiva2003}. Completeness and soundness proofs are provided. A brief\ndiscussion on the computacional complexity of iALC provability is taken. It is\nworth mentioning that iALC is used to formalize legal knowledge\n\\cite{HPR:2010a,HPR:2010ab,Jurix, HPR:2011}, and in fact, was specifically\ndesigned to this goal.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2014 18:09:31 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Haeusler", "Edward Hermann", ""], ["Rademaker", "Alexandre", ""]]}, {"id": "1402.0299", "submitter": "Panos Rondogiannis", "authors": "Zolt\\'an \\'Esik and Panos Rondogiannis", "title": "A Fixed Point Theorem for Non-Monotonic Functions", "comments": "34 pages. Accepted in: Theoretical Computer Science (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fixed point theorem for a class of (potentially) non-monotonic\nfunctions over specially structured complete lattices. The theorem has as a\nspecial case the Knaster-Tarski fixed point theorem when restricted to the case\nof monotonic functions and Kleene's theorem when the functions are additionally\ncontinuous. From the practical side, the theorem has direct applications in the\nsemantics of negation in logic programming. In particular, it leads to a more\ndirect and elegant proof of the least fixed point result of [Rondogiannis and\nW.W.Wadge, ACM TOCL 6(2): 441-467 (2005)]. Moreover, the theorem appears to\nhave potential for possible applications outside the logic programming domain.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 07:42:10 GMT"}, {"version": "v2", "created": "Sun, 1 Feb 2015 11:57:31 GMT"}, {"version": "v3", "created": "Sat, 7 Feb 2015 14:24:30 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["\u00c9sik", "Zolt\u00e1n", ""], ["Rondogiannis", "Panos", ""]]}, {"id": "1402.0474", "submitter": "Maxime Amblard", "authors": "Maxime Amblard (INRIA Nancy - Grand Est / LORIA), Christian Retor\\'e\n  (LaBRI)", "title": "Normalization and sub-formula property for Lambek with product and PCMLL\n  -- Partially Commutative Multiplicative Linear Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes the normalisation of natural deduction or lambda\ncalculus formulation of Intuitionistic Non Commutative Logic --- which involves\nboth commutative and non commutative connectives. This calculus first\nintroduced by de Groote and as opposed to the classical version by Abrusci and\nRuet admits a full entropy which allow order to be relaxed into any suborder.\nOur result also includes, as a special case, the normalisation of natural\ndeduction the Lambek calculus with product, which is unsurprising but yet\nunproved. Regarding Intuitionistic Non Commutative Logic with full entropy does\nnot have up to now a proof net syntax, and that for linguistic applications,\nsequent calculi which are only more or less equivalent to natural deduction,\nare not convenient because they lack the standard Curry-Howard isomorphism.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 19:25:58 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Amblard", "Maxime", "", "INRIA Nancy - Grand Est / LORIA"], ["Retor\u00e9", "Christian", "", "LaBRI"]]}, {"id": "1402.0569", "submitter": "Babak Bagheri Hariri", "authors": "Babak Bagheri Hariri, Diego Calvanese, Marco Montali, Giuseppe De\n  Giacomo, Riccardo De Masellis, Paolo Felli", "title": "Description Logic Knowledge and Action Bases", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 46, pages\n  651-686, 2013", "doi": "10.1613/jair.3826", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description logic Knowledge and Action Bases (KAB) are a mechanism for\nproviding both a semantically rich representation of the information on the\ndomain of interest in terms of a description logic knowledge base and actions\nto change such information over time, possibly introducing new objects. We\nresort to a variant of DL-Lite where the unique name assumption is not enforced\nand where equality between objects may be asserted and inferred. Actions are\nspecified as sets of conditional effects, where conditions are based on\nepistemic queries over the knowledge base (TBox and ABox), and effects are\nexpressed in terms of new ABoxes. In this setting, we address verification of\ntemporal properties expressed in a variant of first-order mu-calculus with\nquantification across states. Notably, we show decidability of verification,\nunder a suitable restriction inspired by the notion of weak acyclicity in data\nexchange.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 01:36:58 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Hariri", "Babak Bagheri", ""], ["Calvanese", "Diego", ""], ["Montali", "Marco", ""], ["De Giacomo", "Giuseppe", ""], ["De Masellis", "Riccardo", ""], ["Felli", "Paolo", ""]]}, {"id": "1402.0575", "submitter": "Diego Calvanese", "authors": "Diego Calvanese, Magdalena Ortiz, Mantas Simkus, Giorgio Stefanoni", "title": "Reasoning about Explanations for Negative Query Answers in DL-Lite", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 48, pages\n  635-669, 2013", "doi": "10.1613/jair.3870", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to meet usability requirements, most logic-based applications\nprovide explanation facilities for reasoning services. This holds also for\nDescription Logics, where research has focused on the explanation of both TBox\nreasoning and, more recently, query answering. Besides explaining the presence\nof a tuple in a query answer, it is important to explain also why a given tuple\nis missing. We address the latter problem for instance and conjunctive query\nanswering over DL-Lite ontologies by adopting abductive reasoning; that is, we\nlook for additions to the ABox that force a given tuple to be in the result. As\nreasoning tasks we consider existence and recognition of an explanation, and\nrelevance and necessity of a given assertion for an explanation. We\ncharacterize the computational complexity of these problems for arbitrary,\nsubset minimal, and cardinality minimal explanations.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 01:39:28 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Calvanese", "Diego", ""], ["Ortiz", "Magdalena", ""], ["Simkus", "Mantas", ""], ["Stefanoni", "Giorgio", ""]]}, {"id": "1402.0705", "submitter": "Sylvain Schmitz", "authors": "Sylvain Schmitz", "title": "Implicational Relevance Logic is 2-EXPTIME-Complete", "comments": null, "journal-ref": "Proceedings of RTA-TLCA 2014, Lecture Notes in Computer Science\n  8560, pp. 395--409, Springer, 2014", "doi": "10.1007/978-3-319-08918-8_27", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that provability in the implicational fragment of relevance logic is\ncomplete for doubly exponential time, using reductions to and from coverability\nin branching vector addition systems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 12:06:05 GMT"}, {"version": "v2", "created": "Thu, 25 Sep 2014 15:44:08 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2015 15:29:24 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Schmitz", "Sylvain", ""]]}, {"id": "1402.0746", "submitter": "Harald Zankl", "authors": "Harald Zankl (University of Innsbruck), Martin Korp (University of\n  Innsbruck)", "title": "Modular Complexity Analysis for Term Rewriting", "comments": "33 pages; Special issue of RTA 2010", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 1 (April 1,\n  2014) lmcs:749", "doi": "10.2168/LMCS-10(1:19)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All current investigations to analyze the derivational complexity of term\nrewrite systems are based on a single termination method, possibly preceded by\ntransformations. However, the exclusive use of direct criteria is problematic\ndue to their restricted power. To overcome this limitation the article\nintroduces a modular framework which allows to infer (polynomial) upper bounds\non the complexity of term rewrite systems by combining different criteria.\nSince the fundamental idea is based on relative rewriting, we study how matrix\ninterpretations and match-bounds can be used and extended to measure complexity\nfor relative rewriting, respectively. The modular framework is proved strictly\nmore powerful than the conventional setting. Furthermore, the results have been\nimplemented and experiments show significant gains in power.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 14:38:21 GMT"}, {"version": "v2", "created": "Sat, 29 Mar 2014 16:55:46 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Zankl", "Harald", "", "University of Innsbruck"], ["Korp", "Martin", "", "University of\n  Innsbruck"]]}, {"id": "1402.0761", "submitter": "Kristina Sojakova", "authors": "Kristina Sojakova", "title": "Higher Inductive Types as Homotopy-Initial Algebras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homotopy Type Theory is a new field of mathematics based on the surprising\nand elegant correspondence between Martin-Lofs constructive type theory and\nabstract homotopy theory. We have a powerful interplay between these\ndisciplines - we can use geometric intuition to formulate new concepts in type\ntheory and, conversely, use type-theoretic machinery to verify and often\nsimplify existing mathematical proofs. A crucial ingredient in this new system\nare higher inductive types, which allow us to represent objects such as\nspheres, tori, pushouts, and quotients. We investigate a variant of higher\ninductive types whose computational behavior is determined up to a higher path.\nWe show that in this setting, higher inductive types are characterized by the\nuniversal property of being a homotopy-initial algebra.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 15:22:49 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Sojakova", "Kristina", ""]]}, {"id": "1402.0897", "submitter": "Bartek Klin", "authors": "Miko{\\l}aj Boja\\'nczyk (University of Warsaw), Bartek Klin (University\n  of Warsaw), S{\\l}awomir Lasota (University of Warsaw)", "title": "Automata theory in nominal sets", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 3 (August\n  15, 2014) lmcs:1157", "doi": "10.2168/LMCS-10(3:4)2014", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study languages over infinite alphabets equipped with some structure that\ncan be tested by recognizing automata. We develop a framework for studying such\nalphabets and the ensuing automata theory, where the key role is played by an\nautomorphism group of the alphabet. In the process, we generalize nominal sets\ndue to Gabbay and Pitts.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 22:09:30 GMT"}, {"version": "v2", "created": "Thu, 14 Aug 2014 19:49:34 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", "", "University of Warsaw"], ["Klin", "Bartek", "", "University\n  of Warsaw"], ["Lasota", "S\u0142awomir", "", "University of Warsaw"]]}, {"id": "1402.1051", "submitter": "Dominique Duval", "authors": "Jean-Guillaume Dumas (LJK), Dominique Duval (LJK), Jean-Claude Reynaud\n  (RC)", "title": "Breaking a monad-comonad symmetry between computational effects", "comments": "arXiv admin note: substantial text overlap with arXiv:1310.0605", "journal-ref": "Mathematical Structures in Computer Science 22, 4 (2012) p.719-722", "doi": "10.1017/S0960129511000752", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational effects may often be interpreted in the Kleisli category of a\nmonad or in the coKleisli category of a comonad. The duality between monads and\ncomonads corresponds, in general, to a symmetry between construction and\nobservation, for instance between raising an exception and looking up a state.\nThanks to the properties of adjunction one may go one step further: the\ncoKleisli-on-Kleisli category of a monad provides a kind of observation with\nrespect to a given construction, while dually the Kleisli-on-coKleisli category\nof a comonad provides a kind of construction with respect to a given\nobservation. In the previous examples this gives rise to catching an exception\nand updating a state. However, the interpretation of computational effects is\nusually based on a category which is not self-dual, like the category of sets.\nThis leads to a breaking of the monad-comonad duality. For instance, in a\ndistributive category the state effect has much better properties than the\nexception effect. This remark provides a novel point of view on the usual\nmechanism for handling exceptions. The aim of this paper is to build an\nequational semantics for handling exceptions based on the coKleisli-on-Kleisli\ncategory of the monad of exceptions. We focus on n-ary functions and\nconditionals. We propose a programmer's language for exceptions and we prove\nthat it has the required behaviour with respect to n-ary functions and\nconditionals.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 14:26:14 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Dumas", "Jean-Guillaume", "", "LJK"], ["Duval", "Dominique", "", "LJK"], ["Reynaud", "Jean-Claude", "", "RC"]]}, {"id": "1402.1377", "submitter": "Edward Haeusler", "authors": "Davi Romero de Vasconcelos and Edward Hermann Haeusler", "title": "Reasoning about Games via a First-order Modal Model Checking Approach", "comments": "Extended version of article published in the SBMF 2007. Accepted to\n  ENTCS. Withdrawn from ENTCS in 2014 in virtue to submission to other venue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a logic based on first-order CTL, namely Game\nAnalysis Logic (GAL), in order to reason about games. We relate models and\nsolution concepts of Game Theory as models and formulas of GAL, respectively.\nPrecisely, we express extensive games with perfect in- formation as models of\nGAL, and Nash equilibrium and subgame perfect equilibrium by means of formulas\nof GAL. From a practical point of view, we provide a GAL model checker in order\nto analyze games automatically. We use our model checker in at least two\ndirections: to find solution con- cepts of Game Theory; and, to analyze players\nthat are based on standard algorithms of the AI community, such as the minimax\nprocedure.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 15:29:21 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 15:54:46 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["de Vasconcelos", "Davi Romero", ""], ["Haeusler", "Edward Hermann", ""]]}, {"id": "1402.1450", "submitter": "Luca Bortolussi", "authors": "Luca Bortolussi and Dimitrios Milios and Guido Sanguinetti", "title": "Smoothed Model Checking for Uncertain Continuous Time Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the satisfaction probability of a\nformula for stochastic models with parametric uncertainty. We show that this\nsatisfaction probability is a smooth function of the model parameters. This\nenables us to devise a novel Bayesian statistical algorithm which performs\nstatistical model checking simultaneously for all values of the model\nparameters from observations of truth values of the formula over individual\nruns of the model at isolated parameter values. This is achieved by exploiting\nthe smoothness of the satisfaction function: by modelling explicitly\ncorrelations through a prior distribution over a space of smooth functions (a\nGaussian Process), we can condition on observations at individual parameter\nvalues to construct an analytical approximation of the function itself.\nExtensive experiments on non-trivial case studies show that the approach is\naccurate and several orders of magnitude faster than naive parameter\nexploration with standard statistical model checking methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 18:23:28 GMT"}, {"version": "v2", "created": "Wed, 22 Oct 2014 12:10:39 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Bortolussi", "Luca", ""], ["Milios", "Dimitrios", ""], ["Sanguinetti", "Guido", ""]]}, {"id": "1402.1535", "submitter": "Ricardo Fernandes", "authors": "R. Q. A Fernandes, and E. H. Haeusler, and L. C. P. D Pereira", "title": "PUC-Logic", "comments": "33 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a logic for Proximity-based Understanding of Conditionals\n(PUC-Logic) that unifies the Counterfactual and Deontic logics proposed by\nDavid Lewis. We also propose a natural deduction system (PUC-ND) associated to\nthis new logic. This inference system is proven to be sound, complete,\nnormalizing and decidable. The relative completeness for the $\\boldsymbol{V}$\nand $\\boldsymbol{CO}$ logics is shown to emphasize the unified approach over\nthe work of Lewis.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 01:32:30 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Fernandes", "R. Q. A", ""], ["Haeusler", "E. H.", ""], ["Pereira", "L. C. P. D", ""]]}, {"id": "1402.1922", "submitter": "Georg Moser", "authors": "Martin Hofmann and Georg Moser", "title": "Amortised Resource Analysis and Typed Polynomial Interpretations\n  (extended version)", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We introduce a novel resource analysis for typed term rewrite systems based\non a potential-based type system. This type system gives rise to polynomial\nbounds on the innermost runtime complexity. We relate the thus obtained\namortised resource analysis to polynomial interpretations and obtain the\nperhaps surprising result that whenever a rewrite system R can be well-typed,\nthen there exists a polynomial interpretation that orients R. For this we\nadequately adapt the standard notion of polynomial interpretations to the typed\nsetting.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 07:08:04 GMT"}, {"version": "v2", "created": "Fri, 14 Mar 2014 11:39:15 GMT"}], "update_date": "2014-03-17", "authors_parsed": [["Hofmann", "Martin", ""], ["Moser", "Georg", ""]]}, {"id": "1402.1992", "submitter": "Mingmin  Chen", "authors": "Mingmin Chen, Shizhuo Yu, Nico Franz, Shawn Bowers, Bertram Lu\\''asher", "title": "Euler/X: A Toolkit for Logic-based Taxonomy Integration", "comments": "8 pages, 14 figures, WFLP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Euler/X, a toolkit for logic-based taxonomy integration. Given\ntwo taxonomies and a set of alignment constraints between them, Euler/X\nprovides tools for detecting, explaining, and reconciling inconsistencies;\nfinding all possible merges between (consistent) taxonomies; and visualizing\nmerge results. Euler/X employs a number of different underlying reasoning\nsystems, including first-order reasoners (Prover9 and Mace4), answer set\nprogramming (DLV and Potassco), and RCC reasoners (PyRCC8). We demonstrate the\nfeatures of Euler/X and provide experimental results showing its feasibility on\nvarious synthetic and real-world examples.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 21:13:30 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Chen", "Mingmin", ""], ["Yu", "Shizhuo", ""], ["Franz", "Nico", ""], ["Bowers", "Shawn", ""], ["Lu\\''asher", "Bertram", ""]]}, {"id": "1402.2071", "submitter": "Radim Belohlavek", "authors": "Radim Belohlavek, Vilem Vychodil", "title": "Attribute Dependencies for Data with Grades", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines attribute dependencies in data that involve grades, such\nas a grade to which an object is red or a grade to which two objects are\nsimilar. We thus extend the classical agenda by allowing graded, or fuzzy,\nattributes instead of Boolean attributes in case of attribute implications, and\nallowing approximate match based on degrees of similarity instead of exact\nmatch in case of functional dependencies. In a sense, we move from bivalence,\ninherently present in the now-available theories of dependencies, to a more\nflexible setting that involves grades. Such a shift has far-reaching\nconsequences. We argue that a reasonable theory of dependencies may be\ndeveloped by making use of mathematical fuzzy logic. Namely, the theory of\ndependencies is then based on a solid logic calculus the same way the classical\ndependencies are based on classical logic. For instance, rather than handling\ndegrees of similarity in an ad hoc manner, we consistently treat them as truth\nvalues, the same way as true (match) and false (mismatch) are treated in\nclassical theories. In addition, several notions intuitively embraced in the\npresence of grades, such as a degree of validity of a particular dependence or\na degree of entailment, naturally emerge and receive a conceptually clean\ntreatment in the presented approach. In the paper, we discuss motivations,\nprovide basic notions of syntax and semantics, and develop basic results which\ninclude entailment of dependencies, associated closure structures, a logic of\ndependencies with two versions of completeness theorem, results and algorithms\nregarding complete non-redundant sets of dependencies, relationship to and a\npossible reductionist interface to classical dependencies, and relationship to\nfunctional dependencies over domains with similarity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 09:08:18 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Belohlavek", "Radim", ""], ["Vychodil", "Vilem", ""]]}, {"id": "1402.2102", "submitter": "Filip Konecny", "authors": "Filip Konecny", "title": "PTIME Computation of Transitive Closures of Octagonal Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing transitive closures of integer relations is the key to finding\nprecise invariants of integer programs. In this paper, we study difference\nbounds and octagonal relations and prove that their transitive closure is a\nPTIME-computable formula in the existential fragment of Presburger arithmetic.\nThis result marks a significant complexity improvement, as the known algorithms\nhave EXPTIME worst case complexity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 11:04:39 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Konecny", "Filip", ""]]}, {"id": "1402.2127", "submitter": "Radu Iosif", "authors": "Radu Iosif and Adam Rogalewicz and Tomas Vojnar", "title": "Deciding Entailments in Inductive Separation Logic with Tree Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separation Logic (SL) with inductive definitions is a natural formalism for\nspecifying complex recursive data structures, used in compositional\nverification of programs manipulating such structures. The key ingredient of\nany automated verification procedure based on SL is the decidability of the\nentailment problem. In this work, we reduce the entailment problem for a\nnon-trivial subset of SL describing trees (and beyond) to the language\ninclusion of tree automata (TA). Our reduction provides tight complexity bounds\nfor the problem and shows that entailment in our fragment is EXPTIME-complete.\nFor practical purposes, we leverage from recent advances in automata theory,\nsuch as inclusion checking for non-deterministic TA avoiding explicit\ndeterminization. We implemented our method and present promising preliminary\nexperimental results.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 12:31:58 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2014 09:35:07 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Iosif", "Radu", ""], ["Rogalewicz", "Adam", ""], ["Vojnar", "Tomas", ""]]}, {"id": "1402.2143", "submitter": "Uli Fahrenberg", "authors": "Uli Fahrenberg and Axel Legay and Louis-Marie Traonouez", "title": "Structural Refinement for the Modal nu-Calculus", "comments": "Accepted at ICTAC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new notion of structural refinement, a sound abstraction of\nlogical implication, for the modal nu-calculus. Using new translations between\nthe modal nu-calculus and disjunctive modal transition systems, we show that\nthese two specification formalisms are structurally equivalent.\n  Using our translations, we also transfer the structural operations of\ncomposition and quotient from disjunctive modal transition systems to the modal\nnu-calculus. This shows that the modal nu-calculus supports composition and\ndecomposition of specifications.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 13:46:55 GMT"}, {"version": "v2", "created": "Tue, 10 Jun 2014 12:53:50 GMT"}], "update_date": "2014-06-11", "authors_parsed": [["Fahrenberg", "Uli", ""], ["Legay", "Axel", ""], ["Traonouez", "Louis-Marie", ""]]}, {"id": "1402.2245", "submitter": "Carlos Lombardi", "authors": "Carlos Lombardi, Alejandro R\\'ios, Roel de Vrijer", "title": "Proof terms for infinitary rewriting, progress report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the notion of proof term to the realm of transfinite reduction.\nProof terms represent reductions in the first-order term format, thereby\nfacilitating their formal analysis. We show that any transfinite reduction can\nbe faithfully represented as an infinitary proof term, which is unique up to,\ninfinitary, associativity.\n  Our main use of proof terms is in a definition of permutation equivalence for\ntransfinite reductions, on the basis of permutation equations. This definition\ninvolves a variant of equational logic, adapted for dealing with infinite\nobjects.\n  A proof of the compression property via proof terms is presented, which\nestablishes permutation equivalence between the original and the compressed\nreductions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 19:33:03 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2014 05:18:30 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Lombardi", "Carlos", ""], ["R\u00edos", "Alejandro", ""], ["de Vrijer", "Roel", ""]]}, {"id": "1402.2359", "submitter": "Josef Urban", "authors": "Cezary Kaliszyk, Josef Urban, Ji\\v{r}\\'i Vysko\\v{c}il", "title": "Machine Learner for Automated Reasoning 0.4 and 0.5", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learner for Automated Reasoning (MaLARea) is a learning and reasoning\nsystem for proving in large formal libraries where thousands of theorems are\navailable when attacking a new conjecture, and a large number of related\nproblems and proofs can be used to learn specific theorem-proving knowledge.\nThe last version of the system has by a large margin won the 2013 CASC LTB\ncompetition. This paper describes the motivation behind the methods used in\nMaLARea, discusses the general approach and the issues arising in evaluation of\nsuch system, and describes the Mizar@Turing100 and CASC'24 versions of MaLARea.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 03:42:00 GMT"}, {"version": "v2", "created": "Wed, 28 May 2014 13:51:17 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""], ["Vysko\u010dil", "Ji\u0159\u00ed", ""]]}, {"id": "1402.2410", "submitter": "Florian Lonsing", "authors": "Florian Lonsing and Uwe Egly", "title": "Incremental QBF Solving", "comments": "revision (camera-ready, to appear in the proceedings of CP 2014,\n  LNCS, Springer)", "journal-ref": null, "doi": "10.1007/978-3-319-10428-7_38", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of incrementally solving a sequence of quantified\nBoolean formulae (QBF). Incremental solving aims at using information learned\nfrom one formula in the process of solving the next formulae in the sequence.\nBased on a general overview of the problem and related challenges, we present\nan approach to incremental QBF solving which is application-independent and\nhence applicable to QBF encodings of arbitrary problems. We implemented this\napproach in our incremental search-based QBF solver DepQBF and report on\nimplementation details. Experimental results illustrate the potential benefits\nof incremental solving in QBF-based workflows.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 09:36:53 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 10:47:27 GMT"}, {"version": "v3", "created": "Mon, 23 Jun 2014 08:52:30 GMT"}], "update_date": "2014-09-05", "authors_parsed": [["Lonsing", "Florian", ""], ["Egly", "Uwe", ""]]}, {"id": "1402.2474", "submitter": "Daniel Weller", "authors": "Stefan Hetzl and Alexander Leitsch and Giselle Reis and Janos\n  Tapolczai and Daniel Weller", "title": "Introducing Quantified Cuts in Logic with Equality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cut-introduction is a technique for structuring and compressing formal\nproofs. In this paper we generalize our cut-introduction method for the\nintroduction of quantified lemmas of the form $\\forall x.A$ (for\nquantifier-free $A$) to a method generating lemmas of the form $\\forall\nx_1\\ldots\\forall x_n.A$. Moreover, we extend the original method to predicate\nlogic with equality. The new method was implemented and applied to the TSTP\nproof database. It is shown that the extension of the method to handle equality\nand quantifier-blocks leads to a substantial improvement of the old algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 12:42:41 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Hetzl", "Stefan", ""], ["Leitsch", "Alexander", ""], ["Reis", "Giselle", ""], ["Tapolczai", "Janos", ""], ["Weller", "Daniel", ""]]}, {"id": "1402.2511", "submitter": "Eugenia Sironi", "authors": "Eugenia Sironi", "title": "Type Theory in Ludics", "comments": "arXiv admin note: text overlap with arXiv:1307.1028 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some first steps in the more general setting of the interpretation\nof dependent type theory in Ludics. The framework is the following: a\n(Martin-Lof) type A is represented by a behaviour (which corresponds to a\nformula) in such a way that canonical elements of A are interpreted in a set\nthat is principal for the behaviour, where principal means in some way a\nminimal generator. We introduce some notions on Ludics and the interpretation\nof Martin-Lof rules. Then we propose a representation for simple types in\nLudics, i.e., natural numbers, lists, the arrow construction and the usual\nconstructors.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 14:53:50 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Sironi", "Eugenia", ""]]}, {"id": "1402.2698", "submitter": "Mateus de Oliveira Oliveira", "authors": "Mateus de Oliveira Oliveira", "title": "Automated Verification, Synthesis and Correction of Concurrent Systems\n  via MSO Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide algorithmic solutions to five fundamental problems\nconcerning the verification, synthesis and correction of concurrent systems\nthat can be modeled by bounded p/t-nets. We express concurrency via partial\norders and assume that behavioral specifications are given via monadic second\norder logic. A c-partial-order is a partial order whose Hasse diagram can be\ncovered by c paths. For a finite set T of transitions, we let P(c,T,\\phi)\ndenote the set of all T-labelled c-partial-orders satisfying \\phi. If N=(P,T)\nis a p/t-net we let P(N,c) denote the set of all c-partially-ordered runs of N.\nA (b, r)-bounded p/t-net is a b-bounded p/t-net in which each place appears\nrepeated at most r times. We solve the following problems:\n  1. Verification: given an MSO formula \\phi and a bounded p/t-net N determine\nwhether P(N,c)\\subseteq P(c,T,\\phi), whether P(c,T,\\phi)\\subseteq P(N,c), or\nwhether P(N,c)\\cap P(c,T,\\phi)=\\emptyset.\n  2. Synthesis from MSO Specifications: given an MSO formula \\phi, synthesize a\nsemantically minimal (b,r)-bounded p/t-net N satisfying P(c,T,\\phi)\\subseteq\nP(N, c).\n  3. Semantically Safest Subsystem: given an MSO formula \\phi defining a set of\nsafe partial orders, and a b-bounded p/t-net N, possibly containing unsafe\nbehaviors, synthesize the safest (b,r)-bounded p/t-net N' whose behavior lies\nin between P(N,c)\\cap P(c,T,\\phi) and P(N,c).\n  4. Behavioral Repair: given two MSO formulas \\phi and \\psi, and a b-bounded\np/t-net N, synthesize a semantically minimal (b,r)-bounded p/t net N' whose\nbehavior lies in between P(N,c) \\cap P(c,T,\\phi) and P(c,T,\\psi).\n  5. Synthesis from Contracts: given an MSO formula \\phi^yes specifying a set\nof good behaviors and an MSO formula \\phi^no specifying a set of bad behaviors,\nsynthesize a semantically minimal (b,r)-bounded p/t-net N such that\nP(c,T,\\phi^yes) \\subseteq P(N,c) but P(c,T,\\phi^no ) \\cap P(N,c)=\\emptyset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 23:50:39 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["Oliveira", "Mateus de Oliveira", ""]]}, {"id": "1402.2840", "submitter": "Mahsa Shirmohammadi", "authors": "Laurent Doyen, Thierry Massart, Mahsa Shirmohammadi", "title": "Robust Synchronization in Markov Decision Processes", "comments": "27 pages, 9 figures, 3 Tables. arXiv admin note: text overlap with\n  arXiv:1310.2935", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider synchronizing properties of Markov decision processes (MDP),\nviewed as generators of sequences of probability distributions over states. A\nprobability distribution is p-synchronizing if the probability mass is at least\np in some state, and a sequence of probability distributions is weakly\np-synchronizing, or strongly p-synchronizing if respectively infinitely many,\nor all but finitely many distributions in the sequence are p-synchronizing.\n  For each synchronizing mode, an MDP can be (i) sure winning if there is a\nstrategy that produces a 1-synchronizing sequence; (ii) almost-sure winning if\nthere is a strategy that produces a sequence that is, for all {\\epsilon} > 0, a\n(1-{\\epsilon})-synchronizing sequence; (iii) limit-sure winning if for all\n{\\epsilon} > 0, there is a strategy that produces a\n(1-{\\epsilon})-synchronizing sequence.\n  For each synchronizing and winning mode, we consider the problem of deciding\nwhether an MDP is winning, and we establish matching upper and lower complexity\nbounds of the problems, as well as the optimal memory requirement for winning\nstrategies: (a) for all winning modes, we show that the problems are\nPSPACE-complete for weakly synchronizing, and PTIME-complete for strongly\nsynchronizing; (b) we show that for weakly synchronizing, exponential memory is\nsufficient and may be necessary for sure winning, and infinite memory is\nnecessary for almost-sure winning; for strongly synchronizing, linear-size\nmemory is sufficient and may be necessary in all modes; (c) we show a\nrobustness result that the almost-sure and limit-sure winning modes coincide\nfor both weakly and strongly synchronizing.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 14:47:05 GMT"}, {"version": "v2", "created": "Fri, 18 Apr 2014 17:00:26 GMT"}, {"version": "v3", "created": "Mon, 30 Jun 2014 15:42:47 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Doyen", "Laurent", ""], ["Massart", "Thierry", ""], ["Shirmohammadi", "Mahsa", ""]]}, {"id": "1402.2908", "submitter": "Sylvain Schmitz", "authors": "Sylvain Schmitz and Philippe Schnoebelen", "title": "The Power of Well-Structured Systems", "comments": "Invited talk", "journal-ref": "Proceedings of Concur 2013, Lecture Notes in Computer Science vol.\n  8052, pp. 5--24", "doi": "10.1007/978-3-642-40184-8_2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well-structured systems, aka WSTSs, are computational models where the set of\npossible configurations is equipped with a well-quasi-ordering which is\ncompatible with the transition relation between configurations. This structure\nsupports generic decidability results that are important in verification and\nseveral other fields.\n  This paper recalls the basic theory underlying well-structured systems and\nshows how two classic decision algorithms can be formulated as an exhaustive\nsearch for some \"bad\" sequences. This lets us describe new powerful techniques\nfor the complexity analysis of WSTS algorithms. Recently, these techniques have\nbeen successful in precisely characterising the power, in a\ncomplexity-theoretical sense, of several important WSTS models like unreliable\nchannel systems, monotonic counter machines, or networks of timed systems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 17:35:34 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Schmitz", "Sylvain", ""], ["Schnoebelen", "Philippe", ""]]}, {"id": "1402.2948", "submitter": "Petr \\v{C}erm\\'ak", "authors": "Petr \\v{C}erm\\'ak, Alessio Lomuscio, Fabio Mogavero, Aniello Murano", "title": "MCMAS-SLK: A Model Checker for the Verification of Strategy Logic\n  Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MCMAS-SLK, a BDD-based model checker for the verification of\nsystems against specifications expressed in a novel, epistemic variant of\nstrategy logic. We give syntax and semantics of the specification language and\nintroduce a labelling algorithm for epistemic and strategy logic modalities. We\nprovide details of the checker which can also be used for synthesising agents'\nstrategies so that a specification is satisfied by the system. We evaluate the\nefficiency of the implementation by discussing the results obtained for the\ndining cryptographers protocol and a variant of the cake-cutting problem.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 18:21:25 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2014 11:05:29 GMT"}, {"version": "v3", "created": "Fri, 16 May 2014 09:47:01 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["\u010cerm\u00e1k", "Petr", ""], ["Lomuscio", "Alessio", ""], ["Mogavero", "Fabio", ""], ["Murano", "Aniello", ""]]}, {"id": "1402.2949", "submitter": "Aaron Karper", "authors": "Aaron Karper", "title": "A Programming Language Oriented Approach to Computability", "comments": "Bachelor thesis at the University of Bern, supervised by Professor\n  Dr. Thomas Strahm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The field of computability and complexity was, where computer science sprung\nfrom. Turing, Church, and Kleene all developed formalisms that demonstrated\nwhat they held \"intuitively computable\". The times change however and today's\n(aspiring) computer scientists are less proficient in building automata or\ncomposing functions and are much more native to the world of programming\nlanguages. This article will try to introduce typical concepts of computability\ntheory and complexity in a form more fitted for a modern developer. It is\nmostly based on \\cite{jones}, but takes input from other sources to provide\nexamples, additional information, etc.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 21:35:37 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Karper", "Aaron", ""]]}, {"id": "1402.2967", "submitter": "Jan K\\v{r}et\\'insk\\'y", "authors": "Tom\\'a\\v{s} Br\\'azdil and Krishnendu Chatterjee and Martin Chmel\\'ik\n  and Vojt\\v{e}ch Forejt and Jan K\\v{r}et\\'insk\\'y and Marta Kwiatkowska and\n  David Parker and Mateusz Ujma", "title": "Verification of Markov Decision Processes using Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general framework for applying machine-learning algorithms to\nthe verification of Markov decision processes (MDPs). The primary goal of these\ntechniques is to improve performance by avoiding an exhaustive exploration of\nthe state space. Our framework focuses on probabilistic reachability, which is\na core property for verification, and is illustrated through two distinct\ninstantiations. The first assumes that full knowledge of the MDP is available,\nand performs a heuristic-driven partial exploration of the model, yielding\nprecise lower and upper bounds on the required probability. The second tackles\nthe case where we may only sample the MDP, and yields probabilistic guarantees,\nagain in terms of both the lower and upper bounds, which provides efficient\nstopping criteria for the approximation. The latter is the first extension of\nstatistical model-checking for unbounded properties in MDPs. In contrast with\nother related approaches, we do not restrict our attention to time-bounded\n(finite-horizon) or discounted properties, nor assume any particular properties\nof the MDP. We also show how our techniques extend to LTL objectives. We\npresent experimental results showing the performance of our framework on\nseveral examples.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 15:33:35 GMT"}, {"version": "v2", "created": "Sun, 23 Mar 2014 19:48:47 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2015 13:59:12 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Chatterjee", "Krishnendu", ""], ["Chmel\u00edk", "Martin", ""], ["Forejt", "Vojt\u011bch", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Kwiatkowska", "Marta", ""], ["Parker", "David", ""], ["Ujma", "Mateusz", ""]]}, {"id": "1402.3011", "submitter": "Mikolas Janota", "authors": "Joao Marques-Silva and Mikolas Janota", "title": "Computing Minimal Sets on Propositional Formulae I: Problems &\n  Reductions", "comments": "This version contains some fixes in formatting and bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean Satisfiability (SAT) is arguably the archetypical NP-complete\ndecision problem. Progress in SAT solving algorithms has motivated an ever\nincreasing number of practical applications in recent years. However, many\npractical uses of SAT involve solving function as opposed to decision problems.\nConcrete examples include computing minimal unsatisfiable subsets, minimal\ncorrection subsets, prime implicates and implicants, minimal models, backbone\nliterals, and autarkies, among several others. In most cases, solving a\nfunction problem requires a number of adaptive or non-adaptive calls to a SAT\nsolver. Given the computational complexity of SAT, it is therefore important to\ndevelop algorithms that either require the smallest possible number of calls to\nthe SAT solver, or that involve simpler instances. This paper addresses a\nnumber of representative function problems defined on Boolean formulas, and\nshows that all these function problems can be reduced to a generic problem of\ncomputing a minimal set subject to a monotone predicate. This problem is\nreferred to as the Minimal Set over Monotone Predicate (MSMP) problem. This\nexercise provides new ways for solving well-known function problems, including\nprime implicates, minimal correction subsets, backbone literals, independent\nvariables and autarkies, among several others. Moreover, this exercise\nmotivates the development of more efficient algorithms for the MSMP problem.\nFinally the paper outlines a number of areas of future research related with\nextensions of the MSMP problem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 00:27:51 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2014 14:48:55 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Marques-Silva", "Joao", ""], ["Janota", "Mikolas", ""]]}, {"id": "1402.3066", "submitter": "Antonis Achilleos", "authors": "Antonis Achilleos", "title": "Complexity Jumps In Multiagent Justification Logic Under Interacting\n  Justifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Logic of Proofs, LP, and its successor, Justification Logic, is a\nrefinement of the modal logic approach to epistemology in which\nproofs/justifications are taken into account. In 2000 Kuznets showed that\nsatisfiability for LP is in the second level of the polynomial hierarchy, a\nresult which has been successfully repeated for all other one-agent\njustification logics whose complexity is known.\n  We introduce a family of multi-agent justification logics with interactions\nbetween the agents' justifications, by extending and generalizing the two-agent\nversions of the Logic of Proofs introduced by Yavorskaya in 2008. Known\nconcepts and tools from the single-agent justification setting are adjusted for\nthis multiple agent case. We present tableau rules and some preliminary\ncomplexity results. In several cases the satisfiability problem for these\nlogics remains in the second level of the polynomial hierarchy, while for\nothers it is PSPACE or EXP-hard. Furthermore, this problem becomes PSPACE-hard\neven for certain two-agent logics, while there are EXP-hard logics of three\nagents.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 09:00:38 GMT"}, {"version": "v2", "created": "Sat, 26 Apr 2014 04:12:50 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Achilleos", "Antonis", ""]]}, {"id": "1402.3277", "submitter": "Marc Zeitoun", "authors": "Thomas Place (Bordeaux University, France), Marc Zeitoun (Bordeaux\n  University, France)", "title": "Separating Regular Languages with First-Order Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 1 (March 9,\n  2016) lmcs:1628", "doi": "10.2168/LMCS-12(1:5)2016", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two languages, a separator is a third language that contains the first\none and is disjoint from the second one. We investigate the following decision\nproblem: given two regular input languages of finite words, decide whether\nthere exists a first-order definable separator. We prove that in order to\nanswer this question, sufficient information can be extracted from semigroups\nrecognizing the input languages, using a fixpoint computation. This yields an\nEXPTIME algorithm for checking first-order separability. Moreover, the\ncorrectness proof of this algorithm yields a stronger result, namely a\ndescription of a possible separator. Finally, we generalize this technique to\nanswer the same question for regular languages of infinite words.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 20:21:16 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2016 16:30:02 GMT"}, {"version": "v3", "created": "Tue, 8 Mar 2016 13:56:54 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Place", "Thomas", "", "Bordeaux University, France"], ["Zeitoun", "Marc", "", "Bordeaux\n  University, France"]]}, {"id": "1402.3314", "submitter": "Anca Muscholl", "authors": "Anca Muscholl (LaBRI), Igor Walukiewicz (LaBRI)", "title": "Distributed synthesis for acyclic architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributed synthesis problem is about constructing cor- rect distributed\nsystems, i.e., systems that satisfy a given specification. We consider a\nslightly more general problem of distributed control, where the goal is to\nrestrict the behavior of a given distributed system in order to satisfy the\nspecification. Our systems are finite state machines that communicate via\nrendez-vous (Zielonka automata). We show decidability of the synthesis problem\nfor all omega-regular local specifications, under the restriction that the\ncommunication graph of the system is acyclic. This result extends a previous\ndecidability result for a restricted form of local reachability specifications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 21:46:24 GMT"}, {"version": "v2", "created": "Wed, 16 Jul 2014 16:22:26 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Muscholl", "Anca", "", "LaBRI"], ["Walukiewicz", "Igor", "", "LaBRI"]]}, {"id": "1402.3388", "submitter": "Jan K\\v{r}et\\'insk\\'y", "authors": "Javier Esparza and Jan K\\v{r}et\\'insk\\'y", "title": "From LTL to Deterministic Automata: A Safraless Compositional Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm to construct a deterministic Rabin automaton for\nan LTL formula $\\varphi$. The automaton is the product of a master automaton\nand an array of slave automata, one for each $G$-subformula of $\\varphi$. The\nslave automaton for $G\\psi$ is in charge of recognizing whether $FG\\psi$ holds.\nAs opposed to standard determinization procedures, the states of all our\nautomata have a clear logical structure, which allows to apply various\noptimizations. Our construction subsumes former algorithms for fragments of\nLTL. Experimental results show improvement in the sizes of the resulting\nautomata compared to existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 07:27:09 GMT"}, {"version": "v2", "created": "Fri, 6 Jun 2014 07:56:35 GMT"}, {"version": "v3", "created": "Wed, 24 Sep 2014 21:21:14 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Esparza", "Javier", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""]]}, {"id": "1402.3578", "submitter": "Cezary Kaliszyk", "authors": "Cezary Kaliszyk and Josef Urban", "title": "Learning-assisted Theorem Proving with Millions of Lemmas", "comments": "journal version of arXiv:1310.2797 (which was submitted to LPAR\n  conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large formal mathematical libraries consist of millions of atomic inference\nsteps that give rise to a corresponding number of proved statements (lemmas).\nAnalogously to the informal mathematical practice, only a tiny fraction of such\nstatements is named and re-used in later proofs by formal mathematicians. In\nthis work, we suggest and implement criteria defining the estimated usefulness\nof the HOL Light lemmas for proving further theorems. We use these criteria to\nmine the large inference graph of the lemmas in the HOL Light and Flyspeck\nlibraries, adding up to millions of the best lemmas to the pool of statements\nthat can be re-used in later proofs. We show that in combination with\nlearning-based relevance filtering, such methods significantly strengthen\nautomated theorem proving of new conjectures over large formal mathematical\nlibraries such as Flyspeck.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 03:08:02 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1402.3690", "submitter": "Jonathan Heras", "authors": "J\\'onathan Heras and Ekaterina Komendantskaya and Martin Schmidt", "title": "(Co)recursion in Logic Programming: Lazy vs Eager", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CoAlgebraic Logic Programming (CoALP) is a dialect of Logic Programming\ndesigned to bring a more precise compile-time and run-time analysis of\ntermination and productivity for recursive and corecursive functions in Logic\nProgramming. Its second goal is to introduce guarded lazy (co)recursion akin to\nfunctional theorem provers into logic programming. In this paper, we explain\nlazy features of CoALP, and compare them with the loop-analysis and eager\nexecution in Coinductive Logic Programming (CoLP). We conclude by outlining the\nfuture directions in developing the guarded (co)recursion in logic programming.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2014 13:28:34 GMT"}, {"version": "v2", "created": "Thu, 15 May 2014 21:25:25 GMT"}, {"version": "v3", "created": "Mon, 19 May 2014 08:07:40 GMT"}, {"version": "v4", "created": "Tue, 20 May 2014 07:46:48 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Heras", "J\u00f3nathan", ""], ["Komendantskaya", "Ekaterina", ""], ["Schmidt", "Martin", ""]]}, {"id": "1402.4062", "submitter": "Alexandra Silva", "authors": "Filippo Bonchi and Stefan Milius and Alexandra Silva and Fabio Zanasi", "title": "How to Kill Epsilons with a Dagger -- A Coalgebraic Take on Systems with\n  Algebraic Label Structure", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2015.03.024", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an abstract framework for modeling state-based systems with\ninternal behavior as e.g. given by silent or $\\epsilon$-transitions. Our\napproach employs monads with a parametrized fixpoint operator $\\dagger$ to give\na semantics to those systems and implement a sound procedure of abstraction of\nthe internal transitions, whose labels are seen as the unit of a free monoid.\nMore broadly, our approach extends the standard coalgebraic framework for\nstate-based systems by taking into account the algebraic structure of the\nlabels of their transitions. This allows to consider a wide range of other\nexamples, including Mazurkiewicz traces for concurrent systems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 17:09:51 GMT"}, {"version": "v2", "created": "Sat, 1 Mar 2014 08:59:48 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Bonchi", "Filippo", ""], ["Milius", "Stefan", ""], ["Silva", "Alexandra", ""], ["Zanasi", "Fabio", ""]]}, {"id": "1402.4172", "submitter": "Wenyan Xu", "authors": "Wenyan Xu", "title": "A propositional system induced by Japaridze's approach to IF logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cirquent calculus is a new proof-theoretic and semantic approach introduced\nfor the needs of computability logic by G.Japaridze, who also showed that,\nthrough cirquent calculus, one can capture, refine and generalize\nindependence-friendly (IF) logic. Specifically, the approach allows us to\naccount for independence from propositional connectives in the same spirit as\nthe traditional IF logic accounts for independence from quantifiers.\nJaparidze's treatment of IF logic, however, was purely semantical, and no\ndeductive system was proposed. The present paper constructs a formal system\nsound and complete w.r.t. the propositional fragment of Japaridze's\ncirquent-based semantics for IF logic. Such a system can thus be considered an\naxiomatization of purely propositional IF logic in its full generality.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 22:54:14 GMT"}, {"version": "v2", "created": "Fri, 23 May 2014 14:44:05 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Xu", "Wenyan", ""]]}, {"id": "1402.4303", "submitter": "Christian Geist", "authors": "Christian Geist", "title": "Finding Preference Profiles of Condorcet Dimension $k$ via SAT", "comments": "Corrected typos, updated references, and added conclusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Condorcet winning sets are a set-valued generalization of the well-known\nconcept of a Condorcet winner. As supersets of Condorcet winning sets are\nalways Condorcet winning sets themselves, an interesting property of preference\nprofiles is the size of the smallest Condorcet winning set they admit. This\nsmallest size is called the Condorcet dimension of a preference profile. Since\nlittle is known about profiles that have a certain Condorcet dimension, we show\nin this paper how the problem of finding a preference profile that has a given\nCondorcet dimension can be encoded as a satisfiability problem and solved by a\nSAT solver. Initial results include a minimal example of a preference profile\nof Condorcet dimension 3, improving previously known examples both in terms of\nthe number of agents as well as alternatives. Due to the high complexity of\nsuch problems it remains open whether a preference profile of Condorcet\ndimension 4 exists.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 11:31:08 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2016 17:01:37 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Geist", "Christian", ""]]}, {"id": "1402.4327", "submitter": "Marc Bagnol", "authors": "Cl\\'ement Aubert, Marc Bagnol", "title": "Unification and Logarithmic Space", "comments": null, "journal-ref": "International Conference on Rewriting Techniques and Applications\n  RTA 2014: Rewriting and Typed Lambda Calculi pp 77-9", "doi": "10.1007/978-3-319-08918-8_6", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present an algebraic characterization of the complexity classes Logspace\nand NLogspace, using an algebra with a composition law based on unification.\nThis new bridge between unification and complexity classes is inspired from\nproof theory and more specifically linear logic and Geometry of Interaction.\n  We show how unification can be used to build a model of computation by means\nof specific subalgebras associated to finite permutations groups. We then prove\nthat whether an observation (the algebraic counterpart of a program) accepts a\nword can be decided within logarithmic space. We also show that the\nconstruction can naturally represent pointer machines, an intuitive way of\nunderstanding logarithmic space computing.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 13:32:50 GMT"}, {"version": "v2", "created": "Mon, 24 Mar 2014 23:20:13 GMT"}, {"version": "v3", "created": "Thu, 27 Mar 2014 11:13:25 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Aubert", "Cl\u00e9ment", ""], ["Bagnol", "Marc", ""]]}, {"id": "1402.4338", "submitter": "Gabriel Istrate", "authors": "Gabriel Istrate and Adrian Cr\\u{a}ciun", "title": "Proof Complexity and the Kneser-Lov\\'asz Theorem", "comments": null, "journal-ref": "Proceedings of the 17th International Conference on Theory and\n  Applications of Satisfiability Testing (SAT'14), vol. 8561, 2014", "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the proof complexity of a class of propositional formulas\nexpressing a combinatorial principle known as the Kneser-Lov\\'{a}sz Theorem.\nThis is a family of propositional tautologies, indexed by an nonnegative\ninteger parameter $k$ that generalizes the Pigeonhole Principle (obtained for\n$k=1$).\n  We show, for all fixed $k$, $2^{\\Omega(n)}$ lower bounds on resolution\ncomplexity and exponential lower bounds for bounded depth Frege proofs. These\nresults hold even for the more restricted class of formulas encoding\nSchrijver's strenghtening of the Kneser-Lov\\'{a}sz Theorem. On the other hand\nfor the cases $k=2,3$ (for which combinatorial proofs of the Kneser-Lov\\'{a}sz\nTheorem are known) we give polynomial size Frege ($k=2$), respectively extended\nFrege ($k=3$) proofs. The paper concludes with a brief announcement of the\nresults (presented in subsequent work) on the proof complexity of the general\ncase of the Kneser-Lov\\'{a}sz theorem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 13:58:07 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 14:52:06 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Istrate", "Gabriel", ""], ["Cr\u0103ciun", "Adrian", ""]]}, {"id": "1402.4413", "submitter": "Marijn Heule", "authors": "Shai Haim and Marijn Heule", "title": "Towards Ultra Rapid Restarts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe a trend regarding restart strategies used in SAT solvers. A few\nyears ago, most state-of-the-art solvers restarted on average after a few\nthousands of backtracks. Currently, restarting after a dozen backtracks results\nin much better performance. The main reason for this trend is that heuristics\nand data structures have become more restart-friendly. We expect further\ncontinuation of this trend, so future SAT solvers will restart even more\nrapidly. Additionally, we present experimental results to support our\nobservations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 17:39:39 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Haim", "Shai", ""], ["Heule", "Marijn", ""]]}, {"id": "1402.4414", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic and Bertfried Fauser", "title": "Smooth coalgebra: testing vector analysis", "comments": "45 pages, 25 figures; to appear in Math. Struct. in Comp. Sci.; this\n  version: affiliations updated, typos corrected", "journal-ref": null, "doi": "10.1017/S0960129515000511", "report-no": null, "categories": "math.CT cs.LO math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processes are often viewed as coalgebras, with the structure maps specifying\nthe state transitions. In the simplest case, the state spaces are discrete, and\nthe structure map simply takes each state to the next states. But the\ncoalgebraic view is also quite effective for studying processes over structured\nstate spaces, e.g. measurable, or continuous. In the present paper we consider\ncoalgebras over manifolds. This means that the captured processes evolve over\nstate spaces that are not just continuous, but also locally homeomorphic to\nBanach spaces, and thus carry a differential structure. Both dynamical systems\nand differential forms arise as coalgebras over such state spaces, for two\ndifferent endofunctors over manifolds. A duality induced by these two\nendofunctors provides a formal underpinning for the informal geometric\nintuitions linking differential forms and dynamical systems in the various\npractical applications, e.g. in physics. This joint functorial reconstruction\nof tangent bundles and cotangent bundles uncovers the universal properties and\na high level view of these fundamental structures, which are implemented rather\nintricately in their standard form. The succinct coalgebraic presentation\nprovides unexpected insights even about the situations as familiar as Newton's\nlaws.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 17:40:05 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 17:30:33 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Pavlovic", "Dusko", ""], ["Fauser", "Bertfried", ""]]}, {"id": "1402.4741", "submitter": "Julio Lemos", "authors": "Julio Lemos", "title": "A normative account of defeasible and probabilistic inference", "comments": null, "journal-ref": "Intuitio 6 (2), 2013, pp. 211-219", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide more evidence for the contention that logical\nconsequence should be understood in normative terms. Hartry Field and John\nMacFarlane covered the classical case. We extend their work, examining what it\nmeans for an agent to be obliged to infer a conclusion when faced with\nuncertain information or reasoning within a non-monotonic, defeasible, logical\nframework (which allows e. g. for inference to be drawn from premises\nconsidered true unless evidence to the contrary is presented).\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 17:52:00 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Lemos", "Julio", ""]]}, {"id": "1402.4827", "submitter": "Rui Soares Barbosa", "authors": "Shane Mansfield and Rui Soares Barbosa", "title": "Extendability in the Sheaf-theoretic Approach: Construction of Bell\n  Models from Kochen-Specker Models", "comments": "18 pages, presented at Quantum Physics and Logic X - 2013 (ICFO,\n  Barcelona), submitted to Electronic Proceedings in Theoretical Computer\n  Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extendability of an empirical model was shown by Abramsky & Brandenburger to\ncorrespond in a unified manner to both locality and non-contextuality. We\ndevelop their approach by presenting a refinement of the notion of\nextendability that can also be useful in characterising the properties of\nsub-models. The refinement is found to have another useful application: it is\nshown that a particular canonical extension, when well-defined, may be used for\nthe construction of Bell-type models from models of more general kinds in such\na way that the constructed model is equivalent to the original in terms of\nnon-locality/contextuality. This is important since on practical and\nfoundational levels, the notion of locality in Bell-type models can more easily\nbe motivated than the corresponding general notion of contextuality. We\nconsider examples of Bell-type models generated from some standard examples of\ncontextual models, including an entire class of Kochen-Specker-like models.\nThis exposes an intriguing relationship between the simplest possible\ncontextual model (the contextual triangle) and Popescu-Rohrlich no-signalling\ncorrelations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 21:09:34 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Mansfield", "Shane", ""], ["Barbosa", "Rui Soares", ""]]}, {"id": "1402.4950", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "On algorithmic equivalence of instruction sequences for computing bit\n  string functions", "comments": "27 pages, the preliminaries have textual overlaps with the\n  preliminaries in arXiv:1308.0219 [cs.PL], arXiv:1312.1529 [cs.PL], and\n  arXiv:1312.1812 [cs.PL]; 27 pages, three paragraphs about Milner's\n  algorithmic equivalence hypothesis added to concluding remarks; 26 pages,\n  several minor improvements of the presentation made", "journal-ref": "Fundamenta Informaticae, 138(4):411--434, 2015", "doi": "10.3233/FI-2015-1219", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every partial function from bit strings of a given length to bit strings of a\npossibly different given length can be computed by a finite instruction\nsequence that contains only instructions to set and get the content of Boolean\nregisters, forward jump instructions, and a termination instruction. We look\nfor an equivalence relation on instruction sequences of this kind that captures\nto a reasonable degree the intuitive notion that two instruction sequences\nexpress the same algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 10:21:52 GMT"}, {"version": "v2", "created": "Sun, 6 Apr 2014 15:02:58 GMT"}, {"version": "v3", "created": "Thu, 5 Feb 2015 15:23:34 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1402.5172", "submitter": "Mingsheng Ying", "authors": "Mingsheng Ying, Nengkun Yu and Yuan Feng", "title": "Alternation in Quantum Programming: From Superposition of Data to\n  Superposition of Programs", "comments": "arXiv admin note: substantial text overlap with arXiv:1209.4379", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extract a novel quantum programming paradigm - superposition of programs -\nfrom the design idea of a popular class of quantum algorithms, namely quantum\nwalk-based algorithms. The generality of this paradigm is guaranteed by the\nuniversality of quantum walks as a computational model. A new quantum\nprogramming language QGCL is then proposed to support the paradigm of\nsuperposition of programs. This language can be seen as a quantum extension of\nDijkstra's GCL (Guarded Command Language). Surprisingly, alternation in GCL\nsplits into two different notions in the quantum setting: classical alternation\n(of quantum programs) and quantum alternation, with the latter being introduced\nin QGCL for the first time. Quantum alternation is the key program construct\nfor realizing the paradigm of superposition of programs.\n  The denotational semantics of QGCL are defined by introducing a new\nmathematical tool called the guarded composition of operator-valued functions.\nThen the weakest precondition semantics of QGCL can straightforwardly derived.\nAnother very useful program construct in realizing the quantum programming\nparadigm of superposition of programs, called quantum choice, can be easily\ndefined in terms of quantum alternation. The relation between quantum choices\nand probabilistic choices is clarified through defining the notion of local\nvariables. We derive a family of algebraic laws for QGCL programs that can be\nused in program verification, transformations and compilation. The expressive\npower of QGCL is illustrated by several examples where various variants and\ngeneralizations of quantum walks are conveniently expressed using quantum\nalternation and quantum choice. We believe that quantum programming with\nquantum alternation and choice will play an important role in further\nexploiting the power of quantum computing.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 23:35:58 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Ying", "Mingsheng", ""], ["Yu", "Nengkun", ""], ["Feng", "Yuan", ""]]}, {"id": "1402.5365", "submitter": "Marco Bernardo", "authors": "Marco Bernardo (University of Urbino), Rocco De Nicola (IMT Lucca),\n  Michele Loreti (University of Firenze)", "title": "Revisiting Trace and Testing Equivalences for Nondeterministic and\n  Probabilistic Processes", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 1 (March 3,\n  2014) lmcs:1137", "doi": "10.2168/LMCS-10(1:16)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two of the most studied extensions of trace and testing equivalences to\nnondeterministic and probabilistic processes induce distinctions that have been\nquestioned and lack properties that are desirable. Probabilistic\ntrace-distribution equivalence differentiates systems that can perform the same\nset of traces with the same probabilities, and is not a congruence for parallel\ncomposition. Probabilistic testing equivalence, which relies only on extremal\nsuccess probabilities, is backward compatible with testing equivalences for\nrestricted classes of processes, such as fully nondeterministic processes or\ngenerative/reactive probabilistic processes, only if specific sets of tests are\nadmitted. In this paper, new versions of probabilistic trace and testing\nequivalences are presented for the general class of nondeterministic and\nprobabilistic processes. The new trace equivalence is coarser because it\ncompares execution probabilities of single traces instead of entire trace\ndistributions, and turns out to be compositional. The new testing equivalence\nrequires matching all resolutions of nondeterminism on the basis of their\nsuccess probabilities, rather than comparing only extremal success\nprobabilities, and considers success probabilities in a trace-by-trace fashion,\nrather than cumulatively on entire resolutions. It is fully backward compatible\nwith testing equivalences for restricted classes of processes; as a\nconsequence, the trace-by-trace approach uniformly captures the standard\nprobabilistic testing equivalences for generative and reactive probabilistic\nprocesses. The paper discusses in full details the new equivalences and\nprovides a simple spectrum that relates them with existing ones in the setting\nof nondeterministic and probabilistic processes.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 17:31:36 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2014 20:36:22 GMT"}, {"version": "v3", "created": "Tue, 4 Mar 2014 09:12:37 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bernardo", "Marco", "", "University of Urbino"], ["De Nicola", "Rocco", "", "IMT Lucca"], ["Loreti", "Michele", "", "University of Firenze"]]}, {"id": "1402.5436", "submitter": "Alessandro Provetti", "authors": "Gianpaolo Brignoli, Stefania Costantini, Ottavio D'Antona, Alessandro\n  Provetti", "title": "Characterizing and computing stable models of logic programs: The\n  non-stratified case", "comments": "Proceedings of the Conference on Information Technology. Bhubaneswar,\n  India, 1999. https://sites.google.com/site/citconference/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stable Logic Programming (SLP) is an emergent, alternative style of logic\nprogramming: each solution to a problem is represented by a stable model of a\ndeductive database/function-free logic program encoding the problem itself.\nSeveral implementations now exist for stable logic programming, and their\nperformance is rapidly improving. To make SLP generally applicable, it should\nbe possible to check for consistency (i.e., existence of stable models) of the\ninput program before attempting to answer queries. In the literature, only\nrather strong sufficient conditions have been proposed for consistency, e.g.,\nstratification. This paper extends these results in several directions. First,\nthe syntactic features of programs, viz. cyclic negative dependencies,\naffecting the existence of stable models are characterized, and their relevance\nis discussed. Next, a new graph representation of logic programs, the Extended\nDependency Graph (EDG), is introduced, which conveys enough information for\nreasoning about stable models (while the traditional Dependency Graph does\nnot). Finally, we show that the problem of the existence of stable models can\nbe reformulated in terms of coloring of the EDG.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 22:17:39 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Brignoli", "Gianpaolo", ""], ["Costantini", "Stefania", ""], ["D'Antona", "Ottavio", ""], ["Provetti", "Alessandro", ""]]}, {"id": "1402.5495", "submitter": "Micha{\\l} Stronkowski", "authors": "Wojciech Dzik and Michal M. Stronkowski", "title": "Almost structural completeness; an algebraic approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.RA", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A deductive system is structurally complete if its admissible inference rules\nare derivable. For several important systems, like modal logic S5, failure of\nstructural completeness is caused only by the underivability of passive rules,\ni.e. rules that can not be applied to theorems of the system. Neglecting\npassive rules leads to the notion of almost structural completeness, that\nmeans, derivablity of admissible non-passive rules. Almost structural\ncompleteness for quasivarieties and varieties of general algebras is\ninvestigated here by purely algebraic means. The results apply to all\nalgebraizable deductive systems.\n  Firstly, various characterizations of almost structurally complete\nquasivarieties are presented. Two of them are general: expressed with finitely\npresented algebras, and with subdirectly irreducible algebras. One is\nrestricted to quasivarieties with finite model property and equationally\ndefinable principal relative congruences, where the condition is verifiable on\nfinite subdirectly irreducible algebras.\n  Secondly, examples of almost structurally complete varieties are provided\nParticular emphasis is put on varieties of closure algebras, that are known to\nconstitute adequate semantics for normal extensions of S4 modal logic. A\ncertain infinite family of such almost structurally complete, but not\nstructurally complete, varieties is constructed. Every variety from this family\nhas a finitely presented unifiable algebra which does not embed into any free\nalgebra for this variety. Hence unification in it is not unitary. This shows\nthat almost structural completeness is strictly weaker than projective\nunification for varieties of closure algebras.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2014 08:42:03 GMT"}, {"version": "v2", "created": "Fri, 22 Aug 2014 20:51:18 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Dzik", "Wojciech", ""], ["Stronkowski", "Michal M.", ""]]}, {"id": "1402.5687", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic", "title": "Monoidal computer II: Normal complexity by string diagrams", "comments": "11 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Monoidal Computer I, we introduced a categorical model of computation\nwhere the formal reasoning about computability was supported by the simple and\npopular diagrammatic language of string diagrams. In the present paper, we\nrefine and extend that model of computation to support a formal complexity\ntheory as well. This formalization brings to the foreground the concept of\nnormal complexity measures, which allow decompositions akin to Kleene's normal\nform. Such measures turn out to be just those where evaluating the complexity\nof a program does not require substantially more resources than evaluating the\nprogram itself. The usual time and space complexity are thus normal measures,\nwhereas the average and the randomized complexity measures are not. While the\nmeasures that are not normal provide important design time information about\nalgorithms, and for theoretical analyses, normal measures can also be used at\nrun time, as practical tools of computation, e.g. to set the bounds for\nhypothesis testing, inductive inference and algorithmic learning.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 22:59:30 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Pavlovic", "Dusko", ""]]}, {"id": "1402.5922", "submitter": "Alexander Kurz", "authors": "Adriana Balan (University Politehnica of Bucharest), Alexander Kurz\n  (University of Leicester), Ji\\v{r}\\'i Velebil (Faculty of Electrical\n  Engineering, Czech Technical University in Prague, Czech Republic)", "title": "Positive fragments of coalgebraic logics", "comments": "51 pages; accepted for publication; expanded and improved version of\n  the previous submission. Proposition 4.15 is new; Section 6 was rewritten in\n  view of new results (theorem 6.9, proposition 6.14, paragraphs A-D);\n  references added", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  22, 2015) lmcs:1594", "doi": "10.2168/LMCS-11(3:18)2015", "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive modal logic was introduced in an influential 1995 paper of Dunn as\nthe positive fragment of standard modal logic. His completeness result consists\nof an axiomatization that derives all modal formulas that are valid on all\nKripke frames and are built only from atomic propositions, conjunction,\ndisjunction, box and diamond. In this paper, we provide a coalgebraic analysis\nof this theorem, which not only gives a conceptual proof based on duality\ntheory, but also generalizes Dunn's result from Kripke frames to coalgebras for\nweak-pullback preserving functors. To facilitate this analysis we prove a\nnumber of category theoretic results on functors on the categories\n$\\mathsf{Set}$ of sets and $\\mathsf{Pos}$ of posets: Every functor\n$\\mathsf{Set} \\to \\mathsf{Pos}$ has a $\\mathsf{Pos}$-enriched left Kan\nextension $\\mathsf{Pos} \\to \\mathsf{Pos}$. Functors arising in this way are\nsaid to have a presentation in discrete arities. In the case that $\\mathsf{Set}\n\\to \\mathsf{Pos}$ is actually $\\mathsf{Set}$-valued, we call the corresponding\nleft Kan extension $\\mathsf{Pos} \\to \\mathsf{Pos}$ its posetification. A\n$\\mathsf{Set}$-functor preserves weak pullbacks if and only if its\nposetification preserves exact squares. A $\\mathsf{Pos}$-functor with a\npresentation in discrete arities preserves surjections. The inclusion\n$\\mathsf{Set} \\to \\mathsf{Pos}$ is dense. A functor $\\mathsf{Pos} \\to\n\\mathsf{Pos}$ has a presentation in discrete arities if and only if it\npreserves coinserters of `truncated nerves of posets'. A functor $\\mathsf{Pos}\n\\to \\mathsf{Pos}$ is a posetification if and only if it preserves coinserters\nof truncated nerves of posets and discrete posets. A locally monotone\nendofunctor of an ordered variety has a presentation by monotone operations and\nequations if and only if it preserves $\\mathsf{Pos}$-enriched sifted colimits.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 19:20:00 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2015 18:45:51 GMT"}, {"version": "v3", "created": "Mon, 18 May 2015 16:02:33 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2015 18:46:32 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Balan", "Adriana", "", "University Politehnica of Bucharest"], ["Kurz", "Alexander", "", "University of Leicester"], ["Velebil", "Ji\u0159\u00ed", "", "Faculty of Electrical\n  Engineering, Czech Technical University in Prague, Czech Republic"]]}, {"id": "1402.6067", "submitter": "Zhilin Wu", "authors": "Zhilin Wu", "title": "Regular path queries on graphs with data: A rigid approach", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular path queries (RPQ) is a classical navigational query formalism for\ngraph databases to specify constraints on labeled paths. Recently, RPQs have\nbeen extended by Libkin and Vrgo$\\rm \\check{c}$ to incorporate data value\ncomparisons among different nodes on paths, called regular path queries with\ndata (RDPQ). It has been shown that the evaluation problem of RDPQs is\nPSPACE-complete and NLOGSPACE-complete in data complexity. On the other hand,\nthe containment problem of RDPQs is in general undecidable. In this paper, we\npropose a novel approach to extend regular path queries with data value\ncomparisons, called rigid regular path queries with data (RRDPQ). The main\ningredient of this approach is an automata model called nondeterministic rigid\nregister automata (NRRA), in which the data value comparisons are \\emph{rigid},\nin the sense that if the data value in the current position $x$ is compared to\na data value in some other position $y$, then by only using the labels (but not\ndata values), the position $y$ can be uniquely determined from $x$. We show\nthat NRRAs are robust in the sense that nondeterministic, deterministic and\ntwo-way variant of NRRAs, as well as an extension of regular expressions, are\nall of the same expressivity. We then argue that the expressive power of RDPQs\nare reasonable by demonstrating that for every graph database, there is a\nlocalized transformation of the graph database so that every RDPQ in the\noriginal graph database can be turned into an equivalent RRDPQ over the\ntransformed one. Finally, we investigate the computational properties of RRDPQs\nand conjunctive RRDPQs (CRRDPQ). In particular, we show that the containment of\nCRRDPQs (and RRDPQs) can be decided in 2EXPSPACE.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 06:54:08 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Wu", "Zhilin", ""]]}, {"id": "1402.6281", "submitter": "Tomasz Brengos", "authors": "Tomasz Brengos", "title": "On coalgebras with internal moves", "comments": "Article: 23 pages, Appendix: 3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the first part of the paper we recall the coalgebraic approach to handling\nthe so-called invisible transitions that appear in different state-based\nsystems semantics. We claim that these transitions are always part of the unit\nof a certain monad. Hence, coalgebras with internal moves are exactly\ncoalgebras over a monadic type. The rest of the paper is devoted to supporting\nour claim by studying two important behavioural equivalences for state-based\nsystems with internal moves, namely: weak bisimulation and trace semantics.\n  We continue our research on weak bisimulations for coalgebras over order\nenriched monads. The key notions used in this paper and proposed by us in our\nprevious work are the notions of an order saturation monad and a saturator. A\nsaturator operator can be intuitively understood as a reflexive, transitive\nclosure operator. There are two approaches towards defining saturators for\ncoalgebras with internal moves. Here, we give necessary conditions for them to\nyield the same notion of weak bisimulation.\n  Finally, we propose a definition of trace semantics for coalgebras with\nsilent moves via a uniform fixed point operator. We compare strong and weak\nbisimilation together with trace semantics for coalgebras with internal steps.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 19:12:55 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Brengos", "Tomasz", ""]]}, {"id": "1402.6459", "submitter": "Emmanuel Beffara", "authors": "Emmanuel Beffara (I2M)", "title": "A proof-theoretic view on scheduling in concurrency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper elaborates on a new approach of the question of the\nproof-theoretic study of concurrent interaction called \"proofs as schedules\".\nObserving that proof theory is well suited to the description of confluent\nsystems while concurrency has non-determinism as a fundamental feature, we\ndevelop a correspondence where proofs provide what is needed to make concurrent\nsystems confluent, namely scheduling. In our logical system, processes and\nschedulers appear explicitly as proofs in different fragments of the proof\nlanguage and cut elimination between them does correspond to execution of a\nconcurrent system. This separation of roles suggests new insights for the\ndenotational semantics of processes and new methods for the translation of\npi-calculi into prefix-less formalisms (like solos) as the operational\ncounterpart of translations between proof systems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 09:09:41 GMT"}, {"version": "v2", "created": "Sun, 20 Apr 2014 19:29:12 GMT"}, {"version": "v3", "created": "Sun, 3 Aug 2014 19:29:31 GMT"}, {"version": "v4", "created": "Sat, 13 Sep 2014 12:38:44 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Beffara", "Emmanuel", "", "I2M"]]}, {"id": "1402.6610", "submitter": "EPTCS", "authors": "Lukas Holik, Lorenzo Clemente", "title": "Proceedings 15th International Workshop on Verification of\n  Infinite-State Systems", "comments": null, "journal-ref": "EPTCS 140, 2014", "doi": "10.4204/EPTCS.140", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of Infinity'13, the 15th International\nWorkshop on Verification of Infinite-State Systems, which was held in Hanoi,\nVietnam on the 14th of October 2013 as a satellite event of ATVA'13. The aim of\nthe INFINITY workshop is to provide a forum for researchers interested in the\ndevelopment of formal methods and algorithmic techniques for the analysis of\nsystems with infinitely many states, and their application in automated\nverification of complex software and hardware systems.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 22:05:42 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["Holik", "Lukas", ""], ["Clemente", "Lorenzo", ""]]}, {"id": "1402.6782", "submitter": "EPTCS", "authors": "Johann Schuster (University of the Federal Armed Forces Munich\n  Neubiberg, Germany), Markus Siegle (University of the Federal Armed Forces\n  Munich Neubiberg, Germany)", "title": "Lattice structures for bisimilar Probabilistic Automata", "comments": "In Proceedings INFINITY 2013, arXiv:1402.6610", "journal-ref": "EPTCS 140, 2014, pp. 1-15", "doi": "10.4204/EPTCS.140.1", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper shows that there is a deep structure on certain sets of bisimilar\nProbabilistic Automata (PA). The key prerequisite for these structures is a\nnotion of compactness of PA. It is shown that compact bisimilar PA form\nlattices. These results are then used in order to establish normal forms not\nonly for finite automata, but also for infinite automata, as long as they are\ncompact.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 03:44:41 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Schuster", "Johann", "", "University of the Federal Armed Forces Munich\n  Neubiberg, Germany"], ["Siegle", "Markus", "", "University of the Federal Armed Forces\n  Munich Neubiberg, Germany"]]}, {"id": "1402.6783", "submitter": "EPTCS", "authors": "Yu-Fang Chen (Academia Sinica, Taiwan), Bow-Yaw Wang (Academia Sinica,\n  Taiwan), Di-De Yen (Academia Sinica, Taiwan)", "title": "A Finite Exact Representation of Register Automata Configurations", "comments": "In Proceedings INFINITY 2013, arXiv:1402.6610", "journal-ref": "EPTCS 140, 2014, pp. 16-34", "doi": "10.4204/EPTCS.140.2", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A register automaton is a finite automaton with finitely many registers\nranging from an infinite alphabet. Since the valuations of registers are\ninfinite, there are infinitely many configurations. We describe a technique to\nclassify infinite register automata configurations into finitely many exact\nrepresentative configurations. Using the finitary representation, we give an\nalgorithm solving the reachability problem for register automata. We moreover\ndefine a computation tree logic for register automata and solve its model\nchecking problem.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 03:44:51 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Chen", "Yu-Fang", "", "Academia Sinica, Taiwan"], ["Wang", "Bow-Yaw", "", "Academia Sinica,\n  Taiwan"], ["Yen", "Di-De", "", "Academia Sinica, Taiwan"]]}, {"id": "1402.6799", "submitter": "Richard Garner", "authors": "Richard Garner", "title": "Combinatorial structure of type dependency", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an account of the basic combinatorial structure underlying the notion\nof type dependency. We do so by considering the category of all dependent\nsequent calculi, and exhibiting it as the category of algebras for a monad on a\npresheaf category. The objects of the presheaf category encode the basic\njudgements of a dependent sequent calculus, while the action of the monad\nencodes the deduction rules; so by giving an explicit description of the monad,\nwe obtain an explicit account of the combinatorics of type dependency. We find\nthat this combinatorics is controlled by a particular kind of decorated ordered\ntree, familiar from computer science and from innocent game semantics.\nFurthermore, we find that the monad at issue is of a particularly well-behaved\nkind: it is local right adjoint in the sense of Street--Weber. In future work,\nwe will use this fact to describe nerves for dependent type theories, and to\nstudy the coherence problem for dependent type theory using the tools of\ntwo-dimensional monad theory.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 06:30:35 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Garner", "Richard", ""]]}, {"id": "1402.6804", "submitter": "Tomer Kotek", "authors": "Tomer Kotek and Mantas Simkus and Helmut Veith and Florian Zuleger", "title": "Extending ALCQIO with reachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a description logic ALCQIO_{b,Re} which adds reachability\nassertions to ALCQIO, a sub-logic of the two-variable fragment of first order\nlogic with counting quantifiers. ALCQIO_{b,Re} is well-suited for applications\nin software verification and shape analysis. Shape analysis requires expressive\nlogics which can express reachability and have good computational properties.\nWe show that ALCQIO_{b,Re} can describe complex data structures with a high\ndegree of sharing and allows compositions such as list of trees.\n  We show that the finite satisfiability and implication problems of\nALCQIO_{b,Re}-formulae are polynomial-time reducible to finite satisfiability\nof ALCQIO-formulae. As a consequence, we get that finite satisfiability and\nfinite implication in ALCQIO_{b,Re} are NEXPTIME-complete. Description logics\nwith transitive closure constructors have been studied before, but\nALCQIO_{b,Re} is the first description logic that remains decidable on finite\nstructures while allowing at the same time nominals, inverse roles, counting\nquantifiers and reachability assertions,\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 06:52:18 GMT"}, {"version": "v2", "created": "Wed, 9 Jul 2014 10:57:34 GMT"}], "update_date": "2014-07-10", "authors_parsed": [["Kotek", "Tomer", ""], ["Simkus", "Mantas", ""], ["Veith", "Helmut", ""], ["Zuleger", "Florian", ""]]}, {"id": "1402.6889", "submitter": "Broes De Cat", "authors": "Broes De Cat, Marc Denecker, Peter Stuckey, Maurice Bruynooghe", "title": "Lazy Model Expansion: Interleaving Grounding with Search", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research, feb 2015, volume 52,\n  pages 235-286", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding satisfying assignments for the variables involved in a set of\nconstraints can be cast as a (bounded) model generation problem: search for\n(bounded) models of a theory in some logic. The state-of-the-art approach for\nbounded model generation for rich knowledge representation languages, like ASP,\nFO(.) and Zinc, is ground-and-solve: reduce the theory to a ground or\npropositional one and apply a search algorithm to the resulting theory.\n  An important bottleneck is the blowup of the size of the theory caused by the\nreduction phase. Lazily grounding the theory during search is a way to overcome\nthis bottleneck. We present a theoretical framework and an implementation in\nthe context of the FO(.) knowledge representation language. Instead of\ngrounding all parts of a theory, justifications are derived for some parts of\nit. Given a partial assignment for the grounded part of the theory and valid\njustifications for the formulas of the non-grounded part, the justifications\nprovide a recipe to construct a complete assignment that satisfies the\nnon-grounded part. When a justification for a particular formula becomes\ninvalid during search, a new one is derived; if that fails, the formula is\nsplit in a part to be grounded and a part that can be justified.\n  The theoretical framework captures existing approaches for tackling the\ngrounding bottleneck such as lazy clause generation and grounding-on-the-fly,\nand presents a generalization of the 2-watched literal scheme. We present an\nalgorithm for lazy model expansion and integrate it in a model generator for\nFO(ID), a language extending first-order logic with inductive definitions. The\nalgorithm is implemented as part of the state-of-the-art FO(ID) Knowledge-Base\nSystem IDP. Experimental results illustrate the power and generality of the\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 12:35:41 GMT"}, {"version": "v2", "created": "Tue, 3 Feb 2015 20:08:25 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["De Cat", "Broes", ""], ["Denecker", "Marc", ""], ["Stuckey", "Peter", ""], ["Bruynooghe", "Maurice", ""]]}, {"id": "1402.7122", "submitter": "Anonymous Anonymous Mr.", "authors": "Meghyn Bienvenu, Diego Calvanese, Magdalena Ortiz, Mantas Simkus", "title": "Nested Regular Path Queries in Description Logics", "comments": "added Figure 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-way regular path queries (2RPQs) have received increased attention\nrecently due to their ability to relate pairs of objects by flexibly navigating\ngraph-structured data. They are present in property paths in SPARQL 1.1, the\nnew standard RDF query language, and in the XML query language XPath. In line\nwith XPath, we consider the extension of 2RPQs with nesting, which allows one\nto require that objects along a path satisfy complex conditions, in turn\nexpressed through (nested) 2RPQs. We study the computational complexity of\nanswering nested 2RPQs and conjunctions thereof (CN2RPQs) in the presence of\ndomain knowledge expressed in description logics (DLs). We establish tight\ncomplexity bounds in data and combined complexity for a variety of DLs, ranging\nfrom lightweight DLs (DL-Lite, EL) up to highly expressive ones. Interestingly,\nwe are able to show that adding nesting to (C)2RPQs does not affect worst-case\ndata complexity of query answering for any of the considered DLs. However, in\nthe case of lightweight DLs, adding nesting to 2RPQs leads to a surprising jump\nin combined complexity, from P-complete to Exp-complete.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 02:52:57 GMT"}, {"version": "v2", "created": "Tue, 4 Mar 2014 18:18:00 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Bienvenu", "Meghyn", ""], ["Calvanese", "Diego", ""], ["Ortiz", "Magdalena", ""], ["Simkus", "Mantas", ""]]}, {"id": "1402.7150", "submitter": "Mukund Raghothaman", "authors": "Rajeev Alur, Milo Martin, Mukund Raghothaman, Christos Stergiou,\n  Stavros Tripakis, Abhishek Udupa", "title": "Synthesizing Finite-state Protocols from Scenarios and Requirements", "comments": "This is the working draft of a paper currently in submission.\n  (February 10, 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenarios, or Message Sequence Charts, offer an intuitive way of describing\nthe desired behaviors of a distributed protocol. In this paper we propose a new\nway of specifying finite-state protocols using scenarios: we show that it is\npossible to automatically derive a distributed implementation from a set of\nscenarios augmented with a set of safety and liveness requirements, provided\nthe given scenarios adequately \\emph{cover} all the states of the desired\nimplementation. We first derive incomplete state machines from the given\nscenarios, and then synthesis corresponds to completing the transition relation\nof individual processes so that the global product meets the specified\nrequirements. This completion problem, in general, has the same complexity,\nPSPACE, as the verification problem, but unlike the verification problem, is\nNP-complete for a constant number of processes. We present two algorithms for\nsolving the completion problem, one based on a heuristic search in the space of\npossible completions and one based on OBDD-based symbolic fixpoint computation.\nWe evaluate the proposed methodology for protocol specification and the\neffectiveness of the synthesis algorithms using the classical alternating-bit\nprotocol.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 07:15:00 GMT"}], "update_date": "2014-03-03", "authors_parsed": [["Alur", "Rajeev", ""], ["Martin", "Milo", ""], ["Raghothaman", "Mukund", ""], ["Stergiou", "Christos", ""], ["Tripakis", "Stavros", ""], ["Udupa", "Abhishek", ""]]}, {"id": "1402.7253", "submitter": "EPTCS", "authors": "Antti Valmari (Tampere University of Technology)", "title": "A Simple Character String Proof of the \"True but Unprovable\" Version of\n  G\\\"odel's First Incompleteness Theorem", "comments": "In Proceedings AFL 2014, arXiv:1405.5272", "journal-ref": "EPTCS 151, 2014, pp. 355-369", "doi": "10.4204/EPTCS.151.25", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rather easy yet rigorous proof of a version of G\\\"odel's first\nincompleteness theorem is presented. The version is \"each recursively\nenumerable theory of natural numbers with 0, 1, +, *, =, logical and, logical\nnot, and the universal quantifier either proves a false sentence or fails to\nprove a true sentence\". The proof proceeds by first showing a similar result on\ntheories of finite character strings, and then transporting it to natural\nnumbers, by using them to model strings and their concatenation. Proof systems\nare expressed via Turing machines that halt if and only if their input string\nis a theorem. This approach makes it possible to present all but one parts of\nthe proof rather briefly with simple and straightforward constructions. The\ndetails require some care, but do not require significant background knowledge.\nThe missing part is the widely known fact that Turing machines can perform\ncomplicated computational tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 14:19:43 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 02:15:22 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Valmari", "Antti", "", "Tampere University of Technology"]]}, {"id": "1402.7276", "submitter": "Vaishak Belle", "authors": "Vaishak Belle, Hector Levesque", "title": "Robot Location Estimation in the Situation Calculus", "comments": "Appears in Proceedings of the Eleventh International Symposium on\n  Logical Formalizations on Commonsense Reasoning, Cyprus, May 27-29, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location estimation is a fundamental sensing task in robotic applications,\nwhere the world is uncertain, and sensors and effectors are noisy. Most systems\nmake various assumptions about the dependencies between state variables, and\nespecially about how these dependencies change as a result of actions. Building\non a general framework by Bacchus, Halpern and Levesque for reasoning about\ndegrees of belief in the situation calculus, and a recent extension to it for\ncontinuous domains, in this paper we illustrate location estimation in the\npresence of a rich theory of actions using an example. We also show that while\nactions might affect prior distributions in nonstandard ways, suitable\nposterior beliefs are nonetheless entailed as a side-effect of the overall\nspecification.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 15:12:17 GMT"}], "update_date": "2014-03-03", "authors_parsed": [["Belle", "Vaishak", ""], ["Levesque", "Hector", ""]]}]