[{"id": "1302.0447", "submitter": "Pavel Naumov", "authors": "Kristine Harjes and Pavel Naumov", "title": "Functional Dependence in Strategic Games", "comments": null, "journal-ref": "Notre Dame J. Formal Logic 57, no. 3 (2016), 341-353", "doi": "10.1215/00294527-3479096", "report-no": null, "categories": "math.LO cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies properties of functional dependencies between strategies of\nplayers in Nash equilibria of multi-player strategic games. The main focus is\non the properties of functional dependencies in the context of a fixed\ndependency graph for pay-off functions. A logical system describing properties\nof functional dependence for any given graph is proposed and is proven to be\ncomplete.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2013 02:47:08 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Harjes", "Kristine", ""], ["Naumov", "Pavel", ""]]}, {"id": "1302.0745", "submitter": "Vojtech Forejt", "authors": "Rajeev Alur, Vojtech Forejt, Salar Moarref and Ashutosh Trivedi", "title": "Safe Schedulability of Bounded-Rate Multi-Mode Systems", "comments": "Technical report for a paper presented at HSCC 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded-rate multi-mode systems (BMMS) are hybrid systems that can switch\nfreely among a finite set of modes, and whose dynamics is specified by a finite\nnumber of real-valued variables with mode-dependent rates that can vary within\ngiven bounded sets. The schedulability problem for BMMS is defined as an\ninfinite-round game between two players---the scheduler and the\nenvironment---where in each round the scheduler proposes a time and a mode\nwhile the environment chooses an allowable rate for that mode, and the state of\nthe system changes linearly in the direction of the rate vector. The goal of\nthe scheduler is to keep the state of the system within a pre-specified safe\nset using a non-Zeno schedule, while the goal of the environment is the\nopposite. Green scheduling under uncertainty is a paradigmatic example of BMMS\nwhere a winning strategy of the scheduler corresponds to a robust\nenergy-optimal policy. We present an algorithm to decide whether the scheduler\nhas a winning strategy from an arbitrary starting state, and give an algorithm\nto compute such a winning strategy, if it exists. We show that the\nschedulability problem for BMMS is co-NP complete in general, but for two\nvariables it is in PTIME. We also study the discrete schedulability problem\nwhere the environment has only finitely many choices of rate vectors in each\nmode and the scheduler can make decisions only at multiples of a given clock\nperiod, and show it to be EXPTIME-complete.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2013 16:24:26 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Alur", "Rajeev", ""], ["Forejt", "Vojtech", ""], ["Moarref", "Salar", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1302.0778", "submitter": "Marius Buliga", "authors": "Marius Buliga", "title": "On graphic lambda calculus and the dual of the graphic beta move", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a short description of graphic lambda calculus, with special emphasis\non a duality suggested by the two different appearances of knot diagrams, in\nlambda calculus and emergent algebra sectors of the graphic lambda calculus\nrespectively. This duality leads to the introduction of the dual of the graphic\nbeta move. While the graphic beta move corresponds to beta reduction in untyped\nlambda calculus, the dual graphic beta move appears in relation to emergent\nalgebras.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2013 17:57:05 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Buliga", "Marius", ""]]}, {"id": "1302.0975", "submitter": "Rasoul Ramezanian", "authors": "Rasoul Ramezanian", "title": "A Constructive Epistemic Logic with Public Announcement\n  (Non-Predetermined Possibilities)", "comments": "12 page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the notion of epistemic \\emph{possible worlds} in\nconstructivism (intuitionism) is not as the same as it is in classic view, and\nthere are possibilities, called non-predetermined worlds, which are ignored in\n(classic) Epistemic Logic. Regarding non-predetermined possibilities, we\npropose a constructive epistemic logic and prove soundness and completeness\ntheorems for it. We extend the proposed logic by adding a public announcement\noperator. To declare the significance of our work, we formulate the well-known\nSurprise Exam Paradox, $\\mathbf{SEP}$, via the proposed constructive epistemic\nlogic and then put forward a solution for the paradox. We clarify that the\npuzzle in the $\\mathbf{SEP}$ is because of students'(wrong) assumption that the\nday of the exam is necessarily predetermined.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 09:54:08 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Ramezanian", "Rasoul", ""]]}, {"id": "1302.1046", "submitter": "Filippo Bonchi", "authors": "Alexandra Silva (Radboud University Nijmegen and Centrum Wiskunde &\n  Informatica), Filippo Bonchi (ENS Lyon, Universite' de Lyon, LIP), Marcello\n  Bonsangue (LIACS - Leiden University), Jan Rutten (Centrum Wiskunde &\n  Informatica and Radboud University Nijmegen)", "title": "Generalizing determinization from automata to coalgebras", "comments": "23 pages", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 1 (March 4,\n  2013) lmcs:1087", "doi": "10.2168/LMCS-9(1:9)2013", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The powerset construction is a standard method for converting a\nnondeterministic automaton into a deterministic one recognizing the same\nlanguage. In this paper, we lift the powerset construction from automata to the\nmore general framework of coalgebras with structured state spaces. Coalgebra is\nan abstract framework for the uniform study of different kinds of dynamical\nsystems. An endofunctor F determines both the type of systems (F-coalgebras)\nand a notion of behavioural equivalence (~_F) amongst them. Many types of\ntransition systems and their equivalences can be captured by a functor F. For\nexample, for deterministic automata the derived equivalence is language\nequivalence, while for non-deterministic automata it is ordinary bisimilarity.\nWe give several examples of applications of our generalized determinization\nconstruction, including partial Mealy machines, (structured) Moore automata,\nRabin probabilistic automata, and, somewhat surprisingly, even pushdown\nautomata. To further witness the generality of the approach we show how to\ncharacterize coalgebraically several equivalences which have been object of\ninterest in the concurrency community, such as failure or ready semantics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 14:33:35 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2013 15:25:57 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Silva", "Alexandra", "", "Radboud University Nijmegen and Centrum Wiskunde &\n  Informatica"], ["Bonchi", "Filippo", "", "ENS Lyon, Universite' de Lyon, LIP"], ["Bonsangue", "Marcello", "", "LIACS - Leiden University"], ["Rutten", "Jan", "", "Centrum Wiskunde &\n  Informatica and Radboud University Nijmegen"]]}, {"id": "1302.1207", "submitter": "Michael Warren", "authors": "\\'Alvaro Pelayo, Vladimir Voevodsky, Michael A. Warren", "title": "A preliminary univalent formalization of the p-adic numbers", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give a preliminary formalization of the p-adic numbers, in\nthe context of the second author's univalent foundations program. We also\nprovide the corresponding code verifying the construction in the proof\nassistant Coq. Because work in the univalent setting is ongoing, the structure\nand organization of the construction of the p-adic numbers we give in this\npaper is expected to change as Coq libraries are more suitably rearranged, and\noptimized, by the authors and other researchers in the future. So our\nconstruction here should be deemed as a first approximation which is subject to\nimprovements.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 21:08:23 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Pelayo", "\u00c1lvaro", ""], ["Voevodsky", "Vladimir", ""], ["Warren", "Michael A.", ""]]}, {"id": "1302.1737", "submitter": "Damien Pous", "authors": "Damien Pous (LIP)", "title": "Kleene Algebra with Tests and Coq Tools for While Programs", "comments": "16+3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Coq library about Kleene algebra with tests, including a proof\nof their completeness over the appropriate notion of languages, a decision\nprocedure for their equational theory, and tools for exploiting hypotheses of a\nparticular shape in such a theory. Kleene algebra with tests make it possible\nto represent if-then-else statements and while loops in most imperative\nprogramming languages. They were actually introduced by Kozen as an alternative\nto propositional Hoare logic. We show how to exploit the corresponding Coq\ntools in the context of program verification by proving equivalences of while\nprograms, correctness of some standard compiler optimisations, Hoare rules for\npartial correctness, and a particularly challenging equivalence of flowchart\nschemes.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 13:15:45 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Pous", "Damien", "", "LIP"]]}, {"id": "1302.2123", "submitter": "Michael Clarkson", "authors": "Andrew K. Hirsch and Michael R. Clarkson", "title": "Belief Semantics of Authorization Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorization logics have been used in the theory of computer security to\nreason about access control decisions. In this work, a formal belief semantics\nfor authorization logics is given. The belief semantics is proved to subsume a\nstandard Kripke semantics. The belief semantics yields a direct representation\nof principals' beliefs, without resorting to the technical machinery used in\nKripke semantics. A proof system is given for the logic; that system is proved\nsound with respect to the belief and Kripke semantics. The soundness proof for\nthe belief semantics, and for a variant of the Kripke semantics, is mechanized\nin Coq.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2013 19:29:44 GMT"}, {"version": "v2", "created": "Sat, 11 May 2013 17:03:01 GMT"}, {"version": "v3", "created": "Sun, 4 Aug 2013 00:18:31 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Hirsch", "Andrew K.", ""], ["Clarkson", "Michael R.", ""]]}, {"id": "1302.2279", "submitter": "Fan Yang", "authors": "Fan Yang", "title": "Expressing Second-order Sentences in Intuitionistic Dependence Logic", "comments": "18 pages", "journal-ref": "Studia Logica, April 2013, Volume 101, Issue 2, pp. 323-342", "doi": "10.1007/s11225-013-9476-5", "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Intuitionistic dependence logic was introduced by Abramsky and Vaananen\n(2009) as a variant of dependence logic under a general construction of Hodges'\n(trump) team semantics. It was proven that there is a translation from\nintuitionistic dependence logic sentences into second order logic sentences. In\nthis paper, we prove that the other direction is also true, therefore\nintuitionistic dependence logic is equivalent to second order logic on the\nlevel of sentences.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2013 23:10:38 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Yang", "Fan", ""]]}, {"id": "1302.2584", "submitter": "Kaustuv Chaudhuri", "authors": "Yuting Wang, Kaustuv Chaudhuri (INRIA Saclay - Ile de France), Andrew\n  Gacek, Gopalan Nadathur", "title": "Reasoning About Higher-Order Relational Specifications", "comments": "Principles and Practice of Declarative Programming (2013)", "journal-ref": null, "doi": "10.1145/2505879.2505889", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logic of hereditary Harrop formulas (HH) has proven useful for specifying\na wide range of formal systems. This logic includes a form of hypothetical\njudgment that leads to dynamically changing sets of assumptions and that is key\nto encoding side conditions and contexts that occur frequently in structural\noperational semantics (SOS) style presentations. Specifications are often\nuseful in reasoning about the systems they describe. The Abella theorem prover\nsupports such reasoning by explicitly embedding the specification logic within\na rich reasoning logic; specifications are then reasoned about through this\nembedding. However, realizing an induction principle in the face of dynamically\nchanging assumption sets is nontrivial and the original Abella system uses only\na subset of the HH specification logic for this reason. We develop a method\nhere for supporting inductive reasoning over all of HH. Our approach takes\nadvantage of a focusing property of HH to isolate the use of an assumption and\nthe ability to finitely characterize the structure of any such assumption in\nthe reasoning logic. We demonstrate the effectiveness of these ideas via\nseveral specification and meta-theoretic reasoning examples that have been\nimplemented in an extended version of Abella.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2013 19:43:21 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2013 07:01:58 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Wang", "Yuting", "", "INRIA Saclay - Ile de France"], ["Chaudhuri", "Kaustuv", "", "INRIA Saclay - Ile de France"], ["Gacek", "Andrew", ""], ["Nadathur", "Gopalan", ""]]}, {"id": "1302.2762", "submitter": "Radu Iosif", "authors": "Radu Iosif (Verimag/CNRS), Filip Konecny (Verimag/CNRS and FIT/BUT),\n  Marius Bozga (Verimag/CNRS)", "title": "Deciding Conditional Termination", "comments": "61 pages, 6 figures, 2 tables", "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 3 (August\n  21, 2014) lmcs:737", "doi": "10.2168/LMCS-10(3:8)2014", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of conditional termination, which is that of defining\nthe set of initial configurations from which a given program always terminates.\nFirst we define the dual set, of initial configurations from which a\nnon-terminating execution exists, as the greatest fixpoint of the function that\nmaps a set of states into its pre-image with respect to the transition\nrelation. This definition allows to compute the weakest non-termination\nprecondition if at least one of the following holds: (i) the transition\nrelation is deterministic, (ii) the descending Kleene sequence\noverapproximating the greatest fixpoint converges in finitely many steps, or\n(iii) the transition relation is well founded. We show that this is the case\nfor two classes of relations, namely octagonal and finite monoid affine\nrelations. Moreover, since the closed forms of these relations can be defined\nin Presburger arithmetic, we obtain the decidability of the termination problem\nfor such loops.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 11:33:33 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2014 20:26:09 GMT"}, {"version": "v3", "created": "Mon, 30 Jun 2014 10:35:01 GMT"}, {"version": "v4", "created": "Wed, 20 Aug 2014 08:37:57 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Iosif", "Radu", "", "Verimag/CNRS"], ["Konecny", "Filip", "", "Verimag/CNRS and FIT/BUT"], ["Bozga", "Marius", "", "Verimag/CNRS"]]}, {"id": "1302.3105", "submitter": "EPTCS", "authors": "Mohamed Faouzi Atig (Uppsala University), Ahmed Rezine (Linkoping\n  University)", "title": "Proceedings 14th International Workshop on Verification of\n  Infinite-State Systems", "comments": null, "journal-ref": "EPTCS 107, 2013", "doi": "10.4204/EPTCS.107", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of Infinity'12, the 14th International\nWorkshop on Verification of Infinite-State Systems, which was held in Paris,\nFrance on the 27th of August 2012 as a satellite event of FM'12. The aim of the\nINFINITY workshop is to provide a forum for researchers interested in the\ndevelopment of formal methods and algorithmic techniques for the analysis of\nsystems with infinitely many states, and their application in automated\nverification of complex software and hardware systems.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2013 03:36:38 GMT"}], "update_date": "2013-02-14", "authors_parsed": [["Atig", "Mohamed Faouzi", "", "Uppsala University"], ["Rezine", "Ahmed", "", "Linkoping\n  University"]]}, {"id": "1302.3290", "submitter": "EPTCS", "authors": "Arnaud Gotlieb (Certus Software V & V Center, SIMULA Research\n  Laboratory, Norway), Tristan Denmat (INRIA Rennes Bretagne-Atlantique,\n  France), Nadjib Lazaar (LIRMM, Montpellier, France)", "title": "Constraint-based reachability", "comments": "In Proceedings Infinity 2012, arXiv:1302.3105", "journal-ref": "EPTCS 107, 2013, pp. 25-43", "doi": "10.4204/EPTCS.107.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative imperative programs can be considered as infinite-state systems\ncomputing over possibly unbounded domains. Studying reachability in these\nsystems is challenging as it requires to deal with an infinite number of states\nwith standard backward or forward exploration strategies. An approach that we\ncall Constraint-based reachability, is proposed to address reachability\nproblems by exploring program states using a constraint model of the whole\nprogram. The keypoint of the approach is to interpret imperative constructions\nsuch as conditionals, loops, array and memory manipulations with the\nfundamental notion of constraint over a computational domain. By combining\nconstraint filtering and abstraction techniques, Constraint-based reachability\nis able to solve reachability problems which are usually outside the scope of\nbackward or forward exploration strategies. This paper proposes an\ninterpretation of classical filtering consistencies used in Constraint\nProgramming as abstract domain computations, and shows how this approach can be\nused to produce a constraint solver that efficiently generates solutions for\nreachability problems that are unsolvable by other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 02:26:33 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Gotlieb", "Arnaud", "", "Certus Software V & V Center, SIMULA Research\n  Laboratory, Norway"], ["Denmat", "Tristan", "", "INRIA Rennes Bretagne-Atlantique,\n  France"], ["Lazaar", "Nadjib", "", "LIRMM, Montpellier, France"]]}, {"id": "1302.3291", "submitter": "EPTCS", "authors": "Parosh Aziz Abdulla (Uppsala University), Richard Mayr (University of\n  Edinburgh)", "title": "Petri Nets with Time and Cost", "comments": "In Proceedings Infinity 2012, arXiv:1302.3105", "journal-ref": "EPTCS 107, 2013, pp. 9-24", "doi": "10.4204/EPTCS.107.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider timed Petri nets, i.e., unbounded Petri nets where each token\ncarries a real-valued clock. Transition arcs are labeled with time intervals,\nwhich specify constraints on the ages of tokens. Our cost model assigns token\nstorage costs per time unit to places, and firing costs to transitions. We\nstudy the cost to reach a given control-state. In general, a cost-optimal run\nmay not exist. However,we show that the infimum of the costs is computable.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 02:26:37 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Abdulla", "Parosh Aziz", "", "Uppsala University"], ["Mayr", "Richard", "", "University of\n  Edinburgh"]]}, {"id": "1302.3293", "submitter": "EPTCS", "authors": "{\\L}ukasz Fronc (IBISC, Universit\\'e d'Evry-Val d'Essonne)", "title": "Effective Marking Equivalence Checking in Systems with Dynamic Process\n  Creation", "comments": "In Proceedings Infinity 2012, arXiv:1302.3105", "journal-ref": "EPTCS 107, 2013, pp. 61-75", "doi": "10.4204/EPTCS.107.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The starting point of this work is a framework allowing to model systems with\ndynamic process creation, equipped with a procedure to detect symmetric\nexecutions (ie., which differ only by the identities of processes). This allows\nto reduce the state space, potentially to an exponentially smaller size, and,\nbecause process identifiers are never reused, this also allows to reduce to\nfinite size some infinite state spaces. However, in this approach, the\nprocedure to detect symmetries does not allow for computationally efficient\nalgorithms, mainly because each newly computed state has to be compared with\nevery already reached state.\n  In this paper, we propose a new approach to detect symmetries in this\nframework that will solve this problem, thus enabling for efficient algorithms.\nWe formalise a canonical representation of states and identify a sufficient\ncondition on the analysed model that guarantees that every symmetry can be\ndetected. For the models that do not fall into this category, our approach is\nstill correct but does not guarantee a maximal reduction of state space.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 02:26:50 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Fronc", "\u0141ukasz", "", "IBISC, Universit\u00e9 d'Evry-Val d'Essonne"]]}, {"id": "1302.3465", "submitter": "Zhenghan Wang", "authors": "J. Michael Dunn, Lawrence S. Moss, and Zhenghan Wang", "title": "The Third Life of Quantum Logic: Quantum Logic Inspired by Quantum\n  Computing", "comments": "To appear in a special issue of Journal of Philosophical Logic", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We begin by discussing the history of quantum logic, dividing it into three\neras or lives. The first life has to do with Birkhoff and von Neumann's\nalgebraic approach in the 1930's. The second life has to do with attempt to\nunderstand quantum logic as logic that began in the late 1950's and blossomed\nin the 1970's. And the third life has to do with recent developments in quantum\nlogic coming from its connections to quantum computation. We discuss our own\nwork connecting quantum logic to quantum computation (viewing quantum logic as\nthe logic of quantum registers storing qubits), and make some speculations\nabout mathematics based on quantum principles.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 16:51:13 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Dunn", "J. Michael", ""], ["Moss", "Lawrence S.", ""], ["Wang", "Zhenghan", ""]]}, {"id": "1302.3481", "submitter": "Artur Je\\.z", "authors": "Artur Je\\.z", "title": "One-variable word equations in linear time", "comments": "submitted to a journal, general overhaul over the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider word equations with one variable (and arbitrary\nmany appearances of it). A recent technique of recompression, which is\napplicable to general word equations, is shown to be suitable also in this\ncase. While in general case it is non-deterministic, it determinises in case of\none variable and the obtained running time is O(n + #_X log n), where #_X is\nthe number of appearances of the variable in the equation. This matches the\npreviously-best algorithm due to D\\k{a}browski and Plandowski. Then, using a\ncouple of heuristics as well as more detailed time analysis the running time is\nlowered to O(n) in RAM model. Unfortunately no new properties of solutions are\nshown.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 17:24:36 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2014 16:15:16 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Je\u017c", "Artur", ""]]}, {"id": "1302.3741", "submitter": "Kousha Etessami", "authors": "Alistair Stewart, Kousha Etessami, and Mihalis Yannakakis", "title": "Upper bounds for Newton's method on monotone polynomial systems, and\n  P-time model checking of probabilistic one-counter automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central computational problem for analyzing and model checking various\nclasses of infinite-state recursive probabilistic systems (including\nquasi-birth-death processes, multi-type branching processes, stochastic\ncontext-free grammars, probabilistic pushdown automata and recursive Markov\nchains) is the computation of {\\em termination probabilities}, and computing\nthese probabilities in turn boils down to computing the {\\em least fixed point}\n(LFP) solution of a corresponding {\\em monotone polynomial system} (MPS) of\nequations, denoted x=P(x).\n  It was shown by Etessami & Yannakakis that a decomposed variant of Newton's\nmethod converges monotonically to the LFP solution for any MPS that has a\nnon-negative solution. Subsequently, Esparza, Kiefer, & Luttenberger obtained\nupper bounds on the convergence rate of Newton's method for certain classes of\nMPSs. More recently, better upper bounds have been obtained for special classes\nof MPSs. However, prior to this paper, for arbitrary (not necessarily\nstrongly-connected) MPSs, no upper bounds at all were known on the convergence\nrate of Newton's method as a function of the encoding size |P| of the input\nMPS, x=P(x).\n  In this paper we provide worst-case upper bounds, as a function of both the\ninput encoding size |P|, and epsilon > 0, on the number of iterations required\nfor decomposed Newton's method (even with rounding) to converge within additive\nerror epsilon > 0 of q^*, for any MPS with LFP solution q^*. Our upper bounds\nare essentially optimal in terms of several important parameters.\n  Using our upper bounds, and building on prior work, we obtain the first\nP-time algorithm (in the standard Turing model of computation) for quantitative\nmodel checking, to within desired precision, of discrete-time QBDs and\n(equivalently) probabilistic 1-counter automata, with respect to any (fixed)\nomega-regular or LTL property.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 12:48:20 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2013 21:55:16 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Stewart", "Alistair", ""], ["Etessami", "Kousha", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "1302.4009", "submitter": "Adam Bjorndahl", "authors": "Adam Bjorndahl", "title": "Topological Subset Space Models for Public Announcements", "comments": "21 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reformulate a key definition given by Wang and Agotnes (2013) to provide\nsemantics for public announcements in subset spaces. More precisely, we\ninterpret the precondition for a public announcement of {\\phi} to be the \"local\ntruth\" of {\\phi}, semantically rendered via an interior operator. This is\nclosely related to the notion of {\\phi} being \"knowable\". We argue that these\nrevised semantics improve on the original and offer several motivating examples\nto this effect. A key insight that emerges is the crucial role of topological\nstructure in this setting. Finally, we provide a simple axiomatization of the\nresulting logic and prove completeness.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2013 22:42:23 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2016 22:07:45 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Bjorndahl", "Adam", ""]]}, {"id": "1302.4187", "submitter": "Philipp Ruemmer", "authors": "Philipp R\\\"ummer (Uppsala University), Hossein Hojjat (EPFL Lausanne),\n  Viktor Kuncak (EPFL Lausanne)", "title": "The Relationship between Craig Interpolation and Recursion-Free Horn\n  Clauses", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite decades of research, there are still a number of concepts commonly\nfound in software programs that are considered challenging for verification:\namong others, such concepts include concurrency, and the compositional analysis\nof programs with procedures. As a promising direction to overcome such\ndifficulties, recently the use of Horn constraints as intermediate\nrepresentation of software programs has been proposed. Horn constraints are\nrelated to Craig interpolation, which is one of the main techniques used to\nconstruct and refine abstractions in verification, and to synthesise inductive\nloop invariants. We give a survey of the different forms of Craig interpolation\nfound in literature, and show that all of them correspond to natural fragments\nof (recursion-free) Horn constraints. We also discuss techniques for solving\nsystems of recursion-free Horn constraints.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 09:08:16 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["R\u00fcmmer", "Philipp", "", "Uppsala University"], ["Hojjat", "Hossein", "", "EPFL Lausanne"], ["Kuncak", "Viktor", "", "EPFL Lausanne"]]}, {"id": "1302.4248", "submitter": "Mickael Randour", "authors": "Krishnendu Chatterjee and Laurent Doyen and Mickael Randour and\n  Jean-Fran\\c{c}ois Raskin", "title": "Looking at Mean-Payoff and Total-Payoff through Windows", "comments": "Extended version of ATVA 2013 version. Full version to appear in\n  Information and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two-player games played on weighted directed graphs with\nmean-payoff and total-payoff objectives, two classical quantitative objectives.\nWhile for single-dimensional games the complexity and memory bounds for both\nobjectives coincide, we show that in contrast to multi-dimensional mean-payoff\ngames that are known to be coNP-complete, multi-dimensional total-payoff games\nare undecidable. We introduce conservative approximations of these objectives,\nwhere the payoff is considered over a local finite window sliding along a play,\ninstead of the whole play. For single dimension, we show that (i) if the window\nsize is polynomial, deciding the winner takes polynomial time, and (ii) the\nexistence of a bounded window can be decided in NP $\\cap$ coNP, and is at least\nas hard as solving mean-payoff games. For multiple dimensions, we show that (i)\nthe problem with fixed window size is EXPTIME-complete, and (ii) there is no\nprimitive-recursive algorithm to decide the existence of a bounded window.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 12:43:08 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2013 10:07:39 GMT"}, {"version": "v3", "created": "Mon, 3 Nov 2014 12:32:28 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Doyen", "Laurent", ""], ["Randour", "Mickael", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "1302.4266", "submitter": "Michael Lampis", "authors": "Michael Lampis (Research Institute for Mathematical Sciences (RIMS),\n  Kyoto University)", "title": "Model Checking Lower Bounds for Simple Graphs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 1 (March 25,\n  2014) lmcs:976", "doi": "10.2168/LMCS-10(1:18)2014", "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-known result by Frick and Grohe shows that deciding FO logic on trees\ninvolves a parameter dependence that is a tower of exponentials. Though this\nlower bound is tight for Courcelle's theorem, it has been evaded by a series of\nrecent meta-theorems for other graph classes. Here we provide some additional\nnon-elementary lower bound results, which are in some senses stronger. Our goal\nis to explain common traits in these recent meta-theorems and identify barriers\nto further progress. More specifically, first, we show that on the class of\nthreshold graphs, and therefore also on any union and complement-closed class,\nthere is no model-checking algorithm with elementary parameter dependence even\nfor FO logic. Second, we show that there is no model-checking algorithm with\nelementary parameter dependence for MSO logic even restricted to paths (or\nequivalently to unary strings), unless E=NE. As a corollary, we resolve an open\nproblem on the complexity of MSO model-checking on graphs of bounded max-leaf\nnumber. Finally, we look at MSO on the class of colored trees of depth d. We\nshow that, assuming the ETH, for every fixed d>=1 at least d+1 levels of\nexponentiation are necessary for this problem, thus showing that the (d+1)-fold\nexponential algorithm recently given by Gajarsk\\`{y} and Hlin\\u{e}n\\`{y} is\nessentially optimal.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 13:40:05 GMT"}, {"version": "v2", "created": "Wed, 19 Mar 2014 12:16:08 GMT"}, {"version": "v3", "created": "Mon, 24 Mar 2014 09:50:54 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Lampis", "Michael", "", "Research Institute for Mathematical Sciences"]]}, {"id": "1302.4350", "submitter": "Abhisekh Sankaran", "authors": "Abhisekh Sankaran, Bharat Adsul and Supratik Chakraborty", "title": "Generalizations of the Los-Tarski Preservation Theorem", "comments": "Added 2 new results: (a) A preservation theorem providing a semantic\n  characterization of \\Sigma^0_n theories for each natural number n (which\n  builds on our generalization of the existential amalgamation theorem) (b)\n  Theories in PSC(k) and PSC_f are equivalent to \\Sigma^0_2 theories and that\n  the latter are strictly more general than the former. These results are in\n  Sections 8 and 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new preservation theorems that semantically characterize the\n$\\exists^k \\forall^*$ and $\\forall^k \\exists^*$ prefix classes of first order\nlogic, for each natural number $k$. Unlike preservation theorems in the\nliterature that characterize the $\\exists^* \\forall^*$ and $\\forall^*\n\\exists^*$ prefix classes, our theorems relate the count of quantifiers in the\nleading block of the quantifier prefix to natural quantitative properties of\nthe models. As special cases of our results, we obtain the classical Los-Tarski\npreservation theorem for sentences in both its extensional and substructural\nversions. For arbitrary finite vocabularies, we also generalize the extensional\nversion of the Los-Tarski preservation theorem for theories. We also present an\ninterpolant-based approach towards these results. Finally, we present partial\nresults towards generalizing to theories, the substructural version of the\nLos-Tarski theorem and in the process, we give a preservation theorem that\nprovides a semantic characterization of $\\Sigma^0_n$ theories for each natural\nnumber $n$.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 16:52:40 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 12:40:05 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Sankaran", "Abhisekh", ""], ["Adsul", "Bharat", ""], ["Chakraborty", "Supratik", ""]]}, {"id": "1302.4421", "submitter": "Oliver Kullmann", "authors": "Matthew Gwynne, Oliver Kullmann", "title": "Towards a theory of good SAT representations", "comments": "59 pages; second version with some extended discussions and editorial\n  corrections, third version with extended introduction, more examples and\n  explanations, and some editorial improvements, fourth version with further\n  examples, explanations and discussions, and with added computational\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at providing a foundation of a theory of \"good\" SAT representations F\nof boolean functions f. We argue that the hierarchy UC_k of unit-refutation\ncomplete clause-sets of level k, introduced by the authors, provides the most\nbasic target classes, that is, F in UC_k is to be achieved for k as small as\nfeasible. If F does not contain new variables, i.e., F is equivalent (as a CNF)\nto f, then F in UC_1 is similar to \"achieving (generalised) arc consistency\"\nknown from the literature (it is somewhat weaker, but theoretically much nicer\nto handle). We show that for polysize representations of boolean functions in\nthis sense, the hierarchy UC_k is strict. The boolean functions for these\nseparations are \"doped\" minimally unsatisfiable clause-sets of deficiency 1;\nthese functions have been introduced in [Sloan, Soerenyi, Turan, 2007], and we\ngeneralise their construction and show a correspondence to a strengthened\nnotion of irredundant sub-clause-sets. Turning from lower bounds to upper\nbounds, we believe that many common CNF representations fit into the UC_k\nscheme, and we give some basic tools to construct representations in UC_1 with\nnew variables, based on the Tseitin translation. Note that regarding new\nvariables the UC_1-representations are stronger than mere \"arc consistency\",\nsince the new variables are not excluded from consideration.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 20:40:06 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2013 00:04:46 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2013 00:46:37 GMT"}, {"version": "v4", "created": "Fri, 10 May 2013 17:45:54 GMT"}], "update_date": "2013-05-13", "authors_parsed": [["Gwynne", "Matthew", ""], ["Kullmann", "Oliver", ""]]}, {"id": "1302.4539", "submitter": "Pierre Ganty", "authors": "Pierre Ganty and Samir Genaim", "title": "Proving Termination Starting from the End", "comments": "16 pages", "journal-ref": null, "doi": "10.1007/978-3-642-39799-8_27", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel technique for proving program termination which introduces\na new dimension of modularity. Existing techniques use the program to\nincrementally construct a termination proof. While the proof keeps changing,\nthe program remains the same. Our technique goes a step further. We show how to\nuse the current partial proof to partition the transition relation into those\nbehaviors known to be terminating from the current proof, and those whose\nstatus (terminating or not) is not known yet. This partition enables a new and\nunexplored dimension of incremental reasoning on the program side. In addition,\nwe show that our approach naturally applies to conditional termination which\nsearches for a precondition ensuring termination. We further report on a\nprototype implementation that advances the state-of-the-art on the grounds of\ntermination and conditional termination.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 08:21:16 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Ganty", "Pierre", ""], ["Genaim", "Samir", ""]]}, {"id": "1302.4545", "submitter": "Burkhard Schipper", "authors": "Burkhard C. Schipper", "title": "Preference-Based Unawareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morris (1996, 1997) introduced preference-based definitions of knowledge and\nbelief in standard state-space structures. This paper extends this\npreference-based approach to unawareness structures (Heifetz, Meier, and\nSchipper, 2006, 2008). By defining unawareness and knowledge in terms of\npreferences over acts in unawareness structures and showing their equivalence\nto the epistemic notions of unawareness and knowledge, we try to build a bridge\nbetween decision theory and epistemic logic. Unawareness of an event is\ncharacterized behaviorally as the event being null and its negation being null.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 08:52:40 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Schipper", "Burkhard C.", ""]]}, {"id": "1302.4739", "submitter": "Dai Liyun", "authors": "Liyun Dai and Bican Xia and Naijun Zhan", "title": "Generating Non-Linear Interpolants by Semidefinite Programming", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpolation-based techniques have been widely and successfully applied in\nthe verification of hardware and software, e.g., in bounded-model check- ing,\nCEGAR, SMT, etc., whose hardest part is how to synthesize interpolants. Various\nwork for discovering interpolants for propositional logic, quantifier-free\nfragments of first-order theories and their combinations have been proposed.\nHowever, little work focuses on discovering polynomial interpolants in the\nliterature. In this paper, we provide an approach for constructing non-linear\ninterpolants based on semidefinite programming, and show how to apply such\nresults to the verification of programs by examples.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 04:05:02 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2013 09:42:17 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Dai", "Liyun", ""], ["Xia", "Bican", ""], ["Zhan", "Naijun", ""]]}, {"id": "1302.4783", "submitter": "Zhe Hou", "authors": "Zhe Hou, Alwen Tiu, and Rajeev Gore", "title": "A Labelled Sequent Calculus for BBI: Proof Theory and Proof Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a labelled sequent calculus for Boolean BI, a classical variant of\nO'Hearn and Pym's logic of Bunched Implication. The calculus is simple, sound,\ncomplete, and enjoys cut-elimination. We show that all the structural rules in\nour proof system, including those rules that manipulate labels, can be\nlocalised around applications of certain logical rules, thereby localising the\nhandling of these rules in proof search. Based on this, we demonstrate a free\nvariable calculus that deals with the structural rules lazily in a constraint\nsystem. A heuristic method to solve the constraints is proposed in the end,\nwith some experimental results.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 01:06:13 GMT"}, {"version": "v2", "created": "Wed, 1 May 2013 05:35:54 GMT"}, {"version": "v3", "created": "Mon, 22 Jul 2013 02:46:29 GMT"}, {"version": "v4", "created": "Tue, 6 Aug 2013 06:32:52 GMT"}, {"version": "v5", "created": "Mon, 4 May 2015 02:12:03 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Hou", "Zhe", ""], ["Tiu", "Alwen", ""], ["Gore", "Rajeev", ""]]}, {"id": "1302.4856", "submitter": "Tomasz Brengos", "authors": "Tomasz Brengos", "title": "An algebraic approach to weak and delay bismulation in coalgebra", "comments": "This paper has been withdrawn due to existing better attempt to model\n  saturators coalgebraically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to introduce an algebraic structure on the set of\nall coalgebras with the same state space over the given type which allows us to\npresent definitions of weak and delay bisimulation for coalgebras.\nAdditionally, we introduce an algebraic structure on the carrier set of the\nfinal coalgebra and characterize a special subcoalgebra of the final coalgebra\nwhich is used in the formulation of the weak coinduction principle. Finally,\nthe new algebraic setting allows us to present a definition of an approximated\nweak bisimulation, study its properties and compare it with previously defined\nweak bisimulation for coalgebras.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 10:02:14 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2013 05:19:42 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Brengos", "Tomasz", ""]]}, {"id": "1302.4931", "submitter": "Luca Boldrin", "authors": "Luca Boldrin, Claudio Sossai", "title": "An Algebraic Semantics for Possibilistic Logic", "comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1995-PG-27-35", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first contribution of this paper is the presentation of a Pavelka - like\nformulation of possibilistic logic in which the language is naturally enriched\nby two connectives which represent negation (eg) and a new type of conjunction\n(otimes). The space of truth values for this logic is the lattice of\npossibility functions, that, from an algebraic point of view, forms a quantal.\nA second contribution comes from the understanding of the new conjunction as\nthe combination of tokens of information coming from different sources, which\nmakes our language \"dynamic\". A Gentzen calculus is presented, which is proved\nsound and complete with respect to the given semantics. The problem of truth\nfunctionality is discussed in this context.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:19:06 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Boldrin", "Luca", ""], ["Sossai", "Claudio", ""]]}, {"id": "1302.5174", "submitter": "EPTCS", "authors": "Maribel Fern\\'andez, Jeffrey Terrell", "title": "Assembling the Proofs of Ordered Model Transformations", "comments": "In Proceedings FESCA 2013, arXiv:1302.4780", "journal-ref": "EPTCS 108, 2013, pp. 63-77", "doi": "10.4204/EPTCS.108.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-driven development, an ordered model transformation is a nested set\nof transformations between source and target classes, in which each\ntransformation is governed by its own pre and post- conditions, but\nstructurally dependent on its parent. Following the\nproofs-as-model-transformations approach, in this paper we consider a\nformalisation in Constructive Type Theory of the concepts of model and model\ntransformation, and show how the correctness proofs of potentially large\nordered model transformations can be systematically assembled from the proofs\nof the specifications of their parts, making them easier to derive.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 04:00:11 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["Fern\u00e1ndez", "Maribel", ""], ["Terrell", "Jeffrey", ""]]}, {"id": "1302.5254", "submitter": "Flavio Ferrarotti", "authors": "F. Ferrarotti, W. Ren, J. M. Turull Torres", "title": "Expressing Properties in Second and Third Order Logic: Hypercube Graphs\n  and SATQBF", "comments": "Pre-print of article submitted to an special issue of the Logic\n  Journal of the IGPL with selected papers from the 16th Brazilian Logic\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It follows from the famous Fagin's theorem that all problems in NP are\nexpressible in existential second-order logic (ESO), and vice versa. Indeed,\nthere are well-known ESO characterizations of NP-complete problems such as\n3-colorability, Hamiltonicity and clique. Furthermore, the ESO sentences that\ncharacterize those problems are simple and elegant. However, there are also NP\nproblems that do not seem to possess equally simple and elegant ESO\ncharacterizations. In this work, we are mainly interested in this latter class\nof problems. In particular, we characterize in second-order logic the class of\nhypercube graphs and the classes SATQBF_k of satisfiable quantified Boolean\nformulae with k alternations of quantifiers. We also provide detailed\ndescriptions of the strategies followed to obtain the corresponding nontrivial\nsecond-order sentences. Finally, we sketch a third-order logic sentence that\ndefines the class SATQBF = \\bigcup_{k \\geq 1} SATQBF_k. The sub-formulae used\nin the construction of these complex second- and third-order logic sentences,\nare good candidates to form part of a library of formulae. Same as libraries of\nfrequently used functions simplify the writing of complex computer programs, a\nlibrary of formulae could potentially simplify the writing of complex second-\nand third-order queries, minimizing the probability of error.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 11:29:12 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["Ferrarotti", "F.", ""], ["Ren", "W.", ""], ["Torres", "J. M. Turull", ""]]}, {"id": "1302.5765", "submitter": "Daisuke Kimura", "authors": "Daisuke Kimura (National Institute of Informatics), Makoto Tatsuta\n  (National Institute of Informatics)", "title": "Call-by-Value and Call-by-Name Dual Calculi with Inductive and\n  Coinductive Types", "comments": "The conference version of this paper has appeared in RTA 2009", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 1 (March 29,\n  2013) lmcs:1055", "doi": "10.2168/LMCS-9(1:14)2013", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the dual calculus with inductive types and coinductive\ntypes. The paper first introduces a non-deterministic dual calculus with\ninductive and coinductive types. Besides the same duality of the original dual\ncalculus, it has the duality of inductive and coinductive types, that is, the\nduality of terms and coterms for inductive and coinductive types, and the\nduality of their reduction rules. Its strong normalization is also proved,\nwhich is shown by translating it into a second-order dual calculus. The strong\nnormalization of the second-order dual calculus is proved by translating it\ninto the second-order symmetric lambda calculus. This paper then introduces a\ncall-by-value system and a call-by-name system of the dual calculus with\ninductive and coinductive types, and shows the duality of call-by-value and\ncall-by-name, their Church-Rosser properties, and their strong normalization.\nTheir strong normalization is proved by translating them into the\nnon-deterministic dual calculus with inductive and coinductive types.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 06:01:19 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 20:27:50 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kimura", "Daisuke", "", "National Institute of Informatics"], ["Tatsuta", "Makoto", "", "National Institute of Informatics"]]}, {"id": "1302.5798", "submitter": "EPTCS", "authors": "Simon Gay, Paul Kelly", "title": "Proceedings Fifth Workshop on Programming Language Approaches to\n  Concurrency- and Communication-cEntric Software", "comments": null, "journal-ref": "EPTCS 109, 2013", "doi": "10.4204/EPTCS.109", "report-no": null, "categories": "cs.PL cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PLACES 2012 (full title: Programming Language Approaches to Concurrency- and\nCommunication-Centric Software) is the fifth edition of the PLACES workshop\nseries. After the first PLACES, which was affiliated to DisCoTec in 2008, the\nworkshop has been part of ETAPS every year since 2009 and is now an established\npart of the ETAPS satellite events. PLACES 2012 was held on 31st March in\nTallinn, Estonia.\n  The workshop series was started in order to promote the application of novel\nprogramming language ideas to the increasingly important problem of developing\nsoftware for systems in which concurrency and communication are intrinsic\naspects. This includes software for both multi-core systems and large-scale\ndistributed and/or service-oriented systems. The scope of PLACES includes new\nprogramming language features, whole new programming language designs, new type\nsystems, new semantic approaches, new program analysis techniques, and new\nimplementation mechanisms.\n  This year's call for papers attracted 17 submissions, from which the\nprogramme committee selected 10 papers for presentation at the workshop. After\nthe workshop, all of the authors were invited to produce revised versions of\ntheir papers for inclusion in the EPTCS proceedings. The authors of six papers\naccepted the invitation, and those papers constitute the present volume.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 13:44:36 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Gay", "Simon", ""], ["Kelly", "Paul", ""]]}, {"id": "1302.5997", "submitter": "EPTCS", "authors": "Rachid Echahed (CNRS, University of Grenoble, France), Detlef Plump\n  (University of York, UK)", "title": "Proceedings 7th International Workshop on Computing with Terms and\n  Graphs", "comments": null, "journal-ref": "EPTCS 110, 2013", "doi": "10.4204/EPTCS.110", "report-no": null, "categories": "cs.SC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Seventh International Workshop on\nComputing with Terms and Graphs (TERMGRAPH 2013). The workshop took place in\nRome, Italy, on March 23rd, 2013, as part of the sixteenth edition of the\nEuropean Joint Conferences on Theory and Practice of Software (ETAPS 2013).\n  Research in term and graph rewriting ranges from theoretical questions to\npractical issues. Computing with graphs handles the sharing of common\nsubexpressions in a natural and seamless way, and improves the efficiency of\ncomputations in space and time. Sharing is ubiquitous in several research\nareas, as witnessed by the modelling of first- and higher-order term rewriting\nby (acyclic or cyclic) graph rewriting, the modelling of biological or chemical\nabstract machines, and the implementation techniques of programming languages:\nmany implementations of functional, logic, object-oriented, concurrent and\nmobile calculi are based on term graphs. Term graphs are also used in automated\ntheorem proving and symbolic computation systems working on shared structures.\nThe aim of this workshop is to bring together researchers working in different\ndomains on term and graph transformation and to foster their interaction, to\nprovide a forum for presenting new ideas and work in progress, and to enable\nnewcomers to learn about current activities in term graph rewriting.\n  These proceedings contain six accepted papers and the abstracts of two\ninvited talks. All submissions were subject to careful refereeing. The topics\nof accepted papers range over a wide spectrum, including theoretical aspects of\nterm graph rewriting, concurrency, semantics as well as application issues of\nterm graph transformation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2013 05:49:14 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Echahed", "Rachid", "", "CNRS, University of Grenoble, France"], ["Plump", "Detlef", "", "University of York, UK"]]}, {"id": "1302.6043", "submitter": "Jan Obdrzalek", "authors": "Robert Ganian (Vienna University of Technology), Petr Hlineny (Masaryk\n  University, Brno), Daniel Kral (University of Warwick), Jan Obdrzalek\n  (Masaryk University, Brno), Jarett Schwartz (UC Berkeley), Jakub Teska\n  (University of West Bohemia, Pilsen)", "title": "FO Model Checking of Interval Graphs", "comments": "Paper as accepted to the LMCS journal. An extended abstract of an\n  earlier version of this paper has appeared at ICALP'13. Main changes to the\n  previous version are mostly small improvements in presentation", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 4 (December\n  14, 2015) lmcs:1612", "doi": "10.2168/LMCS-11(4:11)2015", "report-no": null, "categories": "cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of the FO model checking problem on\ninterval graphs, i.e., intersection graphs of intervals on the real line. The\nmain positive result is that FO model checking and successor-invariant FO model\nchecking can be solved in time O(n log n) for n-vertex interval graphs with\nrepresentations containing only intervals with lengths from a prescribed finite\nset. We complement this result by showing that the same is not true if the\nlengths are restricted to any set that is dense in an open subset, e.g., in the\nset $(1, 1 + \\varepsilon)$.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2013 10:47:59 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2015 10:06:17 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2015 14:03:26 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2015 20:08:03 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Ganian", "Robert", "", "Vienna University of Technology"], ["Hlineny", "Petr", "", "Masaryk\n  University, Brno"], ["Kral", "Daniel", "", "University of Warwick"], ["Obdrzalek", "Jan", "", "Masaryk University, Brno"], ["Schwartz", "Jarett", "", "UC Berkeley"], ["Teska", "Jakub", "", "University of West Bohemia, Pilsen"]]}, {"id": "1302.6325", "submitter": "Nabizath Saleena", "authors": "Saleena Nabeezath and Vineeth Paleri", "title": "A Note on \"A polynomial-time algorithm for global value numbering\"", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global Value Numbering(GVN) is a popular method for detecting redundant\ncomputations. A polynomial time algorithm for GVN is presented by Gulwani and\nNecula(2006). Here we present two limitations of this GVN algorithm due to\nwhich detection of certain kinds of redundancies can not be done using this\nalgorithm. The first one is concerning the use of this algorithm in detecting\nsome instances of the classical global common subexpressions, and the second is\nconcerning its use in the detection of some redundancies that a local value\nnumbering algorithm will detect. We suggest improvements that enable the\nalgorithm to detect these kinds of redundancies as well.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:34:42 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2013 06:54:04 GMT"}, {"version": "v3", "created": "Fri, 8 Mar 2013 04:21:36 GMT"}, {"version": "v4", "created": "Mon, 13 May 2013 06:51:13 GMT"}, {"version": "v5", "created": "Fri, 6 Apr 2018 09:15:06 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Nabeezath", "Saleena", ""], ["Paleri", "Vineeth", ""]]}, {"id": "1302.6330", "submitter": "EPTCS", "authors": "Massimo Bartoletti (Universita' degli Studi di Cagliari), Tiziana\n  Cimoli (Universita' degli Studi di Cagliari), G. Michele Pinna (Universita'\n  degli Studi di Cagliari), Roberto Zunino (DISI-Universita' degli Studi di\n  Trento and COSBI, Italy)", "title": "An event-based model for contracts", "comments": "In Proceedings PLACES 2012, arXiv:1302.5798", "journal-ref": "EPTCS 109, 2013, pp. 13-20", "doi": "10.4204/EPTCS.109.3", "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a basic model for contracts. Our model extends event structures\nwith a new relation, which faithfully captures the circular dependencies among\ncontract clauses. We establish whether an agreement exists which respects all\nthe contracts at hand (i.e. all the dependencies can be resolved), and we\ndetect the obligations of each participant. The main technical contribution is\na correspondence between our model and a fragment of the contract logic PCL.\nMore precisely, we show that the reachable events are exactly those which\ncorrespond to provable atoms in the logic. Despite of this strong\ncorrespondence, our model improves previous work on PCL by exhibiting a\nfiner-grained notion of culpability, which takes into account the legitimate\norderings of events.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:48:55 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Bartoletti", "Massimo", "", "Universita' degli Studi di Cagliari"], ["Cimoli", "Tiziana", "", "Universita' degli Studi di Cagliari"], ["Pinna", "G. Michele", "", "Universita'\n  degli Studi di Cagliari"], ["Zunino", "Roberto", "", "DISI-Universita' degli Studi di\n  Trento and COSBI, Italy"]]}, {"id": "1302.6332", "submitter": "EPTCS", "authors": "Pierpaolo Degano (Dipartimento di Informatica - Universit\\`a di Pisa),\n  Gian-Luigi Ferrari (Dipartimento di Informatica - Universit\\`a di Pisa),\n  Letterio Galletta (Dipartimento di Informatica - Universit\\`a di Pisa),\n  Gianluca Mezzetti (Dipartimento di Informatica - Universit\\`a di Pisa)", "title": "Typing Context-Dependent Behavioural Variation", "comments": "In Proceedings PLACES 2012, arXiv:1302.5798", "journal-ref": "EPTCS 109, 2013, pp. 28-33", "doi": "10.4204/EPTCS.109.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context Oriented Programming (COP) concerns the ability of programs to adapt\nto changes in their running environment. A number of programming languages\nendowed with COP constructs and features have been developed. However, some\nfoundational issues remain unclear. This paper proposes adopting static\nanalysis techniques to reason on and predict how programs adapt their\nbehaviour. We introduce a core functional language, ContextML, equipped with\nCOP primitives for manipulating contexts and for programming behavioural\nvariations. In particular, we specify the dispatching mechanism, used to select\nthe program fragments to be executed in the current active context. Besides the\ndynamic semantics we present an annotated type system. It guarantees that the\nwell-typed programs adapt to any context, i.e. the dispatching mechanism always\nsucceeds at run-time.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:49:09 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Degano", "Pierpaolo", "", "Dipartimento di Informatica - Universit\u00e0 di Pisa"], ["Ferrari", "Gian-Luigi", "", "Dipartimento di Informatica - Universit\u00e0 di Pisa"], ["Galletta", "Letterio", "", "Dipartimento di Informatica - Universit\u00e0 di Pisa"], ["Mezzetti", "Gianluca", "", "Dipartimento di Informatica - Universit\u00e0 di Pisa"]]}, {"id": "1302.6334", "submitter": "EPTCS", "authors": "Guillaume Bonfante (LORIA Universit\\'e de Lorraine), Bruno Guillaume\n  (LORIA Inria Nancy Grand-Est)", "title": "Non-simplifying Graph Rewriting Termination", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 4-16", "doi": "10.4204/EPTCS.110.3", "report-no": null, "categories": "cs.CL cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  So far, a very large amount of work in Natural Language Processing (NLP) rely\non trees as the core mathematical structure to represent linguistic\ninformations (e.g. in Chomsky's work). However, some linguistic phenomena do\nnot cope properly with trees. In a former paper, we showed the benefit of\nencoding linguistic structures by graphs and of using graph rewriting rules to\ncompute on those structures. Justified by some linguistic considerations, graph\nrewriting is characterized by two features: first, there is no node creation\nalong computations and second, there are non-local edge modifications. Under\nthese hypotheses, we show that uniform termination is undecidable and that\nnon-uniform termination is decidable. We describe two termination techniques\nbased on weights and we give complexity bound on the derivation length for\nthese rewriting system.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:08 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Bonfante", "Guillaume", "", "LORIA Universit\u00e9 de Lorraine"], ["Guillaume", "Bruno", "", "LORIA Inria Nancy Grand-Est"]]}, {"id": "1302.6335", "submitter": "EPTCS", "authors": "Patrick Bahr (Department of Computer Science, University of\n  Copenhagen)", "title": "Convergence in Infinitary Term Graph Rewriting Systems is Simple\n  (Extended Abstract)", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 17-28", "doi": "10.4204/EPTCS.110.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this extended abstract, we present a simple approach to convergence on\nterm graphs that allows us to unify term graph rewriting and infinitary term\nrewriting. This approach is based on a partial order and a metric on term\ngraphs. These structures arise as straightforward generalisations of the\ncorresponding structures used in infinitary term rewriting. We compare our\nsimple approach to a more complicated approach that we developed earlier and\nshow that this new approach is superior in many ways. The only unfavourable\nproperty that we were able to identify, viz. failure of full correspondence\nbetween weak metric and partial order convergence, is rectified by adopting a\nstrong convergence discipline.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:15 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Bahr", "Patrick", "", "Department of Computer Science, University of\n  Copenhagen"]]}, {"id": "1302.6336", "submitter": "EPTCS", "authors": "Manfred Schmidt-Schauss", "title": "Linear Compressed Pattern Matching for Polynomial Rewriting (Extended\n  Abstract)", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 29-40", "doi": "10.4204/EPTCS.110.5", "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an extended abstract of an analysis of term rewriting where the\nterms in the rewrite rules as well as the term to be rewritten are compressed\nby a singleton tree grammar (STG). This form of compression is more general\nthan node sharing or representing terms as dags since also partial trees\n(contexts) can be shared in the compression. In the first part efficient but\ncomplex algorithms for detecting applicability of a rewrite rule under\nSTG-compression are constructed and analyzed. The second part applies these\nresults to term rewriting sequences.\n  The main result for submatching is that finding a redex of a left-linear rule\ncan be performed in polynomial time under STG-compression.\n  The main implications for rewriting and (single-position or parallel)\nrewriting steps are: (i) under STG-compression, n rewriting steps can be\nperformed in nondeterministic polynomial time. (ii) under STG-compression and\nfor left-linear rewrite rules a sequence of n rewriting steps can be performed\nin polynomial time, and (iii) for compressed rewrite rules where the left hand\nsides are either DAG-compressed or ground and STG-compressed, and an\nSTG-compressed target term, n rewriting steps can be performed in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:22 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Schmidt-Schauss", "Manfred", ""]]}, {"id": "1302.6337", "submitter": "EPTCS", "authors": "Beniamino Accattoli (Carnegie Mellon University)", "title": "Evaluating functions as processes", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 41-55", "doi": "10.4204/EPTCS.110.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A famous result by Milner is that the lambda-calculus can be simulated inside\nthe pi-calculus. This simulation, however, holds only modulo strong\nbisimilarity on processes, i.e. there is a slight mismatch between\nbeta-reduction and how it is simulated in the pi-calculus. The idea is that\nevaluating a lambda-term in the pi-calculus is like running an\nenvironment-based abstract machine, rather than applying ordinary\nbeta-reduction. In this paper we show that such an abstract-machine evaluation\ncorresponds to linear weak head reduction, a strategy arising from the\nrepresentation of lambda-terms as linear logic proof nets, and that the\nrelation between the two is as tight as it can be. The study is also smoothly\nrephrased in the call-by-value case, introducing a call-by-value analogous of\nlinear weak head reduction.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:30 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Accattoli", "Beniamino", "", "Carnegie Mellon University"]]}, {"id": "1302.6338", "submitter": "EPTCS", "authors": "Clemens Grabmayer (Department of Philosophy, Utrecht University, The\n  Netherlands), Jan Rochel (Department of Computing Sciences, Utrecht\n  University, The Netherlands)", "title": "Term Graph Representations for Cyclic Lambda-Terms", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 56-73", "doi": "10.4204/EPTCS.110.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study various representations for cyclic lambda-terms as higher-order or\nas first-order term graphs. We focus on the relation between\n'lambda-higher-order term graphs' (lambda-ho-term-graphs), which are\nfirst-order term graphs endowed with a well-behaved scope function, and their\nrepresentations as 'lambda-term-graphs', which are plain first-order term\ngraphs with scope-delimiter vertices that meet certain scoping requirements.\nSpecifically we tackle the question: Which class of first-order term graphs\nadmits a faithful embedding of lambda-ho-term-graphs in the sense that (i) the\nhomomorphism-based sharing-order on lambda-ho-term-graphs is preserved and\nreflected, and (ii) the image of the embedding corresponds closely to a natural\nclass (of lambda-term-graphs) that is closed under homomorphism?\n  We systematically examine whether a number of classes of lambda-term-graphs\nhave this property, and we find a particular class of lambda-term-graphs that\nsatisfies this criterion. Term graphs of this class are built from application,\nabstraction, variable, and scope-delimiter vertices, and have the\ncharacteristic feature that the latter two kinds of vertices have back-links to\nthe corresponding abstraction.\n  This result puts a handle on the concept of subterm sharing for higher-order\nterm graphs, both theoretically and algorithmically: We obtain an easily\nimplementable method for obtaining the maximally shared form of\nlambda-ho-term-graphs. Furthermore, we open up the possibility to pull back\nproperties from first-order term graphs to lambda-ho-term-graphs, properties\nsuch as the complete lattice structure of bisimulation equivalence classes with\nrespect to the sharing order.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:38 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Grabmayer", "Clemens", "", "Department of Philosophy, Utrecht University, The\n  Netherlands"], ["Rochel", "Jan", "", "Department of Computing Sciences, Utrecht\n  University, The Netherlands"]]}, {"id": "1302.6339", "submitter": "EPTCS", "authors": "Maribel Fern\\'andez, Ian Mackie, Matthew Walker", "title": "Bigraphical Nets", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 74-81", "doi": "10.4204/EPTCS.110.8", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction nets are a graphical model of computation, which has been used to\ndefine efficient evaluators for functional calculi, and specifically lambda\ncalculi with patterns. However, the flat structure of interaction nets forces\npattern matching and functional behaviour to be encoded at the same level,\nlosing some potential parallelism. In this paper, we introduce bigraphical\nnets, or binets for short, as a generalisation of interaction nets using ideas\nfrom bigraphs and port graphs, and we present a formal notation and operational\nsemantics for binets. We illustrate their expressive power by examples of\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:45 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Fern\u00e1ndez", "Maribel", ""], ["Mackie", "Ian", ""], ["Walker", "Matthew", ""]]}, {"id": "1302.6421", "submitter": "Jonathan Heras", "authors": "J\\'onathan Heras and Ekaterina Komendantskaya", "title": "ML4PG in Computer Algebra verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML4PG is a machine-learning extension that provides statistical proof hints\nduring the process of Coq/SSReflect proof development. In this paper, we use\nML4PG to find proof patterns in the CoqEAL library -- a library that was\ndevised to verify the correctness of Computer Algebra algorithms. In\nparticular, we use ML4PG to help us in the formalisation of an efficient\nalgorithm to compute the inverse of triangular matrices.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 13:02:36 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2013 15:25:05 GMT"}, {"version": "v3", "created": "Fri, 24 May 2013 08:01:20 GMT"}], "update_date": "2013-05-27", "authors_parsed": [["Heras", "J\u00f3nathan", ""], ["Komendantskaya", "Ekaterina", ""]]}, {"id": "1302.6514", "submitter": "Alberto Gatto", "authors": "Alberto Gatto", "title": "Bisimulation and p-morphism for branching-time logics with\n  indistinguishability relations", "comments": "10 pages, corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Zanardo, 1998, the Peircean semantics for branching-time logics is\nenriched with a notion of indistinguishability at a moment t between histories\npassing through t. Trees with indistinguishability relations provide a\nsemantics for a temporal language with tense and modal operators. In this paper\na notion of p-morphism and a notion of bisimulation, wrt this language and\nsemantics, are given and a number of preservation results are proven.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 17:47:37 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 13:37:48 GMT"}], "update_date": "2013-05-03", "authors_parsed": [["Gatto", "Alberto", ""]]}, {"id": "1302.6813", "submitter": "Petr Hajek", "authors": "Petr Hajek, Dagmar Harmancov\\'a, Francesc Esteva, Pere Garcia, Lluis\n  Godo", "title": "On Modal Logics for Qualitative Possibility in a Fuzzy Setting", "comments": "Appears in Proceedings of the Tenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1994)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1994-PG-278-285", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the possibilistic approach to uncertainty modeling, the paper presents\na modal logical system to reason about qualitative (comparative) statements of\nthe possibility (and necessity) of fuzzy propositions. We relate this\nqualitative modal logic to the many--valued analogues MVS5 and MVKD45 of the\nwell known modal logics of knowledge and belief S5 and KD45 respectively.\nCompleteness results are obtained for such logics and therefore, they extend\nprevious existing results for qualitative possibilistic logics in the classical\nnon-fuzzy setting.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 14:16:37 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Hajek", "Petr", ""], ["Harmancov\u00e1", "Dagmar", ""], ["Esteva", "Francesc", ""], ["Garcia", "Pere", ""], ["Godo", "Lluis", ""]]}, {"id": "1302.6890", "submitter": "Gudmund Grov PhD", "authors": "Gudmund Grov, Aleks Kissinger and Yuhui Lin", "title": "A Graphical Language for Proof Strategies", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-45221-5_23", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex automated proof strategies are often difficult to extract, visualise,\nmodify, and debug. Traditional tactic languages, often based on stack-based\ngoal propagation, make it easy to write proofs that obscure the flow of goals\nbetween tactics and are fragile to minor changes in input, proof structure or\nchanges to tactics themselves. Here, we address this by introducing a graphical\nlanguage called PSGraph for writing proof strategies. Strategies are\nconstructed visually by \"wiring together\" collections of tactics and evaluated\nby propagating goal nodes through the diagram via graph rewriting. Tactic nodes\ncan have many output wires, and use a filtering procedure based on goal-types\n(predicates describing the features of a goal) to decide where best to send\nnewly-generated sub-goals.\n  In addition to making the flow of goal information explicit, the graphical\nlanguage can fulfil the role of many tacticals using visual idioms like\nbranching, merging, and feedback loops. We argue that this language enables\ndevelopment of more robust proof strategies and provide several examples, along\nwith a prototype implementation in Isabelle.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 15:58:42 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2013 13:49:58 GMT"}], "update_date": "2014-06-13", "authors_parsed": [["Grov", "Gudmund", ""], ["Kissinger", "Aleks", ""], ["Lin", "Yuhui", ""]]}, {"id": "1302.6960", "submitter": "Guillem Godoy", "authors": "Luis Bargu\\~n\\'o (Universitat Polit\\'ecnica de Catalunya), Carles\n  Creus (Universitat Polit\\'ecnica de Catalunya), Guillem Godoy (Universitat\n  Polit\\'ecnica de Catalunya), Florent Jacquemard (INRIA Saclay, LSV-CNRS),\n  Camille Vacher (LIFL, Univ. Lille I, INRIA Lille)", "title": "Decidable Classes of Tree Automata Mixing Local and Global Constraints\n  Modulo Flat Theories", "comments": "39 pages, to appear in LMCS journal", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 2 (April 2,\n  2013) lmcs:1161", "doi": "10.2168/LMCS-9(2:1)2013", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a class of ranked tree automata TABG generalizing both the tree\nautomata with local tests between brothers of Bogaert and Tison (1992) and with\nglobal equality and disequality constraints (TAGED) of Filiot et al. (2007).\nTABG can test for equality and disequality modulo a given flat equational\ntheory between brother subterms and between subterms whose positions are\ndefined by the states reached during a computation. In particular, TABG can\ncheck that all the subterms reaching a given state are distinct. This\nconstraint is related to monadic key constraints for XML documents, meaning\nthat every two distinct positions of a given type have different values. We\nprove decidability of the emptiness problem for TABG. This solves, in\nparticular, the open question of the decidability of emptiness for TAGED. We\nfurther extend our result by allowing global arithmetic constraints for\ncounting the number of occurrences of some state or the number of different\nequivalence classes of subterms (modulo a given flat equational theory)\nreaching some state during a computation. We also adapt the model to unranked\nordered terms. As a consequence of our results for TABG, we prove the\ndecidability of a fragment of the monadic second order logic on trees extended\nwith predicates for equality and disequality between subtrees, and cardinality.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 12:52:02 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2013 09:29:25 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bargu\u00f1\u00f3", "Luis", "", "Universitat Polit\u00e9cnica de Catalunya"], ["Creus", "Carles", "", "Universitat Polit\u00e9cnica de Catalunya"], ["Godoy", "Guillem", "", "Universitat\n  Polit\u00e9cnica de Catalunya"], ["Jacquemard", "Florent", "", "INRIA Saclay, LSV-CNRS"], ["Vacher", "Camille", "", "LIFL, Univ. Lille I, INRIA Lille"]]}, {"id": "1302.7069", "submitter": "Achilles Beros", "authors": "Achilles Beros", "title": "Learning Theory in the Arithmetic Hierarchy", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the arithmetic complexity of index sets of uniformly computably\nenumerable families learnable under different learning criteria. We determine\nthe exact complexity of these sets for the standard notions of finite learning,\nlearning in the limit, behaviorally correct learning and anomalous learning in\nthe limit. In proving the $\\Sigma_5^0$-completeness result for behaviorally\ncorrect learning we prove a result of independent interest; if a uniformly\ncomputably enumerable family is not learnable, then for any computable learner\nthere is a $\\Delta_2^0$ enumeration witnessing failure.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 03:35:18 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Beros", "Achilles", ""]]}, {"id": "1302.7111", "submitter": "Ruggero Pagnan", "authors": "Ruggero Pagnan", "title": "Syllogisms in Rudimentary Linear Logic, Diagrammatically", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reading of the traditional syllogistics in a fragment of the\npropositional intuitionistic multiplicative linear logic and prove that with\nrespect to a diagrammatic logical calculus that we introduced in a previous\npaper, a syllogism is provable in such a fragment if and only if it is\ndiagrammatically provable. We extend this result to syllogistics with\ncomplemented terms \\`a la De Morgan, with respect to a suitable extension of\nthe diagrammatic reasoning system for the traditional case and a corresponding\nreading of such De Morgan style syllogistics in the previously referred to\nfragment of linear logic.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 08:40:40 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Pagnan", "Ruggero", ""]]}, {"id": "1302.7168", "submitter": "Peter beim Graben", "authors": "Peter beim Graben", "title": "Order effects in dynamic semantics", "comments": "Comment on a target article \"A quantum question order model supported\n  by empirical tests of an a priori and precise prediction\", Topics in\n  Cognitive Science, by Wang and Busemeyer (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their target article, \\citet{WangBusemeyer13} [A quantum question order\nmodel supported by empirical tests of an a priori and precise prediction.\n\\emph{Topics in Cognitive Science}] discuss question order effects in terms of\nincompatible projectors on a Hilbert space. In a similar vein, Blutner recently\npresented an orthoalgebraic query language essentially relying on dynamic\nupdate semantics. Here, I shall comment on some interesting analogies between\nthe different variants of dynamic semantics and generalized quantum theory to\nillustrate other kinds of order effects in human cognition, such as belief\nrevision, the resolution of anaphors, and default reasoning that result from\nthe crucial non-commutativity of mental operations upon the belief state of a\ncognitive agent.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 12:26:49 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Graben", "Peter beim", ""]]}, {"id": "1302.7251", "submitter": "Sofie De Clercq", "authors": "Sofie De Clercq and Steven Schockaert and Martine De Cock and Ann\n  Now\\'e", "title": "Modeling Stable Matching Problems with Answer Set Programming", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Stable Marriage Problem (SMP) is a well-known matching problem first\nintroduced and solved by Gale and Shapley (1962). Several variants and\nextensions to this problem have since been investigated to cover a wider set of\napplications. Each time a new variant is considered, however, a new algorithm\nneeds to be developed and implemented. As an alternative, in this paper we\npropose an encoding of the SMP using Answer Set Programming (ASP). Our encoding\ncan easily be extended and adapted to the needs of specific applications. As an\nillustration we show how stable matchings can be found when individuals may\ndesignate unacceptable partners and ties between preferences are allowed.\nSubsequently, we show how our ASP based encoding naturally allows us to select\nspecific stable matchings which are optimal according to a given criterion.\nEach time, we can rely on generic and efficient off-the-shelf answer set\nsolvers to find (optimal) stable matchings.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 16:43:43 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 05:39:33 GMT"}], "update_date": "2013-05-03", "authors_parsed": [["De Clercq", "Sofie", ""], ["Schockaert", "Steven", ""], ["De Cock", "Martine", ""], ["Now\u00e9", "Ann", ""]]}]