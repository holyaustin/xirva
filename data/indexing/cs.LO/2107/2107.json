[{"id": "2107.00032", "submitter": "Alex Raymond", "authors": "Alex Raymond, Matthew Malencia, Guilherme Paulino-Passos, and Amanda\n  Prorok", "title": "Agree to Disagree: Subjective Fairness in Privacy-Restricted\n  Decentralised Conflict Resolution", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is commonly seen as a property of the global outcome of a system and\nassumes centralisation and complete knowledge. However, in real decentralised\napplications, agents only have partial observation capabilities. Under limited\ninformation, agents rely on communication to divulge some of their private (and\nunobservable) information to others. When an agent deliberates to resolve\nconflicts, limited knowledge may cause its perspective of a correct outcome to\ndiffer from the actual outcome of the conflict resolution. This is subjective\nunfairness.\n  To enable decentralised, fairness-aware conflict resolution under privacy\nconstraints, we have two contributions: (1) a novel interaction approach and\n(2) a formalism of the relationship between privacy and fairness. Our proposed\ninteraction approach is an architecture for privacy-aware explainable conflict\nresolution where agents engage in a dialogue of hypotheses and facts. To\nmeasure the privacy-fairness relationship, we define subjective and objective\nfairness on both the local and global scope and formalise the impact of partial\nobservability due to privacy in these different notions of fairness.\n  We first study our proposed architecture and the privacy-fairness\nrelationship in the abstract, testing different argumentation strategies on a\nlarge number of randomised cultures. We empirically demonstrate the trade-off\nbetween privacy, objective fairness, and subjective fairness and show that\nbetter strategies can mitigate the effects of privacy in distributed systems.\nIn addition to this analysis across a broad set of randomised abstract\ncultures, we analyse a case study for a specific scenario: we instantiate our\narchitecture in a multi-agent simulation of prioritised rule-aware collision\navoidance with limited information disclosure.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 18:00:47 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Raymond", "Alex", ""], ["Malencia", "Matthew", ""], ["Paulino-Passos", "Guilherme", ""], ["Prorok", "Amanda", ""]]}, {"id": "2107.00086", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert, Thomas Rubiano (LIPN), Neea Rusch, Thomas Seiller\n  (LIPN, CNRS)", "title": "An extended and more practical mwp flow analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve and refine a method for certifying that the values' sizes computed\nby an imperative program will be bounded by polynomials in the program's\ninputs' sizes. Our work ''tames'' the non-determinism of the original analysis,\nand offers an innovative way of completing the analysis when a non-polynomial\ngrowth is found. We furthermore enrich the analyzed language by adding function\ndefinitions and calls, allowing to compose the analysis of different libraries\nand offering generally more modularity. The implementation of our improved\nmethod, discussed in a tool paper\n(https://hal.archives-ouvertes.fr/hal-03269121), also required to reason about\nthe efficiency of some of the needed operations on the matrices produced by the\nanalysis. It is our hope that this work will enable and facilitate static\nanalysis of source code to guarantee its correctness with respect to resource\nusages.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 08:18:00 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 09:45:47 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "LIPN"], ["Rubiano", "Thomas", "", "LIPN"], ["Rusch", "Neea", "", "LIPN, CNRS"], ["Seiller", "Thomas", "", "LIPN, CNRS"]]}, {"id": "2107.00097", "submitter": "Clement Aubert", "authors": "Cl\\'ement Aubert, Thomas Rubiano (LIPN), Neea Rusch, Thomas Seiller\n  (LIPN, CNRS)", "title": "An implementation of flow calculus for complexity analysis (tool paper)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CC cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract. We present a tool to automatically perform the data-size analysis\nof imperative programs written in C. This tool, called pymwp, is inspired by a\nclassical work on complexity analysis [10], and allows to certify that the size\nof the values computed by a program will be bounded by a polynomial in the\nprogram's inputs. Strategies to provide meaningful feedback on non-polynomial\nprograms and to ``tame'' the non-determinism of the original analysis were\nimplemented following recent progresses [3], but required particular care to\naccommodate the growing complexity of the analysis. The Python source code is\nintensively documented, and our numerous example files encompass the original\nexamples as well as multiple test cases. A pip package should make it easy to\ninstall pymwp on any plat-form, but an on-line demo is also available for\nconvenience.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 08:19:32 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 09:44:05 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "LIPN"], ["Rubiano", "Thomas", "", "LIPN"], ["Rusch", "Neea", "", "LIPN, CNRS"], ["Seiller", "Thomas", "", "LIPN, CNRS"]]}, {"id": "2107.00108", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe, Nils Jansen, Sebastian Junges, Joost-Pieter Katoen,\n  and Ufuk Topcu", "title": "Convex Optimization for Parameter Synthesis in MDPs", "comments": "Submitted to IEEE TAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic model checking aims to prove whether a Markov decision process\n(MDP) satisfies a temporal logic specification. The underlying methods rely on\nan often unrealistic assumption that the MDP is precisely known. Consequently,\nparametric MDPs (pMDPs) extend MDPs with transition probabilities that are\nfunctions over unspecified parameters. The parameter synthesis problem is to\ncompute an instantiation of these unspecified parameters such that the\nresulting MDP satisfies the temporal logic specification. We formulate the\nparameter synthesis problem as a quadratically constrained quadratic program\n(QCQP), which is nonconvex and is NP-hard to solve in general. We develop two\napproaches that iteratively obtain locally optimal solutions. The first\napproach exploits the so-called convex-concave procedure (CCP), and the second\napproach utilizes a sequential convex programming (SCP) method. The techniques\nimprove the runtime and scalability by multiple orders of magnitude compared to\nblack-box CCP and SCP by merging ideas from convex optimization and\nprobabilistic model checking. We demonstrate the approaches on a satellite\ncollision avoidance problem with hundreds of thousands of states and tens of\nthousands of parameters and their scalability on a wide range of commonly used\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 21:23:56 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2107.00111", "submitter": "Mary Southern", "authors": "Gopalan Nadathur and Mary Southern", "title": "A Logic for Reasoning About LF Specifications", "comments": "arXiv admin note: substantial text overlap with arXiv:2105.04110", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a logic named L_{LF} whose intended use is to formalize properties\nof specifications developed in the dependently typed lambda calculus LF. The\nlogic is parameterized by the LF signature that constitutes the specification.\nAtomic formulas correspond to typing derivations relative to this signature.\nThe logic includes a collection of propositional connectives and quantifiers.\nQuantification ranges over expressions that denote LF terms and LF contexts.\nQuantifiers of the first variety are qualified by simple types that describe\nthe functional structure associated with the variables they bind; deeper,\ndependency related properties are expressed by the body of the formula.\nContext-level quantifiers are qualified by context schemas that identify\npatterns of declarations out of which actual contexts may be constructed. The\nsemantics of variable-free atomic formulas is articulated via the derivability\nin LF of the judgements they encode. Propositional constants and connectives\nare understood in the usual manner and the meaning of quantifiers is explicated\nthrough substitutions of expressions that adhere to the type qualifications.\nThe logic is complemented by a proof system that enables reasoning that is\nsound with respect to the described semantics. The main novelties of the proof\nsystem are the provision for case-analysis style reasoning about LF judgements,\nsupport for inductive reasoning over the heights of LF derivations and the\nencoding of LF meta-theorems. The logic is motivated by the paradigmatic\nexample of type assignment in the simply-typed lambda calculus and the proof\nsystem is illustrated through the formalization of a proof of type uniqueness\nfor this calculus.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 21:33:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Nadathur", "Gopalan", ""], ["Southern", "Mary", ""]]}, {"id": "2107.00319", "submitter": "Giulio Manzonetto", "authors": "Giuseppe Della Penna and Benedetto Intrigila and Giulio Manzonetto", "title": "Addressing Machines as models of lambda-calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Turing machines and register machines have been used for decades in\ntheoretical computer science as abstract models of computation. Also the\n$\\lambda$-calculus has played a central role in this domain as it allows to\nfocus on the notion of functional computation, based on the substitution\nmechanism, while abstracting away from implementation details. The present\narticle starts from the observation that the equivalence between these\nformalisms is based on the Church-Turing Thesis rather than an actual encoding\nof $\\lambda$-terms into Turing (or register) machines. The reason is that these\nmachines are not well-suited for modelling \\lam-calculus programs.\n  We study a class of abstract machines that we call \\emph{addressing machine}\nsince they are only able to manipulate memory addresses of other machines. The\noperations performed by these machines are very elementary: load an address in\na register, apply a machine to another one via their addresses, and call the\naddress of another machine. We endow addressing machines with an operational\nsemantics based on leftmost reduction and study their behaviour. The set of\naddresses of these machines can be easily turned into a combinatory algebra. In\norder to obtain a model of the full untyped $\\lambda$-calculus, we need to\nintroduce a rule that bares similarities with the $\\omega$-rule and the rule\n$\\zeta_\\beta$ from combinatory logic.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 09:19:09 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Della Penna", "Giuseppe", ""], ["Intrigila", "Benedetto", ""], ["Manzonetto", "Giulio", ""]]}, {"id": "2107.00341", "submitter": "Gonzague Yernaux", "authors": "Gonzague Yernaux and Wim Vanhoof", "title": "Technical Report: Anti-unification of Unordered Goals", "comments": "Submitted to CSL 2022", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anti-unification in logic programming refers to the process of capturing\ncommon syntactic structure among given goals, computing as such a single new\ngoal that is more general and hence called a generalization of the given goals.\nFinding an arbitrary common generalization for two goals is trivial, but\nlooking for those common generalizations that are either as large as possible\n(called largest common generalizations) or as specific as possible (called most\nspecific generalizations) is a non-trivial optimization problem, in particular\nwhen goals are considered to be unordered sets of atoms. In this work we\nprovide an in-depth study of the problem by defining two different\ngeneralization relations. We formulate a characterization of what constitutes a\nmost specific generalization in both settings. While these generalizations can\nbe computed in polynomial time, we show that when the number of variables in\nthe generalization needs to be minimized, the problem becomes NP-hard. We\nsubsequently revisit an abstraction of the largest common generalization when\nanti-unification is based on injective variable renamings, and prove that it\ncan be computed in polynomially bounded time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:11:07 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Yernaux", "Gonzague", ""], ["Vanhoof", "Wim", ""]]}, {"id": "2107.00369", "submitter": "Federico Igne", "authors": "Federico Igne, Stefano Germano, Ian Horrocks", "title": "Computing CQ lower-bounds over OWL 2 through approximation to RSA", "comments": "26 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conjunctive query (CQ) answering over knowledge bases is an important\nreasoning task. However, with expressive ontology languages such as OWL, query\nanswering is computationally very expensive. The PAGOdA system addresses this\nissue by using a tractable reasoner to compute lower and upper-bound\napproximations, falling back to a fully-fledged OWL reasoner only when these\nbounds don't coincide. The effectiveness of this approach critically depends on\nthe quality of the approximations, and in this paper we explore a technique for\ncomputing closer approximations via RSA, an ontology language that subsumes all\nthe OWL 2 profiles while still maintaining tractability. We present a novel\napproximation of OWL 2 ontologies into RSA, and an algorithm to compute a\ncloser (than PAGOdA) lower bound approximation using the RSA combined approach.\nWe have implemented these algorithms in a prototypical CQ answering system, and\nwe present a preliminary evaluation of our system that shows significant\nperformance improvements w.r.t. PAGOdA.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:13:00 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Igne", "Federico", ""], ["Germano", "Stefano", ""], ["Horrocks", "Ian", ""]]}, {"id": "2107.00378", "submitter": "Jan-Hendrik Lorenz", "authors": "Florian W\\\"orz and Jan-Hendrik Lorenz", "title": "Evidence for Long-Tails in SLS Algorithms", "comments": "To appear at ESA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic local search (SLS) is a successful paradigm for solving the\nsatisfiability problem of propositional logic. A recent development in this\narea involves solving not the original instance, but a modified, yet logically\nequivalent one. Empirically, this technique was found to be promising as it\nimproves the performance of state-of-the-art SLS solvers.\n  Currently, there is only a shallow understanding of how this modification\ntechnique affects the runtimes of SLS solvers. Thus, we model this modification\nprocess and conduct an empirical analysis of the hardness of logically\nequivalent formulas. Our results are twofold. First, if the modification\nprocess is treated as a random process, a lognormal distribution perfectly\ncharacterizes the hardness; implying that the hardness is long-tailed. This\nmeans that the modification technique can be further improved by implementing\nan additional restart mechanism. Thus, as a second contribution, we\ntheoretically prove that all algorithms exhibiting this long-tail property can\nbe further improved by restarts. Consequently, all SAT solvers employing this\nmodification technique can be enhanced.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:31:39 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["W\u00f6rz", "Florian", ""], ["Lorenz", "Jan-Hendrik", ""]]}, {"id": "2107.00612", "submitter": "Michael Warren", "authors": "Byron Heersink, Pape Sylla and Michael A. Warren", "title": "Formal verification of octorotor flight envelope using barrier functions\n  and SMT solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an approach for formally verifying the safety of the\nflight controller of an octorotor platform. Our method involves finding regions\nof the octorotor's state space that are considered safe, and which can be\nproven to be invariant with respect to the dynamics. Specifically, exponential\nbarrier functions are used to construct candidate invariant regions near\ndesired commanded states. The proof that these regions are invariant is\ndiscovered automatically using the dReal SMT solver, which ensures the accurate\ncommand tracking of the octorotor to within a certain margin of error. Rotor\nfailures in which rotor thrusts become stuck at fixed values are considered and\naccounted for via a pseudo-inverse control allocator. The safety of the control\nallocator is verified in dReal by checking that the thrusts demanded by the\nallocator never exceed the capability of the rotors. We apply our approach on a\nspecific octorotor example and verify the desired command tracking properties\nof the controller under normal conditions and various combinations of rotor\nfailures.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:01:47 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Heersink", "Byron", ""], ["Sylla", "Pape", ""], ["Warren", "Michael A.", ""]]}, {"id": "2107.00723", "submitter": "Siddharth Priya", "authors": "Siddharth Priya, Xiang Zhou, Yusen Su, Yakir Vizel, Yuyan Bao and Arie\n  Gurfinkel", "title": "Verifying Verified Code", "comments": "24 pages, 17 figures, to be included in ATVA 2021 conference\n  proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recent case study from AWS by Chong et al. proposes an effective\nmethodology for Bounded Model Checking in industry. In this paper, we report on\na follow up case study that explores the methodology from the perspective of\nthree research questions: (a) can proof artifacts be used across verification\ntools; (b) are there bugs in verified code; and (c) can specifications be\nimproved. To study these questions, we port the verification tasks for\n$\\texttt{aws-c-common}$ library to SEAHORN and KLEE. We show the benefits of\nusing compiler semantics and cross-checking specifications with different\nverification techniques, and call for standardizing proof library extensions to\nincrease specification reuse. The verification tasks discussed are publicly\navailable online.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 19:59:32 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Priya", "Siddharth", ""], ["Zhou", "Xiang", ""], ["Su", "Yusen", ""], ["Vizel", "Yakir", ""], ["Bao", "Yuyan", ""], ["Gurfinkel", "Arie", ""]]}, {"id": "2107.00804", "submitter": "Yuxin Deng", "authors": "Yuxin Deng and Yuan Feng", "title": "Formal Semantics of a Classical-Quantum Language", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the formal semantics of a simple imperative language that has\nboth classical and quantum constructs. More specifically, we provide an\noperational semantics, a denotational semantics and two Hoare-style proof\nsystems: an abstract one and a concrete one. The two proof systems are\nsatisfaction-based, as inspired by the program logics of Barthe et al for\nprobabilistic programs. The abstract proof system turns out to be sound and\nrelatively complete, while the concrete one is sound only.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 02:30:23 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Deng", "Yuxin", ""], ["Feng", "Yuan", ""]]}, {"id": "2107.00929", "submitter": "Shaun Azzopardi", "authors": "Shaun Azzopardi, Nir Piterman, Gerardo Schneider", "title": "Incorporating Monitors in Reactive Synthesis without Paying the Price", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal synthesis attempts to construct reactive programs that satisfy a\ngiven declarative (LTL) formula. Practitioners have found it challenging to\nwork exclusively with declarative specifications, and have found languages that\ncombine modelling with declarative specifications more useful. Synthesised\ncontrollers may also need to work with pre-existing or manually constructed\nprograms. In this paper we explore an approach that combines synthesis of\ndeclarative specifications in the presence of an existing behaviour model as a\nmonitor, with the benefit of not having to reason about the state space of the\nmonitor. We suggest a formal language with automata monitors as non-repeating\nand repeating triggers for LTL formulas. We use symbolic automata with memory\nas triggers, resulting in a strictly more expressive and succinct language than\nexisting regular expression triggers. We give a compositional synthesis\nprocedure for this language, where reasoning about the monitor state space is\nminimal. To show the advantages of our approach we apply it to specifications\nrequiring counting and constraints over arbitrarily long sequence of events,\nwhere we can also see the power of parametrisation, easily handled in our\napproach. We provide a tool to construct controllers (in the form of symbolic\nautomata) for our language.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 09:37:55 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Azzopardi", "Shaun", ""], ["Piterman", "Nir", ""], ["Schneider", "Gerardo", ""]]}, {"id": "2107.01136", "submitter": "Niklas Metzger", "authors": "Bernd Finkbeiner, Felix Klein, Niklas Metzger", "title": "Live Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesis automatically constructs an implementation that satisfies a given\nlogical specification. In this paper, we study the live synthesis problem,\nwhere the synthesized implementation replaces an already running system. In\naddition to satisfying its own specification, the synthesized implementation\nmust guarantee a sound transition from the previous implementation. This\nversion of the synthesis problem is highly relevant in always-on applications,\nwhere updates happen while the system is running. To specify the correct\nhandover between the old and new implementation, we introduce an extension of\nlinear-time temporal logic (LTL) called LiveLTL. A LiveLTL specification\ndefines separate requirements on the two implementations and ensures that the\nnew implementation satisfies, in addition to its own requirements, any\nobligations left unfinished by the old implementation. For specifications in\nLiveLTL, we show that the live synthesis problem can be solved within the same\ncomplexity bound as standard reactive synthesis, i.e., in 2EXPTIME. Our\nexperiments show the necessity of live synthesis for LiveLTL specifications\ncreated from benchmarks of SYNTCOMP and robot control.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:25:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Klein", "Felix", ""], ["Metzger", "Niklas", ""]]}, {"id": "2107.01155", "submitter": "Alejandro Aguirre", "authors": "Alejandro Aguirre, Gilles Barthe, Marco Gaboardi, Deepak Garg, Shin-ya\n  Katsumata, and Tetsuya Sato", "title": "Higher-order probabilistic adversarial computations: Categorical\n  semantics and program logics", "comments": "Full version of ICFP 21 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial computations are a widely studied class of computations where\nresource-bounded probabilistic adversaries have access to oracles, i.e.,\nprobabilistic procedures with private state. These computations arise routinely\nin several domains, including security, privacy and machine learning. In this\npaper, we develop program logics for reasoning about adversarial computations\nin a higher-order setting. Our logics are built on top of a simply typed\n$\\lambda$-calculus extended with a graded monad for probabilities and state.\nThe grading is used to model and restrict the memory footprint and the cost (in\nterms of oracle calls) of computations. Under this view, an adversary is a\nhigher-order expression that expects as arguments the code of its oracles. We\ndevelop unary program logics for reasoning about error probabilities and\nexpected values, and a relational logic for reasoning about coupling-based\nproperties. All logics feature rules for adversarial computations, and yield\nguarantees that are valid for all adversaries that satisfy a fixed resource\npolicy. We prove the soundness of the logics in the category of quasi-Borel\nspaces, using a general notion of graded predicate liftings, and we use logical\nrelations over graded predicate liftings to establish the soundness of proof\nrules for adversaries. We illustrate the working of our logics with simple but\nillustrative examples.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:54:42 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Aguirre", "Alejandro", ""], ["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""], ["Garg", "Deepak", ""], ["Katsumata", "Shin-ya", ""], ["Sato", "Tetsuya", ""]]}, {"id": "2107.01186", "submitter": "Renaud Vilmart", "authors": "Renaud Vilmart", "title": "Quantum Multiple-Valued Decision Diagrams in Graphical Calculi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical calculi such as the ZH-calculus are powerful tools in the study and\nanalysis of quantum processes, with links to other models of quantum\ncomputation such as quantum circuits, measurement-based computing, etc.\n  A somewhat compact but systematic way to describe a quantum process is\nthrough the use of quantum multiple-valued decision diagrams (QMDDs), which\nhave already been used for the synthesis of quantum circuits as well as for\nverification.\n  We show in this paper how to turn a QMDD into an equivalent ZH-diagram, and\nvice-versa, and show how reducing a QMDD translates in the ZH-Calculus, hence\nallowing tools from one formalism to be used into the other.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:50:11 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Vilmart", "Renaud", ""]]}, {"id": "2107.01428", "submitter": "Konrad Dabrowski", "authors": "Konrad K. Dabrowski and Peter Jonsson and Sebastian Ordyniak and\n  George Osipov", "title": "Solving Infinite-Domain CSPs Using the Patchwork Property", "comments": "34 pages, 2 figures. Parts of this article appeared in the\n  proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constraint satisfaction problem (CSP) has important applications in\ncomputer science and AI. In particular, infinite-domain CSPs have been\nintensively used in subareas of AI such as spatio-temporal reasoning. Since\nconstraint satisfaction is a computationally hard problem, much work has been\ndevoted to identifying restricted problems that are efficiently solvable. One\nway of doing this is to restrict the interactions of variables and constraints,\nand a highly successful approach is to bound the treewidth of the underlying\nprimal graph. Bodirsky & Dalmau [J. Comput. System. Sci. 79(1), 2013] and Huang\net al. [Artif. Intell. 195, 2013] proved that CSP$(\\Gamma)$ can be solved in\n$n^{f(w)}$ time (where $n$ is the size of the instance, $w$ is the treewidth of\nthe primal graph and $f$ is a computable function) for certain classes of\nconstraint languages $\\Gamma$. We improve this bound to $f(w) \\cdot n^{O(1)}$,\nwhere the function $f$ only depends on the language $\\Gamma$, for CSPs whose\nbasic relations have the patchwork property. Hence, such problems are\nfixed-parameter tractable and our algorithm is asymptotically faster than the\nprevious ones. Additionally, our approach is not restricted to binary\nconstraints, so it is applicable to a strictly larger class of problems than\nthat of Huang et al. However, there exist natural problems that are covered by\nBodirsky & Dalmau's algorithm but not by ours, and we begin investigating ways\nof generalising our results to larger families of languages. We also analyse\nour algorithm with respect to its running time and show that it is optimal\n(under the Exponential Time Hypothesis) for certain languages such as Allen's\nInterval Algebra.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 13:04:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dabrowski", "Konrad K.", ""], ["Jonsson", "Peter", ""], ["Ordyniak", "Sebastian", ""], ["Osipov", "George", ""]]}, {"id": "2107.01468", "submitter": "A V Sreejith", "authors": "Bharat Adsul, Saptarshi Sarkar, A.V. Sreejith", "title": "First-Order logic and its Infinitary Quantifier Extensions over\n  Countable Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We contribute to the refined understanding of the language-logic-algebra\ninterplay in the context of first-order properties of countable words. We\nestablish decidable algebraic characterizations of one variable fragment of FO\nas well as boolean closure of existential fragment of FO via a strengthening of\nSimon's theorem about piecewise testable languages. We propose a new extension\nof FO which admits infinitary quantifiers to reason about the inherent\ninfinitary properties of countable words. We provide a very natural and\nhierarchical block-product based characterization of the new extension. We also\nexplicate its role in view of other natural and classical logical systems such\nas WMSO and FO[cut] - an extension of FO where quantification over\nDedekind-cuts is allowed. We also rule out the possibility of a finite basis\nfor a block-product based characterization of these logical systems. Finally,\nwe report simple but novel algebraic characterizations of one variable\nfragments of the hierarchies of the new proposed extension of FO.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 17:08:04 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Adsul", "Bharat", ""], ["Sarkar", "Saptarshi", ""], ["Sreejith", "A. V.", ""]]}, {"id": "2107.01542", "submitter": "Gershom Bazerman", "authors": "Gershom Bazerman", "title": "The Semantics of Package Management via Event Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an approach to the semantics of package management which relates\nit to general event structures, well-known mathematical objects used in the\nsemantics of concurrent, nondeterministic systems. In this approach, the data\nof a package repository is treated as a declarative specification of a\nnondeterministic, concurrent program. We introduce a process calculus\ncorresponding to this data, and investigate its operational and categorical\nsemantics. Our hope is this lays the basis for further formal study of package\nmanagement in which the weight of existing tools can be brought to bear.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 05:14:05 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bazerman", "Gershom", ""]]}, {"id": "2107.01544", "submitter": "EPTCS", "authors": "Chantal Keller (JKU Linz), Mathias Fleury (LRI, Universit\\'e Paris\n  Saclay, and CNRS)", "title": "Proceedings Seventh Workshop on Proof eXchange for Theorem Proving", "comments": null, "journal-ref": "EPTCS 336, 2021", "doi": "10.4204/EPTCS.336", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This volume of EPTCS contains the proceedings of the Seventh Workshop on\nProof Exchange for Theorem Proving (PxTP 2021), held on 11 July 2021 as part of\nthe CADE-28 online conference in Pittsburgh, USA. The PxTP workshop series\nbrings together researchers working on various aspects of communication,\nintegration, and cooperation between reasoning systems and formalisms, with a\nspecial focus on proofs. The progress in computer-aided reasoning, both\nautomated and interactive, during the past decades, made it possible to build\ndeduction tools that are increasingly more applicable to a wider range of\nproblems and are able to tackle larger problems progressively faster. In recent\nyears, cooperation between such tools in larger systems has demonstrated the\npotential to reduce the amount of manual intervention. Cooperation between\nreasoning systems relies on availability of theoretical formalisms and\npractical tools to exchange problems, proofs, and models. The PxTP workshop\nseries strives to encourage such cooperation by inviting contributions on all\naspects of cooperation between reasoning tools, whether automatic or\ninteractive.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 05:29:34 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Keller", "Chantal", "", "JKU Linz"], ["Fleury", "Mathias", "", "LRI, Universit\u00e9 Paris\n  Saclay, and CNRS"]]}, {"id": "2107.01594", "submitter": "Nicolai Kraus", "authors": "Nicolai Kraus and Jakob von Raumer", "title": "A Rewriting Coherence Theorem with Applications in Homotopy Type Theory", "comments": "30 pages. arXiv admin note: text overlap with arXiv:2001.07655", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-dimensional rewriting systems are tools to analyse the structure of\nformally reducing terms to normal forms, as well as comparing the different\nreduction paths that lead to those normal forms. This higher structure can be\ncaptured by finding a homotopy basis for the rewriting system. We show that the\nbasic notions of confluence and wellfoundedness are sufficient to recursively\nbuild such a homotopy basis, with a construction reminiscent of an argument by\nCraig C. Squier. We then go on to translate this construction to the setting of\nhomotopy type theory, where managing equalities between paths is important in\norder to construct functions which are coherent with respect to higher\ndimensions. Eventually, we apply the result to approximate a series of open\nquestions in homotopy type theory, such as the characterisation of the homotopy\ngroups of the free group on a set and the pushout of 1-types.\n  This paper expands on our previous conference contribution \"Coherence via\nWellfoundedness\" (arXiv:2001.07655) by laying out the construction in the\nlanguage of higher-dimensional rewriting.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 11:01:36 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kraus", "Nicolai", ""], ["von Raumer", "Jakob", ""]]}, {"id": "2107.01687", "submitter": "Stefan Kiefer", "authors": "Stefan Kiefer and Pavel Semukhin and Cas Widdershoven", "title": "Linear-Time Model Checking Branching Processes", "comments": "full version of a CONCUR'21 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Multi-type) branching processes are a natural and well-studied model for\ngenerating random infinite trees. Branching processes feature both\nnondeterministic and probabilistic branching, generalizing both transition\nsystems and Markov chains (but not generally Markov decision processes). We\nstudy the complexity of model checking branching processes against linear-time\nomega-regular specifications: is it the case almost surely that every branch of\na tree randomly generated by the branching process satisfies the omega-regular\nspecification? The main result is that for LTL specifications this problem is\nin PSPACE, subsuming classical results for transition systems and Markov\nchains, respectively. The underlying general model-checking algorithm is based\non the automata-theoretic approach, using unambiguous B\\\"uchi automata.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 17:18:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kiefer", "Stefan", ""], ["Semukhin", "Pavel", ""], ["Widdershoven", "Cas", ""]]}, {"id": "2107.01815", "submitter": "Brae Webb", "authors": "Brae J. Webb, Mark Utting, Ian J. Hayes", "title": "A Formal Semantics of the GraalVM Intermediate Representation", "comments": "16 pages, 8 figures, to be published to ATVA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The optimization phase of a compiler is responsible for transforming an\nintermediate representation (IR) of a program into a more efficient form.\nModern optimizers, such as that used in the GraalVM compiler, use an IR\nconsisting of a sophisticated graph data structure that combines data flow and\ncontrol flow into the one structure. As part of a wider project on the\nverification of optimization passes of GraalVM, this paper describes a\nsemantics for its IR within Isabelle/HOL. The semantics consists of a big-step\noperational semantics for data nodes (which are represented in a graph-based\nstatic single assignment (SSA) form) and a small-step operational semantics for\nhandling control flow including heap-based reads and writes, exceptions, and\nmethod calls. We have proved a suite of canonicalization optimizations and\nconditional elimination optimizations with respect to the semantics.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 06:48:18 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Webb", "Brae J.", ""], ["Utting", "Mark", ""], ["Hayes", "Ian J.", ""]]}, {"id": "2107.01877", "submitter": "Lia Morra", "authors": "Francesco Manigrasso and Filomeno Davide Miro and Lia Morra and\n  Fabrizio Lamberti", "title": "Faster-LTN: a neuro-symbolic, end-to-end object detection architecture", "comments": "accepted for presentation at ICANN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of semantic relationships between objects represented in an\nimage is one of the fundamental challenges in image interpretation.\nNeural-Symbolic techniques, such as Logic Tensor Networks (LTNs), allow the\ncombination of semantic knowledge representation and reasoning with the ability\nto efficiently learn from examples typical of neural networks. We here propose\nFaster-LTN, an object detector composed of a convolutional backbone and an LTN.\nTo the best of our knowledge, this is the first attempt to combine both\nframeworks in an end-to-end training setting. This architecture is trained by\noptimizing a grounded theory which combines labelled examples with prior\nknowledge, in the form of logical axioms. Experimental comparisons show\ncompetitive performance with respect to the traditional Faster R-CNN\narchitecture.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:09:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Manigrasso", "Francesco", ""], ["Miro", "Filomeno Davide", ""], ["Morra", "Lia", ""], ["Lamberti", "Fabrizio", ""]]}, {"id": "2107.01883", "submitter": "Sandro Stucki", "authors": "Sandro Stucki and Paolo G. Giarrusso", "title": "A Theory of Higher-Order Subtyping with Type Intervals (Extended\n  Version)", "comments": "73 pages; to be presented at the 26th ACM SIGPLAN International\n  Conference on Functional Programming (ICFP 2021), 22-27 August 2021", "journal-ref": "Proc. ACM Program. Lang. 5 (2021) 69:1-69:30 (ICFP)", "doi": "10.1145/3473574", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The calculus of Dependent Object Types (DOT) has enabled a more principled\nand robust implementation of Scala, but its support for type-level computation\nhas proven insufficient. As a remedy, we propose $F^\\omega_{..}$, a rigorous\ntheoretical foundation for Scala's higher-kinded types. $F^\\omega_{..}$ extends\n$F^\\omega_{<:}$ with interval kinds, which afford a unified treatment of\nimportant type- and kind-level abstraction mechanisms found in Scala, such as\nbounded quantification, bounded operator abstractions, translucent type\ndefinitions and first-class subtyping constraints. The result is a flexible and\ngeneral theory of higher-order subtyping. We prove type and kind safety of\n$F^\\omega_{..}$, as well as weak normalization of types and undecidability of\nsubtyping. All our proofs are mechanized in Agda using a fully syntactic\napproach based on hereditary substitution.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:14:53 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Stucki", "Sandro", ""], ["Giarrusso", "Paolo G.", ""]]}, {"id": "2107.01917", "submitter": "Vedad Hadzic", "authors": "Vedad Hadzic, Robert Primas and Roderick Bloem", "title": "Proving SIFA Protection of Masked Redundant Circuits", "comments": "This is the extended version of the paper published at ATVA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementation attacks like side-channel and fault attacks pose a\nconsiderable threat to cryptographic devices that are physically accessible by\nan attacker. As a consequence, devices like smart cards implement corresponding\ncountermeasures like redundant computation and masking. Recently, statistically\nineffective fault attacks (SIFA) were shown to be able to circumvent these\nclassical countermeasure techniques. We present a new approach for verifying\nthe SIFA protection of arbitrary masked implementations in both hardware and\nsoftware. The proposed method uses Boolean dependency analysis, factorization,\nand known properties of masked computations to show whether the fault detection\nmechanism of redundant masked circuits can leak information about the processed\nsecret values. We implemented this new method in a tool called Danira, which\ncan show the SIFA resistance of cryptographic implementations like AES S-Boxes\nwithin minutes.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 10:20:45 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hadzic", "Vedad", ""], ["Primas", "Robert", ""], ["Bloem", "Roderick", ""]]}, {"id": "2107.01998", "submitter": "Tim Lyon", "authors": "Tim S. Lyon", "title": "Nested Sequents for Intuitionistic Modal Logics via Structural\n  Refinement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM cs.FL math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We employ a recently developed methodology -- called \"structural refinement\"\n-- to extract nested sequent systems for a sizable class of intuitionistic\nmodal logics from their respective labelled sequent systems. This method can be\nseen as a means by which labelled sequent systems can be transformed into\nnested sequent systems through the introduction of propagation rules and the\nelimination of structural rules, followed by a notational translation. The\nnested systems we obtain incorporate propagation rules that are parameterized\nwith formal grammars, and which encode certain frame conditions expressible as\nfirst-order Horn formulae that correspond to a subclass of the Scott-Lemmon\naxioms. We show that our nested systems are sound, cut-free complete, and admit\nhp-admissibility of typical structural rules.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:17:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lyon", "Tim S.", ""]]}, {"id": "2107.02060", "submitter": "Eike Neumann", "authors": "Julian D'Costa, Engel Lefaucheux, Eike Neumann, Jo\\\"el Ouaknine, James\n  Worrell", "title": "On the Complexity of the Escape Problem for Linear Dynamical Systems\n  over Compact Semialgebraic Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of the Escape Problem for discrete-time\nlinear dynamical systems over compact semialgebraic sets, or equivalently the\nTermination Problem for affine loops with compact semialgebraic guard sets.\nConsider the fragment of the theory of the reals consisting of negation-free\n$\\exists \\forall$-sentences without strict inequalities. We derive several\nequivalent characterisations of the associated complexity class which\ndemonstrate its robustness and illustrate its expressive power. We show that\nthe Compact Escape Problem is complete for this class.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:45:23 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["D'Costa", "Julian", ""], ["Lefaucheux", "Engel", ""], ["Neumann", "Eike", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Worrell", "James", ""]]}, {"id": "2107.02203", "submitter": "Missula Meghana", "authors": "Ansuman Biswas, Ashutosh Gupta, Meghana Missula, Mukund Thattai", "title": "Automated inference of production rules for glycans", "comments": "23 pages; 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Glycans are tree-like polymers made up of sugar monomer building blocks. They\nare found on the surface of all living cells, and distinct glycan trees act as\nidentity markers for distinct cell types. Proteins called GTase enzymes\nassemble glycans via the successive addition of monomer building blocks. The\nrules by which the enzymes operate are not fully understood. In this paper, we\npresent the first SMT-solver-based iterative method that infers the assembly\nprocess of the glycans by analyzing the set of glycans from a cell. We have\nbuilt a tool based on the method and applied it to infer rules based on\npublished glycan data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:12:08 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Biswas", "Ansuman", ""], ["Gupta", "Ashutosh", ""], ["Missula", "Meghana", ""], ["Thattai", "Mukund", ""]]}, {"id": "2107.02333", "submitter": "Viorica  Sofronie-Stokkermans", "authors": "Dennis Peuter, Philipp Marohn and Viorica Sofronie-Stokkermans", "title": "Symbol Elimination for Parametric Second-Order Entailment Problems (with\n  Applications to Problems in Wireless Network Theory)", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze possibilities of second-order quantifier elimination for formulae\ncontaining parameters -- constants or functions. For this, we use a constraint\nresolution calculus obtained from specializing the hierarchical superposition\ncalculus. If saturation terminates, we analyze possibilities of obtaining\nweakest constraints on parameters which guarantee satisfiability. If the\nsaturation does not terminate, we identify situations in which finite\nrepresentations of infinite saturated sets exist. We identify situations in\nwhich entailment between formulae expressed using second-order quantification\ncan be effectively checked. We illustrate the ideas on a series of examples\nfrom wireless network research.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 01:04:22 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Peuter", "Dennis", ""], ["Marohn", "Philipp", ""], ["Sofronie-Stokkermans", "Viorica", ""]]}, {"id": "2107.02351", "submitter": "EPTCS", "authors": "Maria Paola Bonacina (Universit\\`a degli Studi di Verona, Italy)", "title": "Proof Generation in CDSAT", "comments": "In Proceedings PxTP 2021, arXiv:2107.01544", "journal-ref": "EPTCS 336, 2021, pp. 1-4", "doi": "10.4204/EPTCS.336.1", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The main ideas in the CDSAT (Conflict-Driven Satisfiability) framework for\nSMT are summarized, leading to approaches to proof generation in CDSAT.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:35:21 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Bonacina", "Maria Paola", "", "Universit\u00e0 degli Studi di Verona, Italy"]]}, {"id": "2107.02352", "submitter": "EPTCS", "authors": "Quentin Garchery", "title": "A Framework for Proof-carrying Logical Transformations", "comments": "In Proceedings PxTP 2021, arXiv:2107.01544", "journal-ref": "EPTCS 336, 2021, pp. 5-23", "doi": "10.4204/EPTCS.336.2", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In various provers and deductive verification tools, logical transformations\nare used extensively in order to reduce a proof task into a number of simpler\ntasks. Logical transformations are often part of the trusted base of such\ntools. In this paper, we develop a framework to improve confidence in their\nresults. We follow a modular and skeptical approach: transformations are\ninstrumented independently of each other and produce certificates that are\nchecked by a third-party tool. Logical transformations are considered in a\nhigher-order logic, with type polymorphism and built-in theories such as\nequality and integer arithmetic. We develop a language of proof certificates\nfor them and use it to implement the full chain of certificate generation and\ncertificate verification.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:35:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Garchery", "Quentin", ""]]}, {"id": "2107.02353", "submitter": "EPTCS", "authors": "Valentin Blot (LMF, Inria, Universit\\'e Paris-Saclay), Louise Dubois\n  de Prisque (LMF, Inria, Universit\\'e Paris-Saclay), Chantal Keller (LMF,\n  Universit\\'e Paris-Saclay), Pierre Vial (LMF, Inria, Universit\\'e\n  Paris-Saclay)", "title": "General Automation in Coq through Modular Transformations", "comments": "In Proceedings PxTP 2021, arXiv:2107.01544", "journal-ref": "EPTCS 336, 2021, pp. 24-39", "doi": "10.4204/EPTCS.336.3", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Whereas proof assistants based on Higher-Order Logic benefit from external\nsolvers' automation, those based on Type Theory resist automation and thus\nrequire more expertise. Indeed, the latter use a more expressive logic which is\nfurther away from first-order logic, the logic of most automatic theorem\nprovers. In this article, we develop a methodology to transform a subset of Coq\ngoals into first-order statements that can be automatically discharged by\nautomatic provers. The general idea is to write modular, pairwise independent\ntransformations and combine them. Each of these eliminates a specific aspect of\nCoq logic towards first-order logic. As a proof of concept, we apply this\nmethodology to a set of simple but crucial transformations which extend the\nlocal context with proven first-order assertions that make Coq definitions and\nalgebraic types explicit. They allow users of Coq to solve non-trivial goals\nautomatically. This methodology paves the way towards the definition and\ncombination of more complex transformations, making Coq more accessible.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:35:47 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Blot", "Valentin", "", "LMF, Inria, Universit\u00e9 Paris-Saclay"], ["de Prisque", "Louise Dubois", "", "LMF, Inria, Universit\u00e9 Paris-Saclay"], ["Keller", "Chantal", "", "LMF,\n  Universit\u00e9 Paris-Saclay"], ["Vial", "Pierre", "", "LMF, Inria, Universit\u00e9\n  Paris-Saclay"]]}, {"id": "2107.02354", "submitter": "EPTCS", "authors": "Hans-J\\\"org Schurr (University of Lorraine, CNRS, Inria, and LORIA),\n  Mathias Fleury (Johannes Kepler University Linz), Haniel Barbosa\n  (Universidade Federal de Minas Gerais), Pascal Fontaine (University of\n  Li\\`ege)", "title": "Alethe: Towards a Generic SMT Proof Format (extended abstract)", "comments": "In Proceedings PxTP 2021, arXiv:2107.01544", "journal-ref": "EPTCS 336, 2021, pp. 49-54", "doi": "10.4204/EPTCS.336.6", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The first iteration of the proof format used by the SMT solver veriT was\npresented ten years ago at the first PxTP workshop. Since then the format has\nmatured. veriT proofs are used within multiple applications, and other solvers\ngenerate proofs in the same format. We would now like to gather feedback from\nthe community to guide future developments. Towards this, we review the history\nof the format, present our pragmatic approach to develop the format, and also\ndiscuss problems that might arise when other solvers use the format.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:36:15 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Schurr", "Hans-J\u00f6rg", "", "University of Lorraine, CNRS, Inria, and LORIA"], ["Fleury", "Mathias", "", "Johannes Kepler University Linz"], ["Barbosa", "Haniel", "", "Universidade Federal de Minas Gerais"], ["Fontaine", "Pascal", "", "University of\n  Li\u00e8ge"]]}, {"id": "2107.02509", "submitter": "Raven Beutner", "authors": "Raven Beutner, Bernd Finkbeiner", "title": "A Temporal Logic for Strategic Hyperproperties", "comments": "Full Version for CONCUR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyperproperties are commonly used in computer security to define\ninformation-flow policies and other requirements that reason about the\nrelationship between multiple computations. In this paper, we study a novel\nclass of hyperproperties where the individual computation paths are chosen by\nthe strategic choices of a coalition of agents in a multi-agent system. We\nintroduce HyperATL*, an extension of computation tree logic with path variables\nand strategy quantifiers. HyperATL* can express strategic hyperproperties, such\nas that the scheduler in a concurrent system has a strategy to avoid\ninformation leakage. HyperATL* is particularly useful to specify asynchronous\nhyperproperties, i.e., hyperproperties where the speed of the execution on the\ndifferent computation paths depends on the choices of the scheduler. Unlike\nother recent logics for the specification of asynchronous hyperproperties, our\nlogic is the first to admit decidable model checking for the full logic. We\npresent a model checking algorithm for HyperATL* based on alternating word\nautomata and show that our algorithm is asymptotically optimal by providing a\nmatching lower bound. We have implemented a prototype model checker for a\nfragment of HyperATL*, able to check various security properties on small\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:07:46 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Beutner", "Raven", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2107.03155", "submitter": "Pierre Clairambault", "authors": "Pierre Clairambault (LIP, PLUME), Hugo Paquet", "title": "The Quantitative Collapse of Concurrent Games with Symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore links between the thin concurrent games of Castellan, Clairambault\nand Winskel, and the weighted relational models of linear logic studied by\nLaird, Manzonetto, McCusker and Pagani. More precisely, we show that there is\nan interpretationpreserving \"collapse\" functor from the former to the latter.\nOn objects, the functor defines for each game a set of possible execution\nstates. Defining the action on morphisms is more subtle, and this is the main\ncontribution of the paper. Given a strategy and an execution state, our functor\nneeds to count the witnesses for this state within the strategy. Strategies in\nthin concurrent games describe non-linear behaviour explicitly, so in general\neach witness exists in countably many symmetric copies. The challenge is to\ndefine the right notion of witnesses, factoring out this infinity while\nmatching the weighted relational model. Understanding how witnesses compose is\nparticularly subtle and requires a delve into the combinatorics of witnesses\nand their symmetries. In its basic form, this functor connects thin concurrent\ngames and a relational model weighted by N $\\cup$ {+$\\infty$}. We will\nadditionally consider a generalised setting where both models are weighted by\nelements of an arbitrary continuous semiring; this covers the probabilistic\ncase, among others. Witnesses now additionally carry a value from the semiring,\nand our interpretation-preserving collapse functor extends to this setting.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 11:32:08 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Clairambault", "Pierre", "", "LIP, PLUME"], ["Paquet", "Hugo", ""]]}, {"id": "2107.03189", "submitter": "Martin Bromberger", "authors": "Martin Bromberger (1), Irina Dragoste (2), Rasha Faqeh (2), Christof\n  Fetzer (2), Markus Kr\\\"otzsch (2), Christoph Weidenbach (1) ((1) Max Planck\n  Institute for Informatics, Saarland Informatics Campus, Saarbr\\\"ucken,\n  Germany, (2) TU Dresden, Dresden, Germany)", "title": "A Datalog Hammer for Supervisor Verification Conditions Modulo Simple\n  Linear Arithmetic", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bernays-Sch\\\"onfinkel first-order logic fragment over simple linear real\narithmetic constraints BS(SLR) is known to be decidable. We prove that BS(SLR)\nclause sets with both universally and existentially quantified verification\nconditions (conjectures) can be translated into BS(SLR) clause sets over a\nfinite set of first-order constants. For the Horn case, we provide a Datalog\nhammer preserving validity and satisfiability. A toolchain from the BS(LRA)\nprover SPASS-SPL to the Datalog reasoner VLog establishes an effective way of\ndeciding verification conditions in the Horn fragment. This is exemplified by\nthe verification of supervisor code for a lane change assistant in a car and of\nan electronic control unit for a supercharged combustion engine.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:48:06 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Bromberger", "Martin", ""], ["Dragoste", "Irina", ""], ["Faqeh", "Rasha", ""], ["Fetzer", "Christof", ""], ["Kr\u00f6tzsch", "Markus", ""], ["Weidenbach", "Christoph", ""]]}, {"id": "2107.03711", "submitter": "Micha{\\l} Pilipczuk", "authors": "Jakub Gajarsk\\'y, Micha{\\l} Pilipczuk, Szymon Toru\\'nczyk", "title": "Stable graphs of bounded twin-width", "comments": "44 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that every class of graphs $\\mathscr C$ that is monadically stable\nand has bounded twin-width can be transduced from some class with bounded\nsparse twin-width. This generalizes analogous results for classes of bounded\nlinear cliquewidth and of bounded cliquewidth. It also implies that monadically\nstable classes of bounded twin-widthare linearly $\\chi$-bounded.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 09:42:00 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gajarsk\u00fd", "Jakub", ""], ["Pilipczuk", "Micha\u0142", ""], ["Toru\u0144czyk", "Szymon", ""]]}, {"id": "2107.03778", "submitter": "Benedikt Pago", "authors": "Benedikt Pago", "title": "Choiceless Polynomial Time, Symmetric Circuits and Cai-F\\\"urer-Immerman\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Choiceless Polynomial Time (CPT) is currently the only candidate logic for\ncapturing PTIME (that is, it is contained in PTIME and has not been separated\nfrom it). A prominent example of a decision problem in PTIME that is not known\nto be CPT-definable is the isomorphism problem on unordered\nCai-F\\\"urer-Immerman graphs (the CFI-query). We study the expressive power of\nCPT with respect to this problem and develop a partial characterisation of\nsolvable instances in terms of properties of symmetric XOR-circuits over the\nCFI-graphs: The CFI-query is CPT-definable on a given class of graphs only if:\nFor each graph $G$, there exists an XOR-circuit $C$, whose input gates are\nlabelled with edges of $G$, such that $C$ is sufficiently symmetric with\nrespect to the automorphisms of $G$ and satisfies certain other circuit\nproperties. We also give a sufficient condition for CFI being solvable in CPT\nand develop a new CPT-algorithm for the CFI-query. It takes as input structures\nwhich contain, along with the CFI-graph, an XOR-circuit with suitable\nproperties. The strongest known CPT-algorithm for this problem can solve\ninstances equipped with a preorder with colour classes of logarithmic size. Our\nresult implicitly extends this to preorders with colour classes of\npolylogarithmic size (plus some unordered additional structure). Finally, our\nwork provides new insights regarding a much more general problem: The existence\nof a solution to an unordered linear equation system $A \\cdot x = b$ over a\nfinite field is CPT-definable if the matrix $A$ has at most logarithmic rank\n(with respect to the size of the structure that encodes the equation system).\nThis is another example that separates CPT from fixed-point logic with\ncounting.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:41:02 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Pago", "Benedikt", ""]]}, {"id": "2107.03794", "submitter": "Anton\\'in Ku\\v{c}era", "authors": "Miroslav Chodil and Anton\\'in Ku\\v{c}era", "title": "The Satisfiability Problem for a Quantitative Fragment of PCTL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a sufficient condition under which every finite-satisfiable formula\nof a given PCTL fragment has a model with at most doubly exponential number of\nstates (consequently, the finite satisfiability problem for the fragment is in\n2-EXPSPACE). The condition is semantic and it is based on enforcing a form of\n``progress'' in non-bottom SCCs contributing to the satisfaction of a given\nPCTL formula. We show that the condition is satisfied by PCTL fragments beyond\nthe reach of existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 12:11:27 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Chodil", "Miroslav", ""], ["Ku\u010dera", "Anton\u00edn", ""]]}, {"id": "2107.03997", "submitter": "Giacomo Bergami", "authors": "Giacomo Bergami, Fabrizio Maria Maggi, Marco Montali, Rafael\n  Pe\\~naloza", "title": "Probabilistic Trace Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Alignments provide sophisticated diagnostics that pinpoint deviations in a\ntrace with respect to a process model and their severity. However, approaches\nbased on trace alignments use crisp process models as reference and recent\nprobabilistic conformance checking approaches check the degree of conformance\nof an event log with respect to a stochastic process model instead of finding\ntrace alignments. In this paper, for the first time, we provide a conformance\nchecking approach based on trace alignments using stochastic Workflow nets.\nConceptually, this requires to handle the two possibly contrasting forces of\nthe cost of the alignment on the one hand and the likelihood of the model trace\nwith respect to which the alignment is computed on the other.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:42:57 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Bergami", "Giacomo", ""], ["Maggi", "Fabrizio Maria", ""], ["Montali", "Marco", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "2107.04298", "submitter": "Hochang Lee", "authors": "Hochang Lee and Kyung Chul Jung and Daewan Han and Panjin Kim", "title": "An Algorithm for Reversible Logic Circuit Synthesis Based on Tensor\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.ET quant-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An algorithm for reversible logic synthesis is proposed. The task is, for\ngiven $n$-bit substitution map $P_n: \\{0,1\\}^n \\rightarrow \\{0,1\\}^n$, to find\na sequence of reversible logic gates that implements the map. The gate library\nadopted in this work consists of multiple-controlled Toffoli gates denoted by\n$C^m\\!X$, where $m$ is the number of control bits that ranges from 0 to $n-1$.\nControlled gates with large $m \\,\\,(>2)$ are then further decomposed into\n$C^0\\!X$, $C^1\\!X$, and $C^2\\!X$ gates. A primary concern in designing the\nalgorithm is to reduce the use of $C^2\\!X$ gate (also known as Toffoli gate)\nwhich is known to be universal. The main idea is to view an $n$-bit\nsubstitution map as a rank-$2n$ tensor and to transform it such that the\nresulting map can be written as a tensor product of a rank-($2n-2$) tensor and\nthe $2\\times 2$ identity matrix. Let $\\mathcal{P}_n$ be a set of all $n$-bit\nsubstitution maps. What we try to find is a size reduction map\n$\\mathcal{A}_{\\rm red}: \\mathcal{P}_n \\rightarrow \\{P_n: P_n = P_{n-1} \\otimes\nI_2\\}$. One can see that the output $P_{n-1} \\otimes I_2$ acts nontrivially on\n$n-1$ bits only, meaning that the map to be synthesized becomes $P_{n-1}$. The\nsize reduction process is iteratively applied until it reaches tensor product\nof only $2 \\times 2$ matrices.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 08:18:53 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 14:29:10 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Lee", "Hochang", ""], ["Jung", "Kyung Chul", ""], ["Han", "Daewan", ""], ["Kim", "Panjin", ""]]}, {"id": "2107.04347", "submitter": "Gilles Falquet", "authors": "Vincenzo Daponte and Gilles Falquet", "title": "An ontology for the formalization and visualization of scientific\n  knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The construction of an ontology of scientific knowledge objects, presented\nhere, is part of the development of an approach oriented towards the\nvisualization of scientific knowledge. It is motivated by the fact that the\nconcepts that are used to organize scientific knowledge (theorem, law,\nexperience, proof, etc.) appear in existing ontologies but that none of these\nontologies is centered on this topic and presents them in a simple and easily\nunderstandable organization. This ontology has been constructed by 1) selecting\nconcepts that appear in high level ontologies or in ontologies of knowledge\nobjects of specific fields and 2) by interviewing scientists in different\nfields. We have aligned this ontology with some of the sources used, which has\nallowed us to verify its consistency with respect to them. The validation of\nthe ontology consists in using it to formalize knowledge from various sources,\nwhich we have begun to do in the field of physics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 10:33:45 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 18:00:17 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Daponte", "Vincenzo", ""], ["Falquet", "Gilles", ""]]}, {"id": "2107.05225", "submitter": "Toby Murray", "authors": "Toby Murray, Pengbo Yan, Gidon Ernst", "title": "Incremental Vulnerability Detection via Back-Propagating Symbolic\n  Execution of Insecurity Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first compositional, incremental static analysis for detecting\nmemory-safety and information leakage vulnerabilities in C-like programs. To do\nso, we develop the first under-approximate relational program logics, including\nInsecurity Separation Logic (InsecSL). We show how InsecSL can be automated via\nback-propagating symbolic execution (BPSE) to build a bottom-up,\ninter-procedural and incremental analysis for detecting vulnerabilities. We\nprove our approach sound in Isabelle/HOL and implement it in a proof-of-concept\ntool, Underflow, for analysing C programs, which we apply to various case\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 07:11:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Murray", "Toby", ""], ["Yan", "Pengbo", ""], ["Ernst", "Gidon", ""]]}, {"id": "2107.05253", "submitter": "Radu Iosif", "authors": "Emma Ahrens and Marius Bozga and Radu Iosif and Joost-Pieter Katoen", "title": "Local Reasoning about Parameterized Reconfigurable Distributed Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a Hoare-style calculus for formal reasoning about\nreconfiguration programs of distributed systems. Such programs delete or create\ninteractions or components while the system components change state according\nto their local behaviour. Our proof calculus uses a configuration logic that\nsupports local reasoning and that relies on inductive predicates to describe\ndistributed systems with an unbounded number of components. The validity of\nreconfiguration programs relies on havoc invariants, assertions about the\nongoing interactions in the system. We present a proof system for such\ninvariants in an assume/rely-guarantee style. We illustrate the feasibility of\nour approach by proving the correctness of self-adjustable tree architectures\nand provide tight complexity bounds for entailment checking in the\nconfiguration logic.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:30:17 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ahrens", "Emma", ""], ["Bozga", "Marius", ""], ["Iosif", "Radu", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "2107.05261", "submitter": "Thomas Ehrhard", "authors": "Thomas Ehrhard (IRIF)", "title": "Coherent differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The categorical models of the differential lambda-calculus are additive\ncategories because of the Leibniz rule which requires the summation of two\nexpressions. This means that, as far as the differential lambda-calculus and\ndifferential linear logic are concerned, these models feature finite\nnondeterminism and indeed these languages are essentially non-deterministic. We\nintroduce a categorical framework for differentiation which does not require\nadditivity and is compatible with deterministic models such as coherence spaces\nand probabilistic models such as probabilistic coherence spaces. Based on this\nsemantics we sketch the syntax of a deterministic version of the differential\nlambdacalculus.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:54:09 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ehrhard", "Thomas", "", "IRIF"]]}, {"id": "2107.05285", "submitter": "Frank Wolter", "authors": "Jean Christoph Jung, Carsten Lutz, Hadrien Pulcini, Frank Wolter", "title": "Separating Data Examples by Description Logic Concepts with Restricted\n  Signatures", "comments": "A short version of this paper has been accepted for publication in\n  the Proceedings of KR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the separation of positive and negative data examples in terms of\ndescription logic concepts in the presence of an ontology. In contrast to\nprevious work, we add a signature that specifies a subset of the symbols that\ncan be used for separation, and we admit individual names in that signature. We\nconsider weak and strong versions of the resulting problem that differ in how\nthe negative examples are treated and we distinguish between separation with\nand without helper symbols. Within this framework, we compare the separating\npower of different languages and investigate the complexity of deciding\nseparability. While weak separability is shown to be closely related to\nconservative extensions, strongly separating concepts coincide with Craig\ninterpolants, for suitably defined encodings of the data and ontology. This\nenables us to transfer known results from those fields to separability.\nConversely, we obtain original results on separability that can be transferred\nbackward. For example, rather surprisingly, conservative extensions and weak\nseparability in ALCO are both 3ExpTime-complete.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 09:42:45 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jung", "Jean Christoph", ""], ["Lutz", "Carsten", ""], ["Pulcini", "Hadrien", ""], ["Wolter", "Frank", ""]]}, {"id": "2107.05296", "submitter": "Anuj Dawar", "authors": "Anuj Dawar and Felipe Ferreira Santos", "title": "Separating LREC from LFP", "comments": "21 pages. Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  LREC= is an extension of first-order logic with a logarithmic recursion\noperator. It was introduced by Grohe et al. and shown to capture the complexity\nclass L over trees and interval graphs. It does not capture L in general as it\nis contained in FPC - fixed-point logic with counting. We show that this\ncontainment is strict. In particular, we show that the path systems problem, a\nclassic P-complete problem which is definable in LFP - fixed-point logic - is\nnot definable in LREC= This shows that the logarithmic recursion mechanism is\nprovably weaker than general least fixed points. The proof is based on a novel\nSpoiler-Duplicator game tailored for this logic.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 10:14:32 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Dawar", "Anuj", ""], ["Santos", "Felipe Ferreira", ""]]}, {"id": "2107.05378", "submitter": "Serenella Cerrito", "authors": "Serenella Cerrito", "title": "Tableaux like model checking on-the-fly for ATL+", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model checking algorithm to test properties of systems that are\nexpressed in the multi-agent temporal logic ATL+. The specificities of this\nalgorithm are: it is on-the-fly, generating states only when they are needed,\nand it works by constructing a candidate formal proof in an inference system\ninspired by tableau proof systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 12:44:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Cerrito", "Serenella", ""]]}, {"id": "2107.05493", "submitter": "EPTCS", "authors": "Nicolas Magaud (ICube - Universit\\'e de Strasbourg)", "title": "Integrating an Automated Prover for Projective Geometry as a New Tactic\n  in the Coq Proof Assistant", "comments": "In Proceedings PxTP 2021, arXiv:2107.01544", "journal-ref": "EPTCS 336, 2021, pp. 40-47", "doi": "10.4204/EPTCS.336.4", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, we developed an automated theorem prover for projective incidence\ngeometry. This prover, based on a combinatorial approach using matroids,\nproceeds by saturation using the matroid rules. It is designed as an\nindependent tool, implemented in C, which takes a geometric configuration as\ninput and produces as output some Coq proof scripts: the statement of the\nexpected theorem, a proof script proving the theorem and possibly some\nauxiliary lemmas. In this document, we show how to embed such an external tool\nas a plugin in Coq so that it can be used as a simple tactic.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:36:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Magaud", "Nicolas", "", "ICube - Universit\u00e9 de Strasbourg"]]}, {"id": "2107.05928", "submitter": "Alexandre Vigny", "authors": "Nicole Schrader, Sebastian Siebertz, Alexandre Vigny", "title": "First-Order Logic with Connectivity Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  First-order logic (FO) can express many algorithmic problems on graphs, such\nas the independent set and dominating set problem, parameterized by solution\nsize. On the other hand, FO cannot express the very simple algorithmic question\nof whether two vertices are connected. We enrich FO with connectivity\npredicates that are tailored to express algorithmic graph properties that are\ncommonly studied in parameterized algorithmics. By adding the atomic predicates\n$conn_k (x, y, z_1 ,\\ldots, z_k)$ that hold true in a graph if there exists a\npath between (the valuations of) $x$ and $y$ after (the valuations of)\n$z_1,\\ldots,z_k$ have been deleted, we obtain separator logic $FO + conn$.\n  We show that separator logic can express many interesting problems such as\nthe feedback vertex set problem and elimination distance problems to\nfirst-order definable classes. We then study the limitations of separator logic\nand prove that it cannot express planarity, and, in particular, not the\ndisjoint paths problem. We obtain the stronger disjoint-paths logic $FO + DP$\nby adding the atomic predicates $disjoint-paths_k [(x_1, y_1 ),\\ldots , (x_k ,\ny_k )]$ that evaluate to true if there are internally vertex disjoint paths\nbetween (the valuations of) $x_i$ and $y_i$ for all $1 \\le i \\le k$.\nDisjoint-paths logic can express the disjoint paths problem, the problem of\n(topological) minor containment, the problem of hitting (topological) minors,\nand many more. Finally, we compare the expressive power of the new logics with\nthat of transitive closure logics and monadic second-order logic.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:59:14 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Schrader", "Nicole", ""], ["Siebertz", "Sebastian", ""], ["Vigny", "Alexandre", ""]]}, {"id": "2107.06042", "submitter": "Raoul Koudijs", "authors": "Raoul Koudijs", "title": "Finite Model Property and Bisimulation for LFD", "comments": "15 pages, submitted for GandALF 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recently, Baltag and van Benthem arXiv:2103.14946 [cs.LO] introduced a new\ndecidable logic of functional dependence (LFD) with local dependence formulas\nand dependence quantifiers. The language is interpreted over dependence models,\nwhich are pairs of first-order structures with a set of available variable\nassignments, also called a team. The team associated with a dependence model\ncan be seen as a labelled transition system over which LFD becomes a modal\nlogic, where the dependence quantifiers become modalities and local dependence\nformulas are treated as special atoms. In this paper, we introduce appropriate\nnotions of bisimulation characterizing LFD (and some related logics) as a\nfragment of first order logic (FOL), and show it is equivalent to a notion of\nbisimulation along more standard lines proposed in arXiv:2102.10368 [cs.LO],\nyet more efficient for bisimilarity-checking. Our main result is that LFD has\nthe finite model property (FMP), by a new application of Herwig's theorem on\nextending partial isomorphisms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:52:23 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Koudijs", "Raoul", ""]]}, {"id": "2107.06045", "submitter": "Michael Greenberg", "authors": "Eric Campbell and Michael Greenberg", "title": "Injecting Finiteness to Prove Completeness for Finite Linear Temporal\n  Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal logics over finite traces are not the same as temporal logics over\npotentially infinite traces. Ro\\c{s}u first proved completeness for linear\ntemporal logic on finite traces (LTLf) with a novel coinductive axiom. We offer\na different proof, with fewer, more conventional axioms. Our proof is a direct\nadaptation of Kr\\\"{o}ger and Merz's Henkin-Hasenjaeger-style proof. The essence\nof our adaption is that we \"inject\" finiteness: that is, we alter the proof\nstructure to ensure that models are finite. We aim to present a thorough,\naccessible proof.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:55:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Campbell", "Eric", ""], ["Greenberg", "Michael", ""]]}, {"id": "2107.06075", "submitter": "Umberto Straccia", "authors": "Giovanni Casini, Umberto Straccia", "title": "A Rational Entailment for Expressive Description Logics via Description\n  Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lehmann and Magidor's rational closure is acknowledged as a landmark in the\nfield of non-monotonic logics and it has also been re-formulated in the context\nof Description Logics (DLs).\n  We show here how to model a rational form of entailment for expressive DLs,\nsuch as SROIQ, providing a novel reasoning procedure that compiles a\nnon-monotone DL knowledge base into a description logic program (dl-program).\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:35:42 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Casini", "Giovanni", ""], ["Straccia", "Umberto", ""]]}, {"id": "2107.06084", "submitter": "Florian Gallay", "authors": "Florian Gallay and Yli\\`es Falcone", "title": "Decentralized LTL Enforcement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the runtime enforcement of Linear-time Temporal Logic formulas on\ndecentralized systems. A so-called enforcer is attached to each system\ncomponent and observes its local trace. Should the global trace violate the\nspecification, the enforcers coordinate to correct their local traces. We\nformalize the decentralized runtime enforcement problem and define the expected\nproperties of enforcers, namely soundness, transparency and optimality. We\npresent two enforcement algorithms. In the first one, the enforcers explore all\npossible local modifications to find the best global correction. Although this\nguarantees an optimal correction, it forces the system to synchronize and is\nmore costly, computation and communication wise. In the second one, each\nenforcer makes a local correction before communicating. The reduced cost of\nthis version comes at the price of the optimality of the enforcer corrections.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:39:46 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Gallay", "Florian", ""], ["Falcone", "Yli\u00e8s", ""]]}, {"id": "2107.06121", "submitter": "Nils Vortmeier", "authors": "Nils Vortmeier, Ioannis Kokkinis", "title": "The Dynamic Complexity of Acyclic Hypergraph Homomorphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a homomorphism from some hypergraph $\\mathcal{Q}$ (or some relational\nstructure) to another hypergraph $\\mathcal{D}$ is a fundamental problem in\ncomputer science. We show that an answer to this problem can be maintained\nunder single-edge changes of $\\mathcal{Q}$, as long as it stays acyclic, in the\nDynFO framework of Patnaik and Immerman that uses updates expressed in\nfirst-order logic. If additionally also changes of $\\mathcal{D}$ are allowed,\nwe show that it is unlikely that existence of homomorphisms can be maintained\nin DynFO.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 14:21:30 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Vortmeier", "Nils", ""], ["Kokkinis", "Ioannis", ""]]}, {"id": "2107.06150", "submitter": "Paolo Pistone", "authors": "Paolo Pistone", "title": "From Identity to Difference: A Quantitative Interpretation of the\n  Identity Type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore a quantitative interpretation of 2-dimensional intuitionistic type\ntheory (ITT) in which the identity type is interpreted as a \"type of\ndifferences\". We show that a fragment of ITT, that we call difference type\ntheory (dTT), yields a general logical framework to talk about quantitative\nproperties of programs like approximate equivalence and metric preservation. To\ndemonstrate this fact, we show that dTT can be used to capture compositional\nreasoning in presence of errors, since any program can be associated with a\n\"derivative\" relating errors in input with errors in output. Moreover, after\nrelating the semantics of dTT to the standard weak factorization systems\nsemantics of ITT, we describe the interpretation of dTT in some quantitative\nmodels developed for approximate program transformations, incremental\ncomputing, program differentiation and differential privacy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 14:54:57 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Pistone", "Paolo", ""]]}, {"id": "2107.06152", "submitter": "Edwin James Beggs", "authors": "Edwin Beggs and John V. Tucker", "title": "A model of systems with modes and mode transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a method of classifying the operation of a system into finitely\nmany modes. Each mode has its own objectives for the system's behaviour and its\nown mathematical models and algorithms designed to accomplish its objectives. A\ncentral problem is deciding when to transition from one mode to some other\nmode, a decision that may be contested and involve partial or inconsistent\ninformation or evidence. We model formally the concept of modes for a system\nand derive a family of data types for analysing mode transitions. The data\ntypes are simplicial complexes, both abstract and realised in euclidean space\n$\\mathbb{R}^{n}$. In the data type, a mode is represented by a simplex. Each\nstate of a system can be evaluated relative to different modes by mapping it\ninto one or more simplices. This calibration measures the extent to which\ndistinct modes are appropriate for the state and can decide on a transition. We\nexplain this methodology based on modes, introduce the mathematical ideas about\nsimplicial objects we need and use them to build a theoretical framework for\nmodes and mode transitions. To illustrate the general model in some detail, we\nwork though a case study of an autonomous racing car.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 15:04:49 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Beggs", "Edwin", ""], ["Tucker", "John V.", ""]]}, {"id": "2107.06232", "submitter": "Marek Soko{\\l}owski", "authors": "Konrad Majewski, Micha{\\l} Pilipczuk, Marek Soko{\\l}owski", "title": "Maintaining $\\mathsf{CMSO}_2$ properties on dynamic structures with\n  bounded feedback vertex number", "comments": "80 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\varphi$ be a sentence of $\\mathsf{CMSO}_2$ (monadic second-order logic\nwith quantification over edge subsets and counting modular predicates) over the\nsignature of graphs. We present a dynamic data structure that for a given graph\n$G$ that is updated by edge insertions and edge deletions, maintains whether\n$\\varphi$ is satisfied in $G$. The data structure is required to correctly\nreport the outcome only when the feedback vertex number of $G$ does not exceed\na fixed constant $k$, otherwise it reports that the feedback vertex number is\ntoo large. With this assumption, we guarantee amortized update time ${\\cal\nO}_{\\varphi,k}(\\log n)$.\n  By combining this result with a classic theorem of Erd\\H{o}s and P\\'osa, we\ngive a fully dynamic data structure that maintains whether a graph contains a\npacking of $k$ vertex-disjoint cycles with amortized update time ${\\cal\nO}_{k}(\\log n)$. Our data structure also works in a larger generality of\nrelational structures over binary signatures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:35:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Majewski", "Konrad", ""], ["Pilipczuk", "Micha\u0142", ""], ["Soko\u0142owski", "Marek", ""]]}, {"id": "2107.06329", "submitter": "Maxime Chaveroche", "authors": "Maxime Chaveroche, Franck Davoine, V\\'eronique Cherfaoui", "title": "Efficient exact computation of the conjunctive and disjunctive\n  decompositions of D-S Theory for information fusion: Translation and\n  extension", "comments": "Extension of an article published in the proceedings of the french\n  conference GRETSI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Dempster-Shafer Theory (DST) generalizes Bayesian probability theory,\noffering useful additional information, but suffers from a high computational\nburden. A lot of work has been done to reduce the complexity of computations\nused in information fusion with Dempster's rule. Yet, few research had been\nconducted to reduce the complexity of computations for the conjunctive and\ndisjunctive decompositions of evidence, which are at the core of other\nimportant methods of information fusion. In this paper, we propose a method\ndesigned to exploit the actual evidence (information) contained in these\ndecompositions in order to compute them. It is based on a new notion that we\ncall focal point, derived from the notion of focal set. With it, we are able to\nreduce these computations up to a linear complexity in the number of focal sets\nin some cases. In a broader perspective, our formulas have the potential to be\ntractable when the size of the frame of discernment exceeds a few dozen\npossible states, contrary to the existing litterature. This article extends\n(and translates) our work published at the french conference GRETSI in 2019.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:41:54 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Chaveroche", "Maxime", ""], ["Davoine", "Franck", ""], ["Cherfaoui", "V\u00e9ronique", ""]]}, {"id": "2107.06591", "submitter": "Beniamino Accattoli", "authors": "Beniamino Accattoli, Maico Leberle", "title": "Useful Open Call-by-Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies useful sharing, which is a sophisticated optimization for\nlambda-calculi, in the context of call-by-need evaluation in presence of open\nterms. Useful sharing turns out to be harder to manipulate in call-by-need than\nin call-by-name or call-by-value, because call-by-need evaluates inside\nenvironments, making it harder to specify when a substitution step is useful.\nWe isolate the key involved concepts and prove the correctness of useful\nsharing in this setting.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 10:29:58 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Leberle", "Maico", ""]]}, {"id": "2107.06672", "submitter": "Frederic Lardeux", "authors": "Fr\\'ed\\'eric Lardeux (LERIA), Eric Monfroy (LERIA)", "title": "Improved SAT models for NFA learning", "comments": null, "journal-ref": "International Conference in Optimization and Learning (OLA), Jun\n  2021, Catania, Italy", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical inference is concerned with the study of algorithms for learning\nautomata and grammars from words. We focus on learning Nondeterministic Finite\nAutomaton of size k from samples of words. To this end, we formulate the\nproblem as a SAT model. The generated SAT instances being enormous, we propose\nsome model improvements, both in terms of the number of variables, the number\nof clauses, and clauses size. These improvements significantly reduce the\ninstances, but at the cost of longer generation time. We thus try to balance\ninstance size vs. generation and solving time. We also achieved some\nexperimental comparisons and we analyzed our various model improvements.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 06:54:07 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Lardeux", "Fr\u00e9d\u00e9ric", "", "LERIA"], ["Monfroy", "Eric", "", "LERIA"]]}, {"id": "2107.06727", "submitter": "Emilio Tuosto", "authors": "Franco Barbanera and Ivan Lanese and Emilio Tuosto", "title": "Composition of choreography automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Choreography automata are an automata-based model of choreographies, that we\nshow to be a compositional one. Choreography automata represent global views of\nchoreographies (and rely on the well-known model of communicating finite-state\nmachines to model local behaviours). The projections of well-formed global\nviews are live as well as lock- and deadlock-free. In the class of choreography\nautomata we define an internal operation of {\\em composition}, which connects\ntwo global views via roles acting as interfaces. We show that under mild\nconditions the composition of well-formed choreography automata is well-formed.\nThe composition operation enables for a flexible modular mechanism at the\ndesign level.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:17:34 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Barbanera", "Franco", ""], ["Lanese", "Ivan", ""], ["Tuosto", "Emilio", ""]]}, {"id": "2107.07016", "submitter": "Ricardo Gon\\c{c}alves", "authors": "Ricardo Gon\\c{c}alves, Matthias Knorr, Jo\\~ao Leite", "title": "Forgetting in Answer Set Programming -- A Survey", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Forgetting - or variable elimination - is an operation that allows the\nremoval, from a knowledge base, of middle variables no longer deemed relevant.\nIn recent years, many different approaches for forgetting in Answer Set\nProgramming have been proposed, in the form of specific operators, or classes\nof such operators, commonly following different principles and obeying\ndifferent properties. Each such approach was developed to somehow address some\nparticular view on forgetting, aimed at obeying a specific set of properties\ndeemed desirable in such view, but a comprehensive and uniform overview of all\nthe existing operators and properties is missing. In this paper, we thoroughly\nexamine existing properties and (classes of) operators for forgetting in Answer\nSet Programming, drawing a complete picture of the landscape of these classes\nof forgetting operators, which includes many novel results on relations between\nproperties and operators, including considerations on concrete operators to\ncompute results of forgetting and computational complexity. Our goal is to\nprovide guidance to help users in choosing the operator most adequate for their\napplication requirements.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 21:37:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gon\u00e7alves", "Ricardo", ""], ["Knorr", "Matthias", ""], ["Leite", "Jo\u00e3o", ""]]}, {"id": "2107.07228", "submitter": "Micha{\\l} Zawidzki", "authors": "Andrzej Indrzejczak and Micha{\\l} Zawidzki", "title": "Tableaux for Free Logics with Descriptions", "comments": "This is a full version of a conference paper that will appear in the\n  proceedings of the 30th International Conference on Automated Reasoning with\n  Analytic Tableaux and Related Methods (TABLEAUX)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The paper provides a tableau approach to definite descriptions. We focus on\nseveral formalizations of the so-called minimal free description theory (MFD)\nusually formulated axiomatically in the setting of free logic. We consider five\nanalytic tableau systems corresponding to different kinds of free logic,\nincluding the logic of definedness applied in computer science and constructive\nmathematics for dealing with partial functions (here called negative quasi-free\nlogic). The tableau systems formalise MFD based on PFL (positive free logic),\nNFL (negative free logic), PQFL and NQFL (the quasi-free counterparts of the\nformer ones). Also the logic NQFLm is taken into account, which is equivalent\nto NQFL, but whose language does not comprise the existence predicate. It is\nshown that all tableaux are sound and complete with respect to the semantics of\nthese logics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 10:08:14 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Indrzejczak", "Andrzej", ""], ["Zawidzki", "Micha\u0142", ""]]}, {"id": "2107.07376", "submitter": "EPTCS", "authors": "Elaine Pimentel (UFRN), Enrico Tassi (Inria)", "title": "Proceedings of the Sixteenth Workshop on Logical Frameworks and\n  Meta-Languages: Theory and Practice", "comments": null, "journal-ref": "EPTCS 337, 2021", "doi": "10.4204/EPTCS.337", "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logical frameworks and meta-languages form a common substrate for\nrepresenting, implementing and reasoning about a wide variety of deductive\nsystems of interest in logic and computer science. Their design, implementation\nand their use in reasoning tasks, ranging from the correctness of software to\nthe properties of formal systems, have been the focus of considerable research\nover the last two decades. This workshop brings together designers,\nimplementors and practitioners to discuss various aspects impinging on the\nstructure and utility of logical frameworks, including the treatment of\nvariable binding, inductive and co-inductive reasoning techniques and the\nexpressiveness and lucidity of the reasoning process.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 05:19:09 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Pimentel", "Elaine", "", "UFRN"], ["Tassi", "Enrico", "", "Inria"]]}, {"id": "2107.07661", "submitter": "EPTCS", "authors": "Giselle Reis (Carnegie Mellon University)", "title": "Facilitating Meta-Theory Reasoning (Invited Paper)", "comments": "In Proceedings LFMTP 2021, arXiv:2107.07376", "journal-ref": "EPTCS 337, 2021, pp. 1-12", "doi": "10.4204/EPTCS.337.1", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Structural proof theory is praised for being a symbolic approach to reasoning\nand proofs, in which one can define schemas for reasoning steps and manipulate\nproofs as a mathematical structure. For this to be possible, proof systems must\nbe designed as a set of rules such that proofs using those rules are correct by\nconstruction. Therefore, one must consider all ways these rules can interact\nand prove that they satisfy certain properties which makes them \"well-behaved\".\nThis is called the meta-theory of a proof system.\n  Meta-theory proofs typically involve many cases on structures with lots of\nsymbols. The majority of cases are usually quite similar, and when a proof\nfails, it might be because of a sub-case on a very specific configuration of\nrules. Developing these proofs by hand is tedious and error-prone, and their\ncombinatorial nature suggests they could be automated.\n  There are various approaches on how to automate, either partially or\ncompletely, meta-theory proofs. In this paper, I will present some techniques\nthat I have been involved in for facilitating meta-theory reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 01:43:52 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Reis", "Giselle", "", "Carnegie Mellon University"]]}, {"id": "2107.07662", "submitter": "EPTCS", "authors": "Gilles Dowek (Inria and ENS Paris-Saclay)", "title": "Interacting Safely with an Unsafe Environment", "comments": "In Proceedings LFMTP 2021, arXiv:2107.07376", "journal-ref": "EPTCS 337, 2021, pp. 30-38", "doi": "10.4204/EPTCS.337.3", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a presentation of Pure type systems where contexts need not be\nwell-formed and show that this presentation is equivalent to the usual one. The\nmain motivation for this presentation is that, when we extend Pure type systems\nwith computation rules, like in the logical framework Dedukti, we want to\ndeclare the constants before the computation rules that are needed to check the\nwell-typedness of their type.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 01:44:04 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Dowek", "Gilles", "", "Inria and ENS Paris-Saclay"]]}, {"id": "2107.07663", "submitter": "EPTCS", "authors": "Qinxiang Cao (John Hopcroft Center of Computer Science, Shanghai Jiao\n  Tong University, Shanghai Key Laboratory of Trustworthy Computing, East China\n  Normal University), Xiwei Wu (Shanghai Jiao Tong University)", "title": "Countability of Inductive Types Formalized in the Object-Logic Level", "comments": "In Proceedings LFMTP 2021, arXiv:2107.07376", "journal-ref": "EPTCS 337, 2021, pp. 55-70", "doi": "10.4204/EPTCS.337.5", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The set of integer number lists with finite length, and the set of binary\ntrees with integer labels are both countably infinite. Many inductively defined\ntypes also have countably many elements. In this paper, we formalize the syntax\nof first order inductive definitions in Coq and prove them countable, under\nsome side conditions. Instead of writing a proof generator in a meta language,\nwe develop an axiom-free proof in the Coq object logic. In other words, our\nproof is a dependently typed Coq function from the syntax of the inductive\ndefinition to the countability of the type. Based on this proof, we provide a\nCoq tactic to automatically prove the countability of concrete inductive types.\nWe also developed Coq libraries for countability and for the syntax of\ninductive definitions, which have value on their own.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 01:44:22 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Cao", "Qinxiang", "", "John Hopcroft Center of Computer Science, Shanghai Jiao\n  Tong University, Shanghai Key Laboratory of Trustworthy Computing, East China\n  Normal University"], ["Wu", "Xiwei", "", "Shanghai Jiao Tong University"]]}, {"id": "2107.07664", "submitter": "EPTCS", "authors": "Laila El-Beheiry (Carnegie Mellon University), Giselle Reis (Carnegie\n  Mellon University), Ammar Karkour (Carnegie Mellon University)", "title": "SMLtoCoq: Automated Generation of Coq Specifications and Proof\n  Obligations from SML Programs with Contracts", "comments": "In Proceedings LFMTP 2021, arXiv:2107.07376", "journal-ref": "EPTCS 337, 2021, pp. 71-87", "doi": "10.4204/EPTCS.337.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Formally reasoning about functional programs is supposed to be\nstraightforward and elegant, however, it is not typically done as a matter of\ncourse. Reasoning in a proof assistant requires \"reimplementing\" the code in\nthose tools, which is far from trivial. SMLtoCoq provides an automatic\ntranslation of SML programs and function contracts into Coq. Programs are\ntranslated into Coq specifications, and function contracts into theorems, which\ncan then be formally proved. Using the Equations plugin and other well\nestablished Coq libraries, SMLtoCoq is able to translate SML programs without\nside-effects containing partial functions, structures, functors, records, among\nothers. Additionally, we provide a Coq version of many parts of SML's basis\nlibrary, so that calls to these libraries are kept almost as is.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 01:44:37 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["El-Beheiry", "Laila", "", "Carnegie Mellon University"], ["Reis", "Giselle", "", "Carnegie\n  Mellon University"], ["Karkour", "Ammar", "", "Carnegie Mellon University"]]}, {"id": "2107.07665", "submitter": "EPTCS", "authors": "Florian Rabe (University Erlangen-Nuremberg), Navid Roux (University\n  Erlangen-Nuremberg)", "title": "Systematic Translation of Formalizations of Type Theory from Intrinsic\n  to Extrinsic Style", "comments": "In Proceedings LFMTP 2021, arXiv:2107.07376", "journal-ref": "EPTCS 337, 2021, pp. 88-103", "doi": "10.4204/EPTCS.337.7", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Type theories can be formalized using the intrinsically (hard) or the\nextrinsically (soft) typed style. In large libraries of type theoretical\nfeatures, often both styles are present, which can lead to code duplication and\nintegration issues.\n  We define an operator that systematically translates a hard-typed into the\ncorresponding soft-typed formulation. Even though this translation is known in\nprinciple, a number of subtleties make it more difficult than naively expected.\nImportantly, our translation preserves modularity, i.e., it maps structured\nsets of hard-typed features to correspondingly structured soft-typed ones.\n  We implement our operator in the MMT system and apply it to a library of\ntype-theoretical features.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 01:44:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Rabe", "Florian", "", "University Erlangen-Nuremberg"], ["Roux", "Navid", "", "University\n  Erlangen-Nuremberg"]]}, {"id": "2107.07666", "submitter": "EPTCS", "authors": "Mary Southern (University of Minnesota), Gopalan Nadathur (University\n  of Minnesota)", "title": "Adelfa: A System for Reasoning about LF Specifications", "comments": "In Proceedings LFMTP 2021, arXiv:2107.07376", "journal-ref": "EPTCS 337, 2021, pp. 104-120", "doi": "10.4204/EPTCS.337.8", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a system called Adelfa that provides mechanized support for\nreasoning about specifications developed in the Edinburgh Logical Framework or\nLF. Underlying Adelfa is a new logic named L_LF. Typing judgements in LF are\nrepresented by atomic formulas in L_LF and quantification is permitted over\ncontexts and terms that appear in such formulas. Contexts, which constitute\ntype assignments to uniquely named variables that are modelled using the\ntechnical device of nominal constants, are characterized in L_LF by context\nschemas that describe their inductive structure. We present these formulas and\nan associated semantics before sketching a proof system for constructing\narguments that are sound with respect to the semantics. We then outline the\nrealization of this proof system in Adelfa and illustrate its use through a few\nexample proof developments. We conclude the paper by relating Adelfa to\nexisting systems for reasoning about LF specifications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 01:45:07 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Southern", "Mary", "", "University of Minnesota"], ["Nadathur", "Gopalan", "", "University\n  of Minnesota"]]}, {"id": "2107.07669", "submitter": "EPTCS", "authors": "Johannes Schoisswohl (University of Manchester), Laura Kov\\'acs (TU\n  Wien)", "title": "Automating Induction by Reflection", "comments": "In Proceedings LFMTP 2021, arXiv:2107.07376. A full version of this\n  paper appears at arXiv:2106.05066", "journal-ref": "EPTCS 337, 2021, pp. 39-54", "doi": "10.4204/EPTCS.337.4", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent advances in automating theorem proving in full first-order\ntheories, inductive reasoning still poses a serious challenge to\nstate-of-the-art theorem provers. The reason for that is that in first-order\nlogic induction requires an infinite number of axioms, which is not a feasible\ninput to a computer-aided theorem prover requiring a finite input. Mathematical\npractice is to specify these infinite sets of axioms as axiom schemes.\nUnfortunately these schematic definitions cannot be formalized in first-order\nlogic, and therefore not supported as inputs for first-order theorem provers.\n  In this work we introduce a new method, inspired by the field of axiomatic\ntheories of truth, that allows to express schematic inductive definitions, in\nthe standard syntax of multi-sorted first-order logic. Further we test the\npractical feasibility of the method with state-of-the-art theorem provers,\ncomparing it to solvers' native techniques for handling induction.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 02:12:02 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Schoisswohl", "Johannes", "", "University of Manchester"], ["Kov\u00e1cs", "Laura", "", "TU\n  Wien"]]}, {"id": "2107.07670", "submitter": "EPTCS", "authors": "Matthieu Sozeau (Inria & LS2N, Universit\\'e de Nantes)", "title": "Touring the MetaCoq Project (Invited Paper)", "comments": "In Proceedings LFMTP 2021, arXiv:2107.07376", "journal-ref": "EPTCS 337, 2021, pp. 13-29", "doi": "10.4204/EPTCS.337.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proof assistants are getting more widespread use in research and industry to\nprovide certified and independently checkable guarantees about theories,\ndesigns, systems and implementations. However, proof assistant implementations\nthemselves are seldom verified, although they take a major share of the trusted\ncode base in any such certification effort. In this area, proof assistants\nbased on Higher-Order Logic enjoy stronger guarantees, as self-certified\nimplementations have been available for some years. One cause of this\ndifference is the inherent complexity of dependent type theories together with\ntheir extensions with inductive types, universe polymorphism and complex sort\nsystems, and the gap between theory on paper and practical implementations in\nefficient programming languages. MetaCoq is a collaborative project that aims\nto tackle these difficulties to provide the first fully-certified realistic\nimplementation of a type checker for the full calculus underlying the Coq proof\nassistant. To achieve this, we refined the sometimes blurry, if not incorrect,\nspecification and implementation of the system. We show how theoretical tools\nfrom this community such as bidirectional type-checking,\nTait-Martin-L\\\"of/Takahashi's confluence proof technique and monadic and\ndependently-typed programming can help construct the following artefacts: a\nspecification of Coq's syntax and type theory, the Polymorphic Cumulative\nCalculus of (Co)-Inductive Constructions (PCUIC); a monad for the manipulation\nof raw syntax and interaction with the Coq system; a verification of PCUIC's\nmetatheory, whose main results are the confluence of reduction, type\npreservation and principality of typing; a realistic, correct and complete\ntype-checker for PCUIC; a sound type and proof erasure procedure from PCUIC to\nuntyped lambda-calculus, i.e., the core of the extraction mechanism of Coq.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 02:13:47 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Sozeau", "Matthieu", "", "Inria & LS2N, Universit\u00e9 de Nantes"]]}, {"id": "2107.07726", "submitter": "Masahiro Hamano", "authors": "Masahiro Hamano", "title": "Double Glueing over Free Exponential: with Measure Theoretic\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a compact method to lift the free exponential\nconstruction of Mellies-Tabareau-Tasson over the Hyland-Schalk double glueing\nfor orthogonality categories. A condition \"reciprocity of orthogonality\" is\npresented simply enough to lift the free exponential over the double glueing in\nterms of the orthogonality. Our general method applies to the monoidal category\nTsK of the s-finite transition kernels with countable biproducts. We show (i)\nTsK^{op} has the free exponential, which is shown to be describable in terms of\nmeasure theory. (ii) The s-finite transition kernels have an orthogonality\nbetween measures and measurable functions in terms of Lebesgue integrals. The\northogonality is reciprocal, hence the free exponential of (i) lifts to the\northogonality category O_I(TsK^{op}), which subsumes Ehrhard et al's\nprobabilistic coherent spaces as the full subcategory of countable measurable\nspaces. To lift the free exponential, the measure-theoretic uniform convergence\ntheorem commuting Lebesgue integral and limit plays a crucial role. Our\nmeasure-theoretic orthogonality is considered as a continuous version of the\northogonality of the probabilistic coherent spaces for linear logic, and in\nparticular provides a two layered decomposition of Crubille et al's direct free\nexponential for these spaces.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 06:52:20 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Hamano", "Masahiro", ""]]}, {"id": "2107.07811", "submitter": "David Carral", "authors": "Camille Bourgaux and David Carral and Markus Kr\\\"otzsch and Sebastian\n  Rudolph and Micha\\\"el Thomazo", "title": "Capturing Homomorphism-Closed Decidable Queries with Existential Rules", "comments": "Technical Report of our KR 2021 Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existential rules are a very popular ontology-mediated query language for\nwhich the chase represents a generic computational approach for query\nanswering. It is straightforward that existential rule queries exhibiting chase\ntermination are decidable and can only recognize properties that are preserved\nunder homomorphisms. In this paper, we show the converse: every decidable query\nthat is closed under homomorphism can be expressed by an existential rule set\nfor which the standard chase universally terminates. Membership in this\nfragment is not decidable, but we show via a diagonalisation argument that this\nis unavoidable.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 10:41:05 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Bourgaux", "Camille", ""], ["Carral", "David", ""], ["Kr\u00f6tzsch", "Markus", ""], ["Rudolph", "Sebastian", ""], ["Thomazo", "Micha\u00ebl", ""]]}, {"id": "2107.08253", "submitter": "Carlos Gustavo Lopez Pombo", "authors": "Carlos G. Lopez Pombo and Thomas S.E. Maibaum", "title": "A proof theoretic basis for relational semantics", "comments": "Many overflows I will solve in the future. Submitted for review to\n  Journal of Logic and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic has proved essential for formally modeling software based systems. Such\nformal descriptions, frequently called specifications, have served not only as\nrequirements documentation and formalisation, but also for providing the\nmathematical foundations for their analysis and the development of automated\nreasoning tools.\n  Logic is usually studied in terms of its two inherent aspects: syntax and\nsemantics. The relevance of the latter resides in the fact that producing\nlogical descriptions of real-world phenomena, requires people to agree on how\nsuch descriptions are to be interpreted and understood by human beings, so that\nsystems can be built with confidence in accordance with their specification. On\nthe more practical side, the metalogical relation between syntax and semantics,\ndetermines important aspects of the conclusions one can draw from the\napplication of certain analysis techniques, like model checking.\n  Abstract model theory (i.e., the mathematical perspective on semantics of\nlogical languages) is of little practical value to software engineering\nendeavours. From our point of view, values (those that can be assigned to\nconstants and variables) should not be just points in a platonic domain of\ninterpretation, but elements that can be named by means of terms over the\nsignature of the specification. In a nutshell, we are not interested in\nproperties that require any semantic information not representable using the\navailable syntax.\n  In this paper we present a framework supporting the proof theoretical\nformalisation of classes of relational models for behavioural logical\nlanguages, whose domains of discourse are guaranteed to be formed exclusively\nby nameable values.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 15:02:32 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Pombo", "Carlos G. Lopez", ""], ["Maibaum", "Thomas S. E.", ""]]}, {"id": "2107.08324", "submitter": "Yuri Gurevich", "authors": "Yuri Gurevich and Andreas Blass", "title": "Quantum circuits with classical channels and the principle of deferred\n  measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IT cs.LO math-ph math.IT math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define syntax and semantics of quantum circuits, allowing measurement\ngates and classical channels. We define circuit-based quantum algorithms and\nprove that, semantically, any such algorithm is equivalent to a single\nmeasurement that depends only on the underlying quantum circuit. Finally, we\nuse our formalization of quantum circuits to state precisely and prove the\nprinciple of deferred measurements.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 23:45:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gurevich", "Yuri", ""], ["Blass", "Andreas", ""]]}, {"id": "2107.08349", "submitter": "Vitor Greati", "authors": "Vitor Greati, S\\'ergio Marcelino, Jo\\~ao Marcos", "title": "Proof Search on Bilateralist Judgments over Non-deterministic Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bilateralist approach to logical consequence maintains that judgments of\ndifferent qualities should be taken into account in determining\nwhat-follows-from-what. We argue that such an approach may be actualized by a\ntwo-dimensional notion of entailment induced by semantic structures that also\naccommodate non-deterministic and partial interpretations, and propose a\nproof-theoretical apparatus to reason over bilateralist judgments using\nsymmetrical two-dimensional analytical Hilbert-style calculi. We also provide a\nproof-search algorithm for finite analytic calculi that runs in at most\nexponential time, in general, and in polynomial time when only rules having at\nmost one formula in the succedent are present in the concerned calculus.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 02:47:16 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Greati", "Vitor", ""], ["Marcelino", "S\u00e9rgio", ""], ["Marcos", "Jo\u00e3o", ""]]}, {"id": "2107.08409", "submitter": "Konstantin Korovin", "authors": "Andr\\'e Duarte and Konstantin Korovin", "title": "AC Simplifications and Closure Redundancies in the Superposition\n  Calculus", "comments": "Full version of the paper to appear in TABLEAUX 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reasoning in the presence of associativity and commutativity (AC) is well\nknown to be challenging due to prolific nature of these axioms. Specialised\ntreatment of AC axioms is mainly supported by provers for unit equality which\nare based on Knuth-Bendix completion. The main ingredient for dealing with AC\nin these provers are ground joinability criteria adapted for AC.\n  In this paper we extend AC joinability from the context of unit equalities\nand Knuth-Bendix completion to the superposition calculus and full first-order\nlogic. Our approach is based on an extension of the Bachmair-Ganzinger model\nconstruction and a new redundancy criterion which covers ground joinability. A\nby-product of our approach is a new criterion for applicability of demodulation\nwhich we call encompassment demodulation. This criterion is useful in any\nsuperposition theorem prover, independently of AC theories, and we demonstrate\nthat it enables demodulation in many more cases, compared to the standard\ncriterion.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 10:30:42 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Duarte", "Andr\u00e9", ""], ["Korovin", "Konstantin", ""]]}, {"id": "2107.08453", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Probabilistic Process Algebra for True Concurrency", "comments": "139 pages, 60 tables. arXiv admin note: substantial text overlap with\n  arXiv:1611.09035, arXiv:2101.05140, arXiv:2104.05438, arXiv:1810.00868,\n  arXiv:1907.02668, arXiv:1811.01070, arXiv:1501.05260, arXiv:1404.0665", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known process algebras, such as CCS, ACP and $\\pi$-calculus, capture\nthe interleaving concurrency based on bisimilarity semantics. We did some work\non truly concurrent process algebras, such as CTC, APTC and $\\pi_{tc}$ ,\ncapture the true concurrency based on truly concurrent bisimilarities, such as\npomset bisimilarity, step bisimilarity, history-preserving (hp-) bisimilarity\nand hereditary history-preserving (hhp-) bisimilarity. Truly concurrent process\nalgebras are generalizations of the corresponding traditional process algebras.\nIn this book, we introduce probabilism into truly concurrent process algebras,\nbased on the work on probabilistic process algebra.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:11:26 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 06:08:24 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "2107.08728", "submitter": "Sergey A. Slavnov", "authors": "Sergey Slavnov", "title": "Cobordisms and commutative categorial grammars", "comments": "This is the final version of the previously posted series of drafts\n  on cobordimns and categorial grammars. Concise and, hopefully, much improved\n  presentation, but no new mathematical content compared to preceding versions.\n  arXiv admin note: text overlap with arXiv:1911.03962", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a concrete surface representation of abstract categorial grammars\nin the category of word cobordisms or cowordisms for short, which are certain\nbipartite graphs decorated with words in a given alphabet, generalizing linear\nlogic proof-nets. We also introduce and study linear logic grammars, directly\nbased on cobordisms and using classical multiplicative linear logic as a typing\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:55:21 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Slavnov", "Sergey", ""]]}, {"id": "2107.08794", "submitter": "Stanly Samuel", "authors": "Stanly Samuel, Deepak D'Souza, Raghavan Komondoor", "title": "GenSys: A Scalable Fixed-point Engine for Maximal Controller Synthesis\n  over Infinite State Spaces", "comments": null, "journal-ref": null, "doi": "10.1145/3468264.3473126", "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The synthesis of maximally-permissive controllers in infinite-state systems\nhas many practical applications. Such controllers directly correspond to\nmaximal winning strategies in logically specified infinite-state two-player\ngames. In this paper, we introduce a tool called GenSys which is a fixed-point\nengine for computing maximal winning strategies for players in infinite-state\nsafety games. A key feature of GenSys is that it leverages the capabilities of\nexisting off-the-shelf solvers to implement its fixed point engine. GenSys\noutperforms state-of-the-art tools in this space by a significant margin. Our\ntool has solved some of the challenging problems in this space, is scalable,\nand also synthesizes compact controllers. These controllers are comparatively\nsmall in size and easier to comprehend. GenSys is freely available for use and\nis available under an open-source license.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:58:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Samuel", "Stanly", ""], ["D'Souza", "Deepak", ""], ["Komondoor", "Raghavan", ""]]}, {"id": "2107.08852", "submitter": "Brandon Bohrer", "authors": "Brandon Bohrer, Andr\\'e Platzer", "title": "Structured Proofs for Adversarial Cyber-Physical Systems", "comments": "Preprint of paper appearing in ESWEEK-TECS (EMSOFT 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cyber-physical systems (CPS) are safety-critical, so it is important to\nformally verify them, e.g. in formal logics that show a model's correctness\nspecification always holds. Constructive Differential Game Logic (CdGL) is such\na logic for (constructive) hybrid games, including hybrid systems. To overcome\nundecidability, the user first writes a proof, for which we present a\nproof-checking tool.\n  We introduce Kaisar, the first language and tool for CdGL proofs, which until\nnow could only be written by hand with a low-level proof calculus. Kaisar's\nstructured proofs simplify challenging CPS proof tasks, especially by using\nprogramming language principles and high-level stateful reasoning. Kaisar\nexploits CdGL's constructivity and refinement relations to build proofs around\nmodels of game strategies. The evaluation reproduces and extends existing case\nstudies on 1D and 2D driving. Proof metrics are compared and reported\nexperiences are discussed for the original studies and their reproductions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:10:22 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bohrer", "Brandon", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "2107.08921", "submitter": "Kees Middelburg", "authors": "C.A. Middelburg", "title": "Dormancy-aware timed branching bisimilarity", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A variant of the standard notion of branching bisimilarity for processes with\ndiscrete relative timing is proposed which is coarser than the standard notion.\nUsing a version of ACP (Algebra of Communicating Processes) with abstraction\nfor processes with discrete relative timing, it is shown that the proposed\nvariant allows of the functional correctness of the PAR (Positive\nAcknowledgement with Retransmission) protocol as well as its performance\nproperties to be analyzed. In the version of ACP concerned, the difference\nbetween the standard notion and its proposed variant is characterized by a\nsingle axiom schema.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:34:54 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Middelburg", "C. A.", ""]]}, {"id": "2107.09119", "submitter": "Muhammad Najib", "authors": "Julian Gutierrez, Lewis Hammond, Anthony W. Lin, Muhammad Najib,\n  Michael Wooldridge", "title": "Rational Verification for Probabilistic Systems", "comments": "18th International Conference on Principles of Knowledge\n  Representation and Reasoning (KR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Rational verification is the problem of determining which temporal logic\nproperties will hold in a multi-agent system, under the assumption that agents\nin the system act rationally, by choosing strategies that collectively form a\ngame-theoretic equilibrium. Previous work in this area has largely focussed on\ndeterministic systems. In this paper, we develop the theory and algorithms for\nrational verification in probabilistic systems. We focus on concurrent\nstochastic games (CSGs), which can be used to model uncertainty and randomness\nin complex multi-agent environments. We study the rational verification problem\nfor both non-cooperative games and cooperative games in the qualitative\nprobabilistic setting. In the former case, we consider LTL properties satisfied\nby the Nash equilibria of the game and in the latter case LTL properties\nsatisfied by the core. In both cases, we show that the problem is\n2EXPTIME-complete, thus not harder than the much simpler verification problem\nof model checking LTL properties of systems modelled as Markov decision\nprocesses (MDPs).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 19:24:16 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 09:52:31 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gutierrez", "Julian", ""], ["Hammond", "Lewis", ""], ["Lin", "Anthony W.", ""], ["Najib", "Muhammad", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2107.09280", "submitter": "Jesko Hecking-Harbusch", "authors": "Bernd Finkbeiner, Manuel Gieseking, Jesko Hecking-Harbusch,\n  Ernst-R\\\"udiger Olderog", "title": "Global Winning Conditions in Synthesis of Distributed Systems with\n  Causal Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the synthesis of distributed systems, we automate the development of\ndistributed programs and hardware by automatically deriving correct\nimplementations from formal specifications. For synchronous distributed\nsystems, the synthesis problem is well known to be undecidable. For\nasynchronous systems, the boundary between decidable and undecidable synthesis\nproblems is a long-standing open question. We study the problem in the setting\nof Petri games, a framework for distributed systems where asynchronous\nprocesses are equipped with causal memory. Petri games extend Petri nets with a\ndistinction between system places and environment places. The components of a\ndistributed system are the players of the game, represented as tokens that\nexchange information during each synchronization. Previous decidability results\nfor this model are limited to local winning conditions, i.e., conditions that\nonly refer to individual components. In this paper, we consider global winning\nconditions such as mutual exclusion, i.e., conditions that refer to the state\nof all components. We provide decidability and undecidability results for\nglobal winning conditions. First, we prove for winning conditions given as bad\nmarkings that it is decidable whether a winning strategy for the system players\nexists in Petri games with a bounded number of system players and one\nenvironment player. Second, we prove for winning conditions that refer to both\ngood and bad markings that it is undecidable whether a winning strategy for the\nsystem players exists in Petri games with at least two system players and one\nenvironment player. Our results thus show that, on the one hand, it is indeed\npossible to use global safety specifications like mutual exclusion in the\nsynthesis of distributed systems. However, on the other hand, adding global\nliveness specifications results in an undecidable synthesis problem for almost\nall Petri games.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 06:48:53 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Gieseking", "Manuel", ""], ["Hecking-Harbusch", "Jesko", ""], ["Olderog", "Ernst-R\u00fcdiger", ""]]}, {"id": "2107.09320", "submitter": "Sravanthi Chede", "authors": "Sravanthi Chede and Anil Shukla", "title": "QRAT Polynomially Simulates Merge Resolution", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Merge Resolution (MRes [Beyersdorff et al. J. Autom. Reason.'2021] ) is a\nrefutational proof system for quantified Boolean formulas (QBF). Each line of\nMRes consists of clauses with only existential literals, together with\ninformation of countermodels stored as merge maps. As a result, MRes has\nstrategy extraction by design. The QRAT [Heule et al. J. Autom. Reason.'2017]\nproof system was designed to capture QBF preprocessing. QRAT can simulate both\nthe expansion-based proof system $\\forall$Exp+Res and CDCL-based QBF proof\nsystem LD-Q-Res.\n  A family of false QBFs called SquaredEquality formulas were introduced in\n[Beyersdorff et al. J. Autom. Reason.'2021] and shown to be easy for MRes but\nneed exponential size proofs in Q-Res, QU-Res, CP+$\\forall$red,\n$\\forall$Exp+Res, IR-calc and reductionless LD-Q-Res. As a result none of these\nsystems can simulate MRes. In this paper, we show a short QRAT refutation of\nthe SquaredEquality formulas. We further show that QRAT strictly p-simulates\nMRes. Besides highlighting the power of QRAT system, this work also presents\nthe first simulation result for MRes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 08:19:15 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chede", "Sravanthi", ""], ["Shukla", "Anil", ""]]}, {"id": "2107.09423", "submitter": "Marcin Kozik", "authors": "Libor Barto and Marcin Kozik", "title": "Combinatorial Gap Theorem and Reductions between Promise CSPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A value of a CSP instance is typically defined as a fraction of constraints\nthat can be simultaneously met. We propose an alternative definition of a value\nof an instance and show that, for purely combinatorial reasons, a value of an\nunsolvable instance is bounded away from one; we call this fact a gap theorem.\n  We show that the gap theorem implies NP-hardness of a gap version of the\nLayered Label Cover Problem. The same result can be derived from the PCP\nTheorem, but a full, self-contained proof of our reduction is quite short and\nthe result can still provide PCP-free NP-hardness proofs for numerous problems.\nThe simplicity of our reasoning also suggests that weaker versions of\nUnique-Games-type conjectures, e.g., the d-to-1 conjecture, might be accessible\nand serve as an intermediate step for proving these conjectures in their full\nstrength.\n  As the second, main application we provide a sufficient condition under which\na fixed template Promise Constraint Satisfaction Problem (PCSP) reduces to\nanother PCSP. The correctness of the reduction hinges on the gap theorem, but\nthe reduction itself is very simple. As a consequence, we obtain that every CSP\ncan be canonically reduced to most of the known NP-hard PCSPs, such as the\napproximate hypergraph coloring problem.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:36:17 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Barto", "Libor", ""], ["Kozik", "Marcin", ""]]}, {"id": "2107.10034", "submitter": "Jan Jakubuv", "authors": "Karel Chvalovsk\\'y, Jan Jakub\\r{u}v, Miroslav Ol\\v{s}\\'ak, Josef Urban", "title": "Learning Theorem Proving Components", "comments": "Accepted to TABLEAUX'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.NE cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Saturation-style automated theorem provers (ATPs) based on the given clause\nprocedure are today the strongest general reasoners for classical first-order\nlogic. The clause selection heuristics in such systems are, however, often\nevaluating clauses in isolation, ignoring other clauses. This has changed\nrecently by equipping the E/ENIGMA system with a graph neural network (GNN)\nthat chooses the next given clause based on its evaluation in the context of\npreviously selected clauses. In this work, we describe several algorithms and\nexperiments with ENIGMA, advancing the idea of contextual evaluation based on\nlearning important components of the graph of clauses.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 12:00:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chvalovsk\u00fd", "Karel", ""], ["Jakub\u016fv", "Jan", ""], ["Ol\u0161\u00e1k", "Miroslav", ""], ["Urban", "Josef", ""]]}, {"id": "2107.10159", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi and Gabriela Reyes", "title": "Answer-Set Programs for Reasoning about Counterfactual Interventions and\n  Responsibility Scores for Classification", "comments": "Extended version with appendices of conference submission (under\n  review). arXiv admin note: text overlap with arXiv:2106.10562", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe how answer-set programs can be used to declaratively specify\ncounterfactual interventions on entities under classification, and reason about\nthem. In particular, they can be used to define and compute responsibility\nscores as attribution-based explanations for outcomes from classification\nmodels. The approach allows for the inclusion of domain knowledge and supports\nquery answering. A detailed example with a naive-Bayes classifier is presented.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:41:56 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Reyes", "Gabriela", ""]]}, {"id": "2107.10160", "submitter": "Emanuele De Angelis", "authors": "Emanuele De Angelis and Wim Vanhoof", "title": "Pre-proceedings of the 31st International Symposium on Logic-Based\n  Program Synthesis and Transformation (LOPSTR 2021)", "comments": "Papers selected for presentation at LOPSTR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume constitutes the pre-proceedings of the 31st International\nSymposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2021),\nheld on 7-8th September 2021 as a hybrid (blended) meeting, both in-person (at\nthe Teachers' House in Tallinn, Estonia) and virtual, and co-located with the\n23rd International Symposium on Principles and Practice of Declarative\nProgramming (PPDP 2021). After discussion at the symposium papers will go\nthrough a second round of refereeing and selection for the formal proceedings.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:43:23 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 07:40:00 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["De Angelis", "Emanuele", ""], ["Vanhoof", "Wim", ""]]}, {"id": "2107.10188", "submitter": "Qingxiang Wang", "authors": "Qingxiang Wang, Cezary Kaliszyk", "title": "JEFL: Joint Embedding of Formal Proof Libraries", "comments": "Submission to FroCoS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The heterogeneous nature of the logical foundations used in different\ninteractive proof assistant libraries has rendered discovery of similar\nmathematical concepts among them difficult. In this paper, we compare a\npreviously proposed algorithm for matching concepts across libraries with our\nunsupervised embedding approach that can help us retrieve similar concepts. Our\napproach is based on the fasttext implementation of Word2Vec, on top of which a\ntree traversal module is added to adapt its algorithm to the representation\nformat of our data export pipeline. We compare the explainability,\ncustomizability, and online-servability of the approaches and argue that the\nneural embedding approach has more potential to be integrated into an\ninteractive proof assistant.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:31:33 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Wang", "Qingxiang", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "2107.10349", "submitter": "Yo\\`av Montacute", "authors": "David Fern\\'andez-Duque and Yo\\`av Montacute", "title": "Dynamic Cantor Derivative Logic", "comments": "26 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological semantics for modal logic based on the Cantor derivative operator\ngives rise to derivative logics, also referred to as $d$-logics. Unlike logics\nbased on the topological closure operator, $d$-logics have not previously been\nstudied in the framework of dynamical systems, which are pairs $(X,f)$\nconsisting of a topological space $X$ equipped with a continuous function\n$f\\colon X\\to X$.\n  We introduce the logics $\\bf{wK4C}$, $\\bf{K4C}$ and $\\bf{GLC}$ and show that\nthey all have the finite Kripke model property and are sound and complete with\nrespect to the $d$-semantics in this dynamical setting. In particular, we prove\nthat $\\bf{wK4C}$ is the $d$-logic of all dynamic topological systems,\n$\\bf{K4C}$ is the $d$-logic of all $T_D$ dynamic topological systems, and\n$\\bf{GLC}$ is the $d$-logic of all dynamic topological systems based on a\nscattered space. We also prove a general result for the case where $f$ is a\nhomeomorphism, which in particular yields soundness and completeness for the\ncorresponding systems $\\bf{wK4H}$, $\\bf{K4H}$ and $\\bf{GLH}$.\n  The main contribution of this work is the foundation of a general proof\nmethod for finite model property and completeness of dynamic topological\n$d$-logics. Furthermore, our result for $\\bf{GLC}$ constitutes the first step\ntowards a proof of completeness for the trimodal topo-temporal language with\nrespect to a finite axiomatisation $\\mathord{-}$ something known to be\nimpossible over the class of all spaces.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 20:32:30 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Fern\u00e1ndez-Duque", "David", ""], ["Montacute", "Yo\u00e0v", ""]]}, {"id": "2107.10493", "submitter": "Sihyun Yu", "authors": "Sihyun Yu, Sangwoo Mo, Sungsoo Ahn, Jinwoo Shin", "title": "Abstract Reasoning via Logic-guided Generation", "comments": "ICML 2021 Workshop on Self-Supervised Learning for Reasoning and\n  Perception (Spotlight Talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract reasoning, i.e., inferring complicated patterns from given\nobservations, is a central building block of artificial general intelligence.\nWhile humans find the answer by either eliminating wrong candidates or first\nconstructing the answer, prior deep neural network (DNN)-based methods focus on\nthe former discriminative approach. This paper aims to design a framework for\nthe latter approach and bridge the gap between artificial and human\nintelligence. To this end, we propose logic-guided generation (LoGe), a novel\ngenerative DNN framework that reduces abstract reasoning as an optimization\nproblem in propositional logic. LoGe is composed of three steps: extract\npropositional variables from images, reason the answer variables with a logic\nlayer, and reconstruct the answer image from the variables. We demonstrate that\nLoGe outperforms the black box DNN frameworks for generative abstract reasoning\nunder the RAVEN benchmark, i.e., reconstructing answers based on capturing\ncorrect rules of various attributes from observations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:28:24 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Yu", "Sihyun", ""], ["Mo", "Sangwoo", ""], ["Ahn", "Sungsoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2107.10801", "submitter": "Peter Streufert", "authors": "Peter A. Streufert", "title": "Specifying a Game-Theoretic Extensive Form as an Abstract 5-ary Relation", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.GT cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper specifies an extensive form as a 5-ary relation (i.e. set of\nquintuples) which satisfies certain abstract axioms. Each quintuple is\nunderstood to list a player, a situation (e.g. information set), a decision\nnode, an action, and a successor node. Accordingly, the axioms are understood\nto specify abstract relationships between players, situations, nodes, and\nactions. Such an extensive form is called a \"5-form\", and a \"5-form game\" is\ndefined to be a 5-form together with utility functions. The paper's main result\nis to construct a bijection between (a) those 5-form games with information-set\nsituations and (b) $\\mathbf{Gm}$ games (Streufert arXiv:2105.11398). In this\nsense, 5-form games equivalently formulate almost all extensive-form games. An\napplication weakens the tree axiom in the presence of the other axioms, which\nleads to a convenient decomposition of 5-forms.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 16:56:07 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Streufert", "Peter A.", ""]]}, {"id": "2107.10832", "submitter": "Joseph Singleton", "authors": "Joseph Singleton", "title": "A Logic of Expertise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we introduce a simple modal logic framework to reason about the\nexpertise of an information source. In the framework, a source is an expert on\na proposition $p$ if they are able to correctly determine the truth value of\n$p$ in any possible world. We also consider how information may be false, but\ntrue after accounting for the lack of expertise of the source. This is relevant\nfor modelling situations in which information sources make claims beyond their\ndomain of expertise. We use non-standard semantics for the language based on an\nexpertise set with certain closure properties. It turns out there is a close\nconnection between our semantics and S5 epistemic logic, so that expertise can\nbe expressed in terms of knowledge at all possible states. We use this\nconnection to obtain a sound and complete axiomatisation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:42:38 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Singleton", "Joseph", ""]]}, {"id": "2107.10986", "submitter": "Gregory Wilsenach", "authors": "Anuj Dawar and Gregory Wilsenach", "title": "Lower Bounds for Symmetric Circuits for the Determinant", "comments": "29 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dawar and Wilsenach (ICALP 2020) introduce the model of symmetric arithmetic\ncircuits and show an exponential separation between the sizes of symmetric\ncircuits for computing the determinant and the permanent. The symmetry\nrestriction is that the circuits which take a matrix input are unchanged by a\npermutation applied simultaneously to the rows and columns of the matrix. Under\nsuch restrictions we have polynomial-size circuits for computing the\ndeterminant but no subexponential size circuits for the permanent. Here, we\nconsider a more stringent symmetry requirement, namely that the circuits are\nunchanged by arbitrary even permutations applied separately to rows and\ncolumns, and prove an exponential lower bound even for circuits computing the\ndeterminant. The result requires substantial new machinery. We develop a\ngeneral framework for proving lower bounds for symmetric circuits with\nrestricted symmetries, based on a new support theorem and new two-player\nrestricted bijection games. These are applied to the determinant problem with a\nnovel construction of matrices that are bi-adjacency matrices of graphs based\non the CFI construction. Our general framework opens the way to exploring a\nvariety of symmetry restrictions and studying trade-offs between symmetry and\nother resources used by arithmetic circuits.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 01:35:49 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 21:25:17 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Dawar", "Anuj", ""], ["Wilsenach", "Gregory", ""]]}, {"id": "2107.10988", "submitter": "Thomas Browning", "authors": "Thomas Browning and Patrick Lutz", "title": "Formalizing Galois Theory", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a project to formalize Galois theory using the Lean theorem\nprover, which is part of a larger effort to formalize all of the standard\nundergraduate mathematics curriculum in Lean. We discuss some of the challenges\nwe faced and the decisions we made in the course of this project. The main\ntheorems we formalized are the primitive element theorem, the fundamental\ntheorem of Galois theory, and the equivalence of several characterizations of\nfinite degree Galois extensions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 01:46:38 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Browning", "Thomas", ""], ["Lutz", "Patrick", ""]]}, {"id": "2107.11280", "submitter": "Chuangjie Xu", "authors": "Serdar Erbatur, Ulrich Sch\\\"opp, Chuangjie Xu", "title": "Type-based Enforcement of Infinitary Trace Properties for Java", "comments": "main part (14 pages) published at PPDP'21; arXiv version contains an\n  appendix on the FJ operational semantics and the extension to support\n  exception handling (15 pages total)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach to improve software quality is to use programming\nguidelines to avoid common kinds of errors. In this paper, we consider the\nproblem of enforcing guidelines for Featherweight Java (FJ). We formalize\nguidelines as sets of finite or infinite execution traces and develop a\nregion-based type and effect system for FJ that can enforce such guidelines. We\nbuild on the work by Erbatur, Hofmann and Z\\u{a}linescu, who presented a type\nsystem for verifying the finite event traces of terminating FJ programs. We\nrefine this type system, separating region typing from FJ typing, and use ideas\nof Hofmann and Chen to extend it to capture also infinite traces produced by\nnon-terminating programs. Our type and effect system can express properties of\nboth finite and infinite traces and can compute information about the possible\ninfinite traces of FJ programs. Specifically, the set of infinite traces of a\nmethod is constructed as the greatest fixed point of the operator which\ncalculates the possible traces of method bodies. Our type inference algorithm\nis realized by working with the finitary abstraction of the system based on\nB\\\"uchi automata.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:45:46 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Erbatur", "Serdar", ""], ["Sch\u00f6pp", "Ulrich", ""], ["Xu", "Chuangjie", ""]]}, {"id": "2107.11674", "submitter": "Andrei Popescu", "authors": "Lorenzo Gheri and Andrei Popescu", "title": "Case Studies in Formal Reasoning About Lambda-Calculus: Semantics,\n  Church-Rosser, Standardization and HOAS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We have previously published the Isabelle/HOL formalization of a general\ntheory of syntax with bindings. In this companion paper, we instantiate the\ngeneral theory to the syntax of lambda-calculus and formalize the development\nleading to several fundamental constructions and results: sound semantic\ninterpretation, the Church-Rosser and standardization theorems, and\nhigher-order abstract syntax (HOAS) encoding. For Church-Rosser and\nstandardization, our work covers both the call-by-name and call-by-value\nversions of the calculus, following classic papers by Takahashi and Plotkin.\nDuring the formalization, we were able to stay focused on the high-level ideas\nof the development -- thanks to the arsenal provided by our general theory: a\nwealth of basic facts about the substitution, swapping and freshness operators,\nas well as recursive-definition and reasoning principles, including a\nspecialization to semantic interpretation of syntax.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 19:25:48 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gheri", "Lorenzo", ""], ["Popescu", "Andrei", ""]]}, {"id": "2107.11679", "submitter": "Zhaowei Xu", "authors": "Zhaowei Xu, Mingsheng Ying and Beno\\^it Valiron", "title": "Reasoning about Recursive Quantum Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Most modern (classical) programming languages support recursion. Recursion\nhas also been successfully applied to the design of several quantum algorithms\nand introduced in a couple of quantum programming languages. So, it can be\nexpected that recursion will become one of the fundamental paradigms of quantum\nprogramming. Several program logics have been developed for verification of\nquantum while-programs. However, there are as yet no general methods for\nreasoning about (mutual) recursive procedures and ancilla quantum data\nstructure in quantum computing (with measurement). We fill the gap in this\npaper by proposing a parameterized quantum assertion logic and, based on which,\ndesigning a quantum Hoare logic for verifying parameterized recursive quantum\nprograms with ancilla data and probabilistic control. The quantum Hoare logic\ncan be used to prove partial, total, and even probabilistic correctness (by\nreducing to total correctness) of those quantum programs. In particular, two\ncounterexamples for illustrating incompleteness of non-parameterized assertions\nin verifying recursive procedures, and, one counterexample for showing the\nfailure of reasoning with exact probabilities based on partial correctness, are\nconstructed. The effectiveness of our logic is shown by three main examples --\nrecursive quantum Markov chain (with probabilistic control), fixed-point\nGrover's search, and recursive quantum Fourier sampling.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 20:11:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Xu", "Zhaowei", ""], ["Ying", "Mingsheng", ""], ["Valiron", "Beno\u00eet", ""]]}, {"id": "2107.11841", "submitter": "Bernd Finkbeiner", "authors": "Bernd Finkbeiner", "title": "Model Checking Algorithms for Hyperproperties", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-67067-2_1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties generalize trace properties by expressing relations between\nmultiple computations. Hyperpropertes include policies from information-flow\nsecurity, like observational determinism or non-interference, and many other\nsystem properties including promptness and knowledge. In this paper, we give an\noverview on the model checking problem for temporal hyperlogics. Our starting\npoint is the model checking algorithm for HyperLTL, a reduction to B\\\"uchi\nautomata emptiness. This basic construction can be extended with propositional\nquantification, resulting in an algorithm for HyperQPTL. It can also be\nextended with branching time, resulting in an algorithm for HyperCTL*. However,\nit is not possible to have both extensions at the same time: the model checking\nproblem of HyperQCTL* is undecidable. An attractive compromise is offered by\nMPL[E], i.e., monadic path logic extended with the equal-level predicate. The\nexpressiveness of MPL[E] falls strictly between that of HyperCTL* and\nHyperQCTL*. MPL[E] subsumes both HyperCTL* and HyperKCTL*, the extension of\nHyperCTL* with the knowledge operator. We show that the model checking problem\nfor MPL[E] is still decidable.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 16:45:14 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Finkbeiner", "Bernd", ""]]}, {"id": "2107.11864", "submitter": "Frederik Schmitt", "authors": "Frederik Schmitt, Christopher Hahn, Markus N. Rabe and Bernd\n  Finkbeiner", "title": "Neural Circuit Synthesis from Specification Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train hierarchical Transformers on the task of synthesizing hardware\ncircuits directly out of high-level logical specifications in linear-time\ntemporal logic (LTL). The LTL synthesis problem is a well-known algorithmic\nchallenge with a long history and an annual competition is organized to track\nthe improvement of algorithms and tooling over time. New approaches using\nmachine learning might open a lot of possibilities in this area, but suffer\nfrom the lack of sufficient amounts of training data. In this paper, we\nconsider a method to generate large amounts of additional training data, i.e.,\npairs of specifications and circuits implementing them. We ensure that this\nsynthetic data is sufficiently close to human-written specifications by mining\ncommon patterns from the specifications used in the synthesis competitions. We\nshow that hierarchical Transformers trained on this synthetic data solve a\nsignificant portion of problems from the synthesis competitions, and even\nout-of-distribution examples from a recent case study.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 18:17:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Schmitt", "Frederik", ""], ["Hahn", "Christopher", ""], ["Rabe", "Markus N.", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2107.12144", "submitter": "Robin Kaarsgaard", "authors": "Chris Heunen and Robin Kaarsgaard", "title": "Quantum Information Effects", "comments": "32 pages, including 10 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the two dual quantum information effects to manipulate the amount of\ninformation in quantum computation: hiding and allocation. The resulting\ntype-and-effect system is fully expressive for irreversible quantum computing,\nincluding measurement. We provide universal categorical constructions that\nsemantically interpret this arrow metalanguage with choice, starting with any\nrig groupoid interpreting the reversible base language. Several properties of\nquantum measurement follow in general, and we translate quantum flow charts\ninto our language. The semantic constructions turn the category of unitaries\nbetween Hilbert spaces into the category of completely positive\ntrace-preserving maps, and they turn the category of bijections between finite\nsets into the category of functions with chosen garbage. Thus they capture the\nfundamental theorems of classical and quantum reversible computing of Toffoli\nand Stinespring.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:21:42 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Heunen", "Chris", ""], ["Kaarsgaard", "Robin", ""]]}, {"id": "2107.12150", "submitter": "Prabhat Kumar Jha", "authors": "Prabhat Kumar Jha", "title": "Cosine and Computation", "comments": "Submitted to FSTTCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.DM cs.LO math.NT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are interested in solving decision problem $\\exists? t \\in \\mathbb{N},\n\\cos t \\theta = c$ where $\\cos \\theta$ and $c$ are algebraic numbers. We call\nthis the $\\cos t \\theta$ problem. This is an exploration of Diophantine\nequations with analytic functions. Polynomial, exponential with real base and\ncosine function are closely related to this decision problem: $ \\exists ? t \\in\n\\mathbb{N}, u^T M^t v = 0$ where $u, v \\in \\mathbb{Q}^n, M \\in\n\\mathbb{Q}^{n\\times n}$. This problem is also known as \"Skolem problem\" and is\nuseful in verification of linear systems. Its decidability remains unknown.\nSingle variable Diophantine equations with exponential function with real\nalgebraic base and $\\cos t \\theta$ function with $\\theta$ a rational multiple\nof $\\pi$ is decidable. This idea is central in proving the decidability of\nSkolem problem when the eigenvalues of $M$ are roots of real numbers. The main\ndifficulty with the cases when eigenvalues are not roots of reals is that even\nfor small order cases decidability requires application of trancendental number\ntheory which does not scale for higher order cases. We provide a first attempt\nto overcome that by providing a $PTIME$ algorithm for $\\cos t \\theta$ when\n$\\theta$ is not a rational multiple of $\\pi$. We do so without using techniques\nfrom transcendental number theory. \\par One of the main difficulty in\nDiophantine equations is being unable to use tools from calculus to solve this\nequation as the domain of variable is $\\mathbb{N}$. We also provide an attempt\nto overcome that by providing reduction of Skolem problem to solving a one\nvariable equation (which involves polynomials, exponentials with real bases and\n$\\cos t \\theta$ function with $t$ ranging over reals and $\\theta \\in [0, \\pi]$)\nover reals.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 05:55:38 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Jha", "Prabhat Kumar", ""]]}, {"id": "2107.12475", "submitter": "Tristan St\\'erin", "authors": "Tristan St\\'erin and Damien Woods", "title": "On the hardness of knowing busy beaver values BB(15) and BB(5,4)", "comments": "12 pages, 5 figures, code and machines available at\n  https://github.com/tcosmo/bbsim", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The busy beaver value BB($n$) is the maximum number of steps made by any\n$n$-state, 2-symbol deterministic halting Turing machine starting on blank\ntape, and BB($n,k$) denotes its $k$-symbol generalisation to $k\\geq 2$. The\nbusy beaver function $n \\mapsto \\text{BB}(n)$ is uncomputable and its values\nhave been linked to hard open problems in mathematics and notions of\nunprovability.\n  In this paper, we show that there are two explicit Turing machines, one with\n15 states and 2 symbols, the other with 5 states and 4 symbols, that halt if\nand only if the following Collatz-related conjecture by Erd\\H{o}s [1979] does\nnot hold does not hold: for all $n>8$ there is at least one digit 2 in the base\n3 representation of $2^n$. This result implies that knowing the values of\nBB(15) or BB(5,4) is at least as hard as solving Erd\\H{o}s' conjecture and\nmakes, to date, BB(15) the smallest busy beaver value that is related to a\nnatural open problem in mathematics. For comparison, Yedidia and Aaronson\n[2016] show that knowing BB(4,888) and BB(5,372) are as hard as solving\nGoldbach's conjecture and the Riemann hypothesis, respectively (later\ninformally improved to BB(27) and BB(744)). Finally, our result puts a finite,\nalbeit large, bound on Erd\\H{o}s' conjecture, by making it equivalent to the\nfollowing finite statement: for all $8 < n \\leq \\min(\\text{BB}(15),\n\\text{BB}(5,4))$ there is at least one digit 2 in the base 3 representation of\n$2^n$.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 21:02:44 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["St\u00e9rin", "Tristan", ""], ["Woods", "Damien", ""]]}, {"id": "2107.12902", "submitter": "Hari Govind Vediramana Krishnan", "authors": "Hari Govind V K, Sharon Shoham, Arie Gurfinkel", "title": "Logical Characterization of Coherent Uninterpreted Programs", "comments": "Accepted at FMCAD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An uninterpreted program (UP) is a program whose semantics is defined over\nthe theory of uninterpreted functions. This is a common abstraction used in\nequivalence checking, compiler optimization, and program verification. While\nsimple, the model is sufficiently powerful to encode counter automata, and,\nhence, undecidable. Recently, a class of UP programs, called coherent, has been\nproposed and shown to be decidable. We provide an alternative, logical\ncharacterization, of this result. Specifically, we show that every coherent\nprogram is bisimilar to a finite state system. Moreover, an inductive invariant\nof a coherent program is representable by a formula whose terms are of depth at\nmost 1. We also show that the original proof, via automata, only applies to\nprograms over unary uninterpreted functions. While this work is purely\ntheoretical, it suggests a novel abstraction that is complete for coherent\nprograms but can be soundly used on arbitrary uninterpreted (and partially\ninterpreted) programs.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 03:52:56 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["K", "Hari Govind V", ""], ["Shoham", "Sharon", ""], ["Gurfinkel", "Arie", ""]]}, {"id": "2107.12986", "submitter": "Khushraj Madnani", "authors": "Shankara Narayanan Krishna, Khushraj Nanik Madnani, Manuel Mazo Jr.,\n  Paritosh K. Pandya", "title": "Logics Meet 2-Way 1-Clock Alternating Timed Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the extension of 1-clock Alternating Timed Automata\n(1-ATA) with the ability to read in both forward and backward direction, the\n2-Way 1-clock Alternating Timed Automata (2-Way 1-ATA). We show that subclass\nof 2-Way 1-ATA with reset free loops (2-Way 1-ATA-rfl) is expressively\nequivalent to MSO[<] extended with Guarded Metric Quantifiers (GQMSO).\nEmptiness Checking problem for 2-Way 1-ATA-rfl (and hence GQMSO) is\nundecidable, in general. We propose a \"non-punctuality\" like restriction,\ncalled non-adjacency, for 2-Way 1-ATA-rfl, and also for GQMSO, for which the\nemptiness (respectively, satisfiability) checking becomes decidable.\nNon-Adjacent 2-Way 1-ATA is the first such class of Timed Automata with\nalternations and 2-wayness for which the emptiness checking is decidable (and\nthat too with elementary complexity). We also show that 2-Way 1-ATA-rfl, even\nwith the non-adjacent restrictions, can express properties is not recognizable\nusing 1-ATA.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:55:36 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Krishna", "Shankara Narayanan", ""], ["Madnani", "Khushraj Nanik", ""], ["Mazo", "Manuel", "Jr."], ["Pandya", "Paritosh K.", ""]]}, {"id": "2107.13242", "submitter": "Tesla Zhang", "authors": "Tesla Zhang", "title": "Type theories in category theory", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce basic notions in category theory to type theorists, including\ncomprehension categories, categories with attributes, contextual categories,\ntype categories, and categories with families along with additional discussions\nthat are not very closely related to type theories by listing definitions,\nlemmata, and remarks. By doing so, this introduction becomes more friendly as a\nreferential material to be read in random order (instead of from the beginning\nto the end). In the end, we list some mistakes made in the early versions of\nthis introduction.\n  The interpretation of common type formers in dependent type theories are\ndiscussed based on existing categorical constructions instead of mechanically\nderived from their type theoretical definition. Non-dependent type formers\ninclude unit, products (as fiber products), and functions (as fiber exponents),\nand dependent ones include extensional equalities (as equalizers), dependent\nproducts, and the universe of (all) propositions (as the subobject classifier).\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 09:54:39 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zhang", "Tesla", ""]]}, {"id": "2107.13347", "submitter": "Vladimir Zamdzhiev", "authors": "Xiaodong Jia, Andre Kornell, Bert Lindenhovius, Michael Mislove,\n  Vladimir Zamdzhiev", "title": "Semantics for Variational Quantum Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT math.OA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a programming language that can manipulate both classical and\nquantum information. Our language is type-safe and designed for variational\nquantum programming, which is a hybrid classical-quantum computational\nparadigm. The classical subsystem of the language is the Probabilistic FixPoint\nCalculus (PFPC), which is a lambda calculus with mixed-variance recursive\ntypes, term recursion and probabilistic choice. The quantum subsystem is a\nfirst-order linear type system that can manipulate quantum information. The two\nsubsystems are related by mixed classical/quantum terms that specify how\nclassical probabilistic effects are induced by quantum measurements, and\nconversely, how classical (probabilistic) programs can influence the quantum\ndynamics. We also describe a sound and computationally adequate denotational\nsemantics for the language. Classical probabilistic effects are interpreted\nusing a recently-described commutative probabilistic monad on DCPO. Quantum\neffects and resources are interpreted in a category of von Neumann algebras\nthat we show is enriched over (continuous) domains. This strong sense of\nenrichment allows us to develop novel semantic methods that we use to interpret\nthe relationship between the quantum and classical probabilistic effects. By\ndoing so we provide the first denotational analysis that relates models of\nclassical probabilistic programming to models of quantum programming.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:22:24 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Jia", "Xiaodong", ""], ["Kornell", "Andre", ""], ["Lindenhovius", "Bert", ""], ["Mislove", "Michael", ""], ["Zamdzhiev", "Vladimir", ""]]}, {"id": "2107.13477", "submitter": "Elizabeth Polgreen", "authors": "Elizabeth Polgreen, Andrew Reynolds and Sanjit A. Seshia", "title": "Satisfiability and Synthesis Modulo Oracles", "comments": "12 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classic program synthesis algorithms, such as counterexample-guided\ninductive synthesis (CEGIS), the algorithms alternate between a synthesis phase\nand an oracle (verification) phase. Many synthesis algorithms use a white-box\noracle based on satisfiability modulo theory (SMT) solvers to provide\ncounterexamples. But what if a white-box oracle is either not available or not\neasy to work with? We present a framework for solving a general class of\noracle-guided synthesis problems which we term synthesis modulo oracles. In\nthis setting, oracles may be black boxes with a query-response interface\ndefined by the synthesis problem. As a necessary component of this framework,\nwe also formalize the problem of satisfiability modulo theories and oracles,\nand present an algorithm for solving this problem. We implement a prototype\nsolver for satisfiability and synthesis modulo oracles and demonstrate that, by\nusing oracles that execute functions not easily modeled in SMT-constraints,\nsuch as recursive functions or oracles that incorporate compilation and\nexecution of code, SMTO and SyMO are able to solve problems beyond the\nabilities of standard SMT and synthesis solvers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:36:26 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Polgreen", "Elizabeth", ""], ["Reynolds", "Andrew", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2107.13827", "submitter": "Shyamali Mitra", "authors": "Shyamali Mitra, Sayantan Banerjee and Mrinal Kanti Naskar", "title": "ReCo1: A Fault resilient technique of Correlation Sensitive Stochastic\n  Designs", "comments": "24 pages,20 figures, 2 tables, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic circuits, major sources of error are correlation errors, soft\nerrors and random fluctuation errors that affect the accuracy and reliability\nof the circuit. The soft error has the effect of changing the correlation\nstatus and in turn changes the probability of numbers leading to the erroneous\noutput. This has serious impact on security and medical systems where highly\naccurate systems are required. We tackle this problem by introducing the\nfault-tolerant technique of correlation-sensitive stochastic logic circuits. We\ndevelop a framework of Remodelling Correlation(ReCo) for Stochastic Logic\nElements; AND, XOR and OR for reliable operation. We present two variants of\nReCo models in combinational circuits with contradictory requirements by\nstating two interesting case studies. The proposed technique selects logic\nelements and places correction blocks based on a priority-based rule that helps\nto converge to the desired MSE quickly requiring less hardware area. It is\nshown that this technique does not alter the reliability of the overall\ncircuit. To demonstrate the practical effectiveness of the proposed framework,\ncontrast stretch operation on a standard image in a noisy environment is\nstudied. A high structural similarity index measure of 92.80 is observed for\nthe output image with the proposed approach compared to the image (with error)\n66.43.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 08:45:39 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Mitra", "Shyamali", ""], ["Banerjee", "Sayantan", ""], ["Naskar", "Mrinal Kanti", ""]]}, {"id": "2107.13953", "submitter": "Miko{\\l}aj Boja\\'nczyk", "authors": "Mikolaj Bojanczyk", "title": "Separator logic and star-free expressions for graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe two formalisms for defining graph languages, and prove that they\nare equivalent:\n  1. Separator logic. This is first-order logic on graphs which is allowed to\nuse the edge relation, and for every $n \\in \\{0,1,\\ldots \\}$ a relation of\narity $n+2$ which says that ``vertex $s$ can be connected to vertex $t$ by a\npath that avoids vertices $v_1,\\ldots,v_n$''.\n  2. Star-free graph expressions. These are expressions that describe graphs\nwith distinguished vertices called ports, and which are built from finite\nlanguages via Boolean combinations and the operations on graphs with ports used\nto construct tree decompositions.\n  Furthermore, we prove a variant of Sch\\\"utzenberger's theorem (about\nstar-free languages being those recognized by a periodic monoids) for graphs of\nbounded pathwidth. A corollary is that, given $k$ and a graph language\nrepresented by an \\mso formula, one can decide if the language can be defined\nin either of two equivalent formalisms on graphs of pathwidth at most $k$.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 13:28:46 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Bojanczyk", "Mikolaj", ""]]}, {"id": "2107.13975", "submitter": "Nils Kurbis", "authors": "Nils K\\\"urbis", "title": "A Sketch of a Proof-Theoretic Semantics for Necessity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper considers proof-theoretic semantics for necessity within Dummett's\nand Prawitz's framework. Inspired by a system of Pfenning's and Davies's, the\nlanguage of intuitionist logic is extended by a higher order operator which\ncaptures a notion of validity. A notion of relative necessary is defined in\nterms of it, which expresses a necessary connection between the assumptions and\nthe conclusion of a deduction.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:02:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["K\u00fcrbis", "Nils", ""]]}, {"id": "2107.13988", "submitter": "Nils Kurbis", "authors": "Nils K\\\"urbis", "title": "Proof-Theoretic Semantics, a Problem with Negation and Prospects for\n  Modality", "comments": null, "journal-ref": null, "doi": "10.1007/s10992-013-9310-6", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper discusses proof-theoretic semantics, the project of specifying the\nmeanings of the logical constants in terms of rules of inference governing\nthem. I concentrate on Michael Dummett's and Dag Prawitz' philosophical\nmotivations and give precise characterisations of the crucial notions of\nharmony and stability, placed in the context of proving normalisation results\nin systems of natural deduction. I point out a problem for defining the meaning\nof negation in this framework and prospects for an account of the meanings of\nmodal operators in terms of rules of inference.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:08:49 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["K\u00fcrbis", "Nils", ""]]}, {"id": "2107.14031", "submitter": "Francesco Dagnino", "authors": "Francesco Dagnino and Giuseppe Rosolini", "title": "Doctrines, modalities and comonads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Doctrines are categorical structures very apt to study logics of different\nnature within a unified environment: the 2-category Dtn of doctrines. Modal\ninterior operators are characterised as particular adjoints in the 2-category\nDtn. We show that they can be constructed from comonads in Dtn as well as from\nadjunctions in it, and the two constructions compare. Finally we show the\namount of information lost in the passage from a comonad, or from an\nadjunction, to the modal interior operator.\n  The basis for the present work is provided by some seminal work of John\nPower.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:38:21 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Dagnino", "Francesco", ""], ["Rosolini", "Giuseppe", ""]]}]