[{"id": "2009.00391", "submitter": "EPTCS", "authors": "Davide Ancona (DIBRIS, University of Genova, Italy), Angelo Ferrando\n  (University of Manchester, UK), Viviana Mascardi (DIBRIS, University of\n  Genova, Italy)", "title": "Can determinism and compositionality coexist in RML?", "comments": "In Proceedings EXPRESS/SOS 2020, arXiv:2008.12414. Author extended\n  version is arXiv:2008.06453", "journal-ref": "EPTCS 322, 2020, pp. 13-32", "doi": "10.4204/EPTCS.322.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Runtime verification (RV) consists in dynamically verifying that the event\ntraces generated by single runs of a system under scrutiny (SUS) are compliant\nwith the formal specification of its expected properties. RML (Runtime\nMonitoring Language) is a simple but expressive Domain Specific Language for\nRV; its semantics is based on a trace calculus formalized by a deterministic\nrewriting system which drives the implementation of the interpreter of the\nmonitors generated by the RML compiler from the specifications. While\ndeterminism of the trace calculus ensures better performances of the generated\nmonitors, it makes the semantics of its operators less intuitive. In this paper\nwe move a first step towards a compositional semantics of the RML trace\ncalculus, by interpreting its basic operators as operations on sets of\ninstantiated event traces and by proving that such an interpretation is\nequivalent to the operational semantics of the calculus.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:34:11 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ancona", "Davide", "", "DIBRIS, University of Genova, Italy"], ["Ferrando", "Angelo", "", "University of Manchester, UK"], ["Mascardi", "Viviana", "", "DIBRIS, University of\n  Genova, Italy"]]}, {"id": "2009.00416", "submitter": "Yannick Forster", "authors": "Yannick Forster", "title": "Church's thesis and related axioms in Coq's type theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Church's thesis\" ($\\mathsf{CT}$) as an axiom in constructive logic states\nthat every total function of type $\\mathbb{N} \\to \\mathbb{N}$ is computable,\ni.e. definable in a model of computation. $\\mathsf{CT}$ is inconsistent in both\nclassical mathematics and in Brouwer's intuitionism since it contradicts Weak\nK\\\"onig's Lemma and the fan theorem, respectively. Recently, $\\mathsf{CT}$ was\nproved consistent for (univalent) constructive type theory.\n  Since neither Weak K\\\"onig's Lemma nor the fan theorem are a consequence of\njust logical axioms or just choice-like axioms assumed in constructive logic,\nit seems likely that $\\mathsf{CT}$ is inconsistent only with a combination of\nclassical logic and choice axioms. We study consequences of $\\mathsf{CT}$ and\nits relation to several classes of axioms in Coq's type theory, a constructive\ntype theory with a universe of propositions which does neither prove classical\nlogical axioms nor strong choice axioms.\n  We thereby provide a partial answer to the question which axioms may preserve\ncomputational intuitions inherent to type theory, and which certainly do not.\nThe paper can also be read as a broad survey of axioms in type theory, with all\nresults mechanised in the Coq proof assistant.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 13:42:30 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 18:01:58 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Forster", "Yannick", ""]]}, {"id": "2009.00418", "submitter": "Kristijonas \\v{C}yras", "authors": "Kristijonas Cyras, Ramamurthy Badrinath, Swarup Kumar Mohalik, Anusha\n  Mujumdar, Alexandros Nikou, Alessandro Previti, Vaishnavi Sundararajan, Aneta\n  Vulgarakis Feljan", "title": "Machine Reasoning Explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a field of AI, Machine Reasoning (MR) uses largely symbolic means to\nformalize and emulate abstract reasoning. Studies in early MR have notably\nstarted inquiries into Explainable AI (XAI) -- arguably one of the biggest\nconcerns today for the AI community. Work on explainable MR as well as on MR\napproaches to explainability in other areas of AI has continued ever since. It\nis especially potent in modern MR branches, such as argumentation, constraint\nand logic programming, planning. We hereby aim to provide a selective overview\nof MR explainability techniques and studies in hopes that insights from this\nlong track of research will complement well the current XAI landscape. This\ndocument reports our work in-progress on MR explainability.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 13:45:05 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 17:09:03 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Cyras", "Kristijonas", ""], ["Badrinath", "Ramamurthy", ""], ["Mohalik", "Swarup Kumar", ""], ["Mujumdar", "Anusha", ""], ["Nikou", "Alexandros", ""], ["Previti", "Alessandro", ""], ["Sundararajan", "Vaishnavi", ""], ["Feljan", "Aneta Vulgarakis", ""]]}, {"id": "2009.00738", "submitter": "Colin Shea-Blymyer", "authors": "Colin Shea-Blymyer, Houssam Abbas", "title": "A Deontic Logic Analysis of Autonomous Systems' Safety", "comments": "11 pages, 4 figures, In 23rd ACM International Conference on Hybrid\n  Systems: Computation and Control", "journal-ref": null, "doi": "10.1145/3365365.3382203", "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the pressing question of how to model, verify, and ensure that\nautonomous systems meet certain \\textit{obligations} (like the obligation to\nrespect traffic laws), and refrain from impermissible behavior (like recklessly\nchanging lanes). Temporal logics are heavily used in autonomous system design;\nhowever, as we illustrate here, temporal (alethic) logics alone are\ninappropriate for reasoning about obligations of autonomous systems. This paper\nproposes the use of Dominance Act Utilitarianism (DAU), a deontic logic of\nagency, to encode and reason about obligations of autonomous systems. We use\nDAU to analyze Intel's Responsibility-Sensitive Safety (RSS) proposal as a\nreal-world case study. We demonstrate that DAU can express well-posed RSS\nrules, formally derive undesirable consequences of these rules, illustrate how\nDAU could help design systems that have specific obligations, and how to\nmodel-check DAU obligations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 22:56:15 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Shea-Blymyer", "Colin", ""], ["Abbas", "Houssam", ""]]}, {"id": "2009.00971", "submitter": "Lutz Schr\\\"oder", "authors": "Clemens Kupke, Dirk Pattinson, Lutz Schr\\\"oder", "title": "Coalgebraic Reasoning with Global Assumptions in Arithmetic Modal Logics", "comments": "Extended version of conference paper in FCT 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a generic upper bound ExpTime for reasoning with global\nassumptions (also known as TBoxes) in coalgebraic modal logics. Unlike earlier\nresults of this kind, our bound does not require a tractable set of tableau\nrules for the instance logics, so that the result applies to wider classes of\nlogics. Examples are Presburger modal logic, which extends graded modal logic\nwith linear inequalities over numbers of successors, and probabilistic modal\nlogic with polynomial inequalities over probabilities. We establish the\ntheoretical upper bound using a type elimination algorithm. We also provide a\nglobal caching algorithm that potentially avoids building the entire\nexponential-sized space of candidate states, and thus offers a basis for\npractical reasoning. This algorithm still involves frequent fixpoint\ncomputations; we show how these can be handled efficiently in a concrete\nalgorithm modelled on Liu and Smolka's linear time fixpoint algorithm. Finally,\nwe show that the upper complexity bound is preserved under adding nominals to\nthe logic, i.e. in coalgebraic hybrid logic.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 12:01:15 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Kupke", "Clemens", ""], ["Pattinson", "Dirk", ""], ["Schr\u00f6der", "Lutz", ""]]}, {"id": "2009.01145", "submitter": "Felipe S. Abrah\\~ao", "authors": "Felipe S. Abrah\\~ao, Klaus Wehmuth, Artur Ziviani", "title": "On the existence of hidden machines in computational time hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenging the standard notion of totality in computable functions, one has\nthat, given any sufficiently expressive formal axiomatic system, there are\ntotal functions that, although computable and \"intuitively\" understood as being\ntotal, cannot be proved to be total. In this article we show that this implies\nthe existence of an infinite hierarchy of time complexity classes whose\nrepresentative members are hidden from (or unknown by) the respective formal\naxiomatic systems. Although these classes contain total computable functions,\nthere are some of these functions for which the formal axiomatic system cannot\nrecognize as belonging to a time complexity class. This leads to incompleteness\nresults regarding formalizations of computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 15:46:09 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Abrah\u00e3o", "Felipe S.", ""], ["Wehmuth", "Klaus", ""], ["Ziviani", "Artur", ""]]}, {"id": "2009.01777", "submitter": "Erwan Mahe", "authors": "Erwan Mahe and Boutheina Bannour and Christophe Gaston and Arnault\n  Lapitre and Pascale Le Gall", "title": "A small-step approach to multi-trace checking against interactions", "comments": "long version - 26 pages (23 for paper, 2 for bibliography, and a 1\n  page annex) - 15 figures (1 in annex)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction models describe the exchange of messages between the different\ncomponents of distributed systems. We have previously defined a small-step\noperational semantics for interaction models. The paper extends this work by\npresenting an approach for checking the validity of multi-traces against\ninteraction models. A multi-trace is a collection of traces (sequences of\nemissions and receptions), each representing a local view of the same global\nexecution of the distributed system. We have formally proven our approach,\nstudied its complexity, and implemented it in a prototype tool. Finally, we\ndiscuss some observability issues when testing distributed systems via the\nanalysis of multi-traces.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:33:20 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 12:22:15 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 23:36:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mahe", "Erwan", ""], ["Bannour", "Boutheina", ""], ["Gaston", "Christophe", ""], ["Lapitre", "Arnault", ""], ["Gall", "Pascale Le", ""]]}, {"id": "2009.01883", "submitter": "Nicolai Kraus", "authors": "Nicolai Kraus", "title": "Internal $\\infty$-Categorical Models of Dependent Type Theory: Towards\n  2LTT Eating HoTT", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using dependent type theory to formalise the syntax of dependent type theory\nis a very active topic of study and goes under the name of \"type theory eating\nitself\" or \"type theory in type theory.\" Most approaches are at least loosely\nbased on Dybjer's categories with families (CwF's) and come with a type CON of\ncontexts, a type family TY indexed over it modelling types, and so on. This\nworks well in versions of type theory where the principle of unique identity\nproofs (UIP) holds. In homotopy type theory (HoTT) however, it is a\nlong-standing and frequently discussed open problem whether the type theory\n\"eats itself\" and can serve as its own interpreter. The fundamental underlying\ndifficulty seems to be that categories are not suitable to capture a type\ntheory in the absence of UIP.\n  In this paper, we develop a notion of $\\infty$-categories with families\n($\\infty$-CwF's). The approach to higher categories used relies on the\npreviously suggested semi-Segal types, with a new construction of identity\nsubstitutions that allow for both univalent and non-univalent variations. The\ntype-theoretic universe as well as the internalised syntax are models, although\nit remains a conjecture that the latter is initial. To circumvent the known\nunsolved problem of constructing semisimplicial types, the definition is\npresented in two-level type theory (2LTT).\n  Apart from introducing $\\infty$-CwF's, the paper explains the shortcomings of\n1-categories in type theory without UIP as well as the difficulties of and\napproaches to internal higher-dimensional categories.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 18:54:58 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 22:43:25 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kraus", "Nicolai", ""]]}, {"id": "2009.02720", "submitter": "Carlos Gustavo Lopez Pombo", "authors": "Carlos G. Lopez Pombo, Marcelo F. Frias, Thomas S.E. Maibaum", "title": "On the construction of explosive relation algebras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fork algebras are an extension of relation algebras obtained by extending the\nset of logical symbols with a binary operator called fork. This class of\nalgebras was introduced by Haeberer and Veloso in the early 90's aiming at\nenriching relation algebra, an already successful language for program\nspecification, with the capability of expressing some form of parallel\ncomputation.\n  The further study of this class of algebras led to many meaningful results\nlinked to interesting properties of relation algebras such as representability\nand finite axiomatizability, among others. Also in the 90's, Veloso introduced\na subclass of relation algebras that are expansible to fork algebras, admitting\na large number of non-isomorphic expansions, referred to as explosive relation\nalgebras.\n  In this work we discuss some general techniques for constructing algebras of\nthis type.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 12:32:19 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 17:49:50 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Pombo", "Carlos G. Lopez", ""], ["Frias", "Marcelo F.", ""], ["Maibaum", "Thomas S. E.", ""]]}, {"id": "2009.02985", "submitter": "Doron Tiferet", "authors": "Alexander Rabinovich and Doron Tiferet", "title": "Ambiguity Hierarchy of Regular Infinite Tree Languages", "comments": "Revised according to the reviewers comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An automaton is unambiguous if for every input it has at most one accepting\ncomputation. An automaton is k-ambiguous (for k>0) if for every input it has at\nmost k accepting computations. An automaton is boundedly ambiguous if there is\nk, such that for every input it has at most k accepting computations. An\nautomaton is finitely (respectively, countably) ambiguous if for every input it\nhas at most finitely (respectively, countably) many accepting computations.\n  The degree of ambiguity of a regular language is defined in a natural way. A\nlanguage is k-ambiguous (respectively, boundedly, finitely, countably\nambiguous) if it is accepted by a k-ambiguous (respectively, boundedly,\nfinitely, countably ambiguous) automaton. Over finite words, every regular\nlanguage is accepted by a deterministic automaton. Over finite trees, every\nregular language is accepted by an unambiguous automaton. Over $\\omega$-words\nevery regular language is accepted by an unambiguous B\\\"uchi automaton and by a\ndeterministic parity automaton. Over infinite trees, Carayol et al. showed that\nthere are ambiguous languages.\n  We show that over infinite trees there is a hierarchy of degrees of\nambiguity: For every k>1 there are k-ambiguous languages which are not k-1\nambiguous; and there are finitely (respectively countably, uncountably)\nambiguous languages which are not boundedly (respectively finitely, countably)\nambiguous.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:08:24 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 12:55:20 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Rabinovich", "Alexander", ""], ["Tiferet", "Doron", ""]]}, {"id": "2009.02995", "submitter": "Markus Iser", "authors": "Markus Iser, Luca Springer, Carsten Sinz", "title": "Collaborative Management of Benchmark Instances and their Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental evaluation is an integral part in the design process of\nalgorithms. Publicly available benchmark instances are widely used to evaluate\nmethods in SAT solving. For the interpretation of results and the design of\nalgorithm portfolios their attributes are crucial. Capturing the interrelation\nof benchmark instances and their attributes is considerably simplified through\nour specification of a benchmark instance identifier. Thus, our tool increases\nthe availability of both by providing means to manage and retrieve benchmark\ninstances by their attributes and vice versa. Like this, it facilitates the\ndesign and analysis of SAT experiments and the exchange of results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:23:08 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Iser", "Markus", ""], ["Springer", "Luca", ""], ["Sinz", "Carsten", ""]]}, {"id": "2009.03074", "submitter": "Benjamin Monmege", "authors": "Thomas Brihaye, Gilles Geeraerts, Axel Haddad, Engel Lefaucheux,\n  Benjamin Monmege", "title": "One-Clock Priced Timed Games with Negative Weights", "comments": "arXiv admin note: substantial text overlap with arXiv:1507.03786", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Priced timed games are two-player zero-sum games played on priced timed\nautomata (whose locations and transitions are labeled by weights modelling the\nprice of spending time in a state and executing an action, respectively). The\ngoals of the players are to minimise and maximise the price to reach a target\nlocation, respectively. We consider priced timed games with one clock and\narbitrary integer weights and show that, for an important subclass of theirs\n(the so-called simple priced timed games), one can compute, in exponential\ntime, the optimal values that the players can achieve, with their associated\noptimal strategies. As side results, we also show that one-clock priced timed\ngames are determined and that we can use our result on simple priced timed\ngames to solve the more general class of so-called negative-reset-acyclic\npriced timed games (with arbitrary integer weights and one clock). The\ndecidability status of the full class of priced timed games with one-clock and\narbitrary integer weights still remains open.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:01:40 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 17:05:30 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Brihaye", "Thomas", ""], ["Geeraerts", "Gilles", ""], ["Haddad", "Axel", ""], ["Lefaucheux", "Engel", ""], ["Monmege", "Benjamin", ""]]}, {"id": "2009.03193", "submitter": "Azlan Iqbal", "authors": "Azlan Iqbal", "title": "An Algorithm for Automatically Updating a Forsyth-Edwards Notation\n  String Without an Array Board Representation", "comments": "6 pages, 6 figures, 4 tables, 1 appendix section; presented at the\n  8th International Conference on Information Technology and Multimedia on 24th\n  August 2020 (final version published by IEEE Xplore)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that correctly updates the Forsyth-Edwards Notation\n(FEN) chessboard character string after any move is made without the need for\nan intermediary array representation of the board. In particular, this relates\nto software that have to do with chess, certain chess variants and possibly\neven similar board games with comparable position representation. Even when\nperformance may be equal or inferior to using arrays, the algorithm still\nprovides an accurate and viable alternative to accomplishing the same thing, or\nwhen there may be a need for additional or side processing in conjunction with\narrays. Furthermore, the end result (i.e. an updated FEN string) is immediately\nready for export to any other internal module or external program, unlike with\nan intermediary array which needs to be first converted into a FEN string for\nexport purposes. The algorithm is especially useful when there are no existing\narray-based modules to represent a visual board as it can do without them\nentirely. We provide examples that demonstrate the correctness of the algorithm\ngiven a variety of positions involving castling, en passant and pawn promotion.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 09:13:58 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 04:26:35 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Iqbal", "Azlan", ""]]}, {"id": "2009.03486", "submitter": "Eitetsu Ken", "authors": "Eitetsu Ken, Masaki Natori, Kenji Tojo, Kazuki Watanabe", "title": "On principal types and well-foundedness of the cummulativity relation in\n  ECC", "comments": "14 pages, no figures, the title changed, the historical remarks\n  modified, the results unchanged, the e-mail addresses added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we investigate a type system, it is helpful if we can establish the\nwell-foundedness of types or terms with respect to a certain hierarchy, and the\nExtended Calculus of Constructions (called $ECC$, defined and studied\ncomprehensively in [Luo,1994]) is no exception. However, under a very natural\nhierarchy relation (called the cumulativity relation in [Luo,1994]), the\nwell-foundedness of the hierarchy does not hold generally.\n  In this article,we show that the cumulativity relation is well-founded if it\nis restricted to one of the following two natural families of terms:\n  \\begin{enumerate}\n  \\item types in a valid context\n  \\item terms having normal forms\n  \\end{enumerate}\n  Also, we give an independent proof of the existence of principal types in\n$ECC$ since it is used in the proof of well-foundedness of cumulativity\nrelation in a valid context although it is often proved by utilizing the\nwell-foundedness of the hierarchy, which would make our argument circular if\nadopted.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 02:15:56 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 04:44:12 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 08:32:13 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 04:24:04 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ken", "Eitetsu", ""], ["Natori", "Masaki", ""], ["Tojo", "Kenji", ""], ["Watanabe", "Kazuki", ""]]}, {"id": "2009.03623", "submitter": "Klaus-Dieter Schewe", "authors": "Klaus-Dieter Schewe and Yamine Ait-Ameur and Sarah Benyagoub", "title": "Realisability of Control-State Choreographies", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choreographies prescribe the rendez-vous synchronisation of messages in a\nsystem of communicating finite state machines. Such a system is called\nrealisable, if the traces of the prescribed communication coincide with those\nof the asynchronous system of peers, where the communication channels either\nuse FIFO queues or multiset mailboxes. In a recent article realisability was\ncharacterised by two necessary conditions that together are sufficient. A\nsimple consequence is that realisability in the presence of a choreography\nbecomes decidable. In this article we extend this work by generalising\nchoreographies to control-state choreographies, which enable parallelism. We\nredefine P2P systems on grounds of control-state machines and show that a\ncontrol-state choreography is equivalent to the rendez-vous compositions of its\npeers and that language-synchronisability coincides with synchronisability.\nThese results are used to characterise realisability of control-state\nchoreographies. As for the case of FSM-based choreographies we prove two\nnecessary conditions: a sequence condition and a choice condition. Then we also\nshow that these two conditions together are sufficient for the realisability of\ncontrol-state choreographies.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 10:04:13 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Schewe", "Klaus-Dieter", ""], ["Ait-Ameur", "Yamine", ""], ["Benyagoub", "Sarah", ""]]}, {"id": "2009.04259", "submitter": "Flavio Ferrarotti", "authors": "Flavio Ferrarotti, Senen Gonzalez, Klaus-Dieter Schewe, Jose Maria\n  Turull-Torres", "title": "Completeness in Polylogarithmic Time and Space", "comments": "Submitted to Annals of Mathematics and Artificial Intelligence. arXiv\n  admin note: text overlap with arXiv:1911.13104", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complexity theory can be viewed as the study of the relationship between\ncomputation and applications, understood the former as complexity classes and\nthe latter as problems. Completeness results are clearly central to that view.\nMany natural algorithms resulting from current applications have\npolylogarithmic time (PolylogTime) or space complexity (PolylogSpace). The\nclassical Karp notion of complete problem however does not plays well with\nthese complexity classes. It is well known that PolylogSpace does not have\ncomplete problems under logarithmic space many-one reductions. In this paper we\nshow similar results for deterministic and non-deterministic PolylogTime as\nwell as for every other level of the polylogarithmic time hierarchy. We achieve\nthat by following a different strategy based on proving the existence of proper\nhierarchies of problems inside each class. We then develop an alternative\nnotion of completeness inspired by the concept of uniformity from circuit\ncomplexity and prove the existence of a (uniformly) complete problem for\nPolylogSpace under this new notion. As a consequence of this result we get that\ncomplete problems can still play an important role in the study of the\ninterrelationship between polylogarithmic and other classical complexity\nclasses.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 14:40:01 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Ferrarotti", "Flavio", ""], ["Gonzalez", "Senen", ""], ["Schewe", "Klaus-Dieter", ""], ["Turull-Torres", "Jose Maria", ""]]}, {"id": "2009.05484", "submitter": "Laura Nenzi", "authors": "Luca Bortolussi, Giuseppe Maria Gallo and Laura Nenzi", "title": "A kernel function for Signal Temporal Logic formulae", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss how to define a kernel for Signal Temporal Logic (STL) formulae.\nSuch a kernel allows us to embed the space of formulae into a Hilbert space,\nand opens up the use of kernel-based machine learning algorithms in the context\nof STL. We show an application of this idea to a regression problem in formula\nspace for probabilistic models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:06:25 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Bortolussi", "Luca", ""], ["Gallo", "Giuseppe Maria", ""], ["Nenzi", "Laura", ""]]}, {"id": "2009.05539", "submitter": "Andrej Bauer", "authors": "Andrej Bauer, Philipp G. Haselwarter, Peter LeFanu Lumsdaine", "title": "A general definition of dependent type theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a general class of dependent type theories, encompassing\nMartin-L\\\"of's intuitionistic type theories and variants and extensions. The\nprimary aim is pragmatic: to unify and organise their study, allowing results\nand constructions to be given in reasonable generality, rather than just for\nspecific theories. Compared to other approaches, our definition stays closer to\nthe direct or naive reading of syntax, yielding the traditional presentations\nof specific theories as closely as possible.\n  Specifically, we give three main definitions: raw type theories, a minimal\nsetup for discussing dependently typed derivability; acceptable type theories,\nincluding extra conditions ensuring well-behavedness; and well-presented type\ntheories, generalising how in traditional presentations, the well-behavedness\nof a type theory is established step by step as the type theory is built up.\nFollowing these, we show that various fundamental fitness-for-purpose\nmetatheorems hold in this generality.\n  Much of the present work has been formalised in the proof assistant Coq.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:23:37 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Bauer", "Andrej", ""], ["Haselwarter", "Philipp G.", ""], ["Lumsdaine", "Peter LeFanu", ""]]}, {"id": "2009.05547", "submitter": "Carlo Angiuli", "authors": "Carlo Angiuli, Evan Cavallo, Anders M\\\"ortberg, Max Zeuner", "title": "Internalizing Representation Independence with Univalence", "comments": "30 pages; ACM SIGPLAN Symposium on Principles of Programming\n  Languages (POPL), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their usual form, representation independence metatheorems provide an\nexternal guarantee that two implementations of an abstract interface are\ninterchangeable when they are related by an operation-preserving\ncorrespondence. If our programming language is dependently-typed, however, we\nwould like to appeal to such invariance results within the language itself, in\norder to obtain correctness theorems for complex implementations by\ntransferring them from simpler, related implementations. Recent work in proof\nassistants has shown that Voevodsky's univalence principle allows transferring\ntheorems between isomorphic types, but many instances of representation\nindependence in programming involve non-isomorphic representations.\n  In this paper, we develop techniques for establishing internal relational\nrepresentation independence results in dependent type theory, by using higher\ninductive types to simultaneously quotient two related implementation types by\na heterogeneous correspondence between them. The correspondence becomes an\nisomorphism between the quotiented types, thereby allowing us to obtain an\nequality of implementations by univalence. We illustrate our techniques by\nconsidering applications to matrices, queues, and finite multisets. Our results\nare all formalized in Cubical Agda, a recent extension of Agda which supports\nunivalence and higher inductive types in a computationally well-behaved way.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:29:29 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 21:18:25 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Angiuli", "Carlo", ""], ["Cavallo", "Evan", ""], ["M\u00f6rtberg", "Anders", ""], ["Zeuner", "Max", ""]]}, {"id": "2009.05554", "submitter": "Yehia Abd Alrahman", "authors": "Yehia Abd Alrahman, Victor Braberman, Nicol\\'as D'Ippolito, Nir\n  Piterman, Sebasti\\'an Uchitel", "title": "Synthesis of Run-To-Completion Controllers for Discrete Event Systems", "comments": "This work is supported by the following grants: the ERC Consolidator\n  grant D-SynMA (No. 772459), the Marie Sk{\\l}odowska-Curie BeHAPI (No.\n  778233), the grants ANPCYT PICT 2018-3835, ANPCYT PICT 2015-1718, CONICET PIP\n  2014/16 N{\\deg}11220130100688CO, and UBACYT 20020170100419 BA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A controller for a Discrete Event System must achieve its goals despite that\nits environment being capable of resolving race conditions between controlled\nand uncontrolled events.Assuming that the controller loses all races is\nsometimes unrealistic. In many cases, a realistic assumption is that the\ncontroller sometimes wins races and is fast enough to perform multiple actions\nwithout being interrupted. However, in order to model this scenario using\ncontrol of DES requires introducing foreign assumptions about scheduling, that\nare hard to figure out correctly. We propose a more balanced control problem,\nnamed run-to-completion (RTC), to alleviate this issue. RTC naturally supports\nan execution assumption in which both the controller and the environment are\nguaranteed to initiate and perform sequences of actions, without flooding or\ndelaying each other indefinitely. We consider control of DES in the context\nwhere specifications are given in the form of linear temporal logic. We\nformalize the RTC control problem and show how it can be reduced to a standard\ncontrol problem.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:39:38 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 10:12:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Alrahman", "Yehia Abd", ""], ["Braberman", "Victor", ""], ["D'Ippolito", "Nicol\u00e1s", ""], ["Piterman", "Nir", ""], ["Uchitel", "Sebasti\u00e1n", ""]]}, {"id": "2009.05774", "submitter": "Christian Anti\\'c", "authors": "Christian Antic", "title": "Finite Horn Monoids via Propositional Horn Theory Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.DM math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Describing complex objects as the composition of elementary ones is a common\nstrategy in computer science and science in general. This paper contributes to\nthe foundations of knowledge representation and database theory by introducing\nand studying the sequential composition of propositional Horn theories.\nSpecifically, we show that the notion of composition gives rise to a family of\nmonoids and seminearrings, which we will call {\\em Horn monoids} and {\\em Horn\nseminearrings} in this paper. Particularly, we show that the combination of\ncomposition and union yields the structure of a finite idempotent seminearring.\nWe also show that the restricted class of proper propositional Krom-Horn\ntheories, which only contain rules with exactly one body atom, yields a finite\nidempotent semiring. On the semantic side, we show that the van Emden-Kowalski\nimmediate consequence operator of a theory can be represented via composition,\nwhich allows us to compute its least model semantics without any explicit\nreference to operators. This bridges the conceptual gap between the syntax and\nsemantics of a propositional Horn theory in a mathematically satisfactory way.\nMoreover, it gives rise to an algebraic meta-calculus for propositional Horn\ntheories. In a broader sense, this paper is a first step towards an algebra of\nrule-based logical theories and in the future we plan to adapt and generalize\nthe methods of this paper to wider classes of theories, most importantly to\nfirst-, and higher-order logic programs, and non-monotonic logic programs under\nthe stable model or answer set semantics and extensions thereof.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 11:57:30 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 14:47:23 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 17:18:49 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Antic", "Christian", ""]]}, {"id": "2009.06087", "submitter": "Alessandro Daniele", "authors": "Alessandro Daniele, Luciano Serafini", "title": "Neural Networks Enhancement through Prior Logical Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent past, there has been a growing interest in Neural-Symbolic\nIntegration frameworks, i.e., hybrid systems that integrate connectionist and\nsymbolic approaches: on the one hand, neural networks show remarkable abilities\nto learn from a large amount of data in presence of noise, on the other, pure\nsymbolic methods can perform reasoning as well as learning from few samples. By\ncombining the two paradigms, it should be possible to obtain a system that can\nboth learn from data and apply inference over some background knowledge. Here\nwe propose KENN (Knowledge Enhanced Neural Networks), a Neural-Symbolic\narchitecture that injects prior knowledge, codified in a set of universally\nquantified FOL clauses, into a neural network model. In KENN, clauses are used\nto generate a new final layer of the neural network which modifies the initial\npredictions based on the knowledge. Among the advantages of this strategy,\nthere is the possibility to include additional learnable parameters, the clause\nweights, each of which represents the strength of a specific clause. We\nevaluated KENN on two standard datasets for multi-label classification, showing\nthat the injection of clauses, automatically extracted from the training data,\nsensibly improves the performances. In a further experiment with manually\ncurated knowledge, KENN outperformed state-of-the-art methods on the VRD\nDataset, where the task is to classify relationships between detected objects\nin images. Finally, to evaluate how KENN deals with relational data, we tested\nit with different learning configurations on Citeseer, a standard dataset for\nCollective Classification. The obtained results show that KENN is capable of\nincreasing the performances of the underlying neural network even in the\npresence of relational data obtaining results in line with other methods that\ncombine learning with logic.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 21:12:20 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Daniele", "Alessandro", ""], ["Serafini", "Luciano", ""]]}, {"id": "2009.06334", "submitter": "EPTCS", "authors": "John Baez, Bob Coecke", "title": "Proceedings Applied Category Theory 2019", "comments": null, "journal-ref": "EPTCS 323, 2020", "doi": "10.4204/EPTCS.323", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applied Category Theory is a new conference series. All papers are carefully\nrefereed, and the bar for acceptance is high. This 1st occurrence in this\nformat resulted in some 70 submitted papers and 150 attendants. The conference\nis part of the Compositionally family, a new diamond open access journal.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 11:43:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Baez", "John", ""], ["Coecke", "Bob", ""]]}, {"id": "2009.06336", "submitter": "Ziba Assadi", "authors": "Ziba Assadi", "title": "Decidability of the Multiplicative and Order Theory of Numbers", "comments": "Ph.D. Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ordered structures of natural, integer, rational and real numbers are\nstudied in this thesis. The theories of these numbers in the language of order\nare decidable and finitely axiomatizable. Also, their theories in the language\nof order and addition are decidable and infinitely axiomatizable. For the\nlanguage of order and multiplication, it is known that the theories of\n$\\mathbb{N}$ and $\\mathbb{Z}$ are not decidable (and so not axiomatizable by\nany computably enumerable set of sentences). By Tarski's theorem, the\nmultiplicative ordered structure of $\\mathbb{R}$ is decidable also. In this\nthesis we prove this result directly by quantifier elimination and present an\nexplicit infinite axiomatization. The structure of $\\mathbb{Q}$ in the language\nof order and multiplication seems to be missing in the literature. We show the\ndecidability of its theory by the technique of quantifier elimination and after\npresenting an infinite axiomatization for this structure, we prove that it is\nnot finitely axiomatizable.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 11:47:11 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Assadi", "Ziba", ""]]}, {"id": "2009.06429", "submitter": "Anna Lukina", "authors": "Anna Lukina, Christian Schilling, Thomas A. Henzinger", "title": "Into the Unknown: Active Monitoring of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural-network classifiers achieve high accuracy when predicting the class of\nan input that they were trained to identify. Maintaining this accuracy in\ndynamic environments, where inputs frequently fall outside the fixed set of\ninitially known classes, remains a challenge. The typical approach is to detect\ninputs from novel classes and retrain the classifier on an augmented dataset.\nHowever, not only the classifier but also the detection mechanism needs to\nadapt in order to distinguish between newly learned and yet unknown input\nclasses. To address this challenge, we introduce an algorithmic framework for\nactive monitoring of a neural network. A monitor wrapped in our framework\noperates in parallel with the neural network and interacts with a human user\nvia a series of interpretable labeling queries for incremental adaptation. In\naddition, we propose an adaptive quantitative monitor to improve precision. An\nexperimental evaluation on a diverse set of benchmarks with varying numbers of\nclasses confirms the benefits of our active monitoring framework in dynamic\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 13:29:47 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 13:00:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lukina", "Anna", ""], ["Schilling", "Christian", ""], ["Henzinger", "Thomas A.", ""]]}, {"id": "2009.06516", "submitter": "Debabrota Basu", "authors": "Bishwamittra Ghosh, Debabrota Basu, Kuldeep S. Meel", "title": "Justicia: A Stochastic SAT Approach to Formally Verify Fairness", "comments": "24 pages, 7 figures, 5 theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a technology ML is oblivious to societal good or bad, and thus, the field\nof fair machine learning has stepped up to propose multiple mathematical\ndefinitions, algorithms, and systems to ensure different notions of fairness in\nML applications. Given the multitude of propositions, it has become imperative\nto formally verify the fairness metrics satisfied by different algorithms on\ndifferent datasets. In this paper, we propose a \\textit{stochastic\nsatisfiability} (SSAT) framework, Justicia, that formally verifies different\nfairness measures of supervised learning algorithms with respect to the\nunderlying data distribution. We instantiate Justicia on multiple\nclassification and bias mitigation algorithms, and datasets to verify different\nfairness metrics, such as disparate impact, statistical parity, and equalized\nodds. Justicia is scalable, accurate, and operates on non-Boolean and compound\nsensitive attributes unlike existing distribution-based verifiers, such as\nFairSquare and VeriFair. Being distribution-based by design, Justicia is more\nrobust than the verifiers, such as AIF360, that operate on specific test\nsamples. We also theoretically bound the finite-sample error of the verified\nfairness measure.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:23:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ghosh", "Bishwamittra", ""], ["Basu", "Debabrota", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2009.06544", "submitter": "Torsten Schaub", "authors": "Felicidad Aguado, Pedro Cabalar, Martin Dieguez, Gilberto Perez,\n  Torsten Schaub, Anna Schuhmann, Concepcion Vidal", "title": "Temporal Answer Set Programming", "comments": "47 pages, 5 figures, 4 tables, lots of theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview on Temporal Logic Programming under the perspective of\nits application for Knowledge Representation and declarative problem solving.\nSuch programs are the result of combining usual rules with temporal modal\noperators, as in Linear-time Temporal Logic (LTL). We focus on recent results\nof the non-monotonic formalism called Temporal Equilibrium Logic (TEL) that is\ndefined for the full syntax of LTL, but performs a model selection criterion\nbased on Equilibrium Logic, a well known logical characterization of Answer Set\nProgramming (ASP). We obtain a proper extension of the stable models semantics\nfor the general case of arbitrary temporal formulas. We recall the basic\ndefinitions for TEL and its monotonic basis, the temporal logic of\nHere-and-There (THT), and study the differences between infinite and finite\ntraces. We also provide other useful results, such as the translation into\nother formalisms like Quantified Equilibrium Logic or Second-order LTL, and\nsome techniques for computing temporal stable models based on automata. In a\nsecond part, we focus on practical aspects, defining a syntactic fragment\ncalled temporal logic programs closer to ASP, and explain how this has been\nexploited in the construction of the solver TELINGO.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:13:36 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 15:57:56 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Aguado", "Felicidad", ""], ["Cabalar", "Pedro", ""], ["Dieguez", "Martin", ""], ["Perez", "Gilberto", ""], ["Schaub", "Torsten", ""], ["Schuhmann", "Anna", ""], ["Vidal", "Concepcion", ""]]}, {"id": "2009.06611", "submitter": "Marko Markovic", "authors": "Marko Markovi\\'c, Stevan Gostoji\\'c", "title": "Knowledge-Based Legal Document Assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a knowledge-based legal document assembly method that\nuses a machine-readable representation of knowledge of legal professionals.\nThis knowledgebase has two components - the formal knowledge of legal norms\nrepresented as a rule-base and the tacit knowledge represented by a document\ntemplate. A document assembly system is developed as a proof of concept. It\ncollects input data in the form of an interactive interview, performs legal\nreasoning over input data, and generates the output document. The system also\ncreates an argument graph as an explanation of the reasoning process providing\nthe user with an interpretation of how the input data and the rule-base\ninfluence the content of the output document. The system also semantically\nmarks up data in the output document, facilitating its further processing and\nproviding support to the interoperability of information systems in the legal\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:51:52 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Markovi\u0107", "Marko", ""], ["Gostoji\u0107", "Stevan", ""]]}, {"id": "2009.06831", "submitter": "EPTCS", "authors": "Neil Ghani (University of Strathclyde), Clemens Kupke (University of\n  Strathclyde), Alasdair Lambert (University of Strathclyde), Fredrik Nordvall\n  Forsberg (University of Strathclyde)", "title": "Compositional Game Theory with Mixed Strategies: Probabilistic Open\n  Games Using a Distributive Law", "comments": "In Proceedings ACT 2019, arXiv:2009.06334", "journal-ref": "EPTCS 323, 2020, pp. 95-105", "doi": "10.4204/EPTCS.323.7", "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the open games framework for compositional game theory to encompass\nalso mixed strategies, making essential use of the discrete probability\ndistribution monad. We show that the resulting games form a symmetric monoidal\ncategory, which can be used to compose probabilistic games in parallel and\nsequentially. We also consider morphisms between games, and show that intuitive\nconstructions give rise to functors and adjunctions between pure and\nprobabilistic open games.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:14:36 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Ghani", "Neil", "", "University of Strathclyde"], ["Kupke", "Clemens", "", "University of\n  Strathclyde"], ["Lambert", "Alasdair", "", "University of Strathclyde"], ["Forsberg", "Fredrik Nordvall", "", "University of Strathclyde"]]}, {"id": "2009.06834", "submitter": "EPTCS", "authors": "Philip Johnson-Freyd (Sandia National Laboratories), Jon Aytac (Sandia\n  National Laboratories), Geoffrey Hulette (Sandia National Laboratories)", "title": "Topos Semantics for a Higher-Order Temporal Logic of Actions", "comments": "In Proceedings ACT 2019, arXiv:2009.06334", "journal-ref": "EPTCS 323, 2020, pp. 161-171", "doi": "10.4204/EPTCS.323.11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TLA is a popular temporal logic for writing stuttering-invariant\nspecifications of digital systems. However, TLA lacks higher-order features\nuseful for specifying modern software written in higher-order programming\nlanguages. We use categorical techniques to recast a real-time semantics for\nTLA in terms of the actions of a group of time dilations, or \"stutters,\" and an\nextension by a monoid incorporating delays, or \"falters.\" Via the geometric\nmorphism of the associated presheaf topoi induced by the inclusion of stutters\ninto falters, we construct the first model of a higher-order TLA.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:15:51 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Johnson-Freyd", "Philip", "", "Sandia National Laboratories"], ["Aytac", "Jon", "", "Sandia\n  National Laboratories"], ["Hulette", "Geoffrey", "", "Sandia National Laboratories"]]}, {"id": "2009.06836", "submitter": "EPTCS", "authors": "Brendan Fong (MIT), David Spivak (MIT)", "title": "String Diagrams for Regular Logic (Extended Abstract)", "comments": "In Proceedings ACT 2019, arXiv:2009.06334. Condensed version of\n  arXiv:1812.05765", "journal-ref": "EPTCS 323, 2020, pp. 196-229", "doi": "10.4204/EPTCS.323.14", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular logic can be regarded as the internal language of regular categories,\nbut the logic itself is generally not given a categorical treatment. In this\npaper, we understand the syntax and proof rules of regular logic in terms of\nthe free regular category FRg(T) on a set T. From this point of view, regular\ntheories are certain monoidal 2-functors from a suitable 2-category of contexts\n-- the 2-category of relations in FRg(T) -- to that of posets. Such functors\nassign to each context the set of formulas in that context, ordered by\nentailment. We refer to such a 2-functor as a regular calculus because it\nnaturally gives rise to a graphical string diagram calculus in the spirit of\nJoyal and Street. We shall show that every natural category has an associated\nregular calculus, and conversely from every regular calculus one can construct\na regular category.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:16:45 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Fong", "Brendan", "", "MIT"], ["Spivak", "David", "", "MIT"]]}, {"id": "2009.06970", "submitter": "Ja\\v{s} \\v{S}emrl", "authors": "Robin Hirsch and Ja\\v{s} \\v{S}emrl", "title": "Finite Representability of Semigroups with Demonic Refinement", "comments": null, "journal-ref": null, "doi": "10.1007/S00012-021-00718-5", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composition and demonic refinement $\\sqsubseteq$ of binary relations are\ndefined by \\begin{align*} (x, y)\\in (R;S)&\\iff \\exists z((x, z)\\in R\\wedge (z,\ny)\\in S)\n  R\\sqsubseteq S&\\iff (dom(S)\\subseteq dom(R) \\wedge\nR\\restriction_{dom(S)}\\subseteq S)\n  \\end{align*} where $dom(S)=\\{x:\\exists y (x, y)\\in S\\}$ and\n$R\\restriction_{dom(S)}$ denotes the restriction of $R$ to pairs $(x, y)$ where\n$x\\in dom(S)$.\n  Demonic calculus was introduced to model the total correctness of\nnon-deterministic programs and has been applied to program verification.\n  We prove that the class $R(\\sqsubseteq, ;)$ of abstract $(\\leq, \\circ)$\nstructures isomorphic to a set of binary relations ordered by demonic\nrefinement with composition cannot be axiomatised by any finite set of\nfirst-order $(\\leq, \\circ)$ formulas. We provide a fairly simple, infinite,\nrecursive axiomatisation that defines $R(\\sqsubseteq, ;)$. We prove that a\nfinite representable $(\\leq, \\circ)$ structure has a representation over a\nfinite base. This appears to be the first example of a signature for binary\nrelations with composition where the representation class is non-finitely\naxiomatisable, but where the finite representations for finite representable\nstructures property holds.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:26:44 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Hirsch", "Robin", ""], ["\u0160emrl", "Ja\u0161", ""]]}, {"id": "2009.07628", "submitter": "EPTCS", "authors": "Julien Lange (Royal Holloway, University of London), Anastasia\n  Mavridou (KBR/NASA Ames Research Center), Larisa Safina (INRIA), Alceste\n  Scalas (DTU Compute, Technical University of Denmark)", "title": "Proceedings 13th Interaction and Concurrency Experience", "comments": null, "journal-ref": "EPTCS 324, 2020", "doi": "10.4204/EPTCS.324", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of ICE'20, the 13th Interaction and\nConcurrency Experience, which was held online on the 19th of June 2020, as a\nsatellite event of DisCoTec'20. The ICE workshop series features a\ndistinguishing review and selection procedure, allowing PC members to interact\nanonymously with authors. As in the past 12 editions, this interaction\nconsiderably improved the accuracy of the feedback from the reviewers and the\nquality of accepted papers, and offered the basis for lively discussion during\nthe workshop. The 2020 edition of ICE included double blind reviewing of\noriginal research papers, in order to increase fairness and avoid bias in\nreviewing. Each paper was reviewed by three PC members, and altogether 5 papers\nwere accepted for publication - plus 5 oral presentations which are not part of\nthis volume. We were proud to host 2 invited talks, by Cinzia Di Giusto and\nKaroliina Lehtinen. The abstracts of these talks are included in this volume\ntogether with the regular papers. The final versions of the contributions,\ntaking into account the discussion at the workshop, are included.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:25:32 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Lange", "Julien", "", "Royal Holloway, University of London"], ["Mavridou", "Anastasia", "", "KBR/NASA Ames Research Center"], ["Safina", "Larisa", "", "INRIA"], ["Scalas", "Alceste", "", "DTU Compute, Technical University of Denmark"]]}, {"id": "2009.07770", "submitter": "Polly Fahey", "authors": "Isolde Adler and Polly Fahey", "title": "Faster Property Testers in a Variation of the Bounded Degree Model", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Property testing algorithms are highly efficient algorithms, that come with\nprobabilistic accuracy guarantees. For a property P, the goal is to distinguish\ninputs that have P from those that are far from having P with high probability\ncorrectly, by querying only a small number of local parts of the input. In\nproperty testing on graphs, the distance is measured by the number of edge\nmodifications (additions or deletions), that are necessary to transform a graph\ninto one with property P. Much research has focussed on the query complexity of\nsuch algorithms, i. e. the number of queries the algorithm makes to the input,\nbut in view of applications, the running time of the algorithm is equally\nrelevant.\n  In (Adler, Harwath STACS 2018), a natural extension of the bounded degree\ngraph model of property testing to relational databases of bounded degree was\nintroduced, and it was shown that on databases of bounded degree and bounded\ntree-width, every property that is expressible in monadic second-order logic\nwith counting (CMSO) is testable with constant query complexity and sublinear\nrunning time. It remains open whether this can be improved to constant running\ntime.\n  In this paper we introduce a new model, which is based on the bounded degree\nmodel, but the distance measure allows both edge (tuple) modifications and\nvertex (element) modifications. Our main theorem shows that on databases of\nbounded degree and bounded tree-width, every property that is expressible in\nCMSO is testable with constant query complexity and constant running time in\nthe new model. We also show that every property that is testable in the\nclassical model is testable in our model with the same query complexity and\nrunning time, but the converse is not true.\n  We argue that our model is natural and our meta-theorem showing constant-time\nCMSO testability supports this.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:55:44 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Adler", "Isolde", ""], ["Fahey", "Polly", ""]]}, {"id": "2009.07989", "submitter": "EPTCS", "authors": "Zorica Savanovi\\'c (IMT School for Advanced Studies Lucca), Letterio\n  Galletta (IMT School for Advanced Studies Lucca), Hugo Torres Vieira (C4 -\n  University of Beira Interior)", "title": "A type language for message passing component-based systems", "comments": "In Proceedings ICE 2020, arXiv:2009.07628", "journal-ref": "EPTCS 324, 2020, pp. 3-24", "doi": "10.4204/EPTCS.324.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Component-based development is challenging in a distributed setting, for\nstarters considering programming a task may involve the assembly of\nloosely-coupled remote components. In order for the task to be fulfilled, the\nsupporting interaction among components should follow a well-defined protocol.\nIn this paper we address a model for message passing component-based systems\nwhere components are assembled together with the protocol itself. Components\ncan therefore be independent from the protocol, and reactive to messages in a\nflexible way. Our contribution is at the level of the type language that allows\nto capture component behaviour so as to check its compatibility with a\nprotocol. We show the correspondence of component and type behaviours, which\nentails a progress property for components.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:47:31 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Savanovi\u0107", "Zorica", "", "IMT School for Advanced Studies Lucca"], ["Galletta", "Letterio", "", "IMT School for Advanced Studies Lucca"], ["Vieira", "Hugo Torres", "", "C4 -\n  University of Beira Interior"]]}, {"id": "2009.07991", "submitter": "EPTCS", "authors": "Ugo de'Liguoro (Universit\\`a di Torino), Hern\\'an Melgratti\n  (Universidad de Buenos Aires), Emilio Tuosto (Gran Sasso Science Institute)", "title": "Towards Refinable Choreographies", "comments": "In Proceedings ICE 2020, arXiv:2009.07628", "journal-ref": "EPTCS 324, 2020, pp. 61-77", "doi": "10.4204/EPTCS.324.6", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate refinement in the context of choreographies. We introduce\nrefinable global choreographies allowing for the underspecification of\nprotocols, whose interactions can be refined into actual protocols. Arbitrary\nrefinements may spoil well-formedness, that is the sufficient conditions that\nguarantee a protocol to be implementable. We introduce a typing discipline that\nenforces well-formedness of typed choreographies. Then we unveil the relation\namong refinable choregraphies and their admissible refinements in terms of an\naxiom scheme.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:48:28 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["de'Liguoro", "Ugo", "", "Universit\u00e0 di Torino"], ["Melgratti", "Hern\u00e1n", "", "Universidad de Buenos Aires"], ["Tuosto", "Emilio", "", "Gran Sasso Science Institute"]]}, {"id": "2009.09158", "submitter": "EPTCS", "authors": "Francesco Ricca (University of Calabria), Alessandra Russo (Imperial\n  College London), Sergio Greco (University of Calabria), Nicola Leone\n  (University of Calabria), Alexander Artikis (University of Piraeus), Gerhard\n  Friedrich (Universit\\\"at Klagenfurt), Paul Fodor (Stony Brook University),\n  Angelika Kimmig (Cardiff University), Francesca Lisi (University of Bari Aldo\n  Moro), Marco Maratea (University of Genova), Alessandra Mileo (INSIGHT Centre\n  for Data Analytics), Fabrizio Riguzzi (Universit\\`a di Ferrara)", "title": "Proceedings 36th International Conference on Logic Programming\n  (Technical Communications)", "comments": null, "journal-ref": "EPTCS 325, 2020", "doi": "10.4204/EPTCS.325", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the first conference held in Marseille in 1982, ICLP has been the\npremier international event for presenting research in logic programming.\nContributions are solicited in all areas of logic programming and related\nareas, including but not restricted to:\n  - Foundations: Semantics, Formalisms, Answer-Set Programming, Non-monotonic\nReasoning, Knowledge Representation.\n  - Declarative Programming: Inference engines, Analysis, Type and mode\ninference, Partial evaluation, Abstract interpretation, Transformation,\nValidation, Verification, Debugging, Profiling, Testing, Logic-based\ndomain-specific languages, constraint handling rules.\n  - Related Paradigms and Synergies: Inductive and Co-inductive Logic\nProgramming, Constraint Logic Programming, Interaction with SAT, SMT and CSP\nsolvers, Logic programming techniques for type inference and theorem proving,\nArgumentation, Probabilistic Logic Programming, Relations to object-oriented\nand Functional programming, Description logics, Neural-Symbolic Machine\nLearning, Hybrid Deep Learning and Symbolic Reasoning.\n  - Implementation: Concurrency and distribution, Objects, Coordination,\nMobility, Virtual machines, Compilation, Higher Order, Type systems, Modules,\nConstraint handling rules, Meta-programming, Foreign interfaces, User\ninterfaces.\n  - Applications: Databases, Big Data, Data Integration and Federation,\nSoftware Engineering, Natural Language Processing, Web and Semantic Web,\nAgents, Artificial Intelligence, Bioinformatics, Education, Computational life\nsciences, Education, Cybersecurity, and Robotics.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 04:18:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ricca", "Francesco", "", "University of Calabria"], ["Russo", "Alessandra", "", "Imperial\n  College London"], ["Greco", "Sergio", "", "University of Calabria"], ["Leone", "Nicola", "", "University of Calabria"], ["Artikis", "Alexander", "", "University of Piraeus"], ["Friedrich", "Gerhard", "", "Universit\u00e4t Klagenfurt"], ["Fodor", "Paul", "", "Stony Brook University"], ["Kimmig", "Angelika", "", "Cardiff University"], ["Lisi", "Francesca", "", "University of Bari Aldo\n  Moro"], ["Maratea", "Marco", "", "University of Genova"], ["Mileo", "Alessandra", "", "INSIGHT Centre\n  for Data Analytics"], ["Riguzzi", "Fabrizio", "", "Universit\u00e0 di Ferrara"]]}, {"id": "2009.09215", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Faster Smarter Induction in Isabelle/HOL", "comments": "This is the preprint of our paper of the same title, which is\n  accepted to IJCAI2021. For the formal proceeding, please refer to the\n  IJCAI2021 website", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proof by induction plays a critical role in formal verification and\nmathematics at large. However, its automation remains as one of the\nlong-standing challenges in Computer Science. To address this problem, we\ndeveloped sem_ind. Given inductive problem, sem_ind recommends what arguments\nto pass to the induct method. To improve the accuracy of sem_ind, we introduced\ndefinitional quantifiers, a new kind of quantifiers that allow us to\ninvestigate not only the syntactic structures of inductive problems but also\nthe definitions of relevant constants in a domain-agnostic style. Our\nevaluation shows that compared to its predecessor sem_ind improves the accuracy\nof recommendation from 20.1% to 38.2% for the most promising candidates within\n5.0 seconds of timeout while decreasing the median value of execution time from\n2.79 seconds to 1.06 seconds.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 11:51:54 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 09:05:41 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 09:41:12 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 07:58:26 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2009.09360", "submitter": "EPTCS", "authors": "Jean-Francois Raskin (Universit\\'e Libre de Bruxelles), Davide\n  Bresolin (Universit\\`a di Padova)", "title": "Proceedings 11th International Symposium on Games, Automata, Logics, and\n  Formal Verification", "comments": null, "journal-ref": "EPTCS 326, 2020", "doi": "10.4204/EPTCS.326", "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the 11th International Symposium on\nGames, Automata, Logic and Formal Verification (GandALF 2020). The symposium\ntook place as a fully online event on September 21-22, 2020. The GandALF\nsymposium was established by a group of Italian computer scientists interested\nin mathematical logic, automata theory, game theory, and their applications to\nthe specification, design, and verification of complex systems. Its aim is to\nprovide a forum where people from different areas, and possibly with different\nbackgrounds, can fruitfully interact. GandALF has a truly international spirit,\nas witnessed by the composition of the program and steering committee and by\nthe country distribution of the submitted papers.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 06:06:52 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Raskin", "Jean-Francois", "", "Universit\u00e9 Libre de Bruxelles"], ["Bresolin", "Davide", "", "Universit\u00e0 di Padova"]]}, {"id": "2009.09541", "submitter": "Jeremy Avigad", "authors": "Jeremy Avigad", "title": "Foundations", "comments": "For the forthcoming Handbook of Proof Assistants and Their\n  Applications in Mathematics and Computer Science, edited by Jasmin Blanchette\n  and Assia Mahboubi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a draft of a chapter on mathematical logic and foundations for an\nupcoming handbook of computational proof assistants.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 22:54:22 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 00:50:19 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 14:43:50 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Avigad", "Jeremy", ""]]}, {"id": "2009.09797", "submitter": "Khalil Ghorbal", "authors": "Khalil Ghorbal and Andrew Sogokon", "title": "Characterizing Positively Invariant Sets: Inductive and Topological\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two characterizations of positive invariance of sets under the\nflow of systems of ordinary differential equations. The first characterization\nuses inward sets which intuitively collect those points from which the flow\nevolves within the set for a short period of time, whereas the second\ncharacterization uses the notion of exit sets, which intuitively collect those\npoints from which the flow immediately leaves the set. Our proofs emphasize the\nuse of the real induction principle as a generic and unifying proof technique\nthat captures the essence of the formal reasoning justifying our results and\nprovides cleaner alternative proofs of known results. The two characterizations\npresented in this article, while essentially equivalent, lead to two rather\ndifferent decision procedures (termed respectively LZZ and ESE) for checking\nwhether a given semi-algebraic set is positively invariant under the flow of a\nsystem of polynomial ordinary differential equations. The procedure LZZ\nimproves upon the original work by Liu, Zhan and Zhao (EMSOFT 2011). The\nprocedure ESE, introduced in this article, works by splitting the problem, in a\nprincipled way, into simpler sub-problems that are easier to check, and is\nshown to exhibit substantially better performance compared to LZZ on problems\nfeaturing semi-algebraic sets described by formulas with non-trivial Boolean\nstructure.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 09:02:20 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 10:29:12 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ghorbal", "Khalil", ""], ["Sogokon", "Andrew", ""]]}, {"id": "2009.09801", "submitter": "Michael Thomazo", "authors": "Meghyn Bienvenu (UB, CNRS, Bordeaux INP, LaBRI), Quentin Mani\\`ere\n  (UB, CNRS, Bordeaux INP, LaBRI), Micha\\\"el Thomazo (VALDA )", "title": "Answering Counting Queries over DL-Lite Ontologies", "comments": null, "journal-ref": "Twenty-Ninth International Joint Conference on Artificial\n  Intelligence (IJCAI 2020), 2020, Yokohama, Japan", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-mediated query answering (OMQA) is a promising approach to data\naccess and integration that has been actively studied in the knowledge\nrepresentation and database communities for more than a decade. The vast\nmajority of work on OMQA focuses on conjunctive queries, whereas more\nexpressive queries that feature counting or other forms of aggregation remain\nlargely unex-plored. In this paper, we introduce a general form of counting\nquery, relate it to previous proposals, and study the complexity of answering\nsuch queries in the presence of DL-Lite ontologies. As it follows from existing\nwork that query answering is intractable and often of high complexity, we\nconsider some practically relevant restrictions, for which we establish\nimproved complexity bounds.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 11:10:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bienvenu", "Meghyn", "", "UB, CNRS, Bordeaux INP, LaBRI"], ["Mani\u00e8re", "Quentin", "", "UB, CNRS, Bordeaux INP, LaBRI"], ["Thomazo", "Micha\u00ebl", "", "VALDA"]]}, {"id": "2009.09802", "submitter": "Edward Haeusler", "authors": "Edward Hermann Haeusler", "title": "On the Intrinsic Redundancy in Huge Natural Deduction proofs II:\n  Analysing $M_{\\imply}$ Super-Polynomial Proofs", "comments": "Second version only changes the format of the paper; it was correct a\n  small typo in figure 5 and replaced l by \\lambda in an index in the proof of\n  theorem 12. arXiv admin note: text overlap with arXiv:2004.10659", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article precisely defines huge proofs within the system of Natural\nDeduction for the Minimal implicational propositional logic \\mil. This is what\nwe call an unlimited family of super-polynomial proofs. We consider huge\nfamilies of expanded normal form mapped proofs, a device to explicitly help to\ncount the E-parts of a normal proof in an adequate way. Thus, we show that for\nalmost all members of a super-polynomial family there at least one sub-proof or\nderivation of each of them that is repeated super-polynomially many times. This\nlast property we call super-polynomial redundancy. Almost all, precisely means\nthat there is a size of the conclusion of proofs that every proof with\nconclusion bigger than this size and that is huge is highly redundant too. This\nresult points out to a refinement of compression methods previously presented\nand an alternative and simpler proof that CoNP=NP.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 16:49:40 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 20:29:41 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Haeusler", "Edward Hermann", ""]]}, {"id": "2009.09806", "submitter": "Paolo Pareti Dr.", "authors": "Paolo Pareti and George Konstantinidis and Fabio Mogavero and Timothy\n  J. Norman", "title": "SHACL Satisfiability and Containment (Extended Paper)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shapes Constraint Language (SHACL) is a recent W3C recommendation\nlanguage for validating RDF data. Specifically, SHACL documents are collections\nof constraints that enforce particular shapes on an RDF graph. Previous work on\nthe topic has provided theoretical and practical results for the validation\nproblem, but did not consider the standard decision problems of satisfiability\nand containment, which are crucial for verifying the feasibility of the\nconstraints and important for design and optimization purposes. In this paper,\nwe undertake a thorough study of different features of non-recursive SHACL by\nproviding a translation to a new first-order language, called SCL, that\nprecisely captures the semantics of SHACL w.r.t. satisfiability and\ncontainment. We study the interaction of SHACL features in this logic and\nprovide the detailed map of decidability and complexity results of the\naforementioned decision problems for different SHACL sublanguages. Notably, we\nprove that both problems are undecidable for the full language, but we present\ndecidable combinations of interesting features.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:52:03 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 10:55:19 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pareti", "Paolo", ""], ["Konstantinidis", "George", ""], ["Mogavero", "Fabio", ""], ["Norman", "Timothy J.", ""]]}, {"id": "2009.09848", "submitter": "EPTCS", "authors": "Spencer Breiner (NIST), Blake Pollard (NIST), Eswaran Subrahmanian\n  (CMU), Olivier Marie-Rose (Prometheus Computing)", "title": "Modeling Hierarchical System with Operads", "comments": "In Proceedings ACT 2019, arXiv:2009.06334", "journal-ref": "EPTCS 323, 2020, pp. 72-83", "doi": "10.4204/EPTCS.323.5", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies operads and functorial semantics to address the problem of\nfailure diagnosis in complex systems. We start with a concrete example,\ndeveloping a hierarchical interaction model for the Length Scale\nInterferometer, a high-precision measurement system operated by the US National\nInstitute of Standards and Technology. The model is expressed in terms of\ncombinatorial/diagrammatic structures called port-graphs, and we explain how to\nextract an operad LSI from a collection of these diagrams. Next we show how\nfunctors to the operad of probabilities organize and constrain the relative\nprobabilities of component failure in the system. Finally, we show how to\nextend the analysis from general component failure to specific failure modes.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:14:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Breiner", "Spencer", "", "NIST"], ["Pollard", "Blake", "", "NIST"], ["Subrahmanian", "Eswaran", "", "CMU"], ["Marie-Rose", "Olivier", "", "Prometheus Computing"]]}, {"id": "2009.09943", "submitter": "Brandon Paulsen", "authors": "Brandon Paulsen, Jingbo Wang, Jiawei Wang, Chao Wang", "title": "NeuroDiff: Scalable Differential Verification of Neural Networks using\n  Fine-Grained Approximation", "comments": "Published as a conference paper at ASE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks make their way into safety-critical systems, where\nmisbehavior can lead to catastrophes, there is a growing interest in certifying\nthe equivalence of two structurally similar neural networks. For example,\ncompression techniques are often used in practice for deploying trained neural\nnetworks on computationally- and energy-constrained devices, which raises the\nquestion of how faithfully the compressed network mimics the original network.\nUnfortunately, existing methods either focus on verifying a single network or\nrely on loose approximations to prove the equivalence of two networks. Due to\noverly conservative approximation, differential verification lacks scalability\nin terms of both accuracy and computational cost. To overcome these problems,\nwe propose NeuroDiff, a symbolic and fine-grained approximation technique that\ndrastically increases the accuracy of differential verification while achieving\nmany orders-of-magnitude speedup. NeuroDiff has two key contributions. The\nfirst one is new convex approximations that more accurately bound the\ndifference neurons of two networks under all possible inputs. The second one is\njudicious use of symbolic variables to represent neurons whose difference\nbounds have accumulated significant error. We also find that these two\ntechniques are complementary, i.e., when combined, the benefit is greater than\nthe sum of their individual benefits. We have evaluated NeuroDiff on a variety\nof differential verification tasks. Our results show that NeuroDiff is up to\n1000X faster and 5X more accurate than the state-of-the-art tool.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:00:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Paulsen", "Brandon", ""], ["Wang", "Jingbo", ""], ["Wang", "Jiawei", ""], ["Wang", "Chao", ""]]}, {"id": "2009.10207", "submitter": "Adithya Murali", "authors": "Adithya Murali, Lucas Pe\\~na, Christof L\\\"oding, P. Madhusudan", "title": "Synthesizing Lemmas for Inductive Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursively defined structures and properties about them are naturally\nexpressed in first-order logic with least fixpoint definitions (FO+lfp), but\nautomated reasoning for such logics has not seen much progress. Such logics,\nunlike pure FOL, do not even admit complete procedures, let alone decidable\nones. In this paper, we undertake a foundational study of finding proofs that\nuse induction to reason with these logics. By treating proofs as purely FO\nproofs punctuated by declarations of induction lemmas, we separate proofs into\ndeductively reasoned components that can be automated and statements of lemmas\nthat need to be divined, respectively. While humans divine such lemmas with\nintuition, we propose a counterexample driven technique that guides the\nsynthesis of such lemmas, where counterexamples are finite models that witness\ninability of proving the theorem as well as other proposed lemmas. We develop\nrelatively complete procedures for synthesizing such lemmas using techniques\nand tools from program/expression synthesis, for powerful FO+lfp logics that\nhave background sorts constrained by natural theories such as arithmetic and\nset theory. We evaluate our procedures and show that over a class of theorems\nthat require finding inductive proofs, our automatic synthesis procedure is\neffective in proving them.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 22:36:31 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Murali", "Adithya", ""], ["Pe\u00f1a", "Lucas", ""], ["L\u00f6ding", "Christof", ""], ["Madhusudan", "P.", ""]]}, {"id": "2009.10237", "submitter": "EPTCS", "authors": "Esra Erdem (Sabanci University), Andreas Herzig (Institut de Recherche\n  en Informatique de Toulouse)", "title": "Solving Gossip Problems using Answer Set Programming: An Epistemic\n  Planning Approach", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 52-58", "doi": "10.4204/EPTCS.325.11", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of Answer Set Programming to solve variations of\ngossip problems, by modeling them as epistemic planning problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:47:55 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Erdem", "Esra", "", "Sabanci University"], ["Herzig", "Andreas", "", "Institut de Recherche\n  en Informatique de Toulouse"]]}, {"id": "2009.10238", "submitter": "EPTCS", "authors": "Joaqu\\'in Arias, Manuel Carro, Zhuo Chen, Gopal Gupta", "title": "Justifications for Goal-Directed Constraint Answer Set Programming", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 59-72", "doi": "10.4204/EPTCS.325.12", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethical and legal concerns make it necessary for programs that may directly\ninfluence the life of people (via, e.g., legal or health counseling) to justify\nin human-understandable terms the advice given. Answer Set Programming has a\nrich semantics that makes it possible to very concisely express complex\nknowledge. However, justifying why an answer is a consequence from an ASP\nprogram may be non-trivial -- even more so when the user is an expert in a\ngiven domain, but not necessarily knowledgeable in ASP. Most ASP systems\ngenerate answers using SAT-solving procedures on ground rules that do not match\nhow humans perceive reasoning. We propose using s(CASP), a query-driven,\ntop-down execution model for predicate ASP with constraints to generate\njustification trees of (constrained) answer sets. The operational semantics of\ns(CASP) relies on backward chaining, which is intuitive to follow and lends\nitself to generating explanations that are easier to translate into natural\nlanguage. We show how s(CASP) provides minimal justifications for, among\nothers, relevant examples proposed in the literature, both as search trees but,\nmore importantly, as explanations in natural language. We validate our design\nwith real ASP applications and evaluate the cost of generating s(CASP)\njustification trees.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:48:05 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Arias", "Joaqu\u00edn", ""], ["Carro", "Manuel", ""], ["Chen", "Zhuo", ""], ["Gupta", "Gopal", ""]]}, {"id": "2009.10239", "submitter": "EPTCS", "authors": "Kinjal Basu, Sarat Chandra Varanasi, Farhad Shakerin, Gopal Gupta", "title": "SQuARE: Semantics-based Question Answering and Reasoning Engine", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 73-86", "doi": "10.4204/EPTCS.325.13", "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the meaning of a text is a fundamental challenge of natural\nlanguage understanding (NLU) and from its early days, it has received\nsignificant attention through question answering (QA) tasks. We introduce a\ngeneral semantics-based framework for natural language QA and also describe the\nSQuARE system, an application of this framework. The framework is based on the\ndenotational semantics approach widely used in programming language research.\nIn our framework, valuation function maps syntax tree of the text to its\ncommonsense meaning represented using basic knowledge primitives (the semantic\nalgebra) coded using answer set programming (ASP). We illustrate an application\nof this framework by using VerbNet primitives as our semantic algebra and a\nnovel algorithm based on partial tree matching that generates an answer set\nprogram that represents the knowledge in the text. A question posed against\nthat text is converted into an ASP query using the same framework and executed\nusing the s(CASP) goal-directed ASP system. Our approach is based purely on\n(commonsense) reasoning. SQuARE achieves 100% accuracy on all the five datasets\nof bAbI QA tasks that we have tested. The significance of our work is that,\nunlike other machine learning based approaches, ours is based on\n\"understanding\" the text and does not require any training. SQuARE can also\ngenerate an explanation for an answer while maintaining high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:48:18 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Basu", "Kinjal", ""], ["Varanasi", "Sarat Chandra", ""], ["Shakerin", "Farhad", ""], ["Gupta", "Gopal", ""]]}, {"id": "2009.10240", "submitter": "EPTCS", "authors": "Michael Dingess (University of Kentucky), Miroslaw Truszczynski\n  (University of Kentucky)", "title": "Automated Aggregator -- Rewriting with the Counting Aggregate", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 96-109", "doi": "10.4204/EPTCS.325.17", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming is a leading declarative constraint programming\nparadigm with wide use for complex knowledge-intensive applications. Modern\nanswer set programming languages support many equivalent ways to model\nconstraints and specifications in a program. However, so far answer set\nprogramming has failed to develop systematic methodologies for building\nrepresentations that would uniformly lend well to automated processing. This\nsuggests that encoding selection, in the same way as algorithm selection and\nportfolio solving, may be a viable direction for improving performance of\nanswer-set solving. The necessary precondition is automating the process of\ngenerating possible alternative encodings. Here we present an automated\nrewriting system, the Automated Aggregator or AAgg, that given a non-ground\nlogic program, produces a family of equivalent programs with complementary\nperformance when run under modern answer set programming solvers. We\ndemonstrate this behavior through experimental analysis and propose the\nsystem's use in automated answer set programming solver selection tools.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:48:33 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Dingess", "Michael", "", "University of Kentucky"], ["Truszczynski", "Miroslaw", "", "University of Kentucky"]]}, {"id": "2009.10241", "submitter": "EPTCS", "authors": "Paul Tarau (University of North Texas), Valeria de Paiva (Topos\n  Institute)", "title": "Deriving Theorems in Implicational Linear Logic, Declaratively", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 110-123", "doi": "10.4204/EPTCS.325.18", "report-no": null, "categories": "cs.LO cs.AI cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem we want to solve is how to generate all theorems of a given size\nin the implicational fragment of propositional intuitionistic linear logic. We\nstart by filtering for linearity the proof terms associated by our Prolog-based\ntheorem prover for Implicational Intuitionistic Logic. This works, but using\nfor each formula a PSPACE-complete algorithm limits it to very small formulas.\nWe take a few walks back and forth over the bridge between proof terms and\ntheorems, provided by the Curry-Howard isomorphism, and derive step-by-step an\nefficient algorithm requiring a low polynomial effort per generated theorem.\nThe resulting Prolog program runs in O(N) space for terms of size N and\ngenerates in a few hours 7,566,084,686 theorems in the implicational fragment\nof Linear Intuitionistic Logic together with their proof terms in normal form.\nAs applications, we generate datasets for correctness and scalability testing\nof linear logic theorem provers and training data for neural networks working\non theorem proving challenges. The results in the paper, organized as a\nliterate Prolog program, are fully replicable.\n  Keywords: combinatorial generation of provable formulas of a given size,\nintuitionistic and linear logic theorem provers, theorems of the implicational\nfragment of propositional linear intuitionistic logic, Curry-Howard\nisomorphism, efficient generation of linear lambda terms in normal form, Prolog\nprograms for lambda term generation and theorem proving.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:48:45 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Tarau", "Paul", "", "University of North Texas"], ["de Paiva", "Valeria", "", "Topos\n  Institute"]]}, {"id": "2009.10243", "submitter": "EPTCS", "authors": "Ridhwan Dewoprabowo, Ari Saptawijaya", "title": "Tabling Optimization for Contextual Abduction", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 137-150", "doi": "10.4204/EPTCS.325.20", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabling for contextual abduction in logic programming has been introduced as\na means to store previously obtained abductive solutions in one context to be\nreused in another context. This paper identifies a number of issues in the\nexisting implementations of tabling in contextual abduction and aims to\nmitigate the issues. We propose a new program transformation for integrity\nconstraints to deal with their proper application for filtering solutions while\nalso reducing the table memory usage. We further optimize the table memory\nusage by selectively picking predicates to table and by pragmatically\nsimplifying the representation of the problem. The evaluation of our proposed\napproach, on both artificial and real world problems, shows that they improve\nthe scalability of tabled abduction compared to previous implementations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:49:10 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Dewoprabowo", "Ridhwan", ""], ["Saptawijaya", "Ari", ""]]}, {"id": "2009.10244", "submitter": "EPTCS", "authors": "Roberta Calegari (CIRSFID - Alma AI, University of Bologna, Italy),\n  Giovanni Sartor (CIRSFID - Alma AI, University of Bologna, Italy)", "title": "Burden of Persuasion in Argumentation", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 151-163", "doi": "10.4204/EPTCS.325.21", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a formal model for the burden of persuasion in dialogues,\nand in particular, in legal proceedings. The model shows how an allocation of\nthe burden of persuasion may induce single outcomes in dialectical contexts in\nwhich, without such an allocation, the status of conflicting arguments would\nremain undecided. Our approach is based on a two-stage labelling. The\nfirst-stage labelling determines what arguments are accepted, rejected or\nundecided, regardless of the allocation of burden. The second-stage labelling\nrevises the dialectical status of first-stage undecided arguments, according to\nburdens of persuasion. The labelling is finally extended in such a way as to\nobtain a complete labelling. Our model combines two ideas that have emerged in\nthe debate on the burden of persuasion: the idea that the burden of persuasion\ndetermines the solution of conflicts between arguments, and the idea that its\nsatisfaction depends on the dialectical status of the arguments concerned. Our\napproach also addresses inversions of the burden of persuasion, namely, cases\nin which the burden of persuasion over an argument does not extend to its\nsubarguments.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:49:25 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Calegari", "Roberta", "", "CIRSFID - Alma AI, University of Bologna, Italy"], ["Sartor", "Giovanni", "", "CIRSFID - Alma AI, University of Bologna, Italy"]]}, {"id": "2009.10246", "submitter": "EPTCS", "authors": "Tobias Geibinger, Hans Tompits", "title": "Sequent-Type Calculi for Systems of Nonmonotonic Paraconsistent Logics", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 178-191", "doi": "10.4204/EPTCS.325.23", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraconsistent logics constitute an important class of formalisms dealing\nwith non-trivial reasoning from inconsistent premisses. In this paper, we\nintroduce uniform axiomatisations for a family of nonmonotonic paraconsistent\nlogics based on minimal inconsistency in terms of sequent-type proof systems.\nThe latter are prominent and widely-used forms of calculi well-suited for\nanalysing proof search. In particular, we provide sequent-type calculi for\nPriest's three-valued minimally inconsistent logic of paradox, and for\nfour-valued paraconsistent inference relations due to Arieli and Avron. Our\ncalculi follow the sequent method first introduced in the context of\nnonmonotonic reasoning by Bonatti and Olivetti, whose distinguishing feature is\nthe use of a so-called rejection calculus for axiomatising invalid formulas. In\nfact, we present a general method to obtain sequent systems for any many-valued\nlogic based on minimal inconsistency, yielding the calculi for the logics of\nPriest and of Arieli and Avron as special instances.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:49:52 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Geibinger", "Tobias", ""], ["Tompits", "Hans", ""]]}, {"id": "2009.10247", "submitter": "EPTCS", "authors": "Tuan Nguyen Quoc (National Institute of Informatics), Katsumi Inoue\n  (National Institute of Informatics), Chiaki Sakama (Wakayama University)", "title": "Enhancing Linear Algebraic Computation of Logic Programs Using Sparse\n  Representation", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 192-205", "doi": "10.4204/EPTCS.325.24", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic characterization of logic programs has received increasing\nattention in recent years. Researchers attempt to exploit connections between\nlinear algebraic computation and symbolic computation in order to perform\nlogical inference in large scale knowledge bases. This paper proposes further\nimprovement by using sparse matrices to embed logic programs in vector spaces.\nWe show its great power of computation in reaching the fixpoint of the\nimmediate consequence operator from the initial vector. In particular,\nperformance for computing the least models of definite programs is dramatically\nimproved in this way. We also apply the method to the computation of stable\nmodels of normal programs, in which the guesses are associated with initial\nmatrices, and verify its effect when there are small numbers of negation. These\nresults show good enhancement in terms of performance for computing\nconsequences of programs and depict the potential power of tensorized logic\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:50:05 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Quoc", "Tuan Nguyen", "", "National Institute of Informatics"], ["Inoue", "Katsumi", "", "National Institute of Informatics"], ["Sakama", "Chiaki", "", "Wakayama University"]]}, {"id": "2009.10248", "submitter": "EPTCS", "authors": "Wolf De Wulf (Vrije Universiteit Brussel), Bart Bogaerts (Vrije\n  Universiteit Brussel)", "title": "LP2PB: Translating Answer Set Programs into Pseudo-Boolean Theories", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 206-219", "doi": "10.4204/EPTCS.325.25", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming (ASP) is a well-established knowledge representation\nformalism. Most ASP solvers are based on (extensions of) technology from\nBoolean satisfiability solving. While these solvers have shown to be very\nsuccessful in many practical applications, their strength is limited by their\nunderlying proof system, resolution. In this paper, we present a new tool LP2PB\nthat translates ASP programs into pseudo-Boolean theories, for which solvers\nbased on the (stronger) cutting plane proof system exist. We evaluate our tool,\nand the potential of cutting-plane-based solving for ASP on traditional ASP\nbenchmarks as well as benchmarks from pseudo-Boolean solving. Our results are\nmixed: overall, traditional ASP solvers still outperform our translational\napproach, but several benchmark families are identified where the balance\nshifts the other way, thereby suggesting that further investigation into a\nstronger proof system for ASP is valuable.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:50:17 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["De Wulf", "Wolf", "", "Vrije Universiteit Brussel"], ["Bogaerts", "Bart", "", "Vrije\n  Universiteit Brussel"]]}, {"id": "2009.10249", "submitter": "EPTCS", "authors": "Basem Atiq (Sabanci University), Volkan Patoglu (Sabanci University),\n  Esra Erdem (Sabanci University)", "title": "Dynamic Multi-Agent Path Finding based on Conflict Resolution using\n  Answer Set Programming", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 223-229", "doi": "10.4204/EPTCS.325.27", "report-no": null, "categories": "cs.AI cs.LO cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a dynamic version of multi-agent path finding problem (called\nD-MAPF) where existing agents may leave and new agents may join the team at\ndifferent times. We introduce a new method to solve D-MAPF based on\nconflict-resolution. The idea is, when a set of new agents joins the team and\nthere are conflicts, instead of replanning for the whole team, to replan only\nfor a minimal subset of agents whose plans conflict with each other. We utilize\nanswer set programming as part of our method for planning, replanning and\nidentifying minimal set of conflicts.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:50:35 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Atiq", "Basem", "", "Sabanci University"], ["Patoglu", "Volkan", "", "Sabanci University"], ["Erdem", "Esra", "", "Sabanci University"]]}, {"id": "2009.10250", "submitter": "EPTCS", "authors": "Stefania Costantini (University of L'Aquila, Italy), Lorenzo De\n  Lauretis (University of L'Aquila, Italy)", "title": "An application of Answer Set Programming in Distributed Architectures:\n  ASP Microservices", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 230-243", "doi": "10.4204/EPTCS.325.28", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to the definition of microservices with an Answer Set\nProgramming (ASP) `core', where microservices are a successful abstraction for\ndesigning distributed applications as suites of independently deployable\ninteracting components. Such ASP-based components might be employed in\ndistributed architectures related to Cloud Computing or to the Internet of\nThings (IoT).\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:50:46 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Costantini", "Stefania", "", "University of L'Aquila, Italy"], ["De Lauretis", "Lorenzo", "", "University of L'Aquila, Italy"]]}, {"id": "2009.10251", "submitter": "EPTCS", "authors": "Yuri Gil Dantas (fortiss GmbH), Antoaneta Kondeva (fortiss GmbH),\n  Vivek Nigam (fortiss GmbH)", "title": "Less Manual Work for Safety Engineers: Towards an Automated Safety\n  Reasoning with Safety Patterns", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 244-257", "doi": "10.4204/EPTCS.325.29", "report-no": null, "categories": "eess.SY cs.CR cs.FL cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of safety-critical systems requires the control of hazards\nthat can potentially cause harm. To this end, safety engineers rely during the\ndevelopment phase on architectural solutions, called safety patterns, such as\nsafety monitors, voters, and watchdogs. The goal of these patterns is to\ncontrol (identified) faults that can trigger hazards. Safety patterns can\ncontrol such faults by e.g., increasing the redundancy of the system.\nCurrently, the reasoning of which pattern to use at which part of the target\nsystem to control which hazard is documented mostly in textual form or by means\nof models, such as GSN-models, with limited support for automation. This paper\nproposes the use of logic programming engines for the automated reasoning about\nsystem safety. We propose a domain-specific language for embedded system safety\nand specify as disjunctive logic programs reasoning principles used by safety\nengineers to deploy safety patterns, e.g., when to use safety monitors, or\nwatchdogs. Our machinery enables two types of automated safety reasoning: (1)\nidentification of which hazards can be controlled and which ones cannot be\ncontrolled by the existing safety patterns; and (2) automated recommendation of\nwhich patterns could be used at which place of the system to control potential\nhazards. Finally, we apply our machinery to two examples taken from the\nautomotive domain: an adaptive cruise control system and a battery management\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:50:58 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Dantas", "Yuri Gil", "", "fortiss GmbH"], ["Kondeva", "Antoaneta", "", "fortiss GmbH"], ["Nigam", "Vivek", "", "fortiss GmbH"]]}, {"id": "2009.10252", "submitter": "EPTCS", "authors": "Elena Mastria (Department of Mathematics and Computer Science,\n  University of Calabria, Italy), Jessica Zangari (Department of Mathematics\n  and Computer Science, University of Calabria, Italy), Simona Perri\n  (Department of Mathematics and Computer Science, University of Calabria,\n  Italy), Francesco Calimeri (Department of Mathematics and Computer Science,\n  University of Calabria, Italy)", "title": "A Machine Learning guided Rewriting Approach for ASP Logic Programs", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 261-267", "doi": "10.4204/EPTCS.325.31", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a declarative logic formalism that allows to\nencode computational problems via logic programs. Despite the declarative\nnature of the formalism, some advanced expertise is required, in general, for\ndesigning an ASP encoding that can be efficiently evaluated by an actual ASP\nsystem. A common way for trying to reduce the burden of manually tweaking an\nASP program consists in automatically rewriting the input encoding according to\nsuitable techniques, for producing alternative, yet semantically equivalent,\nASP programs. However, rewriting does not always grant benefits in terms of\nperformance; hence, proper means are needed for predicting their effects with\nthis respect. In this paper we describe an approach based on Machine Learning\n(ML) to automatically decide whether to rewrite. In particular, given an ASP\nprogram and a set of input facts, our approach chooses whether and how to\nrewrite input rules based on a set of features measuring their structural\nproperties and domain information. To this end, a Multilayer Perceptrons model\nhas then been trained to guide the ASP grounder I-DLV on rewriting input rules.\nWe report and discuss the results of an experimental evaluation over a\nprototypical implementation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:51:13 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mastria", "Elena", "", "Department of Mathematics and Computer Science,\n  University of Calabria, Italy"], ["Zangari", "Jessica", "", "Department of Mathematics\n  and Computer Science, University of Calabria, Italy"], ["Perri", "Simona", "", "Department of Mathematics and Computer Science, University of Calabria,\n  Italy"], ["Calimeri", "Francesco", "", "Department of Mathematics and Computer Science,\n  University of Calabria, Italy"]]}, {"id": "2009.10552", "submitter": "Yuri Gurevich", "authors": "Andreas Blass and Yuri Gurevich", "title": "Negative probabilities: What they are and what they are for", "comments": "This article supersedes arXiv:1502.00666 and arXiv:1807.10382", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO math-ph math.MP math.PR math.QA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantum mechanics, the probability distributions of position and momentum\nof a particle are normally not the marginals of a joint distribution, that is\nunless -- as shown by Wigner in 1932 -- negative probabilities are allowed.\nSince then, much theoretical work has been done to study negative\nprobabilities; most of this work is about what those probabilities are. We\nsuggest shifting the emphasis to what negative probabilities are for. In this\nconnection, we introduce the framework of observation spaces. An observation\nspace is a family $\\mathcal S = \\big\\langle\\mathcal P_i: i\\in I\\big\\rangle$ of\nprobability distributions sharing a common sample space in a consistent way; a\ngrounding for $\\mathcal S$ is a signed probability distribution $\\mathcal P$\nsuch that every $\\mathcal P_i$ is a restriction of $\\mathcal P$; and the\ngrounding problem for $\\mathcal S$ is the problem of describing the groundings\nfor $\\mathcal S$. We show that a wide variety of quantum scenarios can be\nformalized as observation spaces, and we solve the grounding problem for a\nnumber of quantum observation spaces. Our main technical result is a rigorous\nproof that Wigner's distribution is the unique signed probability distribution\nyielding the correct marginal distributions for position and momentum and all\ntheir linear combinations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 13:45:21 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Blass", "Andreas", ""], ["Gurevich", "Yuri", ""]]}, {"id": "2009.10574", "submitter": "Steffen van Bergerem", "authors": "Steffen van Bergerem, Nicole Schweikardt", "title": "Learning Concepts Described by Weight Aggregation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider weighted structures, which extend ordinary relational structures\nby assigning weights, i.e. elements from a particular group or ring, to tuples\npresent in the structure. We introduce an extension of first-order logic that\nallows to aggregate weights of tuples, compare such aggregates, and use them to\nbuild more complex formulas. We provide locality properties of fragments of\nthis logic including Feferman-Vaught decompositions and a Gaifman normal form\nfor a fragment called FOW1, as well as a localisation theorem for a larger\nfragment called FOWA1. This fragment can express concepts from various machine\nlearning scenarios. Using the locality properties, we show that concepts\ndefinable in FOWA1 over a weighted background structure of at most\npolylogarithmic degree are agnostically PAC-learnable in polylogarithmic time\nafter pseudo-linear time preprocessing.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:32:42 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["van Bergerem", "Steffen", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "2009.10875", "submitter": "EPTCS", "authors": "Lucas M. Tabajara (Rice University), Moshe Y. Vardi (Rice University)", "title": "LTLf Synthesis under Partial Observability: From Theory to Practice", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 1-17", "doi": "10.4204/EPTCS.326.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LTL synthesis is the problem of synthesizing a reactive system from a formal\nspecification in Linear Temporal Logic. The extension of allowing for partial\nobservability, where the system does not have direct access to all relevant\ninformation about the environment, allows generalizing this problem to a wider\nset of real-world applications, but the difficulty of implementing such an\nextension in practice means that it has remained in the realm of theory.\nRecently, it has been demonstrated that restricting LTL synthesis to systems\nwith finite executions by using LTL with finite-horizon semantics (LTLf) allows\nfor significantly simpler implementations in practice. With the conceptual\nsimplicity of LTLf, it becomes possible to explore extensions such as partial\nobservability in practice for the first time. Previous work has analyzed the\nproblem of LTLf synthesis under partial observability theoretically and\nsuggested two possible algorithms, one with 3EXPTIME and another with 2EXPTIME\ncomplexity. In this work, we first prove a complexity lower bound conjectured\nin earlier work. Then, we complement the theoretical analysis by showing how\nthe two algorithms can be integrated in practice into an established framework\nfor LTLf synthesis. We furthermore identify a third, MSO-based, approach\nenabled by this framework. Our experimental evaluation reveals very different\nresults from what the theory seems to suggest, with the 3EXPTIME algorithm\noften outperforming the 2EXPTIME approach. Furthermore, as long as it is able\nto overcome an initial memory bottleneck, the MSO-based approach can often\noutperforms the others.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:23:46 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Tabajara", "Lucas M.", "", "Rice University"], ["Vardi", "Moshe Y.", "", "Rice University"]]}, {"id": "2009.10876", "submitter": "EPTCS", "authors": "Oebele Lijzenga (University of Twente), Tom van Dijk (University of\n  Twente)", "title": "Symbolic Parity Game Solvers that Yield Winning Strategies", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 18-32", "doi": "10.4204/EPTCS.326.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parity games play an important role for LTL synthesis as evidenced by recent\nbreakthroughs on LTL synthesis, which rely in part on parity game solving. Yet\nstate space explosion remains a major issue if we want to scale to larger\nsystems or specifications. In order to combat this problem, we need to\ninvestigate symbolic methods such as BDDs, which have been successful in the\npast to tackle exponentially large systems. It is therefore essential to have\nsymbolic parity game solving algorithms, operating using BDDs, that are fast\nand that can produce the winning strategies used to synthesize the controller\nin LTL synthesis.\n  Current symbolic parity game solving algorithms do not yield winning\nstrategies. We now propose two symbolic algorithms that yield winning\nstrategies, based on two recently proposed fixpoint algorithms. We implement\nthe algorithms and empirically evaluate them using benchmarks obtained from\nSYNTCOMP 2020. Our conclusion is that the algorithms are competitive with or\nfaster than an earlier symbolic implementation of Zielonka's recursive\nalgorithm, while also providing the winning strategies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:24:03 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Lijzenga", "Oebele", "", "University of Twente"], ["van Dijk", "Tom", "", "University of\n  Twente"]]}, {"id": "2009.10877", "submitter": "EPTCS", "authors": "Mara Downing (Harvey Mudd College), Abtin Molavi (Harvey Mudd\n  College), Lucas Bang (Harvey Mudd College)", "title": "Symbolic Execution + Model Counting + Entropy Maximization = Automatic\n  Search Synthesis", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 50-65", "doi": "10.4204/EPTCS.326.4", "report-no": null, "categories": "cs.LO cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method of automatically synthesizing steps to solve search\nproblems. Given a specification of a search problem, our approach uses symbolic\nexecution to analyze the specification in order to extract a set of constraints\nwhich model the problem. These constraints are used in a process called model\ncounting, which is leveraged to compute probability distributions relating\nsearch steps to predicates about an unknown target. The probability\ndistribution functions determine an information gain objective function based\non Shannon entropy, which, when maximized, yields the next optimal step of the\nsearch. We prove that our algorithm converges to a correct solution, and\ndiscuss computational complexity issues. We implemented a domain specific\nlanguage in which to write search problem specifications, enabling our static\nanalysis phase. Our experiments demonstrate the effectiveness of our approach\non a set of search problem case studies inspired by the domains of software\nsecurity, computational geometry, AI for games, and user preference ranking.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:24:40 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Downing", "Mara", "", "Harvey Mudd College"], ["Molavi", "Abtin", "", "Harvey Mudd\n  College"], ["Bang", "Lucas", "", "Harvey Mudd College"]]}, {"id": "2009.10878", "submitter": "EPTCS", "authors": "Can Ba\\c{s}kent (Department of Computer Science, Middlesex University,\n  London)", "title": "A Game Theoretical Semantics for Logics of Nonsense", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 66-81", "doi": "10.4204/EPTCS.326.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logics of non-sense allow a third truth value to express propositions that\nare \\emph{nonsense}. These logics are ideal formalisms to understand how errors\nare handled in programs and how they propagate throughout the programs once\nthey appear. In this paper, we give a Hintikkan game semantics for logics of\nnon-sense and prove its correctness. We also discuss how a known solution\nmethod in game theory, the iterated elimination of strictly dominated\nstrategies, relates to semantic games for logics of nonsense. Finally, we\nextend the logics of nonsense only by means of semantic games, developing a new\nlogic of nonsense, and propose a new game semantics for Priest's Logic of\nParadox.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:24:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Ba\u015fkent", "Can", "", "Department of Computer Science, Middlesex University,\n  London"]]}, {"id": "2009.10880", "submitter": "EPTCS", "authors": "Lauri Hella, Antti Kuusisto, Raine R\\\"onnholm", "title": "Bounded Game-Theoretic Semantics for Modal Mu-Calculus and Some Variants", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360. The official\n  conference version of the extended preprint arXiv:1706.00753", "journal-ref": "EPTCS 326, 2020, pp. 82-96", "doi": "10.4204/EPTCS.326.6", "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new game-theoretic semantics (GTS) for the modal mu-calculus.\nOur so-called bounded GTS replaces parity games with alternative evaluation\ngames where only finite paths arise; infinite paths are not needed even when\nthe considered transition system is infinite. The novel games offer alternative\napproaches to various constructions in the framework of the mu-calculus. For\nexample, they have already been successfully used as a basis for an approach\nleading to a natural formula size game for the logic. While our main focus is\nintroducing the new GTS, we also consider some applications to demonstrate its\nuses. For example, we consider a natural model transformation procedure that\nreduces model checking games to checking a single, fixed formula in the\nconstructed models, and we also use the GTS to identify new alternative\nvariants of the mu-calculus with PTime model checking.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:25:12 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hella", "Lauri", ""], ["Kuusisto", "Antti", ""], ["R\u00f6nnholm", "Raine", ""]]}, {"id": "2009.10881", "submitter": "EPTCS", "authors": "Florian Bruse (University of Kassel), J\\\"org Kreiker (University of\n  Applied Sciences, Fulda), Martin Lange (University of Kassel), Marco S\\\"alzer\n  (University of Kassel)", "title": "Local Higher-Order Fixpoint Iteration", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 97-113", "doi": "10.4204/EPTCS.326.7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local fixpoint iteration describes a technique that restricts fixpoint\niteration in function spaces to needed arguments only. It has been studied well\nfor first-order functions in abstract interpretation and also in model\nchecking. Here we consider the problem for least and greatest fixpoints of\narbitrary type order. We define an abstract algebra of simply typed\nhigher-order functions with fixpoints that can express fixpoint evaluation\nproblems as they occur routinely in various applications, including program\nverification. We present an algorithm that realises local fixpoint iteration\nfor such higher-order fixpoints, prove its correctness and study its\noptimisation potential in the context of several applications.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:25:28 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Bruse", "Florian", "", "University of Kassel"], ["Kreiker", "J\u00f6rg", "", "University of\n  Applied Sciences, Fulda"], ["Lange", "Martin", "", "University of Kassel"], ["S\u00e4lzer", "Marco", "", "University of Kassel"]]}, {"id": "2009.10883", "submitter": "EPTCS", "authors": "Andrew M. Wells (Rice University), Morteza Lahijanian (University of\n  Colorado at Boulder), Lydia E. Kavraki (Rice University), Moshe Y. Vardi\n  (Rice University)", "title": "LTLf Synthesis on Probabilistic Systems", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 166-181", "doi": "10.4204/EPTCS.326.11", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many systems are naturally modeled as Markov Decision Processes (MDPs),\ncombining probabilities and strategic actions. Given a model of a system as an\nMDP and some logical specification of system behavior, the goal of synthesis is\nto find a policy that maximizes the probability of achieving this behavior. A\npopular choice for defining behaviors is Linear Temporal Logic (LTL). Policy\nsynthesis on MDPs for properties specified in LTL has been well studied. LTL,\nhowever, is defined over infinite traces, while many properties of interest are\ninherently finite. Linear Temporal Logic over finite traces (LTLf) has been\nused to express such properties, but no tools exist to solve policy synthesis\nfor MDP behaviors given finite-trace properties. We present two algorithms for\nsolving this synthesis problem: the first via reduction of LTLf to LTL and the\nsecond using native tools for LTLf. We compare the scalability of these two\napproaches for synthesis and show that the native approach offers better\nscalability compared to existing automaton generation tools for LTL.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:26:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Wells", "Andrew M.", "", "Rice University"], ["Lahijanian", "Morteza", "", "University of\n  Colorado at Boulder"], ["Kavraki", "Lydia E.", "", "Rice University"], ["Vardi", "Moshe Y.", "", "Rice University"]]}, {"id": "2009.10886", "submitter": "EPTCS", "authors": "\\'I\\~nigo X. \\'Incer Romeo (University of California, Berkeley),\n  Leonardo Mangeruca (Raytheon Technologies Research Center, Rome, Italy),\n  Tiziano Villa (Universit\\`a di Verona, Italy), Alberto\n  Sangiovanni-Vincentelli (University of California, Berkeley)", "title": "The Quotient in Preorder Theories", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 216-233", "doi": "10.4204/EPTCS.326.14", "report-no": null, "categories": "cs.DM cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seeking the largest solution to an expression of the form A x <= B is a\ncommon task in several domains of engineering and computer science. This\nlargest solution is commonly called quotient. Across domains, the meanings of\nthe binary operation and the preorder are quite different, yet the syntax for\ncomputing the largest solution is remarkably similar. This paper is about\nfinding a common framework to reason about quotients. We only assume we operate\non a preorder endowed with an abstract monotonic multiplication and an\ninvolution. We provide a condition, called admissibility, which guarantees the\nexistence of the quotient, and which yields its closed form. We call preordered\nheaps those structures satisfying the admissibility condition. We show that\nmany existing theories in computer science are preordered heaps, and we are\nthus able to derive a quotient for them, subsuming existing solutions when\navailable in the literature. We introduce the concept of sieved heaps to deal\nwith structures which are given over multiple domains of definition. We show\nthat sieved heaps also have well-defined quotients.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:27:38 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Romeo", "\u00cd\u00f1igo X. \u00cdncer", "", "University of California, Berkeley"], ["Mangeruca", "Leonardo", "", "Raytheon Technologies Research Center, Rome, Italy"], ["Villa", "Tiziano", "", "Universit\u00e0 di Verona, Italy"], ["Sangiovanni-Vincentelli", "Alberto", "", "University of California, Berkeley"]]}, {"id": "2009.11011", "submitter": "Uli Fahrenberg", "authors": "Uli Fahrenberg, Axel Legay", "title": "Behavioral Specification Theories: an Algebraic Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a taxonomy of different behavioral specification theories and\nexpose their algebraic properties. We start by clarifying what precisely\nconstitutes a behavioral specification theory and then introduce logical and\nstructural operations and develop the resulting algebraic properties. In order\nto motivate our developments, we give plenty of examples of behavioral\nspecification theories with different operations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 09:16:32 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Fahrenberg", "Uli", ""], ["Legay", "Axel", ""]]}, {"id": "2009.11070", "submitter": "EPTCS", "authors": "Dami\\'an Aparicio-S\\'anchez (VRAIN (Valencian Research Institute for\n  Artificial Intelligence), Universitat Polit\\`ecnica de Val\\`encia), Santiago\n  Escobar (VRAIN (Valencian Research Institute for Artificial Intelligence),\n  Universitat Polit\\`ecnica de Val\\`encia), Julia Sapi\\~na (VRAIN (Valencian\n  Research Institute for Artificial Intelligence), Universitat Polit\\`ecnica de\n  Val\\`encia)", "title": "Variant-based Equational Unification under Constructor Symbols", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158. arXiv admin note:\n  substantial text overlap with arXiv:1909.08241", "journal-ref": "EPTCS 325, 2020, pp. 38-51", "doi": "10.4204/EPTCS.325.10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equational unification of two terms consists of finding a substitution that,\nwhen applied to both terms, makes them equal modulo some equational properties.\nA narrowing-based equational unification algorithm relying on the concept of\nthe variants of a term is available in the most recent version of Maude,\nversion 3.0, which provides quite sophisticated unification features. A variant\nof a term t is a pair consisting of a substitution sigma and the canonical form\nof tsigma. Variant-based unification is decidable when the equational theory\nsatisfies the finite variant property. However, this unification procedure does\nnot take into account constructor symbols and, thus, may compute many more\nunifiers than the necessary or may not be able to stop immediately. In this\npaper, we integrate the notion of constructor symbol into the variant-based\nunification algorithm. Our experiments on positive and negative unification\nproblems show an impressive speedup.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:47:42 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Aparicio-S\u00e1nchez", "Dami\u00e1n", "", "VRAIN"], ["Escobar", "Santiago", "", "VRAIN"], ["Sapi\u00f1a", "Julia", "", "VRAIN"]]}, {"id": "2009.11186", "submitter": "EPTCS", "authors": "Abeer Dyoub (University of L'Aquila, Italy), Stefania Costantini\n  (University of L'Aquila, Italy), Francesca A. Lisi (University of Bari \"A.\n  Moro\", Italy)", "title": "Logic Programming and Machine Ethics", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158. Invited paper for the\n  ICLP2020 Panel on \"Machine Ethics\". arXiv admin note: text overlap with\n  arXiv:1909.08255", "journal-ref": "EPTCS 325, 2020, pp. 6-17", "doi": "10.4204/EPTCS.325.6", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transparency is a key requirement for ethical machines. Verified ethical\nbehavior is not enough to establish justified trust in autonomous intelligent\nagents: it needs to be supported by the ability to explain decisions. Logic\nProgramming (LP) has a great potential for developing such perspective ethical\nsystems, as in fact logic rules are easily comprehensible by humans.\nFurthermore, LP is able to model causality, which is crucial for ethical\ndecision making.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:47:18 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dyoub", "Abeer", "", "University of L'Aquila, Italy"], ["Costantini", "Stefania", "", "University of L'Aquila, Italy"], ["Lisi", "Francesca A.", "", "University of Bari \"A.\n  Moro\", Italy"]]}, {"id": "2009.11403", "submitter": "Nathan Fulton", "authors": "Koundinya Vajjha, Avraham Shinnar, Vasily Pestun, Barry Trager, Nathan\n  Fulton", "title": "CertRL: Formalizing Convergence Proofs for Value and Policy Iteration in\n  Coq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms solve sequential decision-making problems\nin probabilistic environments by optimizing for long-term reward. The desire to\nuse reinforcement learning in safety-critical settings inspires a recent line\nof work on formally constrained reinforcement learning; however, these methods\nplace the implementation of the learning algorithm in their Trusted Computing\nBase. The crucial correctness property of these implementations is a guarantee\nthat the learning algorithm converges to an optimal policy. This paper begins\nthe work of closing this gap by developing a Coq formalization of two canonical\nreinforcement learning algorithms: value and policy iteration for finite state\nMarkov decision processes. The central results are a formalization of Bellman's\noptimality principle and its proof, which uses a contraction property of\nBellman optimality operator to establish that a sequence converges in the\ninfinite horizon limit. The CertRL development exemplifies how the Giry monad\nand mechanized metric coinduction streamline optimality proofs for\nreinforcement learning algorithms. The CertRL library provides a general\nframework for proving properties about Markov decision processes and\nreinforcement learning algorithms, paving the way for further work on\nformalization of reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:28:17 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 19:39:30 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Vajjha", "Koundinya", ""], ["Shinnar", "Avraham", ""], ["Pestun", "Vasily", ""], ["Trager", "Barry", ""], ["Fulton", "Nathan", ""]]}, {"id": "2009.11758", "submitter": "Julien Grange", "authors": "Julien Grange", "title": "Successor-Invariant First-Order Logic on Classes of Bounded Degree", "comments": null, "journal-ref": "LICS 2020, pages 479 to 491", "doi": "10.1145/3373718.3394767", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the expressive power of successor-invariant first-order logic, which\nis an extension of first-order logic where the usage of an additional successor\nrelation on the structure is allowed, as long as the validity of formulas is\nindependent on the choice of a particular successor. We show that when the\ndegree is bounded, successor-invariant first-order logic is no more expressive\nthan first-order logic.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:30:13 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 15:27:14 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Grange", "Julien", ""]]}, {"id": "2009.12081", "submitter": "Robin Hirsch", "authors": "Robin Hirsch, Szabolcs Mikul\\'as and Tim Stokes", "title": "The algebra of non-deterministic programs: demonic operators, orders and\n  axioms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demonic composition, demonic refinement and demonic union are alternatives to\nthe usual \"angelic\" composition, angelic refinement (inclusion) and angelic\n(usual) union defined on binary relations. We first motivate both the angelic\nand demonic via an analysis of the behaviour of non-deterministic programs,\nwith the angelic associated with partial correctness and demonic with total\ncorrectness, both cases emerging from a richer algebraic model of\nnon-deterministic programs incorporating both aspects. Zareckii has shown that\nthe isomorphism class of algebras of binary relations under angelic composition\nand inclusion is finitely axiomatised as the class of ordered semigroups. The\nproof can be used to establish that the same axiomatisation applies to binary\nrelations under demonic composition and refinement, and a further modification\nof the proof can be used to incorporate a zero element representing the empty\nrelation in the angelic case and the full relation in the demonic case. For the\nsignature of angelic composition and union, it is known that no finite\naxiomatisation exists, and we show the analogous result for demonic composition\nand demonic union by showing that the same axiomatisation holds for both. We\nshow that the isomorphism class of algebras of binary relations with the\n\"mixed\" signature of demonic composition and angelic inclusion has no finite\naxiomatisation. As a contrast, we show that the isomorphism class of partial\nalgebras of binary relations with the partial operation of constellation\nproduct and inclusion (also a \"mixed\" signature) is finitely axiomatisable.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 08:13:07 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 10:01:53 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Hirsch", "Robin", ""], ["Mikul\u00e1s", "Szabolcs", ""], ["Stokes", "Tim", ""]]}, {"id": "2009.12154", "submitter": "Simon Foster", "authors": "Simon Foster, Yakoub Nemouchi, Mario Gleirscher, Ran Wei, Tim Kelly", "title": "Integration of Formal Proof into Unified Assurance Cases with\n  Isabelle/SACM", "comments": "28 pages, in revision for Formal Aspects of Computing", "journal-ref": null, "doi": "10.1007/s00165-021-00537-4", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assurance cases are often required to certify critical systems. The use of\nformal methods in assurance can improve automation, increase confidence, and\novercome errant reasoning. However, assurance cases can never be fully\nformalised, as the use of formal methods is contingent on models that are\nvalidated by informal processes. Consequently, assurance techniques should\nsupport both formal and informal artifacts, with explicated inferential links\nbetween them. In this paper, we contribute a formal machine-checked interactive\nlanguage, called Isabelle/SACM, supporting the computer-assisted construction\nof assurance cases compliant with the OMG Structured Assurance Case Meta-Model.\nThe use of Isabelle/SACM guarantees well-formedness, consistency, and\ntraceability of assurance cases, and allows a tight integration of formal and\ninformal evidence of various provenance. In particular, Isabelle brings a\ndiverse range of automated verification techniques that can provide evidence.\nTo validate our approach, we present a substantial case study based on the\nTokeneer secure entry system benchmark. We embed its functional specification\ninto Isabelle, verify its security requirements, and form a modular security\ncase in Isabelle/SACM that combines the heterogeneous artifacts. We thus show\nthat Isabelle is a suitable platform for critical systems assurance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:04:09 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Foster", "Simon", ""], ["Nemouchi", "Yakoub", ""], ["Gleirscher", "Mario", ""], ["Wei", "Ran", ""], ["Kelly", "Tim", ""]]}, {"id": "2009.12210", "submitter": "Felipe S. Abrah\\~ao", "authors": "Felipe S. Abrah\\~ao, Klaus Wehmuth, Artur Ziviani", "title": "Emergence of complex data from simple local rules in a network game", "comments": "arXiv admin note: text overlap with arXiv:1708.09149", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT cs.MA cs.SI cs.SY eess.SY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the main subjects of investigation in data science, network science\nhas been demonstrated a wide range of applications to real-world networks\nanalysis and modeling. For example, the pervasive presence of structural or\ntopological characteristics, such as the small-world phenomenon,\nsmall-diameter, scale-free properties, or fat-tailed degree distribution were\none of the underlying pillars fostering the study of complex networks. Relating\nthese phenomena with other emergent properties in complex systems became a\nsubject of central importance. By introducing new implications on the interface\nbetween data science and complex systems science with the purpose of tackling\nsome of these issues, in this article we present a model for a network game\nplayed by complex networks in which nodes are computable systems. In\nparticular, we present and discuss how some network topological properties and\nsimple local communication rules are able to generate a phase transition with\nrespect to the emergence of incompressible data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:43:27 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Abrah\u00e3o", "Felipe S.", ""], ["Wehmuth", "Klaus", ""], ["Ziviani", "Artur", ""]]}, {"id": "2009.12237", "submitter": "Sagar Malhotra", "authors": "Sagar Malhotra and Luciano Serafini", "title": "Weighted Model Counting in the two variable fragment with Cardinality\n  Constraints: A Closed Form Formula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Weighted First-Order Model Counting (WFOMC) computes the weighted sum of the\nmodels of a first-order theory on a given finite domain. WFOMC has emerged as a\nfundamental tool for probabilistic inference. Algorithms for WFOMC that run in\npolynomial time w.r.t. the domain size are called lifted inference algorithms.\nSuch algorithms have been developed for multiple extensions of FO2(the fragment\nof first-order logic with two variables) for the special case of symmetric\nweight functions. We introduce the concept of lifted interpretations as a tool\nfor formulating polynomials for WFOMC. Using lifted interpretations, we\nreconstruct the closed-form formula for polynomial-time FOMC in the universal\nfragment of FO2, earlier proposed by Beame et al. We then expand this\nclosed-form to incorporate existential quantifiers and cardinality constraints\nwithout losing domain-liftability. Finally, we show that the obtained\nclosed-form motivates a natural definition of a family of weight functions\nstrictly larger than symmetric weight functions.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 13:50:18 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 08:45:49 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 13:29:45 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 11:45:58 GMT"}, {"version": "v5", "created": "Thu, 5 Nov 2020 17:03:19 GMT"}, {"version": "v6", "created": "Fri, 26 Mar 2021 16:51:58 GMT"}, {"version": "v7", "created": "Thu, 13 May 2021 17:29:59 GMT"}, {"version": "v8", "created": "Fri, 28 May 2021 13:26:02 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Malhotra", "Sagar", ""], ["Serafini", "Luciano", ""]]}, {"id": "2009.12250", "submitter": "Claudio Menghi", "authors": "Claudio Menghi and Enrico Vigan\\`o and Domenico Bianculli and Lionel\n  C. Briand", "title": "Trace-Checking CPS Properties: Bridging the Cyber-Physical Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems combine software and physical components.\nSpecification-driven trace-checking tools for CPS usually provide users with a\nspecification language to express the requirements of interest, and an\nautomatic procedure to check whether these requirements hold on the execution\ntraces of a CPS. Although there exist several specification languages for CPS,\nthey are often not sufficiently expressive to allow the specification of\ncomplex CPS properties related to the software and the physical components and\ntheir interactions.\n  In this paper, we propose (i) the Hybrid Logic of Signals (HLS), a\nlogic-based language that allows the specification of complex CPS requirements,\nand (ii) ThEodorE, an efficient SMT-based trace-checking procedure. This\nprocedure reduces the problem of checking a CPS requirement over an execution\ntrace, to checking the satisfiability of an SMT formula.\n  We evaluated our contributions by using a representative industrial case\nstudy in the satellite domain. We assessed the expressiveness of HLS by\nconsidering 212 requirements of our case study. HLS could express all the 212\nrequirements. We also assessed the applicability of ThEodorE by running the\ntrace-checking procedure for 747 trace-requirement combinations. ThEodorE was\nable to produce a verdict in 74.5% of the cases. Finally, we compared HLS and\nThEodorE with other specification languages and trace-checking tools from the\nliterature. Our results show that, from a practical standpoint, our approach\noffers a better trade-off between expressiveness and performance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 14:08:50 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 07:57:42 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Menghi", "Claudio", ""], ["Vigan\u00f2", "Enrico", ""], ["Bianculli", "Domenico", ""], ["Briand", "Lionel C.", ""]]}, {"id": "2009.12285", "submitter": "Cogan Shimizu", "authors": "Cogan Shimizu, Ryan McGranaghan, Aaron Eberhart, Adam C. Kellerman", "title": "Towards a Modular Ontology for Space Weather Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The interactions between the Sun, interplanetary space, near Earth space\nenvironment, the Earth's surface, and the power grid are, perhaps\nunsurprisingly, very complicated. The study of such requires the collaboration\nbetween many different organizations spanning the public and private sectors.\nThus, an important component of studying space weather is the integration and\nanalysis of heterogeneous information. As such, we have developed a modular\nontology to drive the core of the data integration and serve the needs of a\nhighly interdisciplinary community. This paper presents our preliminary modular\nontology, for space weather research, as well as demonstrate a method for\nadaptation to a particular use-case, through the use of existential rules and\nexplicit typing.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:17:13 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 16:24:07 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Shimizu", "Cogan", ""], ["McGranaghan", "Ryan", ""], ["Eberhart", "Aaron", ""], ["Kellerman", "Adam C.", ""]]}, {"id": "2009.12521", "submitter": "EPTCS", "authors": "Grant Passmore (Imandra, Inc. and Clare Hall, Cambridge), Ruben Gamboa\n  (University of Wyoming)", "title": "Proceedings of the Sixteenth International Workshop on the ACL2 Theorem\n  Prover and its Applications", "comments": null, "journal-ref": "EPTCS 327, 2020", "doi": "10.4204/EPTCS.327", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a selection of papers presented at the 16th\nInternational Workshop on the ACL2 Theorem Prover and its Applications\n(ACL2-2020). The workshops are the premier technical forum for presenting\nresearch and experiences related to ACL2.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 05:19:33 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Passmore", "Grant", "", "Imandra, Inc. and Clare Hall, Cambridge"], ["Gamboa", "Ruben", "", "University of Wyoming"]]}, {"id": "2009.12670", "submitter": "Benno van den Berg", "authors": "Benno van den Berg and Eric Faber", "title": "Effective Kan fibrations in simplicial sets", "comments": "170 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO math.AT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of an effective Kan fibration, a new mathematical\nstructure that can be used to study simplicial homotopy theory. Our main\nmotivation is to make simplicial homotopy theory suitable for homotopy type\ntheory. Effective Kan fibrations are maps of simplicial sets equipped with a\nstructured collection of chosen lifts that satisfy certain non-trivial\nproperties. This contrasts with the ordinary, unstructured notion of a Kan\nfibration. We show that fundamental properties of Kan fibrations can be\nextended to explicit constructions on effective Kan fibrations. In particular,\nwe give a constructive (explicit) proof showing that effective Kan fibrations\nare stable under push forward, or fibred exponentials. This is known to be\nimpossible for ordinary Kan fibrations. We further show that effective Kan\nfibrations are local, or completely determined by their fibres above\nrepresentables. We also give an (ineffective) proof saying that the maps which\ncan be equipped with the structure of an effective Kan fibration are precisely\nthe ordinary Kan fibrations. Hence implicitly, both notions still describe the\nsame homotopy theory. By showing that the effective Kan fibrations combine all\nthese properties, we solve an open problem in homotopy type theory. In this way\nour work provides a first step in giving a constructive account of Voevodsky's\nmodel of univalent type theory in simplicial sets.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 19:24:55 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Berg", "Benno van den", ""], ["Faber", "Eric", ""]]}, {"id": "2009.12702", "submitter": "Konstantinos Kogkalidis", "authors": "Konstantinos Kogkalidis, Michael Moortgat, Richard Moot", "title": "Neural Proof Nets", "comments": "14 pages, CoNLL2020", "journal-ref": "Proceedings of the 24th Conference on Computational Natural\n  Language Learning (2020)", "doi": "10.18653/v1/2020.conll-1.3", "report-no": null, "categories": "cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear logic and the linear {\\lambda}-calculus have a long standing tradition\nin the study of natural language form and meaning. Among the proof calculi of\nlinear logic, proof nets are of particular interest, offering an attractive\ngeometric representation of derivations that is unburdened by the bureaucratic\ncomplications of conventional prooftheoretic formats. Building on recent\nadvances in set-theoretic learning, we propose a neural variant of proof nets\nbased on Sinkhorn networks, which allows us to translate parsing as the problem\nof extracting syntactic primitives and permuting them into alignment. Our\nmethodology induces a batch-efficient, end-to-end differentiable architecture\nthat actualizes a formally grounded yet highly efficient neuro-symbolic parser.\nWe test our approach on {\\AE}Thel, a dataset of type-logical derivations for\nwritten Dutch, where it manages to correctly transcribe raw text sentences into\nproofs and terms of the linear {\\lambda}-calculus with an accuracy of as high\nas 70%.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 22:48:47 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kogkalidis", "Konstantinos", ""], ["Moortgat", "Michael", ""], ["Moot", "Richard", ""]]}, {"id": "2009.12978", "submitter": "Oscar Darwin", "authors": "Oscar Darwin and Stefan Kiefer", "title": "Equivalence of Hidden Markov Models with Continuous Observations", "comments": "17 pages, 9 figures, Submitted to FSTTCS 2020", "journal-ref": null, "doi": "10.4230/LIPIcs.CVIT.2016.23", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Hidden Markov Models that emit sequences of observations that are\ndrawn from continuous distributions. For example, such a model may emit a\nsequence of numbers, each of which is drawn from a uniform distribution, but\nthe support of the uniform distribution depends on the state of the Hidden\nMarkov Model. Such models generalise the more common version where each\nobservation is drawn from a finite alphabet. We prove that one can determine in\npolynomial time whether two Hidden Markov Models with continuous observations\nare equivalent.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 23:09:05 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Darwin", "Oscar", ""], ["Kiefer", "Stefan", ""]]}, {"id": "2009.13065", "submitter": "J\\'er\\'emy Dubut", "authors": "J\\'er\\'emy Dubut and Akihisa Yamada", "title": "Fixed Points Theorems for Non-Transitive Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an Isabelle/HOL library of order-theoretic\nfixed-point theorems. We keep our formalization as general as possible: we\nreprove several well-known results about complete orders, often with only\nantisymmetry or attractivity, a mild condition implied by either antisymmetry\nor transitivity. In particular, we generalize various theorems ensuring the\nexistence of a quasi-fixed point of monotone maps over complete relations, and\nshow that the set of (quasi-)fixed points is itself complete. This result\ngeneralizes and strengthens theorems of Knaster-Tarski, Bourbaki-Witt, Kleene,\nMarkowsky, Pataraia, Mashburn, Bhatta-George, and Stouti-Maaden.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:42:15 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 05:30:28 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Dubut", "J\u00e9r\u00e9my", ""], ["Yamada", "Akihisa", ""]]}, {"id": "2009.13128", "submitter": "Guillermo P\\'erez", "authors": "Sebastian Junges, Joost-Pieter Katoen, Guillermo A. P\\'erez, Tobias\n  Winkler", "title": "The Complexity of Reachability in Parametric Markov Decision Processes", "comments": "This is a preprint of an article under submission which follows our\n  earlier CONCUR paper. It contains small corrections and new results regarding\n  qualitative reachability queries", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the complexity of reachability decision problems for\nparametric Markov decision processes (pMDPs), an extension to Markov decision\nprocesses (MDPs) where transitions probabilities are described by polynomials\nover a finite set of parameters. In particular, we study the complexity of\nfinding values for these parameters such that the induced MDP satisfies some\nmaximal or minimal reachability probability constraints. We discuss different\nvariants depending on the comparison operator in the constraints and the domain\nof the parameter values. We improve all known lower bounds for this problem,\nand notably provide ETR-completeness results for distinct variants of this\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 08:17:58 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Winkler", "Tobias", ""]]}, {"id": "2009.13152", "submitter": "Pierre Vandenhove", "authors": "Patricia Bouyer, Thomas Brihaye, Mickael Randour, C\\'edric Rivi\\`ere,\n  Pierre Vandenhove", "title": "Decisiveness of Stochastic Systems and its Application to Hybrid Models\n  (Full Version)", "comments": "Full version of GandALF 2020 paper (arXiv:2001.04347v2), updated\n  version of arXiv:2001.04347v1. 30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.SY eess.SY math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [ABM07], Abdulla et al. introduced the concept of decisiveness, an\ninteresting tool for lifting good properties of finite Markov chains to\ndenumerable ones. Later, this concept was extended to more general stochastic\ntransition systems (STSs), allowing the design of various verification\nalgorithms for large classes of (infinite) STSs. We further improve the\nunderstanding and utility of decisiveness in two ways. First, we provide a\ngeneral criterion for proving decisiveness of general STSs. This criterion,\nwhich is very natural but whose proof is rather technical, (strictly)\ngeneralizes all known criteria from the literature. Second, we focus on\nstochastic hybrid systems (SHSs), a stochastic extension of hybrid systems. We\nestablish the decisiveness of a large class of SHSs and, under a few classical\nhypotheses from mathematical logic, we show how to decide reachability problems\nin this class, even though they are undecidable for general SHSs. This provides\na decidable stochastic extension of o-minimal hybrid systems.\n  [ABM07] Parosh A. Abdulla, Noomene Ben Henda, and Richard Mayr. 2007.\nDecisive Markov Chains. Log. Methods Comput. Sci. 3, 4 (2007).\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:07:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bouyer", "Patricia", ""], ["Brihaye", "Thomas", ""], ["Randour", "Mickael", ""], ["Rivi\u00e8re", "C\u00e9dric", ""], ["Vandenhove", "Pierre", ""]]}, {"id": "2009.13260", "submitter": "B Srivathsan", "authors": "Paul Gastin, Sayan Mukherjee, B Srivathsan", "title": "Reachability for Updatable Timed Automata made faster and more effective", "comments": "Shorter version of this article is accepted at FSTTCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Updatable timed automata (UTA) are extensions of classic timed automata that\nallow special updates to clock variables, like x:= x - 1, x := y + 2, etc., on\ntransitions. Reachability for UTA is undecidable in general. Various subclasses\nwith decidable reachability have been studied. A generic approach to UTA\nreachability consists of two phases: first, a static analysis of the automaton\nis performed to compute a set of clock constraints at each state; in the second\nphase, reachable sets of configurations, called zones, are enumerated. In this\nwork, we improve the algorithm for the static analysis. Compared to the\nexisting algorithm, our method computes smaller sets of constraints and\nguarantees termination for more UTA, making reachability faster and more\neffective. As the main application, we get an alternate proof of decidability\nand a more efficient algorithm for timed automata with bounded subtraction, a\nclass of UTA widely used for modelling scheduling problems. We have implemented\nour procedure in the tool TChecker and conducted experiments that validate the\nbenefits of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 12:28:45 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gastin", "Paul", ""], ["Mukherjee", "Sayan", ""], ["Srivathsan", "B", ""]]}, {"id": "2009.13407", "submitter": "Rafael Pe\\~naloza", "authors": "Leonard Botha, Thomas Meyer and Rafael Pe\\~naloza", "title": "The Probabilistic Description Logic $\\mathcal{BALC}$", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description logics (DLs) are well-known knowledge representation formalisms\nfocused on the representation of terminological knowledge. Due to their\nfirst-order semantics, these languages (in their classical form) are not\nsuitable for representing and handling uncertainty. A probabilistic extension\nof a light-weight DL was recently proposed for dealing with certain knowledge\noccurring in uncertain contexts. In this paper, we continue that line of\nresearch by introducing the Bayesian extension \\BALC of the propositionally\nclosed DL \\ALC. We present a tableau-based procedure for deciding consistency,\nand adapt it to solve other probabilistic, contextual, and general inferences\nin this logic. We also show that all these problems remain \\ExpTime-complete,\nthe same as reasoning in the underlying classical \\ALC.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:22:52 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Botha", "Leonard", ""], ["Meyer", "Thomas", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "2009.13459", "submitter": "Muhammad Najib", "authors": "Oliver Markgraf, Chih-Duo Hong, Anthony W. Lin, Muhammad Najib, Daniel\n  Neider", "title": "Parameterized Synthesis with Safety Properties", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parameterized synthesis offers a solution to the problem of constructing\ncorrect and verified controllers for parameterized systems. Such systems occur\nnaturally in practice (e.g., in the form of distributed protocols where the\namount of processes is often unknown at design time and the protocol must work\nregardless of the number of processes). In this paper, we present a novel\nlearning based approach to the synthesis of reactive controllers for\nparameterized systems from safety specifications. We use the framework of\nregular model checking to model the synthesis problem as an infinite-duration\ntwo-player game and show how one can utilize Angluin's well-known L* algorithm\nto learn correct-by-design controllers. This approach results in a synthesis\nprocedure that is conceptually simpler than existing synthesis methods with a\ncompleteness guarantee, whenever a winning strategy can be expressed by a\nregular set. We have implemented our algorithm in a tool called L*-PSynth and\nhave demonstrated its performance on a range of benchmarks, including robotic\nmotion planning and distributed protocols. Despite the simplicity of L*-PSynth\nit competes well against (and in many cases even outperforms) the\nstate-of-the-art tools for synthesizing parameterized systems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:41:19 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Markgraf", "Oliver", ""], ["Hong", "Chih-Duo", ""], ["Lin", "Anthony W.", ""], ["Najib", "Muhammad", ""], ["Neider", "Daniel", ""]]}, {"id": "2009.13761", "submitter": "EPTCS", "authors": "David M. Russinoff (Arm)", "title": "Formal Verification of Arithmetic RTL: Translating Verilog to C++ to\n  ACL2", "comments": "In Proceedings ACL2 2020, arXiv:2009.12521", "journal-ref": "EPTCS 327, 2020, pp. 1-15", "doi": "10.4204/EPTCS.327.1", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a methodology for formal verification of arithmetic RTL designs\nthat combines sequential logic equivalence checking with interactive theorem\nproving. An intermediate model of a Verilog module is hand-coded in Restricted\nAlgorithmic C (RAC), a primitive subset of C augmented by the integer and\nfixed-point register class templates of Algorithmic C. The model is designed to\nbe as abstract and compact as possible, but sufficiently faithful to the RTL to\nallow efficient equivalence checking with a commercial tool. It is then\nautomatically translated to the logic of ACL2, enabling a mechanically checked\nproof of correctness with respect to a formal architectural specification. In\nthis paper, we describe the RAC language, the translation process, and some\ntechniques that facilitate formal analysis of the resulting ACL2 code.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:09:53 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Russinoff", "David M.", "", "Arm"]]}, {"id": "2009.13762", "submitter": "EPTCS", "authors": "Matt Kaufmann (Univ. of Texas at Austin), J Strother Moore (Univ. of\n  Texas at Austin)", "title": "Iteration in ACL2", "comments": "In Proceedings ACL2 2020, arXiv:2009.12521", "journal-ref": "EPTCS 327, 2020, pp. 16-31", "doi": "10.4204/EPTCS.327.2", "report-no": null, "categories": "cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative algorithms are traditionally expressed in ACL2 using recursion. On\nthe other hand, Common Lisp provides a construct, loop, which -- like most\nprogramming languages -- provides direct support for iteration. We describe an\nACL2 analogue loop$ of loop that supports efficient ACL2 programming and\nreasoning with iteration.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:10:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Kaufmann", "Matt", "", "Univ. of Texas at Austin"], ["Moore", "J Strother", "", "Univ. of\n  Texas at Austin"]]}, {"id": "2009.13763", "submitter": "EPTCS", "authors": "Sol Swords (Centaur Technology, Inc.)", "title": "New Rewriter Features in FGL", "comments": "In Proceedings ACL2 2020, arXiv:2009.12521", "journal-ref": "EPTCS 327, 2020, pp. 32-46", "doi": "10.4204/EPTCS.327.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FGL is a successor to GL, a proof procedure for ACL2 that allows complicated\nfinitary conjectures to be translated into efficient Boolean function\nrepresentations and proved using SAT solvers. A primary focus of FGL is to\nallow greater programmability using rewrite rules. While the FGL rewriter is\nmodeled on ACL2's rewriter, we have added several features in order to make\nrewrite rules more powerful. A particular focus is to make it more convenient\nfor rewrite rules to use information from the syntactic domain, allowing them\nto replace built-in primitives and meta rules in many cases. Since it is easier\nto write, maintain, and prove the soundness of rewrite rules than to do the\nsame for rules programmed at the syntactic level, these features help make it\nfeasible for users to precisely program the behavior or the rewriter. We\ndescribe the new features that FGL's rewriter implements, discuss the solutions\nto some technical problems that we encountered in their implementation, and\nassess the feasibility of adding these features to the ACL2 rewriter.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:10:17 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Swords", "Sol", "", "Centaur Technology, Inc."]]}, {"id": "2009.13764", "submitter": "EPTCS", "authors": "Rob Sumners (Centaur Technology)", "title": "Computing and Proving Well-founded Orderings through Finite Abstractions", "comments": "In Proceedings ACL2 2020, arXiv:2009.12521", "journal-ref": "EPTCS 327, 2020, pp. 47-60", "doi": "10.4204/EPTCS.327.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common technique for checking properties of complex state machines is to\nbuild a finite abstraction then check the property on the abstract system --\nwhere a passing check on the abstract system is only transferred to the\noriginal system if the abstraction is proven to be representative. This\napproach does require the derivation or definition of the finite abstraction,\nbut can avoid the need for complex invariant definition. For our work in\nchecking progress of memory transactions in microprocessors, we need to prove\nthat transactions in complex state machines always make progress to completion.\nAs a part of this effort, we developed a process for computing a finite\nabstract graph of the target state machine along with annotations on whether\ncertain measures decrease or not on arcs in the abstract graph. We then\niteratively divide the abstract graph by splitting into strongly connected\ncomponents and then building a measure for every node in the abstract graph\nwhich is ensured to be reducing on every transition of the original system\nguaranteeing progress. For finite state target systems (e.g. hardware designs),\nwe present approaches for extracting the abstract graph efficiently using\nincremental SAT through GL and then the application of our process to check for\nprogress. We present an implementation of the Bakery algorithm as an example\napplication.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:10:29 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sumners", "Rob", "", "Centaur Technology"]]}, {"id": "2009.13765", "submitter": "EPTCS", "authors": "Mertcan Temel (University of Texas at Austin)", "title": "RP-Rewriter: An Optimized Rewriter for Large Terms in ACL2", "comments": "In Proceedings ACL2 2020, arXiv:2009.12521", "journal-ref": "EPTCS 327, 2020, pp. 61-74", "doi": "10.4204/EPTCS.327.5", "report-no": null, "categories": "cs.LO cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RP-Rewriter (Retain-Property) is a verified clause processor that can use\nsome of the existing ACL2 rewrite rules to prove conjectures through term\nrewriting. Optimized for conjectures that can expand into large terms, the\nrewriter tries to mimic some of the ACL2 rewriting heuristics but also adds\nsome extra features. It can attach side-conditions to terms that help the\nrewriter retain properties about them and prevent possibly some very expensive\nbackchaining. The rewriter supports user-defined complex meta rules that can\nreturn a special structure to prevent redundant rewriting. Additionally, it can\nstore fast alists even when values are not quoted. RP-Rewriter is utilized for\ntwo applications, multiplier design proofs and SVEX simplification, which\ninvolve very large terms.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:10:41 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Temel", "Mertcan", "", "University of Texas at Austin"]]}, {"id": "2009.13766", "submitter": "EPTCS", "authors": "Ruben Gamboa (University of Wyoming), John Cowles (University of\n  Wyoming), Woodrow Gamboa (Stanford University)", "title": "Quadratic Extensions in ACL2", "comments": "In Proceedings ACL2 2020, arXiv:2009.12521", "journal-ref": "EPTCS 327, 2020, pp. 75-86", "doi": "10.4204/EPTCS.327.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a field K, a quadratic extension field L is an extension of K that can\nbe generated from K by adding a root of a quadratic polynomial with\ncoefficients in K. This paper shows how ACL2(r) can be used to reason about\nchains of quadratic extension fields Q = K_0, K_1, K_2, ..., where each K_i+1\nis a quadratic extension field of K_i. Moreover, we show that some specific\nnumbers, such as the cube root of 2 and the cosine of pi/9, cannot belong to\nany of the K_i, simply because of the structure of quadratic extension fields.\nIn particular, this is used to show that the cube root of 2 and cosine of pi/9\nare not rational.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:10:55 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Gamboa", "Ruben", "", "University of Wyoming"], ["Cowles", "John", "", "University of\n  Wyoming"], ["Gamboa", "Woodrow", "", "Stanford University"]]}, {"id": "2009.13767", "submitter": "EPTCS", "authors": "Sol Swords (Centaur Technology, Inc.)", "title": "Generating Mutually Inductive Theorems from Concise Descriptions", "comments": "In Proceedings ACL2 2020, arXiv:2009.12521", "journal-ref": "EPTCS 327, 2020, pp. 95-107", "doi": "10.4204/EPTCS.327.10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe defret-mutual-generate, a utility for proving ACL2 theorems about\nlarge mutually recursive cliques of functions. This builds on previous tools\nsuch as defret-mutual and make-flag, which automate parts of the process but\nstill require a theorem body to be written out for each function in the clique.\nFor large cliques, this tends to mean that certain common hypotheses and\nconclusions are repeated many times, making proofs difficult to read, write,\nand maintain. This utility automates several of the most common patterns that\noccur in these forms, such as including hypotheses based on formal names or\ntypes. Its input language is rich enough to support forms that have some common\nparts and some unique parts per function. One application of\ndefret-mutual-generate has been to support proofs about the FGL rewriter, which\nconsists of a mutually recursive clique of 49 functions. The use of this\nutility reduced the size of the forms that express theorems about this clique\nby an order of magnitude. It also greatly has reduced the need to edit theorem\nforms when changing definitions in the clique, even when adding or removing\nfunctions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:11:07 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Swords", "Sol", "", "Centaur Technology, Inc."]]}, {"id": "2009.13769", "submitter": "EPTCS", "authors": "Alessandro Coglio (Kestrel Institute)", "title": "Ethereum's Recursive Length Prefix in ACL2", "comments": "In Proceedings ACL2 2020, arXiv:2009.12521", "journal-ref": "EPTCS 327, 2020, pp. 108-124", "doi": "10.4204/EPTCS.327.11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive Length Prefix (RLP) is used to encode a wide variety of data in\nEthereum, including transactions. The work described in this paper provides a\nformal specification of RLP encoding and a verified implementation of RLP\ndecoding, developed in the ACL2 theorem prover. This work has led to\nimprovements to the Ethereum documentation and additions to the Ethereum test\nsuite.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:11:19 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Coglio", "Alessandro", "", "Kestrel Institute"]]}, {"id": "2009.13771", "submitter": "EPTCS", "authors": "Alessandro Coglio (Kestrel Institute), Stephen Westfold (Kestrel\n  Institute)", "title": "Isomorphic Data Type Transformations", "comments": "In Proceedings ACL2 2020, arXiv:2009.12521", "journal-ref": "EPTCS 327, 2020, pp. 125-141", "doi": "10.4204/EPTCS.327.12", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stepwise derivations of programs from specifications, data type\nrefinements are common. Many data type refinements involve isomorphic mappings\nbetween the more abstract and more concrete data representations. Examples\ninclude refinement of finite sets to duplicate-free ordered lists or to bit\nvectors, adding record components that are functions of the other fields to\navoid expensive recomputation, etc. This paper describes the APT (Automated\nProgram Transformations) tools to carry out isomorphic data type refinements in\nthe ACL2 theorem prover and gives examples of their use. Because of the\ninherent symmetry of isomorphisms, these tools are also useful to verify\nexisting programs, by turning more concrete data representations into more\nabstract ones to ease verification. Typically, a data type will have relatively\nfew interface functions that access the internals of the type. Once versions of\nthese interface functions have been derived that work on the isomorphic type,\nhigher-level functions can be derived simply by substituting the old functions\nfor the new ones. We have implemented the APT transformations isodata to\ngenerate the former, and propagate-iso for generating the latter functions as\nwell as theorems about the generated functions from the theorems about the\noriginal functions. Propagate-iso also handles cases where the type is a\ncomponent of a more complex one such as a list of the type or a record that has\na field of the type: the isomorphism on the component type is automatically\nlifted to an isomorphism on the more complex type. As with all APT\ntransformations, isodata and propagate-iso generate proofs of the relationship\nof the transformed functions to the originals.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:11:31 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Coglio", "Alessandro", "", "Kestrel Institute"], ["Westfold", "Stephen", "", "Kestrel\n  Institute"]]}, {"id": "2009.14322", "submitter": "Renato Neves", "authors": "Sergey Goncharov and Renato Neves and Jos\\'e Proen\\c{c}a", "title": "Implementing Hybrid Semantics: From Functional to Imperative", "comments": "This is an extended version of a paper accepted in ICTAC'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid programs combine digital control with differential equations, and\nnaturally appear in a wide range of application domains, from biology and\ncontrol theory to real-time software engineering. The entanglement of discrete\nand continuous behaviour inherent to such programs goes beyond the established\ncomputer science foundations, producing challenges related to e.g. infinite\niteration and combination of hybrid behaviour with other effects. A systematic\ntreatment of hybridness as a dedicated computational effect has emerged\nrecently. In particular, a generic idealized functional language HybCore with a\nsound and adequate operational semantics has been proposed. The latter\nsemantics however did not provide hints to implementing HybCore as a runnable\nlanguage, suitable for hybrid system simulation (e.g. the semantics features\nrules with uncountably many premises). We introduce an imperative counterpart\nof HybCore, whose semantics is simpler and runnable, and yet intimately related\nwith the semantics of HybCore at the level of hybrid monads. We then establish\na corresponding soundness and adequacy theorem. To attest that the resulting\nsemantics can serve as a firm basis for the implementation of typical tools of\nprogramming oriented to the hybrid domain, we present a web-based prototype\nimplementation to evaluate and inspect hybrid programs, in the spirit of GHCi\nfor Haskell and UTop for OCaml. The major asset of our implementation is that\nit formally follows the operational semantic rules.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:03:26 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Goncharov", "Sergey", ""], ["Neves", "Renato", ""], ["Proen\u00e7a", "Jos\u00e9", ""]]}, {"id": "2009.14430", "submitter": "Joaqu\\'in Arias", "authors": "Joaqu\\'in Arias, Manuel Carro", "title": "A Theoretical Study of (Full) Tabled Constraint Logic Programming", "comments": "arXiv admin note: text overlap with arXiv:1809.05771", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic programming with tabling and constraints (TCLP, tabled constraint logic\nprogramming) has been shown to be more expressive and, in some cases, more\nefficient than LP, CLP, or LP with tabling. In this paper we provide insights\nregarding the semantics, correctness, completeness, and termination of top-down\nexecution strategies for full TCLP, i.e., TCLP featuring entailment checking in\nthe calls and in the answers. We present a top-down semantics for TCLP and show\nthat it is equivalent to a fixpoint semantics. We study how the constraints\nthat a program generates can effectively impact termination, even for\nconstraint classes that are not constraint compact, generalizing previous\nresults. We also present how different variants of constraint projection impact\nthe correctness and completeness of TCLP implementations. All of the presented\ncharacteristics are implemented (or can be experimented with) in Mod TCLP, a\nmodular framework for Tabled Constraint Logic Programming, part of the Ciao\nProlog logic programming system.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 19:49:48 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Arias", "Joaqu\u00edn", ""], ["Carro", "Manuel", ""]]}, {"id": "2009.14576", "submitter": "Robin Piedeleu", "authors": "Robin Piedeleu and Fabio Zanasi", "title": "A String Diagrammatic Axiomatisation of Finite-State Automata", "comments": "Minor corrections, in particular in the proof of completeness\n  (including the ordering of the steps of Brzozowski's algorithm)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a fully diagrammatic approach to the theory of finite-state\nautomata, based on reinterpreting their usual state-transition graphical\nrepresentation as a two-dimensional syntax of string diagrams. Moreover, we\nprovide an equational theory that completely axiomatises language equivalence\nin this new setting. This theory has two notable features. First, the Kleene\nstar is a derived concept, as it can be decomposed into more primitive\nalgebraic blocks. Second, the proposed axiomatisation is finitary -- a result\nwhich is provably impossible to obtain for the one-dimensional syntax of\nregular expressions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:43:47 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 07:43:12 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Piedeleu", "Robin", ""], ["Zanasi", "Fabio", ""]]}, {"id": "2009.14787", "submitter": "Sara Ayhan", "authors": "Sara Ayhan", "title": "A cut-free sequent calculus for the bi-intuitionistic logic 2Int", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to introduce a bi-intuitionistic sequent\ncalculus and to give proofs of admissibility for its structural rules. The\ncalculus I will present, called SC2Int, is a sequent calculus for the\nbi-intuitionistic logic 2Int. Calculi for this logic represent a kind of\nbilateralist reasoning, since they do not only internalize processes of\nverification or provability but also the dual processes in terms of\nfalsification or what is called dual provability. A normal form theorem for a\nnatural deduction calculus of 2Int has already been stated, in this paper I\nwant to prove a cut-elimination theorem for SC2Int, i.e. if successful, this\nwould extend the results existing so far.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 18:20:50 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ayhan", "Sara", ""]]}]