[{"id": "1203.0103", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze (Shandong University and Villanova University)", "title": "On the system CL12 of computability logic", "comments": "arXiv admin note: substantial text overlap with arXiv:1003.0425 and\n  arXiv:1003.4719", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (July 28,\n  2015) lmcs:1577", "doi": "10.2168/LMCS-11(3:1)2015", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computability logic (see http://www.csc.villanova.edu/~japaridz/CL/) is a\nlong-term project for redeveloping logic on the basis of a constructive game\nsemantics, with games seen as abstract models of interactive computational\nproblems. Among the fragments of this logic successfully axiomatized so far is\nCL12 --- a conservative extension of classical first-order logic, whose\nlanguage augments that of classical logic with the so called choice sorts of\nquantifiers and connectives. This system has already found fruitful\napplications as a logical basis for constructive and complexity-oriented\nversions of Peano arithmetic, such as arithmetics for polynomial time\ncomputability, polynomial space computability, and beyond. The present paper\nintroduces a third, indispensable complexity measure for interactive\ncomputations termed amplitude complexity, and establishes the adequacy of CL12\nwith respect to A-amplitude, S-space and T-time computability under certain\nminimal conditions on the triples (A,S,T) of function classes. This result very\nsubstantially broadens the potential application areas of CL12. The paper is\nself-contained, and targets readers with no prior familiarity with the subject.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2012 07:07:31 GMT"}, {"version": "v10", "created": "Sat, 25 Jul 2015 15:42:03 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2012 13:53:29 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2013 03:21:21 GMT"}, {"version": "v4", "created": "Wed, 22 May 2013 11:10:02 GMT"}, {"version": "v5", "created": "Mon, 3 Jun 2013 01:30:12 GMT"}, {"version": "v6", "created": "Tue, 1 Apr 2014 13:41:01 GMT"}, {"version": "v7", "created": "Sun, 22 Jun 2014 14:43:15 GMT"}, {"version": "v8", "created": "Tue, 13 Jan 2015 11:23:11 GMT"}, {"version": "v9", "created": "Wed, 22 Apr 2015 12:08:00 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Japaridze", "Giorgi", "", "Shandong University and Villanova University"]]}, {"id": "1203.0115", "submitter": "Gunnar Wilken", "authors": "Gunnar Wilken (Okinawa Institute of Science and Technology,\n  Mathematical Biology Unit, Japan), Andreas Weiermann (Ghent University)", "title": "Derivation Lengths Classification of G\\\"odel's T Extending Howard's\n  Assignment", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 6,\n  2012) lmcs:1073", "doi": "10.2168/LMCS-8(1:19)2012", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let T be Goedel's system of primitive recursive functionals of finite type in\nthe lambda formulation. We define by constructive means using recursion on\nnested multisets a multivalued function I from the set of terms of T into the\nset of natural numbers such that if a term a reduces to a term b and if a\nnatural number I(a) is assigned to a then a natural number I(b) can be assigned\nto b such that I(a) is greater than I(b). The construction of I is based on\nHoward's 1970 ordinal assignment for T and Weiermann's 1996 treatment of T in\nthe combinatory logic version. As a corollary we obtain an optimal derivation\nlength classification for the lambda formulation of T and its fragments.\nCompared with Weiermann's 1996 exposition this article yields solutions to\nseveral non-trivial problems arising from dealing with lambda terms instead of\ncombinatory logic terms. It is expected that the methods developed here can be\napplied to other higher order rewrite systems resulting in new powerful\ntermination orderings since T is a paradigm for such systems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2012 08:21:26 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2012 12:49:19 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Wilken", "Gunnar", "", "Okinawa Institute of Science and Technology,\n  Mathematical Biology Unit, Japan"], ["Weiermann", "Andreas", "", "Ghent University"]]}, {"id": "1203.0220", "submitter": "Dov Gabbay", "authors": "Dov M. Gabbay", "title": "The Equational Approach to CF2 Semantics", "comments": "36 pages, version dated 15 February 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a family of new equational semantics for argumentation networks\nwhich can handle odd and even loops in a uniform manner. We offer one version\nof equational semantics which is equivalent to CF2 semantics, and a better\nversion which gives the same results as traditional Dung semantics for even\nloops but can still handle odd loops.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2012 15:45:31 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Gabbay", "Dov M.", ""]]}, {"id": "1203.0415", "submitter": "Jan Blech", "authors": "Jan Olaf Blech", "title": "On Compositional Reasoning for Guaranteeing Probabilistic Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework to formally describe probabilistic system behavior and\nsymbolically reason about it. In particular we aim at reasoning about possible\nfailures and fault tolerance. We regard systems which are composed of different\nunits: sensors, computational parts and actuators. Considering worst-case\nfailure behavior of system components, our framework is most suited to derive\nreliability guarantees for composed systems. The behavior of system components\nis modeled using monad like constructs that serve as an abstract representation\nfor system behavior. We introduce rules to reason about these representations\nand derive results like guaranteed upper bounds for system failure. Our\napproach is characterized by the fact that we do not just map a certain\ncomponent to a failure probability, but regard distributions of error behavior\nand their evolvement over system runs. This serves as basis for deriving\nprobabilities of events, in particular failure probabilities. The work\npresented in this paper slightly extends a complete framework and a case study\nwhich has been previously published. One focus of this report is a more\ndetailed explanation of definitions and a more comprehensive description of\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2012 10:47:42 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Blech", "Jan Olaf", ""]]}, {"id": "1203.0494", "submitter": "Minseong Kim", "authors": "Minseong Kim", "title": "Inconsistency of the Zermelo-Fraenkel set theory with the axiom of\n  choice and its effects on the computational complexity", "comments": "I thought the paper was withdrawn, but apparently it was not. So it\n  is withdrawn. This paper of course does not make any sense", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper exposes a contradiction in the Zermelo-Fraenkel set theory with\nthe axiom of choice (ZFC). While Godel's incompleteness theorems state that a\nconsistent system cannot prove its consistency, they do not eliminate proofs\nusing a stronger system or methods that are outside the scope of the system.\nThe paper shows that the cardinalities of infinite sets are uncontrollable and\ncontradictory. The paper then states that Peano arithmetic, or first-order\narithmetic, is inconsistent if all of the axioms and axiom schema assumed in\nthe ZFC system are taken as being true, showing that ZFC is inconsistent. The\npaper then exposes some consequences that are in the scope of the computational\ncomplexity theory.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2012 15:28:11 GMT"}, {"version": "v2", "created": "Sat, 31 Dec 2016 21:05:57 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Kim", "Minseong", ""]]}, {"id": "1203.0587", "submitter": "Alex Brik", "authors": "Alex Brik, Jeffrey B. Remmel", "title": "Expressing Preferences using Preference Set Constraint Atoms", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an extension of Answer Set Programming called\nPreference Set Constraint Programming which is a convenient and general\nformalism to reason with preferences. PSC programming extends Set Constraint\nProgramming introduced by Marek and Remmel (Marek and Remmel 2004) by\nintroducing two types of preference set constraint atoms, measure preference\nset constraint atoms and pre-ordered preference set constraint atoms, which are\nextensions of set constraint atoms. We show that the question of whether a PSC\nprogram has a preferred stable model is CoNP-complete. We give examples of the\nuses of the preference set constraint atoms and show that Answer Set\nOptimization (Brewka, Niemel\\\"a, and Truszczynski 2003) and General Preference\n(Son and Pontelli 2006) can be expressed using preference set constraint atoms.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2012 23:25:07 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Brik", "Alex", ""], ["Remmel", "Jeffrey B.", ""]]}, {"id": "1203.0670", "submitter": "Delia Kesner", "authors": "Beniamino Accattoli (LIPN (CNRS and Universite Paris-Nord) and INRIA\n  and LIX (Ecole Polytechnique)), Delia Kesner (PPS, Universite Paris-Diderot\n  and CNRS)", "title": "Preservation of Strong Normalisation modulo permutations for the\n  structural lambda-calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 27,\n  2012) lmcs:847", "doi": "10.2168/LMCS-8(1:28)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a recent graphical formalism for lambda-calculus based on linear\nlogic technology, we introduce an untyped structural lambda-calculus, called\nlambda j, which combines actions at a distance with exponential rules\ndecomposing the substitution by means of weakening, contraction and\nderelicition. First, we prove some fundamental properties of lambda j such as\nconfluence and preservation of beta-strong normalisation. Second, we add a\nstrong bisimulation to lambda j by means of an equational theory which captures\nin particular Regnier's sigma-equivalence. We then complete this bisimulation\nwith two more equations for (de)composition of substitutions and we prove that\nthe resulting calculus still preserves beta-strong normalization. Finally, we\ndiscuss some consequences of our results.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2012 17:47:21 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2012 20:26:32 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Accattoli", "Beniamino", "", "LIPN"], ["Kesner", "Delia", "", "PPS, Universite Paris-Diderot\n  and CNRS"]]}, {"id": "1203.0835", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "Functional Logic Programming with Generalized Circular Coinduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to adapt functional logic programming to deal with\nreasoning on coinductively interpreted programs as well as on inductively\ninterpreted programs. In order to do so, we consider a class of objects\ninteresting for this coinductive interpretation, namely regular terms. We show\nhow the usual data structures can be adapted to capture these objects. We adapt\nthe operational semantics of Curry to interpret programs coinductively. We\nillustrate this method with several examples that show the working of our\nmethod and several cases in which it could be useful. Finally, we suggest how\nthe declarative semantics can be adapted suitably.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 09:07:18 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1203.0871", "submitter": "Pietro Galliani Dr", "authors": "Pietro Galliani", "title": "Transition Semantics - The Dynamics of Dependence Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the relationship between Dependence Logic and game logics. A\nvariant of Dynamic Game Logic, called Transition Logic, is developed, and we\nshow that its relationship with Dependence Logic is comparable to the one\nbetween First-Order Logic and Dynamic Game Logic discussed by van Benthem. This\nsuggests a new perspective on the interpretation of Dependence Logic formulas,\nin terms of assertions about reachability in games of im- perfect information\nagainst Nature. We then capitalize on this intuition by developing expressively\nequivalent variants of Dependence Logic in which this interpretation is taken\nto the foreground.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 11:42:44 GMT"}, {"version": "v2", "created": "Tue, 21 May 2013 08:14:00 GMT"}], "update_date": "2013-05-22", "authors_parsed": [["Galliani", "Pietro", ""]]}, {"id": "1203.0920", "submitter": "Luca Bortolussi", "authors": "Luca Bortolussi and Jane Hillston", "title": "Fluid Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate a potential use of fluid approximation\ntechniques in the context of stochastic model checking of CSL formulae. We\nfocus on properties describing the behaviour of a single agent in a (large)\npopulation of agents, exploiting a limit result known also as fast simulation.\nIn particular, we will approximate the behaviour of a single agent with a\ntime-inhomogeneous CTMC which depends on the environment and on the other\nagents only through the solution of the fluid differential equation. We will\nprove the asymptotic correctness of our approach in terms of satisfiability of\nCSL formulae and of reachability probabilities. We will also present a\nprocedure to model check time-inhomogeneous CTMC against CSL formulae.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 14:00:02 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2013 15:51:44 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Bortolussi", "Luca", ""], ["Hillston", "Jane", ""]]}, {"id": "1203.1177", "submitter": "Tichakorn Wongpiromsarn", "authors": "Tichakorn Wongpiromsarn and Emilio Frazzoli", "title": "Control of Probabilistic Systems under Dynamic, Partially Known\n  Environments with Temporal Logic Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the synthesis of control policies for probabilistic systems,\nmodeled by Markov decision processes, operating in partially known environments\nwith temporal logic specifications. The environment is modeled by a set of\nMarkov chains. Each Markov chain describes the behavior of the environment in\neach mode. The mode of the environment, however, is not known to the system.\nTwo control objectives are considered: maximizing the expected probability and\nmaximizing the worst-case probability that the system satisfies a given\nspecification.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2012 12:05:10 GMT"}], "update_date": "2012-03-07", "authors_parsed": [["Wongpiromsarn", "Tichakorn", ""], ["Frazzoli", "Emilio", ""]]}, {"id": "1203.1257", "submitter": "P\\'eter    L. Erd\\H{o}s", "authors": "P\\'eter L. Erd\\H{o}s, Claude Tardif, G\\'abor Tardos", "title": "On infinite-finite duality pairs of directed graphs", "comments": null, "journal-ref": null, "doi": "10.1007/s11083-012-9278-9", "report-no": null, "categories": "math.CO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (A,D) duality pairs play crucial role in the theory of general relational\nstructures and in the Constraint Satisfaction Problem. The case where both\nclasses are finite is fully characterized. The case when both side are infinite\nseems to be very complex. It is also known that no finite-infinite duality pair\nis possible if we make the additional restriction that both classes are\nantichains. In this paper (which is the first one of a series) we start the\ndetailed study of the infinite-finite case.\n  Here we concentrate on directed graphs. We prove some elementary properties\nof the infinite-finite duality pairs, including lower and upper bounds on the\nsize of D, and show that the elements of A must be equivalent to forests if A\nis an antichain. Then we construct instructive examples, where the elements of\nA are paths or trees. Note that the existence of infinite-finite antichain\ndualities was not previously known.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2012 17:18:06 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Erd\u0151s", "P\u00e9ter L.", ""], ["Tardif", "Claude", ""], ["Tardos", "G\u00e1bor", ""]]}, {"id": "1203.1352", "submitter": "Samson Abramsky", "authors": "Samson Abramsky and Lucien Hardy", "title": "Logical Bell Inequalities", "comments": "12 pages", "journal-ref": "Phys. Rev. A 85, 062114 (2012) [11 pages]", "doi": "10.1103/PhysRevA.85.062114", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bell inequalities play a central role in the study of quantum non-locality\nand entanglement, with many applications in quantum information. Despite the\nhuge literature on Bell inequalities, it is not easy to find a clear conceptual\nanswer to what a Bell inequality is, or a clear guiding principle as to how\nthey may be derived. In this paper, we introduce a notion of logical Bell\ninequality which can be used to systematically derive testable inequalities for\na very wide variety of situations. There is a single clear conceptual\nprinciple, based on purely logical consistency conditions, which underlies our\nnotion of logical Bell inequalities. We show that in a precise sense, all Bell\ninequalities can be taken to be of this form. Our approach is very general. It\napplies directly to any family of sets of commuting observables. Thus it covers\nnot only the n-partite scenarios to which Bell inequalities are standardly\napplied, but also Kochen-Specker configurations, and many other examples. There\nis much current work on experimental tests for contextuality. Our approach\ndirectly yields, in a systematic fashion, testable inequalities for a very\ngeneral notion of contextuality.\n  There has been much work on obtaining proofs of Bell's theorem `without\ninequalities' or `without probabilities'. These proofs are seen as being in a\nsense more definitive and logically robust than the inequality-based proofs. On\nthe hand, they lack the fault-tolerant aspect of inequalities. Our approach\nreconciles these aspects, and in fact shows how the logical robustness can be\nconverted into systematic, general derivations of inequalities with provable\nviolations. Moreover, the kind of strong non-locality or contextuality\nexhibited by the GHZ argument or by Kochen-Specker configurations can be shown\nto lead to maximal violations of the corresponding logical Bell inequalities.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2012 23:23:56 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 09:32:11 GMT"}, {"version": "v3", "created": "Mon, 12 Mar 2012 00:11:03 GMT"}, {"version": "v4", "created": "Thu, 15 Mar 2012 11:37:19 GMT"}, {"version": "v5", "created": "Mon, 11 Jun 2012 22:31:38 GMT"}, {"version": "v6", "created": "Wed, 20 Jun 2012 16:32:40 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Abramsky", "Samson", ""], ["Hardy", "Lucien", ""]]}, {"id": "1203.1495", "submitter": "Val\\'erie Murat", "authors": "Thomas Genet, Tristan Le Gall, Axel Legay, Valerie Murat", "title": "Tree Regular Model Checking for Lattice-Based Automata", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree Regular Model Checking (TRMC) is the name of a family of techniques for\nanalyzing infinite-state systems in which states are represented by terms, and\nsets of states by Tree Automata (TA). The central problem in TRMC is to decide\nwhether a set of bad states is reachable. The problem of computing a TA\nrepresenting (an over- approximation of) the set of reachable states is\nundecidable, but efficient solutions based on completion or iteration of tree\ntransducers exist. Unfortunately, the TRMC framework is unable to efficiently\ncapture both the complex structure of a system and of some of its features. As\nan example, for JAVA programs, the structure of a term is mainly exploited to\ncapture the structure of a state of the system. On the counter part, integers\nof the java programs have to be encoded with Peano numbers, which means that\nany algebraic operation is potentially represented by thousands of applications\nof rewriting rules. In this paper, we propose Lattice Tree Automata (LTAs), an\nextended version of tree automata whose leaves are equipped with lattices. LTAs\nallow us to represent possibly infinite sets of interpreted terms. Such terms\nare capable to represent complex domains and related operations in an efficient\nmanner. We also extend classical Boolean operations to LTAs. Finally, as a\nmajor contribution, we introduce a new completion-based algorithm for computing\nthe possibly infinite set of reachable interpreted terms in a finite amount of\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 15:19:52 GMT"}], "update_date": "2012-03-09", "authors_parsed": [["Genet", "Thomas", ""], ["Gall", "Tristan Le", ""], ["Legay", "Axel", ""], ["Murat", "Valerie", ""]]}, {"id": "1203.1743", "submitter": "Christian Retore", "authors": "Christian Retor\\'e (LaBRI)", "title": "Variable types for meaning assembly: a logical syntax for generic noun\n  phrases introduced by most", "comments": null, "journal-ref": "Recherches linguistiques de Vincennes 41 (2012) 18", "doi": null, "report-no": null, "categories": "math.LO cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a way to compute the meanings associated with sentences\nwith generic noun phrases corresponding to the generalized quantifier most. We\ncall these generics specimens and they resemble stereotypes or prototypes in\nlexical semantics. The meanings are viewed as logical formulae that can\nthereafter be interpreted in your favourite models. To do so, we depart\nsignificantly from the dominant Fregean view with a single untyped universe.\nIndeed, our proposal adopts type theory with some hints from Hilbert\n\\epsilon-calculus (Hilbert, 1922; Avigad and Zach, 2008) and from medieval\nphilosophy, see e.g. de Libera (1993, 1996). Our type theoretic analysis bears\nsome resemblance with ongoing work in lexical semantics (Asher 2011; Bassac et\nal. 2010; Moot, Pr\\'evot and Retor\\'e 2011). Our model also applies to\nclassical examples involving a class, or a generic element of this class, which\nis not uttered but provided by the context. An outcome of this study is that,\nin the minimalism-contextualism debate, see Conrad (2011), if one adopts a type\ntheoretical view, terms encode the purely semantic meaning component while\ntheir typing is pragmatically determined.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2012 10:47:07 GMT"}], "update_date": "2012-03-12", "authors_parsed": [["Retor\u00e9", "Christian", "", "LaBRI"]]}, {"id": "1203.1876", "submitter": "Michael Pinsker", "authors": "Manuel Bodirsky, Michael Pinsker", "title": "Topological Birkhoff", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most fundamental mathematical contributions of Garrett Birkhoff is\nthe HSP theorem, which implies that a finite algebra B satisfies all equations\nthat hold in a finite algebra A of the same signature if and only if B is a\nhomomorphic image of a subalgebra of a finite power of A. On the other hand, if\nA is infinite, then in general one needs to take an infinite power in order to\nobtain a representation of B in terms of A, even if B is finite.\n  We show that by considering the natural topology on the functions of A and B\nin addition to the equations that hold between them, one can do with finite\npowers even for many interesting infinite algebras A. More precisely, we prove\nthat if A and B are at most countable algebras which are oligomorphic, then the\nmapping which sends each function from A to the corresponding function in B\npreserves equations and is continuous if and only if B is a homomorphic image\nof a subalgebra of a finite power of A.\n  Our result has the following consequences in model theory and in theoretical\ncomputer science: two \\omega-categorical structures are primitive positive\nbi-interpretable if and only if their topological polymorphism clones are\nisomorphic. In particular, the complexity of the constraint satisfaction\nproblem of an \\omega-categorical structure only depends on its topological\npolymorphism clone.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2012 18:26:42 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2012 22:46:17 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Pinsker", "Michael", ""]]}, {"id": "1203.2241", "submitter": "Yongming Li", "authors": "Yongming Li, Lijun Li", "title": "Model-Checking of Linear-Time Properties Based on Possibility Measure", "comments": "22pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the LTL model-checking in possibilistic Kripke structure using\npossibility measure. First, the notion of possibilistic Kripke structure and\nthe related possibility measure are introduced, then model-checking of\nreachability and repeated reachability linear-time properties in finite\npossibilistic Kripke structure are studied. Standard safety property and\n-regular property in possibilistic Kripke structure are introduced, the\nverification of regular safety property and -regular property using finite\nautomata are thoroughly studied. It has been shown that the verification of\nregular safety property and -regular property in finite possibilistic Kripke\nstructure can be transformed into the verification of reachability property and\nrepeated reachability property in the product possibilistic Kripke structure\nintroduced in this paper. Several examples are given to illustrate the methods\npresented in the paper.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2012 08:26:34 GMT"}, {"version": "v2", "created": "Sun, 25 Sep 2016 03:07:13 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Li", "Yongming", ""], ["Li", "Lijun", ""]]}, {"id": "1203.2505", "submitter": "Debajit Sensarma", "authors": "Debajit Sensarma, Subhashis Banerjee, Krishnendu Basuli, Saptarshi\n  Naskar, Samar Sen Sarma", "title": "On an optimization technique using Binary Decision Diagram", "comments": "10 pages,5 figures,Sensarma D., Banerjee S., Basuli K., Naskar S., &\n  Sarma, S. S \"Minimizing Boolean Sum of Products Functions Using Binary\n  Decision Diagram\", Advances in Computer Science and Information Technology:\n  Computer Science and Information Technology: Second International Conference.\n  Proceedings, Vol. 86, Part III, pp 36-48, CCSIT 2012", "journal-ref": "IJCSEA, Volume 2, Number 1, pg. 73-86, February 2012", "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-level logic minimization is a central problem in logic synthesis, and has\napplications in reliability analysis and automated reasoning. This paper\nrepresents a method of minimizing Boolean sum of products function with binary\ndecision diagram and with disjoint sum of product minimization. Due to the\nsymbolic representation of cubes for large problem instances, the method is\norders of magnitude faster than previous enumerative techniques. But the\nquality of the approach largely depends on the variable ordering of the\nunderlying BDD. The application of Binary Decision Diagrams (BDDs) as an\nefficient approach for the minimization of Disjoint Sums-of-Products (DSOPs).\nDSOPs are a starting point for several applications. The use of BDDs has the\nadvantage of an implicit representation of terms. Due to this scheme the\nalgorithm is faster than techniques working on explicit representations and the\napplication to large circuits that could not be handled so far becomes\npossible. Theoretical studies on the influence of the BDDs to the search space\nare carried out. In experiments the proposed technique is compared to others.\nThe results with respect to the size of the resulting DSOP are as good or\nbetter as those of the other techniques.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2012 14:26:23 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Sensarma", "Debajit", ""], ["Banerjee", "Subhashis", ""], ["Basuli", "Krishnendu", ""], ["Naskar", "Saptarshi", ""], ["Sarma", "Samar Sen", ""]]}, {"id": "1203.2809", "submitter": "Mounira Kourjieh", "authors": "Yannick Chevalier (IRIT), Mounira Kourjieh (INRIA Lorraine - LORIA /\n  LIFC)", "title": "Automated Synthesis of a Finite Complexity Ordering for Saturation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper a new procedure to saturate a set of clauses with\nrespect to a well-founded ordering on ground atoms such that A < B implies\nVar(A) {\\subseteq} Var(B) for every atoms A and B. This condition is satisfied\nby any atom ordering compatible with a lexicographic, recursive, or multiset\npath ordering on terms. Our saturation procedure is based on a priori ordered\nresolution and its main novelty is the on-the-fly construction of a finite\ncomplexity atom ordering. In contrast with the usual redundancy, we give a new\nredundancy notion and we prove that during the saturation a non-redundant\ninference by a priori ordered resolution is also an inference by a posteriori\nordered resolution. We also prove that if a set S of clauses is saturated with\nrespect to an atom ordering as described above then the problem of whether a\nclause C is entailed from S is decidable.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2012 19:36:46 GMT"}], "update_date": "2012-03-14", "authors_parsed": [["Chevalier", "Yannick", "", "IRIT"], ["Kourjieh", "Mounira", "", "INRIA Lorraine - LORIA /\n  LIFC"]]}, {"id": "1203.2900", "submitter": "Dominique Duval", "authors": "Jean-Guillaume Dumas (LJK), Dominique Duval (LJK), Laurent Fousse\n  (LJK), Jean-Claude Reynaud (RC)", "title": "Decorated proofs for computational effects: Exceptions", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a proof system for exceptions which is close to the syntax for\nexceptions, in the sense that the exceptions do not appear explicitly in the\ntype of any expression. This proof system is sound with respect to the intended\ndenotational semantics of exceptions. With this inference system we prove\nseveral properties of exceptions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2012 19:21:55 GMT"}], "update_date": "2012-03-15", "authors_parsed": [["Dumas", "Jean-Guillaume", "", "LJK"], ["Duval", "Dominique", "", "LJK"], ["Fousse", "Laurent", "", "LJK"], ["Reynaud", "Jean-Claude", "", "RC"]]}, {"id": "1203.3167", "submitter": "Stephan Kreutzer", "authors": "Stephan Kreutzer (Oxford University Computing Laboratory)", "title": "On the Parameterized Intractability of Monadic Second-Order Logic", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 26,\n  2012) lmcs:785", "doi": "10.2168/LMCS-8(1:27)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of Courcelle's celebrated results states that if C is a class of graphs\nof bounded tree-width, then model-checking for monadic second order logic\n(MSO_2) is fixed-parameter tractable (fpt) on C by linear time parameterized\nalgorithms, where the parameter is the tree-width plus the size of the formula.\nAn immediate question is whether this is best possible or whether the result\ncan be extended to classes of unbounded tree-width. In this paper we show that\nin terms of tree-width, the theorem cannot be extended much further. More\nspecifically, we show that if C is a class of graphs which is closed under\ncolourings and satisfies certain constructibility conditions and is such that\nthe tree-width of C is not bounded by \\log^{84} n then MSO_2-model checking is\nnot fpt unless SAT can be solved in sub-exponential time. If the tree-width of\nC is not poly-logarithmically bounded, then MSO_2-model checking is not fpt\nunless all problems in the polynomial-time hierarchy can be solved in\nsub-exponential time.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2012 18:23:05 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2012 10:47:38 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kreutzer", "Stephan", "", "Oxford University Computing Laboratory"]]}, {"id": "1203.3298", "submitter": "Yaroslav Sergeyev", "authors": "Yaroslav D. Sergeyev, Alfredo Garro", "title": "Observability of Turing Machines: a Refinement of the Theory of\n  Computation", "comments": "31 pages, 1 figure", "journal-ref": "Informatica, 2010, 21(3), 425-454", "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Turing machine is one of the simple abstract computational devices that\ncan be used to investigate the limits of computability. In this paper, they are\nconsidered from several points of view that emphasize the importance and the\nrelativity of mathematical languages used to describe the Turing machines. A\ndeep investigation is performed on the interrelations between mechanical\ncomputations and their mathematical descriptions emerging when a human (the\nresearcher) starts to describe a Turing machine (the object of the study) by\ndifferent mathematical languages (the instruments of investigation). Together\nwith traditional mathematical languages using such concepts as 'enumerable\nsets' and 'continuum' a new computational methodology allowing one to measure\nthe number of elements of different infinite sets is used in this paper. It is\nshown how mathematical languages used to describe the machines limit our\npossibilities to observe them. In particular, notions of observable\ndeterministic and non-deterministic Turing machines are introduced and\nconditions ensuring that the latter can be simulated by the former are\nestablished.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 09:55:28 GMT"}], "update_date": "2012-03-16", "authors_parsed": [["Sergeyev", "Yaroslav D.", ""], ["Garro", "Alfredo", ""]]}, {"id": "1203.3568", "submitter": "Vincent Demange", "authors": "Lo\\\"ic Colson (LITA), Vincent Demange (LITA)", "title": "Investigations on a Pedagogical Calculus of Constructions", "comments": "18 pages", "journal-ref": "J.UCS Journal of Universal Computer Science 19, 6 (2013) 729-749", "doi": "10.3217/jucs-019-06-0729", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years appeared pedagogical propositional natural deduction\nsystems. In these systems, one must satisfy the pedagogical constraint: the\nuser must give an example of any introduced notion. First we expose the reasons\nof such a constraint and properties of these \"pedagogical\" calculi: the absence\nof negation at logical side, and the \"usefulness\" feature of terms at\ncomputational side (through the Curry-Howard correspondence). Then we construct\na simple pedagogical restriction of the calculus of constructions (CC) called\nCCr. We establish logical limitations of this system, and compare its\ncomputational expressiveness to Godel system T. Finally, guided by the logical\nlimitations of CCr, we propose a formal and general definition of what a\npedagogical calculus of constructions should be.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2012 21:16:55 GMT"}], "update_date": "2014-08-04", "authors_parsed": [["Colson", "Lo\u00efc", "", "LITA"], ["Demange", "Vincent", "", "LITA"]]}, {"id": "1203.3705", "submitter": "Artur Je\\.z", "authors": "Artur Je\\.z", "title": "Recompression: a simple and powerful technique for word equations", "comments": "Submitted to a journal. Since previous version the proofs were\n  simplified, overall presentation improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an application of a simple technique of local\nrecompression, previously developed by the author in the context of compressed\nmembership problems and compressed pattern matching, to word equations. The\ntechnique is based on local modification of variables (replacing X by aX or Xa)\nand iterative replacement of pairs of letters appearing in the equation by a\n`fresh' letter, which can be seen as a bottom-up compression of the solution of\nthe given word equation, to be more specific, building an SLP (Straight-Line\nProgramme) for the solution of the word equation.\n  Using this technique we give a new, independent and self-contained proofs of\nmost of the known results for word equations. To be more specific, the\npresented (nondeterministic) algorithm runs in O(n log n) space and in time\npolynomial in log N, where N is the size of the length-minimal solution of the\nword equation. The presented algorithm can be easily generalised to a generator\nof all solutions of the given word equation (without increasing the space\nusage). Furthermore, a further analysis of the algorithm yields a doubly\nexponential upper bound on the size of the length-minimal solution. The\npresented algorithm does not use exponential bound on the exponent of\nperiodicity. Conversely, the analysis of the algorithm yields an independent\nproof of the exponential bound on exponent of periodicity.\n  We believe that the presented algorithm, its idea and analysis are far\nsimpler than all previously applied. Furthermore, thanks to it we can obtain a\nunified and simple approach to most of known results for word equations.\n  As a small additional result we show that for O(1) variables (with arbitrary\nmany appearances in the equation) word equations can be solved in linear space,\ni.e. they are context-sensitive.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 13:43:45 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2012 10:45:05 GMT"}, {"version": "v3", "created": "Tue, 18 Mar 2014 12:49:35 GMT"}], "update_date": "2014-03-19", "authors_parsed": [["Je\u017c", "Artur", ""]]}, {"id": "1203.3706", "submitter": "Francois Hantry", "authors": "Francois Hantry, Lakhdar Sa\\\"is and Mohand-Sa\\\"id Hacid", "title": "On the Complexity of Computing Minimal Unsatisfiable LTL formulas", "comments": "Minimal unsatisfiable cores For LTL causes inherent vacuity checking\n  redundancy coverage", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that (1) the Minimal False QCNF search-problem (MF-search) and the\nMinimal Unsatisfiable LTL formula search problem (MU-search) are FPSPACE\ncomplete because of the very expressive power of QBF/LTL, (2) we extend the\nPSPACE-hardness of the MF decision problem to the MU decision problem. As a\nconsequence, we deduce a positive answer to the open question of PSPACE\nhardness of the inherent Vacuity Checking problem. We even show that the\nInherent Non Vacuous formula search problem is also FPSPACE-complete.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 13:53:33 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2012 17:30:54 GMT"}], "update_date": "2012-03-26", "authors_parsed": [["Hantry", "Francois", ""], ["Sa\u00efs", "Lakhdar", ""], ["Hacid", "Mohand-Sa\u00efd", ""]]}, {"id": "1203.3724", "submitter": "Antoine Mine", "authors": "Antoine Min\\'e", "title": "Static Analysis of Run-Time Errors in Embedded Real-Time Parallel C\n  Programs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 26,\n  2012) lmcs:799", "doi": "10.2168/LMCS-8(1:26)2012", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a static analysis by Abstract Interpretation to check for run-time\nerrors in parallel and multi-threaded C programs. Following our work on\nAstr\\'ee, we focus on embedded critical programs without recursion nor dynamic\nmemory allocation, but extend the analysis to a static set of threads\ncommunicating implicitly through a shared memory and explicitly using a finite\nset of mutual exclusion locks, and scheduled according to a real-time\nscheduling policy and fixed priorities. Our method is thread-modular. It is\nbased on a slightly modified non-parallel analysis that, when analyzing a\nthread, applies and enriches an abstract set of thread interferences. An\niterator then re-analyzes each thread in turn until interferences stabilize. We\nprove the soundness of our method with respect to the sequential consistency\nsemantics, but also with respect to a reasonable weakly consistent memory\nsemantics. We also show how to take into account mutual exclusion and thread\npriorities through a partitioning over an abstraction of the scheduler state.\nWe present preliminary experimental results analyzing an industrial program\nwith our prototype, Th\\'es\\'ee, and demonstrate the scalability of our\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 14:55:20 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2012 20:05:00 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Min\u00e9", "Antoine", ""]]}, {"id": "1203.3730", "submitter": "Silvio Ghilardi", "authors": "Roberto Bruttomesso, Silvio Ghilardi, Silvio Ranise", "title": "From Strong Amalgamability to Modularity of Quantifier-Free\n  Interpolation", "comments": null, "journal-ref": null, "doi": null, "report-no": "RI 337-12", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of interpolants in verification is gaining more and more importance.\nSince theories used in applications are usually obtained as (disjoint)\ncombinations of simpler theories, it is important to modularly re-use\ninterpolation algorithms for the component theories. We show that a sufficient\nand necessary condition to do this for quantifier-free interpolation is that\nthe component theories have the 'strong (sub-)amalgamation' property. Then, we\nprovide an equivalent syntactic characterization, identify a sufficient\ncondition, and design a combined quantifier-free interpolation algorithm\ncapable of handling both convex and non-convex theories, that subsumes and\nextends most existing work on combined interpolation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 15:10:52 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2012 09:54:34 GMT"}], "update_date": "2012-04-25", "authors_parsed": [["Bruttomesso", "Roberto", ""], ["Ghilardi", "Silvio", ""], ["Ranise", "Silvio", ""]]}, {"id": "1203.3758", "submitter": "Jeffrey Shallit", "authors": "Dane Henshall, Jeffrey Shallit", "title": "Automatic Theorem-Proving in Combinatorics on Words", "comments": "This revision includes a new result on the Rudin-Shapiro sequence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a technique for mechanically proving certain kinds of theorems in\ncombinatorics on words, using automata and a package for manipulating them. We\nillustrate our technique by solving, purely mechanically, an open problem of\nCurrie and Saari on the lengths of unbordered factors in the Thue-Morse\nsequence.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 16:32:09 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2012 09:33:52 GMT"}], "update_date": "2012-03-30", "authors_parsed": [["Henshall", "Dane", ""], ["Shallit", "Jeffrey", ""]]}, {"id": "1203.3814", "submitter": "J\\\"urgen Koslowski", "authors": "Isolde Adler and Mark Weyer", "title": "Tree-width for first order formulae", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 29,\n  2012) lmcs:786", "doi": "10.2168/LMCS-8(1:32)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce tree-width for first order formulae \\phi, fotw(\\phi). We show\nthat computing fotw is fixed-parameter tractable with parameter fotw. Moreover,\nwe show that on classes of formulae of bounded fotw, model checking is fixed\nparameter tractable, with parameter the length of the formula. This is done by\ntranslating a formula \\phi\\ with fotw(\\phi)<k into a formula of the k-variable\nfragment L^k of first order logic. For fixed k, the question whether a given\nfirst order formula is equivalent to an L^k formula is undecidable. In\ncontrast, the classes of first order formulae with bounded fotw are fragments\nof first order logic for which the equivalence is decidable.\n  Our notion of tree-width generalises tree-width of conjunctive queries to\narbitrary formulae of first order logic by taking into account the quantifier\ninteraction in a formula. Moreover, it is more powerful than the notion of\nelimination-width of quantified constraint formulae, defined by Chen and Dalmau\n(CSL 2005): for quantified constraint formulae, both bounded elimination-width\nand bounded fotw allow for model checking in polynomial time. We prove that\nfotw of a quantified constraint formula \\phi\\ is bounded by the\nelimination-width of \\phi, and we exhibit a class of quantified constraint\nformulae with bounded fotw, that has unbounded elimination-width. A similar\ncomparison holds for strict tree-width of non-recursive stratified datalog as\ndefined by Flum, Frick, and Grohe (JACM 49, 2002).\n  Finally, we show that fotw has a characterization in terms of a cops and\nrobbers game without monotonicity cost.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 20:33:28 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2012 12:45:09 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Adler", "Isolde", ""], ["Weyer", "Mark", ""]]}, {"id": "1203.4084", "submitter": "Richard McKinley", "authors": "Richard McKinley", "title": "Canonical Proof nets for Classical Logic", "comments": "Accepted for publication in APAL (Special issue, Classical Logic and\n  Computation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof nets provide abstract counterparts to sequent proofs modulo rule\npermutations; the idea being that if two proofs have the same underlying\nproof-net, they are in essence the same proof. Providing a convincing proof-net\ncounterpart to proofs in the classical sequent calculus is thus an important\nstep in understanding classical sequent calculus proofs. By convincing, we mean\nthat (a) there should be a canonical function from sequent proofs to proof\nnets, (b) it should be possible to check the correctness of a net in polynomial\ntime, (c) every correct net should be obtainable from a sequent calculus proof,\nand (d) there should be a cut-elimination procedure which preserves\ncorrectness. Previous attempts to give proof-net-like objects for propositional\nclassical logic have failed at least one of the above conditions. In [23], the\nauthor presented a calculus of proof nets (expansion nets) satisfying (a) and\n(b); the paper defined a sequent calculus corresponding to expansion nets but\ngave no explicit demonstration of (c). That sequent calculus, called LK\\ast in\nthis paper, is a novel one-sided sequent calculus with both additively and\nmultiplicatively formulated disjunction rules. In this paper (a self-contained\nextended version of [23]), we give a full proof of (c) for expansion nets with\nrespect to LK\\ast, and in addition give a cut-elimination procedure internal to\nexpansion nets - this makes expansion nets the first notion of proof-net for\nclassical logic satisfying all four criteria.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2012 12:00:45 GMT"}], "update_date": "2012-03-20", "authors_parsed": [["McKinley", "Richard", ""]]}, {"id": "1203.4716", "submitter": "Andreas Abel", "authors": "Andreas Abel (Department of Computer Science,\n  Ludwig-Maximilians-University Munich), Gabriel Scherer (Department of\n  Computer Science, Ludwig-Maximilians-University Munich)", "title": "On Irrelevance and Algorithmic Equality in Predicative Type Theory", "comments": "36 pages, superseds the FoSSaCS 2011 paper of the first author,\n  titled \"Irrelevance in Type Theory with a Heterogeneous Equality Judgement\"", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 27,\n  2012) lmcs:1045", "doi": "10.2168/LMCS-8(1:29)2012", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependently typed programs contain an excessive amount of static terms which\nare necessary to please the type checker but irrelevant for computation. To\nseparate static and dynamic code, several static analyses and type systems have\nbeen put forward. We consider Pfenning's type theory with irrelevant\nquantification which is compatible with a type-based notion of equality that\nrespects eta-laws. We extend Pfenning's theory to universes and large\neliminations and develop its meta-theory. Subject reduction, normalization and\nconsistency are obtained by a Kripke model over the typed equality judgement.\nFinally, a type-directed equality algorithm is described whose completeness is\nproven by a second Kripke model.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2012 11:53:19 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2012 20:51:52 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Abel", "Andreas", "", "Department of Computer Science,\n  Ludwig-Maximilians-University Munich"], ["Scherer", "Gabriel", "", "Department of\n  Computer Science, Ludwig-Maximilians-University Munich"]]}, {"id": "1203.4754", "submitter": "Pierre Lescanne", "authors": "Silvia Ghilezan, Pierre Lescanne (LIP), Dragisa Zunic", "title": "Computational interpretation of classical logic with explicit structural\n  rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a calculus providing a Curry-Howard correspondence to classical\nlogic represented in the sequent calculus with explicit structural rules,\nnamely weakening and contraction. These structural rules introduce explicit\nerasure and duplication of terms, respectively. We present a type system for\nwhich we prove the type-preservation under reduction. A mutual relation with\nclassical calculus featuring implicit structural rules has been studied in\ndetail. From this analysis we derive strong normalisation property.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2012 14:53:02 GMT"}], "update_date": "2012-03-23", "authors_parsed": [["Ghilezan", "Silvia", "", "LIP"], ["Lescanne", "Pierre", "", "LIP"], ["Zunic", "Dragisa", ""]]}, {"id": "1203.4912", "submitter": "Sean Fulop", "authors": "Sean A. Fulop", "title": "A survey of proof nets and matrices for substructural logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a survey of two kinds of \"compressed\" proof schemes, the\n\\emph{matrix method} and \\emph{proof nets}, as applied to a variety of logics\nranging along the substructural hierarchy from classical all the way down to\nthe nonassociative Lambek system. A novel treatment of proof nets for the\nlatter is provided. Descriptions of proof nets and matrices are given in a\nuniform notation based on sequents, so that the properties of the schemes for\nthe various logics can be easily compared.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2012 08:40:29 GMT"}], "update_date": "2012-03-23", "authors_parsed": [["Fulop", "Sean A.", ""]]}, {"id": "1203.4988", "submitter": "Aleks Kissinger", "authors": "Bob Coecke and Ross Duncan and Aleks Kissinger and Quanlong Wang", "title": "Strong Complementarity and Non-locality in Categorical Quantum Mechanics", "comments": "15 pages (incl. 5 appendix). To appear: LiCS 2012", "journal-ref": null, "doi": "10.1109/LICS.2012.35", "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical quantum mechanics studies quantum theory in the framework of\ndagger-compact closed categories.\n  Using this framework, we establish a tight relationship between two key\nquantum theoretical notions: non-locality and complementarity. In particular,\nwe establish a direct connection between Mermin-type non-locality scenarios,\nwhich we generalise to an arbitrary number of parties, using systems of\narbitrary dimension, and performing arbitrary measurements, and a new stronger\nnotion of complementarity which we introduce here.\n  Our derivation of the fact that strong complementarity is a necessary\ncondition for a Mermin scenario provides a crisp operational interpretation for\nstrong complementarity. We also provide a complete classification of strongly\ncomplementary observables for quantum theory, something which has not yet been\nachieved for ordinary complementarity.\n  Since our main results are expressed in the (diagrammatic) language of\ndagger-compact categories, they can be applied outside of quantum theory, in\nany setting which supports the purely algebraic notion of strongly\ncomplementary observables. We have therefore introduced a method for discussing\nnon-locality in a wide variety of models in addition to quantum theory.\n  The diagrammatic calculus substantially simplifies (and sometimes even\ntrivialises) many of the derivations, and provides new insights. In particular,\nthe diagrammatic computation of correlations clearly shows how local\nmeasurements interact to yield a global overall effect. In other words, we\ndepict non-locality.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2012 13:46:33 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2012 12:30:49 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Coecke", "Bob", ""], ["Duncan", "Ross", ""], ["Kissinger", "Aleks", ""], ["Wang", "Quanlong", ""]]}, {"id": "1203.5121", "submitter": "Takahito Aoto", "authors": "Takahito Aoto (Tohoku University), Yoshihito Toyama (Tohoku\n  University)", "title": "A Reduction-Preserving Completion for Proving Confluence of\n  Non-Terminating Term Rewriting Systems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 28,\n  2012) lmcs:667", "doi": "10.2168/LMCS-8(1:31)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a method to prove confluence of term rewriting systems that contain\nnon-terminating rewrite rules such as commutativity and associativity. Usually,\nconfluence of term rewriting systems containing such rules is proved by\ntreating them as equational term rewriting systems and considering E-critical\npairs and/or termination modulo E. In contrast, our method is based solely on\nusual critical pairs and it also (partially) works even if the system is not\nterminating modulo E. We first present confluence criteria for term rewriting\nsystems whose rewrite rules can be partitioned into a terminating part and a\npossibly non-terminating part. We then give a reduction-preserving completion\nprocedure so that the applicability of the criteria is enhanced. In contrast to\nthe well-known Knuth-Bendix completion procedure which preserves the\nequivalence relation of the system, our completion procedure preserves the\nreduction relation of the system, by which confluence of the original system is\ninferred from that of the completed system.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2012 20:41:24 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2012 19:31:46 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Aoto", "Takahito", "", "Tohoku University"], ["Toyama", "Yoshihito", "", "Tohoku\n  University"]]}, {"id": "1203.5323", "submitter": "Barnaby Martin", "authors": "Barnaby Martin", "title": "Parameterized Proof Complexity and W[1]", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a program of parameterized proof complexity that aims to provide\nevidence that FPT is different from W[1]. A similar program already exists for\nthe classes W[2] and W[SAT]. We contrast these programs and prove upper and\nlower bounds for W[1]-parameterized Resolution.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2012 19:10:20 GMT"}], "update_date": "2012-03-26", "authors_parsed": [["Martin", "Barnaby", ""]]}, {"id": "1203.5399", "submitter": "Ido Ben-Zvi", "authors": "Ido Ben-Zvi and Yoram Moses", "title": "Agent-time Epistemics and Coordination", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A minor change to the standard epistemic logical language, replacing $K_{i}$\nwith $K_{\\node{i,t}}$ where $t$ is a time instance, gives rise to a generalized\nand more expressive form of knowledge and common knowledge operators. We\ninvestigate the communication structures that are necessary for such\ngeneralized epistemic states to arise, and the inter-agent coordination tasks\nthat require such knowledge. Previous work has established a relation between\nlinear event ordering and nested knowledge, and between simultaneous event\noccurrences and common knowledge. In the new, extended, formalism, epistemic\nnecessity is decoupled from temporal necessity. Nested knowledge and event\nordering are shown to be related even when the nesting order does not match the\ntemporal order of occurrence. The generalized form of common knowledge does\n{\\em not} correspond to simultaneity. Rather, it corresponds to a notion of\ntight coordination, of which simultaneity is an instance.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2012 10:12:05 GMT"}], "update_date": "2012-03-27", "authors_parsed": [["Ben-Zvi", "Ido", ""], ["Moses", "Yoram", ""]]}, {"id": "1203.5423", "submitter": "EPTCS", "authors": "Simona Ronchi della Rocca (UNITO), Elaine Pimentel (UFMG)", "title": "Proceedings 6th Workshop on Logical and Semantic Frameworks with\n  Applications", "comments": null, "journal-ref": "EPTCS 81, 2012", "doi": "10.4204/EPTCS.81", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Sixth Workshop on Logical and\nSemantic Frameworks with Applications (LSFA 2011). The workshop will be hold in\nBelo Horizonte, on August 27th 2011.\n  Logical and semantic frameworks are formal languages used to represent\nlogics, languages and systems. These frameworks provide foundations for formal\nspecification of systems and programming languages, supporting tool development\nand reasoning.\n  The objective of this one-day workshop is to put together theoreticians and\npractitioners to promote new techniques and results, from the theoretical side,\nand feedback on the implementation and the use of such techniques and results,\nfrom the practical side.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2012 15:27:21 GMT"}], "update_date": "2012-03-27", "authors_parsed": [["della Rocca", "Simona Ronchi", "", "UNITO"], ["Pimentel", "Elaine", "", "UFMG"]]}, {"id": "1203.5754", "submitter": "Carsten Fuhs", "authors": "Carsten Fuhs and Cynthia Kop", "title": "Polynomial Interpretations for Higher-Order Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The termination method of weakly monotonic algebras, which has been defined\nfor higher-order rewriting in the HRS formalism, offers a lot of power, but has\nseen little use in recent years. We adapt and extend this method to the\nalternative formalism of algebraic functional systems, where the simply-typed\nlambda-calculus is combined with algebraic reduction. Using this theory, we\ndefine higher-order polynomial interpretations, and show how the implementation\nchallenges of this technique can be tackled. A full implementation is provided\nin the termination tool WANDA.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2012 18:30:28 GMT"}], "update_date": "2012-03-27", "authors_parsed": [["Fuhs", "Carsten", ""], ["Kop", "Cynthia", ""]]}, {"id": "1203.6152", "submitter": "Pascal Weil", "authors": "Manfred Kufleitner, Pascal Weil (LaBRI)", "title": "The FO^2 alternation hierarchy is decidable", "comments": null, "journal-ref": "Proceedings of Computer Science Logic (CSL 2012), P. Cegielski, A.\n  Durand eds., Leibniz International Proceedings in Informatics (LIPIcs) 16,\n  2012, 426-439", "doi": "10.4230/LIPIcs.CSL.2012.426", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the two-variable fragment FO^2[<] of first-order logic over\nfinite words. Numerous characterizations of this class are known. Th\\'erien and\nWilke have shown that it is decidable whether a given regular language is\ndefinable in FO^2[<]. From a practical point of view, as shown by Weis, FO^2[<]\nis interesting since its satisfiability problem is in NP. Restricting the\nnumber of quantifier alternations yields an infinite hierarchy inside the class\nof FO^2[<]-definable languages. We show that each level of this hierarchy is\ndecidable. For this purpose, we relate each level of the hierarchy with a\ndecidable variety of finite monoids. Our result implies that there are many\ndifferent ways of climbing up the FO^2[<]-quantifier alternation hierarchy:\ndeterministic and co-deterministic products, Mal'cev products with definite and\nreverse definite semigroups, iterated block products with J-trivial monoids,\nand some inductively defined omega-term identities. A combinatorial tool in the\nprocess of ascension is that of condensed rankers, a refinement of the rankers\nof Weis and Immerman and the turtle programs of Schwentick, Th\\'erien, and\nVollmer.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 04:38:31 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Kufleitner", "Manfred", "", "LaBRI"], ["Weil", "Pascal", "", "LaBRI"]]}, {"id": "1203.6157", "submitter": "EPTCS", "authors": "Arnon Avron (Tel-Aviv University)", "title": "A Logical Framework for Set Theories", "comments": "In Proceedings LSFA 2011, arXiv:1203.5423", "journal-ref": "EPTCS 81, 2012, pp. 3-15", "doi": "10.4204/EPTCS.81.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axiomatic set theory is almost universally accepted as the basic theory which\nprovides the foundations of mathematics, and in which the whole of present day\nmathematics can be developed. As such, it is the most natural framework for\nMathematical Knowledge Management. However, in order to be used for this task\nit is necessary to overcome serious gaps that exist between the \"official\"\nformulations of set theory (as given e.g. by formal set theory ZF) and actual\nmathematical practice.\n  In this work we present a new unified framework for formalizations of\naxiomatic set theories of different strength, from rudimentary set theory to\nfull ZF. It allows the use of set terms, but provides a static check of their\nvalidity.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 05:05:59 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Avron", "Arnon", "", "Tel-Aviv University"]]}, {"id": "1203.6158", "submitter": "EPTCS", "authors": "Favio Ezequiel Miranda-Perea (Facultad de Ciencias UNAM), Lourdes del\n  Carmen Gonz\\'alez-Huesca (Facultad de Ciencias UNAM)", "title": "Mendler-style Iso-(Co)inductive predicates: a strongly normalizing\n  approach", "comments": "In Proceedings LSFA 2011, arXiv:1203.5423", "journal-ref": "EPTCS 81, 2012, pp. 30-46", "doi": "10.4204/EPTCS.81.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of the second-order logic AF2 with iso-style\ninductive and coinductive definitions specifically designed to extract programs\nfrom proofs a la Krivine-Parigot by means of primitive (co)recursion\nprinciples. Our logic includes primitive constructors of least and greatest\nfixed points of predicate transformers, but contrary to the common approach, we\ndo not restrict ourselves to positive operators to ensure monotonicity, instead\nwe use the Mendler-style, motivated here by the concept of monotonization of an\narbitrary operator on a complete lattice. We prove an adequacy theorem with\nrespect to a realizability semantics based on saturated sets and\nsaturated-valued functions and as a consequence we obtain the strong\nnormalization property for the proof-term reduction, an important feature which\nis absent in previous related work.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 05:06:14 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Miranda-Perea", "Favio Ezequiel", "", "Facultad de Ciencias UNAM"], ["Gonz\u00e1lez-Huesca", "Lourdes del Carmen", "", "Facultad de Ciencias UNAM"]]}, {"id": "1203.6159", "submitter": "EPTCS", "authors": "Paulo A. S. Veloso (COPPE-UFRJ, Brazil), Sheila R. M. Veloso\n  (FEN-UERJ, Brazil)", "title": "On Graph Refutation for Relational Inclusions", "comments": "In Proceedings LSFA 2011, arXiv:1203.5423", "journal-ref": "EPTCS 81, 2012, pp. 47-62", "doi": "10.4204/EPTCS.81.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a graphical refutation calculus for relational inclusions: it\nreduces establishing a relational inclusion to establishing that a graph\nconstructed from it has empty extension. This sound and complete calculus is\nconceptually simpler and easier to use than the usual ones.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 05:06:25 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Veloso", "Paulo A. S.", "", "COPPE-UFRJ, Brazil"], ["Veloso", "Sheila R. M.", "", "FEN-UERJ, Brazil"]]}, {"id": "1203.6160", "submitter": "EPTCS", "authors": "Andr\\'eia B Avelar (Universidade de Bras\\'ilia), Andr\\'e L Galdino\n  (Universidade Federal de Goi\\'as), Fl\\'avio LC de Moura (Universidade de\n  Bras\\'ilia), Mauricio Ayala-Rinc\\'on (Universidade de Bras\\'ilia)", "title": "A Formalization of the Theorem of Existence of First-Order Most General\n  Unifiers", "comments": "In Proceedings LSFA 2011, arXiv:1203.5423", "journal-ref": "EPTCS 81, 2012, pp. 63-78", "doi": "10.4204/EPTCS.81.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a formalization of the theorem of existence of most\ngeneral unifiers in first-order signatures in the higher-order proof assistant\nPVS. The distinguishing feature of this formalization is that it remains close\nto the textbook proofs that are based on proving the correctness of the\nwell-known Robinson's first-order unification algorithm. The formalization was\napplied inside a PVS development for term rewriting systems that provides a\ncomplete formalization of the Knuth-Bendix Critical Pair theorem, among other\nrelevant theorems of the theory of rewriting. In addition, the formalization\nmethodology has been proved of practical use in order to verify the correctness\nof unification algorithms in the style of the original Robinson's unification\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 05:06:30 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Avelar", "Andr\u00e9ia B", "", "Universidade de Bras\u00edlia"], ["Galdino", "Andr\u00e9 L", "", "Universidade Federal de Goi\u00e1s"], ["de Moura", "Fl\u00e1vio LC", "", "Universidade de\n  Bras\u00edlia"], ["Ayala-Rinc\u00f3n", "Mauricio", "", "Universidade de Bras\u00edlia"]]}, {"id": "1203.6242", "submitter": "Ross Duncan", "authors": "Ross Duncan", "title": "A graphical approach to measurement-based quantum computing", "comments": "To appear in \"Compositional methods in Physics and Linguistics\" OUP\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computations are easily represented in the graphical notation known\nas the ZX-calculus, a.k.a. the red-green calculus. We demonstrate its use in\nreasoning about measurement-based quantum computing, where the graphical syntax\ndirectly captures the structure of the entangled states used to represent\ncomputations, and show that the notion of information flow within the entangled\nstates gives rise to rewriting strategies for proving the correctness of\nquantum programs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 12:16:22 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Duncan", "Ross", ""]]}, {"id": "1203.6278", "submitter": "Achille Frigeri", "authors": "Achille Frigeri, Liliana Pasquale, Paola Spoletini", "title": "Fuzzy Time in LTL", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, the adoption of active systems has increased in many\nfields of computer science, such as databases, sensor networks, and software\nengineering. These systems are able to automatically react to events, by\ncollecting information from outside and internally generating new events.\nHowever, the collection of data is often hampered by uncertainty and vagueness\nthat can arise from the imprecision of the monitoring infrastructure,\nunreliable data sources, and networks. The decision making mechanism used to\nproduce a reaction is also imprecise, and cannot be evaluated in a crisp way.\nIt depends on the evaluation of vague temporal constraints, which are expressed\non the collected data by humans. Despite fuzzy logic has been mainly conceived\nas a mathematical abstraction to express vagueness, no attempt has been made to\nfuzzify the temporal modalities. Existing fuzzy languages do not allow us to\nrepresent temporal properties, such as \"almost always\" and \"soon\". Indeed, the\nsemantics of existing fuzzy temporal operators is based on the idea of\nreplacing classical connectives or propositions with their fuzzy counterparts.\nTo overcome these limitations, we propose a temporal framework, FTL (Fuzzy-time\nTemporal Logic), to express vagueness on time. This framework formally defines\na set of fuzzy temporal modalities, which can be customized by choosing a\nspecific semantics for the connectives. The semantics of the language is sound,\nand the introduced modalities respect a set of expected mutual relations. We\nalso prove that under the assumption that all events are crisp, FTL reduces to\nLTL. Finally, for some of the possible fuzzy interpretations of the\nconnectives, we identify adequate sets of temporal operators, from which it is\npossible to derive all the others.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 14:20:19 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Frigeri", "Achille", ""], ["Pasquale", "Liliana", ""], ["Spoletini", "Paola", ""]]}, {"id": "1203.6324", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic", "title": "Tracing the Man in the Middle in Monoidal Categories", "comments": "23 pages, 20 figures, Coalgebraic Methods in Computer Science (CMCS)\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Man-in-the-Middle (MM) is not only a ubiquitous attack pattern in security,\nbut also an important paradigm of network computation and economics.\nRecognizing ongoing MM-attacks is an important security task; modeling\nMM-interactions is an interesting task for semantics of computation. Traced\nmonoidal categories are a natural framework for MM-modelling, as the trace\nstructure provides a tool to hide what happens *in the middle*. An effective\nanalysis of what has been traced out seems to require an additional property of\ntraces, called *normality*. We describe a modest model of network computation,\nbased on partially ordered multisets (pomsets), where basic network\ninteractions arise from the monoidal trace structure, and a normal trace\nstructure arises from an iterative, i.e. coalgebraic structure over terms and\nmessages used in computation and communication. The correspondence is\nestablished using a convenient monadic description of normally traced monoidal\ncategories.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 17:59:41 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Pavlovic", "Dusko", ""]]}, {"id": "1203.6412", "submitter": "Aquinas Hobor", "authors": "Aquinas Hobor (National University of Singapore), Cristian Gherghina\n  (National University of Singapore)", "title": "Barriers in Concurrent Separation Logic: Now With Tool Support!", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 2 (April 20,\n  2012) lmcs:800", "doi": "10.2168/LMCS-8(2:2)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and prove sound a concurrent separation logic for Pthreads-style\nbarriers. Although Pthreads barriers are widely used in systems, and separation\nlogic is widely used for verification, there has not been any effort to combine\nthe two. Unlike locks and critical sections, Pthreads barriers enable\nsimultaneous resource redistribution between multiple threads and are\ninherently stateful, leading to significant complications in the design of the\nlogic and its soundness proof. We show how our logic can be applied to a\nspecific example program in a modular way. Our proofs are machine-checked in\nCoq. We showcase a program verification toolset that automatically applies the\nlogic rules and discharges the associated proof obligations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2012 01:58:29 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2012 19:30:47 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Hobor", "Aquinas", "", "National University of Singapore"], ["Gherghina", "Cristian", "", "National University of Singapore"]]}, {"id": "1203.6859", "submitter": "Matthew J. Parkinson", "authors": "Matthew J. Parkinson (Microsoft Research), Alexander J. Summers (ETH\n  Zurich)", "title": "The Relationship Between Separation Logic and Implicit Dynamic Frames", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 3 (July 31,\n  2012) lmcs:802", "doi": "10.2168/LMCS-8(3:1)2012", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separation logic is a concise method for specifying programs that manipulate\ndynamically allocated storage. Partially inspired by separation logic, Implicit\nDynamic Frames has recently been proposed, aiming at first-order tool support.\nIn this paper, we precisely connect the semantics of these two logics. We\ndefine a logic whose syntax subsumes both that of a standard separation logic,\nand that of implicit dynamic frames as sub-syntaxes. We define a total heap\nsemantics for our logic, and, for the separation logic subsyntax, prove it\nequivalent the standard partial heaps model. In order to define a semantics\nwhich works uniformly for both subsyntaxes, we define the novel concept of a\nminimal state extension, which provides a different (but equivalent) definition\nof the semantics of separation logic implication and magic wand connectives,\nwhile also giving a suitable semantics for these connectives in implicit\ndynamic frames. We show that our resulting semantics agrees with the existing\ndefinition of weakest pre-condition semantics for the implicit dynamic frames\nfragment. Finally, we show that we can encode the separation logic fragment of\nour logic into the implicit dynamic frames fragment, preserving semantics. For\nthe connectives typically supported by tools, this shows that separation logic\ncan be faithfully encoded in a first-order automatic verification tool\n(Chalice).\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2012 17:01:11 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2012 07:35:48 GMT"}, {"version": "v3", "created": "Sun, 29 Jul 2012 23:07:10 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Parkinson", "Matthew J.", "", "Microsoft Research"], ["Summers", "Alexander J.", "", "ETH\n  Zurich"]]}]