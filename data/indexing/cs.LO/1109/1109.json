[{"id": "1109.0032", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "Semantic Integration in the IFF", "comments": "Presented at the Semantic Integration Workshop of the 2nd\n  International Semantic Web Conference (ISWC2003), Sanibel Island, Florida,\n  October 20, 2003", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IEEE P1600.1 Standard Upper Ontology (SUO) project aims to specify an\nupper ontology that will provide a structure and a set of general concepts upon\nwhich domain ontologies could be constructed. The Information Flow Framework\n(IFF), which is being developed under the auspices of the SUO Working Group,\nrepresents the structural aspect of the SUO. The IFF is based on category\ntheory. Semantic integration of object-level ontologies in the IFF is\nrepresented with its fusion construction. The IFF maintains ontologies using\npowerful composition primitives, which includes the fusion construction.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2011 20:45:08 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1109.0113", "submitter": "EPTCS", "authors": "Martin Gebser (University of Potsdam), Roland Kaminski (University of\n  Potsdam), Torsten Schaub (University of Potsdam)", "title": "aspcud: A Linux Package Configuration Tool Based on Answer Set\n  Programming", "comments": "In Proceedings LoCoCo 2011, arXiv:1108.6097", "journal-ref": "EPTCS 65, 2011, pp. 12-25", "doi": "10.4204/EPTCS.65.2", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Linux package configuration tool aspcud based on Answer Set\nProgramming. In particular, we detail aspcud's preprocessor turning a CUDF\nspecification into a set of logical facts.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 07:34:12 GMT"}], "update_date": "2011-09-02", "authors_parsed": [["Gebser", "Martin", "", "University of Potsdam"], ["Kaminski", "Roland", "", "University of\n  Potsdam"], ["Schaub", "Torsten", "", "University of Potsdam"]]}, {"id": "1109.0114", "submitter": "EPTCS", "authors": "Gerhard Friedrich (Alpen-Adria Universit\\\"at), Anna Ryabokon\n  (Alpen-Adria Universit\\\"at), Andreas A. Falkner (Siemens AG \\\"Osterreich),\n  Alois Haselb\\\"ock (Siemens AG \\\"Osterreich), Gottfried Schenner (Siemens AG\n  \\\"Osterreich), Herwig Schreiner (Siemens AG \\\"Osterreich)", "title": "(Re)configuration based on model generation", "comments": "In Proceedings LoCoCo 2011, arXiv:1108.6097", "journal-ref": "EPTCS 65, 2011, pp. 26-35", "doi": "10.4204/EPTCS.65.3", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconfiguration is an important activity for companies selling configurable\nproducts or services which have a long life time. However, identification of a\nset of required changes in a legacy configuration is a hard problem, since even\nsmall changes in the requirements might imply significant modifications. In\nthis paper we show a solution based on answer set programming, which is a\nlogic-based knowledge representation formalism well suited for a compact\ndescription of (re)configuration problems. Its applicability is demonstrated on\nsimple abstractions of several real-world scenarios. The evaluation of our\nsolution on a set of benchmark instances derived from commercial\n(re)configuration problems shows its practical applicability.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 07:34:15 GMT"}], "update_date": "2011-09-02", "authors_parsed": [["Friedrich", "Gerhard", "", "Alpen-Adria Universit\u00e4t"], ["Ryabokon", "Anna", "", "Alpen-Adria Universit\u00e4t"], ["Falkner", "Andreas A.", "", "Siemens AG \u00d6sterreich"], ["Haselb\u00f6ck", "Alois", "", "Siemens AG \u00d6sterreich"], ["Schenner", "Gottfried", "", "Siemens AG\n  \u00d6sterreich"], ["Schreiner", "Herwig", "", "Siemens AG \u00d6sterreich"]]}, {"id": "1109.0115", "submitter": "EPTCS", "authors": "Markus Aschinger, Conrad Drescher, Georg Gottlob", "title": "Introducing LoCo, a Logic for Configuration Problems", "comments": "In Proceedings LoCoCo 2011, arXiv:1108.6097", "journal-ref": "EPTCS 65, 2011, pp. 36-45", "doi": "10.4204/EPTCS.65.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the core of LoCo, a logic-based high-level\nrepresentation language for expressing configuration problems. LoCo shall allow\nto model these problems in an intuitive and declarative way, the dynamic\naspects of configuration notwithstanding. Our logic enforces that\nconfigurations contain only finitely many components and reasoning can be\nreduced to the task of model construction.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 07:34:23 GMT"}], "update_date": "2011-09-02", "authors_parsed": [["Aschinger", "Markus", ""], ["Drescher", "Conrad", ""], ["Gottlob", "Georg", ""]]}, {"id": "1109.0333", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "A KIF Formalization for the IFF Category Theory Ontology", "comments": "Paper presented at the Standard Upper Ontology workshop of the 17th\n  International Joint Conference on Artificial Intelligence (IJCAI-01), August,\n  2001, Seattle, Washington", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper begins the discussion of how the Information Flow Framework can be\nused to provide a principled foundation for the metalevel (or structural level)\nof the Standard Upper Ontology (SUO). This SUO structural level can be used as\na logical framework for manipulating collections of ontologies in the object\nlevel of the SUO or other middle level or domain ontologies. From the\nInformation Flow perspective, the SUO structural level resolves into several\nmetalevel ontologies. This paper discusses a KIF formalization for one of those\nmetalevel categories, the Category Theory Ontology. In particular, it discusses\nits category and colimit sub-namespaces.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2011 00:20:04 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1109.0375", "submitter": "Jan Sefranek", "authors": "Jan Sefranek and Alexander Simko", "title": "Warranted Derivations of Preferred Answer", "comments": "wlp 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are aiming at a semantics of logic programs with preferences defined on\nrules, which always selects a preferred answer set, if there is a non-empty set\nof (standard) answer sets of the given program. It is shown in a seminal paper\nby Brewka and Eiter that the goal mentioned above is incompatible with their\nsecond principle and it is not satisfied in their semantics of prioritized\nlogic programs. Similarly, also according to other established semantics, based\non a prescriptive approach, there are programs with standard answer sets, but\nwithout preferred answer sets. According to the standard prescriptive approach\nno rule can be fired before a more preferred rule, unless the more preferred\nrule is blocked. This is a rather imperative approach, in its spirit.\n  In our approach, rules can be blocked by more preferred rules, but the rules\nwhich are not blocked are handled in a more declarative style, their execution\ndoes not depend on the given preference relation on the rules. An argumentation\nframework (different from the Dung's framework) is proposed in this paper.\nArgu- mentation structures are derived from the rules of a given program. An\nattack relation on argumentation structures is defined, which is derived from\nattacks of more preferred rules against the less preferred rules. Preferred\nanswer sets correspond to complete argumentation structures, which are not\nblocked by other complete argumentation structures.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2011 07:36:57 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Sefranek", "Jan", ""], ["Simko", "Alexander", ""]]}, {"id": "1109.0456", "submitter": "EPTCS", "authors": "Roberto Di Cosmo (Univ Paris Diderot, Sorbonne Paris Cite, and INRIA\n  Rocquencourt, Paris, France), Olivier Lhomme (IBM France, Sophia Antipolis,\n  France), Claude Michel (I3S (UNS-CNRS), Sophia Antipolis Cedex, France)", "title": "Aligning component upgrades", "comments": "In Proceedings LoCoCo 2011, arXiv:1108.6097", "journal-ref": "EPTCS 65, 2011, pp. 1-11", "doi": "10.4204/EPTCS.65.1", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern software systems, like GNU/Linux distributions or Eclipse-based\ndevelopment environment, are often deployed by selecting components out of\nlarge component repositories. Maintaining such software systems by performing\ncomponent upgrades is a complex task, and the users need to have an expressive\npreferences language at their disposal to specify the kind of upgrades they are\ninterested in. Recent research has shown that it is possible to develop solvers\nthat handle preferences expressed as a combination of a few basic criteria used\nin the MISC competition, ranging from the number of new components to the\nfreshness of the final configuration. In this work we introduce a set of new\ncriteria that allow the users to specify their preferences for solutions with\ncomponents aligned to the same upstream sources, provide an efficient encoding\nand report on the experimental results that prove that optimising these\nalignment criteria is a tractable problem in practice.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 07:34:01 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Di Cosmo", "Roberto", "", "Univ Paris Diderot, Sorbonne Paris Cite, and INRIA\n  Rocquencourt, Paris, France"], ["Lhomme", "Olivier", "", "IBM France, Sophia Antipolis,\n  France"], ["Michel", "Claude", "", "I3S"]]}, {"id": "1109.0583", "submitter": "Shahab Tasharrofi", "authors": "Shahab Tasharrofi and Xiongnan (Newman) Wu and Eugenia Ternovska", "title": "Solving Modular Model Expansion Tasks", "comments": "15 pages, 3 figures, 2 algorithms. This paper appears in the\n  Proceedings of the 25th Workshop on Logic Programming (WLP 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work we describe here is a part of a research program of developing\nfoundations of declarative solving of search problems. We consider the model\nexpansion task as the task representing the essence of search problems where we\nare given an instance of a problem and are searching for a solution satisfying\ncertain properties. Such tasks are common in artificial intelligence, formal\nverification, computational biology. Recently, the model expansion framework\nwas extended to deal with multiple modules. In the current paper, inspired by\npractical combined solvers, we introduce an algorithm to solve model expansion\ntasks for modular systems. We show that our algorithm closely corresponds to\nwhat is done in practice in different areas such as Satisfiability Modulo\nTheories (SMT), Integer Linear Programming (ILP), Answer Set Programming (ASP).\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2011 01:40:20 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Tasharrofi", "Shahab", "", "Newman"], ["Xiongnan", "", "", "Newman"], ["Wu", "", ""], ["Ternovska", "Eugenia", ""]]}, {"id": "1109.0633", "submitter": "Jesse Alama", "authors": "Jesse Alama", "title": "Eliciting implicit assumptions of proofs in the MIZAR Mathematical\n  Library by property omission", "comments": "11 pages, 3 tables. Preliminary version presented at the 3rd Workshop\n  on Modules and Libraries for Proof Assistants (MLPA-11), affiliated with the\n  2nd Conference on Interactive Theorem Proving (ITP-2011), Nijmegen, the\n  Netherlands", "journal-ref": null, "doi": "10.1007/s10817-012-9264-3", "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When formalizing proofs with interactive theorem provers, it often happens\nthat extra background knowledge (declarative or procedural) about mathematical\nconcepts is employed without the formalizer explicitly invoking it, to help the\nformalizer focus on the relevant details of the proof. In the contexts of\nproducing and studying a formalized mathematical argument, such mechanisms are\nclearly valuable. But we may not always wish to suppress background knowledge.\nFor certain purposes, it is important to know, as far as possible, precisely\nwhat background knowledge was implicitly employed in a formal proof. In this\nnote we describe an experiment conducted on the MIZAR Mathematical Library of\nformal mathematical proofs to elicit one such class of implicitly employed\nbackground knowledge: properties of functions and relations (e.g.,\ncommutativity, asymmetry, etc.).\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2011 16:27:08 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Alama", "Jesse", ""]]}, {"id": "1109.0775", "submitter": "EPTCS", "authors": "Azer Bestavros (Boston University), Assaf Kfoury (Boston University)", "title": "A Domain-Specific Language for Incremental and Modular Design of\n  Large-Scale Verifiably-Safe Flow Networks (Preliminary Report)", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 24-47", "doi": "10.4204/EPTCS.66.2", "report-no": null, "categories": "cs.PL cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a domain-specific language (DSL) to inductively assemble flow\nnetworks from small networks or modules to produce arbitrarily large ones, with\ninterchangeable functionally-equivalent parts. Our small networks or modules\nare \"small\" only as the building blocks in this inductive definition (there is\nno limit on their size). Associated with our DSL is a type theory, a system of\nformal annotations to express desirable properties of flow networks together\nwith rules that enforce them as invariants across their interfaces, i.e, the\nrules guarantee the properties are preserved as we build larger networks from\nsmaller ones. A prerequisite for a type theory is a formal semantics, i.e, a\nrigorous definition of the entities that qualify as feasible flows through the\nnetworks, possibly restricted to satisfy additional efficiency or safety\nrequirements. This can be carried out in one of two ways, as a denotational\nsemantics or as an operational (or reduction) semantics; we choose the first in\npreference to the second, partly to avoid exponential-growth rewriting in the\noperational approach. We set up a typing system and prove its soundness for our\nDSL.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:15 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Bestavros", "Azer", "", "Boston University"], ["Kfoury", "Assaf", "", "Boston University"]]}, {"id": "1109.0915", "submitter": "Claudia Picardi", "authors": "Daniele Mundici and Claudia Picardi", "title": "Drawing Sound Conclusions from Unsound Premises", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given sets $\\Phi_1=\\{\\phi_{11},...,\\phi_{1u(1)}\\},\n...,\\Phi_{z}=\\{\\phi_{z1},...,\\phi_{zu(z)}\\}$ of boolean formulas, a formula\n$\\omega$ follows from the conjunction $\\bigwedge\\Phi_i= \\bigwedge \\phi_{ij}$\niff $\\neg \\omega\\wedge \\bigwedge_{i=1}^z \\Phi_i$ is unsatisfiable.\n  Now assume that, given integers $0\\leq e_i < u(i)$, we must check if $\\neg\n\\omega\\wedge \\bigwedge_{i=1}^z \\Phi'_i$ remains unsatisfiable, where\n$\\Phi'_i\\subseteq \\Phi_i$ is obtained by deleting $\\,\\,e_{i}$ arbitrarily\nchosen formulas of $\\Phi_i$, for each $i=1,...,z.$\n  Intuitively, does $\\omega$ {\\it stably} follow, after removing $e_i$ random\nformulas from each $\\Phi_i$?\n  We construct a quadratic reduction of this problem to the consequence problem\nin infinite-valued \\luk\\ logic \\L$_\\infty$. In this way we obtain a\nself-contained proof that the \\L$_\\infty$-consequence problem is coNP-complete.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 14:37:27 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Mundici", "Daniele", ""], ["Picardi", "Claudia", ""]]}, {"id": "1109.0983", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "The Information Flow Framework: New architecture", "comments": "Presented at the International Category Theory Conference (CT 2006)\n  June 25 - July 1, 2006 at White Point, Nova Scotia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This presentation discusses a new, modular, more mature architecture for the\nInformation Flow Framework (IFF). The IFF uses institution theory as a\nfoundation for the semantic integration of ontologies. It represents metalogic,\nand as such operates at the structural level of ontologies. The content, form\nand experience of the IFF could contribute to the development of a standard\nontology for category theory. The foundational aspect of the IFF helps to\nexplain the relationship between the fundamental concepts of set theory and\ncategory theory. The development of the IFF follows two design principles:\nconceptual warrant and categorical design. Both are limitations of the logical\nexpression. Conceptual warrant limits the content of logical expression, by\nrequiring us to justify the introduction of new terminology (and attendant\naxiomatizations). Categorical design limits the form of logical expression (of\nall mathematical concepts and constraints) to atomic expressions: declarations,\nequations or relational expressions. The IFF is a descriptive category\nmetatheory. It is descriptive, since it follows the principle of conceptual\nwarrant; it is categorical, since it follows the principle of categorical\ndesign; and it is a metatheory, since it provides a framework for all theories.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 19:15:17 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1109.1248", "submitter": "Marco Gavanelli", "authors": "Massimiliano Cattafi, Marco Gavanelli, Maddalena Nonato, Stefano\n  Alvisi and Marco Franchini", "title": "Optimal Placement of Valves in a Water Distribution Network with CLP(FD)", "comments": "Best paper award at the 27th International Conference on Logic\n  Programming - ICLP 2011; Theory and Practice of Logic Programming, (ICLP'11)\n  Special Issue, volume 11, issue 4-5, 2011", "journal-ref": null, "doi": "10.1017/S1471068411000275", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new application of logic programming to a real-life\nproblem in hydraulic engineering. The work is developed as a collaboration of\ncomputer scientists and hydraulic engineers, and applies Constraint Logic\nProgramming to solve a hard combinatorial problem. This application deals with\none aspect of the design of a water distribution network, i.e., the valve\nisolation system design.\n  We take the formulation of the problem by Giustolisi and Savic (2008) and\nshow how, thanks to constraint propagation, we can get better solutions than\nthe best solution known in the literature for the Apulian distribution network.\n  We believe that the area of the so-called hydroinformatics can benefit from\nthe techniques developed in Constraint Logic Programming and possibly from\nother areas of logic programming, such as Answer Set Programming.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 18:00:08 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Cattafi", "Massimiliano", ""], ["Gavanelli", "Marco", ""], ["Nonato", "Maddalena", ""], ["Alvisi", "Stefano", ""], ["Franchini", "Marco", ""]]}, {"id": "1109.1317", "submitter": "Pashootan Vaezipoor", "authors": "Pashootan Vaezipoor and David Mitchell and Maarten Mari\\\"en", "title": "Lifted Unit Propagation for Effective Grounding", "comments": "Appears in the Proceedings of the 19th International Conference on\n  Applications of Declarative Programming and Knowledge Management (INAP 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A grounding of a formula $\\phi$ over a given finite domain is a ground\nformula which is equivalent to $\\phi$ on that domain. Very effective\npropositional solvers have made grounding-based methods for problem solving\nincreasingly important, however for realistic problem domains and instances,\nthe size of groundings is often problematic. A key technique in ground (e.g.,\nSAT) solvers is unit propagation, which often significantly reduces ground\nformula size even before search begins. We define a \"lifted\" version of unit\npropagation which may be carried out prior to grounding, and describe\nintegration of the resulting technique into grounding algorithms. We describe\nan implementation of the method in a bottom-up grounder, and an experimental\nstudy of its performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 22:35:48 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Vaezipoor", "Pashootan", ""], ["Mitchell", "David", ""], ["Mari\u00ebn", "Maarten", ""]]}, {"id": "1109.1363", "submitter": "EPTCS", "authors": "Cristina Calcagno (Universit\\`a di Torino), Mario Coppo (Universit\\`a\n  di Torino), Ferruccio Damiani (Universit\\`a di Torino), Maurizio Drocco\n  (Universit\\`a di Torino), Eva Sciacca (Universit\\`a di Torino), Salvatore\n  Spinella (Universit\\`a di Torino), Angelo Troina (Universit\\`a di Torino)", "title": "Modelling Spatial Interactions in the Arbuscular Mycorrhizal Symbiosis\n  using the Calculus of Wrapped Compartments", "comments": "In Proceedings CompMod 2011, arXiv:1109.1044", "journal-ref": "EPTCS 67, 2011, pp. 3-18", "doi": "10.4204/EPTCS.67.3", "report-no": null, "categories": "cs.LO cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arbuscular mycorrhiza (AM) is the most wide-spread plant-fungus symbiosis on\nearth. Investigating this kind of symbiosis is considered one of the most\npromising ways to develop methods to nurture plants in more natural manners,\navoiding the complex chemical productions used nowadays to produce artificial\nfertilizers. In previous work we used the Calculus of Wrapped Compartments\n(CWC) to investigate different phases of the AM symbiosis. In this paper, we\ncontinue this line of research by modelling the colonisation of the plant root\ncells by the fungal hyphae spreading in the soil. This study requires the\ndescription of some spatial interaction. Although CWC has no explicit feature\nmodelling a spatial geometry, the compartment labelling feature can be\neffectively exploited to define a discrete surface topology outlining the\nrelevant sectors which determine the spatial properties of the system under\nconsideration. Different situations and interesting spatial properties can be\nmodelled and analysed in such a lightweight framework (which has not an\nexplicit notion of geometry with coordinates and spatial metrics), thus\nexploiting the existing CWC simulation tool.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 06:27:06 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Calcagno", "Cristina", "", "Universit\u00e0 di Torino"], ["Coppo", "Mario", "", "Universit\u00e0\n  di Torino"], ["Damiani", "Ferruccio", "", "Universit\u00e0 di Torino"], ["Drocco", "Maurizio", "", "Universit\u00e0 di Torino"], ["Sciacca", "Eva", "", "Universit\u00e0 di Torino"], ["Spinella", "Salvatore", "", "Universit\u00e0 di Torino"], ["Troina", "Angelo", "", "Universit\u00e0 di Torino"]]}, {"id": "1109.1366", "submitter": "EPTCS", "authors": "Livio Bioglio", "title": "A Minimal OO Calculus for Modelling Biological Systems", "comments": "In Proceedings CompMod 2011, arXiv:1109.1044", "journal-ref": "EPTCS 67, 2011, pp. 50-64", "doi": "10.4204/EPTCS.67.6", "report-no": null, "categories": "cs.CE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a minimal object oriented core calculus for\nmodelling the biological notion of type that arises from biological ontologies\nin formalisms based on term rewriting. This calculus implements encapsulation,\nmethod invocation, subtyping and a simple formof overriding inheritance, and it\nis applicable to models designed in the most popular term-rewriting formalisms.\nThe classes implemented in a formalism can be used in several models, like\nprogramming libraries.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 06:27:29 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Bioglio", "Livio", ""]]}, {"id": "1109.1367", "submitter": "EPTCS", "authors": "Qixia Yuan (University of Luxembourg), Jun Pang (University of\n  Luxembourg), Sjouke Mauw (University of Luxembourg), Panuwat Trairatphisan\n  (University of Luxembourg), Monique Wiesinger (University of Luxembourg),\n  Thomas Sauter (University of Luxembourg)", "title": "A Study of the PDGF Signaling Pathway with PRISM", "comments": "In Proceedings CompMod 2011, arXiv:1109.1044", "journal-ref": "EPTCS 67, 2011, pp. 65-81", "doi": "10.4204/EPTCS.67.7", "report-no": null, "categories": "cs.CE cs.LO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply the probabilistic model checker PRISM to the analysis\nof a biological system -- the Platelet-Derived Growth Factor (PDGF) signaling\npathway, demonstrating in detail how this pathway can be analyzed in PRISM. We\nshow that quantitative verification can yield a better understanding of the\nPDGF signaling pathway.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 06:27:36 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Yuan", "Qixia", "", "University of Luxembourg"], ["Pang", "Jun", "", "University of\n  Luxembourg"], ["Mauw", "Sjouke", "", "University of Luxembourg"], ["Trairatphisan", "Panuwat", "", "University of Luxembourg"], ["Wiesinger", "Monique", "", "University of Luxembourg"], ["Sauter", "Thomas", "", "University of Luxembourg"]]}, {"id": "1109.1368", "submitter": "EPTCS", "authors": "Pietro Li\\`o (Computer Laboratory. University of Cambridge. United\n  Kingdom), Emanuela Merelli (School of Science and Technology. University of\n  Camerino. Italy), Nicola Paoletti (School of Science and Technology.\n  University of Camerino. Italy)", "title": "Multiple verification in computational modeling of bone pathologies", "comments": "In Proceedings CompMod 2011, arXiv:1109.1044", "journal-ref": "EPTCS 67, 2011, pp. 82-96", "doi": "10.4204/EPTCS.67.8", "report-no": null, "categories": "cs.LO cs.CE cs.SY math.OC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a model checking approach to diagnose the emerging of bone\npathologies. The implementation of a new model of bone remodeling in PRISM has\nled to an interesting characterization of osteoporosis as a defective bone\nremodeling dynamics with respect to other bone pathologies. Our approach allows\nto derive three types of model checking-based diagnostic estimators. The first\ndiagnostic measure focuses on the level of bone mineral density, which is\ncurrently used in medical practice. In addition, we have introduced a novel\ndiagnostic estimator which uses the full patient clinical record, here\nsimulated using the modeling framework. This estimator detects rapid (months)\nnegative changes in bone mineral density. Independently of the actual bone\nmineral density, when the decrease occurs rapidly it is important to alarm the\npatient and monitor him/her more closely to detect insurgence of other bone\nco-morbidities. A third estimator takes into account the variance of the bone\ndensity, which could address the investigation of metabolic syndromes, diabetes\nand cancer. Our implementation could make use of different logical combinations\nof these statistical estimators and could incorporate other biomarkers for\nother systemic co-morbidities (for example diabetes and thalassemia). We are\ndelighted to report that the combination of stochastic modeling with formal\nmethods motivate new diagnostic framework for complex pathologies. In\nparticular our approach takes into consideration important properties of\nbiosystems such as multiscale and self-adaptiveness. The multi-diagnosis could\nbe further expanded, inching towards the complexity of human diseases. Finally,\nwe briefly introduce self-adaptiveness in formal methods which is a key\nproperty in the regulative mechanisms of biological systems and well known in\nother mathematical and engineering areas.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 06:27:45 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Li\u00f2", "Pietro", "", "Computer Laboratory. University of Cambridge. United\n  Kingdom"], ["Merelli", "Emanuela", "", "School of Science and Technology. University of\n  Camerino. Italy"], ["Paoletti", "Nicola", "", "School of Science and Technology.\n  University of Camerino. Italy"]]}, {"id": "1109.1587", "submitter": "Laura Titolo", "authors": "Marco Comini and Laura Titolo and Alicia Villanueva", "title": "Abstract Diagnosis for Timed Concurrent Constraint programs", "comments": "16 pages", "journal-ref": "Theory and Practice of Logic Programming 2011, 11(4-5): 487-502\n  (2011)", "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Timed Concurrent Constraint Language (tccp in short) is a concurrent\nlogic language based on the simple but powerful concurrent constraint paradigm\nof Saraswat. In this paradigm, the notion of store-as-value is replaced by the\nnotion of store-as-constraint, which introduces some differences w.r.t. other\napproaches to concurrency. In this paper, we provide a general framework for\nthe debugging of tccp programs. To this end, we first present a new compact,\nbottom-up semantics for the language that is well suited for debugging and\nverification purposes in the context of reactive systems. We also provide an\nabstract semantics that allows us to effectively implement debugging algorithms\nbased on abstract interpretation. Given a tccp program and a behavior\nspecification, our debugging approach automatically detects whether the program\nsatisfies the specification. This differs from other semiautomatic approaches\nto debugging and avoids the need to provide symptoms in advance. We show the\nefficacy of our approach by introducing two illustrative examples. We choose a\nspecific abstract domain and show how we can detect that a program is\nerroneous.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 22:02:45 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Comini", "Marco", ""], ["Titolo", "Laura", ""], ["Villanueva", "Alicia", ""]]}, {"id": "1109.1691", "submitter": "Prateek Karandikar", "authors": "Prateek Karandikar and Philippe Schnoebelen", "title": "Generalized Post Embedding Problems", "comments": null, "journal-ref": "Theory of Computing Systems, 56(4):697-716, 2015", "doi": "10.1007/s00224-014-9561-9", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Regular Post Embedding Problem extended with partial (co)directness is\nshown decidable. This extends to universal and/or counting versions. It is also\nshown that combining directness and codirectness in Post Embedding problems\nleads to undecidability.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 11:28:37 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2011 15:44:46 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2012 18:50:11 GMT"}, {"version": "v4", "created": "Fri, 23 May 2014 11:03:00 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Karandikar", "Prateek", ""], ["Schnoebelen", "Philippe", ""]]}, {"id": "1109.1702", "submitter": "Florian Rabe", "authors": "Steve Awodey (Carnegie Mellon University), Florian Rabe (Jabos\n  University Bremen)", "title": "Kripke Semantics for Martin-L\\\"of's Extensional Type Theory", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (September\n  27, 2011) lmcs:1184", "doi": "10.2168/LMCS-7(3:18)2011", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that simple type theory is complete with respect to\nnon-standard set-valued models. Completeness for standard models only holds\nwith respect to certain extended classes of models, e.g., the class of\ncartesian closed categories. Similarly, dependent type theory is complete for\nlocally cartesian closed categories. However, it is usually difficult to\nestablish the coherence of interpretations of dependent type theory, i.e., to\nshow that the interpretations of equal expressions are indeed equal. Several\nclasses of models have been used to remedy this problem. We contribute to this\ninvestigation by giving a semantics that is standard, coherent, and\nsufficiently general for completeness while remaining relatively easy to\ncompute with. Our models interpret types of Martin-L\\\"of's extensional\ndependent type theory as sets indexed over posets or, equivalently, as\nfibrations over posets. This semantics can be seen as a generalization to\ndependent type theory of the interpretation of intuitionistic first-order logic\nin Kripke models. This yields a simple coherent model theory, with respect to\nwhich simple and dependent type theory are sound and complete.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 12:39:19 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2011 14:37:36 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Awodey", "Steve", "", "Carnegie Mellon University"], ["Rabe", "Florian", "", "Jabos\n  University Bremen"]]}, {"id": "1109.1905", "submitter": "David Monniaux", "authors": "David Monniaux (VERIMAG - IMAG), Martin Bodin (VERIMAG - IMAG, DI)", "title": "Modular Abstractions of Reactive Nodes using Disjunctive Invariants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We wish to abstract nodes in a reactive programming language, such as Lustre,\ninto nodes with a simpler control structure, with a bound on the number of\ncontrol states. In order to do so, we compute disjunctive invariants in\npredicate abstraction, with a bounded number of disjuncts, then we abstract the\nnode, each disjunct representing an abstract state. The computation of the\ndisjunctive invariant is performed by a form of quantifier elimination\nexpressed using SMT-solving. The same method can also be used to obtain\ndisjunctive loop invariants.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 06:38:06 GMT"}], "update_date": "2011-09-12", "authors_parsed": [["Monniaux", "David", "", "VERIMAG - IMAG"], ["Bodin", "Martin", "", "VERIMAG - IMAG, DI"]]}, {"id": "1109.2015", "submitter": "Michael Leuschel", "authors": "Stefan Hallerstede and Michael Leuschel", "title": "Constraint-Based Deadlock Checking of High-Level Specifications", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 11(4--5): 767--782, 2011", "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing the absence of deadlocks is important in many applications of\nformal methods. The use of model checking for finding deadlocks in formal\nmodels is often limited. In this paper we propose a constraint-based approach\nto finding deadlocks employing the ProB constraint solver. We present the\ngeneral technique, as well as various improvements that had to be performed on\nProB's Prolog kernel, such as reification of membership and arithmetic\nconstraints. This work was guided by an industrial case study, where a team\nfrom Bosch was modeling a cruise control system. Within this case study, ProB\nwas able to quickly find counter examples to very large deadlock-freedom\nconstraints. In the paper, we also present other successful applications of\nthis new technique. Experiments using SAT and SMT solvers on these constraints\nwere thus far unsuccessful.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 14:03:41 GMT"}], "update_date": "2011-09-12", "authors_parsed": [["Hallerstede", "Stefan", ""], ["Leuschel", "Michael", ""]]}, {"id": "1109.2222", "submitter": "Lars Wortel", "authors": "Lars Wortel", "title": "Side Effects in Steering Fragments", "comments": "Master's thesis - Master of Logic - University of Amsterdam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis I will give a formal definition of side effects. I will do so\nby modifying a system for modelling program instructions and program states,\nQuantified Dynamic Logic, to a system called DLAf (for Dynamic Logic with\nAssignments as Formulas), which in contrast to QDL allows assignments in\nformulas and makes use of short-circuit evaluation. I will show the underlying\nlogic in those formulas to be a variant of short-circuit logic called\nrepetition-proof short-circuit logic.\n  Using DLAf I will define the actual and the expected evaluation of a single\ninstruction. The side effects are then defined to be the difference between the\ntwo. I will give rules for composing those side effects in single instructions,\nthus scaling up our definition of side effects to a definition of side effects\nin deterministic \\dlaf-programs. Using this definition I will give a\nclassification of side effects, introducing as most important class that of\nmarginal side effects. Finally, I will show how to use our system for\ncalculating the side effects in a real system such as Program Algebra (PGA).\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 13:24:08 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Wortel", "Lars", ""]]}, {"id": "1109.2247", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "The Standard Aspect of Dialectical Logic", "comments": "An abstracted version of this paper, entitled \"Dialectical Program\n  Semantics\", was accepted for presentation at the 1st International Conference\n  on Algebraic Methodology and Software Technology (AMAST'89), University of\n  Iowa, Iowa City, Iowa, 1989", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialectical logic is the logic of dialectical processes. The goal of\ndialectical logic is to introduce dynamic notions into logical computational\nsystems. The fundamental notions of proposition and truth-value in standard\nlogic are subsumed by the notions of process and flow in dialectical logic.\nDialectical logic has a standard aspect, which can be defined in terms of the\n\"local cartesian closure\" of subtypes. The standard aspect of dialectical logic\nprovides a natural program semantics which incorporates Hoare's\nprecondition/postcondition semantics and extends the standard Kripke semantics\nof dynamic logic. The goal of the standard aspect of dialectical logic is to\nunify the logic of small-scale and large-scale programming.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 18:23:07 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1109.2399", "submitter": "EPTCS", "authors": "Ernesto Pimentel, Valent\\'in Valero", "title": "Proceedings Fifth Workshop on Formal Languages and Analysis of\n  Contract-Oriented Software", "comments": "EPTCS 68, 2011", "journal-ref": null, "doi": "10.4204/EPTCS.68", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume consists of the proceedings of the 5th Workshop on Formal\nLanguages and Analysis of Contract-Oriented Software (FLACOS'11). The FLACOS\nWorkshops serve as annual meeting places to bring together researchers and\npractitioners working on language-based solutions to contract-oriented software\ndevelopment. High-level models of contracts are needed as a tool to negotiate\ncontracts and provide services conforming to them. This Workshop provides\nlanguage-based solutions to the above issues through formalization of\ncontracts, design of appropriate abstraction mechanisms, and formal analysis of\ncontract languages and software. The program of this edition consists of 5\nregular papers and 3 invited presentations.\n  Detailed information about the FLACOS 2011 Workshop can be found at\nhttp://flacos2011.lcc.uma.es/. The 5th edition of the FLACOS Workshop was\norganized by the University of M\\'alaga. It took place in M\\'alaga, Spain,\nduring September 22-23, 2011.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 08:28:07 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Pimentel", "Ernesto", ""], ["Valero", "Valent\u00edn", ""]]}, {"id": "1109.2434", "submitter": "Kim Bauters", "authors": "Kim Bauters and Jeroen Janssen and Steven Schockaert and Dirk Vermeir\n  and Martine De Cock", "title": "Expressiveness of Communication in Answer Set Programming", "comments": "35 pages. This article has been accepted for publication in Theory\n  and Practice of Logic Programming, Copyright Cambridge University Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming (ASP) is a form of declarative programming that allows\nto succinctly formulate and efficiently solve complex problems. An intuitive\nextension of this formalism is communicating ASP, in which multiple ASP\nprograms collaborate to solve the problem at hand. However, the expressiveness\nof communicating ASP has not been thoroughly studied. In this paper, we present\na systematic study of the additional expressiveness offered by allowing ASP\nprograms to communicate. First, we consider a simple form of communication\nwhere programs are only allowed to ask questions to each other. For the most\npart, we deliberately only consider simple programs, i.e. programs for which\ncomputing the answer sets is in P. We find that the problem of deciding whether\na literal is in some answer set of a communicating ASP program using simple\ncommunication is NP-hard. In other words: we move up a step in the polynomial\nhierarchy due to the ability of these simple ASP programs to communicate and\ncollaborate. Second, we modify the communication mechanism to also allow us to\nfocus on a sequence of communicating programs, where each program in the\nsequence may successively remove some of the remaining models. This mimics a\nnetwork of leaders, where the first leader has the first say and may remove\nmodels that he or she finds unsatisfactory. Using this particular communication\nmechanism allows us to capture the entire polynomial hierarchy. This means, in\nparticular, that communicating ASP could be used to solve problems that are\nabove the second level of the polynomial hierarchy, such as some forms of\nabductive reasoning as well as PSPACE-complete problems such as STRIPS\nplanning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 11:48:38 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Bauters", "Kim", ""], ["Janssen", "Jeroen", ""], ["Schockaert", "Steven", ""], ["Vermeir", "Dirk", ""], ["De Cock", "Martine", ""]]}, {"id": "1109.2536", "submitter": "Rohit Chadha", "authors": "Rohit Chadha (LSV, ENS Cachan), A. Prasad Sistla (Univ of Illinois,\n  Chicago), Mahesh Viswanathan (Univ of Illinois, Urbana Campaign)", "title": "Power of Randomization in Automata on Infinite Strings", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (September\n  29, 2011) lmcs:948", "doi": "10.2168/LMCS-7(3:22)2011", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic B\\\"uchi Automata (PBA) are randomized, finite state automata\nthat process input strings of infinite length. Based on the threshold chosen\nfor the acceptance probability, different classes of languages can be defined.\nIn this paper, we present a number of results that clarify the power of such\nmachines and properties of the languages they define. The broad themes we focus\non are as follows. We present results on the decidability and precise\ncomplexity of the emptiness, universality and language containment problems for\nsuch machines, thus answering questions central to the use of these models in\nformal verification. Next, we characterize the languages recognized by PBAs\ntopologically, demonstrating that though general PBAs can recognize languages\nthat are not regular, topologically the languages are as simple as\n\\omega-regular languages. Finally, we introduce Hierarchical PBAs, which are\nsyntactically restricted forms of PBAs that are tractable and capture exactly\nthe class of \\omega-regular languages.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 17:09:08 GMT"}, {"version": "v2", "created": "Wed, 28 Sep 2011 18:26:06 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Chadha", "Rohit", "", "LSV, ENS Cachan"], ["Sistla", "A. Prasad", "", "Univ of Illinois,\n  Chicago"], ["Viswanathan", "Mahesh", "", "Univ of Illinois, Urbana Campaign"]]}, {"id": "1109.2548", "submitter": "Jael Kriener", "authors": "Jael Kriener and Andy King", "title": "RedAlert: Determinacy Inference for Prolog", "comments": "Theory and Practice of Logic Programming, 2011, 27th Int'l.\n  Conference on Logic Programming (ICLP'11) Special Issue, volume 11, issue 4-5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the problem of determinacy inference addressing the\nproblem of how to uniformly handle cut. To this end a new semantics is\nintroduced for cut, which is abstracted to systematically derive a backward\nanalysis that derives conditions sufficient for a goal to succeed at most once.\nThe method is conceptionally simpler and easier to implement than existing\ntechniques, whilst improving the latter's handling of cut. Formal arguments\nsubstantiate correctness and experimental work, and a tool called 'RedAlert'\ndemonstrates the method's generality and applicability.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 17:49:01 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Kriener", "Jael", ""], ["King", "Andy", ""]]}, {"id": "1109.2654", "submitter": "EPTCS", "authors": "Enrique Mart\\'inez (University of Castilla-La Mancha), M. Emilia\n  Cambronero (University of Castilla-La Mancha), Gregorio D\\'iaz (University of\n  Castilla-La Mancha), Gerardo Schneider (Chalmers | University of Gothenburg)", "title": "Timed Automata Semantics for Visual e-Contracts", "comments": "In Proceedings FLACOS 2011, arXiv:1109.2399", "journal-ref": "EPTCS 68, 2011, pp. 7-21", "doi": "10.4204/EPTCS.68.3", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  C-O Diagrams have been introduced as a means to have a more visual\nrepresentation of electronic contracts, where it is possible to represent the\nobligations, permissions and prohibitions of the different signatories, as well\nas what are the penalties in case of not fulfillment of their obligations and\nprohibitions. In such diagrams we are also able to represent absolute and\nrelative timing constraints. In this paper we present a formal semantics for\nC-O Diagrams based on timed automata extended with an ordering of states and\nedges in order to represent different deontic modalities.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 01:25:23 GMT"}], "update_date": "2011-09-14", "authors_parsed": [["Mart\u00ednez", "Enrique", "", "University of Castilla-La Mancha"], ["Cambronero", "M. Emilia", "", "University of Castilla-La Mancha"], ["D\u00edaz", "Gregorio", "", "University of\n  Castilla-La Mancha"], ["Schneider", "Gerardo", "", "Chalmers | University of Gothenburg"]]}, {"id": "1109.2655", "submitter": "EPTCS", "authors": "Adrian Francalanza Ph.D (University of Malta), Andrew Gauci M.Sc\n  (University of Malta), Gordon Pace Ph.D (University of Malta)", "title": "Distributed System Contract Monitoring", "comments": "In Proceedings FLACOS 2011, arXiv:1109.2399", "journal-ref": "EPTCS 68, 2011, pp. 23-37", "doi": "10.4204/EPTCS.68.4", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of behavioural contracts, to specify, regulate and verify systems, is\nparticularly relevant to runtime monitoring of distributed systems. System\ndistribution poses major challenges to contract monitoring, from\nmonitoring-induced information leaks to computation load balancing,\ncommunication overheads and fault-tolerance. We present mDPi, a location-aware\nprocess calculus, for reasoning about monitoring of distributed systems. We\ndefine a family of Labelled Transition Systems for this calculus, which allow\nformal reasoning about different monitoring strategies at different levels of\nabstractions. We also illustrate the expressivity of the calculus by showing\nhow contracts in a simple contract language can be synthesised into different\nmDPi monitors.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 01:25:29 GMT"}], "update_date": "2011-09-14", "authors_parsed": [["D", "Adrian Francalanza Ph.", "", "University of Malta"], ["Sc", "Andrew Gauci M.", "", "University of Malta"], ["D", "Gordon Pace Ph.", "", "University of Malta"]]}, {"id": "1109.2656", "submitter": "EPTCS", "authors": "Francois Hantry (UCBLyon France), Mohand-Said Hacid (UCBLyon France)", "title": "Handling Conflicts in Depth-First Search for LTL Tableau to Debug\n  Compliance Based Languages", "comments": "In Proceedings FLACOS 2011, arXiv:1109.2399", "journal-ref": "EPTCS 68, 2011, pp. 39-53", "doi": "10.4204/EPTCS.68.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing adequate tools to tackle the problem of inconsistent compliance\nrules is a critical research topic. This problem is of paramount importance to\nachieve automatic support for early declarative design and to support evolution\nof rules in contract-based or service-based systems. In this paper we\ninvestigate the problem of extracting temporal unsatisfiable cores in order to\ndetect the inconsistent part of a specification. We extend conflict-driven\nSAT-solver to provide a new conflict-driven depth-first-search solver for\ntemporal logic. We use this solver to compute LTL unsatisfiable cores without\nre-exploring the history of the solver.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 01:25:36 GMT"}], "update_date": "2011-09-14", "authors_parsed": [["Hantry", "Francois", "", "UCBLyon France"], ["Hacid", "Mohand-Said", "", "UCBLyon France"]]}, {"id": "1109.2657", "submitter": "EPTCS", "authors": "Seyed M. Montazeri (University of Gothenburg, Sweden), Nivir K.S. Roy\n  (University of Gothenburg, Sweden), Gerardo Schneider (Chalmers | University\n  of Gothenburg, Sweden)", "title": "From Contracts in Structured English to CL Specifications", "comments": "In Proceedings FLACOS 2011, arXiv:1109.2399", "journal-ref": "EPTCS 68, 2011, pp. 55-69", "doi": "10.4204/EPTCS.68.6", "report-no": null, "categories": "cs.CL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a framework to analyze conflicts of contracts\nwritten in structured English. A contract that has manually been rewritten in a\nstructured English is automatically translated into a formal language using the\nGrammatical Framework (GF). In particular we use the contract language CL as a\ntarget formal language for this translation. In our framework CL specifications\ncould then be input into the tool CLAN to detect the presence of conflicts\n(whether there are contradictory obligations, permissions, and prohibitions. We\nalso use GF to get a version in (restricted) English of CL formulae. We discuss\nthe implementation of such a framework.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 01:25:43 GMT"}], "update_date": "2011-09-14", "authors_parsed": [["Montazeri", "Seyed M.", "", "University of Gothenburg, Sweden"], ["Roy", "Nivir K. S.", "", "University of Gothenburg, Sweden"], ["Schneider", "Gerardo", "", "Chalmers | University\n  of Gothenburg, Sweden"]]}, {"id": "1109.2658", "submitter": "EPTCS", "authors": "Daniel Gor\\'in (Dpto. Computaci\\'on, FCEyN, UBA, Buenos Aires,\n  Argentina), Sergio Mera (Dpto. Computaci\\'on, FCEyN, UBA, Buenos Aires,\n  Argentina), Fernando Schapachnik (Dpto. Computaci\\'on, FCEyN, UBA, Buenos\n  Aires, Argentina)", "title": "A Software Tool for Legal Drafting", "comments": "In Proceedings FLACOS 2011, arXiv:1109.2399", "journal-ref": "EPTCS 68, 2011, pp. 71-86", "doi": "10.4204/EPTCS.68.7", "report-no": null, "categories": "cs.CY cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many attempts at automated aids for legal drafting have been made,\nthey were based on the construction of a new tool, completely from scratch.\nThis is at least curious, considering that a strong parallelism can be\nestablished between a normative document and a software specification: both\ndescribe what an entity should or should not do, can or cannot do.\n  In this article we compare normative documents and software specifications to\nfind out their similarities and differences. The comparison shows that there\nare distinctive particularities, but they are restricted to a very specific\nsubclass of normative propositions. The rest, we postulate, can be dealt with\nsoftware tools. For such an enterprise the \\FormaLex tool set was devised: an\nLTL-based language and companion tools that utilize model checking to find out\nnormative incoherences in regulations, contracts and other legal documents. A\nfeature-rich case study is analyzed with the presented tools.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 01:25:51 GMT"}], "update_date": "2011-09-14", "authors_parsed": [["Gor\u00edn", "Daniel", "", "Dpto. Computaci\u00f3n, FCEyN, UBA, Buenos Aires,\n  Argentina"], ["Mera", "Sergio", "", "Dpto. Computaci\u00f3n, FCEyN, UBA, Buenos Aires,\n  Argentina"], ["Schapachnik", "Fernando", "", "Dpto. Computaci\u00f3n, FCEyN, UBA, Buenos\n  Aires, Argentina"]]}, {"id": "1109.3031", "submitter": "Bernhard Reus", "authors": "Jan Schwinghammer (Saarland University), Lars Birkedal (IT University\n  of Copenhagen), Bernhard Reus (University of Sussex), Hongseok Yang\n  (University of Oxford)", "title": "Nested Hoare Triples and Frame Rules for Higher-order Store", "comments": "42 pages", "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (September\n  28, 2011) lmcs:996", "doi": "10.2168/LMCS-7(3:21)2011", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separation logic is a Hoare-style logic for reasoning about programs with\nheap-allocated mutable data structures. As a step toward extending separation\nlogic to high-level languages with ML-style general (higher-order) storage, we\ninvestigate the compatibility of nested Hoare triples with several variations\nof higher-order frame rules. The interaction of nested triples and frame rules\ncan be subtle, and the inclusion of certain frame rules is in fact unsound. A\nparticular combination of rules can be shown consistent by means of a Kripke\nmodel where worlds live in a recursively defined ultrametric space. The\nresulting logic allows us to elegantly prove programs involving stored code. In\nparticular, using recursively defined assertions, it leads to natural\nspecifications and proofs of invariants required for dealing with recursion\nthrough the store.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 09:24:06 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2011 14:51:09 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Schwinghammer", "Jan", "", "Saarland University"], ["Birkedal", "Lars", "", "IT University\n  of Copenhagen"], ["Reus", "Bernhard", "", "University of Sussex"], ["Yang", "Hongseok", "", "University of Oxford"]]}, {"id": "1109.3256", "submitter": "Dean Voets", "authors": "Dean Voets, Danny De Schreye", "title": "Non-termination Analysis of Logic Programs with Integer arithmetics", "comments": "15 pages, 2 figures, journal TPLP (special issue on the international\n  conference of logic programming)", "journal-ref": "TPLP, 2011, volume 11, number 4-5, pages 521 --536", "doi": "10.1017/S1471068411000159", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past years, analyzers have been introduced to detect classes of\nnon-terminating queries for definite logic programs. Although these\nnon-termination analyzers have shown to be rather precise, their applicability\non real-life Prolog programs is limited because most Prolog programs use\nnon-logical features. As a first step towards the analysis of Prolog programs,\nthis paper presents a non-termination condition for Logic Programs containing\ninteger arithmetics. The analyzer is based on our non-termination analyzer\npresented at ICLP 2009. The analysis starts from a class of queries and infers\na subclass of non-terminating ones. In a first phase, we ignore the outcome\n(success or failure) of the arithmetic operations, assuming success of all\narithmetic calls. In a second phase, we characterize successful arithmetic\ncalls as a constraint problem, the solution of which determines the\nnon-terminating queries.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 03:58:37 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Voets", "Dean", ""], ["De Schreye", "Danny", ""]]}, {"id": "1109.3322", "submitter": "Krzysztof R. Apt", "authors": "Floor Sietsma and Krzysztof R. Apt", "title": "Common Knowledge in Email Exchanges", "comments": "34 pages. To appear in ACM Transactions on Computational Logic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a framework in which a group of agents communicates by means of\nemails, with the possibility of replies, forwards and blind carbon copies\n(BCC). We study the epistemic consequences of such email exchanges by\nintroducing an appropriate epistemic language and semantics. This allows us to\nfind out what agents learn from the emails they receive and to determine when a\ngroup of agents acquires common knowledge of the fact that an email was sent.\nWe also show that in our framework from the epistemic point of view the BCC\nfeature of emails cannot be simulated using messages without BCC recipients.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 11:52:55 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2012 12:27:56 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Sietsma", "Floor", ""], ["Apt", "Krzysztof R.", ""]]}, {"id": "1109.3370", "submitter": "James Entwood", "authors": "Robert Constable", "title": "Effectively Nonblocking Consensus Procedures Can Execute Forever - a\n  Constructive Version of FLP", "comments": "17 pages, 6 figures, uses pstricks; http://hdl.handle.net/1813/11512", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fischer-Lynch-Paterson theorem (FLP) says that it is impossible for\nprocesses in an asynchronous distributed system to achieve consensus on a\nbinary value when a single process can fail; it is a widely cited theoretical\nresult about network computing. All proofs that I know depend essentially on\nclassical (nonconstructive) logic, although they use the hypothetical\nconstruction of a nonterminating execution as a main lemma.\n  FLP is also a guide for protocol designers, and in that role there is a\nconnection to an important property of consensus procedures, namely that they\nshould not block, i.e. reach a global state in which no process can decide.\n  A deterministic fault-tolerant consensus protocol is effectively nonblocking\nif from any reachable global state we can find an execution path that decides.\nIn this article we effectively construct a nonterminating execution of any such\nprotocol. That is, given any effectively nonblocking protocol P and a natural\nnumber n, we show how to compute the n-th step of an infinitely indecisive\ncomputation of P. From this fully constructive result, the classical FLP\nfollows as a corollary as well as a stronger classical result, called here\nStrong FLP. Moreover, the construction focuses attention on the important role\nof nonblocking in protocol design.\n  An interesting consequence of the constructive proof is that we can, in\nprinciple, build an undefeatable attacker for a consensus protocol that is\nprovably correct, indeed because it is provably correct. We can do this in\npractice on certain kinds of networks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 14:54:07 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Constable", "Robert", ""]]}, {"id": "1109.3685", "submitter": "Ernst-Erich Doberkat", "authors": "Ernst-Erich Doberkat", "title": "Towards a Coalgebraic Interpretation of Propositional Dynamic Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interpretation of propositional dynamic logic (PDL) through Kripke models\nrequires the relations constituting the interpreting Kripke model to closely\nobserve the syntax of the modal operators. This poses a significant challenge\nfor an interpretation of PDL through stochastic Kripke models, because the\nprograms' operations do not always have a natural counterpart in the set of\nstochastic relations. We use rewrite rules for building up an interpretation of\nPDL. It is shown that each program corresponds to an essentially unique\nirreducible tree, which in turn is assigned a predicate lifting, serving as the\nprogram's interpretation. The paper establishes and studies this\ninterpretation. It discusses the expressivity of probabilistic models for PDL\nand relates properties like logical and behavioral equivalence or bisimilarity\nto the corresponding properties of a Kripke model for a closely related\nnon-dynamic logic of the Hennessy-Milner type.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2011 18:19:36 GMT"}], "update_date": "2011-09-19", "authors_parsed": [["Doberkat", "Ernst-Erich", ""]]}, {"id": "1109.3687", "submitter": "Josef Urban", "authors": "Jesse Alama, Lionel Mamane, Josef Urban", "title": "Dependencies in Formal Mathematics: Applications and Extraction for Coq\n  and Mizar", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two methods for extracting detailed formal dependencies from the Coq and\nMizar system are presented and compared. The methods are used for dependency\nextraction from two large mathematical repositories: the Coq Repository at\nNijmegen and the Mizar Mathematical Library. Several applications of the\ndetailed dependency analysis are described and proposed. Motivated by the\ndifferent applications, we discuss the various kinds of dependencies that we\nare interested in,and the suitability of various dependency extraction methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2011 18:25:18 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2012 19:20:02 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Alama", "Jesse", ""], ["Mamane", "Lionel", ""], ["Urban", "Josef", ""]]}, {"id": "1109.4095", "submitter": "J\\\"org P\\\"uhrer", "authors": "Christian Kloim\\\"ullner, Johannes Oetsch, J\\\"org P\\\"uhrer, and Hans\n  Tompits", "title": "Kara: A System for Visualising and Visual Editing of Interpretations for\n  Answer-Set Programs", "comments": "Proceedings of the 19th International Conference on Applications of\n  Declarative Programming and Knowledge Management (INAP 2011) and 25th\n  Workshop on Logic Programming (WLP 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In answer-set programming (ASP), the solutions of a problem are encoded in\ndedicated models, called answer sets, of a logical theory. These answer sets\nare computed from the program that represents the theory by means of an ASP\nsolver and returned to the user as sets of ground first-order literals. As this\ntype of representation is often cumbersome for the user to interpret, tools\nlike ASPVIZ and IDPDraw were developed that allow for visualising answer sets.\nThe tool Kara, introduced in this paper, follows these approaches, using ASP\nitself as a language for defining visualisations of interpretations. Unlike\nexisting tools that position graphic primitives according to static coordinates\nonly, Kara allows for more high-level specifications, supporting graph\nstructures, grids, and relative positioning of graphical elements. Moreover,\ngeneralising the functionality of previous tools, Kara provides modifiable\nvisualisations such that interpretations can be manipulated by graphically\nediting their visualisations. This is realised by resorting to abductive\nreasoning techniques. Kara is part of SeaLion, a forthcoming integrated\ndevelopment environment (IDE) for ASP.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 17:09:21 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2011 10:03:57 GMT"}], "update_date": "2011-10-12", "authors_parsed": [["Kloim\u00fcllner", "Christian", ""], ["Oetsch", "Johannes", ""], ["P\u00fchrer", "J\u00f6rg", ""], ["Tompits", "Hans", ""]]}, {"id": "1109.4353", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (LIAMA), Claude Kirchner (INRIA Bordeaux\n  Sud-Ouest), Colin Riba (LIP)", "title": "On the confluence of lambda-calculus with conditional rewriting", "comments": null, "journal-ref": "Theoretical Computer Science 411, 37 (2010) 3301-3327", "doi": "10.1016/j.tcs.2009.07.058", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The confluence of untyped \\lambda-calculus with unconditional rewriting is\nnow well un- derstood. In this paper, we investigate the confluence of\n\\lambda-calculus with conditional rewriting and provide general results in two\ndirections. First, when conditional rules are algebraic. This extends results\nof M\\\"uller and Dougherty for unconditional rewriting. Two cases are\nconsidered, whether \\beta-reduction is allowed or not in the evaluation of\nconditions. Moreover, Dougherty's result is improved from the assumption of\nstrongly normalizing \\beta-reduction to weakly normalizing \\beta-reduction. We\nalso provide examples showing that outside these conditions, modularity of\nconfluence is difficult to achieve. Second, we go beyond the algebraic\nframework and get new confluence results using a restricted notion of\northogonality that takes advantage of the conditional part of rewrite rules.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2011 16:56:52 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "LIAMA"], ["Kirchner", "Claude", "", "INRIA Bordeaux\n  Sud-Ouest"], ["Riba", "Colin", "", "LIP"]]}, {"id": "1109.4356", "submitter": "Tom Hirschowitz", "authors": "Tom Hirschowitz (LAMA), Damien Pous (LIG)", "title": "Innocent strategies as presheaves and interactive equivalences for CCS\n  (expanded version)", "comments": "53 pages. Expanded version of ICE '11 paper DOI 10.4204/EPTCS.59.2", "journal-ref": "Scientific Annals of Computer Science 22, 1 (2012) 147-199", "doi": "10.7561/SACS.2012.1.147", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seeking a general framework for reasoning about and comparing programming\nlanguages, we derive a new view of Milner's CCS. We construct a category E of\n'plays', and a subcategory V of 'views'. We argue that presheaves on V\nadequately represent 'innocent' strategies, in the sense of game semantics. We\nequip innocent strategies with a simple notion of interaction. We then prove\ndecomposition results for innocent strategies, and, restricting to presheaves\nof finite ordinals, prove that innocent strategies are a final coalgebra for a\npolynomial functor derived from the game. This leads to a translation of CCS\nwith recursive equations. Finally, we propose a notion of 'interactive\nequivalence' for innocent strategies, which is close in spirit to Beffara's\ninterpretation of testing equivalences in concurrency theory. In this\nframework, we consider analogues of fair testing and must testing. We show that\nmust testing is strictly finer in our model than in CCS, since it avoids what\nwe call 'spatial unfairness'. Still, it differs from fair testing, and we show\nthat it coincides with a relaxed form of fair testing.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2011 16:59:41 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2012 13:03:22 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Hirschowitz", "Tom", "", "LAMA"], ["Pous", "Damien", "", "LIG"]]}, {"id": "1109.4357", "submitter": "Frederic Blanqui", "authors": "Sho Suzuki, Keiichirou Kusakari, Fr\\'ed\\'eric Blanqui (LIAMA)", "title": "Argument filterings and usable rules in higher-order rewrite systems", "comments": null, "journal-ref": "IPSJ Transactions on Programming 4, 2 (2011) 1-12", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The static dependency pair method is a method for proving the termination of\nhigher-order rewrite systems a la Nipkow. It combines the dependency pair\nmethod introduced for first-order rewrite systems with the notion of strong\ncomputability introduced for typed lambda-calculi. Argument filterings and\nusable rules are two important methods of the dependency pair framework used by\ncurrent state-of-the-art first-order automated termination provers. In this\npaper, we extend the class of higher-order systems on which the static\ndependency pair method can be applied. Then, we extend argument filterings and\nusable rules to higher-order rewriting, hence providing the basis for a\npowerful automated termination prover for higher-order rewrite systems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2011 16:59:48 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["Suzuki", "Sho", "", "LIAMA"], ["Kusakari", "Keiichirou", "", "LIAMA"], ["Blanqui", "Fr\u00e9d\u00e9ric", "", "LIAMA"]]}, {"id": "1109.4570", "submitter": "Steffen van Bakel", "authors": "Steffen van Bakel", "title": "Reduction in X does not agree with Intersection and Union Types\n  (Extended abstract)", "comments": "4th International Workshop on Intersection Types and Related Systems\n  (ITRS'08), Turin, Italy, March 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines intersection and union type assignment for the calculus X,\na substitution free language that enjoys the Curry-Howard correspondence with\nrespect to Gentzen's sequent calculus for classical logic. We show that this\nnotion is closed for subject-expansion, and show that it needs to be restricted\nto satisfy subject-reduction as well, making it unsuitable to define a\nsemantics.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2011 16:15:53 GMT"}], "update_date": "2011-09-22", "authors_parsed": [["van Bakel", "Steffen", ""]]}, {"id": "1109.4618", "submitter": "Steffen van Bakel", "authors": "Steffen van Bakel, Reuben N. S. Rowe", "title": "Semantic Predicate Types and Approximation for Class-based Object\n  Oriented Programming", "comments": "Proceedings of 11th Workshop on Formal Techniques for Java-like\n  Programs (FTfJP'09), Genova, Italy, July 6 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the principles of the intersection type discipline to the study of\nclass-based object oriented programs and; our work follows from a similar\napproach (in the context of Abadi and Cardelli's Varsigma-object calculus)\ntaken by van Bakel and de'Liguoro. We define an extension of Featherweight\nJava, FJc and present a predicate system which we show to be sound and\nexpressive. We also show that our system provides a semantic underpinning for\nthe object oriented paradigm by generalising the concept of approximant from\nthe Lambda Calculus and demonstrating an approximation result: all expressions\nto which we can assign a predicate have an approximant that satisfies the same\npredicate. Crucial to this result is the notion of predicate language, which\nassociates a family of predicates with a class.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2011 19:26:52 GMT"}], "update_date": "2011-09-22", "authors_parsed": [["van Bakel", "Steffen", ""], ["Rowe", "Reuben N. S.", ""]]}, {"id": "1109.4623", "submitter": "Fabrizio Angiulli", "authors": "F. Angiulli, R. Ben-Eliyahu-Zohary, L. Palopoli", "title": "Outlier detection in default logics: the tractability/intractability\n  frontier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In default theories, outliers denote sets of literals featuring unexpected\nproperties. In previous papers, we have defined outliers in default logics and\ninvestigated their formal properties. Specifically, we have looked into the\ncomputational complexity of outlier detection problems and proved that while\nthey are generally intractable, interesting tractable cases can be singled out.\nFollowing those results, we study here the tractability frontier in outlier\ndetection problems, by analyzing it with respect to (i) the considered outlier\ndetection problem, (ii) the reference default logic fragment, and (iii) the\nadopted notion of outlier. As for point (i), we shall consider three problems\nof increasing complexity, called Outlier-Witness Recognition, Outlier\nRecognition and Outlier Existence, respectively. As for point (ii), as we look\nfor conditions under which outlier detection can be done efficiently, attention\nwill be limited to subsets of Disjunction-free propositional default theories.\nAs for point (iii), we shall refer to both the notion of outlier of [ABP08] and\na new and more restrictive one, called strong outlier. After complexity\nresults, we present a polynomial time algorithm for enumerating all strong\noutliers of bounded size in an quasi-acyclic normal unary default theory. Some\nof our tractability results rely on the Incremental Lemma that provides\nconditions for a deafult logic fragment to have a monotonic behavior. Finally,\nin order to show that the simple fragments of DL we deal with are still rich\nenough to solve interesting problems and, therefore, the tractability results\nthat we prove are interesting not only on the mere theoretical side, insights\ninto the expressive capabilities of these fragments are provided, by showing\nthat normal unary theories express all NL queries, hereby indirectly answering\na question raised by Kautz and Selman.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2011 19:54:55 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2013 10:56:29 GMT"}], "update_date": "2013-10-31", "authors_parsed": [["Angiulli", "F.", ""], ["Ben-Eliyahu-Zohary", "R.", ""], ["Palopoli", "L.", ""]]}, {"id": "1109.4750", "submitter": "Johannes Ebbing", "authors": "Arnaud Durand, Johannes Ebbing, Juha Kontinen and Heribert Vollmer", "title": "Dependence logic with a majority quantifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the extension of dependence logic D by a majority quantifier M over\nfinite structures. We show that the resulting logic is equi-expressive with the\nextension of second-order logic by second-order majority quantifiers of all\narities. Our results imply that, from the point of view of descriptive\ncomplexity theory, D(M) captures the complexity class counting hierarchy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 09:44:30 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2011 08:41:14 GMT"}, {"version": "v3", "created": "Mon, 26 Sep 2011 13:14:23 GMT"}, {"version": "v4", "created": "Tue, 4 Oct 2011 09:09:22 GMT"}, {"version": "v5", "created": "Mon, 4 Mar 2013 08:31:14 GMT"}, {"version": "v6", "created": "Fri, 8 Mar 2013 14:50:18 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Durand", "Arnaud", ""], ["Ebbing", "Johannes", ""], ["Kontinen", "Juha", ""], ["Vollmer", "Heribert", ""]]}, {"id": "1109.4817", "submitter": "Steffen van Bakel", "authors": "Steffen van Bakel, Luca Cardelli, Maria Grazia Vigliotti", "title": "From X to Pi; Representing the Classical Sequent Calculus in the\n  Pi-calculus", "comments": "International Workshop on Classical Logic and Computation (CL&C'08),\n  Reykjavik, Iceland, July 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Pi-calculus, enriched with pairing and non-blocking input, and\ndefine a notion of type assignment that uses the type constructor \"arrow\". We\nencode the circuits of the calculus X into this variant of Pi, and show that\nall reduction (cut-elimination) and assignable types are preserved. Since X\nenjoys the Curry-Howard isomorphism for Gentzen's calculus LK, this implies\nthat all proofs in LK have a representation in Pi.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 14:05:38 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["van Bakel", "Steffen", ""], ["Cardelli", "Luca", ""], ["Vigliotti", "Maria Grazia", ""]]}, {"id": "1109.4843", "submitter": "Steffen van Bakel", "authors": "Steffen van Bakel, Maria Grazia Vigliotti", "title": "Note on a simple type system for non-interference", "comments": "Nordic Workshop on Programming Theory (NWPT'07), Oslo, October 10-12,\n  2007 Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider CCS with value passing and elaborate a notion of noninterference\nfor the process calculi, which matches closely that of the programming\nlanguage. The idea is to view channels as information carriers rather than as\n\"events\", so that emitting a secret on output channel can be considered safe,\nwhile inputting a secret may lead to some kind of leakage. This is in contrast\nwith the standard notion of noninterference for the process calculi where any\ncausal dependency of low-level action from any high-level action is forbidden.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 15:06:15 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["van Bakel", "Steffen", ""], ["Vigliotti", "Maria Grazia", ""]]}, {"id": "1109.5036", "submitter": "Daniel Kral", "authors": "Zdenek Dvorak and Daniel Kral and Robin Thomas", "title": "Testing first-order properties for subclasses of sparse graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a linear-time algorithm for deciding first-order (FO) properties\nin classes of graphs with bounded expansion, a notion recently introduced by\nNesetril and Ossona de Mendez. This generalizes several results from the\nliterature, because many natural classes of graphs have bounded expansion:\ngraphs of bounded tree-width, all proper minor-closed classes of graphs, graphs\nof bounded degree, graphs with no subgraph isomorphic to a subdivision of a\nfixed graph, and graphs that can be drawn in a fixed surface in such a way that\neach edge crosses at most a constant number of other edges. We deduce that\nthere is an almost linear-time algorithm for deciding FO properties in classes\nof graphs with locally bounded expansion.\n  More generally, we design a dynamic data structure for graphs belonging to a\nfixed class of graphs of bounded expansion. After a linear-time initialization\nthe data structure allows us to test an FO property in constant time, and the\ndata structure can be updated in constant time after addition/deletion of an\nedge, provided the list of possible edges to be added is known in advance and\ntheir simultaneous addition results in a graph in the class. All our results\nalso hold for relational structures and are based on the seminal result of\nNesetril and Ossona de Mendez on the existence of low tree-depth colorings.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 11:30:05 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2013 17:18:57 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Dvorak", "Zdenek", ""], ["Kral", "Daniel", ""], ["Thomas", "Robin", ""]]}, {"id": "1109.5267", "submitter": "Naoki Kobayashi", "authors": "Naoki Kobayashi (Graduate School of Information Sciences, Tohoku\n  University), C.-H. Luke Ong (Oxford University Computing Laboratory)", "title": "Complexity of Model Checking Recursion Schemes for Fragments of the\n  Modal Mu-Calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 4 (January\n  18, 2012) lmcs:1211", "doi": "10.2168/LMCS-7(4:9)2011", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ong has shown that the modal mu-calculus model checking problem\n(equivalently, the alternating parity tree automaton (APT) acceptance problem)\nof possibly-infinite ranked trees generated by order-n recursion schemes is\nn-EXPTIME complete. We consider two subclasses of APT and investigate the\ncomplexity of the respective acceptance problems. The main results are that,\nfor APT with a single priority, the problem is still n-EXPTIME complete;\nwhereas, for APT with a disjunctive transition function, the problem is\n(n-1)-EXPTIME complete. This study was motivated by Kobayashi's recent work\nshowing that the resource usage verification of functional programs can be\nreduced to the model checking of recursion schemes. As an application, we show\nthat the resource usage verification problem is (n-1)-EXPTIME complete.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2011 14:05:50 GMT"}, {"version": "v2", "created": "Tue, 20 Dec 2011 18:20:48 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kobayashi", "Naoki", "", "Graduate School of Information Sciences, Tohoku\n  University"], ["Ong", "C. -H. Luke", "", "Oxford University Computing Laboratory"]]}, {"id": "1109.5468", "submitter": "Frederic Blanqui", "authors": "Keiichirou Kusakari, Yasuo Isogai, Masahiko Sakai, Fr\\'ed\\'eric\n  Blanqui (LIAMA)", "title": "Static Dependency Pair Method based on Strong Computability for\n  Higher-Order Rewrite Systems", "comments": "IEICE Transactions on Information and Systems (2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order rewrite systems (HRSs) and simply-typed term rewriting systems\n(STRSs) are computational models of functional programs. We recently proposed\nan extremely powerful method, the static dependency pair method, which is based\non the notion of strong computability, in order to prove termination in STRSs.\nIn this paper, we extend the method to HRSs. Since HRSs include\n\\lambda-abstraction but STRSs do not, we restructure the static dependency pair\nmethod to allow \\lambda-abstraction, and show that the static dependency pair\nmethod also works well on HRSs without new restrictions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 07:50:07 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Kusakari", "Keiichirou", "", "LIAMA"], ["Isogai", "Yasuo", "", "LIAMA"], ["Sakai", "Masahiko", "", "LIAMA"], ["Blanqui", "Fr\u00e9d\u00e9ric", "", "LIAMA"]]}, {"id": "1109.5506", "submitter": "Cong Tian", "authors": "Cong Tian and Zhenhua Duan", "title": "Detecting Spurious Counterexamples Efficiently in Abstract Model\n  Checking", "comments": "13 pages,6 figures. arXiv admin note: substantial text overlap with\n  arXiv:1007.3569", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction is one of the most important strategies for dealing with the\nstate space explosion problem in model checking. In the abstract model, the\nstate space is largely reduced, however, a counterexample found in such a model\nmay not be a real counterexample in the concrete model. Accordingly, the\nabstract model needs to be further refined. How to check whether or not a\nreported counterexample is spurious is a key problem in the\nabstraction-refinement loop. In this paper, a formal definition for spurious\npath is given. Based on it, efficient algorithms for detecting spurious\ncounterexamples are proposed.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 09:49:05 GMT"}], "update_date": "2011-10-04", "authors_parsed": [["Tian", "Cong", ""], ["Duan", "Zhenhua", ""]]}, {"id": "1109.5522", "submitter": "Robert Mittermayr", "authors": "Robert Mittermayr and Johann Blieberger", "title": "Shared Memory Concurrent System Verification using Kronecker Algebra", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": "183/1-155", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The verification of multithreaded software is still a challenge. This comes\nmainly from the fact that the number of thread interleavings grows\nexponentially in the number of threads. The idea that thread interleavings can\nbe studied with a matrix calculus is a novel approach in this research area.\nOur sparse matrix representations of the program are manipulated using a lazy\nimplementation of Kronecker algebra. One goal is the generation of a data\nstructure called Concurrent Program Graph (CPG) which describes all possible\ninterleavings and incorporates synchronization while preserving completeness.\nWe prove that CPGs in general can be represented by sparse adjacency matrices.\nThus the number of entries in the matrices is linear in their number of lines.\nHence efficient algorithms can be applied to CPGs. In addition, due to\nsynchronization only very small parts of the resulting matrix are actually\nneeded, whereas the rest is unreachable in terms of automata. Thanks to the\nlazy implementation of the matrix operations the unreachable parts are never\ncalculated. This speeds up processing significantly and shows that this\napproach is very promising. Various applications including data flow analysis\ncan be performed on CPGs. Furthermore, the structure of the matrices can be\nused to prove properties of the underlying program for an arbitrary number of\nthreads. For example, deadlock freedom is proved for a large class of programs.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 11:23:04 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Mittermayr", "Robert", ""], ["Blieberger", "Johann", ""]]}, {"id": "1109.5526", "submitter": "Alexander Shen", "authors": "Alexander Shen", "title": "Are random axioms useful?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The famous G\\\"odel incompleteness theorem says that for every sufficiently\nrich formal theory (containing formal arithmetic in some natural sense) there\nexist true unprovable statements. Such statements would be natural candidates\nfor being added as axioms, but where can we obtain them? One classical (and\nwell studied) approach is to add (to some theory T) an axiom that claims the\nconsistency of T. In this note we discuss the other one (motivated by Chaitin's\nversion of the G\\\"odel theorem) and show that it is not really useful (in the\nsense that it does not help us to prove new interesting theorems), at least if\nwe are not limiting the proof complexity. We discuss also some related\nquestions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 11:35:14 GMT"}, {"version": "v2", "created": "Sun, 16 Oct 2011 10:48:36 GMT"}], "update_date": "2011-10-18", "authors_parsed": [["Shen", "Alexander", ""]]}, {"id": "1109.5542", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic", "title": "Gaming security by obscurity", "comments": "15 pages, 9 figures, 2 tables; final version appeared in the\n  Proceedings of New Security Paradigms Workshop 2011 (ACM 2011); typos\n  corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shannon sought security against the attacker with unlimited computational\npowers: *if an information source conveys some information, then Shannon's\nattacker will surely extract that information*. Diffie and Hellman refined\nShannon's attacker model by taking into account the fact that the real\nattackers are computationally limited. This idea became one of the greatest new\nparadigms in computer science, and led to modern cryptography.\n  Shannon also sought security against the attacker with unlimited logical and\nobservational powers, expressed through the maxim that \"the enemy knows the\nsystem\". This view is still endorsed in cryptography. The popular formulation,\ngoing back to Kerckhoffs, is that \"there is no security by obscurity\", meaning\nthat the algorithms cannot be kept obscured from the attacker, and that\nsecurity should only rely upon the secret keys. In fact, modern cryptography\ngoes even further than Shannon or Kerckhoffs in tacitly assuming that *if there\nis an algorithm that can break the system, then the attacker will surely find\nthat algorithm*. The attacker is not viewed as an omnipotent computer any more,\nbut he is still construed as an omnipotent programmer.\n  So the Diffie-Hellman step from unlimited to limited computational powers has\nnot been extended into a step from unlimited to limited logical or programming\npowers. Is the assumption that all feasible algorithms will eventually be\ndiscovered and implemented really different from the assumption that everything\nthat is computable will eventually be computed? The present paper explores some\nways to refine the current models of the attacker, and of the defender, by\ntaking into account their limited logical and programming powers. If the\nadaptive attacker actively queries the system to seek out its vulnerabilities,\ncan the system gain some security by actively learning attacker's methods, and\nadapting to them?\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 12:38:43 GMT"}, {"version": "v2", "created": "Sat, 29 Oct 2011 13:29:11 GMT"}, {"version": "v3", "created": "Wed, 2 Nov 2011 18:45:19 GMT"}, {"version": "v4", "created": "Sun, 16 Sep 2012 15:09:14 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Pavlovic", "Dusko", ""]]}, {"id": "1109.5804", "submitter": "Petr Hlin\\v{e}n\\'y", "authors": "Robert Ganian and Petr Hlin\\v{e}n\\'y and Alexander Langer and Jan\n  Obdr\\v{z}\\'alek and Peter Rossmanith and Somnath Sikdar", "title": "Lower Bounds on the Complexity of MSO1 Model-Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important algorithmic meta-theorems is a famous result by\nCourcelle, which states that any graph problem definable in monadic\nsecond-order logic with edge-set quantifications (i.e., MSO2 model-checking) is\ndecidable in linear time on any class of graphs of bounded tree-width.\nRecently, Kreutzer and Tazari proved a corresponding complexity lower-bound -\nthat MSO2 model-checking is not even in XP wrt. the formula size as parameter\nfor graph classes that are subgraph-closed and whose tree-width is\npoly-logarithmically unbounded. Of course, this is not an unconditional result\nbut holds modulo a certain complexity-theoretic assumption, namely, the\nExponential Time Hypothesis (ETH).\n  In this paper we present a closely related result. We show that even MSO1\nmodel-checking with a fixed set of vertex labels, but without edge-set\nquantifications, is not in XP wrt. the formula size as parameter for graph\nclasses which are subgraph-closed and whose tree-width is poly-logarithmically\nunbounded unless the non-uniform ETH fails. In comparison to Kreutzer and\nTazari; $(1)$ we use a stronger prerequisite, namely non-uniform instead of\nuniform ETH, to avoid the effectiveness assumption and the construction of\ncertain obstructions used in their proofs; and $(2)$ we assume a different set\nof problems to be efficiently decidable, namely MSO1-definable properties on\nvertex labeled graphs instead of MSO2-definable properties on unlabeled graphs.\n  Our result has an interesting consequence in the realm of digraph width\nmeasures: Strengthening the recent result, we show that no subdigraph-monotone\nmeasure can be \"algorithmically useful\", unless it is within a poly-logarithmic\nfactor of undirected tree-width.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2011 08:45:10 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2012 21:20:13 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Ganian", "Robert", ""], ["Hlin\u011bn\u00fd", "Petr", ""], ["Langer", "Alexander", ""], ["Obdr\u017e\u00e1lek", "Jan", ""], ["Rossmanith", "Peter", ""], ["Sikdar", "Somnath", ""]]}, {"id": "1109.6273", "submitter": "Robert Simmons", "authors": "Robert J. Simmons", "title": "Structural focalization", "comments": "A Twelf formalization is included and an Agda formalization is\n  available at https://github.com/robsimmons/agda-lib/tree/focalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Focusing, introduced by Jean-Marc Andreoli in the context of classical linear\nlogic, defines a normal form for sequent calculus derivations that cuts down on\nthe number of possible derivations by eagerly applying invertible rules and\ngrouping sequences of non-invertible rules. A focused sequent calculus is\ndefined relative to some non-focused sequent calculus; focalization is the\nproperty that every non-focused derivation can be transformed into a focused\nderivation.\n  In this paper, we present a focused sequent calculus for propositional\nintuitionistic logic and prove the focalization property relative to a standard\npresentation of propositional intuitionistic logic. Compared to existing\napproaches, the proof is quite concise, depending only on the internal\nsoundness and completeness of the focused logic. In turn, both of these\nproperties can be established (and mechanically verified) by structural\ninduction in the style of Pfenning's structural cut elimination without the\nneed for any tedious and repetitious invertibility lemmas. The proof of cut\nadmissibility for the focused system, which establishes internal soundness, is\nnot particularly novel. The proof of identity expansion, which establishes\ninternal completeness, is a major contribution of this work.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2011 17:01:11 GMT"}, {"version": "v2", "created": "Sat, 7 Jan 2012 23:52:03 GMT"}, {"version": "v3", "created": "Sat, 14 Jan 2012 00:57:07 GMT"}, {"version": "v4", "created": "Mon, 13 Aug 2012 21:02:09 GMT"}, {"version": "v5", "created": "Thu, 18 Apr 2013 17:19:51 GMT"}, {"version": "v6", "created": "Mon, 6 Jan 2014 01:24:16 GMT"}, {"version": "v7", "created": "Mon, 17 Mar 2014 01:00:51 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Simmons", "Robert J.", ""]]}, {"id": "1109.6401", "submitter": "Frederic Dambreville", "authors": "Frederic Dambreville (ENSIETA)", "title": "An Interpretation of Belief Functions by means of a Probabilistic\n  Multi-modal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While belief functions may be seen formally as a generalization of\nprobabilistic distributions, the question of the interactions between belief\nfunctions and probability is still an issue in practice. This question is\ndifficult, since the contexts of use of these theory are notably different and\nthe semantics behind these theories are not exactly the same. A prominent issue\nis increasingly regarded by the community, that is the management of the\nconflicting information. Recent works have introduced new rules for handling\nthe conflict redistribution while combining belief functions. The notion of\nconflict, or its cancellation by an hypothesis of open world, seems by itself\nto prevent a direct interpretation of belief function in a probabilistic\nframework. This paper addresses the question of a probabilistic interpretation\nof belief functions. It first introduces and implements a theoretically\ngrounded rule, which is in essence an adaptive conjunctive rule. It is shown,\nhow this rule is derived from a logical interpretation of the belief functions\nby means of a probabilistic multimodal logic; in addition, a concept of source\nindependence is introduced, based on a principle of entropy maximization.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 05:24:51 GMT"}], "update_date": "2011-10-03", "authors_parsed": [["Dambreville", "Frederic", "", "ENSIETA"]]}, {"id": "1109.6402", "submitter": "Frederic Dambreville", "authors": "Frederic Dambreville (ENSIETA)", "title": "Extension of Boolean algebra by a Bayesian operator; application to the\n  definition of a Deterministic Bayesian Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work contributes to the domains of Boolean algebra and of Bayesian\nprobability, by proposing an algebraic extension of Boolean algebras, which\nimplements an operator for the Bayesian conditional inference and is closed\nunder this operator. It is known since the work of Lewis (Lewis' triviality)\nthat it is not possible to construct such conditional operator within the space\nof events. Nevertheless, this work proposes an answer which complements Lewis'\ntriviality, by the construction of a conditional operator outside the space of\nevents, thus resulting in an algebraic extension. In particular, it is proved\nthat any probability defined on a Boolean algebra may be extended to its\nalgebraic extension in compliance with the multiplicative definition of the\nconditional probability. In the last part of this paper, a new bivalent logic\nis introduced on the basis of this algebraic extension, and basic properties\nare derived.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 05:25:40 GMT"}, {"version": "v2", "created": "Thu, 15 Dec 2011 09:33:02 GMT"}], "update_date": "2011-12-19", "authors_parsed": [["Dambreville", "Frederic", "", "ENSIETA"]]}, {"id": "1109.6761", "submitter": "Catuscia Palamidessi", "authors": "M\\'ario S. Alvim (INRIA Saclay - Ile de France), Miguel E. Andr\\'es\n  (INRIA Saclay - Ile de France), Konstantinos Chatzikokolakis (INRIA Saclay -\n  Ile de France), Catuscia Palamidessi (INRIA Saclay - Ile de France)", "title": "On the relation between Differential Privacy and Quantitative\n  Information Flow", "comments": null, "journal-ref": "38th International Colloquium on Automata, Languages and\n  Programming - ICALP 2011 6756 (2011) 60-76", "doi": "10.1007/978-3-642-22012-8_4", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a notion that has emerged in the community of\nstatistical databases, as a response to the problem of protecting the privacy\nof the database's participants when performing statistical queries. The idea is\nthat a randomized query satisfies differential privacy if the likelihood of\nobtaining a certain answer for a database $x$ is not too different from the\nlikelihood of obtaining the same answer on adjacent databases, i.e. databases\nwhich differ from $x$ for only one individual. Information flow is an area of\nSecurity concerned with the problem of controlling the leakage of confidential\ninformation in programs and protocols. Nowadays, one of the most established\napproaches to quantify and to reason about leakage is based on the R\\'enyi min\nentropy version of information theory. In this paper, we analyze critically the\nnotion of differential privacy in light of the conceptual framework provided by\nthe R\\'enyi min information theory. We show that there is a close relation\nbetween differential privacy and leakage, due to the graph symmetries induced\nby the adjacency relation. Furthermore, we consider the utility of the\nrandomized answer, which measures its expected degree of accuracy. We focus on\ncertain kinds of utility functions called \"binary\", which have a close\ncorrespondence with the R\\'enyi min mutual information. Again, it turns out\nthat there can be a tight correspondence between differential privacy and\nutility, depending on the symmetries induced by the adjacency relation and by\nthe query. Depending on these symmetries we can also build an optimal-utility\nrandomization mechanism while preserving the required level of differential\nprivacy. Our main contribution is a study of the kind of structures that can be\ninduced by the adjacency relation and the query, and how to use them to derive\nbounds on the leakage and achieve the optimal utility.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2011 09:09:52 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Alvim", "M\u00e1rio S.", "", "INRIA Saclay - Ile de France"], ["Andr\u00e9s", "Miguel E.", "", "INRIA Saclay - Ile de France"], ["Chatzikokolakis", "Konstantinos", "", "INRIA Saclay -\n  Ile de France"], ["Palamidessi", "Catuscia", "", "INRIA Saclay - Ile de France"]]}]