[{"id": "2102.00329", "submitter": "Li Zhou", "authors": "Li Zhou, Gilles Barthe, Justin Hsu, Mingsheng Ying, Nengkun Yu", "title": "A Quantum Interpretation of Bunched Logic for Quantum Separation Logic", "comments": "52 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model of the substructural logic of Bunched Implications (BI)\nthat is suitable for reasoning about quantum states. In our model, the\nseparating conjunction of BI describes separable quantum states. We develop a\nprogram logic where pre- and post-conditions are BI formulas describing quantum\nstates -- the program logic can be seen as a counterpart of separation logic\nfor imperative quantum programs. We exercise the logic for proving the security\nof quantum one-time pad and secret sharing, and we show how the program logic\ncan be used to discover a flaw in Google Cirq's tutorial on the Variational\nQuantum Algorithm (VQA).\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 22:24:36 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhou", "Li", ""], ["Barthe", "Gilles", ""], ["Hsu", "Justin", ""], ["Ying", "Mingsheng", ""], ["Yu", "Nengkun", ""]]}, {"id": "2102.00453", "submitter": "Alexander Bentkamp", "authors": "Alexander Bentkamp, Jasmin Blanchette, Sophie Tourret, Petar\n  Vukmirovi\\'c, Uwe Waldmann", "title": "Superposition with Lambdas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We designed a superposition calculus for a clausal fragment of extensional\npolymorphic higher-order logic that includes anonymous functions but excludes\nBooleans. The inference rules work on $\\beta\\eta$-equivalence classes of\n$\\lambda$-terms and rely on higher-order unification to achieve refutational\ncompleteness. We implemented the calculus in the Zipperposition prover and\nevaluated it on TPTP and Isabelle benchmarks. The results suggest that\nsuperposition is a suitable basis for higher-order reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 13:53:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bentkamp", "Alexander", ""], ["Blanchette", "Jasmin", ""], ["Tourret", "Sophie", ""], ["Vukmirovi\u0107", "Petar", ""], ["Waldmann", "Uwe", ""]]}, {"id": "2102.00510", "submitter": "Vladimir Zamdzhiev", "authors": "Xiaodong Jia, Bert Lindenhovius, Michael Mislove, Vladimir Zamdzhiev", "title": "Commutative Monads for Probabilistic Programming Languages", "comments": null, "journal-ref": null, "doi": "10.1109/LICS52264.2021.9470611", "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing open problem in the semantics of programming languages\nsupporting probabilistic choice is to find a commutative monad for probability\non the category DCPO. In this paper we present three such monads and a general\nconstruction for finding even more. We show how to use these monads to provide\na sound and adequate denotational semantics for the Probabilistic FixPoint\nCalculus (PFPC) -- a call-by-value simply-typed lambda calculus with\nmixed-variance recursive types, term recursion and probabilistic choice. We\nalso show that in the special case where we consider continuous dcpo's, then\nall three monads coincide with the valuations monad of Jones and we fully\ncharacterise the induced Eilenberg-Moore categories by showing that they are\nall isomorphic to the category of continuous Kegelspitzen of Keimel and\nPlotkin.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 18:26:38 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Jia", "Xiaodong", ""], ["Lindenhovius", "Bert", ""], ["Mislove", "Michael", ""], ["Zamdzhiev", "Vladimir", ""]]}, {"id": "2102.00582", "submitter": "Lewis Hammond", "authors": "Lewis Hammond and Alessandro Abate and Julian Gutierrez and Michael\n  Wooldridge", "title": "Multi-Agent Reinforcement Learning with Temporal Logic Specifications", "comments": "Accepted to the 20th International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning to satisfy temporal logic\nspecifications with a group of agents in an unknown environment, which may\nexhibit probabilistic behaviour. From a learning perspective these\nspecifications provide a rich formal language with which to capture tasks or\nobjectives, while from a logic and automated verification perspective the\nintroduction of learning capabilities allows for practical applications in\nlarge, stochastic, unknown environments. The existing work in this area is,\nhowever, limited. Of the frameworks that consider full linear temporal logic or\nhave correctness guarantees, all methods thus far consider only the case of a\nsingle temporal logic specification and a single agent. In order to overcome\nthis limitation, we develop the first multi-agent reinforcement learning\ntechnique for temporal logic specifications, which is also novel in its ability\nto handle multiple specifications. We provide correctness and convergence\nguarantees for our main algorithm - ALMANAC (Automaton/Logic Multi-Agent\nNatural Actor-Critic) - even when using function approximation. Alongside our\ntheoretical results, we further demonstrate the applicability of our technique\nvia a set of preliminary experiments.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 01:13:03 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 18:57:49 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hammond", "Lewis", ""], ["Abate", "Alessandro", ""], ["Gutierrez", "Julian", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2102.00865", "submitter": "Mariangiola Dezani", "authors": "Ilaria Castellani (INDES, Inria, UCA), Mariangiola Dezani-Ciancaglini\n  (UNITO), Paola Giannini", "title": "Global types and event structure semantics for asynchronous multiparty\n  sessions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an interpretation of multiparty sessions with asynchronous\ncommunication as Flow Event Structures. We introduce a new notion of global\ntype for asynchronous multiparty sessions, ensuring the expected properties for\nsessions, including progress. Our global types, which reflect asynchrony more\ndirectly than standard global types and are more permissive, are themselves\ninterpreted as Prime Event Structures. The main result is that the Event\nStructure interpretation of a session is equivalent, when the session is\ntypable, to the Event Structure interpretation of its global type.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 14:17:38 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 15:59:50 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Castellani", "Ilaria", "", "INDES, Inria, UCA"], ["Dezani-Ciancaglini", "Mariangiola", "", "UNITO"], ["Giannini", "Paola", ""]]}, {"id": "2102.00876", "submitter": "Nathana\\\"el Fijalkow", "authors": "Nathana\\\"el Fijalkow and Guillaume Lagarde", "title": "The Complexity of Learning Linear Temporal Formulas from Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we initiate the study of the computational complexity of\nlearning linear temporal logic (LTL) formulas from examples. We construct\napproximation algorithms for fragments of LTL and prove hardness results; in\nparticular we obtain tight bounds for approximation of the fragment containing\nonly the next operator and conjunctions, and prove NP-completeness results for\nmany fragments.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 14:34:46 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", ""], ["Lagarde", "Guillaume", ""]]}, {"id": "2102.00905", "submitter": "Benno van den Berg", "authors": "Benno van den Berg and Martijn den Besten", "title": "Quadratic type checking for objective type theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a modification of standard Martin-Lof type theory in which we\neliminate definitional equality and replace all computation rules by\npropositional equalities. We show that type checking for such a system can be\ndone in quadratic time and that it has a natural homotopy-theoretic semantics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:28:35 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Berg", "Benno van den", ""], ["Besten", "Martijn den", ""]]}, {"id": "2102.01167", "submitter": "Karl Crary", "authors": "Karl Crary", "title": "Verifying the Hashgraph Consensus Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": "CMU-CS-21-102", "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hashgraph consensus algorithm is an algorithm for asynchronous Byzantine\nfault tolerance intended for distributed shared ledgers. Its main\ndistinguishing characteristic is it achieves consensus without exchanging any\nextra messages; each participant's votes can be determined from public\ninformation, so votes need not be transmitted.\n  In this paper, we discuss our experience formalizing the Hashgraph algorithm\nand its correctness proof using the Coq proof assistant. The paper is\nself-contained; it includes a complete discussion of the algorithm and its\ncorrectness argument in English.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 21:09:23 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Crary", "Karl", ""]]}, {"id": "2102.01440", "submitter": "Ruben Lapauw", "authors": "Ruben Lapauw, Maurice Bruynooghe, Marc Denecker", "title": "Justifications and a Reconstruction of Parity Game Solving Algorithms", "comments": "16 pages, to appear in \"LNCS Honorary Volume for Manuel Hermenegildo\"\n  [AVERTIS 2019]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parity games are infinite two-player games played on directed graphs. Parity\ngame solvers are used in the domain of formal verification. This paper defines\nparametrized parity games and introduces an operation, Justify, that determines\na winning strategy for a single node. By carefully ordering Justify steps, we\nreconstruct three algorithms well known from the literature.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 11:25:12 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lapauw", "Ruben", ""], ["Bruynooghe", "Maurice", ""], ["Denecker", "Marc", ""]]}, {"id": "2102.01727", "submitter": "Reed Oei", "authors": "Reed Oei, Dun Ma, Christian Schulz, and Philipp Hieronymi", "title": "Pecan: An Automated Theorem Prover for Automatic Sequences using B\\\"uchi\n  Automata", "comments": "Working draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pecan is an automated theorem prover for reasoning about properties of\nSturmian words, an important object in the field of combinatorics on words. It\nis capable of efficiently proving non-trivial mathematical theorems about all\nSturmian words.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 19:49:04 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Oei", "Reed", ""], ["Ma", "Dun", ""], ["Schulz", "Christian", ""], ["Hieronymi", "Philipp", ""]]}, {"id": "2102.01904", "submitter": "Alexey Ignatiev", "authors": "Alexey Ignatiev, Edward Lam, Peter J. Stuckey, and Joao Marques-Silva", "title": "A Scalable Two Stage Approach to Computing Optimal Decision Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is ubiquitous in modern life. Since it is being\ndeployed in technologies that affect our privacy and safety, it is often\ncrucial to understand the reasoning behind its decisions, warranting the need\nfor explainable AI. Rule-based models, such as decision trees, decision lists,\nand decision sets, are conventionally deemed to be the most interpretable.\nRecent work uses propositional satisfiability (SAT) solving (and its\noptimization variants) to generate minimum-size decision sets. Motivated by\nlimited practical scalability of these earlier methods, this paper proposes a\nnovel approach to learn minimum-size decision sets by enumerating individual\nrules of the target decision set independently of each other, and then solving\na set cover problem to select a subset of rules. The approach makes use of\nmodern maximum satisfiability and integer linear programming technologies.\nExperiments on a wide range of publicly available datasets demonstrate the\nadvantage of the new approach over the state of the art in SAT-based decision\nset learning.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 06:51:49 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Ignatiev", "Alexey", ""], ["Lam", "Edward", ""], ["Stuckey", "Peter J.", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "2102.01969", "submitter": "Rasmus M{\\o}gelberg", "authors": "Magnus Baunsgaard Kristensen, Rasmus Ejlers M{\\o}gelberg and Andrea\n  Vezzosi", "title": "A model of Clocked Cubical Type Theory", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Guarded recursion is a powerful modal approach to recursion that can be seen\nas an abstract form of step-indexing. It is currently used extensively in\nseparation logic to model programming languages with advanced features by\nsolving domain equations also with negative occurrences. In its multi-clocked\nversion, guarded recursion can also be used to program with and reason about\ncoinductive types, encoding the productivity condition required for recursive\ndefinitions in types.\n  This paper presents the first denotational model of a type theory combining\nmulti-clocked guarded recursion with the features of Cubical Type Theory. Using\nthe combination of Higher Inductive Types (HITs) and guarded recursion allows\nfor simple programming and reasoning about coinductive types that are\ntraditionally hard to represent in type theory, such as the type of finitely\nbranching labelled transition systems. For example, our results imply that\nbisimilarity for these imply path equality, and so proofs can be transported\nalong bisimilarity proofs.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:41:14 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Kristensen", "Magnus Baunsgaard", ""], ["M\u00f8gelberg", "Rasmus Ejlers", ""], ["Vezzosi", "Andrea", ""]]}, {"id": "2102.02364", "submitter": "EPTCS", "authors": "Nicolas Behr (Universit\\'e de Paris, CNRS, IRIF)", "title": "On Stochastic Rewriting and Combinatorics via Rule-Algebraic Methods", "comments": "In Proceedings TERMGRAPH 2020, arXiv:2102.01804", "journal-ref": "EPTCS 334, 2021, pp. 11-28", "doi": "10.4204/EPTCS.334.2", "report-no": null, "categories": "cs.LO cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building upon the rule-algebraic stochastic mechanics framework, we present\nnew results on the relationship of stochastic rewriting systems described in\nterms of continuous-time Markov chains, their embedded discrete-time Markov\nchains and certain types of generating function expressions in combinatorics.\nWe introduce a number of generating function techniques that permit a novel\nform of static analysis for rewriting systems based upon marginalizing\ndistributions over the states of the rewriting systems via pattern-counting\nobservables.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 01:41:41 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Behr", "Nicolas", "", "Universit\u00e9 de Paris, CNRS, IRIF"]]}, {"id": "2102.02366", "submitter": "EPTCS", "authors": "Thierry Boy de la Tour", "title": "Parallel Independence in Attributed Graph Rewriting", "comments": "In Proceedings TERMGRAPH 2020, arXiv:2102.01804", "journal-ref": "EPTCS 334, 2021, pp. 62-77", "doi": "10.4204/EPTCS.334.5", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to define graph transformations by the simultaneous application of\nconcurrent rules, we have adopted in previous work a structure of attributed\ngraphs stable by unions. We analyze the consequences on parallel independence,\na property that characterizes the possibility to resort to sequential\nrewriting. This property turns out to depend not only on the left-hand side of\nrules, as in algebraic approaches to graph rewriting, but also on their\nright-hand side. It is then shown that, of three possible definitions of\nparallel rewriting, only one is convenient in the light of parallel\nindependence.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 01:42:34 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["de la Tour", "Thierry Boy", ""]]}, {"id": "2102.02576", "submitter": "Tom Hanika", "authors": "Tom Hanika and Johannes Hirth", "title": "Exploring Scale-Measures of Data Sets", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measurement is a fundamental building block of numerous scientific models and\ntheir creation. This is in particular true for data driven science. Due to the\nhigh complexity and size of modern data sets, the necessity for the development\nof understandable and efficient scaling methods is at hand. A profound theory\nfor scaling data is scale-measures, as developed in the field of formal concept\nanalysis. Recent developments indicate that the set of all scale-measures for a\ngiven data set constitutes a lattice and does hence allow efficient exploring\nalgorithms. In this work we study the properties of said lattice and propose a\nnovel scale-measure exploration algorithm that is based on the well-known and\nproven attribute exploration approach. Our results motivate multiple\napplications in scale recommendation, most prominently (semi-)automatic\nscaling.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 12:29:15 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Hanika", "Tom", ""], ["Hirth", "Johannes", ""]]}, {"id": "2102.02600", "submitter": "Filippo Alberto Edoardo Nuccio Mortarino Majno di Capriglio", "authors": "Anne Baanen and Sander R. Dahmen and Ashvni Narayanan and Filippo A.\n  E. Nuccio", "title": "A formalization of Dedekind domains and class groups of global fields", "comments": "To appear in the Leibniz International Proceedings in Informatics -\n  Conference Interactive Theorem Proving 2021 (Rome, Italy)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.NT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dedekind domains and their class groups are notions in commutative algebra\nthat are essential in algebraic number theory. We formalized these structures\nand several fundamental properties, including number theoretic finiteness\nresults for class groups, in the Lean prover as part of the mathlib\nmathematical library. This paper describes the formalization process, noting\nthe idioms we found useful in our development and mathlib's decentralized\ncollaboration processes involved in this project.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 13:29:33 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 18:52:51 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Baanen", "Anne", ""], ["Dahmen", "Sander R.", ""], ["Narayanan", "Ashvni", ""], ["Nuccio", "Filippo A. E.", ""]]}, {"id": "2102.02627", "submitter": "Marco Peressotti", "authors": "Lu\\'is Cruz-Filipe and Fabrizio Montesi, and Marco Peressotti", "title": "Formalising a Turing-Complete Choreographic Language in Coq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theory of choreographic languages typically includes a number of complex\nresults that are proved by structural induction. The high number of cases and\nthe subtle details in some of them lead to long reviewing processes, and\noccasionally to errors being found in published proofs. In this work, we take a\npublished proof of Turing completeness of a choreographic language and\nformalise it in Coq. Our development includes formalising the choreographic\nlanguage and its basic properties, Kleene's theory of partial recursive\nfunctions, the encoding of these functions as choreographies, and proving this\nencoding correct.\n  With this effort, we show that theorem proving can be a very useful tool in\nthe field of choreographic languages: besides the added degree of confidence\nthat we get from a mechanised proof, the formalisation process led us to a\nsignificant simplification of the underlying theory. Our results offer a\nfoundation for the future formal development of choreographic languages.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 14:25:25 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Cruz-Filipe", "Lu\u00eds", ""], ["Montesi", "Fabrizio", ""], ["Peressotti", "Marco", ""]]}, {"id": "2102.02679", "submitter": "Simon Foster", "authors": "Thomas Hickman, Christian Pardillo Laursen, Simon Foster", "title": "Certifying Differential Equation Solutions from Computer Algebra Systems\n  in Isabelle/HOL", "comments": "15 pages, under consideration for NFM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Isabelle/HOL proof assistant has a powerful library for continuous\nanalysis, which provides the foundation for verification of hybrid systems.\nHowever, Isabelle lacks automated proof support for continuous artifacts, which\nmeans that verification is often manual. In contrast, Computer Algebra Systems\n(CAS), such as Mathematica and SageMath, contain a wealth of efficient\nalgorithms for matrices, differential equations, and other related artifacts.\nNevertheless, these algorithms are not verified, and thus their outputs cannot,\nof themselves, be trusted for use in a safety critical system. In this paper we\nintegrate two CAS systems into Isabelle, with the aim of certifying symbolic\nsolutions to ordinary differential equations. This supports a verification\ntechnique that is both automated and trustworthy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 15:18:11 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Hickman", "Thomas", ""], ["Laursen", "Christian Pardillo", ""], ["Foster", "Simon", ""]]}, {"id": "2102.02990", "submitter": "EPTCS", "authors": "Clemens Grabmayer (Gran Sasso Science Institute, L'Aquila)", "title": "Structure-Constrained Process Graphs for the Process Semantics of\n  Regular Expressions", "comments": "In Proceedings TERMGRAPH 2020, arXiv:2102.01804. A full version of\n  this paper, including the full proof of (P1), can be found at\n  arXiv:2012.10869", "journal-ref": "EPTCS 334, 2021, pp. 29-45", "doi": "10.4204/EPTCS.334.3", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Milner (1984) introduced a process semantics for regular expressions as\nprocess graphs. Unlike for the language semantics, where every regular (that\nis, DFA-accepted) language is the interpretation of some regular expression,\nthere are finite process graphs that are not bisimilar to the process\ninterpretation of any regular expression. For reasoning about graphs that are\nexpressible by regular expressions modulo bisimilarity it is desirable to have\nstructural representations of process graphs in the image of the\ninterpretation.\n  For '1-free' regular expressions, their process interpretations satisfy the\nstructural property LEE (loop existence and elimination). But this is not in\ngeneral the case for all regular expressions, as we show by examples. Yet as a\nremedy, we describe the possibility to recover the property LEE for a close\nvariant of the process interpretation. For this purpose we refine the process\nsemantics of regular expressions to yield process graphs with 1-transitions,\nsimilar to silent moves for finite-state automata.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 04:13:55 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Grabmayer", "Clemens", "", "Gran Sasso Science Institute, L'Aquila"]]}, {"id": "2102.03003", "submitter": "Katherine Cordwell", "authors": "Katherine Cordwell and Yong Kiam Tan and Andr\\'e Platzer", "title": "A Verified Decision Procedure for Univariate Real Arithmetic with the\n  BKR Algorithm", "comments": "ITP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the univariate fragment of Ben-Or, Kozen, and Reif's (BKR)\ndecision procedure for first-order real arithmetic in Isabelle/HOL. BKR's\nalgorithm has good potential for parallelism and was designed to be used in\npractice. Its key insight is a clever recursive procedure that computes the set\nof all consistent sign assignments for an input set of univariate polynomials\nwhile carefully managing intermediate steps to avoid exponential blowup from\nnaively enumerating all possible sign assignments (this insight is fundamental\nfor both the univariate case and the general case). Our proof combines ideas\nfrom BKR and a follow-up work by Renegar that are well-suited for\nformalization. The resulting proof outline allows us to build substantially on\nIsabelle/HOL's libraries for algebra, analysis, and matrices. Our main\nextensions to existing libraries are also detailed.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 05:24:21 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 19:31:48 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Cordwell", "Katherine", ""], ["Tan", "Yong Kiam", ""], ["Platzer", "Andr\u00e9", ""]]}, {"id": "2102.03034", "submitter": "A. Feder Cooper", "authors": "A. Feder Cooper and Yucheng Lu and Jessica Zosa Forde and Christopher\n  De Sa", "title": "Hyperparameter Optimization Is Deceiving Us, and How to Stop It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent empirical work shows that inconsistent results, based on choice of\nhyperparameter optimization (HPO) configuration, are a widespread problem in ML\nresearch. When comparing two algorithms J and K, searching one subspace can\nyield the conclusion that J outperforms K, whereas searching another can entail\nthe opposite. In short, the way we choose hyperparameters can deceive us. We\nprovide a theoretical complement to this prior work, arguing that, to avoid\nsuch deception, the process of drawing conclusions from HPO should be made more\nrigorous. We call this process epistemic hyperparameter optimization (EHPO),\nand put forth a logical framework to capture its semantics and how it can lead\nto inconsistent conclusions about performance. Our framework enables us to\nprove EHPO methods that are guaranteed to be defended against deception. We\ndemonstrate its utility by proving and empirically validating a defended\nvariant of random search.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 07:30:43 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 19:46:14 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 21:41:48 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Cooper", "A. Feder", ""], ["Lu", "Yucheng", ""], ["Forde", "Jessica Zosa", ""], ["De Sa", "Christopher", ""]]}, {"id": "2102.03044", "submitter": "Cl\\'ement Hongler", "authors": "Sylvain Carr\\'e, Franck Gabriel, Cl\\'ement Hongler, Gustavo Lacerda,\n  and Gloria Capano", "title": "Smart Proofs via Smart Contracts: Succinct and Informative Mathematical\n  Derivations via Decentralized Markets", "comments": "45 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CL cs.LO cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern mathematics is built on the idea that proofs should be translatable\ninto formal proofs, whose validity is an objective question, decidable by a\ncomputer. Yet, in practice, proofs are informal and may omit many details. An\nagent considers a proof valid if they trust that it could be expanded into a\nmachine-verifiable proof. A proof's validity can thus become a subjective\nmatter and lead to a debate, which may be difficult to settle. Hence, while the\nconcept of valid proof is well-defined, the process to establish validity is\nitself a complex multi-agent problem.\n  We introduce the SPRIG protocol. SPRIG allows agents to propose and verify\nsuccinct and informative proofs in a decentralized fashion; the trust is\nestablished by agents being able to request more details in the proof steps;\ndebates, if they arise, must isolate details of proofs and, if they persist, go\ndown to machine-level details, where they are automatically settled. A\nstructure of bounties and stakes is set to incentivize agents to act in good\nfaith.\n  We propose a game-theoretic discussion of SPRIG, showing how agents with\nvarious types of information interact, leading to a proof tree with an\nappropriate level of detail and to the invalidation of wrong proofs, and we\ndiscuss resilience against various attacks. We then analyze a simplified model,\ncharacterize its equilibria and compute the agents' level of trust.\n  SPRIG is designed to run as a smart contract on a blockchain platform. This\nallows anonymous agents to participate in the verification debate, and to\ncontribute with their information. The smart contract mediates the\ninteractions, settles debates, and guarantees that bounties and stakes are paid\nas specified.\n  SPRIG enables new applications, such as the issuance of bounties for open\nproblems, and the creation of derivatives markets, allowing agents to inject\nmore information pertaining to proofs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 08:00:19 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 09:17:06 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 15:03:04 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Carr\u00e9", "Sylvain", ""], ["Gabriel", "Franck", ""], ["Hongler", "Cl\u00e9ment", ""], ["Lacerda", "Gustavo", ""], ["Capano", "Gloria", ""]]}, {"id": "2102.03117", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet, Ugo Giocanti, Patrice Ossona de Mendez, Pierre\n  Simon, St\\'ephan Thomass\\'e, Szymon Toru\\'nczyk", "title": "Twin-width IV: ordered graphs and matrices", "comments": "53 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.DM cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a list of characterizations of bounded twin-width for\nhereditary, totally ordered binary structures. This has several consequences.\nFirst, it allows us to show that a (hereditary) class of matrices over a finite\nalphabet either contains at least $n!$ matrices of size $n \\times n$, or at\nmost $c^n$ for some constant $c$. This generalizes the celebrated Stanley-Wilf\nconjecture/Marcus-Tardos theorem from permutation classes to any matrix class\nover a finite alphabet, answers our small conjecture [SODA '21] in the case of\nordered graphs, and with more work, settles a question first asked by Balogh,\nBollob\\'as, and Morris [Eur. J. Comb. '06] on the growth of hereditary classes\nof ordered graphs. Second, it gives a fixed-parameter approximation algorithm\nfor twin-width on ordered graphs. Third, it yields a full classification of\nfixed-parameter tractable first-order model checking on hereditary classes of\nordered binary structures. Fourth, it provides a model-theoretic\ncharacterization of classes with bounded twin-width.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 11:43:59 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 11:05:11 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 19:54:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Giocanti", "Ugo", ""], ["de Mendez", "Patrice Ossona", ""], ["Simon", "Pierre", ""], ["Thomass\u00e9", "St\u00e9phan", ""], ["Toru\u0144czyk", "Szymon", ""]]}, {"id": "2102.03164", "submitter": "EPTCS", "authors": "Graham Campbell (School of Mathematics, Statistics and Physics,\n  Newcastle University, Newcastle upon Tyne, United Kingdom)", "title": "Parallel Hyperedge Replacement String Languages", "comments": "In Proceedings TERMGRAPH 2020, arXiv:2102.01804. arXiv admin note:\n  substantial text overlap with arXiv:2101.02310", "journal-ref": "EPTCS 334, 2021, pp. 46-61", "doi": "10.4204/EPTCS.334.4", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are many open questions surrounding the characterisation of groups with\ncontext-sensitive word problem. Only in 2018 was it shown that all finitely\ngenerated virtually Abelian groups have multiple context-free word problems,\nand it is a long-standing open question as to where to place the word problems\nof hyperbolic groups in the formal language hierarchy. In this paper, we\nintroduce a new language class called the parallel hyperedge replacement string\nlanguages, show that it contains all multiple context-free and ET0L languages,\nand lay down the foundations for future work that may be able to place the word\nproblems of many hyperbolic groups in this class.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 01:42:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Campbell", "Graham", "", "School of Mathematics, Statistics and Physics,\n  Newcastle University, Newcastle upon Tyne, United Kingdom"]]}, {"id": "2102.03510", "submitter": "Yuichi Komorida", "authors": "Yuichi Komorida", "title": "Injective Objects and Fibered Codensity Liftings", "comments": "21 pages, presented in International Workshop on Coalgebraic Methods\n  in Computer Science (CMCS) 2020", "journal-ref": "In: Petri\\c{s}an D., Rot J. (eds) Coalgebraic Methods in Computer\n  Science. CMCS 2020. Lecture Notes in Computer Science, vol 12094. Springer,\n  Cham", "doi": "10.1007/978-3-030-57201-3_7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functor lifting along a fibration is used for several different purposes in\ncomputer science. In the theory of coalgebras, it is used to define coinductive\npredicates, such as simulation preorder and bisimilarity. Codensity lifting is\na scheme to obtain a functor lifting along a fibration. It generalizes a few\nprevious lifting schemes including the Kantorovich lifting. In this paper, we\nseek a property of functor lifting called fiberedness. Hinted by a known result\nfor Kantorovich lifting, we identify a sufficient condition for a codensity\nlifting to be fibered. We see that this condition applies to many examples that\nhave been studied. As an application, we derive some results on\nbisimilarity-like notions.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 04:39:59 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Komorida", "Yuichi", ""]]}, {"id": "2102.03824", "submitter": "Mirco Giacobbe", "authors": "Mirco Giacobbe, Daniel Kroening, Julian Parsert", "title": "Neural Termination Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel approach to the automated termination analysis of\ncomputer programs: we train neural networks to act as ranking functions.\nRanking functions map program states to values that are bounded from below and\ndecrease as the program runs. The existence of a valid ranking function proves\nthat the program terminates. While in the past ranking functions were usually\nconstructed using static analysis, our method learns them from sampled\nexecutions. We train a neural network so that its output decreases along\nexecution traces as a ranking function would; then, we use formal reasoning to\nverify whether it generalises to all possible executions. We present a custom\nloss function for learning lexicographic ranking functions and use\nsatisfiability modulo theories for verification. Thanks to the ability of\nneural networks to generalise well, our method succeeds over a wide variety of\nprograms. This includes programs that use data structures from standard\nlibraries. We built a prototype analyser for Java bytecode and show the\nefficacy of our method over a standard dataset of benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 15:45:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Giacobbe", "Mirco", ""], ["Kroening", "Daniel", ""], ["Parsert", "Julian", ""]]}, {"id": "2102.04011", "submitter": "ShangBei Wang", "authors": "ShangBei Wang", "title": "From Matching Logic To Parallel Imperative Language Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program verification is to develop the program's proof system, and to prove\nthe proof system soundness with respect to a trusted operational semantics of\nthe program. However, many practical program verifiers are not based on\noperational semantics and can't seriously validate the program. Matching logic\nis proposed to make program verification based on operational semantics. In\nthis paper, following Grigore Ro{\\c{s}}u 's work, we consider matching logic\nfor parallel imperative language(PIMP). According to our investigation, this\npaper is the first study on matching logic for PIMP. In our matching logic, we\nredefine \"interference-free\" to character parallel rule and prove the soundness\nof matching logic to the operational semantics of PIMP. We also link PIMP's\noperational semantics and PIMP's verification formally by constructing a\nmatching logic verifier for PIMP which executes rewriting logic semantics\nsymbolically on configuration patterns and is sound and complete to matching\nlogic for PIMP. That is our matching logic verifier for PIMP is sound to the\noperational semantics of PIMP. Finally, we also verify the matching logic\nverifier through an example which is a standard problem in parallel\nprogramming.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 06:01:28 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Wang", "ShangBei", ""]]}, {"id": "2102.04307", "submitter": "Alper Kamil Bozkurt", "authors": "Alper Kamil Bozkurt, Yu Wang, Miroslav Pajic", "title": "Learning Optimal Strategies for Temporal Tasks in Stochastic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear temporal logic (LTL) is widely used to formally specify complex tasks\nfor autonomy. Unlike usual tasks defined by reward functions only, LTL tasks\nare noncumulative and require memory-dependent strategies. In this work, we\nintroduce a method to learn optimal controller strategies that maximize the\nsatisfaction probability of LTL specifications of the desired tasks in\nstochastic games, which are natural extensions of Markov Decision Processes\n(MDPs) to systems with adversarial inputs. Our approach constructs a product\ngame using the deterministic automaton derived from the given LTL task and a\nreward machine based on the acceptance condition of the automaton; thus,\nallowing for the use of a model-free RL algorithm to learn an optimal\ncontroller strategy. Since the rewards and the transition probabilities of the\nreward machine do not depend on the number of sets defining the acceptance\ncondition, our approach is scalable to a wide range of LTL tasks, as we\ndemonstrate on several case studies.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:10:50 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Bozkurt", "Alper Kamil", ""], ["Wang", "Yu", ""], ["Pajic", "Miroslav", ""]]}, {"id": "2102.04361", "submitter": "Daniel Stan", "authors": "Daniel Stan and Anthony Widjaja Lin", "title": "Regular Model Checking Approach to Knowledge Reasoning over\n  Parameterized Systems (technical report)", "comments": "Extended version, version of record accepted at the 20th\n  International Conference on Autonomous Agents and Multiagent Systems\n  (AAMAS-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general framework for modelling and verifying epistemic\nproperties over parameterized multi-agent systems that communicate by truthful\npublic announcements. In our framework, the number of agents or the amount of\ncertain resources are parameterized (i.e. not known a priori), and the\ncorresponding verification problem asks whether a given epistemic property is\ntrue regardless of the instantiation of the parameters. For example, in a muddy\nchildren puzzle, one could ask whether each child will eventually find out\nwhether (s)he is muddy, regardless of the number of children.\n  Our framework is regular model checking (RMC)-based, wherein synchronous\nfinite-state automata (equivalently, monadic second-order logic over words) are\nused to specify the systems. We propose an extension of public announcement\nlogic as specification language. Of special interests is the addition of the\nso-called iterated public announcement operators, which are crucial for\nreasoning about knowledge in parameterized systems. Although the operators make\nthe model checking problem undecidable, we show that this becomes decidable\nwhen an appropriate \"disappearance relation\" is given. Further, we show how\nAngluin's L*-algorithm for learning finite automata can be applied to find a\ndisappearance relation, which is guaranteed to terminate if it is regular. We\nhave implemented the algorithm and apply this to such examples as the Muddy\nChildren Puzzle, the Russian Card Problem, and Large Number Challenge.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 17:10:24 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 21:50:29 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 19:20:12 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Stan", "Daniel", ""], ["Lin", "Anthony Widjaja", ""]]}, {"id": "2102.04386", "submitter": "Cole Comfort", "authors": "Cole Comfort", "title": "Distributive Laws, Spans and the ZX-Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We modularly build increasingly larger fragments of the ZX-calculus by\nmodularly adding new generators and relations, at each point, giving some\nconcrete semantics in terms of some category of spans. This is performed using\nLack's technique of composing props via distributive laws, as well as the\ntechnique of pushout cubes of Zanasi. We do this for the fragment of the\nZX-calculus with only the black $\\pi$-phase (and no Hadamard gate) as well as\nwell as the fragment which additionally has the and gate as a generator (which\nis equivalent to the natural number H-box fragment of the ZH-calculus). In the\nformer case, we show that this is equivalent to the full subcategory of spans\nof (possibly empty) free, finite dimensional affine $\\mathbb F_2$-vector\nspaces, where the objects are the non-empty affine vector spaces. In the latter\ncase, we show that this is equivalent to the full subcategory of spans of\nfinite sets where the objects are powers of the two element set. Because these\nfragments of the ZX-calculus have semantics in terms of full subcategories of\ncategories of spans, they can not be presented by distributive laws over\ngroupoids. Instead, we first construct their subcategories of partial\nisomorphisms via distributive laws over all isomorphims with subobjects\nadjoined. After which, the full subcategory of spans are obtained by freely\nadjoining units and counits the the semi-Frobenius structures given by the\ndiagonal and codiagonal maps.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 17:47:28 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 01:26:59 GMT"}, {"version": "v3", "created": "Sat, 13 Mar 2021 00:32:42 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Comfort", "Cole", ""]]}, {"id": "2102.04672", "submitter": "Christian Williams", "authors": "Christian Williams, Michael Stay", "title": "Native Type Theory", "comments": "12 pages, in review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to construct \"native\" type systems for a broad class of\nlanguages, in which types are built from term constructors by predicate logic\nand dependent types. Many languages can be modelled as structured\nlambda-theories, and the internal language of their presheaf toposes provides\ntotal specification the structure and behavior of programs. The construction is\nfunctorial, thereby providing a shared framework of higher-order reasoning for\nmost existing programming languages.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 06:44:13 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 18:59:41 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Williams", "Christian", ""], ["Stay", "Michael", ""]]}, {"id": "2102.04707", "submitter": "Nikolas M\\\"ahlmann", "authors": "Nikolas M\\\"ahlmann, Sebastian Siebertz, Alexandre Vigny", "title": "Recursive Backdoors for SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A strong backdoor in a formula $\\phi$ of propositional logic to a tractable\nclass $\\mathcal{C}$ of formulas is a set $B$ of variables of $\\phi$ such that\nevery assignment of the variables in $B$ results in a formula from\n$\\mathcal{C}$. Strong backdoors of small size or with a good structure, e.g.\nwith small backdoor treewidth, lead to efficient solutions for the\npropositional satisfiability problem SAT. In this paper we propose the new\nnotion of recursive backdoors, which is inspired by the observation that in\norder to solve SAT we can independently recurse into the components that are\ncreated by partial assignments of variables. The quality of a recursive\nbackdoor is measured by its recursive backdoor depth. Similar to the concept of\nbackdoor treewidth, recursive backdoors of bounded depth include backdoors of\nunbounded size that have a certain treelike structure. However, the two\nconcepts are incomparable and our results yield new tractability results for\nSAT.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 08:53:57 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["M\u00e4hlmann", "Nikolas", ""], ["Siebertz", "Sebastian", ""], ["Vigny", "Alexandre", ""]]}, {"id": "2102.04731", "submitter": "Marco Carbone", "authors": "Marco Carbone, Sonia Marin, Carsten Sch\\\"urmann", "title": "Synchronous Forwarders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session types are types for specifying protocols that processes must follow\nwhen communicating with each other. Session types are in a\npropositions-as-types correspondence with linear logic. Previous work has shown\nthat a multiparty session type, a generalisation of session types to protocols\nof two or more parties, can be modelled as a proof of coherence, a\ngeneralisation of linear logic duality. And, protocols expressed as coherence\ncan be simulated by arbiters, processes that act as a middleware by forwarding\nmessages according to the given protocol. In this paper, we generalise the\nconcept of arbiter to that of synchronous forwarder, that is a processes that\nimplements the behaviour of an arbiter in several different ways. In a\npropositions-as-types fashion, synchronous forwarders form a logic equipped\nwith cut elimination which is a special restriction of classical linear logic.\nOur main result shows that synchronous forwarders are a characterisation of\ncoherence, i.e., coherence proofs can be transformed into synchronous\nforwarders and, viceversa, every synchronous forwarder corresponds to a\ncoherence proofs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 09:51:59 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Carbone", "Marco", ""], ["Marin", "Sonia", ""], ["Sch\u00fcrmann", "Carsten", ""]]}, {"id": "2102.05161", "submitter": "Yann Hamdaoui", "authors": "Yann Hamdaoui and Beno\\^it Valiron", "title": "An Interactive Proof of Termination for a Concurrent $\\lambda$-calculus\n  with References and Explicit Substitutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we introduce a typed, concurrent $\\lambda$-calculus with\nreferences featuring explicit substitutions for variables and references.\nAlongside usual safety properties, we recover strong normalization. The proof\nis based on a reducibility technique and an original interactive property\nreminiscent of the Game Semantics approach.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 22:35:54 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Hamdaoui", "Yann", ""], ["Valiron", "Beno\u00eet", ""]]}, {"id": "2102.05404", "submitter": "S\\'ergio Marcelino", "authors": "S\\'ergio Marcelino", "title": "An unexpected Boolean connective", "comments": "19 pages, Am\\'ilcar Sernadas Logic Prize 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a 2-valued non-deterministic connective $\\wedge \\hskip-5.5pt\n\\vee$ defined by the table resulting from the entry-wise union of the tables of\nconjunction and disjunction. Being half conjunction and half disjunction we\nnamed it platypus. The value of $\\wedge \\hskip-5.5pt \\vee$ is not completely\ndetermined by the input, contrasting with usual notion of Boolean connective.\nWe call non-deterministic Boolean connective any connective based on\nmulti-functions over the Boolean set. In this way, non-determinism allows for\nan extended notion of truth-functional connective. Unexpectedly, this very\nsimple connective and the logic it defines, illustrate various key advantages\nin working with generalized notions of semantics (by incorporating\nnon-determinism), calculi (by allowing multiple-conclusion rules) and even of\nlogic (moving from Tarskian to Scottian consequence relations). We show that\nthe associated logic cannot be characterized by any finite set of finite\nmatrices, whereas with non-determinism two values suffice. Furthermore, this\nlogic is not finitely axiomatizable using single-conclusion rules, however we\nprovide a very simple analytical multiple-conclusion axiomatization using only\ntwo rules. Finally, deciding the associated multiple-conclusion logic is\ncoNP-complete, but deciding its single-conclusion fragment is in P.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 12:36:02 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Marcelino", "S\u00e9rgio", ""]]}, {"id": "2102.05421", "submitter": "S\\'ergio Marcelino", "authors": "S\\'ergio Marcelino and Umberto Rivieccio", "title": "Finite axiomatizability of logics of distributive lattices with negation", "comments": "preprint, 21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on order-preserving logics defined from varieties of\ndistributive lattices with negation, and in particular on the problem of\nwhether these can be axiomatized by means of finite Hilbert calculi. On the\nside of negative results, we provide a syntactic condition on the equational\npresentation of a variety that entails failure of finite axiomatizability for\nthe corresponding logic. An application of this result is that the logic of all\ndistributive lattices with negation is not finitely axiomatizable; likewise, we\nestablish that the order-preserving logic of the variety of all Ockham algebras\nis also not finitely axiomatizable. On the positive side, we show that an\narbitrary subvariety of semi-De Morgan algebras is axiomatized by a finite\nnumber of equations if and only if the corresponding order-preserving logic is\naxiomatized by a finite Hilbert calculus. This equivalence also holds for every\nsubvariety of a Berman variety of Ockham algebras. We obtain, as a corollary, a\nnew proof that the implication-free fragment of intuitionistic logic is\nfinitely axiomatizable, as well as a new Hilbert calculus for it. Our proofs\nare constructive in that they allow us to effectively convert an equational\npresentation of a variety of algebras into a Hilbert calculus for the\ncorresponding order-preserving logic, and vice versa. We also consider the\nassertional logics associated to the above-mentioned varieties, showing in\nparticular that the assertional logics of finitely axiomatizable subvarieties\nof semi-De Morgan algebras are finitely axiomatizable as well.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 13:34:39 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Marcelino", "S\u00e9rgio", ""], ["Rivieccio", "Umberto", ""]]}, {"id": "2102.05422", "submitter": "Maximiliano Cristia", "authors": "Maximiliano Cristi\\'a and Gianfranco Rossi", "title": "Integrating Cardinality Constraints into Constraint Logic Programming\n  with Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Formal reasoning about finite sets and cardinality is an important tool for\nmany applications, including software verification, where very often one needs\nto reason about the size of a given data structure and not only about what its\nelements are. The Constraint Logic Programming tool {log} provides a decision\nprocedure for deciding the satisfiability of formulas involving very general\nforms of finite sets, without cardinality. In this paper we adapt and integrate\na decision procedure for a theory of finite sets with cardinality into {log}.\nThe proposed solver is proved to be a decision procedure for its formulas.\nBesides, the new CLP instance is implemented as part of the {log} tool. In\nturn, the implementation uses Howe and King's Prolog SAT solver and Prolog's\nCLP(Q) library, as an integer linear programming solver. The empirical\nevaluation of this implementation based on +250 real verification conditions\nshows that it can be useful in practice.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 13:38:49 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Cristi\u00e1", "Maximiliano", ""], ["Rossi", "Gianfranco", ""]]}, {"id": "2102.05455", "submitter": "S\\'ergio Marcelino", "authors": "S\\'ergio Marcelino and Umberto Rivieccio", "title": "Logics of involutive Stone algebras", "comments": "preprint, 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An involutive Stone algebra (IS-algebra) is a structure that is\nsimultaneously a De Morgan algebra and a Stone algebra (i.e. a\npseudo-complemented distributive lattice satisfying the well-known Stone\nidentity ~xv~~x=1). IS-algebras have been studied algebraically and\ntopologically since the 1980's, but a corresponding logic (here denoted\nIS$\\leq$) has been introduced only very recently. The logic IS$\\leq$ is the\ndeparting point for the present study, which we then extend to a wide family of\npreviously unknown logics defined from IS-algebras. We show that IS$\\leq$ is a\nconservative expansion of the Belnap-Dunn four-valued logic (i.e. the\norder-preserving logic of the variety of De Morgan algebras), and we give a\nfinite Hilbert-style axiomatization for it. More generally, we introduce a\nmethod for expanding conservatively every super-Belnap logic so as to obtain an\nextension of IS$\\leq$. We show that every logic thus defined can be axiomatized\nby adding a fixed finite set of rule schemata to the corresponding super-Belnap\nbase logic. We also consider a few sample extensions of IS$\\leq$ that cannot be\nobtained in the above-described way, but can nevertheless be axiomatized\nfinitely by other methods. Most of our axiomatization results are obtained in\ntwo steps: through a multiple-conclusion calculus first, which we then reduce\nto a traditional one. The multiple-conclusion axiomatizations introduced in\nthis process, being analytic, are of independent interest from a\nproof-theoretic standpoint. Our results entail that the lattice of super-Belnap\nlogics (which is known to be uncountable) embeds into the lattice of extensions\nof IS$\\leq$. Indeed, as in the super-Belnap case, we establish that the\nfinitary extensions of IS$\\leq$ are already uncountably many.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:22:48 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 15:08:28 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Marcelino", "S\u00e9rgio", ""], ["Rivieccio", "Umberto", ""]]}, {"id": "2102.05473", "submitter": "Erich Gr\\\"adel", "authors": "Erich Gr\\\"adel and Lovro Mrkonji\\'c", "title": "Elementary equivalence versus isomorphism in semiring semantics", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.DB cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the first-order axiomatisability of finite semiring interpretations\nor, equivalently, the question whether elementary equivalence and isomorphism\ncoincide for valuations of atomic facts over a finite universe into a\ncommutative semiring. Contrary to the classical case of Boolean semantics,\nwhere every finite structure can obviously be axiomatised up to isomorphism by\na first-order sentence, the situation in semiring semantics is rather\ndifferent, and strongly depends on the underlying semiring. We prove that for a\nnumber of important semirings, including min-max semirings, and the semirings\nof positive Boolean expressions, there exist finite semiring interpretations\nthat are elementarily equivalent but not isomorphic. The same is true for the\npolynomial semirings that are universal for the classes of absorptive,\nidempotent, and fully idempotent semirings, respectively. On the other side, we\nprove that for other, practically relevant, semirings such as the Viterby\nsemiring, the tropical semiring, the natural semiring and the universal\npolynomial semiring N[X], all finite semiring interpretations are first-order\naxiomatisable (and thus elementary equivalence implies isomorphism), although\nsome of the axiomatisations that we exhibit use an infinite set of axioms.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:00:01 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Gr\u00e4del", "Erich", ""], ["Mrkonji\u0107", "Lovro", ""]]}, {"id": "2102.05547", "submitter": "Jelle Piepenbrock", "authors": "Jelle Piepenbrock, Tom Heskes, Mikol\\'a\\v{s} Janota, Josef Urban", "title": "Learning Equational Theorem Proving", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop Stratified Shortest Solution Imitation Learning (3SIL) to learn\nequational theorem proving in a deep reinforcement learning (RL) setting. The\nself-trained models achieve state-of-the-art performance in proving problems\ngenerated by one of the top open conjectures in quasigroup theory, the Abelian\nInner Mapping (AIM) Conjecture. To develop the methods, we first use two\nsimpler arithmetic rewriting tasks that share tree-structured proof states and\nsparse rewards with the AIM problems. On these tasks, 3SIL is shown to\nsignificantly outperform several established RL and imitation learning methods.\nThe final system is then evaluated in a standalone and cooperative mode on the\nAIM problems. The standalone 3SIL-trained system proves in 60 seconds more\ntheorems (70.2%) than the complex, hand-engineered Waldmeister system (65.5%).\nIn the cooperative mode, the final system is combined with the Prover9 system,\nproving in 2 seconds what standalone Prover9 proves in 60 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:33:07 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Piepenbrock", "Jelle", ""], ["Heskes", "Tom", ""], ["Janota", "Mikol\u00e1\u0161", ""], ["Urban", "Josef", ""]]}, {"id": "2102.05736", "submitter": "Yann Hamdaoui", "authors": "Yann Hamdaoui", "title": "Interpreting a concurrent $\\lambda$-calculus in differential proof nets\n  (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we show how to interpret a language featuring concurrency,\nreferences and replication into proof nets, which correspond to a fragment of\ndifferential linear logic. We prove a simulation and adequacy theorem. A key\nelement in our translation are routing areas, a family of nets used to\nimplement communication primitives which we define and study in detail.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 20:59:04 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Hamdaoui", "Yann", ""]]}, {"id": "2102.05945", "submitter": "Marco Maggesi", "authors": "Marco Maggesi, Cosimo Perini Brogi", "title": "A formal proof of modal completeness for provability logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents a formalized proof of modal completeness for G\\\"odel-L\\\"ob\nprovability logic (GL) in the HOL Light theorem prover. We describe the code we\ndeveloped, and discuss some details of our implementation, focusing on our\nchoices in structuring proofs which make essential use of the tools of HOL\nLight and which differ in part from the standard strategies found in main\ntextbooks covering the topic in an informal setting. Moreover, we propose a\nreflection on our own experience in using this specific theorem prover for this\nformalization task, with an analysis of pros and cons of reasoning within and\nabout the formal system for GL we implemented in our code.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:12:30 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Maggesi", "Marco", ""], ["Brogi", "Cosimo Perini", ""]]}, {"id": "2102.05947", "submitter": "Rineke Verbrugge", "authors": "Rineke Verbrugge", "title": "Zero-one laws for provability logic: Axiomatizing validity in almost all\n  models and almost all frames", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown in the late 1960s that each formula of first-order logic\nwithout constants and function symbols obeys a zero-one law: As the number of\nelements of finite models increases, every formula holds either in almost all\nor in almost no models of that size. Therefore, many properties of models, such\nas having an even number of elements, cannot be expressed in the language of\nfirst-order logic. For modal logics, limit behavior for models and frames may\ndiffer. Halpern and Kapron proved zero-one laws for classes of models\ncorresponding to the modal logics K, T, S4, and S5.\n  In this paper, we prove zero-one laws for provability logic with respect to\nboth model and frame validity. Moreover, we axiomatize validity in almost all\nrelevant finite models and in almost all relevant finite frames, leading to two\ndifferent axiom systems. In the proofs, we use a combinatorial result by\nKleitman and Rothschild about the structure of almost all finite partial\norders. On the way, we also show that a previous result by Halpern and Kapron\nabout the axiomatization of almost sure frame validity for S4 is not correct.\nFinally, we consider the complexity of deciding whether a given formula is\nalmost surely valid in the relevant finite models and frames.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:20:24 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 20:24:10 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Verbrugge", "Rineke", ""]]}, {"id": "2102.05952", "submitter": "Marco Maggesi", "authors": "Gianluca Amato, Marco Maggesi, Cosimo Perini Brogi", "title": "Universal Algebra in UniMath", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present recent updates in our development of a library for Universal\nAlgebra in the UniMath proof assistant. The code here discussed concerns\nmulti-sorted signatures and their algebras, along with the basics for equation\nsystems. Moreover, we give neat constructions of the corresponding univalent\ncategories by using the formalism of displayed categories, and show that the\nterm algebra over a signature is the initial object of the category.\n  Besides the formalization, we reflect on the methodological principles --\nbased on the idea of evaluability of our elementary construction by the\nbuilt-in normalization procedure of the system -- leading our coding style, and\nshow that this path is practicable indeed by sketching simple examples.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:29:53 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Amato", "Gianluca", ""], ["Maggesi", "Marco", ""], ["Brogi", "Cosimo Perini", ""]]}, {"id": "2102.06148", "submitter": "Valentin Goranko", "authors": "Valentin Goranko and Fengkui Ju", "title": "A Logic for Conditional Local Strategic Reasoning", "comments": "21 pages, to appear in the LORI'2019 special issue of the Journal of\n  Logic, Language and Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider systems of rational agents who act and interact in pursuit of\ntheir individual and collective objectives. We study and formalise the\nreasoning of an agent, or of an external observer, about the expected choices\nof action of the other agents based on their objectives, in order to assess the\nreasoner's ability, or expectation, to achieve their own objective.\n  To formalize such reasoning we extend Pauly's Coalition Logic with three new\nmodal operators of conditional strategic reasoning, thus introducing the Logic\nfor Local Conditional Strategic Reasoning ConStR. We provide formal semantics\nfor the new conditional strategic operators in concurrent game models,\nintroduce the matching notion of bisimulation for each of them, prove\nbisimulation invariance and Hennessy-Milner property for each of them, and\ndiscuss and compare briefly their expressiveness. Finally, we also propose\nsystems of axioms for each of the basic operators of ConStR and for the full\nlogic.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 17:45:36 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Goranko", "Valentin", ""], ["Ju", "Fengkui", ""]]}, {"id": "2102.06203", "submitter": "Jesse Han", "authors": "Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W. Ayers, Stanislas\n  Polu", "title": "Proof Artifact Co-training for Theorem Proving with Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Labeled data for imitation learning of theorem proving in large libraries of\nformalized mathematics is scarce as such libraries require years of\nconcentrated effort by human specialists to be built. This is particularly\nchallenging when applying large Transformer language models to tactic\nprediction, because the scaling of performance with respect to model size is\nquickly disrupted in the data-scarce, easily-overfitted regime. We propose PACT\n({\\bf P}roof {\\bf A}rtifact {\\bf C}o-{\\bf T}raining), a general methodology for\nextracting abundant self-supervised data from kernel-level proof terms for\nco-training alongside the usual tactic prediction objective. We apply this\nmethodology to Lean, an interactive proof assistant which hosts some of the\nmost sophisticated formalized mathematics to date. We instrument Lean with a\nneural theorem prover driven by a Transformer language model and show that PACT\nimproves theorem proving success rate on a held-out suite of test theorems from\n32\\% to 48\\%.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:59:24 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Han", "Jesse Michael", ""], ["Rute", "Jason", ""], ["Wu", "Yuhuai", ""], ["Ayers", "Edward W.", ""], ["Polu", "Stanislas", ""]]}, {"id": "2102.06275", "submitter": "Benedikt Ahrens", "authors": "Benedikt Ahrens and Paige Randall North and Michael Shulman and\n  Dimitris Tsementzis", "title": "The Univalence Principle", "comments": "A short version of this book is available as arXiv:2004.06572. v2:\n  added references and some details on morphisms of premonoidal categories", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Univalence Principle is the statement that equivalent mathematical\nstructures are indistinguishable. We prove a general version of this principle\nthat applies to all set-based, categorical, and higher-categorical structures\ndefined in a non-algebraic and space-based style, as well as models of\nhigher-order theories such as topological spaces. In particular, we formulate a\ngeneral definition of indiscernibility for objects of any such structure, and a\ncorresponding univalence condition that generalizes Rezk's completeness\ncondition for Segal spaces and ensures that all equivalences of structures are\nlevelwise equivalences.\n  Our work builds on Makkai's First-Order Logic with Dependent Sorts, but is\nexpressed in Voevodsky's Univalent Foundations (UF), extending previous work on\nthe Structure Identity Principle and univalent categories in UF. This enables\nindistinguishability to be expressed simply as identification, and yields a\nformal theory that is interpretable in classical homotopy theory, but also in\nother higher topos models. It follows that Univalent Foundations is a fully\nequivalence-invariant foundation for higher-categorical mathematics, as\nintended by Voevodsky.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 21:23:38 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 19:33:59 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Ahrens", "Benedikt", ""], ["North", "Paige Randall", ""], ["Shulman", "Michael", ""], ["Tsementzis", "Dimitris", ""]]}, {"id": "2102.06326", "submitter": "Steve Dai", "authors": "Steve Dai, Alicia Klinefelter, Haoxing Ren, Rangharajan Venkatesan,\n  Ben Keller, Nathaniel Pinckney, Brucek Khailany", "title": "Verifying High-Level Latency-Insensitive Designs with Formal Model\n  Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latency-insensitive design mitigates increasing interconnect delay and\nenables productive component reuse in complex digital systems. This design\nstyle has been adopted in high-level design flows because untimed functional\nblocks connected through latency-insensitive interfaces provide a natural\ncommunication abstraction. However, latency-insensitive design with high-level\nlanguages also introduces a unique set of verification challenges that\njeopardize functional correctness. In particular, bugs due to invalid\nconsumption of inputs and deadlocks can be difficult to detect and debug with\ndynamic simulation methods. To tackle these two classes of bugs, we propose\nformal model checking methods to guarantee that a high-level\nlatency-insensitive design is unaffected by invalid input data and is free of\ndeadlock. We develop a well-structured verification wrapper for each property\nto automatically construct the corresponding formal model for checking. Our\nexperiments demonstrate that the formal checks are effective in realistic bug\nscenarios from high-level designs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 01:56:23 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Dai", "Steve", ""], ["Klinefelter", "Alicia", ""], ["Ren", "Haoxing", ""], ["Venkatesan", "Rangharajan", ""], ["Keller", "Ben", ""], ["Pinckney", "Nathaniel", ""], ["Khailany", "Brucek", ""]]}, {"id": "2102.06495", "submitter": "Michael Maher", "authors": "Michael J. Maher", "title": "On Signings and the Well-Founded Semantics", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": "10.1017/S1471068421000077", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this note, we use Kunen's notion of a signing to establish two theorems\nabout the well-founded semantics of logic programs, in the case where we are\ninterested in only (say) the positive literals of a predicate $p$ that are\nconsequences of the program. The first theorem identifies a class of programs\nfor which the well-founded and Fitting semantics coincide for the positive part\nof $p$. The second theorem shows that if a program has a signing then computing\nthe positive part of $p$ under the well-founded semantics requires the\ncomputation of only one part of each predicate. This theorem suggests an\nanalysis for query-answering under the well-founded semantics. In the process\nof proving these results, we use an alternative formulation of the well-founded\nsemantics of logic programs, which might be of independent interest.\n  Under consideration in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 12:55:39 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 04:45:11 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Maher", "Michael J.", ""]]}, {"id": "2102.06513", "submitter": "Meven Lennon-Bertrand", "authors": "Meven Lennon-Bertrand", "title": "Complete Bidirectional Typing for the Calculus of Inductive\n  Constructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article presents a bidirectional type system for the Calculus of\nInductive Constructions (CIC). It introduces a new judgement intermediate\nbetween the usual inference and checking, dubbed constrained inference, to\nhandle the presence of computation in types. The key property of the system is\nits completeness with respect to the usual undirected one, which has been\nformally proven in Coq as a part of the MetaCoq project. Although it plays an\nimportant role in an ongoing completeness proof for a realistic typing\nalgorithm, the interest of bidirectionality is wider, as it gives insights and\nstructure when trying to prove properties on CIC or design variations and\nextensions. In particular, we put forward constrained inference, an\nintermediate between the usual inference and checking judgements, to handle the\npresence of computation in types.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:31:56 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 14:07:43 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lennon-Bertrand", "Meven", ""]]}, {"id": "2102.06532", "submitter": "Logical Methods In Computer Science", "authors": "Jiri Adamek", "title": "Algebraic cocompleteness and finitary functors", "comments": "Accidental duplicate of arXiv:1903.02438", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A number of categories is presented that are algebraically complete and\ncocomplete, i.e., every endofunctor has an initial algebra and a terminal\ncoalgebra. For all finitary (and, more generally, all precontinuous) set\nfunctors the initial algebra and terminal coalgebra are proved to carry a\ncanonical partial order with the same ideal CPO-completion. And they also both\ncarry a canonical ultrametric with the same Cauchy completion.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:50:24 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 07:03:56 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Adamek", "Jiri", ""]]}, {"id": "2102.06585", "submitter": "Jay Morgan", "authors": "Tonicha Crook, Jay Morgan, Arno Pauly and Markus Roggenbach", "title": "A Computability Perspective on (Verified) Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a strong consensus that combining the versatility of machine\nlearning with the assurances given by formal verification is highly desirable.\nIt is much less clear what verified machine learning should mean exactly. We\nconsider this question from the (unexpected?) perspective of computable\nanalysis. This allows us to define the computational tasks underlying verified\nML in a model-agnostic way, and show that they are in principle computable.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 15:47:41 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Crook", "Tonicha", ""], ["Morgan", "Jay", ""], ["Pauly", "Arno", ""], ["Roggenbach", "Markus", ""]]}, {"id": "2102.06590", "submitter": "Diogo Behrens", "authors": "Jonas Oberhauser, Rafael Lourenco de Lima Chehab, Diogo Behrens, Ming\n  Fu, Antonio Paolillo, Lilith Oberhauser, Koustubha Bhat, Yuzhong Wen, Haibo\n  Chen, Jaeho Kim, Viktor Vafeiadis", "title": "VSync: Push-Button Verification and Optimization for Synchronization\n  Primitives on Weak Memory Models (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This technical report contains material accompanying our work with same title\npublished at ASPLOS'21. We start in Sec. 1 with a detailed presentation of the\ncore innovation of this work, Await Model Checking (AMC). The correctness\nproofs of AMC can be found in Sec. 2. Next, we discuss three study cases in\nSec. 3, presenting bugs found and challenges encountered when applying VSync to\nexisting code bases. Finally, in Sec. 4 we describe the setup details of our\nevaluation and report further experimental results.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 16:00:48 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Oberhauser", "Jonas", ""], ["Chehab", "Rafael Lourenco de Lima", ""], ["Behrens", "Diogo", ""], ["Fu", "Ming", ""], ["Paolillo", "Antonio", ""], ["Oberhauser", "Lilith", ""], ["Bhat", "Koustubha", ""], ["Wen", "Yuzhong", ""], ["Chen", "Haibo", ""], ["Kim", "Jaeho", ""], ["Vafeiadis", "Viktor", ""]]}, {"id": "2102.06655", "submitter": "Florian Funke", "authors": "Corto Mascle, Christel Baier, Florian Funke, Simon Jantsch, Stefan\n  Kiefer", "title": "Responsibility and verification: Importance value in temporal logics", "comments": "23 pages, 11 figures, full version of a conference paper accepted at\n  LICS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We aim at measuring the influence of the nondeterministic choices of a part\nof a system on its ability to satisfy a specification. For this purpose, we\napply the concept of Shapley values to verification as a means to evaluate how\nimportant a part of a system is. The importance of a component is measured by\ngiving its control to an adversary, alone or along with other components, and\ntesting whether the system can still fulfill the specification. We study this\nidea in the framework of model-checking with various classical types of\nlinear-time specification, and propose several ways to transpose it to\nbranching ones. We also provide tight complexity bounds in almost every case.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:50:05 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 09:25:28 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Mascle", "Corto", ""], ["Baier", "Christel", ""], ["Funke", "Florian", ""], ["Jantsch", "Simon", ""], ["Kiefer", "Stefan", ""]]}, {"id": "2102.06673", "submitter": "Anupam Das", "authors": "Anupam Das and Avgerinos Delkos", "title": "Proof complexity of positive branching programs", "comments": "31 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the proof complexity of systems based on positive branching\nprograms, i.e. non-deterministic branching programs (NBPs) where, for any\n0-transition between two nodes, there is also a 1-transition. Positive NBPs\ncompute monotone Boolean functions, just like negation-free circuits or\nformulas, but constitute a positive version of (non-uniform) NL, rather than P\nor NC1, respectively.\n  The proof complexity of NBPs was investigated in previous work by Buss, Das\nand Knop, using extension variables to represent the dag-structure, over a\nlanguage of (non-deterministic) decision trees, yielding the system eLNDT. Our\nsystem eLNDT+ is obtained by restricting their systems to a positive syntax,\nsimilarly to how the 'monotone sequent calculus' MLK is obtained from the usual\nsequent calculus LK by restricting to negation-free formulas.\n  Our main result is that eLNDT+ polynomially simulates eLNDT over positive\nsequents. Our proof method is inspired by a similar result for MLK by Atserias,\nGalesi and Pudl\\'ak, that was recently improved to a bona fide polynomial\nsimulation via works of Je\\v{r}\\'abek and Buss, Kabanets, Kolokolova and\nKouck\\'y. Along the way we formalise several properties of counting functions\nwithin eLNDT+ by polynomial-size proofs and, as a case study, give explicit\npolynomial-size poofs of the propositional pigeonhole principle.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 18:16:31 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Das", "Anupam", ""], ["Delkos", "Avgerinos", ""]]}, {"id": "2102.06880", "submitter": "Sebastian Siebertz", "authors": "\\'Edouard Bonnet, Jaroslav Ne\\v{s}et\\v{r}il, Patrice Ossona de Mendez,\n  Sebastian Siebertz, St\\'ephan Thomass\\'e", "title": "Twin-width and permutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inspired by a width invariant defined on permutations by Guillemot and Marx,\nthe twin-width invariant has been recently introduced by Bonnet, Kim,\nThomass\\'e, and Watrigant. We prove that a class of binary relational\nstructures (that is: edge-colored partially directed graphs) has bounded\ntwin-width if and only if it is a first-order transduction of a~proper\npermutation class. As a by-product, it shows that every class with bounded\ntwin-width contains at most $2^{O(n)}$ pairwise non-isomorphic $n$-vertex\ngraphs.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 08:03:17 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 21:48:42 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Ne\u0161et\u0159il", "Jaroslav", ""], ["de Mendez", "Patrice Ossona", ""], ["Siebertz", "Sebastian", ""], ["Thomass\u00e9", "St\u00e9phan", ""]]}, {"id": "2102.06881", "submitter": "Szymon Toru\\'nczyk", "authors": "Pierre Simon and Szymon Toru\\'nczyk", "title": "Ordered graphs of bounded twin-width", "comments": "arXiv admin note: text overlap with arXiv:2102.03117", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider hereditary classes of graphs equipped with a total order. We\nprovide multiple equivalent characterisations of those classes which have\nbounded twin-width. In particular, we prove a grid theorem for classes of\nordered graphs which have unbounded twin-width. From this we derive that the\nmodel-checking problem for first-order logic is fixed-parameter tractable over\na hereditary class of ordered graphs if, and -- under common\ncomplexity-theoretic assumptions -- only if the class has bounded twin-width.\nFor hereditary classes of ordered graphs, we show that bounded twin-width is\nequivalent to the NIP property from model theory, as well as the smallness\ncondition from enumerative combinatorics. We prove the existence of a gap in\nthe growth of hereditary classes of ordered graphs. Furthermore, we provide a\ngrid theorem which applies to all monadically NIP classes of structures\n(ordered or unordered), or equivalently, classes which do not transduce the\nclass of all finite graphs.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 08:03:45 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Simon", "Pierre", ""], ["Toru\u0144czyk", "Szymon", ""]]}, {"id": "2102.06889", "submitter": "Anton\\'in Ku\\v{c}era", "authors": "Michal Ajdar\\'ow, Anton\\'in Ku\\v{c}era", "title": "Deciding Polynomial Termination Complexity for VASS Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that for every fixed $k\\geq 3$, the problem whether the\ntermination/counter complexity of a given demonic VASS is $\\mathcal{O}(n^k)$,\n$\\Omega(n^{k})$, and $\\Theta(n^{k})$ is coNP-complete, NP-complete, and\nDP-complete, respectively. We also classify the complexity of these problems\nfor $k\\leq 2$. This shows that the polynomial-time algorithm designed for\nstrongly connected demonic VASS in previous works cannot be extended to the\ngeneral case. Then, we prove that the same problems for VASS games are\nPSPACE-complete. Again, we classify the complexity also for $k\\leq 2$.\nInterestingly, tractable subclasses of demonic VASS and VASS games are obtained\nby bounding certain structural parameters, which opens the way to applications\nin program analysis despite the presented lower complexity bounds.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 10:03:35 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ajdar\u00f3w", "Michal", ""], ["Ku\u010dera", "Anton\u00edn", ""]]}, {"id": "2102.06928", "submitter": "Beniamino Accattoli", "authors": "Beniamino Accattoli, Andrea Condoluci, Claudio Sacerdoti Coen", "title": "Strong Call-by-Value is Reasonable, Implosively", "comments": "Technical report associated to a LICS 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Whether the number of beta-steps in the lambda-calculus can be taken as a\nreasonable time cost model (that is, polynomially related to the one of Turing\nmachines) is a delicate problem, which depends on the notion of evaluation\nstrategy. Since the nineties, it is known that weak (that is, out of\nabstractions) call-by-value evaluation is a reasonable strategy while L\\'evy's\noptimal parallel strategy, which is strong (that is, it reduces everywhere), is\nnot. The strong case turned out to be subtler than the weak one. In 2014\nAccattoli and Dal Lago have shown that strong call-by-name is reasonable, by\nintroducing a new form of useful sharing and, later, an abstract machine with\nan overhead quadratic in the number of beta-steps.\n  Here we show that also strong call-by-value evaluation is reasonable for\ntime, via a new abstract machine realizing useful sharing and having a linear\noverhead. Moreover, our machine uses a new mix of sharing techniques, adding on\ntop of useful sharing a form of implosive sharing, which on some terms brings\nan exponential speed-up. We give examples of families that the machine executes\nin time logarithmic in the number of beta-steps.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 13:36:45 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 15:31:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Condoluci", "Andrea", ""], ["Coen", "Claudio Sacerdoti", ""]]}, {"id": "2102.07401", "submitter": "\\'Etienne Andr\\'e", "authors": "Masaki Waga, \\'Etienne Andr\\'e, Ichiro Hasuo", "title": "Model-bounded monitoring of hybrid systems", "comments": "This is the author (and slightly extended) version of the manuscript\n  of the same name published in the proceedings of the 12th ACM/IEEE\n  International Conference on Cyber-Physical Systems (ICCPS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.FL cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring of hybrid systems attracts both scientific and practical\nattention. However, monitoring algorithms suffer from the methodological\ndifficulty of only observing sampled discrete-time signals, while real\nbehaviors are continuous-time signals. To mitigate this problem of sampling\nuncertainties, we introduce a model-bounded monitoring scheme, where we use\nprior knowledge about the target system to prune interpolation candidates.\nTechnically, we express such prior knowledge by linear hybrid automata (LHAs) -\nthe LHAs are called bounding models. We introduce a novel notion of monitored\nlanguage of LHAs, and we reduce the monitoring problem to the membership\nproblem of the monitored language. We present two partial algorithms - one is\nvia reduction to reachability in LHAs and the other is a direct one using\npolyhedra - and show that these methods, and thus the proposed model-bounded\nmonitoring scheme, are efficient and practically relevant.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 09:00:02 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Waga", "Masaki", ""], ["Andr\u00e9", "\u00c9tienne", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "2102.07463", "submitter": "S. Akshay", "authors": "S. Akshay and Supratik Chakraborty", "title": "On synthesizing Skolem functions for first order logic formulae", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Skolem functions play a central role in logic, from eliminating quantifiers\nin first order logic formulas to providing functional implementations of\nrelational specifications. While classical results in logic are only interested\nin their existence, the question of how to effectively compute them is also\ninteresting, important and useful for several applications. In the restricted\ncase of Boolean propositional logic formula, this problem of synthesizing\nBoolean Skolem functions has been addressed in depth, with various recent work\nfocussing on both theoretical and practical aspects of the problem. However,\nthere are few existing results for the general case, and the focus has been on\nheuristical algorithms.\n  In this article, we undertake an investigation into the computational\nhardness of the problem of synthesizing Skolem functions for first order logic\nformula. We show that even under reasonable assumptions on the signature of the\nformula, it is impossible to compute or synthesize Skolem functions. Then we\ndetermine conditions on theories of first order logic which would render the\nproblem computable. Finally, we show that several natural theories satisfy\nthese conditions and hence do admit effective synthesis of Skolem functions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 11:20:31 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Akshay", "S.", ""], ["Chakraborty", "Supratik", ""]]}, {"id": "2102.07515", "submitter": "Pierre Vial", "authors": "Pierre Vial", "title": "Sequence Types and Infinitary Semantics", "comments": "78 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new representation of non-idempotent intersection types, using\nsequences (families indexed with natural numbers) instead of lists or\nmultisets. This allows scaling up intersection type theory to the infinitary\nlambda-calculus. We thus characterize hereditary head normalization (Klop's\nProblem) and we give a unique type to all hereditary permutators (TLCA Problem\n#20), which is not possible in a finite system. On our way, we use\nnon-idempotent intersection to retrieve some well-known results on infinitary\nterms. This paper begins with a gentle, high-level introduction to intersection\ntype theory and to the infinitary calculus.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:33:41 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Vial", "Pierre", ""]]}, {"id": "2102.07531", "submitter": "Antoine Mottet", "authors": "Antoine Mottet, Tom\\'a\\v{s} Nagy, Michael Pinsker, Micha{\\l} Wrona", "title": "Smooth Approximations and Relational Width Collapses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We prove that relational structures admitting specific polymorphisms (namely,\ncanonical pseudo-WNU operations of all arities $n \\geq 3$) have low relational\nwidth. This implies a collapse of the bounded width hierarchy for numerous\nclasses of infinite-domain CSPs studied in the literature. Moreover, we obtain\na characterization of bounded width for first-order reducts of unary structures\nand a characterization of MMSNP sentences that are equivalent to a Datalog\nprogram, answering a question posed by Bienvenu, ten Cate, Lutz, and Wolter. In\nparticular, the bounded width hierarchy collapses in those cases as well.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 13:06:45 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Mottet", "Antoine", ""], ["Nagy", "Tom\u00e1\u0161", ""], ["Pinsker", "Michael", ""], ["Wrona", "Micha\u0142", ""]]}, {"id": "2102.07636", "submitter": "Floris van Doorn", "authors": "Floris van Doorn", "title": "Formalized Haar Measure", "comments": "16 pages (excluding references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.FA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe the formalization of the existence and uniqueness of Haar measure\nin the Lean theorem prover. The Haar measure is an invariant regular measure on\nlocally compact groups, and it has not been formalized in a proof assistant\nbefore. We will also discuss the measure theory library in Lean's mathematical\nlibrary \\textsf{mathlib}, and discuss the construction of product measures and\nthe proof of Fubini's theorem for the Bochner integral.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 22:12:52 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["van Doorn", "Floris", ""]]}, {"id": "2102.08109", "submitter": "Luca Reggio", "authors": "Samson Abramsky and Luca Reggio", "title": "Arboreal Categories: An Axiomatic Theory of Resources", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce arboreal categories, which have an intrinsic process structure,\nallowing dynamic notions such as bisimulation and back-and-forth games, and\nresource notions such as number of rounds of a game, to be defined. These are\nrelated to extensional or \"static\" structures via arboreal covers, which are\nresource-indexed comonadic adjunctions. These ideas are developed in a very\ngeneral, axiomatic setting, and applied to relational structures, where the\nrecently introduced comonadic constructions for pebbling,\nEhrenfeucht-Fra\\\"iss\\'e and modal bisimulation games are recovered, showing\nthat many of the fundamental notions of finite model theory and descriptive\ncomplexity arise from instances of arboreal covers.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 12:20:24 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Abramsky", "Samson", ""], ["Reggio", "Luca", ""]]}, {"id": "2102.08146", "submitter": "Manfred Schmidt-Schauss", "authors": "Manfred Schmidt-Schau{\\ss} and Temur Kutsia and Jordi Levy and Mateu\n  Villaret and Yunus Kutz", "title": "Nominal Unification and Matching of Higher Order Expressions with\n  Recursive Let", "comments": "35 pages, 9 figures, This paper is an extended version of the\n  conference publication: Manfred Schmidt-Schau{\\ss} and Temur Kutsia and Jordi\n  Levy and Mateu Villaret and Yunus Kutz, Nominal Unification of Higher Order\n  Expressions with Recursive Let, LOPSTR-16, Lecture Notes in Computer Science\n  10184, Springer, p 328 -344, 2016. arXiv admin note: text overlap with\n  arXiv:1608.03771", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A sound and complete algorithm for nominal unification of higher-order\nexpressions with a recursive let is described, and shown to run in\nnondeterministic polynomial time. We also explore specializations like nominal\nletrec-matching for expressions, for DAGs, and for garbage-free expressions and\ndetermine their complexity. Finally, we also provide a nominal unification\nalgorithm for higher-order expressions with recursive let and atom-variables,\nwhere we show that it also runs in nondeterministic polynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 13:36:59 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Schmidt-Schau\u00df", "Manfred", ""], ["Kutsia", "Temur", ""], ["Levy", "Jordi", ""], ["Villaret", "Mateu", ""], ["Kutz", "Yunus", ""]]}, {"id": "2102.08207", "submitter": "Philipp Hieronymi", "authors": "Philipp Hieronymi, Dun Ma, Reed Oei, Luke Schaeffer, Christian Schulz,\n  Jeffrey Shallit", "title": "Decidability for Sturmian words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the first-order theory of Sturmian words over Presburger\narithmetic is decidable. Using a general adder recognizing addition in\nOstrowski numeration systems by Baranwal, Schaeffer and Shallit, we prove that\nthe first-order expansions of Presburger arithmetic by a single Sturmian word\nare uniformly $\\omega$-automatic, and then deduce the decidability of the\ntheory of the class of such structures. Using an implementation of this\ndecision algorithm called Pecan, we automatically reprove many classical\ntheorems about Sturmian words in seconds, and are able to obtain new results\nabout antisquares and antipalindromes in characteristic Sturmian words\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 15:06:52 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Hieronymi", "Philipp", ""], ["Ma", "Dun", ""], ["Oei", "Reed", ""], ["Schaeffer", "Luke", ""], ["Schulz", "Christian", ""], ["Shallit", "Jeffrey", ""]]}, {"id": "2102.08286", "submitter": "Todd Schmid", "authors": "Todd Schmid and Tobias Kapp\\'e and Dexter Kozen and Alexandra Silva", "title": "Guarded Kleene Algebra with Tests: Coequations, Coinduction, and\n  Completeness", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Guarded Kleene Algebra with Tests (GKAT) is an efficient fragment of KAT, as\nit allows for almost linear decidability of equivalence. In this paper, we\nstudy the (co)algebraic properties of GKAT. Our initial focus is on the\nfragment that can distinguish between unsuccessful programs performing\ndifferent actions, by omitting the so-called early termination axiom. We\ndevelop an operational (coalgebraic) and denotational (algebraic) semantics and\nshow that they coincide. We then characterize the behaviors of GKAT expressions\nin this semantics, leading to a coequation that captures the covariety of\nautomata corresponding to behaviors of GKAT expressions. Finally, we prove that\nthe axioms of the reduced fragment are sound and complete w.r.t. the semantics,\nand then build on this result to recover a semantics that is sound and complete\nw.r.t. the full set of axioms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:16:23 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 15:23:22 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Schmid", "Todd", ""], ["Kapp\u00e9", "Tobias", ""], ["Kozen", "Dexter", ""], ["Silva", "Alexandra", ""]]}, {"id": "2102.08595", "submitter": "Farida Kachapova", "authors": "Farida Kachapova", "title": "Formalizing relations in type theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Type theory plays an important role in foundations of mathematics as a\nframework for formalizing mathematics and a base for proof assistants providing\nsemi-automatic proof checking and construction. Derivation of each theorem in\ntype theory results in a formal term encapsulating the whole proof process. In\nthis paper we use a variant of type theory, namely the Calculus of\nConstructions with Definitions, to formalize the standard theory of binary\nrelations. This includes basic operations on relations, criteria for special\nproperties of relations, invariance of these properties under the basic\noperations, equivalence relation, well-ordering, and transfinite induction.\nDefinitions and proofs are presented as flag-style derivations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 06:08:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kachapova", "Farida", ""]]}, {"id": "2102.08711", "submitter": "Robin Kaarsgaard", "authors": "Chris Heunen and Robin Kaarsgaard", "title": "Bennett and Stinespring, Together at Last", "comments": "15 pages, additional proofs in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a universal construction that relates reversible dynamics on open\nsystems to arbitrary dynamics on closed systems: the well-pointed restriction\naffine completion of a monoidal restriction category. This categorical\ncompletion encompasses both quantum channels, via Stinespring dilation, and\nclassical computing, via Bennett's method. Moreover, in these two cases, we\nshow how our construction can be 'undone' by a further universal construction.\nThis shows how both mixed quantum theory and classical computation rest on\nentirely reversible foundations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 11:50:12 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 18:23:39 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 10:44:09 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Heunen", "Chris", ""], ["Kaarsgaard", "Robin", ""]]}, {"id": "2102.08766", "submitter": "Michael Farber", "authors": "Michael F\\\"arber (DEDUCTEAM)", "title": "Small, Fast, Concurrent Proof Checking for the lambda-Pi Calculus Modulo\n  Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several proof assistants, such as Isabelle or Coq, can concurrently check\nmultiple proofs. In contrast, the vast majority of today's small proof checkers\neither does not support concurrency at all or only limited forms thereof,\nrestricting the efficiency of proof checking on multi-core processors. This\nwork presents a small proof checker with support for concurrent proof checking,\nachieving state-of-the-art performance in both concurrent and nonconcurrent\nsettings. The proof checker implements the lambda-Pi calculus modulo rewriting,\nwhich is an established framework to uniformly express a multitude of logical\nsystems. The proof checker is faster than the reference proof checker for this\ncalculus, Dedukti, on all of five evaluated datasets obtained from proof\nassistants and interactive theorem provers.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 13:59:17 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["F\u00e4rber", "Michael", "", "DEDUCTEAM"]]}, {"id": "2102.08777", "submitter": "Felix Weitk\\\"amper", "authors": "Felix Weitk\\\"amper", "title": "An asymptotic analysis of probabilistic logic programming with\n  implications for expressing projective families of distributions", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last years, there has been increasing research on the scaling\nbehaviour of statistical relational representations with the size of the\ndomain, and on the connections between domain size dependence and lifted\ninference. In particular, the asymptotic behaviour of statistical relational\nrepresentations has come under scrutiny, and projectivity was isolated as the\nstrongest form of domain size independence. In this contribution we show that\nevery probabilistic logic program under the distribution semantics is\nasymptotically equivalent to a probabilistic logic program consisting only of\ndeterminate clauses over probabilistic facts. To facilitate the application of\nclassical results from finite model theory, we introduce the abstract\ndistribution semantics, defined as an arbitrary logical theory over\nprobabilistic facts to bridge the gap to the distribution semantics underlying\nprobabilistic logic programming. In this representation, determinate logic\nprograms correspond to quantifier-free theories, making asymptotic quantifier\nresults avilable for use. We can conclude that every probabilistic logic\nprogram inducing a projective family of distributions is in fact captured by\nthis class, and we can infer interesting consequences for the expressivity of\nprobabilistic logic programs as well as for the asymptotic behaviour of\nprobabilistic rules.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:07:16 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 12:03:58 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Weitk\u00e4mper", "Felix", ""]]}, {"id": "2102.08812", "submitter": "Tom de Jong", "authors": "Tom de Jong, Mart\\'in H\\\"otzel Escard\\'o", "title": "Predicative Aspects of Order Theory in Univalent Foundations", "comments": "To appear in the proceedings of FSCD 2021, volume 195 of LIPIcs", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate predicative aspects of order theory in constructive univalent\nfoundations. By predicative and constructive, we respectively mean that we do\nnot assume Voevodsky's propositional resizing axioms or excluded middle. Our\nwork complements existing work on predicative mathematics by exploring what\ncannot be done predicatively in univalent foundations. Our first main result is\nthat nontrivial (directed or bounded) complete posets are necessarily large.\nThat is, if such a nontrivial poset is small, then weak propositional resizing\nholds. It is possible to derive full propositional resizing if we strengthen\nnontriviality to positivity. The distinction between nontriviality and\npositivity is analogous to the distinction between nonemptiness and\ninhabitedness. We prove our results for a general class of posets, which\nincludes directed complete posets, bounded complete posets and sup-lattices,\nusing a technical notion of a $\\delta_{\\mathcal V}$-complete poset. We also\nshow that nontrivial locally small $\\delta_{\\mathcal V}$-complete posets\nnecessarily lack decidable equality. Specifically, we derive weak excluded\nmiddle from assuming a nontrivial locally small $\\delta_{\\mathcal V}$-complete\nposet with decidable equality. Moreover, if we assume positivity instead of\nnontriviality, then we can derive full excluded middle. Secondly, we show that\neach of Zorn's lemma, Tarski's greatest fixed point theorem and Pataraia's\nlemma implies propositional resizing. Hence, these principles are inherently\nimpredicative and a predicative development of order theory must therefore do\nwithout them. Finally, we clarify, in our predicative setting, the relation\nbetween the traditional definition of sup-lattice that requires suprema for all\nsubsets and our definition that asks for suprema of all small families.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 15:17:54 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 16:40:00 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 16:07:54 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 15:23:25 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 07:32:03 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["de Jong", "Tom", ""], ["Escard\u00f3", "Mart\u00edn H\u00f6tzel", ""]]}, {"id": "2102.09658", "submitter": "Stephen Wolfram", "authors": "Stephen Wolfram", "title": "Combinators and the Story of Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We discuss the role of combinators in the development of the modern\nconception of computation over the course of the past century. We describe how\nideas about formalism and mathematical logic led to the introduction of\ncombinators in 1920 as an extension of the discovery of Nand as a basis for\nbasic logic. We then discuss how combinators informed lambda calculus and\nsymbolic computation, and their relationship to the development of practical\ncomputation. We finally describe recent views of combinators in terms of the\ncomputational universe of possible programs, and a recent approach to the\nfundamental theory of physics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 22:51:34 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Wolfram", "Stephen", ""]]}, {"id": "2102.09667", "submitter": "Aleksey Nogin", "authors": "Michael Roberts (1 and 2), Alexei Kopylov (1), and Aleksey Nogin (1)\n  ((1) HRL Laboratories, LLC, Malibu, CA, (2) Cornell University, Ithaca, NY)", "title": "Semantics and Axiomatization for Stochastic Differential Dynamic Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on previous work by Andr\\'e Platzer, we present a formal language\nfor Stochastic Differential Dynamic Logic, and define its semantics, axioms and\ninference rules. Compared to the previous effort, our account of the Stochastic\nDifferential Dynamic Logic follows closer to and is more compatible with the\ntraditional account of the regular Differential Dynamic Logic. We resolve an\nissue with the well-definedness of the original work's semantics, while showing\nhow to make the logic more expressive by incorporating nondeterministic choice,\ndefinite descriptions and differential terms. Definite descriptions necessitate\nusing a three-valued truth semantics. We also give the first Uniform\nSubstitution calculus for Stochastic Differential Dynamic Logic, making it more\npractical to implement in proof assistants.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:28:45 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 00:01:54 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Roberts", "Michael", "", "1 and 2"], ["Kopylov", "Alexei", "", "HRL Laboratories, LLC, Malibu, CA"], ["Nogin", "Aleksey", "", "HRL Laboratories, LLC, Malibu, CA"]]}, {"id": "2102.09756", "submitter": "Minchao Wu", "authors": "Minchao Wu, Michael Norrish, Christian Walder, Amir Dezfouli", "title": "TacticZero: Learning to Prove Theorems from Scratch with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to interactive theorem-proving (ITP) using deep\nreinforcement learning. The proposed framework is able to learn proof search\nstrategies as well as tactic and arguments prediction in an end-to-end manner.\nWe formulate the process of ITP as a Markov decision process (MDP) in which\neach state represents a set of potential derivation paths. This structure\nallows us to introduce a novel backtracking mechanism which enables the agent\nto efficiently discard (predicted) dead-end derivations and restart from\npromising alternatives. We implement the framework in the HOL4 theorem prover.\nExperimental results show that the framework outperforms existing automated\ntheorem provers (i.e., hammers) available in HOL4 when evaluated on unseen\nproblems. We further elaborate the role of key components of the framework\nusing ablation studies.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 06:08:39 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 07:48:40 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wu", "Minchao", ""], ["Norrish", "Michael", ""], ["Walder", "Christian", ""], ["Dezfouli", "Amir", ""]]}, {"id": "2102.09837", "submitter": "Till Hofmann", "authors": "Till Hofmann and Gerhard Lakemeyer", "title": "Controller Synthesis for Golog Programs over Finite Domains with Metric\n  Temporal Constraints", "comments": "A poster about this paper was presented at the 17th International\n  Conference on Principles of Knowledge Representation and Reasoning (KR'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Executing a Golog program on an actual robot typically requires additional\nsteps to account for hardware or software details of the robot platform, which\ncan be formulated as constraints on the program. Such constraints are often\ntemporal, refer to metric time, and require modifications to the abstract Golog\nprogram. We describe how to formulate such constraints based on a modal variant\nof the Situation Calculus. These constraints connect the abstract program with\nthe platform models, which we describe using timed automata. We show that for\nprograms over finite domains and with fully known initial state, the problem of\nsynthesizing a controller that satisfies the constraints while preserving the\neffects of the original program can be reduced to MTL synthesis. We do this by\nconstructing a timed automaton from the abstract program and synthesizing an\nMTL controller from this automaton, the platform models, and the constraints.\nWe prove that the synthesized controller results in execution traces which are\nthe same as those of the original program, possibly interleaved with\nplatform-dependent actions, that they satisfy all constraints, and that they\nhave the same effects as the traces of the original program. By doing so, we\nobtain a decidable procedure to synthesize a controller that satisfies the\nspecification while preserving the original program.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:07:29 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Hofmann", "Till", ""], ["Lakemeyer", "Gerhard", ""]]}, {"id": "2102.09949", "submitter": "Alexander Chunikhin", "authors": "Alexander Chunikhin", "title": "Fundamentals of Semantic Numeration Systems. Can the Context be\n  Calculated?", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": "PIBNASU-2020-12/2", "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work is the first to propose the concept of a semantic numeration system\n(SNS) as a certain class of context-based numeration methods. The development\nof the SNS concept required the introduction of fundamentally new concepts such\nas a cardinal abstract entity, a cardinal semantic operator, a cardinal\nabstract object, a numeration space. The main attention is paid to the key\nelements of semantic numeration systems - cardinal semantic operators. A\nclassification of semantic numeration systems is given.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 21:54:59 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:06:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chunikhin", "Alexander", ""]]}, {"id": "2102.10104", "submitter": "Pierre Vandenhove", "authors": "Patricia Bouyer, Youssouf Oualhadj, Mickael Randour, Pierre Vandenhove", "title": "Arena-Independent Finite-Memory Determinacy in Stochastic Games", "comments": "Full version of CONCUR 2021 conference paper. 38 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic zero-sum games on graphs, which are prevalent tools to\nmodel decision-making in presence of an antagonistic opponent in a random\nenvironment. In this setting, an important question is the one of strategy\ncomplexity: what kinds of strategies are sufficient or required to play\noptimally (e.g., randomization or memory requirements)? Our contributions\nfurther the understanding of arena-independent finite-memory (AIFM)\ndeterminacy, i.e., the study of objectives for which memory is needed, but in a\nway that only depends on limited parameters of the game graphs. First, we show\nthat objectives for which pure AIFM strategies suffice to play optimally also\nadmit pure AIFM subgame perfect strategies. Second, we show that we can reduce\nthe study of objectives for which pure AIFM strategies suffice in two-player\nstochastic games to the easier study of one-player stochastic games (i.e.,\nMarkov decision processes). Third, we characterize the sufficiency of AIFM\nstrategies through two intuitive properties of objectives. This work extends a\nline of research started on deterministic games in [BLO+20] to stochastic ones.\n  [BLO+20] Patricia Bouyer, St\\'ephane Le Roux, Youssouf Oualhadj, Mickael\nRandour, and Pierre Vandenhove. Games Where You Can Play Optimally with\nArena-Independent Finite Memory. CONCUR 2020.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:58:36 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 13:20:03 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 11:14:34 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Bouyer", "Patricia", ""], ["Oualhadj", "Youssouf", ""], ["Randour", "Mickael", ""], ["Vandenhove", "Pierre", ""]]}, {"id": "2102.10127", "submitter": "Eduard Kamburjan", "authors": "Eduard Kamburjan and Marco Scaletta and Nils Rollshausen", "title": "Crowbar: Behavioral Symbolic Execution for Deductive Verification of\n  Active Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Crowbar tool, a deductive verification system for the ABS\nlanguage. ABS models distributed systems with the Active Object concurrency\nmodel. Crowbar implements behavioral symbolic execution: each method is\nsymbolically executed, but specification and prior static analyses influence\nthe shape of the symbolic execution tree. User interaction is realized through\nguided counterexamples, which present failed proof branches in terms of the\ninput program. Crowbar has a clear interface to implement new specification\nlanguages and verification calculi in the Behavioral Program Logic and has been\napplied for the biggest verification case study of Active Objects.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 19:12:24 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kamburjan", "Eduard", ""], ["Scaletta", "Marco", ""], ["Rollshausen", "Nils", ""]]}, {"id": "2102.10368", "submitter": "Erich Gr\\\"adel", "authors": "Erich Gr\\\"adel and Phil P\\\"utzst\\\"uck", "title": "Logics of Dependence and Independence: The Local Variants", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern logics of dependence and independence are based on team semantics,\nwhich means that formulae are evaluated not on a single assignment of values to\nvariables, but on a set of such assignments, called a team. This leads to high\nexpressive power, on the level of existential second-order logic. As an\nalternative, Baltag and van Benthem have proposed a local variant of dependence\nlogic, called logic of functional dependence (LFD). While its semantics is also\nbased on a team, the formulae are evaluated locally on just one of its\nassignments, and the team just serves as the supply of the possible assignments\nthat are taken into account in the evaluation process. This logic thus relies\non the modal perspective of generalized assignments semantics, and can be seen\nas a fragment of first-order logic. For the variant of LFD without equality,\nthe satisfiability problem is decidable.\n  We extend the idea of localising logics of dependence and independence in a\nsystematic way, taking into account local variants of standard atomic\ndependency properties: besides dependence and independence, also inclusion,\nexclusion, and anonymity. We study model-theoretic and algorithmic questions of\nthe localised logics, and also resolve some of the questions that had been left\nopen by Baltag and van Benthem. In particular, we study decidability issues of\nthe local logics, and prove that satisfiability of LFD with equality is\nundecidable. Further, we establish characterisation theorems via appropriate\nnotions of bisimulation and study the complexity of model checking problems for\nthese logics.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 15:13:57 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Gr\u00e4del", "Erich", ""], ["P\u00fctzst\u00fcck", "Phil", ""]]}, {"id": "2102.10532", "submitter": "Michael Maher", "authors": "Michael J. Maher", "title": "Relative Expressiveness of Defeasible Logics II", "comments": "Includes extensive appendix", "journal-ref": "Theory and Practice of Logic Programming 13(4-5): 579-592, 2013", "doi": "10.1017/S1471068413000367", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  (Maher 2012) introduced an approach for relative expressiveness of defeasible\nlogics, and two notions of relative expressiveness were investigated. Using the\nfirst of these definitions of relative expressiveness, we show that all the\ndefeasible logics in the DL framework are equally expressive under this\nformulation of relative expressiveness. The second formulation of relative\nexpressiveness is stronger than the first. However, we show that logics\nincorporating individual defeat are equally expressive as the corresponding\nlogics with team defeat. Thus the only differences in expressiveness of logics\nin DL arise from differences in how ambiguity is handled. This completes the\nstudy of relative expressiveness in DL begun in \\cite{Maher12}.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 07:01:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Maher", "Michael J.", ""]]}, {"id": "2102.10604", "submitter": "Hanlin Niu", "authors": "Hanlin Niu, Ze Ji, Al Savvaris, Antonios Tsourdos, and Joaquin\n  Carrasco", "title": "Model Checking for Decision Making System of Long Endurance Unmanned\n  Surface Vehicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to develop a model checking method to verify the decision\nmaking system of Unmanned Surface Vehicle (USV) in a long range surveillance\nmission. The scenario in this work was captured from a long endurance USV\nsurveillance mission using C-Enduro, an USV manufactured by ASV Ltd. The\nC-Enduro USV may encounter multiple non-deterministic and concurrent problems\nincluding lost communication signals, collision risk and malfunction. The\nvehicle is designed to utilise multiple energy sources from solar panel, wind\nturbine and diesel generator. The energy state can be affected by the solar\nirradiance condition, wind condition, states of the diesel generator, sea\ncurrent condition and states of the USV. In this research, the states and the\ninteractive relations between environmental uncertainties, sensors, USV energy\nsystem, USV and Ground Control Station (GCS) decision making systems are\nabstracted and modelled successfully using Kripke models. The desirable\nproperties to be verified are expressed using temporal logic statement and\nfinally the safety properties and the long endurance properties are verified\nusing the model checker MCMAS, a model checker for multi-agent systems. The\nverification results are analyzed and show the feasibility of applying model\nchecking method to retrospect the desirable property of the USV decision making\nsystem. This method could assist researcher to identify potential design error\nof decision making system in advance.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 13:42:40 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 02:53:18 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Niu", "Hanlin", ""], ["Ji", "Ze", ""], ["Savvaris", "Al", ""], ["Tsourdos", "Antonios", ""], ["Carrasco", "Joaquin", ""]]}, {"id": "2102.10689", "submitter": "Ana Ozaki", "authors": "Ricardo Guimar\\~aes, Ana Ozaki, Cosimo Persia, Baris Sertkaya", "title": "Mining EL Bases with Adaptable Role Depth", "comments": "AAAI 2021 (Main Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Formal Concept Analysis, a base for a finite structure is a set of\nimplications that characterizes all valid implications of the structure. This\nnotion can be adapted to the context of Description Logic, where the base\nconsists of a set of concept inclusions instead of implications. In this\nsetting, concept expressions can be arbitrarily large. Thus, it is not clear\nwhether a finite base exists and, if so, how large concept expressions may need\nto be. We first revisit results in the literature for mining EL bases from\nfinite interpretations. Those mainly focus on finding a finite base or on\nfixing the role depth but potentially losing some of the valid concept\ninclusions with higher role depth. We then present a new strategy for mining EL\nbases which is adaptable in the sense that it can bound the role depth of\nconcepts depending on the local structure of the interpretation. Our strategy\nguarantees to capture all EL concept inclusions holding in the interpretation,\nnot only the ones up to a fixed role depth.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 21:33:49 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 10:13:35 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Guimar\u00e3es", "Ricardo", ""], ["Ozaki", "Ana", ""], ["Persia", "Cosimo", ""], ["Sertkaya", "Baris", ""]]}, {"id": "2102.10698", "submitter": "Marco Peressotti", "authors": "Lu\\'is Cruz-Filipe, Fabrizio Montesi, Marco Peressotti", "title": "Certifying Choreography Compilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choreographic programming is a paradigm for developing concurrent and\ndistributed systems, where programs are choreographies that define, from a\nglobal viewpoint, the computations and interactions that communicating\nprocesses should enact. Choreography compilation translates choreographies into\nthe local definitions of process behaviours, given as terms in a process\ncalculus.\n  Proving choreography compilation correct is challenging and error-prone,\nbecause it requires relating languages in different paradigms (global\ninteractions vs local actions) and dealing with a combinatorial explosion of\nproof cases. We present the first certified program for choreography\ncompilation for a nontrivial choreographic language supporting recursion.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 22:00:34 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Cruz-Filipe", "Lu\u00eds", ""], ["Montesi", "Fabrizio", ""], ["Peressotti", "Marco", ""]]}, {"id": "2102.10931", "submitter": "Erich Gr\\\"adel", "authors": "Rafael Albert and Erich Gr\\\"adel", "title": "Unifying Hidden-Variable Problems from Quantum Mechanics by Logics of\n  Dependence and Independence", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study hidden-variable models from quantum mechanics, and their\nabstractions in purely probabilistic and relational frameworks, by means of\nlogics of dependence and independence, based on team semantics. We show that\ncommon desirable properties of hidden-variable models can be defined in an\nelegant and concise way in dependence and independence logic. The relationship\nbetween different properties, and their simultaneous realisability can thus\nbeen formulated and a proved on a purely logical level, as problems of\nentailment and satisfiability of logical formulae. Connections between\nprobabilistic and relational entailment in dependence and independence logic\nallow us to simplify proofs. In many cases, we can establish results on both\nprobabilistic and relational hidden-variable models by a single proof, because\none case implies the other, depending on purely syntactic criteria. We also\ndiscuss the no-go theorems by Bell and Kochen-Specker and provide a purely\nlogical variant of the latter, introducing non-contextual choice as a\nteam-semantical property.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 12:04:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Albert", "Rafael", ""], ["Gr\u00e4del", "Erich", ""]]}, {"id": "2102.10952", "submitter": "Rupsa Saha", "authors": "Rupsa Saha, Ole-Christoffer Granmo, Vladimir I. Zadorozhny, Morten\n  Goodwin", "title": "A Relational Tsetlin Machine with Applications to Natural Language\n  Understanding", "comments": "14 pages, 3 figures, 7 tables, relational approach to TM in NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TMs are a pattern recognition approach that uses finite state machines for\nlearning and propositional logic to represent patterns. In addition to being\nnatively interpretable, they have provided competitive accuracy for various\ntasks. In this paper, we increase the computing power of TMs by proposing a\nfirst-order logic-based framework with Herbrand semantics. The resulting TM is\nrelational and can take advantage of logical structures appearing in natural\nlanguage, to learn rules that represent how actions and consequences are\nrelated in the real world. The outcome is a logic program of Horn clauses,\nbringing in a structured view of unstructured data. In closed-domain\nquestion-answering, the first-order representation produces 10x more compact\nKBs, along with an increase in answering accuracy from 94.83% to 99.48%. The\napproach is further robust towards erroneous, missing, and superfluous\ninformation, distilling the aspects of a text that are important for real-world\nunderstanding.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 12:40:37 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Saha", "Rupsa", ""], ["Granmo", "Ole-Christoffer", ""], ["Zadorozhny", "Vladimir I.", ""], ["Goodwin", "Morten", ""]]}, {"id": "2102.11025", "submitter": "Emiliano Lorini", "authors": "Emiliano Lorini", "title": "A Qualitative Theory of Cognitive Attitudes and their Change", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": "10.1017/S1471068421000053", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general logical framework for reasoning about agents' cognitive\nattitudes of both epistemic type and motivational type. We show that it allows\nus to express a variety of relevant concepts for qualitative decision theory\nincluding the concepts of knowledge, belief, strong belief, conditional belief,\ndesire, conditional desire, strong desire and preference. We also present two\nextensions of the logic, one by the notion of choice and the other by dynamic\noperators for belief change and desire change, and we apply the former to the\nanalysis of single-stage games under incomplete information. We provide sound\nand complete axiomatizations for the basic logic and for its two extensions.\nThe paper is under consideration in Theory and Practice of Logic Programming\n(TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 10:28:49 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Lorini", "Emiliano", ""]]}, {"id": "2102.11081", "submitter": "Jason Parker", "authors": "Pieter Hofstra, Jason Parker, Philip J. Scott", "title": "Polymorphic Automorphisms and the Picard Group", "comments": "16 pages. Submitted to FSCD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the concept of definable, or inner, automorphism in the\nlogical setting of partial Horn theories. The central technical result extends\na syntactical characterization of the group of such automorphisms (called the\ncovariant isotropy group) associated with an algebraic theory to the wider\nclass of quasi-equational theories. We apply this characterization to prove\nthat the isotropy group of a strict monoidal category is precisely its Picard\ngroup of invertible objects. Furthermore, we obtain an explicit description of\nthe covariant isotropy group of a presheaf category.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:54:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Hofstra", "Pieter", ""], ["Parker", "Jason", ""], ["Scott", "Philip J.", ""]]}, {"id": "2102.11164", "submitter": "Andrew Kenyon-Roberts", "authors": "Andrew Kenyon-Roberts and Luke Ong", "title": "Supermartingales, Ranking Functions and Probabilistic Lambda Calculus", "comments": "35 pages, 3 figures, submitted to LICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a method for proving almost sure termination in the context of\nlambda calculus with continuous random sampling and explicit recursion, based\non ranking supermartingales. This result is extended in three ways. Antitone\nranking functions have weaker restrictions on how fast they must decrease, and\nare applicable to a wider range of programs. Sparse ranking functions take\nvalues only at a subset of the program's reachable states, so they are simpler\nto define and more flexible. Ranking functions with respect to alternative\nreduction strategies give yet more flexibility, and significantly increase the\napplicability of the ranking supermartingale approach to proving almost sure\ntermination, thanks to a novel (restricted) confluence result which is of\nindependent interest. The notion of antitone ranking function was inspired by\nsimilar work by McIver, Morgan, Kaminski and Katoen in the setting of a\nfirst-order imperative language, but adapted to a higher-order functional\nlanguage. The sparse ranking function and confluent semantics extensions are\nunique to the higher-order setting. Our methods can be used to prove almost\nsure termination of programs that are beyond the reach of methods in the\nliterature, including higher-order and non-affine recursion.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:39:42 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 20:39:51 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kenyon-Roberts", "Andrew", ""], ["Ong", "Luke", ""]]}, {"id": "2102.11166", "submitter": "Valentina Castiglioni", "authors": "Luca Aceto, Valentina Castiglioni, Anna Ingolfsdottir, Bas Luttik and\n  Mathias R. Pedersen", "title": "On the Axiomatisability of Parallel Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the existence of finite equational axiomatisations of the\ninterleaving parallel composition operator modulo the behavioural equivalences\nin van Glabbeek's linear time-branching time spectrum. In the setting of the\nprocess algebra BCCSP over a finite set of actions, we provide finite,\nground-complete axiomatisations for various simulation and (decorated) trace\nsemantics. We also show that no congruence over BCCSP that includes\nbisimilarity and is included in possible futures equivalence has a finite,\nground-complete axiomatisation; this negative result applies to all the nested\ntrace and nested simulation semantics.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:45:48 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 08:27:07 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Aceto", "Luca", ""], ["Castiglioni", "Valentina", ""], ["Ingolfsdottir", "Anna", ""], ["Luttik", "Bas", ""], ["Pedersen", "Mathias R.", ""]]}, {"id": "2102.11184", "submitter": "Giuseppe Perelli", "authors": "Giuseppe De Giacomo, Giuseppe Perelli (Sapienza University of Rome)", "title": "Behavioral QLTL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we introduce Behavioral QLTL, which is a ``behavioral'' variant\nof linear-time temporal logic on infinite traces with second-order quantifiers.\nBehavioral QLTL is characterized by the fact that the functions that assign the\ntruth value of the quantified propositions along the trace can only depend on\nthe past. In other words such functions must be``processes''. This gives to the\nlogic a strategic flavor that we usually associate to planning. Indeed we show\nthat temporally extended planning in nondeterministic domains, as well as LTL\nsynthesis, are expressed in Behavioral QLTL through formulas with a simple\nquantification alternation. While, as this alternation increases, we get to\nforms of planning/synthesis in which conditional and conformant planning\naspects get mixed. We study this logic from the computational point of view and\ncompare it to the original QLTL (with non-behavioral semantics) and with\nsimpler forms of behavioral semantics.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 17:01:42 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["De Giacomo", "Giuseppe", "", "Sapienza University of Rome"], ["Perelli", "Giuseppe", "", "Sapienza University of Rome"]]}, {"id": "2102.11482", "submitter": "Hongzhen Zhong", "authors": "Hongzhen Zhong, Hai Wan, Weilin Luo, Zhanhao Xiao, Jia Li, Biqing Fang", "title": "Structural Similarity of Boundary Conditions and an Efficient Local\n  Search Algorithm for Goal Conflict Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In goal-oriented requirements engineering, goal conflict identification is of\nfundamental importance for requirements analysis. The task aims to find the\nfeasible situations which make the goals diverge within the domain, called\nboundary conditions (BCs). However, the existing approaches for goal conflict\nidentification fail to find sufficient BCs and general BCs which cover more\ncombinations of circumstances. From the BCs found by these existing approaches,\nwe have observed an interesting phenomenon that there are some pairs of BCs are\nsimilar in formula structure, which occurs frequently in the experimental\ncases. In other words, once a BC is found, a new BC may be discovered quickly\nby slightly changing the former. It inspires us to develop a local search\nalgorithm named LOGION to find BCs, in which the structural similarity is\ncaptured by the neighborhood relation of formulae. Based on structural\nsimilarity, LOGION can find a lot of BCs in a short time. Moreover, due to the\nlarge number of BCs identified, it potentially selects more general BCs from\nthem. By taking experiments on a set of cases, we show that LOGION effectively\nexploits the structural similarity of BCs. We also compare our algorithm\nagainst the two state-of-the-art approaches. The experimental results show that\nLOGION produces one order of magnitude more BCs than the state-of-the-art\napproaches and confirm that LOGION finds out more general BCs thanks to a large\nnumber of BCs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 04:25:06 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zhong", "Hongzhen", ""], ["Wan", "Hai", ""], ["Luo", "Weilin", ""], ["Xiao", "Zhanhao", ""], ["Li", "Jia", ""], ["Fang", "Biqing", ""]]}, {"id": "2102.11605", "submitter": "Romain P\\'echoux", "authors": "Emmanuel Hainry, Bruce M. Kapron, Jean-Yves Marion, Romain P\\'echoux", "title": "A tier-based typed programming language characterizing Feasible\n  Functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The class of Basic Feasible Functionals BFF$_2$ is the type-2 counterpart of\nthe class FP of type-1 functions computable in polynomial time. Several\ncharacterizations have been suggested in the literature, but none of these\npresent a programming language with a type system guaranteeing this complexity\nbound. We give a characterization of BFF$_2$ based on an imperative language\nwith oracle calls using a tier-based type system whose inference is decidable.\nSuch a characterization should make it possible to link higher-order complexity\nwith programming theory. The low complexity (cubic in the size of the program)\nof the type inference algorithm contrasts with the intractability of the\naforementioned methods and does not overly constrain the expressive power of\nthe language.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 10:35:31 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Hainry", "Emmanuel", ""], ["Kapron", "Bruce M.", ""], ["Marion", "Jean-Yves", ""], ["P\u00e9choux", "Romain", ""]]}, {"id": "2102.11641", "submitter": "Giuseppe Greco", "authors": "Jinsheng Chen, Giuseppe Greco, Alessandra Palmigiano, and Apostolos\n  Tzimoulis", "title": "Syntactic completeness of proper display calculi", "comments": "arXiv admin note: text overlap with arXiv:1604.08822 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent strand of research in structural proof theory aims at exploring the\nnotion of analytic calculi (i.e. those calculi that support general and modular\nproof-strategies for cut elimination), and at identifying classes of logics\nthat can be captured in terms of these calculi. In this context, Wansing\nintroduced the notion of proper display calculi as one possible design\nframework for proof calculi in which the analiticity desiderata are realized in\na particularly transparent way. Recently, the theory of properly displayable\nlogics (i.e. those logics that can be equivalently presented with some proper\ndisplay calculus) has been developed in connection with generalized Sahlqvist\ntheory (aka unified correspondence). Specifically, properly displayable logics\nhave been syntactically characterized as those axiomatized by analytic\ninductive axioms, which can be equivalently and algorithmically transformed\ninto analytic structural rules so that the resulting proper display calculi\nenjoy a set of basic properties: soundness, completeness, conservativity, cut\nelimination and subformula property. In this context, the proof that the given\ncalculus is complete w.r.t. the original logic is usually carried out\nsyntactically, i.e. by showing that a (cut free) derivation exists of each\ngiven axiom of the logic in the basic system to which the analytic structural\nrules algorithmically generated from the given axiom have been added. However,\nso far this proof strategy for syntactic completeness has been implemented on a\ncase-by-case base, and not in general. In this paper, we address this gap by\nproving syntactic completeness for properly displayable logics in any normal\n(distributive) lattice expansion signature. Specifically, we show that for\nevery analytic inductive axiom a cut free derivation can be effectively\ngenerated which has a specific shape, referred to as pre-normal form.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 11:43:43 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Chen", "Jinsheng", ""], ["Greco", "Giuseppe", ""], ["Palmigiano", "Alessandra", ""], ["Tzimoulis", "Apostolos", ""]]}, {"id": "2102.11649", "submitter": "Rafa\\\"el Bocquet", "authors": "Rafa\\\"el Bocquet and Ambrus Kaposi and Christian Sattler", "title": "Relative induction principles for type theories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new induction principles for the syntax of dependent type\ntheories, which we call relative induction principles. The result of the\ninduction principle relative to a functor F into the syntax is stable over the\ncodomain of F. We rely on the internal language of presheaf categories. In\norder to combine the internal languages of multiple presheaf categories, we use\nDependent Right Adjoints and Multimodal Type Theory. Categorical gluing is used\nto prove these induction principles, but it not visible in their statements,\nwhich involve a notion of model without context extensions. As example\napplications of these induction principles, we give short and boilerplate-free\nproofs of canonicity and normalization for some small type theories, and sketch\nproofs of other metatheoretic results.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 12:08:25 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 12:42:20 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bocquet", "Rafa\u00ebl", ""], ["Kaposi", "Ambrus", ""], ["Sattler", "Christian", ""]]}, {"id": "2102.11782", "submitter": "Yasir Mahmood", "authors": "Yasir Mahmood, Arne Meier, Johannes Schmidt", "title": "Parameterized Complexity of Logic-Based Argumentation in Schaefer's\n  Framework", "comments": "Technical report to the final version at AAAI21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logic-based argumentation is a well-established formalism modelling\nnonmonotonic reasoning. It has been playing a major role in AI for decades,\nnow. Informally, a set of formulas is the support for a given claim if it is\nconsistent, subset-minimal, and implies the claim. In such a case, the pair of\nthe support and the claim together is called an argument. In this paper, we\nstudy the propositional variants of the following three computational tasks\nstudied in argumentation: ARG (exists a support for a given claim with respect\nto a given set of formulas), ARG-Check (is a given set a support for a given\nclaim), and ARG-Rel (similarly as ARG plus requiring an additionally given\nformula to be contained in the support). ARG-Check is complete for the\ncomplexity class DP, and the other two problems are known to be complete for\nthe second level of the polynomial hierarchy (Parson et al., J. Log. Comput.,\n2003) and, accordingly, are highly intractable. Analyzing the reason for this\nintractability, we perform a two-dimensional classification: first, we consider\nall possible propositional fragments of the problem within Schaefer's framework\n(STOC 1978), and then study different parameterizations for each of the\nfragment. We identify a list of reasonable structural parameters (size of the\nclaim, support, knowledge-base) that are connected to the aforementioned\ndecision problems. Eventually, we thoroughly draw a fine border of\nparameterized intractability for each of the problems showing where the\nproblems are fixed-parameter tractable and when this exactly stops.\nSurprisingly, several cases are of very high intractability (paraNP and\nbeyond).\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 16:34:42 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Mahmood", "Yasir", ""], ["Meier", "Arne", ""], ["Schmidt", "Johannes", ""]]}, {"id": "2102.11828", "submitter": "Sergey Goncharov", "authors": "Sergey Goncharov", "title": "Uniform Elgot Iteration in Foundations", "comments": "Full version of ICALP 2021 accepted paper", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2021.131", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Category theory is famous for its innovative way of thinking of concepts by\ntheir descriptions, in particular by establishing universal properties.\nConcepts that can be characterized in a universal way receive a certain quality\nseal, which makes them easily transferable across application domains. The\nnotion of partiality is however notoriously difficult to characterize in this\nway, although the importance of it is certain, especially for computer science\nwhere entire research areas, such as synthetic and axiomatic domain theory\nrevolve around notions of partiality. More recently, this issue resurfaced in\nthe context of (constructive) intensional type theory. Here, we provide a\ngeneric categorical iteration-based notion of partiality, which is arguably the\nmost basic one. We show that the emerging free structures, which we dub\nuniform-iteration algebras enjoy various desirable properties, in particular,\nyield an equational lifting monad. We then study the impact of classicality\nassumptions and choice principles on this monad, in particular, we establish a\nsuitable categorial formulation of the axiom of countable choice entailing that\nthe monad is an Elgot monad.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:00:32 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 19:31:54 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Goncharov", "Sergey", ""]]}, {"id": "2102.11854", "submitter": "Joshua Brakensiek", "authors": "Joshua Brakensiek, Venkatesan Guruswami, Sai Sandeep", "title": "Conditional Dichotomy of Boolean Ordered Promise CSPs", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promise Constraint Satisfaction Problems (PCSPs) are a generalization of\nConstraint Satisfaction Problems (CSPs) where each predicate has a strong and a\nweak form and given a CSP instance, the objective is to distinguish if the\nstrong form can be satisfied vs. even the weak form cannot be satisfied. Since\ntheir formal introduction by Austrin, Guruswami, and H\\aa stad, there has been\na flurry of works on PCSPs [BBKO19,KO19,WZ20]. The key tool in studying PCSPs\nis the algebraic framework developed in the context of CSPs where the closure\nproperties of the satisfying solutions known as the polymorphisms are analyzed.\n  The polymorphisms of PCSPs are much richer than CSPs. In the Boolean case, we\nstill do not know if dichotomy for PCSPs exists analogous to Schaefer's\ndichotomy result for CSPs. In this paper, we study a special case of Boolean\nPCSPs, namely Boolean Ordered PCSPs where the Boolean PCSPs have the predicate\n$x \\leq y$. In the algebraic framework, this is the special case of Boolean\nPCSPs when the polymorphisms are monotone functions. We prove that Boolean\nOrdered PCSPs exhibit a computational dichotomy assuming the Rich 2-to-1\nConjecture [BKM21] which is a perfect completeness surrogate of the Unique\nGames Conjecture.\n  Assuming the Rich 2-to-1 Conjecture, we prove that a Boolean Ordered PCSP can\nbe solved in polynomial time if for every $\\epsilon>0$, it has polymorphisms\nwhere each coordinate has Shapley value at most $\\epsilon$, else it is NP-hard.\nThe algorithmic part of our dichotomy is based on a structural lemma that\nBoolean monotone functions with each coordinate having low Shapley value have\narbitrarily large threshold functions as minors. The hardness part proceeds by\nshowing that the Shapley value is consistent under a uniformly random 2-to-1\nminor. Of independent interest, we show that the Shapley value can be\ninconsistent under an adversarial 2-to-1 minor.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:34:13 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Brakensiek", "Joshua", ""], ["Guruswami", "Venkatesan", ""], ["Sandeep", "Sai", ""]]}, {"id": "2102.11924", "submitter": "Henry Soldano", "authors": "Henry Soldano", "title": "Finite Confluences and Closed Pattern Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this article is to propose and investigate a partial order\nstructure weaker than the lattice structure and which have nice properties\nregarding closure operators. We extend accordingly closed pattern mining and\nformal concept analysis to such structures we further call confluences. The\nprimary motivation for investigating these structures is that it allows to\nreduce a lattice to a part whose elements are connected, as in some graph,\nstill preserving a useful characterization of closure operators. Our\ninvestigation also considers how reducing one of the lattice involved in a\nGalois connection affects the structure of the closure operators ranges. When\nextending this way formal concept analysis we will focus on the intensional\nspace, i.e. in reducing the pattern language, while recent investigations\nrather explored the reduction of the extensional space to connected elements.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 09:12:46 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Soldano", "Henry", ""]]}, {"id": "2102.11991", "submitter": "Tzanis Anevlavis", "authors": "Tzanis Anevlavis, Matthew Philippe, Daniel Neider, Paulo Tabuada", "title": "Being correct is not enough: efficient verification using robust linear\n  temporal logic", "comments": "arXiv admin note: text overlap with arXiv:1510.08970", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most approaches in formal methods address system correctness, ensuring\nrobustness has remained a challenge. In this paper we introduce the logic rLTL\nwhich provides a means to formally reason about both correctness and robustness\nin system design. Furthermore, we identify a large fragment of rLTL for which\nthe verification problem can be efficiently solved, i.e., verification can be\ndone by using an automaton, recognizing the behaviors described by the rLTL\nformula $\\varphi$, of size at most $\\mathcal{O} \\left( 3^{ |\\varphi|} \\right)$,\nwhere $|\\varphi|$ is the length of $\\varphi$. This result improves upon the\npreviously known bound of $\\mathcal{O}\\left(5^{|\\varphi|} \\right)$ for rLTL\nverification and is closer to the LTL bound of $\\mathcal{O}\\left( 2^{|\\varphi|}\n\\right)$. The usefulness of this fragment is demonstrated by a number of case\nstudies showing its practical significance in terms of expressiveness, the\nability to describe robustness, and the fine-grained information that rLTL\nbrings to the process of system verification. Moreover, these advantages come\nat a low computational overhead with respect to LTL verification.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 00:14:00 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Anevlavis", "Tzanis", ""], ["Philippe", "Matthew", ""], ["Neider", "Daniel", ""], ["Tabuada", "Paulo", ""]]}, {"id": "2102.12151", "submitter": "Alexander Felfernig", "authors": "Alexander Felfernig and Christoph Zehentner and Paul Blazek", "title": "CoreDiag: Eliminating Redundancy in Constraint Sets", "comments": "A. Felfernig, C. Zehentner, and P. Blazek. COREDIAG: Eliminating\n  Redundancy in Constraint Sets. In the 22nd International Workshop on\n  Principles of Diagnosis, Murnau, Germany, pp. 219-224, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based environments such as configuration systems, recommender\nsystems, and scheduling systems support users in different decision making\nscenarios. These environments exploit a knowledge base for determining\nsolutions of interest for the user. The development and maintenance of such\nknowledge bases is an extremely time-consuming and error-prone task. Users\noften specify constraints which do not reflect the real-world. For example,\nredundant constraints are specified which often increase both, the effort for\ncalculating a solution and efforts related to knowledge base development and\nmaintenance. In this paper we present a new algorithm (CoreDiag) which can be\nexploited for the determination of minimal cores (minimal non-redundant\nconstraint sets). The algorithm is especially useful for distributed knowledge\nengineering scenarios where the degree of redundancy can become high. In order\nto show the applicability of our approach, we present an empirical study\nconducted with commercial configuration knowledge bases.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 09:16:10 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Felfernig", "Alexander", ""], ["Zehentner", "Christoph", ""], ["Blazek", "Paul", ""]]}, {"id": "2102.12201", "submitter": "Steffen van Bergerem", "authors": "Steffen van Bergerem, Martin Grohe, Martin Ritzert", "title": "On the Parameterized Complexity of Learning First-Order Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyse the complexity of learning first-order queries in a\nmodel-theoretic framework for supervised learning introduced by (Grohe and\nTur\\'an, TOCS 2004). Previous research on the complexity of learning in this\nframework focussed on the question of when learning is possible in time\nsublinear in the background structure.\n  Here we study the parameterized complexity of the learning problem. We have\ntwo main results. The first is a hardness result, showing that learning\nfirst-order queries is at least as hard as the corresponding model-checking\nproblem, which implies that on general structures it is hard for the\nparameterized complexity class AW[*]. Our second main contribution is a\nfixed-parameter tractable agnostic PAC learning algorithm for first-order\nqueries over sparse relational data (more precisely, over nowhere dense\nbackground structures).\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 10:54:49 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 11:45:10 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["van Bergerem", "Steffen", ""], ["Grohe", "Martin", ""], ["Ritzert", "Martin", ""]]}, {"id": "2102.12551", "submitter": "Rolf Morel", "authors": "Rolf Morel, Andrew Cropper", "title": "Learning Logic Programs by Explaining Failures", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientists form hypotheses and experimentally test them. If a hypothesis\nfails (is refuted), scientists try to explain the failure to eliminate other\nhypotheses. We introduce similar explanation techniques for inductive logic\nprogramming (ILP). We build on the ILP approach learning from failures. Given a\nhypothesis represented as a logic program, we test it on examples. If a\nhypothesis fails, we identify clauses and literals responsible for the failure.\nBy explaining failures, we can eliminate other hypotheses that will provably\nfail. We introduce a technique for failure explanation based on analysing\nSLD-trees. We experimentally evaluate failure explanation in the Popper ILP\nsystem. Our results show that explaining failures can drastically reduce\nlearning times.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 14:32:20 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Morel", "Rolf", ""], ["Cropper", "Andrew", ""]]}, {"id": "2102.12553", "submitter": "Rolf Morel", "authors": "Rolf Morel", "title": "Refinement Type Directed Search for Meta-Interpretive-Learning of\n  Higher-Order Logic Programs", "comments": "Oxford 2018 MSc thesis; 82 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The program synthesis problem within the Inductive Logic Programming (ILP)\ncommunity has typically been seen as untyped. We consider the benefits of user\nprovided types on background knowledge. Building on the Meta-Interpretive\nLearning (MIL) framework, we show that type checking is able to prune large\nparts of the hypothesis space of programs. The introduction of polymorphic type\nchecking to the MIL approach to logic program synthesis is validated by strong\ntheoretical and experimental results, showing a cubic reduction in the size of\nthe search space and synthesis time, in terms of the number of typed background\npredicates. Additionally we are able to infer polymorphic types of synthesized\nclauses and of entire programs. The other advancement is in developing an\napproach to leveraging refinement types in ILP. Here we show that further\npruning of the search space can be achieved, though the SMT solving used for\nrefinement type checking comes\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 13:40:16 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Morel", "Rolf", ""]]}, {"id": "2102.12842", "submitter": "Hans-Peter Deifel", "authors": "Hans-Peter Deifel, Stefan Milius, Thorsten Wi{\\ss}mann", "title": "Coalgebra Encoding for Efficient Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, we have developed an efficient generic partition refinement\nalgorithm, which computes behavioural equivalence on a state-based system given\nas an encoded coalgebra, and implemented it in the tool CoPaR. Here we extend\nthis to a fully fledged minimization algorithm and tool by integrating two new\naspects: (1) the computation of the transition structure on the minimized state\nset, and (2) the computation of the reachable part of the given system. In our\ngeneric coalgebraic setting these two aspects turn out to be surprisingly\nnon-trivial requiring us to extend the previous theory. In particular, we\nidentify a sufficient condition on encodings of coalgebras, and we show how to\naugment the existing interface, which encapsulates computations that are\nspecific for the coalgebraic type functor, to make the above extensions\npossible. Both extensions have linear run time.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 13:29:04 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 17:36:40 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Deifel", "Hans-Peter", ""], ["Milius", "Stefan", ""], ["Wi\u00dfmann", "Thorsten", ""]]}, {"id": "2102.12855", "submitter": "Mingyu Cai", "authors": "Mingyu Cai, Mohammadhosein Hasanbeig, Shaoping Xiao, Alessandro Abate\n  and Zhen Kan", "title": "Modular Deep Reinforcement Learning for Continuous Motion Planning with\n  Temporal Logic", "comments": "arXiv admin note: text overlap with arXiv:2010.06797", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the motion planning of autonomous dynamical systems\nmodeled by Markov decision processes (MDP) with unknown transition\nprobabilities over continuous state and action spaces. Linear temporal logic\n(LTL) is used to specify high-level tasks over infinite horizon, which can be\nconverted into a limit deterministic generalized B\\\"uchi automaton (LDGBA) with\nseveral accepting sets. The novelty is to design an embedded product MDP\n(EP-MDP) between the LDGBA and the MDP by incorporating a synchronous\ntracking-frontier function to record unvisited accepting sets of the automaton,\nand to facilitate the satisfaction of the accepting conditions. The proposed\nLDGBA-based reward shaping and discounting schemes for the model-free\nreinforcement learning (RL) only depend on the EP-MDP states and can overcome\nthe issues of sparse rewards. Rigorous analysis shows that any RL method that\noptimizes the expected discounted return is guaranteed to find an optimal\npolicy whose traces maximize the satisfaction probability. A modular deep\ndeterministic policy gradient (DDPG) is then developed to generate such\npolicies over continuous state and action spaces. The performance of our\nframework is evaluated via an array of OpenAI gym environments.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 01:11:25 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 18:52:06 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 16:26:14 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Cai", "Mingyu", ""], ["Hasanbeig", "Mohammadhosein", ""], ["Xiao", "Shaoping", ""], ["Abate", "Alessandro", ""], ["Kan", "Zhen", ""]]}, {"id": "2102.13291", "submitter": "Zhiguang Zhao", "authors": "Zhiguang Zhao", "title": "Algorithmic Correspondence for Hybrid Logic with Binder", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.08070", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we develop the algorithmic correspondence theory for\nhybrid logic with binder. We define the class of Sahlqvist inequalities, each\ninequality of which is shown to have a first-order frame correspondent\neffectively computable by an algorithm ALBA.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 03:18:21 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 03:57:55 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhao", "Zhiguang", ""]]}]