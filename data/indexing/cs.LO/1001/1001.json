[{"id": "1001.0441", "submitter": "Rajkumar Kannan", "authors": "Rajkumar Kannan, Balakrishnan Ramadoss", "title": "Semantic Modeling and Retrieval of Dance Video Annotations", "comments": "INFOCOMP Journal of Computer Science, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dance video is one of the important types of narrative videos with semantic\nrich content. This paper proposes a new meta model, Dance Video Content Model\n(DVCM) to represent the expressive semantics of the dance videos at multiple\ngranularity levels. The DVCM is designed based on the concepts such as video,\nshot, segment, event and object, which are the components of MPEG-7 MDS. This\npaper introduces a new relationship type called Temporal Semantic Relationship\nto infer the semantic relationships between the dance video objects. Inverted\nfile based index is created to reduce the search time of the dance queries. The\neffectiveness of containment queries using precision and recall is depicted.\nKeywords: Dance Video Annotations, Effectiveness Metrics, Metamodeling,\nTemporal Semantic Relationships.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2010 05:32:05 GMT"}], "update_date": "2010-01-05", "authors_parsed": [["Kannan", "Rajkumar", ""], ["Ramadoss", "Balakrishnan", ""]]}, {"id": "1001.0641", "submitter": "Pierre Clairambault", "authors": "Pierre Clairambault (PPS)", "title": "Least and greatest fixpoints in game semantics", "comments": null, "journal-ref": "Foundations of Software Science and Computational Structures, York\n  : United Kingdom (2009)", "doi": "10.1007/978-3-642-00596-1_3", "report-no": null, "categories": "cs.LO cs.GT cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how solutions to many recursive arena equations can be computed in a\nnatural way by allowing loops in arenas. We then equip arenas with winning\nfunctions and total winning strategies. We present two natural winning\nconditions compatible with the loop construction which respectively provide\ninitial algebras and terminal coalgebras for a large class of continuous\nfunctors. Finally, we introduce an intuitionistic sequent calculus, extended\nwith syntactic constructions for least and greatest fixed points, and prove it\nhas a sound and (in a certain weak sense) complete interpretation in our game\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2010 07:31:37 GMT"}], "update_date": "2010-01-06", "authors_parsed": [["Clairambault", "Pierre", "", "PPS"]]}, {"id": "1001.0735", "submitter": "Lutz Schr\\\"oder", "authors": "Lutz Schroeder and Dirk Pattinson", "title": "Named Models in Coalgebraic Hybrid Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid logic extends modal logic with support for reasoning about individual\nstates, designated by so-called nominals. We study hybrid logic in the broad\ncontext of coalgebraic semantics, where Kripke frames are replaced with\ncoalgebras for a given functor, thus covering a wide range of reasoning\nprinciples including, e.g., probabilistic, graded, default, or coalitional\noperators. Specifically, we establish generic criteria for a given coalgebraic\nhybrid logic to admit named canonical models, with ensuing completeness proofs\nfor pure extensions on the one hand, and for an extended hybrid language with\nlocal binding on the other. We instantiate our framework with a number of\nexamples. Notably, we prove completeness of graded hybrid logic with local\nbinding.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2010 17:25:01 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 14:03:16 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Schroeder", "Lutz", ""], ["Pattinson", "Dirk", ""]]}, {"id": "1001.0820", "submitter": "Yuliya Lierler", "authors": "Yuliya Lierler", "title": "Abstract Answer Set Solvers with Learning", "comments": "Long version of the paper that will appear in special issue of Theory\n  and Practice of Logic Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nieuwenhuis, Oliveras, and Tinelli (2006) showed how to describe enhancements\nof the Davis-Putnam-Logemann-Loveland algorithm using transition systems,\ninstead of pseudocode. We design a similar framework for several algorithms\nthat generate answer sets for logic programs: Smodels, Smodels-cc, Asp-Sat with\nLearning (Cmodels), and a newly designed and implemented algorithm Sup. This\napproach to describing answer set solvers makes it easier to prove their\ncorrectness, to compare them, and to design new systems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2010 05:53:29 GMT"}], "update_date": "2010-01-07", "authors_parsed": [["Lierler", "Yuliya", ""]]}, {"id": "1001.1043", "submitter": "Shang Yun", "authors": "Ruqian Lu, Lixing Li, Yun Shang, Xiaoyu Li", "title": "Process Algebra as Abstract Data Types", "comments": "74pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduced an algebraic semantics for process algebra in\nform of abstract data types. For that purpose, we developed a particular type\nof algebra, the seed algebra, which describes exactly the behavior of a process\nwithin a labeled transition system. We have shown the possibility of\ncharacterizing the bisimulation of two processes with the isomorphism of their\ncorresponding seed algebras. We pointed out that the traditional concept of\nisomorphism of algebra does not apply here, because there is even no one-one\ncorrespondence between the elements of two seed algebras. The lack of this\none-one correspondence comes from the non-deterministic choice of transitions\nof a process. We introduce a technique of hidden operations to mask unwanted\ndetails of elements of a seed algebra, which only reflect non-determinism or\nother implicit control mechanism of process transition. Elements of a seed\nalgebra are considered as indistinguishable if they show the same behavior\nafter these unwanted details are masked. Each class of indistinguishable\nelements is called a non-hidden closure. We proved that bisimulation of two\nprocesses is equivalent to isomorphism of non-hidden closures of two seed\nalgebras representing these two processes. We call this kind of isomorphism a\ndeep isomorphism. We get different models of seed algebra by specifying\ndifferent axiom systems for the same signature. Each model corresponds to a\ndifferent kind of bisimulation. By proving the relations between these models\nwe also established relations between 10 different bisimulations, which form a\nacyclic directed graph.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2010 09:58:04 GMT"}], "update_date": "2010-01-08", "authors_parsed": [["Lu", "Ruqian", ""], ["Li", "Lixing", ""], ["Shang", "Yun", ""], ["Li", "Xiaoyu", ""]]}, {"id": "1001.1526", "submitter": "Fatih Basciftci", "authors": "Fatih Basciftci, Sirzat Kahramanli", "title": "A Reduced Offset Based Method for Fast Computation of the Prime\n  Implicants Covering a Given Cube", "comments": "35 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to generate prime implicants for a given cube (minterm), most of\nminimization methods increase the dimension of this cube by removing one\nliteral from it at a time. But there are two problems of exponential\ncomplexity. One of them is the selection of the order in which the literals are\nto be removed from the implicant at hand. The latter is the mechanism that\nchecks whether a tentative literal removal is acceptable. The reduced Offset\nconcept has been developed to avoid of these problems. This concept is based on\npositional-cube representation where each cube is represented by two n-bit\nstrings. We show that each reduced Off-cube may be represented by a single\nn-bit string and propose a set of bitwise operations to be performed on such\nstrings. The experiments on single-output benchmarks show that this approach\ncan significantly speed up the minimization process, improve the quality of its\nresults and reduce the amount of memory required for this aim.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2010 15:42:36 GMT"}], "update_date": "2010-01-12", "authors_parsed": [["Basciftci", "Fatih", ""], ["Kahramanli", "Sirzat", ""]]}, {"id": "1001.1662", "submitter": "Dominique Duval", "authors": "Jean-Guillaume Dumas (LJK), Dominique Duval (LJK), Laurent Fousse\n  (LJK), Jean-Claude Reynaud (RC)", "title": "States and exceptions considered as dual effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the two major computational effects of states and\nexceptions, from the point of view of diagrammatic logics. We get a surprising\nresult: there exists a symmetry between these two effects, based on the\nwell-known categorical duality between products and coproducts. More precisely,\nthe lookup and update operations for states are respectively dual to the throw\nand catch operations for exceptions. This symmetry is deeply hidden in the\nprogramming languages; in order to unveil it, we start from the monoidal\nequational logic and we add progressively the logical features which are\nnecessary for dealing with either effect. This approach gives rise to a new\npoint of view on states and exceptions, which bypasses the problems due to the\nnon-algebraicity of handling exceptions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2010 14:12:08 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2010 13:38:05 GMT"}, {"version": "v3", "created": "Mon, 31 May 2010 09:02:30 GMT"}, {"version": "v4", "created": "Fri, 20 May 2011 09:05:16 GMT"}], "update_date": "2011-05-23", "authors_parsed": [["Dumas", "Jean-Guillaume", "", "LJK"], ["Duval", "Dominique", "", "LJK"], ["Fousse", "Laurent", "", "LJK"], ["Reynaud", "Jean-Claude", "", "RC"]]}, {"id": "1001.1933", "submitter": "Ashutosh Trivedi Dr", "authors": "Marta Kwiatkowska, Gethin Norman, and Ashutosh Trivedi", "title": "Quantitative Games on Probabilistic Timed Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-player zero-sum games are a well-established model for synthesising\ncontrollers that optimise some performance criterion. In such games one player\nrepresents the controller, while the other describes the (adversarial)\nenvironment, and controller synthesis corresponds to computing the optimal\nstrategies of the controller for a given criterion. Asarin and Maler initiated\nthe study of quantitative games on (non-probabilistic) timed automata by\nsynthesising controllers which optimise the time to reach a final state. The\ncorrectness and termination of their approach was dependent on exploiting the\nproperties of a special class of functions, called simple functions, that can\nbe finitely represented. In this paper we consider quantitative games over\nprobabilistic timed automata. Since the concept of simple functions is not\nsufficient to solve games in this setting, we generalise simple functions to\nso-called quasi-simple functions. Then, using this class of functions, we\ndemonstrate that the problem of solving games with either expected\nreachability-time or expected discounted-time criteria on probabilistic timed\nautomata are in NEXPTIME $\\cap$ co-NEXPTIME.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 16:18:40 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2010 11:02:29 GMT"}], "update_date": "2010-06-04", "authors_parsed": [["Kwiatkowska", "Marta", ""], ["Norman", "Gethin", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1001.1960", "submitter": "Lila Fontes", "authors": "Lila Fontes", "title": "Formal Theories for Logspace Counting", "comments": "33 pages, uses newalg.sty (file included)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two-sorted theories in the style of Cook and Nguyen for the\ncomplexity classes ParityL and DET, whose complete problems include\ndeterminants over GF(2) and Z, respectively. The definable functions in these\ntheories are the functions in the corresponding complexity classes; thus each\ntheory formalizes reasoning using concepts from its corresponding complexity\nclass.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 17:59:31 GMT"}], "update_date": "2010-01-13", "authors_parsed": [["Fontes", "Lila", ""]]}, {"id": "1001.1979", "submitter": "Rdv Ijcsis", "authors": "P.Chinniah, Dr.S.Muttan", "title": "ICD 10 Based Medical Expert System Using Fuzzy Temporal Logic", "comments": "6 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS December 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 3, pp. 084-089, December 2009, USA", "doi": null, "report-no": "Volume 6, No. 3, ISSN 1947 5500", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical diagnosis process involves many levels and considerable amount of\ntime and money are invariably spent for the first level of diagnosis usually\nmade by the physician for all the patients every time. Hence there is a need\nfor a computer based system which not only asks relevant questions to the\npatients but also aids the physician by giving a set of possible diseases from\nthe symptoms obtained using logic at inference. In this work, an ICD10 based\nMedical Expert System that provides advice, information and recommendation to\nthe physician using fuzzy temporal logic. The knowledge base used in this\nsystem consists of facts of symptoms and rules on diseases. It also provides\nfuzzy severity scale and weight factor for symptom and disease and can vary\nwith respect to time. The system generates the possible disease conditions\nbased on modified Euclidean metric using Elders algorithm for effective\nclustering. The minimum similarity value is used as the decision parameter to\nidentify a disease.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 18:53:19 GMT"}], "update_date": "2010-01-13", "authors_parsed": [["Chinniah", "P.", ""], ["Muttan", "Dr. S.", ""]]}, {"id": "1001.2086", "submitter": "Markus Lohrey", "authors": "Dietrich Kuske, Jiamou Liu and Markus Lohrey", "title": "The Isomorphism Problem On Classes of Automatic Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic structures are finitely presented structures where the universe and\nall relations can be recognized by finite automata. It is known that the\nisomorphism problem for automatic structures is complete for $\\Sigma^1_1$; the\nfirst existential level of the analytical hierarchy. Several new results on\nisomorphism problems for automatic structures are shown in this paper: (i) The\nisomorphism problem for automatic equivalence relations is complete for\n$\\Pi^0_1$ (first universal level of the arithmetical hierarchy). (ii) The\nisomorphism problem for automatic trees of height $n \\geq 2$ is\n$\\Pi^0_{2n-3}$-complete. (iii) The isomorphism problem for automatic linear\norders is not arithmetical. This solves some open questions of Khoussainov,\nRubin, and Stephan.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 07:28:23 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Kuske", "Dietrich", ""], ["Liu", "Jiamou", ""], ["Lohrey", "Markus", ""]]}, {"id": "1001.2100", "submitter": "Carlo Alberto Furia", "authors": "Carlo A. Furia", "title": "What's Decidable About Sequences?", "comments": "Fixed a few lapses in the Mergesort example", "journal-ref": "Proceedings of the 8th International Symposium on Automated\n  Technology for Verification and Analysis (ATVA'10). Lecture Notes in Computer\n  Science, 6252:128--142, Springer-Verlag, September 2010", "doi": "10.1007/978-3-642-15643-4_11", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a first-order theory of sequences with integer elements,\nPresburger arithmetic, and regular constraints, which can model significant\nproperties of data structures such as arrays and lists. We give a decision\nprocedure for the quantifier-free fragment, based on an encoding into the\nfirst-order theory of concatenation; the procedure has PSPACE complexity. The\nquantifier-free fragment of the theory of sequences can express properties such\nas sortedness and injectivity, as well as Boolean combinations of periodic and\narithmetic facts relating the elements of the sequence and their positions\n(e.g., \"for all even i's, the element at position i has value i+3 or 2i\"). The\nresulting expressive power is orthogonal to that of the most expressive\ndecidable logics for arrays. Some examples demonstrate that the fragment is\nalso suitable to reason about sequence-manipulating programs within the\nstandard framework of axiomatic semantics.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 16:21:06 GMT"}, {"version": "v2", "created": "Thu, 10 Feb 2011 10:36:29 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Furia", "Carlo A.", ""]]}, {"id": "1001.2160", "submitter": "Serge Grigorieff", "authors": "Serge Grigorieff and Pierre Valarcher", "title": "Evolving MultiAlgebras unify all usual sequential computation models", "comments": "12 pages, Symposium on Theoretical Aspects of Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  It is well-known that Abstract State Machines (ASMs) can simulate\n\"step-by-step\" any type of machines (Turing machines, RAMs, etc.). We aim to\novercome two facts: 1) simulation is not identification, 2) the ASMs simulating\nmachines of some type do not constitute a natural class among all ASMs. We\nmodify Gurevich's notion of ASM to that of EMA (\"Evolving MultiAlgebra\") by\nreplacing the program (which is a syntactic object) by a semantic object: a\nfunctional which has to be very simply definable over the static part of the\nASM. We prove that very natural classes of EMAs correspond via \"literal\nidentifications\" to slight extensions of the usual machine models and also to\ngrammar models. Though we modify these models, we keep their computation\napproach: only some contingencies are modified. Thus, EMAs appear as the\nmathematical model unifying all kinds of sequential computation paradigms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 13:35:20 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 11:53:47 GMT"}], "update_date": "2010-03-26", "authors_parsed": [["Grigorieff", "Serge", ""], ["Valarcher", "Pierre", ""]]}, {"id": "1001.2175", "submitter": "Christian Mathissen", "authors": "Christian Mathissen", "title": "Weighted Logics for Nested Words and Algebraic Formal Power Series", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 1 (February\n  19, 2010) lmcs:854", "doi": "10.2168/LMCS-6(1:5)2010", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested words, a model for recursive programs proposed by Alur and Madhusudan,\nhave recently gained much interest. In this paper we introduce quantitative\nextensions and study nested word series which assign to nested words elements\nof a semiring. We show that regular nested word series coincide with series\ndefinable in weighted logics as introduced by Droste and Gastin. For this we\nestablish a connection between nested words and the free bisemigroup. Applying\nour result, we obtain characterizations of algebraic formal power series in\nterms of weighted logics. This generalizes results of Lautemann, Schwentick and\nTherien on context-free languages.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 14:21:36 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2010 21:52:26 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Mathissen", "Christian", ""]]}, {"id": "1001.2416", "submitter": "Marcel Wild", "authors": "Marcel Wild", "title": "Computing the output distribution and selection probabilities of a stack\n  filter from the DNF of its positive Boolean function", "comments": "This is the version published in Journal of Mathematical Imaging and\n  Vision, online first, 1 august 2012", "journal-ref": "Journal of Mathematical Imaging and Vision 46 (2013) 66-73", "doi": "10.1007/s10851-012-0370-y", "report-no": null, "categories": "cs.LO cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many nonlinear filters used in practise are stack filters. An algorithm is\npresented which calculates the output distribution of an arbitrary stack filter\nS from the disjunctive normal form (DNF) of its underlying positive Boolean\nfunction. The so called selection probabilities can be computed along the way.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2010 11:00:33 GMT"}, {"version": "v2", "created": "Mon, 29 Nov 2010 10:29:00 GMT"}, {"version": "v3", "created": "Wed, 8 Dec 2010 14:40:45 GMT"}, {"version": "v4", "created": "Thu, 2 Jun 2011 11:09:45 GMT"}, {"version": "v5", "created": "Fri, 4 Nov 2011 17:18:42 GMT"}, {"version": "v6", "created": "Mon, 27 Aug 2012 14:10:22 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Wild", "Marcel", ""]]}, {"id": "1001.2508", "submitter": "Julien Brusten", "authors": "Bernard Boigelot, Julien Brusten, Veronique Bruyere", "title": "On the Sets of Real Numbers Recognized by Finite Automata in Multiple\n  Bases", "comments": "17 pages", "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 1 (February\n  24, 2010) lmcs:818", "doi": "10.2168/LMCS-6(1:6)2010", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies the expressive power of finite automata recognizing sets\nof real numbers encoded in positional notation. We consider Muller automata as\nwell as the restricted class of weak deterministic automata, used as symbolic\nset representations in actual applications. In previous work, it has been\nestablished that the sets of numbers that are recognizable by weak\ndeterministic automata in two bases that do not share the same set of prime\nfactors are exactly those that are definable in the first order additive theory\nof real and integer numbers. This result extends Cobham's theorem, which\ncharacterizes the sets of integer numbers that are recognizable by finite\nautomata in multiple bases.\n  In this article, we first generalize this result to multiplicatively\nindependent bases, which brings it closer to the original statement of Cobham's\ntheorem. Then, we study the sets of reals recognizable by Muller automata in\ntwo bases. We show with a counterexample that, in this setting, Cobham's\ntheorem does not generalize to multiplicatively independent bases. Finally, we\nprove that the sets of reals that are recognizable by Muller automata in two\nbases that do not share the same set of prime factors are exactly those\ndefinable in the first order additive theory of real and integer numbers. These\nsets are thus also recognizable by weak deterministic automata. This result\nleads to a precise characterization of the sets of real numbers that are\nrecognizable in multiple bases, and provides a theoretical justification to the\nuse of weak automata as symbolic representations of sets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2010 17:40:10 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2010 16:34:18 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Boigelot", "Bernard", ""], ["Brusten", "Julien", ""], ["Bruyere", "Veronique", ""]]}, {"id": "1001.2572", "submitter": "Martin Grohe", "authors": "Martin Grohe", "title": "Fixed-Point Definability and Polynomial Time on Chordal Graphs and Line\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of whether there is a logic that captures polynomial time was\nformulated by Yuri Gurevich in 1988. It is still wide open and regarded as one\nof the main open problems in finite model theory and database theory. Partial\nresults have been obtained for specific classes of structures. In particular,\nit is known that fixed-point logic with counting captures polynomial time on\nall classes of graphs with excluded minors. The introductory part of this paper\nis a short survey of the state-of-the-art in the quest for a logic capturing\npolynomial time.\n  The main part of the paper is concerned with classes of graphs defined by\nexcluding induced subgraphs. Two of the most fundamental such classes are the\nclass of chordal graphs and the class of line graphs. We prove that capturing\npolynomial time on either of these classes is as hard as capturing it on the\nclass of all graphs. In particular, this implies that fixed-point logic with\ncounting does not capture polynomial time on these classes. Then we prove that\nfixed-point logic with counting does capture polynomial time on the class of\nall graphs that are both chordal and line graphs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2010 22:14:00 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2010 14:32:32 GMT"}], "update_date": "2010-04-30", "authors_parsed": [["Grohe", "Martin", ""]]}, {"id": "1001.2811", "submitter": "Krishnendu Chatterjee", "authors": "Yashdeep Godhal and Krishnendu Chatterjee and Thomas A. Henzinger", "title": "Synthesis of AMBA AHB from Formal Specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard procedure for hardware design consists of describing circuit in\na hardware description language at logic level followed by extensive\nverification and logic-synthesis. However, this process consumes significant\ntime and needs a lot of effort. An alternative is to use formal specification\nlanguage as a high-level hardware description language and synthesize hardware\nfrom formal specification. Bloem et.al. gave formal specifications and\nsynthesize the AMBA AHB Arbiter. Our contributions are as follows:(1) We\npresent more complete and compact formal specifications for the AMBA AHB\nArbiter, and obtain significant (order of magnitude) improvement in synthesis\nresults (both with respect to time and the number of gates of the synthesize\ncircuit); (2) we present formal specification and synthesize to generate\ncompact circuits for the remaining two components of the AMBA AHB protocol,\nnamely, the AMBA AHB Master and AMBA AHB Slave; and (3) from the lessons learnt\nwe present few principles for writing formal specifications for efficient\nhardware synthesis. Thus with intelligently written complete formal\nspecifications we are able to automatically synthesize an important and widely\nused industrial protocol.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2010 08:32:17 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2010 21:18:51 GMT"}], "update_date": "2010-02-01", "authors_parsed": [["Godhal", "Yashdeep", ""], ["Chatterjee", "Krishnendu", ""], ["Henzinger", "Thomas A.", ""]]}, {"id": "1001.2932", "submitter": "Artur Je\\.z", "authors": "Artur Je\\.z, Alexander Okhotin", "title": "On equations over sets of integers", "comments": "12 apges, 0 figures", "journal-ref": "Theory of Computing Systems 51:2, 2012, pages 196-228", "doi": "10.1007/s00224-011-9352-5", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Systems of equations with sets of integers as unknowns are considered. It is\nshown that the class of sets representable by unique solutions of equations\nusing the operations of union and addition $S+T=\\makeset{m+n}{m \\in S, \\: n \\in\nT}$ and with ultimately periodic constants is exactly the class of\nhyper-arithmetical sets. Equations using addition only can represent every\nhyper-arithmetical set under a simple encoding. All hyper-arithmetical sets can\nalso be represented by equations over sets of natural numbers equipped with\nunion, addition and subtraction $S \\dotminus T=\\makeset{m-n}{m \\in S, \\: n \\in\nT, \\: m \\geqslant n}$. Testing whether a given system has a solution is\n$\\Sigma^1_1$-complete for each model. These results, in particular, settle the\nexpressive power of the most general types of language equations, as well as\nequations over subsets of free groups.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2010 22:32:49 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2010 12:31:39 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Je\u017c", "Artur", ""], ["Okhotin", "Alexander", ""]]}, {"id": "1001.3219", "submitter": "Thomas Ehrhard", "authors": "Thomas Ehrhard (PPS)", "title": "A finiteness structure on resource terms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our paper \"Uniformity and the Taylor expansion of ordinary lambda-terms\"\n(with Laurent Regnier), we studied a translation of lambda-terms as infinite\nlinear combinations of resource lambda-terms, from a calculus similar to\nBoudol's lambda-calculus with resources and based on ideas coming from\ndifferential linear logic and differential lambda-calculus. The good properties\nof this translation wrt. beta-reduction were guaranteed by a coherence relation\non resource terms: normalization is \"linear and stable\" (in the sense of the\ncoherence space semantics of linear logic) wrt. this coherence relation. Such\ncoherence properties are lost when one considers non-deterministic or algebraic\nextensions of the lambda-calculus (the algebraic lambda-calculus is an\nextension of the lambda-calculus where terms can be linearly combined). We\nintroduce a \"finiteness structure\" on resource terms which induces a linearly\ntopologized vector space structure on terms and prevents the appearance of\ninfinite coefficients during reduction, in typed settings.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 08:23:54 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Ehrhard", "Thomas", "", "PPS"]]}, {"id": "1001.3263", "submitter": "Bernd Schuh", "authors": "Bernd R. Schuh", "title": "A Real World Mechanism for Testing Satisfiability in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether the satisfiability of any formula F of propositional calculus can be\ndetermined in polynomial time is an open question. I propose a simple procedure\nbased on some real world mechanisms to tackle this problem. The main result is\nthe blueprint for a machine which is able to test any formula in conjunctive\nnormal form (CNF) for satisfiability in linear time. The device uses light and\nsome electrochemical properties to function. It adapts itself to the scope of\nthe problem without growing exponentially in mass with the size of the formula.\nIt requires infinite precision in its components instead.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 11:18:54 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Schuh", "Bernd R.", ""]]}, {"id": "1001.3368", "submitter": "Sandra Alves", "authors": "Sandra Alves (1), Maribel Fern\\'andez (2), M\\'ario Florido (1) and Ian\n  Mackie (3) ((1) University of Porto, (2) King's College London, (3) \\'Ecole\n  Polytechnique)", "title": "Linear Recursion", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define two extensions of the typed linear lambda-calculus that yield\nminimal Turing-complete systems. The extensions are based on unbounded\nrecursion in one case, and bounded recursion with minimisation in the other. We\nshow that both approaches are compatible with linearity and typeability\nconstraints. Both extensions of the typed linear lambda-calculus are minimal,\nin the sense that taking out any of the components breaks the universality of\nthe system. We discuss implementation techniques that exploit the linearity of\nthe calculi. Finally, we apply the results to languages with fixpoint\noperators: we give a compilation of the programming language PCF into a linear\nlambda-calculus with linear unbounded recursion.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 17:38:25 GMT"}, {"version": "v2", "created": "Thu, 14 Oct 2010 16:08:38 GMT"}, {"version": "v3", "created": "Fri, 14 Jan 2011 11:16:08 GMT"}, {"version": "v4", "created": "Fri, 25 Nov 2016 15:11:40 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Alves", "Sandra", ""], ["Fern\u00e1ndez", "Maribel", ""], ["Florido", "M\u00e1rio", ""], ["Mackie", "Ian", ""]]}, {"id": "1001.3464", "submitter": "Shamim Ripon", "authors": "Shamim H. Ripon, Michael Butler", "title": "Formalizing cCSP Synchronous Semantics in PVS", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compensating CSP (cCSP) is a language defined to model long running business\ntransactions within the framework of standard CSP process algebra. In earlier\nwork, we have defined both traces and operational semantics of the language. We\nhave shown the consistency between the two semantic models by defining a\nrelationship between them. Synchronization was missing from the earlier\nsemantic definitions which is an important feature for any process algebra. In\nthis paper, we address this issue by extending the syntax and semantics to\nsupport synchronization and define a relationship between the semantic models.\nMoreover, we improve the scalability of our proof technique by mechanically\nverifying the semantic relationship using theorem prover PVS. We show how to\nembed process algebra terms and semantics into PVS and to use these embeddings\nto prove the semantic relationship.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2010 17:52:02 GMT"}], "update_date": "2010-01-21", "authors_parsed": [["Ripon", "Shamim H.", ""], ["Butler", "Michael", ""]]}, {"id": "1001.4021", "submitter": "Mark Kaminski", "authors": "Mark Kaminski and Gert Smolka", "title": "A Minimal Propositional Type Theory", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional type theory, first studied by Henkin, is the restriction of\nsimple type theory to a single base type that is interpreted as the set of the\ntwo truth values. We show that two constants (falsity and implication) suffice\nfor denotational and deductive completeness. Denotational completeness means\nthat every value of the full set-theoretic type hierarchy can be described by a\nclosed term. Deductive completeness is shown for a sequent-based proof system\nthat extends a propositional natural deduction system with lambda conversion\nand Boolean replacement.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2010 16:05:07 GMT"}], "update_date": "2010-01-25", "authors_parsed": [["Kaminski", "Mark", ""], ["Smolka", "Gert", ""]]}, {"id": "1001.4251", "submitter": "Vincent Aravantinos", "authors": "Vincent Aravantinos, Ricardo Caferra, Nicolas Peltier", "title": "A Decidable Class of Nested Iterated Schemata (extended version)", "comments": "43 pages, extended version of \"A Decidable Class of Nested Iterated\n  Schemata\", submitted to IJCAR 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems can be specified by patterns of propositional formulae\ndepending on a parameter, e.g. the specification of a circuit usually depends\non the number of bits of its input. We define a logic whose formulae, called\n\"iterated schemata\", allow to express such patterns. Schemata extend\npropositional logic with indexed propositions, e.g. P_i, P_i+1, P_1, and with\ngeneralized connectives, e.g. /\\i=1..n or i=1..n (called \"iterations\") where n\nis an (unbound) integer variable called a \"parameter\". The expressive power of\niterated schemata is strictly greater than propositional logic: it is even out\nof the scope of first-order logic. We define a proof procedure, called DPLL*,\nthat can prove that a schema is satisfiable for at least one value of its\nparameter, in the spirit of the DPLL procedure. However the converse problem,\ni.e. proving that a schema is unsatisfiable for every value of the parameter,\nis undecidable so DPLL* does not terminate in general. Still, we prove that it\nterminates for schemata of a syntactic subclass called \"regularly nested\". This\nis the first non trivial class for which DPLL* is proved to terminate.\nFurthermore the class of regularly nested schemata is the first decidable class\nto allow nesting of iterations, i.e. to allow schemata of the form /\\i=1..n\n(/\\j=1..n ...).\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2010 16:16:35 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Aravantinos", "Vincent", ""], ["Caferra", "Ricardo", ""], ["Peltier", "Nicolas", ""]]}, {"id": "1001.4255", "submitter": "Arne Meier", "authors": "Arne Meier and Thomas Schneider", "title": "The Complexity of Satisfiability for Sub-Boolean Fragments of ALC", "comments": "17 pages, accepted (in short version) to Description Logic Workshop\n  2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard reasoning problem, concept satisfiability, in the basic\ndescription logic ALC is PSPACE-complete, and it is EXPTIME-complete in the\npresence of unrestricted axioms. Several fragments of ALC, notably logics in\nthe FL, EL, and DL-Lite family, have an easier satisfiability problem;\nsometimes it is even tractable. All these fragments restrict the use of Boolean\noperators in one way or another. We look at systematic and more general\nrestrictions of the Boolean operators and establish the complexity of the\nconcept satisfiability problem in the presence of axioms. We separate tractable\nfrom intractable cases.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2010 17:21:46 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2010 10:42:54 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2010 15:36:05 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2010 10:48:41 GMT"}, {"version": "v5", "created": "Fri, 19 Feb 2010 12:20:23 GMT"}, {"version": "v6", "created": "Mon, 29 Mar 2010 11:42:44 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Meier", "Arne", ""], ["Schneider", "Thomas", ""]]}, {"id": "1001.4381", "submitter": "EPTCS", "authors": "Hans Zantema (TU Eindhoven), Matthias Raffelsieper (TU Eindhoven)", "title": "Stream Productivity by Outermost Termination", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 83-95", "doi": "10.4204/EPTCS.15.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streams are infinite sequences over a given data type. A stream specification\nis a set of equations intended to define a stream. A core property is\nproductivity: unfolding the equations produces the intended stream in the\nlimit. In this paper we show that productivity is equivalent to termination\nwith respect to the balanced outermost strategy of a TRS obtained by adding an\nadditional rule. For specifications not involving branching symbols\nbalancedness is obtained for free, by which tools for proving outermost\ntermination can be used to prove productivity fully automatically.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 14:20:12 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Zantema", "Hans", "", "TU Eindhoven"], ["Raffelsieper", "Matthias", "", "TU Eindhoven"]]}, {"id": "1001.4405", "submitter": "EPTCS", "authors": "Jarred McGinnis (Royal Holloway, University of London), Kostas Stathis\n  (Royal Holloway, University of London), Francesca Toni (Imperial College\n  London)", "title": "A Formal Framework of Virtual Organisations as Agent Societies", "comments": null, "journal-ref": "EPTCS 16, 2010, pp. 1-14", "doi": "10.4204/EPTCS.16.1", "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formal framework that supports a model of agent-based Virtual\nOrganisations (VOs) for service grids and provides an associated operational\nmodel for the creation of VOs. The framework is intended to be used for\ndescribing different service grid applications based on multiple agents and, as\na result, it abstracts away from any realisation choices of the service grid\napplication, the agents involved to support the applications and their\ninteractions. Within the proposed framework VOs are seen as emerging from\nsocieties of agents, where agents are abstractly characterised by goals and\nroles they can play within VOs. In turn, VOs are abstractly characterised by\nthe agents participating in them with specific roles, as well as the workflow\nof services and corresponding contracts suitable for achieving the goals of the\nparticipating agents. We illustrate the proposed framework with an earth\nobservation scenario.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 12:38:22 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["McGinnis", "Jarred", "", "Royal Holloway, University of London"], ["Stathis", "Kostas", "", "Royal Holloway, University of London"], ["Toni", "Francesca", "", "Imperial College\n  London"]]}, {"id": "1001.4427", "submitter": "EPTCS", "authors": "Tony Bourdier (INRIA Nancy Grand-Est), Horatiu Cirstea (INRIA Nancy\n  Grand-Est), Daniel Dougherty (Worcester Polytechnic Institute), H\\'el\\`ene\n  Kirchner (INRIA Bordeaux Sud-Ouest)", "title": "Extensional and Intensional Strategies", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 1-19", "doi": "10.4204/EPTCS.15.1", "report-no": null, "categories": "cs.GT cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a contribution to the theoretical foundations of strategies. We\nfirst present a general definition of abstract strategies which is extensional\nin the sense that a strategy is defined explicitly as a set of derivations of\nan abstract reduction system. We then move to a more intensional definition\nsupporting the abstract view but more operational in the sense that it\ndescribes a means for determining such a set. We characterize the class of\nextensional strategies that can be defined intensionally. We also give some\nhints towards a logical characterization of intensional strategies and propose\na few challenging perspectives.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 13:52:00 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Bourdier", "Tony", "", "INRIA Nancy Grand-Est"], ["Cirstea", "Horatiu", "", "INRIA Nancy\n  Grand-Est"], ["Dougherty", "Daniel", "", "Worcester Polytechnic Institute"], ["Kirchner", "H\u00e9l\u00e8ne", "", "INRIA Bordeaux Sud-Ouest"]]}, {"id": "1001.4429", "submitter": "EPTCS", "authors": "Eduardo Bonelli (CONICET and Universidad Nacional de Quilmes,\n  Argentina), Pablo Barenbaum (Universidad de Buenos Aires, Argentina)", "title": "Superdevelopments for Weak Reduction", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 20-31", "doi": "10.4204/EPTCS.15.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study superdevelopments in the weak lambda calculus of Cagman and Hindley,\na confluent variant of the standard weak lambda calculus in which reduction\nbelow lambdas is forbidden. In contrast to developments, a superdevelopment\nfrom a term M allows not only residuals of redexes in M to be reduced but also\nsome newly created ones. In the lambda calculus there are three ways new\nredexes may be created; in the weak lambda calculus a new form of redex\ncreation is possible. We present labeled and simultaneous reduction\nformulations of superdevelopments for the weak lambda calculus and prove them\nequivalent.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 13:59:29 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Bonelli", "Eduardo", "", "CONICET and Universidad Nacional de Quilmes,\n  Argentina"], ["Barenbaum", "Pablo", "", "Universidad de Buenos Aires, Argentina"]]}, {"id": "1001.4434", "submitter": "EPTCS", "authors": "Besik Dundua (RISC, JKU Linz), Temur Kutsia (RISC, JKU Linz), Mircea\n  Marin (University of Tsukuba)", "title": "Strategies in PRholog", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 32-43", "doi": "10.4204/EPTCS.15.3", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PRholog is an experimental extension of logic programming with strategic\nconditional transformation rules, combining Prolog with Rholog calculus. The\nrules perform nondeterministic transformations on hedges. Queries may have\nseveral results that can be explored on backtracking. Strategies provide a\ncontrol on rule applications in a declarative way. With strategy combinators,\nthe user can construct more complex strategies from simpler ones. Matching with\nfour different kinds of variables provides a flexible mechanism of selecting\n(sub)terms during execution. We give an overview on programming with strategies\nin PRholog and demonstrate how rewriting strategies can be expressed.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 14:06:29 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Dundua", "Besik", "", "RISC, JKU Linz"], ["Kutsia", "Temur", "", "RISC, JKU Linz"], ["Marin", "Mircea", "", "University of Tsukuba"]]}, {"id": "1001.4436", "submitter": "EPTCS", "authors": "Ariel Gonzalez (Universidad Nacional de Rio Cuarto, Argentina), Carlos\n  Luna (Universidad ORT, Uruguay)", "title": "Specification of Products and Product Lines", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 44-55", "doi": "10.4204/EPTCS.15.4", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of variability in software development has become increasingly\nimportant in recent years. A common mechanism to represent the variability in a\nproduct line is by means of feature models. However, the relationship between\nthese models and UML design models is not straightforward. UML statecharts are\nextended introducing variability in their main components, so that the behavior\nof product lines can be specified. The contribution of this work is the\nproposal of a rule-based approach that defines a transformation strategy from\nextended statecharts to concrete UML statecharts. This is accomplished via the\nuse of feature models, in order to describe the common and variant components,\nin such a way that, starting from different feature configurations and applying\nthe rule-based method, concrete state machines corresponding to different\nproducts of a line can be obtained.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 14:10:31 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Gonzalez", "Ariel", "", "Universidad Nacional de Rio Cuarto, Argentina"], ["Luna", "Carlos", "", "Universidad ORT, Uruguay"]]}, {"id": "1001.4437", "submitter": "EPTCS", "authors": "Bernhard Gramlich (Vienna University of Technology), Felix\n  Schernhammer (Vienna University of Technology)", "title": "Extending Context-Sensitivity in Term Rewriting", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 56-68", "doi": "10.4204/EPTCS.15.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalized version of context-sensitivity in term rewriting\nbased on the notion of \"forbidden patterns\". The basic idea is that a rewrite\nstep should be forbidden if the redex to be contracted has a certain shape and\nappears in a certain context. This shape and context is expressed through\nforbidden patterns. In particular we analyze the relationships among this novel\napproach and the commonly used notion of context-sensitivity in term rewriting,\nas well as the feasibility of rewriting with forbidden patterns from a\ncomputational point of view. The latter feasibility is characterized by\ndemanding that restricting a rewrite relation yields an improved termination\nbehaviour while still being powerful enough to compute meaningful results.\nSufficient criteria for both kinds of properties in certain classes of rewrite\nsystems with forbidden patterns are presented.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 14:14:03 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Gramlich", "Bernhard", "", "Vienna University of Technology"], ["Schernhammer", "Felix", "", "Vienna University of Technology"]]}, {"id": "1001.4438", "submitter": "EPTCS", "authors": "Daniel Ventura (Universidade de Brasilia), Mauricio Ayala-Rinc\\'on\n  (Universidade de Brasilia), Fairouz Kamareddine (Heriot-Watt University,\n  Edinburgh)", "title": "Principal Typings in a Restricted Intersection Type System for Beta\n  Normal Forms with De Bruijn Indices", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 69-82", "doi": "10.4204/EPTCS.15.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lambda-calculus with de Bruijn indices assembles each alpha-class of\nlambda-terms in a unique term, using indices instead of variable names.\nIntersection types provide finitary type polymorphism and can characterise\nnormalisable lambda-terms through the property that a term is normalisable if\nand only if it is typeable. To be closer to computations and to simplify the\nformalisation of the atomic operations involved in beta-contractions, several\ncalculi of explicit substitution were developed mostly with de Bruijn indices.\nVersions of explicit substitutions calculi without types and with simple type\nsystems are well investigated in contrast to versions with more elaborate type\nsystems such as intersection types. In previous work, we introduced a de Bruijn\nversion of the lambda-calculus with an intersection type system and proved that\nit preserves subject reduction, a basic property of type systems. In this paper\na version with de Bruijn indices of an intersection type system originally\nintroduced to characterise principal typings for beta-normal forms is\npresented. We present the characterisation in this new system and the\ncorresponding versions for the type inference and the reconstruction of normal\nforms from principal typings algorithms. We briefly discuss the failure of the\nsubject reduction property and some possible solutions for it.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 14:17:36 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Ventura", "Daniel", "", "Universidade de Brasilia"], ["Ayala-Rinc\u00f3n", "Mauricio", "", "Universidade de Brasilia"], ["Kamareddine", "Fairouz", "", "Heriot-Watt University,\n  Edinburgh"]]}, {"id": "1001.4573", "submitter": "EPTCS", "authors": "Maribel Fern\\'andez (King's College London)", "title": "Proceedings Ninth International Workshop on Reduction Strategies in\n  Rewriting and Programming", "comments": null, "journal-ref": "EPTCS 15, 2010", "doi": "10.4204/EPTCS.15", "report-no": null, "categories": "cs.PL cs.LO cs.SC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains selected papers presented at the 9th International\nWorkshop on Reduction Strategies in Rewriting and Programming, WRS2009, which\nwas held in Brasilia on the 28th June 2009, associated to RTA 2009 (the 20th\nInternational Conference on Rewriting Techniques and Applications) at RDP, the\nFederated Conference on Rewriting, Deduction and Programming. Reduction\nstrategies define which (sub)expression(s) should be selected for evaluation\nand which rule(s) should be applied. These choices affect fundamental\nproperties of reductions, such as completeness, laziness and efficiency in\ngeneral. The WRS workshops promote research and collaboration in the area of\nreduction strategies and their applications in specification and programming,\ntheorem proving, software engineering, etc.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2010 01:05:09 GMT"}], "update_date": "2010-01-27", "authors_parsed": [["Fern\u00e1ndez", "Maribel", "", "King's College London"]]}, {"id": "1001.4898", "submitter": "Ccsd", "authors": "Sylvie Boldo (INRIA Saclay - Ile de France, LRI), Fran\\c{c}ois\n  Cl\\'ement (INRIA Rocquencourt), Jean-Christophe Filli\\^atre (INRIA Saclay -\n  Ile de France, LRI), Micaela Mayero (LIPN, INRIA Rh\\^one-Alpes / LIP\n  Laboratoire de l'Informatique du Parall\\'elisme), Guillaume Melquiond (INRIA\n  Saclay - Ile de France, LRI), Pierre Weis (INRIA Rocquencourt)", "title": "Formal Proof of a Wave Equation Resolution Scheme: the Method Error", "comments": "This paper has been withdrawn by the authors. Please refere to\n  arXiv:1005.0824", "journal-ref": null, "doi": null, "report-no": "RR-7181", "categories": "cs.LO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular finite difference numerical schemes for the resolution of the\none-dimensional acoustic wave equation are well-known to be convergent. We\npresent a comprehensive formalization of the simplest one and formally prove\nits convergence in Coq. The main difficulties lie in the proper definition of\nasymptotic behaviors and the implicit way they are handled in the mathematical\npen-and-paper proofs. To our knowledge, this is the first time such kind of\nmathematical proof is machine-checked.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 10:33:52 GMT"}, {"version": "v2", "created": "Fri, 7 May 2010 09:16:40 GMT"}, {"version": "v3", "created": "Wed, 9 Nov 2011 10:17:06 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Boldo", "Sylvie", "", "INRIA Saclay - Ile de France, LRI"], ["Cl\u00e9ment", "Fran\u00e7ois", "", "INRIA Rocquencourt"], ["Filli\u00e2tre", "Jean-Christophe", "", "INRIA Saclay -\n  Ile de France, LRI"], ["Mayero", "Micaela", "", "LIPN, INRIA Rh\u00f4ne-Alpes / LIP\n  Laboratoire de l'Informatique du Parall\u00e9lisme"], ["Melquiond", "Guillaume", "", "INRIA\n  Saclay - Ile de France, LRI"], ["Weis", "Pierre", "", "INRIA Rocquencourt"]]}, {"id": "1001.5019", "submitter": "Siamak Tazari", "authors": "Stephan Kreutzer and Siamak Tazari", "title": "Lower Bounds for the Complexity of Monadic Second-Order Logic", "comments": "Preliminary version appeared in proceedings of the 25th IEEE\n  symposium on Logic in Computer Science (LICS'10), Edinburgh, Scotland, UK,\n  pp. 189-198, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Courcelle's famous theorem from 1990 states that any property of graphs\ndefinable in monadic second-order logic (MSO) can be decided in linear time on\nany class of graphs of bounded treewidth, or in other words, MSO is\nfixed-parameter tractable in linear time on any such class of graphs. From a\nlogical perspective, Courcelle's theorem establishes a sufficient condition, or\nan upper bound, for tractability of MSO-model checking.\n  Whereas such upper bounds on the complexity of logics have received\nsignificant attention in the literature, almost nothing is known about\ncorresponding lower bounds. In this paper we establish a strong lower bound for\nthe complexity of monadic second-order logic. In particular, we show that if C\nis any class of graphs which is closed under taking subgraphs and whose\ntreewidth is not bounded by a polylogarithmic function (in fact, $\\log^c n$ for\nsome small c suffices) then MSO-model checking is intractable on C (under a\nsuitable assumption from complexity theory).\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 20:51:47 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2011 20:50:43 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Kreutzer", "Stephan", ""], ["Tazari", "Siamak", ""]]}, {"id": "1001.5183", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Laurent Doyen", "title": "Energy Parity Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy parity games are infinite two-player turn-based games played on\nweighted graphs. The objective of the game combines a (qualitative) parity\ncondition with the (quantitative) requirement that the sum of the weights\n(i.e., the level of energy in the game) must remain positive. Beside their own\ninterest in the design and synthesis of resource-constrained omega-regular\nspecifications, energy parity games provide one of the simplest model of games\nwith combined qualitative and quantitative objective. Our main results are as\nfollows: (a) exponential memory is necessary and sufficient for winning\nstrategies in energy parity games; (b) the problem of deciding the winner in\nenergy parity games can be solved in NP \\cap coNP; and (c) we give an algorithm\nto solve energy parity by reduction to energy games. We also show that the\nproblem of deciding the winner in energy parity games is polynomially\nequivalent to the problem of deciding the winner in mean-payoff parity games,\nwhile optimal strategies may require infinite memory in mean-payoff parity\ngames. As a consequence we obtain a conceptually simple algorithm to solve\nmean-payoff parity games.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2010 14:35:16 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2010 12:25:07 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2010 08:20:59 GMT"}, {"version": "v4", "created": "Tue, 3 Apr 2012 07:36:00 GMT"}], "update_date": "2012-04-04", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Doyen", "Laurent", ""]]}, {"id": "1001.5404", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Georg Moser", "title": "Efficient Implementation of Rewriting Revisited Technical Report", "comments": "Submitted to RTA 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Recently, many techniques have been introduced that allow the (automated)\nclassification of the runtime complexity of term rewrite systems (TRSs for\nshort). In earlier work, the authors have shown that for confluent TRSs,\ninnermost polynomial runtime complexity induces polytime computability of the\nfunctions defined.\n  In this paper, we generalise the above result to full rewriting. Following\nour previous work, we exploit graph rewriting. We give a new proof of the\nadequacy of graph rewriting for full rewriting that allows for a precise\ncontrol of the resources copied. In sum we completely describe an\nimplementation of rewriting on a Turing machine (TM for short). We show that\nthe runtime complexity of the TRS and the runtime complexity of the TM is\npolynomially related. Our result strengthens the evidence that the complexity\nof a rewrite system is truthfully represented through the length of\nderivations. Moreover our result allows the classification of non-deterministic\npolytime-computation based on runtime complexity analysis of rewrite systems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2010 13:44:28 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2010 18:14:44 GMT"}, {"version": "v3", "created": "Wed, 8 Jun 2011 07:01:49 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Avanzini", "Martin", ""], ["Moser", "Georg", ""]]}]