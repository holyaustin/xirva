[{"id": "2001.00406", "submitter": "Ilias Tachmazidis", "authors": "Michael J. Maher, Ilias Tachmazidis, Grigoris Antoniou, Stephen Wade,\n  Long Cheng", "title": "Rethinking Defeasible Reasoning: A Scalable Approach", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 552-586", "doi": "10.1017/S1471068420000010", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technological advances have led to unprecedented amounts of generated\ndata that originate from the Web, sensor networks and social media. Analytics\nin terms of defeasible reasoning - for example for decision making - could\nprovide richer knowledge of the underlying domain. Traditionally, defeasible\nreasoning has focused on complex knowledge structures over small to medium\namounts of data, but recent research efforts have attempted to parallelize the\nreasoning process over theories with large numbers of facts. Such work has\nshown that traditional defeasible logics come with overheads that limit\nscalability. In this work, we design a new logic for defeasible reasoning, thus\nensuring scalability by design. We establish several properties of the logic,\nincluding its relation to existing defeasible logics. Our experimental results\nindicate that our approach is indeed scalable and defeasible reasoning can be\napplied to billions of facts.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 12:00:49 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Maher", "Michael J.", ""], ["Tachmazidis", "Ilias", ""], ["Antoniou", "Grigoris", ""], ["Wade", "Stephen", ""], ["Cheng", "Long", ""]]}, {"id": "2001.00758", "submitter": "Mateus de Oliveira Oliveira", "authors": "Mateus de Oliveira Oliveira", "title": "On Supergraphs Satisfying CMSO Properties", "comments": "A preliminary version of this work appeared at the 26th EACSL Annual\n  Conference on Computer Science Logic, CSL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let CMSO denote the counting monadic second order logic of graphs. We give a\nconstructive proof that for some computable function $f$, there is an algorithm\n$\\mathfrak{A}$ that takes as input a CMSO sentence $\\varphi$, a positive\ninteger $t$, and a connected graph $G$ of maximum degree at most $\\Delta$, and\ndetermines, in time $f(|\\varphi|,t)\\cdot 2^{O(\\Delta \\cdot t)}\\cdot\n|G|^{O(t)}$, whether $G$ has a supergraph $G'$ of treewidth at most $t$ such\nthat $G'\\models \\varphi$. The algorithmic metatheorem described above sheds new\nlight on certain unresolved questions within the framework of graph completion\nalgorithms. In particular, using this metatheorem, we provide an explicit\nalgorithm that determines, in time $f(d)\\cdot 2^{O(\\Delta \\cdot d)}\\cdot\n|G|^{O(d)}$, whether a connected graph of maximum degree $\\Delta$ has a planar\nsupergraph of diameter at most $d$. Additionally, we show that for each fixed\n$k$, the problem of determining whether $G$ has an $k$-outerplanar supergraph\nof diameter at most $d$ is strongly uniformly fixed parameter tractable with\nrespect to the parameter $d$. This result can be generalized in two directions.\nFirst, the diameter parameter can be replaced by any contraction-closed\neffectively CMSO-definable parameter $\\mathbf{p}$. Examples of such parameters\nare vertex-cover number, dominating number, and many other\ncontraction-bidimensional parameters. In the second direction, the planarity\nrequirement can be relaxed to bounded genus, and more generally, to bounded\nlocal treewidth.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 08:21:11 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 00:23:13 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Oliveira", "Mateus de Oliveira", ""]]}, {"id": "2001.00819", "submitter": "Petr Savick\\'y", "authors": "Petr Ku\\v{c}era, Petr Savick\\'y", "title": "Bounds on the size of PC and URC formulas", "comments": "24 pages, minor corrections and improvements of the text", "journal-ref": "Journal of Artificial Intelligence Research 69 (2020) 1395-1420", "doi": "10.1613/jair.1.12006", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate CNF formulas, for which the unit propagation is\nstrong enough to derive a contradiction if the formula together with a partial\nassignment of the variables is unsatisfiable (unit refutation complete or URC\nformulas) or additionally to derive all implied literals if the formula is\nsatisfiable (propagation complete or PC formulas). If a formula represents a\nfunction using existentially quantified auxiliary variables, it is called an\nencoding of the function. We prove several results on the sizes of PC and URC\nformulas and encodings. One of them are separations between the sizes of\nformulas of different types. Namely, we prove an exponential separation between\nthe size of URC formulas and PC formulas and between the size of PC encodings\nusing auxiliary variables and URC formulas. Besides of this, we prove that the\nsizes of any two irredundant PC formulas for the same function differ at most\nby a factor polynomial in the number of the variables and present an example of\na function demonstrating that a similar statement is not true for URC formulas.\nOne of the separations above implies that a q-Horn formula may require an\nexponential number of additional clauses to become a URC formula. On the other\nhand, for every q-Horn formula, we present a polynomial size URC encoding of\nthe same function using auxiliary variables. This encoding is not q-Horn in\ngeneral.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 13:15:32 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 09:52:20 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 13:40:47 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Ku\u010dera", "Petr", ""], ["Savick\u00fd", "Petr", ""]]}, {"id": "2001.01088", "submitter": "Sankha Basu", "authors": "Sankha S. Basu and Mihir K. Chakraborty", "title": "Restricted Rules of Inference and Paraconsistency", "comments": "The final version of this paper has been published online in Logic\n  Journal of the IGPL\n  (https://academic.oup.com/jigpal/advance-article/doi/10.1093/jigpal/jzab019/6299942).\n  Minor typos fixed; Theorem 3.7 has been changed to Remark 3.7; other minor\n  rearrangements of the material done; further justification added in Remark\n  4.28 (now Remark 4.27)", "journal-ref": null, "doi": "10.1093/jigpal/jzab019", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study two companions to a logic, viz., the left variable\ninclusion companion and the restricted rules companion, their nature and\ninterrelations, especially in connection with paraconsistency. A sufficient\ncondition for the two companions to coincide has also been proved. Two new\nlogical systems - Intuitionistic Paraconsistent Weak Kleene logic (IPWK) and\nParaconsistent Pre-Rough logic (PPRL) - are presented here as examples of\nlogics of left variable inclusion. IPWK is the left variable inclusion\ncompanion of Intuitionistic Propositional logic (IPC) and is also the\nrestricted rules companion of it. PPRL, on the other hand, is the left variable\ninclusion companion of Pre-Rough logic (PRL) but differs from the restricted\nrules companion of it. We have discussed algebraic semantics for these logics\nin terms of P{\\l}onka sums. This amounts to introducing a contaminating truth\nvalue, intended to denote a state of indeterminacy.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 15:23:44 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 11:44:05 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 11:45:50 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Basu", "Sankha S.", ""], ["Chakraborty", "Mihir K.", ""]]}, {"id": "2001.01089", "submitter": "Michael Morak", "authors": "Manuel Bichler, Michael Morak, and Stefan Woltran", "title": "selp: A Single-Shot Epistemic Logic Program Solver", "comments": "19 pages, 2 figures, under consideration in Theory and Practice of\n  Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epistemic Logic Programs (ELPs) are an extension of Answer Set Programming\n(ASP) with epistemic operators that allow for a form of meta-reasoning, that\nis, reasoning over multiple possible worlds. Existing ELP solving approaches\ngenerally rely on making multiple calls to an ASP solver in order to evaluate\nthe ELP. However, in this paper, we show that there also exists a direct\ntranslation from ELPs into non-ground ASP with bounded arity. The resulting ASP\nprogram can thus be solved in a single shot. We then implement this encoding\nmethod, using recently proposed techniques to handle large, non-ground ASP\nrules, into the prototype ELP solving system \"selp\", which we present in this\npaper. This solver exhibits competitive performance on a set of ELP benchmark\ninstances. Under consideration in Theory and Practice of Logic Programming\n(TPLP).\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 15:36:31 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Bichler", "Manuel", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "2001.01324", "submitter": "Rajdeep Mukherjee", "authors": "Rajdeep Mukherjee, Saurabh Joshi, John O'Leary, Daniel Kroening, Tom\n  Melham", "title": "Hardware/Software Co-verification Using Path-based Symbolic Execution", "comments": "6 pages, 3 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional tools for formal hardware/software co-verification use bounded\nmodel checking techniques to construct a single monolithic propositional\nformula. Formulas generated in this way are extremely complex and contain a\ngreat deal of irrelevant logic, hence are difficult to solve even by the\nstate-of-the-art Satis ability (SAT) solvers. In a typical hardware/software\nco-design the firmware only exercises a fraction of the hardware state-space,\nand we can use this observation to generate simpler and more concise formulas.\nIn this paper, we present a novel verification algorithm for hardware/software\nco-designs that identify partitions of the firmware and the hardware logic\npertaining to the feasible execution paths by means of path-based symbolic\nsimulation with custom path-pruning, property-guided slicing and incremental\nSAT solving. We have implemented this approach in our tool COVERIF. We have\nexperimentally compared COVERIF with HW-CBMC, a monolithic BMC based\nco-verification tool, and observed an average speed-up of 5X over HW-CBMC for\nproving safety properties as well as detecting critical co-design bugs in an\nopen-source Universal Asynchronous Receiver Transmitter design and a large SoC\ndesign.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 22:39:28 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Mukherjee", "Rajdeep", ""], ["Joshi", "Saurabh", ""], ["O'Leary", "John", ""], ["Kroening", "Daniel", ""], ["Melham", "Tom", ""]]}, {"id": "2001.01337", "submitter": "Francesco Gavazzo", "authors": "Ugo Dal Lago and Francesco Gavazzo", "title": "A Diagrammatic Calculus for Algebraic Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a new diagrammatic notation for representing the result of\n(algebraic) effectful computations. Our notation explicitly separates the\neffects produced during a computation from the possible values returned, this\nway simplifying the extension of definitions and results on pure computations\nto an effectful setting. Additionally, we show a number of algebraic and\norder-theoretic laws on diagrams, this way laying the foundations for a\ndiagrammatic calculus of algebraic effects. We give a formal foundation for\nsuch a calculus in terms of Lawvere theories and generic effects.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 23:48:41 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 08:45:23 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Gavazzo", "Francesco", ""]]}, {"id": "2001.01516", "submitter": "Florian Frohn", "authors": "Florian Frohn", "title": "A Calculus for Modular Loop Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loop acceleration can be used to prove safety, reachability, runtime bounds,\nand (non-)termination of programs operating on integers. To this end, a variety\nof acceleration techniques has been proposed. However, all of them are\nmonolithic: Either they accelerate a loop successfully or they fail completely.\nIn contrast, we present a calculus that allows for combining acceleration\ntechniques in a modular way and we show how to integrate many existing\nacceleration techniques into our calculus. Moreover, we propose two novel\nacceleration techniques that can be incorporated into our calculus seamlessly.\nAn empirical evaluation demonstrates the applicability of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 12:22:14 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 10:30:09 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 09:15:14 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Frohn", "Florian", ""]]}, {"id": "2001.01619", "submitter": "Federico Olimpieri", "authors": "Federico Olimpieri", "title": "Normalization, Taylor expansion and rigid approximation of\n  $\\lambda$-terms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to characterize three fundamental normalization\nproprieties in lambda-calculus trough the Taylor expansion of $ \\lambda$-terms.\nThe general proof strategy consists in stating the dependence of ordinary\nreduction strategies on their resource counterparts and in finding a convenient\nresource term in the Taylor expansion that behaves well under the considered\nkind of reduction.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 15:03:41 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Olimpieri", "Federico", ""]]}, {"id": "2001.01835", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "Understanding the QuickXPlain Algorithm: Simple Explanation and Formal\n  Proof", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his seminal paper of 2004, Ulrich Junker proposed the QuickXPlain\nalgorithm, which provides a divide-and-conquer computation strategy to find\nwithin a given set an irreducible subset with a particular (monotone) property.\nBeside its original application in the domain of constraint satisfaction\nproblems, the algorithm has since then found widespread adoption in areas as\ndifferent as model-based diagnosis, recommender systems, verification, or the\nSemantic Web. This popularity is due to the frequent occurrence of the problem\nof finding irreducible subsets on the one hand, and to QuickXPlain's general\napplicability and favorable computational complexity on the other hand.\n  However, although (we regularly experience) people are having a hard time\nunderstanding QuickXPlain and seeing why it works correctly, a proof of\ncorrectness of the algorithm has never been published. This is what we account\nfor in this work, by explaining QuickXPlain in a novel tried and tested way and\nby presenting an intelligible formal proof of it. Apart from showing the\ncorrectness of the algorithm and excluding the later detection of errors (proof\nand trust effect), the added value of the availability of a formal proof is,\ne.g., (i) that the workings of the algorithm often become completely clear only\nafter studying, verifying and comprehending the proof (didactic effect), (ii)\nthe shown proof methodology can be used as a guidance for proving other\nrecursive algorithms (transfer effect), and (iii) the possibility of providing\n\"gapless\" correctness proofs of systems that rely on (results computed by)\nQuickXPlain, such as numerous model-based debuggers (completeness effect).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 01:37:41 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 07:59:09 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "2001.01862", "submitter": "Klaus-Dieter Schewe", "authors": "Egon B\\\"orger (1), Klaus-Dieter Schewe (2) ((1) Universit\\`a di Pisa,\n  Dipartimento di Informatica, Pisa, Italy (2) Zhejiang University, UIUC\n  Institute, Haining, China)", "title": "A Behavioural Theory of Recursive Algorithms", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"What is an algorithm?\" is a fundamental question of computer science.\nGurevich's behavioural theory of sequential algorithms (aka the sequential ASM\nthesis) gives a partial answer by defining (non-deterministic) sequential\nalgorithms axiomatically, without referring to a particular machine model or\nprogramming language, and showing that they are captured by (non-deterministic)\nsequential Abstract State Machines (nd-seq ASMs). Moschovakis pointed out that\nrecursive algorithms such as mergesort are not covered by this theory. In this\narticle we propose an axiomatic definition of the notion of sequential\nrecursive algorithm which extends Gurevich's axioms for sequential algorithms\nby a Recursion Postulate and allows us to prove that sequential recursive\nalgorithms are captured by recursive Abstract State Machines, an extension of\nnd-seq ASMs by a CALL rule. Applying this recursive ASM thesis yields a\ncharacterization of sequential recursive algorithms as finitely composed\nconcurrent algorithms all of whose concurrent runs are partial-order runs.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 02:41:16 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 01:35:58 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["B\u00f6rger", "Egon", ""], ["Schewe", "Klaus-Dieter", ""]]}, {"id": "2001.01873", "submitter": "Klaus-Dieter Schewe", "authors": "Klaus-Dieter Schewe (1), Flavio Ferrarotti (2) ((1) Zhejiang\n  University, UIUC Institute, Haining, China (2) Software Competence Center\n  Hagenberg, Hagenberg, Austria)", "title": "Behavioural Theory of Reflective Algorithms I: Reflective Sequential\n  Algorithms", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a behavioural theory of reflective sequential algorithms (RSAs),\ni.e. sequential algorithms that can modify their own behaviour. The theory\ncomprises a set of language-independent postulates defining the class of RSAs,\nan abstract machine model, and the proof that all RSAs are captured by this\nmachine model. As in Gurevich's behavioural theory for sequential algorithms\nRSAs are sequential-time, bounded parallel algorithms, where the bound depends\non the algorithm only and not on the input. Different from the class of\nsequential algorithms every state of an RSA includes a representation of the\nalgorithm in that state, thus enabling linguistic reflection. Bounded\nexploration is preserved using terms as values. The model of reflective\nsequential abstract state machines (rsASMs) extends sequential ASMs using\nextended states that include an updatable representation of the main ASM rule\nto be executed by the machine in that state. Updates to the representation of\nASM signatures and rules are realised by means of a sophisticated tree algebra.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 03:33:59 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Schewe", "Klaus-Dieter", ""], ["Ferrarotti", "Flavio", ""]]}, {"id": "2001.02029", "submitter": "Margherita Zorzi", "authors": "Simone Martini and Andrea Masini and Margherita Zorzi", "title": "A journey in modal proof theory: From minimal normal modal logic to\n  discrete linear temporal logic", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending and generalizing the approach of 2-sequents (Masini, 1992), we\npresent sequent calculi for the classical modal logics in the K, D, T, S4\nspectrum. The systems are presented in a uniform way-different logics are\nobtained by tuning a single parameter, namely a constraint on the applicability\nof a rule. Cut-elimination is proved only once, since the proof goes through\nindependently from the constraints giving rise to the different systems. A\nsequent calculus for the discrete linear temporal logic ltl is also given and\nproved complete. Leitmotiv of the paper is the formal analogy between modality\nand first-order quantification.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 13:45:02 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Martini", "Simone", ""], ["Masini", "Andrea", ""], ["Zorzi", "Margherita", ""]]}, {"id": "2001.02144", "submitter": "Marc Vinyals", "authors": "Susanna F. de Rezende, Or Meir, Jakob Nordstr\\\"om, Toniann Pitassi,\n  Robert Robere, Marc Vinyals", "title": "Lifting with Simple Gadgets and Applications to Circuit and Proof\n  Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We significantly strengthen and generalize the theorem lifting\nNullstellensatz degree to monotone span program size by Pitassi and Robere\n(2018) so that it works for any gadget with high enough rank, in particular,\nfor useful gadgets such as equality and greater-than. We apply our generalized\ntheorem to solve two open problems:\n  * We present the first result that demonstrates a separation in proof power\nfor cutting planes with unbounded versus polynomially bounded coefficients.\nSpecifically, we exhibit CNF formulas that can be refuted in quadratic length\nand constant line space in cutting planes with unbounded coefficients, but for\nwhich there are no refutations in subexponential length and subpolynomial line\nspace if coefficients are restricted to be of polynomial magnitude.\n  * We give the first explicit separation between monotone Boolean formulas and\nmonotone real formulas. Specifically, we give an explicit family of functions\nthat can be computed with monotone real formulas of nearly linear size but\nrequire monotone Boolean formulas of exponential size. Previously only a\nnon-explicit separation was known.\n  An important technical ingredient, which may be of independent interest, is\nthat we show that the Nullstellensatz degree of refuting the pebbling formula\nover a DAG G over any field coincides exactly with the reversible pebbling\nprice of G. In particular, this implies that the standard decision tree\ncomplexity and the parity decision tree complexity of the corresponding\nfalsified clause search problem are equal.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 16:06:24 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["de Rezende", "Susanna F.", ""], ["Meir", "Or", ""], ["Nordstr\u00f6m", "Jakob", ""], ["Pitassi", "Toniann", ""], ["Robere", "Robert", ""], ["Vinyals", "Marc", ""]]}, {"id": "2001.02155", "submitter": "Christian Retor\\'e", "authors": "Christian Retor\\'e", "title": "Pomset logic: a logical and grammatical alternative to the Lambek\n  calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thirty years ago, I introduced a non commutative variant of classical linear\nlogic, called POMSET LOGIC, issued from a particular denotational semantics or\ncategorical interpretation of linear logic known as coherence spaces. In\naddition to the multiplicative connectives of linear logic, pomset logic\nincludes a non-commutative connective, \"$<$\" called BEFORE, which is\nassociative and self-dual: $(A<B)^\\perp=A^\\perp < B^\\perp$ (observe that there\nis no swapping), and pomset logic handles Partially Ordered MultiSETs of\nformulas. This classical calculus enjoys a proof net calculus, cut-elimination,\ndenotational semantics, but had no sequent calculus, despite my many attempts\nand the study of closely related deductive systems like the calculus of\nstructures. At the same period, Alain Lecomte introduced me to Lambek calculus\nand grammars. We defined a grammatical formalism based on pomset logic, with\npartial proof nets as the deductive systems for parsing-as-deduction, with a\nlexicon mapping words to partial proof nets. The study of pomset logic and of\nits grammatical applications has been out of the limelight for several years,\nin part because computational linguists were not too keen on proof nets.\nHowever, recently Sergey Slavnov found a sequent calculus for pomset logic, and\nreopened the study of pomset logic. In this paper we shall present pomset logic\nincluding both published and unpublished material. Just as for Lambek calculus,\nPomset logic also is a non commutative variant of linear logic --- although\nLambek calculus appeared 30 years before linear logic ! --- and as in Lambek\ncalculus it may be used as a grammar. Apart from this the two calculi are quite\ndifferent, but perhaps the algebraic presentation we give here, with terms and\nthe semantic correctness criterion, is closer to Lambek's view.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 16:28:34 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Retor\u00e9", "Christian", ""]]}, {"id": "2001.02209", "submitter": "Matthijs V\\'ak\\'ar", "authors": "Mathieu Huot, Sam Staton, Matthijs V\\'ak\\'ar", "title": "Correctness of Automatic Differentiation via Diffeologies and\n  Categorical Gluing", "comments": "Proceedings of FoSSaCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present semantic correctness proofs of Automatic Differentiation (AD). We\nconsider a forward-mode AD method on a higher order language with algebraic\ndata types, and we characterise it as the unique structure preserving macro\ngiven a choice of derivatives for basic operations. We describe a rich\nsemantics for differentiable programming, based on diffeological spaces. We\nshow that it interprets our language, and we phrase what it means for the AD\nmethod to be correct with respect to this semantics. We show that our\ncharacterisation of AD gives rise to an elegant semantic proof of its\ncorrectness based on a gluing construction on diffeological spaces. We explain\nhow this is, in essence, a logical relations argument. Finally, we sketch how\nthe analysis extends to other AD methods by considering a continuation-based\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 18:21:52 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 07:56:36 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 08:05:26 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Huot", "Mathieu", ""], ["Staton", "Sam", ""], ["V\u00e1k\u00e1r", "Matthijs", ""]]}, {"id": "2001.02296", "submitter": "Dan Shiebler", "authors": "Dan Shiebler, Alexis Toumi, Mehrnoosh Sadrzadeh", "title": "Incremental Monoidal Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we define formal grammars in terms of free monoidal categories,\nalong with a functor from the category of formal grammars to the category of\nautomata. Generalising from the Booleans to arbitrary semirings, we extend our\nconstruction to weighted formal grammars and weighted automata. This allows us\nto link the categorical viewpoint on natural language to the standard machine\nlearning notion of probabilistic language model.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 22:37:12 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 12:37:53 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Shiebler", "Dan", ""], ["Toumi", "Alexis", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "2001.02659", "submitter": "Paul He", "authors": "Yannick Zakowski, Paul He, Chung-Kil Hur, Steve Zdancewic", "title": "An Equational Theory for Weak Bisimulation via Generalized Parameterized\n  Coinduction", "comments": "To be published in CPP 2020", "journal-ref": null, "doi": "10.1145/3372885.3373813", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Coinductive reasoning about infinitary structures such as streams is widely\napplicable. However, practical frameworks for developing coinductive proofs and\nfinding reasoning principles that help structure such proofs remain a\nchallenge, especially in the context of machine-checked formalization.\n  This paper gives a novel presentation of an equational theory for reasoning\nabout structures up to weak bisimulation. The theory is both compositional,\nmaking it suitable for defining general-purpose lemmas, and also incremental,\nmeaning that the bisimulation can be created interactively. To prove the\ntheory's soundness, this paper also introduces generalized parameterized\ncoinduction, which addresses expressivity problems of earlier works and\nprovides a practical framework for coinductive reasoning. The paper presents\nthe resulting equational theory for streams, but the technique applies to other\nstructures too.\n  All of the results in this paper have been proved in Coq, and the generalized\nparameterized coinduction framework is available as a Coq library.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:03:10 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Zakowski", "Yannick", ""], ["He", "Paul", ""], ["Hur", "Chung-Kil", ""], ["Zdancewic", "Steve", ""]]}, {"id": "2001.02828", "submitter": "Christopher Jenkins", "authors": "Christopher Jenkins and Aaron Stump", "title": "Monotone recursive types and recursive data representations in Cedille", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guided by Tarksi's fixpoint theorem in order theory, we show how to derive\nmonotone recursive types with constant-time roll and unroll operations within\nCedille, an impredicative, constructive, and logically consistent pure typed\nlambda calculus. This derivation takes place within the preorder on Cedille\ntypes induced by type inclusions, a notion which is expressible within the\ntheory itself. As applications, we use monotone recursive types to generically\nderive two recursive representations of data in lambda calculus, the Parigot\nand Scott encoding. For both encodings, we prove induction and examine the\ncomputational and extensional properties of their destructor, iterator, and\nprimitive recursor in Cedille. For our Scott encoding in particular, we\ntranslate into Cedille a construction due to Lepigre and Raffalli that equips\nScott naturals with primitive recursion, then extend this construction to\nderive a generic induction principle. This allows us to give efficient and\nprovably unique (up to function extensionality) solutions for the iteration and\nprimitive recursion schemes for Scott-encoded data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 04:04:27 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 01:46:55 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Jenkins", "Christopher", ""], ["Stump", "Aaron", ""]]}, {"id": "2001.02889", "submitter": "Duligur Ibeling", "authors": "Duligur Ibeling, Thomas Icard", "title": "Probabilistic Reasoning across the Causal Hierarchy", "comments": "AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formalization of the three-tier causal hierarchy of association,\nintervention, and counterfactuals as a series of probabilistic logical\nlanguages. Our languages are of strictly increasing expressivity, the first\ncapable of expressing quantitative probabilistic reasoning -- including\nconditional independence and Bayesian inference -- the second encoding\ndo-calculus reasoning for causal effects, and the third capturing a fully\nexpressive do-calculus for arbitrary counterfactual queries. We give a\ncorresponding series of finitary axiomatizations complete over both structural\ncausal models and probabilistic programs, and show that satisfiability and\nvalidity for each language are decidable in polynomial space.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 08:52:14 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 16:03:38 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 17:40:29 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 23:55:30 GMT"}, {"version": "v5", "created": "Wed, 2 Jun 2021 08:14:53 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ibeling", "Duligur", ""], ["Icard", "Thomas", ""]]}, {"id": "2001.03256", "submitter": "\\'Akos Hajdu", "authors": "\\'Akos Hajdu, Dejan Jovanovi\\'c", "title": "SMT-Friendly Formalization of the Solidity Memory Model", "comments": "Authors' manuscript. Published in P. M\\\"uller (Ed.): ESOP 2020, LNCS\n  12075, 2020. The final publication is available at Springer via\n  https://doi.org/10.1007/978-3-030-44914-8_9", "journal-ref": null, "doi": "10.1007/978-3-030-44914-8_9", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Solidity is the dominant programming language for Ethereum smart contracts.\nThis paper presents a high-level formalization of the Solidity language with a\nfocus on the memory model. The presented formalization covers all features of\nthe language related to managing state and memory. In addition, the\nformalization we provide is effective: all but few features can be encoded in\nthe quantifier-free fragment of standard SMT theories. This enables precise and\nefficient reasoning about the state of smart contracts written in Solidity. The\nformalization is implemented in the solc-verify verifier and we provide an\nextensive set of tests that covers the breadth of the required semantics. We\nalso provide an evaluation on the test set that validates the semantics and\nshows the novelty of the approach compared to other Solidity-level contract\nanalysis tools.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 23:29:19 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 13:09:17 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Hajdu", "\u00c1kos", ""], ["Jovanovi\u0107", "Dejan", ""]]}, {"id": "2001.03540", "submitter": "Thomas Powell", "authors": "Thomas Powell", "title": "On the computational content of Zorn's lemma", "comments": null, "journal-ref": null, "doi": "10.1145/3373718.3394745", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a computational interpretation to an abstract instance of Zorn's\nlemma formulated as a wellfoundedness principle in the language of arithmetic\nin all finite types. This is achieved through G\\\"odel's functional\ninterpretation, and requires the introduction of a novel form of recursion over\nnon-wellfounded partial orders whose existence in the model of total continuous\nfunctionals is proven using domain theoretic techniques. We show that a\nrealizer for the functional interpretation of open induction over the\nlexicographic ordering on sequences follows as a simple application of our main\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 16:13:30 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 09:21:34 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Powell", "Thomas", ""]]}, {"id": "2001.03662", "submitter": "Brandon Paulsen", "authors": "Brandon Paulsen, Jingbo Wang, Chao Wang", "title": "ReluDiff: Differential Verification of Deep Neural Networks", "comments": "Extended version of ICSE 2020 paper. This version includes an\n  appendix with proofs for some of the content in section 4.3", "journal-ref": null, "doi": "10.1145/3377811.3380337", "report-no": null, "categories": "cs.LG cs.LO cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks are increasingly being deployed in practice, their\nefficiency has become an important issue. While there are compression\ntechniques for reducing the network's size, energy consumption and\ncomputational requirement, they only demonstrate empirically that there is no\nloss of accuracy, but lack formal guarantees of the compressed network, e.g.,\nin the presence of adversarial examples. Existing verification techniques such\nas Reluplex, ReluVal, and DeepPoly provide formal guarantees, but they are\ndesigned for analyzing a single network instead of the relationship between two\nnetworks. To fill the gap, we develop a new method for differential\nverification of two closely related networks. Our method consists of a fast but\napproximate forward interval analysis pass followed by a backward pass that\niteratively refines the approximation until the desired property is verified.\nWe have two main innovations. During the forward pass, we exploit structural\nand behavioral similarities of the two networks to more accurately bound the\ndifference between the output neurons of the two networks. Then in the backward\npass, we leverage the gradient differences to more accurately compute the most\nbeneficial refinement. Our experiments show that, compared to state-of-the-art\nverification tools, our method can achieve orders-of-magnitude speedup and\nprove many more properties than existing tools.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 20:47:22 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 21:29:59 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Paulsen", "Brandon", ""], ["Wang", "Jingbo", ""], ["Wang", "Chao", ""]]}, {"id": "2001.03829", "submitter": "Sen Zheng", "authors": "Sen Zheng, Renate A. Schmidt", "title": "Deciding the Loosely Guarded Fragment and Querying Its Horn Fragment\n  Using Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following query answering problem: Given a Boolean\nconjunctive query and a theory in the Horn loosely guarded fragment, the aim is\nto determine whether the query is entailed by the theory. In this paper, we\npresent a resolution decision procedure for the loosely guarded fragment, and\nuse such a procedure to answer Boolean conjunctive queries against the Horn\nloosely guarded fragment. The Horn loosely guarded fragment subsumes classes of\nrules that are prevalent in ontology-based query answering, such as Horn ALCHOI\nand guarded existential rules. Additionally, we identify star queries and cloud\nqueries, which using our procedure, can be answered against the loosely guarded\nfragment.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 02:29:18 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Zheng", "Sen", ""], ["Schmidt", "Renate A.", ""]]}, {"id": "2001.03894", "submitter": "Mickael Randour", "authors": "Patricia Bouyer and St\\'ephane Le Roux and Youssouf Oualhadj and\n  Mickael Randour and Pierre Vandenhove", "title": "Games Where You Can Play Optimally with Arena-Independent Finite Memory", "comments": "Updated title, full version of CONCUR 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decades, two-player (antagonistic) games on graphs have been a framework\nof choice for many important problems in theoretical computer science. A\nnotorious one is controller synthesis, which can be rephrased through the\ngame-theoretic metaphor as the quest for a winning strategy of the system in a\ngame against its antagonistic environment. Depending on the specification,\noptimal strategies might be simple or quite complex, for example having to use\n(possibly infinite) memory. Hence, research strives to understand which\nsettings allow for simple strategies.\n  In 2005, Gimbert and Zielonka provided a complete characterization of\npreference relations (a formal framework to model specifications and game\nobjectives) that admit memoryless optimal strategies for both players. In the\nlast fifteen years however, practical applications have driven the community\ntoward games with complex or multiple objectives, where memory -- finite or\ninfinite -- is almost always required. Despite much effort, the exact frontiers\nof the class of preference relations that admit finite-memory optimal\nstrategies still elude us.\n  In this work, we establish a complete characterization of preference\nrelations that admit optimal strategies using arena-independent finite memory,\ngeneralizing the work of Gimbert and Zielonka to the finite-memory case. We\nalso prove an equivalent to their celebrated corollary of great practical\ninterest: if both players have optimal (arena-independent-)finite-memory\nstrategies in all one-player games, then it is also the case in all two-player\ngames. Finally, we pinpoint the boundaries of our results with regard to the\nliterature: our work completely covers the case of arena-independent memory\n(e.g., multiple parity objectives, lower- and upper-bounded energy objectives),\nand paves the way to the arena-dependent case (e.g., multiple lower-bounded\nenergy objectives).\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 09:27:36 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 09:20:32 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 06:43:28 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 07:29:27 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Bouyer", "Patricia", ""], ["Roux", "St\u00e9phane Le", ""], ["Oualhadj", "Youssouf", ""], ["Randour", "Mickael", ""], ["Vandenhove", "Pierre", ""]]}, {"id": "2001.03945", "submitter": "Xingchi Su", "authors": "Jie Fan, Davide Grossi, Barteld Kooi, Xingchi Su, Rineke Verbrugge", "title": "Commonly Knowing Whether", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the notion of `commonly knowing whether', a\nnon-standard version of standard common knowledge which is defined on the basis\nof `knowing whether', instead of standard `knowing that'. After giving five\npossible definitions of this notion, we explore the logical relations among\nthem in the single-agent and multi-agent cases. We propose a sound and complete\naxiomatization. We investigate one of the five definitions in terms of\nexpressivity via a strategy of modal comparison games.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 15:22:37 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 10:54:56 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 12:31:09 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Fan", "Jie", ""], ["Grossi", "Davide", ""], ["Kooi", "Barteld", ""], ["Su", "Xingchi", ""], ["Verbrugge", "Rineke", ""]]}, {"id": "2001.04100", "submitter": "Bernhard Gleiss", "authors": "Bernhard Gleiss, Laura Kovacs, Lena Schnedlitz", "title": "Interactive Visualization of Saturation Attempts in Vampire", "comments": null, "journal-ref": "Ahrendt W., Tapia Tarifa S. (eds) Integrated Formal Methods. IFM\n  2019. Lecture Notes in Computer Science, vol 11918. Springer, Cham", "doi": "10.1007/978-3-030-34968-4_28", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of formal methods require automated reasoning about system\nproperties, such as system safety and security. To improve the performance of\nautomated reasoning engines, such as SAT/SMT solvers and first-order theorem\nprover, it is necessary to understand both the successful and failing attempts\nof these engines towards producing formal certificates, such as logical proofs\nand/or models. Such an analysis is challenging due to the large number of\nlogical formulas generated during proof/model search. In this paper we focus on\nsaturation-based first-order theorem proving and introduce the SATVIS tool for\ninteractively visualizing saturation-based proof attempts in first-order\ntheorem proving. We build SATVIS on top of the world-leading theorem prover\nVAMPIRE, by interactively visualizing the saturation attempts of VAMPIRE in\nSATVIS. Our work combines the automatic layout and visualization of the\nderivation graph induced by the saturation attempt with interactive\ntransformations and search functionality. As a result, we are able to analyze\nand debug (failed) proof attempts of VAMPIRE. Thanks to its interactive\nvisualisation, we believe SATVIS helps both experts and non-experts in theorem\nproving to understand first-order proofs and analyze/refine failing proof\nattempts of first-order provers.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 08:19:41 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Gleiss", "Bernhard", ""], ["Kovacs", "Laura", ""], ["Schnedlitz", "Lena", ""]]}, {"id": "2001.04242", "submitter": "James Smith", "authors": "James E. Smith", "title": "(Newtonian) Space-Time Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The space-time (s-t) algebra provides a mathematical model for communication\nand computation using values encoded as events in discretized linear\n(Newtonian) time. Consequently, the input-output behavior of s-t algebra and\nimplemented functions are consistent with the flow of time. The s-t algebra and\nfunctions are formally defined. A network design framework for s-t functions is\ndescribed, and the design of temporal neural networks, a form of spiking neural\nnetworks, is discussed as an extended case study. Finally, the relationship\nwith Allen's interval algebra is briefly discussed.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:40:56 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 00:54:33 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 17:58:12 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 13:30:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Smith", "James E.", ""]]}, {"id": "2001.04249", "submitter": "Salman Haider", "authors": "Salman Haider, Dr. Syed Asad Raza Kazmi", "title": "An extended quantum process algebra (eQPAlg) approach for distributed\n  quantum systems", "comments": "4 figures, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL quant-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work, we have expounded the communication procedure of quantum\nsystems by means of process algebra. The main objective of our research effort\nis to formally represent the communication between distributed quantum systems.\nIn this new proposed communication model we have ameliorated the existing rules\nof Lalire's quantum process algebra QPAlg. We have brought some important\nmodification in QPAlg by introducing the concept of formally specifying the\nQuantum teleportation protocol. We have further introduced the formal\ndescription of protocol by using programs that best explains its working and\nsatisfies the specification. Examples have been provided to describe the\nworking of the improved algebra that formally explain the sending and receiving\nof both classical as well as quantum data, keeping in mind the principal\nfeatures of quantum mechanics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 11:02:35 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Haider", "Salman", ""], ["Kazmi", "Dr. Syed Asad Raza", ""]]}, {"id": "2001.04265", "submitter": "Alexander Chunikhin", "authors": "Alexander Yu. Chunikhin, Marina D. Sviatnenko", "title": "On Concept of Petri Nets Receptors and Effectors", "comments": "11 pages, 16 figures. arXiv admin note: text overlap with\n  arXiv:1910.09326", "journal-ref": null, "doi": null, "report-no": "PIBNASU-2019/12", "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New subclasses of Petri nets - Petri nets receptors and Petri nets effectors\nare introduced. The introduction/exclusion of such substructures in the main\nPetri net may be fulfilled in accordance with the Fusion/Defusion principles.\nWe propose two pairs of entities: position marking receptor (effector) and\ntransition marking receptor (effector), which allow to observe parameters of\nthe main Petri net and, if necessary, to carry out their regulation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:17:22 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Chunikhin", "Alexander Yu.", ""], ["Sviatnenko", "Marina D.", ""]]}, {"id": "2001.04284", "submitter": "Thomas Ehrhard", "authors": "Thomas Ehrhard (IRIF (UMR\\_8243))", "title": "On the linear structure of cones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For encompassing the limitations of probabilistic coherence spaces which do\nnot seem to provide natural interpretations of continuous data types such as\nthe real line, Ehrhard and al. introduced a model of probabilistic higher order\ncomputation based on (positive) cones, and a class of totally monotone\nfunctions that they called \"stable\". Then Crubill{\\'e} proved that this model\nis a conservative extension of the earlier probabilistic coherence space model.\nWe continue these investigations by showing that the category of cones and\nlinear and Scott-continuous functions is a model of intuitionistic linear\nlogic. To define the tensor product, we use the special adjoint functor\ntheorem, and we prove that this operation is and extension of the standard\ntensor product of probabilistic coherence spaces. We also show that these\nlatter are dense in cones, thus allowing to lift the main properties of the\ntensor product of probabilistic coherence spaces to general cones. Last we\ndefine in the same way an exponential of cones and extend measurability to\nthese new operations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:32:46 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ehrhard", "Thomas", "", "IRIF"]]}, {"id": "2001.04289", "submitter": "Ernst Moritz Hahn", "authors": "Ernst Moritz Hahn and Arnd Hartmanns", "title": "Symblicit Exploration and Elimination for Probabilistic Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary decision diagrams can compactly represent vast sets of states,\nmitigating the state space explosion problem in model checking. Probabilistic\nsystems, however, require multi-terminal diagrams storing rational numbers.\nThey are inefficient for models with many distinct probabilities and for\niterative numeric algorithms like value iteration. In this paper, we present a\nnew \"symblicit\" approach to checking Markov chains and related probabilistic\nmodels: We first generate a decision diagram that symbolically collects all\nreachable states and their predecessors. We then concretise states one-by-one\ninto an explicit partial state space representation. Whenever all predecessors\nof a state have been concretised, we eliminate it from the explicit state space\nin a way that preserves all relevant probabilities and rewards. We thus keep\nfew explicit states in memory at any time. Experiments show that very large\nmodels can be model-checked in this way with very low memory consumption.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 08:02:53 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hahn", "Ernst Moritz", ""], ["Hartmanns", "Arnd", ""]]}, {"id": "2001.04301", "submitter": "Daniel Selsam", "authors": "Daniel Selsam, Sebastian Ullrich, Leonardo de Moura", "title": "Tabled Typeclass Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typeclasses provide an elegant and effective way of managing ad-hoc\npolymorphism in both programming languages and interactive proof assistants.\nHowever, the increasingly sophisticated uses of typeclasses within proof\nassistants, especially within Lean's burgeoning mathematics library, mathlib,\nhave elevated once-theoretical limitations of existing typeclass resolution\nprocedures into major impediments to ongoing progress. The two most devastating\nlimitations of existing procedures are exponential running times in the\npresence of diamonds and divergence in the presence of cycles. We present a new\nprocedure, tabled typeclass resolution, that solves both problems by tabling,\nwhich is a generalization of memoizing originally introduced to address similar\nlimitations of early logic programming systems. We have implemented our\nprocedure for the upcoming version (v4) of Lean, and have confirmed empirically\nthat our implementation is exponentially faster than existing systems in the\npresence of diamonds. Although tabling is notoriously difficult to implement,\nour procedure is notably lightweight and could easily be implemented in other\nsystems. We hope our new procedure facilitates even more sophisticated uses of\ntypeclasses in both software development and interactive theorem proving.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:40:59 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 15:09:43 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Selsam", "Daniel", ""], ["Ullrich", "Sebastian", ""], ["de Moura", "Leonardo", ""]]}, {"id": "2001.04333", "submitter": "Marcin Jurdzi\\'nski", "authors": "Marcin Jurdzi\\'nski, R\\'emi Morvan", "title": "A Universal Attractor Decomposition Algorithm for Parity Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An attractor decomposition meta-algorithm for solving parity games is given\nthat generalizes the classic McNaughton-Zielonka algorithm and its recent\nquasi-polynomial variants due to Parys (2019), and to Lehtinen, Schewe, and\nWojtczak (2019). The central concepts studied and exploited are attractor\ndecompositions of dominia in parity games and the ordered trees that describe\nthe inductive structure of attractor decompositions.\n  The main technical results include the embeddable decomposition theorem and\nthe dominion separation theorem that together help establish a precise\nstructural condition for the correctness of the universal algorithm: it\nsuffices that the two ordered trees given to the algorithm as inputs embed the\ntrees of some attractor decompositions of the largest dominia for each of the\ntwo players, respectively.\n  The universal algorithm yields McNaughton-Zielonka, Parys's, and\nLehtinen-Schewe-Wojtczak algorithms as special cases when suitable universal\ntrees are given to it as inputs. The main technical results provide a unified\nproof of correctness and deep structural insights into those algorithms.\n  A symbolic implementation of the universal algorithm is also given that\nimproves the symbolic space complexity of solving parity games in\nquasi-polynomial time from $O(d \\lg n)$---achieved by Chatterjee,\nDvo\\v{r}\\'{a}k, Henzinger, and Svozil (2018)---down to $O(\\lg d)$, where $n$ is\nthe number of vertices and $d$ is the number of distinct priorities in a parity\ngame. This not only exponentially improves the dependence on $d$, but it also\nentirely removes the dependence on $n$.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:19:05 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jurdzi\u0144ski", "Marcin", ""], ["Morvan", "R\u00e9mi", ""]]}, {"id": "2001.04347", "submitter": "EPTCS", "authors": "Patricia Bouyer (LSV, CNRS and ENS Paris-Saclay, Universit\\'e\n  Paris-Saclay, France), Thomas Brihaye (UMONS - Universit\\'e de Mons,\n  Belgium), Mickael Randour (F.R.S.-FNRS and UMONS - Universit\\'e de Mons,\n  Belgium), C\\'edric Rivi\\`ere (UMONS - Universit\\'e de Mons, Belgium), Pierre\n  Vandenhove (F.R.S.-FNRS, UMONS - Universit\\'e de Mons, Belgium and LSV, CNRS\n  and ENS Paris-Saclay, Universit\\'e Paris-Saclay, France)", "title": "Decisiveness of Stochastic Systems and its Application to Hybrid Models", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 149-165", "doi": "10.4204/EPTCS.326.10", "report-no": null, "categories": "cs.LO cs.FL cs.SY eess.SY math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [ABM07], Abdulla et al. introduced the concept of decisiveness, an\ninteresting tool for lifting good properties of finite Markov chains to\ndenumerable ones. Later, this concept was extended to more general stochastic\ntransition systems (STSs), allowing the design of various verification\nalgorithms for large classes of (infinite) STSs. We further improve the\nunderstanding and utility of decisiveness in two ways. First, we provide a\ngeneral criterion for proving decisiveness of general STSs. This criterion,\nwhich is very natural but whose proof is rather technical, (strictly)\ngeneralizes all known criteria from the literature. Second, we focus on\nstochastic hybrid systems (SHSs), a stochastic extension of hybrid systems. We\nestablish the decisiveness of a large class of SHSs and, under a few classical\nhypotheses from mathematical logic, we show how to decide reachability problems\nin this class, even though they are undecidable for general SHSs. This provides\na decidable stochastic extension of o-minimal hybrid systems. [ABM07] Parosh A.\nAbdulla, Noomene Ben Henda, and Richard Mayr. 2007. Decisive Markov Chains.\nLog. Methods Comput. Sci. 3, 4 (2007).\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:37:49 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 01:26:29 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Bouyer", "Patricia", "", "LSV, CNRS and ENS Paris-Saclay, Universit\u00e9\n  Paris-Saclay, France"], ["Brihaye", "Thomas", "", "UMONS - Universit\u00e9 de Mons,\n  Belgium"], ["Randour", "Mickael", "", "F.R.S.-FNRS and UMONS - Universit\u00e9 de Mons,\n  Belgium"], ["Rivi\u00e8re", "C\u00e9dric", "", "UMONS - Universit\u00e9 de Mons, Belgium"], ["Vandenhove", "Pierre", "", "F.R.S.-FNRS, UMONS - Universit\u00e9 de Mons, Belgium and LSV, CNRS\n  and ENS Paris-Saclay, Universit\u00e9 Paris-Saclay, France"]]}, {"id": "2001.04405", "submitter": "Andrew Mironov", "authors": "Andrew M. Mironov", "title": "State diagrams of functional programs", "comments": "arXiv admin note: text overlap with arXiv:1604.04240", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we introduce graphical objects (called state diagrams) related\nto functional programs. It is shown that state diagrams of functional programs\ncan be used to solve problems of verification of functional programs. The\nproposed approach is illustrated by an example of verification of a sorting\nprogram.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 16:38:13 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Mironov", "Andrew M.", ""]]}, {"id": "2001.04439", "submitter": "Ankush Das", "authors": "Ankush Das and Frank Pfenning", "title": "Session Types with Arithmetic Refinements and Their Application to Work\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session types statically prescribe bidirectional communication protocols for\nmessage-passing processes and are in a Curry-Howard correspondence with linear\nlogic propositions. However, simple session types cannot specify properties\nbeyond the type of exchanged messages. In this paper we extend the type system\nby using index refinements from linear arithmetic capturing intrinsic\nattributes of data structures and algorithms so that we can express and verify\namortized cost of programs using ergometric types. We show that, despite the\ndecidability of Presburger arithmetic, type equality and therefore also type\nchecking are now undecidable, which stands in contrast to analogous dependent\nrefinement type systems from functional languages. We also present a practical\nincomplete algorithm for type equality and an algorithm for type checking which\nis complete relative to an oracle for type equality. Process expressions in\nthis explicit language are rather verbose, so we also introduce an implicit\nform and a sound and complete algorithm for reconstructing explicit programs,\nborrowing ideas from the proof-theoretic technique of focusing. We conclude by\nillustrating our systems and algorithms with a variety of examples that have\nbeen verified in our implementation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:20:50 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 14:49:47 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 23:19:49 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Das", "Ankush", ""], ["Pfenning", "Frank", ""]]}, {"id": "2001.04457", "submitter": "Natarajan Shankar", "authors": "Clement Blaudeau and Natarajan Shankar", "title": "A Verified Packrat Parser Interpreter for Parsing Expression Grammars", "comments": "15 pages, 15 figures, Certified Proofs and Programs", "journal-ref": null, "doi": "10.1145/3372885.3373836", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing expression grammars (PEGs) offer a natural opportunity for building\nverified parser interpreters based on higher-order parsing combinators. PEGs\nare expressive, unambiguous, and efficient to parse in a top-down recursive\ndescent style. We use the rich type system of the PVS specification language\nand verification system to formalize the metatheory of PEGs and define a\nreference implementation of a recursive parser interpreter for PEGs. In order\nto ensure termination of parsing, we define a notion of a well-formed grammar.\nRather than relying on an inductive definition of parsing, we use abstract\nsyntax trees that represent the computational trace of the parser to provide an\neffective proof certificate for correct parsing and ensure that parsing\nproperties including soundness and completeness are maintained. The correctness\nproperties are embedded in the types of the operations so that the proofs can\nbe easily constructed from local proof obligations. Building on the reference\nparser interpreter, we define a packrat parser interpreter as well as an\nextension that is capable of semantic interpretation. Both these parser\ninterpreters are proved equivalent to the reference one. All of the parsers are\nexecutable. The proofs are formalized in mathematical terms so that similar\nparser interpreters can be defined in any specification language with a type\nsystem similar to PVS.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:45:14 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Blaudeau", "Clement", ""], ["Shankar", "Natarajan", ""]]}, {"id": "2001.04458", "submitter": "Rahul Savani", "authors": "John Fearnley, Rasmus Ibsen-Jensen, Rahul Savani", "title": "One-Clock Priced Timed Games are PSPACE-hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main result of this paper is that computing the value of a one-clock\npriced timed game (OCPTG) is PSPACE-hard. Along the way, we provide a family of\nOCPTGs that have an exponential number of event points. Both results hold even\nin very restricted classes of games such as DAGs with treewidth three. Finally,\nwe provide a number of positive results, including polynomial-time algorithms\nfor even more restricted classes of OCPTGs such as trees.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:46:42 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 19:05:44 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Fearnley", "John", ""], ["Ibsen-Jensen", "Rasmus", ""], ["Savani", "Rahul", ""]]}, {"id": "2001.04669", "submitter": "Ami Sakakibara", "authors": "Ryohei Oura, Ami Sakakibara, Toshimitsu Ushio", "title": "Reinforcement Learning of Control Policy for Linear Temporal Logic\n  Specifications Using Limit-Deterministic Generalized B\\\"uchi Automata", "comments": "7 pages, 6 figures; an extended version of a manuscript accepted to\n  IEEE L-CSS", "journal-ref": null, "doi": "10.1109/LCSYS.2020.2980552", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter proposes a novel reinforcement learning method for the synthesis\nof a control policy satisfying a control specification described by a linear\ntemporal logic formula. We assume that the controlled system is modeled by a\nMarkov decision process (MDP). We convert the specification to a\nlimit-deterministic generalized B\\\"uchi automaton (LDGBA) with several\naccepting sets that accepts all infinite sequences satisfying the formula. The\nLDGBA is augmented so that it explicitly records the previous visits to\naccepting sets. We take a product of the augmented LDGBA and the MDP, based on\nwhich we define a reward function. The agent gets rewards whenever state\ntransitions are in an accepting set that has not been visited for a certain\nnumber of steps. Consequently, sparsity of rewards is relaxed and optimal\ncirculations among the accepting sets are learned. We show that the proposed\nmethod can learn an optimal policy when the discount factor is sufficiently\nclose to one.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 08:55:56 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 07:25:09 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 07:39:51 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Oura", "Ryohei", ""], ["Sakakibara", "Ami", ""], ["Ushio", "Toshimitsu", ""]]}, {"id": "2001.04701", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller", "title": "A (Simplified) Supreme Being Necessarily Exists, says the Computer:\n  Computationally Explored Variants of G\\\"odel's Ontological Argument", "comments": "11 pages, 11 figures", "journal-ref": "KR 2020 -- The 17th International Conference on Principles of\n  Knowledge Representation and Reasoning, Rhodes, Greece, September 12-18, 2020", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL math.GN math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to universal (meta-)logical reasoning in classical higher-order\nlogic is employed to explore and study simplifications of Kurt G\\\"odel's modal\nontological argument. Some argument premises are modified, others are dropped,\nmodal collapse is avoided and validity is shown already in weak modal logics K\nand T. Key to the gained simplifications of G\\\"odel's original theory is the\nexploitation of a link to the notions of filter and ultrafilter from topology.\nThe paper illustrates how modern knowledge representation and reasoning\ntechnology for quantified non-classical logics can contribute new knowledge to\nother disciplines. The contributed material is also well suited to support\nteaching of non-trivial logic formalisms in classroom.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:26:51 GMT"}, {"version": "v10", "created": "Sun, 14 Jun 2020 06:25:33 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 12:16:56 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 09:27:58 GMT"}, {"version": "v4", "created": "Sun, 9 Feb 2020 08:32:22 GMT"}, {"version": "v5", "created": "Tue, 11 Feb 2020 10:13:53 GMT"}, {"version": "v6", "created": "Sat, 15 Feb 2020 17:06:34 GMT"}, {"version": "v7", "created": "Thu, 12 Mar 2020 08:52:54 GMT"}, {"version": "v8", "created": "Wed, 25 Mar 2020 14:43:57 GMT"}, {"version": "v9", "created": "Mon, 4 May 2020 15:17:25 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2001.04952", "submitter": "Steve Huntsman", "authors": "Steve Huntsman, Michael Robinson", "title": "The geometry of syntax and semantics for directed file transformations", "comments": null, "journal-ref": "LangSec workshop at IEEE S&P (2020);\n  http://spw20.langsec.org/papers.html", "doi": "10.1109/SPW50608.2020.00062", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a conceptual framework that associates syntax and semantics with\nvertical and horizontal directions in principal bundles and related\nconstructions. This notion of geometry corresponds to a mechanism for\nperforming goal-directed file transformations such as \"eliminate unsafe syntax\"\nand suggests various engineering practices.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:15:30 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Huntsman", "Steve", ""], ["Robinson", "Michael", ""]]}, {"id": "2001.04971", "submitter": "Sebastian Enqvist", "authors": "Sebastian Enqvist", "title": "A circular proof system for the hybrid mu-calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a circular and cut-free proof system for the hybrid mu-calculus\nand prove its soundness and completeness. The system uses names for fixpoint\nunfoldings, like the circular proof system for the mu-calculus previously\ndeveloped by Stirling.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:58:13 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 11:57:18 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 10:57:22 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Enqvist", "Sebastian", ""]]}, {"id": "2001.05059", "submitter": "Petar Maksimovi\\'c", "authors": "Jos\\'e Fragoso Santos, Petar Maksimovi\\'c, Sacha-\\'Elie Ayoun,\n  Philippa Gardner", "title": "Gillian: Compositional Symbolic Execution for All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Gillian, a language-independent framework for the development of\ncompositional symbolic analysis tools. Gillian supports three flavours of\nanalysis: whole-program symbolic testing, full verification, and bi-abduction.\nIt comes with fully parametric meta-theoretical results and a modular\nimplementation, designed to minimise the instantiation effort required of the\nuser. We evaluate Gillian by instantiating it to JavaScript and C, and perform\nits analyses on a set of data-structure libraries, obtaining results that\nindicate that Gillian is robust enough to reason about real-world programming\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 22:03:48 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Santos", "Jos\u00e9 Fragoso", ""], ["Maksimovi\u0107", "Petar", ""], ["Ayoun", "Sacha-\u00c9lie", ""], ["Gardner", "Philippa", ""]]}, {"id": "2001.05132", "submitter": "Farzaneh Derakhshan", "authors": "Farzaneh Derakhshan, Frank Pfenning", "title": "Strong Progress for Session-Typed Processes in a Linear Metalogic with\n  Circular Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an infinitary first order linear logic with least and greatest\nfixed points. To ensure cut elimination, we impose a validity condition on\ninfinite derivations. Our calculus is designed to reason about rich signatures\nof mutually defined inductive and coinductive linear predicates. In a major\ncase study we use it to prove the strong progress property for binary\nsession-typed processes under an asynchronous communication semantics. As far\nas we are aware, this is the first proof of this property.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 04:47:39 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 17:33:54 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Derakhshan", "Farzaneh", ""], ["Pfenning", "Frank", ""]]}, {"id": "2001.05263", "submitter": "Ondrej Kuzelka", "authors": "Timothy van Bremen, Ondrej Kuzelka", "title": "Approximate Weighted First-Order Model Counting: Exploiting Fast\n  Approximate Model Counters and Symmetry", "comments": "Presented at StarAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the symmetric weighted first-order model counting task and present\nApproxWFOMC, a novel anytime method for efficiently bounding the weighted\nfirst-order model count in the presence of an unweighted first-order model\ncounting oracle. The algorithm has applications to inference in a variety of\nfirst-order probabilistic representations, such as Markov logic networks and\nprobabilistic logic programs. Crucially for many applications, we make no\nassumptions on the form of the input sentence. Instead, our algorithm makes use\nof the symmetry inherent in the problem by imposing cardinality constraints on\nthe number of possible true groundings of a sentence's literals. Realising the\nfirst-order model counting oracle in practice using the approximate\nhashing-based model counter ApproxMC3, we show how our algorithm outperforms\nexisting approximate and exact techniques for inference in first-order\nprobabilistic models. We additionally provide PAC guarantees on the generated\nbounds.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:21:06 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["van Bremen", "Timothy", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "2001.05952", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "On Expert Behaviors and Question Types for Efficient Query-Based\n  Ontology Fault Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We challenge existing query-based ontology fault localization methods wrt.\nassumptions they make, criteria they optimize, and interaction means they use.\nWe find that their efficiency depends largely on the behavior of the\ninteracting expert, that performed calculations can be inefficient or\nimprecise, and that used optimization criteria are often not fully realistic.\nAs a remedy, we suggest a novel (and simpler) interaction approach which\novercomes all identified problems and, in comprehensive experiments on faulty\nreal-world ontologies, enables a successful fault localization while requiring\nfewer expert interactions in 66 % of the cases, and always at least 80 % less\nexpert waiting time, compared to existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 17:23:07 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "2001.05977", "submitter": "Dominik Wojtczak", "authors": "E. M. Hahn, M. Perez, S. Schewe, F. Somenzi, A. Trivedi, D. Wojtczak", "title": "Reward Shaping for Reinforcement Learning with Omega-Regular Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, successful approaches have been made to exploit good-for-MDPs\nautomata (B\\\"uchi automata with a restricted form of nondeterminism) for model\nfree reinforcement learning, a class of automata that subsumes good for games\nautomata and the most widespread class of limit deterministic automata. The\nfoundation of using these B\\\"uchi automata is that the B\\\"uchi condition can,\nfor good-for-MDP automata, be translated to reachability.\n  The drawback of this translation is that the rewards are, on average, reaped\nvery late, which requires long episodes during the learning process. We devise\na new reward shaping approach that overcomes this issue. We show that the\nresulting model is equivalent to a discounted payoff objective with a biased\ndiscount that simplifies and improves on prior work in this direction.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:22:50 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hahn", "E. M.", ""], ["Perez", "M.", ""], ["Schewe", "S.", ""], ["Somenzi", "F.", ""], ["Trivedi", "A.", ""], ["Wojtczak", "D.", ""]]}, {"id": "2001.06163", "submitter": "EPTCS", "authors": "Alessandro Aldini (University of Urbino), Herbert Wiklicky (Imperial\n  College London)", "title": "Proceedings 16th Workshop on Quantitative Aspects of Programming\n  Languages and Systems", "comments": null, "journal-ref": "EPTCS 312, 2020", "doi": "10.4204/EPTCS.312", "report-no": null, "categories": "cs.PL cs.GT cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This EPTCS volume contains the proceedings of the 16th Workshop on\nQuantitative Aspects of Programming Languages and Systems (QAPL 2019) held in\nPrague, Czech Republic, on Sunday 7 April 2019. QAPL 2019 was a satellite event\nof the European Joint Conferences on Theory and Practice of Software (ETAPS\n2019).\n  QAPL focuses on quantitative aspects of computations, which may refer to the\nuse of physical quantities (time, bandwidth, etc.) as well as mathematical\nquantities (e.g., probabilities) for the characterisation of the behaviour and\nfor determining the properties of systems. Such quantities play a central role\nin defining both the model of systems (architecture, language design,\nsemantics) and the methodologies and tools for the analysis and verification of\nsystem properties. The aim of the QAPL workshop series is to discuss the\nexplicit use of time and probability and general quantities either directly in\nthe model or as a tool for the analysis or synthesis of systems.\n  The 16th edition of QAPL also focuses on discussing the developments,\nchallenges and results in this area covered by our workshop in its nearly\n20-year history.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 05:38:50 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Aldini", "Alessandro", "", "University of Urbino"], ["Wiklicky", "Herbert", "", "Imperial\n  College London"]]}, {"id": "2001.06235", "submitter": "Florian Zuleger", "authors": "Jens Pagel, Florian Zuleger", "title": "Strong-Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most automated verifiers for separation logic target the symbolic-heap\nfragment, disallowing both the magic-wand operator and the application of\nclassical Boolean operators to spatial formulas. This is not surprising, as\nsupport for the magic wand quickly leads to undecidability, especially when\ncombined with inductive predicates for reasoning about data structures. To\ncircumvent these undecidability results, we propose to assign a more\nrestrictive semantics to the separating conjunction. We argue that the\nresulting logic, strong-separation logic, can be used for compositional program\nverification and bi-abductive static analysis just like \"standard\" separation\nlogic, while remaining decidable even in the presence of both the magic wand\nand the list-segment predicate -- a combination of features that leads to\nundecidability assuming the standard semantics.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 10:56:34 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 20:11:32 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Pagel", "Jens", ""], ["Zuleger", "Florian", ""]]}, {"id": "2001.06272", "submitter": "Filip Mazowiecki", "authors": "Agnishom Chattopadhyay, Filip Mazowiecki, Anca Muscholl and Cristian\n  Riveros", "title": "Pumping lemmas for weighted automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present pumping lemmas for five classes of functions definable by\nfragments of weighted automata over the min-plus semiring, the max-plus\nsemiring and the semiring of natural numbers. As a corollary we show that the\nhierarchy of functions definable by unambiguous, finitely-ambiguous,\npolynomially-ambiguous weighted automata, and the full class of weighted\nautomata is strict for the min-plus and max-plus semirings.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 12:49:59 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 14:24:44 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 12:48:35 GMT"}, {"version": "v4", "created": "Tue, 20 Jul 2021 16:01:14 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chattopadhyay", "Agnishom", ""], ["Mazowiecki", "Filip", ""], ["Muscholl", "Anca", ""], ["Riveros", "Cristian", ""]]}, {"id": "2001.06348", "submitter": "Bas Westerbaan", "authors": "Louis Parlant, Jurriaan Rot, Alexandra Silva, Bas Westerbaan", "title": "Preservation of Equations by Monoidal Monads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If a monad $T$ is monoidal, then operations on a set $X$ can be lifted\ncanonically to operations on $TX$. In this paper we study structural properties\nunder which $T$ preserves equations between those operations. It has already\nbeen shown that any monoidal monad preserves linear equations; affine monads\npreserve drop equations (where some variable appears only on one side, such as\n$x\\cdot y = y$) and relevant monads preserve dup equations (where some variable\nis duplicated, such as $x \\cdot x = x$). We start the paper by showing a\nconverse: if the monad at hand preserves a drop equation, then it must be\naffine. From this, we show that the problem whether a given (drop) equation is\npreserved is undecidable. A converse for relevance turns out to be more subtle:\npreservation of certain dup equations implies a weaker notion which we call\n$n$-relevance. Finally, we identify the subclass of equations such that their\npreservation is equivalent to relevance.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 14:45:12 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 10:53:29 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Parlant", "Louis", ""], ["Rot", "Jurriaan", ""], ["Silva", "Alexandra", ""], ["Westerbaan", "Bas", ""]]}, {"id": "2001.06358", "submitter": "Peter Lindner", "authors": "Martin Grohe, Benjamin Lucien Kaminski, Joost-Pieter Katoen, Peter\n  Lindner", "title": "Generative Datalog with Continuous Distributions", "comments": "Extended Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arguing for the need to combine declarative and probabilistic programming,\nB\\'ar\\'any et al. (TODS 2017) recently introduced a probabilistic extension of\nDatalog as a \"purely declarative probabilistic programming language.\" We\nrevisit this language and propose a more principled approach towards defining\nits semantics based on stochastic kernels and Markov processes - standard\nnotions from probability theory. This allows us to extend the semantics to\ncontinuous probability distributions, thereby settling an open problem posed by\nB\\'ar\\'any et al.\n  We show that our semantics is fairly robust, allowing both parallel execution\nand arbitrary chase orders when evaluating a program. We cast our semantics in\nthe framework of infinite probabilistic databases (Grohe and Lindner, ICDT\n2020), and show that the semantics remains meaningful even when the input of a\nprobabilistic Datalog program is an arbitrary probabilistic database.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:02:21 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 11:56:00 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Grohe", "Martin", ""], ["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""], ["Lindner", "Peter", ""]]}, {"id": "2001.06380", "submitter": "Anton Freund", "authors": "Anton Freund and Michael Rathjen and Andreas Weiermann", "title": "Minimal bad sequences are necessary for a uniform Kruskal theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimal bad sequence argument due to Nash-Williams is a powerful tool in\ncombinatorics with important implications for theoretical computer science. In\nparticular, it yields a very elegant proof of Kruskal's theorem. At the same\ntime, it is known that Kruskal's theorem does not require the full strength of\nthe minimal bad sequence argument. This claim can be made precise in the\nframework of reverse mathematics, where the existence of minimal bad sequences\nis equivalent to a principle known as $\\Pi^1_1$-comprehension, which is much\nstronger than Kruskal's theorem. In the present paper we give a uniform version\nof Kruskal's theorem by relativizing it to certain transformations of well\npartial orders. We show that $\\Pi^1_1$-comprehension is equivalent to our\nuniform Kruskal theorem (over $\\mathbf{RCA}_0$ together with the\nchain-antichain principle). This means that any proof of the uniform Kruskal\ntheorem must entail the existence of minimal bad sequences. As a by-product of\nour investigation, we obtain uniform proofs of several Kruskal-type\nindependence results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:41:58 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Freund", "Anton", ""], ["Rathjen", "Michael", ""], ["Weiermann", "Andreas", ""]]}, {"id": "2001.06676", "submitter": "Micha{\\l} Wrona", "authors": "Micha{\\l} Wrona", "title": "Relational Width of First-Order Expansions of Homogeneous Graphs with\n  Bounded Strict Width", "comments": "A long version of an extended abstract that appeared in STACS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Solving the algebraic dichotomy conjecture for constraint satisfaction\nproblems over structures first-order definable in countably infinite finitely\nbounded homogeneous structures requires understanding the applicability of\nlocal-consistency methods in this setting. We study the amount of consistency\n(measured by relational width) needed to solve CSP for first-order expansions S\nof countably infinite homogeneous graphs that additionally have bounded strict\nwidth, i.e., for which establishing local consistency of an instance of the CSP\nnot only decides if there is a solution but also ensures that every solution\nmay be obtained from a locally consistent instance by greedily assigning values\nto variables, without backtracking.\n  Our main result is that the structures S under consideration have relational\nwidth exactly (2, L) where L is the maximal size of a forbidden subgraph of a\nhomogeneous graph under consideration, but not smaller than 3. It beats the\nupper bound (2m, 3m) where m = max(arity(S)+1, L, 3) and arity(S) is the\nlargest arity of a relation in S, which follows from a sufficient condition\nimplying bounded relational width from the literature. Since L may be\narbitrarily large, our result contrasts the collapse of the relational bounded\nwidth hierarchy for finite structures , whose relational width, if finite, is\nalways at most (2,3).\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 14:53:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wrona", "Micha\u0142", ""]]}, {"id": "2001.06702", "submitter": "Adnan Rashid", "authors": "Adnan Rashid, Ayesha Gauhar and Osman Hasan", "title": "FASiM: A Framework for Automatic Formal Analysis of Simulink Models of\n  Linear Analog Circuits", "comments": null, "journal-ref": "IEEE International Systems Conference (SysCon 2020)", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulink is a graphical environment that is widely adapted for the modeling\nand the Laplace transform based analysis of linear analog circuits used in\nsignal processing architectures. However, due to the involvement of the\nnumerical algorithms of MATLAB in the analysis process, the analysis results\ncannot be termed as complete and accurate. Higher-order-logic theorem proving\nis a formal verification method that has been recently proposed to overcome\nthese limitations for the modeling and the Laplace transform based analysis of\nlinear analog circuits. However, the formal modeling of a system is not a\nstraightforward task due to the lack of formal methods background for engineers\nworking in the industry. Moreover, due to the undecidable nature of\nhigher-order logic, the analysis generally requires a significant amount of\nuser guidance in the manual proof process. In order to facilitate industrial\nengineers to formally analyze the linear analog circuits based on the Laplace\ntransform, we propose a framework, FASiM, which allows automatically conducting\nthe formal analysis of the Simulink models of linear analog circuits using the\nHOL Light theorem prover. For illustration, we use FASiM to formally analyze\nSimulink models of some commonly used linear analog filters, such as Sallen-key\nfilters.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 17:26:25 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Rashid", "Adnan", ""], ["Gauhar", "Ayesha", ""], ["Hasan", "Osman", ""]]}, {"id": "2001.06863", "submitter": "Stepan Kuznetsov", "authors": "Stepan L. Kuznetsov, Stanislav O. Speranski", "title": "Infinitary Action Logic with Exponentiation", "comments": "Submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce infinitary action logic with exponentiation -- that is, the\nmultiplicative-additive Lambek calculus extended with Kleene star and with a\nfamily of subexponential modalities, which allows some of the structural rules\n(contraction, weakening, permutation). The logic is presented in the form of an\ninfinitary sequent calculus. We prove cut elimination and, in the case where at\nleast one subexponential allows non-local contraction, establish exact\ncomplexity boundaries in two senses. First, we show that the derivability\nproblem for this logic is $\\Pi_1^1$-complete. Second, we show that the closure\nordinal of its derivability operator is $\\omega_1^{\\mathrm{CK}}$. In the case\nwhere no subexponential allows contraction, we show that complexity is the same\nas for infinitary action logic itself. Namely, the derivability problem in this\ncase is $\\Pi^0_1$-complete and the closure ordinal is not greater than\n$\\omega^\\omega$.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 16:55:13 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 11:48:37 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 21:49:12 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kuznetsov", "Stepan L.", ""], ["Speranski", "Stanislav O.", ""]]}, {"id": "2001.06905", "submitter": "Vladimir Zamdzhiev", "authors": "Vladimir Zamdzhiev", "title": "Semantics for first-order affine inductive data types via slice\n  categories", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-57201-3_10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affine type systems are substructural type systems where copying of\ninformation is restricted, but discarding of information is permissible at all\ntypes. Such type systems are well-suited for describing quantum programming\nlanguages, because copying of quantum information violates the laws of quantum\nmechanics. In this paper, we consider a first-order affine type system with\ninductive data types and present a novel categorical semantics for it. The most\nchallenging aspect of this interpretation comes from the requirement to\nconstruct appropriate discarding maps for our data types which might be defined\nby mutual/nested recursion. We show how to achieve this for all types by taking\nmodels of a first-order linear type system whose atomic types are discardable\nand then presenting an additional affine interpretation of types within the\nslice category of the model with the tensor unit. We present some concrete\ncategorical models for the language ranging from classical to quantum. Finally,\nwe discuss potential ways of dualising and extending our methods and using them\nfor interpreting coalgebraic and lazy data types.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 21:15:34 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Zamdzhiev", "Vladimir", ""]]}, {"id": "2001.06942", "submitter": "EPTCS", "authors": "Alessandro Aldini (University of Urbino)", "title": "Quantitative Aspects of Programming Languages and Systems over the past\n  $2^4$ years and beyond", "comments": "In Proceedings QAPL 2019, arXiv:2001.06163", "journal-ref": "EPTCS 312, 2020, pp. 1-19", "doi": "10.4204/EPTCS.312.1", "report-no": null, "categories": "cs.PL cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative aspects of computation are related to the use of both physical\nand mathematical quantities, including time, performance metrics, probability,\nand measures for reliability and security. They are essential in characterizing\nthe behaviour of many critical systems and in estimating their properties.\nHence, they need to be integrated both at the level of system modeling and\nwithin the verification methodologies and tools. Along the last two decades a\nvariety of theoretical achievements and automated techniques have contributed\nto make quantitative modeling and verification mainstream in the research\ncommunity. In the same period, they represented the central theme of the series\nof workshops entitled Quantitative Aspects of Programming Languages and Systems\n(QAPL) and born in 2001. The aim of this survey is to revisit such achievements\nand results from the standpoint of QAPL and its community.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 02:17:03 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Aldini", "Alessandro", "", "University of Urbino"]]}, {"id": "2001.06952", "submitter": "Xiaokang Qiu", "authors": "Xiaokang Qiu", "title": "Streaming Transformations of Infinite Ordered-Data Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define streaming register transducer (SRT), a one-way,\nletter-to-letter, transductional machine model for transformations of infinite\ndata words whose data domain forms a linear group. Comparing with existing data\nword transducers, SRT are able to perform two extra operations on the\nregisters: a linear-order-based comparison and an additive update. We consider\nthe transformations that can be defined by SRT and several subclasses of SRT.\nWe investigate the expressiveness of these languages and several decision\nproblems. Our main results include: 1) SRT are closed under union and\nintersection, and add-free SRT are also closed under composition; 2)\nSRT-definable transformations can be defined in monadic second-order (MSO)\nlogic, but are not comparable with first-order (FO) definable transformations;\n3) the functionality problem is decidable for add-free SRT, the reactivity\nproblem and inclusion problem are decidable for deterministic add-free SRT, but\nnone of these problems is decidable in general for SRT.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 02:53:35 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Qiu", "Xiaokang", ""]]}, {"id": "2001.07063", "submitter": "Jean-Marie Madiot", "authors": "Jean-Marie Madiot, Damien Pous, Davide Sangiorgi", "title": "Modular coinduction up-to for higher-order languages via first-order\n  transition systems", "comments": "This paper is an improved and extended version of a paper appeared in\n  Proc. CONCUR 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The bisimulation proof method can be enhanced by employing `bisimulations\nup-to' techniques. A comprehensive theory of such enhancements has been\ndeveloped for first-order (i.e., CCS-like) labelled transition systems (LTSs)\nand bisimilarity, based on abstract fixed-point theory and compatible\nfunctions.\n  We transport this theory onto languages whose bisimilarity and LTS go beyond\nthose of first-order models. The approach consists in exhibiting fully abstract\ntranslations of the more sophisticated LTSs and bisimilarities onto the\nfirst-order ones. This allows us to reuse directly the large corpus of up-to\ntechniques that are available on first-order LTSs. The only ingredient that has\nto be manually supplied is the compatibility of basic up-to techniques that are\nspecific to the new languages. We investigate the method on the pi-calculus,\nthe lambda-calculus, and a (call-by-value) lambda-calculus with references.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 11:32:03 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 11:14:32 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 12:52:11 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Madiot", "Jean-Marie", ""], ["Pous", "Damien", ""], ["Sangiorgi", "Davide", ""]]}, {"id": "2001.07141", "submitter": "Bastien Maubert", "authors": "Bastien Maubert, Aniello Murano, Sophie Pinchinat, Fran\\c{c}ois\n  Schwarzentruber and Silvia Stranieri", "title": "Dynamic Epistemic Logic Games with Epistemic Temporal Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Epistemic Logic (DEL) is a logical framework in which one can\ndescribe in great detail how actions are perceived by the agents, and how they\naffect the world. DEL games were recently introduced as a way to define classes\nof games with imperfect information where the actions available to the players\nare described very precisely. This framework makes it possible to define\neasily, for instance, classes of games where players can only use public\nactions or public announcements. These games have been studied for reachability\nobjectives, where the aim is to reach a situation satisfying some epistemic\nproperty expressed in epistemic logic; several (un)decidability results have\nbeen established. In this work we show that the decidability results obtained\nfor reachability objectives extend to a much more general class of winning\nconditions, namely those expressible in the epistemic temporal logic LTLK. To\ndo so we establish that the infinite game structures generated by DEL public\nactions are regular, and we describe how to obtain finite representations on\nwhich we rely to solve them.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 15:27:23 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Pinchinat", "Sophie", ""], ["Schwarzentruber", "Fran\u00e7ois", ""], ["Stranieri", "Silvia", ""]]}, {"id": "2001.07205", "submitter": "Zhiyu Liu", "authors": "Zhiyu Liu, Meng Jiang, Hai Lin", "title": "A graph-based spatial temporal logic for knowledge representation and\n  automated reasoning in cognitive robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new graph-based spatial temporal logic for knowledge\nrepresentation and automated reasoning in this paper. The proposed logic\nachieves a balance between expressiveness and tractability in applications such\nas cognitive robots. The satisfiability of the proposed logic is decidable. We\napply a Hilbert style axiomatization for the proposed graph-based spatial\ntemporal logic, in which Modus ponens and IRR are the inference rules. We show\nthat the corresponding deduction system is sound and complete and can be\nimplemented through SAT.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 18:44:27 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 19:43:21 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 23:08:37 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Liu", "Zhiyu", ""], ["Jiang", "Meng", ""], ["Lin", "Hai", ""]]}, {"id": "2001.07317", "submitter": "Chuyu Xiong", "authors": "Chuyu Xiong", "title": "Sampling and Learning for Boolean Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we continue our study on universal learning machine by\nintroducing new tools. We first discuss boolean function and boolean circuit,\nand we establish one set of tools, namely, fitting extremum and proper sampling\nset. We proved the fundamental relationship between proper sampling set and\ncomplexity of boolean circuit. Armed with this set of tools, we then introduce\nmuch more effective learning strategies. We show that with such learning\nstrategies and learning dynamics, universal learning can be achieved, and\nrequires much less data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 03:01:14 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Xiong", "Chuyu", ""]]}, {"id": "2001.07541", "submitter": "Ana Ozaki", "authors": "Camille Bourgaux, Ana Ozaki, Rafael Pe\\~naloza and Livia Predoiu", "title": "Provenance for the Description Logic ELHr", "comments": "This is the long version of IJCAI 2020 paper 2243 (24 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of handling provenance information in ELHr ontologies.\nWe consider a setting recently introduced for ontology-based data access, based\non semirings and extending classical data provenance, in which ontology axioms\nare annotated with provenance tokens. A consequence inherits the provenance of\nthe axioms involved in deriving it, yielding a provenance polynomial as an\nannotation. We analyse the semantics for the ELHr case and show that the\npresence of conjunctions poses various difficulties for handling provenance,\nsome of which are mitigated by assuming multiplicative idempotency of the\nsemiring. Under this assumption, we study three problems: ontology completion\nwith provenance, computing the set of relevant axioms for a consequence, and\nquery answering.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:56:48 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 22:16:35 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Bourgaux", "Camille", ""], ["Ozaki", "Ana", ""], ["Pe\u00f1aloza", "Rafael", ""], ["Predoiu", "Livia", ""]]}, {"id": "2001.07592", "submitter": "Yakov Savelyev", "authors": "Yasha Savelyev", "title": "Incompleteness for stably consistent formal systems", "comments": "17 pages, rewritten with stronger results generalizing the original\n  Godel incompleteness theorems to stable consistency. Added background\n  concerning recent related works. Simplified the language, particularly the\n  notion of an abstract Turing machine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first partly develop a mathematical notion of stable consistency intended\nto reflect the actual consistency property of human beings. Then we give a\ngeneralization of the first and second G\\\"odel incompleteness theorem to stably\n$1,2$-consistent formal systems. Our argument in particular re-proves the\noriginal incompleteness theorems from first principles, using Turing machine\nlanguage to (computably) construct our \"G\\\"odel sentence\" directly, in\nparticular we do not use the diagonal lemma, nor any meta-logic, with the proof\nnaturally formalizable in set theory. In practice such a stably consistent\nformal system could be meant to represent the mathematical output of humanity\nevolving in time, so that the above gives a formalization of a famous\ndisjunction of G\\\"odel, obstructing computability of intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:04:15 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 00:55:26 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 16:47:08 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 23:10:14 GMT"}, {"version": "v5", "created": "Thu, 5 Nov 2020 18:22:25 GMT"}, {"version": "v6", "created": "Wed, 19 May 2021 17:40:44 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Savelyev", "Yasha", ""]]}, {"id": "2001.07655", "submitter": "Nicolai Kraus", "authors": "Nicolai Kraus and Jakob von Raumer", "title": "Coherence via Well-Foundedness: Taming Set-Quotients in Homotopy Type\n  Theory", "comments": "v2: essentially the version published in the proceedings of Logic in\n  Computer Science, numbering identical", "journal-ref": "Logic in Computer Science 2020 (LICS'20)", "doi": "10.1145/3373718.3394800.", "report-no": null, "categories": "math.LO cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we are given a graph and want to show a property for all its cycles\n(closed chains). Induction on the length of cycles does not work since\nsub-chains of a cycle are not necessarily closed. This paper derives a\nprinciple reminiscent of induction for cycles for the case that the graph is\ngiven as the symmetric closure of a locally confluent and (co-)well-founded\nrelation. We show that, assuming the property in question is sufficiently nice,\nit is enough to prove it for the empty cycle and for cycles given by local\nconfluence.\n  Our motivation and application is in the field of homotopy type theory, which\nallows us to work with the higher-dimensional structures that appear in\nhomotopy theory and in higher category theory, making coherence a central\nissue. This is in particular true for quotienting - a natural operation which\ngives a new type for any binary relation on a type and, in order to be\nwell-behaved, cuts off higher structure (set-truncates). The latter makes it\nhard to characterise the type of maps from a quotient into a higher type, and\nseveral open problems stem from this difficulty.\n  We prove our theorem on cycles in a type-theoretic setting and use it to show\ncoherence conditions necessary to eliminate from set-quotients into 1-types,\nderiving approximations to open problems on free groups and pushouts. We have\nformalised the main result in the proof assistant Lean.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 17:13:27 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 03:58:52 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kraus", "Nicolai", ""], ["von Raumer", "Jakob", ""]]}, {"id": "2001.07658", "submitter": "Tim A. C. Willemse", "authors": "Jan Friso Groote and Tim A. C. Willemse", "title": "A symmetric protocol to establish service level agreements", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (September\n  30, 2020) lmcs:6812", "doi": "10.23638/LMCS-16(3:19)2020", "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a symmetrical protocol to repeatedly negotiate a desired service\nlevel between two parties, where the service levels are taken from some totally\nordered finite domain. The agreed service level is selected from levels\ndynamically proposed by both parties and parties can only decrease the desired\nservice level during a negotiation. The correctness of the protocol is stated\nusing modal formulas and its behaviour is explained using behavioural\nreductions of the external behaviour modulo weak trace equivalence and\ndivergence-preserving branching bisimulation. Our protocol originates from an\nindustrial use case and it turned out to be remarkably tricky to design\ncorrectly.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 17:17:57 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 13:29:22 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 12:42:47 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 20:52:35 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Groote", "Jan Friso", ""], ["Willemse", "Tim A. C.", ""]]}, {"id": "2001.07754", "submitter": "Anneke Haga", "authors": "Anneke Haga, Carsten Lutz, Johannes Marti, Frank Wolter", "title": "A Journey into Ontology Approximation: From Non-Horn to Horn", "comments": "21 pages, 4 figures, paragraph with examples added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study complete approximations of an ontology formulated in a non-Horn\ndescription logic (DL) such as $\\mathcal{ALC}$ in a Horn DL such\nas~$\\mathcal{EL}$. We provide concrete approximation schemes that are\nnecessarily infinite and observe that in the $\\mathcal{ELU}$-to-$\\mathcal{EL}$\ncase finite approximations tend to exist in practice and are guaranteed to\nexist when the original ontology is acyclic. In contrast, neither of this is\nthe case for $\\mathcal{ELU}_\\bot$-to-$\\mathcal{EL}_\\bot$ and for\n$\\mathcal{ALC}$-to-$\\mathcal{EL}_\\bot$ approximations. We also define a notion\nof approximation tailored towards ontology-mediated querying, connect it to\nsubsumption-based approximations, and identify a case where finite\napproximations are guaranteed to exist.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:47:21 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 09:18:11 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 09:45:13 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 20:01:03 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Haga", "Anneke", ""], ["Lutz", "Carsten", ""], ["Marti", "Johannes", ""], ["Wolter", "Frank", ""]]}, {"id": "2001.08040", "submitter": "Thorsten Wissmann", "authors": "Mario Bravetti", "title": "Axiomatizing Maximal Progress and Discrete Time", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (January\n  21, 2021) lmcs:7116", "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Milner's complete proof system for observational congruence is crucially\nbased on the possibility to equate $\\tau$ divergent expressions to\nnon-divergent ones by means of the axiom $recX. (\\tau.X + E) = recX. \\tau. E$.\nIn the presence of a notion of priority, where, e.g., actions of type $\\delta$\nhave a lower priority than silent $\\tau$ actions, this axiom is no longer\nsound. Such a form of priority is, however, common in timed process algebra,\nwhere, due to the interpretation of $\\delta$ as a time delay, it naturally\narises from the maximal progress assumption. We here present our solution,\nbased on introducing an auxiliary operator $pri(E)$ defining a \"priority\nscope\", to the long time open problem of axiomatizing priority using standard\nobservational congruence: we provide a complete axiomatization for a basic\nprocess algebra with priority and (unguarded) recursion. We also show that,\nwhen the setting is extended by considering static operators of a discrete time\ncalculus, an axiomatization that is complete over (a characterization of)\nfinite-state terms can be developed by re-using techniques devised in the\ncontext of a cooperation with Prof. Jos Baeten.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:51:13 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 17:39:39 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 18:06:10 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 16:16:45 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Bravetti", "Mario", ""]]}, {"id": "2001.08064", "submitter": "Roman Nesterov", "authors": "Luca Bernardinello, Irina Lomazova, Roman Nesterov, Lucia Pomello", "title": "Soundness-preserving composition of synchronously and asynchronously\n  interacting workflow net components", "comments": "Preprint of the paper submitted to \"Fundamenta Informaticae\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a compositional approach to construct formal models\nof complex distributed systems with several synchronously and asynchronously\ninteracting components. A system model is obtained from a composition of\nindividual component models according to requirements on their interaction. We\nrepresent component behavior using workflow nets - a class of Petri nets. We\npropose a general approach to model and compose synchronously and\nasynchronously interacting workflow nets. Through the use of Petri net\nmorphisms and their properties, we prove that this composition of workflow nets\npreserves component correctness.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 14:24:06 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 12:06:24 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Bernardinello", "Luca", ""], ["Lomazova", "Irina", ""], ["Nesterov", "Roman", ""], ["Pomello", "Lucia", ""]]}, {"id": "2001.08133", "submitter": "Johan Bos", "authors": "Johan Bos", "title": "Drawing Prolog Search Trees: A Manual for Teachers and Students of Logic\n  Programming", "comments": "20 pages, 8 listings, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Programming in Prolog is hard for programmers that are used to procedural\ncoding. In this manual the method of drawing search trees is introduced with\nthe aim to get a better understanding of how Prolog works. After giving a first\nexample of a Prolog database, query and search tree, the art of drawing search\ntrees is systematically introduced giving guidelines for queries with\nvariables, conjunction, disjunction, and negation. Further examples are\nprovided by giving the complete search trees that are shown in Learn Prolog\nNow!\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:31:45 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Bos", "Johan", ""]]}, {"id": "2001.08190", "submitter": "Simon Kn\\\"auer", "authors": "Manuel Bodirsky, Simon Kn\\\"auer, Florian Starke", "title": "ASNP: a tame fragment of existential second-order logic", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amalgamation SNP (ASNP) is a fragment of existential second-order logic that\nstrictly contains binary connected MMSNP of Feder and Vardi and binary guarded\nmonotone SNP of Bienvenu, ten Cate, Lutz, and Wolter; it is a promising\ncandidate for an expressive subclass of NP that exhibits a complexity\ndichotomy. We show that ASNP has a complexity dichotomy if and only if the\ninfinite-domain dichotomy conjecture holds for constraint satisfaction problems\nfor first-order reducts of binary finitely bounded homogeneous structures. For\nsuch CSPs, powerful universal-algebraic hardness conditions are known that are\nconjectured to describe the border between NP-hard and polynomial-time\ntractable CSPs. The connection to CSPs also implies that every ASNP sentence\ncan be evaluated in polynomial time on classes of finite structures of bounded\ntreewidth. We show that the syntax of ASNP is decidable. The proof relies on\nthe fact that for classes of finite binary structures given by finitely many\nforbidden substructures, the amalgamation property is decidable.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:18:39 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 08:46:42 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Bodirsky", "Manuel", ""], ["Kn\u00e4uer", "Simon", ""], ["Starke", "Florian", ""]]}, {"id": "2001.08478", "submitter": "Joerg Endrullis", "authors": "J\\\"org Endrullis, Jan Willem Klop, Roy Overbeek", "title": "Star Games and Hydras", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (May 27,\n  2021) lmcs:7518", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recursive path ordering is an established and crucial tool in term\nrewriting to prove termination. We revisit its presentation by means of some\nsimple rules on trees (or corresponding terms) equipped with a 'star' as\ncontrol symbol, signifying a command to make that tree (or term) smaller in the\norder being defined. This leads to star games that are very convenient for\nproving termination of many rewriting tasks. For instance, using already the\nsimplest star game on finite unlabeled trees, we obtain a very direct proof of\ntermination of the famous Hydra battle, direct in the sense that there is not\nthe usual mention of ordinals. We also include an alternative road to setting\nup the star games, using a proof method of Buchholz, adapted by van Oostrom,\nresulting in a quantitative version of the star as control symbol. We conclude\nwith a number of questions and future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 12:55:27 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 13:55:07 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 16:17:29 GMT"}, {"version": "v4", "created": "Wed, 26 May 2021 10:35:16 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Endrullis", "J\u00f6rg", ""], ["Klop", "Jan Willem", ""], ["Overbeek", "Roy", ""]]}, {"id": "2001.08603", "submitter": "Nitesh Kumar", "authors": "Kumar Nitesh, Kuzelka Ondrej and De Raedt Luc", "title": "Learning Distributional Programs for Relational Autocompletion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational autocompletion is the problem of automatically filling out some\nmissing values in multi-relational data. We tackle this problem within the\nprobabilistic logic programming framework of Distributional Clauses (DC), which\nsupports both discrete and continuous probability distributions. Within this\nframework, we introduce DiceML { an approach to learn both the structure and\nthe parameters of DC programs from relational data (with possibly missing\ndata). To realize this, DiceML integrates statistical modeling and\ndistributional clauses with rule learning. The distinguishing features of\nDiceML are that it 1) tackles autocompletion in relational data, 2) learns\ndistributional clauses extended with statistical models, 3) deals with both\ndiscrete and continuous distributions, 4) can exploit background knowledge, and\n5) uses an expectation-maximization based algorithm to cope with missing data.\nThe empirical results show the promise of the approach, even when there is\nmissing data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:34:42 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 11:51:31 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 17:22:42 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 14:08:55 GMT"}, {"version": "v5", "created": "Mon, 5 Jul 2021 14:35:00 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nitesh", "Kumar", ""], ["Ondrej", "Kuzelka", ""], ["Luc", "De Raedt", ""]]}, {"id": "2001.08688", "submitter": "Heng Zhang", "authors": "Heng Zhang, Yan Zhang, Guifei Jiang", "title": "Model-theoretic Characterizations of Existential Rule Languages", "comments": "17 pages, 2 figures, the full version of a paper submitted to IJCAI\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existential rules, a.k.a. dependencies in databases, and Datalog+/- in\nknowledge representation and reasoning recently, are a family of important\nlogical languages widely used in computer science and artificial intelligence.\nTowards a deep understanding of these languages in model theory, we establish\nmodel-theoretic characterizations for a number of existential rule languages\nsuch as (disjunctive) embedded dependencies, tuple-generating dependencies\n(TGDs), (frontier-)guarded TGDs and linear TGDs. All these characterizations\nhold for arbitrary structures, and most of them also work on the class of\nfinite structures. As a natural application of these characterizations,\ncomplexity bounds for the rewritability of above languages are also identified.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:29:18 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Zhang", "Heng", ""], ["Zhang", "Yan", ""], ["Jiang", "Guifei", ""]]}, {"id": "2001.08944", "submitter": "Jurriaan Rot", "authors": "Rick Erkens, Jurriaan Rot, Bas Luttik", "title": "Up-to Techniques for Branching Bisimilarity", "comments": null, "journal-ref": "Extended abstract published in the proceedings of SOFSEM 2020,\n  LNCS 12011, pages 285 - 297, Springer", "doi": "10.1007/978-3-030-38919-2_24", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever since the introduction of behavioral equivalences on processes one has\nbeen searching for efficient proof techniques that accompany those\nequivalences. Both strong bisimilarity and weak bisimilarity are accompanied by\nan arsenal of up-to techniques: enhancements of their proof methods. For\nbranching bisimilarity, these results have not been established yet. We show\nthat a powerful proof technique is sound for branching bisimilarity by\ncombining the three techniques of up to union, up to expansion and up to\ncontext for Bloom's BB cool format. We then make an initial proposal for\ncasting the correctness proof of the up to context technique in an abstract\ncoalgebraic setting, covering branching but also {\\eta}, delay and weak\nbisimilarity.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 10:33:33 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Erkens", "Rick", ""], ["Rot", "Jurriaan", ""], ["Luttik", "Bas", ""]]}, {"id": "2001.09066", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe, Zhe Xu, Ufuk Topcu", "title": "Policy Synthesis for Factored MDPs with Graph Temporal Logic\n  Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the synthesis of policies for multi-agent systems to implement\nspatial-temporal tasks. We formalize the problem as a factored Markov decision\nprocess subject to so-called graph temporal logic specifications. The\ntransition function and the spatial-temporal task of each agent depend on the\nagent itself and its neighboring agents. The structure in the model and the\nspecifications enable to develop a distributed algorithm that, given a factored\nMarkov decision process and a graph temporal logic formula, decomposes the\nsynthesis problem into a set of smaller synthesis problems, one for each agent.\nWe prove that the algorithm runs in time linear in the total number of agents.\nThe size of the synthesis problem for each agent is exponential only in the\nnumber of neighboring agents, which is typically much smaller than the number\nof agents. We demonstrate the algorithm in case studies on disease control and\nurban security. The numerical examples show that the algorithm can scale to\nhundreds of agents.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 16:03:34 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Xu", "Zhe", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2001.09245", "submitter": "Elizabeth Polgreen", "authors": "Elizabeth Polgreen, Ralph Abboud, Daniel Kroening", "title": "CounterExample Guided Neural Synthesis", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis is the generation of a program from a specification.\nCorrect synthesis is difficult, and methods that provide formal guarantees\nsuffer from scalability issues. On the other hand, neural networks are able to\ngenerate programs from examples quickly but are unable to guarantee that the\nprogram they output actually meets the logical specification. In this work we\ncombine neural networks with formal reasoning: using the latter to convert a\nlogical specification into a sequence of examples that guides the neural\nnetwork towards a correct solution, and to guarantee that any solution returned\nsatisfies the formal specification. We apply our technique to synthesising loop\ninvariants and compare the performance to existing solvers that use SMT and\nexisting techniques that use neural networks. Our results show that the formal\nreasoning based guidance improves the performance of the neural network\nsubstantially, nearly doubling the number of benchmarks it can solve.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:11:53 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Polgreen", "Elizabeth", ""], ["Abboud", "Ralph", ""], ["Kroening", "Daniel", ""]]}, {"id": "2001.09365", "submitter": "Evgeny Kharlamov", "authors": "Dmitriy Zheleznyakov, Evgeny Kharlamov, Werner Nutt, Diego Calvanese", "title": "On Expansion and Contraction of DL-Lite Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KBs) are not static entities: new information constantly\nappears and some of the previous knowledge becomes obsolete. In order to\nreflect this evolution of knowledge, KBs should be expanded with the new\nknowledge and contracted from the obsolete one. This problem is well-studied\nfor propositional but much less for first-order KBs. In this work we\ninvestigate knowledge expansion and contraction for KBs expressed in DL-Lite, a\nfamily of description logics (DLs) that underlie the tractable fragment OWL 2\nQL of the Web Ontology Language OWL 2. We start with a novel knowledge\nevolution framework and natural postulates that evolution should respect, and\ncompare our postulates to the well-established AGM postulates. We then review\nwell-known model and formula-based approaches for expansion and contraction for\npropositional theories and show how they can be adapted to the case of DL-Lite.\nIn particular, we show intrinsic limitations of model-based approaches: besides\nthe fact that some of them do not respect the postulates we have established,\nthey ignore the structural properties of KBs. This leads to undesired\nproperties of evolution results: evolution of DL-Lite KBs cannot be captured in\nDL-Lite. Moreover, we show that well-known formula-based approaches are also\nnot appropriate for DL-Lite expansion and contraction: they either have a high\ncomplexity of computation, or they produce logical theories that cannot be\nexpressed in DL-Lite. Thus, we propose a novel formula-based approach that\nrespects our principles and for which evolution is expressible in DL-Lite. For\nthis approach we also propose\n  polynomial time deterministic algorithms to compute evolution of DL-Lite KBs\nwhen evolution affects only factual data.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 21:58:32 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zheleznyakov", "Dmitriy", ""], ["Kharlamov", "Evgeny", ""], ["Nutt", "Werner", ""], ["Calvanese", "Diego", ""]]}, {"id": "2001.09649", "submitter": "Stefan Ciobaca", "authors": "\\c{S}tefan Ciob\\^ac\\u{a}, Dorel Lucanu and Andrei Sebastian\n  Buruian\\u{a}", "title": "Operationally-based Program Equivalence Proofs using LCTRSs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an operationally-based deductive proof method for program\nequivalence. It is based on encoding the language semantics as logically\nconstrained term rewriting systems (LCTRSs) and the two programs as terms. The\nmain feature of our method is its flexibility. We illustrate this flexibility\nin two applications, which are novel. For the first application, we show how to\nencode low-level details such as stack size in the language semantics and how\nto prove equivalence between two programs operating at different levels of\nabstraction. For our running example, we show how our method can prove\nequivalence between a recursive function operating with an unbounded stack and\nits tail-recursive optimized version operating with a bounded stack. This type\nof equivalence checking can be used to ensure that new, undesirable behavior is\nnot introduced by a more concrete level of abstraction. For the second\napplication, we show how to formalize read-sets and write-sets of symbolic\nexpressions and statements by extending the operational semantics in a\nconservative way. This enables the relational verification of program schemas,\nwhich we exploit to prove correctness of compiler optimizations, some of which\ncannot be proven by existing tools. Our method requires an extension of\nstandard LCTRSs with axiomatized symbols. We also present a prototype\nimplementation that proves the feasibility of both applications that we\npropose.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:47:07 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ciob\u00e2c\u0103", "\u015etefan", ""], ["Lucanu", "Dorel", ""], ["Buruian\u0103", "Andrei Sebastian", ""]]}, {"id": "2001.09705", "submitter": "Bernhard Gleiss", "authors": "Bernhard Gleiss, Martin Suda", "title": "Layered Clause Selection for Theory Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explicit theory axioms are added by a saturation-based theorem prover as one\nof the techniques for supporting theory reasoning. While simple and effective,\nadding theory axioms can also pollute the search space with many irrelevant\nconsequences. As a result, the prover often gets lost in parts of the search\nspace where the chance to find a proof is low. In this paper we describe a new\nstrategy for controlling the amount of reasoning with explicit theory axioms.\nThe strategy refines a recently proposed two-layer-queue clause selection and\ncombines it with a heuristical measure of the amount of theory reasoning in the\nderivation of a clause. We implemented the new strategy in the automatic\ntheorem prover Vampire and present an evaluation showing that our work\ndramatically improves the state-of-the-art clause-selection strategy in the\npresence of theory axioms.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:44:24 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 08:29:04 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 11:05:53 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Gleiss", "Bernhard", ""], ["Suda", "Martin", ""]]}, {"id": "2001.09715", "submitter": "Pedro S\\'anchez Terraf", "authors": "Emmanuel Gunther (1), Miguel Pagano (1), Pedro S\\'anchez Terraf (1,2)\n  ((1) Universidad Nacional de C\\'ordoba. Facultad de Matem\\'atica,\n  Astronom\\'ia, F\\'isica y Computaci\\'on, (2) Centro de Investigaci\\'on y\n  Estudios de Matem\\'atica (CIEM-FaMAF), Conicet. C\\'ordoba. Argentina)", "title": "Formalization of Forcing in Isabelle/ZF", "comments": "15 pages. Accepted at the 10th International Joint Conference on\n  Automated Reasoning (IJCAR 2020). v2: Added expanded section on related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the theory of forcing in the set theory framework of\nIsabelle/ZF. Under the assumption of the existence of a countable transitive\nmodel of ZFC, we construct a proper generic extension and show that the latter\nalso satisfies ZFC. In doing so, we remodularized Paulson's ZF-Constructibility\nlibrary.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 12:28:28 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 16:42:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gunther", "Emmanuel", ""], ["Pagano", "Miguel", ""], ["Terraf", "Pedro S\u00e1nchez", ""]]}, {"id": "2001.09787", "submitter": "Grygoriy Zholtkevych", "authors": "Grygoriy Zholtkevych and Maksym Labzhaniia", "title": "Understanding Safety Constraints Coalgebraically", "comments": null, "journal-ref": "CEUR WS Proceedings, 2604 (2020) 1-19", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety constraints are crucial to the development of mission-critical\nsystems. The practice of developing software for systems of this type requires\nreliable methods for identifying and analysing project artefacts. This paper\nproposes a coalgebraic approach to understanding behavioural constraints for\nsystems of a kind. The advantage of the proposed approach is that it gives a\nframework for providing abstract semantic models of the domain-specific\nlanguages designed for specifying behavioural constraints.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 13:56:37 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zholtkevych", "Grygoriy", ""], ["Labzhaniia", "Maksym", ""]]}, {"id": "2001.09966", "submitter": "Mikhail Raskin", "authors": "Mikhail Raskin, Chana Weil-Kennedy, Javier Esparza", "title": "Flatness and Complexity of Immediate Observation Petri Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous paper we introduced immediate observation (IO) Petri nets, a\nclass of interest in the study of population protocols and enzymatic chemical\nnetworks. In the first part of this paper we show that IO nets are globally\nflat, and so their safety properties can be checked by efficient symbolic model\nchecking tools using acceleration techniques, like FAST. In the second part we\nstudy Branching IO nets (BIO nets), whose transitions can create tokens. BIO\nnets extend both IO nets and communication-free nets, also called BPP nets, a\nwidely studied class. We show that, while BIO nets are no longer globally flat,\nand their sets of reachable markings may be non-semilinear, they are still\nlocally flat. As a consequence, the coverability and reachability problem for\nBIO nets, and even a certain set-parameterized version of them, are in PSPACE.\nThis makes BIO nets the first natural net class with non-semilinear\nreachability relation for which the reachability problem is provably simpler\nthan for general Petri nets.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:41:16 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:43:32 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 15:35:27 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Raskin", "Mikhail", ""], ["Weil-Kennedy", "Chana", ""], ["Esparza", "Javier", ""]]}, {"id": "2001.10213", "submitter": "Bernhard Gleiss", "authors": "Bernhard Gleiss, Laura Kovacs, Jakob Rath", "title": "Subsumption Demodulation in First-Order Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications of first-order theorem proving to software\nanalysis, we introduce a new inference rule, called subsumption demodulation,\nto improve support for reasoning with conditional equalities in\nsuperposition-based theorem proving. We show that subsumption demodulation is a\nsimplification rule that does not require radical changes to the underlying\nsuperposition calculus. We implemented subsumption demodulation in the theorem\nprover Vampire, by extending Vampire with a new clause index and adapting its\nmulti-literal matching component. Our experiments, using the TPTP and SMT-LIB\nrepositories, show that subsumption demodulation in Vampire can solve many new\nproblems that could so far not be solved by state-of-the-art reasoners.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 08:45:18 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Gleiss", "Bernhard", ""], ["Kovacs", "Laura", ""], ["Rath", "Jakob", ""]]}, {"id": "2001.10630", "submitter": "Ethan Cecchetti", "authors": "Andrew K. Hirsch, Pedro H. Azevedo de Amorim, Ethan Cecchetti, Ross\n  Tate, Owen Arden", "title": "First-Order Logic for Flow-Limited Authorization", "comments": "Coq code can be found at https://github.com/FLAFOL/flafol-coq", "journal-ref": null, "doi": "10.1109/CSF49147.2020.00017", "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Flow-Limited Authorization First-Order Logic (FLAFOL), a logic\nfor reasoning about authorization decisions in the presence of information-flow\npolicies. We formalize the FLAFOL proof system, characterize its\nproof-theoretic properties, and develop its security guarantees. In particular,\nFLAFOL is the first logic to provide a non-interference guarantee while\nsupporting all connectives of first-order logic. Furthermore, this guarantee is\nthe first to combine the notions of non-interference from both authorization\nlogic and information-flow systems. All theorems in this paper are proven in\nCoq.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 23:01:05 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Hirsch", "Andrew K.", ""], ["de Amorim", "Pedro H. Azevedo", ""], ["Cecchetti", "Ethan", ""], ["Tate", "Ross", ""], ["Arden", "Owen", ""]]}, {"id": "2001.10723", "submitter": "Ilya Sergey", "authors": "Andreea Costea, Amy Zhu, Nadia Polikarpova, Ilya Sergey", "title": "Concise Read-Only Specifications for Better Synthesis of Programs with\n  Pointers -- Extended Version", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In program synthesis there is a well-known trade-off between concise and\nstrong specifications: if a specification is too verbose, it might be harder to\nwrite than the program; if it is too weak, the synthesised program might not\nmatch the user's intent. In this work we explore the use of annotations for\nrestricting memory access permissions in program synthesis, and show that they\ncan make specifications much stronger while remaining surprisingly concise.\nSpecifically, we enhance Synthetic Separation Logic (SSL), a framework for\nsynthesis of heap-manipulating programs, with the logical mechanism of\nread-only borrows. We observe that this minimalistic and conservative SSL\nextension benefits the synthesis in several ways, making it more (a) expressive\n(stronger correctness guarantees are achieved with a modest annotation\noverhead), (b) effective (it produces more concise and easier-to-read\nprograms), (c) efficient (faster synthesis), and (d) robust (synthesis\nefficiency is less affected by the choice of the search heuristic). We explain\nthe intuition and provide formal treatment for read-only borrows. We\nsubstantiate the claims (a)--(d) by describing our quantitative evaluation of\nthe borrowing-aware synthesis implementation on a series of standard benchmark\nspecifications for various heap-manipulating programs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 08:35:41 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Costea", "Andreea", ""], ["Zhu", "Amy", ""], ["Polikarpova", "Nadia", ""], ["Sergey", "Ilya", ""]]}, {"id": "2001.10799", "submitter": "Rustam Tagiew", "authors": "Rustam Tagiew", "title": "Business Negotiation Definition Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The target of this paper is to present an industry-ready prototype software\nfor general game playing. This software can also be used as the central element\nfor experimental economics research, interfacing of game-theoretic libraries,\nAI-driven software testing, algorithmic trade, human behavior mining and\nsimulation of (strategic) interactions. The software is based on a\ndomain-specific language for electronic business to business negotiations --\nSIDL3.0. The paper also contains many examples to prove the power of this\nlanguage.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 11:07:00 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Tagiew", "Rustam", ""]]}, {"id": "2001.10834", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Smart Induction for Isabelle/HOL (System Description)", "comments": "Under submission at IJCAR2020 as a System Description", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof assistants offer tactics to facilitate inductive proofs. However, it\nstill requires human ingenuity to decide what arguments to pass to those\ninduction tactics. To automate this process, we present smart_induct for\nIsabelle/HOL. Given an inductive problem in any problem domain, smart_induct\nlists promising arguments for the induct tactic without relying on a search.\nOur evaluation demonstrated smart_induct produces valuable recommendations\nacross problem domains.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:29:34 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2001.11142", "submitter": "Toby Murray", "authors": "Daniel Schoepe, Toby Murray and Andrei Sabelfeld", "title": "VERONICA: Expressive and Precise Concurrent Information Flow Security\n  (Extended Version with Technical Appendices)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for proving that concurrent software does not leak its secrets has\nremained an active topic of research for at least the past four decades.\nDespite an impressive array of work, the present situation remains highly\nunsatisfactory. With contemporary compositional proof methods one is forced to\nchoose between expressiveness (the ability to reason about a wide variety of\nsecurity policies), on the one hand, and precision (the ability to reason about\ncomplex thread interactions and program behaviours), on the other. Achieving\nboth is essential and, we argue, requires a new style of compositional\nreasoning.\n  We present VERONICA, the first program logic for proving concurrent programs\ninformation flow secure that supports compositional, high-precision reasoning\nabout a wide range of security policies and program behaviours (e.g. expressive\nde-classification, value-dependent classification, secret-dependent branching).\nJust as importantly, VERONICA embodies a new approach for engineering such\nlogics that can be re-used elsewhere, called decoupled functional correctness\n(DFC). DFC leads to a simple and clean logic, even while achieving this\nunprecedented combination of features. We demonstrate the virtues and\nversatility of VERONICA by verifying a range of example programs, beyond the\nreach of prior methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 00:58:11 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Schoepe", "Daniel", ""], ["Murray", "Toby", ""], ["Sabelfeld", "Andrei", ""]]}, {"id": "2001.11186", "submitter": "Daniel Huang", "authors": "Daniel Huang", "title": "Elementary Logic in Linear Space", "comments": "Preprint, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order logic is typically presented as the study of deduction in a\nsetting with elementary quantification. In this paper, we take another vantage\npoint and conceptualize first-order logic as a linear space that encodes\n\"plausibility\". Whereas a deductive perspective emphasizes how (i.e., process),\na space perspective emphasizes where (i.e., location). We explore several\nconsequences that a shift in perspective to \"signals in space\" has for\nfirst-order logic, including (1) a notion of proof based on orthogonal\ndecomposition, (2) a method for assigning probabilities to sentences that\nreflects logical uncertainty, and (3) a \"models as boundary\" principle that\nrelates the models of a theory to its \"size\".\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 06:03:24 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Huang", "Daniel", ""]]}, {"id": "2001.11298", "submitter": "Matthew Moore", "authors": "Matthew Moore, Taylor Walenczyk", "title": "The Hidden Subgroup Problem for Universal Algebras", "comments": null, "journal-ref": null, "doi": "10.1145/3373718.3394764", "report-no": null, "categories": "cs.LO math.CO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hidden Subgroup Problem (HSP) is a computational problem which includes\nas special cases integer factorization, the discrete logarithm problem, graph\nisomorphism, and the shortest vector problem. The celebrated polynomial-time\nquantum algorithms for factorization and the discrete logarithm are restricted\nversions of a generic polynomial-time quantum solution to the HSP for abelian\ngroups, but despite focused research no full solution has yet been found. We\npropose a generalization of the HSP to include arbitrary algebraic structures\nand analyze this new problem on powers of 2-element algebras. We prove a\ncomplete classification of every such power as quantum tractable (i.e.\npolynomial-time), classically tractable, quantum intractable, and classically\nintractable. In particular, we identify a class of algebras for which the\ngeneralized HSP exhibits super-polynomial speedup on a quantum computer\ncompared to a classical one.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:09:35 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 20:14:21 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Moore", "Matthew", ""], ["Walenczyk", "Taylor", ""]]}, {"id": "2001.11825", "submitter": "Alexandros Arvanitakis", "authors": "A.D. Arvanitakis", "title": "Recursion and evolution: Part I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG math.LO q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A self-editing algorithm is one that edits its program. The present paper\nstudies evolution of self-editing algorithms that undergo some form of natural\nor artificial selection. We show that such an algorithm may be simply\nprogrammed, by a procedure we call diagonalization, so as to use selection as\nan information, to adjust accordingly its genetic behavior. We provide a lot of\nexamples regarding this principle, including ones that diagonalization is used\nto evolve its own mechanism. (This last one being possible due to self-editing\nproperty and to the general nature of this procedure).\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 11:04:52 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 07:21:56 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Arvanitakis", "A. D.", ""]]}, {"id": "2001.11875", "submitter": "Silvano Dal Zilio", "authors": "Vincent Mussot, Silvano Dal Zilio (LAAS-VERTICS), Loic Correnson\n  (LIST), Serge Rainjonneau, Yves Bardout, Gr\\'egoire Scano", "title": "Formal Approach for the Verification of Onboard Autonomous Functions in\n  Observation Satellites", "comments": null, "journal-ref": "10th European Congress on Embedded Real Time Software and Systems\n  (ERTS 2020), Jan 2020, Toulouse, France", "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for modelling the functional behaviour of an Earth\nobservation satellite. We leverage this approach in order to develop a safety\ncritical software, a \"telecommand verifier\", that is in charge of checking\nonboard whether a sequence of instructions is safe for execution. This new\nservice is needed in order to add more autonomy to satellites. To do so, we\npropose a new Domain Specific Modelling Language and the toolchain required for\nintegration into an embedded software. This framework is based on the\ncomposition of deterministic finite state machines with safety conditions ,\ntimeouts, and transitions that accept durations as a parameter. It is able to\ngenerate code in the synchronous programming language Lustre from a high-level\nspecification of the satellite. This gives a formal way to derive an\nevent-based algorithm simulating the execution of telecommand sequence and,\nthereupon, a provably correct onboard verifier.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 14:45:11 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mussot", "Vincent", "", "LAAS-VERTICS"], ["Zilio", "Silvano Dal", "", "LAAS-VERTICS"], ["Correnson", "Loic", "", "LIST"], ["Rainjonneau", "Serge", ""], ["Bardout", "Yves", ""], ["Scano", "Gr\u00e9goire", ""]]}, {"id": "2001.11895", "submitter": "Simon Doherty", "authors": "James Cranch and Simon Doherty and Georg Struth", "title": "Relational Semigroups and Object-Free Categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note relates axioms for partial semigroups and monoids with those for\nsmall object-free categories, either with multiple monoidal units or with\nsource and target maps. We discuss the adjunction of a zero element to both\nkinds of category and provide examples that separate the algebras considered.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:18:35 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Cranch", "James", ""], ["Doherty", "Simon", ""], ["Struth", "Georg", ""]]}, {"id": "2001.11906", "submitter": "Thomas Seiller", "authors": "Thomas Seiller (CNRS, LIPN)", "title": "Zeta Functions and the (Linear) Logic of Markov Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.DS math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a series of papers, the author introduced models of linear logic known as\n\"Interaction Graphs\". These models generalise Girard's various geometry of\ninteraction constructions, providing a unifying framework for those. In this\nwork, we exhibit how these models can be understood mathematically through a\ncocycle property satisfied by zeta functions of dynamical systems. Focussing on\nprobabilistic models, we then explain how the notion of graphings used in the\nmodels captures a natural class of Markov processes. We further extend previous\nconstructions to provide a model of second-order linear logic as a type system\nover the set of all (discrete-time) sub-Markov processes.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:32:58 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 09:11:29 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 08:23:29 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Seiller", "Thomas", "", "CNRS, LIPN"]]}, {"id": "2001.11973", "submitter": "Curtis Bright", "authors": "Curtis Bright and Kevin K. H. Cheung and Brett Stevens and Ilias\n  Kotsireas and Vijay Ganesh", "title": "Unsatisfiability Proofs for Weight 16 Codewords in Lam's Problem", "comments": "To appear in Proceedings of the 29th International Joint Conference\n  on Artificial Intelligence (IJCAI 2020)", "journal-ref": null, "doi": "10.24963/ijcai.2020/203", "report-no": null, "categories": "cs.DM cs.LO cs.SC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the 1970s and 1980s, searches performed by L. Carter, C. Lam, L. Thiel,\nand S. Swiercz showed that projective planes of order ten with weight 16\ncodewords do not exist. These searches required highly specialized and\noptimized computer programs and required about 2,000 hours of computing time on\nmainframe and supermini computers. In 2011, these searches were verified by D.\nRoy using an optimized C program and 16,000 hours on a cluster of desktop\nmachines. We performed a verification of these searches by reducing the problem\nto the Boolean satisfiability problem (SAT). Our verification uses the\ncube-and-conquer SAT solving paradigm, symmetry breaking techniques using the\ncomputer algebra system Maple, and a result of Carter that there are ten\nnonisomorphic cases to check. Our searches completed in about 30 hours on a\ndesktop machine and produced nonexistence proofs of about 1 terabyte in the\nDRAT (deletion resolution asymmetric tautology) format.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 17:43:22 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 14:55:36 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bright", "Curtis", ""], ["Cheung", "Kevin K. H.", ""], ["Stevens", "Brett", ""], ["Kotsireas", "Ilias", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2001.11974", "submitter": "Curtis Bright", "authors": "Curtis Bright, Kevin K. H. Cheung, Brett Stevens, Ilias Kotsireas, and\n  Vijay Ganesh", "title": "Nonexistence Certificates for Ovals in a Projective Plane of Order Ten", "comments": "Appears in the Proceedings of the 31st International Workshop on\n  Combinatorial Algorithms (IWOCA 2020)", "journal-ref": "Lecture Notes in Computer Science 12126 (2020) 97-111", "doi": "10.1007/978-3-030-48966-3_8", "report-no": null, "categories": "cs.DM cs.LO cs.SC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1983, a computer search was performed for ovals in a projective plane of\norder ten. The search was exhaustive and negative, implying that such ovals do\nnot exist. However, no nonexistence certificates were produced by this search,\nand to the best of our knowledge the search has never been independently\nverified. In this paper, we rerun the search for ovals in a projective plane of\norder ten and produce a collection of nonexistence certificates that, when\ntaken together, imply that such ovals do not exist. Our search program uses the\ncube-and-conquer paradigm from the field of satisfiability (SAT) checking,\ncoupled with a programmatic SAT solver and the nauty symbolic computation\nlibrary for removing symmetries from the search.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 17:43:24 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 23:14:59 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 21:12:16 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Bright", "Curtis", ""], ["Cheung", "Kevin K. H.", ""], ["Stevens", "Brett", ""], ["Kotsireas", "Ilias", ""], ["Ganesh", "Vijay", ""]]}]