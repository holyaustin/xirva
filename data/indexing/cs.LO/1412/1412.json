[{"id": "1412.0320", "submitter": "Yuping Shen", "authors": "Yuping Shen and Xishun Zhao", "title": "Canonical Logic Programs are Succinctly Incomparable with Propositional\n  Formulas", "comments": "This is an extended version of a conference paper with the same name\n  in KR2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\emph{Canonical (logic) programs} (CP) refer to normal logic programs\naugmented with connective $not\\ not$. In this paper we address the question of\nwhether CP are \\emph{succinctly incomparable} with \\emph{propositional\nformulas} (PF). Our main result shows that the PARITY problem, which can be\npolynomially represented in PF but \\emph{only} has exponential representations\nin CP. In other words, PARITY \\emph{separates} PF from CP. Simply speaking,\nthis means that exponential size blowup is generally inevitable when\ntranslating a set of formulas in PF into an equivalent program in CP (without\nintroducing new variables). Furthermore, since it has been shown by Lifschitz\nand Razborov that there is also a problem that separates CP from PF (assuming\n$\\mathsf{P}\\nsubseteq \\mathsf{NC^1/poly}$), it follows that CP and PF are\nindeed succinctly incomparable. From the view of the theory of computation, the\nabove result may also be considered as the separation of two \\emph{models of\ncomputation}, i.e., we identify a language in $\\mathsf{NC^1/poly}$ which is not\nin the set of languages computable by polynomial size CP programs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 01:10:30 GMT"}, {"version": "v2", "created": "Sat, 24 Jan 2015 11:47:04 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Shen", "Yuping", ""], ["Zhao", "Xishun", ""]]}, {"id": "1412.0537", "submitter": "Pierre-Alain Reynier", "authors": "Emmanuel Filiot and Pierre-Alain Reynier", "title": "On Streaming String Transducers and HDT0L Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copyless streaming string transducers (copyless SST) have been introduced by\nR. Alur and P. Cerny in 2010 as a one-way deterministic automata model to\ndefine transformations of finite strings. Copyless SST extend deterministic\nfinite state automata with a set of registers in which to store intermediate\noutput strings, and those registers can be combined and updated all along the\nrun, in a linear manner, i.e., no register content can be copied on\ntransitions. It is known that copyless SST capture exactly the class of\nMSO-definable string-to-string transformations, as defined by B. Courcelle, and\nare equi-expressive to deterministic two-way transducers. They enjoy good\nalgorithmic properties. Most notably, they have decidable equivalence problem\n(in PSpace). In this paper, we show that they still have decidable equivalence\nproblem even without the copyless restriction. The proof reduces to the HDT0L\nsequence equivalence problem, which is known to be decidable. We also show that\nthis latter problem is as difficult as the SST equivalence problem, modulo\nlinear time reduction.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 16:42:00 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Filiot", "Emmanuel", ""], ["Reynier", "Pierre-Alain", ""]]}, {"id": "1412.0542", "submitter": "Marco B. Caminati", "authors": "Marco B. Caminati, Manfred Kerber, Colin Rowat", "title": "Budget Imbalance Criteria for Auctions: A Formalized Theorem", "comments": "6th Podlasie Conference on Mathematics 2014, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF cs.GT cs.LO q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an original theorem in auction theory: it specifies general\nconditions under which the sum of the payments of all bidders is necessarily\nnot identically zero, and more generally not constant. Moreover, it explicitly\nsupplies a construction for a finite minimal set of possible bids on which such\na sum is not constant. In particular, this theorem applies to the important\ncase of a second-price Vickrey auction, where it reduces to a basic result of\nwhich a novel proof is given. To enhance the confidence in this new theorem, it\nhas been formalized in Isabelle/HOL: the main results and definitions of the\nformal proof are re- produced here in common mathematical language, and are\naccompanied by an informal discussion about the underlying ideas.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 15:01:01 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Caminati", "Marco B.", ""], ["Kerber", "Manfred", ""], ["Rowat", "Colin", ""]]}, {"id": "1412.0773", "submitter": "Heng Zhang", "authors": "Heng Zhang, Yan Zhang", "title": "Expressiveness of Logic Programs under General Stable Model Semantics", "comments": "Technical report, an extended version of arXiv:1304.0620", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stable model semantics had been recently generalized to non-Herbrand\nstructures by several works, which provides a unified framework and solid\nlogical foundations for answer set programming. This paper focuses on the\nexpressiveness of normal and disjunctive programs under the general stable\nmodel semantics. A translation from disjunctive programs to normal programs is\nproposed for infinite structures. Over finite structures, some disjunctive\nprograms are proved to be intranslatable to normal programs if the arities of\nauxiliary predicates and functions are bounded in a certain way. The\nequivalence of the expressiveness of normal programs and disjunctive programs\nover arbitrary structures is also shown to coincide with that over finite\nstructures, and coincide with whether NP is closed under complement. Moreover,\nto capture the exact expressiveness, some intertranslatability results between\nlogic program classes and fragments of second-order logic are obtained.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 03:29:20 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["Zhang", "Heng", ""], ["Zhang", "Yan", ""]]}, {"id": "1412.0825", "submitter": "EPTCS", "authors": "Nikolaj Bj{\\o}rner (Microsoft Research), Fabio Fioravanti (University\n  of Chieti-Pescara), Andrey Rybalchenko (Microsoft Research), Valerio Senni\n  (ALES s.r.l.)", "title": "Proceedings First Workshop on Horn Clauses for Verification and\n  Synthesis", "comments": null, "journal-ref": "EPTCS 169, 2014", "doi": "10.4204/EPTCS.169", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of HCVS 2014, the First Workshop on Horn\nClauses for Verification and Synthesis which was held on July 17, 2014 in\nVienna, Austria as a satellite event of the Federated Logic Conference (FLoC)\nand part of the Vienna Summer of Logic (VSL 2014).\n  HCVS 2014 was affiliated to the 26th International Conference on Computer\nAided Verification (CAV 2014) and to the 30th International Conference on Logic\nProgramming (ICLP 2014).\n  Most Program Verification and Synthesis problems of interest can be modeled\ndirectly using Horn clauses and many recent advances in the Constraint/Logic\nProgramming and Program Verification communities have centered around\nefficiently solving problems presented as Horn clauses.\n  Since Horn clauses for verification and synthesis have been advocated by\nthese communities in different times and from different perspectives, the HCVS\nworkshop was organized to stimulate interaction and a fruitful exchange and\nintegration of experiences.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 09:30:55 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["Bj\u00f8rner", "Nikolaj", "", "Microsoft Research"], ["Fioravanti", "Fabio", "", "University\n  of Chieti-Pescara"], ["Rybalchenko", "Andrey", "", "Microsoft Research"], ["Senni", "Valerio", "", "ALES s.r.l."]]}, {"id": "1412.0885", "submitter": "Chan Ngo", "authors": "Van Chan Ngo (ESPRESSO), Axel Legay (ESTASYS), Jean Quilbeuf (ESTASYS)", "title": "Dynamic Verification of SystemC with Statistical Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many embedded and real-time systems have a inherent probabilistic behaviour\n(sensors data, unreliable hardware,...). In that context, it is crucial to\nevaluate system properties such as \"the probability that a particular hardware\nfails\". Such properties can be evaluated by using probabilistic model checking.\nHowever, this technique fails on models representing realistic embedded and\nreal-time systems because of the state space explosion. To overcome this\nproblem, we propose a verification framework based on Statistical Model\nChecking. Our framework is able to evaluate probabilistic and temporal\nproperties on large systems modelled in SystemC, a standard system-level\nmodelling language. It is fully implemented as an extension of the Plasma-lab\nstatistical model checker. We illustrate our approach on a multi-lift system\ncase study.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 12:23:37 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2015 12:58:20 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Ngo", "Van Chan", "", "ESPRESSO"], ["Legay", "Axel", "", "ESTASYS"], ["Quilbeuf", "Jean", "", "ESTASYS"]]}, {"id": "1412.1042", "submitter": "Marco Peressotti", "authors": "Marino Miculan and Marco Peressotti", "title": "A CSP implementation of the bigraph embedding problem", "comments": "arXiv admin note: text overlap with arXiv:1503.02434", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial problem for many results and tools about bigraphs and bigraphical\nreactive systems is bigraph embedding. An embedding is more informative than a\nbigraph matching, since it keeps track of the correspondence between the\nvarious components of the redex (guest) within the agent (host). In this paper,\nwe present an algorithm for computing embeddings based on a reduction to a\nconstraint satisfaction problem. This algorithm, that we prove to be sound and\ncomplete, has been successfully implemented in LibBig, a library for\nmanipulating bigraphical reactive systems. This library can be used for\nimplementing a wide range of tools, and it can be adapted to various extensions\nof bigraphs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 08:52:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 10:16:25 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Miculan", "Marino", ""], ["Peressotti", "Marco", ""]]}, {"id": "1412.1151", "submitter": "EPTCS", "authors": "Emanuele De Angelis, Fabio Fioravanti, Jorge A. Navas, Maurizio\n  Proietti", "title": "Verification of Programs by Combining Iterated Specialization with\n  Interpolation", "comments": "In Proceedings HCVS 2014, arXiv:1412.0825", "journal-ref": "EPTCS 169, 2014, pp. 3-18", "doi": "10.4204/EPTCS.169.3", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a verification technique for program safety that combines Iterated\nSpecialization and Interpolating Horn Clause Solving. Our new method composes\ntogether these two techniques in a modular way by exploiting the common Horn\nClause representation of the verification problem. The Iterated Specialization\nverifier transforms an initial set of verification conditions by using\nunfold/fold equivalence preserving transformation rules. During transformation,\nprogram invariants are discovered by applying widening operators. Then the\noutput set of specialized verification conditions is analyzed by an\nInterpolating Horn Clause solver, hence adding the effect of interpolation to\nthe effect of widening. The specialization and interpolation phases can be\niterated, and also combined with other transformations that change the\ndirection of propagation of the constraints (forward from the program\npreconditions or backward from the error conditions). We have implemented our\nverification technique by integrating the VeriMAP verifier with the FTCLP Horn\nClause solver, based on Iterated Specialization and Interpolation,\nrespectively. Our experimental results show that the integrated verifier\nimproves the precision of each of the individual components run separately.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 01:39:18 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["De Angelis", "Emanuele", ""], ["Fioravanti", "Fabio", ""], ["Navas", "Jorge A.", ""], ["Proietti", "Maurizio", ""]]}, {"id": "1412.1152", "submitter": "EPTCS", "authors": "Pierre-Loic Garoche (Onera, The French Aerospace Lab), Arie Gurfinkel\n  (SEI / CMU), Temesghen Kahsai (NASA Ames / CMU)", "title": "Synthesizing Modular Invariants for Synchronous Code", "comments": "In Proceedings HCVS 2014, arXiv:1412.0825", "journal-ref": "EPTCS 169, 2014, pp. 19-30", "doi": "10.4204/EPTCS.169.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore different techniques to synthesize modular\ninvariants for synchronous code encoded as Horn clauses. Modular invariants are\na set of formulas that characterizes the validity of predicates. They are very\nuseful for different aspects of analysis, synthesis, testing and program\ntransformation. We describe two techniques to generate modular invariants for\ncode written in the synchronous dataflow language Lustre. The first technique\ndirectly encodes the synchronous code in a modular fashion. While in the second\ntechnique, we synthesize modular invariants starting from a monolithic\ninvariant. Both techniques, take advantage of analysis techniques based on\nproperty-directed reachability. We also describe a technique to minimize the\nsynthesized invariants.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 01:39:27 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Garoche", "Pierre-Loic", "", "Onera, The French Aerospace Lab"], ["Gurfinkel", "Arie", "", "SEI / CMU"], ["Kahsai", "Temesghen", "", "NASA Ames / CMU"]]}, {"id": "1412.1153", "submitter": "EPTCS", "authors": "Hossein Hojjat (Cornell University, USA), Philipp R\\\"ummer (Uppsala\n  University, Sweden), Pavle Subotic (Uppsala University, Sweden), Wang Yi\n  (Uppsala University, Sweden)", "title": "Horn Clauses for Communicating Timed Systems", "comments": "In Proceedings HCVS 2014, arXiv:1412.0825", "journal-ref": "EPTCS 169, 2014, pp. 39-52", "doi": "10.4204/EPTCS.169.6", "report-no": null, "categories": "cs.LO cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Languages based on the theory of timed automata are a well established\napproach for modelling and analysing real-time systems, with many applications\nboth in industrial and academic context. Model checking for timed automata has\nbeen studied extensively during the last two decades; however, even now\nindustrial-grade model checkers are available only for few timed automata\ndialects (in particular Uppaal timed automata), exhibit limited scalability for\nsystems with large discrete state space, or cannot handle parametrised systems.\nWe explore the use of Horn constraints and off-the-shelf model checkers for\nanalysis of networks of timed automata. The resulting analysis method is fully\nsymbolic and applicable to systems with large or infinite discrete state space,\nand can be extended to include various language features, for instance\nUppaal-style communication/broadcast channels and BIP-style interactions, and\nsystems with infinite parallelism. Experiments demonstrate the feasibility of\nthe method.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 01:39:51 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Hojjat", "Hossein", "", "Cornell University, USA"], ["R\u00fcmmer", "Philipp", "", "Uppsala\n  University, Sweden"], ["Subotic", "Pavle", "", "Uppsala University, Sweden"], ["Yi", "Wang", "", "Uppsala University, Sweden"]]}, {"id": "1412.1154", "submitter": "EPTCS", "authors": "Bishoksan Kafle, John P. Gallagher", "title": "Convex polyhedral abstractions, specialisation and property-based\n  predicate splitting in Horn clause verification", "comments": "In Proceedings HCVS 2014, arXiv:1412.0825", "journal-ref": "EPTCS 169, 2014, pp. 53-67", "doi": "10.4204/EPTCS.169.7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to constrained Horn clause (CHC) verification\ncombining three techniques: abstract interpretation over a domain of convex\npolyhedra, specialisation of the constraints in CHCs using abstract\ninterpretation of query-answer transformed clauses, and refinement by splitting\npredicates. The purpose of the work is to investigate how analysis and\ntransformation tools developed for constraint logic programs (CLP) can be\napplied to the Horn clause verification problem. Abstract interpretation over\nconvex polyhedra is capable of deriving sophisticated invariants and when used\nin conjunction with specialisation for propagating constraints it can\nfrequently solve challenging verification problems. This is a contribution in\nitself, but refinement is needed when it fails, and the question of how to\nrefine convex polyhedral analyses has not been studied much. We present a\nrefinement technique based on interpolants derived from a counterexample trace;\nthese are used to drive a property-based specialisation that splits predicates,\nleading in turn to more precise convex polyhedral analyses. The process of\nspecialisation, analysis and splitting can be repeated, in a manner similar to\nthe CEGAR and iterative specialisation approaches.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 01:40:03 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Kafle", "Bishoksan", ""], ["Gallagher", "John P.", ""]]}, {"id": "1412.1156", "submitter": "EPTCS", "authors": "Alan Perotti (University of Turin, Italy), Guido Boella (University of\n  Turin, Italy), Artur d'Avila Garcez (City University London, UK)", "title": "Runtime Verification Through Forward Chaining", "comments": "In Proceedings HCVS 2014, arXiv:1412.0825", "journal-ref": "EPTCS 169, 2014, pp. 68-81", "doi": "10.4204/EPTCS.169.8", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel rule-based approach for Runtime Verification\nof FLTL properties over finite but expanding traces. Our system exploits Horn\nclauses in implication form and relies on a forward chaining-based monitoring\nalgorithm. This approach avoids the branching structure and exponential\ncomplexity typical of tableaux-based formulations, creating monitors with a\nsingle state and a fixed number of rules. This allows for a fast and scalable\ntool for Runtime Verification: we present the technical details together with a\nworking implementation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 01:40:16 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Perotti", "Alan", "", "University of Turin, Italy"], ["Boella", "Guido", "", "University of\n  Turin, Italy"], ["Garcez", "Artur d'Avila", "", "City University London, UK"]]}, {"id": "1412.1505", "submitter": "Guy Van den Broeck", "authors": "Paul Beame, Guy Van den Broeck, Eric Gribkoff, Dan Suciu", "title": "Symmetric Weighted First-Order Model Counting", "comments": "To appear at PODS'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FO Model Counting problem (FOMC) is the following: given a sentence\n$\\Phi$ in FO and a number $n$, compute the number of models of $\\Phi$ over a\ndomain of size $n$; the Weighted variant (WFOMC) generalizes the problem by\nassociating a weight to each tuple and defining the weight of a model to be the\nproduct of weights of its tuples. In this paper we study the complexity of the\nsymmetric WFOMC, where all tuples of a given relation have the same weight. Our\nmotivation comes from an important application, inference in Knowledge Bases\nwith soft constraints, like Markov Logic Networks, but the problem is also of\nindependent theoretical interest. We study both the data complexity, and the\ncombined complexity of FOMC and WFOMC. For the data complexity we prove the\nexistence of an FO$^{3}$ formula for which FOMC is #P$_1$-complete, and the\nexistence of a Conjunctive Query for which WFOMC is #P$_1$-complete. We also\nprove that all $\\gamma$-acyclic queries have polynomial time data complexity.\nFor the combined complexity, we prove that, for every fragment FO$^{k}$, $k\\geq\n2$, the combined complexity of FOMC (or WFOMC) is #P-complete.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 22:03:52 GMT"}, {"version": "v2", "created": "Mon, 22 Dec 2014 13:29:54 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2015 14:58:14 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Beame", "Paul", ""], ["Broeck", "Guy Van den", ""], ["Gribkoff", "Eric", ""], ["Suciu", "Dan", ""]]}, {"id": "1412.1862", "submitter": "Bryan Renne", "authors": "Paul Egr\\'e and Paul Marty and Bryan Renne", "title": "Knowledge, Justification, and Reason-Based Belief", "comments": "v3 edits acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is knowledge definable as justified true belief (\"JTB\")? We argue that one\ncan legitimately answer positively or negatively, depending on how the notion\nof justification is understood. To facilitate our argument, we introduce a\nsimple propositional logic of reason-based belief. We show that this logic is\nsufficiently flexible to accommodate various useful features, including\nquantification over reasons. We use our framework to contrast two notions of\nJTB: one internalist, the other externalist. We argue that Gettier cases\nessentially challenge the internalist notion but not the externalist one. In\nparticular, we may equate knowledge and JTB if the latter is grounded in what\nwe call \"adequate\" reasons.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 23:21:12 GMT"}, {"version": "v2", "created": "Tue, 20 Jan 2015 05:05:05 GMT"}, {"version": "v3", "created": "Wed, 20 May 2015 13:54:36 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Egr\u00e9", "Paul", ""], ["Marty", "Paul", ""], ["Renne", "Bryan", ""]]}, {"id": "1412.2105", "submitter": "Arthur Ramos BSCS", "authors": "Arthur Ramos, Ruy J. G. B. de Queiroz, Anjolina G. de Oliveira", "title": "Sequences of Rewrites: A Categorical Interpretation", "comments": "13 pages, submitted to a scientific conference (WoLLIC 2015);\n  corrected typos; Moved part of Section 2.4 to the appendix; corrected small\n  issues in Section 3 (typos and some compositions order), results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Martin-L\\\"of's Intensional Type Theory, identity type is a heavily used\nand studied concept. The reason for that is the fact that it's responsible for\nthe recently discovered connection between Type Theory and Homotopy Theory. The\nmain problem with identity types, as originally formulated, is that they are\ncomplex to understand and use. Using that fact as motivation, a much simpler\nformulation for the identity type was proposed by Queiroz & Gabbay (1994) and\nfurther developed by de Queiroz & de Oliveira (2013). In this formulation, an\nelement of an identity type is seen as a sequence of rewrites (or computational\npaths). Together with the logical rules of this new entity, there exists a\nsystem of reduction rules between sequence of rewrites called LND_{EQS}-RWS.\nThis system is constructed using the labelled natural deduction (i.e. Prawitz'\nNatural Deduction plus derivations-as-terms) and is responsible for\nestablishing how a sequence of rewrites can be rewritten, resulting in a new\nsequence of rewrites. In this context, we propose a categorical interpretation\nfor this new entity, using the types as objects and the rules of rewrites as\nmorphisms. Moreover, we show that our interpretation is in accordance with some\nknown results, like that types have a groupoidal structure. We also interpret\nmore complicated structures, like the one formed by a rewrite of a sequence of\nrewrites.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 19:25:32 GMT"}, {"version": "v2", "created": "Sun, 15 Feb 2015 14:06:28 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Ramos", "Arthur", ""], ["de Queiroz", "Ruy J. G. B.", ""], ["de Oliveira", "Anjolina G.", ""]]}, {"id": "1412.2118", "submitter": "Carlos Lombardi", "authors": "Eduardo Bonelli, Delia Kesner, Carlos Lombardi, Alejandro Rios", "title": "On abstract normalisation beyond neededness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study normalisation of multistep strategies, strategies that reduce a set\nof redexes at a time, focussing on the notion of necessary sets, those which\ncontain at least one redex that cannot be avoided in order to reach a normal\nform. This is particularly appealing in the setting of non-sequential rewrite\nsystems, in which terms that are not in normal form may not have any needed\nredex. We first prove a normalisation theorem for abstract rewrite systems\n(ARS), a general rewriting framework encompassing many rewriting systems\ndeveloped by P-A.Melli\\`es in his PhD thesis. The theorem states that multistep\nstrategies reducing so called necessary and never-gripping sets of redexes at a\ntime are normalising in any ARS. Gripping refers to an abstract property\nreflecting the behavior of higher-order substitution. We then apply this result\nto the particular case of PPC, a calculus of patterns and to the\nlambda-calculus with parallel-or.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 19:59:18 GMT"}, {"version": "v2", "created": "Wed, 31 Dec 2014 01:34:27 GMT"}, {"version": "v3", "created": "Mon, 9 May 2016 14:26:00 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Bonelli", "Eduardo", ""], ["Kesner", "Delia", ""], ["Lombardi", "Carlos", ""], ["Rios", "Alejandro", ""]]}, {"id": "1412.2219", "submitter": "Pierre Lescanne", "authors": "S. Ghilezan, J. Ivetic, P. Lescanne (LIP), S. Likavec", "title": "Resource control and intersection types: an intrinsic connection", "comments": "arXiv admin note: substantial text overlap with arXiv:1306.2283", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the $\\lambda$ -calculus, a $\\lambda$-calculus\nenriched with resource control. Explicit control of resources is enabled by the\npresence of erasure and duplication operators, which correspond to thinning and\ncon-traction rules in the type assignment system. We introduce directly the\nclass of $\\lambda$ -terms and we provide a new treatment of substitution by its\ndecompo-sition into atomic steps. We propose an intersection type assignment\nsystem for $\\lambda$ -calculus which makes a clear correspondence between three\nroles of variables and three kinds of intersection types. Finally, we provide\nthe characterisation of strong normalisation in $\\lambda$ -calculus by means of\nan in-tersection type assignment system. This process uses typeability of\nnormal forms, redex subject expansion and reducibility method.\n", "versions": [{"version": "v1", "created": "Sat, 6 Dec 2014 10:52:17 GMT"}], "update_date": "2014-12-20", "authors_parsed": [["Ghilezan", "S.", "", "LIP"], ["Ivetic", "J.", "", "LIP"], ["Lescanne", "P.", "", "LIP"], ["Likavec", "S.", ""]]}, {"id": "1412.2235", "submitter": "Masahiro Sato", "authors": "Masahiro Sato", "title": "An Intuitionistic Set-theoretical Model of the Extended Calculus of\n  Constructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Werner's set-theoretical model is one of the most intuitive models of ECC. It\ncombines a functional view of predicative universes with a collapsed view of\nthe impredicative sort Prop. However this model of Prop is so coarse that the\nprinciple of excluded middle holds. In this paper, we interpret Prop into a\ntopological space (a special case of Heyting algebra) to make it more\nintuitionistic without sacrificing simplicity. We prove soundness and show some\napplications of our model.\n", "versions": [{"version": "v1", "created": "Sat, 6 Dec 2014 13:36:52 GMT"}, {"version": "v2", "created": "Thu, 11 Dec 2014 04:18:48 GMT"}, {"version": "v3", "created": "Mon, 16 Feb 2015 05:07:36 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Sato", "Masahiro", ""]]}, {"id": "1412.2643", "submitter": "Edwin James Beggs", "authors": "Edwin Beggs and John V. Tucker", "title": "Analogue-digital systems with modes of physical behaviour", "comments": "Ver 3: references and background material added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex environments, processes and systems may exhibit several distinct\nmodes of physical behaviour or operation. Thus, for example, in their design, a\nset of mathematical models may be needed, each model having its own domain of\napplication and representing a particular mode of behaviour or operation of\nphysical reality. The models may be of disparate kinds { discrete or continuous\nin data, time and space. Furthermore, some physical modes may not have a\nreliable model. Physical measurements determine modes of operation. We explore\nthe question: What is a mode of behaviour? How do we specify algorithms and\nsoftware that monitor or govern a complex physical situation with many modes?\nHow do we specify a portfolio of modes, and the computational problem of\ntransitioning from using one mode to another mode as physical modes change? We\npropose a general definition of an analogue-digital system with modes. We show\nhow any diverse set of modes { with or without models { can be bound together,\nand how the transitions between modes can be determined, by constructing a\ntopological data type based upon a simplicial complex. We illustrate the ideas\nof physical modes and our theory by reflecting on simple examples, including\ndriverless racing cars.\n", "versions": [{"version": "v1", "created": "Mon, 8 Dec 2014 16:15:14 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2015 14:37:36 GMT"}, {"version": "v3", "created": "Wed, 26 Oct 2016 15:16:40 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Beggs", "Edwin", ""], ["Tucker", "John V.", ""]]}, {"id": "1412.2905", "submitter": "Alexander Kartzow", "authors": "Claudia Carapelle, Shiguang Feng, Alexander Kartzow and Markus Lohrey", "title": "Satisfiability of ECTL* with tree constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL math.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recently, we have shown that satisfiability for $\\mathsf{ECTL}^*$ with\nconstraints over $\\mathbb{Z}$ is decidable using a new technique. This approach\nreduces the satisfiability problem of $\\mathsf{ECTL}^*$ with constraints over\nsome structure A (or class of structures) to the problem whether A has a\ncertain model theoretic property that we called EHD (for \"existence of\nhomomorphisms is decidable\"). Here we apply this approach to concrete domains\nthat are tree-like and obtain several results. We show that satisfiability of\n$\\mathsf{ECTL}^*$ with constraints is decidable over (i) semi-linear orders\n(i.e., tree-like structures where branches form arbitrary linear orders), (ii)\nordinal trees (semi-linear orders where the branches form ordinals), and (iii)\ninfinitely branching trees of height h for each fixed $h\\in \\mathbb{N}$. We\nprove that all these classes of structures have the property EHD. In contrast,\nwe introduce Ehrenfeucht-Fraisse-games for $\\mathsf{WMSO}+\\mathsf{B}$ (weak\n$\\mathsf{MSO}$ with the bounding quantifier) and use them to show that the\ninfinite (order) tree does not have property EHD. As a consequence, a different\napproach has to be taken in order to settle the question whether satisfiability\nof $\\mathsf{ECTL}^*$ (or even $\\mathsf{LTL}$) with constraints over the\ninfinite (order) tree is decidable.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 10:44:03 GMT"}, {"version": "v2", "created": "Tue, 24 Feb 2015 11:36:55 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Carapelle", "Claudia", ""], ["Feng", "Shiguang", ""], ["Kartzow", "Alexander", ""], ["Lohrey", "Markus", ""]]}, {"id": "1412.3271", "submitter": "Etienne Payet", "authors": "Fred Mesnard and Etienne Payet", "title": "A Second-Order Formulation of Non-Termination", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the termination/non-termination property of a class of loops.\nSuch loops are commonly used abstractions of real program pieces. Second-order\nlogic is a convenient language to express non-termination. Of course, such\nproperty is generally undecidable. However, by restricting the language to\nknown decidable cases, we exhibit new classes of loops, the non-termination of\nwhich is decidable. We present a bunch of examples.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 11:58:18 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Mesnard", "Fred", ""], ["Payet", "Etienne", ""]]}, {"id": "1412.3480", "submitter": "M. H. van Emden", "authors": "M.H. van Emden", "title": "Logic programming beyond Prolog", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "DCS-355-IR", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A logic program is an executable specification. For example, merge sort in\npure Prolog is a logical formula, yet shows creditable performance on long\nlinked lists. But such executable specifications are a compromise: the logic is\ndistorted by algorithmic considerations, yet only indirectly executable via an\nabstract machine. This paper introduces relational programming, a method that\nsolves the difficulty with logic programming by a separation of concerns. It\nrequires three texts: (1) the axioms, a logical formula that specifies the\nproblem and is not compromised by algorithmic considerations, (2) the theorem,\na logical formula that expresses the idea of the algorithm and follows from the\naxioms, and (3) the code, a transcription of the theorem to a procedural\nlanguage. Correctness of the code relies on the logical relationship of the\ntheorem with the axioms and relies on an accurate transcription of the theorem\nto the procedural language. Sorting is an example where relational programming\nhas the advantage of a higher degree of abstractness: the data to be sorted can\nbe any data type in C++ (the procedural language we use in our examples) that\nsatisfies the axioms of linear order, while the pure-Prolog version is limited\nto data structures in the form of linked cells. We show another advantage of\nrelational programs: they have a model-theoretic and fixpoint semantics\nequivalent to each other and analogous to those of pure Prolog programs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 21:45:04 GMT"}, {"version": "v2", "created": "Tue, 23 Dec 2014 04:27:31 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2015 01:43:26 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["van Emden", "M. H.", ""]]}, {"id": "1412.3588", "submitter": "Muhammad Taimoor Khan", "authors": "Muhammad Taimoor Khan, Dimitrios Serpanos, Howard Shrobe", "title": "On the Formal Semantics of the Cognitive Middleware AWDRAT", "comments": "Technical report (submitted) to CSAIL, MIT, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work is two fold: on one hand we want to formalize the\nbehavior of critical components of the self generating and adapting cognitive\nmiddleware AWDRAT such that the formalism not only helps to understand the\nsemantics and technical details of the middleware but also opens an opportunity\nto extend the middleware to support other complex application domains of\ncybersecurity; on the other hand, the formalism serves as a pre-requisite for\nour proof of the behavioral correctness of the critical components to ensure\nthe safety of the middleware itself. However, here we focus only on the core\nand critical component of the middleware, i.e. Execution Monitor which is a\npart of the module \"Architectural Differencer\" of AWDRAT. The role of the\nexecution monitor is to identify inconsistencies between runtime observations\nof the target system and predictions of the System Architectural Model.\nTherefore, to achieve this goal, we first define the formal (denotational)\nsemantics of the observations (runtime events) and predictions (executable\nspecifications as of System Architectural Model); then based on the\naforementioned formal semantices, we formalize the behavior of the \"Execution\nMonitor\" of the middleware.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 09:57:28 GMT"}, {"version": "v2", "created": "Sun, 14 Dec 2014 14:37:46 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Khan", "Muhammad Taimoor", ""], ["Serpanos", "Dimitrios", ""], ["Shrobe", "Howard", ""]]}, {"id": "1412.3633", "submitter": "Jan Triska", "authors": "Jan Triska and Vilem Vychodil", "title": "Logic of temporal attribute implications", "comments": null, "journal-ref": null, "doi": "10.1007/s10472-016-9526-6", "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study logic for reasoning with if-then formulas describing dependencies\nbetween attributes of objects which are observed in consecutive points in time.\nWe introduce semantic entailment of the formulas, show its fixed-point\ncharacterization, investigate closure properties of model classes, present an\naxiomatization and prove its completeness, and investigate alternative\naxiomatizations and normalized proofs. We investigate decidability and\ncomplexity issues of the logic and prove that the entailment problem is NP-hard\nand belongs to EXPSPACE. We show that by restricting to predictive formulas,\nthe entailment problem is decidable in pseudo-linear time.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 12:41:51 GMT"}, {"version": "v2", "created": "Mon, 4 May 2015 08:01:28 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Triska", "Jan", ""], ["Vychodil", "Vilem", ""]]}, {"id": "1412.3644", "submitter": "Christoph Rauch", "authors": "Shiguang Feng, Markus Lohrey, Karin Quaas", "title": "Path Checking for MTL and TPTL over Data Words", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  4, 2017) lmcs:3898", "doi": "10.23638/LMCS-13(3:19)2017", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric temporal logic (MTL) and timed propositional temporal logic (TPTL) are\nquantitative extensions of linear temporal logic, which are prominent and\nwidely used in the verification of real-timed systems. It was recently shown\nthat the path checking problem for MTL, when evaluated over finite timed words,\nis in the parallel complexity class NC. In this paper, we derive precise\ncomplexity results for the path-checking problem for MTL and TPTL when\nevaluated over infinite data words over the non-negative integers. Such words\nmay be seen as the behaviours of one-counter machines. For this setting, we\ngive a complete analysis of the complexity of the path-checking problem\ndepending on the number of register variables and the encoding of constraint\nnumbers (unary or binary). As the two main results, we prove that the\npath-checking problem for MTL is P-complete, whereas the path-checking problem\nfor TPTL is PSPACE-complete. The results yield the precise complexity of model\nchecking deterministic one-counter machines against formulae of MTL and TPTL.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 13:30:50 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2015 14:22:26 GMT"}, {"version": "v3", "created": "Thu, 1 Sep 2016 13:48:58 GMT"}, {"version": "v4", "created": "Wed, 19 Jul 2017 08:14:45 GMT"}, {"version": "v5", "created": "Wed, 26 Jul 2017 07:46:21 GMT"}, {"version": "v6", "created": "Fri, 1 Sep 2017 09:45:49 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Feng", "Shiguang", ""], ["Lohrey", "Markus", ""], ["Quaas", "Karin", ""]]}, {"id": "1412.3670", "submitter": "Sagar Jha", "authors": "Devendra Bhave, Sagar Jha, Shankara Narayanan Krishna, Sven Schewe,\n  Ashutosh Trivedi", "title": "Bounded-Rate Multi-Mode Systems Based Motion Planning", "comments": "14 pages, 12 figures, HSCC - 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded-rate multi-mode systems are hybrid systems that can switch among a\nfinite set of modes. Its dynamics is specified by a finite number of\nreal-valued variables with mode-dependent rates that can vary within given\nbounded sets. Given an arbitrary piecewise linear trajectory, we study the\nproblem of following the trajectory with arbitrary precision, using motion\nprimitives given as bounded-rate multi-mode systems. We give an algorithm to\nsolve the problem and show that the problem is co-NP complete. We further prove\nthat the problem can be solved in polynomial time for multi-mode systems with\nfixed dimension. We study the problem with dwell-time requirement and show the\ndecidability of the problem under certain positivity restriction on the rate\nvectors. Finally, we show that introducing structure to the multi-mode systems\nleads to undecidability, even when using only a single clock variable.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 19:26:03 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Bhave", "Devendra", ""], ["Jha", "Sagar", ""], ["Krishna", "Shankara Narayanan", ""], ["Schewe", "Sven", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1412.4020", "submitter": "S{\\l}awomir Lasota", "authors": "S{\\l}awomir Lasota", "title": "Equivariant algorithms for constraint satisfaction problems over coset\n  templates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the Constraint Satisfaction Problem (CSP) over templates with\na group structure, and algorithms solving CSP that are equivariant, i.e.\ninvariant under a natural group action induced by a template. Our main result\nis a method of proving the implication: if CSP over a coset template T is\nsolvable by an equivariant algorithm then T is 2-Helly (or equivalently, has a\nmajority polymorphism). Therefore bounded width, and definability in\nfixed-point logics, coincide with 2-Helly. Even if these facts may be derived\nfrom already known results, our new proof method has two advantages. First, the\nproof is short, self-contained, and completely avoids referring to the\nomitting-types theorems. Second, it brings to light some new connections\nbetween CSP theory and descriptive complexity theory, via a construction\nsimilar to CFI graphs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 15:26:39 GMT"}, {"version": "v2", "created": "Sat, 28 Feb 2015 13:10:12 GMT"}, {"version": "v3", "created": "Tue, 5 Apr 2016 19:06:24 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Lasota", "S\u0142awomir", ""]]}, {"id": "1412.4259", "submitter": "Michael Blondin", "authors": "Michael Blondin, Alain Finkel, Stefan G\\\"oller, Christoph Haase,\n  Pierre McKenzie", "title": "Reachability in Two-Dimensional Vector Addition Systems with States is\n  PSPACE-complete", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": "10.1109/LICS.2015.14", "report-no": null, "categories": "cs.FL cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the complexity of the reachability problem for vector addition\nsystems with states (VASS) is a long-standing open problem in computer science.\nLong known to be decidable, the problem to this day lacks any complexity upper\nbound whatsoever. In this paper, reachability for two-dimensional VASS is shown\nPSPACE-complete. This improves on a previously known doubly exponential time\nbound established by Howell, Rosier, Huynh and Yen in 1986. The coverability\nand boundedness problems are also noted to be PSPACE-complete. In addition,\nsome complexity results are given for the reachability problem in\ntwo-dimensional VASS and in integer VASS when numbers are encoded in unary.\n", "versions": [{"version": "v1", "created": "Sat, 13 Dec 2014 17:10:34 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Blondin", "Michael", ""], ["Finkel", "Alain", ""], ["G\u00f6ller", "Stefan", ""], ["Haase", "Christoph", ""], ["McKenzie", "Pierre", ""]]}, {"id": "1412.4550", "submitter": "Laura Titolo", "authors": "Damian Adalid and Maria del Mar Gallardo and Laura Titolo", "title": "Modeling Hybrid Systems in Hy-tccp", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent,reactive and hybrid systems require quality modeling languages to\nbe described and analyzed. The Timed Concurrent Constraint Language (tccp) was\nintroduced as a simple but powerful model for reactive systems. In this paper,\nwe present hybrid tccp (hy-tccp), an extension of tccp over continuous time\nwhich includes new con- structs to model the continuous dynamics of hybrid\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 11:32:54 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Adalid", "Damian", ""], ["Gallardo", "Maria del Mar", ""], ["Titolo", "Laura", ""]]}, {"id": "1412.4586", "submitter": "Sumit Sourabh", "authors": "Sebastian Enqvist, Sumit Sourabh", "title": "Generalized Vietoris Bisimulations", "comments": null, "journal-ref": null, "doi": "10.1093/logcom/exy001", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study bisimulations for coalgebras on Stone spaces [14]. Our\nnotion of bisimulation is sound and complete for behavioural equivalence, and\ngeneralizes Vietoris bisimulations [4]. The main result of our paper is that\nbisimulation for a $\\mathbf{Stone}$ coalgebra is the topological closure of\nbisimulation for the underlying $\\mathbf{Set}$ coalgebra.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 13:43:47 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Enqvist", "Sebastian", ""], ["Sourabh", "Sumit", ""]]}, {"id": "1412.4737", "submitter": "Volker Diekert", "authors": "Volker Diekert, Florent Martin, Geraud Senizergues, Pedro V. Silva", "title": "Equations over free inverse monoids with idempotent variables", "comments": "28 pages. The conference version of this paper appeared in the\n  proceedings of 10th International Computer Science Symposium in Russia, CSR\n  2015, Listvyanka, Russia, July 13-17, 2015. Springer LNCS 9139, pp. 173-188\n  (2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of idempotent variables for studying equations in\ninverse monoids.\n  It is proved that it is decidable in singly exponential time (DEXPTIME)\nwhether a system of equations in idempotent variables over a free inverse\nmonoid has a solution. The result is proved by a direct reduction to solve\nlanguage equations with one-sided concatenation and a known complexity result\nby Baader and Narendran: Unification of concept terms in description logics,\n2001. We also show that the problem becomes DEXPTIME hard , as soon as the\nquotient group of the free inverse monoid has rank at least two.\n  Decidability for systems of typed equations over a free inverse monoid with\none irreducible variable and at least one unbalanced equation is proved with\nthe same complexity for the upper bound.\n  Our results improve known complexity bounds by Deis, Meakin, and Senizergues:\nEquations in free inverse monoids, 2007.\n  Our results also apply to larger families of equations where no decidability\nhas been previously known.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 17:01:12 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2015 10:38:55 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Diekert", "Volker", ""], ["Martin", "Florent", ""], ["Senizergues", "Geraud", ""], ["Silva", "Pedro V.", ""]]}, {"id": "1412.5090", "submitter": "Bryan Renne", "authors": "Jan van Eijck and Bryan Renne", "title": "Belief as Willingness to Bet", "comments": "Removed date from v1 to avoid confusion on citation/reference,\n  otherwise identical to v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate modal logics of high probability having two unary modal\noperators: an operator $K$ expressing probabilistic certainty and an operator\n$B$ expressing probability exceeding a fixed rational threshold $c\\geq\\frac\n12$. Identifying knowledge with the former and belief with the latter, we may\nthink of $c$ as the agent's betting threshold, which leads to the motto \"belief\nis willingness to bet.\" The logic $\\mathsf{KB.5}$ for $c=\\frac 12$ has an\n$\\mathsf{S5}$ $K$ modality along with a sub-normal $B$ modality that extends\nthe minimal modal logic $\\mathsf{EMND45}$ by way of four schemes relating $K$\nand $B$, one of which is a complex scheme arising out of a theorem due to\nScott. Lenzen was the first to use Scott's theorem to show that a version of\nthis logic is sound and complete for the probability interpretation. We\nreformulate Lenzen's results and present them here in a modern and accessible\nform. In addition, we introduce a new epistemic neighborhood semantics that\nwill be more familiar to modern modal logicians. Using Scott's theorem, we\nprovide the Lenzen-derivative properties that must be imposed on finite\nepistemic neighborhood models so as to guarantee the existence of a probability\nmeasure respecting the neighborhood function in the appropriate way for\nthreshold $c=\\frac 12$. This yields a link between probabilistic and modal\nneighborhood semantics that we hope will be of use in future work on modal\nlogics of qualitative probability. We leave open the question of which\nproperties must be imposed on finite epistemic neighborhood models so as to\nguarantee existence of an appropriate probability measure for thresholds\n$c\\neq\\frac 12$.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 17:34:25 GMT"}, {"version": "v2", "created": "Wed, 17 Dec 2014 22:49:14 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["van Eijck", "Jan", ""], ["Renne", "Bryan", ""]]}, {"id": "1412.5143", "submitter": "Matthew Hague", "authors": "Matthew Hague, Anthony Widjaja Lin, Luke Ong", "title": "Detecting Redundant CSS Rules in HTML5 Applications: A Tree-Rewriting\n  Approach", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HTML5 applications normally have a large set of CSS (Cascading Style Sheets)\nrules for data display. Each CSS rule consists of a node selector (given in an\nXPath-like query language) and a declaration block (assigning values to\nselected nodes' display attributes). As web applications evolve, maintaining\nCSS files can easily become problematic. Some CSS rules will be replaced by new\nones, but these obsolete (hence redundant) CSS rules often remain in the\napplications. Not only does this \"bloat\" the applications, but it also\nsignificantly increases web browsers' processing time. Most works on detecting\nredundant CSS rules in HTML5 applications do not consider the dynamic behaviors\nof HTML5 (specified in JavaScript); in fact, the only proposed method that\ntakes these into account is dynamic analysis (a.k.a. testing), which cannot\nsoundly prove redundancy of CSS rules. In this paper, we introduce an\nabstraction of HTML5 applications based on monotonic tree-rewriting and study\nits \"redundancy problem\". We establish the precise complexity of the problem\nand various subproblems of practical importance (ranging from P to EXP). In\nparticular, our algorithm relies on an efficient reduction to an analysis of\nsymbolic pushdown systems (for which highly optimised solvers are available),\nwhich yields a fast method for checking redundancy in practice. We implemented\nour algorithm and demonstrated its efficacy in detecting redundant CSS rules in\nHTML5 applications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 14:22:03 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2015 02:30:30 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2015 12:24:10 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2015 13:25:58 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Hague", "Matthew", ""], ["Lin", "Anthony Widjaja", ""], ["Ong", "Luke", ""]]}, {"id": "1412.5159", "submitter": "Felix Klein", "authors": "Felix Klein", "title": "Solving 3-Color Parity Games in $ O(n^2) $ Time", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  Lemma 1.7, which additionally needs the assumption that V' is a trap for\n  Player 1-i. However, this assumption is not given for equation (1)\n  invalidating Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parity games are an expressive framework to consider realizability questions\nfor omega-regular languages. However, it is open whether they can be solved in\npolynomial time, making them unamenable for practical usage. To overcome this\nrestriction, we consider 3-color parity games, which can be solved in\npolynomial time. They still cover an expressive fragment of specifications, as\nthey include the classical B\\\"uchi and co-B\\\"uchi winning conditions as well as\ntheir union and intersection. This already suffices to express many useful\ncombinations of safety and liveness properties, as for example the family of\nGR(1). The best known algorithm for 3-color parity games solves a game with n\nvertices in $ O(n^{2}\\sqrt{n}) $ time. We improve on this result by presenting\na new algorithm, based on simple attractor constructions, which only needs time\n$ O(n^2) $. As a result, we match the best known running times for solving\n(co)-B\\\"uchi games, showing that 3-color parity games are not harder to solve\nin general.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 15:38:03 GMT"}, {"version": "v2", "created": "Fri, 19 Dec 2014 07:40:44 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Klein", "Felix", ""]]}, {"id": "1412.5795", "submitter": "Camilo Thorne", "authors": "Camilo Thorne", "title": "The Expressive Power of DL-Lite", "comments": "7pp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description logics are knowledge representation formalisms that provide the\nformal underpinning of the semantic web and in particular of the $\\text{OWL}$\nOntology Web Language. In this paper we investigate the expressive power of\nlogic $\\text{DL-Lite}_{R,\\sqcap}$, and some of its computational properties. We\nrely on simulations to characterize the absolute expressive power of\n$\\text{DL-Lite}_{R,\\sqcap}$ as a concept language, and to show that disjunction\nis not expressible. We also show that no simulation-based closure property\nexists for $\\text{DL-Lite}_{R,\\sqcap}$ assertions. Finally, we show that query\nanswering of unions of conjunctive queries is $\\text{NP-complete}$.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 10:31:35 GMT"}, {"version": "v2", "created": "Wed, 18 Feb 2015 19:16:40 GMT"}], "update_date": "2015-02-19", "authors_parsed": [["Thorne", "Camilo", ""]]}, {"id": "1412.5943", "submitter": "Nobuko Yoshida", "authors": "Dimitrios Kouzapas (University of Glasgow), Nobuko Yoshida (Imperial\n  College London)", "title": "Globally Governed Session Semantics", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (December\n  30, 2014) lmcs:775", "doi": "10.2168/LMCS-10(4:20)2014", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a bisimulation theory based on multiparty session types\nwhere a choreography specification governs the behaviour of session typed\nprocesses and their observer. The bisimulation is defined with the observer\ncooperating with the observed process in order to form complete global session\nscenarios and usable for proving correctness of optimisations for globally\ncoordinating threads and processes. The induced bisimulation is strictly more\nfine-grained than the standard session bisimulation. The difference between the\ngoverned and standard bisimulations only appears when more than two interleaved\nmultiparty sessions exist. This distinct feature enables to reason real\nscenarios in the large-scale distributed system where multiple choreographic\nsessions need to be interleaved. The compositionality of the governed\nbisimilarity is proved through the soundness and completeness with respect to\nthe governed reduction-based congruence. Finally, its usage is demonstrated by\na thread transformation governed under multiple sessions in a real usecase in\nthe large-scale cyberinfrustracture.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 08:49:06 GMT"}, {"version": "v2", "created": "Mon, 29 Dec 2014 08:51:25 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2015 12:49:22 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kouzapas", "Dimitrios", "", "University of Glasgow"], ["Yoshida", "Nobuko", "", "Imperial\n  College London"]]}, {"id": "1412.6396", "submitter": "Till Tantau", "authors": "Till Tantau", "title": "Existential Second-Order Logic Over Graphs: A Complete\n  Complexity-Theoretic Classification", "comments": "Technical report version of a STACS 2015 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Descriptive complexity theory aims at inferring a problem's computational\ncomplexity from the syntactic complexity of its description. A cornerstone of\nthis theory is Fagin's Theorem, by which a graph property is expressible in\nexistential second-order logic (ESO logic) if, and only if, it is in NP. A\nnatural question, from the theory's point of view, is which syntactic fragments\nof ESO logic also still characterize NP. Research on this question has\nculminated in a dichotomy result by Gottlob, Kolatis, and Schwentick: for each\npossible quantifier prefix of an ESO formula, the resulting prefix class either\ncontains an NP-complete problem or is contained in P. However, the exact\ncomplexity of the prefix classes inside P remained elusive. In the present\npaper, we clear up the picture by showing that for each prefix class of ESO\nlogic, its reduction closure under first-order reductions is either FO, L, NL,\nor NP. For undirected, self-loop-free graphs two containment results are\nespecially challenging to prove: containment in L for the prefix $\\exists R_1\n\\cdots \\exists R_n \\forall x \\exists y$ and containment in FO for the prefix\n$\\exists M \\forall x \\exists y$ for monadic $M$. The complex argument by\nGottlob, Kolatis, and Schwentick concerning polynomial time needs to be\ncarefully reexamined and either combined with the logspace version of\nCourcelle's Theorem or directly improved to first-order computations. A\ndifferent challenge is posed by formulas with the prefix $\\exists M \\forall\nx\\forall y$: We show that they express special constraint satisfaction problems\nthat lie in L.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 15:51:33 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Tantau", "Till", ""]]}, {"id": "1412.6545", "submitter": "Pablo Fillottrani", "authors": "Pablo R. Fillottrani, C. Maria Keet", "title": "KF metamodel formalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The KF metamodel is a comprehensive unifying metamodel covering the static\nstructural entities and constraints of UML Class Diagrams (v2.4.1), ER, EER,\nORM, and ORM2, and intended to boost interoperability of common conceptual data\nmodelling languages. It was originally designed in UML with textual\nconstraints, and in this report we present its formalisations in FOL and OWL,\nwhich accompanies the paper that describes, discusses, and analyses the KF\nmetamodel in detail. These new formalizations contribute to give a precise\nmeaning to the metamodel, to understand its complexity properties and to\nprovide a basis for future implementations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 21:56:59 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Fillottrani", "Pablo R.", ""], ["Keet", "C. Maria", ""]]}, {"id": "1412.6579", "submitter": "Tarmo Uustalu", "authors": "Keiko Nakata (Institute of Cybernetics), Tarmo Uustalu (Institute of\n  Cybernetics)", "title": "A Hoare logic for the coinductive trace-based big-step semantics of\n  While", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (February\n  11, 2015) lmcs:692", "doi": "10.2168/LMCS-11(1:1)2015", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In search for a foundational framework for reasoning about observable\nbehavior of programs that may not terminate, we have previously devised a\ntrace-based big-step semantics for While. In this semantics, both traces and\nevaluation (relating initial states of program runs to traces they produce) are\ndefined coinductively. On terminating runs, this semantics agrees with the\nstandard inductive state-based semantics. Here we present a Hoare logic\ncounterpart of our coinductive trace-based semantics and prove it sound and\ncomplete. Our logic subsumes the standard partial-correctness state-based Hoare\nlogic as well as the total-correctness variation: they are embeddable. In the\nconverse direction, projections can be constructed: a derivation of a Hoare\ntriple in our trace-based logic can be translated into a derivation in the\nstate-based logic of a translated, weaker Hoare triple. Since we work with a\nconstructive underlying logic, the range of program properties we can reason\nabout has a fine structure; in particular, we can distinguish between\ntermination and nondivergence, e.g., unbounded classically total search fails\nto be terminating, but is nonetheless nondivergent. Our meta-theory is entirely\nconstructive as well, and we have formalized it in Coq.\n", "versions": [{"version": "v1", "created": "Sat, 20 Dec 2014 02:00:11 GMT"}, {"version": "v2", "created": "Sun, 8 Feb 2015 11:06:59 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Nakata", "Keiko", "", "Institute of Cybernetics"], ["Uustalu", "Tarmo", "", "Institute of\n  Cybernetics"]]}, {"id": "1412.6781", "submitter": "St\\'ephane Graham-Lengrand", "authors": "St\\'ephane Graham-Lengrand", "title": "Polarities & Focussing: a journey from Realisability to Automated\n  Reasoning", "comments": "Dissertation submitted towards the degree of Habilitation \\`a Diriger\n  des Recherches. Universit\\'e Paris-Sud. 212 pages. Thesis publicly defended\n  on 17th December 2014 before a panel consisting of Laurent Regnier, Wolfgang\n  Ahrendt, Hugo Herbelin, Frank Pfenning, Sylvain Conchon, David Delahaye,\n  Didier Galmiche, Christine Paulin-Mohring", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This dissertation explores the roles of polarities and focussing in various\naspects of Computational Logic. These concepts play a key role in the the\ninterpretation of proofs as programs, a.k.a. the Curry-Howard correspondence,\nin the context of classical logic. Arising from linear logic, they allow the\nconstruction of meaningful semantics for cut-elimination in classical logic,\nsome of which relate to the Call-by-Name and Call-by-Value disciplines of\nfunctional programming. The first part of this dissertation provides an\nintroduction to these interpretations, highlighting the roles of polarities and\nfocussing. For instance: proofs of positive formulae provide structured data,\nwhile proofs of negative formulae consume such data; focussing allows the\ndescription of the interaction between the two kinds of proofs as pure\npattern-matching. This idea is pushed further in the second part of this\ndissertation, and connected to realisability semantics, where the structured\ndata is interpreted algebraically, and the consumption of such data is modelled\nwith the use of an orthogonality relation. Most of this part has been proved in\nthe Coq proof assistant. Polarities and focussing were also introduced with\napplications to logic programming in mind, where computation is proof-search.\nIn the third part of this dissertation, we push this idea further by exploring\nthe roles that these concepts can play in other applications of proof-search,\nsuch as theorem proving and more particularly automated reasoning. We use these\nconcepts to describe the main algorithm of SAT-solvers and SMT-solvers: DPLL.\nWe then describe the implementation of a proof-search engine called Psyche. Its\narchitecture, based on the concept of focussing, offers a platform where smart\ntechniques from automated reasoning (or a user interface) can safely and\ntrustworthily be implemented via the use of an API.\n", "versions": [{"version": "v1", "created": "Sun, 21 Dec 2014 13:25:11 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Graham-Lengrand", "St\u00e9phane", ""]]}, {"id": "1412.6783", "submitter": "Kosta Dosen", "authors": "Kosta Dosen", "title": "On Sets of Premises", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conceiving of premises as collected into sets or multisets, instead of\nsequences, may lead to triviality for classical and intuitionistic logic in\ngeneral proof theory, where we investigate identity of deductions. Any two\ndeductions with the same premises and the same conclusions become equal. In\nterms of categorial proof theory, this is a consequence of a simple fact\nconcerning adjunction with a full and faithful functor applied to the\nadjunction between the diagonal functor and the product biendofunctor, which\ncorresponds to the conjunction connective.\n", "versions": [{"version": "v1", "created": "Sun, 21 Dec 2014 13:35:24 GMT"}, {"version": "v2", "created": "Sat, 24 Jan 2015 17:04:23 GMT"}, {"version": "v3", "created": "Thu, 5 Feb 2015 13:57:49 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2015 11:51:39 GMT"}, {"version": "v5", "created": "Thu, 4 Jun 2015 16:16:51 GMT"}, {"version": "v6", "created": "Mon, 8 Jun 2015 01:01:36 GMT"}, {"version": "v7", "created": "Wed, 8 Jun 2016 20:30:33 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Dosen", "Kosta", ""]]}, {"id": "1412.6790", "submitter": "St\\'ephane Graham-Lengrand", "authors": "Damien Rouhling, Mahfuza Farooque, St\\'ephane Graham-Lengrand, Assia\n  Mahboubi, and Jean-Marc Notin", "title": "Axiomatic constraint systems for proof search modulo theories", "comments": "24 pages (incl. appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Goal-directed proof search in first-order logic uses meta-variables to delay\nthe choice of witnesses; substitutions for such variables are produced when\nclosing proof-tree branches, using first-order unification or a theory-specific\nbackground reasoner. This paper investigates a generalisation of such\nmechanisms whereby theory-specific constraints are produced instead of\nsubstitutions. In order to design modular proof-search procedures over such\nmechanisms, we provide a sequent calculus with meta-variables, which\nmanipulates such constraints abstractly. Proving soundness and completeness of\nthe calculus leads to an axiomatisation that identifies the conditions under\nwhich abstract constraints can be generated and propagated in the same way\nunifiers usually are. We then extract from our abstract framework a component\ninterface and a specification for concrete implementations of background\nreasoners.\n", "versions": [{"version": "v1", "created": "Sun, 21 Dec 2014 14:44:44 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2015 15:22:50 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Rouhling", "Damien", ""], ["Farooque", "Mahfuza", ""], ["Graham-Lengrand", "St\u00e9phane", ""], ["Mahboubi", "Assia", ""], ["Notin", "Jean-Marc", ""]]}, {"id": "1412.7148", "submitter": "Tarmo Uustalu", "authors": "Thosten Altenkirch (University of Nottingham), James Chapman\n  (Institute of Cybernetics), Tarmo Uustalu (Institute of Cybernetics)", "title": "Monads need not be endofunctors", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 6,\n  2015) lmcs:928", "doi": "10.2168/LMCS-11(1:3)2015", "report-no": null, "categories": "cs.PL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generalization of monads, called relative monads, allowing for\nunderlying functors between different categories. Examples include\nfinite-dimensional vector spaces, untyped and typed lambda-calculus syntax and\nindexed containers. We show that the Kleisli and Eilenberg-Moore constructions\ncarry over to relative monads and are related to relative adjunctions. Under\nreasonable assumptions, relative monads are monoids in the functor category\nconcerned and extend to monads, giving rise to a coreflection between relative\nmonads and monads. Arrows are also an instance of relative monads.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 20:53:17 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2015 21:10:14 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Altenkirch", "Thosten", "", "University of Nottingham"], ["Chapman", "James", "", "Institute of Cybernetics"], ["Uustalu", "Tarmo", "", "Institute of Cybernetics"]]}, {"id": "1412.7998", "submitter": "Fan Yang", "authors": "Fan Yang and Jouko V\\\"a\\\"an\\\"anen", "title": "Propositional Logics of Dependence", "comments": null, "journal-ref": "Annals of Pure and Applied Logic, Volume 167, Issue 7, July 2016,\n  pp. 557-589", "doi": "10.1016/j.apal.2016.03.003", "report-no": null, "categories": "math.LO cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we study logics of dependence on the propositional level. We\nprove that several interesting propositional logics of dependence, including\npropositional dependence logic, propositional intuitionistic dependence logic\nas well as propositional inquisitive logic, are expressively complete and have\ndisjunctive or conjunctive normal forms. We provide deduction systems and prove\nthe completeness theorems for these logics.\n", "versions": [{"version": "v1", "created": "Fri, 26 Dec 2014 22:11:44 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2015 21:35:05 GMT"}, {"version": "v3", "created": "Mon, 7 Mar 2016 13:58:34 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Yang", "Fan", ""], ["V\u00e4\u00e4n\u00e4nen", "Jouko", ""]]}, {"id": "1412.8091", "submitter": "Mario Carneiro", "authors": "Mario Carneiro", "title": "Conversion of HOL Light proofs into Metamath", "comments": "14 pages, 2 figures, accepted to Journal of Formalized Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for converting proofs from the OpenTheory interchange\nformat, which can be translated to and from any of the HOL family of proof\nlanguages (HOL4, HOL Light, ProofPower, and Isabelle), into the ZFC-based\nMetamath language. This task is divided into two steps: the translation of an\nOpenTheory proof into a Metamath HOL formalization, $\\mathtt{\\text{hol.mm}}$,\nfollowed by the embedding of the HOL formalization into the main ZFC\nfoundations of the main Metamath library, $\\mathtt{\\text{set.mm}}$. This\nprocess provides a means to link the simplicity of the Metamath foundations to\nthe intense automation efforts which have borne fruit in HOL Light, allowing\nthe production of complete Metamath proofs of theorems in HOL Light, while also\nproving that HOL Light is consistent, relative to Metamath's ZFC\naxiomatization.\n", "versions": [{"version": "v1", "created": "Sat, 27 Dec 2014 23:29:46 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2015 21:19:28 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Carneiro", "Mario", ""]]}, {"id": "1412.8102", "submitter": "EPTCS", "authors": "Bob Coecke (University of Oxford), Ichiro Hasuo (The University of\n  Tokyo), Prakash Panangaden (McGill University)", "title": "Proceedings of the 11th workshop on Quantum Physics and Logic", "comments": null, "journal-ref": "EPTCS 172, 2014", "doi": "10.4204/EPTCS.172", "report-no": null, "categories": "cs.LO cs.CL cs.PL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the 11th International Workshop on\nQuantum Physics and Logic (QPL 2014), which was held from the 4th to the 6th of\nJune, 2014, at Kyoto University, Japan.\n  The goal of the QPL workshop series is to bring together researchers working\non mathematical foundations of quantum physics, quantum computing and\nspatio-temporal causal structures, and in particular those that use logical\ntools, ordered algebraic and category-theoretic structures, formal languages,\nsemantic methods and other computer science methods for the study of physical\nbehavior in general. Over the past few years, there has been growing activity\nin these foundational approaches, together with a renewed interest in the\nfoundations of quantum theory, which complement the more mainstream research in\nquantum computation. Earlier workshops in this series, with the same acronym\nunder the name \"Quantum Programming Languages\", were held in Ottawa (2003),\nTurku (2004), Chicago (2005), and Oxford (2006). The first QPL under the new\nname Quantum Physics and Logic was held in Reykjavik (2008), followed by Oxford\n(2009 and 2010), Nijmegen (2011), Brussels (2012) and Barcelona (2013).\n", "versions": [{"version": "v1", "created": "Sun, 28 Dec 2014 03:54:16 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Coecke", "Bob", "", "University of Oxford"], ["Hasuo", "Ichiro", "", "The University of\n  Tokyo"], ["Panangaden", "Prakash", "", "McGill University"]]}, {"id": "1412.8525", "submitter": "EPTCS", "authors": "Daniel Marsden (Department of Computer Science, University of Oxford,\n  UK)", "title": "Fibred Coalgebraic Logic and Quantum Protocols", "comments": "In Proceedings QPL 2013, arXiv:1412.7917", "journal-ref": "EPTCS 171, 2014, pp. 90-99", "doi": "10.4204/EPTCS.171.9", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in modelling quantum systems using coalgebraic\ntechniques, we introduce a fibred coalgebraic logic. Our approach extends the\nconventional predicate lifting semantics with additional modalities relating\nconditions on different fibres. As this fibred setting will typically involve\nmultiple signature functors, the logic incorporates a calculus of modalities\nenabling the construction of new modalities using various composition\noperations. We extend the semantics of coalgebraic logic to this setting, and\nprove that this extension respects behavioural equivalence.\n  We show how properties of the semantics of modalities are preserved under\ncomposition operations, and then apply the calculational aspect of our logic to\nproduce an expressive set of modalities for reasoning about quantum systems,\nbuilding these modalities up from simpler components. We then demonstrate how\nthese modalities can describe some standard quantum protocols. The novel\nfeatures of our logic are shown to allow for a uniform description of unitary\nevolution, and support local reasoning such as \"Alice's qubit satisfies\ncondition\" as is common when discussing quantum protocols.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 01:43:13 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Marsden", "Daniel", "", "Department of Computer Science, University of Oxford,\n  UK"]]}, {"id": "1412.8526", "submitter": "EPTCS", "authors": "Yoshihiro Maruyama (Quantum Group, Department of Computer Science,\n  University of Oxford)", "title": "Duality Theory and Categorical Universal Logic: With Emphasis on Quantum\n  Structures", "comments": "In Proceedings QPL 2013, arXiv:1412.7917", "journal-ref": "EPTCS 171, 2014, pp. 100-112", "doi": "10.4204/EPTCS.171.10", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical Universal Logic is a theory of monad-relativised hyperdoctrines\n(or fibred universal algebras), which in particular encompasses categorical\nforms of both first-order and higher-order quantum logics as well as classical,\nintuitionistic, and diverse substructural logics. Here we show there are those\ndual adjunctions that have inherent hyperdoctrine structures in their predicate\nfunctor parts. We systematically investigate into the categorical logics of\ndual adjunctions by utilising Johnstone-Dimov-Tholen's duality-theoretic\nframework. Our set-theoretical duality-based hyperdoctrines for quantum logic\nhave both universal and existential quantifiers (and higher-order structures),\ngiving rise to a universe of Takeuti-Ozawa's quantum sets via the\ntripos-to-topos construction by Hyland-Johnstone-Pitts. The set-theoretical\nhyperdoctrinal models of quantum logic, as well as all quantum hyperdoctrines\nwith cartesian base categories, turn out to give sound and complete semantics\nfor Faggian-Sambin's first-order quantum sequent calculus over cartesian type\ntheory; in addition, quantum hyperdoctrines with monoidal base categories are\nsound and complete for the calculus over linear type theory. We finally\nconsider how to reconcile Birkhoff-von Neumann's quantum logic and\nAbramsky-Coecke's categorical quantum mechanics (which is modernised quantum\nlogic as an antithesis to the traditional one) via categorical universal logic.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 01:43:24 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Maruyama", "Yoshihiro", "", "Quantum Group, Department of Computer Science,\n  University of Oxford"]]}, {"id": "1412.8527", "submitter": "EPTCS", "authors": "Anne Preller (LIRMM, France)", "title": "From Logical to Distributional Models", "comments": "In Proceedings QPL 2013, arXiv:1412.7917", "journal-ref": "EPTCS 171, 2014, pp. 113-131", "doi": "10.4204/EPTCS.171.11", "report-no": null, "categories": "cs.LO cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper relates two variants of semantic models for natural language,\nlogical functional models and compositional distributional vector space models,\nby transferring the logic and reasoning from the logical to the distributional\nmodels.\n  The geometrical operations of quantum logic are reformulated as algebraic\noperations on vectors. A map from functional models to vector space models\nmakes it possible to compare the meaning of sentences word by word.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 01:43:39 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Preller", "Anne", "", "LIRMM, France"]]}, {"id": "1412.8528", "submitter": "EPTCS", "authors": "Frank Roumen (Inst. for Mathematics, Astrophysics and Particle Physics\n  (IMAPP), Radboud University Nijmegen)", "title": "Categorical characterizations of operator-valued measures", "comments": "In Proceedings QPL 2013, arXiv:1412.7917", "journal-ref": "EPTCS 171, 2014, pp. 132-144", "doi": "10.4204/EPTCS.171.12", "report-no": null, "categories": "cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most general type of measurement in quantum physics is modeled by a\npositive operator-valued measure (POVM). Mathematically, a POVM is a\ngeneralization of a measure, whose values are not real numbers, but positive\noperators on a Hilbert space. POVMs can equivalently be viewed as maps between\neffect algebras or as maps between algebras for the Giry monad. We will show\nthat this equivalence is an instance of a duality between two categories. In\nthe special case of continuous POVMs, we obtain two equivalent representations\nin terms of morphisms between von Neumann algebras.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 01:43:49 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Roumen", "Frank", "", "Inst. for Mathematics, Astrophysics and Particle Physics"]]}, {"id": "1412.8539", "submitter": "EPTCS", "authors": "Giulio Chiribella (Institute for Interdisciplinary Information\n  Sciences, Tsinghua University)", "title": "Dilation of states and processes in operational-probabilistic theories", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 1-14", "doi": "10.4204/EPTCS.172.1", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a concise summary of the framework of\noperational-probabilistic theories, aimed at emphasizing the interaction\nbetween category-theoretic and probabilistic structures. Within this framework,\nwe review an operational version of the GNS construction, expressed by the\nso-called purification principle, which under mild hypotheses leads to an\noperational version of Stinespring's theorem.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 02:59:36 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Chiribella", "Giulio", "", "Institute for Interdisciplinary Information\n  Sciences, Tsinghua University"]]}, {"id": "1412.8540", "submitter": "EPTCS", "authors": "Masanao Ozawa (Nagoya University)", "title": "Quantum Set Theory Extending the Standard Probabilistic Interpretation\n  of Quantum Theory (Extended Abstract)", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 15-26", "doi": "10.4204/EPTCS.172.2", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of equality between two observables will play many important roles\nin foundations of quantum theory. However, the standard probabilistic\ninterpretation based on the conventional Born formula does not give the\nprobability of equality relation for a pair of arbitrary observables, since the\nBorn formula gives the probability distribution only for a commuting family of\nobservables. In this paper, quantum set theory developed by Takeuti and the\npresent author is used to systematically extend the probabilistic\ninterpretation of quantum theory to define the probability of equality relation\nfor a pair of arbitrary observables. Applications of this new interpretation to\nmeasurement theory are discussed briefly.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 02:59:43 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Ozawa", "Masanao", "", "Nagoya University"]]}, {"id": "1412.8541", "submitter": "EPTCS", "authors": "Rui Soares Barbosa (Department of Computer Science, University of\n  Oxford)", "title": "On monogamy of non-locality and macroscopic averages: examples and\n  preliminary results", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 36-55", "doi": "10.4204/EPTCS.172.4", "report-no": null, "categories": "quant-ph cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a connection between monogamy of non-locality and a weak\nmacroscopic locality condition: the locality of the average behaviour. These\nare revealed by our analysis as being two sides of the same coin.\n  Moreover, we exhibit a structural reason for both in the case of Bell-type\nmultipartite scenarios, shedding light on but also generalising the results in\nthe literature [Ramanathan et al., Phys. Rev. Lett. 107, 060405 (2001);\nPawlowski & Brukner, Phys. Rev. Lett. 102, 030403 (2009)]. More specifically,\nwe show that, provided the number of particles in each site is large enough\ncompared to the number of allowed measurement settings, and whatever the\nmicroscopic state of the system, the macroscopic average behaviour is local\nrealistic, or equivalently, general multipartite monogamy relations hold.\n  This result relies on a classical mathematical theorem by Vorob'ev [Theory\nProbab. Appl. 7(2), 147-163 (1962)] about extending compatible families of\nprobability distributions defined on the faces of a simplicial complex -- in\nthe language of the sheaf-theoretic framework of Abramsky & Brandenburger [New\nJ. Phys. 13, 113036 (2011)], such families correspond to no-signalling\nempirical models, and the existence of an extension corresponds to locality or\nnon-contextuality. Since Vorob'ev's theorem depends solely on the structure of\nthe simplicial complex, which encodes the compatibility of the measurements,\nand not on the specific probability distributions (i.e. the empirical models),\nour result about monogamy relations and locality of macroscopic averages holds\nnot just for quantum theory, but for any empirical model satisfying the\nno-signalling condition.\n  In this extended abstract, we illustrate our approach by working out a couple\nof examples, which convey the intuition behind our analysis while keeping the\ndiscussion at an elementary level.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 03:00:17 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Barbosa", "Rui Soares", "", "Department of Computer Science, University of\n  Oxford"]]}, {"id": "1412.8542", "submitter": "EPTCS", "authors": "Kohei Kishida (University of Oxford)", "title": "Stochastic Relational Presheaves and Dynamic Logic for Contextuality", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 115-132", "doi": "10.4204/EPTCS.172.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presheaf models provide a formulation of labelled transition systems that is\nuseful for, among other things, modelling concurrent computation. This paper\naims to extend such models further to represent stochastic dynamics such as\nshown in quantum systems. After reviewing what presheaf models represent and\nwhat certain operations on them mean in terms of notions such as internal and\nexternal choices, composition of systems, and so on, I will show how to extend\nthose models and ideas by combining them with ideas from other\ncategory-theoretic approaches to relational models and to stochastic processes.\nIt turns out that my extension yields a transitional formulation of\nsheaf-theoretic structures that Abramsky and Brandenburger proposed to\ncharacterize non-locality and contextuality. An alternative characterization of\ncontextuality will then be given in terms of a dynamic modal logic of the\nmodels I put forward.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 03:01:14 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Kishida", "Kohei", "", "University of Oxford"]]}, {"id": "1412.8543", "submitter": "EPTCS", "authors": "Robin Adams (Radboud University Nijmegen)", "title": "QPEL: Quantum Program and Effect Language", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 133-153", "doi": "10.4204/EPTCS.172.10", "report-no": null, "categories": "cs.LO cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the syntax and rules of deduction of QPEL (Quantum Program and\nEffect Language), a language for describing both quantum programs, and\nproperties of quantum programs - effects on the appropriate Hilbert space. We\nshow how semantics may be given in terms of state-and-effect triangles, a\ncategorical setting that allows semantics in terms of Hilbert spaces,\nC*-algebras, and other categories. We prove soundness and completeness results\nthat show the derivable judgements are exactly those provable in all\nstate-and-effect triangles.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 03:01:23 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Adams", "Robin", "", "Radboud University Nijmegen"]]}, {"id": "1412.8545", "submitter": "EPTCS", "authors": "Kenta Cho (Radboud University Nijmegen)", "title": "Semantics for a Quantum Programming Language by Operator Algebras", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 165-190", "doi": "10.4204/EPTCS.172.12", "report-no": null, "categories": "cs.LO math.OA quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel semantics for a quantum programming language by\noperator algebras, which are known to give a formulation for quantum theory\nthat is alternative to the one by Hilbert spaces. We show that the opposite\ncategory of the category of W*-algebras and normal completely positive\nsubunital maps is an elementary quantum flow chart category in the sense of\nSelinger. As a consequence, it gives a denotational semantics for Selinger's\nfirst-order functional quantum programming language QPL. The use of operator\nalgebras allows us to accommodate infinite structures and to handle classical\nand quantum computations in a unified way.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 03:01:51 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Cho", "Kenta", "", "Radboud University Nijmegen"]]}, {"id": "1412.8546", "submitter": "EPTCS", "authors": "Kazuya Yasuda (The University of Tokyo), Takahiro Kubota (The\n  University of Tokyo), Yoshihiko Kakutani (The University of Tokyo)", "title": "Observational Equivalence Using Schedulers for Quantum Processes", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 191-203", "doi": "10.4204/EPTCS.172.13", "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the study of quantum process algebras, researchers have introduced\ndifferent notions of equivalence between quantum processes like bisimulation or\nbarbed congruence. However, there are intuitively equivalent quantum processes\nthat these notions do not regard as equivalent. In this paper, we introduce a\nnotion of equivalence named observational equivalence into qCCS. Since quantum\nprocesses have both probabilistic and nondeterministic transitions, we\nintroduce schedulers that solve nondeterministic choices and obtain probability\ndistribution of quantum processes. By definition, the restrictions of\nschedulers change observational equivalence. We propose some definitions of\nschedulers, and investigate the relation between the restrictions of schedulers\nand observational equivalence.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 03:02:00 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Yasuda", "Kazuya", "", "The University of Tokyo"], ["Kubota", "Takahiro", "", "The\n  University of Tokyo"], ["Kakutani", "Yoshihiko", "", "The University of Tokyo"]]}, {"id": "1412.8548", "submitter": "EPTCS", "authors": "Krzysztof Bar (Department of Computer Science, University of Oxford),\n  Jamie Vicary (Department of Computer Science, University of Oxford)", "title": "A 2-Categorical Analysis of Complementary Families, Quantum Key\n  Distribution and the Mean King Problem", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 316-332", "doi": "10.4204/EPTCS.172.23", "report-no": null, "categories": "cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of 2-categorical technology for describing and\nreasoning about complex quantum procedures. We give syntactic definitions of a\nfamily of complementary measurements, and of quantum key distribution, and show\nthat they are equivalent. We then show abstractly that either structure gives a\nsolution to the Mean King problem, which we also formulate 2-categorically.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 03:04:40 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Bar", "Krzysztof", "", "Department of Computer Science, University of Oxford"], ["Vicary", "Jamie", "", "Department of Computer Science, University of Oxford"]]}, {"id": "1412.8552", "submitter": "EPTCS", "authors": "Aleks Kissinger (University of Oxford), David Quick (University of\n  Oxford)", "title": "Tensors, !-graphs, and non-commutative quantum structures", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 56-67", "doi": "10.4204/EPTCS.172.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical quantum mechanics (CQM) and the theory of quantum groups rely\nheavily on the use of structures that have both an algebraic and co-algebraic\ncomponent, making them well-suited for manipulation using diagrammatic\ntechniques. Diagrams allow us to easily form complex compositions of\n(co)algebraic structures, and prove their equality via graph rewriting. One of\nthe biggest challenges in going beyond simple rewriting-based proofs is\ndesigning a graphical language that is expressive enough to prove interesting\nproperties (e.g. normal form results) about not just single diagrams, but\nentire families of diagrams. One candidate is the language of !-graphs, which\nconsist of graphs with certain subgraphs marked with boxes (called !-boxes)\nthat can be repeated any number of times. New !-graph equations can then be\nproved using a powerful technique called !-box induction. However, previously\nthis technique only applied to commutative (or cocommutative) algebraic\nstructures, severely limiting its applications in some parts of CQM and\n(especially) quantum groups. In this paper, we fix this shortcoming by offering\na new semantics for non-commutative !-graphs using an enriched version of\nPenrose's abstract tensor notation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 03:38:03 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Kissinger", "Aleks", "", "University of Oxford"], ["Quick", "David", "", "University of\n  Oxford"]]}, {"id": "1412.8739", "submitter": "Wlodzimierz Drabent", "authors": "W{\\l}odzimierz Drabent", "title": "Correctness and completeness of logic programs", "comments": "29 pages, 2 figures; with editorial modifications, small corrections\n  and extensions. arXiv admin note: text overlap with arXiv:1411.3015. Overlaps\n  explained in \"Related Work\" (p. 21)", "journal-ref": "ACM Transactions on Computational Logic, 17, 3, Article 18 (May\n  2016)", "doi": "10.1145/2898434", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss proving correctness and completeness of definite clause logic\nprograms. We propose a method for proving completeness, while for proving\ncorrectness we employ a method which should be well known but is often\nneglected. Also, we show how to prove completeness and correctness in the\npresence of SLD-tree pruning, and point out that approximate specifications\nsimplify specifications and proofs.\n  We compare the proof methods to declarative diagnosis (algorithmic\ndebugging), showing that approximate specifications eliminate a major drawback\nof the latter. We argue that our proof methods reflect natural declarative\nthinking about programs, and that they can be used, formally or informally, in\nevery-day programming.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 19:24:45 GMT"}, {"version": "v2", "created": "Sun, 17 May 2015 09:38:24 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Drabent", "W\u0142odzimierz", ""]]}]