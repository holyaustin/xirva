[{"id": "1002.0172", "submitter": "Florian Widmann", "authors": "Rajeev Gor\\'e and Florian Widmann", "title": "Optimal and Cut-free Tableaux for Propositional Dynamic Logic with\n  Converse", "comments": "30 pages, minor improvements, some typos, change of title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an optimal (EXPTIME), sound and complete tableau-based algorithm for\ndeciding satisfiability for propositional dynamic logic with converse (CPDL)\nwhich does not require the use of analytic cut. Our main contribution is a\nsound methodto combine our previous optimal method for tracking least\nfix-points in PDL with our previous optimal method for handling converse in the\ndescription logic ALCI. The extension is non-trivial as the two methods cannot\nbe combined naively. We give sufficient details to enable an implementation by\nothers. Our OCaml implementation seems to be the first theorem prover for CPDL.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2010 02:06:47 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2010 11:16:15 GMT"}], "update_date": "2010-04-16", "authors_parsed": [["Gor\u00e9", "Rajeev", ""], ["Widmann", "Florian", ""]]}, {"id": "1002.0930", "submitter": "EPTCS", "authors": "Hugo A. L\\'opez (IT University of Copenhagen), Carlos Olarte (\\'Ecole\n  Polytechnique - Universidad Javeriana Cali), Jorge A. P\\'erez (University of\n  Bologna)", "title": "Towards a Unified Framework for Declarative Structured Communications", "comments": null, "journal-ref": "EPTCS 17, 2010, pp. 1-15", "doi": "10.4204/EPTCS.17.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework for the declarative analysis of structured\ncommunications. By relying on a (timed) concurrent constraint programming\nlanguage, we show that in addition to the usual operational techniques from\nprocess calculi, the analysis of structured communications can elegantly\nexploit logic-based reasoning techniques. We introduce a declarative\ninterpretation of the language for structured communications proposed by Honda,\nVasconcelos, and Kubo. Distinguishing features of our approach are: the\npossibility of including partial information (constraints) in the session\nmodel; the use of explicit time for reasoning about session duration and\nexpiration; a tight correspondence with logic, which formally relates session\nexecution and linear-time temporal logic formulas.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2010 09:19:23 GMT"}], "update_date": "2010-02-05", "authors_parsed": [["L\u00f3pez", "Hugo A.", "", "IT University of Copenhagen"], ["Olarte", "Carlos", "", "\u00c9cole\n  Polytechnique - Universidad Javeriana Cali"], ["P\u00e9rez", "Jorge A.", "", "University of\n  Bologna"]]}, {"id": "1002.0935", "submitter": "EPTCS", "authors": "Marco Carbone (IT University of Copenhagen), Joshua Guttman (Worcester\n  Polytechnic Institute)", "title": "Execution Models for Choreographies and Cryptoprotocols", "comments": null, "journal-ref": "EPTCS 17, 2010, pp. 31-41", "doi": "10.4204/EPTCS.17.3", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A choreography describes a transaction in which several principals interact.\nSince choreographies frequently describe business processes affecting\nsubstantial assets, we need a security infrastructure in order to implement\nthem safely. As part of a line of work devoted to generating cryptoprotocols\nfrom choreographies, we focus here on the execution models suited to the two\nlevels.\n  We give a strand-style semantics for choreographies, and propose a special\nexecution model in which choreography-level messages are faithfully delivered\nexactly once. We adapt this model to handle multiparty protocols in which some\nparticipants may be compromised.\n  At level of cryptoprotocols, we use the standard Dolev-Yao execution model,\nwith one alteration. Since many implementations use a \"nonce cache\" to discard\nmultiply delivered messages, we provide a semantics for at-most-once delivery.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2010 09:36:47 GMT"}], "update_date": "2010-02-05", "authors_parsed": [["Carbone", "Marco", "", "IT University of Copenhagen"], ["Guttman", "Joshua", "", "Worcester\n  Polytechnic Institute"]]}, {"id": "1002.1422", "submitter": "M. H. van Emden", "authors": "M.H. van Emden", "title": "Integrating Interval Constraints into Logic Programming", "comments": "21 pages, 2 tables, no figures", "journal-ref": null, "doi": null, "report-no": "DCS-133-IR", "categories": "cs.PL cs.LO cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CLP scheme uses Horn clauses and SLD resolution to generate multiple\nconstraint satisfaction problems (CSPs). The possible CSPs include rational\ntrees (giving Prolog) and numerical algorithms for solving linear equations and\nlinear programs (giving CLP(R)). In this paper we develop a form of CSP for\ninterval constraints. In this way one obtains a logic semantics for the\nefficient floating-point hardware that is available on most computers.\n  The need for the method arises because in the practice of scheduling and\nengineering design it is not enough to solve a single CSP. Ideally one should\nbe able to consider thousands of CSPs and efficiently solve them or show them\nto be unsolvable. This is what CLP/NCSP, the new subscheme of CLP described in\nthis paper is designed to do.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2010 00:03:40 GMT"}], "update_date": "2010-02-09", "authors_parsed": [["van Emden", "M. H.", ""]]}, {"id": "1002.1464", "submitter": "Anthony Widjaja To", "authors": "Anthony Widjaja To", "title": "Parikh Images of Regular Languages: Complexity and Applications", "comments": "Full version of submission to LICS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Parikh image of the language of an NFA with n states over an\nalphabet of size k can be described as a finite union of linear sets with at\nmost k generators and total size 2^{O(k^2 log n)}, i.e., polynomial for all\nfixed k >= 1. Previously, it was not known whether the number of generators\ncould be made independent of n, and best upper bounds on the total size were\nexponential in n. Furthermore, we give an algorithm for performing such a\ntranslation in time 2^{O(k^2 log(kn))}. Our proof exploits a previously unknown\nconnection to the theory of convex sets, and establishes a normal form theorem\nfor semilinear sets, which is of independent interests. To complement these\nresults, we show that our upper bounds are tight and that the results cannot be\nextended to context-free languages. We give four applications: (1) a new\npolynomial fragment of integer programming, (2) precise complexity of\nmembership for Parikh images of NFAs, (3) an answer to an open question about\npolynomial PAC-learnability of semilinear sets, and (4) an optimal algorithm\nfor LTL model checking over discrete-timed reversal-bounded counter systems.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2010 16:00:56 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2010 20:29:57 GMT"}], "update_date": "2010-02-12", "authors_parsed": [["To", "Anthony Widjaja", ""]]}, {"id": "1002.1796", "submitter": "Carlo Alberto Furia", "authors": "Paul Z. Kolano, Carlo A. Furia, Richard A. Kemmerer, Dino Mandrioli", "title": "Refinement and Verification of Real-Time Systems", "comments": "59 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses highly general mechanisms for specifying the refinement\nof a real-time system as a collection of lower level parallel components that\npreserve the timing and functional requirements of the upper level\nspecification. These mechanisms are discussed in the context of ASTRAL, which\nis a formal specification language for real-time systems. Refinement is\naccomplished by mapping all of the elements of an upper level specification\ninto lower level elements that may be split among several parallel components.\nIn addition, actions that can occur in the upper level are mapped to actions of\ncomponents operating at the lower level. This allows several types of\nimplementation strategies to be specified in a natural way, while the price for\ngenerality (in terms of complexity) is paid only when necessary. The refinement\nmechanisms are first illustrated using a simple digital circuit; then, through\na highly complex phone system; finally, design guidelines gleaned from these\nspecifications are presented.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2010 08:46:24 GMT"}], "update_date": "2010-02-10", "authors_parsed": [["Kolano", "Paul Z.", ""], ["Furia", "Carlo A.", ""], ["Kemmerer", "Richard A.", ""], ["Mandrioli", "Dino", ""]]}, {"id": "1002.1833", "submitter": "Rafael Caballero", "authors": "F.J. L\\'opez-Fraguas, J. Rodr\\'iguez-Hortal\\'a", "title": "The Full Abstraction Problem for Higher Order Functional-Logic Programs", "comments": null, "journal-ref": "WLPE 2009 Proceedings", "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing suitable formal semantics can be of great help in the\nunderstanding, design and implementation of a programming language, and act as\na guide for software development tools like analyzers or partial evaluators. In\nthis sense, full abstraction is a highly desirable property, indicating a\nperfect correspondence between the semantics and the observable behavior of\nprogram pieces. In this work we address the question of full abstraction for\nthe family of modern functional logic languages, in which functions can be\nhigher order and non-deterministic, and where the semantics adopted for\nnon-determinism is \\emph{call-time choice}. We show that, with respect to\nnatural notions of \\emph{observation}, any semantics based on\n\\emph{extensional} functions is necessarily unsound; in contrast, we show that\nthe higher order version of \\emph{CRWL}, a well-known existing semantic\nframework for functional logic programming, based on an \\emph{intensional} view\nof functions, turns out to be fully abstract and compositional.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2010 12:08:35 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["L\u00f3pez-Fraguas", "F. J.", ""], ["Rodr\u00edguez-Hortal\u00e1", "J.", ""]]}, {"id": "1002.1836", "submitter": "Rafael Caballero", "authors": "F. Bueno, J. Navas, and M. Hermenegildo", "title": "Towards Parameterized Regular Type Inference Using Set Constraints", "comments": null, "journal-ref": "WLPE 2009 Proceedings", "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for inferring \\emph{parameterized regular types} for\nlogic programs as solutions for systems of constraints over sets of finite\nground Herbrand terms (set constraint systems). Such parameterized regular\ntypes generalize \\emph{parametric} regular types by extending the scope of the\nparameters in the type definitions so that such parameters can relate the types\nof different predicates. We propose a number of enhancements to the procedure\nfor solving the constraint systems that improve the precision of the type\ndescriptions inferred. The resulting algorithm, together with a procedure to\nestablish a set constraint system from a logic program, yields a program\nanalysis that infers tighter safe approximations of the success types of the\nprogram than previous comparable work, offering a new and useful efficiency vs.\nprecision trade-off. This is supported by experimental results, which show the\nfeasibility of our analysis.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2010 12:21:31 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Bueno", "F.", ""], ["Navas", "J.", ""], ["Hermenegildo", "M.", ""]]}, {"id": "1002.2236", "submitter": "Khalil Ghorbal", "authors": "Khalil Ghorbal, Eric Goubault, Sylvie Putot", "title": "A Logical Product Approach to Zonotope Intersection", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-14295-6_22", "report-no": null, "categories": "cs.LO cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and study a new abstract domain which is a fine-grained combination\nof zonotopes with polyhedric domains such as the interval, octagon, linear\ntemplates or polyhedron domain. While abstract transfer functions are still\nrather inexpensive and accurate even for interpreting non-linear computations,\nwe are able to also interpret tests (i.e. intersections) efficiently. This\nfixes a known drawback of zonotopic methods, as used for reachability analysis\nfor hybrid sys- tems as well as for invariant generation in abstract\ninterpretation: intersection of zonotopes are not always zonotopes, and there\nis not even a best zonotopic over-approximation of the intersection. We\ndescribe some examples and an im- plementation of our method in the APRON\nlibrary, and discuss some further in- teresting combinations of zonotopes with\nnon-linear or non-convex domains such as quadratic templates and maxplus\npolyhedra.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2010 23:08:49 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2010 13:08:41 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2010 10:02:17 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["Ghorbal", "Khalil", ""], ["Goubault", "Eric", ""], ["Putot", "Sylvie", ""]]}, {"id": "1002.2578", "submitter": "Dimitri Hendriks", "authors": "Joerg Endrullis, Dimitri Hendriks and Jan Willem Klop", "title": "Modular Construction of Fixed Point Combinators and Clocked Boehm Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fixed point combinators (and their generalization: looping combinators) are\nclassic notions belonging to the heart of lambda-calculus and logic. We start\nwith an exploration of the structure of fixed point combinators (fpc's), vastly\ngeneralizing the well-known fact that if Y is an fpc, Y(SI) is again an fpc,\ngenerating the Boehm sequence of fpc's. Using the infinitary lambda-calculus we\ndevise infinitely many other generation schemes for fpc's. In this way we find\nschemes and building blocks to construct new fpc's in a modular way.\n  Having created a plethora of new fixed point combinators, the task is to\nprove that they are indeed new. That is, we have to prove their\nbeta-inconvertibility. Known techniques via Boehm Trees do not apply, because\nall fpc's have the same Boehm Tree (BT). Therefore, we employ `clocked BT's',\nwith annotations that convey information of the tempo in which the data in the\nBT are produced. BT's are thus enriched with an intrinsic clock behaviour,\nleading to a refined discrimination method for lambda-terms. The corresponding\nequality is strictly intermediate between beta-convertibility and BT-equality,\nthe equality in the classical models of lambda-calculus. An analogous approach\npertains to Levy-Longo Berarducci trees. Finally, we increase the\ndiscrimination power by a precision of the clock notion that we call `atomic\nclock'.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2010 15:49:51 GMT"}], "update_date": "2010-02-15", "authors_parsed": [["Endrullis", "Joerg", ""], ["Hendriks", "Dimitri", ""], ["Klop", "Jan Willem", ""]]}, {"id": "1002.2800", "submitter": "Vasco Brattka", "authors": "Vasco Brattka, Matthew de Brecht and Arno Pauly", "title": "Closed Choice and a Uniform Low Basis Theorem", "comments": null, "journal-ref": "Annals of Pure and Applied Logic 163:8 (2012) 986--1008", "doi": "10.1016/j.apal.2011.12.020", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study closed choice principles for different spaces. Given information\nabout what does not constitute a solution, closed choice determines a solution.\nWe show that with closed choice one can characterize several models of\nhypercomputation in a uniform framework using Weihrauch reducibility. The\nclasses of functions which are reducible to closed choice of the singleton\nspace, of the natural numbers, of Cantor space and of Baire space correspond to\nthe class of computable functions, of functions computable with finitely many\nmind changes, of weakly computable functions and of effectively Borel\nmeasurable functions, respectively. We also prove that all these classes\ncorrespond to classes of non-deterministically computable functions with the\nrespective spaces as advice spaces. Moreover, we prove that closed choice on\nEuclidean space can be considered as \"locally compact choice\" and it is\nobtained as product of closed choice on the natural numbers and on Cantor\nspace. We also prove a Quotient Theorem for compact choice which shows that\nsingle-valued functions can be \"divided\" by compact choice in a certain sense.\nAnother result is the Independent Choice Theorem, which provides a uniform\nproof that many choice principles are closed under composition. Finally, we\nalso study the related class of low computable functions, which contains the\nclass of weakly computable functions as well as the class of functions\ncomputable with finitely many mind changes. As one main result we prove a\nuniform version of the Low Basis Theorem that states that closed choice on\nCantor space (and the Euclidean space) is low computable. We close with some\nrelated observations on the Turing jump operation and its initial topology.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2010 21:17:54 GMT"}, {"version": "v2", "created": "Tue, 28 Sep 2010 11:05:22 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Brattka", "Vasco", ""], ["de Brecht", "Matthew", ""], ["Pauly", "Arno", ""]]}, {"id": "1002.2864", "submitter": "EPTCS", "authors": "Luca Aceto (Reykjavik University), Matteo Cimini (Reykjavik\n  University), Anna Ingolfsdottir (Reykjavik University)", "title": "A Bisimulation-based Method for Proving the Validity of Equations in\n  GSOS Languages", "comments": null, "journal-ref": "EPTCS 18, 2010, pp. 1-16", "doi": "10.4204/EPTCS.18.1", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a bisimulation-based method for establishing the\nsoundness of equations between terms constructed using operations whose\nsemantics is specified by rules in the GSOS format of Bloom, Istrail and Meyer.\nThe method is inspired by de Simone's FH-bisimilarity and uses transition rules\nas schematic transitions in a bisimulation-like relation between open terms.\nThe soundness of the method is proven and examples showing its applicability\nare provided. The proposed bisimulation-based proof method is incomplete, but\nthe article offers some completeness results for restricted classes of GSOS\nspecifications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 12:08:08 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Aceto", "Luca", "", "Reykjavik University"], ["Cimini", "Matteo", "", "Reykjavik\n  University"], ["Ingolfsdottir", "Anna", "", "Reykjavik University"]]}, {"id": "1002.2867", "submitter": "EPTCS", "authors": "Magnus Johansson (Uppsala University), Bj\\\"orn Victor (Uppsala\n  University), Joachim Parrow (Uppsala University)", "title": "A Fully Abstract Symbolic Semantics for Psi-Calculi", "comments": null, "journal-ref": "EPTCS 18, 2010, pp. 17-31", "doi": "10.4204/EPTCS.18.2", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a symbolic transition system and bisimulation equivalence for\npsi-calculi, and show that it is fully abstract with respect to bisimulation\ncongruence in the non-symbolic semantics.\n  A psi-calculus is an extension of the pi-calculus with nominal data types for\ndata structures and for logical assertions representing facts about data. These\ncan be transmitted between processes and their names can be statically scoped\nusing the standard pi-calculus mechanism to allow for scope migrations.\nPsi-calculi can be more general than other proposed extensions of the\npi-calculus such as the applied pi-calculus, the spi-calculus, the fusion\ncalculus, or the concurrent constraint pi-calculus.\n  Symbolic semantics are necessary for an efficient implementation of the\ncalculus in automated tools exploring state spaces, and the full abstraction\nproperty means the semantics of a process does not change from the original.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 12:30:43 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Johansson", "Magnus", "", "Uppsala University"], ["Victor", "Bj\u00f6rn", "", "Uppsala\n  University"], ["Parrow", "Joachim", "", "Uppsala University"]]}, {"id": "1002.2868", "submitter": "EPTCS", "authors": "MohammadReza Mousavi (Eindhoven University of Technology)", "title": "Causality in the Semantics of Esterel: Revisited", "comments": null, "journal-ref": "EPTCS 18, 2010, pp. 32-45", "doi": "10.4204/EPTCS.18.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We re-examine the challenges concerning causality in the semantics of Esterel\nand show that they pertain to the known issues in the semantics of Structured\nOperational Semantics with negative premises. We show that the solutions\noffered for the semantics of SOS also provide answers to the semantic\nchallenges of Esterel and that they satisfy the intuitive requirements set by\nthe language designers.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 12:35:17 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Mousavi", "MohammadReza", "", "Eindhoven University of Technology"]]}, {"id": "1002.2869", "submitter": "EPTCS", "authors": "Filippo Bonchi (CWI Amsterdam), Fabio Gadducci (Universit\\`a di Pisa),\n  Giacoma Valentina Monreale (Universit\\`a di Pisa)", "title": "On Barbs and Labels in Reactive Systems", "comments": null, "journal-ref": "EPTCS 18, 2010, pp. 46-61", "doi": "10.4204/EPTCS.18.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive systems (RSs) represent a meta-framework aimed at deriving\nbehavioral congruences for those computational formalisms whose operational\nsemantics is provided by reduction rules. RSs proved a flexible specification\ndevice, yet so far most of the efforts dealing with their behavioural semantics\nfocused on idem pushouts (IPOs) and saturated (also known as dynamic)\nbisimulations. In this paper we introduce a novel, intermediate behavioural\nequivalence: L-bisimilarity, which is able to recast both its IPO and saturated\ncounterparts. The equivalence is parametric with respect to a set L of RSs\nlabels, and it is shown that under mild conditions on L it is indeed a\ncongruence. Furthermore, L-bisimilarity can also recast the notion of barbed\nsemantics for RSs, proposed by the same authors in a previous paper. In order\nto provide a suitable test-bed, we instantiate our proposal by addressing the\nsemantics of (asynchronous) CCS and of the calculus of mobile ambients.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 12:38:56 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Bonchi", "Filippo", "", "CWI Amsterdam"], ["Gadducci", "Fabio", "", "Universit\u00e0 di Pisa"], ["Monreale", "Giacoma Valentina", "", "Universit\u00e0 di Pisa"]]}, {"id": "1002.2871", "submitter": "EPTCS", "authors": "Iain Phillips (Imperial College London), Irek Ulidowski (University of\n  Leicester)", "title": "Reverse Bisimulations on Stable Configuration Structures", "comments": null, "journal-ref": "EPTCS 18, 2010, pp. 62-76", "doi": "10.4204/EPTCS.18.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationships between various equivalences on configuration structures,\nincluding interleaving bisimulation (IB), step bisimulation (SB) and hereditary\nhistory-preserving (HH) bisimulation, have been investigated by van Glabbeek\nand Goltz (and later Fecher). Since HH bisimulation may be characterised by the\nuse of reverse as well as forward transitions, it is of interest to investigate\nforms of IB and SB where both forward and reverse transitions are allowed. We\ngive various characterisations of reverse SB, showing that forward steps do not\nadd extra power. We strengthen Bednarczyk's result that, in the absence of\nauto-concurrency, reverse IB is as strong as HH bisimulation, by showing that\nwe need only exclude auto-concurrent events at the same depth in the\nconfiguration.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 12:43:41 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Phillips", "Iain", "", "Imperial College London"], ["Ulidowski", "Irek", "", "University of\n  Leicester"]]}, {"id": "1002.2872", "submitter": "EPTCS", "authors": "Gilles Dowek (\\'Ecole Polytechnique and INRIA), C\\'esar Mu\\~noz\n  (National Institute of Aerospace), Camilo Rocha (University of Illinois)", "title": "Rewriting Logic Semantics of a Plan Execution Language", "comments": null, "journal-ref": "EPTCS 18, 2010, pp. 77-91", "doi": "10.4204/EPTCS.18.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Plan Execution Interchange Language (PLEXIL) is a synchronous language\ndeveloped by NASA to support autonomous spacecraft operations. In this paper,\nwe propose a rewriting logic semantics of PLEXIL in Maude, a high-performance\nlogical engine. The rewriting logic semantics is by itself a formal interpreter\nof the language and can be used as a semantic benchmark for the implementation\nof PLEXIL executives. The implementation in Maude has the additional benefit of\nmaking available to PLEXIL designers and developers all the formal analysis and\nverification tools provided by Maude. The formalization of the PLEXIL semantics\nin rewriting logic poses an interesting challenge due to the synchronous nature\nof the language and the prioritized rules defining its semantics. To overcome\nthis difficulty, we propose a general procedure for simulating synchronous set\nrelations in rewriting logic that is sound and, for deterministic relations,\ncomplete. We also report on two issues at the design level of the original\nPLEXIL semantics that were identified with the help of the executable\nspecification in Maude.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 12:48:09 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Dowek", "Gilles", "", "\u00c9cole Polytechnique and INRIA"], ["Mu\u00f1oz", "C\u00e9sar", "", "National Institute of Aerospace"], ["Rocha", "Camilo", "", "University of Illinois"]]}, {"id": "1002.2873", "submitter": "EPTCS", "authors": "Michel A. Reniers (Eindhoven University of Technology), Tim A.C.\n  Willemse (Eindhoven University of Technology)", "title": "Analysis of Boolean Equation Systems through Structure Graphs", "comments": null, "journal-ref": "EPTCS 18, 2010, pp. 92-107", "doi": "10.4204/EPTCS.18.7", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the problem of solving Boolean equation systems through the use of\nstructure graphs. The latter are obtained through an elegant set of\nPlotkin-style deduction rules. Our main contribution is that we show that\nequation systems with bisimilar structure graphs have the same solution. We\nshow that our work conservatively extends earlier work, conducted by Keiren and\nWillemse, in which dependency graphs were used to analyse a subclass of Boolean\nequation systems, viz., equation systems in standard recursive form. We\nillustrate our approach by a small example, demonstrating the effect of\nsimplifying an equation system through minimisation of its structure graph.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 12:51:45 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Reniers", "Michel A.", "", "Eindhoven University of Technology"], ["Willemse", "Tim A. C.", "", "Eindhoven University of Technology"]]}, {"id": "1002.2954", "submitter": "Phuong Nguyen", "authors": "Phuong Nguyen, Stephen Cook", "title": "The Complexity of Proving the Discrete Jordan Curve Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Jordan Curve Theorem (JCT) states that a simple closed curve divides the\nplane into exactly two connected regions. We formalize and prove the theorem in\nthe context of grid graphs, under different input settings, in theories of\nbounded arithmetic that correspond to small complexity classes. The theory\n$V^0(2)$ (corresponding to $AC^0(2)$) proves that any set of edges that form\ndisjoint cycles divides the grid into at least two regions. The theory $V^0$\n(corresponding to $AC^0$) proves that any sequence of edges that form a simple\nclosed curve divides the grid into exactly two regions. As a consequence, the\nHex tautologies and the st-connectivity tautologies have polynomial size\n$AC^0(2)$-Frege-proofs, which improves results of Buss which only apply to the\nstronger proof system $TC^0$-Frege.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 21:32:42 GMT"}], "update_date": "2010-02-17", "authors_parsed": [["Nguyen", "Phuong", ""], ["Cook", "Stephen", ""]]}, {"id": "1002.2978", "submitter": "EPTCS", "authors": "Bartek Klin (University of Cambridge, Warsaw University), Pawe{\\l}\n  Soboci\\'nski (University of Southampton)", "title": "Proceedings Sixth Workshop on Structural Operational Semantics", "comments": null, "journal-ref": "EPTCS 18, 2010", "doi": "10.4204/EPTCS.18", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of SOS 2009, the Sixth Workshop on\nStructural Operational Semantics held on the 31st of August 2009 in Bologna,\nItaly as a affiliated workshop of CONCUR 2009, the 20th International\nConference on Concurrency Theory.\n  Structural operational semantics (SOS) is a technique for defining\noperational semantics for programming and specification languages. The workshop\nis forum for researchers, students and practitioners interested in new\ndevelopments and directions for future investigations in the area of SOS. One\nof the specific goals of the workshop is to provide a meeting point for the\nconcurrency and programming language communities. Another goal is the\ndissemination of the theory and practice of SOS amongst postgraduate students\nand young researchers worldwide.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 23:32:42 GMT"}], "update_date": "2010-02-17", "authors_parsed": [["Klin", "Bartek", "", "University of Cambridge, Warsaw University"], ["Soboci\u0144ski", "Pawe\u0142", "", "University of Southampton"]]}, {"id": "1002.3083", "submitter": "Rafael Caballero", "authors": "Hai-Feng Guo, Wen Zheng, Mahadevan Subramaniam", "title": "L2C2: Logic-based LSC Consistency Checking", "comments": "To be included in the on-line proceedings of WLPE'2009", "journal-ref": "WLPE 2009 proceedings", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Live sequence charts (LSCs) have been proposed as an inter-object\nscenario-based specification and visual programming language for reactive\nsystems. In this paper, we introduce a logic-based framework to check the\nconsistency of an LSC specification. An LSC simulator has been implemented in\nlogic programming, utilizing a memoized depth-first search strategy, to show\nhow a reactive system in LSCs would response to a set of external event\nsequences. A formal notation is defined to specify external event sequences,\nextending the regular expression with a parallel operator and a testing\ncontrol. The parallel operator allows interleaved parallel external events to\nbe tested in LSCs simultaneously; while the testing control provides users to a\nnew approach to specify and test certain temporal properties (e.g., CTL\nformula) in a form of LSC. Our framework further provides either a state\ntransition graph or a failure trace to justify the consistency checking\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2010 14:09:43 GMT"}], "update_date": "2010-02-17", "authors_parsed": [["Guo", "Hai-Feng", ""], ["Zheng", "Wen", ""], ["Subramaniam", "Mahadevan", ""]]}, {"id": "1002.3131", "submitter": "Daniel de Carvalho", "authors": "Daniel de Carvalho and Lorenzo Tortora de Falco", "title": "The relational model is injective for Multiplicative Exponential Linear\n  Logic (without weakenings)", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for Multiplicative Exponential Linear Logic (without weakenings)\nthe syntactical equivalence relation on proofs induced by cut-elimination\ncoincides with the semantic equivalence relation on proofs induced by the\nmultiset based relational model: one says that the interpretation in the model\n(or the semantics) is injective. We actually prove a stronger result: two\ncut-free proofs of the full multiplicative and exponential fragment of linear\nlogic whose interpretations coincide in the multiset based relational model are\nthe same \"up to the connections between the doors of exponential boxes\".\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2010 19:20:03 GMT"}, {"version": "v2", "created": "Mon, 7 Feb 2011 18:59:34 GMT"}], "update_date": "2011-02-08", "authors_parsed": [["de Carvalho", "Daniel", ""], ["de Falco", "Lorenzo Tortora", ""]]}, {"id": "1002.3222", "submitter": "Michel Reniers", "authors": "Jeroen Keiren, Michel A. Reniers, and Tim A.C. Willemse", "title": "Structural Analysis of Boolean Equation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the problem of solving Boolean equation systems through the use of\nstructure graphs. The latter are obtained through an elegant set of\nPlotkin-style deduction rules. Our main contribution is that we show that\nequation systems with bisimilar structure graphs have the same solution. We\nshow that our work conservatively extends earlier work, conducted by Keiren and\nWillemse, in which dependency graphs were used to analyse a subclass of Boolean\nequation systems, viz., equation systems in standard recursive form. We\nillustrate our approach by a small example, demonstrating the effect of\nsimplifying an equation system through minimisation of its structure graph.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2010 08:15:12 GMT"}], "update_date": "2010-02-18", "authors_parsed": [["Keiren", "Jeroen", ""], ["Reniers", "Michel A.", ""], ["Willemse", "Tim A. C.", ""]]}, {"id": "1002.3330", "submitter": "Shamim Ripon", "authors": "Shamim H. Ripon, Michael Butler", "title": "Deriving Relationship Between Semantic Models - An Approach for cCSP", "comments": "8 Pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS January 2010, ISSN 1947 5500", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 7, No. 1, pp. 47-54, January 2010, USA", "doi": null, "report-no": "Computer Science Volume 7 ISSN 19475500", "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal semantics offers a complete and rigorous definition of a language. It\nis important to define different semantic models for a language and different\nmodels serve different purposes. Building equivalence between different\nsemantic models of a language strengthen its formal foundation. This paper\nshows the derivation of denotational semantics from operational semantics of\nthe language cCSP. The aim is to show the correspondence between operational\nand trace semantics. We extract traces from operational rules and use induction\nover traces to show the correspondence between the two semantics of cCSP.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2010 20:06:19 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2010 01:12:38 GMT"}], "update_date": "2010-02-18", "authors_parsed": [["Ripon", "Shamim H.", ""], ["Butler", "Michael", ""]]}, {"id": "1002.3438", "submitter": "Jean-Louis Krivine", "authors": "Jean-Louis Krivine (PPS)", "title": "Alg\\`ebres de r\\'ealisabilit\\'e: un programme pour bien ordonner R", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a method to transform into programs, classical proofs using a well\nordering of the reals. The technics uses a generalization of Cohen's forcing\nand the theory of classical realizability introduced by the author.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2010 07:47:04 GMT"}, {"version": "v2", "created": "Mon, 31 May 2010 09:16:11 GMT"}], "update_date": "2010-06-01", "authors_parsed": [["Krivine", "Jean-Louis", "", "PPS"]]}, {"id": "1002.4061", "submitter": "EPTCS", "authors": "Ozan Kahramano\\u{g}ullari (The Microsoft Research - University of\n  Trento, Centre for Computational and Systems Biology)", "title": "Flux Analysis in Process Models via Causality", "comments": null, "journal-ref": "EPTCS 19, 2010, pp. 20-39", "doi": "10.4204/EPTCS.19.2", "report-no": null, "categories": "cs.CE cs.LO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for flux analysis in process algebra models of\nbiological systems. We perceive flux as the flow of resources in stochastic\nsimulations. We resort to an established correspondence between event\nstructures, a broadly recognised model of concurrency, and state transitions of\nprocess models, seen as Petri nets. We show that we can this way extract the\ncausal resource dependencies in simulations between individual state\ntransitions as partial orders of events. We propose transformations on the\npartial orders that provide means for further analysis, and introduce a\nsoftware tool, which implements these ideas. By means of an example of a\npublished model of the Rho GTP-binding proteins, we argue that this approach\ncan provide the substitute for flux analysis techniques on ordinary\ndifferential equation models within the stochastic setting of process algebras.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2010 06:27:29 GMT"}], "update_date": "2010-02-23", "authors_parsed": [["Kahramano\u011fullari", "Ozan", "", "The Microsoft Research - University of\n  Trento, Centre for Computational and Systems Biology"]]}, {"id": "1002.4066", "submitter": "EPTCS", "authors": "Sara Capecchi (Dipartimento di Informatica, Universit\\`a di Torino),\n  Angelo Troina (Dipartimento di Informatica, Universit\\`a di Torino)", "title": "Types for BioAmbients", "comments": null, "journal-ref": "EPTCS 19, 2010, pp. 103-115", "doi": "10.4204/EPTCS.19.7", "report-no": null, "categories": "cs.CE cs.LO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The BioAmbients calculus is a process algebra suitable for representing\ncompartmentalization, molecular localization and movements between\ncompartments. In this paper we enrich this calculus with a static type system\nclassifying each ambient with group types specifying the kind of compartments\nin which the ambient can stay. The type system ensures that, in a well-typed\nprocess, ambients cannot be nested in a way that violates the type hierarchy.\nExploiting the information given by the group types, we also extend the\noperational semantics of BioAmbients with rules signalling errors that may\nderive from undesired ambients' moves (i.e. merging incompatible tissues).\nThus, the signal of errors can help the modeller to detect and locate unwanted\nsituations that may arise in a biological system, and give practical hints on\nhow to avoid the undesired behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2010 06:42:38 GMT"}], "update_date": "2010-02-23", "authors_parsed": [["Capecchi", "Sara", "", "Dipartimento di Informatica, Universit\u00e0 di Torino"], ["Troina", "Angelo", "", "Dipartimento di Informatica, Universit\u00e0 di Torino"]]}, {"id": "1002.4286", "submitter": "Jos\\'e L Balc\\'azar", "authors": "Jose L. Balcazar", "title": "Redundancy, Deduction Schemes, and Minimum-Size Bases for Association\n  Rules", "comments": "LMCS accepted paper", "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 2 (June 27,\n  2010) lmcs:812", "doi": "10.2168/LMCS-6(2:4)2010", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Association rules are among the most widely employed data analysis methods in\nthe field of Data Mining. An association rule is a form of partial implication\nbetween two sets of binary variables. In the most common approach, association\nrules are parameterized by a lower bound on their confidence, which is the\nempirical conditional probability of their consequent given the antecedent,\nand/or by some other parameter bounds such as \"support\" or deviation from\nindependence. We study here notions of redundancy among association rules from\na fundamental perspective. We see each transaction in a dataset as an\ninterpretation (or model) in the propositional logic sense, and consider\nexisting notions of redundancy, that is, of logical entailment, among\nassociation rules, of the form \"any dataset in which this first rule holds must\nobey also that second rule, therefore the second is redundant\". We discuss\nseveral existing alternative definitions of redundancy between association\nrules and provide new characterizations and relationships among them. We show\nthat the main alternatives we discuss correspond actually to just two variants,\nwhich differ in the treatment of full-confidence implications. For each of\nthese two notions of redundancy, we provide a sound and complete deduction\ncalculus, and we show how to construct complete bases (that is,\naxiomatizations) of absolutely minimum size in terms of the number of rules. We\nexplore finally an approach to redundancy with respect to several association\nrules, and fully characterize its simplest case of two partial premises.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2010 10:02:24 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2010 22:44:45 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Balcazar", "Jose L.", ""]]}, {"id": "1002.4334", "submitter": "Abhisekh Sankaran", "authors": "Abhisekh Sankaran and Supratik Chakraborty", "title": "On Semantic Generalizations of the Bernays-Sch\\\"onfinkel-Ramsey Class\n  with Finite or Co-finite Spectra", "comments": "26 pages, no figures, submitted to LICS 2010 (decision pending); just\n  added a reference to a related work in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by model-theoretic properties of the BSR class, we present a family\nof semantic classes of FO formulae with finite or co-finite spectra over a\nrelational vocabulary \\Sigma. A class in this family is denoted\nEBS_\\Sigma(\\sigma), where \\sigma is a subset of \\Sigma. Formulae in\nEBS_\\Sigma(\\sigma) are preserved under substructures modulo a bounded core and\nmodulo re-interpretation of predicates outside \\sigma. We study properties of\nthe family EBS_\\Sigma = {EBS_\\Sigma(\\sigma) | \\sigma \\subseteq \\Sigma}, e.g.\nclasses in EBS_\\Sigma are spectrally indistinguishable, EBS_\\Sigma(\\Sigma) is\nsemantically equivalent to BSR over \\Sigma, and EBS_\\Sigma(\\emptyset) is the\nset of all FO formulae over \\Sigma with finite or co-finite spectra.\nFurthermore, (EBS_\\Sigma, \\subseteq) forms a lattice isomorphic to the powerset\nlattice (\\wp({\\Sigma}), \\subseteq). This gives a natural semantic\ngeneralization of BSR as ascending chains in (EBS_\\Sigma, \\subseteq). Many\nwell-known FO classes are semantically subsumed by EBS_\\Sigma(\\Sigma) or\nEBS_\\Sigma(\\emptyset). Our study provides alternative proofs of interesting\nresults like the Lo\\'s-Tarski Theorem and the semantic subsumption of the\nL\\\"owenheim class with equality by BSR. We also present a syntactic sub-class\nof EBS_\\Sigma(\\sigma) called EDP_\\Sigma(\\sigma) and give an expression for the\nsize of the bounded cores of models of EDP_\\Sigma(\\sigma) formulae. We show\nthat the EDP_\\Sigma(\\sigma) classes also form a lattice structure. Finally, we\nstudy some closure properties and applications of the classes presented.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2010 15:57:36 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2010 16:40:37 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Sankaran", "Abhisekh", ""], ["Chakraborty", "Supratik", ""]]}, {"id": "1002.4392", "submitter": "Serguei Mokhov", "authors": "Xin Tong, Joey Paquet, and Serguei A. Mokhov", "title": "Complete Context Calculus Design and Implementation in GIPSY", "comments": "21 page; 18 listings; 2 figures; a complete version of the referenced\n  simple context calculus implementation", "journal-ref": null, "doi": "10.1109/COMPSAC.2008.200", "report-no": null, "categories": "cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the integration into the GIPSY of Lucx's context calculus\ndefined in Wan's PhD thesis. We start by defining different types of tag sets,\nthen we explain the concept of context, the types of context and the context\ncalculus operators. Finally, we present how context entities have been\nabstracted into Java classes and embedded into the GIPSY system.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2010 19:29:43 GMT"}], "update_date": "2010-02-24", "authors_parsed": [["Tong", "Xin", ""], ["Paquet", "Joey", ""], ["Mokhov", "Serguei A.", ""]]}, {"id": "1002.4535", "submitter": "Rafael Caballero", "authors": "Rafael Caballero and John Gallagher (eds.)", "title": "Proceedings of the 19th Workshop on Logic-based methods in Programming\n  Environments (WLPE 2009)", "comments": "Html page including the links to the papers presented at the\n  Workshop. The papers are already in CoRR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at the 19th Workshop on Logic-\nbased methods in Programming Environments (WLPE'09), which was held in\nPasadena, USA, on July 14th, 2009.\n  WLPE aims at providing an informal meeting for researchers working on\nlogic-based methods and tools which support program development and analy- sis.\nThis year, we have continued and consolidated the shift in focus from en-\nvironmental tools for logic programming to logic-based environmental tools for\nprogramming in general, so that this workshop can be possibly interesting for a\nwider scientific community.\n  All the papers submitted to WLPE'09 have gone through a careful process of\npeer reviewing, with at least three reviews for each paper and a subsequent\nin-depth discussion in the Program Committee.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2010 12:27:21 GMT"}], "update_date": "2010-02-25", "authors_parsed": [["Caballero", "Rafael", "", "eds."], ["Gallagher", "John", "", "eds."]]}, {"id": "1002.4616", "submitter": "Arie Gurfinkel", "authors": "Arie Gurfinkel and Marsha Chechik", "title": "Robust Vacuity for Branching Temporal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in techniques for detecting whether a logic\nspecification is satisfied too easily, or vacuously. For example, the\nspecification \"every request is eventually followed by an acknowledgment\" is\nsatisfied vacuously by a system that never generates any requests. Vacuous\nsatisfaction misleads users of model-checking into thinking that a system is\ncorrect.\n  There are several existing definitions of vacuity. Originally, Beer et al.\nformalized vacuity as insensitivity to syntactic perturbation. However, this\ndefinition is only reasonable for vacuity in a single occurrence. Armoni et al.\nargued that vacuity must be robust -- not affected by semantically invariant\nchanges, such as extending a model with additional atomic propositions. They\nshow that syntactic vacuity is not robust for LTL, and propose an alternative\ndefinition -- trace vacuity.\n  In this article, we continue this line of research. We show that trace\nvacuity is not robust for branching time logic. We refine it to apply uniformly\nto linear and branching time logic and to not suffer from the common pitfalls\nof prior definitions. Our new definition -- bisimulation vacuity -- is a proper\nnon-trivial extension of both syntactic and trace vacuity. We discuss the\ncomplexity of detecting bisimulation vacuity, and give efficient algorithms to\ndetect vacuity for several practically-relevant subsets of CTL*.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2010 20:33:57 GMT"}, {"version": "v2", "created": "Wed, 13 Oct 2010 18:59:01 GMT"}], "update_date": "2010-10-14", "authors_parsed": [["Gurfinkel", "Arie", ""], ["Chechik", "Marsha", ""]]}]