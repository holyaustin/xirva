[{"id": "1508.00059", "submitter": "Mohan Sridharan", "authors": "Zenon Colaco and Mohan Sridharan", "title": "Mixed Logical and Probabilistic Reasoning for Planning and Explanation\n  Generation in Robotics", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots assisting humans in complex domains have to represent knowledge and\nreason at both the sensorimotor level and the social level. The architecture\ndescribed in this paper couples the non-monotonic logical reasoning\ncapabilities of a declarative language with probabilistic belief revision,\nenabling robots to represent and reason with qualitative and quantitative\ndescriptions of knowledge and degrees of belief. Specifically, incomplete\ndomain knowledge, including information that holds in all but a few exceptional\nsituations, is represented as a Answer Set Prolog (ASP) program. The answer set\nobtained by solving this program is used for inference, planning, and for\njointly explaining (a) unexpected action outcomes due to exogenous actions and\n(b) partial scene descriptions extracted from sensor input. For any given task,\neach action in the plan contained in the answer set is executed\nprobabilistically. The subset of the domain relevant to the action is\nidentified automatically, and observations extracted from sensor inputs perform\nincremental Bayesian updates to a belief distribution defined over this domain\nsubset, with highly probable beliefs being committed to the ASP program. The\narchitecture's capabilities are illustrated in simulation and on a mobile robot\nin the context of a robot waiter operating in the dining room of a restaurant.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2015 00:26:46 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Colaco", "Zenon", ""], ["Sridharan", "Mohan", ""]]}, {"id": "1508.00093", "submitter": "Yuxi Fu", "authors": "Yuxi Fu, Han Zhu", "title": "The Name-Passing Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Name-passing calculi are foundational models for mobile computing. Research\ninto these models has produced a wealth of results ranging from relative\nexpressiveness to programming pragmatics. The diversity of these results call\nfor clarification and reorganization. This paper applies a model independent\napproach to the study of the name-passing calculi, leading to a uniform\ntreatment and simplification. The technical tools and the results presented in\nthe paper form the foundation for a theory of name-passing calculus.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2015 07:35:41 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Fu", "Yuxi", ""], ["Zhu", "Han", ""]]}, {"id": "1508.00116", "submitter": "Arjun Bhardwaj", "authors": "Arjun Bhardwaj", "title": "Extending SROIQ with Constraint Networks and Grounded Circumscription", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developments in semantic web technologies have promoted ontological encoding\nof knowledge from diverse domains. However, modelling many practical domains\nrequires more expressiveness than what the standard description logics (most\nprominently SROIQ) support. In this paper, we extend the expressive DL SROIQ\nwith constraint networks (resulting in the logic SROIQc) and grounded\ncircumscription (resulting in the logic GC-SROIQ). Applications of constraint\nmodelling include embedding ontologies with temporal or spatial information,\nwhile those of grounded circumscription include defeasible inference and closed\nworld reasoning.\n  We describe the syntax and semantics of the logic formed by including\nconstraint modelling constructs in SROIQ, and provide a sound, complete and\nterminating tableau algorithm for it. We further provide an intuitive algorithm\nfor Grounded Circumscription in SROIQc, which adheres to the general framework\nof grounded circumscription, and which can be applied to a whole range of\nexpressive logics for which no such specific algorithm presently exists.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2015 13:07:46 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Bhardwaj", "Arjun", ""]]}, {"id": "1508.00455", "submitter": "EPTCS", "authors": "Cyprien Mangin (Univ Paris Diderot & \\'Ecole Polytechnique), Matthieu\n  Sozeau (Inria Paris & PPS, Univ Paris Diderot)", "title": "Equations for Hereditary Substitution in Leivant's Predicative System F:\n  A Case Study", "comments": "In Proceedings LFMTP 2015, arXiv:1507.07597. www:\n  http://equations-fpred.gforge.inria.fr/", "journal-ref": "EPTCS 185, 2015, pp. 71-86", "doi": "10.4204/EPTCS.185.5", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a case study of formalizing a normalization proof for\nLeivant's Predicative System F using the Equations package. Leivant's\nPredicative System F is a stratified version of System F, where type\nquantification is annotated with kinds representing universe levels. A weaker\nvariant of this system was studied by Stump & Eades, employing the hereditary\nsubstitution method to show normalization. We improve on this result by showing\nnormalization for Leivant's original system using hereditary substitutions and\na novel multiset ordering on types. Our development is done in the Coq proof\nassistant using the Equations package, which provides an interface to define\ndependently-typed programs with well-founded recursion and full dependent\npattern- matching. Equations allows us to define explicitly the hereditary\nsubstitution function, clarifying its algorithmic behavior in presence of term\nand type substitutions. From this definition, consistency can easily be\nderived. The algorithmic nature of our development is crucial to reflect\nlanguages with type quantification, enlarging the class of languages on which\nreflection methods can be used in the proof assistant.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 08:21:28 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Mangin", "Cyprien", "", "Univ Paris Diderot & \u00c9cole Polytechnique"], ["Sozeau", "Matthieu", "", "Inria Paris & PPS, Univ Paris Diderot"]]}, {"id": "1508.01045", "submitter": "Florian Lonsing", "authors": "Florian Lonsing, Martina Seidl, and Allen Van Gelder", "title": "The QBF Gallery: Behind the Scenes", "comments": "preprint of an article to appear in Artificial Intelligence,\n  Elsevier, 2016", "journal-ref": null, "doi": "10.1016/j.artint.2016.04.002", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, much progress has been made in the theory and\npractice of solving quantified Boolean formulas (QBF). Novel solvers have been\npresented that either successfully enhance established techniques or implement\nnovel solving paradigms. Powerful preprocessors have been realized that tune\nthe encoding of a formula to make it easier to solve. Frameworks for\ncertification and solution extraction emerged that allow for a detailed\ninterpretation of a QBF solver's results, and new types of QBF encodings were\npresented for various application problems.\n  To capture these developments the QBF Gallery was established in 2013. The\nQBF Gallery aims at providing a forum to assess QBF tools and to collect new,\nexpressive benchmarks that allow for documenting the status quo and that\nindicate promising research directions. These benchmarks became the basis for\nthe experiments conducted in the context of the QBF Gallery 2013 and follow-up\nevaluations. In this paper, we report on the setup of the QBF Gallery. To this\nend, we conducted numerous experiments which allowed us not only to assess the\nquality of the tools, but also the quality of the benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 12:17:07 GMT"}, {"version": "v2", "created": "Fri, 15 Apr 2016 11:49:17 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Lonsing", "Florian", ""], ["Seidl", "Martina", ""], ["Van Gelder", "Allen", ""]]}, {"id": "1508.01127", "submitter": "Christoph Wagner", "authors": "Meike Hatzel and Christoph Wagner and Kirstin Peters and Uwe Nestmann", "title": "Encoding CSP into CCS (Extended Version)", "comments": "Extended version of the article \"Encoding CSP into CCS\" in\n  EXPRESS/SOS'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study encodings from CSP into asynchronous CCS with name passing and\nmatching, so in fact, the asynchronous pi-calculus. By doing so, we discuss two\ndifferent ways to map the multi-way synchronisation mechanism of CSP into the\ntwo-way synchronisation mechanism of CCS. Both encodings satisfy the criteria\nof Gorla except for compositionality, as both use an additional top-level\ncontext. Following the work of Parrow and Sj\\\"odin, the first encoding uses a\ncentral coordinator and establishes a variant of weak bisimilarity between\nsource terms and their translations. The second encoding is decentralised, and\nthus more efficient, but ensures only a form of coupled similarity between\nsource terms and their translations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 16:57:49 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Hatzel", "Meike", ""], ["Wagner", "Christoph", ""], ["Peters", "Kirstin", ""], ["Nestmann", "Uwe", ""]]}, {"id": "1508.01288", "submitter": "Anvesh Komuravelli", "authors": "Anvesh Komuravelli, Nikolaj Bjorner, Arie Gurfinkel, Kenneth L.\n  McMillan", "title": "Compositional Verification of Procedural Programs using Horn Clauses\n  over Integers and Arrays", "comments": "8 pages, FMCAD 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a compositional SMT-based algorithm for safety of procedural C\nprograms that takes the heap into consideration as well. Existing SMT-based\napproaches are either largely restricted to handling linear arithmetic\noperations and properties, or are non-compositional. We use Constrained Horn\nClauses (CHCs) to represent the verification conditions where the memory\noperations are modeled using the extensional theory of arrays (ARR). First, we\ndescribe an exponential time quantifier elimination (QE) algorithm for ARR\nwhich can introduce new quantifiers of the index and value sorts. Second, we\nadapt the QE algorithm to efficiently obtain under-approximations using models,\nresulting in a polynomial time Model Based Projection (MBP) algorithm. Third,\nwe integrate the MBP algorithm into the framework of compositional reasoning of\nprocedural programs using may and must summaries recently proposed by us. Our\nsolutions to the CHCs are currently restricted to quantifier-free formulas.\nFinally, we describe our practical experience over SV-COMP'15 benchmarks using\nan implementation in the tool SPACER.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 06:27:27 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Komuravelli", "Anvesh", ""], ["Bjorner", "Nikolaj", ""], ["Gurfinkel", "Arie", ""], ["McMillan", "Kenneth L.", ""]]}, {"id": "1508.01600", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling", "title": "Remark on the hypothetical judgment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the proper explanation of intuitionistic hypothetical judgment, and\nthence propositional implication? The answer is unclear from the writings of\nBrouwer and Heyting, who in their lifetimes propounded multiple (sometimes\nconflicting) explanations of the hypothetical judgment. To my mind, the\ndetermination of an acceptable explanation must take into account its adequacy\nfor the expression of the bar theorem and, more generally, the development of\nan open-ended framework for transcendental arguments in mathematics.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 04:36:53 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 04:00:21 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2015 04:20:29 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2015 22:34:23 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Sterling", "Jonathan", ""]]}, {"id": "1508.01927", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "Incorporating Inductions and Game Semantics into Logic Programming", "comments": "11 pages. arXiv admin note: substantial text overlap with\n  arXiv:1507.07228", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductions and game semantics are two useful extensions to traditional logic\nprogramming. To be specific, inductions can capture a wider class of provable\nformulas in logic programming. Adopting game semantics can make logic\nprogramming more interactive.\n  In this paper, we propose an execution model for a logic language with these\nfeatures. This execution model follows closely the reasoning process in real\nlife.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2015 17:14:09 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "1508.02149", "submitter": "Murray Elder", "authors": "Laura Ciobanu and Volker Diekert and Murray Elder", "title": "Solution sets for equations over free groups are EDT0L languages", "comments": "38 pages, 3 figures. A conference version of this paper was presented\n  at ICALP 2015, Kyoto (Japan), July 4-10, 2015, see\n  http://arxiv.org/abs/1502.03426", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CC cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, given an equation over a finitely generated free group, the set\nof all solutions in reduced words forms an effectively constructible EDT0L\nlanguage. In particular, the set of all solutions in reduced words is an\nindexed language in the sense of Aho. The language characterization we give, as\nwell as further questions about the existence or finiteness of solutions,\nfollow from our explicit construction of a finite directed graph which encodes\nall the solutions. Our result incorporates the recently invented recompression\ntechnique of Je\\.z, and a new way to integrate solutions of linear Diophantine\nequations into the process.\n  As a byproduct of our techniques, we improve the complexity from quadratic\nnondeterministic space in previous works to $\\mathsf{NSPACE}(n\\log n)$ here.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 07:32:10 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 06:53:43 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Ciobanu", "Laura", ""], ["Diekert", "Volker", ""], ["Elder", "Murray", ""]]}, {"id": "1508.02326", "submitter": "Hoang Nga Nguyen", "authors": "Nils Bulling and Hoang Nga Nguyen", "title": "Model Checking Resource Bounded Systems with Shared Resources via\n  Alternating B\\\"uchi Pushdown Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the verification of resource-constrained multiagent\nsystems is undecidable in general. In many such settings, resources are private\nto agents. In this paper, we investigate the model checking problem for a\nresource logic based on Alternating-Time Temporal Logic (ATL) with shared\nresources. Resources can be consumed and produced up to any amount. We show\nthat the model checking problem is undecidable if two or more of such unbounded\nresources are available. Our main technical result is that in the case of a\nsingle shared resource, the problem becomes decidable. Although intuitive, the\nproof of decidability is non-trivial. We reduce model checking to a problem\nover alternating B\\\"uchi pushdown systems. An intermediate result connects to\ngeneral automata-based verification: we show that model checking Computation\nTree Logic (CTL) over (compact) alternating B\\\"uchi pushdown systems is\ndecidable.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 17:10:13 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2015 16:15:38 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Bulling", "Nils", ""], ["Nguyen", "Hoang Nga", ""]]}, {"id": "1508.02626", "submitter": "Stefan Borgwardt", "authors": "Stefan Borgwardt and Theofilos Mailis and Rafael Pe\\~naloza and\n  Anni-Yasmin Turhan", "title": "Answering Fuzzy Conjunctive Queries over Finitely Valued Fuzzy\n  Ontologies", "comments": "submitted to the Journal on Data Semantics, v1: 19 pages, v2: 20\n  pages, improved evaluation section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy Description Logics (DLs) provide a means for representing vague\nknowledge about an application domain. In this paper, we study fuzzy extensions\nof conjunctive queries (CQs) over the DL $\\mathcal{SROIQ}$ based on finite\nchains of degrees of truth. To answer such queries, we extend a well-known\ntechnique that reduces the fuzzy ontology to a classical one, and use classical\nDL reasoners as a black box. We improve the complexity of previous reduction\ntechniques for finitely valued fuzzy DLs, which allows us to prove tight\ncomplexity results for answering certain kinds of fuzzy CQs. We conclude with\nan experimental evaluation of a prototype implementation, showing the\nfeasibility of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 15:25:21 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2015 09:10:31 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Borgwardt", "Stefan", ""], ["Mailis", "Theofilos", ""], ["Pe\u00f1aloza", "Rafael", ""], ["Turhan", "Anni-Yasmin", ""]]}, {"id": "1508.02705", "submitter": "Ioannis Filippidis", "authors": "Ioannis Filippidis and Richard M. Murray", "title": "Symbolic construction of GR(1) contracts for synchronous systems with\n  full information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a symbolic algorithm for the construction of\nassume-guarantee specifications that allow multiple agents to cooperate. Each\nagent is assigned goals expressed in a fragment of linear temporal logic known\nas generalized reactivity of rank 1 (GR(1)). These goals may be unrealizable,\nunless additional assumptions are made by each agent about the behavior of the\nother agents. The proposed algorithm constructs weakly fair assumptions for\neach agent, to ensure that they can cooperate successfully. A necessary\nrequirement is that the given goals be cooperatively satisfiable. We prove that\nthere exist games for which the GR(1) fragment with liveness properties over\nstates is not sufficient to ensure realizability from any state in the\ncooperatively winning set. The obstruction is due to circular dependencies of\nliveness goals. To prevent circularity, we introduce nested games as a\nformalism to express specifications with conditional assumptions. The algorithm\nis symbolic, with fixpoint structure similar to the GR(1) synthesis algorithm,\nimplying time complexity polynomial in the number of states, and linear in the\nnumber of recurrence goals.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 19:53:14 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Filippidis", "Ioannis", ""], ["Murray", "Richard M.", ""]]}, {"id": "1508.02767", "submitter": "Adilson Bonifacio", "authors": "Adilson Luiz Bonifacio and Arnaldo Vieira Moura", "title": "Intrinsic Properties of Complete Test Suites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Completeness is a desirable property of test suites. Roughly, completeness\nguarantees that a non-equivalent implementation under test will always be\nidentified. Several approaches proposed sufficient, and sometimes also\nnecessary, conditions on the specification model and on the test suite in order\nto guarantee completeness. Usually, these approaches impose several\nrestrictions on the specification and on the implementations, such as requiring\nthem to be reduced or complete. Further, test cases are required to be\nnon-blocking --- that is, they must run to completion --- on both the\nspecification and the implementation models. In this work we deal test cases\nthat can be blocking, we define a new notion that captures completeness, and we\ncharacterize test suite completeness in this new scenario. We establish an\nupper bound on the number of states of implementations beyond which no test\nsuite can be complete, both in the classical sense and in the new scenario with\nblocking test cases.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 22:44:50 GMT"}], "update_date": "2015-08-13", "authors_parsed": [["Bonifacio", "Adilson Luiz", ""], ["Moura", "Arnaldo Vieira", ""]]}, {"id": "1508.02864", "submitter": "Mayer Goldberg", "authors": "Mayer Goldberg (Ben-Gurion University)", "title": "Ellipses and Lambda Definability", "comments": "31 pages", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (October\n  1, 2015) lmcs:1601", "doi": "10.2168/LMCS-11(3:25)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ellipses are a meta-linguistic notation for denoting terms the size of which\nare specified by a meta-variable that ranges over the natural numbers. In this\nwork, we present a systematic approach for encoding such meta-expressions in\nthe \\^I-calculus, without ellipses: Terms that are parameterized by\nmeta-variables are replaced with corresponding \\^I-abstractions over actual\nvariables. We call such \\^I-terms arity-generic. Concrete terms, for particular\nchoices of the parameterizing variable are obtained by applying an\narity-generic \\^I-term to the corresponding numeral, obviating the need to use\nellipses. For example, to find the multiple fixed points of n equations, n\ndifferent \\^I-terms are needed, every one of which is indexed by two\nmeta-variables, and defined using three levels of ellipses. A single\narity-generic \\^I-abstraction that takes two Church numerals, one for the\nnumber of fixed-point equations, and one for their arity, replaces all these\nmultiple fixed-point combinators. We show how to define arity-generic\ngeneralizations of two historical fixed-point combinators, the first by Curry,\nand the second by Turing, for defining multiple fixed points. These historical\nfixed-point combinators are related by a construction due to B\\~Ahm: We show\nthat likewise, their arity-generic generalizations are related by an\narity-generic generalization of B\\~Ahm's construction. We further demonstrate\nthis approach to arity-generic \\^I-definability with additional \\^I-terms that\ncreate, project, extend, reverse, and map over ordered n-tuples, as well as an\narity-generic generator for one-point bases.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 09:58:30 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2015 11:38:03 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Goldberg", "Mayer", "", "Ben-Gurion University"]]}, {"id": "1508.03388", "submitter": "EPTCS", "authors": "Catherine Dubois (ENSIIE), Paolo Masci (Queen Mary University of\n  London), Dominique M\\'ery (LORIA, Universit\\'e de Lorraine)", "title": "Proceedings Second International Workshop on Formal Integrated\n  Development Environment", "comments": null, "journal-ref": "EPTCS 187, 2015", "doi": "10.4204/EPTCS.187", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of F-IDE 2015, the second international\nworkshop on Formal Integrated Development Environment, which was held as an FM\n2015 satellite event, on June 22, 2015, in Oslo (Norway). High levels of\nsafety, security and also privacy standards require the use of formal methods\nto specify and develop compliant software (sub)systems. Any standard comes with\nan assessment process, which requires a complete documentation of the\napplication in order to ease the justification of design choices and the review\nof code and proofs. Thus tools are needed for handling specifications, program\nconstructs and verification artifacts. The aim of the F-IDE workshop is to\nprovide a forum for presenting and discussing research efforts as well as\nexperience returns on design, development and usage of formal IDE aiming at\nmaking formal methods \"easier\" for both specialists and non-specialists.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 00:14:35 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Dubois", "Catherine", "", "ENSIIE"], ["Masci", "Paolo", "", "Queen Mary University of\n  London"], ["M\u00e9ry", "Dominique", "", "LORIA, Universit\u00e9 de Lorraine"]]}, {"id": "1508.03389", "submitter": "EPTCS", "authors": "Maurice H. ter Beek (ISTI-CNR, Pisa, Italy), Alberto Lluch Lafuente\n  (DTU, Denmark)", "title": "Proceedings 11th International Workshop on Automated Specification and\n  Verification of Web Systems", "comments": null, "journal-ref": "EPTCS 188, 2015", "doi": "10.4204/EPTCS.188", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These proceedings contain the papers presented at the 11th International\nWorkshop on Automated Specification and Verification of Web Systems (WWV 2015),\nwhich was held on 23 June 2015 in Oslo, Norway, as a satellite workshop of the\n20th International Symposium on Formal Methods (FM 2015). WWV is a yearly\ninterdisciplinary forum for researchers originating from the following areas:\ndeclarative, rule-based programming, formal methods, software engineering and\nweb-based systems. The workshop fosters the cross-fertilisation and advancement\nof hybrid methods from such areas.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 00:21:41 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["ter Beek", "Maurice H.", "", "ISTI-CNR, Pisa, Italy"], ["Lafuente", "Alberto Lluch", "", "DTU, Denmark"]]}, {"id": "1508.03630", "submitter": "Guillaume Hoffmann", "authors": "Guillaume Hoffmann", "title": "Undecidability of a Very Simple Modal Logic with Binding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show undecidability of the satisfiability problem of what is arguably the\nsimplest non-sub-Boolean modal logic with an implicit notion of binding. This\nwork enriches the series of existing results of undecidability of modal logics\nwith binders, which started with Hybrid Logics and continued with Memory\nLogics.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 20:00:51 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Hoffmann", "Guillaume", ""]]}, {"id": "1508.03838", "submitter": "Hern\\'an Vanzetto", "authors": "Stephan Merz and Hern\\'an Vanzetto", "title": "Encoding TLA+ set theory into many-sorted first-order logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an encoding of Zermelo-Fraenkel set theory into many-sorted\nfirst-order logic, the input language of state-of-the-art SMT solvers. This\ntranslation is the main component of a back-end prover based on SMT solvers in\nthe TLA+ Proof System.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2015 15:47:07 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Merz", "Stephan", ""], ["Vanzetto", "Hern\u00e1n", ""]]}, {"id": "1508.03846", "submitter": "Jose Picado", "authors": "Jose Picado, Arash Termehchy, Alan Fern, Parisa Ataei", "title": "Schema Independent Relational Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning novel concepts and relations from relational databases is an\nimportant problem with many applications in database systems and machine\nlearning. Relational learning algorithms learn the definition of a new relation\nin terms of existing relations in the database. Nevertheless, the same data set\nmay be represented under different schemas for various reasons, such as\nefficiency, data quality, and usability. Unfortunately, the output of current\nrelational learning algorithms tends to vary quite substantially over the\nchoice of schema, both in terms of learning accuracy and efficiency. This\nvariation complicates their off-the-shelf application. In this paper, we\nintroduce and formalize the property of schema independence of relational\nlearning algorithms, and study both the theoretical and empirical dependence of\nexisting algorithms on the common class of (de) composition schema\ntransformations. We study both sample-based learning algorithms, which learn\nfrom sets of labeled examples, and query-based algorithms, which learn by\nasking queries to an oracle. We prove that current relational learning\nalgorithms are generally not schema independent. For query-based learning\nalgorithms we show that the (de) composition transformations influence their\nquery complexity. We propose Castor, a sample-based relational learning\nalgorithm that achieves schema independence by leveraging data dependencies. We\nsupport the theoretical results with an empirical study that demonstrates the\nschema dependence/independence of several algorithms on existing benchmark and\nreal-world datasets under (de) compositions.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2015 16:57:20 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 20:35:32 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Picado", "Jose", ""], ["Termehchy", "Arash", ""], ["Fern", "Alan", ""], ["Ataei", "Parisa", ""]]}, {"id": "1508.03891", "submitter": "Mohan Sridharan", "authors": "Mohan Sridharan, Michael Gelfond, Shiqi Zhang, Jeremy Wyatt", "title": "REBA: A Refinement-Based Architecture for Knowledge Representation and\n  Reasoning in Robotics", "comments": "72 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an architecture for robots that combines the\ncomplementary strengths of probabilistic graphical models and declarative\nprogramming to represent and reason with logic-based and probabilistic\ndescriptions of uncertainty and domain knowledge. An action language is\nextended to support non-boolean fluents and non-deterministic causal laws. This\naction language is used to describe tightly-coupled transition diagrams at two\nlevels of granularity, with a fine-resolution transition diagram defined as a\nrefinement of a coarse-resolution transition diagram of the domain. The\ncoarse-resolution system description, and a history that includes (prioritized)\ndefaults, are translated into an Answer Set Prolog (ASP) program. For any given\ngoal, inference in the ASP program provides a plan of abstract actions. To\nimplement each such abstract action, the robot automatically zooms to the part\nof the fine-resolution transition diagram relevant to this action. A\nprobabilistic representation of the uncertainty in sensing and actuation is\nthen included in this zoomed fine-resolution system description, and used to\nconstruct a partially observable Markov decision process (POMDP). The policy\nobtained by solving the POMDP is invoked repeatedly to implement the abstract\naction as a sequence of concrete actions, with the corresponding observations\nbeing recorded in the coarse-resolution history and used for subsequent\nreasoning. The architecture is evaluated in simulation and on a mobile robot\nmoving objects in an indoor domain, to show that it supports reasoning with\nviolation of defaults, noisy observations and unreliable actions, in complex\ndomains.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 01:17:49 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 11:01:57 GMT"}, {"version": "v3", "created": "Wed, 19 Apr 2017 20:50:13 GMT"}, {"version": "v4", "created": "Fri, 21 Sep 2018 12:47:50 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Sridharan", "Mohan", ""], ["Gelfond", "Michael", ""], ["Zhang", "Shiqi", ""], ["Wyatt", "Jeremy", ""]]}, {"id": "1508.03892", "submitter": "EPTCS", "authors": "Dipak L. Chaudhari, Om Damani", "title": "Building an IDE for the Calculational Derivation of Imperative Programs", "comments": "In Proceedings F-IDE 2015, arXiv:1508.03388", "journal-ref": "EPTCS 187, 2015, pp. 1-13", "doi": "10.4204/EPTCS.187.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe an IDE called CAPS (Calculational Assistant for\nProgramming from Specifications) for the interactive, calculational derivation\nof imperative programs. In building CAPS, our aim has been to make the IDE\naccessible to non-experts while retaining the overall flavor of the\npen-and-paper calculational style. We discuss the overall architecture of the\nCAPS system, the main features of the IDE, the GUI design, and the trade-offs\ninvolved.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 01:36:36 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Chaudhari", "Dipak L.", ""], ["Damani", "Om", ""]]}, {"id": "1508.03894", "submitter": "EPTCS", "authors": "Frank Dordowsky (ESG Elektroniksystem- und Logistik GmbH)", "title": "An experimental Study using ACSL and Frama-C to formulate and verify\n  Low-Level Requirements from a DO-178C compliant Avionics Project", "comments": "In Proceedings F-IDE 2015, arXiv:1508.03388", "journal-ref": "EPTCS 187, 2015, pp. 28-41", "doi": "10.4204/EPTCS.187.3", "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety critical avionics software is a natural application area for formal\nverification. This is reflected in the formal method's inclusion into the\ncertification guideline DO-178C and its formal methods supplement DO-333.\nAirbus and Dassault-Aviation, for example, have conducted studies in using\nformal verification. A large German national research project, Verisoft XT,\nalso examined the application of formal methods in the avionics domain.\n  However, formal methods are not yet mainstream, and it is questionable if\nformal verification, especially formal deduction, can be integrated into the\nsoftware development processes of a resource constrained small or medium\nenterprise (SME). ESG, a Munich based medium sized company, has conducted a\nsmall experimental study on the application of formal verification on a small\nportion of a real avionics project. The low level specification of a software\nfunction was formalized with ACSL, and the corresponding source code was\npartially verified using Frama-C and the WP plugin, with Alt-Ergo as automated\nprover.\n  We established a couple of criteria which a method should meet to be fit for\npurpose for industrial use in SME, and evaluated these criteria with the\nexperience gathered by using ACSL with Frama-C on a real world example. The\npaper reports on the results of this study but also highlights some issues\nregarding the method in general which, in our view, will typically arise when\nusing the method in the domain of embedded real-time programming.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 01:36:49 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Dordowsky", "Frank", "", "ESG Elektroniksystem- und Logistik GmbH"]]}, {"id": "1508.03895", "submitter": "EPTCS", "authors": "Carlo A. Furia, Christopher M. Poskitt, Julian Tschannen", "title": "The AutoProof Verifier: Usability by Non-Experts and on Standard Code", "comments": "In Proceedings F-IDE 2015, arXiv:1508.03388", "journal-ref": "EPTCS 187, 2015, pp. 42-55", "doi": "10.4204/EPTCS.187.4", "report-no": null, "categories": "cs.SE cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal verification tools are often developed by experts for experts; as a\nresult, their usability by programmers with little formal methods experience\nmay be severely limited. In this paper, we discuss this general phenomenon with\nreference to AutoProof: a tool that can verify the full functional correctness\nof object-oriented software. In particular, we present our experiences of using\nAutoProof in two contrasting contexts representative of non-expert usage.\nFirst, we discuss its usability by students in a graduate course on software\nverification, who were tasked with verifying implementations of various sorting\nalgorithms. Second, we evaluate its usability in verifying code developed for\nprogramming assignments of an undergraduate course. The first scenario\nrepresents usability by serious non-experts; the second represents usability on\n\"standard code\", developed without full functional verification in mind. We\nreport our experiences and lessons learnt, from which we derive some general\nsuggestions for furthering the development of verification tools with respect\nto improving their usability.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 01:36:56 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Furia", "Carlo A.", ""], ["Poskitt", "Christopher M.", ""], ["Tschannen", "Julian", ""]]}, {"id": "1508.03901", "submitter": "EPTCS", "authors": "Adrian Francalanza (CS, ICT, University of Malta), Marco Giunti\n  (RELEASE, DI, Universidade da Beira Interior & NOVA LINCS, DI-FCT,\n  Universidade NOVA de Lisboa), Ant\\'onio Ravara (NOVA LINCS, DI-FCT,\n  Universidade NOVA de Lisboa)", "title": "Unlocking Blocked Communicating Processes", "comments": "In Proceedings WWV 2015, arXiv:1508.03389", "journal-ref": "EPTCS 188, 2015, pp. 23-32", "doi": "10.4204/EPTCS.188.4", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of disentangling locked processes via code refactoring.\nWe identify and characterise a class of processes that is not lock-free; then\nwe formalise an algorithm that statically detects potential locks and propose\nrefactoring procedures that disentangle detected locks. Our development is cast\nwithin a simple setting of a finite linear CCS variant \\^a although it suffices\nto illustrate the main concepts, we also discuss how our work extends to other\nlanguage extensions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 01:51:02 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Francalanza", "Adrian", "", "CS, ICT, University of Malta"], ["Giunti", "Marco", "", "RELEASE, DI, Universidade da Beira Interior & NOVA LINCS, DI-FCT,\n  Universidade NOVA de Lisboa"], ["Ravara", "Ant\u00f3nio", "", "NOVA LINCS, DI-FCT,\n  Universidade NOVA de Lisboa"]]}, {"id": "1508.03908", "submitter": "EPTCS", "authors": "Nosheen Gul (University of Leicester, England)", "title": "A Calculus of Mobility and Communication for Ubiquitous Computing", "comments": "In Proceedings WWV 2015, arXiv:1508.03389", "journal-ref": "EPTCS 188, 2015, pp. 6-22", "doi": "10.4204/EPTCS.188.3", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Calculus of Mobility and Communication (CMC) for the modelling\nof mobility, communication and context-awareness in the setting of ubiquitous\ncomputing. CMC is an ambient calculus with the in and out capabilities of\nCardelli and Gordon's Mobile Ambients. The calculus has a new form of global\ncommunication similar to that in Milner's CCS. In CMC an ambient is tagged with\na set of ports that agents executing inside the ambient are allowed to\ncommunicate on. It also has a new context-awareness feature that allows\nambients to query their location. We present reduction semantics and labelled\ntransition system semantics of CMC and prove that the semantics coincide. A new\nnotion of behavioural equivalence is given by defining capability barbed\nbisimulation and congruence which is proved to coincide with barbed\nbisimulation congruence. The expressiveness of the calculus is illustrated by\ntwo case studies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 01:59:25 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Gul", "Nosheen", "", "University of Leicester, England"]]}, {"id": "1508.04360", "submitter": "George Metcalfe", "authors": "George Metcalfe (University of Bern), Leonardo Cabrer (University of\n  Florence)", "title": "Exact Unification and Admissibility", "comments": "arXiv admin note: substantial text overlap with arXiv:1410.5583", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 3 (September\n  28, 2015) lmcs:1599", "doi": "10.2168/LMCS-11(3:23)2015", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new hierarchy of \"exact\" unification types is introduced, motivated by the\nstudy of admissible rules for equational classes and non-classical logics. In\nthis setting, unifiers of identities in an equational class are preordered, not\nby instantiation, but rather by inclusion over the corresponding sets of\nunified identities. Minimal complete sets of unifiers under this new\npreordering always have a smaller or equal cardinality than those provided by\nthe standard instantiation preordering, and in significant cases a dramatic\nreduction may be observed. In particular, the classes of distributive lattices,\nidempotent semigroups, and MV-algebras, which all have nullary unification\ntype, have unitary or finitary exact type. These results are obtained via an\nalgebraic interpretation of exact unification, inspired by Ghilardi's algebraic\napproach to equational unification.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 15:43:46 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2015 14:24:58 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Metcalfe", "George", "", "University of Bern"], ["Cabrer", "Leonardo", "", "University of\n  Florence"]]}, {"id": "1508.04428", "submitter": "Steffen Lewitzka", "authors": "Andreas B. M. Brunner, Steffen Lewitzka", "title": "Topological representation of intuitionistic and distributive abstract\n  logics", "comments": "19 pages. The results of this article were presented in a session at\n  the XVI. Brazilian Logic Conference EBL in Petr\\'opolis, Brazil, in 2011", "journal-ref": null, "doi": "10.1007/s11787-017-0166-3", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue work of our earlier paper (Lewitzka and Brunner: Minimally\ngenerated abstract logics, Logica Universalis 3(2), 2009), where abstract\nlogics and particularly intuitionistic abstract logics are studied. Abstract\nlogics can be topologized in a direct and natural way. This facilitates a\ntopological study of classes of concrete logics whenever they are given in\nabstract form. Moreover, such a direct topological approach avoids the often\ncomplex algebraic and lattice-theoretic machinery usually applied to represent\nlogics. Motivated by that point of view, we define in this paper the category\nof intuitionistic abstract logics with stable logic maps as morphisms, and the\ncategory of implicative spectral spaces with spectral maps as morphisms. We\nshow the equivalence of these categories and conclude that the larger\ncategories of distributive abstract logics and distributive sober spaces are\nequivalent, too.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 20:01:48 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Brunner", "Andreas B. M.", ""], ["Lewitzka", "Steffen", ""]]}, {"id": "1508.04849", "submitter": "EPTCS", "authors": "Franco Barbanera (Dipartimento di Matematica e Informatica, University\n  of Catania), Steffen van Bakel (Department of Computing, Imperial College\n  London), Ugo de'Liguoro (Dipartimento di Informatica, University of Torino)", "title": "Orchestrated Session Compliance", "comments": "In Proceedings ICE 2015, arXiv:1508.04595", "journal-ref": "EPTCS 189, 2015, pp. 21-36", "doi": "10.4204/EPTCS.189.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the notion of orchestrated compliance for client/server\ninteractions in the context of session contracts. Devising the notion of\norchestrator in such a context makes it possible to have orchestrators with\nunbounded buffering capabilities and at the same time to guarantee any message\nfrom the client to be eventually delivered by the orchestrator to the server,\nwhile preventing the server from sending messages which are kept indefinitely\ninside the orchestrator. The compliance relation is shown to be decidable by\nmeans of 1) a procedure synthesising the orchestrators, if any, making a client\ncompliant with a server, and 2) a procedure for deciding whether an\norchestrator behaves in a proper way as mentioned before.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 01:40:28 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Barbanera", "Franco", "", "Dipartimento di Matematica e Informatica, University\n  of Catania"], ["van Bakel", "Steffen", "", "Department of Computing, Imperial College\n  London"], ["de'Liguoro", "Ugo", "", "Dipartimento di Informatica, University of Torino"]]}, {"id": "1508.04850", "submitter": "EPTCS", "authors": "Bas Luttik (Eindhoven University of Technology), Fei Yang (Eindhoven\n  University of Technology)", "title": "Executable Behaviour and the \\pi-Calculus (extended abstract)", "comments": "In Proceedings ICE 2015, arXiv:1508.04595. arXiv admin note:\n  substantial text overlap with arXiv:1410.4512", "journal-ref": "EPTCS 189, 2015, pp. 37-52", "doi": "10.4204/EPTCS.189.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive Turing machines extend classical Turing machines with a facility to\nmodel observable interactive behaviour. We call a behaviour executable if, and\nonly if, it is behaviourally equivalent to the behaviour of a reactive Turing\nmachine. In this paper, we study the relationship between executable behaviour\nand behaviour that can be specified in the pi-calculus. We establish that all\nexecutable behaviour can be specified in the pi-calculus up to\ndivergence-preserving branching bisimilarity. The converse, however, is not\ntrue due to (intended) limitations of the model of reactive Turing machines.\nThat is, the pi-calculus allows the specification of behaviour that is not\nexecutable up to divergence-preserving branching bisimilarity. Motivated by an\nintuitive understanding of executability, we then consider a restriction on the\noperational semantics of the pi-calculus that does associate with every pi-term\nexecutable behaviour, at least up to the version of branching bisimilarity that\ndoes not require the preservation of divergence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 01:40:36 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Luttik", "Bas", "", "Eindhoven University of Technology"], ["Yang", "Fei", "", "Eindhoven\n  University of Technology"]]}, {"id": "1508.04851", "submitter": "EPTCS", "authors": "Eike Best (Oldenburg), Uli Schlachter (Oldenburg)", "title": "Analysis of Petri Nets and Transition Systems", "comments": "In Proceedings ICE 2015, arXiv:1508.04595", "journal-ref": "EPTCS 189, 2015, pp. 53-67", "doi": "10.4204/EPTCS.189.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a stand-alone, no-frills tool supporting the analysis of\n(labelled) place/transition Petri nets and the synthesis of labelled transition\nsystems into Petri nets. It is implemented as a collection of independent,\ndedicated algorithms which have been designed to operate modularly, portably,\nextensibly, and efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 01:40:51 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Best", "Eike", "", "Oldenburg"], ["Schlachter", "Uli", "", "Oldenburg"]]}, {"id": "1508.04852", "submitter": "EPTCS", "authors": "Cl\\'ement Aubert (INRIA -- Univ. Paris-Est, LACL), Ioana Cristescu\n  (Univ. Paris Diderot, P.P.S.)", "title": "Reversible Barbed Congruence on Configuration Structures", "comments": "In Proceedings ICE 2015, arXiv:1508.04595", "journal-ref": "EPTCS 189, 2015, pp. 68-85", "doi": "10.4204/EPTCS.189.7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard contextual equivalence for process algebras is strong barbed\ncongruence. Configuration structures are a denotational semantics for processes\nin which one can define equivalences that are more discriminating, i.e. that\ndistinguish the denotation of terms equated by barbed congruence. Hereditary\nhistory preserving bisimulation (HHPB) is such a relation. We define a strong\nback and forth barbed congruence using a reversible process algebra and show\nthat the relation induced by the back and forth congruence is equivalent to\nHHPB, providing a contextual characterization of HHPB.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 01:41:01 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Aubert", "Cl\u00e9ment", "", "INRIA -- Univ. Paris-Est, LACL"], ["Cristescu", "Ioana", "", "Univ. Paris Diderot, P.P.S."]]}, {"id": "1508.04853", "submitter": "EPTCS", "authors": "Alceste Scalas (Universit\\`a di Cagliari, Italy and Imperial College\n  London, UK), Massimo Bartoletti (Universit\\`a di Cagliari, Italy)", "title": "The LTS WorkBench", "comments": "In Proceedings ICE 2015, arXiv:1508.04595", "journal-ref": "EPTCS 189, 2015, pp. 86-98", "doi": "10.4204/EPTCS.189.8", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labelled Transition Systems (LTSs) are a fundamental semantic model in many\nareas of informatics, especially concurrency theory. Yet, reasoning on LTSs and\nrelations between their states can be difficult and elusive: very simple\nprocess algebra terms can give rise to a large (possibly infinite) number of\nintricate transitions and interactions. To ease this kind of study, we present\nLTSwb, a flexible and extensible LTS toolbox: this tutorial paper discusses its\ndesign and functionalities.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 01:41:07 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Scalas", "Alceste", "", "Universit\u00e0 di Cagliari, Italy and Imperial College\n  London, UK"], ["Bartoletti", "Massimo", "", "Universit\u00e0 di Cagliari, Italy"]]}, {"id": "1508.04854", "submitter": "EPTCS", "authors": "Thomas Given-Wilson (Inria), Axel Legay (Inria)", "title": "On the Expressiveness of Joining", "comments": "In Proceedings ICE 2015, arXiv:1508.04595. arXiv admin note:\n  substantial text overlap with arXiv:1408.1455", "journal-ref": "EPTCS 189, 2015, pp. 99-113", "doi": "10.4204/EPTCS.189.9", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressiveness of communication primitives has been explored in a common\nframework based on the pi-calculus by considering four features: synchronism\n(asynchronous vs synchronous), arity (monadic vs polyadic data), communication\nmedium (shared dataspaces vs channel-based), and pattern-matching (binding to a\nname vs testing name equality vs intensionality). Here another dimension\ncoordination is considered that accounts for the number of processes required\nfor an interaction to occur. Coordination generalises binary languages such as\npi-calculus to joining languages that combine inputs such as the Join Calculus\nand general rendezvous calculus. By means of possibility/impossibility of\nencodings, this paper shows coordination is unrelated to the other features.\nThat is, joining languages are more expressive than binary languages, and no\ncombination of the other features can encode a joining language into a binary\nlanguage. Further, joining is not able to encode any of the other features\nunless they could be encoded otherwise.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 01:41:18 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Given-Wilson", "Thomas", "", "Inria"], ["Legay", "Axel", "", "Inria"]]}, {"id": "1508.04855", "submitter": "EPTCS", "authors": "Xian Xu (East China University of Science and Technology), Qiang Yin\n  (Shanghai Jiao Tong University), Huan Long (Shanghai Jiao Tong University)", "title": "On the Computation Power of Name Parameterization in Higher-order\n  Processes", "comments": "In Proceedings ICE 2015, arXiv:1508.04595", "journal-ref": "EPTCS 189, 2015, pp. 114-127", "doi": "10.4204/EPTCS.189.10", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterization extends higher-order processes with the capability of\nabstraction (akin to that in lambda-calculus), and is known to be able to\nenhance the expressiveness. This paper focuses on the parameterization of\nnames, i.e. a construct that maps a name to a process, in the higher-order\nsetting. We provide two results concerning its computation capacity. First,\nname parameterization brings up a complete model, in the sense that it can\nexpress an elementary interactive model with built-in recursive functions.\nSecond, we compare name parameterization with the well-known pi-calculus, and\nprovide two encodings between them.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 01:41:25 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Xu", "Xian", "", "East China University of Science and Technology"], ["Yin", "Qiang", "", "Shanghai Jiao Tong University"], ["Long", "Huan", "", "Shanghai Jiao Tong University"]]}, {"id": "1508.04940", "submitter": "Fredrik Dahlqvist", "authors": "Fredrik Dahlqvist and David Pym", "title": "Coalgebraic completeness-via-canonicity for distributive substructural\n  logics", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove strong completeness of a range of substructural logics with respect\nto a natural poset-based relational semantics using a coalgebraic version of\ncompleteness-via-canonicity. By formalizing the problem in the language of\ncoalgebraic logics, we develop a modular theory which covers a wide variety of\ndifferent logics under a single framework, and lends itself to further\nextensions. Moreover, we believe that the coalgebraic framework provides a\nsystematic and principled way to study the relationship between resource models\non the semantics side, and substructural logics on the syntactic side.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 10:18:10 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2016 11:10:17 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Dahlqvist", "Fredrik", ""], ["Pym", "David", ""]]}, {"id": "1508.05023", "submitter": "Matthijs V\\'ak\\'ar", "authors": "Samson Abramsky, Radha Jagadeesan, Matthijs V\\'ak\\'ar", "title": "Games for Dependent Types", "comments": "revised version of ICALP 2015 publication", "journal-ref": "ICALP 2015, Part II, LNCS 9135", "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model of dependent type theory (DTT) with Pi-, 1-, Sigma- and\nintensional Id-types, which is based on a slight variation of the category of\nAJM-games and history-free winning strategies. The model satisfies Streicher's\ncriteria of intensionality and refutes function extensionality. The principle\nof uniqueness of identity proofs is satisfied.\n  We show it contains a submodel as a full subcategory which gives a faithful\nmodel of DTT with Pi-, 1-, Sigma- and intensional Id-types and, additionally,\nfinite inductive type families. This smaller model is fully (and faithfully)\ncomplete with respect to the syntax at the type hierarchy built without\nId-types, as well as at the class of types where we allow for one strictly\npositive occurrence of an Id-type. Definability for the full type hierarchy\nwith Id-types remains to be investigated.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 16:08:17 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Abramsky", "Samson", ""], ["Jagadeesan", "Radha", ""], ["V\u00e1k\u00e1r", "Matthijs", ""]]}, {"id": "1508.05072", "submitter": "Ohad Kammar", "authors": "Ohad Kammar", "title": "An absolute characterisation of locally determined omega-colimits", "comments": "Talk proposal for the Domains XI 2014 Workshop, uploaded for\n  archiving purposes", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterising colimiting omega-cocones of projection pairs in terms of least\nupper bounds of their embeddings and projections is important to the solution\nof recursive domain equations. We present a universal characterisation of this\nlocal property as omega-cocontinuity of locally continuous functors. We present\na straightforward proof using the enriched Yoneda embedding. The proof can be\ngeneralised to Cattani and Fiore's notion of locality for adjoint pairs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 16:50:05 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Kammar", "Ohad", ""]]}, {"id": "1508.05465", "submitter": "Hiroshi Hirai", "authors": "Hiyori Yoshikawa, Hiroshi Hirai, Kazuhisa Makino", "title": "A representation of antimatroids by Horn rules and its application to\n  educational systems", "comments": "Major revision; including references/connections on implicational\n  systems and updating experiments; Version 3 (final) to appear in Journal of\n  Mathematical Psychology; Version 4 (fixing an error in Example 2.1)", "journal-ref": "Journal of Mathematical Psychology 77 (2017), 82-93", "doi": "10.1016/j.jmp.2016.09.002", "report-no": null, "categories": "math.CO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a representation of an antimatroid by Horn rules, motivated by its\nrecent application to computer-aided educational systems. We associate any set\n$\\mathcal{R}$ of Horn rules with the unique maximal antimatroid\n$\\mathcal{A}(\\mathcal{R})$ that is contained in the union-closed family\n$\\mathcal{K}(\\mathcal{R})$ naturally determined by ${\\cal R}$. We address\nalgorithmic and Boolean function theoretic aspects on the association ${\\cal R}\n\\mapsto \\mathcal{A}(\\mathcal{R})$, where ${\\cal R}$ is viewed as the input. We\npresent linear time algorithms to solve the membership problem and the\ninference problem for ${\\cal A}({\\cal R})$. We also provide efficient\nalgorithms for generating all members and all implicates of ${\\cal A}({\\cal\nR})$. We show that this representation is essentially equivalent to the\nKorte-Lov\\'{a}sz representation of antimatroids by rooted sets. Based on the\nequivalence, we provide a quadratic time algorithm to construct the\nuniquely-determined minimal representation. % These results have potential\napplications to computer-aided educational systems, where an antimatroid is\nused as a model of the space of possible knowledge states of learners, and is\nconstructed by giving Horn queries to a human expert.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2015 03:50:10 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2016 02:27:17 GMT"}, {"version": "v3", "created": "Tue, 27 Sep 2016 09:43:16 GMT"}, {"version": "v4", "created": "Sun, 9 Sep 2018 08:14:54 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Yoshikawa", "Hiyori", ""], ["Hirai", "Hiroshi", ""], ["Makino", "Kazuhisa", ""]]}, {"id": "1508.05497", "submitter": "S. Akshay", "authors": "Ajith K. John, Shetal Shah, Supratik Chakraborty, Ashutosh Trivedi, S.\n  Akshay", "title": "Skolem Functions for Factored Formulas", "comments": "Full version of FMCAD 2015 conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a propositional formula F(x,y), a Skolem function for x is a function\n\\Psi(y), such that substituting \\Psi(y) for x in F gives a formula semantically\nequivalent to \\exists F. Automatically generating Skolem functions is of\nsignificant interest in several applications including certified QBF solving,\nfinding strategies of players in games, synthesising circuits and bit-vector\nprograms from specifications, disjunctive decomposition of sequential circuits\netc. In many such applications, F is given as a conjunction of factors, each of\nwhich depends on a small subset of variables. Existing algorithms for Skolem\nfunction generation ignore any such factored form and treat F as a monolithic\nfunction. This presents scalability hurdles in medium to large problem\ninstances. In this paper, we argue that exploiting the factored form of F can\ngive significant performance improvements in practice when computing Skolem\nfunctions. We present a new CEGAR style algorithm for generating Skolem\nfunctions from factored propositional formulas. In contrast to earlier work,\nour algorithm neither requires a proof of QBF satisfiability nor uses\ncomposition of monolithic conjunctions of factors. We show experimentally that\nour algorithm generates smaller Skolem functions and outperforms\nstate-of-the-art approaches on several large benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2015 11:23:27 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2015 18:41:26 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["John", "Ajith K.", ""], ["Shah", "Shetal", ""], ["Chakraborty", "Supratik", ""], ["Trivedi", "Ashutosh", ""], ["Akshay", "S.", ""]]}, {"id": "1508.05559", "submitter": "Mauricio Toro", "authors": "Mauricio Toro", "title": "Structured Interactive Music Scores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interactive Scores is a formalism for the design and performance of\ninteractive scenarios that provides temporal relations (TRs) among the objects\nof the scenario. We can model TRs among objects in Time Stream Petri nets, but\nit is difficult to represent global constraints. This can be done explicitly in\nthe Non-deterministic Timed Concurrent Constraint (ntcc) calculus. We want to\nformalize a heterogeneous system that controls in one subsystem the concurrent\nexecution of the objects using ntcc, and audio and video processing in the\nother. We also plan to develop an automatic verifier for ntcc.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2015 02:44:36 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2015 00:00:42 GMT"}, {"version": "v3", "created": "Sat, 1 Sep 2018 18:15:56 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Toro", "Mauricio", ""]]}, {"id": "1508.06096", "submitter": "Nicholas Downing", "authors": "Nicholas Downing, Thibaut Feydy, Peter J. Stuckey", "title": "Unsatisfiable Cores and Lower Bounding for Constraint Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Programming (CP) solvers typically tackle optimization problems by\nrepeatedly finding solutions to a problem while placing tighter and tighter\nbounds on the solution cost. This approach is somewhat naive, especially for\nsoft-constraint optimization problems in which the soft constraints are mostly\nsatisfied. Unsatisfiable-core approaches to solving soft constraint problems in\nSAT (e.g. MAXSAT) force all soft constraints to be hard initially. When solving\nfails they return an unsatisfiable core, as a set of soft constraints that\ncannot hold simultaneously. These are reverted to soft and solving continues.\nSince lazy clause generation solvers can also return unsatisfiable cores we can\nadapt this approach to constraint programming. We adapt the original MAXSAT\nunsatisfiable core solving approach to be usable for constraint programming and\ndefine a number of extensions. Experimental results show that our methods are\nbeneficial on a broad class of CP-optimization benchmarks involving soft\nconstraints, cardinality or preferences.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 10:11:42 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Downing", "Nicholas", ""], ["Feydy", "Thibaut", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "1508.06121", "submitter": "Vitaly Perevoshchikov", "authors": "Vitaly Perevoshchikov", "title": "Weight Assignment Logic", "comments": "This is the full version of the paper published at DLT 2015", "journal-ref": "DLT 2015. LNCS, vol. 9168, pp. 413-425. Springer (2015)", "doi": "10.1007/978-3-319-21500-6_33", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a weight assignment logic for reasoning about quantitative\nlanguages of infinite words. This logic is an extension of the classical MSO\nlogic and permits to describe quantitative properties of systems with multiple\nweight parameters, e.g., the ratio between rewards and costs. We show that this\nlogic is expressively equivalent to unambiguous weighted B\\\"uchi automata. We\nalso consider an extension of weight assignment logic which is expressively\nequivalent to nondeterministic weighted B\\\"uchi automata.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 11:57:31 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Perevoshchikov", "Vitaly", ""]]}, {"id": "1508.06347", "submitter": "EPTCS", "authors": "Silvia Crafa, Daniel E. Gebler", "title": "Proceedings of the Combined 22th International Workshop on\n  Expressiveness in Concurrency and 12th Workshop on Structural Operational\n  Semantics", "comments": null, "journal-ref": "EPTCS 190, 2015", "doi": "10.4204/EPTCS.190", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Combined 22nd International\nWorkshop on Expressiveness in Concurrency and the 12th Workshop on Structural\nOperational Semantics (EXPRESS/SOS 2015) which was held on 31 August 2015 in\nMadrid, Spain, as an affiliated workshop of CONCUR 2015, the 26th International\nConference on Concurrency Theory. The EXPRESS workshops aim at bringing\ntogether researchers interested in the expressiveness of various formal systems\nand semantic notions, particularly in the field of concurrency. Their focus has\ntraditionally been on the comparison between programming concepts (such as\nconcurrent, functional, imperative, logic and object-oriented programming) and\nbetween mathematical models of computation (such as process algebras, Petri\nnets, event structures, modal logics, and rewrite systems) on the basis of\ntheir relative expressive power. The EXPRESS workshop series has run\nsuccessfully since 1994 and over the years this focus has become broadly\nconstrued. The SOS workshops aim at being a forum for researchers, students and\npractitioners interested in new developments, and directions for future\ninvestigation, in the field of structural operational semantics. One of the\nspecific goals of the SOS workshop series is to establish synergies between the\nconcurrency and programming language communities working on the theory and\npractice of SOS. Since 2012, the EXPRESS and SOS communities have organized an\nannual combined EXPRESS/SOS workshop on the expressiveness of mathematical\nmodels of computation and the formal semantics of systems and programming\nconcepts.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 02:17:37 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Crafa", "Silvia", ""], ["Gebler", "Daniel E.", ""]]}, {"id": "1508.06556", "submitter": "Amena Mahmoud", "authors": "Amena Mahmoud", "title": "The Power of the Depth of Iteration in Defining Relations by Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis we study inductive definitions over finite structures,\nparticularly, the depth of inductive definitions. We also study infinitary\nfinite variable logic which contains fixed-point logic and we introduce a new\ncomplexity measure $\\textrm{FO}_{\\bigvee}[f(n),g(n)]$ which counts the number,\n$f(n)$, of $\\vee$-symbols, and the number, $g(n)$, of variables, in first-order\nformulas needed to express a given property. We prove that for $f(n)\\geq\n\\log{n}$, $\\textrm{NSPACE}[f(n)] \\subseteq\n\\textrm{FO}_{\\bigvee}[f(n)+\\left(\\frac{f(n)}{\\log{n}}\\right)^2,\\frac{f(n)}{\\log{n}}]$,\nand that for any $f(n),g(n)$, $\\textrm{FO}_{\\bigvee}[f(n),g(n)]\\subseteq\n\\textrm{DSPACE}[f(n)g(n)\\log{n}]$. Also we study the expressive power of\nquantifier rank and number of variables and we prove that there is a property\nof words expressible with two variables and quantifier rank $2^n+2$ but not\nexpressible with quantifier rank $n$ with any number of variables.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 16:23:17 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Mahmoud", "Amena", ""]]}, {"id": "1508.06613", "submitter": "Srdjan Krstic", "authors": "Marcello M. Bersani, Domenico Bianculli, Carlo Ghezzi, Srdan Krstic,\n  Pierluigi San Pietro", "title": "Efficient Large-scale Trace Checking Using MapReduce", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of checking a logged event trace against a temporal logic\nspecification arises in many practical cases. Unfortunately, known algorithms\nfor an expressive logic like MTL (Metric Temporal Logic) do not scale with\nrespect to two crucial dimensions: the length of the trace and the size of the\ntime interval for which logged events must be buffered to check satisfaction of\nthe specification. The former issue can be addressed by distributed and\nparallel trace checking algorithms that can take advantage of modern cloud\ncomputing and programming frameworks like MapReduce. Still, the latter issue\nremains open with current state-of-the-art approaches.\n  In this paper we address this memory scalability issue by proposing a new\nsemantics for MTL, called lazy semantics. This semantics can evaluate temporal\nformulae and boolean combinations of temporal-only formulae at any arbitrary\ntime instant. We prove that lazy semantics is more expressive than standard\npoint-based semantics and that it can be used as a basis for a correct\nparametric decomposition of any MTL formula into an equivalent one with\nsmaller, bounded time intervals. We use lazy semantics to extend our previous\ndistributed trace checking algorithm for MTL. We evaluate the proposed\nalgorithm in terms of memory scalability and time/memory tradeoffs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 19:20:14 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Bersani", "Marcello M.", ""], ["Bianculli", "Domenico", ""], ["Ghezzi", "Carlo", ""], ["Krstic", "Srdan", ""], ["Pietro", "Pierluigi San", ""]]}, {"id": "1508.06707", "submitter": "EPTCS", "authors": "Ornela Dardha (University of Glasgow, United Kingdom), Jorge A.\n  P\\'erez (University of Groningen, The Netherlands)", "title": "Comparing Deadlock-Free Session Typed Processes", "comments": "In Proceedings EXPRESS/SOS 2015, arXiv:1508.06347", "journal-ref": "EPTCS 190, 2015, pp. 1-15", "doi": "10.4204/EPTCS.190.1", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Besides respecting prescribed protocols, communication-centric systems should\nnever \"get stuck\". This requirement has been expressed by liveness properties\nsuch as progress or (dead)lock freedom. Several typing disciplines that ensure\nthese properties for mobile processes have been proposed. Unfortunately, very\nlittle is known about the precise relationship between these disciplines--and\nthe classes of typed processes they induce.\n  In this paper, we compare L and K, two classes of deadlock-free, session\ntyped concurrent processes. The class L stands out for its canonicity: it\nresults naturally from interpretations of linear logic propositions as session\ntypes. The class K, obtained by encoding session types into Kobayashi's usage\ntypes, includes processes not typable in other type systems.\n  We show that L is strictly included in K. We also identify the precise\ncondition under which L and K coincide. One key observation is that the degree\nof sharing between parallel processes determines a new expressiveness hierarchy\nfor typed processes. We also provide a type-preserving rewriting procedure of\nprocesses in K into processes in L. This procedure suggests that, while\neffective, the degree of sharing is a rather subtle criteria for distinguishing\ntyped processes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 03:21:08 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Dardha", "Ornela", "", "University of Glasgow, United Kingdom"], ["P\u00e9rez", "Jorge A.", "", "University of Groningen, The Netherlands"]]}, {"id": "1508.06709", "submitter": "EPTCS", "authors": "Jovana Dedei\\'c (University of Novi Sad, Serbia), Jovanka Pantovi\\'c\n  (University of Novi Sad, Serbia), Jorge A. P\\'erez (University of Groningen,\n  The Netherlands)", "title": "On Compensation Primitives as Adaptable Processes", "comments": "In Proceedings EXPRESS/SOS 2015, arXiv:1508.06347", "journal-ref": "EPTCS 190, 2015, pp. 16-30", "doi": "10.4204/EPTCS.190.2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare mechanisms for compensation handling and dynamic update in calculi\nfor concurrency. These mechanisms are increasingly relevant in the\nspecification of reliable communicating systems. Compensations and updates are\nintuitively similar: both specify how the behavior of a concurrent system\nchanges at runtime in response to an exceptional event. However, calculi with\ncompensations and updates are technically quite different. We investigate the\nrelative expressiveness of these calculi: we develop encodings of core process\nlanguages with compensations into a calculus of adaptable processes developed\nin prior work. Our encodings shed light on the (intricate) semantics of\ncompensation handling and its key constructs. They also enable the transference\nof existing verification and reasoning techniques for adaptable processes to\ncore languages with compensation handling.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 03:21:16 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Dedei\u0107", "Jovana", "", "University of Novi Sad, Serbia"], ["Pantovi\u0107", "Jovanka", "", "University of Novi Sad, Serbia"], ["P\u00e9rez", "Jorge A.", "", "University of Groningen,\n  The Netherlands"]]}, {"id": "1508.06710", "submitter": "EPTCS", "authors": "Pedro R. D'Argenio (FaMAF, Universidad Nacional de C\\'ordoba -\n  CONICET), Matias David Lee (FaMAF, Universidad Nacional de C\\'ordoba -\n  CONICET), Daniel Gebler (Department of Computer Science, VU University\n  Amsterdam)", "title": "SOS rule formats for convex and abstract probabilistic bisimulations", "comments": "In Proceedings EXPRESS/SOS 2015, arXiv:1508.06347", "journal-ref": "EPTCS 190, 2015, pp. 31-45", "doi": "10.4204/EPTCS.190.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic transition system specifications (PTSSs) in the $nt \\mu f\\theta\n/ nt\\mu x\\theta$ format provide structural operational semantics for\nSegala-type systems that exhibit both probabilistic and nondeterministic\nbehavior and guarantee that bisimilarity is a congruence for all operator\ndefined in such format. Starting from the $nt \\mu f\\theta / nt\\mu x\\theta$\nformat, we obtain restricted formats that guarantee that three coarser\nbisimulation equivalences are congruences. We focus on (i) Segala's variant of\nbisimulation that considers combined transitions, which we call here \"convex\nbisimulation\"; (ii) the bisimulation equivalence resulting from considering\nPark & Milner's bisimulation on the usual stripped probabilistic transition\nsystem (translated into a labelled transition system), which we call here\n\"probability obliterated bisimulation\"; and (iii) a \"probability abstracted\nbisimulation\", which, like bisimulation, preserves the structure of the\ndistributions but instead, it ignores the probability values. In addition, we\ncompare these bisimulation equivalences and provide a logic characterization\nfor each of them.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 03:21:26 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["D'Argenio", "Pedro R.", "", "FaMAF, Universidad Nacional de C\u00f3rdoba -\n  CONICET"], ["Lee", "Matias David", "", "FaMAF, Universidad Nacional de C\u00f3rdoba -\n  CONICET"], ["Gebler", "Daniel", "", "Department of Computer Science, VU University\n  Amsterdam"]]}, {"id": "1508.06711", "submitter": "EPTCS", "authors": "Kirstin Peters, Rob van Glabbeek", "title": "Analysing and Comparing Encodability Criteria", "comments": "In Proceedings EXPRESS/SOS 2015, arXiv:1508.06347. The Isabelle/HOL\n  source files, and a full proof document, are available in the Archive of\n  Formal Proofs, at\n  http://afp.sourceforge.net/entries/Encodability_Process_Calculi.shtml", "journal-ref": "EPTCS 190, 2015, pp. 46-60", "doi": "10.4204/EPTCS.190.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encodings or the proof of their absence are the main way to compare process\ncalculi. To analyse the quality of encodings and to rule out trivial or\nmeaningless encodings, they are augmented with quality criteria. There exists a\nbunch of different criteria and different variants of criteria in order to\nreason in different settings. This leads to incomparable results. Moreover it\nis not always clear whether the criteria used to obtain a result in a\nparticular setting do indeed fit to this setting. We show how to formally\nreason about and compare encodability criteria by mapping them on requirements\non a relation between source and target terms that is induced by the encoding\nfunction. In particular we analyse the common criteria full abstraction,\noperational correspondence, divergence reflection, success sensitiveness, and\nrespect of barbs; e.g. we analyse the exact nature of the simulation relation\n(coupled simulation versus bisimulation) that is induced by different variants\nof operational correspondence. This way we reduce the problem of analysing or\ncomparing encodability criteria to the better understood problem of comparing\nrelations on processes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 03:21:35 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Peters", "Kirstin", ""], ["van Glabbeek", "Rob", ""]]}, {"id": "1508.06712", "submitter": "EPTCS", "authors": "Meike Hatzel, Christoph Wagner, Kirstin Peters, Uwe Nestmann", "title": "Encoding CSP into CCS", "comments": "In Proceedings EXPRESS/SOS 2015, arXiv:1508.06347", "journal-ref": "EPTCS 190, 2015, pp. 61-75", "doi": "10.4204/EPTCS.190.5", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study encodings from CSP into asynchronous CCS with name passing and\nmatching, so in fact, the asynchronous pi-calculus. By doing so, we discuss two\ndifferent ways to map the multi-way synchronisation mechanism of CSP into the\ntwo-way synchronisation mechanism of CCS. Both encodings satisfy the criteria\nof Gorla except for compositionality, as both use an additional top-level\ncontext. Following the work of Parrow and Sj\\\"odin, the first encoding uses a\ncentralised coordinator and establishes a variant of weak bisimilarity between\nsource terms and their translations. The second encoding is decentralised, and\nthus more efficient, but ensures only a form of coupled similarity between\nsource terms and their translations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 03:21:47 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Hatzel", "Meike", ""], ["Wagner", "Christoph", ""], ["Peters", "Kirstin", ""], ["Nestmann", "Uwe", ""]]}, {"id": "1508.06713", "submitter": "EPTCS", "authors": "Reuben N. S. Rowe (UCL)", "title": "Encoding the Factorisation Calculus", "comments": "In Proceedings EXPRESS/SOS 2015, arXiv:1508.06347", "journal-ref": "EPTCS 190, 2015, pp. 76-90", "doi": "10.4204/EPTCS.190.6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jay and Given-Wilson have recently introduced the Factorisation (or SF-)\ncalculus as a minimal fundamental model of intensional computation. It is a\ncombinatory calculus containing a special combinator, F, which is able to\nexamine the internal structure of its first argument. The calculus is\nsignificant in that as well as being combinatorially complete it also exhibits\nthe property of structural completeness, i.e. it is able to represent any\nfunction on terms definable using pattern matching on arbitrary normal forms.\nIn particular, it admits a term that can decide the structural equality of any\ntwo arbitrary normal forms.\n  Since SF-calculus is combinatorially complete, it is clearly at least as\npowerful as the more familiar and paradigmatic Turing-powerful computational\nmodels of Lambda Calculus and Combinatory Logic. Its relationship to these\nmodels in the converse direction is less obvious, however. Jay and Given-Wilson\nhave suggested that SF-calculus is strictly more powerful than the\naforementioned models, but a detailed study of the connections between these\nmodels is yet to be undertaken.\n  This paper begins to bridge that gap by presenting a faithful encoding of the\nFactorisation Calculus into the Lambda Calculus preserving both reduction and\nstrong normalisation. The existence of such an encoding is a new result. It\nalso suggests that there is, in some sense, an equivalence between the former\nmodel and the latter. We discuss to what extent our result constitutes an\nequivalence by considering it in the context of some previously defined\nframeworks for comparing computational power and expressiveness.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 03:21:54 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Rowe", "Reuben N. S.", "", "UCL"]]}, {"id": "1508.06779", "submitter": "EPTCS", "authors": "Henning Basold (Radboud University)", "title": "Dependent Inductive and Coinductive Types are Fibrational Dialgebras", "comments": "In Proceedings FICS 2015, arXiv:1509.02826", "journal-ref": "EPTCS 191, 2015, pp. 3-17", "doi": "10.4204/EPTCS.191.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I establish the categorical structure necessary to interpret\ndependent inductive and coinductive types. It is well-known that dependent type\ntheories \\`a la Martin-L\\\"of can be interpreted using fibrations. Modern\ntheorem provers, however, are based on more sophisticated type systems that\nallow the definition of powerful inductive dependent types (known as inductive\nfamilies) and, somewhat limited, coinductive dependent types. I define a class\nof functors on fibrations and show how data type definitions correspond to\ninitial and final dialgebras for these functors. This description is also a\nproposal of how coinductive types should be treated in type theories, as they\nappear here simply as dual of inductive types. Finally, I show how dependent\ndata types correspond to algebras and coalgebras, and give the correspondence\nto dependent polynomial functors.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 09:49:29 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2015 05:31:17 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Basold", "Henning", "", "Radboud University"]]}, {"id": "1508.06780", "submitter": "Leszek Ko{\\l}odziejczyk", "authors": "Leszek Aleksander Ko{\\l}odziejczyk and Henryk Michalewski", "title": "How unprovable is Rabin's decidability theorem?", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the strength of set-theoretic axioms needed to prove Rabin's theorem\non the decidability of the MSO theory of the infinite binary tree. We first\nshow that the complementation theorem for tree automata, which forms the\ntechnical core of typical proofs of Rabin's theorem, is equivalent over the\nmoderately strong second-order arithmetic theory $\\mathsf{ACA}_0$ to a\ndeterminacy principle implied by the positional determinacy of all parity games\nand implying the determinacy of all Gale-Stewart games given by boolean\ncombinations of ${\\bf \\Sigma^0_2}$ sets. It follows that complementation for\ntree automata is provable from $\\Pi^1_3$- but not $\\Delta^1_3$-comprehension.\n  We then use results due to MedSalem-Tanaka, M\\\"ollerfeld and\nHeinatsch-M\\\"ollerfeld to prove that over $\\Pi^1_2$-comprehension, the\ncomplementation theorem for tree automata, decidability of the MSO theory of\nthe infinite binary tree, positional determinacy of parity games and\ndeterminacy of $\\mathrm{Bool}({\\bf \\Sigma^0_2})$ Gale-Stewart games are all\nequivalent. Moreover, these statements are equivalent to the\n$\\Pi^1_3$-reflection principle for $\\Pi^1_2$-comprehension. It follows in\nparticular that Rabin's decidability theorem is not provable in\n$\\Delta^1_3$-comprehension.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 09:53:20 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Ko\u0142odziejczyk", "Leszek Aleksander", ""], ["Michalewski", "Henryk", ""]]}, {"id": "1508.06827", "submitter": "Tim King", "authors": "Kshitij Bansal, Andrew Reynolds, Tim King, Clark Barrett, Thomas Wies", "title": "On Deciding Local Theory Extensions via E-matching", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-21668-3_6", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satisfiability Modulo Theories (SMT) solvers incorporate decision procedures\nfor theories of data types that commonly occur in software. This makes them\nimportant tools for automating verification problems. A limitation frequently\nencountered is that verification problems are often not fully expressible in\nthe theories supported natively by the solvers. Many solvers allow the\nspecification of application-specific theories as quantified axioms, but their\nhandling is incomplete outside of narrow special cases.\n  In this work, we show how SMT solvers can be used to obtain complete decision\nprocedures for local theory extensions, an important class of theories that are\ndecidable using finite instantiation of axioms. We present an algorithm that\nuses E-matching to generate instances incrementally during the search,\nsignificantly reducing the number of generated instances compared to eager\ninstantiation strategies. We have used two SMT solvers to implement this\nalgorithm and conducted an extensive experimental evaluation on benchmarks\nderived from verification conditions for heap-manipulating programs. We believe\nthat our results are of interest to both the users of SMT solvers as well as\ntheir developers.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 12:30:29 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Bansal", "Kshitij", ""], ["Reynolds", "Andrew", ""], ["King", "Tim", ""], ["Barrett", "Clark", ""], ["Wies", "Thomas", ""]]}, {"id": "1508.06899", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Contradiction-tolerant process algebra with propositional signals", "comments": "25 pages; 26 pages, occurrences of wrong symbol for bisimulation\n  equivalence replaced; 26 pages, Proposition 1 added; 27 pages, explanation of\n  the phrase 'in contradiction' added to section 2 and presentation of the\n  completeness result in section 2 improved; 27 pages, uniqueness result in\n  section 2 revised; 27 pages, last paragraph of section 8 revised", "journal-ref": "Fundamenta Informaticae, 153(1-2): 29-55 (2017)", "doi": "10.3233/FI-2017-1530", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous paper, an ACP-style process algebra was proposed in which\npropositions are used as the visible part of the state of processes and as\nstate conditions under which processes may proceed. This process algebra,\ncalled ACPps, is built on classical propositional logic. In this paper, we\npresent a version of ACPps built on a paraconsistent propositional logic which\nis essentially the same as CLuNs. There are many systems that would have to\ndeal with self-contradictory states if no special measures were taken. For a\nnumber of these systems, it is conceivable that accepting self-contradictory\nstates and dealing with them in a way based on a paraconsistent logic is an\nalternative to taking special measures. The presented version of ACPps can be\nsuited for the description and analysis of systems that deal with\nself-contradictory states in a way based on the above-mentioned paraconsistent\nlogic.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 15:28:17 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2016 16:36:31 GMT"}, {"version": "v3", "created": "Tue, 22 Nov 2016 15:38:26 GMT"}, {"version": "v4", "created": "Sun, 27 Nov 2016 13:40:52 GMT"}, {"version": "v5", "created": "Thu, 9 Feb 2017 12:13:43 GMT"}, {"version": "v6", "created": "Sun, 19 Mar 2017 11:19:42 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1508.07829", "submitter": "Matt Lewis", "authors": "Cristina David and Daniel Kroening and Matt Lewis", "title": "Using Program Synthesis for Program Analysis", "comments": "19 pages, to appear in LPAR 2015. arXiv admin note: text overlap with\n  arXiv:1409.4925", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we identify a fragment of second-order logic with restricted\nquantification that is expressive enough to capture numerous static analysis\nproblems (e.g. safety proving, bug finding, termination and non-termination\nproving, superoptimisation). We call this fragment the {\\it synthesis\nfragment}. Satisfiability of a formula in the synthesis fragment is decidable\nover finite domains; specifically the decision problem is NEXPTIME-complete. If\na formula in this fragment is satisfiable, a solution consists of a satisfying\nassignment from the second order variables to \\emph{functions over finite\ndomains}. To concretely find these solutions, we synthesise \\emph{programs}\nthat compute the functions. Our program synthesis algorithm is complete for\nfinite state programs, i.e. every \\emph{function} over finite domains is\ncomputed by some \\emph{program} that we can synthesise. We can therefore use\nour synthesiser as a decision procedure for the synthesis fragment of\nsecond-order logic, which in turn allows us to use it as a powerful backend for\nmany program analysis tasks. To show the tractability of our approach, we\nevaluate the program synthesiser on several static analysis problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 13:58:14 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["David", "Cristina", ""], ["Kroening", "Daniel", ""], ["Lewis", "Matt", ""]]}, {"id": "1508.07851", "submitter": "Vladimir Krupski", "authors": "Vladimir N. Krupski and Alexey Yatmanov", "title": "Sequent Calculus for Intuitionistic Epistemic Logic", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formal system of intuitionistic epistemic logic IEL was proposed by S.\nArtemov and T. Protopopescu. It provides the formal foundation for the study of\nknowledge from an intuitionistic point of view based on\nBrouwer-Hayting-Kolmogorov semantics of intuitionism. We construct a cut-free\nsequent calculus for IEL and establish that polynomial space is sufficient for\nthe proof search in it. So, we prove that IEL is PSPACE-complete.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 14:41:55 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Krupski", "Vladimir N.", ""], ["Yatmanov", "Alexey", ""]]}]