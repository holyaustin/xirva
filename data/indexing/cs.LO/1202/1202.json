[{"id": "1202.0137", "submitter": "Alexander Kartzow", "authors": "Alexander Kartzow", "title": "First-Order Model Checking on Generalisations of Pushdown Graphs", "comments": "phd thesis, 255 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the first-order model checking problem on two generalisations of\npushdown graphs. The first class is the class of nested pushdown trees. The\nother is the class of collapsible pushdown graphs. Our main results are the\nfollowing. First-order logic with reachability is uniformly decidable on nested\npushdown trees. Considering first-order logic without reachability, we prove\ndecidability in doubly exponential alternating time with linearly many\nalternations. First-order logic with regular reachability predicates is\nuniformly decidable on level 2 collapsible pushdown graphs. Moreover, nested\npushdown trees are first-order interpretable in collapsible pushdown graphs of\nlevel 2. This interpretation can be extended to an interpretation of the class\nof higher-order nested pushdown trees in the collapsible pushdown graph\nhierarchy. We prove that the second level of this new hierarchy of nested trees\nhas decidable first-order model checking. Our decidability result for\ncollapsible pushdown graph relies on the fact that level 2 collapsible pushdown\ngraphs are uniform tree-automatic. Our last result concerns tree-automatic\nstructures in general. We prove that first-order logic extended by Ramsey\nquantifiers is decidable on all tree-automatic structures.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2012 10:21:41 GMT"}], "update_date": "2012-02-02", "authors_parsed": [["Kartzow", "Alexander", ""]]}, {"id": "1202.0474", "submitter": "M. H. van Emden", "authors": "Philip Kelly and M. H. van Emden", "title": "Relational Semantics for Databases and Predicate Calculus", "comments": "18 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:cs/0607039", "journal-ref": null, "doi": null, "report-no": "University of Victoria Department of Computer Science report number\n  DCS-343-IR", "categories": "cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relational data model requires a theory of relations in which tuples are\nnot only many-sorted, but can also have indexes that are not necessarily\nnumerical. In this paper we develop such a theory and define operations on\nrelations that are adequate for database use. The operations are similar to\nthose of Codd's relational algebra, but differ in being based on a\nmathematically adequate theory of relations. The semantics of predicate\ncalculus, being oriented toward the concept of satisfiability, is not suitable\nfor relational databases. We develop an alternative semantics that assigns\nrelations as meaning to formulas with free variables. This semantics makes the\nclassical predicate calculus suitable as a query language for relational\ndatabases.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2012 16:13:17 GMT"}, {"version": "v2", "created": "Sun, 5 Feb 2012 06:58:20 GMT"}, {"version": "v3", "created": "Tue, 7 Feb 2012 16:57:13 GMT"}], "update_date": "2012-02-08", "authors_parsed": [["Kelly", "Philip", ""], ["van Emden", "M. H.", ""]]}, {"id": "1202.0664", "submitter": "Urban Larsson Mr", "authors": "Urban Larsson and Johan W\\\"astlund", "title": "From heaps of matches to the limits of computability", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study so-called invariant games played with a fixed number $d$ of heaps of\nmatches. A game is described by a finite list $\\mathcal{M}$ of integer vectors\nof length $d$ specifying the legal moves. A move consists in changing the\ncurrent game-state by adding one of the vectors in $\\mathcal{M}$, provided all\nelements of the resulting vector are nonnegative. For instance, in a two-heap\ngame, the vector $(1,-2)$ would mean adding one match to the first heap and\nremoving two matches from the second heap. If $(1,-2) \\in \\mathcal{M}$, such a\nmove would be permitted provided there are at least two matches in the second\nheap. Two players take turns, and a player unable to make a move loses. We show\nthat these games embrace computational universality, and that therefore a\nnumber of basic questions about them are algorithmically undecidable. In\nparticular, we prove that there is no algorithm that takes two games\n$\\mathcal{M}$ and $\\mathcal{M}'$ (with the same number of heaps) as input, and\ndetermines whether or not they are equivalent in the sense that every\nstarting-position which is a first player win in one of the games is a first\nplayer win in the other.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2012 11:21:43 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["Larsson", "Urban", ""], ["W\u00e4stlund", "Johan", ""]]}, {"id": "1202.0904", "submitter": "Murdoch Gabbay", "authors": "Murdoch Gabbay and Aleksandar Nanevski", "title": "Denotation of syntax and metaprogramming in contextual modal type theory\n  (CMTT)", "comments": null, "journal-ref": null, "doi": "10.1016/j.jal.2012.07.002", "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modal logic S4 can be used via a Curry-Howard style correspondence to\nobtain a lambda-calculus. Modal (boxed) types are intuitively interpreted as\n`closed syntax of the calculus'. This lambda-calculus is called modal type\ntheory --- this is the basic case of a more general contextual modal type\ntheory, or CMTT.\n  CMTT has never been given a denotational semantics in which modal types are\ngiven denotation as closed syntax. We show how this can indeed be done, with a\ntwist. We also use the denotation to prove some properties of the system.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2012 16:18:04 GMT"}], "update_date": "2013-05-28", "authors_parsed": [["Gabbay", "Murdoch", ""], ["Nanevski", "Aleksandar", ""]]}, {"id": "1202.0914", "submitter": "Sebastian Rudolph", "authors": "Sebastian Rudolph (Karlsruhe Institute of Technology), Markus\n  Kr\\\"otzsch (Oxford University), Pascal Hitzler (Wright State University,\n  Dayton, Ohio)", "title": "Type-elimination-based reasoning for the description logic SHIQbs using\n  decision diagrams and disjunctive datalog", "comments": "38 pages, 3 figures, camera ready version of paper accepted for\n  publication in Logical Methods in Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (February\n  27, 2012) lmcs:806", "doi": "10.2168/LMCS-8(1:12)2012", "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, type-elimination-based method for reasoning in the\ndescription logic SHIQbs including DL-safe rules. To this end, we first\nestablish a knowledge compilation method converting the terminological part of\nan ALCIb knowledge base into an ordered binary decision diagram (OBDD) which\nrepresents a canonical model. This OBDD can in turn be transformed into\ndisjunctive Datalog and merged with the assertional part of the knowledge base\nin order to perform combined reasoning. In order to leverage our technique for\nfull SHIQbs, we provide a stepwise reduction from SHIQbs to ALCIb that\npreserves satisfiability and entailment of positive and negative ground facts.\nThe proposed technique is shown to be worst case optimal w.r.t. combined and\ndata complexity and easily admits extensions with ground conjunctive queries.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2012 18:50:13 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 23:59:27 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Rudolph", "Sebastian", "", "Karlsruhe Institute of Technology"], ["Kr\u00f6tzsch", "Markus", "", "Oxford University"], ["Hitzler", "Pascal", "", "Wright State University,\n  Dayton, Ohio"]]}, {"id": "1202.0915", "submitter": "Dirk Hofmann", "authors": "Dirk Hofmann and Manuel A. Martins", "title": "On a coalgebraic view on Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present methods of transition from one perspective on logic\nto others, and apply this in particular to obtain a coalgebraic presentation of\nlogic. The central ingredient in this process is to view consequence relations\nas morphisms in a category.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2012 18:56:47 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["Hofmann", "Dirk", ""], ["Martins", "Manuel A.", ""]]}, {"id": "1202.1309", "submitter": "Fabio Mogavero PhD", "authors": "Fabio Mogavero, Aniello Murano, Giuseppe Perelli, and Moshe Y. Vardi", "title": "A Decidable Fragment of Strategy Logic", "comments": "arXiv admin note: text overlap with arXiv:1112.6275", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Strategy Logic (SL, for short) has been recently introduced by Mogavero,\nMurano, and Vardi as a useful formalism for reasoning explicitly about\nstrategies, as first-order objects, in multi-agent concurrent games. This logic\nturns to be very powerful, subsuming all major previously studied modal logics\nfor strategic reasoning, including ATL, ATL*, and the like. Unfortunately, due\nto its expressiveness, SL has a non-elementarily decidable model-checking\nproblem and a highly undecidable satisfiability problem, specifically,\n$\\Sigma_{1}^{1}$-Hard. In order to obtain a decidable sublogic, we introduce\nand study here One-Goal Strategy Logic (SL[1G], for short). This logic is a\nsyntactic fragment of SL, strictly subsuming ATL*, which encompasses formulas\nin prenex normal form having a single temporal goal at a time, for every\nstrategy quantification of agents. SL[1G] is known to have an elementarily\ndecidable model-checking problem. Here we prove that, unlike SL, it has the\nbounded tree-model property and its satisfiability problem is decidable in\n2ExpTime, thus not harder than the one for ATL*.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 22:43:55 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2012 09:04:15 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Mogavero", "Fabio", ""], ["Murano", "Aniello", ""], ["Perelli", "Giuseppe", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1202.1409", "submitter": "Roberto Sebastiani", "authors": "Roberto Sebastiani and Silvia Tomasi", "title": "Optimization in SMT with LA(Q) Cost Functions", "comments": "A shorter version is currently under submission", "journal-ref": null, "doi": null, "report-no": "Technical report # DISI-12-003, DISI, University of Trento, Italy", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the contexts of automated reasoning and formal verification, important\ndecision problems are effectively encoded into Satisfiability Modulo Theories\n(SMT). In the last decade efficient SMT solvers have been developed for several\ntheories of practical interest (e.g., linear arithmetic, arrays, bit-vectors).\nSurprisingly, very few work has been done to extend SMT to deal with\noptimization problems; in particular, we are not aware of any work on SMT\nsolvers able to produce solutions which minimize cost functions over\narithmetical variables. This is unfortunate, since some problems of interest\nrequire this functionality.\n  In this paper we start filling this gap. We present and discuss two general\nprocedures for leveraging SMT to handle the minimization of LA(Q) cost\nfunctions, combining SMT with standard minimization techniques. We have\nimplemented the proposed approach within the MathSAT SMT solver. Due to the\nlack of competitors in AR and SMT domains, we experimentally evaluated our\nimplementation against state-of-the-art tools for the domain of linear\ngeneralized disjunctive programming (LGDP), which is closest in spirit to our\ndomain, on sets of problems which have been previously proposed as benchmarks\nfor the latter tools. The results show that our tool is very competitive with,\nand often outperforms, these tools on these problems, clearly demonstrating the\npotential of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 13:05:30 GMT"}], "update_date": "2012-02-08", "authors_parsed": [["Sebastiani", "Roberto", ""], ["Tomasi", "Silvia", ""]]}, {"id": "1202.1641", "submitter": "Ugo Dal Lago", "authors": "Beniamino Accattoli, Ugo Dal Lago", "title": "On the Invariance of the Unitary Cost Model for Head Reduction (Long\n  Version)", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lambda calculus is a widely accepted computational model of higher-order\nfunctional pro- grams, yet there is not any direct and universally accepted\ncost model for it. As a consequence, the computational difficulty of reducing\nlambda terms to their normal form is typically studied by reasoning on concrete\nimplementation algorithms. In this paper, we show that when head reduction is\nthe underlying dynamics, the unitary cost model is indeed invariant. This\nimproves on known results, which only deal with weak (call-by-value or\ncall-by-name) reduction. Invariance is proved by way of a linear calculus of\nexplicit substitutions, which allows to nicely decompose any head reduction\nstep in the lambda calculus into more elementary substitution steps, thus\nmaking the combinatorics of head-reduction easier to reason about. The\ntechnique is also a promising tool to attack what we see as the main open\nproblem, namely understanding for which normalizing strategies derivation\ncomplexity is an invariant cost model, if any.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 10:02:15 GMT"}], "update_date": "2012-02-09", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Lago", "Ugo Dal", ""]]}, {"id": "1202.1980", "submitter": "Alexander Kartzow", "authors": "Alexander Kartzow", "title": "First-Order Logic on Higher-Order Nested Pushdown Trees", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new hierarchy of higher-order nested pushdown trees\ngeneralising Alur et al.'s concept of nested pushdown trees. Nested pushdown\ntrees are useful representations of control flows in the verification of\nprograms with recursive calls of first-order functions. Higher-order nested\npushdown trees are expansions of unfoldings of graphs generated by higher-order\npushdown systems. Moreover, the class of nested pushdown trees of level n is\nuniformly first-order interpretable in the class of collapsible pushdown graphs\nof level n+1. The relationship between the class of higher-order pushdown\ngraphs and the class of collapsible higher-order pushdown graphs is not very\nwell understood. We hope that the further study of the nested pushdown tree\nhierarchy leads to a better understanding of these two hierarchies. In this\npaper, we are concerned with the first-order model checking problem on\nhigher-order nested pushdown trees. We show that the first-order model checking\non the first two levels of this hierarchy is decidable. Moreover, we obtain an\n2-EXPSPACE algorithm for the class of nested pushdown trees of level 1. The\nproof technique involves a pseudo-local analysis of strategies in the\nEhrenfeucht-Fraisse games on two identical copies of a nested pushdown tree.\nOrdinary locality arguments in the spirit of Gaifman's lemma do not apply here\nbecause nested pushdown trees tend to have small diameters. We introduce the\nnotion of relevant ancestors which provide a sufficient description of the FO_k\n-type of each element in a higher-order nested pushdown tree. The local\nanalysis of these ancestors allows us to prove the existence of restricted\nwinning strategies in the Ehrenfeucht-Fraisse game. These strategies are then\nused to create a first-order model checking algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 13:37:40 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Kartzow", "Alexander", ""]]}, {"id": "1202.2296", "submitter": "Sam Buss", "authors": "Maria Luisa Bonet and Sam Buss", "title": "An Improved Separation of Regular Resolution from Pool Resolution and\n  Clause Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the graph tautology principles of Alekhnovich, Johannsen,\nPitassi and Urquhart have polynomial size pool resolution refutations that use\nonly input lemmas as learned clauses and without degenerate resolution\ninferences. We also prove that these graph tautology principles can be refuted\nby polynomial size DPLL proofs with clause learning, even when restricted to\ngreedy, unit-propagating DPLL search.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 16:19:17 GMT"}, {"version": "v2", "created": "Tue, 22 May 2012 00:34:50 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Bonet", "Maria Luisa", ""], ["Buss", "Sam", ""]]}, {"id": "1202.2407", "submitter": "EPTCS", "authors": "James Chapman (Institute of Cybernetics, Tallinn), Paul Blain Levy\n  (University of Birmingham)", "title": "Proceedings Fourth Workshop on Mathematically Structured Functional\n  Programming", "comments": null, "journal-ref": "EPTCS 76, 2012", "doi": "10.4204/EPTCS.76", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Fourth Workshop on Mathematically\nStructured Functional Programming (MSFP 2012), taking place on 25 March, 2012\nin Tallinn, Estonia, as a satellite event of the European Joint Conferences on\nTheory and Practice of Software, ETAPS 2012.\n  MSFP is devoted to the derivation of functionality from structure. It\nhighlights concepts from algebra, semantics and type theory as they are\nincreasingly reflected in programming practice, especially functional\nprogramming. The workshop consists of two invited presentations and eight\ncontributed papers on a range of topics at that interface.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2012 03:55:47 GMT"}], "update_date": "2012-02-14", "authors_parsed": [["Chapman", "James", "", "Institute of Cybernetics, Tallinn"], ["Levy", "Paul Blain", "", "University of Birmingham"]]}, {"id": "1202.2918", "submitter": "EPTCS", "authors": "Chris Casinghino (University of Pennsylvania), Vilhelm Sj\\\"oberg\n  (University of Pennsylvania), Stephanie Weirich (University of Pennsylvania)", "title": "Step-Indexed Normalization for a Language with General Recursion", "comments": "In Proceedings MSFP 2012, arXiv:1202.2407", "journal-ref": "EPTCS 76, 2012, pp. 25-39", "doi": "10.4204/EPTCS.76.4", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Trellys project has produced several designs for practical dependently\ntyped languages. These languages are broken into two\nfragments-a_logical_fragment where every term normalizes and which is\nconsistent when interpreted as a logic, and a_programmatic_fragment with\ngeneral recursion and other convenient but unsound features. In this paper, we\npresent a small example language in this style. Our design allows the\nprogrammer to explicitly mention and pass information between the two\nfragments. We show that this feature substantially complicates the metatheory\nand present a new technique, combining the traditional Girard-Tait method with\nstep-indexed logical relations, which we use to show normalization for the\nlogical fragment.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 03:01:23 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Casinghino", "Chris", "", "University of Pennsylvania"], ["Sj\u00f6berg", "Vilhelm", "", "University of Pennsylvania"], ["Weirich", "Stephanie", "", "University of Pennsylvania"]]}, {"id": "1202.3174", "submitter": "EPTCS", "authors": "Dale Miller (INRIA-Saclay, France), Zolt\\'an \\'Esik (University of\n  Szeged, Hungary)", "title": "Proceedings 8th Workshop on Fixed Points in Computer Science", "comments": "For more information about FICS 2012, please visit the webpage of the\n  conference: http://www.inf.u-szeged.hu/fics2012/", "journal-ref": "EPTCS 77, 2012", "doi": "10.4204/EPTCS.77", "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Eighth Workshop on Fixed Points\nin Computer Science which took place on 24 March 2012 in Tallinn, Estonia as an\nETAPS-affiliated workshop. Past workshops have been held in Brno (1998,\nMFCS/CSL workshop), Paris (2000, LC workshop), Florence (2001, PLI workshop),\nCopenhagen (2002, LICS (FLoC) workshop), Warsaw (2003, ETAPS workshop), Coimbra\n(2009, CSL workshop), and Brno (2010, MFCS-CSL workshop).\n  Fixed points play a fundamental role in several areas of computer science and\nlogic by justifying induction and recursive definitions. The construction and\nproperties of fixed points have been investigated in many different frameworks\nsuch as: design and implementation of programming languages, program logics,\nand databases. The aim of this workshop is to provide a forum for researchers\nto present their results to those members of the computer science and logic\ncommunities who study or apply the theory of fixed points.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 23:15:54 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Miller", "Dale", "", "INRIA-Saclay, France"], ["\u00c9sik", "Zolt\u00e1n", "", "University of\n  Szeged, Hungary"]]}, {"id": "1202.3264", "submitter": "Jacob Vosmaer", "authors": "Yde Venema, Steve Vickers and Jacob Vosmaer", "title": "Generalized powerlocales via relation lifting", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an endofunctor $\\VT$ on the category of frames,\nparametrized by an endofunctor $\\T$ on the category $\\Set$ that satisfies\ncertain constraints. This generalizes Johnstone's construction of the Vietoris\npowerlocale, in the sense that his construction is obtained by taking for $\\T$\nthe finite covariant power set functor. Our construction of the\n$\\T$-powerlocale $\\VT \\bbL$ out of a frame $\\bbL$ is based on ideas from\ncoalgebraic logic and makes explicit the connection between the Vietoris\nconstruction and Moss's coalgebraic cover modality.\n  We show how to extend certain natural transformations between set functors to\nnatural transformations between $\\T$-powerlocale functors. Finally, we prove\nthat the operation $\\VT$ preserves some properties of frames, such as\nregularity, zero-dimensionality, and the combination of zero-dimensionality and\ncompactness.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2012 10:32:31 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Venema", "Yde", ""], ["Vickers", "Steve", ""], ["Vosmaer", "Jacob", ""]]}, {"id": "1202.3317", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago, Paolo Parisen Toldin", "title": "An Higher-Order Characterization of Probabilistic Polynomial Time (Long\n  Version)", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RSLR, an implicit higher-order characterization of the class PP of\nthose problems which can be decided in probabilistic polynomial time with error\nprobability smaller than 1/2. Analogously, a (less implicit) characterization\nof the class BPP can be obtained. RSLR is an extension of Hofmann's SLR with a\nprobabilistic primitive, which enjoys basic properties such as subject\nreduction and confluence. Polynomial time soundness of RSLR is obtained by\nsyntactical means, as opposed to the standard literature on SLR-derived\nsystems, which use semantics in an essential way.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2012 14:21:42 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Toldin", "Paolo Parisen", ""]]}, {"id": "1202.3355", "submitter": "Alexander Lauser", "authors": "Manfred Kufleitner and Alexander Lauser", "title": "Lattices of Logical Fragments over Words", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR no. 2012/03", "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an abstract notion of fragments of monadic second-order\nlogic. This concept is based on purely syntactic closure properties. We show\nthat over finite words, every logical fragment defines a lattice of languages\nwith certain closure properties. Among these closure properties are residuals\nand inverse C-morphisms. Here, depending on certain closure properties of the\nfragment, C is the family of arbitrary, non-erasing, length-preserving,\nlength-multiplying, or length-reducing morphisms. In particular, definability\nin a certain fragment can often be characterized in terms of the syntactic\nmorphism. This work extends a result of Straubing in which he investigated\ncertain restrictions of first-order logic formulae. In contrast to Straubing's\nmodel-theoretic approach, our notion of a logical fragment is purely syntactic\nand it does not rely on Ehrenfeucht-Fraisse games.\n  As motivating examples, we present (1) a fragment which captures the\nstutter-invariant part of piecewise-testable languages and (2) an acyclic\nfragment of Sigma_2. As it turns out, the latter has the same expressive power\nas two-variable first-order logic FO^2.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2012 16:32:24 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2012 17:14:14 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Kufleitner", "Manfred", ""], ["Lauser", "Alexander", ""]]}, {"id": "1202.3484", "submitter": "Yuan Feng", "authors": "Yuan Feng, Yuxin Deng, and Mingsheng Ying", "title": "Symbolic bisimulation for quantum processes", "comments": "30 pages, 7 figures, comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the previous notions of bisimulation presented in literature, to check\nif two quantum processes are bisimilar, we have to instantiate the free quantum\nvariables of them with arbitrary quantum states, and verify the bisimilarity of\nresultant configurations. This makes checking bisimilarity infeasible from an\nalgorithmic point of view because quantum states constitute a continuum. In\nthis paper, we introduce a symbolic operational semantics for quantum processes\ndirectly at the quantum operation level, which allows us to describe the\nbisimulation between quantum processes without resorting to quantum states. We\nshow that the symbolic bisimulation defined here is equivalent to the open\nbisimulation for quantum processes in the previous work, when strong\nbisimulations are considered. An algorithm for checking symbolic ground\nbisimilarity is presented. We also give a modal logical characterisation for\nquantum bisimilarity based on an extension of Hennessy-Milner logic to quantum\nprocesses.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 01:11:36 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2012 04:49:01 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Feng", "Yuan", ""], ["Deng", "Yuxin", ""], ["Ying", "Mingsheng", ""]]}, {"id": "1202.3496", "submitter": "EPTCS", "authors": "Andreas Abel (Department of Computer Science,\n  Ludwig-Maximilians-University Munich)", "title": "Type-Based Termination, Inflationary Fixed-Points, and Mixed\n  Inductive-Coinductive Types", "comments": "In Proceedings FICS 2012, arXiv:1202.3174", "journal-ref": "EPTCS 77, 2012, pp. 1-11", "doi": "10.4204/EPTCS.77.1", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type systems certify program properties in a compositional way. From a bigger\nprogram one can abstract out a part and certify the properties of the resulting\nabstract program by just using the type of the part that was abstracted away.\nTermination and productivity are non-trivial yet desired program properties,\nand several type systems have been put forward that guarantee termination,\ncompositionally. These type systems are intimately connected to the definition\nof least and greatest fixed-points by ordinal iteration. While most type\nsystems use conventional iteration, we consider inflationary iteration in this\narticle. We demonstrate how this leads to a more principled type system, with\nrecursion based on well-founded induction. The type system has a prototypical\nimplementation, MiniAgda, and we show in particular how it certifies\nproductivity of corecursive and mixed recursive-corecursive functions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 02:41:10 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Abel", "Andreas", "", "Department of Computer Science,\n  Ludwig-Maximilians-University Munich"]]}, {"id": "1202.3497", "submitter": "EPTCS", "authors": "Luca Aceto, Anna Ing\\'olfsd\\'ottir", "title": "Characteristic Formulae for Relations with Nested Fixed Points", "comments": "In Proceedings FICS 2012, arXiv:1202.3174", "journal-ref": "EPTCS 77, 2012, pp. 15-22", "doi": "10.4204/EPTCS.77.3", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general framework for the connection between characteristic formulae and\nbehavioral semantics is described in [2]. This approach does not suitably cover\nsemantics defined by nested fixed points, such as the n-nested simulation\nsemantics for n greater than 2. In this study we address this deficiency and\ngive a description of nested fixed points that extends the approach for single\nfixed points in an intuitive and comprehensive way.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 02:41:15 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Aceto", "Luca", ""], ["Ing\u00f3lfsd\u00f3ttir", "Anna", ""]]}, {"id": "1202.3498", "submitter": "EPTCS", "authors": "Axel Haddad (LIGM & LIAFA)", "title": "IO vs OI in Higher-Order Recursion Schemes", "comments": "In Proceedings FICS 2012, arXiv:1202.3174", "journal-ref": "EPTCS 77, 2012, pp. 23-30", "doi": "10.4204/EPTCS.77.4", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a study of the modes of derivation of higher-order recursion\nschemes, proving that value trees obtained from schemes using\ninnermost-outermost derivations (IO) are the same as those obtained using\nunrestricted derivations. Given that higher-order recursion schemes can be used\nas a model of functional programs, innermost-outermost derivations policy\nrepresents a theoretical view point of call by value evaluation strategy.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 02:41:23 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Haddad", "Axel", "", "LIGM & LIAFA"]]}, {"id": "1202.3499", "submitter": "EPTCS", "authors": "Andr\\'e Hirschowitz (Laboratoire J.-A. Dieudonn\\'e, Universit\\'e de\n  Nice - Sophia Antipolis), Marco Maggesi (Dipartimento di Matematica \"U.\n  Dini\", Universit\\`a degli Studi di Firenze)", "title": "Initial Semantics for Strengthened Signatures", "comments": "In Proceedings FICS 2012, arXiv:1202.3174", "journal-ref": "EPTCS 77, 2012, pp. 31-38", "doi": "10.4204/EPTCS.77.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new general definition of arity, yielding the companion notions of\nsignature and associated syntax. This setting is modular in the sense requested\nby Ghani and Uustalu: merging two extensions of syntax corresponds to building\nan amalgamated sum. These signatures are too general in the sense that we are\nnot able to prove the existence of an associated syntax in this general\ncontext. So we have to select arities and signatures for which there exists the\ndesired initial monad. For this, we follow a track opened by Matthes and\nUustalu: we introduce a notion of strengthened arity and prove that the\ncorresponding signatures have initial semantics (i.e. associated syntax). Our\nstrengthened arities admit colimits, which allows the treatment of the\n\\lambda-calculus with explicit substitution.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 02:41:30 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Hirschowitz", "Andr\u00e9", "", "Laboratoire J.-A. Dieudonn\u00e9, Universit\u00e9 de\n  Nice - Sophia Antipolis"], ["Maggesi", "Marco", "", "Dipartimento di Matematica \"U.\n  Dini\", Universit\u00e0 degli Studi di Firenze"]]}, {"id": "1202.3500", "submitter": "EPTCS", "authors": "Martin Lange (School of Electrical Engineering and Computer Science,\n  University of Kassel, Germany), Etienne Lozes (School of Electrical\n  Engineering and Computer Science, University of Kassel, Germany)", "title": "Model-Checking the Higher-Dimensional Modal mu-Calculus", "comments": "In Proceedings FICS 2012, arXiv:1202.3174", "journal-ref": "EPTCS 77, 2012, pp. 39-46", "doi": "10.4204/EPTCS.77.6", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The higher-dimensional modal mu-calculus is an extension of the mu-calculus\nin which formulas are interpreted in tuples of states of a labeled transition\nsystem. Every property that can be expressed in this logic can be checked in\npolynomial time, and conversely every polynomial-time decidable problem that\nhas a bisimulation-invariant encoding into labeled transition systems can also\nbe defined in the higher-dimensional modal mu-calculus. We exemplify the latter\nconnection by giving several examples of decision problems which reduce to\nmodel checking of the higher-dimensional modal mu-calculus for some fixed\nformulas. This way generic model checking algorithms for the logic can then be\nused via partial evaluation in order to obtain algorithms for theses problems\nwhich may benefit from improvements that are well-established in the field of\nprogram verification, namely on-the-fly and symbolic techniques. The aim of\nthis work is to extend such techniques to other fields as well, here\nexemplarily done for process equivalences, automata theory, parsing, string\nproblems, and games.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 02:41:37 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Lange", "Martin", "", "School of Electrical Engineering and Computer Science,\n  University of Kassel, Germany"], ["Lozes", "Etienne", "", "School of Electrical\n  Engineering and Computer Science, University of Kassel, Germany"]]}, {"id": "1202.3501", "submitter": "EPTCS", "authors": "Grigori Mints, Thomas Studer", "title": "Cut-elimination for the mu-calculus with one variable", "comments": "In Proceedings FICS 2012, arXiv:1202.3174", "journal-ref": "EPTCS 77, 2012, pp. 47-54", "doi": "10.4204/EPTCS.77.7", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish syntactic cut-elimination for the one-variable fragment of the\nmodal mu-calculus. Our method is based on a recent cut-elimination technique by\nMints that makes use of Buchholz' Omega-rule.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 02:41:43 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Mints", "Grigori", ""], ["Studer", "Thomas", ""]]}, {"id": "1202.3502", "submitter": "EPTCS", "authors": "Tarmo Uustalu", "title": "Structured general corecursion and coinductive graphs [extended\n  abstract]", "comments": "In Proceedings FICS 2012, arXiv:1202.3174", "journal-ref": "EPTCS 77, 2012, pp. 55-61", "doi": "10.4204/EPTCS.77.8", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bove and Capretta's popular method for justifying function definitions by\ngeneral recursive equations is based on the observation that any structured\ngeneral recursion equation defines an inductive subset of the intended domain\n(the \"domain of definedness\") for which the equation has a unique solution. To\naccept the definition, it is hence enough to prove that this subset contains\nthe whole intended domain.\n  This approach works very well for \"terminating\" definitions. But it fails to\naccount for \"productive\" definitions, such as typical definitions of\nstream-valued functions. We argue that such definitions can be treated in a\nsimilar spirit, proceeding from a different unique solvability criterion. Any\nstructured recursive equation defines a coinductive relation between the\nintended domain and intended codomain (the \"coinductive graph\"). This relation\nin turn determines a subset of the intended domain and a quotient of the\nintended codomain with the property that the equation is uniquely solved for\nthe subset and quotient. The equation is therefore guaranteed to have a unique\nsolution for the intended domain and intended codomain whenever the subset is\nthe full set and the quotient is by equality.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 02:41:50 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Uustalu", "Tarmo", ""]]}, {"id": "1202.3538", "submitter": "Hans van Ditmarsch", "authors": "Laura Bozzelli, Hans van Ditmarsch, Tim French, James Hales, and\n  Sophie Pinchinat", "title": "Refinement Modal Logic", "comments": null, "journal-ref": "Information and Computation, Volume 239, December 2014, Pages\n  303-339", "doi": "10.1016/j.ic.2014.07.013", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present {\\em refinement modal logic}. A refinement is like a\nbisimulation, except that from the three relational requirements only `atoms'\nand `back' need to be satisfied. Our logic contains a new operator 'all' in\naddition to the standard modalities 'box' for each agent. The operator 'all'\nacts as a quantifier over the set of all refinements of a given model. As a\nvariation on a bisimulation quantifier, this refinement operator or refinement\nquantifier 'all' can be seen as quantifying over a variable not occurring in\nthe formula bound by it. The logic combines the simplicity of multi-agent modal\nlogic with some powers of monadic second-order quantification. We present a\nsound and complete axiomatization of multi-agent refinement modal logic. We\nalso present an extension of the logic to the modal mu-calculus, and an\naxiomatization for the single-agent version of this logic. Examples and\napplications are also discussed: to software verification and design (the set\nof agents can also be seen as a set of actions), and to dynamic epistemic\nlogic. We further give detailed results on the complexity of satisfiability,\nand on succinctness.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 09:13:18 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2013 09:29:30 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Bozzelli", "Laura", ""], ["van Ditmarsch", "Hans", ""], ["French", "Tim", ""], ["Hales", "James", ""], ["Pinchinat", "Sophie", ""]]}, {"id": "1202.3672", "submitter": "{\\L}ukasz Czajka", "authors": "{\\L}ukasz Czajka", "title": "Higher-order illative combinatory logic", "comments": null, "journal-ref": "Journal of Symbolic Logic, vol. 78, issue 3, pp. 837-872, 2013", "doi": null, "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a model construction for a system of higher-order illative\ncombinatory logic $\\mathcal{I}_\\omega$, thus establishing its strong\nconsistency. We also use a variant of this construction to provide a complete\nembedding of first-order intuitionistic predicate logic with second-order\npropositional quantifiers into the system $\\mathcal{I}_0$ of Barendregt, Bunder\nand Dekkers, which gives a partial answer to a question posed by these authors.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 19:18:01 GMT"}, {"version": "v10", "created": "Sat, 9 Jul 2016 20:40:52 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2012 18:12:12 GMT"}, {"version": "v3", "created": "Tue, 14 Aug 2012 14:13:46 GMT"}, {"version": "v4", "created": "Wed, 29 Aug 2012 19:30:33 GMT"}, {"version": "v5", "created": "Wed, 3 Oct 2012 21:50:41 GMT"}, {"version": "v6", "created": "Sat, 9 Mar 2013 14:54:41 GMT"}, {"version": "v7", "created": "Thu, 27 Feb 2014 23:11:27 GMT"}, {"version": "v8", "created": "Thu, 20 Nov 2014 19:40:46 GMT"}, {"version": "v9", "created": "Sun, 16 Aug 2015 12:44:49 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Czajka", "\u0141ukasz", ""]]}, {"id": "1202.3957", "submitter": "Diego Figueira", "authors": "Diego Figueira (INRIA & ENS Cachan, LSV)", "title": "Alternating register automata on finite words and trees", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 9,\n  2012) lmcs:907", "doi": "10.2168/LMCS-8(1:22)2012", "report-no": null, "categories": "cs.DB cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study alternating register automata on data words and data trees in\nrelation to logics. A data word (resp. data tree) is a word (resp. tree) whose\nevery position carries a label from a finite alphabet and a data value from an\ninfinite domain. We investigate one-way automata with alternating control over\ndata words or trees, with one register for storing data and comparing them for\nequality. This is a continuation of the study started by Demri, Lazic and\nJurdzinski. From the standpoint of register automata models, this work aims at\ntwo objectives: (1) simplifying the existent decidability proofs for the\nemptiness problem for alternating register automata; and (2) exhibiting\ndecidable extensions for these models. From the logical perspective, we show\nthat (a) in the case of data words, satisfiability of LTL with one register and\nquantification over data values is decidable; and (b) the satisfiability\nproblem for the so-called forward fragment of XPath on XML documents is\ndecidable, even in the presence of DTDs and even of key constraints. The\ndecidability is obtained through a reduction to the automata model introduced.\nThis fragment contains the child, descendant, next-sibling and\nfollowing-sibling axes, as well as data equality and inequality tests.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 16:38:10 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2012 23:57:49 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Figueira", "Diego", "", "INRIA & ENS Cachan, LSV"]]}, {"id": "1202.4144", "submitter": "Adolfo Neto", "authors": "Adolfo Neto, Celso A. A. Kaestner and Marcelo Finger", "title": "Towards an efficient prover for the C1 paraconsistent logic", "comments": "16 pages", "journal-ref": "Electronic Notes in Theoretical Computer Science. Volume 256, 2\n  December 2009, Pages 87-102. Proceedings of the Fourth Workshop on Logical\n  and Semantic Frameworks, with Applications (LSFA 2009)", "doi": "10.1016/j.entcs.2009.11.007", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The KE inference system is a tableau method developed by Marco Mondadori\nwhich was presented as an improvement, in the computational efficiency sense,\nover Analytic Tableaux. In the literature, there is no description of a theorem\nprover based on the KE method for the C1 paraconsistent logic. Paraconsistent\nlogics have several applications, such as in robot control and medicine. These\napplications could benefit from the existence of such a prover. We present a\nsound and complete KE system for C1, an informal specification of a strategy\nfor the C1 prover as well as problem families that can be used to evaluate\nprovers for C1. The C1 KE system and the strategy described in this paper will\nbe used to implement a KE based prover for C1, which will be useful for those\nwho study and apply paraconsistent logics.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 11:14:50 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Neto", "Adolfo", ""], ["Kaestner", "Celso A. A.", ""], ["Finger", "Marcelo", ""]]}, {"id": "1202.4175", "submitter": "Nisarg Shah", "authors": "Krishnendu Chatterjee and Manas Joglekar and Nisarg Shah", "title": "Average Case Analysis of the Classical Algorithm for Markov Decision\n  Processes with B\\\"uchi Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov decision processes (MDPs) with $\\omega$-regular\nspecifications given as parity objectives. We consider the problem of computing\nthe set of almost-sure winning vertices from where the objective can be ensured\nwith probability 1. The algorithms for the computation of the almost-sure\nwinning set for parity objectives iteratively use the solutions for the\nalmost-sure winning set for B\\\"uchi objectives (a special case of parity\nobjectives). We study for the first time the average case complexity of the\nclassical algorithm for computing almost-sure winning vertices for MDPs with\nB\\\"uchi objectives. Our contributions are as follows: First, we show that for\nMDPs with constant out-degree the expected number of iterations is at most\nlogarithmic and the average case running time is linear (as compared to the\nworst case linear number of iterations and quadratic time complexity). Second,\nwe show that for general MDPs the expected number of iterations is constant and\nthe average case running time is linear (again as compared to the worst case\nlinear number of iterations and quadratic time complexity). Finally we also\nshow that given all graphs are equally likely, the probability that the\nclassical algorithm requires more than constant number of iterations is\nexponentially small.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 18:22:02 GMT"}, {"version": "v2", "created": "Sun, 15 Jul 2012 19:47:32 GMT"}, {"version": "v3", "created": "Thu, 4 Oct 2012 09:02:54 GMT"}, {"version": "v4", "created": "Wed, 19 Nov 2014 20:58:50 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Joglekar", "Manas", ""], ["Shah", "Nisarg", ""]]}, {"id": "1202.4193", "submitter": "Roman Kontchakov", "authors": "Stanislav Kikot and Roman Kontchakov and Vladimir Podolskii and\n  Michael Zakharyaschev", "title": "Exponential Lower Bounds and Separation for Query Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish connections between the size of circuits and formulas computing\nmonotone Boolean functions and the size of first-order and nonrecursive Datalog\nrewritings for conjunctive queries over OWL 2 QL ontologies. We use known lower\nbounds and separation results from circuit complexity to prove similar results\nfor the size of rewritings that do not use non-signature constants. For\nexample, we show that, in the worst case, positive existential and nonrecursive\nDatalog rewritings are exponentially longer than the original queries;\nnonrecursive Datalog rewritings are in general exponentially more succinct than\npositive existential rewritings; while first-order rewritings can be\nsuperpolynomially more succinct than positive existential rewritings.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 22:28:54 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 12:51:33 GMT"}, {"version": "v3", "created": "Sun, 25 Mar 2012 13:32:29 GMT"}, {"version": "v4", "created": "Sun, 13 May 2012 14:29:53 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Kikot", "Stanislav", ""], ["Kontchakov", "Roman", ""], ["Podolskii", "Vladimir", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1202.4281", "submitter": "Amir Ben-Amram", "authors": "Amir M. Ben-Amram and Michael Vainer", "title": "Bounded Termination of Monotonicity-Constraint Transition Systems", "comments": "46 pages. Research has been presented at DICE 2011 (Saarbruecken,\n  Germany, March 2011), 2FC 2011 (Novi Sad, Serbia, May 2011) and DANSAS\n  (Odense, Denmark, August 2011). Revised (twice) to correct errors in previous\n  versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intuitively, if we can prove that a program terminates, we expect some\nconclusion regarding its complexity. But the passage from termination proofs to\ncomplexity bounds is not always clear. In this work we consider Monotonicity\nConstraint Transition Systems, a program abstraction where termination is\ndecidable (based on the size-change termination principle). We show that these\nprograms also have a decidable complexity property: one can determine whether\nthe length of all transition sequences can be bounded in terms of the initial\nstate. This is the Bounded Termination problem. Interestingly, if a bound\nexists, it must be polynomial. We prove that the bounded termination problem is\nPSPACE-complete.\n  We also discuss, theoretically, the use of bounds on the abstract program to\ninfer conclusions on a concrete program that has been abstracted. The\nconclusion maybe a polynomial time bound, or in other cases polynomial space or\nexponential time. We argue that the monotonicity-constraint abstraction\npromises to be useful for practical complexity analysis of programs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 10:24:52 GMT"}, {"version": "v2", "created": "Wed, 30 Apr 2014 11:10:54 GMT"}], "update_date": "2014-05-01", "authors_parsed": [["Ben-Amram", "Amir M.", ""], ["Vainer", "Michael", ""]]}, {"id": "1202.4509", "submitter": "EPTCS", "authors": "Simon Busard (UCLouvain, Belgium), Charles Pecheur (UCLouvain,\n  Belgium)", "title": "Rich Counter-Examples for Temporal-Epistemic Logic Model Checking", "comments": "In Proceedings IWIGP 2012, arXiv:1202.4229", "journal-ref": "EPTCS 78, 2012, pp. 39-53", "doi": "10.4204/EPTCS.78.4", "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking verifies that a model of a system satisfies a given property,\nand otherwise produces a counter-example explaining the violation. The verified\nproperties are formally expressed in temporal logics. Some temporal logics,\nsuch as CTL, are branching: they allow to express facts about the whole\ncomputation tree of the model, rather than on each single linear computation.\nThis branching aspect is even more critical when dealing with multi-modal\nlogics, i.e. logics expressing facts about systems with several transition\nrelations. A prominent example is CTLK, a logic that reasons about temporal and\nepistemic properties of multi-agent systems. In general, model checkers produce\nlinear counter-examples for failed properties, composed of a single computation\npath of the model. But some branching properties are only poorly and partially\nexplained by a linear counter-example.\n  This paper proposes richer counter-example structures called tree-like\nannotated counter-examples (TLACEs), for properties in Action-Restricted CTL\n(ARCTL), an extension of CTL quantifying paths restricted in terms of actions\nlabeling transitions of the model. These counter-examples have a branching\nstructure that supports more complete description of property violations.\nElements of these counter-examples are annotated with parts of the property to\ngive a better understanding of their structure. Visualization and browsing of\nthese richer counter-examples become a critical issue, as the number of\nbranches and states can grow exponentially for deeply-nested properties.\n  This paper formally defines the structure of TLACEs, characterizes adequate\ncounter-examples w.r.t. models and failed properties, and gives a generation\nalgorithm for ARCTL properties. It also illustrates the approach with examples\nin CTLK, using a reduction of CTLK to ARCTL. The proposed approach has been\nimplemented, first by extending the NuSMV model checker to generate and export\nbranching counter-examples, secondly by providing an interactive graphical\ninterface to visualize and browse them.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2012 01:41:57 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Busard", "Simon", "", "UCLouvain, Belgium"], ["Pecheur", "Charles", "", "UCLouvain,\n  Belgium"]]}, {"id": "1202.4535", "submitter": "EPTCS", "authors": "Pedro Quaresma (University of Coimbra, Portugal), Ralph-Johan Back\n  ({\\AA}bo Akademi University, Finland)", "title": "Proceedings First Workshop on CTP Components for Educational Software", "comments": null, "journal-ref": "EPTCS 79, 2012", "doi": "10.4204/EPTCS.79", "report-no": null, "categories": "cs.SY cs.LO cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The THedu'11 workshop received thirteen submissions, twelve of which were\naccepted and presented during the workshop. For the post-conference proceedings\nnine submission where received and accepted. The submissions are within the\nscope of the following points, which have been announced in the call of papers:\nCTP-based software tools for education; CTP technology combined with novel\ninterfaces, drag and drop, etc.; technologies to access ITP knowledge relevant\nfor a certain step of problem solving; usability considerations on representing\nITP knowledge; combination of deduction and computation; formal problem\nspecifications; effectiveness of ATP in checking user input; formats for\ndeductive content in proof documents, geometric constructions, etc; formal\ndomain models for e-learning in mathematics and applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2012 05:56:10 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Quaresma", "Pedro", "", "University of Coimbra, Portugal"], ["Back", "Ralph-Johan", "", "\u00c5bo Akademi University, Finland"]]}, {"id": "1202.4678", "submitter": "Barbara Petit", "authors": "Barbara Petit", "title": "A Categorical Model for the Lambda Calculus with Constructors", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lambda calculus with constructors is an extension of the lambda calculus\nwith variadic constructors. It decomposes the pattern-matching a la ML into a\ncase analysis on constants and a commutation rule between case and application\nconstructs. Although this commutation rule does not match with the usual\ncomputing intuitions, it makes the calculus expressive and confluent, with a\nrather simple syntax. In this paper we define a sound notion of categorical\nmodel for the lambda calculus with constructors. We then prove that this\ndefinition is complete for the fragment of the calculus with no match-failure,\nusing the model of partial equivalence relations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2012 15:48:06 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2012 14:16:59 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Petit", "Barbara", ""]]}, {"id": "1202.4824", "submitter": "Daniel Borchmann", "authors": "Daniel Borchmann", "title": "A General Form of Attribute Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general form of attribute exploration, a knowledge completion\nalgorithm from Formal Concept Analysis. The aim of our presentation is not only\nto extend the applicability of attribute exploration by a general description.\nIt may also allow to view different existing variants of attribute exploration\nas instances of a general form, which may simplify theoretical considerations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:05:06 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Borchmann", "Daniel", ""]]}, {"id": "1202.4828", "submitter": "EPTCS", "authors": "Serge Autexier (German Research Center for Artificial Intelligence\n  (DFKI), Bremen, Germany), Dominik Dietrich (German Research Center for\n  Artificial Intelligence (DFKI), Bremen, Germany), Marvin Schiller (Brunel\n  University, London, UK)", "title": "Towards an Intelligent Tutor for Mathematical Proofs", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 1-28", "doi": "10.4204/EPTCS.79.1", "report-no": null, "categories": "cs.AI cs.LO cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-supported learning is an increasingly important form of study since\nit allows for independent learning and individualized instruction. In this\npaper, we discuss a novel approach to developing an intelligent tutoring system\nfor teaching textbook-style mathematical proofs. We characterize the\nparticularities of the domain and discuss common ITS design models. Our\napproach is motivated by phenomena found in a corpus of tutorial dialogs that\nwere collected in a Wizard-of-Oz experiment. We show how an intelligent tutor\nfor textbook-style mathematical proofs can be built on top of an adapted\nassertion-level proof assistant by reusing representations and proof search\nstrategies originally developed for automated and interactive theorem proving.\nThe resulting prototype was successfully evaluated on a corpus of tutorial\ndialogs and yields good results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:41:20 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Autexier", "Serge", "", "German Research Center for Artificial Intelligence"], ["Dietrich", "Dominik", "", "German Research Center for\n  Artificial Intelligence"], ["Schiller", "Marvin", "", "Brunel\n  University, London, UK"]]}, {"id": "1202.4829", "submitter": "EPTCS", "authors": "Ralph-Johan Back ({\\AA}bo Akademi University), Johannes Eriksson\n  ({\\AA}bo Akademi University)", "title": "An Exercise in Invariant-based Programming with Interactive and\n  Automatic Theorem Prover Support", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 29-48", "doi": "10.4204/EPTCS.79.2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariant-Based Programming (IBP) is a diagram-based correct-by-construction\nprogramming methodology in which the program is structured around the\ninvariants, which are additionally formulated before the actual code. Socos is\na program construction and verification environment built specifically to\nsupport IBP. The front-end to Socos is a graphical diagram editor, allowing the\nprogrammer to construct invariant-based programs and check their correctness.\nThe back-end component of Socos, the program checker, computes the verification\nconditions of the program and tries to prove them automatically. It uses the\ntheorem prover PVS and the SMT solver Yices to discharge as many of the\nverification conditions as possible without user interaction. In this paper, we\nfirst describe the Socos environment from a user and systems level perspective;\nwe then exemplify the IBP workflow by building a verified implementation of\nheapsort in Socos. The case study highlights the role of both automatic and\ninteractive theorem proving in three sequential stages of the IBP workflow:\ndeveloping the background theory, formulating the program specification and\ninvariants, and proving the correctness of the final implementation.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:41:29 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Back", "Ralph-Johan", "", "\u00c5bo Akademi University"], ["Eriksson", "Johannes", "", "\u00c5bo Akademi University"]]}, {"id": "1202.4831", "submitter": "EPTCS", "authors": "Filip Mari\\'c (Faculty of Mathematics, University of Belgrade,\n  Serbia), Ivan Petrovi\\'c (Faculty of Mathematics, University of Belgrade,\n  Serbia), Danijela Petrovi\\'c (Faculty of Mathematics, University of Belgrade,\n  Serbia), Predrag Jani\\v{c}i\\'c (Faculty of Mathematics, University of\n  Belgrade, Serbia)", "title": "Formalization and Implementation of Algebraic Methods in Geometry", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 63-81", "doi": "10.4204/EPTCS.79.4", "report-no": null, "categories": "cs.SC cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our ongoing project of formalization of algebraic methods for\ngeometry theorem proving (Wu's method and the Groebner bases method), their\nimplementation and integration in educational tools. The project includes\nformal verification of the algebraic methods within Isabelle/HOL proof\nassistant and development of a new, open-source Java implementation of the\nalgebraic methods. The project should fill-in some gaps still existing in this\narea (e.g., the lack of formal links between algebraic methods and synthetic\ngeometry and the lack of self-contained implementations of algebraic methods\nsuitable for integration with dynamic geometry tools) and should enable new\napplications of theorem proving in education.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:41:45 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Mari\u0107", "Filip", "", "Faculty of Mathematics, University of Belgrade,\n  Serbia"], ["Petrovi\u0107", "Ivan", "", "Faculty of Mathematics, University of Belgrade,\n  Serbia"], ["Petrovi\u0107", "Danijela", "", "Faculty of Mathematics, University of Belgrade,\n  Serbia"], ["Jani\u010di\u0107", "Predrag", "", "Faculty of Mathematics, University of\n  Belgrade, Serbia"]]}, {"id": "1202.4832", "submitter": "EPTCS", "authors": "Walther Neuper", "title": "Automated Generation of User Guidance by Combining Computation and\n  Deduction", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 82-101", "doi": "10.4204/EPTCS.79.5", "report-no": null, "categories": "cs.LO cs.HC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herewith, a fairly old concept is published for the first time and named\n\"Lucas Interpretation\". This has been implemented in a prototype, which has\nbeen proved useful in educational practice and has gained academic relevance\nwith an emerging generation of educational mathematics assistants (EMA) based\non Computer Theorem Proving (CTP).\n  Automated Theorem Proving (ATP), i.e. deduction, is the most reliable\ntechnology used to check user input. However ATP is inherently weak in\nautomatically generating solutions for arbitrary problems in applied\nmathematics. This weakness is crucial for EMAs: when ATP checks user input as\nincorrect and the learner gets stuck then the system should be able to suggest\npossible next steps.\n  The key idea of Lucas Interpretation is to compute the steps of a calculation\nfollowing a program written in a novel CTP-based programming language, i.e.\ncomputation provides the next steps. User guidance is generated by combining\ndeduction and computation: the latter is performed by a specific language\ninterpreter, which works like a debugger and hands over control to the learner\nat breakpoints, i.e. tactics generating the steps of calculation. The\ninterpreter also builds up logical contexts providing ATP with the data\nrequired for checking user input, thus combining computation and deduction.\n  The paper describes the concepts underlying Lucas Interpretation so that open\nquestions can adequately be addressed, and prerequisites for further work are\nprovided.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:41:51 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Neuper", "Walther", ""]]}, {"id": "1202.4834", "submitter": "EPTCS", "authors": "Wolfgang Schreiner", "title": "Computer-Assisted Program Reasoning Based on a Relational Semantics of\n  Programs", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 124-142", "doi": "10.4204/EPTCS.79.8", "report-no": null, "categories": "cs.LO cs.MS cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to program reasoning which inserts between a program\nand its verification conditions an additional layer, the denotation of the\nprogram expressed in a declarative form. The program is first translated into\nits denotation from which subsequently the verification conditions are\ngenerated. However, even before (and independently of) any verification\nattempt, one may investigate the denotation itself to get insight into the\n\"semantic essence\" of the program, in particular to see whether the denotation\nindeed gives reason to believe that the program has the expected behavior.\nErrors in the program and in the meta-information may thus be detected and\nfixed prior to actually performing the formal verification. More concretely,\nfollowing the relational approach to program semantics, we model the effect of\na program as a binary relation on program states. A formal calculus is devised\nto derive from a program a logic formula that describes this relation and is\nsubject for inspection and manipulation. We have implemented this idea in a\ncomprehensive form in the RISC ProgramExplorer, a new program reasoning\nenvironment for educational purposes which encompasses the previously developed\nRISC ProofNavigator as an interactive proving assistant.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:42:11 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Schreiner", "Wolfgang", ""]]}, {"id": "1202.4835", "submitter": "EPTCS", "authors": "Makarius Wenzel, Burkhart Wolff", "title": "Isabelle/PIDE as Platform for Educational Tools", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 143-153", "doi": "10.4204/EPTCS.79.9", "report-no": null, "categories": "cs.LO cs.AI cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Isabelle/PIDE platform addresses the question whether proof assistants of\nthe LCF family are suitable as technological basis for educational tools. The\ntraditionally strong logical foundations of systems like HOL, Coq, or Isabelle\nhave so far been counter-balanced by somewhat inaccessible interaction via the\nTTY (or minor variations like the well-known Proof General / Emacs interface).\nThus the fundamental question of math education tools with fully-formal\nbackground theories has often been answered negatively due to accidental\nweaknesses of existing proof engines.\n  The idea of \"PIDE\" (which means \"Prover IDE\") is to integrate existing\nprovers like Isabelle into a larger environment, that facilitates access by\nend-users and other tools. We use Scala to expose the proof engine in ML to the\nJVM world, where many user-interfaces, editor frameworks, and educational tools\nalready exist. This shall ultimately lead to combined mathematical assistants,\nwhere the logical engine is in the background, without obstructing the view on\napplications of formal methods, formalized mathematics, and math education in\nparticular.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:42:17 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Wenzel", "Makarius", ""], ["Wolff", "Burkhart", ""]]}, {"id": "1202.4905", "submitter": "Enrico Tassi", "authors": "Andrea Asperti (University of Bologna), Wilmer Ricciotti (University\n  of Bologna), Claudio Sacerdoti Coen (University of Bologna), Enrico Tassi\n  (INRIA - Microsoft Research)", "title": "A Bi-Directional Refinement Algorithm for the Calculus of (Co)Inductive\n  Constructions", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 2,\n  2012) lmcs:1044", "doi": "10.2168/LMCS-8(1:18)2012", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes the refinement algorithm for the Calculus of\n(Co)Inductive Constructions (CIC) implemented in the interactive theorem prover\nMatita. The refinement algorithm is in charge of giving a meaning to the terms,\ntypes and proof terms directly written by the user or generated by using\ntactics, decision procedures or general automation. The terms are written in an\n\"external syntax\" meant to be user friendly that allows omission of\ninformation, untyped binders and a certain liberal use of user defined\nsub-typing. The refiner modifies the terms to obtain related well typed terms\nin the internal syntax understood by the kernel of the ITP. In particular, it\nacts as a type inference algorithm when all the binders are untyped. The\nproposed algorithm is bi-directional: given a term in external syntax and a\ntype expected for the term, it propagates as much typing information as\npossible towards the leaves of the term. Traditional mono-directional\nalgorithms, instead, proceed in a bottom-up way by inferring the type of a\nsub-term and comparing (unifying) it with the type expected by its context only\nat the end. We propose some novel bi-directional rules for CIC that are\nparticularly effective. Among the benefits of bi-directionality we have better\nerror message reporting and better inference of dependent types. Moreover,\nthanks to bi-directionality, the coercion system for sub-typing is more\neffective and type inference generates simpler unification problems that are\nmore likely to be solved by the inherently incomplete higher order unification\nalgorithms implemented. Finally we introduce in the external syntax the notion\nof vector of placeholders that enables to omit at once an arbitrary number of\narguments. Vectors of placeholders allow a trivial implementation of implicit\narguments and greatly simplify the implementation of primitive and simple\ntactics.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 13:33:26 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2012 20:49:22 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Asperti", "Andrea", "", "University of Bologna"], ["Ricciotti", "Wilmer", "", "University\n  of Bologna"], ["Coen", "Claudio Sacerdoti", "", "University of Bologna"], ["Tassi", "Enrico", "", "INRIA - Microsoft Research"]]}, {"id": "1202.5850", "submitter": "Arnaud Sangnier", "authors": "Giorgio Delzanno, Arnaud Sangnier, Riccardo Traverso and Gianluigi\n  Zavattaro", "title": "The Cost of Parameterized Reachability in Mobile Ad Hoc Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the impact of spontaneous movement in the complexity of\nverification problems for an automata-based protocol model of networks with\nselective broadcast communication. We first consider reachability of an error\nstate and show that parameterized verification is decidable with polynomial\ncomplexity. We then move to richer queries and show how the complexity changes\nwhen considering properties with negation or cardinality constraints.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 08:28:11 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Delzanno", "Giorgio", ""], ["Sangnier", "Arnaud", ""], ["Traverso", "Riccardo", ""], ["Zavattaro", "Gianluigi", ""]]}, {"id": "1202.5961", "submitter": "Jannis Bulian", "authors": "Jannis Bulian and Ian Hodkinson", "title": "Bare canonicity of representable cylindric and polyadic algebras", "comments": null, "journal-ref": "Annals of Pure and Applied Logic 164 (2013), pp. 884-906", "doi": "10.1016/j.apal.2013.04.002", "report-no": null, "categories": "math.LO cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for finite n at least 3, every first-order axiomatisation of the\nvarieties of representable n-dimensional cylindric algebras, diagonal-free\ncylindric algebras, polyadic algebras, and polyadic equality algebras contains\nan infinite number of non-canonical formulas. We also show that the class of\nstructures for each of these varieties is non-elementary. The proofs employ\nalgebras derived from random graphs.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 14:56:09 GMT"}], "update_date": "2013-05-22", "authors_parsed": [["Bulian", "Jannis", ""], ["Hodkinson", "Ian", ""]]}, {"id": "1202.6148", "submitter": "Evgenij Thorstensen", "authors": "Peter Baumgartner and Evgenij Thorstensen", "title": "Instance Based Methods --- A Brief Overview", "comments": "Final publication availible at http://www.springerlink.com", "journal-ref": "KI - K\\\"unstliche Intelligenz 24(1):35--42, 2010", "doi": "10.1007/s13218-010-0002-x", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance-based methods are a specific class of methods for automated proof\nsearch in first-order logic. This article provides an overview of the major\nmethods in the area and discusses their properties and relations to the more\nestablished resolution methods. It also discusses some recent trends on\nrefinements and applications.\n  This overview is rather brief and informal, but we provide a comprehensive\nliterature list to follow-up on the details.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 08:36:27 GMT"}], "update_date": "2012-02-29", "authors_parsed": [["Baumgartner", "Peter", ""], ["Thorstensen", "Evgenij", ""]]}, {"id": "1202.6352", "submitter": "Matthias Baaz", "authors": "Matthias Baaz (Department of Discrete Mathematics and Geometry, TU\n  Vienna), Agata Ciabattoni (Department of Computer Languages, TU Vienna),\n  Christian G Ferm\\\"uller (Department of Computer Languages, TU Vienna)", "title": "Theorem proving for prenex G\\\"odel logic with Delta: checking validity\n  and unsatisfiability", "comments": "23 pages, accepted for LMCS (Logical Methods in Computer Science)", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 6,\n  2012) lmcs:833", "doi": "10.2168/LMCS-8(1:20)2012", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  G\\\"odel logic with the projection operator Delta (G_Delta) is an important\nmany-valued as well as intermediate logic. In contrast to classical logic, the\nvalidity and the satisfiability problems of G_Delta are not directly dual to\neach other. We nevertheless provide a uniform, computational treatment of both\nproblems for prenex formulas by describing appropriate translations into sets\nof order clauses that can be subjected to chaining resolution. For validity a\nversion of Herbrand's Theorem allows us to show the soundness of standard\nSkolemization. For satisfiability the translation involves a novel, extended\nSkolemization method.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 20:38:20 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2012 15:58:01 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Baaz", "Matthias", "", "Department of Discrete Mathematics and Geometry, TU\n  Vienna"], ["Ciabattoni", "Agata", "", "Department of Computer Languages, TU Vienna"], ["Ferm\u00fcller", "Christian G", "", "Department of Computer Languages, TU Vienna"]]}, {"id": "1202.6472", "submitter": "Frederic Blanqui", "authors": "Xiaomu Shi (LIAMA), Jean-Fran\\c{c}ois Monin (LIAMA, UJF), Frederic\n  Tuong (LIAMA), Fr\\'ed\\'eric Blanqui (LIAMA)", "title": "First steps towards the certification of an ARM simulator using Compcert", "comments": "First International Conference on Certified Programs and Proofs 7086\n  (2011)", "journal-ref": null, "doi": "10.1007/978-3-642-25379-9_25", "report-no": null, "categories": "cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simulation of Systems-on-Chip (SoC) is nowadays a hot topic because,\nbeyond providing many debugging facilities, it allows the development of\ndedicated software before the hardware is available. Low-consumption CPUs such\nas ARM play a central role in SoC. However, the effectiveness of simulation\ndepends on the faithfulness of the simulator. To this effect, we propose here\nto prove significant parts of such a simulator, SimSoC. Basically, on one hand,\nwe develop a Coq formal model of the ARM architecture while on the other hand,\nwe consider a version of the simulator including components written in\nCompcert-C. Then we prove that the simulation of ARM operations, according to\nCompcert-C formal semantics, conforms to the expected formal model of ARM. Size\nissues are partly dealt with using automatic generation of significant parts of\nthe Coq model and of SimSoC from the official textual definition of ARM.\nHowever, this is still a long-term project. We report here the current stage of\nour efforts and discuss in particular the use of Compcert-C in this framework.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 07:50:13 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Shi", "Xiaomu", "", "LIAMA"], ["Monin", "Jean-Fran\u00e7ois", "", "LIAMA, UJF"], ["Tuong", "Frederic", "", "LIAMA"], ["Blanqui", "Fr\u00e9d\u00e9ric", "", "LIAMA"]]}, {"id": "1202.6473", "submitter": "Frederic Blanqui", "authors": "Fr\\'ed\\'eric Blanqui (LIAMA), Adam Koprowski", "title": "CoLoR: a Coq library on well-founded rewrite relations and its\n  application to the automated verification of termination certificates", "comments": null, "journal-ref": "Mathematical Structures in Computer Science 21, 4 (2011) 827-859", "doi": "10.1017/S0960129511000120", "report-no": null, "categories": "cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Termination is an important property of programs; notably required for\nprograms formulated in proof assistants. It is a very active subject of\nresearch in the Turing-complete formalism of term rewriting systems, where many\nmethods and tools have been developed over the years to address this problem.\nEnsuring reliability of those tools is therefore an important issue. In this\npaper we present a library formalizing important results of the theory of\nwell-founded (rewrite) relations in the proof assistant Coq. We also present\nits application to the automated verification of termination certificates, as\nproduced by termination tools.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 07:52:05 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Blanqui", "Fr\u00e9d\u00e9ric", "", "LIAMA"], ["Koprowski", "Adam", ""]]}]